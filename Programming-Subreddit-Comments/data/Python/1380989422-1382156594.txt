Thanks for giving me the opportunity to advertize for my python module MoviePy, which I coded exactly for this purpose :) http://zulko.github.io/moviepy/ It is not perfect yet and definitely needs tester ! 
as the rest of the blogposts
Make sure to set http_proxy *and* https_proxy - it might be one of the two is downloading over https and the other over http.
pip install --proxy user:pass@yourproxyaddress:port
I use and really like PyCharm, but Sublime Text is really nice, too. Hah, I wish PyCharm had the flash and responsiveness of ST, or ST had the robust IDE of PyCharm.
This. I've experienced the same thing - both in Netbeans and PyCharm. It's actually one of the things that's making me consider getting a Mac if and when the new laptops come out.
Some may accuse you of leaving a useless comment, but I'm actually glad to have a crowdsourced content-filtering solution for mah reddit. I'm a lazy fuck...
Thanks! 
I have a lot of experience with ffmpeg. It is a great utility, but also a nightmare to deal with. There is so many codecs, parameters, version differences, bugs, etc. that wrapping it in a python library is very difficult, and would end up supporting a limited set of functionality. 
As the author of [another FFmpeg interface][pyav], I have to dispute your parenthesized claim that they are not faster for two reasons. One: They will not be faster if you treat them the same, and sometimes seek to an hour into a video by reading through 45GB of uncompressed data. I know you didn't actually do this, but it is the sort of solution that is sometimes necessary with such restraints. By having access to the library internals you can be so much more creative with those files in ways that won't result in Python doing the heavy lifting. Two: They **are** faster. See https://gist.github.com/mikeboers/6843684. [PyAV][pyav] is twice as fast as reading the pipe. [pyav]: https://github.com/mikeboers/PyAV
The example calls Python functions loaded from a resource and interpreted in real-time. If not immediately dynamic, it at least illustrates the concept.
Ok, I removed the claim. My point was more that if you need once to get some frames from a movie, linking to libav is a little overkill. However, I don't think your examples are really instructive, the times that you observe could be due to the opening of the process, the opeining of the pipe, to the loading of numpy, the fact that in one case you store the frames as Numpy arrays and in the other case you store them as PIL images... Have you tried to measure, for instance how long it takes to read 1000 frames with the two methods.
Good idea. Another difference is that I'm turning them into PIL images in one. Trying again with a 1920x1080 video with 2663 frames takes ~1:08s with the pipe (40fps), ~0:40 (67fps) with PyAV into PIL images, and ~0:51 (52fps) with PyAV into numpy arrays. So, much less dramatic of an increase, but it is still there. (I am running this multiple times so that the video is entire in the disk's cache (or however that works, I'm not much of a hardware person); there is no disk activity on subsequent runs). Don't get me wrong though: your original point is a great one. Linking to libav is also much more difficult due to the fact that you can have either ffmpeg or libav, and it is very hard to work with them exactly the same. The last VFX shop I was working pipeline at did a ton of manipulating video via pipes to/from ffmpeg. That is actually why I started this project, because we found it so limiting. 
The reason that PIL is faster is because it is using the buffer interface to share image data with the frames that PyAv is reading, so there isn't an extra copy of all of the data.
Maybe because it is on GPL?
I'm not familiar with PHP, python is more strict than PHP?
It's not so much Python that is strict; but more that PHP is quite forgiving - if that makes any sense!
What's your obsession with characterizing libraries as 'heavy'? 
The `ffmpeg` way to do it is to convert both videos to mpg, then $ cat video1.mpg video2.mpg &gt; concat.mpg and eventually convert it to a more suitable format.
I don't think I'd use "strict" in the same way you are. Python is more a fully functional programming language than PHP, but it's one of the least strict languages that are actually used by most standards of strictness. Python is weakly typed, both object oriented and functional, dynamic, and gives you open access to almost all it's guts with very little complaining. I wouldn't say python is more strict than PHP unless I was saying that python is more strictly a programming language than PHP.
Sorry my other comment wasn't helpful. This is the go to guide for python http://docs.python.org/2/tutorial/ Being on mac is not a problem at all for python. It's a very very platform agnostic language. http://learnpythonthehardway.org/ this is another very common python resource. It's more comprehensive than the one on the python site. I'd probably recommend this one for it's completeness, but honestly you'll be up and running regardless of which one you do.
Python is dynamic typed (like php) but also strong typed (php is weak typed): * https://wiki.python.org/moin/Why%20is%20Python%20a%20dynamic%20language%20and%20also%20a%20strongly%20typed%20language * http://en.wikipedia.org/wiki/Type_system#Static_and_dynamic_type_checking_in_practice
I didn't learn from it, I just took the tests and sped through some lessons and found I had missed a lot of stuff. Like arrays with negative indexes... who knew!?
[Learn Python the hard way](http://learnpythonthehardway.org/) is a good start like /u/SwiftSpear mentioned. If you know your web, have a look at [Flask](http://flask.pocoo.org/). It is a nice framework for many things. If you want something that will hold your hand along the way, have a look at [Django](https://www.djangoproject.com/).
www.programarcadegames.com in the graphics chapter.
Funny that you should ask that, as the project creator just spent the past couple of days making this a bit more clear in two all-new tutorials: http://leoeditor.com/intro.html You can read the tutorials without installing, and they don't take all that long to read (10 minutes or so?) if you're not working through them. I can boil it down to a few items though: - full API access to your outlines, meaning you can have a smalltalk/lisp-like homoiconic representation of your data *and* your code, where your data and code are both stored in nodes, and can be operated on by code - the ability to reorganize your code into infinite different views, by using clones. This allows a very literate-like approach to examining and writing your code. - nearly infinite untapped potential: the API is fully exposed to your outlines, meaning you can do some awesome things *within* the documents you're editing. I recently submitted the rss.py plugin, which turns Leo into an RSS feed reader... and it was one of the easiest things I've ever written. Mind you, I only started using Leo in February, and I'm already a dev. It's one of the easiest large open source programs to get involved in, and is such a joy to use (in my opinion). I know this is clear as mud, but I'm not the best at explaining these things. I suggest you revisit the home page -- it was updated literally 30 minutes ago to be more clear to potential users. Feel free to ask more questions, though!
It is pretty amazing :p To answer: 1) They're created dynamically by scripts, on a per-outline basis. There are ways to make prettier buttons, but the functionality is what most people are after. The whole system is themable, though, which is a recent addition. Here's a screenshot of the leo-dark-1 theme (like Sublime Text 2) that was recently added by a dev: https://plus.google.com/103097156557482112329/posts/6D9GPRCdXVh 2) The plugins are required to be bilingual, but this really ends up being a non-issue. Print statements are avoided (replaced with calls to g.es or g.trace), imports are handled on a per-case basis, and any bugs that pop up about python2/3 compatibility are quickly fixed by one of the devs -- so long as we get a report on LaunchPad! Feel free to ask more questions. I hope these answers helped! --&gt;Jake
looks like pyloris
Thanks for answering! Yeah, Kate handles #2 likewise. Whati never with #1, though: PyQt’s buttons are naively styled per default, one has to actually try to make them ugly. So why is that the case here?
I wouldn't know, to be honest. The button code came along before the Qt interface AFAIK, and then updated for PyQt, so perhaps it's a legacy thing? Prior to the PyQt4 interface, apparently Leo was on a Tk interface, and before that the whole thing was in C++ using god-knows-what. I'm new to the team -- just started using it in February, actually. It's already grown leaps and bounds in those 9 months, though -- and it's been in development since at least 1998 in one form or another. I think it might have something to do with looking uniform no matter which platform. I do know that the button color can be changed when you make them via a script. To be fair, though, I personally don't care much for aesthetics in my editors... I care about functionality :p I'm not the authority on this matter. Printing, markdown support, and rss feed support, along with documentation, however, is where I come in. :P **EDIT:** Just dug into the "create button" code. Looks like this is the culprit function: http://bazaar.launchpad.net/~leo-editor-team/leo-editor/trunk3/view/head:/leo/plugins/mod_scripting.py#L662 It appears to set a basic stylesheet with a default color. That most likely overrides the native stylesheet. I imagine that this was done so that different buttons could have different colors to allow for more immediately-visible differentiation -- reducing cognitive load in some cases. A lot of thought has been put into small things to make Leo more usable -- including many small details that make it run a bit away from the normal way of doing things. But despite it's less-than-flashy appearance, it really is a breeze to use once you realize that there are all these little hints scattered around the interface. Though, those are my $0.02. YMMV.
Actually, the latest research disagrees. Some educators gave tests to incoming CS students. They found that being able to grasp a few things, particularly recursion, had a HUGE correlation with whether the students would do well in the course or not (I've personally observed that recursion is one of the areas where lots of students tend to drop out of CS). These correlations were found even with different courses and teachers. The authors of the paper somewhat dejectedly pondering whether some people are just "hard-wired" for computer science or not and that nothing they do in intro to comp sci classes will be able to change that. 
I'm not a guru by any means but if you can load the pyOpenGL library you can use that to generate a cylinder and put it in a coordinate system to your liking. I've done it with Processing and OpenGL. OpenGL is easy to use once you get the hang of it. http://python-opengl-examples.blogspot.com/?m=1
"...except for languages like Pascal where you can't actually get anything done anyway." I spend lots of time arguing with Delphi developers about how Python is Pascal++ and how it's so much more powerful, yet easier, than Delphi/Pascal. I have to read through the most inane garbage in response (including the claims that type inference 'is impossible', automatic memory management is for lazy people, functional programming, design by contract, etc. are 'just fads') and then this morning there was this talk description for Delphi's Code Rage 8 online conference (online because there aren't enough developers to host it in the real world anymore): &gt;Functional Programming in Delphi XE5 &gt;This session demonstrates efficient usage of the latest language features for &gt;functional programming in Delphi XE5 such as unanimous methods, class &gt;helpers, and record helpers. &gt; &gt;Level: Advanced Note that "unanimous methods" was in the original announcement, and there are no functional programming capabilities in Delphi, and even iteration, which was added in 2005, in anemic and was never brought to many of the classes of the standard library, such as files or database queries. And apparently syntactic sugar has something to do with functional programming now. *smacks head* Anyway, your comment made my day as I prepare to attempt for probably the last time to convince my former Pascal brethren that the fat lady has sung. :-)
&gt;It might be possible for a minority of people who have never programmed before to &gt;pick up some decent programming skills just through an O'Reilly book and 3 hours &gt;a week of practice, As opposed to a teacher who reads out of the textbook and assigns three hours a week of homework? 
Thanks for the quick reply, what does "put it in a coordinate system to your liking" mean - does it equal "export to a file type of your choice" ?
Just [learn Django](http://djangoproject.com). Honestly it's documentation is just about the best out there. Then there are some wonderful other frameworks that you can explore after you get the lay of the land.
Even if there are classes with such little work, yes, there is a sometimes very large difference between unskilled people trying to pick up knowledge on their own and learning from an experienced tutor.
Some of the versions are broken. More info an how to work aroun it here: http://pythontesting.net/python/pip
I'd approach this by creating an N-sided approximation of a circle, and then rotating and translating copies into proper position along the line points. You are going to need to calculate a few things. First, you'll need to generate the points of an N-gon of radius R (probably N&gt;7, but you may want this to be proportional to R). You'll need to determine the angle made by three consecutive points so that you know the orientation of each circle you place. Lastly, each time you place another set of circle points, you'll need to connect them into edges and faces. Use two adjacent points on circle x-1 in conjunction with the same two points reversed on circle x to form each face. Hope that helps! 
I believe dynamic programming has a specific technical meaning. Try Wikipedia
How is this a compiler crash? You're REPL is hanging because you requested a very slow mathematical operation.
&gt; from what I understood -- to do blender python scripting we need to open blender first… Actually you don't. Blender can be automated running in headless (UI-less) mode by writing a batch script (see Blender's '-b' option). That'd still be cheating though :) Generating a cylinder mesh isn't exactly hard, depending on what 'passing though a set of points' means exactly.
Here's something I came across that will get you a PLG file dump of the object you create as well as give basic geometry creation. I have no idea how to translate the PLG into something else but I suppose you could create a parser to translate to obj or something. Good luck. http://rpm.pbone.net/index.php3/stat/4/idpl/21416105/dir/opensuse_12.x/com/perl-OpenGL-PLG-0.03-5.1.noarch.rpm.html
You shake hands with your mother with those fingers?
Ha! I just started with Python too, coming from PHP. My first stop was at [tutorial](http://docs.python.org/2/tutorial/index.html). Now I'm playing with [Bottle](http://bottlepy.org/) to create a REST api Next will be Flask, then Django I'm writing a lot of low level applications now. And it feels very comfy to write in Python instead of PHP I hope my road map could put you on some route too... 
I'm going to be in the same area of Python as you are soon so I'm trying to get a handle on OpenGL too. This is the library you want to use. http://assimp.sourceforge.net/ Here's the Python Library for it. https://github.com/assimp/assimp/tree/master/port/PyAssimp It can import and export all the cool kids. And Here's how to draw a cylinder in OpenGL http://www.opengl.org/discussion_boards/showthread.php/167115-Creating-cylinder But of coarse do a quick browse of this. http://math.hws.edu/bridgeman/courses/324/s06/doc/opengl.html Or there's http://www.cse.ohio-state.edu/~parent/classes/581/Lectures/10.HierarchicalHandout.pdf for a fast overview.
 &gt;Hi guys, Hi &gt;I'm a PHP developer by trade, quite experienced with PHP frameworks. I'm probably going to get hell for this but PHP barely passes as a programming language. Python is perhaps one of the easier programming languages to grasp, at least from the initial sit down with Python. Obviously everything you know about PHP goes out the window when you transition to Python. &gt;I feel like it's time to learn a new language - I'd ideally like a 'stricter' language that's perhaps less forgiving than PHP - a few people pointed at Python so here I am! Python is a full or complete language, it isn't extremely strict though. Ultimately if you are going to program for a living you need to learn multiple languages. Python is a fantastic scripting language to have in your bag of tricks. However formal education goes a long ways to understanding some of the concepts used when programming with something like Python. I'd strongly recommend learning a bit of C++ or C too. First it is good to understand a systems programming language. Second Python goes together with C like peanut butter and jelly. &gt;Are there any definitive guides or go-to places for starting up. Will be on Mac OS X if that helps. Eclipse.org and PyDev for a development environment is one possibility. In the past I've used XCode to do Python development but dropped it, I haven't tried this at all with the latest versions of XCode. Any serious Developer using a Mac will have XCode already installed just to get the developer tools and documentation. &gt;Any pointers would be greatly appreciated! There is a tremendous amount of free code out there. Some good some not so good, but reading the code of others can be informative. There will be disagreements here but I'd start learning on the Python 3.x series. The series has finally reached a fairly robust point with much of the library community converted. 
Read the Python.org tutorial first, then try another one. I like http://getpython3.com/diveintopython3/ but they're all fine. /r/learnpython is where you want to go next.
Apart from being easy, Useless must get around...
If you want an IDE, check out PyCharm If you want an editor, check out Sublime Text
dont know .I will check on monday, I installed it 2 months ago using apt-get. Its pip 1.0 . I shouldnt have installed using apt-get 
I used [PyWin](http://sourceforge.net/projects/pywin32/files/pywin32/Build%20218/) as my first IDE. But lately everyone has been excited about [Pycharm.](http://www.jetbrains.com/pycharm/download/) Either one will work, Pywin includes some handy windows libraries (if you want to make your computer beep at annoyingly high frequencies for example, or if you want to cheat a cookie clicker). Anything else you would need depends on what level of experience you have with programming.
may be u r right. I didnt set my https_proxy. Yes I didnt set my https proxy
Check this out; it converts XML to Jason! http://rochacbruno.com.br/xmltodict-python-module-that-makes-working-with-xml-feel-like-you-are-working-with-json/
Get a Mac. Use Eclipse with PyDev.
1. Buy Mac to blend in with the cool kids. 2. nuke hard drive, install linux. 3. ???? 4. Profit
Any decent text editor will do. On Windows, I use [Notepad++](http://notepad-plus-plus.org/). On Unix-like systems, I prefer Vim (which, by the way, has an *extremely* steep learning curve, and you'd probably prefer to learn one thing at a time).
Check out http://www.reddit.com/r/learnpython as well
Rice is offering a free University-level [Intro to Python course](https://www.coursera.org/course/interactivepython) through Coursera starting next week you might try. Also, I'm a Sublime Text fan for my text editor for Pyhton.
is this for perl only ? 
Eclipse and pydev is pretty good, if annoying and clunky sometimes. Debugger excellent. No reason why a mac is necessary though I do prefer Linux over windows for security and command line tools.
Preferably he'd say something like "If you try to learn on your own, either online or by using a course-book, make sure to take the online exam on LINK in order to ensure you've learned everything needed for the classes" rather than "it's impossible to learn programming without help" (note: it's not, however, you'll need to get challenges that makes your perspective wider, bitwise operations and such are not occurring naturally for quite a lot of Python beginners)
If it's a function shape I'd check the first and second differentiation of the function for critical points and see if the cylinder fits into those. I.e. whether relevant point + 1/2 length of the cylinder * linearisation of the function at the relevant point + 1/2 diameter of the cylinder * 1/ linearisation of the function at the relevant point is outside of the cylinder. same check for all 4 points in 2d. Get the extreme points of the cylinder and see if they fit into your tube definition.
The best editor is emacs, bar none.
PTVS http://pytools.codeplex.com/ 
JetBrains has a free version of Pycharm 3 now. Having used Eclipse, Komodo, etc. in the past, PyCharm feels great. http://www.jetbrains.com/pycharm/ 
Even if you'd like too use a more complete out of the box solution such as PyCharm, keep in mind that the best *editors* will still be vim and emacs, and both can be configured with autocomplete and all that jazz using plug-ins/scripts. If you're going to be a programmer I'd suggest you invest the time into one of then (or both) as they are universal as compared to something like PyCharm. 
sublime text is absolutely brilliant. I am doing a lot of python at the moment and whilst I have no doubt you can add a debugger on to it I am just using it as an editor but also you can run your scripts in it (ctrl + b). It's autocomplete and text highlighting style gives the nicest support I have ever seen and the way it lets you find/replace and edit multiple lines at once is unparalleled. It has me in the palm of its hand :o 
plus one to this - there are some great threads on learnpython to help you with online resources, books, and even folks who will help you with your code!
I started using vim with vimtutor and I was functional in half an hour. That was several years ago, and I continue to learn new things about vim, but you're right; it's possible to get started with vim relatively quickly. 
Fixed link: [vim learning curve is a myth](http://robots.thoughtbot.com/post/13164810557/the-vim-learning-curve-is-a-myth).
I really enjoy using Dreampie
Perhaps it is. Searching the googles gives me a few hits of Qt not doing so hot at emulating native style for windows.
I used PyCharm for a while, but it was slow as hell so I searched for another one and found Python Tools for Visual Studio. VS has always been a pretty potent and powerfull IDE so I tried it and it blew my mind. You should totally check it out, and for the "normal" developer its free. http://pytools.codeplex.com/
While I personally use vim a lot, I wouldn't say you need to learn emacs or vim to be a programmer. This is very elitist thinking. Vim is only worth it if your whole development environment is rather mouseless , have a lot of free time and really are motivated to learn it except of course if you have to ssh a lot into servers then it can be quite handy to be a fluent vim user. ;) I'd say go with a texteditor while learning the syntax, because a simple editor will force you to pay attention to the details of the syntax. After you feel rather fluent in the syntax go with PyCharm, Ninja-IDE or Spyder(Python2 only so far). Whatever floats your boat. :)
What I meant to say was that by default, the windows native styles aren't compiled... they need an external library installed or something. They have to be enabled with compile-time switches. I imagine that Riverbank didn't include those when building PyQt4. Or perhaps there's something else going on. Either way, this post isn't about the intricacies of Qt on Windows, it's about Python Editors for Linux.
`turtle` is a great module for beginners, especially children: it lets them view the results graphically rather than textually. When learning to write a loop, for example, seeing the little cursor going forward and turning left 4 times to draw a square is way more appealing than writing the lyrics of *99 bottles of beer on the wall*.
Obviously, you need basic knowledge like insert vs normal mode, how to quit, etc. After that, however, it's not nearly as difficult as you make it sound. A half hour of memorizing and experimenting with the mnemonics (not that hard, considering they're, well, mnemonic), and I was as set as a rookie with any text editor. Not comprehensive, but as you said, one thing at a time. 
I am trying to skip ahead to the oop section, but it won't let me, is it an issue with my browser?
The output would be a list of the coordinates of every point in all the placed circles, and another lost to hold 4-tuples of indexes into the point list. That reminds me, it would probably be easier to form quads instead of triangles. Most 3D software is totally cool with that, and modelers prefer them anyway. Take a look at the .obj format (very simplistic), then use your data to write the file! 
I use a plugin called [Sublimelinter](https://github.com/SublimeLinter/SublimeLinter), helps me write python that follows [PEP8](http://www.python.org/dev/peps/pep-0008/).
Don't know man, neither can i./ You can download though the source code of it from here http://www.pythonforrookies.org/sourceCode.html
Lectures after 2a haven't been loaded if you look at the source code. It states "Coming soon".
I think using Wakari / IPython NB is a great idea. So is graphical output. Maybe be able to load the site on an iPad, but as a requirement ... seems a little odd. I would find something that interests them and can be coded in 20 lines or less. * tweets on a map, http://matplotlib.org/basemap/users/examples.html * graphing (interesting) csv data * http://hci.stanford.edu/jheer/workshop/data/ * http://introcs.cs.princeton.edu/java/data/ * http://www.calvin.edu/~stob/data/ The content in http://en.wikipedia.org/wiki/Programming_Collective_Intelligence is excellent although the code should taken from improved versions hosted on github.
One thing that should be remembered: Math, English, physics, etc are not all taught at the same level. We gradually build on previous knowledge. So when you ask for a single activity which can be done by kids aged 12 -17, you are going down the wrong path. There is much more to programming than just writting code. Someone can learn all the syntax they want, and still be a terrible programmer. Computer science should cover. * Algorithms - Sorting, shortest path, searching, dynamic programming, trees etc. * Some algorithm topics are very advanced, while other are simple and with the right examples can be taught in context of almost anything. * Computer architecture. * This may be boring, but kids need to start learning that; not all computers are made equal. Without the proper hardware, somethings cannot be done, and some components have physical limits and present bottle necks. * Language/grammars * python is one of many languages. * teach them the syntax, and how it is similar to some and very different from others. And if you like, show everyone that once upon a time, all software was opensource, starting with punch cards. Until Xerox came along, many of the algorithms were shared, until they started to distribute only the binary files. Showing why programming is important is easy. The software industry is booming, and it has only just started. Software and computer code is EVERYWHERE. If kids like building, tinkering or 'hacking' (A hacker is someone who enjoys playful cleverness—not necessarily with computers.), NEED to know how to program. There are also kids who don't care. They just want to use a computer, like they use a car. This is fine, but I still think it is important for those kids to learn algorithms and logic. After everyone knows why they should learn, the next question is how. Ofcourse, we have to start at the basics. Since you are a math teacher, I would begin with by showing how to create a very simple calculator, and then make the calculator more complex. Find the roots of the following equations: y = X^2 y = -5x^4 +3x^3 -15 ... etc. Now we could take out a piece of paper, and write it all out, but what if the 'boss' comes back and tell you, he has made a mistake. The -5, in the second equation should have been +7. All the work done on paper is now useless. If we create a root-solver in python, we just specify the degree of the equation, and input the numbers, and it spits out the correct answer instantly. If you can show the kids that repetive tasks such as boring math can be removed from their lived by software, life will be real good. But also point out that if you only have to solve for y=X^2, once in a lifetime, the programming effort may not pay off. Is programming applicable to: * English? * Yes, spell checker, and grammar checkers * Art? * yes, Video games, music production, video production, fractal art, etc, * History? * maybe... * Math * this shouldn't even be a question. * See "R", "Octave", etc
Do you want to teach programming or do you want to tell people why being able to program can enrich their classes/lessons? I assume the latter because you can't do the former at all in 45 minutes. And if you do the latter then forget about point (3). You can think about how to implement this whole thing technically **after** you've whet their appetite. The really important and hard part here is point (2) or rather: how to find really good use cases where it actually makes sense to use programming? You should think about that very carefully. But it's not a question/problem that is related to Python in particular. The programming language and environment doesn't really matter. **TL;DR** You don't need technical help. You need sample problems where it makes sense to use programming to solve them.
Are there any stats on Python framework usage? Do the majority of Python developers use Django? Is Bottle similar to Slim/Silex PHP?
So 3 would be the right way forward - seems to be a lot of discussion re: 3 vs 2.7?
you mean 1a
Exactly my thinking - I enjoy PHP, but I want to broaden my horizons - and if I'm honest, I want to work with some real programming concepts and get quite deep into the theory rather than just knocking stuff together in PHP. A few people offline have pointed to PyCharm as an IDE, do you have any experience with it? I did have a tinker with XCode - but it didn't fit that well so I am keeping an eye out for alternatives.
The idea is to use it as much as you can. It is quite extensible and there are many enhancements. 90% of the time it is wonderful and all you need. For that final 10% you roll your own.
Oh, you want to extrude a circle along a spline. You might want to read up on the [Frenet frame](http://www.unchainedgeometry.com/jbloom/pdf/ref-frames.pdf) (PDF).
To be honest, (2) is where I am trying to focus. If I think about installing software then things like nodebox or processing come to mind, but I would prefer not to have people worry about installing something. I also don't see those kinds of things as having much application outside of a computer programming curriculum.
Great links! Thanks!
I don't see why you'd use N++ over gvim or something. It's losing 90% of the functionality.
Not anymore, neither in Python nor any other language. [The functionality was abused and removed.](http://blog.chromium.org/2012/12/no-more-silent-extension-installs.html)
oh damn, thanks anyway. 
Thanks but I'm a Mac user so that wouldn't work for me.
Any feedback would be really appreciated!
it kind of is, but i'd generally stick with [flask](https://github.com/mitsuhiko/flask) or browse some code on [requests](https://github.com/kennethreitz/requests) just for starters/general code
It doesn't matter which you learn first, you'll know both eventually. They're 99% identical. Here: in 2, use `print "Hello"` and in 3, use `print("Hello")`. You now know most of what you need to know to use both 2 and 3. :-) Just make a note of which version your tutorial expects you to use and make sure to use that yourself. Think of 2 vs. 3 this way: if you were learning English as a second language, would you want to learn American English first or British English? Well, it depends on where you live, what you plan to do, where your teacher is from, personal preference, etc. But at the end of your studies, would you be consider "fluent" in English if you knew what a "truck" is but not a "lorry" or about "colour" but not "color"? Obviously, a fluent English speaker will have a variety he/she is most familiar with, but ought to be able to adapt and use either British or American as the situation requires. So too, a good Python programmer ought to be able to use 2 or 3. I personally prefer 3 for my own projects, but my work projects are all in 2 at the moment because the software we're using was only ported to 3 in the last year or so. It's not hard to switch once you know the differences (and by far, the biggest difference is `print "Hello"` vs. `print("Hello")`).
[Editorial](http://omz-software.com/editorial/) is an iPad text editor app with built-in Python support. It may be a good way to make Python practical for students — pitch it as a way to automate everyday word processing tasks.
It is a small program but quite interesting to get started with. Here are a few things I would have done differently: * I do not think asking user to copy your script in /usr/bin or /usr/local/bin is common or desirable. chmod +x should be enough or just ask them to run it by invoking $ python alien.py [subreddit name]. If you want to support Windows as well, you might want to provide some [frozen binary](http://stackoverflow.com/questions/12339671/how-to-compile-python-script-to-binary-executable). * The command line usage is simple enough, but you could have use one of the different command line arguments parsing/usage display library to manage it. Check out [argparse](http://docs.python.org/2.7/library/argparse.html) if you want to expand your usage. * httplib is more than enough for this simple cases like this, but you might want to check out the [Requests](http://docs.python-requests.org/en/latest/index.html) library if you want to expand your use cases. I would have use Requests. * I would have put your time formatting section (lines 48 to 61) in a separate function. I might have used a different strategy for formatting like using one of those datetime library like [Arrow](http://crsmithdev.com/arrow/). * I would have put the formatting section (line 70 to 79) in a separate function. Anyway, it is still a pretty good start. Congratulations!
Err... Yeah. Perhaps poor wording on my part. I realize that my post isn't about dynamic algorithms and the like (http://en.wikipedia.org/wiki/Dynamic_programming). I never actually considered that the title may have been interpreted that way. Oops! It seemed to flow a bit better than "Using a Dynamic Programming Language such as Python from within C#". I'll pay closer attention next time. Thanks!
We use proxychains with pip when needed. Likehttp://chasemp.github.io/2012/02/18/proxychains/
I've taken this. The teachers are a lot of fun and much more involved than other online classes I've taken. Actually, the whole class was fun. You have weekly projects where you make a game based on certain minimum requirements. You can go as far beyond those requirements as you want and it's really interesting to see the amazing things other people write. 
I am in. Forgot that it started today. It should be fun couple of months. 
How does it compare to edx one?
I thought it started tomorrow. I can't wait to get started. 
ST3 is a great tool. While I've never experienced your error exactly, I'd suggest making sure that your system path has Python on it. Just so you know, Sublime Text isn't connected to stdin, so you won't be able to use input(), raw_input(), ect. I'd check out the plugin SublimeREPL if you're going to be using sublime full time. :)
Any relatively new or completely new python users should take this course. I started with Python around January, and took this course during the spring. Which helped me a lot. While most of the projects will be pretty easy for anyone with preexisting experience, it's helpful to have some concepts explained, even though you know how to use them. 
I've taken the Coursera, Udacity and Edx intro classes. I took Udacity's first, then I took Coursera and Edx at the same time. Here's a short summary of my experiences with each. *** **Udacity** I took this class first so it might affect how I view the other classes. When I started, I had no knowledge of programming. I didn't understand variables, types, data structures, loops, etc. I didn't even know what a function was. The class was 'work at your own pace', which was ideal for a total beginner. I could spend as much time as it took to grasp new concepts. The format is a long playlist of short videos, perhaps 1-5 minutes each. At the end of each video, you would have to either answer a short question, or write some short code to solve a problem. Over the course of the class, you are taking the concepts you learn and using them to build a web crawler. Each unit, you add a little more to the program and it's basically one long project. Because I didn't take this class "live" the forums were not very active and in fact, I don't think the instructors had even logged on in several months. However, the forums were well laid out, and the previous group of students had asked and answered every question I had. My criticism of this class is it's quizzes. Most of the questions asked you to write a function that would solve 3-5 test cases. The problem with this is you could write sloppy code, write code that answers the test cases correctly but is actually wrong, or just cheat and have the function return the answer the grader is looking for. I found that this system requires a lot of self motivation. Often, I would spend a lot of time working on a solution before finally passing the test cases, only to find that my solution was actually wrong. It was quite demotivating sometimes to spend an hour on a problem, get excited that you finally passed the test, then find out that you missed the entire concept of the question. Then, you have to make yourself go back, re watch the lectures, re watch the solutions, read the forums, etc. *** **Coursera** I feel like the Coursera class taught the least amount of the 3. If you want a solid grasp of programming/python basics, I think the other 2 classes do a better job. However, Coursera was the most enjoyable by far. Instead of watching 'boring' lectures and reading a textbook, you jump right in and start making simple yet interesting games. The class format was like this: Each week, a new series of videos are posted, I think about 4 or 5 videos 15 minutes each. There is a short quiz covering exactly what is in the videos. You are given a project to build. Each step of the project and the requirements are clearly laid out. Everything is done in an online interpreter that saves and runs your program in the browser. There is no need to download or install python at all. At the start of each new week, you will grade your classmate's projects. You are given a check list of requirements the game must meet. It doesn't matter how the program is written or looks, as long as it works. You grade 5 projects and then grade your own. The great thing about this, is you get to see other ways to solve the same problem, as well as see what those who went beyond the requirements did. Personally, it also made me focus on writing readable code. Their forums were well laid out, very active and had constant participation from the instructors. These guys really enjoy what they do and it shows. *** **Edx** By far, the hardest of the 3 classes, but I feel like it gave the most solid instruction. Once I was able to understand and pass a unit, so many things became clearer about Python and programming. The class moves at a faster pace and goes into more depth than the other classes. At times, it was even stressful. Also, while I certainly think the instructors of the Udacity and Coursera courses are well qualified and knowledgeable, the MIT instructors seemed like a level or 2 above them. Just my opinion, maybe it's how they presented themselves, idk. The format of the class is like a mix of both Udacity and Coursera. You watch a video playlist but the videos are longer and there are only about 3-4 each week. After the videos, you would have to answer a series of quizzes that could be quite challenging. There would also be some short challenges where you write some code in the browser by an automatic grader similar to Udacity's. However, there were far more test cases and the grader was much more in depth. It did a pretty good job of preventing you from being sloppy or cheating, and it gave very good feedback. You could see where you went wrong and edit your code accordingly. There would also be a weekly assignment that involved downloading and editing/creating some programs. I found these projects fascinating, especially the modeling projects. (Example:Simulating the Spread of Disease and Virus Population Dynamics, Simulating robots). These projects were graded by the automatic graders also. The class also has 2 midterms and a Final Exam. (see [picture](http://i.imgur.com/EiOmJ4t.jpg)) Edx had some problems when I took the class. I think they had one person writing all of the automatic graders and handling the forums, and that person got sick. So, the last 2 weeks were actually just videos. I don't remember getting any other projects which is too bad since they were really getting interesting. There were also several complaints that the class was too hard, but I think this is because people were expecting to be hand held through everything. You definitely need to read the provided textbook and even read the Python docs to be able to keep up. My main criticism of the class is the forums. They had some awful layout that was difficult to navigate or follow topics. In fact, the top threads on that forum were people complaining about the forum. *** **TL;DR** http://i.imgur.com/EiOmJ4t.jpg **Udacity** Good for total beginners. Teaches the very basics. Class project is building a web crawler. Self-paced. **Coursera** Good for beginners. Teaches the basics enough to complete projects. Weekly project is to build a game. **Edx** Good for those who already have been exposed to the basics or those who are very self motivated. Goes more in depth, touches on OOP and modeling/statistics. Challenging but thorough.
Wow, awesome post! Thanks or so much, sounds like edx will be the course for me, as it gets into statistics and numerical analysis.
OK, so it should have been called dynamic code execution. Dynamic programming sounds incredibly dull anyway.
Thank you very much for your advice. I will look into those things you mentioned. So far it's been a lot of fun to do it in Python!
Thanks for taking the time to write this.
Thanks for taking the time to write this.
Wow, that's one awesomely misinformed article. I especially liked this bit: Also it’s weak in terms of security since its open source, all people can see the source code I knew it that Stallman was anti-privacy and anti-security!
I am really surprised that LiClipse is not a free software.
Op here. Great comment. I have also taking Udacity. Well, I'm currently taking it, and I have put it on hold for this Coursera course. So far, Udacity has been pretty bad. I have had previous experience with Python, and I would say I'm approaching the stage of intermediate. But, I thought Udacity's course was badly taught and I have not learned very much. I am over half way though the course. I have really high expectations for edX courses. Thanks for your responses! I look forward to Coursera and also edX eventually!
http://www.reddit.com/r/Python/comments/1n9iow/a_billion_rows_per_second_metaprogramming_python/
Make sure python is in your PATH environment variable. And just an opinion: ST gets way too much credit from its fanboys. It's nothing great from my experience.
I can't use the Unix shell from gvim in Windows, so it feels pointless. Yes, I could use Cygwin, but it's slow as shit on a stick. I don't develop much on Windows anyway, so I really just need a simple, no-bullshit option anyway.
[OT] why the hate for scribd? 
Python 3 streams can even be used in Python 2: import io input = io.open("input.txt", "rt", encoding="utf-16") output = io.open("output.txt", "wt", encoding="utf-8") 
Not having used it myself but this [BLOG post](http://www.kartikkumar.com/spyder-matlab-for-python/) had good things to say.
&gt; if you've discovered an error (which is easily possible as I've just learned about this stuff) i, for one, love tutorials written by neophytes. 
Spyder is just an IDE for Python/iPython (a front-end). It's a very good IDE that is easily approachable and has many quality-of-life features, like on-the-fly code analysis to tell you if you goofed, and the ability to restart the interactive Python console if you indeed goofed (which would otherwise crash IDEs like PyScripter), but I don't think it bears any comparison to Matlab since that is a language unto itself with lots of built-in math/statistics features. These features are available in Python as separate libraries, however. 
Not in the philosophical sense, but in the sense that I can read the source code when programming and (especially) debugging, it matters immensely. 
Why does the font look like crap?
Yes, because I can use it just about everywhere. I don't like to invest a lot of time learning platform-specific tools. That's why Perl, Python and C are my strongest languages.
The, comma, completely, changes, the, meaning, of, that, question. :) I usually tell people to make tetris. :)
python was my first taste of programming, and i'm very interested in continuing to learn. i'm hoping this course can show me new places i can go with my knowledge of python; i've had a hard time progressing since completing the basic tutorials (learn python the hard way and codecademy).
Agreed, although an IDE like spyder is usually used by folks who have installed the libraries that turn python into a real tool in this arena. When I have people try something like this, I usually point them to the Anaconda python distribution, pythonxy, EPD or one of the other scientific python distributions - which makes the fact that the libraries are not installed by default somewhat moot.
Hm, could you upload a screenshot? Are you using Chrome on Windows? They have a terrible webfont rendering bug. I don't usually work on Windows, so it's hard for me to fix, but I'll try :)
Ha! I didn't even see that. That's what I suggest to people who want to make games, actually. I point them to an 'easy' game and tell them to copy it exactly. It's amazing how many people realize that maybe making games isn't as easy as they thought.
Sublime is great when I want to edit any kind of file. Pycharm is what I use for Python development. They're both great programs and you should use both as appropriate.
I would suggest installing pythonxy or winpython (winpython is the portable version of pythonxy), which includes spyder and a lot of great libraries to mimic Matlab like matplotlib and numpy.
I used to code with Spider a lot, but then I switched to the IPython notebook, which I think is more agreable to use for scientific/technical programming. However if you are going for a large project (say, a module with 1000 lines of code) then spider might be more adapted.
I wouldn't advise it. The edX course alone demands 12 hours a week. What you should do, and I'm doing this for myself, is take the edX course the next time which is this coming February 4th. This works because the Coursera class ends sometime in December and that way you will have enough time to fully complete the Coursera course without other deadlines to worry about.
There's nothing to stop you using both - writing top level analyses in the notebook, and moving code to a module in Spyder when you want to reuse it. There are also plans for future integration, so that you can open a notebook inside Spyder.
After over fifteen years as a hard core matlab computational scientist, i made the switch to python. Just install what you need and use pydev/eclipse. It pales in comparison to the matlab IDE, but it gets the job done.
Doesn't matter really, but it's usually put at the end of the file.
I think Wakari is a great idea. One advantage of using this for a demo is that with 5 minutes to go you can publish the Notebook that you worked on to a public URL and then email out the link so everyone can open it on their IPad
(*Disclaimer*: I'm an Spyder dev) One of the main goals of Spyder is to make it easy the transition to Scientific Python to Matlab users. Spyder is not as polished as Matlab but all in all I think it makes that transition quite pleasant by offering a similar interface. As others have pointed out, Spyder is just one entry point to use all the great scientific python libraries out there (the others being Canopy and the IPython notebook), so it's better for you to install a scientific python distribution to have something really close to Matlab (in terms of graphical interface and programming possibilities).
I am already using REPL and Python is in my PATH as well. 
I have already made sure that Python is in my path. Is it worth it for me to begin learnin how to use a fully featured IDE?
People here are recommending NLTK for the language-processing piece of things. You might be interested in [TextBlob](https://github.com/sloria/TextBlob), a python project I remember seeing on github which is a wrapper around NTLK and provides easy sentiment analysis.
http://imgur.com/BwvYUyQ chrome on windows. its slightly annoying to read.
Frankly, Spyder is great as a Python IDE but the PyCharm Community Edition is the better IDE. Personally, I am not much of a fan of IDEs for Python. I prefer a good shell (iPython) and a good text editor (Emacs). An IDE is just not needed as much when you have such a good REPL. Still, if you want to use an IDE, particularly for big projects, I'd prefer PyCharm to Spyder. If your only goal is maximum Matlab compatibility though, Spyder might fit the bill. While PyCharm might still be the better Python IDE overall, Spyder is somewhat closer to Matlab. 
For a more advanced GPU accelerated tutorial: http://deeplearning.net/tutorial/mlp.html
If you like winpython, you may also like Anaconda python distribution. 
I'm working on a research project at my university which should make this possible. The main focus is converting data points into tangible/printable 3D statistics. It'll be in a form of a Python library which generates code for different backends. At first I'll only support OpenSCAD, which in turn can generate STL files and other formats. A first prototype should be finished in 1-2 months.
FYI the [PyML](http://pyml.sourceforge.net/) package is specifically built for doing machine learning in Python.
For the third time, most articles are not deleted due to the subject not being notable, but rather for the article making no claim on notability. Wikipedia has a very clearly defined set of rules as to what is needed on this front (as decided by consensus among the editors), and if you don't follow it they will delete it. There is always at least a small amount of subjectivity in any decision, but I don't see how you can claim this is purely subjective. It's as if you write code with 3-space indentation, 300-character lines, and spaces between function calls and their arguments and then say someone is being subjective when they say you're not following PEP8. They're not stating your code is ugly (well, maybe they are), but rather that it's not following a defined set of rules. You may also be confused about Wikipedia's goals. One of the project scopes is to [not be a collection of all information](https://en.wikipedia.org/wiki/Wikipedia:Not#Wikipedia_is_not_an_indiscriminate_collection_of_information). Just because information exists does not mean it should be on Wikipedia, nor does something not being suitable for Wikipedia mean it should not exist elsewhere. As with any other free content source, you are free [to fork it](https://en.wikipedia.org/wiki/Citizendium) to lead in a different path.
And there's also http://scikit-learn.org/.
Thank you! :) Much appreciated.
&gt;windows I think I found your problem. I kid, I kid. Someone was bound to make the joke, though =)
Creator here. Would love to answer any questions if you have them.
Neat :)
Instead of busy-waiting with 'pass', use the wait() method on threading.Event
Awesome idea, looking forward to trying it out!
Thanks for the tip! I've signed up now as well. Ran through Python the Hard Way last year and I've been working on different projects off an on ever since. Hope this gives me a better foundation now that I'm used to the language. Pretty cool opportunity, really it feels just like a college course.
A. maz. ing. Miss you man.
I was going to make the same comment but looking at the implementation of the threading module it seems that `wait()` just polls is_set anyway. I'd still favor the wait method but being able to control the poll interval is certainly good.
Ummm wut? 
thanks ! I fixed it.
Got it. Thanks!
You can double-click the line on Spyder and it has a graphical front-end for pdb. IMO it's not as smooth, mainly because of awkward hotkeys, but works.
I just recently switched from text editors and terminals to PyCharm and I doubt I'll ever switch back.
This is an XML etree reference I made for myself https://github.com/c4collins/python-standard-library-examples/blob/master/7.6-xml.etree.ElementTree.py
text
I'm currently transitioning from Matlab to SciPy. I'm going to an open source platform because I need my scripts to run for days and days and I use and external server to do it for me. I'm no stranger to programming and I knew the basics of Python, but I must say the transitions is harder than I had thought. Most of the problems came with Pandas, a data structure module. Pandas is way more advanced than anything available in Matlab, but it takes time to get to know the basics. However, if you're serious about trying something different, SciPy is the way to go. The number of things you can do is enormous. Pandas is great for handling complex data. Python is easy to learn and easy to understand, just take some time to get to know Python, then NumPy and Pandas, and then SciPy. Spyder should feel 'homely' for Matlab users, but I prefer iPython Notebook. The idea is you type a block of code, run it, check the results (or errors) and continue to the next block. If you do a lot of plotting, for instance, all scripts, plots and results are printed in one screen, just scroll up and down to see all your work. I really prefer this over the tabbed interface in Matlab/Spyder.
Have you thought about using this to do onsite-optimization? It seems to be a cool way to visualize usability data directly on the site itself. 
This looks awesome. Thanks! 
Awesome! Keep up the good work.
Awesome! By the time I thought to look back to check for a sleep call I was too far from my laptop to care but that's really good to know :)
Looks good, like the author I've always been confused by the myriad of built in (yet incomplete) time/date Python libraries. Does this utilize any of them under the hood, or is it basically from scratch? One thing I'm a bit hesitant about is that the `get()` method seems overly flexible, to the point where it might end up parsing something it shouldn't instead of raising an error. Hopefully this isn't a practical concern. Also does this implement its own time delta class? If I subtract two `Arrow` objects do I get another `Arrow` or a Python `timedelta` object?
Thanks. From the stdlib it uses all the standard ones (datetime, time, calendar, etc.). The only 3rd-party library currently being used in Arrow is dateutil (largely for relativedeltas and timezone manipulation).
I know it's not the most popular opinion, but FP is only that good in Python. If you want real FP, go with Haskell or whatever other language that has an insanely complicated compiler and a type system and whatnot. The main advantage of FP in that case is that it scales like crazy. Haskell can run the same code on a single thread or on a cluster of machines, and it'll scale almost linearly. Python won't. You can still use a lot of `functools` and [fn.py](https://github.com/kachayev/fn.py) goodness in your imperative code, or even write purely functional code for educational reasons, but to get the real advantages of FP you'll need to go with a purely functional language.
Can you explain a bit more? I'm not quite sure what you're suggesting. 
&gt; The main advantage of FP in that case is that it scales like crazy. Haskell can run the same code on a single thread or on a cluster of machines. This is pretty much outright false.
I see no reason whatsoever to use Sublime Text over PyCharm. Even if you want to have ipython or something open in a separate terminal window, just using PyCharm as an editor has more features with less setup. If you want to go the really minimalist route, I'd say vim is better, because touch-typing and navigating is faster in vim than Sublime Text.
&gt; the manager came in one day and decided all code must have alphabetically sorted imports. I prefer to sort imports in 3 sections, each alphabetized: # core imports # 3rd party imports # local imports 
The problem with FP in Python is not the nitty-gritty of the technical implementation - that part could be fixed, because unlike JavaScript, Python does not contain any show stoppers in its language specification; the GIL is an implementation detail of the reference implementation, but not all Python implementations use it, and it is not necessary for being a correct Python implementation. Further, functional programming has a reputation of scaling well, but this has nothing to do with the technical side of things: functional programming is just a paradigm that is very suitable for writing concurrent and parallel code. The actual problem is that there are a few things about Python's semantics and syntax that make serious functional programming awkward. The most famous example is the one-line lambda limitation, which is often seen as a direct consequence of the whitespace-as-syntax design decision, but the root cause is actually much deeper: The statement/expression boundary. Python makes a very strong distinction between these two, and a lambda can only contain one expression - but even though expressions can (and often do) have side effects, it is not possible to chain them together in a do-block fashion. Typical functional programming languages usually just consider *everything* an expression, and they provide a way to chain them together sequentially, such as `progn` in many Lisps, or certain Monads in Haskell. This means that while we have first-class functions and lambdas in Python, they lack the full power that their brethren in Lisp, Haskell, Erlang, and even JavaScript, provide. But there's more: Python is imperative at heart, and mutable state is ingrained into most of its data structures. There is no way to enforce immutability in a consistent, reliable and idiomatic way; worse yet, Python thoroughly subscribing to dynamic typing means that mutability travels with values, not with variables - tuples are immutable, but the variables that hold them are not. By contrast, functional programming makes a big point of purity and immutable data structures - so much that Haskell, for example, doesn't provide mutable variables *at all*. Yes, you *can* do functional programming in Python, but if you really go all the way and apply FP patterns everywhere, the resulting code is going to be a completely un-pythonic mess.
Also, because of how Python works, there is limit on recursion depth (and recursion is important in FP). Maybe go with something like this: Functional programming in Scala: https://class.coursera.org/progfun-003 From what I saw until now, it really focuses on FP and not on Scala, only tiny subset of Scala is used to explain functional concepts.
Oh wow, this is excellent, thank you :)
This is indeed how isort sorts: # stdlib (aka core) # third-party # project level (aka local) 
Its like Requests of dates.
I need to grab the midpoint of a line and make it Cyan. I cant do this with the provided odd expression.
&gt; unlike JavaScript, Python does not contain any show stoppers in its language specification What show-stoppers are those, out of curiosity? 
This looks great! Can't wait to refactor some code.
lobotomized lambdas for one
Very much so. In fact, Kenneth Reitz (author of Requests) mentioned dates &amp; times in this presentation: https://speakerdeck.com/kennethreitz/python-for-humans, which I happened to read while looking for something to do for a Python project.
Just yesterday I was getting frustrated with dealing with date code. Thanks a bunch for this, it's going to save me a bunch of time. Edit: One small quibble. Calling arrow.get(None) should probably throw an exception, not return the current time. There are all sorts of situations where that could get hairy.
The whole `get()` method kinda worries me a bit, given how flexible it is.
There is some pandas stuff I guess, but this is a very poor coverage of NumPy and SciPy
re: the .get() method, yes it is intended to be flexible, but less so than, say, the .parse() method from dateutil. The cases for how it handles what combinations of inputs are pretty minimal, and I doubt I'll even consider adding anything else to it, ever. So far, I have not personally had, nor ever heard of, anyone having issues due to it being too flexible. Additionally, all the functionality provided in .get() is really just proxied from other parts of Arrow (factory methods on the Arrow class, calls to the parser, etc.) so if you're concerned about that, a quick look at the source should point you to the right method to use that will accept ONLY much more narrow inputs. Arrow does not implement its own timedelta, and will return a timedelta if you're doing subtraction. This is to keep it in compatibility with the datetime interface.
There might be more, but I can see a potential issue with these two cases: &gt;&gt;&gt; arrow.get('1367900664') &lt;Arrow [2013-05-07T04:24:24+00:00]&gt; &gt;&gt;&gt; arrow.get('2013-09-30T15:34:00.000-07:00') &lt;Arrow [2013-09-30T15:34:00-07:00]&gt; If for some reason you passed `get` a string like '2013' (as a result of mis-parsing a ISO-8601 date, or corrupt data, for example), Arrow would treat '2013' as a timestamp instead of raising an exception. Perhaps you should require an int/float when using `get()` with a timestamp, and not allow strings?
Awesome! Date/time handling in Python has been a huge problem for a very, very long time. I was quite surprised that nothing was done for this during the 2 -&gt; 3 break. In the past I also tried making date/time handling better in Python. You might find some of my work interesting, but I think we cover a lot of the same ground. My project is here: [https://github.com/danielgtaylor/paodate](https://github.com/danielgtaylor/paodate) It's been used successfully in production in a few places, and made a bunch of invoice handling and processing code much, much easier to write. I'm really happy to see your project is trying to do the same thing and use Moment.js as inspiration. I do a lot of Node.js stuff these days and absolutely love Moment.js. One thing I will say is that for my invoice handling case the ability to get tuples representing the week or month or year is insanely useful. Also, it was really nice to be able to easily get e.g. the total number of hours a time delta represents, which I don't think your library provides (it is easy to calculate yourself however). Anyway very cool and keep up the awesome work! Edit: Oh it looks like you can get tuples for the month/year/etc with your time spans and ranges. Very cool!
In what sense does JavaScript have lobotomized lambdas? 
I'm still a noob but for running command line arguments you should look into the subprocess module.
As someone who recently started a project reliant on date/time handling, thanks so much for doing this! Between this and Pandas I'll be all set.
I've personally had at least one case where it was super-convenient to recognize timestamp strings, so that will likely not change unless issues arise. Again, if the flexibility / ambiguity of .get is dangerous in your particular situation, it's easy to call methods to only parse ISO strings, or only parse integer / floating-point timestamps.
You're welcome! I've been using it on production apis / distributed systems for a long time now and it's definitely made life easier for me too.
I had to use this book so I think I can help. When you call the getCenter() function, it returns the object, not its coordinates. So, when you say p1 = line.getCenter(), p1 becomes a point object itself. So when you say print(p1), the console just looks at it and returns the object and its memory address. If you're trying to find the points coords, you need to call the attributes using the get functions: getX() and getY(). But, more simply, you should be able to operate on the point using the library functions setFill() without worrying about the coords. remember to use the draw() function to update the pixel.
I concur. A table like this would help folks just finding the library understand why it is so helpful.
Thanks (both) for the suggestion, I agree that this would help to further call out why it should be used.
datetime works fine already.
.... Watson Really.
Can't tell if sarcastic - these kinds of "tutorials" are helpful for me seeing how the latest generation of programmers perceive things.
Strange, but remember, calling .get() with a single string argument will attempt to parse it as an ISO-8601-formatted string...there are some that aren't recognized yet (such as those which involve week numbers, which actually are valid ISO-8601 strings). It's possible that the parser might give you something for a different kind of string. This is also the first release that offers that, so I'll be improving / adjusting the behavior as needed.
Sure it works, but it's incomplete and could be a lot easier to use.
&gt; The most famous example is the one-line lambda limitation, which is often seen as a direct consequence of the whitespace-as-syntax design decision, but the root cause is actually much deeper: The statement/expression boundary. Python makes a very strong distinction between these two, and a lambda can only contain one expression - but even though expressions can (and often do) have side effects, it is not possible to chain them together in a do-block fashion. * lambda functions in Python that span more than one line must be wrapped in parentheses * lambda functions have no `__name__` or `__doc__` strings * many style guides discourage multi-line lambdas and nested list comprehensions, because they are not maintanable &gt; Typical functional programming languages usually just consider everything an expression, and they provide a way to chain them together sequentially, such as progn in many Lisps, or certain Monads in Haskell. * https://github.com/logpy/logpy * https://pypi.python.org/pypi/pyDatalog * http://docs.python.org/2/library/ast.html &gt; functional programming is just a paradigm that is very suitable for writing concurrent and parallel code. * http://docs.python.org/2/howto/functional.html * http://docs.python.org/2/library/functools.html * http://docs.python.org/2/library/itertools.html &gt; There is no way to enforce immutability in a consistent, reliable and idiomatic way * `str`s, `unicode`s, and `tuple`s are immutable [*](http://docs.python.org/2/reference/datamodel.html#the-standard-type-hierarchy) * define a [`@property`](http://docs.python.org/2/library/functions.html#property) getter without a setter. * http://doc.pypy.org/en/latest/project-ideas.html#stm-software-transactional-memory ([EDIT] http://www.reddit.com/r/Python/comments/1fq3j1/pypy_stm_on_the_drawing_board/) &gt; Yes, you can do functional programming in Python, but if you really go all the way and apply FP patterns everywhere, the resulting code is going to be a completely un-pythonic mess. Why doesn't everyone like my macros? * http://docs.python.org/3/library/functools.html#functools.reduce * http://docs.python.org/2/library/collections.html#collections-abstract-base-classes * http://docs.zope.org/zope.interface/ 
Advantages and disadvantages - GUI toolkits: - PyQt - Good for building GUIs, powerful system, looks quite native on all platforms - Tkinter - Less installation hassle, because it comes with Python, but looks quite ugly Visualisation: - matplotlib - the most popular and well supported 2d plotting interface - pygame - not designed for scientific visualisation, but it probably supports live updating visualisations better than mpl. Popular. - Chaco - 2D plotting with apparently better support for live updating than matplotlib. Haven't tried it. There are also various 3D capable visualisation tools built on OpenGL, but I don't know much about them.
great idea for a tutorial... but this is not a tutorial. this is just one barely-explained example. 
Agreed, although I will say that the Pandas portion is very good. I honestly think this cheat-sheet should be split up into three sheets: numpy &amp; scipy, pandas, and Quandl.
I thi.k using this with pandas will help. Pandas datetime can be very I.compatible with datetime modules.
You are a correct noob. 
Matplotlib is a great library, but if you're going to use it for lots of figures, it has a huge overhead. However, if you clear out your figure object, you can cut runtime by ~70%. The interface sucks though.
Awesome! Will have to play with this more.
Thanks for the warning, I just started the project so I haven't seen any incompatibilities yet but I'll keep a look out for them.
* http://www.reddit.com/r/statistics/comments/1kxwuq/do_you_have_any_ideas_for_teaching_intro_stat/#cbua9qe * http://www.reddit.com/r/Python/comments/1gsxcb/python_graphingchart_toolslibraries/#canksc8 * http://www.reddit.com/r/Python/comments/1i573f/my_76_year_old_meteorology_professor_wants_to_try/ http://matplotlib.org/users/whats_new.html#pyqt4-pyside-and-ipython (/r/ipython sidebar)
I was watching Sherlock Holmes at the time I started writing it :P
I recently converted my time critical stuff (continuously updating plots in a gui for an external data recording peripheral) to pyqtgraph, which is designed for low overhead, and I've been very happy with it. Matplotlib can still make prettier graphs, but if you want things that can update in real time, you should look at pyqtgraph.
IBM's Watson sort of owns that namespace.. It's a bit like calling your project Yahoo
The date and time handling has been my bane in Python. It seems like everytime I need to go to or from a timestamp, I make the same mistakes. I'd like to kiss you on the mouth for this. 
You can lose hours in the cesspool that is subprocess. Envoy is far better. So is Sh, though it's much different.
http://matplotlib.org/users/whats_new.html#webagg-backend
subprocess.call(cmd,shell=True) or subprocess.check_output(cmd,shell=True) haven't steered me wrong. 
maybe im being naive here but how and where do you store the json files so that python "knows" where to grab them?
They did add a timestamp method to the datetime object in python 3, which is nice. 
What you are looking for is called WARGames. But its a movie not a book. Honestly it will not teach you much.... I reccomnd thenewboston videos (he is a man who lives in Boston and he does good tutorials on computers). If that helped you please rate up or even give me Reddit gold :-) 
No need for the colon but I will be sharing your Awesome post with a friend or two! We are starting our own company so this will be really handy. Thank you
.get() still has no documentation on what I can stick into the format argument for date parsing. Is there a standard I don't know of?
Braindead? With first-class functions, multi-line lambdas don't make sense. They're also unreadable. Delphi didn't listen despite having first-class functions; now they have beautiful code like this: lg.Sort(TIntegerComparer.Construct( function (const L, R: integer): integer begin result := R - L; end ));
&gt; With first-class functions, multi-line lambdas don't make sense. That's just plain wrong. First off, lambdas can *only* exist when the language supports first class functions. Second, lambdas wouldn't have to be multiline if a) Python supported statements in lambdas and b) Python didn't require some statements to be multiline. And third, if you want to make some_dict['fn'] a function, you shoudn't have to come up with the name for the function, because "some_dict['fn']" already *is* a name for all intents and purposes. Same for passing anonymous functions as arguments, the name of argument *is* their name.
No, that's not it. This was an actual interview challenge that a guy posted.
[Here is](http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python/1594484#1594484) a slightly better (albeit, significantly longer) explanation of creating and using decorators in Python.
Cheers to you both, speed is fairly important to me for this, so it's good to know matplotlib has overhead. Thanks for the alternative though!
3d isn't an issue for me at all, I basically just need something that can do this: http://www.bitstorm.org/gameoflife/screenshots/winxp.png sort of thing The key features I'm worried about are interacting with that grid by clicking on it, and the speed of the thing. Sounds like pygame might be the way to go, or pyqtgraph. The way you've formatted your post are you saying that this needs to be done with a GUI toolkit with a visualisation component running "inside" (in the visual sense), or just to use one or the other?
Yeah I really recommend that you read this slideshow. It really shows you the power of generators.
What I've been doing lately is implementing some sort of REST API with a python web framework and writing the GUI in a browser. I'm much more comfortable with HTML, CSS and Javascript than trying to figure out Qt stuffs for hours on end.
Shouldn't this integrate pytz and do all the stuff that you're supposed to do, like timezone normalization ?
you could create a partial: `shell = partial(subprocess.call, shell=True)`
I recently used it to calculate a live moving average, i.e. the average of the last N elements that it was given: def moving_average(window_size): def avg(seq): return float(sum(seq)) / len(seq) arr = [] new_elem = yield None # Fill the first window_size elements. for i in xrange(window_size): arr.append(new_elem) new_elem = yield avg(arr) while True: arr = arr[1:] + [new_elem] new_elem = yield avg(arr) Usage example: &gt;&gt;&gt; m = moving_average(3) &gt;&gt;&gt; m.next() &gt;&gt;&gt; m.send(100) # [100] 100.0 &gt;&gt;&gt; m.send(0) # [100, 0] 50.0 &gt;&gt;&gt; m.send(200) # [100, 0, 200] 100.0 &gt;&gt;&gt; m.send(1000) # [0, 200, 1000] 400.0 EDIT: mitsuhiko shows [a much nicer class-based solution](http://www.reddit.com/r/Python/comments/1o1ll8/anyone_regularly_using_the_send_function_of/cco3b6s). Please use his version. :) Just for reference, here's a shorter version of the generator-based version above: def moving_average(window_size): arr = [] new_elem = yield None while True: arr = [new_elem] + arr[:(window_size - 1)] new_elem = yield float(sum(arr)) / len(arr) 
Perfect !!! Thanks so much! Final question (and I could google- fu this but I'll ask anyway) does Vincent have an export to png function? 
Why not use a class? Much easier to read, understand, faster and less code: &gt;&gt;&gt; class MovingAverage(object): ... def __init__(self, window_size): ... self.window_size = window_size ... self.window = [] ... def feed(self, value): ... self.window = [value] + self.window[:self.window_size - 1] ... return float(sum(self.window)) / len(self.window) ... &gt;&gt;&gt; m = MovingAverage(3) &gt;&gt;&gt; m.feed(100) 100.0 &gt;&gt;&gt; m.feed(0) 50.0 &gt;&gt;&gt; m.feed(200) 100.0 &gt;&gt;&gt; m.feed(1000) 400.0
Personally I would recommend to stand away from from `.send()`. Before Python 3.3 it's impossible to build complex systems with it because of the lack of `yield from` which trashes the return channel. And even in 3.3 I am not sure if the whole concept of generators as coroutines is a good idea. I would recommend looking at greenlets instead.
there is a good example of its use in conjunction with the "yield from" expression in one of the original examples provided by greg ewing. it is used to feed tokens to an incremental parser: http://www.cosc.canterbury.ac.nz/greg.ewing/python/yield-from/yf_current/Examples/Parser/parser_gen.py
You're right, I like your solution better. I guess my solution shows the process it underwent - it originally had a sequence as parameter, so it was much simpler and no 'send' was needed. Then I modified it so that values are fed to it one by one, and so it got to its current form.
Was it definitely posted to /r/Python, or might it have been posted to another subreddit like /r/programming or /r/technology? Also, you might want to try crossposting this to /r/tipofmytongue, they're usually good at finding things like this.
BTW, why faster? Is a method call always faster than a generator's 'send' (assuming they do the same work)? EDIT: The class-based solution is actually a little slower: &gt;&gt;&gt; m = MovingAverage(3) &gt;&gt;&gt; %timeit -c -n 1000000 m.feed(1000) 1000000 loops, best of 3: 1.46 µs per loop &gt;&gt;&gt; m = moving_average(3) &gt;&gt;&gt; m.next() &gt;&gt;&gt; %timeit -c -n 1000000 m.send(1000) 1000000 loops, best of 3: 1.26 µs per loop
I did [Langton's Ant](https://github.com/iminurnamez/LangtonsAnt) in pygame. Does up to 12 states IIRC and you can toggle drawing to eke out a little more speed.
It *might* have been /r/programming, I've searched there with no success, I'm 90% sure it was written in python which is why I posted here but it may be somewhere else I guess. Off to TOMT I go!
I once used it to improve upon itertools.cycle to allow me to jump to indices like in an infinite list: def cycle(iterable): copy = list(iterable) size = len(copy) n = 0 while True: sent = yield copy[n] if sent is not None: n = sent % size n = (n + 1) % size
You could also use [collections.deque](http://docs.python.org/2/library/collections.html#collections.deque) for the `window` attribute.
It's useful to implement a kind-of coroutine in Python. For example, this allows elegant implementation of state machines: http://eli.thegreenplace.net/2009/08/29/co-routines-as-an-alternative-to-state-machines/
I used it to simplify callbacks in my code. Using [FutureThread](https://github.com/epage/DialCentral/blob/master/dialcentral/util/qore_utils.py) as a pool for [AsyncTaskQueue](https://github.com/epage/DialCentral/blob/master/dialcentral/util/concurrent.py) I queue up functions to run whose main body executes in the UI thread (where all my classes members are modified, so no locking needed) while yielding function calls to be run on a background thread (see [login and _login](https://github.com/epage/DialCentral/blob/master/dialcentral/session.py)
TIL about deque. Thanks! &gt;&gt;&gt; def moving_average(window_size): ... window = deque(maxlen=window_size) ... new_elem = yield None ... while True: ... window.append(new_elem) ... new_elem = yield float(sum(window)) / len(window) ... &gt;&gt;&gt; m = moving_average(3) &gt;&gt;&gt; m.next() &gt;&gt;&gt; %timeit -t -n 1000000 m.send(1000) 1000000 loops, best of 3: 781 ns per loop EDIT: deque~~ue~~
A while back I had a really cool use case for `send`, but I'm not sure I can find it any more... EDIT: found it, it was an AST walker. You could send a true value to the iterator to stop it from going further down that branch. This was useful, because it would continue with its siblings, unlike if I had used `break`. Here's the whole thing (and yeah, it's pretty simple): def _walk(o, path=()): if (yield o, path): return if isinstance(o, list): for i, v in enumerate(o): yield from _walk(v, path + (i,)) elif isinstance(o, dict): for k, v in o.items(): yield from _walk(v, path + (k,)) def gen_buffer(it): """A "buffer" for generators &gt;&gt;&gt; gen = gen_buffer(some_generator()) &gt;&gt;&gt; for spam in gen: ... if some_condition(spam): ... gen.send('ham') # a value would be dropped right here, if not for gen_buffer""" x = None while True: v = it.send(x) x = yield v if x is not None: # gen_buffer(it).send(x) was called yield ... # a throw-away value, so the next value from it goes into the for-loop def walk(o, path=()): return gen_buffer(_walk(o, path)) 
It's "deque" by the way (pronounced like "deck").
This is a good idea. Numpy, Scipy and Matplotlib have disgusting APIs and horrible documentations websites which lag in my afternoon when the US wake up. I think I'll start making one for myself.
This was posted on /r/PHP but it fits your description pretty well: http://www.bitfalls.com/2013/08/autofight-php-job-interview-task-part-1.html
Great thanks! 
Perhaps this? stock_var = 1023 Menu="\nDrinks menu\n\ 1. Coke ({})\n".format(stock_var) http://docs.python.org/2/library/string.html#string.Formatter.format
the best introductory use-case for a decorator I found was when I was working through Project Euler problems and I wrote "recursive" Fibonacci functions that were taking ~forever~. The right way to do it of course is to not write it recursively. However, with a "cache-ing" decorator you can obtain the same results, and it's pretty awesome to just tag a function @cache and suddenly getting that functionality regardless of what is actually happening inside. (Cache in this context means that the function only runs if it has not been run before with those exact same arguments- if it has you just return the value from last time)
Oh shit that's it, can't believe that, cheers!
A friend of mine wrote an async http/s client library using coroutines: https://github.com/rootfoo/blackmamba
Because what happens on a feed may not always be so easy to encompass in a function, even with the class state. 
I like... stock_var = 1023 Menu1="\nDrinks menu\n\ 1. Coke (%s)\n" % (stock_var) Menu2="\nDrinks menu\n\ 1. Coke (%r)\n" % (stock_var) Menu3="\nDrinks menu\n\ 1. Coke (%g)\n" % (stock_var) depending.
You can use it to write a version of `range()` that can be set to a different value while iterating: def rrange(start, end=None, step=1): "The extra r is for 'resettable'" if end is None: start, end = 0, start start, end, nextval = start - step, end - step, None while start &lt; end: start = (start + step) if nextval is None else (nextval - step) nextval = yield start r = rrange(10): for x in r: print x, if x == 5: # skip 6 and 7 r.send(8) print Yields: 0 1 2 3 4 5 8 9
Why not? I actually like it better because it make control flow more explicit, while style allowing coroutine-style concurrency. Specifically, I always know when my thread-of-execution is going to pause, which makes it easier for me to build atomic operations inside of them.
Here's a little decorator lets you write a generator with a function-style interface, i.e., calling the function starts the generator if it's not started, then gets the next value on successive calls. You can then easily have C-style "static" variables that retain their values between invocations of the function, just by writing it as a generator and using `yield` instead of `return`. .send() is used to pass new values to the generator. import functools def gen2func(func): gen = [] @functools.wraps(func) def wrapper(*args): if not gen: gen.append(func(*args)) return next(gen[0]) return gen[0].send(*args) return wrapper @gen2func def accum(a): total = a while True: a = yield total total += a accum(3) # returns 3 accum(5) # returns 8: 3 + 5 accum(2) # returns 10: 3 + 5 + 2 
thanks for the heads up for envoy. kenneth reitz once again makes my life a little easier
Slightly unrelated, but check out this CSS minifier written in Python which uses genetic algorithms. The PyCon video seems to have been taken down? But here's the github page: https://github.com/ryansb/genetic-css There's a few articles on it too: https://plus.google.com/+ColtMcAnlis/posts/LVxdn6LCcJu It might not be super useful, but I think it's pretty cool.
This is really true. I started python last summer and got to the "find a project" stumbling block. I decided to write a script to receive texts and responds with that day's lunch menu (I'm in highschool). I'm not quite finished, but it's taught me about imaplib, web scraping (via BeautifulSoup), and (I think most importantly) that people get *really* annoyed when my script crashes. It's really pushed me from 50 line dinky scripts to 6-700 line ones that use object-oriented extensively.
My name is Joe :(
Cool, one less third-party dependency required for building media dependencies for websites!
I've found that if you want to do complex things with generators, it's easier to use the greenlet package. That way you can yield control across multiple stack levels without everything in between having to know what the generator is doing.
http://docs.python.org/2/library/collections.html#collections.deque
Ya, I'm changing the name of the module to "iterators.py" and removed that haha.
Could you put this in a different medium?
&gt; Spyder is great as a Python IDE but the PyCharm Community Edition is the better IDE. In the general sense, this is true. But without ~~good~~ any integration with pylab/qtconsole, PyCharm will always be a webdev-only tool to me.
It's cool to reinvent the wheel with a poorly performing version. Especially since deque is implemented in C.
Ah I didn't realize that - cool!
This version has cool getters and setters!
As a member of the YUI team, and also someone who prefers having less dependencies in my Python asset pipelines, this is really awesome! Thanks!
I like Kivy http://kivy.org It's very nice for more free-form GUIs like a game or drawing tool. I.e. it has a minimal set of widgets, but it's very easy to render your own widgets.
An idea I have on the backburner is a Python program that reads google calendars, interprets certain entries and then converts them into text files or perhaps google sheets. The idea is to automatically generate invoices from appointment bookings. The calendar entries take the form of "ClientName (BillableTime[ +Expenses])". It's reasonably simple from a programming perspective, but it requires some delving into the google libraries. PM me if you are interested.
lol
This would be better suited for /r/learnpython.
 from random import randint def ss(): s = str(randint(1, 9)) + str(randint(0, 9)) + str(randint(0, 9)) + "-" + str(randint(0, 8)) + str(randint(0, 8)) + "-" + str(randint(0, 9)) + str(randint(0, 9)) + str(randint(0, 9)) + str(randint(0, 9)) while s[-1] == "5": s = s[:-1] + str(randint(0, 9)) return s Not exactly the smoothest or most pythonic solution with the while loop, but it does what you want. EDIT: So I disrupted the flow of /r/python by answering OP's question? Nice.
The exact same way you posted it to /r/python. Try clicking the link suspiciously labeled "submit a new text post" in the top right.
As a side note: minifiers are greatly overrated when you plan to compress your statics anyway.
Find something you are interested in, and scrape every piece of data you can from it off the internet. Then normalize the data. All using Python.
I wrote a tool a while back that actually parses the CSS and performs neat optimizations on it, most notably sorting lists of selectors and declarations (improves Gzipping). It's written in both Python and JS: https://github.com/mattbasta/crass Very much "alpha" but pull requests are welcome!
What does that even mean? You use a minifier *to* compress your assets.
You definitely want to use the Enthought Tool Suite (Traits / TraitsUI / Chaco). This can use either Qt or WX as its GUI toolkit (Qt probably preferred). These packages were developed specifically to accelerate scientific application development and they are a huge boost. There is a newer declarative gui library which is being developed "Enaml" which would be a good alternative to traitsUI is you don't mind it's immaturity.
Depends, I started off writing a simple calculator in nano, but the reddit api is always fun to play around with!
ctrl+f pytz and upboat. Another thing is make pytz timezone files optional, use system timezone info when available. I hate shipping millions of timezone files with pytz.
Python stdlib distutils has you covered. Use the package_data/dir config option in setup.py http://docs.python.org/2/distutils/setupscript.html#installing-package-data 
&gt; Thanks! But what actually I wanted to know is if it's "OK" to put these files in a pypi package that would make it at least 300MB big or if there are alternatives or best practices. Are users of your module going to need your pictures / videos for normal operation? Seems unlikely. If you are distributing an application, then PyPi probably isn't the best way to do that. If its fairly generic, then you would probably want to allow the developer to use their own assets.
No, PyPI will give you 413 when you try to upload the package, as it's over quota (which was 40mb until recently, but I think it's been increased since, not sure what to). I would probably host the larger assets on S3 and have a first-run script that downloads them, but that's not trivial to do in x-platform manner. EDIT: Also, it's possible the PyPI is not the best distribution form for your project? Does it need to be installed by developers or end users? If end users, you probably want a platform specific installer. 
Ah, I was expecting something like that, but could not find the limit. I'll probably go the route with downloading on installation, then.
Even better, we don't rely on mime types and verify that uploaded file is indeed an image (see data-images-only attr https://uploadcare.com/documentation/widget/#advanced-configuration) Second, no problems with touch interface, as for low res, you can customize widget appearance via css. And yes, we have mobile widget!
Here's one I've been thinking of for a while but every time I come to start it I realize I'm procrastinating and should be doing other things. Problem: I have about 5 external hard drives that have all been contaminated with various backups and copies of files as I have basically used them as a dumping ground for a few years. I'd like to be able pass their mounted locations into a script that will then give me the locations of duplicated files/ duplicate directory structures. Much of the files are media so the directories will be stuff like artist&gt;album&gt;song or show&gt;series&gt;episode Basically I want to free up some space by finding the duplicates Bonus: Give me an option to delete duplicates with and without a 'Are you sure you want to delete this one' Solution: from os import path # your code here :)
Evidently still procrastinating, just on reddit now. Damn it!
I think you must have posted this as I was writing up mine! Well played for getting in first :) It is a good starter project, especially for getting to grips with the os library. Nice webcam project too.
PyMongo with safe writes off is no better than writing to /dev/null. Of course it's fast. I exaggerate, but you basically have no guarantee that writes happen at all. 
Don't bundle it, you'll regret it~ 1) Large, annoying to download, pypi handles large files badly. 2) Not zip safe, you need to use (__ file __) to locate assets, bundling assets (eg. using pyinstaller or other bundlers) fails. 3) Messes up your source control because binary files don't fare well with source control. Store assets on github / bitbucket / sourceforge / whatever and use: os.environ['BLAH_ASSETS_FOLDER'] Let the package user specify the location the assets are installed in; this is a good way to handle ctypes bindings to libraries too. 
&gt; Not zip safe, you need to use (__ file __) to locate assets If file names are static, `pkgutil.get_data` should work in zipped imports as well as on the filesystem. It can not be used to e.g. list and traverse directories, so it won't work for everything (does not work for Babel for instance). IIRC setuptools/distribute has something for that case, but that adds the dependency. &gt; Messes up your source control because binary files don't fare well with source control. Depends on your source control. Binary-heavy project will often use binary-compatible source control systems such as svn or perforce. Right tool, right job and all that. Having essential assets stored and versioned alongside the corresponding code is probably a bigger gain than somewhat better code-only VCS.
An asset management tool with [CDN](https://en.wikipedia.org/wiki/Content_delivery_network) [*](http://highscalability.com/blog/2013/2/7/ask-highscalability-web-asset-server-concept-3rd-party-softw.html) support may also be helpful for working with pictures and videos in addition to HTML, CSS, and JS files. * http://www.fanstatic.org/ * http://elsdoerfer.name/docs/webassets/ * git submodule with git-annex / hg subrepo with hg largefiles Asset compression: * [smush.it](http://www.smushit.com/ysmush.it/) (smush.py, smooshy, smooshy-py) * https://github.com/jorgebastida/glue [EDIT] Conceptually, it could be as simple as a JSON file with pathnames and optionally cached file-level metadata; optimally containing [dereferenceable URIs](https://en.wikipedia.org/wiki/Dereferenceable_Uniform_Resource_Identifier) (URLs) linking the data with structured attributes; for example certain categories or tags. * http://yeoman.io/ "modern workflows for modern webapps" * http://bower.io/ "a package manager for the web"
Minifying your code SIGNIFICANTLY improves compression rates. Whitespace is often irregular, and name mangling allows the same gzip entity to be used in more places than it otherwise would. We have compression (gzip) turned on with our project, and when we first launched we did so without any minification (if there were stack traces, we wanted to be able to debug easily). Turning minification on decreased the size of our asset bundle by 40% (~700K -&gt; ~400K). That's nothing to shake a stick at.
Depends on your definition of "greatly overrated" I guess. I have a site where the size of uncompressed CSS is 558kb (66.5 gzipped). After minification it's 304kb (49.4 gzipped) -- 25% less. So yeah, it's not a significant saving, but something you can do to make your site load a bit faster with a very little effort. Also, keep in mind that browsers need to parse the CSS you feed them, and that time also counts.
History of Python: http://www.reddit.com/r/Python/comments/1nmigi/im_looking_for_a_more_nuts_and_bolt_version_of/#cckc2tp
my biggest challenge with the current libs is datetime math.. specifically the difference between two dates or adding HH:MM to datetime object. it doable.. just really ugly right now. (nevermind the whole "ValueError: year=1899 is before 1900; the datetime strftime() methods require year &gt;= 1900" thing.) does arrow handle these use cases well ? 
Ha, i guess you did not liked it and seems other redditors didn't liked it too. I thought would be of some interest, but since i am newcomer to python and programming, i would love to learn why this article is a turn off.
Not sure what are you trying to say here ... The point was that arrow should do normalization when converting to different timezone. I'm too lazy to post relevant examples but this is a problem I had in the past ...
The problem is not the article -- it's actually a good little snippet of basic-to-intermediate python advice. The problem is in the presentation. First, keep capslock off. All-capital letters convey one of the following: 1. I'm 70 years old and not sure how to computer, or 2. I'm a spammy advertiser trying to grab your attention, or 3. I'm very very angry with you and I'm trying to show screaming/yelling/shouting. Second, I'd drop the blog title off the reddit headline. It lends even more to the idea that you're more interested in advertising (see #2 above) than in content, since the blog title doesn't help clarify what the article is about in any way. Third, and this is nitpicky, the formatting on your blog doesn't lend itself that well to code blocks. I'd suggest embedding the python code as [gists](http://gist.github.com) so they're formatted more readably.
This is not my blog neither i have any relation with the author, and of course i din't post the link here to advertise it, as long as the capital letters, that's my bad cause i copied &amp; pasted the title that was all ready capitalized. Anyway thanks for your opinion, i was more interested if the content of the specific article was faulty or something. 
This is actually non-trivial if you require a VALID ssn; but you have to get the current mappings from the social administration agency. 
Download a title from the Gutenberg Project. Go through the text, cataloging every word. Print out a lexicon: every word in the text, with the number of times each word appears. Challenge #1: Given the title, download the file automatically. (Use the text version.) Challenge #2: Be able to sort the results by frequency, order in which they first appear in the text, or alphabetically. Challenge #3: Find a list of the most popular 1-3,000 words, and filter out those. Challenge #4: (This is easier if you have a Unix/Linux/Mac system.) Filter out all of the words that are in your system's dictionary, leaving (almost) only character names and place names.
 * https://wiki.python.org/moin/IntegratedDevelopmentEnvironments * https://wiki.python.org/moin/PythonEditors * http://code.google.com/p/spyderlib/ (vim) http://www.reddit.com/r/Python/comments/1h53fq/best_program_for_coding_python/#cara4d6 
There is little value in having the *fastest* database. There are more value in having consistency, availability, good response time, durability, atomicity, data distribution, isolation, fault tolerance, ease of use or some kind of combination of those for different needs.
Is this free to use or do we need to sign up on their webiste?
I just wasn't quite clear what you need. A GUI toolkit does things like buttons, sliders, textboxes and so on. The visualisation tools are capable of creating a basic window, or some of them (matplotlib especially) can be embedded in a GUI. For an interactive game of life type simulation, I'd probably look at PyGame. Someone else has mentioned Kivy below, which is another interesting possibility - that's designed especially for touch-based UIs.
Ubuntu Studio * http://ubuntustudio.org/tour/audio/ * https://en.wikipedia.org/wiki/Ubuntu_Studio#Low-latency_kernel * http://distrowatch.com/table.php?distribution=ubuntustudio DreamStudio * http://dreamstudio.dickmacinnis.com/about-dream-studio/ * http://opensource.com/life/13/1/what-artists-want-software * http://distrowatch.com/table.php?distribution=dreamstudio * https://launchpad.net/~dreamstudio/+archive/audio
It is fully webscale! 
testcomment
Yes, but that's not the GIL's fault. If you poke around, you'll find a version of 1.4 (I think it was) that had the GIL taken out of it. It ran much, much slower than the version with the GIL. Even with multiple cores available. The problem was the reference counting VM. Every time you do an assignment you have to change two reference counts. With the GIL, that's a couple of read/write's. Without the GIL, you have to acquire and release the appropriate lock for each counter. Probably in series, so as to avoid possible deadlocks.
Yeah, in languages with hard brackets, you have to be super paranoid about making sure you only cut-n-paste segments with matching pairs, or fixing them afterwards. Finding a missing bracket is a lot harder than finding a missing indent/outdent, as witnessed by people using automatic indenters to make sure the stuff is right. The case quoted here happened to change the code to code that was still valid. A missing hard bracket that has the same result would be equally bad. In fact, after running an indenter over it, it would be the same.
The best way to make sure the code you wrote is secure is to get as many independent reviewers as possible. "Security through obscurity" is an oxymoron. The ability to redefine the code on the fly only works if someone can modify your executables - in which case you're already hosed. If you're trying to secure the algorithms used as some kind of corporate secret, then yeah, Python has problems if you also want to sell it for people to run on their computers. That doesn't seem likely in an accounting system.
Awesome! Thanks! I wish I saw this when I first got mine. But, I haven't gone anywhere since I first bought my kit so I'm gonna read over this so I can start over.
Do something like class Person(object): def __init__(self, init_dict): for key, value in init_dict.items() setattr(self, key, value)
That's amazing. I've been using Python for years now, and have never stumbled across setattr(). This is exactly what I need, and will trim my class init sections down by like 90%. Thanks!
What about having a separate reference count for each thread? That way only the garbage collector has to deal with locks, and then only in the worst case (check to see if any of the reference counts are non-zero, unlocked. If it appears that all of them are zero, lock the reference counts and double-check.) Or what about having a fast/slow implementation? Have a field that marks an object as potentially being used by multiple threads, and only lock if the field is set. Or alternatively, don't use reference counting. There are other garbage collection schemes, after all.
It seems like a [pymcu](http://www.pymcu.com/overview.html) would be a more reasonable choice for this task.
You know what? Thank you so damn much, I needed this!
Perhaps pysdl2? -&gt; https://gist.github.com/shadowmint/6928668 
Yeah, I would have *at least* liked to see a disclaimer and a reference to \_\_all\_\_ for * imports. Instead the author chose to say "don't do it unless you know what you're doing" which most people will take as "I know what I'm doing". Plus the example the author is pointing to as "an interesting good use..." is being done out of ease/what may others have done....which doesn't necessarily mean it's a good idea. This post does not even discuss the more subtle things that are really important when debugging import problems such as: * directories without \_\_init\_\_.py files * overloaded/preexisting object in sys.modules * import hooks * the several cases where reload() won't do what you expect In general I like simple articles, but not at the expense of making things harder in the long run.
You're not exaggerating at all....I've seen major issues with MongoDB's consistency especially when dealing with lossy networks and clusters. Oh you just wrote some data but your local node is a slave? Here you can this nice null entry till I decide to sync the data, you said you didn't need to wait on it right? What bothers me more is that the comparisons being done are against entirely different data stores and protocol architectures &gt;.&lt;
The most explicit and least magical solution is to use kwargs and default argument values. class MyClass(object): def __init__(self, contact=None, bio=None, ...): self.contact = contact self.bio = bio ... d = { "bio": "bio", } c = MyClass(**d) c.bio # "bio" c.contact # None
Very cool writeup! Along similar lines, I wrote a serial bridge library to make python--&gt;arduino simple. You can clone it from https://github.com/thearn/Python-Arduino-Command-API Or just 'pip install Arduino' if git isn't your thing. It's similar to protocols like firmata, except I tried to keep the syntax as 1 to 1 with arduino sketch code as possible. 
In addition to what others have suggested, you might also want to take a look at the [dict.get(...)](http://docs.python.org/2/library/stdtypes.html#dict.get) method for future reference. self.bio = my_dict.get('bio') self.contact = my_dict.get('contact') If the key doesn't exist it returns None by default rather than throwing an exception. The above lines have the same effect as initializing your variables to None then checking for existence of the key before doing the assignment; except using 'get' only has to do the hash table lookup once instead of twice. If you happen to want some default value other than None, you can pass it as the optional second parameter: self.my_member = my_dict.get('my_member', -1) 
how does this course work? I have never tried this before.
[Link to the original StackOverflow answer.](http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python#1594484)
https://wiki.python.org/moin/PythonInMusic
I hadn't heard of BreakfastSerial before. I have tried pyFirmata in the past, but always tend to go back to writing the program on the board and having my own serial triggers. If I want something real time I tend to use Labview. The Labview interface for Arduino is great...though the price of Labview and lack of affordable versions outside the US kills this for most people.
I did not mean to say that it never helps, just that often gains are miniscule. I am in no way suggesting that minifiers should be considered a crime or anything.
May sound weird, but using pygame to play music is easy: http://www.pygame.org/docs/ref/music.html
Tend to agree... I've played around with pyFirmata, and it is pretty cool, but for my needs it's never been worth the additional complexity/overhead. I'll have to check out the labview interface. 
For the sake of convenience, and just to be Good Guy PythonDev, do you have any links to more comprehensive importing docs/blogs, especially for edge cases? I'm especially interested in the consensus on relative imports, given that the newish book Two Scoops of Django recommends their use in certain situations, while acknowledging their previous disavowal by the python community.
There's also: class Person(object): def __init__(self, init_dict): self.__dict__.update(init_dict) which turns out to be used quite a bit in the stdlib.
I did a quick search and came across an ipfix library. https://pypi.python.org/pypi/ipfix ipfix and netflow v9 are quite closely related so this might help you.
PyCX might be relevant to you're interests. http://pycx.sourceforge.net/
Also missing: import numpy as np 
You should sign up on https://uploadcare.com/ There's pretty large free account plan
Falls under this statement &gt; The other reason, which I’ve seen used a few times is when you import a lone-named function (or class) and use it extensively throughout your code and want to shorten its name. Though given its frequency adn wide adaptation, I almost expected to see `import numpy as np` written out as an example.
You can see how I experimented with various C/Python libraries to play mp3 for [my music player in python](https://raw.github.com/fabiomdiniz/Frey/gh-pages/img/screenshot.gif): [pygame](https://github.com/fabiomdiniz/Frey/blob/master/g2tsg.py) [audiere](https://github.com/fabiomdiniz/Frey/blob/master/g2tsg_audiere.py) [bass](https://github.com/fabiomdiniz/Frey/blob/master/g2tsg_bass.py) [GStreamer](https://github.com/fabiomdiniz/Frey/blob/master/g2tsg_gst.py) [QT's Phonon](https://github.com/fabiomdiniz/Frey/blob/master/g2tsg_phonon.py) In the end I picked bass, ultra reliable, multi platform and full of features. 
Ah I agree with that :)
Do you know of any Python frameworks for deploying online psych / decision-making experiments? Right now I am looking at psiTurk but it does not offer much except for mTurk integration (which I appreciate).
I would check out screencasts if your are experienced developer. They will let you see someone else do the work they do and progress from there. 
This solution doesn't "ensure that everyone has new neighbors." It merely selects a random permutation, which may be identical to the starting configuration.
Dude thats awesome
This is a cool idea. Its too bad the documentation assumes you know how to use `make`.
The problem here is that "neighbours" only refers to people to the left and right of one particular list element - in reality, any actual office seating arrangement will probably be much more complicated - for example your "opposite" neighbour. Any effective solution needs to take table layout into account.
This is to teach through seeing. If you want to read documentation here it is. http://pandas.pydata.org/pandas-docs/dev/ That being said, you may have a point. You can look at the actual code from the screencast in the links section under the video.
I've used wxPython and pyQt4. Wx is a joke as compared to Qt in terms of code clarity and avoiding stupid bugs. I'm stuck using Wx though because my coworkers know it better. Also, for all intents and purposes, Pyside is PyQt, so use Pyside. The code is the same. For a comparison of wx and qt for 99% the same code, here's some of my stuff... Qt https://code.google.com/p/pynastran/source/browse/branches/v0.6/pyNastran/gui/gui_qt.py Wx https://code.google.com/p/pynastran/source/browse/branches/v0.6/pyNastran/gui/gui.py and https://code.google.com/p/pynastran/source/browse/branches/v0.6/pyNastran/gui/guiPanel.py
If you want something with a "certificate", I believe you can still sign up for the [coursera class](https://class.coursera.org/interactivepython-003/class) that just started last week. Weekly quizzes, video lectures, mini-projects.
So the theory behind this is that everyone has "new" neighbors, presumably so everyone in the office gets exposure to new people. But this system only really makes sure that they're not the same as last time. There's nothing really stopping this from just cycling between two permutation states so that people actually never meet new people, they just meet the same people they met the time before last time.
Certs are a poor substitute for examples. Employers would much rather see work you've done than a piece of paper that says you have the ability to do work.
No. I would have a good chuckle at anyone who had a certification as you usually find that on commercial toolskits. Instead, commit some code to an open source project or create a github (or other repo) account and maintain some of your work there.
 filepath = path / 'test.txt' That I like. p('.') path.makedirs() No &gt; filepath.open('w').write('hello world') I could have sworn that was supported. In fact I'm sure it is... &gt; PyPy does not support refcounting semantics. The following code won't fill the file immediately, but only after a certain period of time, when the GC does a collection: open("filename", "w").write("stuff") http://pypy.org/compat.html My biggest issue with this module is I don't think a "path object" should be an full fledged object. I think a string is adequate. You'd have to declare every path as a path object as string division is not allowed. I think this library makes some assumptions about paths that are not realistic.
&gt; for all intensive purposes intents and purposes
Thanks...I'll keep that in mind. My current work doesn't call for any of this. Its something I am doing purely on my own so I don't have any publications, etc with any of my work. 
Look at what [Quod Libet](https://code.google.com/p/quodlibet/) uses internally.
 from math import * Really?
wxPython. I think Boa Constructor 0.6.1 is a good GUI designer for it (and a good IDE), but it is stuck at wxPyton 2.8.11 for now (which means Python 2.6 or less) and has been in stasis for years. There is wxDesigner and Glade, too. Most people seem to be of the opinion that it is better to just hand-code your GUI rather than use a GUI builder; I disagree for my own tastes, but completely respect that approach, too. I chose it long ago because it had good press, was native "cross-platform" (well, with some tweaks!), and I immediately sensed the community was as good as could be. I have not heard people bragging about how "Pythonic" it is; if anything, you'll read that it is more following the C++ patterns of its core, wxWidgets. I really don't care either way about that, though.
&gt; Although the term mondegreen has been used for misheard phrases not from songs and poems, eggcorn, which originated in a 2003 Language Log post, has been advanced as a broader term for misheard words or phrases that retain their original meanings. It's in the link with the title as... &gt; Eggcorns and mondegreens Don't complain about the url.
Communication and serialization in ROS is rather simple, basically offering a PUB/SUB and an RPC mechanism. ROS comes with it's own interface description format stored in [.msg](http://wiki.ros.org/ROS/Tutorials/CreatingMsgAndSrv#Creating_a_msg) and [.srv](http://wiki.ros.org/ROS/Tutorials/CreatingMsgAndSrv#Creating_a_srv) files, together with a bunch of pre-defined message types for PODs and data types you'd typically find on a robot, i.e. data describing image sensors, data from a laser scanner or a depth camera etc. Nodes can subscribe to topics, i.e. strings organized in a file-like hierarchy to request data from a given topic (e.g. "*/camera/rgb/image_raw*"), the list of available topics and the subscription / connection process is managed using a "master" node your code can talk to via XML-RPC. There are several client libraries available to automate this (Python, C++ and Java, mostly). Now, none of that is actually very interesting, the whole communication architecture in ROS is rather simple, to be honest. Transport is TCP, although there is a UDP transport layer being developed. ROS has [nodelets](http://wiki.ros.org/nodelet) as a simple in-process communication mechanism, although I feel that could be handled better if implemented differently. The good thing about ROS is the tool support that comes with it. There is quite a bunch of tools written in Python to manage nodes, topics, services, to diagnose the runtime node graph and the communication between its nodes, handle logging, that kind of stuff. We have [rxconsole](http://wiki.ros.org/rxconsole) as a simple, distributed syslog w/ facilities, [rxplot](http://wiki.ros.org/rxplot) to visualize (certain) sensor messages, [rviz](http://wiki.ros.org/rviz) for more complex 3d visualization (if it doesn't SEGFAULT right away, that is) and [rosbag](http://wiki.ros.org/rosbag) to record and replay sensor data (or any messages in general) at a later time, or with different update frequencies. The latter is rather invaluable for simulation when you don't want to watch your robot's new action planner act out all 17 hours of a given scenario in real time... While it's distributed nature is a part of ROS, I'd say it's not really its greatest strength. In fact, I often wish both serialization and the actual communication layer would be more modular / adaptable. By using ROS, you kinda have to buy into the complete ecosystem, i.e. create nodes, use ROS's build system (rosmake, or more recently, catkin), the runtime facilities, for example launch files to start stuff and manage runtime node/service dependencies and so on. I hardly seeing ROS being a replacement for typical PyRo use cases. Source: I work in robotics and we heavily use and contribute to ROS.
Many of these Python courses already offer or are starting to offer some sort of certificate or badge to indicate completion: * http://www.class-central.com/search?q=python * http://www.reddit.com/r/learnpython/wiki/index#wiki_videos.2Flectures * http://www.codecademy.com/tracks/python Sources on http://github.com and http://bitbucket.org could be helpful. * http://nbviewer.ipython.org/5920182 ([gist](https://gist.github.com/rpmuller/5920182/)) * https://github.com/rubik/radon * https://github.com/biopython/biopython ([tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html)) 
Yeah, an office floor is two-dimensional, so I don't really understand how a one-dimensional script is supposed to work. The numbering will likely snake back and forth, and people will end up being next to others that the script has no idea about. Might as well just use a random shuffle.
You don't need publications. Anyone can see your Github, and will be able to see that you know Python (or don't) by browsing your code. I've got side projects and data-visualization scripts up on my Github. Nothing fancy.
Cool problem. This code could use a little work, IMHO. I believe `find_position(key, lizst)` is simply a redefinition of `lizst.index(key)`. `all_perms` seems to be a slower version of `itertools.permutations`. You're importing `random` and never using it - just taking the first permutation that works. And you really shouldn't have a local variable called `new_neighbors` inside a function called `new_neighbors`. And it's extremely slow by the time you get to about 13 people.
Amen. I shuddered when I saw that.
&gt;My biggest issue with this module is I don't think a "path object" should be an full fledged object. I think a string is adequate. Paths don't have have same semantics as strings. While it's often convenient to just use a string, a path object allows for more natural and expressive functions. For example: path(".") should be equal to path("~/x/working_directory") when the working directory is "working_directory". Likewise: path("/home/x/working_directory") should be equal to path("~/x/working_directory"). &gt; I think a string is adequate. You'd have to declare every path as a path object as string division is not allowed. I don't like the overriding of the division operator though, + for concatenation has been pretty standard for a long time. There should be some method for auto-coersioning a string to a path fragment and having the resultant object be a path object. So: path("xge") + "geeg" -&gt; path("xge/geeg") 
Yeah, that makes sense. I referred to this problem in my post though, in a way. They wont have the people to see if I know Python or not, does that make sense? Most researchers don't have programmers on staff. I was looking for kind of third party to say 'Hey, this guy at least has a certifiable level of knowledge' but it doesnt seem like that exists. I'll get on making a Github. Thanks for the advice.
It can be the smallest things too. Most of my work is quick fixes and prototypes. It's important to just have something to show and underline the idea that you've been out there and engaged. (or at least this is what I would look for)
&gt; There should be some method for auto-coersioning a string to a path fragment and having the resultant object be a path object. So: Why not a method? path('xge').join('geeg') -&gt; path("xge/geeg") is much clearer imo.
certs aren't much of a thing in programming. Microsoft and Oracle and other big, dumb enterprise oriented companies will charge you money to get a cert but those are of truly dubious value unless you're trying for a career position as digital janitor (i.e. enterprise IT specialist, the guy who installs MS Office for corporate cubicle workstations). in the open source world the best thing is to just write some code and put it up on github. nothing certifies your skill better than real code that other people can look at. 
Thanks!
I'm happy with join() as well, but I'm just talking about syntactic sugar (i.e., *if* they were going to override an operator)
glad I could at least help you remember what you were looking for.! Please be sure to rate up my posts since they helped! :-)
Path comparison isn't that rare, and when I need to do it it's trivial to use os.path.abspath to normalize things. The point was just to illustrate a difference in the semantics. Another example would to to validate that it actually represents a valid path, or that it's a relative or absolute path, or functions to get the parent or root of the path, or extract the filename, etc. os.path does a lot of what a native path object would do, just in a C / procedural-like fashion vs. a class oriented approach. &gt;Yes, but it doesn't take into account windows vs linux and mac. + would be fine if it were a path object, but is terrible as a string Exactly the point, string handling of paths is problematic. The idea is that you're not using strings, you're using a path object, where the object would have some internal representation of the path data and the external representation would be os dependent. 
People learn in different ways, some can read, some are stimulated more by sound, and even some weird folks like myself generally need to manipulate physical objects in order to best understand a concept. 
**STEM + /r/IPython: http://www.reddit.com/r/IPython/comments/1dl8wc/seeking_advice_for_introducing_ipython_in_high/c9rws29**
Note that the random import _is never used_. This is in no sense a random shuffle, and the import is only misleading.
&gt;the solution for 3 people is obvious. Are you sure? It seems to me that the person in the middle cannot possibly have new neighbors since they'll always be placed adjacent to one or both of their current neighbors.
This is awesome. Why did you delete your username though??
Github has a great certification program. Step 1. Create an open repo. Step 2. Upload excellent code that solves a problem under the MIT license. Step 3. Congratulation! You're now certified. Warning: Certifications may be valued differently, depending on who reviews the code.
vim
Yes. Please. I read the article expecting to find an explanation for edge cases. If anyone knows a good article, please share.
Coursera, Udacity and EdX offer free online courses from actual unversities (for example EdX is Harvard and MIT) that in many cases give certificates in computer science related topics. These are the same modules that their own students take as part of their BSc.
Except that you shouldn't play with `__dict__`
A provisional package would get that status for one release only. I see you subscribe to the idea that everyone always get api design decisions exactly right, first time, every time? And if they don't, well the best idea is to simply fall on their sword and deal with it, rather than improve and make it more useful and effective for the next five years to come? I for one, like a language with a standard library that works well and elegantly by design and from experience, not from guessing in the dark.
Because the division operator is the represented by the same symbol as the most common operating system path divider? And strings don't have an existing overloading for it in the first place, so it can't be confusing? Did python include operator overloading in the language for no reason whatsoever? 
&gt; I don't like the overriding of the division operator though, + for concatenation has been pretty standard for a long time. That's a different operation, though. \+ can't arbitrarily tell the difference in intent between `path('folder') + 'subfolder'` and `path('file') + '.extension'` or `path('en') + '_US'` 
Hence the solution is obvious, no?
Plus, paths might be unicode or bytes. Correct semantics should care about `sys.getfilesystemencoding()` and `os.path.supports_unicode_filenames`. Edit: and abstract that away, for both 2/3 support and cross-platform compatibility.
The os.* modules and functions are not user-friendly but ugh: from path import path as p filepath = (p('.') / 'test_dirs').makedirs() / 'test.txt' filepath.open('w').write('hello world') This is just horrible. The mix and match of operator overloading coupled with classes just for the sake of supporting those new idioms. I don't see how this is more readable. 
Someone _please, please, please_ package up the std library already! It'd be lovely to know what versions of the packages are being used and have the option to upgrade those packages and make the damn thing compatible with the rest of the python packaging ecosystem.
Obviously nonexistent, perhaps.
It's pretty true that some of Python's api's are a bit crummy and non-uniform. 
I often do that in both python and java. For the maths library (only) I don't think it's so bad.
Only ~2 minutes to train a scikit-learn RF with 50 trees on covertype with over a half million examples? Am I missing some sort of optimized library?
Only bad programmers should get certified. If you're actually capable of writing good code then show it on github. If someone shows me their programming certificate or degree I'll start to wonder why they are trying to avoid showing me their code.
&gt; Am I missing some sort of optimized library? Probably :-) Are you using 0.13+? They dramatically improved training times for trees in the last two releases. Also, are you enabling multiprocessing with n_jobs parameter? 
Way too much exposed functionality for most uses. Long tutorials only scratch 1% of the surface of the monster. So much functionality that whenever you need to do something hard you could spend days digging through the knobs and levers to figure out exactly which one you need, and how to use it without breaking everything else.
Implementing a decent log is way too tedious. Handlers, formatting, etc... I know there is the 'basic' config, but I can't help to feel it could be fixed up a little.
Yep, I'm currently using 0.14.1. For some reason I thought n_jobs defaulted to -1, meaning that it would utilize all of the available cores, but now I see that it's just set to '1'. Adjusting that value would definitely help.
Same, wx here. It just works on everything. For some reason it's super slow on OS X.
I actually think the functional API is better. But if there had to be an object, I'd prefer a .join method.
&gt; "+" can't arbitrarily tell the difference in intent between path('folder') + 'subfolder' and path('file') + '.extension' or path('en') + '_US' That's a good point. Maybe using methods would be better, but it'd get a little cumbersome. 
In all honesty, most of the stuff I know comes from either fixing critical issues in a production system or reading CPython's source :(. However, by no means are Python's import mechanisms a general problem but they can be when someone tries to use it in an non-standard fashion. So all that said I'll at least try to provide some examples here but try to keep in mind many of these were probably due to the nature of the environment I was working in, the fact that it was Python 2.5/2.6, and various other problems which were unique to the situation. Most of the issues I had above are decently well known and I don't think they're really considered bugs just behaviors which could lead to problems for some. **overloaded/preexisting object in sys.modules** Say you're working with a package (packgeA), which imports 'foo'. Then someone else comes along and creates another package (packageB) which also imports 'foo' but from a different location. Whomever imports that name first will win and it will be loaded into sys.modules to be reused. The problem is that for very large code bases, we're talking 10M+ lines with over a decade of hacks and bugfixes, this can be very difficult to track down without spending a day or more finding it and then two to three days making sure fixing it won't break anything else (especially legacy code). Another good example where this is a problem is when someone invents a new module or function and decides everyone should use it without updating their code. They can either monkey patch it: import os import subprocess def Popen(*args, **kwargs): pass sys.modules['subprocess'].Popen = Popen Or worst case, replace it entirely with some subtle differences that makes things easiear short term but severly break things down the line: import sys import subprocess # sys.path has a directory with this module in it, before the builtins sys.modules["subprocess"] = subprocess **Import Hooks** These are actually pretty cool and a decent example of this is Flask's [exthook](https://github.com/mitsuhiko/flask/blob/master/flask/exthook.py). Basically, it allows for interceptions of the import statement so from flask.ext import admin does (mostly) the same thing as import flask_admin as admin The problem is that it can sometimes make it harder to track down an import problem and it modifies sys.modules. That said one thing it has forced people to do in this case is follow a standard naming convention. If you're working for a large company with lots of Python code an import hook can make it easy to extend a root 'namespace', flask.ext in this case, while at the same time enfocing the base package to follow a naming convention such as flask_&lt;extension&gt;. **reload() not doing what you expect** reload() is great for development and sometimes debugging but if you're using it within code it probably not doing what you expect. Generally speaking I've seen reload() cause a problem in several circumstances. That said many of thse problems I've only seen once or twiceL * sys.path is dynamic and can be changed by some kind of loader defined at the intreperter startup. This can in some circumstances cause a module to be loaded from a differencet location * you're expecting reload(module) to reload existing instances of a class * you have a Python module with the same name as a c-extension causing reload() to possibly reload the Python module instead of c-extension I'll admit that some of the above are pretty obvious now, expecially after reading through CPython's entire source tree. For those new to the language however you can encounter these kinds of issues when speeding along with a new idea and thinking that just because the language allows you to do it, you can. That said, many will never encounter the problems above but as you delve into large code bases, distributed systems, or even becoming a library developer you'll slowly hit the above issues. **Namespace Packages** Though not directly related to Python's import call they're similiar enough they deserve some mention. Namespace packages essentially allow you to have two code bases which share the same root name but can be installed separately. I've just started working with these myself but the basics of it are something like this: ~/repos foo_core/ foo/ __init__.py core/ __init__.py ... setup.py foo_models/ foo/ __init__.py models/ __init__.py ... setup.py When you install your code, you'll get foo.models and foo.core. To get this working you need a few things, first setup the top level \_\_init\_\_.py files to look like this: import pkg_resources pkg_resources.declare_namespace(__name__) Once that's done, each setup.py would be written to look like this (example below would be for foo_models) setup( name="foo.models", namespace_packages=["foo"], packages=["foo", "foo.models"]) Then finally, installation using pip and a virtualenv: virtualenv foo . foo/bin/activate cd repos/foo_models pip install -e . --egg # --egg is an important argument here because of the namespace package cd .. cd repos/foo_core pip install -e . --egg # you **must** use --egg here 
Precisely :)
What's so horrible about separating "folder concatenation" into the overloading of `/`, which looks completely natural? It's not as if strings already have that operator defined for them, so users shouldn't get confused by its use.
[enaml](http://nucleic.github.io/enaml/docs/), a declarative DSL is amazing. think of it as a highly pythonic equivalent of QML. data binding is achieved the byte compilation stage and are so powerful that most of the time you don't need to write controllers. layout is handled by constraints layout, so achieving beautiful looking GUI's is very achievable. 
Uhhh, no. There is tonnes of standard library which is old and clunky. Most people agree the subclassing API design in asynccore/chat was artificially limiting. Not even a second go at urllib got an overall excellent api. Almost noone likes the built in time and date modules. Did you see all the deletions and renamings that went on just in 2 -&gt; 3? Standard libraries have been coming and going ever since Python 2.0, and this process helps to make sure that fewer of them ever need to go because of a unknowably bad initial first api design. Why would you ever be against that?
Why not just use a `.__truediv__(arg)` method instead? Except then, you can call it with ` / arg` instead, a much shorter and easily recognisable syntax for paths.
But that's why the proposal explicitly demarcates all such packages as provisional, meaning that any user MUST expect that the api COULD change on the next point release. This doesn't seem to me so different from browsers introducing experimental implementations of new css3 / html5. The only way they can figure out if their experiment has a good api is by pushing it provisionally public and letting people try it out and report back; things would be a horrible mess by now if they were forced to absolutely stick with every implementation they tried. And FWIW, 2.7 is done and dusted now afaik.
Doesn't matter what you are doing. You should be using version control. I like git. Github is a great way to share code and also get an automatic backup at the same time. You should be using something like this anyway. So why not use this as an excuse to well... Do it? 
I think being neighbours in an office is of dubious utility.
The tooling (build tools, environment tools, etc) should be a little better with Ubuntu compared to OSX. I did manage to install most of the common build tools on my OSX but that took some efforts. With Ubuntu, it's a simple apt-get install [whatever you need]. Ubuntu also have many packages for scipy and numpy and the life for which you only need to apt-get install [package]. In that sense, it would be easier with Ubuntu. I don't know about the scipy superpack, EPD or conda packages but try them and see if they work for you. Now, the choice to go with either python2.7 or python3 is full of heavily opinionated people arguing endlessly. In my humble opinion, it all boils down to the library you need or might need and their support for python3. There is not much real syntax difference between python2.7 and python3 that can you easily switch from one to another. It seems like scipy and numpy do support python3 if you want to go that route. If you ever need a third party library that does not support python 3 yet, you should know that in most cases little to no effort is needed to change your code to go from python3 to python7. You could write your python 3 code in a way that is backward compatible by following just a [few tips](http://docs.python.org/3/whatsnew/3.0.html).
Just my 2 cents but you can always host somewhere else (github or something) then just provide a pointer to that when you register at pypi. 
Or how about restarting a logger without creating double lines? Why is that so damn hard?
&gt; Another example would to to validate that it actually represents a valid path so if I have this... ~/$WORKDIR/work ~//work The first line can be valid without it following intent. There's always... path = os.path.abspath(os.path.expanduser(os.path.expandvars(path))) &gt; Exactly the point, string handling of paths is problematic. Sure, but as soon as you lose intent. Sometimes I want to pass a relative path because it's going to get mangled on the other end and sometimes want it to just be a full path. The paths are not the same. It's like saying 1 == 1.0 is True. &gt; Exactly the point, string handling of paths is problematic. Be a big kid. User os.path.join. Path objects don't really buy you much. You're still going to have to declare it as a path (or you could just use join). They still should fail path comparison because I don't want it auto-expanding my paths. It should leave them alone unless I explicitly tell it to do it. How bout we have python automatically create a directory if I open a file in a given location, but the folder doesn't exist...that seems more basic to me.
And for default initial values, be careful about using anything like: class MyPerson(object): def __init__(self, children=[], ...): self.children = children Because that will always initialize to that first list you make with [] when not provided. So other people will end up sharing any children you add to them later. Instead, use None as the default value, then initialize a new list if it is left as None. That's a common pitfall.
That's really interesting. Would be even more interesting if you provided results in terms of accuracy.
This seems like a really obvious idea... why isn't it being done this way? EDIT: I mean that in a "why didn't I think of that!?" kind of way, not a put down :)
If you're constantly naming your variables in python result, some_variable and another_variable, I imagine most things will be confusing.
This is truly brilliant, thanks!
Very bad news for the Oracles and Accentures of the world if high profile customers make the transition to OSS. Hope they do it succesfully: not too many government services are any good at this.
So what do you do to become a Python dba? 
[Blogspam](http://www.urbandictionary.com/define.php?term=blogspam).
The accuracy has been the same as sklearn on the datasets we've tried, but we could use broader testing. Care to try it out?
I believe there is a suggestion that the std library should be pegged to the Python release. Hence no version numbers as they are redundant. Not saying I agree/disagree, but that is what I recall having read.
Why would it be bad for the Accentures of the world? Those firms are certainly invested in proprietary stacks but many of those consulting firms do work with open source software and there's nothing to stop them from migrating that way. They're just implementers.
If I understood well the problem, then this answers it: def shuffle_separate(l): """ Shuffles a list so that two neighbours in the original list are not neighbours in the shuffled list. """ L = len(l) return sum( zip(l[:L/2], l[L-L/2:][::-1]), () )[:L] &gt;&gt;&gt; shuffle_separate(list('ABCDEFGHI')) &gt;&gt;&gt; ('A', 'F', 'B', 'G', 'C', 'H', 'D', 'I') Depending, on the size of the team, this may have cycles though. For a team of 100 people it is very efficient (mixes very well, all pairs are formed in about a hundred shuffles). Would be interesting to hear about an optimal solution for long term shuffling.
Open sauce for the flavour!
I know this is probably not what you want to hear but the "GUI toolkit" I use these days is "the web." I've been down the fat client route and I'm done with it. QT is the best of the bunch but I just can't stand dealing with the whole "distribute the packages and make sure they're upgraded" anymore. Even if you're dealing with a platform with a nice packaging system (e.g. Debian/Ubuntu) you still have problems pushing out in-between bug fixes. No one wants to wait 6+ months to get that annoying (but non-critical) bug fixed. Don't get me wrong: Fat clients have their place but unless you *need* one I would just develop a web app. JavaScript sucks (hard) but after a while you'll get the hang of it. You could also try out one of the compiles-to-JavaScript languages like Coffeescript or Dart. Now that I've said all that, I should disclose that I'm currently developing a web application that will allow fat client apps to run on the web in a seamless/natural fashion. Here's a screenshot of some of my recent progress: http://i.imgur.com/oT0YqdQ.png So go ahead and make your fat client and I'll make sure you have a mechanism to make it available on any web site (yes, any--you can run your Gate One server at foo.company.com and make your app available at bar.company.com since WebSockets have no origin restrictions).
The std lib is way to big for a single package. The std lib needs releases independent of the Python releases. This way people can pull down fixes without needing to upgrade to a whole new Python release. Projects like 'simplejson' got absorbed into the std lib and now they no longer work with packaging tools (e.g. 'pip list simplejson' will show nothing, yet the lib is there for import but you can't declare that project as a dependency in your setup.py). Developers shouldn't be punished by having to jump through crazy hoops to pull down fixes just because they wanted to use a package in the std lib. 
Ubuntu does have commercial support.
Could be wrong, but my bet is that an Oracle / SAP implementation would practically mean going with a big or even directly related consultancy firm. The nature of open source is much more scattered with interdependent components. Knowledge maybe the same. That would open up opportunities for smaller businesses. 
Unless you're using a large swathe of those functions and are disciplined to never clobber them, I suppose it works. Still ugly and doesn't indicate what you're using though
Exactly it is not necessarily bad in general. They just make money by putting butts in seats for long periods of time. It is just that in the short term the butts they put in seats have "Oracle Certificed &lt;something&gt; &lt;something&gt;" so now they'll have to get "RabbitMQ Certified &lt;something&gt; &lt;something&gt;" titles.
Easy: 1) learn Python 2) become a fucking DBA 
&gt; That would open up opportunities for smaller businesses. So basically just changing the landscape, not so much leveling it. I see your line of reasoning and upvote.
I worked for Basho when this happened. We weren't allowed to release this video at the time. http://vimeo.com/63232221 Basically the NHS spends so much money on oracle that is the equivalent of a baby every 2 weeks (in quality mean adjusted life years). Amazing stuff.
I love PyQt but after using IPython Notebook I'm starting to see the appeal.
Ahhh they've password protected it. Bummer.
If you like math, Project Euler is really fun and gives lots of problems for you to solve. You don't necessarily even have to know many of the math terms as they provide examples. It is how I have been learning to make my programs more efficient while also learning more complex ways to code!
Sorry for being crude: how much a baby is worth?
&gt; Training Random Forests in Python Every now and then it strikes me how odd the language of today would sound to someone from, say, 100 years ago.
This won't work unless the system in question has Internet access. This is often not the case in corporate environments. Never assume the user has Internet access.
...and if you need any help *I am the author*!
* http://fileconveyor.org/ * http://pythonhosted.org/fs/ * http://en.wikipedia.org/wiki/Rsync * https://github.com/openstack/swift * http://docs.openstack.org/developer/swift/associated_projects.html#associated-projects * btrfs, openZFS, Ceph, GlusterFS
my guess is that the data that they need to display already exists and the djnago orm probably will be useless in that scenario. and if you can't use the orm, there's not really any value left in django. 
Depends on baby _what_. Baby carrots are a dollar a pound, I think.
I think it will be as an api frontend for services, not a user-facing site that Django would have excelled at.
As someone who did PHP for about half their 15-year web development career, switched to Python and never looked back, I can give some advice. The links most people gave are dead on. There are books and tutorials for just about every kind of learner. I learn best from hacking on examples and seeing how things I'm used to are done - check out sites like https://github.com/faif/python-patterns, and http://melp.nl/2010/12/python-for-php-programmers/ (there are a bazillion other examples, I'd suggest going through several to get a well-rounded experience). Once you get the basics down, wander through the standard library and play around with what you find: http://docs.python.org/2/library/ When I first found it, I was reminded of the PHP manual on PHP.net, minus the comments, and I felt very much at home :D. I take issue with jumping right into web frameworks when someone is new to Python, especially something like Django. I would strongly advise against it. Switching to Python took me from *just a web developer* who was proficient at wrangling a messy but powerful web framework (PHP) to being a *programmer*. There were things I struggled against in PHP (namespaces, testing - at the time, OOP implementation, generated documentation, crafting user-friendly APIs...), that any sane language would provide, and Python does really well. To me, it's a step backwards to go jumping right into the arms of a kind, friendly monster that will chew your food for you if you let it (Django, Zope, some of the 'easier' microframeworks). Its important to understand what a framework buys you. My advice is to focus on getting to know how to wield Python like its second nature. Then, learn the fundamentals of socket programming, HTTP, and WSGI/CGI (I want to assume you have a leg up on this, but I did PHP for like 7 years so I know it might be a lot to ask). Get comfortable with what the standard library provides for web development - it's not always perfect, but it's the foundation of everything else that anyone does with web programming. At that point, you can make an informed decision about what sort of web framework you need to meet your project requirements - there's a reason why there are dozens and dozens of them in Python, many with great history and communities: there are many, many ways to approach web application development, and very smart people have implemented most of them, in Python :) Good Luck!
On the contrary, going with a custom stack like that referred to in the headline will almost always require more consulting not less - the idea is that the saving on the software itself is still greater.
I've been having the same issues. :-/
PHP does type juggling - it tries to figure out what you mean to do with a value and make a decision for you (an example: http://stackoverflow.com/questions/8671942/php-string-comparasion-to-0-integer-returns-true) Python is duck typed, so it's dynamic and flexible, but rigid in pragmatic ways - for example a string is immutable, but you can iterate over it (treat it like a list/array) - so it's tempting to do something like: my_string = 'hello' print [x for x in my_string] my_string[3] = 'a' The attempt to change the 4th letter in the variable fails - IIRC PHP will let you do this. PHP doesn't care about formatting, especially whitespace. PHP lets you intermix code and STDOUT. You can do things like Hello &lt;?=$world?&gt; in a bare code file (I've done it in places that I struggle to admit, like inside of a class method body). PHP interpolates double-quoted strings like Perl - "hello $world". PHP has the concept of "includes", which work a little like server-side includes in Apache - you call &lt;? include("file.php"); ?&gt; and the code is executed inline, as if you wrote the code in the parent file (there's some nuance, but that's basically how it works) So in these ways, PHP is a less strict language. The term is confusing because it's also used in the concept of "strict typing", like Java, but PHP is infuriatingly flexible :) - maybe not as flexible as Ruby (or Perl), but even Ruby and Perl don't allow things like bare output inside of code :) Maybe a better term is "rigid" - Python is more rigid than PHP... maybe "pragmatic" fits best? I've found that Python has just the right mix of flexibility and pragmatism (not so much *strictness*). [PEP8](http://www.python.org/dev/peps/pep-0008/) is a great example - it's very natural to the way any Pythonista might write Python, yet it's prescriptive in some stylistic ways that some people wouldn't nitpick over. 
I thought I give you an answer instead of my opinion, as others did here: There is the O'Reilly School of technology certificate course, consisting of four paid courses. A free alternative would be the Udacity 101course.
Great answer and I fully agree, but I still prefer `gevent` to both of them :)
Anaconda can also set up environments using either Python 2 or 3, so it's easy to try out both.
Was just an example :)
Why does no-one every discuss packaging python *applications*. Sure, writing libraries is great but at some point, there has to be an end-user or there's just no point.
As someone who has studied the Twisted source code, I can tell you it's generally pretty OK. The main issues are the fact that a huge amount of documentation hasn't been updated in ages (you wouldn't know that you're supposed to use Endpoints for creating sockets now if someone didn't tell you), and the developer team tend to struggle with architectural issues being pointed out to them (twisted.cred is a mess, and implementing it in a maintainably secure manner is impossible based on their interfaces). Also, for all its flexibility, it can be extremely rigid in places. For example, twisted.web.template doesn't allow you to inject raw HTML into the output, at present.
I've thought about this myself... The simplest solution is to just use the ctypes module to allocate and destroy your data structures as needed.
For what it's worth, I like to do both. I certainly want written documentation, but video screencasts are useful to get a quick overall gist. Things like general use cases can often be conveyed more easily through speech and/or video. Keep up the good work.
The Hitch hiker's link is broken. I think you probably want [this](http://python-packaging-user-guide.readthedocs.org/en/latest/index.html), but it's not fully complete yet.
I'm legitimately curious to see how much of this can be expressed with NumPyPy and how the performance compares. Since, however, we're all busy working on our own projects... Pull requests are welcome: https://github.com/numfocus/python-benchmarks 
It's just that I wrote the benchmark and reporting script in one afternoon and it was more complex to add support for PyPy as it requires spawning a separate process to run the PyPy benchmarks whereas all the other accelerators are just libraries for the traditional CPython process. Adding support for benchmarking PyPy was planned from the start as stated in the [second commit of this repo](https://github.com/numfocus/python-benchmarks/commit/4b7b4bc3384ff29e972381324346d1873ff2ef1d). I don't have much time to work on improving the bench / report generator now but I would be happy to review and merge pull requests to add PyPy benchmarking results. Matti Picus sent me an email as he was interested to add support for PyPy almost a month ago but I have no news. Disclaimer: I am a contributor to none of the benchmarked projects. I was just curious to know how they compare on a neutral ground (my laptop :) and just made a tool to push a report to share the results with library authors.
 C:\Users\Ivo&gt;dir go Volume in drive C is System Volume Serial Number is **** Directory of C:\Users\Ivo\go 15/05/2013 05:13 PM &lt;DIR&gt; . 15/05/2013 05:13 PM &lt;DIR&gt; .. 16/05/2013 02:46 PM &lt;DIR&gt; euler 0 File(s) 0 bytes 3 Dir(s) 145,369,853,952 bytes free C:\Users\Ivo&gt;cd go/euler C:\Users\Ivo\go\euler&gt;cd ../.. C:\Users\Ivo&gt;python Python 3.3.2 (v3.3.2:d047928ae3f6, May 16 2013, 00:06:53) [MSC v.1600 64 bit (AMD64)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import os; os.chdir('go/euler'); os.getcwd() 'C:\\Users\\Ivo\\go\\euler' &gt;&gt;&gt; No offense, but you're kind of new to programming if you haven't realised how long this has worked for... This is a path divider, not the start of one. You can't say `x = / sub_dir` any more than you can `x = // sub_dir`.
The overloading is a bit ugly, but in many cases it is very useful to use instances of classes to represent something like a file system path. For example, it would be nice to be able to do something like: p = path("/home/user/dir/") for f in path: print f.name for dir in p.dirs: print dir.name print list(dir) # everything inside the directory for f in p.files: print f.read() Iterating through files and directories as lazy file objects with some utility methods and attributes is nicer than having to do `os.path.listdir()` and `os.path.isdir()` and `os.path.isfile()`. Operator overloading should only be used in the clearest and simplest of cases though, I agree.
Here's my running commentary as I read it. This is rather negative, but I'm trying to be constructive about it. This is addressed to the author of the module, who may or may not be OP, I'm not sure. `cat` is obviously redundant to `itertools.chain` and it even points this out (~~NB: The `chain.from_iterable(...)` looks silly when you can just write `chain(*list_of_lists)`~~). The `list()` call around the `chain` is unnecessary most of the time; it additionally wastes memory if I'm merely going to iterate over the chain. Overall, this is not a great start, and looks like little more than keystroke-saving. It's also eager by default, which is bad form in Python 3. Oh, and don't say that something "requires imports" when your own module does too. Especially since the other option is installed by default; importing a standard library is much less of a big deal than importing a third-party module. For `merge`, you can use `itertools.chain(d1.items(), d2.items(), ...)` (assuming Python 3 so `dict.items` is lazy; otherwise use `iteritems` instead), and you can even pass the result to `dict()` if you need more than iteration. Sets can be unioned with `|`, and tuples are heterogeneous; "merging" them makes no sense since the elements may be of different types. Just concatenating them is easily accomplished with the `+` operator. Having a single function for all these things seems odd since they have totally different semantics. The regex stuff is mildly interesting since regexen in Python are moderately annoying to write, at least for me, but not worth a whole module for. This is bad: from funcy import * Don't tell people to do that. It indiscriminately dumps a bunch of objects into the user's global namespace, polluting it rather badly. You can instead do something like this: import funcy as fy That way, you still have a namespace, but it has a nice short name. Most of the stuff with `re_tester` can be done clearly and succinctly with `lambda`, so they're just keystroke-savers. The collections stuff is largely redundant to comprehensions, and IMHO harder to read. The data manipulation stuff does look moderately interesting, since I couldn't immediately think of reasonable one-liners to replace most of them.
Hi, I'm the author. I admit a lot of the practice questions materials aren't up yet (I think I only have about 8 of the 24 chapters done), but I'll pick up that ball again.
Qt-Designer and PySide are good!
I explained the way I use imports here http://hackflow.com/blog/2013/10/13/functional-python-made-easy/#comment-1081574650 Most other stuff is about having nice names being a low value. I don't think so, especially when you need to use a pattern to avoid it. I agree however you should carefully choose when you use funcy tools and when stay with just list or dict comprehensions.
I always use PySide (Qt) whenever I need to add a multiplatform GUI for one of my applications. It takes some time to get acquainted with the sometimes not-so-pythonic API of Qt (though PySide is a great help in that regard) and the signals/slots concept, but once you've got that put behind you, you can be very productive with it. Plus your GUI will work on Linux, Windows and Mac OSX with native looks!
**This isn't functional**. It's some handy generic functions. There's a big, but not always appreciated, difference. This is a **really** good talk to learn some important "malpractices" of 'functional' libraries from, and also some of the reasons why a lot of so-called functional libraries that have become trendy don't actually help as much as they could (should) in primarily OO/imperative languages: http://functionaltalks.org/2013/05/27/brian-lonsdorf-hey-underscore-youre-doing-it-wrong/ I highly advise you check it out and see if you can apply any improvements :)
Unless I tried to use this library each and every single day, I think I'd be able to compose standard library functions into the same functionality faster than I could lookup the names from here. Rather than simple one-liners over the basic data types, I'd try and write higher order functions which make combination easier. I know there's some cases where haskell lets you write 5 lines of code that would represent 40 in any other non-first-class-functional language, because its means of composition are so well designed - that's the sort of thing that would get me interested in a library of this type, not one that just lets me write two lines of python in one.
But that doesn't explain your advocacy of bad practices.
http://docs.python-guide.org/en/latest/#scenario-guide
In the very first example from operator import concat reduce(concat, list_of_lists) Can't you just do reduce(list.__add__, list_of_lists)
I got sick of remembering which TV episodes I was up to when downloading torrents, so I wrote a python script that: - keeps a local database of the current season + episode # for each TV show I watch - walks through the TV show list once a week, scraping thepiratebay for candidate torrents - chooses the best torrent for each episode (a fuzzy combination of many factors including file format, file size, number of seeders/leechers) and downloads it with Deluge - increments the episode counter - occasionally checks for completed downloads and moves them into the correct TV show folder - scrapes metadata for each TV show folder (box art etc.) from IMDB or similar There were a LOT of edge cases and external dependencies to think about with this script, and it was something I chipped away at over a year or two as a side project. Now it works pretty flawlessly and I get an email report once a week from my HTPC telling me what new episodes have downloaded and are ready to watch. Occasionally something will break (eg. TPB changing domains, the great 2012 switch from torrents -&gt; magnets etc.) but I've got some unit tests that run on startup and report failures to me via email. I believe there's software out there similar to this already, but I prefer my solution as it's more robust/flexible, plus it was a fun learning exercise. I also wrote a puzzle game level generator that used genetic algorithms to zone in on "interesting" level designs (ones that took many moves to "solve"). I never finished this one as it was a bit of a black hole in terms of effort and goals, but it was a great way to learn about genetic algorithms and PyPy. A while back I was making an iOS app that used neural networks to analyze the camera image in realtime and look for katakana, then overlay the phonetic pronounciation in English, so travellers in Japan could "read" the menus with their phones. I wrote a python script (using Python Imaging Library) to generate much of the training data for the neural networks, namely thousands and thousands of PNGs of katakana characters in different fonts and orientations, with varying amounts of noise. Again this was a really fun (and ambitious) project which I got probably 70% of the way there, but ultimately it was just too glitchy and slow to really be useful so I threw in the towel. At work (I'm in game development) I'm constantly writing Python scripts to automate build pipelines and processes. On Dead Space 1 &amp; 3 I wrote a one-click Python script to get the latest build from Perforce and generate all code, levels + data (which took several hours for a clean build, and involved maybe 10-15 steps). Made life a lot easier. I've also written Windows system tray apps that offer shortcuts to automated build tools as above. Gamedev requires a lot of in-house tools and pipelines as you can imagine. All in all, Python is a brilliant glue language, and the whole "batteries included" thing is really true... there's a library for just about everything, whether it's reading/writing a specific file format, interfacing with the internet, or doing big computational stuff.
"*Merge some dicts*" is now possible with [ChainMap](http://docs.python.org/dev/library/collections#collections.ChainMap)
Automated most of my bluray collection ripping. Now the track extraction, subtitle conversion, handbrake encode, and mkvMerge all happen automatically based on parameters you pass it in the file name itself and the scripts ini file. Did a Star Wars FFG dice app that was decent enough for FFG to ask me to pull it while leaving all the other ones up. On hold: Star Wars nav-computer (galaxy explorer) interactive map of all 5000 known stellar objects, trade routes, sectors in the Star Wars galaxy. The last one is very cool, but it needs a LOT of optimizing before I can move on, it's damn near unusable right now.
One of my first python projects was a script that synced my friends list across all my reddit accounts. It helped me learn how http requests, lists and list comprehension, and regexes work in python. It can be found [here](https://github.com/gehsekky/reddit-scripts). Another beginner project I did was making an IRC bot which introduced me to the Twisted networking lib as well as the html parser object and file IO. It can be found [here](https://github.com/gehsekky/shibalbot). Good luck on your python journey!
The company that employs me has an Android AV product that I work on as a reverse engineer. We have over 3 million APKs in our system to scan for malware which is no small task. We have a large processing cluster that analyzes the files for malware indicators and flags them for an analyst to look at if there are any. It's all running on Python. Most of our custom tools are also written in Python and other tools such as IDA Pro have Python scripts and extensions. Python lets me do things in a fraction of the time it would take using the other languages in use at the company.
Oh I see. I was taking the argument description, `list_of_lists`, too literally.
Wow I want to be you.
Thank you! This looks great. I hope to be able to send you PRs. I could never understand bokeh's approach: you need redis, coffeescript, etc. Wat? This looks cool. Works in the notebook, dependencies are all pretty normal.
As someone who has used Celery extensively, and uses it every day, I would not recommend using Celery in this manner. Celery is a fantastic tool, but it wasn't designed to be an API management layer. Its meant to quickly and easily create asynchronous tasks in an infrastructure that can be trivially scaled. Using celery as an API manager would encourage bad coding practices. One of the great parts about SOA is that you should have small components that communicate to each other through very limited channels (read: Unix philosophy). Therefore, it is very important to take time to structure your APIs in a scalable, maintainable, sane way. What you allow them to communicate is just as important as what you don't allow them to communicate. Limitation is a feature. Celery is fantastic because I can make a simple python function asynchronous with literally one line of code. Awesome, powerful stuff. However, this is not a good thing when using it to create an API. It would make it *too* easy for developers to create endpoints, leading to really shitty API design. As a side note: Also surprised author missed Celery webhooks when discussing this: http://docs.celeryproject.org/en/latest/userguide/remote-tasks.html EDIT: I re-read that and thought it sounded a bit harsh. I actually really liked the article. I thought the author made a good effort explaining to the reader what felt like an investigation into an interesting possible architecture decision. I just wanted to make sure no one makes the mistake of ACTUALLY doing this :-) 
Cool! Was thinking to start branching out to android. Definitely going to look into this!
Does it need a lot of processing power? Sounds like a great idea for enhancing a game like that.
Dead Space 3 coop is awesome, so thank you for that game ;). But these kind of projects are exactly what i was looking for. Just everyday/work problems converted into useful programs. 
Mandatory "half or more of EVE Online is written in python" http://www.slideshare.net/Arbow/stackless-python-in-eve 
nice!
Many moons ago, I worked at a place that handled DNS for a certain large well known internet company. I wrote a python application that handled the DNS change requests from them. It was a really screwy modified XMLRPC protocol, where no one could use normal XMLRPC libraries. It had something to do with making XMLRPC transactional. I used Twisted to handle the network side of things, and because of the bizarro modded XMLRPC, I had to do double XML parsing. Because I had to return status of each request as it was received (as opposed to waiting until we got the entire transaction, then parse it). As I said, it was screwy. We also had to write our own ORM, because we had one DB feature that none of the existing ones had (at the time at least, things may have change). Good times.
Wow. I can think of dozen friends who are clinging to R for ggplot. This is a huge win for the data community! 
I always feel like game development is something that most people avoid in Python, but it's definitely possible. I'm working on a roguelike inspired by the likes of STALKER and Fallout, with some very detailed AI that manage needs, form factions, perform tasks together, etc. It's still not the fastest language in the world, but the idea of games not being possible (or people being told to avoid making them) in Python is largely false. A combination of Cython and well-optimized code works wonders. Some screenshots: http://i.imgur.com/rAnZQ9M.png and http://i.imgur.com/33tScHc.png
That is exactly correct. I was screwing around with this recently, and I think the name of the function type is BinaryExpression. You can do some really wacky stuff with it, although I'm sure it's not recommended. 
Finally! Thank you, yhat!
&gt; /u/im14 -&amp;gt; /u/V_IojjjoI_V 0.0003 Bitcoin
As a volunteer [this](http://teachers.supersaturday.org) which was re-written by someone who was more comfortable with the microsoft stach after I stopped volunteering. It was originally in turbogears. Professionally [this](http://batterii.com) (the product, not that website) backend written in pyramid runs on appengine, front end is emberjs. For fun... [my github](https://github.com/twillis) 
It's usually not a good idea to do things like that off-the-cuff in your own code, but if you're writing something as complex as an ORM package, implementing something like this would make the most sense, as it would remove complexity for the users, without making it complicated.
What is/are the benefits of ggplot compared to to matplotlib/pylab? Also what is/are the advantages of R for big data? (Or where is a good place to start reading about R?)
&gt;What is/are the benefits of ggplot compared to to matplotlib/pylab? please answer this! 
check out section 20.5 in the SQLAlchemy chapter of [the architecture of open source applications](http://aosabook.org/en/sqlalchemy.html), describes the history and general mechanism of this feature.
Thanks for the info. I might play around with it, but since I'm already good with matplotlib and dealing with the default setttings, I'll decide later if I actually want to switch and/or use ggplot for somethings. 
Are you using libtcod or pygame? or even pyglet :O? I'm a fan of game-making in python too, countless failed attempts at games but I'm onto one that actually is seeing an end! 
Just flipping through my dev folder- * signature generator- This pulls info from active directory and generates html, rtf, and plaintext signatures for Outlook using Jinja2. It sets the registry entries and copies the signatures to the proper destinations. Bam! Unified signature control. * asterisk trunk count- We use Asterisk exclusively for telephony, this give me an accurate count of how many trunks we currently have in use companywide. * windows process watcher- Watches a specific process and kills it if it's cpu usage is &gt; x% for x seconds. 
FYI the [mpltools package](http://tonysyu.github.io/mpltools/auto_examples/index.html) has a ggplot style and [integrates directly with matplotlib](http://tonysyu.github.io/mpltools/auto_examples/style/plot_ggplot.html).
&gt; That's kinda neat, but not sure if it's a terribly good idea. What do you guys think? i think it's a good idea for the context. 
Looks good, I'll look into it.
i came here wanting to write nearly the same. I also did a tv tool in python with the exception, that mine has a nice webinterface instead of weekly mails, so i can load episodes right onto my phone in the morning. and i am using transmission via rpc. additionally it gets its information about what episodes to look for from tvrage.com.
 filter(foo == bar, ich == elaine) versus filter(foo = bar, ich = elaine) First ensures order which doesn't matter so much with the SQL servers SQLAlchemy uses but it becomes a big problem when the order of conditions is important ( ex Cassandra ). Greater or less than is filter(foo &gt; bar)` versus filter((foo, "&gt;", bar))` or filter(foo__gt = bar) #I really hate this though will admit its a clever and cheap fix filter(my_model.foo.lt(bar)) #I haven't seen this in Python land but I vaguely remember a PHP Domain model system did something to this effect. Ranges can also be done by overloading __contains__ and or __iter__ so filter(foo in [1,2,3]) would become `WHERE 'foo' in (1,2,3)` or however the SQL engine of choice handles membership testing. A fun problem that is legal python but I don't think SQLAlchemy handles is `1 &lt; foo &lt; 5` and is True in python when foo is greater than 1 and less than 5 (2...4). 
We have made a video downloader. It supports more than 100 websites including Youtube, Facebook and Dailymotion! The source code is on github. The name of the script is youtube-dl. It is currently one of the trending python projects on Github. The link is http://www.github.com/rg3/youtube-dl
I wrote this: A Python script that uses ffmpeg and the mp4v2 tools plus data from themoviedb.com or thetvdb.com to create a neat, iTunes accepted .mp4 file for a movie https://github.com/dvorberg/movierip Years of experience fiddling with ffmpeg switches went into this script ;-)
http://docs.pythonpackages.com/en/latest/
So... it's a fancy way of doing ``./setup.py upload``?
Ohh my. :-)
&gt; Twisted is Java code that was machine translated into Python Marry me.
&gt; Also what is/are the advantages of R for big data? Big data is a bit amorphous to define. The more useful definitions I've seen suggest that data are "big" if they run afoul of one or more of the 3 Vs: * Volume (genuinely large quantity of data--probably terabytes), * Velocity (data need to be processed on the fly because warehousing is impractical), * Variety (data don't readily conform to a neat schema). If we consider only volume, neither Python nor R are really ideal. R is notorious for inefficient use of system RAM through it's everything-in-RAM/copy-on-everything features. Python is marginally better on the RAM front in that passing references is a thing. However, Python's multiprocessing story is also not great, which makes it somewhat less than ideal. That said, I generally prefer R to Python for data-ish tasks because I find its more functional idioms nicer than Python. I also can be pretty sure that R will have support for any sort of analysis I could imagine. I think the best place to start with R is to dive in with a project. Bootstrap at [the interactive tryr tutorial site](http://tryr.codeschool.com). Maybe take [Roger Peng's Coursera course](https://www.coursera.org/course/compdata). Then dive in. Packages, tutorials, and papers written by Hadley Wickham tend to be informative and awesome. Other tools for big data? Well, I think functional languages have a conceptual advantage. Clojure and Julia are my two contenders for "languages that are not R or Python that I would consider using." EDIT: markdown bracket dyslexia
Thanks for the very detailed response. I currently use python for everything that I do with my analysis. I'm only working with ~10% of a 2TB data set (Volume) which is not growing (velocity), and conforms very nicely to a (set of) format(s) (Variety), so I don't do anything that fits under "big data" and more or less haven't run into any limitations with Python. Thanks again for the resources. 
Also don't discount good old fashioned SQL. I took the Intro to Data Science course on Coursera, and it really opened my eyes to how truly awesome and efficient SQL can be for data analysis. In short, people who are about 600 trillion times smarter than me figured out the gnarly details of relational algebra, indexing strategies, and query optimisation. Depending on the database, the DB can even multithread your queries automagically in many cases.
I wrote Gate One: https://github.com/liftoff/GateOne It's a web-based terminal emulator and SSH client but soon it will also be an X11/remote desktop tool, file transfer/batch mechanism, and some other things. X11 is what I've been spending most of my time on lately. I've got it working OK but it needs some features to make it more robust like rate limiting and windowing features (e.g. minimize--maximize works great though =). I'd also like to re-work the way its packaged. Right now it installs itself into /opt (or whatever prefix you give it) but I'd like to make it install more like a regular Python module where you can do "from gateone.utils import shell_command" from anywhere (as opposed to just inside /opt/gateone) with the settings_dir changed to something like /etc/gateone by default.
Yeah, as someone who hasn't used R, this API is just plain horrible. Print statements for making a plot? What the hell! I'll stick to matplotlib thanks.
&gt; That said, I generally prefer R to Python for data-ish tasks because I find its more functional idioms nicer than Python. I also can be pretty sure that R will have support for any sort of analysis I could imagine. I think the best place to start with R is to dive in with a project. Bootstrap at the interactive tryr tutorial site[1] . Maybe take Roger Peng's Coursera course[2] . Then dive in. Packages, tutorials, and papers written by Hadley Wickham tend to be informative and awesome. As someone who's worked in 'big data' in Python and now is using R, allow me to provide a counter argument for Python. R is an awesome language for doing EDA, and admittedly there's a package for just about every statistical method ever developed. None the less, I find it cumbersome going beyond EDA. I find R's OO isn't as nice as Python's, nobody in R seems to like namespaces, and while there are all those nice statistical packages, the API is all over the place. Basically R feels like the perl of data analysis to me. R also has fewer good web/graphical toolkits if you ever want to change your one off analysis script into an application. I also like Cython more than Rcpp for optimizing code.
What's with everybody importing * into their namespaces in graphics tool kits?
...Uhhh..
Also a huge peeve of mine.
Yeah I'll stick with matplotlib and just use this. I totally forgot about matplotlibrc file. Thanks for reminding me.
Is there a video of this talk? Edit: Found http://blip.tv/pycon-us-videos-2009-2010-2011/stackless-python-in-eve-pt-2-1959372
&gt; But I think it's reasonable to say that many R programmers are statisticians who grew into programming, rather than programmers who grew into statistics. QFT. I find this is very much the case, and the libraries exhibit some of these warts. But it is getting better. Both are fine languages, I just wanted to include some arguments for why you might want to choose python over R. As for OO, since most of my 'big data' work has been in developing tools and libraries for analysis rather than doing the analysis, I like OO as a design methodology. 
ggplot's API isn't really based around R idioms, it's its own thing entirely. Python probably has a more defined sense of what is and isn't idiomatic, but I wouldn't dismiss it on that basis. It didn't do well in the R community because it was R, it did well because it's fantastic. It's really focused on the mapping between your data and the visual features of your plot, and if you haven't tried it you definitely should. 
To save time than `from X import a,b,c,d,e,f,g,h,i,j,k,etc`
 &gt;&gt;&gt; class A(): ... def __eq__(self, val):print 'nope' ... &gt;&gt;&gt; a=A() &gt;&gt;&gt; a=='reddit' nope 
Aren't you just restating what I said as a benefit and not a bad design decision? To understand my point you need to know that matplotlib started out the same way and has spent a decade trying to reverse it.
The huge advantage of this is that you can gradually build up your query, as well as the condition on which you want to filter : condition_1 = Author.name == author_name condition_2 = Author.first_name != author_first_name query = session.query(Author).filter( and_( condition_1, condition_2 ) ) This allows reuse of parts of your query, and makes it possible to handle complex queries.
I literally spent 2 days getting at code to port over solely so I could use ggplot !!! Well done! 
&gt; Brokeh I see what you did there.
&gt; Basically R feels like the perl of data analysis to me. I've always thought this. Great for short to medium scripts; a little more difficult to manage when the project becomes bigger. R now has java/python-style reference classes, in addition to the S3 and S4 object systems which are more like CLOS. So you get to choose...
When the global space is cluttered, that's user error - not a language problem.
Just open a github repository and get going. :) Maybe take a look at: http://blog.smartbear.com/open-source/how-to-turn-your-pile-of-code-into-an-open-source-project/ for ideas
Indeed. However, I find data frames in R easier to use than data frames in pandas, and also the syntax of R is more familiar for doing models. I guess it's a thing of getting used to it, but...
oh i totally understand. R was my first language, so for several years I was all about the `foo$bar` syntax. I just wish R enforced a more consistent api across packages. 
that must be exhausting! on the other hand, working out why your project breaks because some shitty third partly library added def list(*args): return "HAHAHA" is not at all time consuming, especially if multiple libraries are doing import * to save time. That sort of madness does not scale.
Is there any video recording or slides ? I only see an abstract there.
How do you like Clojure? It has a fantastic concurrency model, but have had any slowdowns doing matrix operations on the JVM?
I keep coming back to this project to check progress. I'm glad they finally added BFGS for optimization tasks, but it's still fairly bare bones. have you tried Weka or Mahout with Clojure at all?
What I firstly programmed in Python is a small scrapping script that downloads all user-uploaded images from an image board. It’s about 2005, and I used no third-party libraries but some modules in the standard library: `re` for parsing HTML strings, `urllib2` for requesting the image board and downloading images, and `threading` for parallelizing these tasks. Before that I used Java to achieve similar tasks, but I immediately had fallen in love with Python. It was an amazing experience for me. I was a high school student at that time.
Yes, it's only the abstract. I'm afraid that no material is available yet. 
This will be about the Quartz project. JP Morgan have a similar project called Athena. Both Athena and Quartz are based on the same fundamental design exemplified by Goldman Sach's proprietary system SecDB/Slang. Unlike GS, thjey don't use a proprietary programming language (Slang) as they've adopted Python. However, they do use proprietary NoSQL tech, and a proprietary graph based calulation model that's very closely integrated with Python using decorators.
it's actually quite trivial to measure completely bypassing the benchmark runner. PyPy for loops were about 12x faster than pure Python, the numpy tile was not working and I broadcasting was, but I don't remember the results (I think it was slower than numpy. This attitude is a bit annoying though and that's why I won't spend any time trying to even make benchmark runner help.
No, I only use R for regressions. Just look at this horrible syntax in python: * slope, intercept, r_value, p_value, std_err = stats.linregress(xi,y) vs R's pretty: * data_set.lm = lm(y~x+x2+x3+x4, data=data_set)
&gt;change the order in which statements are executed Whoa, no. Flow control is deciding which block of instructions execute, not changing execution order.
Indeed. It's obviously a lot less complete than the whole of R, but it's a great starting place. The [Clojure Numerics people](https://groups.google.com/forum/#!forum/numerical-clojure) are making nice progress toward eventually being the pluggable, modular replacement matrix math backend for Incanter. Incanter itself recently swapped out Colt for JBlas, which improved things.
I was at the talk, if you have any questions maybe I can answer.
 Clojure, the language, has a lot to recommend it beyond just the concurrency model. Everywhere I look, the core functions are really consistent and well thought out. Going through the exercises at [4Clojure](http://www.4clojure.com/) is a fun way to get an appreciation for some of the core functions. On the other hand, the JVM definitely has downsides for the numerical part. The [Clojure Numerics](https://groups.google.com/forum/#!forum/numerical-clojure) group is working toward on improving the matrix math story in Clojure, but my understanding is that there is only so much you can do with the JVM. Performance isn't horrible, but matrix ops aren't going to be as fast as something that is able to work directly with OpenBLAS or MKL. At some point, I sort of imagine Clojure making the jump to LLVM to be great for numerics. There are definitely people working toward this, but who knows when that will happen. Right now the benefits of being on the JVM are in terms of the interop with Hadoop. For numerics, the other up-and-comer is [Julia](http://julialang.org/), which is making staggeringly fast progress in terms of library development. The matrix math story is better there, by virtue of targeting LLVM/OpenBLAS from day one. I'm not sure I like Julia as well as Clojure from an elegance perspective, however, Julia does have some really compelling features. They even claim to be fully homoiconic (like Clojure / Common Lisp / Scheme), but without the SExpression syntax that polarizes people.
Can you give us the slides or the video?
Is there any reason (beside lack of time and funds) why PyPy doesn't have its own C API which could be a target for Cython (with something like `--pypy-capi` flag)? I understand why PyPy can't follow CPython C API and needs cpyext emulation layer, but there must be a way of exposing PyPy object system, GC API and other internals to C world. I'm asking because I love Cython and it's quite sad the only real option to make a module work ok with PyPy is rewriting it with cffi. http://docs.cython.org/src/userguide/pypy.html works, but uses cpyext layer.
Unfortunately they were not provided to attendees either! If they are I can link them perhaps.
Interesting, I had a very different view of the initiative after seeing the talk. Of course, it was a python conference so some bias may have been introduced. Could you elaborate on what you know? 
For my Google Summer of Code, I wrote a Cython backend aiming python + ctypes, I didn't have enough time to finish it though. One day we might try again with python + cffi. The main issue I had was with emulating the C semantics in Python.
Can you share some bullet points and maybe keywords to get at least basic idea behind their move? Short summary would be highly appreciated too. Thanks!
[not the most informed person on this topic, but from my limited understanding...] I think one big reason is that PyPy's internals are so incredibly flexible -- swapping out GCs, STM (software transactional memory), etc. There may not be enough of a fixed target with enough useful commonalities to create an API *for*. CFFI on the other hand seems to be designed to make the C code unaware it's not talking to another C library, and push all the C&lt;-&gt;Python interface work into cffi and the python wrapper author. This lets whatever Python VM you're running (potentially) do much more optimization and analysis of the interface (metadata which PyPy's VM *needs* to have). The example I'm most familiar with is the psycopg2 library (a sophisticated Python wrapper for the postgres libpq client library). Internally it's C code is roughly split into two sections: the libpq wrapper bits, providing a common api for the C level behaviors psycopg2 needs to offer in order to fulfill Python's DBAPI; and a second section, which is basically just dedicated to wrapping all of that up in the Python C API. Once exposed, you've just got a handful of opaque Python-level datatypes, which happen to be backed by C code. If that library were rewritten to use CFFI, that second section would be written in Python, and (from the VM's point of view), they would no longer be opaque C extension classes, but introspectable Python classes, wrapping a C API whose metadata is available to the VM as well. This means you go from knowing *nothing* to knowing pretty much everything that's needed to compile assembly code to interact at the C level... all because the foreign function bridge was moved from the other language, and into Python where the VM could annotate and inspect it.
A ton of stuff. A multithreaded checksum [calculator](https://bitbucket.org/Quare/multihash) (generates md5, sha1, etc for isos), an HexChat [plugin](https://bitbucket.org/Quare/hexpaste) to paste poetry on the irc, a simple static site [generator](https://bitbucket.org/Quare/thingamablog)... Lately I've been tinkering with roguelikes. I'm wondering whether a roguelike with non-euclidean level generation would be fun.
I think the main reason is that noone will use a PyPy-specific C API. Cython itself is quite tied to CPython C API and exposing an API that makes sense (which means for example that you can't have pointer to things, because they can move) would not fit well in it's model. On the contrary, cffi bindings can be shared between CPython and PyPy and that way you can have only *one* implementation of something instead of two.
Haha youtube is the only website which gave us a problem. It required a lot of work because the encrypted signatures changed often. However we have automated the signature cracking process :D. And for the second question the answer is No. Till now nothing bad has happened. :D I hope for the same in future but who knows what is coming next!
That was my question with the latest version of statsmodels - for instance, check out [this page](http://statsmodels.sourceforge.net/stable/examples/generated/example_interactions.html). They've made the model syntax much more R like, at least for defining models (here salary_fit is a pandas frame with factors S, E, M and X): In [21]: formula = 'S ~ C(E) + C(M) + X' In [22]: lm = ols(formula, salary_table).fit() In [23]: print lm.summary()
ponyorm is WICKED. I had never heard of it. Thank you for the link. I wonder how updates to the visual schema migrates to the modelling of the database tables... and whether it updates tables, etc. They need a mailing list so we can chat about this excellent project.
that looks nice... sadly I haven't had time to actually learn pandas, I always struggle adding a simple row where I want it to be and other lame stuff like that.
If you're doing importing that much, just do `import X` and use `X.a`, `X.b`, etc. That way there's no chance of surprise namespace collisions, it's faster to track an imported function's location, and the extra attribute access will never\* slow down your application. \* for a really small non-zero value of never
Aw jeez, fijal. I like you, I like PyPy, let's not fight. Do you have any ideas for using PyPy from inside the runner?
&gt; They also moved to a custom VCS which allows developers throughout the company to work on any project they need too. Non-standard due to some legal requirements and general being a huge bank. That is an interesting statement. I think anyone would advise to simply use Git / Bazaar / SVN or Mercurial. With some of these even written in Python. Were any follow up questions asked about this? None of these would have licenses that would restrict use within a bank. I see how the GPL v2 (for Git, Mercurial and Bazaar) could make a bank run a little scared but to be honest they would never have to meddle with the code itself. 
Clever (I respect that), but why?
Why not? I like toying with Python to see what I can and can't do with such a dynamic language. Previously I made something to [inline python function calls](http://tomforb.es/automatically-inline-python-function-calls), entirely useless but it's cool that it could be done.
having to work with R and perl makes me appreciate the zen of python more and more
you could also use rpy2 to push data from python into R and use R to plot it.
Looks good on the surface, but it's sad to see that GC is still an issue. It's great that only 1 in 200 collections now take more than 15.7ms, but 15.7ms is still too big of a pause for many games to run smoothly, as that's roughly half your CPU budget for a typical 30 frames per second game. If such collections are quite frequent, it could continue to be a problem.
well, as you can see on a 10min of running such a benchmark with a big heap (1G) there were 3 or 4. I guess that counts as "unfrequent". Also there is an API to cause the collection step if you have some spare time in the frame. That should sort you out usually (we don't have the maximum-time limit yet, mostly because reading time is hard)
I can't see any indication that the benchmark was running for 10 minutes or that there were only 3 or 4 large pauses (the table indicates at least 129, for example). Not saying you're wrong, just that the data doesn't make what you say very clear. Being able to force a manual collection may help a lot. I'd certainly be interested in seeing any benchmark that was able to make use of that. 
Tail-call optimization would actually make it possible to write more succinct and clear (and hence less buggy) code. A lot of time, the obvious solution to a problem is recursive, so we write that and then convert it to an iterative version for "production."
Forgot to add, we plan to implement generation of Django models and SQLAlchemy entities from visual diagrams as well (without direct migration support, but this ORMs already have instruments to do migrations)
&gt;the obvious solution to a problem is recursive There's a difference between "recursive" and "tail-recursive". Even a factorial-calculating function requires using an accumulator to make it tail-recursive (the *obvious* solution, `x! = x * (x - 1)!`, is not.) More complex stuff, such as the depth-first search, cannot be written in tail-recursive form at all (as it's tree-recursive.) There's also the fact that a) when you remove stack frames, you lose debugging info; and b) you cannot easily prove that `f(x)` at the end of a function called `f` is in fact a call to the same function in a dynamic language.
Thanks for reply. You're right that PyPy is probably moving too fast to maintain a sensible C API. &gt; If that library were rewritten to use CFFI You are aware of https://pypi.python.org/pypi/psycopg2cffi, are you? :)
I was not aware. Cool! I'm gonna have to browse through that code a bit... I've been wanting to both use psycopg under pypy, and find a good example to study for using cffi + distutils in one of my own libraries. 
ok, sorry, my fault for not reading your numbers correctly. With 10ms to spare you need to be quite clever. E.g. tweak the nursery size (the default may cause the minor collection to last 30ms) and collect by hand. I don't think we can help to have sensible defaults for interactive and non-interactive purposes without input from the user.
But does it comment each section?
I expect most game developers would be happy to provide input. It would be very useful just to get some control over all these parameters. Keeping to the game example (as that is the use case I know best), there are some games which would probably prefer to try and do a tiny bit of GC every frame (eg. 30 or 60x per second), but there are others that would be happy to see memory usage grow for up to 5 or 10 minutes if it meant being able to avoid any slow GC cycles. I think this control is especially important since - unless PyPy improves on this significantly over CPython - there's little scope for using objects on the stack to avoid allocations.
That's a very good reason: don't stop pushing the boundaries.
It's pretty painful yeah. However that said, I'm not sure what else would work better in a large environment like BAML. I've heard war stories from other banks that make BAML seem like heaven. It's also very early days, I think quartz is only like 4 years old. Good luck refactoring a bazillion lines of python a C++ though!
try calling gc.collect(1) after each frame as a start. I would need a game example though (and pygame is not ported and pyglet uses ctypes which allocates tons of garbage, *cough*)
Ctrl+f transaction: &gt;Automatic transaction management using the db_session decorator or context manager. All data will be stored to the database after the transaction is finished, or rolled back if an exception happened. Of course Django does this too.
Maybe you'd cough less if you didn't eat garbage, lol.
might be a cool hack, but if you need a script to find out who's your friend and who's not, you're doing it wrong.
Hi, Pony ORM author is here. I'll try to explain what we had in mind when wrote this phrase. There are two popular patterns which can be used when implementing an ORM - one is "ActiveRecord" and another, more complex, is "IdentityMap". Django uses the simpler ActiveRecord pattern. This means that when ORM sends SQL query to the database and receives resulting rows, new object instances are constructed every time. This way multiple copies of the same object can coexist in the memory. The ORM doesn't know which objects belong to current transaction, and a programmer must explicitly call obj.save() method to store changes back to the database on each object. The ActiveRecord pattern used by Django is simpler to implement, but has several drawbacks: 1) In order to call save() method, the programmer must track which objects have been changed and it can be tedious and error-prone. There are situations when an object is updated in memory in one part of the application and then transferred to another application layer, and after that it may be hard to track which objects have been updated and should be saved. To simplify program logic, you can call save() method right after the object has been changed, but this can lead to ineffective code, when the program changes and then saves the same object several times. 2) Since the ActiveRecord pattern doesn't prevent situations when multiple copies of the same object exist in memory, it can lead to lost updates. If you modify several copies of the same object in memory and then call save() for each of them, only last update survives. 3) When you call Product.objects.get(pk=123) in Django, it is possible that the object is already loaded into memory. Because ActiveRecord pattern doesn't track which objects are loaded, it will lead to duplicate SQL query (which hurts performance) and to creation of multiple instances of the same object. In addition to aforementioned drawbacks caused by using the ActiveRecord pattern, Django works in autocommit mode by default. This means that each call of save() method is performed in a separate transaction. Transactions are not cheap, for example in SQLite you can do many thousands of updates per second, but only few dozen transactions per second (http://www.sqlite.org/faq.html#q19). I believe this is true to some degree with most other databases as well. So if your logical transaction contains several updates, in order to obtain good performance you should do a single COMMIT at the end of a logical transaction. The other problem with the autocommit is loss of transactional atomicity. When your program works in the autocommit mode it is possible that another process will read database after your program saves just a part of updates. This way another process will see logically incorrect database state and (by reading incorrect information and doing further updates) can logically corrupt data. Also, if your program raises an exception in the middle of the execution, only part of that changes will be persisted in the database, and the database state may be logically corrupted. --- Now I'd like to discuss what is different in Pony. 1) Pony uses the IdentityMap pattern, which keeps track of all objects loaded into memory during the current transaction. When an object is changed, Pony will remember this and upon commit will save all created and updated objects automatically. This way the programmer is freed from the necessity to call save() explicitly or remembering which instance was changed. If the same object was updated several times within the same transaction, only one cumulative update will be sent to the database. In addition to objects tracking, Pony tracks individual attributes and knows which object attributes were read and which were updated, so only updated columns will be saved to the database. Pony is not the only ORM which uses the IdentityMap. SQLAlchemy also implements this pattern. The difference is that in SQLAlchemy a programmer (by default) must explicitly tie instances to the current session, while in Pony this is happened automatically. This is just the matter of personal preferences, but I think that Pony frees the programmer from writing a boilerplate code. In the same time the feature of tracking of read/write status of separate attributes seems unique to Pony. 2) When a programmer requests the same object several times (by writing expressions like Product[123]), Pony understands that this object is already loaded into the IdentityMap, and will not send a new query to the database. Instead, Pony will return the instance which is already presented in the IdentityMap. 3) Pony ORM has two transaction modes - optimistic and traditional. In the optimistic mode Pony reads data from the database in autocommit mode (this mode is actually good for read-only queries, it is updates which are problematic in this mode), but when it comes to writing to the database Pony starts a short write-only transaction and saves all the accumulated changes to the database. Since Pony knows which attributes were read and written during the logical transaction, Pony adds optimistic checks to the update commands. This way Pony implements optimistic concurrency control and provides transaction atomicy at the same time. (In future release Pony ORM 0.5 we plan to combine both transaction modes into a single even more powerful mode). --- Back to phrase "automatic transaction management". We had no intention to say that Django totally lacks transaction management. In Django it is just turned off by default, and updating data in the autocommit mode can lead to logical data corruption. The Django docs discourages from using transactions by saying that "While the simplicity of this transaction model is appealing, it also makes it inefficient when traffic increases. Opening a transaction for every view has some overhead." In principle this is true, because the 'BEGIN TRANSACTION' adds roundtrip to the database server, and this is unnecessary for read-only views (Pony also doesn’t open a transaction using 'BEGIN TRANSACTION' if there were no changes when used in the optimistic mode). But suggesting using autocommit for updates instead of a separate transaction can lead to logical data corruption, especially when you need to make multiple updates within the same logical transaction. The most visible benefit of Pony transaction management is the automatic tracking which objects belong to the current transaction and saving all updated objects on commit automatically, without manually calling save() on each object. On the other hand, Django currently supports transaction savepoints and this is currently not implemented in Pony ORM yet.
Indeed it does, as is apparent for most Postgres users using pyscopg2 (sp?) with pgbouncer (connection proxy to keep stress off the RDMS ) http://stackoverflow.com/questions/8198990/pgbouncer-closing-because-unclean-server-on-every-connection
Mostly a crap ton of HL7 wrangling code.
I agree with your main point but a C++ lib for a bespoke socket protocol should be quite easy to wrap in python and there are some libraries to talk to java via JNI although I'd go with a service facade connected via something like zmq.
there's no namespace in algebra or statistics. Everyone use global functions for scientific formulas.. If A-Z are all used out, used Greek letters. (I think there's a special field in algebra for namespace management, but I forgot its name)
A great and useful library that I just downloaded the other day.
I've been using CFFI on my [pylib7zip](http://github.com/harvimt/pylib7zip/) module (which is also mostly broken), so I can sympathize with the author on several points. &gt; And sometimes Python segfaults, and I am very sad about that. This was said about Cython, but it's equally true with CFFI (CFFI doesn't lilke NULL pointers, who'd a thought?). Segfaults are hard to debug, I got really strange behavior, like I'd `assert x != ffi.NULL` and it would segfault, but if I did `import pdb; pdb.set_trace()` and then checked if it was null, it wouldn't be and I'd be fine. All sorts of weirdness with windows `PROPVARIANTS` too. &gt; One downside: CFFI claims a parse error when you use a C type that hasn’t been declared yet, and lays the blame on the next token with no mention of the name it didn’t recognize. This was not obvious at first. This needs to be documented better, it definitely violates the principle of least surprise, I'm pretty sure it's a problem with how CFFI interacts with pycparser though. I'm also targeting Python 3 primarily, and CFFI's python 3 support is preliminary. I can also relate to the weird library thing, 7-Zip is a C++ library that uses windows COM conventions... sort of. It doesn't actually register itself with the COM system, so you can't use `win32com` or `comtypes`. So you have to manually manipulate structs filled with function pointers which theoretically should never be NULL but sometimes are (at least on Linux). And pass in pointers to structs filled with function pointers which then callback. Everything uses `HRESULT` values to signal errors, but then uses undocumented error-codes.
I can't really give you an example, because it was just a general statement. To some degree it's already too late for game development on Python because performance has been neglected for too long, and because the only 2 options are Pyglet (poorly supported but fast rendering) and PyGame (well supported but slow rendering). But maybe PyPy will encourage further game development, especially if PySDL2 is supported. (But again, it uses ctypes. If ctypes is intrinsically a problem then I'm not sure what the way around this is. Easy access to C libraries is going to be near essential for games, one way or another.)
False, PyPy has no C Api since it is written in (R)Python. (So it emulates CPythons API for compatibility)
&gt; We're talking about overhauling the risk calculators So, have you guys estimated what the chances of Python succeeding in this tech transformation?
kivy is pretty awesome. Over the summer I made a drum machine/sample arpeggiator with kivy. 
To me, matplotlib has always felt unweildy. I had years of experience in Matlab (and in Python), and still found it hard to use. It has a lot of features, but the documentation once you get off the beaten path is cryptic and sometimes even incomplete. There are also a number of gotchas and stuff that just feels awkward. I'm not that familiar with ggplot, but it looks like they have a design that is more geared towards making good looking graphs with minimal effort.
Yeah, this is kind of a red flag to me. Also, the author's trepidation about installing the dependencies and hesitant advice to use brew or get the binaries. Can you not use pip to install those dependencies, or better yet include a "requirements.txt" in your package and pip install from that? This seems like a great package, but it just makes me a bit wary about other things they may have missed. edit: it seems that you cannot easily install scipy/numpy purely via pip
Thanks, but this isn't exactly what I'm looking for. This matches images exactly (fingerprinting). I need something with a bit of tolerance. CBIR will match images that are similar even if they don't have the same fingerprint. 
Ok, let's call it a leaky abstraction and call it a day. ;-) PS.Abstraction is only worth something when it hides underlying complexity.. In my experience, SQLAlchemy fails at that. But I'm willing to admit that it may be domain/application specific..
I feel that the description masks some simple intuition. All this kind of incremental garbage collection does is mark nodes as "not processed", "processing", or "processed". Whenever program logic updates a processed node, mark it as processing to make sure we didn't miss anything. Am I missing anything important? And is there anything stopping gc cycles from working concurrently with program logic? The only thing I can think of is updates to unreachable data perpetuating a cycle of unsubstantiated "grey" status. 
&gt;I mapping that back to capable objects is not quite possible without something like SQLAlchemy in between I guess, there are two main situations: (1) You use a database, essentially, to serialize data in your application. Your app is in full control of the database and may want to store some complex stuff in there. (E.g complex interconnected objects) Is it the case you have in mind? Then I don't have a good answer ;-) (2) The database already exists and your app is just one of many which accesses it. I mostly see the the 2nd case where I strongly prefer to have dumb Row objects which just have data attributes with very little or no behavior. And leave everything else to the upper layers of code.. 
Not sure I'd say Python's syntax is worse or better in your example. In Python example, it is unboxing values, that's why it has less cluttered parameter arguments. In R example, it has more cluttered parameter arguments. So it is a matter of preference on how cluttered you want the parameter arguments you can bear.
&gt; Also, nothing wrong with using propriety or combining the two. Nobody said there was. The observation in and of itself is interesting. For example, I didn't know GS used their own proprietary PL.
This is why its at least **partially** also a language problem. I get a script from someone or find one on the net. It uses 3 libraries that I am not familiar with. Without going through the process of learning the guts of *each* of those libraries, I do not know which methods are allowed to be used on what type of objects. When the method lives in the namespace of the object it is unambiguous and I can start using that code RIGHT AWAY. Thats kind of one of the **points** of the OO model. R seems like is a perfect example of a [Camel](http://en.wikipedia.org/wiki/Design_by_committee#Aphorisms) language. Each library has its own conventions that IF YOURE LUCKY you can glean from reading the docs top to bottom. But seriously, R really doesn’t seem to *want* you to have an easy time learning new libraries. However, there is another problem. Because the objectMethod lives in global namespace, it can be overwritten if you load another library that has an object with a method of the same name. Remember that I am new to these libs. This is *exactly* why object methods live in the **local** namespace of their objects in most languages. (Again, R does you no favors on helping people learn it) Look, I use R, I have to. It **KICKS ASS** at what it does. I am not disputing that. But I MUCH prefer to work in a language like Python that bends over backwards **for me** rather than expecting me to bend ass over tea-kettle every time I want to use a new library or adapt a colleague's script. I think that R needs to deal with this pretty soon, bc as Python continues to develop top notch analysis libraries (`numpy`, `pandas`, `scipy` (and children -- `scikit.learning` etc), and `statsmodels`) R will likely see AT LEAST a drop in people willing to start learning the language. It has survived by being the only REAL stats workhorse in free languages, but if it doesnt get a handle on its heterogeneity, it is likely to lose out soon. Just read the posts here that are falling over themselves to NOT use it EXCEPT for that one thing... 
I don't think abstraction is actually about hiding at all, and my talks all refer to this. The "hiding" is only a common side effect of abstraction's true purpose which is one of automation. I recommend you take a look at my Pycon 2012 talk [Hand Coded Applications with SQLAlchemy](http://techspot.zzzeek.org/2012/03/12/pycon-2012-hand-coded-applications-with-sqlalchemy/) for background on this, this talk addresses the terms "abstraction" and "leaky abstraction" directly.
My point was that i like R's syntax, specially for formulas and dataframes.
http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy
I suggest Anaconda. There's a free version https://store.continuum.io/cshop/anaconda/
Is this what you're doing? Because it seems to work fine: In [3]: Counter([1,1,1,2,2,2,2,2,2,2,2]).most_common(1) Out[3]: [(2, 8)] edit: I bet you were doing this: In [8]: Counter([1,1,1,2,2,2,2,2,2,2,2]).items()[0] Out[8]: (1, 3) Counter objects are actually dicts with some extra stuff (like most_common) which map item to number of occurrences. 
I fail to see the relevance.
That does not stop you from writing a C API to be honest. Anyway, those are *our* reasons why PyPy does not have a C API.
So, no mention of the Directed Acyclic Graph? Any details on the NoSQL DB (SecDB@GS, Hydra@JP) ?
http://www.reddit.com/r/Python/comments/1ohwue/incremental_garbage_collector_in_pypy/
Is that why you only stayed 4 months on the project? Were you permie or contract?
&gt;That's kinda neat, but not sure if it's a terribly good idea. What do you guys think? google://DSL
I've been following Julia on and off for almost a year now, it had great strides indeed! The type system looks great. I just don't have the bandwidth the start learning yet another language. Sometimes i feel like there just aren't enough hours in the day. 
I was contract. I only stayed 4 months because I got offered my dream job on the same money. It was frustrating, but I would have stayed - like I said there are plenty of worse projects out there!
Python does not have call/cc.
Yes, you're right. CPS is even farther from the obvious solution than accumulators, though, but I suppose it's possible to make a decorator for that, too. (As long as you don't need to call the recursive function on anything other than CPython or PyPy, of course. :-)
Nice! I use that on my Beaglebone.
Hey, Cheers for response. I have been searching around and the PyQt Phonon module was recommended. But I've been having some problems getting the PyQt module installed on my Mac. Got about 15 chrome tabs open right now all with different advice on how to install PyQt on a Mac :S !
I use homebrew on mac and works like a charm. In my opinion the best way to work with python2.7 and 3 on mac is via homebrew although I have not tried phonon.
Might want to check out: http://pythonide.blogspot.com/2008/03/howto-write-wxpython-video-player-with.html
It would be nice if the [simple example](https://github.com/percolate/redset/blob/master/README.md#simple-example) created duplicate entries to demonstrate the advantage of this on the producer side. Also, on the consumer side, it would be nice if it the various consumers were run from separate terminals to demonstrate how the consumers would hook into the same distributed sorted set. Furthermore, I think `redsset` is a better name because this emulates a sorted set, not a set. 
I think the simplest solution is to embed a browser in your GUI and point it at your video stream. [WxWebkit](http://sourceforge.net/projects/wxwebkit/) should do what you want.
Speaking from a Windows environment, I know that you can't use PIP. I had to use the binary installers for windows (which leads to problems with IDE and virtualenvs.) EDIT for clarity: You CAN use PIP on Windows, just not for PyQt and other certain packages. It appears there are MAC binaries somewhere: http://www.pythonschool.net/mac_pyqt/ If you need to use a virtualenv (which you should be doing anyway), I take the PyQt folder under Lib/site-packages and copy it to the virtualenv Lib/site-packages. You may need to re-register the paths in the IDE (auto-completion and unresolved import errors might happen.) Or just setup the IDE to look in the base installation. Yak shaving at it's finest. EDIT: Also, while I'm at it, you can use easy_install to run on .EXE package files if the EXE is made with distutils(?) and is in the proper EGG format. This way you can install the package in a virtualenv if the installer insists on searching the registry and using only the base python installation. But, yeah. Yak shaving.
This is the first resource I always check whenever I need a win64 binary for python
Just chiming in for homebrew. As a regular user of Linux, OS X, and Windows, I used to miss having a package manager on Mac. Now I only miss it on Windows.
Sure, they are called facebook "friends", but it's not like we are actually close friends with 300 people. Most of them are friendly acquaintances that we choose to socialize with online. I find it useful to know when one of them opts out of that interaction. 
Or just build the GUI in the browser and control it using websockets the ws4py library works, I have been using it with cherrypy.
[This question](http://stackoverflow.com/questions/19317619/how-to-efficiently-read-and-save-video-from-an-ip-camera) on SO has a hacked way to grab a jpeg stream from an ip camera and save to file. Instead of saving to file you could put each image onto your wxpython GUI through PIL or probably several other methods.
Oh God PyPy you are so hot right now.....
Great to see this progressing, love the work being done with PyPy these days.
You have any kind of blog or write up on the process? I've honestly never heard of this approach. I'd love to trade my hideous mess of `wx.BoxSizer`s, for some css layout control. Can you do everything you can in a normal webapp..? 
Macports for me. sudo port install pyqt-5
Why can't you use Pip on windows?
Nah, when people do the chained small text so you can't read it, the bot is actually a time saver.
You can't use PIP to install certain packages without adding certain compilers and DLLs, specifically in this case: http://stackoverflow.com/questions/5517924/pip-install-pyqt-ioerror
it's an os thing not a python thing http://stackoverflow.com/questions/386945/limiting-certain-processes-to-cpu-linux 
I would suggest that you first try to learn the basics of making an interface. If its just you who would be using this, a command-line interface might suffice, but python also comes with Tk, which can be used to make graphical interfaces. For this purpose, I think command line interfaces may be a bit more problematic, since while your program is waiting for you to input your command, it can't do anything else, so it can't check if the time you set for your alarm has been reached. In this case, you would create a thread that runs in the background that checks for the time and plays a sound or does whatever type of notification you wish. If you go that route, you get your input with something like: command = raw_input('') then you check what the command is: if command == 'tuesday': set_tuesday_time() Since you need a calendar, the dates and times you set need to be stored somewhere, perhaps a text file. Have a look at http://effbot.org/tkinterbook/ for learning to make an interface with Tk and for playing sounds like an alarm, i find pygame is the easiest method. www.pygame.org/
That's not what I'm asking. Assuming all things equal, is it possible to get the performance of GoLang in python? It's not what performance I need, it's the potential of performance. As an extreme example, no matter how good you are, you are not going to get C speed in Python
In Python, we often use modules such as SciPy, or NumPy, or SymPy, and the parallel performance of an application is going to rely as much on the application design as the modules it uses. So that's why it depends. Can you describe what you'd like to do with Python?
Welcome to python! If you haven't already heard of [multiprocessing](http://docs.python.org/2/library/multiprocessing.html), then you should definitely read all about that and [threading](http://docs.python.org/2/library/threading.html). C-like performance, well... I doubt it. There's also [celery](http://www.celeryproject.org) if you have a bunch of computers and you want to distribute tasks (python functions, basically) to them. I don't know GoLang so I can't say, but that's what works for python.
See sidebar: http://wiki.python.org/moin/Python2orPython3
Hello, thanks! And thanks for the answer. I'm not looking for C like performance. I just wanted to know if anyone knew how it compares to GoLang. Because I tried GoLang and boy is it fast, but I like the python community and documentation better. I used google but I get extremely contradicting results. Maybe a fairer comparison would have been between Python and Node? Node is fast as fuck too, but still not GoLang level
&gt; Assuming all things equal, is it possible to get the performance of GoLang in python? 
'I noticed that the compilers I have seen do not compile 3.3.2 or even 3' This makes no sense to me. Could you explain more precisely what the problem you found is ?
I've been working on something similar... Streaming screen capture data to web browsers over a WebSocket. It is *not* a trivial task! Holy cow where do I start? First, there's the fact that you need to convert the frames into something that will render on a `&lt;canvas&gt;` element. Then you need to perform that action at whatever framerate/image size you want to be able to stream. This will likely involve a significant CPU overhead. Also, if you're not capturing the stream of data via something like shared memory it might be too slow to make it all the way to something like 30fps (depending on the system). Then there's the task of getting your binary image data through the WebSocket... They *do* support binary modes (two of them!) but how you convert that data from something like a JavaScript arrayBuffer into something you can draw on a canvas is a whole topic in itself! A simpler approach would be to base64-encode your binary image data and then copy it to the canvas as a data URI (which will work fine) but this adds a non-trivial amount of bandwidth overhead. For something like streaming a video it could be a dramatic amount more bandwidth. So yeah, I've solved all these problems :) . I'll be posting the code to the Gate One github repo soon but in the mean time consider the following: * Use shared memory (ctypes are your friend here!) to copy the image data from whatever is streaming it (unless you're decoding it in pure Python in which case watch that CPU consumption!). In Gate One I was using X11's SHM extension in conjunction with the xpyb module (XCB bindings for Python) *in conjunction with* the DAMAGE extension to grab *just* the portion of windows that changed in order to keep bandwidth consumption at a minimum. Though for streaming video you'll want to use a different mechanism (scale down the resolution and up-convert it at the client based on a bandwidth calculation?). * Figure out how to use PIL's Image.frombuffer() method. You can feed it raw data as output by various C libraries (if you're doing that sort of thing). It's a lot faster than any other method of reading in the data (of course, that won't apply if you're doing the read in pure Python). * Don't use Socket.IO or SockJS. They won't let you mix &amp; match binary mode transfers with ASCII. * Using something like bson, bjson, or similar binary-to-ascii encoding methods is OK but not as efficient as a pure binary transfer (dealing with raw bytes sucks but it is fast). * Try to keep it simple but good luck with that!
Please forgive my ignorance, but what is STM. I am a cython user, never tried PyPy. Is it worth shifting to pypy?
Yes, since any bottleneck in your code can be refactored into a C module or you could even use Go to write your module! See: http://gopy.qur.me/extensions/examples.html I haven't tried it yet but that "writing Python modules in Go" thing does look promising. Also, rather than focus on the multiprocessing module as others have suggested I'd recommend looking at concurrent.futures and asynchronous modules like Tornado. Together the two are quite powerful. Note that concurrent.futures will use multiprocessing or threading depending on the choices you make which is nice: For CPU-bound stuff you can use a ProcessPoolExecutor and for IO-bound stuff you can use ThreadPoolExecutor. With a bit more abstraction you can combine the two into a tidy little concurrent processing class that starts itself up on demand and cleans up after itself when done: https://github.com/liftoff/GateOne/blob/master/gateone/go_async.py#L409 (I wrote that code =)
Pygame is a library, not a compiler.
I want to wear your skin.
This is mature ass fuck.
I use Cython (not CPython), for quick and dirty estimates, and c++ for resource intensive code. I use cython mostly because I can do it in sage notebooks. So I guess I should shift to PyPy soon.
So does it just speed up code that was written parallelized, or does it speed up code that wasn't written with any specific parallelization in mind?
I went to start using Pony the other day, and I was really liking it, until I had to do a migration. As far as I can tell, there's no way to do south-like migrations in Pony, which is a major stopping point for me. Am I missing something?
If there is one thing programmers are great at, its making analogies... And programming.
Software Transactional Memory is one way of implementing concurrency, without requiring the code to do lots of locking etc. As python generally does not do locking etc, the usual paradigm is to only run one thread at once. Thus CPython is not able to do real multi-threading, but STM allows PyPy to do true multithreading.
Pygame does actually work with Python 3, they just don't advertise it very well. There are downloads [here](https://bitbucket.org/pygame/pygame/downloads).
The majority of libraries now work on Python 3. Have a look at https://python3wos.appspot.com/ to see which libraries work on Python 3, and which do not (yet).
True concurrency is nice, but I wish they focused on implementing Python 3.3 first. Their insistence on using 2.7 as a base branch does not help the 2-to-3 transition, especially if you consider that a). many widely-used libraries (e.g. Jinja2 and, by extension, Flask) require 3.3+; and b). PyPy3 beta1 does not have JIT compilation yet, making it about 9 times as slow as CPython.
I am seeking serious advice as to how to go from here. 
Or use CFFI. CFFI is compatible with both CPython and PyPy, and I prefer it to Cython. It basically lets you use true C libraries from Python. Personally, I prefer writing pure C to writing Cython.
I sympathise but you have answered your own question. Forget about learning yet another language and start applying what you already know to real-world problems. You need to make the leap from beginner to experienced coder. Keep your targets realistic and achievable with practical time-scales. Find a charity or small business and offer your services for free for a week. It's tempting to think you can be proficient in many things. Job adverts will have you thinking there is some sort of super-race of programmers out there but there isn't. Choose one/two specific skills that are in demand and aim to increase your knowledge in these on a daily basis. Finally, set aside some regular time-out to do some fun programming to avoid getting in a mental rut.
You misunderstood which part I was having a problem with.
That's true, currently there is no migration tool for Pony. But we are working on it and going to release it soon.
Dem caches.
Jinja2 requires 3.3? News to me, and contradicts the docs which state that [py3k support is experimental](http://jinja.pocoo.org/docs/intro/#experimental-python-3-support) as of jinja 2.7: 
I created a UI to select output from pipe in terminal # selected process to kill ps ax | MyScript | xargs kill -9
This. You've started with a few languages, now find a manageable project you can complete. It might just be building a static web page to start, then slowly adding some javascript effects and then some server side functionality. Just commit to building something you're interested in, then read up on how people have built similar things and use them as examples to start coding. Don't listen to the blog commenter that said "learn Haskell" haha. Either python or ruby will suffice for backend languages (forget php) and keep learning more about javascript since you'll need it too. Learning to program can be tough because there is a wealth of introductory resources that make the learning process really fun and rewarding (ahem, code academy) but that really just gets you 1% of the way towards being an adequate coder. There will be many, many, frustrating hours spent reading and thinking things through in a non-gamified fashion. Best of luck!
Realise that the language doesn't matter, at least not initially. What's important is to learn how to build something that works. Learning language constructs and features is definitely useful, but it's only one aspect of writing code. Another is being able to take a project from design to finish. Once people see you can do that they will mostly just assume you know the various language details. Pick something like a Twitter clone and blog about building it as you go. If you post your code to Github and link your blog posts here then I'm sure you'll get feedback. The language choice you make is important only to the point that it's the right tool for the job. In this respect, for web development, it doesn't really matter a huge amount if you pick Ruby,Python, or PHP when starting out. What matters is that you make a pragmatic decision to choose one, and build something with it. Once you've done that learning other languages and frameworks is just a time investment. Choosing Python might be a good decision since you seem to have invested a large amount of time in learning it already. The nice thing about building a twitter clone is that it can be as simple or as complex as you want it to be. You can start out by building a very basic feature set (let people choose who to follow, and display their tweets and their followers' tweets ordered by time posted). Once you've done that then add features as appropriate (e.g. unfollowing someone). Think about the implications of each feature, e.g. unfollowing should remove the tweets of people you're following from your feed. Once you've built it try and iterate on the design to see what improvements you could make.
I've always developed best when I've had a project. I've mainly been in an academic context, so you already have set goals to achieve, but just finding little things to do can be helpful- for example, when I was getting used to a language, I implemented Conway's Game of Life, wrote a sudoku solver (which works for easy-moderate puzzles), implemented a few statistical methods, that sort of thing. I don't find reading to be that helpful in actually learning a language- it's necessary for picking up entirely new concepts but won't make you a programmer. The important thing is to be able to translate what you want to do in your head, into something a computer can understand: doesn't matter if it's horribly inefficient so begin with, when you learn of different functions and libraries and so on your 'vocabulary' will improve. 
Not really, while I really love Python, it is not as performant as Go. If you are CPU bound (heavy calculations) you can benefit from NumPy and similar libraries. Depending on your application if you are primarily doing IO, check out some async frameworks like gevent and tornado. If you like tornado, check out pypy, it is very likely that you will get significant performance boost (order of magnitude or so, depending on what you are doing). 
I've found myself in the same rut as you before, and my personal solution to this has always been rooted in solving problems or improving on things that I care about. It doesn't have to be an improvement in something I'm especially passionate about, or even enjoy using. I look for something I can do in a better way, or a feature that just isn't available. Something that will have real tangible benefits to me (bonus if it helps others too) always provides me with a drive that I just can't find elsewhere. So what if 90% of your app/website is available elsewhere. Or someone else has written something more efficient. Oft times, it's a single feature that can set you apart. I find this route is best advanced by keeping tabs of all your ideas. When you have one, WRITE IT DOWN. Get something that can sync across your devices and always write stuff down. Even if it seems insignificant, or a fraction of an idea that can't necessarily be applied to anything else off the top of your head, keep track of it. It may take you a while to get enough ideas down for you to feel the desire to get cracking on one, but eventually, something always pops out at me. Too often do I see people learn to program only to perform menial tasks for their job or something they don't really care about. If you are trying to be self taught, it's all about passion, and for me, that comes from my own ideas that I genuinely feel would be useful.
&gt; Early optimisation is the root of all evil. When we're talking about learning programming, I believe that language choice is an optimisation problem. A programmer with long experience can wring extra performance (be it CPU cycles or development time) out of a project by choosing a language most appropriate to the problem. As a beginner, you aren't qualified to make that choice. In fact most programmers just know a subset of languages so pick one of them that they think best suits the problem. If you know one language -- pick that one. We're only talking minor gains anyway. You've picked a good general purpose language with low startup costs, python. I wouldn't advise changing language from that. There is nothing you can do in C, C++, Java, Ruby, Haskell, or whatever, that you can't do in Python. This is all the more true when you realise that the skill in programming is not knowing the language, it's architectural. It's the design that matters more than the language. Learn to think object oriented; learn to think functional; learn to think imperative. You do that by tackling real problems. If you haven't got to the stage were you will get on the job experience, then you'll have to work on your own projects. Maybe an open source project -- although there are some nasty buggers working on these, so be ready to wear flame-proof clothing or just walk away and find something nicer. If you can find yourself a friendly mentor who will look over your work, I'm sure that will be most helpful. In my experience, motivated beginners usually just need a bit of guidance to get them started, and a bit of friendly criticism once they're running. HTH
The very link you've provided states: &gt;experimental support for Python **&gt;=3.3**
Check out beanstalkd. Put jobs onto queues, results onto other queues. Job data can be anything; you parse it yourself in your app. Json, yaml, whatevs. I use it all the time for synchronising tasks between systems. Just remember to turn the log on, so you can recover if the server fails.
Stick with python, and get on #python on freenode irc, instant help and a wonderful community. Answer questions if you know the answer. Read code and listen to others if you dont.
It seems like a lot of the time when your discussing performance lost in python it's in lengthy execution times associated with some algorithm. Numpy gets you close in that arena (close enough considering if your that performance critical you shouldn't be in python). The refactoring into C for specific modules is pretty easy with Cython. I only picked up Python a few months ago and haven't done serious coding in almost 8 years, yet I managed to rewrite parts of my code in C through Cython and called it with Multiprocessing.Pool(). So its pretty easy to run with, albeit my Cython versus Numpy wasn't an enormous speedup for the 500x500 arrays I'm working with but it was minimal work to get it done. I've just had a problem with some parts of the numpy.linalg package not playing nice with multiprocessing, wonder if tornado would have the same issue.
&gt;an aspiring hacker says it all really the only way forward is **eat,test,code** 
Thanks, it's nice. Main problem with it: my primary target platform is Windows and it's a desktop app so I would really like to avoid adding another demon process on top of already running AutoCAD and Python code.
Just left a comment on your site with a link to a course for free that will step you up. Do it, and the web app course from the same site, it starts easy but escalated quickly and will get you going for sure. You're welcome. 
Request/reply with guaranteed delivery and order starts to sound more like remote procedure call than a message queue. The point of message queue systems is to be more loosely coupled than that. Distributed computing and cross-language bridging are not the same thing. Using the same tool for both may or may not be the right approach for your situation. And the words "might" and "sometime" make me suspect you are deep in [future coding](http://sebastiansylvan.com/2013/08/16/the-perils-of-future-coding/) territory. Just use IronPython in Microsoft's excellent [Python Tools for Visual Studio](https://pytools.codeplex.com/) development environment and you get instant access from Python to all .NET APIs. Worry about remoting later. You will then have the option of doing it using either tools written in pure Python (e.g. [RPyC](http://rpyc.readthedocs.org/) or [Pyro](http://pythonhosted.org/Pyro4/)). You could use some .NET based solutions, too.
A message queue is a good solution for a distributed problem like yours. If ZeroMQ does not guarantee message delivery/order, I'm pretty sure [RabbitMQ](http://www.rabbitmq.com/) does. Check out the documentation for both to make sure. You could still make some public API (using REST or something else) for your .NET app so it can be called from Python and maybe some public API for you Python app so it can be called from your .NET app. That would dispense for the need of a third party application like a message queue. You could still scale later when you really need it by using a third party.
Make something, even if it already exists.
Any sort of message queue should work, really. Beanstalkd is nice because it's very lightweight and simple. Same workflow applies: pass messages between the systems using the message queues/channels/tubes. Everything becomes very modular, so chaining new elements into the system becomes trivial.
You should stick to realistic goals. One year is not really a lot of time. If you already learned some basics that's good enough. And finding your way in recent developments is also a skill that you have to learn. So you have to make experiments with different languages and frameworks, that takes time. This time is what makes you valuable because you are not confused by people saying ".. bla bla new Haskell library here.." or ".. super big data there.." anymore. 
The short answer: YES For example, the guys of IPython used it to develop their notebook and cluster support. Very impressive stuff. Regarding RPC: It's already been done. It's called ZeroRPC But there is no reason you need to go down that road. If you control both ends, ZeroMQ will give you the power to implement whatever scenario you need.
Indeed a welcome update. But PyPy is already quite fast. I'd rather see binary compatibility with CPython libraries than further performance improvements. It's the single most important reason keeping me away from using PyPy.
Forget about C++ for now (it's a behemoth language) and grind hard working on Python. Once you've learned how to "think" in Python you'll find picking up other languages easier.
I'm with tempid39. I'd add the option of choosing yourself a project. That doesn't have to involve solving bugs more for other people than for yourself on projects that you're maybe not that invested in. What you really need is focus on a real world problem. Also [classes and inheritance](http://docs.python.org/2/tutorial/classes.html). Very useful. Not sure if that's included in what you learned about modules. Other than that your list seems pretty complete imo.
If I understand it right RabbitMQ will require me to run an additional broker process like you said and I woul like to avoid that (the primary target platform is a Windows desktop). I think I will give ZMQ a try, the current progress looks neat and more or less productive. Thanks for the feedback! Edit: for future readers' reference, ZMQ Guide Chapter 4 contains patterns to address reliability issues.
Make something. Then put in pastebin, then let us review it. It can be a simple number guessing game. Then build something more complex and repeat.
Thanks for the information! For reference: this is a SE thread with the same question. http://programmers.stackexchange.com/questions/214729/is-zeromq-a-good-choice-to-make-a-python-app-and-a-c-managed-assembly-work-toge **Summary of the problem** from what I understand: my approach isn't exactly the most optimal one but it's not bad either.
Okay, thanks. I think I'm going to proceed with ZMQ and solve reliability issues when they manifest.
&gt;Django can easily handle legacy data. it's funny that the term for data that was not designed by a programmer with the django orm is "legacy data" as if it's old and crufty and should be replaced. &gt; once you jettison the ORM its value as a framework drops dramatically. exactly
which means that it works on 2.7 and experimentally on &gt;=3.3, not that it does not work on 2.7. Anyway, how about you try?
Don't forget PHP... yes, it's not as good a language as python (however I hate rails with a passion so I can't say that about Ruby... the rails just colours my perception too much). PHP is often in higher demand than python, always higher demand than ruby... if your goal is to make a living, absolutely do not overlook PHP (I don't remember the last time I saw an entry level ruby job posted). Obviously Java, C++, C#, etc. are in higher demand still, but once you have a decent grasp of python or PHP you can approach other languages and learn them quickly.
There is a small catch. If you try to evaluate a string which does not represent an integer, it results in an error. So, add a try-except-statement. while x &lt; 0: try: x = int(input('Enter int: ')) except: pass
Thank you for the help! and will try the /r/learnpython :)
I think because that's the immediate reaction to "legacy code" - you expect big balls of mud, spaghetti, uncommented mess etc. That said, not sure the data model generated by Django (at least in Postgres) is entirely horrible. A dba could do better, sure, but a naive coder writing lots of CREATE TABLE statements would probably do worse.
Well, full professional setup would be virtualbox&amp;some linux, or vagrant and then write in that VM (login through ssh(putty.exe from earth.li) to execute your scripts). If you create a shared folder between your windows host and the linux guest vm you can put your code there and still use your favourite windows editor. Advantage of that approach is that your environment to develop in will be very similar to server environments, so if you decide to do computation heavy stuff or want to deploy a webapp you are very likely not to have to modify anything. For the actual python deployment I recommend (pip, virtualenv, and fabric for deployment, possibly puppet or similar for server configuration(not for actual code deployment)). If you want to stick to Windows 8 there are solutions to deploy python as well, but keep in mind that some packages that you install through pip might need some libraries(graphic stuff for example) to be present on your computer and that they might be a bit more annoying to install on windows than on linux (thats just my opinion here, don't rip me apart if you are a windows fanboy). For writing Python under windows you could check out Eclipse Python, maybe that comes packed with everything and a python binary, but I haven't looked into that for at least 5 years. If you just want to fiddle around with Python a bit, Windows might be perfectly fine for a start and python should be easy to install there. If you want stuff that works better to deploy several scripts and develop more and longer, you should look into the VM options that I described. Its a bit of a pain to get your head around as well, so plan 2-3 days where you just configure stuff and check stuff out till you find a solution that works for you. Source: M.Sc. in CS and several years of WebDev experience with mainly Python and the above described stuff.
I would highly recommend PyCharm for an IDE to write your code.
dual boot Ubuntu - Ubuntu is really easy to use and that way you can have the same setup at home that you'd be using at Uni. 
I like to learn new skills, including new languages, even though I am already a decent programmer. However I experience much the same as you do when *I* try to teach myself something new. The truth is that 'wanting to learn' is rarely enough. It's just like wanting to be able to do anything else, or wanting to be anything in particular - you have to be invested in the journey. You have to have something that tells you along the way "Keep going". Some people can just tell themselves "keep going", and that's enough. These people are fairly rare. Some people find that if they enroll on a course and have someone *else* saying "keep going" then that's enough. But even with the best intentions, this magic often wears out and you need something more. What works the best for me is to invested in the gradual improvement itself, rather than just being invested in the end goal. The end goal is going to remain a long way off for a long time, and if you concentrate only on that then your resolve will probably fail along the way. When it comes to programming I find that the best way to get myself invested in my own improvement is to be working on a project. If I can't think of a project, or my idea isn't really that interesting to me, then then I wont get far. I tend to write game-like programs, because I feel they are much more engaging and creative as a programmer than trying to write... a word processor, or some nondescript business software. Your mileage may vary - just find something that *already* exists (for a game it could be something like mario, or breakout) and write it all yourself. Then add your own ideas and improvements. Whenever you make something as a project try and keep it as simple as possible. Strip down its features and implement just one thing. Then another. Then another. Don't worry about "making mario". Instead think about "How do I draw a character on a screen?" and then "how do I get keyboard input to control the character"? With a project to work on I feel I can invest myself. I start thinking about ideas for it even when I'm not working on it. I start wondering "What if I wanted to add X? How would I do that?" That's what improves your skills. That's what leads you to being a programmer. A year goes by very quickly. Don't be hard on yourself for not reaching your goals. A life is for living, not for regretting. Goals are good, but don't keep them completely fixed and distant. Give yourself smaller, attainable goals. When you make something you are proud of, show people. When you aren't sure of something, ask people. You haven't failed. Not by a long way. There is a huge amount of cool stuff you can and will learn, so think up a simple project and get stuck in!
So many organisations and companies are looking more to Python and real open source tech like flask,sql alchemy, tornado etc Stick to one language and to be honest, python is the best of the bunch for pretty much.....EVERYTHING. Wanna build a website? Use Python with Flask. Check this link for a good start:- http://net.tutsplus.com/tutorials/python-tutorials/an-introduction-to-pythons-flask-framework/ You can just get away with basic HTML/CSS and create a proper website with templates/routing etc.
#1: start making shit #2: stop letting SO dictate what you should be doing.(and reddit for that matter)
My advice for you: Don't be so hard on yourself. It seems like you've picked up a lot in a year. You're currently measuring in terms of 'what you can build', but the measurement you're progressing in is 'how long it takes to learn the next thing'. Eventually you'll start to realize just how much progress you've made, and it will feel great. Your goal is to get a better job programming, right? Keep in mind that most jobs are landed through who you know, not through cold interviews. Keep interviewing, but make your goal be to make some connections, rather than just to land a single job. Also keep in mind that most programming job descriptions are written by non-programmers with unrealistic expectations. So feel free to apply for jobs you don't feel qualified for. For your first programming job, try to land somewhere that either A) has a dedicated training and on-boarding phase for new team members or B) has so little in-house expertise that they will be willing to tolerate you doing some initial learning on the job. In either scenario, remember that learning on the job will be the norm for the rest of your career.
I think you have to take the Zen of Python as a complete package as each statement influences how you should think about the other. These aren't a set of standalone guidelines, but a holistic viewpoint. So to answer your question, you should also think about these points: * Simple is better than complex. * Readability counts. * Although practicality beats purity. And remember that the phrasing matters. It doesn't say "Don't be implicit" it just says that in general you should prefer "explicit" when it's practical. 
Personally, I'd recommend getting the [enthought python distribution](https://www.enthought.com/downloads/), since it comes with IPython pre-installed and the ipython notebook is just fucking fantastic. On top of that, it has a bunch of libraries that you may find helpful. You already mentioned scipy in your post; EPD (now called "canopy" for some reason) comes with scipy in the package ready to go. As far as code-editors go, you can use pretty much anything. Notepad, Notepad++, gvim, there's probably an emacs port for windows, sublime text, ... But be sure to try out the ipython notebook in any case! It's a darn fine environment/workflow.
What is SO?
The nice thing about using zmq or beanstalkd is that you can swap out the messaging component itself if it becomes an issue when scaling, if you write your interfaces on either side fairly generically.
heh thanks :-) 
Aww jeez, how did i miss that? Thanks.
Hmm. Not sure that's what this admonition means. I take it to mean: when writing code, make what the algorithm requires obvious. For example, if my algorithm is waiting for a variable to take a particular flag value, test for that flag if variable == SOMETHING_WE_WANT_TO_HAPPEN: If the value happens to be 0, don't just go with if not variable That sort of thing. So it becomes unnecessary to add comments to the effect of # variable is 0 when we need this to happen Not sure this applies to your example.
&gt; I hate rails with a passion May I ask why? How does it compare with Python frameworks such as Django or Flask, IYO?
you can do anything with either, 
&gt; Here's a secret that I really wish people would share with HR departments I wouldn't bother trying to tell them: those that can, do; those that can't, work in HR.
http://django-helpdesk.readthedocs.org/en/latest/
&gt; There is nothing you can do in C, C++, Java, Ruby, Haskell, or whatever, that you can't do in Python. Like using real STM, having referential transparency, scaling to many cores with or without concurrent semantics, or using the type checker to isolate effects? :-) Generally, I agree, and Python is definitely a good first choice, but let's be clear: Every language that is Turing complete is not equivalent. If they were, people would still be using FORTRAN for everything. It's more fair to say that there is no specific kind of system (written however which way, in X language) that you couldn't make in Python. [Learn Python the Hard Way](http://learnpythonthehardway.org/book/) is a great way to start.
&gt; Every language that is Turing complete is not equivalent. If they were, people would still be using FORTRAN for everything. I certainly don't mean to imply that (although it depends on your definition of equivalent, since "Turing Complete" does, in some sense, mean exactly that). Each language has its strengths and weaknesses for particular problems. There is no computing problem that you can't tackle with any of these languages though; and it's far better for a beginner to start learning design rather than constantly flitting between them for the corner cases where the differences matter. 
&gt; I certainly don't mean to imply that (although it depends on your definition of equivalent, since "Turing Complete" does, in some sense, mean exactly that). Languages that are Turing complete can be wildly different, and thus not equivalent. They both meet that criterion, but it doesn't make them the same, is what I mean. &gt; There is no computing problem that you can't tackle with any of these languages though; and it's far better for a beginner to start learning design rather than constantly flitting between them for the corner cases where the differences matter. I definitely agree that Python is the best way to start, and a great all-around language. I'm just adding that it's not necessarily the be-all-end-all of programming.
MAKE SOMETHING.
Honestly? It just clicked badly with me. It's a personal prejudice, something I freely admit. 
Try both and decide for yourself.
I agree! There were lots of false starts when I started coding. Just keep going. Lots of people here seem to be saying that you should start a project, but it may also be worthwhile to do some bite-sized exercises. [Project Euler](https://projecteuler.net/) has a series of problems in math and algorithms that gradually ramp up in difficulty. Learning to program isn't about learning a language. It's about learning a disciplined way of thinking. Just keep solving problems and you will improve.
also, just getting this out of the way... "Use Django" "I like bottle" "I find web2py more to my liking" "quit being a pussy and roll your own" "plone...dudes just try it" "zope gave me herpes" 
Love the neutral comments so far.
I can't answer for him, but from the brief overview I got of Rails and the pieces that I read about it, Django is for control freaks, Rails is for those okay with the fact that there's more going on than meets the eye. Django will not alter your databases for you, Rails will. Django has a fairly substantive configuration file for you to tweak or break, Rails does not. Django expects you to write what you want, but provides a framework to accomplish it more quickly, Rails attempts to predetermine what you want to do and tries to make it easier. Many people say that Rails has some "magic" that goes on behind the scenes, you really get this feeling from their motto: "Convention over configuration". I don't know either well, but from the brief dealings I've had, I prefer Django, there's no magic behind the scenes. I don't like my code doing things I didn't explicitly tell it to, whether it works well or not. If my database needs to be reworked, I'd rather write the code to do that and know how it ends up where it is than have Ruby do it and later log in and realize that I have no idea how my original tables match up with the ones that are there now. That being said, I wouldn't look down on Rails or on people who prefer Rails, it's just not the environment I prefer to work in. As long as the end application performs similarly, I could care less what it's written in (except Java, I do hate Java just for being Java along with everyone that has ever chosen to write their application in Java).
&gt; I'm just adding that it's not necessarily the be-all-end-all of programming. It certainly isn't. It's not my favourite at all. Personally I like my languages strongly typed. I was only suggesting it here because the OP has a good start with it; and it's good enough that it won't be the limiting factor at this stage. 
https://pypi.python.org/pypi/roundup
I have tried Flask, Pyramid and Django and i seem to like Pyramid more because of its super flexibility and one more reason to choose Pyramid over Django is SQLAlchemy, i just love it.
The ActiveState Python distribution is an easy way to get started.
hahahahahaha love it
Write code to do something that you'd appreciate getting done. It's odd to me that you are thinking of what you've accomplished as a failure. Programming is really really difficult. You are just scratching the surface of how difficult it can really be. People spend a lot of time saying crazy stuff like "anyone can code", why don't people say "anyone can slam dunk" or "anyone can swim the english channel"? Anyone who programs for a living fails at least hundreds of times a day, on a good maybe thousands, not everyone can handle that kind of stress. That alone prevents some people from programming. The impression I got from your article is that you aren't showing the task you're trying to accomplish the respect it deserves. 
What I have to say is not to the OP but to the people commenting here. I'm in somewhat the same boat as the OP, and all I can say is that the comments on here are both generous and thoughtful. Thank you to everyone. I'm going give my misanthropy the day off ;-)
this might actually be the best comparison of the two I've read (and i've googled extensively on the matter) You're not describing the difference between the two in terms of functionality and structures but in terms of attitude and approach, which I think is a more relevant distinction to most people who want to know how the two frameworks differ
This was great to read. I wish you were my life coach, we would make an awesome team.
PHP is often in higher demand because there's a lot of stuff written in it because the bar to entry is so low. If you can do productive things in Python, don't worry about PHP. I'm going to be doing a resume/LinkedIn update very soon, and PHP is coming off my skill list despite the fact that I'm fine programming in it.
I wonder about the language order a bit. Python is great because you can do so much with so little code: download bottle.py and write 30 lines of code and you've got a functional web server dishing out pages dynamically. Unfortunately, I'm not sure you learn much by doing that because everything of value is hidden in the libraries. If one is truly dedicated to becoming a developer, it might be better to start with C. You can't do as much as quickly, but anything you accomplish, you'll have a good understanding of it.
https://github.com/peterbe/IssueTrackerProduct
Basically just answered your own question because anyone elses answer would likely be subjective or anecdotal to their needs. 
1. Stop learning new programming languages and stick with just one for the moment. Familiarity with dozens of different syntaxes doesn't make you suddenly know how to program. At some point, yes it is good to be well-versed in a several programming languages so its easy to jump to a new language if needed. But this is pretty simple task, especially with a good IDE (that corrects silly mistakes like using `elsif` (ruby) in python). I'd really recommend sticking with python -- its a very good modern language and doesn't force you to work around a powerful type system. Avoid PHP and perl; they were great 10-20 years ago, but make it easy to write bad code in bad style. That said, if you want to design webapps, you may need to learn some HTML, CSS, JS, and maybe even SQL (if your framework doesn't have a good ORM). 2. Take some CS classes; especially an algorithms course or an intro CS course. Coursera, udacity, and edx all have excellent courses in this regard, which have the difference of giving you feedback. Learn about the importance of abstractions and various data structures. Yes, CS courses aren't really about programming (e.g., you'll learn how to prove mergesort is Θ(N lg N)), but you'll learn to think algorithmically and solve problems. For work, I've never needed to implement a sort function (you can usually call an existing sort), but learning about algorithms with the example of sorting is a very good practice that helps all the time in thinking about how to code things up efficiently. 3. Read a book like Code Complete to know how to do software engineering. How to come up with maintainable code (code you look at in a year and understand), use version control, etc. 4. Learn the idioms of your language. For python that is read [code like a pythonista](http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html) 5. Learn domain specific knowledge. E.g., if you want to build networked applications, learn about computer networks. If you want to do crypto, take a crypto course. If you need to do database heavy stuff, take a DB class or read [Use the Index, Luke](http://use-the-index-luke.com/). 6. Write some code, do a github project. 7. Have fun, don't pressure yourself, and don't expect big changes overnight. PS: I really recommend taking free online classes. Don't worry about taking a class that's already started or may be too hard. Watch the videos, try the assignments, and if its not for you, drop it. No harm lost. The certificates are pretty meaningless at this point, but if you learn the knowledge that could be invaluable in learning to program (or passing interviews).
Sure. What I'm saying is that if he can get good at less crappy languages for which there is also demand, he could get better gigs. 
Here is the direct link: http://www.continuum.io/downloads (which requires no email)
Cool, thanks. I'll look into it!
You're right, certainly worth picking up at some point! I just meant that right now his time is best served by diving deep and mastering one of the languages he's begun to learn rather than introducing new ones (at a novice level).
In addition to PySide, there are also bindings for Clutter. http://www.majorsilence.com/pygtk_clutter (think of it like a sane GTK) http://blogs.gnome.org/clutter/
Good feedback; thanks.
Why does the language matter in this case? It seems like such an arbitrary requirement.
I'm actually really happy that I learned C first. It wasn't the easiest thing to do in the world but it gave me a great understanding that I've used in every language since. The absolute most fun I had with that language was writing code for AVR microcontrollers. It introduced me to so much, and broke down abstractions so I could see how things were really working in hardware. I will admit that hopping to languages like java, python, php, and javascript that weren't strongly typed took a little getting used to, but it wasn't too bad.
Can anyone sell me on this? What's the benefit of Visual Studio over PyCharm or other IDEs? 
According to the documentation Python Tools for Visual Studio 2.0 works with the free version of Visual Studio. 
Yes, I built the core of a hedge fund on python talking to C# and C++ over zmq and protocol buffers. It's a great choice!
If only I was using windows... This looks really nice, and there isn't really an alternative to this that's free for linux, not including PyCharm.
Can echo that. I've been programming in C after Python and find it easier than I thought it would be.
i think this is a common conception, but it's actually not very true. pyramid is much closer in size and features to flask than it is to, say, django or rails.
Note [edX/MITx - Introduction to Computer Science and Programming Using Python started yesterday](https://www.edx.org/course/mit/6-00-1x/introduction-computer-science/1122). I haven't taken it, but it looks exactly like the type of course you need to transition to go beyond merely seeing the syntax of programming languages.
While perhaps not the motivation of the OP, I can think of one reason that has motivated me to ask similar questions: that this person has experience in how such systems should work, and that they know enough Python to want to contribute. Such a person would both learn Python faster and also contribute useful user-driven content to such projects.
Tutorials are great for exposure. That's about it. Pick a small goal. Do it. Lather, Rinse, Repeat. If there's a solution available, you're not really learning.
No time for pooping...must code.
Guaranteed Reliability, High Performance, Low Complexity. Choose 2.
&gt; I am going to start learning Python but I have heard a few different things about what version to learn. I have heard that 3.x is slower and the community isn't moving to it. If any difference in speed is important to you, python is the wrong language in the first place. Or conversely, unless you really need high speed for some particular reason, it really won't matter - if it did, you'd want to use a language serving that particular niche better. (That's if the statement is even true...I have no idea about the statistics). &gt; and the community isn't moving to it. Well...it's true that not everyone moved quickly to python3 as soon as it was released, but the shift has been quite steady, especially more recently as more and more popular modules have made the shift. I think it's modules that really held people back, but that factor is rapidly decreasing. &gt; I have heard that I should learn 3.x if I want to build a new project and 2.x if I want to work on older ones in a work environment. I'd say...use 2.x if you need it for some reason (as above, this reason might be maintaining old code, though converting it to python3 should at least be considered in that case), and python3 otherwise. There's not much reason to use 2 unless you need it for some specific reason. As a final point...I'm not sure this is actually important *at all*. I can't imagine you could learn one fine but somehow struggle with the other.
3.0 was slower than 2.x, but the performance issues have mostly been fixed in 3.1. ([Source](http://stackoverflow.com/questions/2112298/python-2-x-vs-3-x-speed)) I don't know if there's that big of a difference.
If you are going to be supporting old systems then use 2.X. Once you have learnt a fair amount then learn what the difference is for 3.X. Easier to move forward than back. At least that is my plan as I am also learning.
Spaghetti code.
_Yes_, especially that final point. Python 2 and Python 3 aren't really that different in day-to-day usage, and there's no rule that you have to choose one and only one. OP, Python 3 brings a lot to the table (better strings, `yield from`, and a thousand other things), but a lot of libraries and big projects still sort of hang around Python 2, mainly due to inertia. So learn both! Use Python 3 when you can, use Python 2 when you must.
think of a project. a web app that you would really like to make. pick a language. DO IT! don't do any thing else until its done. you might think you'll get bored, but you will face new problems and learn things you didn't even think you needed to learn before. that's the only way you are going to get comfortable in any language, books and tutorials will only get you so far. for your next project chose a different language and it will be way easier. 
From sidebar: http://wiki.python.org/moin/Python2orPython3
no need to poop TDD eliminates waste
Python 2 or 3, depends on what libraries you're using and if they support t PyCharm as IDE: http://www.jetbrains.com/pycharm/ pip for installing new libraries, you can download .exe installer here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip (You'll probably need to manually add "C:\PythonX\Scripts\" to your PATH, instructions [here](http://superuser.com/questions/502358/easier-way-to-change-environment-variables-in-windows-8)) As far as scipy, numpy, matplotlib etc goes you could download scipy stack which has all those included and many of their dependencies http://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy-stack You should also look into [virtualenv](https://pypi.python.org/pypi/virtualenv)/[virtualenvwrapper](http://virtualenvwrapper.readthedocs.org/en/latest/). If you don't need full blown IDE then I'd recommend [SublimeText](http://www.sublimetext.com/) - it's not free but you can use the trial version indefinitely, it just has popup on every 20 or so saves. Some plugins that you'll probably find useful for ST: Package Control: https://sublime.wbond.net/installation - for installing new packages. SublimeCodeIntel - improved code completion PyLinter - http://www.pylint.org/ intgration Also you could use http://ipython.org/ or just IDLE for smaller code testing. That's some general development environment I'd suggest, this may not be the best advice depending on what you need and do. The *closest* thing that comes to Ubuntu/Geany is more or less just Notepad++ with few plugins, and required libraries(scipy,math etc) installed. The best solution is, IMO, to use virtual machine or dual boot with Ubuntu, configuring and using python is easier on gnu/Linux than on windows and you'll have same environment as on your university.
You mention installing Pillow in Windows without the binary installer: don't do that. We provide eggs (and wheels) for a reason: because compiling the source on Windows is non-trivial. The challenge is to know what you can and can't expect to do easily across various platforms, then advise your users accordingly.
Which, I think... would mean that Visual Studio can do HTML/CSS/Javascript as well, which the community edition of PyCharm is not designed to do. VS is still hampered by the fact that it's Windows only.
The thing is that a lot of libraries still only support 2.x series and not 3.x So it you are building an application which relies heavily on external dependencies then I think that you should use 2.x otherwise there is no reason to leave 3.x behind. However 3.x is the standard now and eventually all libraries will migrate to 3.x 
I find PyCharm a better IDE, but Visual Studio is a lot snappier. I think Visual Studio is better than Komodo Edit (haven't tried the paid version) and PyDev.
[This page has a download link for the free version](https://pytools.codeplex.com/wikipage?title=PTVS%20Installation). I found it a little confusing to get here from the landing page.
Try using shell=True in your argument.
Did this course as a refresher last year and fully recommend it.
Have a look at [basemap](http://matplotlib.org/basemap/users/examples.html) which is a toolkit that sits on top of [matplotlib](http://matplotlib.org).
Matplotlib and the Basemap libraries can probably do that. See http://matplotlib.org/basemap/users/examples.html I think it includes a basic dataset with country outlines etc... if you look at http://matplotlib.org/basemap/users/geography.html
I don't understand where you expect me to use that argument... I am currently doing: C:\Users\gorlak&gt; foo Where foo.py is a python file in my PATH, .PY exists in my PATHEXT, and .py files are associated with an installed Python.exe.
&gt;I also have learned that the harder it gets in programming, the more errors or the more failures, it constitutes learning. Totally agree. At my work we're in the middle of getting all our projects over to a more agile workflow, and one of the things that always sticks with me is that a "failed" sprint (a sprint is just a chunk of time for a dev team), in which stuff was massively broke and we took "too much" time troubleshooting/fixing stuff, may not actually be a failure; ideally the team learns *something* from the work that happened, even if it feels unproductive in terms of advancing the project.
Mixed mode debugging is pretty crazy. IntelliJ/PyCharm doesn't support C++ at all as of yet.
Trivial, if every function takes same parameter AND returns the same result, apply Dont Repeat Yourself. Otherwise, you are not repeating yourself: cos(r), sin(r), tan(r) all take same argument.
OK. I thought you were calling a process using Python (that was also written in Python). Why is your behavior a problem?
Maybe try it with pythonw.exe?
I think the use of *method* is important here. As an example of what the OP is thinking: class Day: def is_weekday(self, weekdays): return self in weekdays def is_weekend(self, weekdays): return self not in weekdays In some cases, this may be the correct thing to do (as in the above) since we don't really want to know about whether this is a weekday or not. In other cases, this is obviously not the right thing to do: class Number: def add(self, other): return self + other def subtract(self, other): return self - other The key to the first is that the parameter is a constant (or in some cases is a sort of "local constant" like "parent" for a node) which has one meaning always. The second is designed to be applied to many values.
I have used ZeroMQ (clrzmq) in C# and Lua with on Windows Embedded system and worked great. 
I wrote the code that makes this repo up after learning to use cython myself, by collecting up the bits of example code I had generated. I put the repo together as a small tutorial for colleagues, who are still learning other basic concepts of python package generation and maintenance.
The problem with learning Python 2 is that there are so many similarities that you will not be motivated to learn 3. The problem with learning 3 is that 90% of software uses 2. The difference is just in the "dead zone". Enough to break code from Python 2, but not enough to be big time useful. My recommendation: Learn 3. It's better. Then get used to using 2.
hey Dino, mate I downloaded the PTVSIntegrated executable, and installing it it prompts for me to open PythonToolsIntegrated.exe, and when it can't find it aborts the install. Any ideas?
It's definitely quicker than PyCharm (java based). I find the VS debugger to be more reliable than any of the other IDEs I use (Komodo, PyCharm) for debugging code built on top of bottle/flask. However it does tie you to Windows.
Opening up a new console window when I run a python script is a problem because the output of that script is lost when the new console window disappears. In prior versions of windows, running a python script output its stdout to the console window where the command was run.
I tried this and I got no output from my script at all.
Never mind, looks like it was a corrupted download
Does `python foo.py` work?
Use web2py!!!
&gt; Python 3.x is the present and future of the language Until you try to use any one of the many libraries that don't support 3.x yet. I'd love it if 3 were the present, but it isn't yet.
Yeah, the issue only happens when launching through windows file associations.
Seeing as you're on windows, I would recommend Python Tools for Visual Studio [Integrated w/ Visual Studio Download 199mb](https://pytools.codeplex.com/downloads/get/744521) You'll still need a python interpreter though, I'd grab latest 32 bit 2.7.x, and 3.3.x, and 64 bit versions, and probably grab pypy 2.1 as well, just to confuse you even more. Oh ok, just grab Python 3.3 32 bit.
My approach to dependency hell on Windows that has so far not failed me. Step 1: Attempt to pip install. If this requires compilation, ignore and continue. Step 2: Attempt to easy_install. easy_install searches for and uses binaries if they have been provided. This gets 90% of the stuff I can't get from pip. Step 3: Download a binary, and then easy_install the binary. You can actually pass binary installers to easy_install, and if you have your venv activated, it will actually install correctly and everything. I haven't found a package that this doesn't work with. As for my users, I provide a requirements.txt, and make a note in the installation instructions if any of the dependencies require compilation, and indicate if they should use easy_install or install a binary dependency.
I realise it doesn't have to be a python thing, but since iPython spawns the python kernels, I was wondering you could tell it to spawn them with a ulimit.
Can you explain what you mean? I'm just trying to transfer/evaluate a file or selection in REPL, and all I get is an error message that says, "Cannot find REPL for 'python.'" EDIT: I've figured out what you mean and I've done that, but now I can only do basic stuff such as print statements.
I just discovered your vincent library recently. I'm looking into developing some dynamic/interactive javascript plotting within ipython. Do you think the vincent/vega framework would be useful for that or do I need to look at lower level d3 packages? I'm using a zmq-websocket bridge and an iframe to show a visualization while a python thread does its work.
You can end up with the same things, sqlalchemy, whatever form library you like, whatever template library you feel like dropping in(though jinja2 is technically a requirement of Flask I think) etc. what does either choice actually tie you to? How you map url's to callables? A global style? I think not much.
I attended this years EuroScipy conference. The speaker said he tried all those libraries, and he recommends cartopy over basemap and everything else. Maybe you can find the video somewhere.
Vincent is really meant for static visualization, unfortunately. If you're interested in dynamic vis, take a look at python NVD3: https://github.com/areski/python-nvd3 or my other lib, Bearcart: https://github.com/wrobstory/bearcart I might put in a little work this weekend to integrate it more tightly with the ipython notebook. If you're looking for interactive D3 libs that are easy to work with, I highly recommend Dimple as well: http://dimplejs.org/
That's not quite correct, express does not support plugins. &gt; you cannot install PTVS (or any extension for that matter) into the VS Express editions. PTVS is a special stand alone version they've made available.
I hope you never write anything security critical if you think like this.
I have found the opposite. I use VS 2012 for work. 2013 for PTVS. PyCharm runs OK on my home development machine, which has 12 GB of RAM. So I use PyCharm at home. On my work box, with 6 GB of RAM, it hangs quite often. PTVS is much snappier on my work box.
ugh.. Visual Studio 
Thanks, good to know! I went into COM for a little bit and began hitting various comtypes problems soon. I will surely need it if I work up the courage to convert my old VBA routines to Python.
 pip install --use-wheel Pillow Should work in windows...
Thanks. You should also read these * http://jakevdp.github.io/blog/2012/08/08/memoryview-benchmarks/ * http://stackoverflow.com/questions/16039851/bakeoff-part-1-python-vs-cython-vs-cython-typed-memory-views-lda-by-gibbs-sampl I would be interested in seeing the speedup as you do a lot of slicing.
Notable changes include: * Supported versions - Support for Python 2.5 and Jython 2.5 has been dropped. They may still work, but no promises. * Bug Fixes - [#39] is_empty was missing from the global namespace * New Features - Support for numpy numeric values in iscloseto (Alexander Beedie) - A matcher targeting exceptions and call results (Per Fagrell) 
I posted this comment on another thread, but it's relevant here: I've played a little bit with maps and public data using Python. Here are a couple of links that might help you: [Tutorial on shapefiles](http://www.geophysique.be/2013/02/12/matplotlib-basemap-tutorial-10-shapefiles-unleached-continued/) (this helps for plotting data for regions on a map) [Raw data from UK Govenment](http://data.gov.uk/data) [Portable Atlas](http://ian.macky.net/pat/index.html) (more general interest) I used the first two links to create [this](https://docs.google.com/file/d/0B4XYiI1jRviXTlJPS3ZVMWl1UUE/edit?usp=sharing).
this is the python subreddit and I assume we should talk about python it's a nice general purpose language, at least from the point of writing code, has a lot of libraries and its learning experience is certainly less painful and sometimes even pleasant compared to other languages (I laughed loudly at that haskell post in the comments, as someone who has tried to learn haskell multiple times and failed, while being reasonably comfortable with python, if you don't think of advanced stuff like metaclasses and so on)
&gt; Once you've learned how to "think" in Python you'll find picking up other languages easier. sometimes I think it's the opposite, knowledge of python is so dominant that the temptation to write almost everything in python is very strong (since I already know it well enough to be comfortable with it) recent example: found out phantomjs and casperjs, tried to write some basic examples in javascript, cursed a lot while finding out that the version I had installed didn't have implemented yet those features that were already documented, also cursed a lot at javascript syntax which seemed so weird (I blame my habit of dealing with python). At some point during googling I find out that there's a phantomjs driver for selenium (which has python bindings) and life suddenly starts looking so good again :D
I'm using Anaconda distribution + PTVS.
Did you upgrade from Windows 8.0, or from an earlier version? If from 8.0, was Python installed already and working as expected before the upgrade?
Wow, I had no idea about that library, looks really good. Python's chart and visualization libraries have been exploding lately, and I love that all of them seem to have tight iPython Notebook integration.
I don't have this issue on 8.1.
Depends, if you are new to python and are starting with your first project. You should learn python 3.3.2 as it is the new standard and will be evolving why 2.7.5 is only going to evolve in bug fixies. on the other side 3.3.2 still has many unsupported libraries which are available in 2.7.5 I have some python experience in 2.7.5 and I have some difficulties with 3.3.2 as some libraries are suddenly not available or renamed still if you are new you should learn 3.3.2 as this is will be maintained more properly and will evolve while 2.7.5 while slowly fade out
Very good reads, looks like I should try the no-wraparound decorator as well. I'll give that and memory views a shot (very simple changes). Thanks for sharing. 
tx
Not OP but sounds pretty annoying to me to be working in a command line and to keep generating new windows. I just want to run the script in my current command line. Also I've experienced in earlier versions of windows that newly spawned command windows are not always in the proper path. I don't remember the details but it was something like the new window was in the path of the script or in a system folder. Of course this means that if you have file arguments you have to specify the full path instead of just the file name. Not sure if this is the case in Windows 8.1. 
The arduino board uses serial, yes. There are other options like the Nanode which include an Ethernet jack. You can use pyserial to write to it. What are you trying to do?
How to use python to make yourself unhappy :P
True, but since 2.x is not being developed and 3.x is I would say Python 3.x is the present. (I still use 2.x for all of my scientific coding)
http://www.reddit.com/r/Python/comments/1ohwue/incremental_garbage_collector_in_pypy/ http://www.reddit.com/r/Python/comments/1ok8a6/pypy_status_blog_incremental_garbage_collector_in/
Nice. What is the Arduino going to do in this process? Will it be on the suit or part of the machine vision (if you go that route) processes which capture the motion? Sending to/receiving from the board is relatively easy, using pyserial. If you can program it, and get the board to blink a light (the Blink sketch) you are halfway there. The Arduino site has a Python section: http://playground.arduino.cc/interfacing/python 
Nice teaching blog post: it is a good example for beginners on how to implement a thread safe queue. As a complement, for production use, I'd rather go for Queue.Queue which implements all the machinery for you out of the box. I would also use the hidden class ThreadPool from multiprocessing.pool. Finally, know that threading in Python is inefficient for CPU bound tasks because of the GIL. The best resource on earth about the GIL can be found here: http://www.dabeaz.com/GIL/. 
Of course, one would use the [queue](http://docs.python.org/2/library/queue.html) module instead of hand-coding your own queue and managing it with a lack of encapsulation.
Which actually shorten the code like: from threading import Thread import time import random from Queue import LifoQueue as Queue queue = Queue(10) class ProducerThread(Thread): def run(self): global queue nums = range(5) while True: num = random.choice(nums) queue.put(num) print "Produced", num time.sleep(random.random()) class ConsumerThread(Thread): def run(self): global queue while True: num = queue.get() print "Consumed", num time.sleep(random.random()) ProducerThread().start() ConsumerThread().start()
The question you are asking doesnt have an easy answer, thats what these folks are trying to get you to realize. Can you equal Go performance in an IO bound program? Probably. Can you beat it doing raw number calculation using regular python? Probably not. Can you design a program or system to use python's strengths and other tools to match or beat a pure Go implementation? Probably. You can't assume all things are equal. They are never equal. It depends...
The CPython C api can't be made fast with PyPy's moving GC. It was also redesigned in Python 3. Your best option is to port dependencies to CFFI.
Whats Major Differences Between Pyramid and Flask? - Pyramid is heavy configurable - Flask is ready to use Can we use Flask for creating a Complex Web App or its better to use Pyramid for Complex Apps ? It depends of what kind of complexity you are talking about... For exemple, Pyramid have a great ACL support, so it is simpler to manage user privilleges using Pyramid, but maybe a flask plugin do it as well. 
I think for a tutorial its better to stick to basic structures like list. Not everybody would be knowing queue and trying to learn two things at one time is always hard.
You can integrate with Sphinx using SphinxAPI. It has an official Python implementation. Check out *api/sphinxapi.py* in the official Sphinx source release and the [api reference documentation](http://sphinxsearch.com/docs/current.html#api-reference). Solr also have [an official Python API implementation](https://wiki.apache.org/solr/SolPython). There are also a few independent implementations on that same web page. Lucene is the core for Solr and it seems to have a nice Python implementation called [PyLucene](https://lucene.apache.org/pylucene/). Solr/Lucene is based on Java and the current tooling/documentation might require you to read/execute/understand/deduce stuff using java or java idioms. Free and open source wise, Sphinx and Solr/Lucene are some of the best and most popular Full Text Search engines. If you have the money, you can also check out [the proprietary ones](https://en.wikipedia.org/wiki/Full_text_search#Proprietary_software). I've heard that the PostgreSQL full text engine is good as well but you might need more configuration and it usually comes with less tools such as extracting text from Word or PDF files. If you need to have proprietary file format support, I think you are better with Solr and some of its' related tools.
Makes sense, pythonw is for windowless execution.
http://bildr.org/2012/03/stable-orientation-digital-imu-6dof-arduino/ http://invensense.com/mems/gyro/mpu6050.html It would gonna be platform for all sensors and hardware IO. going the low cost route, I would probably use inertial measurement chip (the cheap stuff used in mobile phones). Although It's just rough project plans, experiments, and technical milestone for now. tx for links.
If you are using Django, then pay a visit to [Haystack](http://haystacksearch.org/).
True and if it doesn't please open a ticket: https://github.com/python-imaging/Pillow/issues/new (You can also use easy_install Pillow)
I'm a pyramid fan but is some times hard to get consumers to buy it.
Agile eliminates waste too.
I'll poop when I'm dead.
Look at haystack if using Django. Then its Whoosh or if you need something more scalable choose solr or elasticsearch. I never used sphinx but it apear to have a smaller ecosystem so the alternatives pointed earlier seems better. 
None so far, at least when with Django. I've tried both ElasticSearch and Whoosh, and had issues with both.
Haystack + Whoosh is relatively easy to configure.
i would prefer to not help you build an auto-blog type website for you to slap your referral ID to. there is legality around this as well as in any scrapped content, the owner can turn around and says it copyrighted and if they are feeling particularly angry they can send a take down notice to your host (if you're in the united states.. ive done it myself, its pretty easy. most hosts will just do it) that being said.. amazon offer its on retailer portal type website if that what you want to do, skip the scrapping. 
Pagination is a lot better in the flask extension, sessions are handled "automagically", and the appropriate HTTP handlers (404s) are baked in.
&gt; windows So it seems, but that does nothing to solve the problem for me or my (at this point hypothetical) users. "To install, first remove your OS." One of the reasons I left Linux was because I got tired of constantly worrying about package management and how my system would break if I tried to update it. But I do miss the uniformity of the C toolchain.
Thanks. I ended up using easy_install and abandoning virtualenv. My original environment already had numpy and other packages, so that probably helped.
Good tips, thanks. It's a shame we can't just have the two merged into one tool, and those working binary installers loaded onto pypi so I don't have to download it separately.
Thanks. It appears there's yet another method/standard for package management I was unaware of: wheel. I realize things are better than the last time someone posted on this subreddit about package management woes, but do we have any hope of this madness ending within the next couple years? I understand it's an easy matter for you and the others who have kindly responded, but it's near impenetrable for those of us who aren't already experienced with the details. Especially when there's no definitive guide (a wiki or blog post) that covers the current state of the art.
My website is not an auto-blog and I am not in any affiliate programs (well except Amazon, but they required that for their product API which I no longer use in favor of Semantics3). My question, which your last statement may have answered, is if I can scrape shopping cart data, literally just what's in a user's cart. I'll have to check this out since I only had experience with their product API. For future onlookers, since this is an aggregate shopping cart we're talking about, the crawler's job would go something like this: if user not logged in, log in &gt; add item into cart &gt; go to cart page of retailer &gt; return cart data to me for aggregation
wasn't trying to "solve your problem", I was answering your (unjustified) rant. compiling code on windows that is not .net centric is intentionally a royal pain in the ass regardless of whether you are doing it for python or not. So basically a lot of the libs you are ranting about being piss poor support on windows and somehow pythons fault and should be fixed, is a bit misplaced IMO. 
Yup, but I couldn't get the Model filters to work.
I am using Pyramid.
Does Whoosh go along with Pyramid Well.
What do you mean by this? &gt; is any there any way to integrate [Sphinx, solr] in Python Based sites https://www.google.de/search?q=python+solr&amp;oq=python+solr&amp;aqs=chrome..69i57j69i60l5.1028j0j7&amp;sourceid=chrome&amp;espv=210&amp;es_sm=91&amp;ie=UTF-8#es_sm=91&amp;espv=210&amp;q=solr+and+python Although, personally speaking, I'm a much bigger fan of elasticsearch now, having experience of both.
I have trouble understanding what you are trying to do, especially since I would expect your example return to be [(1,1), (2,2), (6,2), (9,1)] Since your wanted_values are 1,2,2,1 not 1,2,1,2
and just for fun, here is a disgusting one liner that has side effects in a list comprehension values = [(i, i%4) for i in range(20)] wanted = [1, 2, 2, 1] # eww. [(x, wanted.pop(0))[0] for x in values if wanted and x[1] == wanted[0]]
My colleague has a lot of experience with Sphinx, Solr, Lucene, and ElasticSearch. He said it's not even a competition -- elastic search is the best thing since sliced bread.
Pyramid is going to be able to plugin to any search engine you need. It doesn't make any assumptions in that respect. I haven't looked into Whoosh at all, but you could probably bootstrap a connection to its api by making it a [request method](http://docs.pylonsproject.org/projects/pyramid/en/latest/api/config.html#pyramid.config.Configurator.add_request_method).
He might be from Germany, where nouns are title-cased.
Right you are. Fix'd.
I agree with a lot of others that you have made a lot of progress. I just want to add that knowing how to code and making money from it are not as correlated as one would think. Most well-paid and sought-after programmers are getting paid for particular domain knowledge more than skill in a specific language. The easiest way to create your unique value would be to try to connect programming to things you already know. You mentioned in an earlier blog post that sales and marketing is your thing, so trying to work on projects that loosely relate to that would probably take you much further. i.e. even 'aspiring CRM app programmer with years of sales experience' sounds much more valuable to me than 'python programmer'. All the best!
This is a different "wart", but still related to list comprehensions. Type this at the REPL. z = {} [adsf for z['wat'] in [0]] print z or z = {} print [z['wat'] for z['wat'] in [0]][0] print z
I use plain sqlalchemy for some projects that share webapp and non webapp code/models in the same codebase. For purely a webapp, there is little reason to not use flask-sqlalchemy really.
I second Whoosh. I used it for building ourthriftynickel.com
I believe it's because it translates it to something like this. tmp_lst = [] for x in [0]: z['wat'] = x tmp_list.append(adsf) 
Yeah, this is just an annoyance bug, I have to call to python.exe manually instead of letting file associations do it for me.
I did upgrade from 8.0, and I did have python installed before the upgrade. I uninstalled and re-installed python after I started experiencing the issue, and it did not fix the issue.
&gt; Yeah, the issue only happens when launching through windows file associations. 
If you added a make install to that work flow after the extraction, you could can have your make file handle the dependancies. 
While there are many learning styles, I don't think this should be the primary route taken. At the very least, take time to do structured learning on the side. That is don't learn another equally useful programming language, but learn about data structures, algorithms, and more specific knowledge as necessary when it comes up (e.g., HTML, CSS, sql databases, nosql, networking, AJAX, game design, 3d graphics, GUIs, machine learning, [unicode/encodings](http://www.joelonsoftware.com/articles/Unicode.html), [floating point](http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html), JSON, OAuth, web development, mobile development, etc). A project can help you, but don't just blindly cut and paste / slightly alter code snippets that you don't really understand until by chance it seems to work. You can get stuff working without understanding what's going on and write bad, inefficient, buggy, ugly, and unmaintainable code. E.g., your project is one giant function / file, not under version control, with bad variable names, unused sections commented out, recalculates things unnecessarily, etc. Few musicians would recommend to someone yearning to be a professional to learn a musical instrument by just picking it up without a book or a teacher and to instead just try and start writing songs. Granted, a fun project can be quite helpful to motivate you to push on and is great motivation to learn new things. But you don't want to get to the point where you hack things together that barely work in the end.
Yea... I'm trying to avoid downloading dependencies during installation. Our servers are internal and do not have a access to the internet. Obviously, this can be resolved by having an internal package server, and we do have that, but I would rather have dependencies contained within the package.
I think the problem is the way we're learning code nowadays. When I started I learned algorithms and pseudocode first (I'm talking about Turbo Pascal times). Knowing how to think about a problem logically, learning a new language was the same rote: learn the basic logical construct and statements (decision making, loops, data structures) and begin to work with the language reference at my lap. When the different paradigms arrived (OOP, functional programming, etc) the exercise was a little more difficult. But there were the logical foundations. Now i see people doing tutorial after tutorial and learn how to do things instead of how to resolve problems. When things get complicated they feel frustrated. 
Have a look at buildout: http://www.buildout.org/en/latest/, https://pypi.python.org/pypi/zc.buildout/2.2.1. You can easily specify a local path where to look for dependencies.
question for you, how's the packaging system on .net? Because it used to suck just as bad for 3rd party libraries depending on different runtimes or service packs, god forbid you had commercial 3rd party library dependencies. And before .net it was even worse with COM/activex regsrv32 crap. 
~~When you type "python foo.py" the word python gets replaced by the value of the python environment variable (at least on win7 and xp). Make sure that the environment variable named "python" points to the same place as the file association.~~ 
I'm gonna say that in 90% of the cases you will not have that much data to make Whoosh feel slow (for both, indexing and querying).
Check out my small [libcollect script](http://eli.thegreenplace.net/2008/07/03/libcollect-collecting-python-distributions/) - I've used it a lot in the past - quick and simple.
&gt;Variables – Global/ Local &gt;Data Types &gt;Strings &gt;Lists/ Dictionaries &gt;Functions &gt;Control Flow &gt;Modules &gt;File I/O (read, write, open, close - That’s it) &gt;Indentation You have a solid skill-set to build applications that don't have to do fancy things. You can build small desktop applications or web apps. If you want to build something fancy, honestly you can build that, too. It'll be ugly, and you'll keep learning as you go, but you will. It's long past time to build stuff. So build stuff.
Yes. You upload the [firmata](http://firmata.org/wiki/Main_Page) software to the Arduino then you can talk to it over USB serial using many high level languages. BreakfastSerial lets you talk to it using Python.
Really? Every noun? TIL.
Favoring any software engineering principle to the exclusion of all else causes problems, because there are inherently tradeoffs in design. Hence praising sometimes-contradictory principles.
&gt;sessions are handled "automagically" I thought the Flask way was anti-magic?
I believe [PyPy](http://doc.pypy.org/en/latest/faq.html) uses some form of type inference. [This paper](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.3231), Localized Type Inference of Atomic Types in Python (2005) by Brett Cannon, is &gt; an exploration of implementing a type inference algorithm for Python without changing the semantics of the language. [This paper](http://www.python.org/workshops/2000-01/proceedings/papers/aycock/aycock.html), Aggressive Type Inference by John Aycock, has some details and a nice references listing about type inference. [The PyLint project](http://dj1.willowmail.com/~jeske/Projects/PyLint/) has a type inference algorithm. There seems to be a dedicated group/project on the google code about Python type inference. Check [their resources list](https://code.google.com/p/python-type-inference/wiki/Resources). [This paper](http://www.dcc.fc.up.pt/~nam/publica/artigoDYLA.pdf), A Static Type Inference for Python by Maia, Moreira and Reis, seems to have some interesting ideas about it. [This other paper](http://dspace.mit.edu/handle/1721.1/16688), Starkiller : a static type inferencer and compiler for Python by Salib, Michael, is another reference you might want to check. Did you really search because in the 5 minutes I did [a google search about it](http://lmgtfy.com/?q=python+type+inference), I found quite a lot of material?
Yup. I started off with Fask-SQLAlchemy and moved away from it in large part for this reason.
I don't see anything obvious there, could you either open a bug on CodePlex w/ the full install log or just send the log to ptvshelp@microsoft.com? 
I wouldn't know, I'm not a .NET programmer. My concern here is not comparing Python to .NET, linux to windows, or apples to oranges. It's comparing Python as it is now to Python how it should ideally be.
It's not about speed, it's about compatibility. For instance, I'd rather have a slow implementation of matplotlib on PyPy than no matplotlib at all.
I hope you finish it !
Thanks for helping, I was able to get a first version of the code done. I'll attach the code to the question above.
Yes, that's the thing I was looking for "extrude" a shape along a path :-) With all you people's help I was able to get a basic version of the code done. I'll attach the code to the question above. Cheers!
I use this instead: https://github.com/lucuma/orm Like Flask-SQLAlchemy but without requiring an app context
PyDev (Eclipse plugin) and PyCharm both do this if you're more interested in using the tool than developing a new tool.
I wrote a library just for this https://github.com/thearn/Python-Arduino-Command-API
 lovePython = True while True: print "Thank You Python Community!" 