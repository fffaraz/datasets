I see nothing there where he says they are unpythonic. I see him saying that developers misuse them, but then developers misuse a lot of pythonic things ;)
And alternatively, there's scikit-learns implementation using the LIBLINEAR library, and they also have a stochastic gradient descent implementation for on-line learning. Although the closed-form solution (the "normal equations") in statsmodels and via the NumPy linalg model are probably preferable for typical tasks, LIBLINEAR and SGD can be useful when working with large datasets since inverting a matrix can be quite expensive.
I've never heard about doing this - aren't static files pulled down client-side?
I would think nginx would be a better place to handle everything on that list except for the task queue.
Or you can use something like grequests or requests-futures for your external calls. Personally, I only use a task queues for really heavy/long running tasks. I don't really see the need if it's just external API calls that will return in &lt;1 second 99.9% of the time. 
well I'm using the funcAnimation function. It upgrades the graph already. But only the x-axis is not getting updated. import numpy as np from matplotlib import pyplot as plt from matplotlib import animation # First set up the figure, the axis, and the plot element we want to animate fig = plt.figure() ax = plt.axes(xlim=(0, 2), ylim=(-2, 2)) line, = ax.plot([], [], lw=2) y = np.zeros(1) # initialization function: plot the background of each frame def init(): line.set_data([], []) return line, # animation function. This is called sequentially def animate(i): global y, ax y = np.append(y,np.sin(len(y)*0.1)) x = np.arange(0,len(y)) *0.1 if x[-1] &gt; ax.get_xlim()[1]: ax.set_xlim([0,x[-1]]) line.set_data(x, y) return line, # call the animator. blit=True means only re-draw the parts that have changed. anim = animation.FuncAnimation(fig, animate, init_func=init, frames=200, interval=0.001, blit=True) plt.show()
But every professional statistician out there that I've ever met (quite a few) has been doing programming for their whole careers. The rebranding seems very odd. Is "statistics" just not a sexy enough term?
&gt; Don't use // and % -- just use divmod I also didn't know this existed - what's the reasoning for using this over %?
can anyone tell me how do I get started writing intelligent things?
80 lines and keras. Either way good work! 
Very good news. I absolutely love Anaconda! It changed my whole workflow with Python for the better.
Enable debug mode : https://docs.python.org/3/library/asyncio-dev.html
I think another component is that data scientist implies that you're working with big data (on the scale of petabytes) and not doing so much collection as processing. At that scale, your sample almost looks like a population. Statisticians do a lot of data acquisition and think about how to deal with sample bias and stuff. They're probably less likely to deal with huge amounts of data and more likely to figure out how to take small amounts of data and massage it into something representative of the population.
[pub](https://www.dartlang.org/tools/pub/pubspec.html) comes to mind. 
Sadly, /r/python isn't the subreddit for python questions. You want /r/learnpython.
&gt; sentance
Thanks! I ended up using Console2 with Cygwin (the only reason for console 2 is for multiple tabs). If that doesn't work out I'll consider Gvim.
I'd argue that /r/learnenglish would be better suited to his needs, but what do I know?
Recently, I had to plot some geo coordinates on a map and wrote a little about the experience: [plotting-points-on-map](http://kazuar.github.io/plotting-points-on-map/) I'll be happy to help as I think it should be much easier to do that.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/datascience] [Continuum Analytics Raises $24M for Anaconda Python and PyData](https://np.reddit.com/r/datascience/comments/3ecrn1/continuum_analytics_raises_24m_for_anaconda/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
I was unaware of that feature. Why wouldn't this be enabled by default? [EDIT] Enabling debug mode did not display any additional information for this type of error. It's possible I've done it wrong but exporting an environment variable PYTHONASYNCIODEBUG=1 is pretty straight forward.
Anyone have a starter bot in Python?
It might negatively affect performance. I'm not sure. 
Yes, use anaconda if you are an idiot and have no clue what you need. If you mention anaconda in an interview, i will show you the door.
Yes, this is generally called "web scraping". [Chapter 11 of Automate the Boring Stuff with Python](http://automatetheboringstuff.com/chapter11/) (a free book for beginners) covers web scraping.
Why the ridiculous hostility towards Anaconda? Most people adopting Python in the sciences need a simple, all-in-one (remember the Python mantra, "batteries included") toolkit. Sure, they'll probably only use a fraction of the modules that ship with Anaconda. But that's really perfectly fine for basic analysis. The optimal approach of miniconda + an environment with only required dependencies for your particular analysis is great for shipping a reproducible product at the end of your work, but it's not necessary from the get-go.
Kivy is meant for mobile and it doesn't offer much of what I need. WX is completely squared off. I hate the look of that.
I'm mostly posting this here so that I can tell people that generators plus itertools are often the better choice. So instead of print([(x,y) for x in range(5) for y in range(5)]) use import itertools xgen = range(5) ygen = range(5) print(list(itertools.product(xgen, ygen)))
You can use miniconda to distribute? 
I use Anaconda (it's free btw), but I guess that negates all my degrees and years of experience? LOL
Okay will do, I didn't even knew that subredit existed!
&gt; Frog out of core arrays/dataframes Cool! All my frogs are in-core. 
A searchable PDF document management/delivery platform and scanning system. Oh, wait, did you mean something *interesting*?
I'm assuming it's because of the outer parentheses on the first example, as this works: `(2,2) in ((2,2),)`
Raytracing is actually very fun and challenging to write. Definitely a good exercise!
Just an FYI :) Anaconda may be free for all use but one has to pay attention to all licensing found within the available packages for use. Anything GPL'd will not be of use to a company who wishes to retain secrecy of their product. The answer of 'just don't use that package' seems like a valid answer except a piece of software that is GPL as part of the base installation could cause some legal headaches if the author(s) of said software wanted to make an example of a situation. Sooooo, if you happen to work in an environment where you are walking a line between open source and closed source, for commercial use, Anaconda may not solve your issues due to licensing. 
You have *literally no idea* what you're talking about. You don't have to pay Enthought or Continuum a single penny to use their software, which - save for a few exceptions - are all entirely open source and free to use, modify, and re-distribute. The services they offer are boutique consulting services which the vast majority of users would have no need for. But, you're obviously an uninformed troll. So there's no point talking with you.
The Template engine of bottle. Not big, but dense. A lot of thoughts went into it.
Your dismissal of Anaconda shows that you aren't actually very acquainted with the project. The anaconda tool and their public server is free. The open source tools and a lot of their libraries are free as well. If you want to run their server with support, you need to pay. If you want their closed source libraries for high performance computing (not the every day kind of computing) you need to pay. If you want their general consulting services, you need to pay. I was talking to the Continuum guys at the SciPy convention a couple weeks ago and they even said it's technically possible to get the conda server set up yourself, but there aren't really any walkthroughs for it and isn't a very straightforward task. This is true of PyPI as well (I know because I've tried). The 330+ packages that they advertise are _pre-built binaries_. If you want numba installed on Windows (yes, some of us are stuck on Windows, it's terrible as a Linux guy), you can try to compile it and LLVM from source, or try to get the standalone binaries to work, or you can `conda install numba` and it just works. You want numpy? Just `conda install numpy`. No hassle, no compiling, no problems. Additionally, you still get `pip` and `virtualenv` if you want so you can install packages normally. They're even set up to use the conda environments that go alongside your system installed Python. I currently have Python 2.7 and Python 3.4 installed to my system, and then several custom conda environments that are a mix of the two. The conda environments just don't even interact with the system installed Python distributions. It's just easy.
Looks like it can, as long as it has a note in the documentation or license saying that blaze is included and copying the blaze license.
It is really useful. Though I can't comment about speed compared to other approaches its simplicity is really good. I've used it myself for a library that deals with parsing range types from Postgres databases: Project GitHub: https://github.com/runfalk/psycospans Scanner usage: https://github.com/runfalk/psycospans/blob/master/psycospans/_utils.py
If you show me the door because I use anaconda in my research, then I'll happily take myself and my PhD elsewhere, because I don't want to work for you.
Thanks. I thought so, but was suspicious given they didn't see to name a known open source license like apache, mit etc. 
Interesting, didn't realize that. Seems like a reason to use python instead of R for these things also. I think R is GPL
Just because it can, doesn't mean it should. Splitting them up into 5 services makes it easier to scale things. Also, if one part of your stack (e.g., Celery) goes down, everything doesn't go down.
Mainly pypdf, reportlab, xhtml2pdf, pdftk, mod_python. Despite years of browbeating the IT department I have thus far been unable to convince them to switch to mod_wsgi on production. We are also still running on Python 2.4 on production, thanks to RHEL 5.5 having serious issues with upgrading the Python which is used for yum and a bunch of other critical system functions. Trying to fight corporate inertia is no fun.
If you don't appreciate Anaconda, I'll show myself the door. 
Most complex public code is probably this: https://github.com/EntilZha/ScalaFunctional It is a library for functional programming with pipelines/chaining functions together. It is very helpful for local data cleaning/transformation when its not large enough for something like spark, but not well formatted enough for pandas. Hardest part is keeping track of list of transformations to apply to a collection, and those that already have been applied. A lot of thought also went into how it behaves and creating desirable default behavior.
[Dave, is that you?](https://youtu.be/D1twn9kLmYg?t=8617)
I'm somewhat confused about the difference between using anaconda and just setting up a virtualenv then using pip install, does anyone mind clarifying? It seems this is just a package manager, or a distribution of python that comes with a bunch of packages I could otherwise install from some other place, is there some advantage to using Anaconda? 
No, there's likely not much you can do. CPython is not exactly fast and can't be made fast without writing things in C, which is why `list.sort()` exists which will totally smoke anything you try to write by hand, even if it's run under PyPy. 
This is posted in r/python and they don't have a python starter bot?
Pip is catching up with stuff like wheels. Conda still has an edge as you can specify exact versions of packages. Also does virtualenv support swapping between py2/3? And they have some nice add on packages (accelerate has MKL bindings + numba pro)
((2,2),) is a tuple containing (2,2) whereas ((2,2)) is just a parenthesized expression containing (2,2) and evaluating to the tuple (2,2). Yes, this is rather idiosyncratic. I have known a few people who like to take advantage of the fact that you can leave trailing commas in sequence types to add entries later also cite this as another reason to just make a habit of it but your mileage may vary.
Uhh, you can specify a version of a package with pip `pip install django==1.8.2`.
Yeah I was at a Python in Finance conference and this guy sits next to me. We start talking and he introduces himself as Travis. I didn't know who he was until he tells me he's going up to speak later (we were sitting in the middle section). I immediately started gushing but tried to hold it back. I met Peter at a talk hosted by Enthought in NYC and visited them in Austin (read: botched an interview...sort of - at the time my coding experience was that of a trader and less so of a pure dev). While the interview went terribly, my conversation with Peter went beautifully. I had some friends higher up in finance so we spoke a lot about strategy and what Continuum could bring in that area. Meanwhile, I got back and brushed up on my comp sci - turns out it had been awhile. They didn't judge though and took me out to bbq. 10/10 would do again.
Wait for people to click on a topic link that doesn't give any indication what the question will be?
The most complex thing I've wrote is a Java to C++ converter that allowed you to port mobile games from J2ME to BREW. The code ran faster than hand converted code. It was written in Java unfortunately (based on a bytecode optimizer I wrote in C++)
They are awesome guys (Continuum). One of their devs I adjacently work with from Continuum is probably the friendliest of all the researchers I am near. Makes me want to work in Austin.
The advantages of Anaconda and conda are many-fold: * You can easily install binary packages for libraries that are traditionally very hard to build * The inter-dependencies between the C/C++/FORTRAN level libraries of some scipy/pydata extension modules are carefully managed and tracked, so you don't end up installing incompatible versions of things * Actually with FORTRAN the situation is even more abysmal because different *compilers* have incompatible ABIs. So if someone gives you a wheel package of some scipy library that happens to have FORTRAN code in it, you have no guarantees that it will work with some other wheel of some other library. * Native extension modules in conda packages are built to be relocatable, and conda's post-install facility handles things like rpath rewriting and such. This is very important to making binary packages work correctly, especially when they share common underlying libraries like libjpeg, etc. * conda's environments feature is much more robust than virtualenv when managing these aforementioned C/C++/FORTRAN level ABI issues. In case you are thinking, "I never use C++/FORTRAN", the truth is that a LOT of useful engineering and foundational libraries in the SciPy ecosystem do rely on these. It's part of the reason why Python is winning in this space, and e.g. Ruby is basically irrelevant. So it's very important that we handle this kind of thing correctly. Another major appeal of Anaconda for many users is that it basically Just Works on all major platforms - Windows, Linux, Mac. It doesn't interfere with pre-existing installs of Python or system Python, and you just set your PATH variable to use it, or change your PATH to stop using it. On Windows, our installers can be run as non-root, which is massively useful for lots of business users who are stuck on laptops that IT has locked down. Conda and Anaconda allow them to get all of Python+SciPy+PyData and then manage additional libraries on top of that, without begging for local admin access from IT. So for many people who are teaching Python to students or large groups of new Data Science users, Anaconda is something they can rely on to Just Work, regardless if someone brings in an old 32-bit XP laptop or if they have a shiny new Macbook Pro. People run the Anaconda installer, and they're in business with IPython notebook and plotting data within minutes. I know that some people in the broader (non-scientific) Python ecosystem scoff or roll their eyes at the things we've done with Anaconda and conda, but the reality is that we are solving actual users' pains, and taking care of myriad little details that have plagued SciPy ecosystem adoption for over a decade. 
I'll investigate that. Probably won't get to it until Monday or Tuesday. Thanks for the tip!
I believe all of our open source software is 3-clause BSD/MIT. We may have an Apache licensed thing here or there, but we very much try to use permissive OSS license whenever possible.
Ahh, I see. That makes a lot of sense, thanks for explaining
Cool! Congratulations and thanks for supporting open source!
Yes! So glad to see python grow in the field of data science. Enterprise bullshit like SAS needs to die. 
Just use "pip install ...".
I believe it's because the only thing inside of the () that denotes a tuple is the comma, since () can also be used for mathematical expressions. That's why if you add the comma ((2,2),) it is seen as a 1 element tuple. I could be wrong though. 
I love Python, but maybe this will convince you to switch to something with a better type system, that would warn you about this.
You were missing a comma: `(2,2) in ((2,2))` cannot be True -- because `(2,2) == ((2,2))` is True. # the 2nd comma makes it a tuple containing 1 tuple In [1]: (2,2) in ((2,2),) Out[1]: True In [2]: type((2,2)) Out[2]: tuple # but you don't need the comma for an empty tuple In [3]: type(()) Out[3]: tuple In [4]: len(((2,2))) Out[4]: 2 In [5]: len(((2,2),)) Out[5]: 1 Without the comma, `((2,2))` means precisely the same thing as `(2,2)`. 
I'm very new into learning python and one of the current projects i'm working on, is actually with reading/searching/gathering the contents of a PDF file with user data. Which library or module is best to use? much thanks!
In addition to what cristian-mann said, adding a comma at the end of an expression will cause the end result to become a tuple. For example, &gt; t = 5 == 5, &gt; print t &gt; (True,) This cause me a good bit of frustration for about 20 minutes.
I'm curious why you're following /r/Python if you (seem to) generally think that people should migrate away from it?
Awesome news !
Going into a data program. Was looking at a statistics program and I was asking the professor this question. She said, "If you give me a perfectly sampled, clean, dataset of the appropriate size, it'll take me five minutes to answer your question (Implying the techniques already exist and are straightforward to implement). The interesting work comes when you have too much or not enough information."
You may be interested in the parallel installable python27 packages from [IUS](https://iuscommunity.org). The system tools keep using Python 2.4, but you can have your application explicitly call /usr/bin/python2.7 instead.
Lol. Get out. 
Man, all the statisticians I know work on very abstracted stuff (mostly measure theory and applied analysis).
I don't generally think that. I'm curious why you assume that based on a single comment. Not really, but it does seem odd.
A news video discovery algorithm. It has a bunch of machine learning algorithms doing the job. Multiple keyword detection systems, a voting algorithm to determine best keywords to use. And it also uses a graph database to find connections between news articles. Shameless plug. wingztv.com Im not the best front end chap so bear with the slowness. But you get new videos that the algorithm discovers daily!
&gt; Set the log level of the asyncio logger to logging.DEBUG. For example, call logging.basicConfig(level=logging.DEBUG) at startup. 
What do you mean change your path variable to use it? What does this do? 
So given that the script i'm trying to write reads and stores data from a PDF file which then searches for the same information asked in the first PDF and fills it out onto the second, would it be troublesome given that the output wouldn't be garbage?
Use Anaconda
Well, that's not entirely accurate. `x == y and x in y` can be true for some special cases. See this example: &gt;&gt;&gt; x = [] &gt;&gt;&gt; x.append(x) &gt;&gt;&gt; x in x True &gt;&gt;&gt; x == x True &gt;&gt;&gt; print x [[...]] It's a pretty interesting case that can break a lot of things dependent on some assumptions that are usually true. 
I'd like to know how to do it. For knowledges sake
You use SWIG, Cython, or numpy/scipy/pandas if you want C level performance in CPython. Numpy, scipy, and pandas are amazing, but you can't write your algorithms like that or they'll be slow. You have to vectorize them, size your arrays, and define types. Also, /r/python or /r/learnpython is the place to go for questions like this.
Tkinter : https://docs.python.org/3/library/tk.html
This already is r/python
Interesting. I've learnt something today! &gt;&gt;&gt; (2,2) is ((2,2)) 0: False &gt;&gt;&gt; (2,2) is (2,2) 1: False &gt;&gt;&gt; (2,2) == (2,2) 2: True &gt;&gt;&gt; (2,2) == (2,2), 3: (True,) &gt;&gt;&gt; (2,2) is (2,2), 4: (False,) &gt;&gt;&gt; (2,2) is ((2,2),) 5: False &gt;&gt;&gt; (2,2) in ((2,2),) 6: True &gt;&gt;&gt; 
So on Windows, this is the %PATH% variable, and on Linux/Mac, it's your $PATH. This variable determines what directories are searched for various commands you type at the command line. So if you pre-pend the Anaconda installation directory to your PATH, then when you type "python" at the command prompt or terminal, then it will load up Anaconda Python. To stop using Anaconda, you just remove that directory reference in your PATH, and it will revert to using your previously installed Python (if you had one). 
Terrible say nothing blog spam that has nothing to do with python.
Absolutely, by Basemap do you mean matplotlibs Basemap? Certainly this can easily be done - the trouble is having the underlying maps
And then Ubuntu upgrades from Python 3.4.2 to 3.4.3, and while virtualenv moves the python binary into the virtualenv, it still uses ctypes from your /usr/lib/python3.4, which suddenly isn't the same version as the interpreter, and you have to rebuild your virtualenv. Which isn't that difficult, but there's a reason you don't want to use your system python for your own software, and virtualenv doesn't solve this problem.
Would depend on your operating system. As a Fedora Linux user, I simply install the appropriate packages from the Fedora repositories. Anaconda is really good though, so I am seriously considering switching over to that. Especially since it helps when you want to run the same code over machines with different operating systems.
There are actualy 14 bots in Python in the competition, http://theaigames.com/competitions/ai-block-battle/leaderboard/language We asked for starterbots here http://theaigames.com/discussions/ai-block-battle/55b1f1115d203ccf128b4572/starterbots-wanted/1/show From earlier experience, think will have a starterbot for Python soon here: http://theaigames.com/competitions/ai-block-battle/getting-started :) 
If you simply re-order the arguments by priority, then it works. &gt;&gt;&gt; nop = lambda y, x: x &gt;&gt;&gt; scanner = re.Scanner([(r'\+=', nop), (r'\+', nop), (r'=', nop)]) &gt;&gt;&gt; scanner.scan('+=') (['+='], '') Though, it might not work for far more complex situations. But still, I find it pretty useful for some simple lexical analysis, like parsing assembly.
A real-time image processing pipeline.
asyncio is the networking library that will keep Python relevant for the foreseeable future.
The way I have done in past for some of my projects is to first check whether that website has an API. If they do provide an API always, always use that instead of scraping the website. Going through the entire API documentation isn't necessary at all. Just find the things you need for your work and you are good to go. To check API endpoints before writing them down you could use Postman which is awesome for this work. Also PRAW is a wrapper for Reddit API and not the actual API. Wrappers help you to use API easily in your favorite programming language. In case they don't have an API you need to manually figure out the HTML structure and use libraries such as beautiful soup to parse required elements to scrape your data. Please also note that scraping might be not allowed for some websites. You need to check with them. I will suggest you to take a look at requests library and Beautiful Soup library. Make a real project, you'll learn things as you go 
that's cool!
+1 for itertools. It's awesome what can be done with this module in combination with list comprehension.
did you try or are you making an actual assumptions without trying? I can bet you pure-int list in pypy can be sorted faster in pure python than list.sort() in CPython wanna bet?
just use [beautiful soup](http://www.crummy.com/software/BeautifulSoup/) a cool example of how to use it: http://codereview.stackexchange.com/questions/32667/python-ebay-scraper-with-beautifulsoup an alternative (non-python) is phantomjs and selenium. but that may be out of the scope needed for your current project 
`range` returns a list in Python 2: py&gt; range(3)*2 [0, 1, 2, 0, 1, 2] In Python 3, `range` is equivalent to Python2's `xrange`.
No, the implementation of `is` differs between different python implementations, but the semantics do not. The `is` operator tests if two objects are the same object. If you need to test if two objects are in fact the same object and not only have the same value, use this `is` operator. However, if you want to test if two objects have the same value, don't use the `is` operator, use the `==` operator.
No, you can't mimic it in pure Python. You need a JIT optimizing compiler, which is what PyPy is. How PyPy *actually* works is too clever for me, but fortunately [how it *could* work is easier to understand](https://glyph.twistedmatrix.com/2012/02/this-isnt-how-pypy-works-but-it-might.html).
it works with ion()
Itertools (mentioned elsewhere) and functools. Functools gives you some functional programming standards that are otherwise missing (though the whatever package also helps, but is not in the stl).
You should be using virtualenvs, whether you're using Anaconda or another python. Use the conda installer to create Anaconda virtualenvs, which will come with the relevant packages. Then you don't have to worry about other pythons, or even other anaconda environments. 
Don't use anaconda. Just use a virtual environment and the packages you actually want.
Wait, what exactly is going on here? Why isn't the result just `[[]]`? Is there any situation where... what appears to be an infinitely self-nested list... is useful? Presumably some kind of mathematics? Is there a name for this feature, or perhaps a PEP? &gt;&gt;&gt; x = [[]] &gt;&gt;&gt; x [[]] &gt;&gt;&gt; x = [] &gt;&gt;&gt; x [] &gt;&gt;&gt; x.append(x) &gt;&gt;&gt; x [[...]] &gt;&gt;&gt; x[0][0][0] = [] &gt;&gt;&gt; x [[]] &gt;&gt;&gt; x[0][0][0] = [] Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; IndexError: list index out of range Why does this behavior even exist?
This story is somewhat complicated by the fact that the empty tuple *is* represented by parentheses. Makes it more confusing. 
It might be a bit of a jump, but I find it odd that the first reaction to "I ran into this wart in Python" would be "choose a language with a better type system." That seems like a pretty general statement.
There's a much simpler case of `'a' in 'a' and 'a' == 'a'`.
second answer in this thread but I want to vote for ctypes also. My software is not on a server but distributed to regular users, so every dependency (or the lack of a depency) increases acceptance and stability of the software in the future. Having knowledge of ctypes enables you to directly access you common C libs for these small tasks you need here and there, eg. talking to X11 . There is a python binding for nearly everything but you always draw in a huge package of stuff you don't need anyway.
Comma in a tuple. Not reading the docs mistake. 
Just for fun I rewrote this to use Cython, using a C++ integer vector. All the inner loops are then basically pure C++. My expectation was that this would be at least as fast as PyPy, but it turns out that PyPy is over 4 times faster! (0.183 s for PyPy vs 0.844 s for Cython). How on earth is that possible? Here is the Cython code: # distutils: language=c++ from libcpp.vector cimport vector def c_insertion_sort(list array not None): cdef int un, st, val cdef vector[int] vect for un in range(len(array)): vect.push_back(array[un]) for un in range(1, vect.size()): st = un - 1 val = vect[un] while st &gt;= 0 and vect[st] &gt; val: vect[st + 1] = vect[st] st -= 1 vect[st + 1] = val array = [vect[i] for i in range(vect.size())] return array I also ported to Py3. Turns out Python3 is quite a bit slower here, 21.0 s vs 16.1 s for Py2.
It exists because it's a valid thing to do. Lists are things that contain objects, and a list is an object. You can append a list to a list, so that list that you append could happen to be the same list. Saying you shouldn't be allowed to is effectively making this a special case, and as the quote goes, "Special cases aren't special enough to break the rules". As for usefulness, there are definitely cases where you want something that ultimately "contains" itself at some level. Eg. a [Graph](https://en.wikipedia.org/wiki/Graph_%28abstract_data_type%29) data structure is one that can contain cycles - a node can link back to itself, or link to a node that links back to itself, and so on (think of something like a rail network or simialr). If each node is represented by a list of connected nodes, then there will be these recursive references to nodes "higher up" in the list in such a graph. There does have to be some care taken with such structures though, as a naive algorithm could end up looping infinitely if it tries to process them as if they were a tree, since they're effectively infinitely deep. Eg. if you try to print something like this, you'll note that python replaces lists it has already seen with "[...]", because if it continued printing the contents, it'd never end up finishing (ie the list that contained itself is "`[[[[[[[[[[[[[[[[[.....]]]]]]]]]]]]]]]]]`)".
Great, thx for your effort. I don't know much Cython. Is that improvement due to gcc or other C-compiler optimizations ? In the meantime I did rewrote the original algorithm to Ruby and it has much better results then CPython, without additional tweaks: def insert_sort(array) (1 ... array.length).each do |un| value = array[un] st = un - 1 while st &gt;= 0 &amp;&amp; array[st] &gt; value st -= 1 end unless st == un - 1 array[st + 2 .. un] = array[st + 1 .. un-1] array[st+1] = value end end array end On the same machine: CPython 2.7.10 â†’ 14.43 s CPython 3.4.3 â†’ 13.57 s CRuby 2.2.2 â†’ 4.04 s Also surprising how much CRuby VM did improved over time, where CPython seems stalled â€¦
Semantically seen, though, the bug might be that you want to check for containment in a tuple. It may well be that a plain list `[(2, 2)]` is the more appropriate data type anyway.
Use `list` constructor there, replace `xrange` with `range` and wrap print argument in parens `()` to run on Py3.
This isn't monkey patching. Rather, he's doing dynamic stack inspection to get the caller, making the assumption that this is always a method of an object with a .request attribute, and getting it from there. Nothing gets monkey patched.
I'd put it in the "insult to God and humanity" box. You end up with a function that's going to fail in unexpected ways if called somewhere unexpected (eg. via some intermediate function with a different "request" attribute) etc. I'd say a better way to do this would be to make request a thread local global variable. Yes, this is still a little hacky, but much less so that walking up the stack. You'd just need a bit of code at the toplevel to store it, and then just grab it again in your function. This will work regardless of where you're called from, and seems much cleaner. The only issue would be if you use this in some spun off thread, in which case, you'll need to also copy the thread local across when creating the thread.
It looks like the most costly operations are python's `list` insertions/deletions, which standard CPython bytecode compiler &amp; interpreter can't optimize (unlike PyPy). If the sorting algorithm would be rewritten for a (bi-directional) linked list, I'd expect significant speed improvement.
/r/imgoingtohellforthis
Yes, I have already annotated with the arrow. But I was in a situation where I wanted to set the alpha of the arrow (and the annotation) to zero temporarily. When I tried to address the annotation as noted above, it only removed the text but not the arrows.
Arguably, the set is the better data structure for doing membership testing.
Annotating with genius an ipython notebook? Very interesting idea
You could maybe use your hack to print or log the locations where it is necessary, and then that would give you a list of places that must be refactored? 
Pip comes with python. Why go through all that nonsense when it can be done with one pip command? I think you are the troll. Anaconda is totally unnecessary.
And this is why unit tests exist.
Does this library has any advantage over pyalgotrade?
+1 for beautiful soup. [Script using beautiful soup]( https://github.com/monstermudder78/HockeyLight/blob/master/HockeyLight.py )
It's looking up the stackframe for a variable named `self` in order to find an attribute called `request` instead of just making the function take a `request` variable.
Rather than passing in the HTTP Request to the function (and changing code in every place that calls the function), he searches up the call stack for a calling object that has a "request" attribute, and uses that.
Pyramid makes a function available, aptly named `get_current_request()` as documented here: http://docs.pylonsproject.org/projects/pyramid//en/latest/api/threadlocal.html#pyramid.threadlocal.get_current_request It's a threadlocal. You can use that instead to fetch the current request without needing to do any hacking. It's one of the few threadlocal "global" variables that exists in Pyramid.
Thanks for refactoring our sentence.
I use scrapy( for all my scraping needs. www.scrapy.org Its pretty cool. And yeah like in the other comments it uses beautiful soup to actually handle the extraction of content from the HTML. A quick Google would get you some starter templates I'm scrapy to start scraping away at the web.
This is not the request you are looking for....
`playerCard == 11` Is checking to see if the variable playerCard is equal to 11. That's perfect for an if statement, since you want to check the current value of the variable. However if you want to assign a new value to a variable, you have to use =. So, change your `playerCard == 10` line to `playerCard = 10`
Thank you! Worked perfectly!
Well, that's brilliant alright. It's also a *really* bad idea.
Still need to make the application go though all branches in the application to find all the call locations.
No, it's actually specific to what he said and what I said was not a command. :|
Your problem here is that raw_input returns a string, but you're testing for ints (numbers). Change `if ace_input == 1:` to `if ace_input == '1':` and then do the same with your `elif ace_input == 11:` Does that make sense?
You cannot mimic it with pure Python. PyPy uses a JIT and finds the hot spots of your code. Certain Python idioms (e.g. data types changing) will confuse the JIT, but that's probably not too much of an issue. They're then compiled with LLVM. There is startup time associated with the JIT, so short codes will be much longer. PyPy will even optimize across library boundaries, so it can theoretically be faster than C in certain cases.
And here is another general purpose implementation: http://werkzeug.pocoo.org/docs/0.10/local/
This is what test coverage is for.
mitsuhiko mentions this technique in one of my favorite python talks [5 years of bad ideas](https://www.youtube.com/watch?v=8e0l_Dt28MQ). Here's a [direct link to the slide](https://speakerdeck.com/mitsuhiko/5-years-of-bad-ideas?slide=15)
beautiful soup and selenium work well together (you can grab everything and it avoids a lot of the server side scrape detection since it actually *is* a browser requesting).
Agreed. This is a bomb just waiting for a fuse. All that's needed is another object involved in the call stack somewhere that also has a member named "request."
Agreed, I use Python for stuff I would have used bash scripting for years ago and os.path is lovely to work with.
&gt; How would you hand-optimize insert_sort for CPython to get closer results of PyPy ? def insertion_sort(array): return sorted(array) edit: this is more than just snark. Dealing with arrays in Python is the kind of thing where the interpreter adds lots of overhead that is very easily removed by a JIT that is going to use native machine-level data structures in almost a 1-1 way. Python gets around the limitation of interpreter overhead for fine-grained operations by providing *lots of primitives*, like `sorted()`. If you find yourself tinkering around with low-level data structures like arrays, and end up writing code that looks a lot like C code, chances are you need to take advantage of builtins some more. 
I do R&amp;D, so... The two biggest failures my company has made regarding software were 1) Pushing a geometry creation tool that seemed great at the time, but fell apart at the very end of the project when another, much easier, much better tool was released by our customer for free. I was at the release presentation. My heart just sank. 2) During that same project, we had two tools at one point, but only pushed one. For 5 years after the other tool was released, both tools were dead. We finally found a way to integrate the second tool in a way that worked with the free geometry tool and it was 100x better than what we had. We chose the wrong tool to push because we misunderstood the community. In my experience, software projects fail because of bad ideas. You build megalithic systems around bad ideas and have a pretty GUI, but it's still a bad idea. It's the really good ideas that you can have the most unintuitive GUI (or even a buggy text based interface), that succeed despite their unfriendly interface.
Pretty sure this is how a lot of companies operate. and now I'm sad :(
My first thought was "at least check that your `self` object is the right type..."
A surprisingly good place to discover web scraping techniques is by googling 'data journalism' and similar terms. There are courses in journalism departments that teach how to do web scraping, whether in python or another handrolled method, or with google spreadsheets (yes they can autopopulate stuff with the right cell type), SaaS solutions, etc. Here's a quick example - http://datajournalismhandbook.org/1.0/en/getting_data_3.html
Yeah, it *definitely* doesn't work in complex cases. Currently I'm using a bunch of negative lookaheads.
Wanted to follow up here on the nginx thing. We've just pushed 0.4.0-RC1 which removes nginx as a dependency on the Mac side and containerizes it. Check it out!
Haha that's a funny video. Thanks for the time you spent in watching some videos. It means a lot to me. Although for me its technically an algorithmical fail to have detected that video... Difficult to determine that automatically though.. News article to video title connection is all the algo can see. :) behold the limits of AI. If I could transcript all YouTube videos and do a match on them I'm sure I'd get better results.. Its still very much a WIP though.. But not sure if there's any worth in pursuing it further / improving it further. www.twitter.com/wingston also posts a lot more videos if you want to keep in touch with the daily discoveries of the algorithm.
Hmm, I really should have linked to [the blog post](https://medium.com/@nathanstocks/green-2-0-0-released-6e89eedd16c1). /facepalm
"segment fault core dump"
Y-combinator is quite mind-blowing: * http://rosettacode.org/wiki/Y_combinator * http://rosettacode.org/wiki/Y_combinator#Python 
Full implementation of Magic the Gathering rules engine (as of 2012 - could handle most rules except particular static effect dependency edge cases) plus GUI - https://github.com/Incantus/incantus. Here's some videos - http://www.slightlymagic.net/forum/viewtopic.php?f=23&amp;t=4282
A [simulation of cancer growth and metastasis](https://github.com/zafarali/hgen-396) for academic credit. Right now working on a tool to simulate infinite cellular genomes on that framework!
A game where you have to shoot the enemy before it gets you. For the bot's AI, I implemented the MinMax algorithm.
I built a thing for work that will navigate through a CSV full of product information, download product images, analyze the colors based on a configuration file and issue an HTML report on the products and their color analysis.
You said "Don't use `is`" because it was implementation dependant. If by that you meant what you said in your next reply, I daresay you should write more carefully. :)
That's awesome! So you basically built TCP over SMS?
Can anyone explain to me what is wrong with changing this def common_function_called_in_gazillion_places( variables, action ): # Old code into this def common_function_called_in_gazillion_places( variables, action, request=None ): if request is not None: # Handle request # Old code ? You don't break any existing code, and where it is needed you can supply the request parameter.
Because you don't need one : &gt;&gt;&gt; l = range(10) &gt;&gt;&gt; l[1::2], l[::2] = l[::2], l[1::2] &gt;&gt;&gt; l [1, 0, 3, 2, 5, 4, 7, 6, 9, 8] &gt;&gt;&gt; l[0], l[1] = l[1], l[0] &gt;&gt;&gt; l [0, 1, 3, 2, 5, 4, 7, 6, 9, 8] Plus, it's not a very common need. I can't recall the last I had to do this in a real life code. 
\^ I wanna see that bet!
You are better off using docker instead of vagrant. Vagrant for its virtualization uses an actual VM, versus docker uses linux kernel namespaces. That means a docker process will run at the same speed as a native one. When you start the docker container programically like with python for example, you can specify the hosts and dns. If need be you can attach a bash shell to the machine and configure that way, myself I use rpyc python to go inside the container. For things like digitalocean droplets, I make it so the droplet can be only accessed by ssh. So if droplet A has mongo running in a docker container it just listens on local host. Droplet B is running an ipython notebook in a docker container. I want to connect to my mongo in A, I open an ssh tunnel between the two. That way it is really secure.
The hack is clever, but probably not worth it in the long run. As others have said, this really makes it harder to understand the codebase. I generally try to respect the [Law of Demeter](https://en.wikipedia.org/wiki/Law_of_Demeter), and the "gazillions" of calls to the same method may even be a great indication you should DRY out the codebase a bit. With that done, the proper call changes are likely easier.
Presumably, the code needs a new feature in common\_function\_... that should be run every time it's called and needs access to the request.
It would be trivial to add, but then it would be trivial to add hundreds of similar one liners to Python. Thanks but no thanks, I like "Python In A Nutshell" fitting in my pocket, not on board a container ship like "Java in A Nutshell" :)
I have been told to refrain from using BeautifulSoup. There are several opinions apart from a website's own API. I just don't know which one is easier and which one can do it all.
How is selenium better?
Beautiful soup and selenium together are shit. So you will pull the html source from selenium and then feed it into beautiful soup ? Then you will search the dom with beautiful soup ? That is slow. The reason why it is slow is because the python has to go over a bridge into the JS and then when it returns the reverse happens. I wrote a patch for python gtk webkit that does that, and it talked to the JS engine directly using the C++ API. I think the patch is still kicking around on the internet someplace. Use javascript to searchand parse the dom. That is what it is designed to do. Get the results and send them back to python.
Now that you have mentioned, I tried scraping images off r/nsfw via beautifulsoup alone. Nothing happened. No links generated. Apparently you need to very your age after logging in via some cookie settings and I couldn't solve it properly. Still stuck with that problem. I was told about json API, but I don't know how to go page after page, because its just going to show the first page's links. Selective text extraction didn't work either.
Then they usually hire me to do the job ðŸ˜ƒ
There seems to be a minor bug in Firefox: in the 'New' menu, the categories on the left don't show up, so I couldn't create a new notebook that way. I can work around it by going to datasets, samples, and clicking 'open in notebook' with a dataset selected.
If you don't want arrows, why are you using axes.annotate instead of axes.text?
It's a strange and wonderful language we work with.
Do I need to make sure the file is in a specific location? 
I'd guess because python tries to discourage using indexes at all. I assume you are trying to implement a quicksort or something ... but you are supposed to use the built-in `sort()` method, or something that's compiled and fast. Besides, it's stupidly easy to implement, either your way or a quick function: &gt;&gt;&gt; def swap(self, i, j): ... self[i], self[j] = self[j], self[i] ... &gt;&gt;&gt; r = range(4) &gt;&gt;&gt; swap(r,1,2) &gt;&gt;&gt; r [0, 2, 1, 3] All that said, I wish they would add it.
What's the difference between canopy and conda? 
Never looked into Docker.. I'm doing development, and it looks more like a way to package things up.. Where as I'm more into developing on VM's.. Plus I'm on OSX, not linux, so I think I would need a VM anyways to run Docker. Not to mention, we need to use Salt to configure things, as it fits into our infrastructure that way (I work for a CDN)
Why does it take so long?
can't find a link anywhere on the page you've created.
That's weird, your photo doesn't look like David Beazley, butyour code does...
He's a real team player.
It's more for testing and it's a very heavy framework (do NOT commit to source - seen people do that in projects) You're better off using a combination of BeautifulSoup4, requests and html5lib. There's also the option to use robobrowser for easier to manage forms and cookies when login is required.
SAS is gonna be around for a long time, for better or for worse. 
Right tool for the job. On linux docker uses namespaces, so it is running as a native process. On OSX it runs in a VM, and it doesn't work properly as of now. Half of the docker commands do not work. On linux it rocks, basically you make a docker file which generates an image. But then you can make additional docker files which will build off the old image. I work independently, my clients don't really care how it works as long as it works ðŸ˜ƒ
serious question: how high are you right now?
:(
The module 
[wha?](https://www.youtube.com/watch?v=RlbARlVyRAc)
It's called "Tuple parameter unpacking", apparently. It's a bad enough idea that it's eliminated in python3. http://legacy.python.org/dev/peps/pep-3113/
Nice! Actually worth finally getting a microsoft account for. To the rest of the community, am I right that this is the first place that does a freely hosted notebook, that does not require any public user to get an account for? You need an account to create one, but I was able to log out and still access my existing one, so I could link to it and readers could immediately run the code, without either copying the file and starting a local server or creating an account somewhere like Wakiri etc. 
That just made me throw up in my mouth a little bit. Maybe use a default argument, have it yell a lot when it isn't set, *then* "do the hack." That way, you can phase it out without failing where you haven't refactored yet. 
Still don't know what you're talking about. Try not to use jargon like "stackframe".
You beat me to it by 44 minutes :)
I still can't imagine it would take nearly an hour. I learned how to use regexes in about five minutes the first time I needed them. 
well, not all of msft, but our small team which built the service. it was actually straight forward and fit the bill nicely (linux+docker). windows container story isnt that great right now.
If they go the amazon route and offer computing services, this changes many things. IBM used to make computing machines, but now they have sold all of that off and they just offer services. For datastore amazon rocks but thier EC2 sucks. 
OP Is a hero. Thank you so much for this!
Too little, too late. 
what exactly it is? any ELi15? Thanks (:
Yup. With instructions on what feature to remove in case the frame searching stops working for some reason.
Can I just say that I *love* the direction your company has taken recently?
By mentioning Half-Life 3 you have delayed it by 1 Month. Half-Life 3 is now estimated for release in May 2647 ___ ^I ^am ^a ^bot, ^this ^action ^was ^performed ^automatically. ^If ^you ^have ^feedback ^please ^message ^/u/APIUM- ^or ^for ^more ^info ^go ^to ^/r/WhenIsHL3
:/
Thanks I will give it a try, it is using the latest version of the webkit engine but it also appears a new version of phantomjs has cone out also, the uses the latest version of the webkit engine.
I've got more than I can handle, thanks ;)
[C:/Users/duckythescientist/python/reddit_projects/kloro2006](https://www.youtube.com/watch?v=dQw4w9WgXcQ) 
youre absolutely right. the network access limitation to azure is temporary. we have to figure out some security stuff &amp; then will open it up. note that you can dump your stuff to blob storage on azure &amp; access it there. Azure ML also has a whole bunch of datasets ready to use.
Well you could take two seconds to google Jupyter or IPython since they're both incredibly common tools. Or you could just act like a dick on the internet, either or.
tbh, I did google and it was bit confusing. now op explained and I tried again and I get it. Also iPython itself is bit...hard to understand at first. 
and that's fine, but there is no need to post something like... &gt; wtf is a 'notebook service'? I shouldn't have to click links just to figure out what that is. I guess some people forget that just because we're on the internet doesn't mean you should act like a tool.
Since we're programmers, the usage of jargon is going to be unavoidable. We could explain everything out each time, but for the majority of people that's a waste of time. I'll make an attempt though. In calls in Python, functions that belong to a class must receive a "self" variable as the first variable and it's the instance object of the class itself. Attributes are variables that are part of an object (and thus part of that "self" variable). It's like you have an "Animal" class and a "number_of_legs" attribute. The concept of a "stackframe" or "call stack" is fairly common and appears in most (all?) programming languages. It's just the list of nested function calls we made to get to a certain location. So as /u/Ph3rny mentions, the hack function looks through all of the functions called to get to this point in the hope that one of them is a class object (thus having 'self') and then looks to see if it has a 'request' attribute. And then it returns it as if the hack function itself produced the attribute.
dynamic monkey stack snatch.
Whopper &amp; Big Mac
6 hours
 &gt;&gt;&gt; (2,2) in ((2,2),) True 
Just to shorten your code: for x in ['720p', '480p', '-', '_', 'hdtv', ...]: newname = newname.replace(x, '')
Not in my PYTHONPATH, but in my PYTHONSTARTUP file : # coding: utf-8 from __future__ import unicode_literals, print_function, absolute_import # import all the stuff I use all the time import sys import os import re import json import csv import random import hashlib import tempfile import shelve import subprocess import atexit from glob import glob from uuid import uuid4 from pprint import pprint from codecs import open from itertools import * from collections import * from datetime import datetime, timedelta # best lib to handle date times try: import arrow except ImportError: pass # best lib to handle HTTP try: import requests except ImportError: pass # best lib to handle path try: from path import path except ImportError: pass # missing tools from python # dict merging, recursive getmember, etc try: from minibelt import * except ImportError: pass # activate autocomplete on python 2.7 shell try: import rlcompleter import readline readline.parse_and_bind("tab: complete") except ImportError: pass # if in virtualenv env = os.environ.get('VIRTUAL_ENV') if env: # display the env name in the ipython shell promp env_name = os.path.basename(env) sys.ps1 = '(%s) %s ' % (env_name, getattr(sys, 'ps1', '&gt;&gt;&gt;')) # display all modules installed in the virtualenv at the shell # start print("\nVirtualenv '{}' contains:\n".format(env_name)) cmd = subprocess.check_output([env + "/bin/pip", "freeze"], stderr=subprocess.STDOUT) try: cmd = cmd.decode('utf8') except: pass cmd = cmd.strip().split("\n") p = re.compile(r'(^.*\:\s)|((#|@).*$)|(==.*$)') print("'" + "', '".join(sorted(set(os.path.basename(p.sub('', f)) for f in cmd))) + "'\n") # print fast p = print pp = pprint # make sure you always have a temp dir available TEMP_DIR = os.path.join(tempfile.gettempdir(), 'pythontemp') try: os.makedirs(TEMP_DIR) TEMP_DIR = path(TEMP_DIR) # make it a Path object except Exception as e: pass # persistent key/value store class Store(object): def __init__(self, filename): object.__setattr__(self, 'DICT', shelve.DbfilenameShelf(filename)) atexit.register(self._clean) def __getattribute__(self, name): if name not in ("DICT", '_clean'): try: return self.DICT[name] except: return None return object.__getattribute__(self, name) def __setattr__(self, name, value): if name in ("DICT", '_clean'): raise ValueError("'%s' is a reserved name for this store" % name) self.DICT[name] = value def _clean(self): self.DICT.sync() self.DICT.close() # Now you can do store.foo = 'bar' and get back store.foo in the next # session. python_version = "py%s" % sys.version_info.major try: store = Store(os.path.join(TEMP_DIR, 'store.%s.db') % python_version) except: print('\n/!\ A session using this store already exists.') 
\_\_builtin\_\_
Because in the end I did want the arrows, but I wanted to hide them temporarily.
I really love the OS direction your company is taking. :) I definitely love Microsoft now.
`map()` returns an iterator rather than a list, and it's exhausted after being iterated over more than once. You can fix it by using `list(map(...))` or better, a list comprehension: titles = [title.lower() for title in lines[0].split()] By the way, you don't need to write a lambda if you're going to use `map()`: titles = list(map(str.lower, lines[0].split())) Also, you could simplify this whole thing considerably: lines = worker.docker_cmd('ps aux') titles = list(map(str.lower, lines[0].split())) processes = [dict(zip(titles, line.split())) for line in lines[1:]] 
Oh, that one's easy, you didn't use import psutil â˜º
If you are familiar with PHP, why not use PHP? You can also solve this via python but why introduce another interpreter if the existing application is build in PHP?
Normally that would work, but I am running the ps in a docker container using docker python bindings.
Nice ðŸ˜ƒ I think I will like this python 3, the main reason I decided to switch is because you can reraise exceptions and not lose the stack trace. 
i guess there's no way to install modules?
You're importing 'random' twice
Did you ``pip install praw``?
In the meantime, I read the blog post at: http://blogs.technet.com/b/machinelearning/archive/2015/07/24/introducing-jupyter-notebooks-in-azure-ml-studio.aspx ...and was excited to see this example from scikit-learn featured there: http://scikit-learn.org/stable/auto_examples/covariance/plot_outlier_detection.html ...but it turns out that it doesn't actually on the Python 3 kernel there, because sklearn doesn't seem to be available for it. So use Python 2 instead!
Nice! It only took me a minute, but then I already knew that there was a problem with the code and it was due to a difference between 2 and 3. It probably would have taken me a bit longer without that information.
Yup. No problem. Just be aware this isn't secure. This is basically what I think you want: plaintext = 'The quick brown fox jumped over the lazy dog' ciphertext = [] print(''.join(['I am plaintext: ', plaintext])) for item in plaintext: cipher_number = ord(item) + 1 cipher_letter = chr(cipher_number) ciphertext.append(cipher_letter) ciphertext = ''.join(ciphertext) print(''.join(['I am ciphertext: ', ciphertext])) reconstituted_text = [] for item in ciphertext: plain_number = ord(item) - 1 plain_letter = chr(plain_number) reconstituted_text.append(plain_letter) reconstituted_text = ''.join(reconstituted_text) print(''.join(['I am plaintext again: ', reconstituted_text])) Prints: I am plaintext: The quick brown fox jumped over the lazy dog I am ciphertext: Uif!rvjdl!cspxo!gpy!kvnqfe!pwfs!uif!mb{z!eph I am plaintext again: The quick brown fox jumped over the lazy dog
My pleasure. Again for emphasis, this is not a cryptographically secure solution. People smarter than I could ever hope to be have dedicated their lives to putting together public key cryptography solutions like PGP. The Python standard library may not be the best tool for the job here.
Without a previously agreed upon method of transmission and decoding of this method, it's not a very good communication option.
Can't use miniconda to manage the many dependencies. First win7 install of 64-bit version puts conflicting 32-bit dll(s), so install the 32-bit version to run at all. Then could not create a separate environment. Using the root environment defeats the purpose of conda. Even trying to install just one package failed, e.g., conda create --name scikit numpy. At this point, I decided to stop wasting my time.
Best practice today is to use [cffi](http://cffi.readthedocs.org/en/latest/) instead of ctypes. Its not part of the standard library but it has quickly become one of the most popular 3rd party libraries. It offers many advantages such as * Uses the same syntax of C so there is less to learn. * Doesn't have a weird number of strange behaviors to learn and remember as ctypes has. * Has lower overhead, so it runs faster. Especially when using PyPy, as it able to eliminate most of the extra overhead associated with making external calls. * Better alternative to using the Python C API as you don't have to worry about compatibility issues between Python 2 &amp; 3 C APIs. Nor do you have to worry about C API calls being slow when using PyPy.
Or, taking advantage of some nice python3 syntax: lines = worker.docker_cmd('ps aux') titles, *process_data = (line.split() for line in lines) processes = [dict(zip(titles, data)) for data in process_data] Doing all the line splitting in one place avoids some code duplication, and avoids any fussing with indices.
For everybody else who has never used a thread local in Python - this is how it's done, according to the docs: import threading local_storage = threading.local() local_storge.some_var = 42
He is asking for feedback but I don't think he is interested in getting that feedback from people who doesn't even know what iPython notebooks are... If you want to know what he is talking about Google it, that's how Internet works. 
I wouldn't think about subclassing list, I'd just write a function could swapped any elements in any container you care to provide. However I doubt that I'd actually bother as I don't recall the need to do so. And yes, that little one liner you've shown is neat :)
Thanks genius, I know how to Google, but my point still stands. He'd get more customers by including a few extra lines about what a 'notebook service' is. Even the OP seems to agree, given he did elaborate further: &gt; [â€“]smortaz[S] 29 points 10 hours ago &gt; sorry my bad - i wrongly assume that folks in /r/python knew what tmpnb.org, wakari.io, etc (which are all hosted IPython/Jupyter notebook services were). apologies &gt; ELI5: Python has a prompt. you type in code, it's run &amp; the results are printed out. IPython is the same thing but on steroids. you type in code, it spits out results, or returns a visualization (via matlab for example). it also supports 'markdown' cell for formatted documentation. it's kind of like "Word docs for python code" -- code + text + images + video, etc. all in an "executable notebook". &gt; Jupyter is the new version of IPython - while IPython was primarily for Python, &gt; Jupyter has architectural level support for multiple languages. &gt; Jupyter notebooks are normally run locally on your machine - ie, you have to install a bunch of stuff (or a distro that has all that stuff) to get a working system. &gt; a Jupyter notebook /service/ is basically Jupyter running in the cloud - just go there, get a notebook, nothing to install and code away. ie much like google docs, but for writing Python, etc. &gt; hope that helps! Way to go, you 1/2 pound dingleberry.
I don't think that `l.swap(i, j)` is more explicit than actually explicitly swapping the items. 
I don't think I knew you could do generator comprehensions like that. On second thought, I might be terrified. 
You wouldn't, but in parts of Python's documentation they mention that adding a comma implies a tuple. Making the rule so generic makes it easy on Python's parser. And it's not necessarily just at the end of a statement. It's within any grouped expression which is why "(5,)" is the same as "5," but not the same as "(5)". Parenthesis are syntactically groups which are reduced to Python objects while commas are syntactically tuples.
Ugh, why? That is a disgusting use of python.
The easiest way to do this right now would be to put your certificate in blob storage and download it using the Azure SDK. Another option would be to just have a base64 encoded string and include it in the notebook. We want to add the ability to upload files, but there's a bit of a tension between whether they're stored locally or in your AzureML account that we need to work out.
Not an easy way. You can put a wheel in Azure blob storage and then download it, store it somewhere in your user directory, and then add that to sys.path. Over time we'll relax the network restrictions and set things up so that you can pip install packages.
I'm sure there are better ways of sending a secret message than trying to obfuscate it in code. 
Don't know if you already know about this: [Moving from Python 2 to Python 3](http://ptgmedia.pearsoncmg.com/imprint_downloads/informit/promotions/python/python2python3.pdf)
Why do you say that? I honestly don't know one way or the other since I'm new to this, so I'm curious why you'd say that.
You can also switch around split and lower to avoid the need for map, I think: titles = lines[0].lower().split()
Should be only one way to do it. That way.
It also makes the code significantly easier to read.
Actually, it downloads it when [`setup.py`](https://github.com/spoqa/iso4217/blob/master/setup.py#L49) is imported. Is this a terrible idea? My gut feeling says that it is...
&gt; ftp.sunet.se now there's a name that takes me back ages. it was always the fastest mirror for everything.
I'm curious when the videos will be online. I wish I'd known about this, but most of,the talks I wanted to see were yesterday. 
Such a function also hides what index argument gives an IndexError if i, j or both are out of bounds
PYTHONSTARTUP is only used for interactive sessions so this isn't for scripts being shared with anyone. 
I work for a studio developing a Industry administration cloud based web application. We primarily use Django framework and Agile/Issues development. Doing fixes and implementing features to the system. One of the most interesting things (at least for me) is that you can listen to music while you program. And the learning for new packages and tools. 
Well, I don't want to put the certificate in storage, and the SDK does not allow me to read it from a base64 encoded string since the certificate parameter is a filename, so I'm stuck...
You get run these periodic tasks asynchronously as well if you implement Celery with all of this. In some cases this might be better than a cron entry (i.e. a task takes longer than 5 min). [Celery docs](http://celery.readthedocs.org/en/latest/)
You just need to pass the row idx into the `row_values` function. import xlrd file_location = "C:\Users\chavezpr\Documents\Lottery_history.xlsx" workbook = xlrd.open_workbook(file_location) sheet = workbook.sheet_by_index(0) data = [] for row in range(sheet.nrows): data.append(sheet.row_values(row)) if row == 1051: break print row print data This line, `for row in range(sheet.nrows):` -- this counts up to the number of rows in the sheet, but it just gives you an index (`row` is an integer).
You can do "!pip install requests" to shell out. But that won't work on our hosted service as we don't currently allow you to access most network services.
&gt; `map()` returns an iterator rather than a list Indeed. This is perhaps the change I'm least happy about with the move to Python 3, if you broaden it to include the various related changes to `filter`, `zip` and friends and to `reduce` doing something completely different again. I do understand the efficiency motivation. However, the fact is that Python 3 is now using these terms differently not only to Python 2 but to approximately *the entire rest of the programming world*. And as the original challenge here demonstrates, it's now an accident waiting to happen, even though it was entirely avoidable. :-(
The above code is part of a function called "docker_ps" which is being called by another function which looks for a certain process in a docker container, if it exists it kills it, and then starts if again. This function in turn is being called by another. So anyway it took a while to figure out the problem is the process is not restarting. Then I ofcourse looked for the bug in all the other functions first instead of the ps one. Possibly is is a bad design choice on my behalf, I should have saved the pid of the process when I first started it. 
Haha. Links help. Thanks for saying that. 
I had to retread this a couple of times not believing MS would openly use Linux for anything. 
Just a heads up, this post likely won't be well received. Cool project just the wrong audience. 
Hell some people don't know what Python 3 is! 
What? Why? I am new to reddit. Care to Explain, please?
Tried to follow, only got this far before I found some jargon: &gt;In calls in Python, *functions*
Because Reddit hates 9gag. 
Not really a fan of the site, but cool project nonetheless. When sharing code you might wan't to have a look at the [Style Guide](https://www.python.org/dev/peps/pep-0008/).
How are you running the script? If you're running it on your local computer, it's still downloading the same amount of data that would be downloaded when viewing in a browser. 
Yes, I am running it locally. And yes, the data downloaded is the same. The only advantage is that the data is downloaded in a burst. The images are downloaded by an external downloader which takes time, but after that, when everything is downloaded you can view it locally without waiting for inter-post delay.
:). believe it. i think some 30% of Azure VMs are already running linux!
Eh, this is a programming subreddit, that's not /r/programming, 9gag is mostly hated on /r/funny etc. since 9gag content is taken from there. 
thx. i'm sure at some point someone will make us start charging (maybe). so meanwhile, enjoy the free cpu cycles! re maybe - the trend so far has been to provide tooling for free &amp; charge for operationalization/consuming. for example there is no charge for Azure ML Studio which can include python and R code... 
https://gist.github.com/Socialery/c88bd57eec47ee7dc4b9 bit excess on the `*` imports, but its nice in practice with those specific modules listadder = lambda a,b:list(starmap(add,zip(a,b)))
I meant "except:" without the type of exception afterwards. It's a catch-all which might silence errors you didn't intend to, and so it makes the code much harder to debug.
This week's [15.3 release](http://twistedmatrix.com/Releases/pre/15.3.0pre1/NEWS.txt) brought a bunch more python 3 support, and the Python Software Foundation [funded porting the test runner](https://www.python.org/psf/records/board/minutes/2015-06-23/#trial-porting-to-python-3). These days there is progress being made here every week.
&gt; since you seem poorly informed Far from it.
Did you get it to work on your end?
I don't think having multiple constructors in a class is allowed in Python. If you want to allow for the constructor to be called with no arguments, you can set defaults in the method header def _ init _(self, url=None): If you want to have a clean way of creating new instances of a class with different defaults, you can try using @classmethod instead. Check these out for more info: http://stackoverflow.com/questions/682504/what-is-a-clean-pythonic-way-to-have-multiple-constructors-in-python http://stackoverflow.com/questions/2164258/multiple-constructors-in-python 
Is it feasible to set s flag on the items? class Item: pickupable = False class PickUpItem(Item): pickupable = True Or maybe adding an `interact` method? 
Yeah, setting a flag definitely works for this example, but my concern in the general case is that adding flags and properties to the superclass only goes so far in replacing the parent object -&gt; child object design pattern.
sorry for the late reply - we're busy running @Pydata Seattle this wknd... selling point as in what sets this feature apart? or what are we selling ultimately? former: there isnt much differentiation yet. one could argue that persistent notebooks + integration with Azure ML studio are a couple. being in the same data center also enables quick access to gigs of data w/o having to xfer bits too far. much more integration is to come which might become selling points - eg notebook storage &amp; sharing via OneDrive, a REPL in excel (?), etc. 
`map` is historically pure. Plus, `2to3` fixes this, do people seriously not use it?
Give pysdl2 a look. 
I would at *least* put an `isinstance` check with the `hasattr` check, and use `getattr` instead actually, or even `except AttributeError`.
You might want to use [feedparser](https://pypi.python.org/pypi/feedparser) instead of doing it by hand using etree. This will give you atom support for free in addition of smaller and stronger code. On a more aesthetic note, you'll probably want to read and follow pep8 for the coding conventions, this is the standard way of doing things in the python community. The [pep8 tool](https://pypi.python.org/pypi/pep8/1.6.2) and [autopep8](https://github.com/hhatto/autopep8) might help. Just remember that those are guidelines and not absolute rules. You have a duplicated \_\_init\_\_ in this class, the first one will be ignored so you can remove it: https://github.com/rad08d/PythonRSSReader/blob/master/RssClass.py#L36 You might want to put all you *.py files in a "src/" folder. You'll probably want to see if there is a [pyflakes](https://pypi.python.org/pypi/pyflakes) plugin for your editor, this will catch a lot of common mistake and unused code. For example, here "threading" is imported but unused https://github.com/rad08d/PythonRSSReader/blob/master/rssStart.py#L4 Process here https://github.com/rad08d/PythonRSSReader/blob/master/guiclass.py#L4 To avoid bugs, for path construction use [os.path.join](https://docs.python.org/2/library/os.path.html#os.path.join) for cases like here: https://github.com/rad08d/PythonRSSReader/blob/master/guiclass.py#L20 Otherwise congratz, it's great you've managed to reach this level by yourself, you can be proud of yourself :)
&gt; Plus, `2to3` fixes this, do people seriously not use it? I'm sure they do, but presumably only for projects that were first written in Python 2. It's not particularly helpful for overcoming the unconventional behaviour for anyone writing new projects or those coming straight to Python 3 from other programming languages.
I suggest downloading the simplegui zip file, unzip it, and run it through 2to3. Likely to be rather easier than manual edits or looking at other choices.
i got in the habit of using flake8 https://github.com/nvie/vim-flake8 for just such purposes. 
I use vim as my editor. IDEs are drastically overrated; see "[Unix as IDE](http://blog.sanctum.geek.nz/series/unix-as-ide/)".
No, table.xml is included in sdist (\*.tar.gz) and bdist_wheel (\*.whl). Download package files from PyPI, and unpack them if you want to check.
Of course it's in the standard library provisionally, and even though others would likely pick it up if it was removed this is certainly reason to be hesitant to adopt it for production software.
What version of Python does the course use? I am already suspicious of that course for recommending a heavyweight IDE to new students but you may first want to install the same version of Python as the course through [Homebrew](http://brew.sh/). Once you have Python installed, just launch the terminal and type idle and it should launch IDLE, the editor that comes with Python. It's more than sufficient for learning the language. Alternatively, just about any text editor will do. I personally use Emacs but that's not something I can recommend to a new student whose focus should be on learning Python. Use something like [Atom](https://atom.io/) instead.
IDEs are overrated, but suggesting any editor with a learning curve to an absolute beginner isn't a good idea. They could use less distractions as is.
Python REPL in excel???? Yes please! Don't make us suffer through R pls :)
I'm similarly suspicious of this Course. Recommendation: Download Python (either 2.7 or 3 - depending on what your course uses). Download &amp; use [Sublime Text](http://www.sublimetext.com/) ... It's probably the easiest text editor you could use &amp; has great syntax highlighting. Recommendation: Go to [Invent With Python](http://inventwithpython.com/ "Invent With Python") &amp; learn from the free books there. They're very beginner friendly, and games are a really fun &amp; concrete way to learn programming. Also consider [Learn Python The Hard Way](http://learnpythonthehardway.org/ "Learn Python The Hard Way") and [Tutorials Point - Python](http://www.tutorialspoint.com/python/ "Tutorials Point - Python") Tips: -To run things in terminal, find your directory/file &amp; type python filename -Python 2.7 may be a better choice - Migration to 3 has been a bit slow Good Luck :)
Thx for the response. That's good to know. I can understand why. In future, hoping msft will come up with private pip repo so at least common pip installs are supported. Access to these libraries improves developer productivity.
I wrote up a [post](https://www.reddit.com/r/learnprogramming/comments/3alvlj/xpost_from_rlearnpython_my_thoughts_on_learning/) of my thoughts and recommendations after a year of learning python not too long ago. Everything from various tutorials, text editors, etc. 
Loading unnecessary libraries is discouraged. It is best to be explicit and call only what is required when you know you need it. If you have a real aversion to loading all of your requirements, it would be best to make a metapackage that wrapped everything you used (ie import mydefaultsettings) at the start of each file. That being said, if it makes you more productive, do what works. Practicality beats purity.
Awesome. Thanks so much! :)
Nice work, dude. Your code is well documented and super clean! A great contribution to the Django community for those who need it :)
Forgive my ignorance but I ran the script and I can' t seem to find the pix. Any help?
thx for the reply !
Would you mind expanding on how you're getting to errors on the server? I decided to look up BaseException in the docs, and I saw that the only built-in exceptions that inherit directly from it are SystemExit, KeyboardInterrupt, GeneratorExit, and Exception. 
That looks very good. I was looking at their [milestone "Python-3.x"](http://twistedmatrix.com/trac/milestone/Python-3.x): &gt; Total number of tickets: 195 - closed: 142 - active: 53 This would be 72% ready. 
I found it harder to learn the IDE than to learn the language. I just use a text editor and the command line.
Yes, I'm starting to see the reasoning / structure here. It makes sense and allows for objects to share interfaces without sharing specifics of implementation. Edit: And I'm starting to see the logic here too. After all, whether an object has a method or not is more obvious than whether an object is of a certain class anyway. If you want to know if an object can be picked up, ask if it can be picked up.
Or skip the asking and just try to pick it up, see if it works.
To say something that hasn't been said yet, how about concurrent.futures?
All the images links are saved in links.txt file. All you have to do is download those images using external downloader. The instructions on Linux is given on the github readme. On Windows however, use a GUI downloader that can import downloads from txt file. IDM or Orbit downloader should be able to do that.
Yup, this no type-checking bullshit is terrible, especially when you consider how different strings and lists are, but how similar their APIs are. Suppose you had a tree of lists with strings at their leaves - you basically have to be "unpythonic" to get shit done.
You'll need to run apt update apt upgrade apt install python
Thanks! Though apt upgrade should not be necessary for installing python (it's for upgrading installed packages, so while really good to run regularly, it should not be required for the initial python installation).
What do you mean "provisionally"?
True, but this makes it a bit easier to pick-up, imho. Furthermore, there are already quite a few libs written on top of asyncio, e.g., for https, websockets, RPC, â€¦
You think you are a smart-ass don' you?
Uses `sudo pip`, and even worse for things that have packages.
Sorry, i dont get what you are looking for. What to you want to write?
Very nice work. Thank you! Does the TTS stuff need anything else to be installed? On a Moto G 2014 with Lollipop I get no spoken output, just a ping sound. `termux-tts-speak --help` refers to a command `device-tts-engines` which is not found. Any pointers gratefully received!
No. Just import downloads via txt file in Orbit downloader.
You can say me how to use it step with step ? 
Some sort of cronjobs like scheduler would be really nice. Can I install third party modules? setuptools? (requests would be really nice. python people are spoiled to the core :P) Many thanks for making something like this. PS: I am a member of a bunch of python communities on FB. I shall promote your app as much as I can. Every now and then someone asks for a way to run python properly on android. By far this is the most near native implementation. 
+1 for feedparser. As someone who lived through the halcyon days of RSS, the Atom split etc, I can honestly say that nobody really has any idea how f*ed up RSS feeds can be. Feedparser has been battle-tested for more than a decade, and understands syndication feeds better than you or I will ever do. +1 also for using os.path.join.
If Django wants to be DRY it doesn't make sense to repeat implementation detail on every single line. People make mistakes. Also you can still use regular expressions with my code, the URLPattern is only part of the module, I would say that much more interesting functionality is the flask like registration of views... I consider the current URL system awkward because you have to edit functionality at multiple files. BTW who uses regex for routing anyway? * Flask? No. * Bottle? No. * Werkzeug? No. See http://werkzeug.pocoo.org/docs/0.10/routing/ * Pyramid? No. http://docs.pylonsproject.org/projects/pyramid//en/latest/narr/urldispatch.html 
Pygame is not so much an engine as a framework.
No, as you haven't told us what the error was. Please be precise when asking questions, it helps us to help you :)
[Panda3D](http://www.panda3d.org/) is the only serious one I'm aware of. For simple tasks in 2D [PySDL2](http://pysdl2.readthedocs.org/en/latest/) modules brought the best results. Due to underlaying SDL2 supporting hw acceleration got double fps by straight rewrote of my Pygame based sources, which works on SDL1. There is also a cffi version which also works with PyPy for more impressive results. Both are only wrappers so you may miss all the bells &amp; whistles from full blown frameworks. 
&gt; Some sort of cronjobs like scheduler would be really nice. The busybox crontab and crond implementation is available as part of the base system! Prepare it by creating a folder (the system will set it up in the next busybox package update, but for now this is needed): mkdir -p $PREFIX/var/spool/cron/crontabs/ Now edit the crontab with 'crontab -e', and then start the `crond` daemon. If there is a problem with the system going to sleep or killing the crond background process, and you really want the cronjobs to run on time, you may take a wake lock by using the "WAKE" action available when expanding the Termux notification (http://termux.com/images/termux-notification-expanded.png). &gt; Can I install third party modules? setuptools? (requests would be really nice. python people are spoiled to the core :P) Pip works for installing packages - I have verified installing `httpie` as well as `gmpy2`, so even packages requiring native code should work as long as the required -dev packages are installed. Let me know if there is anything else that does not work or is needed!
Oh fuck yes it's what I always wanted. Any plans on putting it on f-droid? They accept open source applications, and it would be a lot easier to install.
Does it work on Intel Atom processors? I have a lenovo s8 tablet.
Where are you getting your trade data?
It's not as much tested on x86 as on arm - but most things should! Note however that Android 5.0+ is required as Android version, due to the extensive libc changes made in that version.
Oh, I'm running cyanogenmod and managed to get SSH enabled on my device, would this still work (over SSH, not just in the app itself).
Would it be possible to provide an apk? My phone does not have the play store. 
&gt; Do you need a dump of the error message? If just install a global NPM package (I used express-generator and yeoman) and try to scaffold something then it won't work. Great, file an issue at https://github.com/termux/termux-packages/issues, so you will be able to track progress on it as well! &gt; So its fully functional right? Can I host webpages and stuff with Node express or Python flask? Hopefully :). It's an early version and not heavily tested, so there may be issues that will be squashed eventually - just file github issues for broken stuff!
Yes, you can ssh into your devices from a computer! Password logins are not supported, so you need a public key in $HOME/.ssh/authorized_keys. Also, since we run as non-root, we cannot bind to port 22 which ssh uses by default. So sshd has been patched to use 8022 by default, so use `ssh -p 8022 $DEVICE_IP` to connect. You may use any username. Execute `logcat -s syslog:*`on the device to see what sshd outputs to syslog if you need to diagnose problems.
I wanted to get my thoughts on here as well, in case you haven't made a decision yet, hopefully this helps. I've been coding in Python on both Windows and Mac for years now and use vagrant and puppet heavily. I strongly suggest sticking with 8GB RAM (especially on Windows), regardless of which platform you decide to go with. Windows "works" for development purposes. Granted, you will eventually run in to some oddities where you need to find some alternative configurations to get some things working. e.g. I had an issue with generating keys in Windows. Actually, this Stackoverflow discussion illustrates what I had to do to get things working: [Stack Overflow discussion - Encryption keys](http://stackoverflow.com/questions/1020320/how-to-do-pgp-in-python-generate-keys-encrypt-decrypt) Furthermore, I also faced this issue on Windows when developing in Python: [Stack Overflow discussion - msvcp90-dll](http://stackoverflow.com/questions/12127869/error-msvcp90-dll-no-such-file-or-directory-even-though-microsoft-visual-c) When I started facing issues like that, I was starting to get skeptical that an exclusive Windows environment would be good for me. The economical solution if you are still wanting to spend money on a laptop would probably to get a Windows machine and dual boot Linux. But, please still get that 8GB RAM. If you want to go down the Apple route, consider the 8GB/256 option. Also, as an added bonus, that retina screen is pretty damn nice to look at. :p I have yet to find any limitations on the Mac when I started using that as my main development environment. I am still convinced that the only argument to not go for it is cost. Which is very justifiable and you can get yourself a non-mac machine at a margin of the cost and install linux on it. Hope this helps. 
The sample I use for the tests and most charts was gathered manually for 2006 (I wanted something real) because 2006 was the last year in which all trading sessions happened in calendar weeks belonging to the year. Backtrader has support for Yahoo CSV data either by performing a real-time download or reading it from a file (which may have previously reversed to put it in the right order) **Direct Download of daily data for 2006** import datetime import backtrader.feeds as btfeed data = btfeed.YahooFinanceData( dataname='YHOO', fromdate=datetime.datetime(2006, 1, 1), todate=datetime.datetime(2006, 12, 31)) Adding other forms of CSV and/or binary should be straightforward In the distribution there is a tools directory which allows downloading the Yahoo Data and storing it to a file, which can then be used as seen in the Quickstart part of the Documentation: backtrader.readthedocs.org Best regards
Look in C:\Python27\Lib\site-packages to see if you have a pyautogui directory. If you have then you've a configuration issue with pycharm or IDLE, although your edited post appears to me as a standard Python interactive interpreter display. If you haven't this command "c:\python27\scripts\pip2.7 install pyautogui" from the command prompt worked for me.
Thanks for this. I was familiar with "Programming Computer Vision with Python" by Jan Erik Solem, and was looking for more resources. 
I don't know what a spork is :) I'll fix it anyway.
If you're not using any editor at all at the moment I'd be inclined to stick with IDLE. That way if you do run into problems you've plenty of places to ask for help, here, stackoverflow, daniweb and the main and tutor Python mailing lists amongst many others. Please come back with your OS as that could influence your choice.
It's more of an internet thing than an English thing. I think it popped up on /b/ a number of years ago.
How do I run pip in this?
wget https://bootstrap.pypa.io/get-pip.py Connecting to bootstrap.pypa.io (103.245.222.175:443) wget: error getting response: Connection reset by peer Running get-pip.py doesn't work. python -m pip says no module called pip. apt install python-dev throws 404
Not sure I agree, a beginner would really benefit from intellisense and intelligent refactoring support that pycharm has.
Nope i do not have pyaautogui directory. Let me just run your command. 
Just run e.g. 'pip install httpie' after installing python!
Search "ide" or "editor" on this sub and you'll find this question has been asked what seems like about once a week. That being said emacs is the one true editor, bow to lord emacs.
Let me just say, this thing is frigging AWESOME!! You are my hero!
I disagree with vim for beginners. Notepad++, sublime, and textwrangler all support syntax highlighting out of the box, are familiar application-style software, and offer more powerful tools at a lower barrier to entry. This coming from a daily vim-user. 
While that's true I think it would be overkill and too expensive for a beginner though. Idle or vim/sublime/atom + plugins can do a lot of that (but not everything) too and is free. 
Not available on my Nexus 7 2013. :-( 
Recommend for a beginner? Depends on how much help you want your editor/ide to give you. As a simple editor I'd say use something like Notepad++. But if you want a full featured IDE, go check out pycharm from the jetbrains guys. It's...badass. Disclaimer: I use emacs. But that's because I use emacs to do everything from my laundry to my email. Sadly, I wouldn't recommend it for a beginner. 
Community edition is Free as in beer.
By file I meant IPython notebook. It is rare for me to do anything interactive at the shell, because no matter how simple I think it is (oh, I'll just requests this file, beautifulsoup this tag, and save the uniques to a file) I inevitably regret not having the fluid editing cycle of the notebook.
See above - if you have an updated python (currently 3.4.3-3) the `pip` program should already be installed! About the `wget` problem: The wget program installed by default is a very lightweight one from busybox, which does not support https. Execute `apt install wget` to get the full GNU wget with https support, or `apt install curl` to get curl which also supports https!
A valid observation but if a beginner gets frustrated with setting stuff up and gives up then everything is taken away from the learning experience. I grew up in an era when access to programming on home computers was zero friction, you booted them up and started programming, that level of ease is a huge thing for beginners imo. 
Have you updated it to Android 5.0 or later?
I might if php-mode wasn't so bad (necessary evil for work).
Android 5.0+
I used web-mode + php-mode successfully for a bit. It was something like [this](https://truongtx.me/2014/07/22/setup-php-development-environment-in-emacs/).
That looks a lot better than the last time I tried, added to my list of things to play with :).
Thanks for the quick response! It is a little annoying that the Play Store does not give any useful information about why an app is incompatible with a device. It would have been useful if the store link had simply stated the minimum Android version required rather just marking it as "incompatible". Surely the version would have to be known to the store to know about the version conflict in the first place. Rants aside, my Android device is a fairly obscure model and doesn't look like the manufacturer is going to be offering me any further upgrades past 4.1.2. I'll look forward to trying this when I get a new phone. 
That's essentially what I'm doing now; local repo. It would just be convenient to put a couple in-progress projects up someplace where I had relatively decent security. There's no silver bullet solution. I'm just weighing the options before I get too deep in the work I'm doing. 
it requires Android 5.0 or higher from OP's reply to another question: &gt;&gt; Note however that Android 5.0+ is required as Android version, due to the extensive libc changes made in that version.
better suited for /r/learnpython 
Do NOT use Panda3D. It was entirely broken last time I tried it. You can't build it on Linux at all even if you try really hard. I recommend heavily against it.
Yeah, updated and it works fine. was able to pip install requests without any problem. 
I am sorry. thanks for the information though. 
This looks promising! I've been trying to run a QPython script from tasker, but since sl4a doesn't work with lollipop I've had no luck. Will there be any way to use this in a tasker task eventually?
Ahh. Sorry.
? It runs for literally every row of data. The point is that there are times where a blanket except statement is useful.
Awesome. One of the biggest things keeping me from Django is having to use regex for URL routing. Maybe I'll try it out with this. As an aside, you can do `__div__ = __truediv__ = add_part` to avoid explicitly defining functions for those two.
I can't help directly but please see this part of the matplotlib [FAQ](http://matplotlib.org/faq/installing_faq.html#checking-your-installation)
You are using it in a very limited context and with explicit safeguards. Like goto, sometimes using "bad" things make sense.
Thanks a lot - I've added them to a list of ideas to look at next!
I have never used tasker, will look at how to make it usable. Thanks for the feedback!
I used to be a very heavy Sublime user. I moved to Pycharm and haven't looked back. I paid for the pro version for my personal use. I use IntelliJ at work. You can get the free community edition which should meet all your current needs. I'll always have a soft spot for Sublime Text because of how customizable it is. You can make it as light or as heavy as you want with the fantastic package manager. I strongly advise against vim as a beginner. Don't get me wrong, I love vim dearly, but I think focusing on learning the language for now would be best. However, there are very neat vim plugins that will turn it in to a really awesome editor to use within a shell. Take a look at pathogen if you are interested in vim. Everything you want to solve in vim, there probably is is a pathogen plugin for it. If you want to give Sublime a shot, let me know, I can give you some more information on what plugins I used to set myself up for my Python dev. Alternatively, Pycharm is pretty out-of-the-box ready, but it being a pretty complete IDE, there is a bit of a curve to learn some of the neat stuff it has to offer to make your time with Python much nicer. :)
Well, as the other guy said, you can just catch `Exception` and get the desired effect, and that lets you ctrl-C (`KeyboardInterrupt`). Issues on the remote server you don't control won't cause any of those other exceptions. When I mean errors on the remote server, I mean it might have been taken down for maintenance, it might start giving permission denied for a minute, it might give you malformed data (jacked up RSS feed or something), and that could cause an issue in your code that you didn't expect. I have to write a lot of proof of concepts for work, and just accumulate a ton of data and I'll let things like this sit overnight. I need the data the next day, but I don't necessarily need this thing to work properly for every condition, and I don't want to sit around and debug in the middle of the night if there's an unforeseen error. More importantly, I don't usually need the code after I get the data, so there's not much point to making it production ready. Regardless, if I was to catch specific exceptions, I'd log them and continue on. When I log `traceback.format_exc()` I see those exact errors anyway and a full stacktrace. It's the same result as if I knew exactly the error. I log it and wait in exponential time increments. If it was a socket timeout, I'd log it and wait. If it passed me malformed data, I'd log it and wait, then try again, etc. These are things I can't control since I'm scraping data from a server I don't own, so a catch-all exception with traceback logging is all I need for the most part. Of course, I'm not doing this all the time, just for little PoCs that need to run for a day or two without me hand-holding it.
Are you gyus excited about coroutines with async and await syntax?
Dealing with unicode. Maybe I'm doing it wrong, but I've spent an awful amount of time trying to do simple file writing because of unicode character. I'm really glad they improved that in Python 3
same question
Just FYI, it is possible in python2 , though it's not as nice as in 3.x. It's also buried in the [simple statements](https://docs.python.org/2/reference/simple_stmts.html#the-raise-statement) section of the documentation. I first found out about it from [PEP 3109](https://www.python.org/dev/peps/pep-3109/), the PEP that got rid of the syntax. The following example re-raises a new exception type using the previous traceback in Python 2.x. It's much uglier than "raise from" in both writing it and reading the output, but at least you can find out where your exception really came from when you're stuck on 2.x: ~ python --version Python 2.7.9 ~ cat tmp/test.py import sys def inner(): raise RuntimeError('blah') def outer(): try: inner() except RuntimeError: exc_type, exc_val, exc_tb = sys.exc_info() raise ValueError, ValueError(*exc_val.args), exc_tb outer() ~ python tmp/test.py Traceback (most recent call last): File "tmp/test.py", line 13, in &lt;module&gt; outer() File "tmp/test.py", line 7, in outer inner() File "tmp/test.py", line 3, in inner raise RuntimeError('blah') ValueError: blah Note that the new type and value should match up, if not your exceptions will look even more weird in the tracebacks.
This thing is very cool but there is also QPython on the store. EDIT: no, it is SUPER cool. 
*shudders* That's not something you want to become. Turn back while you still can!
Just to make sure I've got all the details: I download stackhut, I use it in my project, and then it uploads my code to your servers and runs from there? Not locally?
Queries to match medical records between two separate vendors' files. Turns out that doing so accurately is an active area of research. This was not Python work, though.
They do but i think it's because they're a big company but everything is very complex i feel. Like most apis just require you to sign up for a secret token and then append that to your URL request but google has HUGE documentation and they have you use OATH2 which is huge beast in itself and even after you authenticate with oauth2, there so much documentation and everything is compartmentalized. So to properly use the APIs, you have to read through EVERYTHING to make sure you didn't miss anything and that everything is proper. And their API isn't fully documented or implemented in their tools either. Their python API for example didn't implement youtube recommended items when i wanted to use it last (a couple years ago i believe) and so i had to search through their whole documentation to realize that the api call existed but that i'd have to authenticate myself rather than using the tool. And depending on your type of program, sometimes the clients don't work or you need to do weird things. I will say though that once you write a project using their API and have the process down it's easier after that because their API is pretty consistent over all their platforms and services. There's almost no changes (although some of the changes are so small it's a pain). Oh, to give perspective, I've never used any of Google's official API clients. I've always used third-party ones because they're usually more fleshed-out. I feel like the official clients are just starters to get your feet wet but you might not want to use them in real life. That's my opinion though and it's been a while since i've tried to work with them. After my miserable failure with the youtube api and then their google voice/hangouts api which i realized basically doesn't exist, i gaveu p 
Explain? &gt; "The growth of Internet and general connectivity has triggered the proportionate need for responsive and scalable code. This proposal aims to answer that need by making writing explicitly asynchronous, concurrent Python code easier and more Pythonic. &gt; It is proposed to make coroutines a proper standalone concept in Python, and introduce new supporting syntax. The ultimate goal is to help establish a common, easily approachable, mental model of asynchronous programming in Python and make it as close to synchronous programming as possible." **Specifically:** &gt; The following new syntax is used to declare a native coroutine : async def read_data(db): pass **Key Properties:** &gt;async def functions are always coroutines, even if they do not contain await expressions. It is a SyntaxError to have yield or yield from expressions in an async function. Internally, two new code object flags were introduced: CO_COROUTINE is used to mark native coroutines (defined with new syntax.) CO_ITERABLE_COROUTINE is used to make generator-based coroutines compatible with native coroutines (set by types.coroutine() function). Regular generators, when called, return a generator object ; similarly, coroutines return a coroutine object. StopIteration exceptions are not propagated out of coroutines, and are replaced with a RuntimeError . For regular generators such behavior requires a future import (see PEP 479 ). When a coroutine is garbage collected, a RuntimeWarning is raised if it was never awaited on (see also Debugging Features .) See also Coroutine objects section.
Ergh, I've had to do a similar thing. Had to match a large set of customer data with an updated one which had some information added and/or removed. The worst part was that whoever filled it out did a terrible job in keeping the format consistent.
Hi! Yeah, sorry about the wall of text there. Yep, download the stackhut tool, write your code as normal Python (or ES6), with a single class representing the service entrypoints. Then run `stackhut deploy` and the service/code is run on our hosted platform at scale (kinda like a heroku but for functions if that helps!) You can try them out [live in the browser](https://stackhut.com/#/u/lanthias/pdf-tools).
Now explain what it is?
No particular reason. The tool already exists. I use aria2c on Cygwin.
Oh, I didn't get your question. I'm no expert, so I will point you here: https://msdn.microsoft.com/en-us/library/hh191443.aspx
thanks!
Yes! Also extened unpacking syntax.
Thx,
Thx.
&gt;The worst part was that whoever filled it out did a terrible job in keeping the format consistent. For you and for others, here's a list of considerations I've documented: *The File Itself* * Files may not be tabular * Format may not even be regular (this one is usually 5+ billable hours, requiring regex find-and-replace) * Files will probably be pdf (requiring shitty OCR) * Table schemes will not match ever * Data formats in tables will probably not match *The Contents* * Given names can change * Given names may be spelled differently if a guardian is filling out the info * Surnames *regularly* change, especially for women and children * Asian names are occasionally Surname Given * Names with punctuation may or may not include punctuation (T'kisha or Tkisha) * Hyphenated names may be listed Surname Surname instead of Given Surname (~20% of our population is Hispanic, which favors hyphenated surnames) * Babies in the hospital are sometimes not yet named, sometimes will be named something completely different, and almost always have a different last name (named after mother, then changed to father's name) * If you have more than a first initial for given name, you're in luck. * Dealing with inpatients, starting and ending days will regularly be listed differently (sometimes broken up across months, sometimes an additional day on front and back). The exact nature of these files will change roughly once every three months as different IT or managers take charge of the reporting systems.
I second that. Google Analytics' web interface is a pain in the ass to use so I thought I'd try and use the Python API. Turns out it's even worse
Yeah I know, but I like the definition as they are because it might happen that I will need to add custom handling to py3 or py2 implementations...
Hey, sorry for the delay in response got busy with work. Thank you for the write up. I believe my error is with switching between lists and arrays. Still working on it 
This is the reason we should be naming babies with ID codes instead of names.
just tried the demo... pretty cool! although it took a little while (20 seconds). Maybe cause im in the middle east...
"Isn't 070abc22-022f-48bc-9bf4-9bb8ba75e287 just the cutest little thing you've ever seen?" Though no doubt someone, somewhere would think it's a good idea to chop the hyphens out and save 4 bytes of memory per record, ruining the dream for everyone.
I'm not sure if it's sad so much as the state of parallelism in Python seems to be getting more complex and more confusing. Remember there was that infamous tweet from David Beasley in which he declared he was trying to "wrap his head around" the new asyncio syntax, and now here we are in the next release adding even more language and syntax changes. I'm thinking of the Zen of Python line, &gt; If the implementation is hard to explain, it's a bad idea.
This is really impressive, thanks! I've been looking for a set of python3 patches for android so that I can add python3 building to Kivy's python-for-android - there are a few older ones, but I don't have a working patchset for 3.4 or above. I saw the termux ones [here](https://github.com/termux/termux-packages/tree/master/packages/python) - could I ask where you got them (or did you resolve the issues yourself?), and may I try adding them to python-for-android, are they under an MIT-compatible license?
Well, I am and I have no problem with that. Seriously though. There are very popular packages out there to do exactly what you want. You can post, but you can't search? You should put forth some effort to your questions. It's less work, you'd get a faster response, and you'd see the 2 options out there.
write one for OSX, there aren't any good guides and it's complicated!
I do a lot of web development, so this seems quite useful.
&gt; porting programs from python 2 to python 3 for big ones. It's easy on small ones but it's a drastic jump when you get to big programs. It's suprsingly hard. I feel your pain. A long time ago I decided I was going to focus entirely on Python 3 so as not to incur any technical debt. Then I decided to use Twisted with a project, and figured "how hard could it be?" After a month of just trying to get some basics working in Python 3 with Twisted I gave up and went back to 2.
Unless the patches state a source by a comment at the top the issues were resolved by me, and I will gladly hereby use the MIT license itself it that works well for you? Note that some are a bit messy, so if you find a bug or improvement please tell! At least one has been submitted upstream to the python tracker, but seems to linger due to hesitation to apply android-specific patches in python core. Are you a kivy developer? Do you think it would be reasonable to try to support building kivy apps from inside Termux (so that Termux can be used on-device for source control and editing, and then build a kivy app)? EDIT: Reading up on kivy (http://kivy.org/docs/guide/packaging-android.html#packaging-your-application-for-the-kivy-launcher), I guess Termux could be used to edit files under `/sdcard/kivy/&lt;yourapplication&gt;`, and then use the kivy android launcher to run it (perhaps by an intent launched from a build script running under Termux)?
Just to add a bit more information: Like /u/DaOneTwo said, virtual environments are just a way to isolate dependencies from multiple python projects and your system in general. When you create a virtualenv, it will _install_ python in the directory that you specify. There you can find two important directories: * **bin** - where you can find the python executable and the script to _activate_ the virtualenv (basically replacing python in your path so that it points to the one installed in the virtualenv) * **lib** - where all the dependencies and external packages are installed. Although this is completely separate from PyCharm, it is also important to tell it what your _active_ python environment is, so that it call do all it's IDE thing correctly. This can be be done on the project settings, where you can specify the python interpreter associated with the current project (`&lt;virtualenv&gt;/bin/python`)
I once worked at the HQ of an American retailer with 3 "B"s in its name. There was an Access program used to match up freight billing data with purchase orders (in other words, we got a bill for shipping 200 spatulas to store X... the outside freight payment firm confirms the freight charge is correct, but are we sure we ever ordered 200 spatulas for store X?). The data was processed in a batch every 2 weeks. There were generally so many false rejections (2800+) that it took an employee half a day every two weeks just to go through them and fix them. When I started at the job I stated that I could fix the process and my new boss laughed at me! The guy responsible for hand-cleaning the results diplomatically told me that lots of talented people had come through here and thought the same thing but didn't realize how complicated it was. Since I wasn't officially allowed to work on it, after a few weeks there learning the systems I began to devote my lunch hour to the problem with a little bit of staying late. After about 2 weeks I had a program in hand (not coded in Python). I'd just pulled the first false rejection off the stack, asked how it happened, and followed through then went to the next one. I figured out the problem was so complex because there were not one, not two, but **18** different reasons the system was failing! My favorite involved "PRO numbers", which freight carriers assign to shipments to track them. Unlike my predecessors, I'd worked at a supply chain consulting firm so I understood the data I was analyzing very well. The PRO numbers in out system didn't look right to me. It turns out the geniuses in IT had coded the PRO Number field in the DB2 database as a number rather than as text so PROs that started with zeros had them chopped off! :-( I couldn't change our ERP, so that fix involved prefixing the right number of zeroes to shipments rejected for PROs not found and searching again. There were lots of other issues and most involved inventive workarounds. My final system eliminated about 98.5% of bill rejections! Many of what remained were legitimate, and I ended up finding a flaw in our database that caused the other mismatches. This ultimately led to my quitting, sadly, as my boss did not want to let the VP know that our reports may have been up to 1.8% off for 2.5 years (coincidentally the entire time he'd been in the job) because of the mistake I'd found. He began stonewalling me and isolating me and otherwise hampering my ability to resolve the problem and that, combined with other things (like realizing I'd been low-balled when I took the job) made it too unpleasant to work there anymore and he'd begun trying to make me want to quit. Anyway, yes, it seems like matching up data/records can be one of the superficially most simple and in reality most complex data-oriented programming tasks. 
Huzzah!
As noted below, I've never used kivy myself, but reading http://kivy.org/docs/guide/packaging-android.html#packaging-your-application-for-the-kivy-launcher, I get the impression that you can use Termux to edit `/sdcard/kivy/&lt;yourapplication&gt;` as described in the linked resource, and then launch the application using the kivy launcher.
the use case is that our team (Azure Machine Learning), has a drag/drop style IDE for building ML Experiments and this provides a 2nd canvas for slicing, dicing and visualizing data. for some cases a D&amp;D style environment is useful, for some others a REPL is more appropriate. so it's about rounding out the ML authoring &amp; analysis environment. ultimately it's about time to insight &amp; providing tools that customers want/already use.
Can somebody give me a very simple example of how coroutines might work? I'm writing a bot that does a bit of language analysis / POS chunking. I usually have to wait awhile until the chunking completes. Could I use coroutines to do other things while the chunking routine is running?
Here is the most basic example they give: &gt; The following new await expression is used to obtain a result of coroutine execution: async def read_data(db): data = await db.fetch('SELECT ...') ... &gt;await , similarly to yield from , suspends execution of read_data coroutine until db.fetch awaitable completes and returns the result data. But it seems like you could use the [async iterators](https://www.python.org/dev/peps/pep-0492/#asynchronous-iterators-and-async-for) for your problem.
I'm really looking forward to this. I tend to develop in tornado frequently and the "yield/yield from" syntax has others reading the code thinking "oh, generators inline?!" vs "coroutine" which I hope the "await" syntax will correct. Edit -- Words/grammer.
Great, thanks for checking it out! The pdf example is slow because the operation itself takes a while -- latency for normal operations is about half a second at the moment.
Terminal Vim on Linux (my preference), and Gvim on Windows (for work).
I'm blessed to be new enough to Python coding that I'm still having the opposite experience... everything that was difficult in my former language is ridiculously simple in Python so far! :-)
Thanks. There were actually two things broken by me here: - It should say `termux-tts-engines`, not `device-tts-engines`. - Both `termux-tts-engines` and `termux-tts-speak` were broken due to a mistake. I've fixed it and pushed the updated package to the apt repo - if you update with `apt update &amp;&amp; apt upgrade -y` you should be updated to version 0.5 of the termux-api package which fixes the problems. Let me know if you encounter any more issues!
I'm not so sure. Building useful things out of descriptors is very hard to explain. So is writing a decorator as a function that takes a function and returns a function, or even worse, a function that returns a function that takes a function and returns a function and oh, god. Python has never really been a simple language. Now, generators aren't hard to explain, but they can be used in a complex way to do asynchronous event handling, which is a complex issue. Its uses are so complex that implementing it over an unrelated language mechanic turned out to be too complex, so they decided to decouple async programming and generators by adding new language syntax.
I have both and if you plan to work in Python, use PyCharm. The features are going to be more up-to-date and the code completion will be slightly better. On the other hand, if I knew they were so similar, I might have bought just IntelliJ because I don't always use Python. PyCharm for Pythonistas, IntelliJ for polyglots. :)
Hi - I used the iPython notebook for Quantitative Equity Portfolio Management so I suppose I'm in a related field. First question I wanted to ask is where the data you intend to use, stored? If it's on some type of RDBMS perhaps you could try connecting to it using Python and the pyodbc library? Once you've done this, the next step would be to try to replicate the operational analysis you perform using other python libraries such as Pandas? Finally, you could look into Python libraries that help you read and write to Excel worksheets to output your data.
Any reason why? I use sublime for larger projects just fine, I find PyCharm to be pretty bloated for most cases. It takes forever to start up and uses a ton of ram, although it does have a lot of nice features. For the record I usually recommend PyCharm for beginners and sublime for a better overall text editor. 
 $ termux-camera-photo -h usage: /data/data/com.termux/files/usr/bin/termux-camera-photo [OPTIONS] &lt;output-file&gt; Take a photo and save it in a file. Valid options: -c, --camera &lt;camera-id&gt; the id of the camera to use See the termux-camera-info for getting information about available cameras $ termux-camera-photo -c 0 pic.jpg Error type 3 Error: Activity class {com.termux.extras/com.termux.extras.PhotoActivity} does not exist. $ Any idea why this is happening?
I have sucessfully replaced several excel spreadsheets with python (django webframework) for business applications like finance reports, quaterly analytics for income/spendings. The big difference is that we spend less time maintaining macros
I'm on OS X, so I like to stick with TextWrangler, running my programs from Terminal
Sorry, just discovered this subreddit and completely missed that one. Thanks.
Now say that out loud three times fast. :-)
I find the new asyncio functionality difficult to understand. I'm not sure if/how it's any better than Twisted or node.js. Most of all, I haven't been able to find many good examples of how to use asyncio online. 
It might be helpful for you to know that list[-1] refers to the last item in a list and list[:-1] evaluates to a list including all but the last element on the list. I think you can simplify your solution quite a bit w/ that info.
Would it not be better, from a package point of view, to make it self-sufficient by having it download the files too? If you want, you can implement batch downloading as well, making it costumizable based on the user's internet connection
Yes, it would. Customizable how?
I'm laughing for real right now
Yes! After recently using ES7 and C# 6, async await in python is a feature that can't come soon enough. Side note: does anyone know if celery will/does support coroutines or asyncio? I'm going to be in back-end land soon and need to brush up. I was never a real fan of the de facto pre-fork model :/
You lucky bastard ;) 
Any tutes for Python 3.5 for those stuck in 2.7 land?
Sure , M working on it .. 
&gt; I'm not sure if it's sad so much as the state of parallelism in Python seems to be getting more complex and more confusing. While we're simplifying the language, let's remove parallelism, multiprocessing, and C extensions. Shoot, assembly is hard, let's remove that. So are binary file formats. You don't have to use them, but you have to allow it to exist. You don't use async. I don't. Other people do. It's hard to explain because it's hard. If you want a say, you're expected to have some level of knowledge about the topic or go learn about it so you do.
&gt; We all want line numbers. Until I read that I had no idea that it was missing. Turned them on too, makes it a hell of a lot easier to find lines when debugging.
Yes, we've been using it at my company for 11 years. New people start that are experts in C++ and Fortran and they're soon converted. We subtly push it externally, but will do what our customer wants. Internally, we push it very hard. I use Python for 99% of my code. I'm an aerospace engineer and make software tools for myself to do my analyses and create engineering programs. &gt; Excel has been the tool of choice Excel is not an engineering tool. No matrix multiplication, eigenvalues...what a joke. Equations are easy enough to write, but hard to read and debug. It's insufficient for most of what I do. You owe it to yourself to learn Python.
And no XP support.
I forgot to update the termux-camera-photo script to use the correct internal parameters - if you do a `apt update &amp;&amp; apt -y upgrade` you should get the fixed 0.6 version of the termux-api package. Thanks!
conda is a great tool. As rothnic said, it's a tool which looks like to a package manager and it's very useful when you install scientific Python libraries such as scipy, numpy, pandas etc. since you don't have to compile in C, C++ or fortran some dependencies. A few years ago, I just used conda without installing the Python distribution from Continuum Analytics. Now, I've some difficulties to use it by itself. Actually, when you already have a package manager in a GNU/Linux distribution (with a python2.7 and python3.4 for instance), the installation and configuration of conda is tedious (some warnings, deprecated messages). And it's better if you install miniconda or anaconda (but I don't want to...). In Cont. Analytics point of view, it's better if you install and use their Python distribution. But when I have to work on a Windows station, this distribution is a piece of cake !
I don't understand the question.
I thought that myself. Or you could use pylab from matplotlib to dump a load of useful stuff straight into the namespace for handling vectors and matrices although it's not very well documented. 
Yep, I am aware of numpy. For most things that's probably a better option. It's also probably faster and more efficient. This was more just a fun project. It's a much simpler library for which it is easier to read the source and stuff. Edit: Also I'm not sure if numpy does echelon and row reduced echelon form. I think SciPy does that though
Except of course naming itself. It's really not so much about Flask, or rather really shouldn't focus on Flask. Because as you said, it covers a variety of topics that are not at all Flask related.
This is why I recommend Brainfuck for beginners! Such a relief!
Threads is one of the solution. It works, it has worked in the past for many people. However, it has drawbacks : - you don't know when your context is switching (when which par of your code is running and the other one is not). - you have to be careful about shared ressources, or use mechanismes to no share ressources (such as queues). - debugging is hard. - you need to pre-allocate enough threads. Asyncio is aiming to address these, by providing : - explicit context switching (if you see "await", you know the context will switch from here). - hence a very clear pattern to share ressources (a ressource is available between two context switches). - and easier debugging : you just follow the execution order VS trying to imagine where you are in your threads. - You don't need to care about maxing you threads since you got only one. 
Thanks. I've never actually used the PyCharm console/debugger... maybe it's time to give that a go as well.
Not bad. Don't make a new retry at zero and increment it. Instead, "for retry_count in range(5)" and on not retrying, break. Next, make a loop for the whole game session. Don't have a function call itself without a great reason. That's not a good way to loop. After a thousand games, it would crash. play() while still_interested(): play()
For more information on why you should be careful when a function calls itself, read up on the "execution stack". Sloppy use will make the stack run out of space and overflow onto other memory or crash. Yes, *stack overflow*.
this look cool. love spotify hate the program. 
Sounds like a nightmare.
Works great! thanks.
Thanks for heads up with Supervisor. Looking at it http://supervisord.org/introduction.html it seems like it is python, and has XML-RPC and a web-server control panel, which worry's me more than a little. But the concept of starting something and keeping it alive is amazing :D. We are not entirely looking into ditching PHP, as it is amazing as a proof-of-concept, and to be honest we are emotionally tied. The switch I am interested for, is our main web-app; we do want to switch this to Python! 
Are you actually complaining?
Plugin lags for several months, codebase and functionality are the same.
The best lightweight option out there is PyCharm. It is really memory-efficient and it is completely free of bloat. Just kidding. Although PyCharm is my IDE of choice professionally, as a begginer I was in love with Sublime and perhaps this is the most beginner-friendly editor out there for now. If you don't feel like getting into the Emacs/Vim abyss, Sublime is probably your cup of tea. There are more, but most of them are either in development hibernation or on the verge of irrelevancy. On Windows there is Notepad++, but I never worked on Windows and generally Python development doesn't mix well with that platform,
Just to add to other answers: a multi-user web application working with several timezones. This froze our team's progress for a couple of weeks. Especially when you have different kinds of entities that need different relationship with time and you try to make your user's experience as hassle-free as possible. My head still hurts every time I remember brainstorming about timezone issues. Here is a good [video](https://youtu.be/-5wpm-gesOY) on this topic. 
Perhaps a beginner-friendly one that would let him create a new Skyrim from scratch in whooping 5 days.
Do you intend to generate an order statistics? 
I use eclipse and add the pydev to it. It works very well. There are lots of tutorials on how to install eclipse and install pydev to it. It is not difficult.
Very cool! Really like this 
Thanks
Oh I'm using a python shell that may be the problem. Not sure how to use the terminal guess I'll Google it 
Total noob here, thank you for the tip. How can you check / print the file type? 
I use it to produce regular reports using IPython Notebook and producing charts and graphs along with adding in explanatory text. I then produce clean PDF's for publication. Each month or quarter I just re-run, connecting to the updated data, and update the text. Way improved workflow to using either Excel or access... Pandas is pretty key as is the IPython notebook.
Well, it's a corporate project and GeoServer might pose some support/Production difficulties. I'm also not terribly familiar with on-the-fly visualizations with GeoServer+Python. Do you have any good references for this sort of thing? Thanks!
Thank you, fixed. Crayon plugin for wordpress was messing it up.
After walking back through a simple use case, I did find that you can use conda to manage pip requirements, for those things that aren't on anaconda.org. Here is the use case of creating a flask app, which requires some random pypi project that happens to not be on anaconda.org. Note, I removed the outputs of some of the commands: &gt; conda create -n mydemoapp python flask &gt; source activate mydemoapp This fails... &gt; conda install singleton123 My workflow is now to use pip instead: &gt; pip install singleton123 Now, I want to save the configuration so someone else can run it. What I didn't know before was that this command also saves and manages things that were installed with pip. &gt; conda env export name: mydemoapp dependencies: - flask=0.10.1=py27_1 - itsdangerous=0.24=py27_0 - jinja2=2.7.3=py27_1 - markupsafe=0.23=py27_0 - openssl=1.0.1k=1 - pip=7.1.0=py27_0 - python=2.7.10=0 - readline=6.2=2 - setuptools=18.0.1=py27_0 - sqlite=3.8.4.1=1 - tk=8.5.18=0 - werkzeug=0.10.4=py27_0 - zlib=1.2.8=0 - pip: - singleton123==1.0 Now, someone else can use my app (avoiding env name clashes) with this command: &gt; source deactivate &gt; conda env create -n demo2 -f environment.yml Fetching package metadata: ...... Solving package specifications: Linking packages ... [ COMPLETE ]|###| 100% Collecting singleton123==1.0 Using cached Singleton123-1.0.tar.gz Installing collected packages: singleton123 Running setup.py install for singleton123 Successfully installed singleton123-1.0 # # To activate this environment, use: # $ source activate demo2 
 print(type(my_var)) 
And the join version: myl = ['apples', 'bananas', 'tofu', 'cats'] print ", ".join(myl[:-1]) + " and {}".format(myl[-1]) Output: In [2]: myl Out[2]: ['apples', 'bananas', 'tofu', 'cats'] In [3]: print ", ".join(myl[:-1]) + " and {}".format(myl[-1]) apples, bananas, tofu and cats You can add in an oxford comma by changing it to: ", and {}"... It won't work especially well with single-item lists, but that's life. You can just make the appending " and {}" bit in an if statement.
Just what I was looking for :) My Pi and Camera arrived this morning. Thanks!
Don't get me wrong, I have a number of python packages installed with pip, and have no problems doing so, but I usually check conda and binstar (now conda-server) first when seeking out those packages.
&gt; it's using less than 500MB of RAM and about 1% CPU. That is a benefit for very large projects, but it also uses about that much when nothing is opened, and I've never seen it get down to 1% CPU on my system. &gt; I find it easier to stay in the editor for things like running scripts, unit tests, Git, etc. and I really like staying in the editor instead of having lots of extra windows open and alt-tabbing. Personal preference there, I like using a command line for everything =P &gt; I really love their code refactoring capabilities. PyCharm's are better than the plugins I've tried for Sublime. &gt; I find PyCharm handles search better than Sublime and it's easier to use. Personal preference though, Sublimes search features are really good. The built-in search features are more than powerful enough for my purposes, I can search by file, by symbol, by method, or just with regex, matching case or full words, and doing a "Find All" pulls up a scratch buffer that lets you jump to the location in a particular file just by double clicking. &gt; Going to the definition of methods I find is easier in PyCharm. Especially in larger projects where "magic" happens and it's not directly obvious what method definition is the correct one for the editor to use. I've seen PyCharm fail at this, but it's been mostly when working with a lot of lower level libraries that access DLLs for doing hardware management (I work with a lot of extra hardware, like oscilloscopes, I2C, servos, etc). For me I have SublimeJEDI installed and I just have a keyboard shortcut or a right click menu option for jumping to the definition, it usually works pretty well. It fails on the same cases PyCharm does, though. &gt; I like how easily it handles my virtual envs, pip, etc. again without me having to switch windows or anything and just stay in the editor. Again, comes down to whether you want to do it in your editor or the command line. &gt; The integrated code coverage results stuff for seeing what code is covered by a run, especially tests. My big argument against this is when I'm passing off the code to another developer. They aren't necessarily using the same editor or tools that I am, but we do have some in common. I write a `setup.py` file that has the necessary configuration for running tests and coverage (nose is awesome), that way anyone can run it regardless of their editor. &gt; The integrated DB tools for browsing databases, testing SQL queries, etc. That sounds fancy, I wonder if there's a plugin for Sublime that can do that... For your workflow, it sounds like PyCharm is better, but for mine I still think that Sublime has the ability to match and in some cases beat PyCharm. In particular, I find that the plethora of text editing tools, those agnostic of the language you're using, really make Sublime shine. I have a coworker who uses PyCharm heavily, but he always mentions how he wishes he had certain plugins that I use simply because they allow me to edit code quickly. Multiple cursors, generating numbers from X to Y, selecting the text between delimiters such as brackets, splitting and joining selections, I even have shortcuts for swapping between different naming conventions, like camelCase to snake_case. These help me write code quickly regardless of the tools used for running or analyzing. If PyCharm had a comparable set of features to Sublime in this regard it would be a lot harder for me to justify using Sublime, other than it being totally language agnostic.
As others have suggested start with "Python for Data Analysis" by McKinney. An O'Reilly book It covers Pandas and IPython pretty well. Producing PDF reports is an add on to IPython Notebook, so do the basics first. There are a lot of pieces so getting them all is probably easiest using the Anaconda distribution of Python. Particularly if you are on Windows. 
&gt; Files will probably be pdf (requiring shitty OCR) Aren't PDFs mostly just containers? So you should be able to extract out the data directly, assuming it was exported to PDF by a sane program. Edit: I might be thinking of the MS Office .*x formats.
Awesome! Assuming you are using the Raspberry Pi camera board, when you go to install `picamera` to get access to the camera module, be sure to install it via: $ pip install "picamera[array]" Which will pull in NumPy support. [This post](http://www.pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/) on accessing the Raspberry Pi camera will probably also help a bit.
Syas video id is invalid. Is that just me?
Could this simplify the installation of Caffe on OSX?
It should be a link to the playlist page, not any single video...
Caffe looks awesome and getting it running is on my to do list, I'll be sure to update the repo.
I've tried again and it went nowhere. Please link me on comment if you can. 
Visual Studio 2015 can compile for XP just fine, you need to install the XP support when you install the C++ tools though. The compiler itself does not run on XP, but this is a different matter.
Here's a link to the [first video in the series](https://youtu.be/WfpFUmV1d0w). You should be able to find the whole playlist from there.
Pretty nifty. 
I don't know if it is temporary, I sure hope so. I thing PySide5 makes a lot of sense.
XP is dead and insecure. Time to move on!
Great idea! I'll see about adding that. For now you can fork/clone the repo and tweak the .dots script (or any of the other scripts that it calls) based on what you'd like to install. Edit: I added this feature, thanks for the tip. https://github.com/donnemartin/dev-setup#single-setup-script
Thanks!
&gt; Yes! After recently using ES7 and C# 6, async await in python is a feature that can't come soon enough. Me too. Not a big fan of JavaScript, but `await`/`async` makes it so much more pleasant. 
Hm, which device and android version? Rooted? What is the output of `which ssh`?
I think this is the correct way of doing things. Generally for me it has been a 4-step process: 1. Is it on anaconda.org (if yes: conda install) 2. Is the author willing to package on anaconda.org (if yes: help, then conda install) 3. Does the author care if I put it on anaconda.org (if not: conda skeleton from pypi and then conda install) 4. Install with pip
Is there a guide for step 2 or 3 out there? I would love to help packages be available on the conda environment, and I want to be a good citizen about it, but I don't want to get in the way...
I did this for one of my first projects as well, but it was on a TI calculator.
Right, you can use an *environment.yaml* to manage pip requirements. What I dont like about this is that you cannot use it with both pip/virtualenv and conda/environments. I'd love to do one of the following write an extension to pip to install all python deps from an *environment.yaml*. Given a *requirements.txt* I can install those dependencies with both pip and conda.
Postgres could you please add?
I make .csv files that load into Python nicely. You can't make graphs, which I why I'll make the graph once and then paste over it with a new data set. It's good enough for most heavy Python work. You can also use xlswrite to make/edit excel files (I've never done that). Still, when I'm using Excel 100% instead of 99% Python, 1% Excel, I'd much rather code in Python in Excel.
Other than the [official docs](http://conda.pydata.org/docs/build_tutorials.html) i'm not aware of any other tutorials. Perhaps I'll do that now! Edit: Working on a follow up blog post now ;)
&gt; Also I'm not sure if numpy does echelon and row reduced echelon form. I think SciPy does that though I had to look that up. I never thought of an LU decomposition being the same as row echeolon. I just thought of it as this weird esoteric method that gave you a lower/upper triangular matrix that you could do other operations on. TIL.
Thanks, this is exactly what I was looking for. Good to know what the alternatives are for doing something similar.
Thanks man, there isn't much I can do to contribute to the community but if I can do little stuff like that, it would at least make me feel better haha. 
In the spirit of practicality, given the current state of conda, 95% of people will probably skip directly to 4 for any simple dependency. 2/3 have some bit of time involved with them, especially for people that are new to conda.
Glad to see an answer from PythonAnywhere. If you could make a simple screen-cast on, how to deploy web.py application on PythonAnywhere would be very helpful. This is what the error thrown in log file: &gt; 2015-07-27 17:07:55,120 :Traceback (most recent call last): 2015-07-27 17:07:55,120 : File "/bin/user_wsgi_wrapper.py", line 130, in __call__ 2015-07-27 17:07:55,120 : self.error_log_file.logger.exception("Error running WSGI application") 2015-07-27 17:07:55,121 : File "/usr/lib/python2.7/logging/__init__.py", line 1185, in exception 2015-07-27 17:07:55,121 : self.error(msg, *args, **kwargs) 2015-07-27 17:07:55,121 : File "/usr/lib/python2.7/logging/__init__.py", line 1178, in error 2015-07-27 17:07:55,121 : self._log(ERROR, msg, args, **kwargs) 2015-07-27 17:07:55,121 : File "/usr/lib/python2.7/logging/__init__.py", line 1270, in _log 2015-07-27 17:07:55,122 : record = self.makeRecord(self.name, level, fn, lno, msg, args, exc_info, func, extra) 2015-07-27 17:07:55,122 : File "/usr/lib/python2.7/logging/__init__.py", line 1244, in makeRecord 2015-07-27 17:07:55,122 : rv = LogRecord(name, level, fn, lno, msg, args, exc_info, func) 2015-07-27 17:07:55,122 : File "/usr/lib/python2.7/logging/__init__.py", line 284, in __init__ 2015-07-27 17:07:55,122 : self.threadName = threading.current_thread().name 2015-07-27 17:07:55,122 : File "/usr/lib/python2.7/threading.py", line 1160, in currentThread 2015-07-27 17:07:55,122 : return _active[_get_ident()] 2015-07-27 17:07:55,122 : File "/bin/user_wsgi_wrapper.py", line 122, in __call__ 2015-07-27 17:07:55,123 : app_iterator = self.app(environ, start_response) 2015-07-27 17:07:55,123 : File "/bin/user_wsgi_wrapper.py", line 136, in import_error_application 2015-07-27 17:07:55,123 : raise e 2015-07-27 17:07:55,123 :AttributeError: 'module' object has no attribute 'app'
Didn't Vagrant already solve this?
One great thing I noticed is that the condo distribution of numpy on Windows comes with the MKL bindings. And on Linux, it looks like you get the ATLAS bindings which aren't quite ad fast, but still better than the default install. 
&gt;While we're simplifying the language, let's remove parallelism, multiprocessing, Parallelism and multiprocessing are quite easy to explain in Python. I'm worried that Python might be on the road to getting lots of subtly different versions of the same thing, which goes against the easy to explain and one obvious way to do it maxims. Heck, I came to Python from a language that has at least FOUR different string types, plus one alias and a C-style pointer to a character! When I start to see entities multiplying I start to sweat and my hands begin shaking. :-) &gt;You don't use async. I don't. Other people do. It's hard to explain because it's &gt;hard. People like Bruce Eckel famously talked about the FLOW CHART Java's docs present to help you decide how to open a file. I don't want Python to need a flow chart to explain all the subtly different ways one has for parallelizing operations. That said, I haven't gone over the forthcoming changes yet in detail so they might actually be simplifying existing patterns. 
I have several articles on my blog about using pandas and python to replace Excel. Here is one article on generating PDF reports: http://pbpython.com/pdf-reports.html Here are some more articles focused on Excel: http://pbpython.com/tag/excel.html Hope this helps.
Very cool blog, thanks for the links! I will read through this tonight.
MesoPy is a little package I made for the [MesoWest](http://mesowest.utah.edu/cgi-bin/droman/mesomap.cgi?state=CO&amp;rawsflag=3) API. It is useful for retrieving millions of observations from over 40,000 stations across the U.S. &amp;nbsp; I welcome any feedback, any contribution and of course I (and the MesoWest folks) would love to know how you're using it. All I ask is that you request an API key from MesoWest first (directions on repo) to avoid usage restrictions. &amp;nbsp; Thanks for looking! edit: gross, it used my picture for the preview image...
I usually extract the files to create a portable version of the Python distribution (with pip, tkinter, and a few packages installed with pip) that I can carry around on a flash drive as I constantly switch between a few PCs everyday. Things seem to be a bit more difficult with the new installer though and the embeddable version seems to be lacking pip and tkinter. I'm hoping there's something that I've overlooked to extract the files. 
Also Boxen I believe.
dude, this already exists. It's called Homebrew and it works wonderfully. http://brew.sh
&gt; Parallelism and multiprocessing are quite easy to explain in Python. I disagree. Many people are confused by the GIL and what it's limitations actually are. &gt; Heck, I came to Python from a language that has at least FOUR different string types, plus one alias and a C-style pointer to a character! Python still has 2 string types. The fact that it's simpler doesn't mean it's simple. Python 3 is used by ~20% of the community because unicode is hard to learn. I'm glad they unified the int/long type, but I still have to test for `isinstance(value, (int, int32))`, when using numpy even though they're obviously both ints. &gt; I don't want Python to need a flow chart to explain all the subtly different ways one has for parallelizing operations. Why? I'd love if I didn't need to care about how my data was organized in memory, but that stuff matters for performance.
I wonder what a packet looks like. and what the users done with it
did you try groovy ?
You can certainly add pip to the files from the embeddable distribution, and you can probably add Tkinter too, though it might involve a bit more fiddling to get the right libraries in place. I expect there's also some way to extract the files from the installers, but I don't know what combination of extractor tools you'd need.
wow idiot trying to beg other people to help because you can't
I found a halfway decent video that explains [how to solve the code. ](https://youtu.be/dQw4w9WgXcQ)
https://pip.pypa.io/en/stable/installing.html#install-pip
I don't know much about the actual PDF specification, but my understanding is that it's basically a lovecraftian wasteland, only traversable by those who seek forbidden lore. Even if they are easy to figure out, that assumes they've been organized in a reasonable way. In reality, they look more like [this](http://www.activant.com/EAGLECUSTOMERS/olh/Reports/AR_Rept_Examples/RAG01_rptmanolh.jpg) except: * way more information overall * every record contains different fields * columns are shifted around * entries extending past their columns * irregular detail/summary lines that aren't really labeled Oh, and they're between 3 and 10,000 pages.
Docker and Vagrant are great solutions. We use Vagrant where I work to ensure dev matches up with our test and production tiers. I've only played a little bit with Docker, it seems it doesn't run natively on OS X. For Mac users, Docker and Vagrant both rely on using virtual machines, which has pros and cons. I think Boxen is a cool solution, although some might find it more geared towards "more mature companies or devops teams". I've seen some discussions of [headaches as it is using Puppet under the hood](https://github.com/boxen/our-boxen/issues/742). The repo is a more lighter-weight approach using a combination of Homebrew, Homebrew Cask, and shell scripts to do basic system setup. I also try to provide installation, configuration, and usage discussions for most major apps/tools.
Homebrew is indeed wonderful. It's actually what does most of the heavy lifting in this repo along with casks and shell scripts that do basic system setup.
This post is a follow up to my [previous post](http://kylepurdon.com/blog/using-continuum-analytics-conda-as-a-replacement-for-virtualenv-pyenv-and-more.html) on conda posted to /r/python [here](https://www.reddit.com/r/Python/comments/3ep2ae/using_continuum_analytics_conda_as_a_replacement/).
upvoted! EDIT: Thanks for posting this, there was a definite need in this area for sure!
/r/learnpython You should also confirm the version of python you have on your mac (Most likely pre 2.7.5 if you're using the OS default, which I think is the version pip came installed by default) is supported by the module you're using that will be installed by pip. If it's not supported, you'll need to learn how to set up other versions of python on your Mac.
[https://bootstrap.pypa.io/get-pip.py]
But even if you mock external libraries, when you do a "pip" update, your tests wont tell you whether your still code works.
Cant look it over until after work, but Peter Norvig of Google wrote a great article on exactly this. http://norvig.com/sudoku.html
Xperia Z3, Stock rom, rooted /data/data/com.termux/files/usr/bin/ssh I am not using su when I try to run it. have tried purging and reinstalling openssl and openssh with no luck. edit: so I tried it again and it seems to be working now, odd. Thanks for the great app! 
the only thing I could think about using Python 3.5 would be through a conda environment, but that doesn't help you when it comes to dealing with the dependencies...
You can look in the direction of Heroku or OpenShift. DigitalOcean has ok vps plans. Heroku free tier will put your script to sleep if you aren't accessing it between ~30m intervals, it also will require your app to be down for a certain amount of time every day (you can ignore it during beta, but it will spam you with notifications). Paid plan (~7$) doesn't have these restrictions. It uses git and their command line utility to deploy and configure your app. Can't say much about OpenShift. 
Did you type this while incredibly drunk?
I don't know, I'm not a Windows guy. But I can tell you there is a separate Windows zip file containing the files, just for redistribution / etc.
Does it pull historical data too?
You really don't need docker to run natively unless your target platform is not Linux - I run it purely inside linux VMs, and it works great. With the right images the resource usage is amazingly minimal, even with multiple containers running together. I'm currently running nginx, django, postgres, and redis in just over 140MB of RAM, with a little over 800MB of disk space for the images. You can even run docker containers inside of other docker containers - [tmpnb.org](http://tmpnb.org) is a good example of that, and I suspect Microsoft's recent ML Studio Jupyter notebooks are using the same kind of setup. Also check [docker-compose](https://www.docker.com/docker-compose), it takes docker to the next level. There's also docker-machine, for setting up those VM hosts, but I honestly haven't used it as of yet (and don't know if it supports OSX).
So far I am lovin this app. I can edit my kivy scripts plus python scripts and debug them using vim, tmux, ipython and pudb! Having a stable vim app is something that I've wanted for quite some time as the Android vim app in the app store just doesn't cut it. While waiting for the kivy devs to find a way to launch kivy from the term as well as bring it up to full python 3.x support (that means the builder for the apk needs to support python 3.x) I've begun restructuring my kivy apps to use conditional imports, bypassing any imports of kivy related modules out of my application's business rules or logic so that I can debug the application's state and behaviour on my phone and tablet. My wish list for this app? Would love to get cython to compile as well as zodb. gcc seems to be missing some things. Also if we could have vim compiled with python, I would be in seventh heaven. A minor wish would be to have the ability to do an alternate install of the com.term folder into the sdcard like qpython does so that my file explorers like total commander can access the com.termux folder. But hey, cp and scp permit me to move files into the termux's application folders too.
If you don't want to rent a server or similar and don't need that much processing power, you could go with a raspberry pi (or similar). It's a one time purchase and doesn't need much power even if it runs 24/7
I messaged him on FB, small world! edit: also, thank you for sharing!
i dont know. ive never worked with it. When i googled asynchronous in python asynchio was the most common result. Also the fact that aynchio was shiny and new made me think it would have more advanced features.
I missed the note about it not supporting 3, and after fighting with some syntax errors I gave up and switched back to 2. Then I checked the docs and there it was: "Not supported for Python 3". Sad day
http://c9.io
This is great! Now I don't have to use wunderground :D
Hello, so if money isn't a factor, I would highly recommend using ec2 and a cron job. You can run the free tier if you don't need much space or compute power. It'd be fairly empowering to understand all of that. I can help you setup an ec2 instance if you like. pm me
here's the link for the curious - http://norvig.com/spell-correct.html
Yeah, I achieved to build 3.5.beta4 in a conda env and even faked the metadata to be 3.4.4.dev0, conda install does then work, but downgrade the python in the env to 3.4.3 ...
Do you know of a similar API or service that can be used for international locations? I'm most interated in East and West Africa (for example Nigeria and Ethiopia). Until now I've been using the Wunderground API but if you habe suggestions for something better I woupd greatly appreciate it.
If you are a student, the [Github education pack](https://education.github.com/pack) includes $100 in platform credit for new users at [Digital Ocean](https://www.digitalocean.com/)
pycontracts?
You can also go to [DiscoverFlask.com](http://discoverflask.com)
It's ongoing, but there is no timeframe for when it will be done. The guys behind it are very appreciative of patches though.
Thank you so much for posting this! I've been looking for a library like this to make a program that will scan a site and detect if it's vulnerable to sql injection. Looking forward to getting home now to start it! 
Scrapy is built on the Twisted framework for asynchronous processing. Unfortunately Twisted is still Python 2.x only - but they're hard at work upgrading it. This is likely the main bottleneck to Python 3 support in scrapy.
In general you do not need to change the net.core.somaxconn setting. It's the number of waiting connection, connections that was not established. This is not the number of concurrent users.
Don't bother with EC2, use something like Digital Ocean. I've been using that myself for several years and never was I disappointed. It's a breeze, especially if you're OK with terminals/SSH and basic server stuff.
AFAIK Py3 porting is going on in the [tmp-py3] (https://github.com/scrapy/scrapy/tree/tmp-py3) branch of the scrapy github repo.
[I'll let them answer that for you](http://doc.scrapy.org/en/latest/faq.html#does-scrapy-work-with-python-3)
It can scrape any. If you want to get links from posts as well just add in a field to the TextPostItem, then grab the xpath for links. It should follow the same format as the others, so it wouldn't be too hard. So yes, you can scrape all the porn you want. You could just go right to the source and scrape Pornhub if you really wanted to.
Actually recently in a post discussion I read that scraping nsfw subreddits using beautifulsoup redirects you to another website for age verification and then you can go further which isn't really possible in bs4. Its some kind of cookie sending receiving thing.
I hadn't even known is responded to anything in this thread. Sorry for the butt-reply 
My only criticism of this is that your build script is not cross-platform. Since you use ``find``, you are limited to Unix systems. If you want the recipe to be cross-platform you should probably use the bld.bat/build.sh infrastructure. However, I totally recognize that you were going for the basics and that you use conda's functionality to automatically build cross-platform packages! Really nice tutorials by the way, I appreciate them a lot! I will definitely be sending people to them when I need to try and explain what conda is, since I rely very heavily on conda myself.
Just add four spaces to the beginning of every line: spam = ['apples', 'bananas', 'tofu', 'cats'] def mylister(the_list): returnstr = myList[0] for lst in the_list[1:]: if lst == the_list[-1]: sep = ', and ' else: sep = ', ' returnstr += sep + lst return returnstr print mylister(spam) 
How to in a script?
That's the job of integration tests, not unit tests...
I'm currently hacking on some music production code, and music programming is turning out to be much more difficult than what I tought.. I can't find any easy and straightforward python audio manipulation/generation modules. Plus, music is a LOT of math itself, if you dig a little.. :)
I have written some groovy, but I had issues getting it set up in my dev environment. I'll have to give it another go when I get around to updating one of our groovy projects.
&gt; for yahoo.pipes How was your experience with yahoo pipes? Also, how to begin wit it?
Do you still need it?
Iirc scrapy has a speed option and is throttled by default.
Nope.
Throwing it up on github might be a better idea than using drive if you want people to work with you.
Reddit is a bad example to show off scrapy. You should either use the [json api](https://github.com/reddit/reddit/wiki/API) directly or the really good wrapper [PRAW](https://praw.readthedocs.org/en/v3.1.0/). [example](https://www.reddit.com/r/Python/comments/3eur2d/basic_web_crawling_with_scrapy/ctiw3w1)
You have ignored my question.
The worst thing about OpenCV 3.0 is that they do not provide binaries for the opencv contrib modules. So, even if you're working with Python, you'll have to compile OpenCV contrib parts by yourself. Also, the amount of trouble that the move of the **xfeatures2d** from the core to the contrib can be [seen here](http://stackoverflow.com/search?q=%5Bopencv%5D+xfeatures2d), I wonder why they didn't included a warning when importing the xfeatures2d module telling about the changes..
Bs4 is more for parsing html and xml than it is for building a scraper directly, compared to scrapy which is a full framework. You could use the requests lib along with bs4 to do this
This. Add a README describing what it is, how to get it running and how to contribute. 
It would probably be easiest with PRAW
I added it to github, here's the link : https://github.com/Dogeek/DnDApp
Hi @BSscience, YQL is more than just scrapping web pages. Yes indeed, you could use *beautiful soup* to do so. [What is YQL](https://developer.yahoo.com/yql) ?
Gateway is great, but it's only geared towards providing an API layer; we are interested in automating the entire journey from your function to the consumer of that function. On an implementation note, we use JSON-RPC as opposed to straight HTTP actions, so you can call your stackhut functions like native code (this is just a matter of preference, but it allows some cool stuff like type-checking input, which is impossible in HTTP) You can achieve a similar product to StackHut by hooking gateway up to a Lambda function. We found that a lot of our users were unhappy with Lambda for a few reasons: a) You have to use JS/Java b) You can't easily do a lot of things that are traditionally accomplished on the server. The biggest of these is dependency management: adding an operating system dependency is a huge pain-point in lambda (you have to package it up as an NPM module, they have to be under 60mb, you have to upload this and require() it). With StackHut you can specify which OS you want, and what dependencies / files you need in your config file. For instance, here: https://github.com/lanthias/pdf-compress/blob/master/Hutfile c) The containers they use are not refreshed on each request, so files / state is left lying around and can cause issues -- especially at scale or with leaky software like PhantomJS. That's not to say we don't think it's awesome; it's just built for a different use-case. Would be awesome to hear your thoughts on this and hear what you think we should focus on building. 
I did not know that, English is not my native language, that's why I didn't understand the quiproquo. TIL
I've had a good time using Digital Oceans 'Dokku' application. It costs $5/month, is just like Heroku, based on Ubuntu server and you deploy your code using Git. Easy and cheap.
\*sigh\* If only it were that easy for everyone. There are many cases (my company *was* one) where the death of XP meant the death of the company. There are literally tens of thousands of specialized hardware peripherals operating on ISA and PCI busses. They are made in small quantities, but have mission critical importance. So here's how our process went (2 years before XP's death): 1. "Hey guys. Vista is coming out. We need to look into getting our hardware and software stack to work with Vista." -Customers refuse to use Vista, so it's not a problem right now. Do not want to upgrade old computers that worked fine for a decade, and are still working perfectly fine with XP. Begin to try compatibility modes, driver install tweaks, etc... Nothing is working 100% and it has to. 2. "Let's call the hardware guys and see what they are doing about this." -Hardware guys are literally fucking dead. Died of old age. The guys who wrote the drivers are in retirement or dead. 3. "Let's find someone who can write a driver for this hardware." -Get a quote of over $600K. Can't afford that. And that's IF someone finds the original development code. Microsoft wants a ton of money for legacy support for IT auditing. Ain't happening. 4. "Looks like the are going to end XP for good. No more copies in retail stores." -We scrounge copies of XP anywhere we could. Ebay, craiglist, etc... Customers assure us they will take machines off the network. If it ain't broke don't fix it. 5. "Well, looks like were are out of XP." -Try running XP image in a VM. It just couldn't keep up the with the hardware. Software wouldn't work, machine wouldn't work correctly with the delays. Licensing issues abound. Attempt the downgrade rights crap. Useless 6. "Looks like everyone has to find a new job." -Yeah it sucks, but that's life I guess. We are all going to lose our jobs over a $120 piece of software that we can't buy anymore. Fantastic. There is no doubt that XP had to go. It was stifling in so many ways, but it just fucking worked. Yeah, sure, make all the excuses you want, but not making it available for those who know the risks is a shitty thing to happen. There is a happy ending though. One of the driver guys comes around and wanted the challenge of doing it on a new OS. So out the pure kindness of his heart, he saved a company and a couple dozen employees and their families because he wanted a challenge. And we were not the only company to experience that. Some made it, some didn't. Systems running on old SCSI Bus cards, frame grabbers, motion controls. Of course you can always start fresh with brand new off the shelf hardware, but then you may have to change all the stuff that connects to it. Try telling a customer they need $20,000 in upgrades and $10,000 in labor because XP is dead.
I recently finished this tutorial. It helped me more than Miguel's flask tutorial. It added more detail on things that Miguel didn't cover. However Miguel's tutorial goes more indepth with some 'advance/different' stuff so it's a tradeoff
If you're familiar with the command line, renting a cheap vps is going to be the lowest cost, most straightforward option.
Personally I'd just like to see that you care about some project and have taken the time to build something. In my experience just that puts you ahead of the field.
So it is probably good learning to try one of the server suggestions given already. But if you want to solve the immediate problem, you can set your computer to wake from sleep at a specific time, just before your script is scheduled to run and then it will go back to sleep depending on your power saving options. I have a desktop Mac that does this every night at midnight. My scripts run at 12:01, computer is back asleep by 12:05. For a Mac: System Preferences &gt; Energy Saver &gt; There is a Schedule button in lower right. Set the time and you are done. For a PC: A quick google found: http://www.howtogeek.com/119028/how-to-make-your-pc-wake-from-sleep-automatically/ For Linux: http://www.howtogeek.com/121241/how-to-make-your-linux-pc-wake-from-sleep-automatically/ It sounds like you already have your script scheduled but if you don't. LaunchControl is a great little Launchd manager for Mac. For PC you can also use Task Scheduler I believe, although personally have never tried. For Linux use cron which is built in. 
Author here! Would love some feedback on my writing, as I do not do it often. My time at HumanGeo was awesome, and I hope that they enjoyed the code that I wrote (I was an intern).
Nice post. This shows the cProfile output's default pstats summary, which can provide some information, but is a lot less useful than a hierarchical view provided with a profile output visualizer, such as runsnakerun. I recommend anyone profiling your code use a tool like runsnakerun.
Send PR, Thx
Your refactored version results in: &gt; TypeError: 'async for' requires an object with __aiter__ method, got list Returning something still ends the function, so that doesn't help me either.
Plex Server
I'm quite sure it was already possible using asyncio.wait and the correct flags. EDIT: typos
When interviewing candidates I look for the same. Show me passion about a project and explain its evolution and I am all ears. Hand me a portfolio of dozen projects or prototypes that are done just to have quantity and you become a statistic. Anyone can churn out work; not everyone has passion. Show me aptitude, a love of learning/experimentation, and mesh with my team and you will have a job. 
~~Hm? How could asyncio.wait help here?~~ Edit: Okay, this version does what I want, even though it's not quite syntactically beautiful: import aiohttp import asyncio URLS = ['http://i.imgur.com/vy35i0G.jpg']*3 async def get_content_type(url): response = await aiohttp.request('HEAD', url) response.close() return response.headers['CONTENT-TYPE'] async def main(): tasks = [] for url in URLS: task = asyncio.ensure_future(get_content_type(url)) tasks.append(task) not_done = tasks while not_done: done, not_done = await asyncio.wait(not_done, return_when=asyncio.FIRST_COMPLETED) for task in done: print(task.result()) loop = asyncio.get_event_loop() loop.run_until_complete(main()) 
What is so different about pypy that requires you to rewrite the library? I thought all "flavors" of python implementations followed the same specs so all code would be compatible.
&gt; I have a week to write something so I'm looking for ideas that will impress? That seems potentially incompatible. I guess if you are very skillful and put in as many hours as you can (and maybe have some base of code to build on), maybe you can bang out something impressive. But I wouldn't bet on it. Why does it have to be in one week?
yes I do. I tried to make a campain on it to play with my friends, but i found it quite unpleasant to use. The map tool isn't convenient, and leading a campain is hard due to all of this. That's why I want to do something maybe more user friendly, and a tool that you can use both for online or IRL play.
or use praw over oauth.
Last time it was submitted 6 years ago in /r/Python. So I think it's time we go over again this gem of post by Norvig
(Caution! Self-promotion ahead!) This exact Norvig article and a Markovian "[gibberish detector](https://github.com/rrenaud/Gibberish-Detector)" was what inspired my own implementation of [autocomplete](https://github.com/rodricios/autocomplete) functionality (also written in Python) - you'll find a tl;dr and an eli5 explanation of the markov chain I used. These sorts of implementations - sprinkled with light jargon - really helped in my understanding of introductory AI. I hope my project's README helps anyone out in understanding markov chains!
good suggestions! thanks! i have a question about dweet, how can i use it if i dont own any "internet of things"? 
yeah, what I'm fairly sure will work is def get_content_type(url): response = yield from aiohttp.request('HEAD', url) response.close() yield content_type async def main(): aysnc for url in URLS: print(await get_content_type(url) will work, but I don't know how to convert the first part to a "new-style" coroutine.
I find that for whatever reason, people just don't understand the value of VPS's. Here's my favorite site: https://www.ramnode.com/ $15 a year for 80GB of storage. Not a lot of ram, but chances are VERY good that you won't need it. I currently am using one of these to scrape Riot's API. I recommend you select a debian distro to be installed on it. Then all you have to do is apt-get install python3 and you can run everything.
The *async for* loop cannot loop over a normal list. A version of what you wrote that works is: import aiohttp import asyncio URLS = ['http://i.imgur.com/vy35i0G.jpg']*3 async def get_content_type(url): response = await aiohttp.request('HEAD', url) response.close() return response.headers['CONTENT-TYPE'] async def main(): for url in URLS: print(await get_content_type(url)) loop = asyncio.get_event_loop() loop.run_until_complete(main()) Which is pretty much just a sequential version which acts like it isn't.
What should be improved? Here's it is, as a pro would write it. (Only written, not run or tested. Probably an error somewhere.) https://gist.github.com/chadmiller/bd918575bb2bbf49bec6
argh sorry I'm making all sorts of mistakes. def get_content_types(urls): for url in urls: response = yield from aiohttp.request('HEAD', url) response.close() yield content_type async def main(): aysnc for content_type in get_content_types(URLS): print(content_type)
actually you *should* be able to use the coroutine decorator, `@asyncio.coroutine` should be a cleaner solution.
This makes me wonder if I should just present the Django app. It was a simple app that ran on a RaspberryPi that let you upload a script for a RainbowDuino (3x3 rgb led cube), it would then compile it and upload it to the RainbowDuino. In the end it didn't take a whole lot of code but at least I could talk about the various problems encountered along the way and how they were solved. There's even an outstanding bug that only happens on the Pi that I ran out of time to solve (also access to a Pi!).
 import types @types.coroutine I'm an idiot. [That should work.](https://www.python.org/dev/peps/pep-0492/#types-coroutine)
It doesn't seem to change anything :/ async for requires something that implements the *__aiter__* method and coroutines don't seem to do that. From what I understand, *types.coroutine* only returns an awaitable object as a wrapper around the generator, so I could simply use a native coroutine. It implements *__await__*, not *__aiter__*. Of course with *__await__* one can then use *asyncio.wait*, but using a native coroutine/*async* function is easier than using a generator and wrapping it with *types.coroutine*.
Yes. That's more or less the gist of what made me open up this thread. I'm used to python making these things simple, not requiring complicated workarounds. There should be an asyncio function that converts a list of awaitables into an asynchronous iterator. That's nothing that people should have to build themselves over and over again.
At least one of the errors you include (10057) you would only get if you were using sendto, which is used for UDP, not TCP. So you're including a lot of details here which don't really relate to the client/server you've given us. I would start with those, and get just the simplest socket connection working. Actually, I would start with the first examples of an echo client/server from [here](https://docs.python.org/2/library/socket.html#example). I don't know why someone would tell you there's no loopback interface on Windows. That's definitely not the case. So you can replace the 'daring.cwi.nl' address from the echo client example with '127.0.0.1' on any system, linux or windows, and it should work fine. In fact, with that one change, it should work just about anywhere with the client and server running on the same machine. If it doesn't, it really seems like a system administration issue. Something like a firewall would have to be blocking the connection.
Implementing something simple in different programming paradigms (oo, functional, imperative and procedural) should help immensely.
I guess it *might* be because you *should* consume a coroutine async iterator the same way you consume any other async iterator (generator). As in, def main(): for content_type in get_content_types(URLS): print(content_type) would work just fine in terms of consuming the asynchronously generated content types, you would iterate through and things would be yielded as necessary. Where the async for and all this come in is when you want to pass async code to other async code, so if you wanted to loop over the content asynchronously and modify it and then pass that to something else, `async for` could be a bit easier than `yield from` that said, it would still be nice if python provided a clean wrapper to generate aiterables.
How so? Not having time for passion projects is hardly age related--it's just a matter of having other priorities. 
??
I have never personally tried web2py yet, I do however run several internal apps at work, all of which are coded in python/flask. Up until present I have always managed to find a library and documentation for the flask framework that supports anything I have needed or wanted to achieve. I can say that most problems I have faced with flask have been thoroughly answered several times over on community forums / Stack-Overflow. I would suggest however trying out some basic flask apps to get a feel for it however, to see if it suits your needs before moving an entire working API to it, only for you to change your mind later on down the line.
Python is converted into executable code as it runs. I think there are some resources you can use to turn python into a compilable language, but I've no idea how they work. The advantage of Python is that you can make a quick edit and rerun the program, rather than having to compile each time, for the cost of some efficiency. Someone please correct me if I am wrong.
You could be me! I'm in the exact same situation. Legacy app in web2py, which I find frustrating on a number of levels wrt. supporting a RESTful (mostly) api. So, I'm moving in fits and starts towards flask. You should buy the [o'reilly flask book](http://shop.oreilly.com/product/0636920031116.do) it's been really helpful for me. 
1. Open terminal. 2. Type 'python your_program.py' 
Okay, I will bite. From what I wrote, how do you take 'ageist' away? What assumptions are you employing to land on such a conclusion?
Could you elaborate on that? I don't know what any of that means.
In a serious setup you would use PyPy to increase the through put of your requests!
&gt; Python is converted into executable code as it runs. See that is what I don't get. I've read this many times but I still don't understand. When I go to my PycharmProjects folder and try to open a .py file it doesn't open like a .exe file, it has to be opened with an editor. That's what I meant.
If you're on mac/linux you can open the terminal, write python and then the .py-file's name. This will cause the python interpreter to start going through the code in the .py-file and do what ever the code does. If you are on windows, the same can be achieved using the Python Shell (get it here: https://www.python.org/downloads/). TL;DR: You feed the interpreter the .py-file instead of letting an IDE do it for you.
PyCharm, in the background, is running your scripts using the python interpreter. The python interpreter is a program that accepts python code as commands and "runs" it. What you actually need to do is point the python interpreter that's installed on your machine to your python script that you wrote. Where it is located depends on where you installed it. You'll need to either open the windows command prompt or a linux terminal and run something similar to the following "python C:\path\to\your\python_file.py" Also if you run into python command not found or something like that, follow this guide http://stackoverflow.com/questions/6318156/adding-python-path-on-windows-7
/r/learnpython http://cli.learncodethehardway.org/book/
Good to know I'm not alone on this! So are you moving only your API calls onto Flask?
You are applying an us/them you/me approach to this. I am on your side... Allow me to clear this up :) &gt;&gt; I feel that this wanting to have your cake and eat it too. Asking for devs who love what they do? This is why I quit MSFT...I wanted to work with people who loved what they do. Not sure that is wanting and having cake. &gt;&gt; I have about 10 projects on my resume, the ones I've spent the most time on (creating cryptography breaking algorithms, etc) are not the ones I'm most passionate about. So you show the 10 projects and focus on what you were most passionate about. I care about what you care enough to show me. If you had written a python library that did odd things to strings because you LOVE manipulating strings, show me that. What I am getting at is this...for me, I want to see someone who found enjoyment with what they do...not just someone who needs a paycheck. I suggest Amazon and MSFT to those looking to fluff a resume, build a resume, etc. &gt;&gt; But do you as an interviewer / resume reader only want to see the app I made that shows me anime pictures? I'm sure if that was the only project I had on there you would turn me down. I was not suggesting that either a passion project OR a portfolio. I was simply saying that I learn much more about a candidate from seeing them show me something they truly care about versus something they completed as an item to check-off their list. Don't read into that too much :) &gt;&gt; I feel as if you're unfairly judging people who actively put in the time to get better, enjoy themselves, and try to appease you. Nobody knows what to bring to an interview loop. I ask people to bring examples of projects they love to share with people as well as something that they feel may demonstrate an implementation of something that challeneged them. I leave it open-ended as I want to experience whatever it is an candidate wants to show me. How do you mean I am unfairly judging people who are tying to better themselves? Learning is essential to being a well-rounded person. &gt;&gt; It takes 10 seconds for you to look over a resume, but it takes days or weeks for us to do projects. You think I breeze over resumes; that is quite presumptuous of you. I happen to enjoy the entire interview process (including the creation and reading of resumes, conducting and attending interviews, whiteboarding code, etc) and because of that, I read through each resume as if it were the only applicant. No resume filtering happens between submission and review. I also do not rule people out who are missing a degree, in case you were wondering. &gt;&gt; Please have some humanity. a tad melodramatic but don't worry...I have plenty of humanity. A resume is just a snapshot of a peek into the life of a stranger. This should never be used as the final decision as to the fate of another person. Someone took the time to craft their portfolio, their resume, and apply for a job. I take the time needed to assess whatever is submitted. I also make it a point to phone-screen as many as I can. My last hire was beyond unsure about being able to even pass the interview. He and I spent an hour on the phone discussing expectations and our tech stack. His resume, his projects, and his personality that I discovered on the phone were plenty to extend an offer after the interview loop. Had I approach this without humanity... :) I am an oddball...I am okay with that.
Thanks!
I wrote a basic php CRUD database front end for MySQL. I didn't make it pretty; I just used Boilerplate (https://html5boilerplate.com/) to handle the majority of the front end. You could traverse multiple pages of records. I did it in a weekend, drunk no less. He was impressed because 1: did it in a weekend, 2: it was object oriented, and 3: it was MVC. I was hired, despite my assumption I was reeking of alcohol when I presented it. edit: still have the code if you want to see it. But this is really only useful for the backend coders. And I realize this is in /r/Python, but the basic concept is the same. edit 2: and if you're hiring...
Hey folks - book author here. Based on community requests from fullstackpython.com I wrote a step-by-step guide for deploying Python web applications. It just launched publicly this morning. Happy to answer questions!
Do some multiprocessing. Bitches love multiprocessing. ^(*Not actual advice, I haven't got a clue.)
great!
Great post, I ended up finding that method of memoizing with a decorator the coolest part.
Woot! I'm a huge fan of Matt's work. He's an awesome guy, and his site is honestly a great resource for python developers. I've spoken with tons of new developers who have used it over the last year or so. Congrats on the book launch!
Thank you Randall! Definitely was inspired when I read your The Heroku Hacker's Guide a few years ago - thanks for blazing the trail.
Hey man, apologies, I wasn't implying you are ageist , just that your requirements would probably favour someone with more time on their hands and that typically would be your 18-25 age bracket. I have a wife and kids and I love coding but beyond doing what I need to do to earn money, my family life has to take priority over pet projects. I understand some people have more time available but I feel like a large portion of people with families just don't have the time to sometimes keep up with the progression of the industry, let alone work on side projects. This is just my feels though so please take what I say lightly, I didn't mean to offend or appear like I was trying to provoke ya ;)
After reading your reply and thinking about your response I think I've unfairly judged you, I apologize. Although you enjoy the entire interview process (and are probably incredibly skilled as a consequence) I feel that it is stressful and unsavory. I thought you wanted only one project that someone is passionate about, which is why I said you want to have your cake and eat it. I'm not saying I don't enjoy what I do, if I didn't I wouldn't have over 50 project ideas on my notepad, with over a dozen already done. As far as showing off what I love, the only thing I really love is Japanese culture (anime) and the apps I use regularly that I've built all focus around this topic. Not every interviewer is receptive to my hobby and thus I go over it in passing and gauge interest when I mention the scope of the project. You're correct in saying that no one knows what to bring to an interview, however the most challenging project I've worked on, that has made me grow the most as an engineer is incredibly boring, and I fell out of love with it after working on it for almost a year. However this is what I always make sure to mention as it universally makes an impression when someone hears that I have made it and what went into making it. I was most wrong about your lack of empathy for interviewers, as I've gotten a hefty amount of advice and testimony from interviewers and resume readers that they only spend 10-30 seconds on a resume at most. What convinced me was a study done by tracking reviewer eye-balls. I feel that you are unique in actually caring about us interviewers and honestly you've changed my perspective today. I feel pressure on all sides when it comes to the interview process from reviewing data structures and algorithms, trying to remember how many balls fit in a bus, going over old projects in case I get questioned, investigating languages and frameworks to learn and put on my resume to get past automated filters looking for 10 languages and knowledge of Rails, Django, MEAN, and justCameOutFiveMinutesAgoJS, people graduating code bootcamps with much more prowess in web development than I have as a traditional college student (which is what many firms ask for in addition to "knowing the fundamentals"), spending hours poring over my resume changing the spacing, formatting, wording, font size, margins, project descriptions, etc. I feel that the emphasis placed on "passion" is too much when the advice is not to learn Rails because it's cool, but learn it to show "passion", and while you're at it make a non-trivial project to show "passion", then write a blog to show "passion". My internal response is "Why can't I show passion learning what I love (Python), and making things I find interesting (robots that cheat at games)?" The takeaway is, I unfairly characterized you as a harsh resume reviewer, but if what you've written is true you're one of the best. You won't toss my resume because I don't know Elixir, you look at my projects and actually want to know what I care about most, and you actually read them, understanding I took time out of my life to write this thing and make it look decent, time I could've spent . You actually care, thank you.
What makes a python program (.py) run is called an interpreter. What the interpreter does is it will read the .py file line by line and essentially turn it into something the computer can understand. Now here's the thing, once that line is executed it is thrown away (it might be saved in ram if it may be needed again though). All of this makes python a little slower because everything is on-demand, but it adds some versatility. Note: this is an extreme ELI5, the interpreter is a bit more complicated than I described.
I substituted the port/IP on purpose, but I I know that they're fine. I also know that there's nothing wrong with my code, either. I just tried connecting my bad computer (BC) to the good computer (GC), and it works perfectly. Just not the other way around. It will time out if I try it the other way around. As for a firewall, I've tried turning off both Windows firewall and my Router firewall, but nothing changes. I have no antivirus, too.
Hey guys! I'm open to questions here. I made an encouraging and positive community around Angular, and I'm hoping we can do the same with Python. :)
Seconded :)
Hey guys! I'm open to questions here. I already run an Angular community, and I hope to encourage the same positive and supportive community around Python. :)
Way to stay positive about criticism, man. That's a skill a lot of bloggers don't have.
Very cool.
I'm a bit puzzled as to why he doesn't make a real package index and forces everyone to use that page with that annoying javascript hotlink protection. There's free hosting here: https://pypi.binstar.org/ After all, installing the compilers on windows once is easier than downloading files with your browser all the time. 
It could be that `common_function_called_in_gazillion_places` is being called from within another function that also does not have the request in scope. Your approach is still a great starting point, but I'm betting there are still many function calls that have to relay the request somewhere above this function in the call stack.
Open either cmd.exe or Powershell if it's installed Type `dir &lt;path_to_your_file&gt;` ie 'c:/Users/Bob/Python/' Type `python &lt;your program_name&gt;` If it complains about not being able to find python you need to replace `python` with the path to python.exe which is probably `C:/PythonXX/python.exe` where XX is some number like 27 or 34
Yes, I entirely agree. Building a brand new IDE is, as they used to say in the RAF during WWII, a "piece of cake". Apart from 1,000,001 minor little issues that plague software development it shouldn't take too long at all :)
That was about the clearest and easiest to understand explanation of generators I've read. 
When I use python for the first time as a newbie and as a windows user, his site is more user friendly to me than figurung what is easy install or pip (conda hasn't existed)
What don't you like about pickle/cpickle? I have found pickle to be more versital but slower... are those not meeting your needs?
I misread error 10057, so you're right it has nothing to do with sendto in this case. But your problems are almost certainly due to the way your network and/or the OS's you're using are configured. Your Python code is fine, and I doubt there is anything wrong with IDLE or the Twisted code.
This is a relatively simple spider. You can get significantly more in depth such as saving data to databases or doing more complex parsing. Give this a try then try adding in database functionality as an exercise. Perfecting that is next on the list for me.
Hes dutch. Straight forward.
Rude/insulting and straightforward are not mutually exclusive.
I think it's great for beginners to have a simple IDE like IDLE immediately available. When I started I just wanted to write code and run my programs, and everything else would have been annoying or frustrating. /u/AlSweigart is working on a redesign called [IDLE reimagined](http://inventwithpython.com/blog/2014/11/20/idle-reimagined/) which looks like a promising replacement. There's also the [IdleX](http://idlex.sourceforge.net/about.html) project which makes IDLE more comfortable to use, but of course it's nowhere near IDEs like PyCharm. Unfortunately it's not maintained anymore and has some bugs. ~~Also, it's only available on Sourceforge.~~ It's also available on [pypi](https://pypi.python.org/pypi/idlex/1.12).
Should IDLE be packaged with Python though? I wouldn't have thought many people would use it, and beginners could be put off by it. Why not just let people choose an editor or IDE they're comfortable with? 
I had to write a few scrapers at work, but I used BeautifulSoup4 for my HTML parsing, and Selenium + PhantomJS to work with websites that rely on javascript.
Great work!
Ah, I didn't have these problems, because the tutorial with which I started told me how to use IDLE. But you're right, if someone doesn't have that information available, s/he could get confused. I didn't realize this could be an issue for other people. BTW, in IdleX you can use the command history with the arrow keys.
I believe scipy has methods that provide the kind of convenience wrapper you're describing. If you're doing data analysis you should already be availing yourself of the complete scipy stack. For speed and flexibility, hdf5 is the way to go, matlab .mat files are hdf5 files with a unique header. 
Sometimes the truth hurts. 
You would have to write a windows service. http://www.chrisumbel.com/article/windows_services_in_python 
Works OK on Linux as long as its package managed. Otherwise spider breaks every time Qt updates.
You can also login in the browser and use the browsers cookie's in python. Edit: ex. browser_cookie is one module that allows you to do that.
What did he mean by "the process"?
Just glancing through the chapter titles, isn't fabric effectively dead now?
When I started I had no idea what an IDE was, so it was nice to have it auto install. I've currently got Canopy and PyCharm
Guido wrote IDLE though, so, it's not as though he's talking *entirely* out of his ass. Do you know for a fact that any IDLE maintainers are insulted by this, or are you just assuming that's likely to be the case? I think they probably don't disagree with him.
I didn't even know people used IDLE outside of intro to programming classes
I second Selenium; I use it + the Chrome driver to run most my scrapers. I ended up dockerizing this setup for nice CI testing 
I can't speak for autisticpig, but since this is sort of a follow up to my original comment I'll bite: I am now a parent of a 1 year old so I absolutely feel that. But the things is you have to see these responses in context. This is about people who are young and don't have experience from real jobs. People who are older normally have work experience (even if it's not in programming!) and that really is worth a lot more in an interview than a hobby project on github. The github passion project thing is for people who are trying to get in the door without having work experience, maybe even without any formal education.
I don't remember having much problems, but it was a while since I used it last... did you set up the path mapping correctly? That's the only thing I remember that was a bit fiddly...
IDLE has history browsing in alt-P and alt-N. I actually find it extremely good and I miss it when I work in a more capable environment than IDLE.
it's the pythonic solution.
You mean the open source BSD'd version of PyCharm? 
The open source apache 2-licenced version of PyCharm: https://www.jetbrains.com/pycharm/download/
I'm not sure I follow. You miss these bizarre hotkeys?
Having the keys as not up arrow and down arrow allows you to use up arrow and down arrow to browse through lines normally when you edit the history text. I feel it's better than what e.g ipython does.
I think any summary of profiling would have a brief description of the different approaches to profiling, which is hwy I think line_profiler is important, and why most blog posts about profiling I have seen at least mention it. As for general comments, I think it would be hard for beginners to make use of your explanation since you don't really tell users what they are looking at. What do those columns mean? What do they tell you? What should you be looking for to figure out what is slow? I think that is important information to be able to make use of profiling. Also, your suggestions at the end seem pretty focused on the particular niche you are using, rather than being general suggestions. You mention IO, regex, and then jump straight into memoization and Pypy. I think there are a lot of other options that someone might consider before the last two (using better data structures, avoiding copies and type conversions, using hashes instead of linear searches, moving expensive operations out of loops, vectorization), and I would be very surprised if regex was really a major culprit in most code. I would probably have split that off into a separate blog post and used the space to go into more detail about what exactly someone is looking at when they get a profile result. So as general comments I would suggest taking a step back and thinking about what beginners are likely to know and not know, I would suggest either making sure your suggestions are general or explicitly mention they are focused on your particular usage, and I would suggest going into more detail about the subject of the blog post and separate out other topics into separate posts.
You're modifying a list as you iterate over it, which is always a recipe for sadness. The iterator is not aware of the fact that you're removing items from the list, so it's going to increment the current "pointer" each time through the list. But if you remove the current item, then the item that came after it becomes the new current item. The iterator is not aware of that, so at the end of the loop it's going to advance to the next element for the next time through the loop body. That effectively skips over the new current item without even testing it. Don't mutate lists while iterating over them. Create a new list that contains the items you want to keep. Python gives you very concise and handy ways of doing that, such as the list comprehension. 
Somewhat similar to vim's ctrl+p / ctrl+n to scroll through a list.
This is the real issue. People joke that the standard library is where modules go to die, and in many ways that's true. Once something is being distributed with Python, it starts falling under all sorts of constraints on release cycles, compatibility, etc. which tend to drastically slow if not outright kill further development. And I've personally seen multiple people run into exactly this problem when trying to get even minor improvements into IDLE: being distributed with Python is useful since you can guarantee it's there, but it's a disadvantage since it becomes far more difficult to do any work on it once it's included.
for loops control uses a temporary index to know which element it is processing at each time. so, let's say that while processing [0, 1, 2, 3...] you are at the index 1, and remove that element, your list is now [0, 2, 3, ...] and at the next interaction, the index 2 (and the for loop) will get the value 3 in this list. if you really need to remove from a list, while interacting over it, one simple trick is to copy it: a = [(0, -1), (1,-1), (1,0), (0, 1), (-1, 1), (-1, 0), (1, 1), (-1, -1)] for x in a[::]: if x[0] &lt; 0 or x[1] &lt; 0: a.remove(x) print a you can see that the copied list doesn't change and thus your program runs as expected. but that are better ways to do what you want, see /u/kinygos answer.
I agree 100%. If it was removed then it could be made into something much better.
I use it if I want to test a line or two quickly.
Yup, here is a version using `filter`. Judging from the `print` statement, the OP is on python 2. &gt;&gt;&gt; a = [(0, -1), (1,-1), (1,0), (0, 1), (-1, 1), (-1, 0), (1, 1), (-1, -1)] &gt;&gt;&gt; a = filter(lambda x: x[0] &gt;= 0 and x[1] &gt;= 0, a) &gt;&gt;&gt; print a [(1, 0), (0, 1), (1, 1)] The same code but for tuples of any amount of members. &gt;&gt;&gt; a = [(0, -1), (1,-1), (1,0), (0, 1), (-1, 1), (-1, 0), (1, 1), (-1, -1)] &gt;&gt;&gt; a = filter(lambda x: all(map(lambda x: x &gt;= 0, x)), a) &gt;&gt;&gt; print a [(1, 0), (0, 1), (1, 1)] &gt;&gt;&gt; 
Well, I actually have a few questions. I've never found a Scrapy tutorial that goes beyond the basics, and last time I checked, the docs were not much of a help. First, what's an elegant solution to run Scrapy on a server without manual supervision? Assuming it would run different spiders for lots of different websites? Second, how does one deal with the inevitable errors in an elegant way? Since the HTML of the scraped website sometimes changes, one needs to have some way of figuring this out. If I recall correctly, the error log has a bit too much information, and sometimes not the right one. E-mails for each incomplete item seems like overkill, since an automated spider may break badly in the future. Third, HTML is sometimes messy, ie. the wanted information may be under different xpaths across different pages on the same website. I'm currently adding all known paths and clean it up later. Is there a more elegant solution? Thanks in advance!
The thing to rember is scrapy is a framework once you know what your doing it makes it super easy to write simple crawlers fast. but some projects are going to be better off without it especially if you want to do something distributed.
Why not the python repl? Though I guess that's harder to use on windows
It is documented [here](https://docs.python.org/3/reference/expressions.html#boolean-operations)
+1 for PyCharm. I'm a beginner Python'er and I really like it. I've been using the community edition. It's cross platform too.
I understand the logic behind it, however ability to use logic operators with equal has a broadening effect on one's mind. It had on mine. Now I feel myself a completely different person than I was this morning. My life will never be the same. Thank you for your explanation though.
Interesting. I can see its use then. 
I don't know how it compares to Amazon's course, but Udacity has a nice [Intro to ML](https://www.udacity.com/course/intro-to-machine-learning--ud120) course too (and it is actually free).
If you are not on Windows, you would already have a terminal open.
Hi /u/xragon, please let me point our that it is not scam at all. You can cancel and reactivate your subscription whenever you want and of course you will receive at least one warning email before your trial ends. Nobody is trying to trick you: we are transparently selling our training product, which improves every day, also thanks to our members' feedback. Besides that, I would love to hear your feedback about the ML course itself. :)
Press 'windows key'+R, type 'python' and hit enter.
Why type "cmd" first? windows+R -&gt; py -&gt; press enter 
And maybe a package/virtualenv manager as well. We should probably name it something similar to python, like a different kind of snake maybe, anyone got any ideas? 
While it's true Fabric has not made the transition to Python 3 yet, it's still a damn useful tool for automation. Ansible, which is used heavily in the book, is not yet compatible with Python 3.x. When Ansible is upgraded to work with 3.x I'll evaluate whether or not to keep Fabric in the book as I update based on reader feedback.
You're totally right - it's been fixed now. Sorry about that!
For simple solutions I would recommend http://scrapy.org/ However, there are times when it didn't work (example: NTLM authentication we had in our company; now I see in Google search results that people managed to correctly use scrapy with NTLM but that wasn't the case when I was developing my crawlers). Also, keep in mind that there are more ways to do authentication - HTTP basic auth, cookies, sessions, etc. You can even encounter captcha :)
I read it like: "How to rape a website ...". Damn you Bill Cosby.
Had I known such a thing existed I would definitely make my life easier. Thanks for pointing this proxy out!
This is beautiful, thanks.
Build instructions for the source http://www.jetbrains.org/pages/viewpage.action?pageId=983225 I have found that building and debugging the open source IntelliJ to be very fast and painless.
I think [this page](http://effbot.org/zone/re-sub.htm#unescape-html) has the function you're looking for. There's no built-in way to do this as far as I know.
I'm having a problem similar to OP and was wondering if you or someone else could help me. I have a list of objects that will likely grow to be up to 20000 elements long and each object takes up about 3.5kB because each has a pymunk body associated with it (I'm not entirely sure why the pymunk body needs to be so large). I need to iterate over the list and sometimes remove an object based on a randomly generated number. I'm solving the OPs problem at the moment by incrementing a variable, 'offset', every time I remove an element from the list. My code looks something (but not exactly) like this: class SomeObject(object): def _init_(self): self.chanceofremoval = random.random() ...pymunk initialisation code... def removefromlist(list, offset): if random.random() &lt; self.chanceofremoval: ...pymunk code... list.remove(self) #offset += 1 offset[0] += 1 #Fill the list (not how it actually happens in my project) list = [] for x in range(100): list.append(SomeObject()) #iterate through the list and remove some #offset = 0 offset = [0] for x in range(len(list)): list[x - offset[0]].removefromlist(list, offset) Is there a more appropriate/pythonic way to do this? Edit: just realised int is immutable so this wouldn't actually work. Wrapping up offset in a list might work 
I think that Python should come with a core GUI toolkit that isn't tkinter. After we get that, we can talk about bundling a new IDE with Python.
Well, they are all open source, right? Put them up yourself.
Do you live in Austin?
Try .encode('utf-8') on the string
Ah, I've just seen "cobra" like a thousand times this past month in /r/austin: https://www.reddit.com/r/Austin/search?q=cobra&amp;sort=top&amp;restrict_sr=on
Edit - Forget what I wrote. That only minimizes by a small amount. It only eliminates cases where two people owe each other, but does not find cycles, or any larger combining of payments. I do think you could do something like what I'm talking about as part of a pre-processing routine, however. In many cases, columns and rows are empty, which means they can be eliminated, reducing the complexity before entering into the awful N^N run time... I think this can be done much more easily with an array of names. Basically a distance matrix with both the rows and columns listing out all unique names involved in the transaction set. Then, you basically go through the matrix once, comparing the upper triangle to the lower triangle of the matrix. The lesser value is subtracted from the greater (if two people owe each other money and one owes more). The result will be a half matrix that you could minimize. Any rows with all zeros can be eliminated (because that person doesn't owe anyone anything). Any rows with a non-zero value are kept. This doesn't seem like O(n^n)... maybe O(n)? 
Na it's the only other type of snake I could think of that wasn't anaconda
I agree, but is there a cross-platform GUI toolkit with a compatible license that's better than TK?
It's written in Java, though, right? So now installing Python will require me to install a JRE?
I don't know. I don't like most of the GUI toolkits for Python right now. Most of them have leaky abstractions... (PyGTK feels like GTK. PyQT/PySide feels like QT, WX Python feels like WX, and Kivy feels weird.) Nothing just feels pythonic. I'm not saying that TKInter somehow feels better than these others. I just don't think anything we've got right now "feels" right. So, maybe adopting an existing library isn't the right way to go. Granted, creating a new GUI toolkit is no small undertaking. So maybe it'll be easier to just create a really good wrapper. I don't pretend to know what I want. I just don't want to "pick one" because we want one.
 &gt;I think it's great for beginners to have a simple IDE like IDLE immediately available. Sure, but I don't think it needs to be included in the standard distribution, especially given all the constraints that imposes on the choice of IDE (must be BSD licensed, use standard libs only, written in Python, etc). Seems like it would be better to have a "beginner's bundle" as a separate install, something like anaconda for example. 
My first idea was to look at coveralls.io since they offer free Coverage for open source projects. However, they don't seem to have an index of projects where they are used. However, with a pretty basic Google Search, I find plenty: [site:https://coveralls.io/github python](https://www.google.de/search?&amp;q=site:https:%2F%2Fcoveralls.io%2Fgithub+python)
I will admit that IDLE has a bunch of warts, but these are things that can be fixed. The [IDLE Reimagined](https://github.com/asweigart/idle-reimagined/wiki) design has an interactive shell pane on the bottom and tabbed text editor windows on top. The no-history-for-up-arrow is so that you can move the cursor up to previous lines, then press Enter to copy/paste a previous line. You can make an argument that this is better, but I agree with you that having a standard up-arrow-history design would be better. Though at least IDLE today has fixed that no-.py-extension problem. That drove me nuts too.
"wxPython is the best and most mature cross-platform GUI toolkit, given a number of constraints. The only reason wxPython isn't the standard Python GUI toolkit is that Tkinter was there first." -- Guido van Rossum http://www.wxpython.org/quotes.php Although I haven't used PyQT, I'd have to agree, wxPython is a great GUI toolkit.
Thanks Benjamin, that's a great TL;DR! :D
I'm the guy behind the [IDLE Reimagined](https://github.com/asweigart/idle-reimagined/wiki) project. I've been diving into the IDLE code base and community on and off for the last few months. It's blunt, but what GvR says is accurate. The code base needs a lot of documentation, unit tests, and refactoring before we can even start with updating IDLE. Most of my submitted patches, even the small uncontroversial ones, have sat on the bug tracker. Terry Reedy is doing a heroic job, but I don't think there are enough devs to make IDLE a healthy ecosystem. A few people have talked to me about how IDLE hasn't been very warm to new contributors. It's not outright bad, but we don't take the basic steps to recruit and help out new contributors. There's a lot of work that can (and should, imo) be done with IDLE, but it's a hard project to get involved with. For what it's worth, I'm still willing to take a crack at it.
word-to-the-wise, Python isn't named after a snake. 
Another good one is %reset, which is equivalent to R's "rm(list=ls())" It removes all objects. Very helpful for working with the notebook, making sure a stale variable isn't present.
&gt; The best thing about IDLE is that it uses the existing tkinter module for its GUI. Any replacement of IDLE would have to have the same. Why? It's an option to install tkinter. Why can't you just install PyQt instead? Surely this isn't a binary size issue. Guido said years ago that he wished he added wxpython instead of tkinter. Things can change. &gt; wxPython is the best and most mature cross-platform GUI toolkit, given a number of constraints. The only reason wxPython isn't the standard Python GUI toolkit is that Tkinter was there first. http://www.wxpython.org/quotes.php I think that quote was made in like 2003
No Python3 version looking at the site.
you want to get encoding/decoding working right, but if the rest of your code is very latin-1 dependent, you can try unidecode: https://pypi.python.org/pypi/Unidecode/0.04.18
What a stupid name! Nobody would ever call it that! 
Ack. You're right. They have their [phoenix project](http://wiki.wxpython.org/ProjectPhoenix) supports Python 3, but I'm not sure what its maturity status is.
They have those stats readily available? That is really cool! I wonder if I could find the same thing for the NHL, instead of trying to 'geo'reference them to a rink in ArcGIS. Edit: Less run on sentence
I remember seeing that quote when I picked up wxPython. I was using Python 2.5 at the time. I've stopped using wxPython because they didn't have a Python 3 compatible version. There was an effort to fix this but it seems dead at this point. 
&gt;&gt; After reading your reply and thinking about your response I think I've unfairly judged you, I apologize. Appreciated but not necessary. You are 100% validated in everything you were assuming as that has been my experience with the process of finding a (new) job in this industry for as far back as I can recall... I started back in 4th grade with basic (applesoft basic) and now at age 36, I am still going strong with Python. But professionally I am not a programmer. This is why I approach the entire process differently. I gave up coding in favor of technical writing as I was disgusted at just how poor coverage was to get people up and running with amazing tech. I believe that your tech is only as good as how you present it to others for use/employment. Because of this, I went the route of educator with a love of coding rather than a coder who questions why he is still coding :P Seriously though, burn-out was on the horizon and the transition was an easy one. Here is the funny part. The way you prejudged me as someone who is a hiring lead/mgr is exactly what I get from most engineers/scientists when they see my job title :) So what makes me different...As a writer, I am forced to interface with all users of our products and be able to help solve any disconnect. This means I have to be able to explain simple stuff like what a RESTful API is and how to use it (we build and publish APIs on the fly) all the way to building/training/publishing models (machine learning and natural language processing are at the core of what we do). Not having empathy and patience for how each person learns and adopts new stuff means I fail miserably at my job :P I used to be ruthless with my interviews; this is what happens when you go through interview training at MSFT I suppose. Opening up an interview loop with a whiteboard logic puzzle at 9am? I deserved a throat-punch. Now I take people to grab a coffee or bagel or whatever they would feel is comfort food for the morning and just chat. The thing that most people forget who are doing the interviewing: a candidate is interviewing both you and your employer in the same way you are interviewing them. Anyways, rather than rambling on for ages about this and not landing anywhere concrete; thank you for the kind words and I am really glad that I helped paint a brighter picture of how things can be :) Here is the awesome part...my entire work-family is like this (and we are hiring :)) 
It really depends on what you are looking to do with code. It is also about life priorities. My wife and I decided years ago that we simply were not going to have any children. As a parent, the time you would have spent as 'me time' is now invested in different ways; amazing ways. My friends who are all starting to have kids (I am 36) are starting to realize that they did not give enough thought to children having until it was too late. Regrets? Nope. But I would guess not all of them would have given up their paths for this new one had they known what the changes meant. I personally don't care if someone has worked for 10 years or 30 years in a given field. What you do and how you do what you do is what I care about (the application of your tools and knowledge). I don't even care about degrees for the most part (for the senior machine learning roles that is obviously not the case). You are spot on though about the variance in the traditional approach to hiring that github has created. I like this shake-up. I like that people can spend a year fully-invested in MOOCs, start on projects, and be on-par with many CS graduates anymore. The knowledge bar keeps going up :) 
Definitely. No experienced developers use IDLE. But I can't stress how great it is for beginners to have a simple IDE that comes with Python (on Windows at least). No configuration or dealing with terminal commands (different for each OS). All for a cost of 2 megs, uncompressed. No other language does this, and I think having something like IDLE is one reason why Python is *the* language for beginner to adopt.
Does anyone know when scrapy will support python3? 
Actually, it `eval`s what's inside. So please don't use it in real code, lest you eventually get passed something sinister as the parameters.. :p &gt;&gt;&gt; `exit()`==`os.unlink("everything")`[::-1] **Edit**: actually, I remembered wrong and my test code was wrong too... It is just a deprecated alias for `__repr__`. Sorry!
One of the simpler [google foobar](http://www.google.com/foobar/) problems is to find for a given integer `n` the smallest base `b` in which `n` is a palindrome. There weren't any constraints but I wanted to do it without converting to a string and reversing it. [This is what I came up with.](https://bpaste.net/show/6bd2d4362a01) The strategy is recursive divide and conquer based primarily on the fact that in every base the least significant digit of a palindrome will never be zero.
Could you edit it with proper formatting. You might also want to look at http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html
There actually are 64 characters in the filename. What I was trying to do with the for line in filename was to actually read each line in the file. How would you suggest I do that?
Thank you
Thanks
Thank you
You're using the wrong variable name for the sequence in your `for` loop. That's why you're iterating over the characters in the filename and not the lines in the file. You're using the filename variable instead of the file variable that you just created. P.S. Please edit your question to format the code. Put four spaces in front of every line of code. What is your end goal here, by the way? Do you really just want to count lines for some reason, or is this a test before you do other stuff with the file?
Hopefully the code is formatted correctly now. Sorry about that. The end goal here is not to just count the rows, I tried to simplify it a bit before posting here since the rest of the code seems to work, just only with the first 64 lines. What I am trying to do it read through each line in the file, and based on an IF, it will decide whether or not to write that value to a new file.
This does not work in all cases: &gt;&gt;&gt; def p(n): return `n`==`n`[::-1] ... &gt;&gt;&gt; p(99999999999999999999999999999999999999) False (It would work in Python 3 if it supported the backtick operator.)
Anything from the Pylons/Pyramid project.
Screenshots?
It looks like I am indeed setting up the path mapping incorrectly. I assumed that the local path would be to my local file, and the remote path set to the file I'm using as the remote. The auto-detect path mappings isn't helping, either. Any suggestions? Thank you!
I don't know how much clearer /u/Drakken_LOL and I can make it to you: you are iterating over `filename` instead of iterating over `file`. This is why you are getting 64 results. You are not reading 64 lines from the file and then stopping. You are reading 64 characters from the filename and then stopping because you have reached the end of the filename, which has 64 characters. Add a `print line` statement to the inside of the for loop. What do you see?
You're right. The culprit here is 'L' suffix.
I'm glad that the industry on the whole seems to be breaking away from horseshit brainteasers as interview questions. "How many stairs did you come across in this building while you were on your way to this interview?"? "Prove to me in one minute that you're honest"? *really?*
Is it a confidence test? Like "we want a candidate that can be confident their code is free from errors"? That's all I can think of. 
Oh. I understand now. That's your hello world now you want me to give you 15 errors: 1. Not python 3 compatible. import print from \_\_future__ 2. Writing functions that do one specific thing is a good design strategy; however, when the function returns a literal, just use the literal instead. 3. I wouldn't even bother with checking whether the module is being executed as main and put print('Hello World') at the top level. Your assignment is to print Hello World and therefore the code only needs to reflect that. Use python's execute everything at the first level in a module to your advantage. That's honestly all I can come up with. Resulting code: from __future__ import print print('Hello World')
Is there some bullshit I'm not getting here, like 15 in hex? Binary? It's a test to see if your confident enough to say no?
You can use bitbucket.org to host your code while you await github to be unhidden. 
Yeah, we heard you the first two times you explained the situation.
Done!
There are 16.
Thanks guys. I was able to get it to work by looking at the correct variable and exploring context managers. Thanks again!
IDLE is for IDLERS
There's an option for it in the installer. Besides, the installer adds "Python (command line)" to the start menu anyway.
The stairs one is actually decent, they're looking for you to explain your process for coming up with an answer. Any 'honest' or 'what's your biggest weakness' though are totally useless.
It's not dead, just slow going. Not many developers on it. It's mainly Robin Dunn. See https://www.github.com/wxWidgets/Phoenix
I'm pretty sure there's a way to make an import module return a function so you can just do p(n) instead of p.p(n) and you have an extra space between the ; and the p.p
It's true. This would do it, in a hypothetical `p.py` def my_function(): pass # Edit: Updated to resolve name conflict. n = my_function But that's not very impressive considering he or she actually wrote the logic with one more character!
1. Your code would break if a user updated from Python 2 to Python 3. 2. Python 2 IIRC defaults to ASCII strings; your code would break in an environment that expected UTF-16 or any other encoding not compatible with ASCII. 3. Your example only prints "Hello, world!" in English and offers no support for other languages. 4. Your example requires the user to invoke the Python interpreter explicitly; a shebang would trivially fix this on Unix-like systems without affecting non-Unix systems. 5. Your example requires a Python interpreter to be installed in order to run; an ideal solution would not carry external dependencies. 6. Your solution doesn't offer any way of customizing of the message; if I wanted it to say "Hello, /u/acwaters!", I would have to manually edit the `hello_world` function (and lose the original functionality) or else write my own from scratch. That's all I got, and some of those are a stretch. Honestly, I dislike this question. The *spirit* of it is good, encouraging developers to think critically about their code and to consider edge cases, extensibility, and scalability; but the way it is phrased makes anyone who poses it or answers it properly sound like a pedant. Of the six issues I just mentioned, only 1 and 2 could actually be considered "errors", and even those only by an exceptionally strict reviewer.
I think it's possible to achieve this with following code. def p(n): return `n`==`n`[::-1] import sys sys.modules['p']=p However I don't know what would be exact consequences of overriding sys.modules['p'] inside p module :)
Your idea itself is very good direction I think. Unfortunately my whole solution for these palprimes contained while loop. Since the while loop is compound statement I couldn't have multiple expressions in one line (with semicolons). Of course I've tried other approaches with lambda-fu etc., but solution with the loop was the shortest one I came with :)
elisp comes with an editor, but it's 8 megs and constantly swapping. At least on my PDP.
The datastores.sh now installs postgresql. I plan on adding a discussion on config/usage at some point. Tracked here: https://github.com/donnemartin/dev-setup/issues/1
Why doesn't that work?
CELERYD_TASK_SOFT_TIME_LIMIT is in seconds by the way. Nice tips that I hadn't come across before.
Great stuff! You should put this on github edit: ipython notebook is on github, duh
Look into the [ftfy](https://github.com/LuminosoInsight/python-ftfy) package.
The first one is just storing the result of the == comparation between two numbers into the bool_two variable. Think of it as storing the condition for an if statement. And the second one is just about the same, a comparation between two integers. Remember that comparation operators (==, &gt;, &lt;) are evaluated before the =.
Break it down. The best place to start is the bit right in the middle of the left-hand side -2 In maths, we read this as "minus two" or "negative two", as one number. Python can't do this, it reads it as "two", preceded by "negation". Then, when it starts executing your program, it gets to this value, and proceeds to calculate it - "two, negated" is equal to "minus two". Wrapping something in brackets just says "work out this bit first". In this case, it doesn't make any difference, but it makes things easier to understand. So if we move one stage up, we get this: -(-2) Brackets say "do this bit first", so we should do the bit in brackets first. We know that `-2` is "two, negated", which will become "minus two" when the code is calculated. So what does the outer `-` mean? Well, if `-2` is "two, negated", and we've calculated "two, negated" to equal "minus two", then `-(-2)` is "(two, negated), negated", which is equal to "minus two, negated". Negating a minus number equals a plus number, and we end up with "two". We can keep on doing this, so that -(-(-(-2))) equals "two, negated, negated, negated, negated". If you take the time to work out all of the steps, you end up with -2. I hope this is the right sort of explanation. Check out /r/learnpython for better answers.
if your file isn't too big it is faster (and shorter) to read all lines in one go and count the length of the resulting list: with open(filename) as f: num_lines = len(f.readlines())
Thanks a lot!
Great explanation, I understand it a lot better now. Thanks!
Do some googling for "sql injection vulnerability scanners" i wont help you anymore than that in case you do something dumb.
I am not familiar with the sqlalchemy.func behavior so I can't comment on using MySQLs timestampadd function through it. My first suggestion would be to use the datetime.timedelta to accomplish the same thing in Python: Item.query.filter(Item.created &lt;= (datetime_now + datetime.timedelta(0,1))) 
/r/learnpython is the right subreddit for python questions.
The unit (hour, minute, etc) is stored in the database. So using a built-in SQL function is necessary.
You're right. It doesn't. Python is managed language. It would be very hard to have short code and small memory footprint (to have a cake and eat it ;)
This is pretty cool, I might take a closer look at this some time. I like the use of using a class like a function so you can overload the operators to make new operators in a way. &gt;&gt;&gt; L[1, 2, 3] L[1, 2, 3] &gt;&gt;&gt; my_list = ["a", "b", "c"] &gt;&gt;&gt; L[my_list] L['a', 'b', 'c'] &gt;&gt;&gt; L[(x**2 for x in range(1, 11))] L[1 ... ] Shame we don't have lambdas with more than a single expression. I wonder could this person work their magic to make it happen in a non-super-hacky way?
You need to wrap WEEK in sqlalchemy.text('WEEK'): print sess.query(sa.func.timestampadd(sa.text('WEEK'), 1, dt.datetime.now())) SELECT timestampadd(WEEK, :timestampadd_2, :timestampadd_3) AS timestampadd_1
Oh, Jesus. Thank you. &lt;3
Hey, author here! If you poke around the Hask repo, you'll see pretty quickly that most things are implemented in a super-hacky way. :) I too lament the lack of multi-expression lambdas. One of the things on my to-do list is let expressions, which should provide some of the same functionality. But I'm not sure how pretty the result will look--things could get ugly. 
I have no idea. It just feels like it is a better way to describe your intention to copy a list. But I never really tough about it until now....
It doesn't matter for Flask. With Python there's a very long tail of community packages. Many common ones work with Python 3 but overall you may wish to keep your options open and use Python 2 so you're not restricted. You can't always predict what you'll want to use later on. But if you just want to learn and real world productivity isn't a goal, use whichever.
Somehow it works when I write the singular elements I.E tds[3] but not the whole table
Is there anything else I needed to configure or import before doing what you said? Because I'm getting the message "The SDK seems invalid"
Why would you need to configure PyCharm so it can see any library? "pip install psychopy" will place the code in your site-packages directory and you're flying.
Thanks...great help. I was looking for recommendations of what people consider to be the better beginners guide??
Python can do anything any other programming language can do. It might not be able to go as fast as you want it to, but that's such a small subset of programming. Are you working with data rates of 1 GHz like we are at my company (for one project) and needing to sample 100 channels for 4 hours? It can't do that. The better question is what do you want to do? There are plenty of libraries out there to help you work in Python that give you the speed of another language.
With the Python Launcher it doesn't need to, py -x.y will give the precise version of Python that you want at the interactive prompt.
Honestly, I have nothing to do with programming when it comes to my work. But in the future if I could make some money off of it, that'd be great. But at work I do use Excel and make very basic spreadsheets, so I was hoping to use it to maybe clean them up a bit. I'm not really sure, but I feel like when I learn the ropes I'll understand what I can do much more. Right now I was just going over Syntax errors and doing some small exercises on doing basic calculations. I think the next thing is basic functions I can use like print. Yes, I'm that early in. I need a new hobby that tickles my aging, dusty brain (I'm 27). With this you have to be engaged to learn, so it's a good fit thus far.
Please take my advice, don't hold your breath :)
You'd have to work to not be able to be faster, more clear, and prettier than Excel using Python. You can even do IO on excel files. Using Python makes formulas much easier, but graphing things after the fact will be more difficult since all your data isn't in Excel.
Hmm... what else could I do? Create general programs? Since I'm still in the beginning stages I'm not sure. What are some fundamental programs and scripts that people write now?
[File names](http://wxpython.org/Phoenix/snapshot-builds/) indicate development is going along rather nicely, but I don't think it's been formally released yet. I've drawn a blank looking for a release date, perhaps someone else succeeds where I've failed.
Depends on what you want to do... &gt; Hmm... what else could I do? Create general programs? Again, you can do anything you want that is clearly definable. Here's a [GUI](https://github.com/SteveDoyle2/pynastran/raw/master/pyNastran/gui/qt.png) that I wrote that parses a file that looks like [this](https://raw.githubusercontent.com/SteveDoyle2/pyNastran/master/models/iSat/ISat_Dploy_Sm.dat) It's a horribly complicated file format with 500+ "cards" that follow (and that's just the input file). The point of the code isn't even to make a GUI. It was to interface with the input and output file. The input is ascii. The output is binary that follows again a horrible process. It's 200,000+ lines of code in the project and it's fast.
If you're using Python 3 that could be caused if psychopy hasn't been upgraded from Python 2. However I don't like guessing so could you post the output here so we can take a look. Not that I'll be doing it right now, it's 02:15 here in the UK and I'm going to bed :)
As an interviewer, I would take your claims of how long it took with a grain of salt. What I'd be looking at is code style, organization, documentation, and ability to discuss the project on an ad-hoc basis. FYI for anyone reading your comment.
You should ask this in /r/learnpython next time. You need to return the numbers from your add function. Take another look at the documentation on functions.
Just because he works on it doesn't mean he disagrees. If they ship it with Python it should work to a certain level of expectancy, at least. Based on a quick skim of [idlelib's NEWS.txt](https://hg.python.org/cpython/file/256d5c7146cb/Lib/idlelib/NEWS.txt) it doesn't appear to have received a ton of attention for quite some time outside of mainly closing bugs. Even a good portion of those seem to have been submitted by other people. Unless you can point out some better-than-circumstantial evidence, I'd rather assume that the IDLE maintainers agree with him to at least some extent. Besides, GvR's quote is specifically a response to someone else stating that they want to make IDLE better for education. He seems to be telling *them specifically* that their efforts would be more productively spent elsewhere, not lambasting IDLE in general.
Much agreed. I used to recommend Py2 for people new to Python, but now I recommend 3.x. It doesn't make much sense to learn 2.7 if you're just going to re-learn Python in a few years.
&gt; So you typed out all of those lines? I copy, paste, &amp; modify things a lot, but I wrote most of it. I maybe wrote 3 of the test examples out of the 5500 that I run. Other people help as well. Put it up on github, make it useful, and you'll find people offer to add new features. It didn't start out nearly as good as it is. I've learned a lot about numpy/scipy/vtk/docopt along the way. Given enough time, you can make pretty impressive things with a bit of googling. You don't see the 1000s of mistakes I've made, but a search for oops will pop up more than a few. Start by making something you want. I'd recommend something that isn't GUI based to start out, skim a tutorial to kind of learn what things there are to learn, and start coding. Going through tutorials doesn't give you the same sense of accomplishment, but they're good for filling in the gaps. I still don't know how to prompt the user for an input even after 10 years of Python, but I know I can do it. That's probably like lesson #3. Also, 200k lines isn't a good thing. You don't want a 200k lined project. It can be a nightmare of complexity if you don't have a good organizational structure.
&gt; Prove to me in one minute that you're honest If worded exactly like this, my answer would have been "I'm not." -- paradox (dun dun dun).
How about this for a start.. Since you are already using excel for work, try making a program that reads in your excel, puts the data in some list of dictionaries, or some other data structure, does a little work on it the same as the excel functions you are using, and write out a new xls. Sooner or later some tool will ask you to add 1000 new rows to your xls from some file or another, and you may have your own python tools to get the job done with much less effort. Then maybe put it in a database like SQL instead. Then maybe a web interface for your database... Think about how your data gets into the spreadsheet, can you automate this? The first time you try may take twice as long, the next may take 1/10 the time. My point is try and learn what might be useful for what makes you money right now. In most job environments anyone who can even do a little programing is god like. If you don't believe me check out how much gov entities pay for simple database programming. Enjoy
I'm fairly new to PySpark (~5 months or so) but a long time Python data background. I'm constantly blown away by spark, very cool stuff I'm already seeing out there and I'm convinced it'll explode in popularity once people realize it's not just for ETL work anymore.
And that's why it was removed in Python 3. Also BDFL banned backticks.
Cookiecutter has 96% test coverage across Python 2.7, 3.3, 3.4, and PyPy on OSX, Linux, and Windows. See https://github.com/audreyr/cookiecutter FWIW, we switched from `coveralls` to `codecov` because the former would change test percentages up and down a few points even on documentation commits. :/
Is there anything more cancerous than this for the industry?
&gt;This works because the import machinery is actively enabling this hack, and as its final step pulls the actual module out of sys.modules, after loading it. (This is no accident. The hack was proposed long ago and we decided we liked enough to support it in the import machinery.) ... Wow.
We'd been running Celery in prod with default settings, with no problems so far, but these are good tips. Thanks for these. Are there any advantages or disadvantages to using different brokers (Redis vs. RabbitMQ)?
It prints "Hello World!" instead of "Hello World".
Great idea! This code was created for a tutorial purpose, so I find it more important to match what I'm teaching, than to save myself the extra few seconds and confuse others. That's why I chose to manually enter it and reset it.
["We strongly recommend using Python 2.6 and 2.7 with activated Python 3 warnings during development. "](http://flask.pocoo.org/docs/0.10/advanced_foreword/#the-status-of-python-3) I vaguely remember the author of Flask has had a nightmare over the years in trying to get it to work well with Python 3 due to the way it changed the relationship between text and bytes - a change that makes sense for most applications but is not necessarily an accurate representation of how the web has historically operated. (See his article here: http://lucumr.pocoo.org/2014/5/12/everything-about-unicode/) I wouldn't listen to anybody who suggests you're going to be left behind if you write in Python 2. Not only will your code be fairly easily portable later, but probably the vast majority of apps and developers are still on 2. You won't necessarily know whether you need a 2-only library until you try and install one and find it doesn't work, so there is a bit of a risk there.
&gt; The strategy is recursive divide and conquer based primarily on the fact that in every base the least significant digit of a palindrome will never be zero. I would have never thought of this :/ thanks for posting 
What about PyScripter? It's only a few megabytes and extremely easy to use.
ok i'm more than aware of all the 'sql scanners' like sqlmap and bbqsql for XSS. i'm a pen-tester, so no i'm not going to do anything 'dumb'. What i was asking for was a library that is capable of scraping html after i configure it to edit the URL. in order to detect if a site is vulnerable. I've found BeautifulSoup which i believe is capable of doing what i want anyway.
Have a look at my library hot-redis: https://github.com/stephenmcd/hot-redis - it fits both the small and lesser known bills. It mimics all of the built-in Python data types, as well as a bunch found in the standard library, which results in tons and tons of tiny functions: https://github.com/stephenmcd/hot-redis/blob/master/hot_redis/types.py Given that, it's extremely testable and ended up with more code for tests than for the actual implementation: https://github.com/stephenmcd/hot-redis/blob/master/hot_redis/tests.py It's one of the only projects I've worked on that was actually fun to write tests for. :-)
More output (in the form of [Miliband](https://en.wikipedia.org/wiki/Ed_Miliband)-mashups) here: http://imgur.com/a/3WFTt 
It would be great if (somehow) these wheels could make their way onto PyPi. Then all of those packages could be just a `pip install` away.
I have never heard of such a thing. Wouldn't like 99% of your lines of code probably not use any bandwidth whatsoever?
i think [fn.py](https://github.com/kachayev/fn.py) allows lambdas with an arbitrary amount of inputs.
Hey all, I'm not super familiar with python but a friend of mine thought it would be cool if he could have a program watch his directory for changes, and save a copy of his file to an external drive. Any code comments, suggestions, etc would be extremely helpful. 
Is there a link to this step by step guide ?
true... I am mainly interested in the per function usage but since there are limited (or no) tools anything would do..
Monkey patching read/write socket functions and storing results in a kind of global dict should do the job. Then it would display entries in sorted order by cumulated bandwidth, throughput, or per call. A good use case would be to find if bottlenecks come from the network, disk I/Os, or CPU-intensive computations (could also come from memory contention but it's harder to observe with throughput only metrics). Like any non-sampling (statistical) compiler it would involve an slight overhead, so the user should be warned that many small reads or writes may gain latency. I do not know any project that does this at the moment. Any reference would be welcome.
Most. http://w3techs.com/technologies/details/pl-python/all/all - 99% of the websites measured were on Python 2. https://alexgaynor.net/2014/jan/03/pypi-download-statistics/ - over 90% of PyPi downloads were for Python 2 versions. http://www.i-programmer.info/news/98-languages/8269-python-2-versus-python-3-revisited.html - 68% of devs used Python 2 more than Python 3. Python 3 use is the clear minority.
What are your current ideas? Have your threads send the data to a queue. The queue then outputs to the file. 
It is 2015 and people are still filming things on a tripod-mounted ipad, compress the video and send it over a broken DVI cable to a PAL television and filming the screen on a tape-camcorder before they digitize and upload to Youtube?
Regarding errors, I'll be implementing [Logstash](https://www.elastic.co/products/logstash) once I get that far in my project. Relatively simple to set up and use. 
Using the looping dict way is the best way by far. just make sure your handlng it proprly if "make" is not set ie: if "Brand" in itemdict: item['make'] = itemdict['Brand'] else: item['make'] = False
That looks cool, I'll take a look at the paper later. The OpenCV function seems to be OpenCV version 3 only, which seems to be relatively cutting edge? It doesn't seem to be in my package repository.
SQLAlchemy supports connection pooling by default, that might be sufficient for your needs.
&gt; and workers were unable to write to it so setting a time-out should help ? 
I'll be happy to provide the result, as I would love to gather additional insight. But it is important to note: claims are one thing; facts are quite another. I was asked for the code on Friday and produced it on Monday. I made no claims; I simply produced. Again, while the front end isn't all that pretty, it is designed for the front end designers to expand upon, since it is MVC. And I think the back end is solid, stable, and easy to read. It can even be expandable on the back end. But it is a basic CRUD. It was just a proof of concept of how I code, which I realize must be adjusted from culture to culture.
Beyond what has already been said. - No module docstring, - no function docstring. - no program `__version__` - no use of argparse to display help. - no unit testing. - no documentation next to it I suppose. - it does not have any license and/or copyright - no date or author. - no way to package/publish it - no version control. And yes all that is part of programming. You can get more by comparing this to the Gnu Hello project (http://www.gnu.org/software/hello/) that is "just" meant to print hello world, but does it, as usual in an extreme manner.
OpenCV 3 was officially released on June 4th -- you're probably running the 2.4.X flavor, which most of us still are. 
I can't believe I'm saying this, but you should crank out some faceswap app. Your approach is awesome and people like silly tinkering things like that.
Monkey Patching? Or just subclassing the sockets? #from socket import socket from profiling_socket import socket And I'd think you'd want it be logging to a file so that you can get and analyze the profile information after the program completes. I believe you can get the calling function from the [traceback](https://docs.python.org/2/library/traceback.html) module.
I have to say I love that UI on unbury. Damn beautiful. Thanks for mentioning that. After checking the avalanche results, happy to say that it's equivalent to my results. My calc is definitely less efficient and time consuming (especially when increasing the range), but it was a fun project. And now I know how to generate permutations for a brute force attack &gt;:D 
My project at work already uses quite a lot of functional programming stuff ([pyrsistent](https://pypi.python.org/pypi/pyrsistent), [toolz](https://pypi.python.org/pypi/toolz), [Effect](https://pypi.python.org/pypi/effect), [sumtypes](https://pypi.python.org/pypi/sumtypes), and to some extent even [attrs](https://pypi.python.org/pypi/attrs) is functional-ish)). So I think my team is pretty primed for this kind of thing, but the syntax is _really_ crazy, so I'm not sure I'm going to push it... :)
Not sure what you mean by "inputs", but of course Python lambdas can have multiple inputs: `lambda x, y: x + y`. But yeah, fn.py does have some pretty wacky syntax for creating lambdas with a more terse syntax (similar to the `__` stuff in Hask, IIRC).
You're right, but only because of the name conflict between the module `p` and the function `p`. I updated the example.
Thanks for asking. Here: https://github.com/Permafacture/terminal_windows/issues/6
For loops, you can use list comprehensions, map, filter, and (most powerfully) reduce. For conditionals, you can use conditional expressions: `foo if bar else baz`.
I am the author. :-)
I have for a bit, and am trying to write a replacement.
Wow, I am really out of the loop when it comes to the FP-in-Python ecosystem. PyMonad is a really solid library. Lots of interesting ideas in there, including do-notation, which I have yet to come up with a satisfactory solution for in Hask. I suspect there is some yet-undiscovered cleverness that could provide a nicer interface. Another issue that PyMonad sort of skirts around (and which I do not yet have a solution for) is polymorphism for things like `mzero`, and return type polymorphism more generally.
Came here to say something along those lines but with the added acknowledgement that sometimes being able to work your way through a problem with your own process makes it easier to accept and adopt the solution :). For reasonably simple setups like this I've never had too much of a problem because at some point I figured out that "a dollar that's paid against a debt of x% prevents that dollars-worth of debt from accruing interest at that rate, so applying money toward the highest interest rate is the most efficient way to do it" but at the same time I've gone to great lengths to model variations on that theme over the years because sometimes there's more to it than simple mathematical efficiency. For instance when you've got some debts with variable interest rates, or different compounding strategies to consider, or mushy-life-based considerations like monthly cash-flow (if paying off a low-interest loan frees up $200 a month to do other things with, and you want to make sure that if your old beater takes a dump you can afford to add a car loan into the mix, for instance), then it can be worth modeling different approaches. 
Open CMD, type "pip install psychopy", I have a PATH for python. And that works. But yea, pip easy install is only for 3.x versions of python.
Short direct reply to your question: unicodetext.encode("utf-8") Longer reply: it depends on what you are doing with the text. Do you write it to your standard output in the console? Find out what encoding your console supports and use that. Do you write it to a file? Chose an encoding to your liking. etc. Probably the simplest and most important concept to remember is: outside world bytes (file, web, network, ...) | +-&gt; .decode('whatever encoding it is in') | +-&gt; unicode, handled by your python program logic | +-&gt; .encode('encoding you want') | +-&gt; outside world bytes (file, console print, ...) In any case, try to spend some time learning the basics of unicode and character encodings and how Python deals with them. Some pointers may be found here: https://www.reddit.com/r/Python/comments/1g62eh/explain_it_like_im_five_python_and_unicode/ Probably the most important general one (not tied to Python): http://www.joelonsoftware.com/articles/Unicode.html There's a big change in how this stuff is done since Python 3.0 (for a good reason). The first link has many details on this.
Subclassing if you explicitly use standard socket library. Monkey patching if you use higher level libraries (such as boto.s3) or protocol (HTTP). That's what [gevent](https://github.com/gevent/gevent/blob/master/gevent/monkey.py) does to prevent sockets from blocking (the greenlet cooperatively yields instead to let another greenlet run). For the output why not taking inspiration from the profile module?
I'm not quite sure what's gone wrong there, but that did lead me to find [a related bug.](https://github.com/billpmurphy/hask/issues/5) Should be fixed soon.
Not at all. How will learning after a couple of months or years would help when you have same problem. You could look at beautiful soup library which does Web scraping.. Idk how will that get you an alert for new content but you can check it out 
This really isn't an infinite list, just a data structure with a pointer to itself. He was confused by the way it gets printed. Frankly the way it gets printed is fairly confusing. I suspect they decided to express a loop using ... before the Elipsis object got added to the language. In [1]: [1, [...], 2] Out[1]: [1, [Ellipsis], 2]
Well structurally infinite if you will. Old books called that syntactic recursion.
Wow, what's a timing! Anyway I really enjoy the project I always want to learn haskell and this will make it a lot easier!
Doing something like this with Python would be pretty straightforward, but it seems that you're wanting the ends, not the means. Have you checked out services like http://www.watchthatpage.com/ ?
The step-by-step guide is in the PDF &amp; EPUB versions of the new book. More general Python web app deployment information can be found on http://www.fullstackpython.com/.
Speaking as someone for who Python was pretty much their first introduction to programming on their own, IDLE was a godsend. I could do everything I wanted to do right after I downloaded and installed Python. I have since outgrown it, but I think it is a valuable thing to have. 
It should be pretty forward to do that with Python, though almost any programming language would allow you to that. You should try to think about it in a high-level manner, and then implement it with the features of the language you select. The problem you describe can be solved by storing a list of the known job ads, periodically reading from the web the ads and comparing them to the stored ones to check it there is a new one, and if there is then e-mail it to you. This script detects the references for the jobappforms of the link you referenced: import urllib.request from html.parser import HTMLParser website = "http://rocklandgov.com/departments/personnel/civil-service-examinations/open-competitive-examination-announcements/" class myHTMLParser(HTMLParser): def __init__(self): super().__init__() self.jobappforms = [] def handle_starttag(self, tag, attrs): for i in attrs: for j in i: if "jobappform" in j: self.jobappforms.append(j) with urllib.request.urlopen(website) as response: html = response.read().decode("utf-8") myparser = myHTMLParser() myparser.feed(html) for i in myparser.jobappforms: print("{}".format(i)) You can keep developing on top of it to provide the features you want.
And not only that, but the Timsort algorithm has a recently discovered bug in it, one that Python will not experience on current machines: http://www.envisage-project.eu/proving-android-java-and-python-sorting-algorithm-is-broken-and-how-to-fix-it/
Scrape every hour. If there are updates, email them home.
Syntax highlighting. Auto-indenting. Copy-pasting. IDLE has its uses.
Alt+P. IDLE's dicky, but it's super minimal and free. Nothing wrong with that.
None of that changes the fact that something already works in tk, and everyone's familiar with. Why spend time developing an IDE to replace IDLE, and waste core dev time getting it into the main distro, when people who care that much just choose their own IDE anyway? It's not like there's a shortage; PTVS, PyDev, PyCharm, vim, emacs, Notepad++, VS Code...
Or, [Unbury.me](http://unbury.me/).
Its incomplete but here it is. I hashed out the close() at the bottom to check it on idle and it works fine/won't save but on PyCharm as soon as the program finished even if the close() was completely removed the .txt file is altered as if it was closed. dictList = [] choice = None taskList = open("/_PythonClass/Mod5/Todo.txt","r+") for task in taskList: tsk, pri = task.rsplit(",") dict = {tsk:pri} dictList.append(dict) ''' print(tsk) print(pri) print(dicc) print(dictList) ''' print("*-------------------------------------*") print("| Task Master v1.0 |") print("*-------------------------------------*") while choice != "3": print("\n") print("0 - Display Tasks") print("1 - Add Task") print("2 - Remove Task") print("3 - Save And Exit") choice = input("&gt;&gt; ") if choice == "0": for dict in dictList: print(dict) elif choice == "1": tsk = input("What is the new task? ") pri = input("What is its priority level? ") dict = {tsk:pri} dictList.append(dict) taskList.write(tsk + "," + pri + "\n") elif choice == "2": for taskRow in dictList: print(taskRow) deltsk = input("What task would you like to remove? ") for dic in dictList: if deltsk in dic: del dictList[dictList.index(dic)] #taskList.write(str(diclst)) print("Task removed.") taskList.seek(0) for taskRow in dictList: print(taskRow) elif choice == "3": break else: print("ERROR COMMAND NOT RECOGNIZED.") #taskList.close() print("\nSaved.") 
Why are you opening it as "r+" if you don't want to write to it?
I do plan on writing in it, I was attempting to make a save and a don't save feature but I noticed when I when I exited the program bypassing the .close() - don't save- it saved anyway. I have been under the impression that .close() was necessary to save, but that only seems true for IDLE. 
In python2, input(promt) is (I think) the same as eval(raw_input(prompt)) That means that what the user types will be interpreted in the context of your program, by the same interpreter. That's **very bad**. Treat the user's data as data, not instructions. To get a hint of why it's bad, import sys in your program, and type "sys.exit()" as the number.
Sure, but you're not ready for it yet. When you are processing a structure of data, where there are pieces that look similar at every place. The classic example is a tree. def eat_leaves(branch): if branch.at_leaf(): eat_leaf(branch) else: for subbranch in branch: eat_leaves(subbranch) eat_leaves(trunk) That will eat every leaf on a tree.
When you understand every line in that gist, you'll know a lot.
Sure. How can I send it to you? It uses Schoenburgs matrix generation techniques as the basis for notes, and then transforms them and adds time using a number of other generic techniques for defining random ranges of certain parameters. Then it spits everything out as midi files. So far I have made 6 songs with it. 
No, that only happens when you open with a with statement. Calling .write() is poor form but it should't write to the file. I don't have this issue in IDLE or the terminal.
I'm not sure what your setup is, but I just tested in the terminal this code: f = open("test.txt", "r+") f.write("Bla bla") exit() It does write to the file, even without a close() or a with statement. There's a [post on stackoverflow](https://stackoverflow.com/questions/7395542/is-explicitly-closing-files-important) explaining more in details when the close() is called by python. 
IDLE does kinda suck...I'd be happy seeing Spyder as the default IDE. I'd bundle it as an "executable" built using PyInstaller or something, so you don't have external library issues.
Could you explain multiple expression lambdas?
Also, principal.
You're being dishonest by not even linking the [newest docs](http://flask.pocoo.org/docs/dev/python3/#recommendations)
something like this took me about 2 months to do. Starting from the beginning learning to code. I took my time learning, put in about 1-2 hours a day.
Tell me who starts projects in 2.7 without need and I'll come and have a long, stern talk to them.
This, seriously, we can make it work. 
I don't think it has a name as such. /u/Saedeas has posted a good explanation of the formula in the /r/programming thread: http://www.reddit.com/r/programming/comments/3f591x/so_i_wrote_a_script_that_swaps_peoples_faces_in/ctmfnwo?context=1
I'm the author of this tool. I'm happy to answer any questions.
Close doesn't save anything. The file can be considered written when `write` is called -- the `.close()` function just flushes the output buffer and releases the file lock. The reason it works like you'd expect it to in IDLE is probably how file pointers are handled by the C-based process. Writes will queue the buffer but not commit until the close is called. However, when you run Python in PyCharm you're running the process from within the IDE, which pretty much removes all guarantees on streams and buffers; this is especially true when run in debug mode as your entire process is ran from within a server container for breakpoints. This behavior will also be inconsistent between Windows and Linux based versions of PyCharm and shouldn't be expected to guarantee a "do not save these changes" type feature.
You can't use statements so the following aren't allowed. # Variables being declared lambda x: y = x + 4 return x + y # Loops lambda x: for i in range(10): print(x) # Multiple expressions lambda x: print("Printing x: {}".format(x)) a = x ** 2 return x + a That kind of stuff. It's not great as you cannot set up other variables, use statements or do more than one expression. There are likely other issues but I don't know a huge amount of FP, just enough to do the basics with `map` and `reduce` etc.
&gt; No, that only happens when you open with a with statement. No. A file object is implicitly closed when it's garbage collected, which in CPython is when its refcount falls to 0 (which may or may not happen on process termination, incidentally). &gt; Calling .write() is poor form but it should't write to the file. You're high as a kite. `write` is not a transactional operation, `write` will or will not write to the file depending on the IO layer's buffering configuration. In fact its docstrings spells exactly that: due to buffering the on-disk version *may* not contain written data before a `flush()` or `close()`, it doesn't say *will not*, and the expectation certainly isn't that `.write` mustn't write data to files, especially given you can run Python itself in unbuffered mode. Which is exactly what PyCharm does by default (http://i.imgur.com/mZvDH6O.png) Your code is intrinsically broken, PyCharm merely demonstrates it. If you don't want a file to be written to, don't write to it, and don't make up fantasy reasons why your broken code should work. And if you have no idea how things work, check the documentation, don't make it up.
&gt; not sure why it only occurs with pyCharm thoughâ€¦ Because /u/gabe_cant_python's code is completely broken and by default PyCharm runs scripts unbuffered (http://i.imgur.com/mZvDH6O.png) which exposes the issue
What is the airspeed velocity of an unladen swallow?
Yeah , I can understand your point . its just becasue of permissions you can additionally pass ` --user` with pip to install as user 
So that's what p^T means :l
That's pretty cool charts. I've already seen some neat things in LaTeX or whatever but looking at this, I think I'm going to get a deeper Python knowledge. It's a language that looks more and more useful!
No idea. It'd be different per site.
Yes essentially what I said
Is there a particular reason you left out the cheeks?
Hardly. 0.10 is the current version and the page I linked was from there. The page you list there may well have been written more recently but I'd never seen it before.
Amazing, perfect going away present for a beer loving colleague who is about to move abroad.
I would like to see a copy too, if you don't mind (seva17@gmail.com).
Wrote this as a bit of fun. I'll be adding more features to it as I explore the Imgur API a bit and suchlike, figured could use some feedback though and ideas for features. This is a very, very, early version with only the one feature I happened to want at the time :)
I'm currently making something similar, can I ask you which modules you used for midi generation?
As of a year ago, the opinion of /u/mitsuhiko (the author of Flask) was: [I would recommend nobody to use [my libraries] on [Python 3] if they can also use them on 2.x.](https://news.ycombinator.com/item?id=7799917) I wonder if this is still the case?
They reference this GvR keynote. https://www.youtube.com/watch?v=yCg3EMf9EYI&amp;t=510 
Update - I now have a stdlib only version because I went to the pub and thought "maybe I should revisit urllib. I had a bad time with it once, but maybe its improved?".
He's done this for code golf, and not to save memory. Python is also the wrong language for code golf. :-)
0.10 is the latest â€œstableâ€ version, but pretty old itself. Even the dev docs I linked are old (they still don't contain my fixes from spring)
Approximately 25 miles/hour. I should have been more specific in my comment. I'm happy to answer any questions about this project. :)
&gt; if u can comment what evey line does I would appreciate it... haha, no... 
You probably want to assume this person has no idea what you just said.. Also the invalid syntax error hints to him trying to enter this into a python shell
I'd never noticed the `parse` module before, and it looks pretty handy, so thanks for that. What were the reasons you didn't end up using it?
MIDIUtil, Which works great on either mac or PC on python 3. I think it works on 2 also.
That sounds pretty cool, but is it somewhat generic in it's outputs? I was hoping to work with someone who develops fairly unique animations.
&gt; sara.and.zuka@gmail.com Sent you a zipped bundle. The license info is in the "How to" file. The file was sent from an outlook.com email, so watch your junk folders.
&gt; seva17@gmail.com Sent you a zipped bundle. The license info is in the "How to" file. The file was sent from an outlook.com email, so watch your junk folders.
Output is up to whoever designs the animation. Which, looking at the rest of the comments, might have to be you. API docs to help you: http://www.blender.org/api/blender_python_api_2_75_3/bpy.ops.graph.html (look for `bpy.ops.graph.sound_bake()`) plus general [Blender API docs](http://www.blender.org/api/blender_python_api_2_75_3/) and [tutorial](https://www.youtube.com/watch?v=V3fRrvs7hM4) on doing it like any other animation without the API
I personally find [PEP 8](https://www.python.org/dev/peps/pep-0008/) to be liberating precisely because it means I do not have to think about these issues. Usually writing a program on my own I will try to adopt the dominant style of the language (K&amp;R for C, for instance). In fact, C++'s lack of an accepted style convention always bothered me because I didn't know what to do, which is why I tend to default to the STL naming and style conventions when working on my own. When working with others, though, it is important to yield to the prevailing convention. It is kind of infuriating, and I am not sure there is an easy way to get around it. Linters or style converters like Go's lint are not an option because you are inevitably gonna be making line edits within source files you didn't write. To be fair, if you are using two-space indents and camelCase variables, you will find that most Python developers will be using a different style from yours. It may be time to start drinking the PEP 8 Kool-Aid! But yeah... in general... seeing code that doesn't jive with your personal style is a fact of life. Best not to let it get under your skin!
I feel your pain, however with time you get used to whichever style you use most often. For this reason it's worth getting used to PEP8 as it's the closest thing to a 'standard' we have... generally anywhere with a good consistent house code style will use PEP8 or something close to it 
Configuring your editor to lint PEP8 style + setting up precommit hooks to run flake8, autopep8, and other easy auto fixes on commit (i recommend checking out http://pre-commit.com ) handles most of this for me. I don't think about it or feel too strongly about line lengths or indents. 
Glad to see that the thing that annoys GvR also annoys me, packaging. 
"Internet hug." **LOL**. I know how it feels. There must be a tool to automatically translate 2 spaces indentation into 4 spaces. If there isn't it's easy to develop. A command line program. Look on github. About the 120 char lines, idk how such translation could be done. 120 char lines is definitely a dumb decision. There's plenty of articles about that. How ~80 chars are the best length to read. Code is worse! Harder to read! Code should obey the 80 chars rule more than anything else.
Any textual summary?
Phew glad I am not alone :) I will 4-space but I don't have to like it!
Never doubt Python; It can do anything. 
You might like sysdig It's like the tcpdump for system calls and does so much more. http://www.sysdig.org/
Things should be optionally complex, not optionally simple, if they're to be a user's first interaction with a thing.
Honestly I'd avoid Windows 10! At least until it is stable and has proven itself. That could be years from now. 
Awesome talk!
&gt; Things should be optionally complex, not optionally simple, Potato, potato. If we agree to use Spyder, and we agree it's overly complicated for a beginner, the simple mode can be the default, even though Spyder itself is by default the more complicated version. By making a simple version of Spyder with optional complexity that is distributed with Python, you're still creating an optionally simple IDE where the default is simple. The difference in how I think about it lies in what came first; the complex version.
Have you ever walked into a restaurant, looked at the menu, and taken 5 minutes to actually understand any of the words? Newbies have that when they come to things. IDLE is a fantastic interface. It's literally just a blank syntax-highlighted box with a REPL. You can put Spyder, or PTVS, or PyDev, or whatever you want, in as standard, but what's that quote again? "The standard library is where code goes to die"?
Don't put it in the standard library? Just make a stupid "executable" and update the installer periodically. This is a solvable problem. Tkinter is not part of the standard library, yet IDLE uses it. Tkinter is tacked on by default for Windows, but not Linux.
Sigh, I know, I started programming python with people who all worked for the same company, one that enforces 2-space, which is totally the reason that I am used to it. Time marches on, and so must my spacing.
But "Unicode is kind of insane" is a better headline ;)
Great, thanks!
I just started to use the bokeh module, and I love it. It's imo the best module to plot data in python. It's super simple and you can create interactive and live graphs that will be rendered in every browser. Also it looks good and modern out of the box.
Whomever downvoted you is a mindless idiot. Win10 hasn't been around long enough to assure that older python packages work. So advising that one waits for a while is good advice. Do people seriously expect everything to work without a hitch every new OS? There are always hiccups. And there may be an annoying bug in PySerial that is being triggered in a Win10 environment.
Well, first I don't know how to use github, and second, I'm not sure how I feel about putting it completely into the wild. I don't think I'll ever make money on it, but I have other reasons. You can PM me your email and I'll send you the zip bundle. My goals here weren't so much to showcase my code, but rather to try to find an animator to work with.
Agreed. Also, the functional aspects let you sidestep a lot of the complexity of design patterns. Python ain't Java. Still, it's really useful to see all the patterns here. Borg, for example, is a cool Python-specific pattern that I hadn't seen before.
Mainly, it was because I was working on a project where 3rd party packages needed to be reviewed, and I knew that process would take longer than I would've wanted to wait. The `parse` module certainly does a lot more than my simple example does, but I didn't need any of the additional features.
Maybe you should have written better VBA as majority of the tasks outlined can easily be done in a few lines of VBA.
To this day, I still don't understand why spaces are preferred (for indentation) over `\t`. If you use tabs, can't you just set how they display in your editor and then everyone is happy? To be clear, this isn't an incredulous "I don't understand" this is genuine. If there's a reason why spaces are better than tabs, I'd like to be educated.
I beg to differ. It's pretty simple syntax, verbose yes but not messy. 