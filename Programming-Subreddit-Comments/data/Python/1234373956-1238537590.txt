So you are one of the downvoters? You are even perhaps the one who down voted me. Personally I don't care. But I do want to read everybody, and you are preventing me from that.
Today, I tried several times to access it but I couldn't 
There is a simpler way, though little ugly: placeholders = ','.join(['?'] * len(args)) sql = 'select * from table where key in (%s)' % placeholders conn.execute(sql, args) 
It looks like the site is back up.
[RPy](http://rpy.sourceforge.net/)?
IronPython is slow. Actually it is not entirely slow but the startup time is an embarrassment. It kills IronPython for me for doing .NET scripting or using it with Silverlight etc. I would to lose credibility if I'd recommend IronPython and people had to wait 5-10 seconds for a console to start or a script to run.
I did some thing similar a while back with weather station temperature and found it awfully slow.
No, I'm not a downvoter. You asked a question, and I answered it. Personally you do care, otherwise you would not be asking why you are being downvoted, and then replying to the answer to your question. You can read comments that are downvoted below your threshold by clicking the "+" next to the text "Comment score below threshold"
Ok. You win.
How is this relevant to Python?
I do love python like the rest of the redditors, but indexing is mostly io bound (if you use a decent algorithm like B+tree) I don't see what's so surprising about being *pure-python* in this case.
How about: new = [x for x in old]
Seems slow and cumbersome.
Really, slow? Surely any list copying routine will be O(n) anyway, no? I personally like it much better than new = old[:], and slightly better than list(old), which I don't find very pythonic. 
 % python -m timeit 'a = range(0, 1000)' 'b = a[:]' 10000 loops, best of 3: 27.2 usec per loop % python -m timeit 'a = range(0, 1000)' 'b = list(a)' 10000 loops, best of 3: 30.2 usec per loop % python -m timeit 'a = range(0, 1000)' 'b = [x for x in a]' 10000 loops, best of 3: 124 usec per loop Not that it matters but ok ;p
I'm pretty sure nobody looking at your code really cares whether you use the list() or list[:] idiom to copy a list. At least I don't. But I'd probably balk at the list comprehension style though; for no apparent reason other than I don't ever do it that way. That said, a quick test: * $ python -m timeit "[ x for x in range(0, 1200) ]" == 10000 loops, best of 3: 138 usec per loop * $ python -m timeit "list(range(0, 1200))" == 10000 loops, best of 3: 40.4 usec per loop * $ python -m timeit "range(0, 1200)[:]" == 10000 loops, best of 3: 38.9 usec per loop 
Surely indeed, but in the real world there's a difference between O(n) and O(1000n).
Fair enough -- it proves to be slower. And I agree that probably no one really cares. 
&gt; Prime example of why testing is always needed. Or a good working knowledge of how the various language constructs measure up against each other performance-wise (so that you don't run into mistakes like using a regular expression when the only match you care about is at the beginning or end of a string, for example).
[:] is more pythonic :-)
Coding a lot where speed does matter, and thus doing a lot of profiling, do help with the ability to judge the speed of a piece of code. A decent understanding of what is going on "under the hood" does help too. That doesn't mean that I never get surprised. It isn't strange to make a qualified guess about the speed of a piece of code from it syntax. Even though the compiler (or interpreter) often make some kind of higher order magic, there is certainly a correlation between the higher order syntax and the instructions generated. In this case it is quite trivial to guess that it would take longer to loop over the list than just copy big chunks of memory. Of course, in this case, the interpreter could have reduced the loop to copying huge chunks of memory, but only if the author of the interpreter would have thought and cared about the possibility that someone would use such a cumbersome way to copy a list when there is many more trivial ways. 
casting a list to a list seems unintuitive, and might be expected to return the argument rather than copying it. perhaps the right way is something like: a = [1, 2, 3] import copy b = copy.copy(a)
I see this mistake a lot. O(n) says nothing about 'speed'. It says something about the running time in relation to the input size. Given two O(n) algorithms X and Y, X can very well be a gazillion times slower than Y. The only thing you can deduce from O(n) is that if X or Y take 100 seconds for 1 element, it will take 200 seconds for 2 elements, etc. In other words, it says more about the scalability of the algorithm than the speed.
i gotta agree. there a lot of python idioms that look strange at first blush (list comprehensions anyone?) and this method of copying a list is one of them. but once you familiarize yourself with it, it makes sense. the author's main point seems to be about readability. i find the [:] to be very readable and concise. 
And if ones simulations take hours or days, there is even a very substantial difference between n and 2n.
So this article is promoting that we shouldn't learn noob Python programmers anything they don't already know? Slicing is a core Python concept, and Python programmers should learn it. If a programmer understands that l[:] means 'a slice from the beginning to the end', he'll probably be able to infer he'll get a complete copy of the list. Rather they ask early on "hey, what's this brackety-thingy supposed to do then?"
It's not a cast though - its a constructor. It seems pretty natural to me: `MyClass(args)` creates a new instance of class MyClass using the args, so obviously `list(args)` creates a new instance of the list type based on the args. When the arguments are a sequence, whether an existing list or some other type, that's what gets used to create it.
There are cases where [:] is preferable though. It has the advantage that it is usually type preserving. Obviously for tuples and strings, this is irrelevant (there's never a need to copy these unless its to convert them to some mutable type), but if a user passes in a custom list class, it can be valuable to preserve this in the return value, while returning lists for lists. Obviously this can be bad too - if you rely on the functionality of a *real* list (mutability etc), you may want it to definitely be that type.
Agree !
what the heck? Thats not the right way, imho. For this kind of things there is the [copy module](http://docs.python.org/library/copy.html) with two important functions: &gt; copy(x) &gt; Shallow copy operation on arbitrary Python objects. &gt; &gt; deepcopy(x, memo=None, _nil=[]) &gt; Deep copy operation on arbitrary Python objects. *batteries included*
Hopefully this release gets delayed by a day, (Valentines), and then 3.0.1 can be "the Python release for Lovers" instead of "the bad luck Python release" (Friday the 13th). 
Well in my case, it means it'll make it easier to integrate into my Python projects. Even though there are already good attempts at using things like Lucene/Solr and Sphinx with Django, I've come across issues that are quite frankly difficult for me to deal with because I'm not as accustomed to dealing with those sorts of issues with those languages, but with whoosh I can just drop it in my PYTHONPATH and use it right away.
&gt; Thats not the right way, imho. Well your humble opinion is completely wrong then.
Fun stuff: on my machine, bumping the upper limit of the range to 10000 or 100000 makes `list` come out ahead of the slice (but the behavior's the one you displayed for 1000)
Just fyi: python has true strong typing, that is, python has no casts. At all.
&gt;i find the [:] to be very readable and concise. very concise. Almost perlish.
Nope. He's right. [:] is good for simple lists. The copy module is highly recommended for anything beyond that. If you make a nested list (e.g 2-D array): A=[[1, 2, 3], [4, 5, 6]] and use either list() or [:] to copy it, and then modify A so that instead of the number 3, you have the number 10, then your copy will also be modified - and that's usually unintentional. The copy module - using deepcopy, is the way to copy the list. 
I think the fact that Python is very readable by non-Pythonistas is a strong argument in favour of the language. [:] detracts (slightly) from that readability.
everytime I hear someone speaking about "pythonic" shit I want to punch him in the face, you guys really suck.
I like the suggestion, not because of the "pythonic" idea (which is only in your fanboi imagination) but because [:] looks like crap. oh and you program in python have the decency to at least learn its syntax, not knowing what [:] means is no excuse and even less reason to not use it.
A light has just gone off in my head, I finally understand Big O Notation. Thank you. 
&gt; The copy module - using deepcopy, is the way to copy the list. On the other hand, as any experienced Python developer knows, "import copy" is almost always a sign of code smell. If you think you need to copy stuff, chances are that there's a better way to do it.
you're right more(functions(would(be(pythonic()))))
No one really cares? We are talking about 3x slower... and I don't even agree list comprehensions are more legible here. It is also just not true that no one cares, see [why google displays only 10 search results](http://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20.html).
How does this compare to [Sphinx](http://sphinxsearch.com)?
So there is this random guy coming up and telling the world that this is more pythonic than that with some "this syntax is unreadable" statement about one of python's most important syntax elements. Let me just give a classic comeback: http://www.youtube.com/watch?v=QsogswrH6ck
&gt; If you wrote this with .setdefault(), you would be creating and then throwing away a SomeClass object every time the key had already been seen before, churning memory in the process. His other setdefault example creates and throws away list objects. Display syntax creates objects too... In modern Python, the **defaultdict** class in the collections module is usually a better choice than setdefault. In older Python, try/except or explicit testing can be more efficient (which one depends on the "hit rate" for the specific use case - try/except is cheap if the rate is high, explicit testing if the rate is low). (And btw, "setdefault" is pronounced "get or set". I thought all Pythoneers knew that...)
Yeah same. Why don't people just explain it like that to begin with?
this article is so **depricated, haha..** &gt;.&gt; Seriously, arguing about which language is best is so 5-10 years ago...
They have also raised the response deadline to 30 seconds, which is good. Had a few problems with that recently. 
author can't spell, haha.
"Java is useless because it's verbose"? Seriously, who writes this dreck? I love Python as much as the next guy, but what the hell!
I normally don't bitch about spelling, but in this case it's especially egregious. The term _deprecated_ is practically a keyword in Java; it's difficult to find a package in the JDK that doesn't feature _some_ deprecated feature. What's next: bitching about c's swetch statement? How about python's cPackle module? Assembly programmers use regishtars, am I right?
PHP's *register_globes* option is especially unlikeable.
They have a limit on simultaneous active requests, isn't scaling about breaking that limit? So does that "scales like mad" claim still stand?
&gt; Seriously, who writes this dreck? More problematically, who upvotes it?
Hey, acting like that is unpythonic :\
AFAIK you still can't pay for more quota. Presumably the simultaneous active request limit will be raised or removed once you can pay for it? I think the idea is that the model can scale, but they're not willing to give you unlimited access to their hardware just yet. 
some people who've worked hard to learn difficult things often feel that "other people don't deserve simple explanations". They feel everybody should spend as much time as they have before being allowed to grasp things. Some other people are just too smart to understand that other people don't get it as easily as they did, or they're too smart to explain it in a simple way. Often people also forget that tiny piece of the puzzle that gave them their "Eureka!" moment, and fail to teach other people that crucial little piece.
&gt;We are talking about 3x slower... and I don't even agree list comprehensions are more legible here. True, but we're talking about *u*secs here. The Google example you cite is talking about .5 *seconds*. As for the legible bit, that's subjective, of course... 
Same here, fing strange. Python 2.5.1.
I strongly agree that this *looks* like casting. Using list() will not help any beginner but only make them more confused.
&gt; obviously list(args) creates a new instance Not obvious at all. list() does return a new object, but str() doesn't. WTF?? (Yes, I know why it does this, but you wouldn't immediately guess this if you were new to python.)
Not necessarily strange, `list` might have a slightly better scaling but a slightly bigger constant factor.
Strange because I assumed that [:] is special-cased by the compiler and all it has to do is make a copy. I don't see how that could have a smaller constant factor.
&gt;you wouldn't immediately guess this if you were new to python. There's no reason you'd need guess it if you're new to python though - there's no situation beyond actual `id()` or `is` testing where str() creating a new object is distinguishable from reusing an existing reference. A python implementation would be perfectly valid if it *does* always return a new object (indeed, cpython will do this depending how the string is built) - only the fact that not doing so won't change behaviour in any way allows the optimisation to be taken.
There is a nice under that post: [Blub paradox](http://blog.appenginefan.com/2009/02/blub-paradox.html)
be afraid, be very afraid. hahahahaha.=
Orange selection colour??? How can anyone read this (I presume everyone reads while highlighting paragraphs)?
At suggestion of commenter I updated the walkthrough to use virtualenv for sandboxing each project/domain. May take an hour for my lazy caching to actually show that version however... ;/
``chsh`` (or even ``EDITOR=emacs vipw``) instead of editing the ``/etc/passwd`` file directly. I also use the %sudo group instead of will (in /etc/sudoers) and let only members of this group ssh in. ``listen_addresses = &lt;empty list&gt;`` disables the PostgreSQL TCP listener on *any* interface; that removes the possibility of being exploited in the listener code. Commenting all host lines in ``pg_hba.conf`` keeps it listening, just denying all attempts after trying to authenticate. The same goes for Apache: you can have it listen on 127.0.0.1:80 and nginx listening on $EXTERNAL:80. I use NameVirtualHost $IP:80 as well, because that way I can choose on which virtual-IP a certain vhost will be available. Follow the tips on ``mod_wsgi``'s page about having a virgin virtualenv for the whole of Apache. And since you're doing virtualenv, why not use pip -E &lt;domain&gt; install &lt;package&gt; as well? You don't really need the egg's ability for multiple versions, since you have a virtualenv for each project: you'll be using one version only.
These are good tips, and I've updated the tutorial to reflect the ones that I understand (do you have a site I can link back to for credit?). Some questions: 1. AFAIK postgres isn't listening on an external port, so it shouldn't be susceptible to external attacks. Am I incorrect? Are you suggesting that an internal user could attack it, so having any listeners is a vulnerability? 2. I considered going with the virgin virtualenv for all of Apache. Do you see an advantage over my current approach of discarding the default deployment's path? (Taken from further down the same page ;) 3. Err. I've never used pip. I will look into it. :/ 4. If you have more tips, I'll update the article with as many as you have. :)
Very cool, this was the tutorial that helped me setup Django on Ubuntu among others for the first time. Bookmarked this one for reading
Hi, some tips: 0. /usr/bin/editor is a symlink to /etc/alternatives/editor, which itself can be configured to set your favorite editor 1. (step 8/11) it's always a good idea to stay logged in until you're sure the newly created account can log in. Especially when changing ssh configuration etc. Usually, connections are not disconnected when restarting ssh. Should there be any error in your config, you won't be locked out of your system that way. 2. (step 10) ssh-copy-id saves some effort here 3. (step 12) it's git-core, not gitcore. libc6-dev is included in build-essential dependencies 4. (step 13) instead of `sudo su postgres -c psql` you can type `sudo -u postgres psql` 5. (step 14) instead of `sudo python setup.py install` maybe mention `sudo checkinstall python set.py install` here. This makes removal easier, as it ties into the package management 6. (step 15) you didn't install curl in your tutorial! wget is a dependency of `ubuntu-standard`, though. 7. (step 16) there's no package `apache` in intrepid. see `apache2` 8. (step 19) you can specify groups on chown like this: `chown user:group filename` 9. 
meh, I'm just lighttpd+django+postgresql+fastcgi+gentoo myself... nginx and apache... seems a little nuts :P
I prefer to run nginx with fcgi django modules running.
Credit? There's a 'permalink' button on each comment.
Hmm. Doing some performance testing on the setup from above, somewhat surprisingly (for me) it has a throughput of 50 requests per second on 256 meg VPS. Each hit includes one Postgres access to load the page. Compared to my mod_python experience this is fairly impressive. Have to admit I've never run numbers on lighttpd+fcgi or nginx+fcgi, and would be curious to see them.
Don't even try to make an acronym for this.
a newbie question, what about Ubuntu 8.04? did Ubuntu 8.04 work fine for this step by step tut? 
ADMMNPU? MMADPUN? 
Your useradd, mkdir, chsh, chown, visudo should be replaced with: useradd -m -g admin -s /bin/bash django 
This might look complicated but don't worry. If you don't want to set all this up but you want to try out Django, then you can try it out online via Google App Engine (if you don't mind using a service provided by the evil empire), or any of a number of other web hosting services that will set up the environment for you. Then once you have gotten the hang of it, and experimented writing some simple applications, you can then decide if its worth continuing with it. If so, then you can have a go at setting up the environment on your own and configuring it specifically for your needs. This is when this guide might come in useful. 
You are completely correct about PostgreSQL; I was mistaken, don't know where I got the idea that ``listen_addresses`` defaulted to * (it actually defaults to ``localhost``). I was thinking of external threats, not internal. You're not really worried about local users, right? I've also done this: LogFormat "%{X-Forwarded-For}i %v:%p %h %l %u %t \"%r\" %&gt;s %b \"%{Referer}i\" \"%{User-Agent}i\"" LogLevel warn ErrorLog /var/log/apache2/error.log TransferLog /var/log/apache2/access.log That's my ``/etc/apache2/httpd.conf``, included by the master apache2.conf file. ``TransferLog`` uses the most recent unnamed ``LogFormat``, and then you can choose if you need a separate access.log for each vhost (thereby doing just ``TransferLog /vhost/logs/access.log``) or if you can live with a global access.log. Ubuntu comes with an ``a2ensite`` command, right? I mean, these are great: * a2enmod * a2ensite * a2dismod * a2dissite A quick pip example: ``pip -E /var/www/trac.company.com install trac``. This won't give you an insane sys.path full of eggs, and ``/var/www/trac.company.com`` is a standard virtualenv (the ``--no-site-packages`` kind). I further ``easy_install -ZU setuptools``, because I'm using the ``virtualenv`` provided by Debian (which uses the outdated system ``setuptools``). Then I un-egg setuptools by moving the .egg contents to .../site-packages and renaming the resulting EGG-INFO folder. ``pip freeze`` might be useful to you, since you mention freezing requirements when deploying. I wasn't sure about the hello.wsgi code, but now that I've tested it, it puts the virtualenv site-packages in front of the path. I had ``apt-get install python-trac`` for one project and deployed trac inside a virtualenv (all hail pip!), but mod_wsgi was using the global Python and had the wrong sys.path even after I used ``WSGIDaemonProcess python-path /var/www/trac.company.com``. The only "problem" is that I'd prefer my .wsgi file to be ignorant of any deployment details, as per the Java idea of .war files. I'm the one who should be crediting you, for bringing the bottom of mod-wsgi:VirtualEnvironments to my attention in a different light; thank you! EDIT: I've removed the "provide more tips" from my reply above. Didn't mean to come off as a know-it-all, and you easily erased my cockishness by actually knowing it all. :)
&gt; maybe mention sudo checkinstall python set.py install here. This makes removal easier, as it ties into the package management Thank you for that tip! &gt; Usually, connections are not discarded when restarting ssh. You say "usually". Have you been bitten the same way I was? I had a RH8 machine in need of an SSH upgrade (That One SSH Bug), so I put a new copy of the binary listening on 9022. The ``service ssh restart``: * invoked ``kill-daemon`` IIRC, * which reads ``/var/run/ssh.pid`` * happily ignore the PID it read * invoking ``killall sshd`` I wasn't impressed.
What are your numbers for Apache+mod_wsgi+django+postgres? PS: I've been meaning to ask "Why nginx?" in front of Apache too.
Ah ok, maybe there's really a difference between how distros do that. I only know Debian/Ubuntu :) Well after all, it doesn't hurt to spawn a new terminal to try if new logins work, when your old connection still lives
I'm personally just asking Why Apache? lighttpd kicks it's ass, so does nginx, pick one of them instead.
I've written things like that. :P
I did mention RH8, right? Ancient by Linux standards (you over there with the CDC3600 manual can stop snickering Right Now!). Notice how I didn't mention ``service ssh restart`` actually completed: the killall sshd murdered the its own controlling terminal as well :)
Because of mod_wsgi, which approximates the idea of a long-running container of apps; and apache is a great HTTP server (or at least better than the Python HTTP servers). So, if I see the need for a real HTTP server as dogma, I need an integration library (WSGI comes to the rescue). What other solution do I have?
Nobody likes OCaml.
So what does this do that SCons doesn't?
&gt; Jython follows java rules, which means there is no support for multiple inheritance as you would do in CPython This is incorrect; if multiple inheritance was forbidden in Jython, a lot of popular Python software (which works on Jython) wouldn't work on Jython.
So that is why I'm still waiting for a native Linux version of Chrome. 
swtoolkit is: &gt; A set of extensions to the open-source SCons build tool (www.scons.org) 
&gt;For the second year running Python has been selected as the Language of the Year in the 2008 LinuxQuestions.org Members Awards. Will they finally stop voting for Language of the Year 2008 now that it's 2009?
via: http://plope.com/Members/chrism/zope.pipeline
http://xapian.wordpress.com/2009/02/12/xapian-performance-comparision-with-whoosh/
It's not as well-documented or mature, but there is a [mod\_wsgi](http://wiki.codemongers.com/NginxNgxWSGIModule) for nginx.
Java classes in Jython are still Java classes and as such do not support multiple inheritance. Python classes, on the other hand..
"Using assert immediately kicks you out of the program on failure." No it doesn't - unittest catches the AssertionError and marks that test as a failure. If you're going to comment on reddit, at least make sure... no wait..
Less contrived example: turn "foo:bar:baz" into "baz:bar:foo". "foo:bar:baz".split(":").reverse().join(":") # logical join ':', reverse split /:/, 'foo:bar:baz' # also logical, and valid perl ":".join("foo:bar:baz".split(":").reverse()) # python The first two are orderly progressions, albeit in opposite directions. The third is function salad.
Definitely a better example. I'm not sure if this was your intent, but the inclusion of the non-OO version (which by its nature will be the exact reverse of the logical OO version, or is here at any rate) seems to help highlight how foreign that looks in Python where it's a jumbled up version of the other two. Perl is actually my primary language, so I really wish I'd thought of that myself.
I can't imagine what sort of "significant administrative overhead" you're referring to. Installing it? Oh noes! The API interface isn't fantastic, but it's pretty usable, and xappy makes it better.
Need to hack the setup.py to get it to compile on Mac OS X -- Even so, I'm having problems getting the boost:python dylib to compile properly, so I get dynamic link errors on import. Grabbing the latest arch linux image and will give it a go on there. Looks exciting anyway!
I imagine Richard's post was inspired by some copy on the Whoosh home page, which originally stated that performance was "comparable" to Xapian. That text has since been removed, as the Whoosh author rightly realised that setting Whoosh up as a competitor to Xapian wasn't particularly helpful.
Sweet
There is a python binding for recoll, a Qt desktop search engine based on Xapian that you can make do whatever you want (extend) with the python binding. recoll also ships with a set of scripts for indexing a large number of file format (starting pdf2txt, those kind of tools), give it a try.
Nice to extend the slowest of build tools.
Whenever I program something, the storage methods I usually use are (in order of complexity) flat-file, sqlite, mysql/pgsql. Can someone please explain to me where Tokyo Cabinet is the most appropriate solution to their problem, or where it fits in my list? (I honestly do not know, I am not trying to be condescending) 
A few additional explanations would be nice. How does `engine.eval("hello()")` work? Is the Python source translated to JS? What can be translated? etc. 
&gt;Why does engine.eval("hello()") work? I haven't examined the code but from the way most scripting interfaces work, what's happening is that when you call `hello()` the interpreter calls back to the native python code and executes the hello method in python. If you see the sample code, there's this line: &gt;&gt;&gt; engine = PyV8.Engine(Global()) So what's probably happening here is that the v8 engine is being initialized with an instance of the Global object (which is a live object instance python). You could, in this way, use javascript to execute any python code you wish to expose to it. I have to say though, I don't see much utility in putting a *different* scripting engine into a python app unless it's for the specific purpose of testing javascript code.
via: http://ironpython-urls.blogspot.com/2009/02/introduction-to-wpf-with-ironpython.html
That would be a lot cleaner as a Mercurial extension than as an ad-hoc parser for the git output.
Just be aware that the preferred method to document Python 3.x source is [Sphinx](http://sphinx.pocoo.org/), not PyDoc anymore.
I don't see a benefit in eliminating manual commits of work... Commits have a logical grouping of some sort, such as work on a single feature, or fixing a specific bug, or whatever. Being able to track those commits and, especially, revert them easily, saves way more time and effort in the long run than not having to type "git commit -a" whenever you're done working on something. Also, what if you're doing design work and editing a master CSS file every 2 minutes for 4 hours? That file wouldn't get committed until the very end even though there are likely many changes that warranted an actual commit.
Awesome, I was just thinking about this last week. At work we have nerf fights every week and I was trying to figure out how to use the usb missile launchers to auto-target people. I'll need to dig into python a bit more, but I imagine I could hook up a webcam, and come with an application that displays the feed along with targets for either launcher. It would be manually controlled though as I haven't a clue how to to auto-targetting (but that would be awesome).
Would work much better as an extension for you text editor (emacs?) that would do a commit on every save. Edit: As posted before, if you edit a file every 2 minutes, it will miss a few revisions, and if you are editing it, you could be halfway through typing something when it commits. I guess one could make an extension for your editor of choice that runs the command on every save or whatnot, though.
Woot! I have one of these at home, can't wait to get off work.
I got a pair of these from the same Woot sale. Currently sitting on top of my speakers, pointing menacingly at whomever dares to walk through the door.
This doesn't work on Linux, does it? Looking at the source code, with my basic Python knowledge, I'd have to say it doesn't.
Why Picon? What about Tauron, or Caprica? Oh, PyCon, right. Carry on.
Python + OpenGL = great to prototype or more. It's so much easier and faster to code with python than with C/C++.
&gt; git.el is not part of GNU Emacs but resides in the emacs contrib’s section of the Git distribution in contrib/emacs http://www.emacswiki.org/emacs/Git
Virtualbox maybe...
Why do people insist on things like apache+mod_python or apache+mod_wsgi? Sounds very slow and like a huge waste of memory to me. I currently run lighttpd and fastcgi on my setup, but recently I read some article that made me think about even that - why fastcgi? Why all these hops and conversions of requests into different intermediate formats? Then I did some benchmarking with lighttpd in front, proxying all dynamic requests to a pure-python webserver (cherrypy's wsgi webserver is amazing). In my tests I got massive speedups. I still need to write it up nicely and publish all the code, but if you just think about it you will realise it makes complete sense. I also wrote a wrapper to run multiple cherrypy servers embedding my app on different ports (8001, 8002, 8003, 8004, etc) and lighttpd basically round-robins (or whatever) between them. I'm sure you can do the same with nginx and I would love to benchmark that to compare the difference. Anyway.. my guess is this multi-process, multi-threaded hybrid approach should give better performance on a multi-core system than just one cherrypy process, but haven't had time to benchmark it extensively yet. It should help to get around python's GIL and all that. (btw, this setup is similar to nginx+mongrel or thin in rails-land. Go read up on the motivations behind that for more opinions) Point is, proxying dynamic (django or whatever) requests from a modern lightweight webserver like lighttpd or nginx to a pure-python webserver over plain old http uses much less memory (less than half in my case), allows you to handle many more concurrent requests and also gives you much better performance because of much lower overhead (I got more than double the amount of requests per second on simple hello world tests designed to just test overhead). And you still have lots of room for fine-tuning.
This is not as much for code, but for documents where things don't usually break up as easily. I think the idea was to get something lighter as well.
Or Wine, maybe. But the point is that it's almost useless to me. Been done better elsewhere where it works in Linux.
I am the author of Concurrence. It is now also able to run on plain Python + Greenlets.
I use Netbeans EA with CPython; from my experience it's a *decent* IDE. I hope that in the final release they fix annoyances such as: * many debugger problems (can't step out, can't break on some lines, can't get a list of all BPs, exceptions kill the debugger, etc) * no VS key mappings (WingIDE gets this). Customizing the keys by hand is horrible, you have to search in a tree control for each key. * unit test support doesn't work (If I add a tests dir in the project options it disappears when I choose OK and the test menus are disabled). * PyLint support doesn't do anything. * Can't add tasks by hand, it just searches for TODOs and such in the source code Last but not least, I'd appreciate it if they released more often and kept a more accurate progress report. From what I understand, they have added more features and fixed quite a few bugs, but you have to compile NB yourself if you want the latest version.
What kind of name is netbeans?
I think the idea is for it not to act as traditional source code control, but to provide a timeline of changes. Committing on every change is not necessary for this.
Show us the code...
I've extricated myself out of those problems by running one of the continuous build out of their Continuous Integration server: http://deadlock.netbeans.org/hudson/job/python/ I'm running #640 (what a number...), and I have a good unittest runner (basically you need to inherit from ``unittest.TestCase`` *anywhere* and the runner will find it). Also, I have coverage (bit rough on the edges). Debugger? Haven't tested it.
Very instructive.
Dulwich isn't really a village, any more It's a posh area in a grim part of south london, trivia fans http://en.wikipedia.org/wiki/Dulwich
Best part: &gt; Dulwich is developed in Bazaar at the moment, but a Git mirror is also available.
Thanks for the link, I think I'll try one of the latest builds and see how things go.
Yeah I found that a bit weird
agreed. very odd.
What's wrong with bc?
PythonOCC wraps the very impressive OpenCASCADE CAD kernel, therefore allowing you to develop high performance CAD apps in a very short time
Been useing this for years because of it's simplicity. However, anything complicated I use qualculate.
Wots dat?
Kinda reminds me of Java's catch or specify.
well, maybe the author just wants better interoperability with git froma bzr point of view (hear hear mercurialists!)
Good luck; from what I can see, there are always pitfalls when running -HEAD. It's not a stable IDE, but you can work in it. It's mostly annoyances, but it works pretty good compared to my VS 2005.
After adding parens to make sense of that mess, my answer is also no. Is (Is Ruby Better Than Python) Better Than (Is Python Better Than Ruby)?
I prefer vim. Oh wait, this is not about editors
&gt; my answer is also no. Hit refresh.
Having used both, I will say that Python is more mature and has better documentation. Ruby has more of a learning curve, but could be more powerful is better than perl is better than awk sed grep sort uniq
I can't believe people pay 10 bucks for a domain name just so that they can do this. Still funny.
i imagine this is kinda slow ... ?
There are several issues with this method. I don't see how it was obvious to do it this way... First of all, your benchmark is rigged. The range_code would naturally be 0 in most cases because the high-order bits of *lower* and *upper* are likely to be different in most cases. The reason it doesn't appear that way in your benchmark is because of this code: a = random.randrange(1&lt;&lt;30) b = a+random.randrange(1&lt;&lt;20) code = range_code(a,b) You're forcing a and b to have the same high order bit. Try: a = random.randrange(1&lt;&lt;30) b = random.randrange(1&lt;&lt;30) if a &gt; b: tmp = a a = b b = tmp code = range_code(a,b) That'll give you a truly random range and you'll see that your method has no benefit. It gives the same performance as without range codes. If you know, however, that the higher order bits will stay constant in practice for your needs, or your ranges will stay narrow, you can actually use a simpler method and just record that higher order bits as your range_code. Basically your method is overcomplicating things. Interval trees are still the best method for what you want. Unfortunately, there are few implementations and you often can't easily use existing red-black tree code because it modifies the essential data structures and algorithms.
Another note: if you abandon the sqlite requirement, you can probably just use [PostgreSQL's seg module](http://www.postgresql.org/docs/current/static/seg.html). It uses a special GiST index that I'd imagine looks a lot like interval trees, but I'm not completely sure, since I've never used it.
In fact, the engine object will bind an implicit context with a global object; so, the "hello()" calling will be redirected to the object that you pass as global object. &gt;&gt;&gt; engine = PyV8.Engine(Global()) &gt;&gt;&gt; engine.eval("hello()") It means, the previous expressions will same to "Global().hello()". The purpose is to make a bridge between javascript and python objects, and we could easy simulate a DOM tree with python class, and access it from javascript, vice versa. You could check the unit test in PyV8.py for more detail.
sorry, I haven't Mac OS X environment; so, could you submit your error message to the issues? Maybe we could find some guys to fix it later :) http://code.google.com/p/pyv8/issues/list
Sorry, Randall.
To me, the real joy is that they have an [svn directory full of Python interpretor crashers](http://svn.python.org/view/python/trunk/Lib/test/crashers/).
Dammit, I am absolutely going to miss this. On the bright side, I'll be in England and python development will be (still) paying my bills.
I really wanted to use this tool but my project at work is an ASP.NET web app and this tool didn't handle the viewstate, so my webapp kept failing. No problem, it's python, and pretty darn clean python at that, so I popped open the source and coded a quick hotfix to persist the viewstate across requests and now I have a nice open source load testing tool that works for me. Love this tool. Mark
Django 1.0 hit the release target date bang on the nose. Django 1.1 looks set to ship one month later than planned.
Django 1.0 required an incredible commitment on the part of some of the core developers, I know Malcolm and Jacob practically worked day and night on it to make it happen, it's unreasonable to expect that type of sheer time commitment from the developers for each and every release cycle.
Moving on. That's old news. 
All of those crashes are fairly harmless. [Here's](http://bugs.python.org/issue1856) one that's been really annoying me lately.
Ah, I hate that one too. I wouldn't call these harmless though. A (what I'm pretty sure is a) recursion error in a third party library keeps bringing down a major service of mine. This thing loads over a million items from the database when it starts and takes as much as half an hour to get running again. Huge pain! Anyone know the hard limit or recursion depth for amd64 linux in cpython?
1000 is the default for Cpython regardless of CPU afaik
Not default, I mean maximum hard limit before segfaulting is possible.
A single mention on an idiot's blog now counts as preferred.
Upmodded for being "non-GST"
I'm still running from `hg tip` and see no reason to change that anytime soon.
I wouldn't go to Chicago for thatg
How do I know if I'm "Corporate/Government" or "Hobbyist"? If I go, I'd be paying my own way. But, I am one of those making noise in my division to switch all higher level software tools from C/C++/Perl to Python and building multiple proof of concept designs. Am I pro, or am I noob?
diacritical
[Mock objects.](http://www.thesoundarchive.com/play-wav-files.asp?sound=simpsons/misc/haha.wav)
in rpython
There's an error in the code. One of his comments reads: # This evaluates it's argument and calls it's continuation without it. It should be "its" not "it's" in this context. Otherwise, it's all nice self-documenting code.
paying your own way says hobbyist to me, this is an honor system sort of thing and that doesn't seem the least bit dishonorable, especially if the higher rate would keep you from participation
That's some mighty nasty javascript that pypy generates. Then again, it generates javascript from python code, which is kinda cool.
If you're paying your own way, go "hobbyist". (if on the other hand you can get your corp. to pay your way, help the PSF out and go "Corporate")
That's quite possibly the worst python code I've ever seen. You do realize haskell / lisp etc is faster than python - why make python bend over to use their paradigms
actually, I'm used to just hearing "diactitics".
Ew. Why not just write your javascript game in, you know, javascript? Or, for an even cooler hack, write your javascript game as a python interpreter, then write your actual gameplay in python. Also, release your interpreter open source. Thanks.
 &gt; Or, for an even cooler hack, write your javascript game as a python interpreter, then write your actual gameplay in python. Think about that. I doubt an interpreter for Python could be implemented in Javascript successfully. And regardless, it'd be dreadfully slow.
For a very powerful but rather underdocumented memory tracing system, have a look at Guppy-PE. Here's an intro I like: http://www.pkgcore.org/trac/pkgcore/doc/dev-notes/heapy.rst A typical use scenario for web apps is: start your app, put it in a known initialized state, take a snapshot, do your request and then compare current object state with the snapshot. Then you can look at any new objects and find any that are not really supposed to be there and who is referencing them. 
The trouble with this is that the usual reason for stripping diacritical marks from text is because you're using some kind of non-Unicode-safe storage or transport medium, and stripping diacritical marks doesn't help with other common non-ASCII characters like € or curly quotes.
And it looks like the author still can't decide whether it's called Pydev, PyDev or pydev.
*tl;dr*: I don't know how to install and configure stuff. It's too hard. Make it easier. Also: I don't seem to be able to configure MoinMoin and this is Python's problem! I say that Django and Turbogears are easier to setup, but hey, Python's problem nevertheless! I don't seem to see any difference between web framework and web application. Oh, and I don't want to do anything by myself, it should be provided. KTHXBAI! Also: Php instead of PHP, python instead of Python.
It's turing complete, if you can use pypy to write a python interpreter, it's at least theoretically possible to do it in JS. And dreadfully slow depends a lot on how exactly it works. Javascript engines are getting very fast these days.
Footnote: Normalization was added in 2.3. If you're stuck using an older version, or wants to handle things like Æ or Ð, or use non-standard decompositions (e.g. mapping Ä to AE), you can use the approach outlined here: http://effbot.org/zone/unicode-convert.htm
I think it should be consistent with JDT, and CDT, and just be called PDT
PyKE : http://pyke.sourceforge.net/
Pretty cool.
There's also an article series on this subject here: http://lethain.com/entry/2007/dec/04/two-faced-django-part-1-building-project-exists-si/
it seems to be a lot like memcachedb, but with a couple of extra features.
This is ridiculously easy. If you were writing a minilanguage I expect the next step would be to create a state object and then wade through the list of tokens to modify the state. I expect there are smart ways of doing that though - ? For example - I suppose you could wrap this in a SAX interface, and then use XSLT to to steer it. 
You could. I wouldn't.
Sorry, mistyped. Its actually called LEPL.
So that it'll crash more often on the Mac? So that it can be destroyed along with Gnome when the almighty Microsoft patent shitstorm arrives? Yeah, good thinking.
this, for once, it's an interesting post on pyreddit. I suppose you could do the same using re.sub with callables as replacements but of coursem that way is an ugly hack the way presented on this article is the it should be. anyone knows why it is undocumented? or some more info about how reliable it is? EDIT: found something here http://mail.python.org/pipermail/python-dev/2003-April/035070.html
&gt; I expect the next step would be to create a state object and then wade through the list of tokens to modify the state. You'd probably want to parse it first: turn the flat list of tokens into a tree of expressions. An AST is much easier to work with than a stream of tokens.
Scroll down to the "Assignments" to download the papers and solutions.
That's what pypy does. It can compile the whole Python interpreter (pypy is rpython) to the supported targets.
Lovely. At this point, with CPython's generator support, what's the advantage of stackless Python?
That is awesome, actually, I was not aware of that. Apparently I fail at python.
I'm not much of a fan of XSLT either, but I admire the functionality it achieve - a language which is designed solely for transformation of trees. You can train people as stylesheet technicians without needing to teach them a lot of nuts and bolts programming stuff they don't need. Is there anything mainstream outside of the XML world that achieves equivalent functionality against a tree? 
I've never used lexx, but how useful/fast would using this be compared to using lexx?
I wish I could take this class :-(
Saved and Rapidshared. http://rapidshare.com/files/201025520/compiler.rar (n.b. if someone from the university doesn't like me doing this, send me a pm and I'll take it down)
Agreed. I've only read the first section but it's clear the guy behind this really knows that he's talking about. When I went to university I got the distinct impression none of my lecturers had any real idea what they were teaching.
Thanks for the comment. I've just updated the custom lexer with the following: * Fixed the way input is passed in * Fixed the flags variable (how did I miss this, really?) * Implemented optional callbacks
The course _is_ available for distant learning: http://caete.colorado.edu/coursedb/view-course/310
People who have 100% code coverage aren't making software people use.
I'm a bit confused by the code. Is there any reason for InputScanner to be declared locally in the scan method? also, you assign 'self.lexer' but then use 'lexer' directly later. Why not make that class external and take 'lexer' and 'input' as a parameter in __init__, that way scan would be just "return InputScanner(self, input)". Other than that, nice article.
 &gt; Why not make that class external and take 'lexer' and 'input' as a parameter in init, that way scan would be just "return InputScanner(self, input)". Because that would be too easy. (lol) Ok, so I wrote that addition to the code at 4:30 in the morning, and now I've updated it with your suggestion, which makes much more sense than the way I had been doing it. Thanks.
Hah! The post is mildly amusing, but isn't about code coverage at all.
Picture or it didn't happen.
Yeah, I'm really not willing to download anything graphical without checking out screenshots first
Yeah.
*especially* since it's the "GUI of your dreams".
I decided to try it out anyway. Here's his example programs: [Example 1](http://s5.tinypic.com/2nb5c09.jpg) [Example 2](http://i44.tinypic.com/2d5c93.png) [Example 3](http://i44.tinypic.com/23lfbbr.png) I had to install setuptools, then Cellulose because cellulose is only available as a .egg (you have to use the easy install.exe in the python25/scripts/ folder if anyone is unfamiliar with easy_install as I was) I already had pygame installed. Edit: I have previously used some GUI toolkit that seems like its more polished than this, I think it was probably pgu which anyone who is interested in this is probably already aware of
impressive, Does anyone know any open source dynamic graph visualization tool like Ubigraph?
Here are some hints from an [earlier discussion](http://www.reddit.com/r/programming/comments/6jwh3/ubigraph_free_dynamic_graph_visualization/c0424tc) on this: There's [Paraview](http://www.paraview.org/) (based on the [VTK library](http://www.vtk.org/)), [OpenDX](http://www.opendx.org/) (apparently discontinued since 2007) and for fast 2D-drawing there's [Pmw.Blt](http://heim.ifi.uio.no/~hpl/Pmw.Blt/doc/). Similar to Ubigraph, there's [Graphviz](http://www.graphviz.org/), which is only 2D and doesn't seem to accept live interaction like the Ubigraph server, but it's open source. Apparently, someone already did a Twitter analysis using Python &amp; Graphviz: [Twitter activity in the US](http://www.youtube.com/watch?v=xrFjN92Swi8) | [HD version for the whole globe](http://www.vimeo.com/1690380).
Meh, I'd want this for Element Trees.
Where'd you go to university?
Processing has some physics libs for force directed graphs.
I can be inpressed by the code and the effort, but at the end of it all it's just another graph/network. I just don't find these visualisation useful, they don't scale. As soon as a major network hub is encountered, it clutters the space. Bravo for the effort though.
Queensland University of Technology, Gardens Point campus. I don't have a lot to compare it to, but frankly I felt I didn't learn a hell of a lot about programming there. (Did a Bachelor of IT, majoring in Software Engineering and Data Communications)
So apparently the Python web site calls people who translate perl modules "authors"? Wow. I wonder how python real authors (the ones who actually write original code, I assume there are some) feel about being lumped together with people who are monkey-scraping CPAN. 
Thanks for the effort.
Don't be so literal.
I though Matlab was the swiss army for almost all research subjects...
This looks very interesting. It's nice to see a unique package combining many algorithms &amp; techniques for Machine Learning and NN's in one place, very comprehensive. Without looking at the source I would be interested to see how speed is acheived (is it pure python/psyco/numpy etc or are you wrapping eg. C/C++ underneath for training &amp; updating the nn's). Many thanks for bringing this out - it looks like a lot of work has gone into it .. I am downloading it now...
I don't know, I pretty much fell back asswards into it, but what I've seen work for other people: Network like you would in any industry. Go to pycon if you can, there's a ton of networking and recruiting there. Be active in local python and related groups. Get a little exposure and a thicker portfolio by working on open source projects and starting a blog about what you do.
Try the [python job board]( http://www.python.org/community/jobs/ ). 
http://www.yelp.com/jobs#softwareEngineer
Fix the typos. I couldn't make it though the first paragraph.
Post your resume on: python.specialtyjobmarkets.com
ahh! my eyes
Thanks so much for the link - this could be incredibly helpful for combining with my Python GA for my thesis research.
Looks great, a project with a clear description, a simple demo, and a clean architecture that looks like it ought to work. The only thing missing are testimonials from real users. 
Uh-oh.... Everyone be on the lookout for PyZombies.
That seems like a really bad idea that I might have to try out.
Twill is cool but Selenium does everything that Twill does and more. And Titus doesn't pay a whole lot of attention to Twill these days. Test with Selenium because the support is waaay better. ** edit ** Also check out [PureTest](http://www.minq.se/products/puretest/)
Most of the stuff is pure python. If you want speed, there is a C++ core that is more of a hassle to install, but worth the effort if you really need it. Also check out the google group: http://groups.google.de/group/pybrain
warning: if you've never used Time Machine, do note that it's fairly slow, and it only worsens. And it worsens *fast*. edit: downmods, really, so the 10-15mn preparation and finishing times I get when Time Machining 15MB (w/o the backuping of those 15MB) are figments of my overactive imagination?
Doesn't Selenium test the browser? I never understood why people do that, as if just calling the URL or the API wasn't enough...
It's strange -- it seems to have evolution strategies and competitive coevolution, but (according to the features page) not a simple GA?
Basically, he's trying to give people using GoogleAppEngine the ability to open some files without getting write access, so he's made a locked down version of the file object. Can you break it?
Yes, but without the knife.
Just be good at your job, then you can choose what technology to use. If Python is the best tool for the job, use it. Be good at your job and people will trust you to make the correct choice. Also, get involved in an open source project, then if you don't get to use Python at work you still get to use it. You can mimic a lot of Python in other languages (so long as { and } don't strike fear into your soul)... You could always port the open flash chart python library to a Python web framework for me :) write some tutorials and examples and stuff.
As a cat, I must weigh in. Your grammar and spelling are atrocious.
Actually his end game is to be able to give people a template language like genshi(which uses Python bytecodes) and have it render sandboxed, because right now if you passed a function that returned some data to the template(so the user could have that data) they'd be able to get into the cell contents of it and pull out say the DB connection.
Please, show me a poor man with a $1,200 mac.
You've obviously never visited the visual arts department of your college.
There's work on [Twill again](http://code.google.com/p/twill/updates/list) these days. There's also a sprint planned at PyCon. In my experience, twill for the bulk of the functional testing + Selenium for javascript works. Twill is so much faster than Selenium it's not even funny. It gets to the point where you don't even want to run the Selenium tests because they take so long.
Didn't read the article, just the headline. However I think I have the "basic" understanding of the challenge. I would make the room as cold as possible by disguising myself as a heating technician and sabotaging their thermostat. Meanwhile, my associate, disguised as a heat rock salesman, shows off his wares, and installs "promotional" heat rocks in the far corner underneath the python security desk. You see, pythons are reptiles, and ectothermic. When it's too cold they seek heat sources or restrict movement. Their fatal flaw. At exactly 3pm, the air starts pumping. The higher the temperature the python security guard sets the thermostat, the lower the temperature goes. As it gets colder still, he abandons his post, and coils on top of the heat rock. This allows me to sneak past security to steal the snake gold from their reptile vault. They'll never know what hit them. Only problem is I have to get out of town. Probably someplace cold ...
Is there a way to reset it to the current state or do I need to reformat the external backup drive?
All New! Now you can pay money to deploy your forked GoogJango™!
Doesn't pretty much all that apply to Turbogears as well? As far as framework Turbogears and Pylons are very similar and share many of the same pieces. So how does Pylons stand out as opposed to Turbogears?
yet another repost....
AFAIK Turbogears will be using Pylons in its next version... So, Turbogears is Pylons plus some extra stuff. 
I am not a TurboGears dev, obviously, but... As I understand it, the plan is that TG2 will be built on top of Pylons: it'll use Pylons' infrastructure as the foundation, and make some default component choices on top of that, along with integration code and utilities. The defaults will still be just defaults (as, technically, they are in pretty much any Python framework -- so long as you don't mind losing some level of integration stuff and utilities built on the default choices, you can always just use whatever stuff you like), but I can see that providing a useful baseline target for application developers.
Djoogle?
I should have said Djangostien™
meow *paws at the keyboard*
English, motherfucker. Do you speak it?
Most of the hippies and liberal arts majors who are broke still manage to have a mac on their desks, somehow.
... that was the point.
at last !
Djerwelcome
&gt; We're psyched to announce that developers can now purchase additional computing resources on App Engine (..) Google really is different, they're psyched making you pay. You gotta love Barney's style. &gt; You can now set a daily budget for your app that represents the maximum amount you're willing to pay for computing resources each day. So now I need each day to think about how much resources I may need. How is this sustainable on a daily basis? I would understand on a monthly basis but daily... overwhelming.
If a GET to your URL returns some HTML, how do you check that this bit of HTML is correct?* How do you test it works as expected in various browsers? Selenium helps you do just that. \* Please tell me you don't parse the HTML for a specific value.
Nice. Wondering how it compares with Axon/Kamaelia.
Are you calling logging.shutdown()?
Setting a per-day budget doesn't mean you have to change it every day.
It seems like Time Machine could be replicated, and replicated much faster, with a good VCS backing it - git, mercurial, SVN, whatever. Thoughts?
Time Machine is an incremental backup solution. As that it's geared towards high amounts of data (hundred of megabytes to gigabytes) (note: it's not that good a backup solution either, but it has the advantage of being simple to use and well integrated into the finder), which is why it degrades badly to small amounts of changes (a few megabytes) with big lead-ins and closures. VCS are exactly the opposite, and I'm not sure they'd respond well to full-scale backups. On the other hand, VCS are a very good idea to backup specific parts of your FS: `/etc` and the textual stuff in `~` are very commonly put under version control, and some people even use those VCS to keep several machines in sync.
or your could... \#!/usr/bin/python import datetime td = datetime.timedelta(seconds=100) print td 
I use a testing framework that calls the page generation API directly instead of simulating a click in the web browser. 
Wow, I didn't know timedeleta's `__str__` was that cool. It doesn't do weeks/years though, only goes up to days :/
Yeah but years have leap years, meaning your delta is now specific to a given year's worth of days. Same problem with months (28, 30 or 31 days?). Weeks is just "td.days / 7" + the odd days remainder.
&gt; Briefly, AOP is about separating out Aspects which are are interspersed throughout your code (in AOP lingo, cross-cutting). This explains about as much as "Briefly, bajiggling is about separating out Joulsies which are interspersed throughout your code (in bajiggling lingo, zoobilating)."
So you're not testing the browser's behavior then. That's fine but totally different.
Guess you all missed that they are dropping the "free" bandwidth quota to 1GB and are limiting total downloads for free apps at 56 MByte/min and paid apps to 740 MByte/min Here is more bad news stuffed at the very bottom of the announcement: App Engine will always remain free to get started. However, along with many performance improvements, we have learned that we were overly conservative with our initial free quota estimates. Therefore, 90 days after February 24th, 2009, we will be reducing the free quota resources. We believe these new levels will continue to serve a reasonably efficient application around 5 million page views per month, completely free. The new quota levels, which will take effect on May 25th, 2009, are: * CPU Time: 6.5 hours of CPU time per day * Bandwidth: 1 Gigabyte of data transferred in and out of the application per day * Stored Data &amp; Email Recipients: these quotas will remain unchanged. These changes may also affect the fixed quotas applied to applications without billing enabled.
What's wrong with kilosecond or megasecond?
That is the clearest explanation of AOP that I have ever heard.
&gt; Yeah but years have leap years Use the average gregorian year of 31,556,952 seconds per year (365.2425 days) &gt; Same problem with months (28, 30 or 31 days?). TFA doesn't use months, probably for that reason. &gt; Weeks is just "td.days / 7" + the odd days remainder. And minutes is just "td.seconds / 60" + the odd days remainder. The whole point of TFA is to display human readable time spans.
This looks really cool but there's currently no source code for people to try it out for themselves.
Yes, as the article says, I don't need to test whether the browser works...
Really? It's also the clearest explanation of bajiggling I've ever heard! I'm going to zoobilate all my code from now on, to get rid of those damn Joulsies.
so what's wrong with selenium if it's not what you need?
You forgot "the canonical example, logging". Downmod for quoting out of context.
I hope something like this gets into ctypes soon.
FUCKING AWESOME! I WANT THAT!
Basicly, it's about implementing the COME FROM statement from the C-INTERCAL esoteric programming language. It's like a huge practical joke gone wrong.
Nothing, I'm just wondering why people use it. What is the usefulness?
Like I said, you may need to ensure that the result you get from the server works as expected in your browser and selenium helps you do that by letting you check for values within the page and their location. You could have a perfectly valid response from the server perspective but that is broken once in the browser. Selenium can help you detect those errors.
Usually, it is nice syntax, but I'll miss being able to do syntax like this for small metaclasses: class Example(object): class __metaclass__(type): def foo(self): pass def __init__(self): pass def bar(self): pass
and LISP is the most interesting language to do simple things.
does anyone know what's the tool he use to record it? I'm a Linux newbie.
s/simple/impossible/ NB: sed is the most interesting 'language' to edit reddit comments with.
I rather like english myself.
I have to agree. I've used Python, Ruby, Perl, and PHP. Perl get's hung up a bit when it's time to do OO or complicated data structures. With PHP it's the libraries that drive me crazy. I love Ruby but Python is smaller and because of its "there should be one—and preferably only one—obvious way to do it" philosophy it makes code written by others easier to read then any other language I know of.
COBOL ON VAX IS THE EASIEST WAY TO CAPSLOCK TO DEATH.
I brew a war smelling flames.
So it helps you detect rendering errors as well?
I war flames smelling a brew?
In a way yes. I invite you to give a try to the selenium Firefox addon and see for yourself what it could do. You might find it useful in the future :)
I flame war while brew smelling.
Speaking as someone who uses OpenCV on a daily basis (albeit from C++) what are some quantified advantages of this over the python bindings that OpenCV ships with? Edit: Added 'quantified', assertions regarding memory management should be substantiated please.
Speaking as someone who has visited the linked page, &gt; OpenCV has its own swig-based Python wrapper. However, it has conflicts in memory management between C/C++ and Python, and hence is not suitable for large projects. It is also particularly hard to maintain and develop.
&gt; OpenCV has its own swig-based Python wrapper. &gt; However, it has conflicts in memory management &gt; between C/C++ and Python, and hence is not suitable &gt; for large projects. It is also particularly hard to &gt; maintain and develop. I can read too smart ass. I just was not happy with an unsubstantiated assertion. I was looking for more detail. 
Sorry, I have a hard time respecting anything that gives more weight or legitimacy to WSGI (let's reinvent HTTP!).
Then you should have said!
Sorry
It's okay man. I will give you more details on this package (and OpenCV) if I ever use it!
I flame a brew war smellin'.
(smell I (a-brewin flame-war))
The source code was released, http://pyevolve.sourceforge.net/wordpress/?p=210
what a strange thread.
WSGI specifies how data is represented in Python and is on totally different level comapred to HTTP. And if you like HTTP then FAPWS is for you because you can set up things like this: Lighttpd + mod\_proxy for dynamic content -&gt; HTTP -&gt; Python backend (Django) Instead of: Lighttpd + mod_fcgi for dynamic content -&gt; FastCGI -&gt; Python backend (Django)
`print [ x for x in things if x==interesting ][0]=="python"` `true` 
I will give you more details on this thread if I ever read it.
True
Interesting.
Decorators are hardly the same thing as aspects. Neither is the WITH stuff.
 # I smell a flame war a brewin'. from conflict import War class FlameWar(War): pass def brew(): return FlameWar() self.smell( brew() ) 
More like; let's fix CGI.
Any Python sample code for license plate detection floating around?
Every day reddit feels more and more like 4cha
That just tells us that python is the first interesting thing. What you need is more like: print 'python' == languages.sort( lambda la,lb: cmp( mean([ease(la,y) for y in things where y.interesting()]), mean([ease(lb,y) for y in things where y.interesting()]) ))[0]
&gt; IronPython is a one-way gate Big surprise there.
C# 4.
You should go learn what WSGI is.
I'm a CS student who has taken an intro Java and C++ course, and I'm just starting a new class where the instructor uses Python for examples. I'm quickly falling in love but am having trouble keeping up the motivation to learn without a tangible goal, so my question to reddit is what would a good program to write be that wouldn't be too overly difficult for a new CS student but would give me room to be creative and delve into some of the depths of Python? I wrote a hangman game, but it didn't really satisfy my desires to learn.
Try writing a data structure like a linked list, binary search tree etc ... I find that implementing data structures while learning a new language is a great experience 
I think you can write plasmoids in python. http://en.wikipedia.org/wiki/Plasma_(KDE) 
Write something that will do something you actually want to do. Maybe you want to sell some stuff on eBay. Write a simple application for listing items using the eBay API. If you want to learn specific aspects of the language, figure out a way to build that into your design. I have a project that I'm planning to work on over the course of the summer -- the main goal is to write something in C++ and Gtkmm, but I've found an actual application that will be useful to me too. I'm hoping that the intersection of the two will keep me motivated to finish.
A genetic algorithm is fun. But then you have to figure out a problem you want the GA to solve.
&gt; More like; let's fix CGI. Except, to be perfectly fair, WSGI _didn't_ fix CGI, and punted on several hard-but-useful areas of HTTP/gateways in the process.
Interface to some API on the web. Write a desktop front-end to blogger or Google calendar or something along those lines.
I agree, GAs are great for lazy programmers like myself. Watching the computer figure out you're problem is priceless sometimes :)
I suggest the following if you like math problems: http://www.projecteuler.net It's also great for getting to know the basic aspects of the language like objects, lists, list comprehensions, loops, inheritance, etc. If you're into more practical things, why not write a simple chat client using Python sockets? Learn the differences between Pythons handling of UDP and TCP. Build a packet spammer that probes your wireless LAN vicinity for clients and ECM the heck out of them.
A maze generator and solver is a very fun problem to solve. It takes you around arrays, recursion and many other concepts nicely. You may also find it interesting to generate the mazes and the solutions as PNG's, with the added bonus of learning image processing along the way. I recommend PIL for that purpose.
There is spawning too for pure python wsgi server. http://pypi.python.org/pypi/Spawning/0.7
That would be ideal, and I've put quite a bit of thought into it already. The problem is I can't think of an application I actually want because I don't do anything really that unique on the computer. The only thing I've thought of that I would use is far to difficult an undertaking for me at this point, and there also happens to be a perfectly suitable solution out there already.
I'm into math, but not -that- much; thanks for the suggestion though. As far as a simple chat client, that's actually something I already thought of while sitting around trying to come up with an idea. It does seem like an ideal way to learn useful concepts and do soemthing fun, but I've been too daunted by it to get started. Like I said I've only taken a few introductory classes of programming so far, and I don't even know what the differences between UDP and TCP are, or what sockets really mean. I guess that is exactly the reason I should make a chat client, to learn what I don't already know. I'll start researching the basics and see if I can figure it out, thanks.
This sounds extremely fun and challenging without being out of my reach. Great suggestion -- I'm going to get started on figuring this out right now.
I'll make it very simple: Sockets are pretty much like wall sockets that a client can plug itself into in order to communicate with a server. I consider UDP to be an easy-to-use protocol. The server initiates a socket connection and binds itself to an address. In order to receive data from a client, the server doesn't need to handshake the client prior to that. No real steady connection is initiated between client and server, they just randomly send packages to each other's address and hope the other one is able to receive them. UDP is the preferred method used for games, streams and stuff like that, where lost packets aren't critical. Each packet contains a checksum of itself so they can verify themselves upon arrival and check for corruption. The TCP protocol is a little more complicated to use. You first need to initiate a connection between client and server. They need to get to know each other and stay connected all the time through the data exchange. If you just send packets the server's way, they will be discarded without the client handshaking first. If a TCP packet is lost, the server resends them as often as needed until received and the client needs to wait until server is done and packet is received. This makes the transfer more accurate but slower. You usually use this for chats, data transfers, and everything that would suffer from packet loss. You should go here: http://docs.python.org/library/socket.html And to get started real quick (UDP): http://www.evolt.org/article/Socket_Programming_in_Python/17/60276/ Good luck.
I am most happy you liked the suggestion. You might also like [The Python Challenge](http://www.pythonchallenge.com/), which is quite fun and turns learning Python (and most other scripting languages) into a very intelligent treasure hunt. If you have the patience (to get around level 15 or so I think,) you will find that the idea of mazes was not entirely mine. :) It was from one of the brightest puzzles I've come accross.
At least we've added two new parties.
&gt; IronPython opens up the world of .NET to Python programmers. To be fair, pythonnet does it as well although it lacks behind the current .NET 3.5 framework which is a pity. The main advantage of pythonnet over IronPython is that it doesn't need 20 seconds to start a Python script that loads a few other modules.
&gt; Careful when using the above codes. I have not checked them yet!
This has been done before, and better, by [Construct](http://construct.wikispaces.com/). It's pretty much my one-stop shop for binary parsing; the library makes it actually fun. Be sure to check out the examples in the library; they've implemented a bunch of common file formats like RAR, BMP, GIF, JPEG, as well as some network protocols like ARP, IP, TCP, UDP, and so on. All in a really lovely declarative style that makes it genuinely fun to write code in. The one criticism I have is that I found it difficult to debug. You have two options; first, you can insert a Probe() into a structure, which will cause it to dump its state when it parses that part of the structure, or wrap the whole struct in a debugger, which will drop you into pdb whenever parsing blows up. Probe's output is hard to read, and I'm not very good with pdb, so debugging is still a bit painful for me.
Great, but how about using `numpy`? The library that is, you know, tested, optimized and so on?
What wrong with the .NET language `Boo`?
Nothing special except that it is off topic here.
It's essentially an image of a load of python code. Not being able to copy and paste it I cannot simply run it and I haven't the time to try and work out what it does.
You can't represent an arbitary real number on a computer. You can aproximate it to a rational but you can't actually store the thing. No matter how many millions of digits of Pi you compute, you're just making a bigger and bigger rational number. In modern computing, where we have billions of cycles and we're using a _scripting_ language, which wastes millions of cycles anyway, it is unacceptable to present an 32-bit integer as a basic type. Integers should count up (or down) until you run out of memory. Rational numbers should do the same. This makes the symantics of what an "int" means closer to the mathematical definition of an integer. Rationals are just a fancy pair of integers anyway. You can do all your mathematics on this pair of integers and when you want a decimal expansion of it, you compute it at the end of the process. This would save the world billions in getting rid of unneccessary rounding errors. 
It condemns you to Python Hell.
Follow the blogspam to here: http://www.nishiohirokazu.org/blog/2006/09/how_to_write_oneliner_in_pytho.html It plays rock &amp; scissors. The brainfuck interpreter there is even neater.
This looks like regular perl one-liners. :-)
Explanation why you are being downmodded. Python: &gt;2**32 &gt;4294967296 &gt;2**40 &gt;1099511627776 &gt;2** 1000 &gt;10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376L Note the L there - our int was silently coerced to Long, which can grow until you run out of memory. The types are completely unified in Python 3. 
Thanks, I was a bit puzzled :)
One advantage is that it connects better with Maya, and properly also with other extern applications. I'm using ctypes-opencv + pyqt and Maya in this video: http://www.youtube.com/watch?v=vFQTDPjy4sg&amp;feature=channel 
The main disadvantage of pythonnet is that it is not maintained and the last release basically doesn't work (although you can apply a set of patches yourself)...
and not true...
C# 4 will make interacting with dynamic objects substantially simpler (at the cost of type-safety of course) but you still need to go through the IronPython hosting API to *get* the dynamic objects. Not difficult but C# 4 is not quite the magic bullet in this area that some people think it is...
The fact that he's getting a DeprecationWarning is a strong hint that there's a rationale hidden in the archives of python-dev and/or the PEP:s. It's always a good idea to go there before ranting away. (And what kind of programmer is he if he needs to use floating point to round integers to even multiples of 4? I thought everyone who's made it through programming 101 knew that (x+4-1)&amp;-4 does the trick ;-).
I started coding that. But gave up before it was working correctly. Happy that someone else did it :)
Nice Mathematica replacement. I always hated Mathematica. And Matlab had a better programming language than Mathematica but no "worksheet" mode like Mathematica did.
I love re-writting tools in python but I don't quite get why they don't move to SCons or CMake instead ...
The screenshot reminds me of the Maple I used in college.
If Reinteract applied to iPython, they we could have pic/video preview when `tab` through folders. Hmm it's like Mozilla's Ubiquity
I (ab)use Reinteract to do file I/O and string operations, and I haven't quite figured out what it does with file-like objects, how it shelves/copies them, etc. But the end result is that I tend to end up with files that have the contents duplicated, or only half of the contents, or some such on Mac OS. On Linux, it seems to behave properly.
Not quite a replacement, but still good progress.
&gt; Hmm it's like Mozilla's Ubiquity I really wish opensource programming/scientific applications would take a greater interest in usability.
&gt; I (ab)use Reinteract to do file I/O and string operations, Can you elaborate on that? I thought the main thing was just integrated plotting.
Also check out [pyreport](http://gael-varoquaux.info/computers/pyreport)
Do you have an idea what it costs to bring the project up to date and where the pain points are? Last time I used pythonnet successfully was about 2005 with Python 2.4. Even at that time IronPython got all the attention despite being an instable research prototype. Now it feels like a stable research prototype - one where a script takes the time of Eclipse or more to load but otherwise behaves as expected.
add audio that explains
No idea about cost - but not too much I don't think. The core project is in pretty good shape it has just bit-rotted a bit and is out of step with recent versions of .NET and Python. You exaggerate the IronPython startup time... 
ya, you're right. I have created a short guide, explaining the basic concept here: http://mikkeljans.blogspot.com/2009/02/python-color-tracking.html I know, I should have posted the guide instead of the video. sorry :)
Even with this "dumbed down" version, I still don't get it. Y(fac)(1000) still gives me "RuntimeError: maximum recursion depth exceeded". What is it good for? Simply an alternative way of creating recursive functions?
I just checked out pythonnet and I can say it worked fine so far ( at least for .NET - no idea about Mono ). Since .NET 3.5 works with the CLR 2.0 one just has to add a few file system paths to the PYTHONPATH via sys.path to import e.g. Linq classes. It's just a first examination but and encouraging one. &gt; You exaggerate the IronPython startup time... I wished this was true. I started a script that needed to import a bunch of modules: 34 seconds. At that time it hasn't even done anything relevant. Running an empty(!) `__init__.py` : 6-7 seconds. WTF.
&gt;"It always takes longer than you think, even when you consider Hoffstadter's Law." this is a law?
Love Editra!
second that.
Originally it was just Douglas Hofstadter being self-important. Then it was a shibboleth for people who read *Gödel, Escher, Bach*. Given what this guy did to both the quote and Hofstadter's name, I'm not sure what it's become now.
[Here](http://code.activestate.com/recipes/576366/) you find a working example of an Y combinator in Python. In the comment section there is also a discussion about the relation between the recursive nature of the combinator and the fixed point property. &gt; What is it good for? Simply an alternative way of creating recursive functions? Yes. It is mostly a gadget for people who try to define programming language semantics by reduction to a simple language like lambda calculus. It's tricky and unintuitive and has little ramifications in practice. 
Without a Python prompt it is not Python.
My favourite parts: "Hobbyists either don't spend money or spend relatively little so I discounted them as a target audience of interest." "The fact that Google App Engine is limited to only Python meaning that it is unavailable to developers using WISC platforms and only a subset of developers using LAMP can participate on the platform." "Other limitations for Python developers are that they can't use all of their existing knowledge of Python libraries since it only supports a subset of Python libraries." "That said, Google App Engine does address the long tail of developers which I guess is nothing to sneeze at." 
 from __future__ import Peace
I guess yet another reason _not_ to do `from foo import bar`
don't get all emotional, it's a programming language. Learn to deal with it like a man.
[Ticket filed](http://bugs.python.org/issue5401). :)
the cake is a lie.
That was (part of) the problem. Just doing `import foo` was the fix.
yah i missed a 'not' in my comment
Can you explain how `from foo import bar` causes this? I'm not a python expert.
It wasn't `from foo import bar` exactly, it was the fact that `bar` was redefining itself, such that the calling module never got to see the new version. btw, the problem is already fixed. http://svn.python.org/view/python/trunk/Lib/mimetypes.py?revision=70086&amp;view=markup 
The problem is in the monkey patching that's being done. `from foo import bar` should *not* break functionality of any module. 
And resolved through a fix. party on!
I was agreeing with you idiot.
If that's the case, what about some backup solution that automatically switches based on the context of the backup being made? If i'm dealing with tiny files, it should use some regular lightweight VCS, but if massive amounts of data come into play, suddenly it initializes the engine and churns away.
It seems like you can still get huge queues of data if ctee condition doesn't split the sequence evenly, or if there are large sections where the condition is either always true or always false. Still pretty cool, though.
What I meant to say was "Thanks for explaining the joke."
I'd like to mention a book that also targets this niche. I made "Invent Your Own Computer Games with Python" available online for free under a Creative Commons license. http://pythonbook.coffeeghost.net Instead of going over language syntax and tedious lists of functions, each chapter offers the complete source code for a new game, and explains the programming concepts from the example. I, too, also fondly remember the days of typing in source code from magazines and books, and it was the best way that taught me programming.
Dude seriously needs to get the hell over himself. 
Reinteract is a full Python shell, so you can do all sorts of Python-y stuff with it. Graphing is just a side effect of having nice numerical and plotting libraries for Python.
(talking about the fix) Is the use of the global variable inited thread safe (I really don't know a lot about threads) ?
I used your book as a secondary learning reference when I taught myself Python. I really missed all the *cool* stuff like graphics, OOP, sound, network. I know you excluded those things for the sake of simplicity but I imagine that actual kids would be a lot more interested in doing cool stuff with graphics and sound. When you get that far, you don't have to artificially introduce them to OOP, a desire to learn it will come automatically since no kid wants to keep track of 50 global variables for 25 moving creatures (for example). I suggest a version two of your book where you cover those aspects using Pygame. Apart from that, I liked the things that you did write and teach in your current book, so keep it up :)
I am very likely in the majority by holding this opinion, but I find that decorator syntax for exposing URLs to be much, much more Pythonic than the Django/Paste/et. al. method of using classes until your eyes bleed. I never found the class model to provide a useful extension for web page views. For ORM, then yes, but for rendering a web page, not so much. The worst offender (I feel) was Zope, which basically built a Java-style web framework in a different language. Does anyone care to hurl stones at my argument? (Noting that I work in Zope daily and love it, but dislike its nearly baroque structure)
That guy is pretty abrasive, even though I mostly agree with this post.
No, I think your understanding of this is pretty much spot-on. I've been very pleased to see the recent resurgence of "lightweight" web frameworks (Juno here, CherryPy, Werkzeug, et al). If you're building anything that doesn't fall directly into the traditional CMS model, the advantages of heavier frameworks like Zope, Django, and Pylons are lost, and the lighter frameworks really begin to shine. I've chosen CherryPy for my own needs, as it's mature and feature-rich yet simple and Pythonic, and I'm quite pleased with my choice. I've found that organizing pages using classes helps about as much as it hurts. With a simple framework like CherryPy, the stylistic overhead of using classes is present but not overwhelming. For what I'm doing, the class structure works pretty well (for instance, I've got a `UserAccount` class that handles URLs of the form `http://example.com/UserAccount/...` and keeps the logic for managing account settings all in one place. It's convenient and it works. I use a CherryPy decorator on all the member functions I want to expose as valid URLs, and mount a single instance of the class on CherryPy's publisher tree, and it's online. The Juno syntax looks *great* for smaller sites with only a few URLs to worry about, but the extra structure of CherryPy's approach seems to me like it helps when things get bigger. I don't know about the heavier frameworks, but I suspect CherryPy's approach is very middle-of-the-road compared to Juno on one hand and Django on the other.
&gt; Is the use of the global variable inited thread safe. No, it's not. Even innocent python statements like `x += 1` are not thread safe, as the interpreter can run other code between the x lookup and assignment. 
I hear you, and I tend to agree with you and the author. However, I think it's nothing more than masturbatory to write that much on the topic and say so little.
&gt; Does anyone care to hurl stones at my argument? There's one and only one thing that keeps me from agreeing with you: decoupling URLs from the code that runs in response to requests for those URLs. In my mind, they should be totally decoupled so that the code can be (a) run in response to more than one URL, (b) run in a different application, and (c) migrated at run-time. I might be able to do some of this with url-decorated-functions, but I wouldn't want to. 
Surprisingly, I do have a response to this. I would frame it under the guidance of making hard/common tasks easy while making hard/uncommon tasks possible (to paraphrase any of the more common formulations of that saying). Using decorator syntax simply gives you the option of using it as a decorator; after all, a decorator is simply a callable that returns a callable. If you need to expose under multiple URLs, why not just stack the decorators? Likewise, if you want to separate the routing entirely, why not explicitly call the decorator function in your routing code? # Case 1 @route('/') @route('/index') def index(web): #... # Case 2 (in some other file, e.g.) routes = [ ('/', index), ('/index', index), ... ] for path, method in routes: route(path)(method) The second is a little obtuse at first glance, but the loop could easily be hidden away by a single function within the library. Then the common case of function-per-path is no harder than it was before, but the less common case of using the same code for multiple routes and/or maintaining the list of routes in a separate file is possible (and, notably, not any harder than using "real" routing libraries).
You're right about providing the simplest interface for the most common use. But if you go down that path, your code is tied to your URLs and vice versa. There's nothing wrong with that until you try to modularize and/or share your code with other projects. &gt; If you need to expose under multiple URLs, why not just stack the decorators? When I write a shell script, I don't write it for one or two directories in my file system; I write it such that it works where ever I happen to run it. 
&gt; I find that decorator syntax for exposing URLs to be much, much more Pythonic than the Django/Paste/et. al. method of using classes until your eyes bleed. Your argument might make more sense if all the things you're talking about actually used explicit class definitions to implement URL routing: Django doesn't, for example, and I've never seen a (popular) framework where end developers write Paste URL-parsing classes (typically people use higher-level abstractions on top of those, with cleaner syntax).
anybody have an informed opinion of how this compares to web.py?
I'm always torn on that, on one hand, the decorator syntax is great to read. On the other hand, having all my urls in one file gives me an easy place to go to when I want to figure out what handles what url.
how many times have i read that tag line before? how about "a heavyweight web framework thrown together to make your life a living hell - and we make you pay for it" edit: I feel like M$ probably has a (few) product(s) like this
She is also pregnant to a guy who would rather eat tic-tacs than sign on to the Arrested Development movie with the potential adopted father of the baby....
350 pages, which could be reduced to 100.
i'm a long time user of web.py. my least favorite thing about web.py is that it adds a lot of code because it wont outsource anything: sessions, db, templates. it looks like juno does so using the best options out there: beaker, sqlalchemy, and mako (or jinja). i like the decorator syntax in juno. even if you dont, as with some of the commentors above, you can just do (untested): def hello(web, name): return 'Hello, %s' %name def bye(web, name): return 'bye, %s' %name # routing in one place. route("hello/:name:/")(hello) route("/bye/:name:/")(bye) route isn't magic, it's just a function. so you can have all your urls in the same spot--even in a separate module. a brief look at the code looks like it wont handle unicode. is that true?
The decorator syntax is very python... but having the URLs centrally managed it just overall better design.
I have used Django, I don't see how it relies on a CMS model. Could you expound?
* Sharepoint * ASP.NET + all the paid extensions people seem to need
Well, I've coded full time in Python for many years now. And I would have agreed with you a couple years ago. I preferred using simple functions to structure code rather classes. Only use classes when you need them. Web apps *seem* to fall into a simple "input" / "output" pattern, which a function is fine for. However, now that I've written a whole bunch of web apps, and I find that you do need classes for request handlers. Why? Because backends should *always* be passed into the constructor (dependency injection style). You need this flexibility for 1) testing and 2) performance. First, you need to be able to test without a live backend, which requires substituting an alternate implementation. And second, you need to be able to instrument your back end requests, and also cache them, balance them, etc. The best pattern to do this is to provide another implementation with identical interface to a your front end logic, and to do that you need a class basically. I have yet to see a nontrivial webapp that doesn't need speeding up by optimizing the number/kind of backend requests. I also like to separate the URLs from the classes. I think that's another good reason, although I haven't had much experience with the opposite. 
&gt; I don't know about the heavier frameworks, but I suspect CherryPy's approach is very middle-of-the-road compared to Juno on one hand and Django on the other. So, here's how Django's URL configuration works. You set up a sequence of tuples (one tuple for each URL, the whole set passed into a function which parses and registers them) of the following form: (regex, callback, arguments, name) where `arguments` and `name` are optional. Requests for URLs which match `regex` will then be sent to `callback`, which can be either an actual callable Python object, or a string containing the dotted path to such an object (it'll be looked up as needed). If `regex` had any capturing groups, they'll be passed along to `callback` as well (non-named groups become positional arguments, named groups become keyword arguments). The optional `name` is used to do "reverse" lookups (e.g., instead of "here's a URL, send it to the right callback", you're doing "here's a name and some arguments, tell me what URL would end up there"). Sequences of URLs defined in this manner can be included into other sequences as a single block, allowing collections of related URLs to be placed under a prefix all in one go. And... well, that's it. That's the whole Django URL-routing system, right there. So I guess I'm kinda stumped as to how that's "heavyweight" or, in the parent post's words, "classes until your eyes bleed". 
Well, while the author does state that STDlib is old, magical and unpractical, he does also justify it as being a good thing: it's the cost of strict backwards compatibility giving us painless upgrades.
Devil's in the detail, in this case: regexes. But then again some people speak them fluently.
Worth noting that CherryPy 3 does come with a HTTP method dispatcher as well as one based on routes. You can also find one based on selector. The cost? One line in your config.
*sigh* and I have to work with ASP.NET everyday. /sulk
&gt; hay guys look at me!
Does not compute. How about some examples?
I did not make the original comment, but I think it is a good characterization. Django makes it easy to create, modify, and view content. This is the model followed by the majority of web frameworks. It is natural to build CMS applications with them.
Isn't that what most web apps do? THis doesn't seem to be the exclusive domain of CMSs
I am so impressed with PyQt after reading that. (and Qt in general); having done some wx coding, Qt is clean(er). And I love the idea of "signals" (just register for some events, then handle them. genius!)
glad you liked it. You are going to love actions (session 3 or 4 :-)
this really should be in the docs
If only everything became an expression...
I'd like to read this article, but you need access to the NYU network. Assuming this is nothing too sensitive, could this be duplicated somewhere public?
How would you change syntax change (if at all) to support this? Genuinely curious, as I'd love to have "def" statements as expressions so that I could do something like this (javascript): bar = function(foo) { body } Me, I can't see it with the existing Python syntax. Maybe: bar = def (foo): body But that's pretty ugly.
It doesn't necessarily have to be regular expressions; several other popular URL routing systems for Python use a simpler pattern syntax, for example, but nearly all of them (the ones people use, anyway) fall into that "here's a pattern and here's where to send URLs that match it" paradigm. I've no idea where all this "classes until your eyes bleed" stuff is coming from, unless it's from frameworks that try to emulate some of the Rails-style auto-routing based on controller names.
No idea why it is more "ugly" than any other compound statement... which it is. It is not much different from an assignment statement except of having a thunk.
Unfortunately, that only works for single-line functions. I realize the issues with trying to have multi-line lambdas, but those are the exact problems ringzero is talking about.
The code style is straightforward, I'm not sure I can convey the benefits until you've worked on scaling a large web app: `class FooRequestHandler(object):` ` def __init__(self, backend1, backend2):` ` self.backend1 = backend1` ` self.backend2 = backend2` ` def GET(self, request):` ` self.backend1.Query1(request.somestuff)` ` ... logic` ` self.backend1.Query2(request.somestuff)` ` ... logic` ` self.backend2.Query1(request.otherstuff)` (sorry, can't get this comment syntax to indent right) Your production code uses a backend implementation that wraps a database. For testing, you can use simple dummy implementations of the backends, or maybe SQLite, so you don't have to start servers in your tests. And for performance, you can substitute backend1 and backend2 with classes with methods that just log traces and do timing measurements, and then call Query1 and Query2. My experience is that this is the ideal way to structure a web app. Of course, this actually doesn't rule out using decorators on the methods, although I don't use that style. I prefer the URLs to be separated from the request handlers. 
&gt;(sorry, can't get this comment syntax to indent right) Begin each line of code in a code block with at least 4 spaces or 1 tab. 4 spaces is flush. 8 spaces is indented.
How about: def bar(foo): body
tcl?
what's wrong with bar= def (foo): body EDIT: markup
In Tcl, they are expressions (or rather, commands, defined to be always nestable).
Remember Python's equivalent of braces are INDENT and DEDENT tokens, i.e. increaing indentation and reducing indentation. What's the problem with your example? It's perfectly consistent with Python syntax. It's far better and clearer than the current syntax for lambda, being limited and requiring parens for multi-line clarity. It would mean the whole if..else drama would go away too, as you could also use if as an expression, e.g.: a = if b: 3 else: 2 All Python would need is to remove the artificial, arbitrary, unnecessary restriction that statements are the poor cousin of expressions and may not go anywhere while expressions may, to extend the syntax to make them so (minimal change), and to make previous statements return values (for example, the last evaluated value, which would make my previous example work perfectly).
What if I want to define a one-time-use function and execute immediately (e.g for namespace protection, as you would use let in Lisp)? What if I'm building a function for use with a higher-order function? What if the function I'm defining is going to be part of a list of functions or a dictionary, not a single symbol such as bar? Right now my Python programs are **full** of unreadable warts like: def _1(...): ... def _2(...): ... do_something(_1, _2, ...) def _(...): ... a[1] = _ This is ugly and disgusting, while Python is so clean, conceptually sound, minimalistic and beautiful (or at least \_\_beautiful\_\_) pretty much elsewhere.
This works, but since lambda can only take expressions, and statements are their poor cousin who absolutely, totally arbitrarily cannot be used in expression context and cannot return values, you can't do much with lambda.
Read my other posts. Statements are a design wart: something limited on purpose when something better was already available in the language, that language designers keep including today just because FORTRAN was a terrible programming language (John Backus felt like shit all his life for having created it).
If you are worried about namespace protection then your functions are probably too long. Replace your underscore functions with meaningful names and it won't look so ugly. 
Using regex for the URLs in webpy let's you ensure the types of your request arguments. With Juno, wouldn't you have to do a lot of checking types and aborting requests if they don't match?
Sorry if it sounds harsh but I'm not interested in your opinion and I'm not going to discuss it. I just wanted to know why the aesthetic feelings of `ringzero` are hurt in cases where a syntax proposal follows some familiar pattern?
aaah, but you know that you can do everything in lambda, and with just lambda! 8)
Ah, ok: def do_something_first_parameter(...): ... def do_something_second_parameter(...): ... do_something(do_something_first_parameter, do_something_second_parameter) Now it's clear.
I didn't know it was possible to say anything about zope that wasn't a criticism.
Zope is built with python. Zope has a website. Zope is easy to pronounce. That's all I got.
I tried Plone. Seemed like a good idea. I couldn't get past Zope. It was obviously doable, I just wasn't willing to go through all the apparent trouble just to get a CMS working. Zope made me feel like I was trying to get MS Sharepoint to do something. I didn't like that feeling.
I also experienced it while trying Plone. Zope just seemed like a black hole of code that seemed unnecessarily complex.
Thank you for this one too, ralsina. Can't wait for Session 4. I'm already off on a tangent, thinking about some silly application I can write.
then my job is done ;-) session 4 *may* be done by saturday.
I saw this on commandlinefu.com and bookmarked it there too. Awesome little bit of knowledge. :)
I greatly prefer Class-based Views. One class, one view. I think it greatly simplifies things. 1. At first it seems like using a function is simpler, but some views are more complex so they are deserving of a class. Making everything a class is more consistent. When a View function starts getting larger, there is greater hesitation as to when to refactor into a class, since you may find yourself thinking, "hmm, is this deserving of a whole class?" 2. You can put a decent amount of View functionality in the common base class of a class-based View. e.g. self.url(), self.request, self.model 3. Instead of decorators, you can make declarative assertions as class attributes. @route('/spam') def spam(web): # do stuff # usually manually fetch a template and render it versus class Spam(View): route = '/spam' # template can use conventions # to be associated with the view # and base class can handle rendering 4. Forms are simplified. Forms can be treated as sub-classes of a generic View base class. Instead of a function which then creates a Form object and renders it, just merge the two together into one class. 5. Classes in Python are dead simple to write. you can make a whole class in one line, just like a function - it's only a matter of a 5 character keyword vs. a 3 character keyword. class Spam(View): pass 
It's been submitted already 24h ago but whatever, I'll vote it up again because it's so awesome.
Does this mean that using Plone is a bad idea?
&gt;If you want to share your URL with someone outside of your router, you’ll have to set up port forwarding on your router. Enjoy! That sounds safe.
I never could really see a compelling reason to use it either, especially when it came to the customization. Zope has some good ideas, but like any project that has built up a huge library of frameworks, concepts, ideas: if you don't live and breath it, its very hard to make it work for you. 
Zope is Java for Python. It's your usual PROFESSIONAL ENTERPRISE MULTITIER SCALABLE FIVE-NINES TURNKEY WEB 2.0 BUSINESS SOLUTION. It's bloated, overstructured, overengineered and overdone in every possible way by means of Object-Obsessed Programming.
maybe i'm missing the point, but why not use (the pythonic): if something is None: when you're specifically checking for 'null'? 
Django (opinion based on not having used any of the others)
ditto
I am only looked at Zope, Django and TurboGears. I hate the little time that I spent with Zope. I really like Django, and will be using it whenever possible, I am looking forward to more support for it by shared hosts. I have little experience with TurboGears, but its just a consolidation of several different projects. It looks good to me, but the tightness of Django along with their documentation is pretty good. I have no knocks against TurboGears. I know of others but haven't touched any. My vote is for Django. For me Zope == MS Sharepoint.
Having tried only web2py and Django, i'd say Django. I'm using it for a little project right now, and so far it's made the development process pretty fun (of course excepting for issues getting it running on my host, which wasn't even that bad).
web2py.
I liked it for the short while I used it. The application required a fair bit of DB interaction, which I ended up writing a whole bunch of custom methods for, and it really got quite a bit easier with Django since it has the whole built in DB stuff. Much more versatile than Django, but ultimately it wasn't worth it since Django has everything I needed.
I am starting to use Pylons. I like it alot so far. Good documentation pylonshq.com. I also picked up "The Definitive guide to Pylons" www.pylonsbook.com
a gui program to track ip addresses?
[Pun about extending python]
Be careful of whom you swap pythons with, you might catch a bug or two.
Bah, the .com version doesn't even have an IPv6 address.
But on the other hand, it has tits.
Have you tried Grok?
I find that Substratum is better when I adhere to Porthole Angora on my centigram cluster. The multiway overcook behavior is obnoxious in Absurdest, much as I like the destinations chinchillas, which of course hasn't been ported yet. Anyway, I totally agree, Fabric over using Capistrano to deploy Afrigator any day.
Why is wordpress so inept at not formatting the DO NOT FORMAT tag... It adds non-ascii quotes to the script, so annoying to remove. /rant
No pictures?
The following, adds IPv6 and threaded server support: import SocketServer, BaseHTTPServer, SimpleHTTPServer, signal, sys, socket class MyHTTPServer(SocketServer.ThreadingMixIn, BaseHTTPServer.HTTPServer): address_family = getattr(socket, 'AF_INET6', None) SimpleHTTPServer.test(ServerClass=MyHTTPServer) 
http://codepad.org/KQC7y9Er There, enjoy.
"Beware: The Python codes above has not been throughly tested." = CTRL-C/CTRL-V
I think the sourcecode plugin works fine as well. You (the blogger) just do: [sourcecode language='python'] code here [/sourcecode]
buy? 
Thanks :)
You actually run a centigram cluster? Wow! Impressive. I could barely afford the decigram. Doesn't handle as many chinchillas, but it does the job.
(There is a small bug in the nist case.. Xbar should be divided by the sum of the weights)
How about showing some real world code rather than contrived examples?
I made this guide to illustrate how to set up a server using multiprocessing.py to execute long running tasks in the context of a Django web app. It's the first how-to I've done, be kind.
Tried that - it's a bit nasty in pretty much every way. imho it is a good example of exactly what not to do. Then I found [newf](http://github.com/JaredKuolt/newf/tree/master) which is quite nice. Just use any template engine and database abstraction layer. But on the other hand, wsgi makes it so easy to just put together your own framework that there's little reason not to. URL "dispatchers" or "routers" are trivial to write. 
Money back please Two substantial paras and some supporting sentences. I'm sure my fellow redditors could be more explicit on what the minimum for a rant is, but 2 paras is surely just a whinge
These improvements need to be back-ported to 2.5
Erm, looked like a lot of the difference was the I/O rewrite, which is not capable of providing performance improvements over a 2.x Python (since I/O didn't hit its big slowdown until 3.0)...
web2py is indeed a powerful and easy web framework. edit : :s/webpy/web2py 
&lt;peeve&gt;An -alpha isn't a release. It's part of a release process: the "request feedback" stage.&lt;/peeve&gt;
So if I/O slowed down in py3k, then these improvements are actually bug fixes?
see also: http://prabhuramachandran.blogspot.com/2009/03/mayavi2-in-sage-notebook-on-web.html
webpy and web2py are two different web frameworks.
sqlalchemy supports dropping an index using index.drop().
Most of them are. You really need to compare against 2.6 to have a useful/interesting number.
This is actually pretty neat. 
But what advantage does this have over: for emp in employees.select: etc
From what I can gather, the ruby-style block approach given adds side effects to a filter function. This breaks the rule of least astonishment: filters are expected to only decide whether to include an item in a sequence. The `for` approach has the advantage of having the expectation of side effects.
Duplicate [\\o/](http://www.reddit.com/r/programming/comments/830h0/rubystyle_blocks_in_python/) As I [commented on the other submission](http://www.reddit.com/r/programming/comments/830h0/rubystyle_blocks_in_python/c08455d) it's already possible with the "with" statement, pretty much: from __future__ import with_statement class Configery(object): def __init__(self): self.yay = None def __enter__(self): return self def __exit__(self, a, b, c): pass config = Configery() with config as c: c.yay = "yay for the with statement!" print config.yay # outputs: yay for the with statement! ..and no syntax additions needed!
Why not having just plain real λ-expressions? This can be achieved through one of two approaches: 1. Allowing a multi-line `lambda` with statements within it. 2. Getting rid of the nonsense, useless distinction between real, full blown expressions such as if..else or lambda, and their poor cousins the statements, who are artifically, arbitrarily limited to appearing only in certain points in the code. In other words, make everything, including `def`, an expression. This way you could use `def`, or use anything else within `lambda`.
Downvoted by the Python Imperative Inquisition? I'm more interested on a solid explanation on why this would be a bad idea; otherwise I'm to think it's a good idea, but since this kind of sanity is common to functional programming langauges, it's violently hated and rejected by some in the Python community.
As far as you can call reimplementing in lower level language a bugfix - yes.
This blog post has little to no information in it, where are the upvotes coming from?
It has a very attractive menu. But it also has too many inaccuracies or errors in the content. 
http://www.packtpub.com/view_errata/book/expert-python-programming lists 3 technical errata. that's too many for you?
these guys have been spamming reddit for ever about this crappy book.
So what do they mean by "capabilities"?
http://en.wikipedia.org/wiki/Capability-based_security
I used SQLAlchemy for my last project and loved it - anyone know how Storm compares?
Could it be that the publisher sent a lot of free books to be reviewed, and it's also a book that wants to be important for every serious Python developer? Why does it have to be spam? You're browsing a website where the news are self-regulating, thanks to the community moderation
That was always confusing me, since Zope 3 uses `__parent__` and `__name__` in the zope.location package. And zope.interface uses `__sro__` for it's Specification Resolution Order. But then it would be really nice if `__sro__` was an official Python name. 
IIRC there's a proposal that objects for use on the web should implement `__html__`, and it happened fairly recently (a bunch of template engines implemented it). So sadly this sort of thing is still going, apparently.
OT: Code Singer is not a good name for a blog. Even, or especially, if it's about someone who writes code and is a singer.
&gt; People get legalistic about this, but I haven't seen it cause problems That's an interesting take on it. Part of the reason that Python is so easy to write well is *because* people follow the "rules" (PEPs). If everyone had the attitude, "well, it hasn't caused any problems yet," I suspect Python would not be as stable as it is today.
Storm doesn't look ready for public use. The manual is missing huge parts. The API documentation is missing from massive amounts of the code. This looks like the typical unmanaged (or programmer/developer managed) project. The author focused on all the fun stuff. Documentation comes last, if ever. The tutorial is a teaser. Without the documentation, it's just another big pile of code. I've reverse engineering enough code in the course of making my own documentation to last a lifetime. Highlights say: &gt; Storm is developed in a test-driven manner. An untested line of code is considered a bug. That's great, but I say: An undocumented function or class or variable is considered a bug. 
Could someone explain to me, CLEARLY, what is this article saying ? Why shouldn't I use __ init __ ? O_o
You should use `__init__`. You can use the double-underscore defined functions all you want. But you should leave the definition of new double-underscore functions to the Python language itself. 
That's what I thought. Then, WHY is the title "Don't use __ * __" ? It doesn't mean "Do not define new functions with double underscore", it means "don't use anything with double underscore in it" It's really confusing... (and by the way, how do you insert &lt;code&gt;&lt;/code&gt; in reddit ?)
The only rule PEP I am consciously against (so far) is the space for indentation rule.
Came here to basically ask the same thing. That article should have started out by clearly stating why someone should consider this (seriously) instead of SQLAlchemy.
&gt; (and by the way, how do you insert &lt;code&gt;&lt;/code&gt; in reddit ?) Start each line with four spaces: like this
Thirded. If Storm is being used by Canonical and powers launchpad it must have something going for it, but sqlalchemy is like, goddamn.
I chose Storm because from a look at the two websites it looked like I'd be able to pick it up more quickly. As stated in the post, I had about one night, and SQLAlchemy looked like overkill for my project (from a 5-10 minute glance at the website). I didn't have very complex needs (5 tables total), and Storm seems to be meeting them nicely.
I try to do it on debian, but I got the MemoryError.
Well I think we've seen the reinvent the wheel thing from Microsoft, and it's generally a hit or miss things. So I'm not prepared to assume that it has anything going for it just because Ubuntu uses it.
I'm guessing you didn't look at Elixr.
That was a pain for me at first too, but most of the editors can be configured to convert tabs for you (like emacs, for example).
For code within a comment you can enclose it in backticks. For example, `` ` ``this text`` ` `` produces `this text` as a result.
The author of [Dragonfly](http://code.google.com/p/dragonfly/), a library to add spoken word control to Python programs, uses speech exclusively to code Dragonfly. I guess Code Singer just takes it to the next level.
Yes. If you're using a programmers editor that can't do that, it is a failure of a programmers editor. These days, that ability is as much of a requirement as syntax highlighting.
I didn't see that one in my search, but it looks good. If I have another ORM related task in the future, I may take a look at it. Thanks.
Wait, JIT...interpreter? Finally!
&gt; That's an interesting take on it. Part of the reason that Python is so easy to write well is because people follow the "rules" (PEPs). If everyone had the attitude, "well, it hasn't caused any problems yet," I suspect Python would not be as stable as it is today. Can I stay in your world for a while? Mine is filled with people who think that the language allowing you to do someting is justification enough for doing it.
Test : `test hello hi` Thank you very much :)
Using [] as default value for function arguments is actually quite a common, uninteresting bug. Every python programmer did that at least once in his life.
JIT *compiler*, surely.
So instead of reinventing Python you're now reinventing Psyco? Brilliant!
Psyco, sadly, isn't being developed anymore (I think the articlementions this)
It's not like Python's list comprehensions are very difficult to understand: it's been specified (and that's been a reason for rejecting some listcomp-related proposals recently) that listcomps should be transformable into "regular" python code by: 1. Indenting and adding colons to the statements (`for` and `if`) 2. removing the surrounding brackets 3. moving the outermost expression to the deepest part of the new compound statement, and appending it to a result list So the form [(x, y, z) for x in xs for y in ys for z in zs if pred1(x) if pred2(y) if pred2(z)] becomes 1: [(x, y, z) for x in xs: for y in ys: for z in zs: if pred1(x): if pred2(y): if pred3(z): ] 2\. (x, y, z) for x in xs: for y in ys: for z in zs: if pred1(x): if pred2(y): if pred3(z): 3\. result = list() for x in xs: for y in ys: for z in zs: if pred1(x): if pred2(y): if pred3(z): result.append((x, y, z)) 
There has to be a better way than this mess!
A better way to do what?
Do you feel your penis is larger now that you've written that?
Here's something I always like to show people: A deck of cards in one line of Python. `[rank+suit for suit in "SHDC" for rank in "23456789TJQKA"]`
This article really clarifies this for me. I did know and use nested comprehensions, but they were always for x and y being two unrelated dimensions, such as [x+y for x in range(5) for y in range (5)]. These examples give no insight into how the loops are processed. Now I really understand it - thanks!
#Reads a csv file into a nested list list_of_lists = [line.split(',') for line in [line.strip() for line in csv_file.readlines()]]
I always just think of it as a [cartesian product](http://en.wikipedia.org/wiki/Cartesian_product): &gt;&gt;&gt; [(x,y) for x in [1,2,3] for y in [4,5,6]] [(1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3, 6)]
so dies this [line.strip().split(",") for line in csv_file]
Someone is continuing Psyco. Well, I guess 'maintaining' is a better word for it.
Finally.
&gt; How many other Python programmers understand them? Has everyone else been using them without problems? Consensus: yes.
Let's use the most depressing and unreadable color scheme for our graph: black on gray.
While learning Pylons, I found myself digging into the documentation of a few different tools that come packaged with it. FormEncode has so far been the most intriguing. I ended up digging into the code, and found a hidden gem. I've also got a few improvement ideas to toss around, in the form of oh-so-tender beef
It's an interesting enough tool that I've subscribed to the blog as a whole.
Thank you! :)
If you had taken a little bit time to read the tutorial in the python distribution, you would have already understood it. 
Protip: Be sure to click on the chart first. Otherwise, the article doesn't make any fucking sense.
Can't wait for next session. Thanks
Totally different story.
Actually, that's too few for me:) I have only managed to skim through several pages. Here is my two little addition to the list of errors or inaccuracies: Page 84: "The \_\_new\_\_ method must return an instance of the class." which is quite different from what's in the python doc: "The return value of \_\_new\_\_() should be the new object instance (usually an instance of cls). " Page 230 (in "Section Structure"): "They can be overlined and underlined, " which is not as clear as what is in "A ReStructuredText Primer" by richard jones: "...section headers...are a single line of text (one or more words) with adornment: an underline alone, or an underline and an overline together" p.s. I'm not a native english speaker. Please correct me, if I misunderstood the differences between the above two pair of sentences. Thanks in advance.
and herein lies one of the major problems with open source: the author losing interest. edit: when I said open source, I meant free software. It was really early in the morning ;)
Honestly I'm surprised anyone stayed interested in the idea of parsing anything-that-even-pretends-to-be-HTML for this long...
sure, closed software offers eternal support...
Depends which way you look at it. If a person loses interest in (or otherwise abandons) a closed source application then you're pretty much screwed. With an open source application then at least there's nothing stopping people from picking up where they left off.
&gt; Now there are lots of programmable lenient HTML parsers Can anybody recommend some?
I will try to have it done for tomorrow (march 14) but it's unlikely
Upvoted for the *Oklahoma* reference. 
Have a look at the ['highly concurrent' web server](http://opensource.hyves.org/concurrence/#a-highly-concurrent-greeting) that sends "Hello World!" over HTTP, in ~20 lines of Python. &gt; Concurrence presents a familiar blocking IO model, while at the same time achieving high concurrency and low latency by using asynchronous IO in the background. Seems to be good stuff.
`html5lib` and `lxml.html` work fine.
There's some magic to be had, namely as tasklet functions can magically know their task through the super-`Tasklet`. It's not too bad though. This plugs some nontrivial holes in what Stackless Python (and greenlets) is: networking. I've myself tackled this problem, with varying success. Good thing I'm not alone these days!
as long as the browsers support it you'll have to it as well for any serious project.
I'm happy to see this. I am developing new projects with ZODB. I just move a PyQt app from mysql to ZODB as well.
The source code is pretty short, and provided. The most useful thing the module does is the attachment handling, I think. Somewhat useful.
why is this on /r/python?
You must admit the stock SMTP module is rather un-pythonic. This is overdue.
eh it is a bit unwieldy, but I don't see where he actually uses SMTP without downloading that source code.
That's the part that got me too. At first I was thinking that it was okay but nothing amazing then I read how it handled that and now I'm pretty impressed by it.
Cython looks seductive but does anyobdy here have a real experience with Cython ? 
As I see it, __stuff\_\_ is for interfaces, that cut across classes hierarchy. like __getitem\_\_ for example. The new ABC in python has the same philosophy. I don't buy "the reserved to python core"...
Uhm, something is broken here on 1.13: $ bzr log --format gnu-changelog bzr: ERROR: no such option: --format
A little. I had one class with overloaded __eq__ and __neq__ methods that I had to use for a ton of comparisons (~10^6 objects, lots of checking if the object was already in a list]. In pure Python, I was getting killed on performance. I cut this one class into a separate module (no change needed to the code), then compiled that module with Cython then gcc with all the optimizations. Immediately I got a speedup somewhere between 100x-1000x. I am a huge fan of what Cython can do (in the right situations). I have a small pain point of making sure that the latest version of the code is compiled (I often forget to run setup.py before running my unit tests). Thanks to the Cython/Pyrex developers!
via: http://www.voidspace.org.uk/python/weblog/arch_d7_2009_03_14.shtml#e1066 Introduction to ConfigObj Article
I have used BS for many little screen scrapes over the years. It will keep going because it is free. I think I will give him a couple of bucks in thanks for his hard work, making it easy for me.
This critter must become the official Django mascot!
It's all about [the pony](http://www.flickr.com/photos/ubernostrum/3252784273/).
That's pretty strong, I'm gonna start using that in all my projects.
[Awe, that's so cuuuuuuuuuuute.](http://www.thebestpageintheuniverse.net/c.cgi?u=irule)
EVEN STRONGER TYPING IS TO USE ALL CAPS!!!
Actually, the Django critter looks a lot like the Reddit Alien..
(Implementation for killbot left as an exercise for the reader.)
Awwwwwwww!
[or is it](http://hackety.org/2008/09/15/documentsRevealDjangoPonyTailOfLies.html)?
Pretty non-content blog post
Better version: def some_function(in_string): """ If you pass anything other than a string to this function, I will find you and kill you """ ... 
I love the critter badges on that someone created.
Meh, just lose mod_python and get mod_wsgi.
The Reddit one must be the evil twin then, cuz I can't get anything done around here.
You couldn't add "DB2" to the headline?
It's not just for DB2. It's for Informix Dynamic Server as well.
You couldn't add "DB2 and others" to the headline?
Sure, it could have been "IBM's Python driver for DB2 and others is out of beta". I kept the original title instead, but what's the big deal?
I'm glad to see IBM supporting Python.
the description is amazing. I think she nailed it.
anyone used boo - http://en.wikipedia.org/wiki/Boo_(programming_language) ? ^ reddit ate the link
If this is just for learning then Python 3.0. But if you will have to deal with legacy code or the libraries you want to use are not available for 3.0 yet then go with 2.6. But honestly, learn 3.0 regardless and then pick up the differences with 2.6.
Well I guess I should give more details. I, currently, am just learning, but I do plan (if I don't give up, as happened before) to eventually use it. My direction is not clear though. I'd like, in some form or another, to have my own business one day. I assume most likely that will be web based, whether it's simply a web site, making games, applications, etc... This is the first language I've learned, and currently the one I know best (eg. not so much), but I figured it'd be both a good learning tool and I'm sure it will come in handy for practical purposes in one way or another. I'm sure that will be, at the very least, 1-2 years down the road though. I know that external libraries will take time to catch up, but I'd imagine by the time I'd start to get into doing actual... 'work' most will have, or there'd at least be work arounds or w/e. Besides, I'm sure I can apply my knowledge to python 2.6+ if need be anyways. From what I've gathered they aren't drastically different, it's just that it breaks alot of compatibility with 2.6 based libraries. If it matters I'm planning on learning along with 2 or 3 other guys. We'll all be working together and sharing ideas/knowledge etc. I'm pretty sure I know more than they do about python, so I figured that likely wouldn't be a factor and what I decide, on this, they'd go with. I'll have to talk about it with them of course though too. I *knew* pretty much everything about the core language, and quite a few built in libraries, though that was over a year or 2 ago and I've just dabbled in it since, so I've pretty much all but forgotten most of it. Now I'm coming back, and... well, need to decide where to pickup at. 
Then I think you should go 2.6. Try Django, it's pretty easy even when you don't know python very well; but afaik it works only with &lt;3.0 for now. Same goes to other web frameworks.
That's awesome. Also, somehow kind of fitting for the project and all :). On a related note, how long can a small girl hold her breath?
 def some_function(in_string): if not isinstance(in_string, basestring): raise TypeError("I will find you and kill you") some_function("hi") some_function(some_function) *Edit:* Using voidspace's suggestion of isinstance'ing with `basestring`
If you want to use it within 6-12 months, go with 2.6. most libs will take *at least* until Python 3.1 before they *start* porting to 3.x
basestring :-)
It's not at all clear that this is about a database adapter. You're getting a bunch of downvotes because of this.
 def some_function(in_string): if not isinstance(in_string, (str, unicode)): raise TypeError("I will find you and kill you.") `isinstance` can accept a tuple of types to check against.
I am a guy but I gotta say "Awwww..."
There's not much difference between well written 2.6 and ordinary 3.0. Just pick up Django in 2.6 and be aware of the small changes that are in 3.0. It's not a big deal as far as changes go, it's just that it breaks existing code. 
3.0 or bust.
Checkout pyimportx in this version, it makes the compilation automatic(and you can even have it attempt to compile pure python modulels and have it fallback to their normal python excecution if you want).
2.6, definitely. 3.0 is too new / not ready for prime time. Part of the appeal of python is its seemingly unending supply of third party libraries, most of which don't work in 3.0 yet.
Maybe it's because I'm mathtarded or maybe it's because I just woke up, but after reading that, I'm not 100% sure of the answer to this question: If you didn't want to know all primes up to *n*, but only whether *n* itself is prime, would the last, best algorithm presented in that post (which would have to compute all primes up to *n* regardless) still be the fastest one of the bunch? **EDIT**: Folks, my question has been answered perfectly well by nevinera, you can stop posting factoids that are merely vaguely related to it and absolutely not an answer ...
The best algorithm for that (that was presented in the article) would be the second one - it is O(n^.5). The best variant of the last method still runs fully for all primes up to the square root of n, so that would be at least O(n^.63) = O((n^1.25)^.5)
My thinking is that if more people start using 3.0 exclusively, then developers of said libraries will have more of a reason to get them working.
This saves tons of time. Thanks dude!
To see if *n* is prime, you only need to try all the primes up to sqrt(*n*).
I played a bit with the python code ... The idea that, when you build the array of primes against which to check *n* in the third algorithm, you can stop at sqrt(*n*) instead of *n*, is pretty nifty. Speeds things up *a lot*. But not enough to beat the second algorithm, of course ... now I can see that. Thanks!
[wikipedia to the rescue](http://en.wikipedia.org/wiki/Primality_test)
No problem, I hope it can be of use to you, so my three days of work haven't gone to waste.
Great! Thanks poro!
2.5 if you want to use anything with numpy...
No problem, I am quite loving it. Also, I found gpulib, which looks good.
Yet another blog entry that reinvents a sieve of Erastothenes. Is this what the blogosphere is about, recycling trite stuff in dumbed down language that can be found more clearly and comprehensively elsewhere?
actually its whatever the hell someone wants ot write.
Great stuff, but do we really need more social networks?
Wow... I clicked on the link and saw your site then thought... [this looks familiar](http://www.dragonvein.org/). _(note: my WoW guild site =p)_
Voted down. From that link: &gt; Initial development of PyStream was done by Tech-X Corporation. Tech-X Corporation **has shifted its efforts to a new GPU related project, called GPULib**, that has a higher level API than PyStream and also supports other languages other than Python. Because of this change, **PyStream is no longer being actively developed**. However, PyStream will remain available under the BSD license. 
You first.
Uh, I've been using 3 exclusively since January.
Absolutely. SMTPlib is horseshit.
leonh complained that PyStream is no longer being actively developed. There is another package, pycuda, that supports CUDA. http://mathema.tician.de/software/pycuda I have been meaning to explore this for quite awhile, but haven't had the time yet. Since I haven't used either yet, I don't have an opinion of the relative advantages of either package.
I have been doing this for years. I have around 10 active projects in pyqt right now. I am a heavy VIM user but I find I spend most my time in Eric3/4 the debugger rules. I use inno to deploy as well.
No, but there's lots of useful code here for other projects. Open source ftw.
pystream works, gpulib doesn't (in Windows, anyway).
See http://www.reddit.com/r/Python/comments/85lpi/pycuda093betawin32py25exe_binary_for_any_redditor/
tried PyCuda? 
Sadly, yes: http://www.reddit.com/r/Python/comments/85lpi/pycuda093betawin32py25exe_binary_for_any_redditor/
Thanks for that, and now I see that's currently directly next to this entry on the Python tab. While I am using Linux, I feel your pain on trying to get some use out of it. As I think back, I too got into some issue with upgrading boost, having some sort of problem, and resolving to get back to it someday. And, I still hope to get back to it, because it seems like there are some significant advantages to it. Good luck as you go forward.
Same here, I tried to use Linux with no luck :/ After having compiled it, though, I probably could make it work in Linux too, but my main OS is Windows so it's better. I'm working with it now (trying to find how to work with multiple blocks) and it's very interesting... PyCUDA allows you to do anything, if you can get it installed. pystream (and gpulib) allow you to call CUDA functions and nothing more.
So did I, until I got "busted" in #python and they advised me to stick with 2.x for now. That is, I'm learning Python.
via: http://ironpython-urls.blogspot.com/2009/03/using-nose-with-ironpython.html
Let's sit and wait until Zed tries to do anything that doesn't fall into Django's path. We'll probably get yet another Zed's rant that Django is a freakin' mess. zzzz. 
&gt; I’m going to Prague for EuroDjangoCon **2008** to give a keynote woah (as in Keanu); time travel
I believe he posted something to the effect of him trying to turn a new leaf and get away from the negative rants.
Yeah, felt that his quote &gt; [Django being cool] in no way states that your framework isn’t also good. Sorta implied such shift in attitude.
I thought he gave Django a good short review, but one thing he said - "usually I only hear this complaint from Emacs users because somehow Emacs fucked up the Python editing mode so that it uses inconsistent tabs and spaces.... I usually recommend people use any other editor than Emacs,..". I've coded in python for years with Emacs just using the standard python mode and I've never had a whitespace problem. Just lucky, I guess.
&gt; In Python code mixing tabs and spaces is the **death**! In Python 3 it is worse then death - it is an error.
&gt; Usually I only hear this complaint from Emacs users because somehow Emacs fucked up the Python editing mode so that it uses inconsistent tabs and spaces. I just checked the 30kloc of python files for my work site, all edited in Emacs: no tabs. Does anyone know what he's talking about?
Honestly, I don't see it happening. There's something about django's culture that allows people to critique without others getting defensive. http://jeffcroft.com/blog/2008/jul/25/top-ten-things-suck-about-django-revisited/ is an example of how django devs are critical of the framework as well. That's a good thing.
Actually, I'd argue that python 3000 is much better, since it pretty much eliminates the problem. An explicit compilation error is always better than code that looks like it does one thing but actually does another.
I was trying to switch from vim to emacs. Python and php modes both caused me great headaches so I switched back. Not really emacs fault, but that stuff sorta works out of the box in vim and python required some fiddling to get working, which I didn't want to waste time on. Plus my pinky started hurting :P
&gt; This change in the architecture of a site from “the site is the application” to the “site has many small applications” is powerful to me. There are some good things about PHP.
To paraphrase some things mentioned — "I don't know python almost at all, and I've just started messing around with django, yet I'm already going to djangocon to give a keynote" — how does this magic work?
I just browsed the code a bit. So far, this is just a GL wrapper and not an engine (right?), but this is about to change, right? I'm just hoping the engine will be more helpful about handling game state and the updating thereof than how this is done in the example game :) Don't get me wrong, I really like how simple and short the example game's code is, and every change I'd make to it would probably make the code longer and more complex. Aside from the fact that this project could be very interesting for people who'd like to help develop it, is there a reason to use it right now, instead of one of the more established GL wrappers for Python? And, once it has arrived at being an engine that is easy to get into for beginners, will there be a reason to use it for people who already know how to do 3D programming and might also go for Ogre or CS or whatever?
I'm new to this -- what are some of the more established GL wrappers for Python?
This is pretty interesting, I never knew about the dis module.
I don't know statistics on which are the most widely-used ways of getting at GL from Python, but I can give you some pointers if you're interested in trying some GL coding in Python yourself. Setting apart higher-level stuff that abstracts GL away (and might just as well have a DirectX backend) and gives you scene-graphs and stuff, it is customary to not try to make things 'pythonic' and give you a pretty unadulterated OpenGL API, to the point where the lines of code inside a function could be both valid Python and valid C (Python won't complain about semicolons terminating lines). There's two ways to go about this: You can have a pure Python module that directly hooks into GL via ctypes. IIRC Pyglet works this way. Performance suffers this way (especially if you code in the 1.x era OpenGL style and do lots of immediate mode stuff), but you have fewer dependencies. Or you can have a Python extension module written in C; in that case, you have to put a platform-native binary in place, but the module itself will look practically identical to you. PyGame gives you that (and all of the SDL as well). PyGame is more established, but I recommend both alternatives. In the higher-level area, you have mostly C and C++ engines for which Python wrappers are available. For example, there's the popular Ogre3D (no idea how many people use it from Python though), the somewhat odd Soya3D, or good old Coin3D. I'd say, before you play with those, it's always good to first start with something that gives you raw GL, because it's good to know what happens closer to the GPU.
er, black text on dark gray background? Hard to read :C
sorry :/ Plan to fix that.. eventually. I'm a wanna be programmer, not a web designer :(
Use a bookmarklet (works at least with firefox) from http://codepad.org/LEvGnH4c
just lighten up the background a bit, feels like there's a dark overlay right now, and the popup it's highlighting is just missing.
Well right now it's mostly a solo effort, we're just talking to one another mainly for motivation to see how each other is doing stuff yunno. If we've got questions we discuss, but so far we've just started and we, or at least I am, (are) taking it kinda slow. If you want you can join in with us, pm me and I'll give you my email address or aim sn or something. Er.. actually, this is my aim sn (kryptobs2000). I've read learning python and about 1/4 of programming python (just what interested me). That was a year or 2 ago, so I need to refresh my memory in almost everything. So right now I'm just going through the python docs, they're a very good learning... guide, I guess you could put it. From there I'm not really sure. 
Waouw. Now, there's no more raison to use launchpad instead of redmine+transifex...
I keep trying to find the lightbox, then i realized the site actually designed that dark.
Yeah, my first thought was "wow, who put the lights out?".
hey, thanks for listing this!
working on that now..
more acceptable now? A bit easier on the eyes? Please don't judge on pure eye appeal, but on readability. I'm already aware it's not the prettiest site in the world.
I thought this was going to be about the [glassware](http://www.pyrex.com/).
is it possible to choose a worst license for a game engine than the one the pysoy devs chose?
While he makes a few interesting points, I couldn't help but chuckle at the "elegance" of "writing C code in C".
As did I, but then I noticed the subreddit. I was expecting another informative article on how the "world's kitchen" branded pyrex is no longer borosilicate glass and thus cannot stand up to the rigours expected of it especially those of thermal stress. Pity corning sold the name off :( Anybody have any sources for real borosilicate cookware?
Why not avoid all these headaches with threads altogether? Use Stackless along with [multiprocessing](http://docs.python.org/library/multiprocessing.html) (if possible)?
Anyone have any thoughts on how this compares to BeautifulSoup?
It's much, much, much faster; and the query system is more powerful &amp; flexible (as you can use XPath, which is pretty much the only nice XML technology). I don't know if it parses tagsoup as well as BF though.
I'm a big fan of e4x over XPath.. you familiar?
I wrote to him about this, saying, "I've used Python and emacs out of the box on numerous machines and never a problem." He wrote back, obviously not having read what I wrote, saying, "Yes, a lot of users report that problem too." I wrote back saying, "No, I said I'd never seen the problem on all sorts of machines." Last I heard from him. I hate stuff like that - Fear, Uncertainty and Doubt.
I'm baffled by this... I tried several random machines, wrote tiny Python programs, no sweat. Are you on Windows? Perhaps this is a Windows-only thing (I don't have access to any Windows machines)?
I've read a bit on it, I find it not as good as XPath for pure selection (it mixes selection and action, only the descendant axis is well handled ascendants and neighbors nodes aren't). On the other hand, it's correctly integrated with the JS syntax which is cool. It does require the addition of quite a lot of syntax though, which can potentially leak into uncaught "general javascript" errors due to dynamic typing. 
byteplay is a great module for playing with bytecode.
Sure, I'm always interested in parser libraries and if they work with 3.0, the better. Thanks for writing it :)
But my understanding is that lxml only works with well-formed HTML. I use BeautifulSoup to parse other people's HTML, which I can't guarantee is well-formed. How does lxml perform with potentially bad HTML?
O__________________________________________________o Hi, I'm Chris Hanson. Why don't you take a seat over there.
I guess I'll start then.
Maybe you're not aware, but lxml has support for BeautifulSoup generated trees, as well as the fact that BS has given up writing their own html parser and recommend using lxml.html for that
If you use [lxml.etree.HTMLParser](http://codespeak.net/lxml/parsing.html#parsing-html), lxml will try to make sense of whatever you give it, with a error-recovery rate similar to what you'd get from a browser's parser.
&gt; But my understanding is that lxml only works with well-formed HTML. Nope, the lxml.html package parses "real world" HTML aka tagsoup. &gt; How does lxml perform with potentially bad HTML? According to Ian Bicking [it performs better than BF at recovering fubared HTML](http://blog.ianbicking.org/2008/12/10/lxml-an-underappreciated-web-scraping-library/), and the document it yields and the queries you can perform seem to be much better (e.g. it understands lists of classes, while BF doesn't). And of course [it's much, much faster](http://blog.ianbicking.org/2008/03/30/python-html-parser-performance/). BeautifulSoup apparently does better encoding detection and handling though, which is why lxml integrates BF's parser in case you need it.
What advantage does "safesec" have over [Brent's Method](http://en.wikipedia.org/wiki/Brent's_method)?
I am the author of the blog post. &lt;b&gt;Update (20090324):&lt;/b&gt; According to &lt;a href="http://kbyanc.blogspot.com/2007/07/python-serializer-benchmarks.html" rel="nofollow"&gt;Extra Cheese&lt;/a&gt;, cjson 1.0.5 has an incompatibility with simplejson in processing slashes. A fix is available from &lt;a href="http://www.vazor.com/cjson.html" rel="nofollow"&gt;Matt Billenstein&lt;/a&gt;. However, Dan Pascu, the author of cjson, deprecates Matt Billenstein's cjson 1.0.6 because Matt's patch parses the JSON twice, which makes it twice as slow. This will still be faster than all alternatives in certain circumstances. You will not find Matt's cjson on the cheeseshop, only on Matt's site. 
Not really, just references to generic network programming books and guides. They're good references, but there's nothing specific for S60 here (yet).
Not helpful at all. As the [pydoc warns](http://docs.python.org/library/socket.html) a lot of BSD-style sockets are platform dependant. I'm pretty sure pys60 sockets use P.I.P.S API for sockets, some interesting info on P.I.P.S sockets can be [found here](http://developer.symbian.com/main/documentation/books/books_files/pdf/P.I.P.S..pdf). Notably, &gt; P.I.P.S. supports a subset of standard socket options and IOCTLflags. and &gt; P.I.P.S. supports a number of 'non-standard' socket options that enable &gt; access to native networking features To complicate things py60 only recently replaced an older socket module (based on Symbian OS sockets) with the BSD-style sockets. The old API has been renamed `btsocket` and can still be used- [see pys60 changelog](http://tinyurl.com/cle9gu) . There is functionality in `btsocket` which isn't in `socket`. Most pys60 programs, including Nokia's pys60 examples, still use `btsocket`. I'd also like to warn about different behaviour between pys60 and cpython. In pys60 `gethostname()` will always return `localhost` no matter what interesting network adapters are online. In cpython the adapter facing the outside is returned by default. I couldn't find a nice way to choose between network adapters in `socket` (although you can in `btsocket`). I'd like to know if anyone has worked out how how to do this- I made a work around that pinged an outside server that then replied with the phone's IP. To sum up, py60 implementation of `socket` is relatively new and I have been bitten by a couple of bugs (tip: stay away from `makefile()`!). There are now monthly pys60 releases that will hopefully go some way to fixing these. 
About time!
Still no interlaced PNG reading support. Revert back to ImageMagick. ):
Au contraire. This change was long overdue. As elegant as LISP was it had no success outside of Paul Graham. When reddit switched from LISP to Python, that was the signal that even good ideas, without serious development end up collapsing under their own weight. It's heartening to see MIT getting honest about this finally.
so is the MIT course available on the Net ?
I switched to Python from Lisp to do web dev. Lisp simply doesn't have the tools, its module system is a mess and the language is still largely stuck in the 80s. That said, I think it's a /huge/ shame that MIT is moving away from it in teaching. I've heard Gerry say that "Python is basically a Lisp". Regrettable, and probably an indication that he doesn't program anymore. If the language doesn't treat data as code, it's not a Lisp. "Data as code" is a fundamental idea which lays bare fundamental concepts in computer science: logic, symbolic programming, the abstract syntax tree. This stuff is very difficult to demonstrate in a language like Python... you have to do acrobatics to do what is possible in a few small obvious lines of Lisp. So, it's really sad they're not using Lisp in teaching any more. The "messy world" justification Sussman gives for using Python is really an indication of the failure of the /Lisp community/ to further develop the standard, and particularly the failure to develop a standard module system and a proper compiler (which produces stand alone executables). These things make Lisp horribly impractical, and make it very difficult to build up a community around the language. But this is not a problem with S-expressions or any of the fundamental concepts of Lisp - it's a failure to design specific facilities into the language standard. It's practical things like this that have held back Lisp. Someone needs to redesign the thing to solve this stuff. Paul Graham sadly squandered the interest he generated around Arc by failing to solve any of the problems which are actually holding Lisp back. I'm using Python now, and it's cute, but I feel like I'm coding with my hands tied behind my back. The perfect language hasn't arrived, but when it does, it'll have S-expressions and a python-like module system. When we have it we'll be able to deal with the messy complexity of the real world and the deep problems at the same time - this new language will allow us to build a web framework that will put Django and Rails to shame. We'll never look back. I'm still waiting.
That's not the point of education, i.e. to teach students about Computer Science. Scheme can do that as easily as python, if not better.
The paraphrasing seems to lack any reasonable argument. IMO its always good to think a lot and write a little rather than the other way around. And.. i dont see what scheme/python have to do with any of that. The last paragraph basically gave away the answer that they wanted the undergrads to be "productive" from day 1. 
Seems like once you really get LISP you lose your perspective and no longer understand what everyone on the outside doesn't get. You start to think that everyone would care about code and data interchangeability, etc. It's been mentioned elsewhere, but what LISP needs is a leader and a useful showboat project. Where PG failed is that arc is totally, utterly wholly and in every possible way useless. He's totally stuck inside the LISP universe. Now if you wrote a C compiler in LISP, why hell, that would be useful, and a non-trivial LISP project (as opposed to writing a LISP in LISP) Think about how cool it would be to easily extend the compiler with LISP. C programmers everywhere would flock to it, because C is more common and therefore useful in the real world. But because C is really complicated, C tools basically have to tend toward becoming a compiler themselves to do anything interesting. I would love to manipulate the syntax trees of my C programs with LISP.
This report makes me feel somehow very content. Scheme has been a great trainer and mind stretcher for me, but it has never felt comfortable for large scale development. I see much enjoyable parts of Python that is Scheme-ish (or Lispy) and I adore Python in general, and always admired MIT, so this decision "feels good" to me. Now, had they honored c++ or, fsm forbit, visual basic, in the same way, there would be hell to pay.
What languages does the job market ask for most?
You've hit on the key points. MIT's big problem is a cultural fear of failure. Actually working with the technology up to your elbows, as a professional coder must, mandates a near continual admission to one's self at the very least, and possibly to ones colleagues, of lots of small and large failures. This fear underlies a basic disrespect for the tools of the trade that was certainly endemic in the lisp era. There's no shortage of brain power at MIT, there is or was a serious shortage of cultural growth and ironically Paul Graham's essay on [the identity issues of non-experts applies very much amongst the experts](http://www.paulgraham.com/identity.html). The things we often talk best about are the things we know about ourselves but do not often acknowledge. &gt;I switched to Python from Lisp to do web dev. Lisp simply doesn't have the tools, its module system is a mess and the language is still largely stuck in the 80s. This is why the world developed in C++ until the late 90s when some guys managed to break out of the culture and get to Java. The whole Java/Internet era has been about making the ideas from lisp actually useful. What are the DOM and the browser all about if not a poor man's lisp/emacs with a naive attempt at handling and simplifying window manager issues? Smart people need love not fear. Change the culture of fear to a culture love and the solutions you wish for will follow. 
Then why does squeak exist?
English. Sorry, [no Klingon](http://www.boingboing.net/2003/05/11/qapla-hospital-seeks.html).
&gt; never felt comfortable for large scale development I had the same experience.
There are technical reasons for why scheme is not compiled. Because it is a dynamic language types have to be tracked no matter what. Because real closures exist garbage collection is a must. It is possible to compile executables that do this but then every executable that is made must contain this repeated functionality. The executables end up not really faster than just interpreting either. Python has the same issues. RC6 standardized a module system for scheme. The real problems with scheme are simply not separable from its strengths. The incredibly consistent syntax of scheme for example means that scheme code can be hard to read because it all looks the same. 
It's like you stepped out of some 60's CS dept....upvoted!
&gt;Scheme can do that as easily as python, if not better. Try to express an algorithm in Python, and then in Scheme before making that conclusion.
Just came here to say that... I'm seriously considering reading the PNG spec and trying to implement it myself.
Just online readings and assignments: http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2007/CourseHome/index.htm
Really depends. "Think a lot, write a little" works if you're an academic, and would like to write the most elegant code. The majority of programming does not fall into that category - it's messy, unstructured, inelegant. As a scientist, I love python - I can run complex analysis with minimal effort, but I'm also not concerned about code elegance. Another feature in science is that you normally do not know what works best. All the thinking in the world wouldn't help you if the analysis *doesn't work* in the end. There's a reason why Matlab is so popular amongst scientists. It's fast to draft up code, it's heavily interactive, and operating on large data sets is relatively fast if you do it right. Yeah it's slow as a bitch if you don't do it right (which is true for *most* programs) and frequently ugly as sin. It's also retardedly designed, flying in the face of a majority of other languages (1-indexed arrays? wtf mate?) However, it does tackle the one thing that many proponents of functional languages overlook - practicality. I'm only running this analysis on one data set! The less the brain power I can devote to actually programming this silly thing, the better. Incidentally, python fixes the majority of these problems (first and foremost the $600 price tag). All the retarded indexing, inconsistent syntax, ugly code, mostly gone. It even has proper object structuring, and can masquerade as a functional language if pressed! It is definitely lacking partially in the interactivity arena, but efforts like ipython are definitely improving things.
I've only R6RS to blame and I [saw](http://www.nz.reddit.com/r/programming/comments/85cqh/too_much_is_not_enough_the_revised6_report_on_the/c08aglz) this coming.
Oh yeah, like Haskell's better suited for dealing with Real World problems. 
To make smalltalk environments look butt-ugly?
I have extensive experience in both, and they're both fine languages. But scheme is more natural; there's no imperative iteration, for example, unless you write a method for that yourself with `do` or `call/cc`.
&gt; IMO its always good to think a lot and write a little rather than the other way around. That works provided the entire problem is already loaded into your head. Back in the day, that was the case: there were fewer things to know and more basic problems needing to be solved. Now, however, much of that ground has already been covered by others. Where before it made sense to sit in deep contemplation of how to best implement an in place sort, now you should spend that time reading the documentation for the libraries you have available and *use* the solution that a previous programmer provided for you. There are still plenty of interesting problems to solve out there, but the inputs for those problems are much larger and messier: you'll be building on lots of existing code and solving problems that are much less cleanly defined. The end result: less time staring at a blank screen, more time reading docs and prototyping. This doesn't mean programming is less thoughtful than it was before, just that the thinking process is more interactive now.
&gt; I'm still waiting. Sounds like you know what you want. Why not stop waiting and starting making it? If you're right, others will join in.
This sounds to me like a paraphrase of somebody that disagreed with the decision, and so characterized it poorly. I'd be curious to hear an explanation from someone who argued in favor of the switch.
I'd be interested. I think that any new language now would have to hook into an existing library framework though. A lispy syntax that can use python libraries would get my goat.
You can naturally express recursive algorithms in Python as well. You can also express iterative algorithms in Python naturally too. While any iterative algorithm can be reformulated as a recursive algorithm, it's not always natural to do so. Examples include many graph algorithms, e.g. breadth first search with the use of a queue. The way an algorithm is expressed in Python is more similar to the way that people conceptualize algorithms (written in pseudocode).
&gt; A lispy syntax that can use python libraries would get my goat. If Java libs are close enough for you, try Clojure.
I'd have to re-learn them, but probably. Thanks for the tip :-)
It's exactly the situation in mathematics. A small subset continues to examine the foundations, while most use those foundations, and expand upon what works.
&gt;The way an algorithm is expressed in Python is more similar to the way that people conceptualize algorithms (written in pseudocode). Winner!
awesome thanks !
you already know the answer right ?
Good analogy. Saying every CS or programmer should be using Scheme is like saying every mathematician should be using set theory.
Clojure looks pretty nice. One of the best efforts out there. I don't quite understand how namespaces differ from packages. Do files have their own symbol tables (ala Python)? This is critical for modular development.
&gt; Smart people need love not fear. Change the culture of fear to a culture love and the solutions you wish for will follow. Yes and yes. The Lisp culture killed Lisp more than anything else. The new 'S-expression language' could do well leaving the old ways behind and pick up all the good stuff from Java, Python and Ruby.
Lisp is compilable: Fasls and images (on many systems) contain machine instructions, not byte code. The problem is you can't create small stand-alone executables. 
Sounds promising. One thing I've always hated is how slow Python 'for' loops are (compared to, say, MATLAB). Hopefully they can do something about that.
As I said in the post, I spoke with Sussman about this before posting my paraphrasing of his remarks. I wouldn't be so presumptuous as to think I knew what he was thinking, but my completely personal read on it is that he's fully on-board with the broader goals and intentions behind the switch. I think he probably has no particular opinion on the specific choice of python (vs. other possible choices that fulfill the same requirements), but he perhaps does take issue with whatever internal processes (the committee, etc.) were used to make that selection. In the longer, scheduled talk he gave yesterday (the day after his impromptu 6.001-related remarks), he railed very hard against the notion of trying to dogmatically squeeze every problem in the world into a single approach or programming language. IMO, Scheme (and other lisps) happen to be outstanding solutions for a very large set of problems that happen to be some of the most challenging problems that we face in computing and the world. That doesn't speak at all towards completely different types of problems, including those that are perhaps more commonplace where "doing science on the components you're working with" is the only way to get things done. The best solutions there may or may not include a lisp, or whatever your preferred language/environment/approach may be.
It is my experience that Matlab's for loops are just as slow, hence techniques like vectorization. But I haven't measured it.
No, they're *much* faster, at least in newer versions of MATLAB. But if you're careful and vectorize your code, Python might be faster.
So I take it you've never seen Chicken Scheme.
They're faster *now* because Matlab includes a JIT compiler. But it's still a little funny that you mention the speed of 'for' loops as a benefit of Matlab---even now most scientists I'm acquainted with complain about Matlab's slowness, continuing to exhibit a vectorization fetish.
&gt; You can naturally express recursive algorithms in Python as well. You can, but not very elegantly. No tail call optimization, for example. &gt; You can also express iterative algorithms in Python naturally too. While any iterative algorithm can be reformulated as a recursive algorithm, it's not always natural to do so. Examples include many graph algorithms, e.g. breadth first search with the use of a queue. You can iterate in scheme as well, just not with for loops and the such, which should not be necessary. Maps and folds are equivalent. &gt; The way an algorithm is expressed in Python is more similar to the way that people conceptualize algorithms (written in pseudocode). Yes, but this is mostly because people already write iteratively; I'm not sure this is a valid argument for or against python. Look, python is fine, but I was saying that python's pros might not be as pronounced in an academic setting.
Tail call optimization is good point. But I don't think it's a big deal in the sense that the recursive algorithms that hurt you are the ones that can not be tail-called optimized easily; i.e. the ones that run in exponential time. Many of those recursive algorithms can be optimized by converting them into iterative forms such as "dynamic programming". In fact, people who study algorithms spent years developing intellectual techniques to help design efficient "iterative" dynamic programming algorithms. And they have to do that because the current Random Access Memory architecture cannot automatically "optimize" recursive formulations so that they don't run in exponential time. In other words, tail-call optimization is a neat trick, but it's just the first layer of effective optimization. You are right that people have been very familiar with the iterative framework already. But that's no coincidence. Von-neumann invented the RAM architecture, upon which Knuth put forward the notion of "algorithms", which is a Python-like description of computer programs. A lot of things (such as array manipulations, graph traversals, etc.) are just more naturally to be done iteratively instead of recursively (using maps, folds, etc.). There's a guy at MIT who built a list-based architecture so that LISP can run efficiently and naturally on it, but I don't think it got anywhere.
&gt; They're faster now because Matlab includes a JIT compiler. They've probably had faster loops since around 2002. That 'vectorization fetish' also applies to Python/NumPy, but MATLAB is much more forgiving when you fall back on a loop.
It's not really just the way for is handled what's slow. It's the whole virtual machine. Compare the following: for i in xrange(50000000): pass with i = 50000000 while i: i -= 1 The later takes over two times longer. The way for works, building an iterator object, calling .next and handling StopIteration doesn't seem to be particularly slower than just everything else (unless for var in xrange is special-cased in the Python 2.5 I've used to try that).
Well, I think the difference is that I see scheme as an elegant way to produce algorithms, and you see python as an elegant way to represent algorithms. I think they're both fine in their own respects—scheme being more "mathematical", i.e., functional, the way we were taught to think of math, whereas python is imperative, the way computers work. Regarding the map and fold thing, that has little to do with lists, that's just a functional method of iterating and accumulating, `for loop`'s main function.
this sounds awesome, JIT, no more GIL, much better performance. It'll provide a very good stopgap while wait 5 more years for PyPy to do whatever the hell they're trying to accomplish
I can't get enough of this stuff.
1) i hope it actually comes out 2) hopefully it doesn't break my stuff
Do it! Seriously, do it! I am not really interested in interlaced PNG support but just want to cheer you on. Instead of wasting time on reddit you could actually do something useful! :) 
&gt; It's good to see friendly competition, and we think that should take up the challenge and see if we can produce faster pickling, run 2to3 and Django faster than what they can come up with. We also talked to IronPython and Jython developers and all agreed that some common benchmarks would be good. And maybe do weekly press releases about small speed increases? :) Exciting times ahead! :)
Heh, you're right. Thanks. I'll try it!
I find PyOgre to be very useful and simple. Though I haven't tried the other wrappers/engines.
&gt; So Google has launched the unladen swallow project Is there evidence that Google is involved other than hosting on code.google.com? I just found [Ars](http://www.reddit.com/r/programming/comments/87t1g/google_searches_for_holy_grail_of_python/) corroborating.
isn't this in the django documentation?
the first release of US has already shown a good 25%+ speed increase in most areas, PyPy on the other hand is still slower than CPython after 5 years of work
Doesn't everyone know the best way to do pattern matching in Python is via decorators? @match(condition) def func(blah): .... With type annotations in Python 3, this becomes even easier. Look up PEAK or email Philip J. Eby for more. 
I wonder if it will use Parrot eventually. Edit: Ah the mysterious downmods.
It is not fair to compare their approach. RPython is fe heaps faster than Python. I do think that the PyPy project will have their JIT ready soon, they are making great progress. It falls to be seen how unladen swallow will solve the coming problems. It feels as if they are being overly optimistic. Just as PyPy was in the beginning. 
Is this 'Python and the Holy Grail'?
Gee, where do you suppose Python got its name?
African, or european?
I think the PyPy project is more likely to have the flexibility to be able to easily add Parrot as a target than Unladen Swallow will be.
The snake.
(I know it didn't really, but don't act as if there's nothing else called "python" than Monty Python).
Doubt it... the two projects seem diametrically opposed on the subject of a JIT.
I do kind of wonder about the choice of v2.6 as the base. I mean, v3.0 is already out, so why not target that instead? I was not under the impression that there were a lot of changes to the VM between the two however.
2.x is supposed to be around for a long time. As an example, reddit depends on pylons, pycrypto, babel, flup, simplejson, sqlalchemy, beautifulsoup, cssutils, chardet, psycopg2, and py_interface -- and many of them in turn depend on other packages (mako, paster, nose, webhelpers, etc). Pretty much none of these packages will work on 3.x for a long, long time. 
No thanks Google, you see, he's already got one! _&lt;turns around&gt;_ I told them he's already got one! _&lt;snicker&gt;_
also look at [Durus](http://www.mems-exchange.org/software/durus/)!
Long, long time? You must be a young person. Few years tops for most of those.
Don't they both have a JIT?
Erm, why link to the Ars article? It includes nothing new that the Google Code project page doesn't. Way to promote quality journalism!
Internet time. Duh.
He's saying their JIT approaches are pretty much mutually exclusive. The other would have to throw out most of their stuff to join the other.
Because 3.x is too young arrogant and slow
Could be deadlocking, more probably a call to an external library is hanging and holding on to the GIL. The lockups are as long as 10 seconds at a time, so I see no reason why I couldn't get a dump of the current lines of code executing for all threads when this is occurring. Perhaps this reporting could even be automated in some kind of 'freeze_detector' module for time-sensitive python services. $25 just to show my appreciation for helping to free me from this locking hell.
I did this recently and used gdb to attach to the Python process and inspect the C stack of each thread. E.g. here is an article about it: http://www.python.org/~jeremy/weblog/031003.html
FYI, socket.ssl is not implemented last time I checked.
Tedious, not quite python scriptable, but getting closer. Whatever the solution, I'd have to run it live without interrupting the service. I looked up other remote debuggers and found these too: http://winpdb.org/cgi-bin/moin.cgi/WinpdbTutorial 
I had been thinking of using git under Paver. There is a build system called Vesta which caches everything used in a build, including strings. I think that git could make it easy to build such a system on Paver.
The vast majority of Google Python code is 2.x
I'm posting this as a test of mysterious downmods.
Looks like I can roll my own, with some pretty massive overhead though... http://www.dalkescientific.com/writings/diary/archive/2005/04/20/tracing_python_code.html
Couldn't you use profiling or a strace dump ? If it happens only in production your out of luck though ..
Yes, live in production. I mainly want detailed alerts to be emailed to me when everything freezes up in any consumer-facing apps I have. This is similar to how I have stack traces from exceptions emailed to me already. Something close to the solution is trivial to put together using [the code here](http://www.reddit.com/r/Python/comments/87zbh/ask_good_general_way_to_locate_the_lines_of_code/c08i3yf), just really slow.
Could be the garbage collector checking for cycles. You could try by forcing it at a time you know about.
Sweet, sweet and more sweet. Thanks Google.
Why posting link that someone have already posted? and with the same title??
I don't know the answer, but perhaps you would do better to ask your question on [StackOverflow](http://www.stackoverflow.com). Whole site dedicated to Q&amp;A, I like it a lot.
Yeah they had some answers that are close. I'll try tonight.
Use brain, look for deadlock! :-) Ok, more seriously: you did not specify what kind of synch primitives you are using. Just locks? Semaphores? Condition Variables? If you are using condition variables, chances are the code is issuing naked "wait" calls. You get deadlocks that are cleared when another thread does a notifyall. If you do something like: "if(X): foo.wait()", it is almost guaranteed to be wrong. The condition must be wrapped in a while loop, like so "while(X): foo.wait()" because there is no guarantee X holds at the moment of wakeup. Let us know what synch regime the code uses if you want informed help.
and I got two of them.
I've had a 100% success rate at getting answers on SO, most of the time within a few hours or less.
Yes, it is fun to see how trivial patterns in Python look like. I have implemented many patterns in Python without knowing that the technique has a name -- it seemed straightforward.
[1](http://lmgtfy.com/?q=holy+grail+of+Python+performance) [2](http://lmgtfy.com/?q=holy+grail+of+Python+performance) [3](http://lmgtfy.com/?q=holy+grail+of+Python+performance) 
Attach to a deadlocked process with gdb. Go to the frame that corresponds to the Python call. Use the gdb helper scripts at http://wiki.python.org/moin/DebuggingWithGdb and you'll know exactly what line of Python code is being called.
First: I am insane. Now that that's out of the way: Write a python script to replace all newlines in your source file with "&lt;newline&gt;print LOGFILE '&lt;thread&gt;:&lt;next line of code&gt;' &lt;newline&gt;" Run the logified script and look at the logfile to see what executed last before the fall. I am insane.
I approve.
I have done this. It works like a charm, though you really see how not-in-order the lines are run in a complicated program.
There's also an equivalent `hgshelve` floating around (Google for it, I don't have the link handy), and in general I prefer to use Mercurial's APIs when I'm working in Python (since Mercurial _is_ Python, which makes things much easier).
I've done a few OpenGL games in Python, and I use [Pygame](http://pygame.org) to get a window and input events and [PyOpenGL](http://pyopengl.sourceforge.net/) for OpenGL calls. Be warned, PyOpenGL is really slow in immediate mode. With display lists and vertex buffers you can get semi-complex scenes at reasonable frame rates, but for high frame rates or complex scenes you'll have to put at least some of the draw code into C.
http://hg.piranha.org.ua/hgshelve/ It may need update to current Mercurial API, though that's not so hard. ;-)
Given my extreme love affair with all things git, I think I'm going to start using this right away for storing all data for no good reason :-)
Shouldn't that be 'SyPy'?
No mystery here.
Comments on Reddit, he said?
This is silly.
This is a lightning talk, they are allowed to be silly. Take a look at Jesse's other 2 talks once they're up, he knows his shit.
Yeah, I can guess you've suffered in the wide world. I feel for ya, man. Being ugly ain't easy. But my experiment was to observe the random downvotes that have been occurring on Reddit that have nothing to do with the topic. I hope you can afford to get some medical attention or plastic surgery to remove that ugly that's all over you. Best of luck.
4chan IRL? My gods.
This is awesome, Soo funny.
Haha what on earth?
This is not funny.
It would be good to collect them together, I find my self implementing them in the GOF style, but am sure there are probably easier ways sometimes.
I can see shit for all the lindberg'ds on this page
Why don't you just tell the reddit guys up on stage that you van lindberg'd them.
You're just jealous because people find its submissions more useful than yours :-)
Just sat through a keynote where the two founders basically said they believe otherwise. Whats your proof?
I hope SciPy and Matplotlib aren't too far behind, I can't wait to play with Python 2.6.
Would be cool if this could nicely format output with LaTeX or something. Also a variable workspace area (like MATLAB) would be useful.
Reinventing the square wheel. Four factory methods imbedded in the constructor rather then being exposed to the consumer of the class.
Why is this in python sub-reddit. 
Haha fucking coffee.
And I still got 3 upvotes :)
I know *exactly* what you mean. I use git with gay abandon.
&gt; I’m not totally used to the lack of curly braces, but I like the fact that you must have good formatting to have runnable Python. INDENT and DEDENT are your curly braces. If you're indenting properly, curly braces are superfluous. &gt; I was surprised to learn that Python is strongly typed which in some way I think is odd because it seems like it’d be simpler if it was weakly typed. Simpler, and insane and disgustingly error-prone like Javascript. In fact, I love the fact there's no automatic text to number conversion. If I designed a programming language, "3" + 3 would do little short of raising KillItWithFireException, in addition to attempting to delete the source code and log your user out.
&gt; Passing arguments by reference doesn’t seem to be possible As Alex Martelli puts it: &gt;The terminology problem may be due to the fact that, in python, the value of a name is a reference to an object. So, you always pass the value (no implicity copying), and that value is always a reference. &gt; I find it simpler to explain as: the semantics of argument passing are _exactly_ identical to that of assignment (binding) to a barename; you can fruitfully see argument passing as local (bare) names of the called function being assigned initial values by the caller (that's exactly what happens, in practice). Now if you want to coin a name for that, such as "by object reference", "by uncopied value", or whatever, be my guest. Trying to reuse terminology that is more generally applied to languages where "variables are boxes" to a language where "variables are post-it tags" is, IMHO, more likely to confuse than to help.
I think it's more helpful (though more complex) to think in terms of references to immutable/mutable objects. Tuples, strings, and numbers are immutable. `x = 3` means x is a reference to the object '3'. There's only one "3". Obviously, then, since you can't change the *number* 3, if you do `x += 1`, you get a *new* reference assigned to x, one to the integer 4. On the other hand, if you do `y = []`, y now has a reference to *some* (mutable) list. In other words, `[]` is not *the* empty list, just *an* empty list, which can be changed, and the behavior of `y += [1]` makes more sense.
LOL. I know that removing curly braces cleans it up. I guess I said that weak-typing would be simpler because Python itself seems to be a very “lazy” language and what’s lazier than “3″ + 3 = “33″? I see your point there, of course.
Wait...are we having this discussion here too? &gt;I guess I said that weak-typing would be simpler because Python itself seems to be a very “lazy” language and what’s lazier than “3″ + 3 = “33″? I figured "3" + 3 = 6 in a weakly typed language. Guess that's another reason for strong typing. Actually, I know it's another reason strong typing is superior. Once you understand how python's class system works and how to overload operators in classes and use them with metaclasses to create small embedded DSLs (for example, a crypto library where encryption is `cipher &lt;&lt; "plaintext"` and decryption is `"encrypted text" &lt;&lt; cipher` plus plenty of other features that would make it a true eDSL) you'll see the simple elegance of python's type system.
&gt; what’s lazier than “3″ + 3 = “33″? `"3" + 3 = 6` (or even better, `"3" + 3 = "6"`) And all 3 of these are potentially valid expectations for the operation. In other words, what's lazier than that would be knowing what the fuck the language is going to do, and "weak" typing removes that.
That closure example does not create a closure. The inner function is called inside the scope of the outer and only a value is returned. To create a closure, return the inner function only and call it outside of the outer scope.
Eh well in Javascript “3″ + 3 is “33″ anyway. At least we won’t have to worry about it with Python :)
Oops. You’re exactly right I totally spaced that, didn’t I? I'll fix it.
Thanks, suddenly I get what closure means. 
There's still no closure :) Now you just pass the `closure` function by reference. A closure is created when the invocation data of a function lives beyond its execution. Usually the invocation data is simply a stack frame, as it contains the values of parameters and local variables. The problem is that stack frames must be purged when the function returns. Languages that support closures either allocate the invocation data on the heap, or provide a way to move a stack frame to the heap if its needed. This is why I avoid the name "stack frame" and instead said "invocation data" (often called "invocation record" as well). For example: def outer(your_name): title = random.choice(["Mr", "Mrs", "Miss"]) def greeter(greeting): print greeting, title, your_name return greeter g = outer("Eric") # invoke it # g now contains a reference to the inner # function, but as that uses variables # from the local scope of outer, the invocation # data has been stored in a closure # Execution of outer is finished, but g # can still reference its local variables # through the closure: g("Hi") # prints "Hi Miss Eric" :D
Ok fine I'm stealing your example verbatim, even with the little jab. Thanks for the great explanation. Interestingly, I pulled my last example from a "closure" example in Programming Groovy by Venkat Subramaniam. 
I feel weird upvoting a twit(ter page).
You're welcome to it :) Strange about the Groovy example. It is common to mix function references and closures though.
Likewise. Sign of the times I guess... Anyway, anyone have any context? I wasn't aware there was a discussion going on. I'd be curious to see why they decided to go with Mercurial over Bazaar, and why Git wasn't on the list (or was eliminated as an option early on). Edit: Stumbled across Guido's [email](http://lwn.net/Articles/326201/) on LWN.
tweet.
They did an internal survey with the core-dev and git ranked significantly lower than Mercurial and Bazaar. Some other possible reasons that were mentioned at Pycon was that it wasn't written in Python, and it doesn't fully work on Windows just yet.
The command line git tools work just fine on windows with msysGit... but even that seems like a weird reason to have significantly lower preference considering Git seems to be in pretty wide use. It's the reason behind the ranking that I'm wondering about.
For educational purposes, could you post the 2 erroneous versions of your closure example so that we can learn from it? It would just be nice to see what arnar is talking about in his first post. 
There isn't a non-hacky official way to host GIT via a service to expose across http on Windows afaik
Might this also mean that Google will be leaning heavily towards Hg?
While I love the msys/mingw project, in my experience it's been kind of fragile, and git is (last I explored it) a complicated mess of code on the backend, so while it's great under posix, they may have decided the risk of unpredictable behavior was too much (even if it's working fine right now). But those are all wishy-washy reasons... the other thing is that python is not Windows and Posix. It's windows, posix, macos, and a number of other environments and architectures I can't think of at the moment. For that reason, any vcs they chose is gonna need to be extremely stable across a wide variety of hosts. Not just stable, really, but designed from the ground up to be natively cross-platform, and take advantage of each platform as best as possible, with sane predictable behavior across multiple hosts. Msys, with it's dos&lt;-&gt;posix path munging, continually has issues in this realm. Seen under that light, git drops further down on the list. While it works under windows, the current edition is still very posix-oriented. Hg &amp; Bzr, on the other hand, are pretty platform independant, so that's probably why they were the main contenders, given that non-distributed systems like Svn just aren't right for large open source projects. In the end, the thing which probably made the decision was the written-in-python aspect of Hg... anything written on top of python gets some very nice cross platform support (just using the "os.path" module fixes so many problems), but more importantly, GvR seems to really like to eat his own dog food, to prove python can hack it; even when the language is successful enough that no one thinks he has to prove his case anymore. Because of all of that, I'd have been somewhat surprised if they picked anything else in the end. (-- Not that I'm bashing git. It's dead perfect for what it was originally written for, and it's been rapidly expanding into other arenas since then. But the right tool for the right job, and there's currently enough specialization that no one vcs works for all cases.)
Sure thing -- 1st) &lt;pre&gt;&lt;code&gt; mystr = "outer" def change_mystr(innerstr): innerstr = "inner" print innerstr #prints inner def closure(string): string = innerstr+"closure" return string return closure(innerstr) mystr = change_mystr(mystr) print mystr #prints innerclosure &lt;/code&gt;&lt;/pre&gt; 2nd) &lt;pre&gt;&lt;code&gt; mystr = "outer" def change_mystr(string, closure): return closure(string) def closure(string): return string + "closure" mystr = change_mystr(mystr, closure) print mystr #prints outerclosure &lt;/code&gt;&lt;/pre&gt;
Yay!
Interesting, thanks for the insight :) It definitely makes sense to eat your own dog food, but I would think that'd be mentioned explicitly if it factored into the decision making at all. I would probably assume Hg as well just for that reason.
Deja vu...
I like it -- came here to post it myself, in fact.
ACK.
actually the os.path is not that usefull cause on win32 one wants to work with the unicode apis and on any unix one can only try to guess the encoding of the filenames so encoding is the main issue, and thats not solved nicely yet, as its a social problem on any unix platform (except plan9, where i know for sure that utf-8 is a given for filenames)
So far they've been a mix of svn, p4 and git.
Think you mean 'twot'.
Don't mind me, I was just being dumb. It's an acknowledgment of surfsat's contribution, despite the fact that I've ignored it for the sake of wordplay.
I was just being dumb in kind. And making fun of Twitter a little bit.
*facepalm* I see it now.
I usually call it an environment that gets magically linked with a return value.
I was looking for something like this before. I hope that this works better. Does anyone here have any experience with this lib?
Dear OP, I have some questions. Was Perl choosing git the death nell? Was this a well thought out choice or one of passion? Hg is Python based, how much did this fact contribute to the decision? 
I've never used Mercurial before, but I have to say I'm happy to see this anyway. I haven't heard of a high profile project picking Mercurial in a while. As much as some folks might like to see one DVCS to rule them all, I *like* that there's some diversity and some competition out there. 
I use it for PDF support in my [online word-counting program](http://felix-cat.com/tools/wordcount/). Getting the international support set up was a big pain, and I had to modify the code for my needs, but it's working pretty well now. I also believe that the author can't distribute the international support files, so it's not really his fault it's such a pain to set up.
I'm a non-canonical employee who also agonized over Hg vs Bzr, but finally chose Bzr. It's been good, and extremely flexible, for my style (and scale) of work. It's also been very reliable despite the repository formats having been changed several times since I started using it (upgrades have been smooth). But it seems to me that in these luckly post-cvs days, it really matters so much less that it has in the past as to which VCS one chooses. Conversion between them is a lot easier than it once was; some of them even have built-in/plug-in interfaces directly to other repositories. It's all good (or at least *mostly* good). 
isnt up to date but I used to get great results with [threadframe](http://www.majid.info/mylos/stories/2004/06/10/threadframe.html). not sure if it runs against current python versions.
hashlib has some pretty fast C-functions (md5, sha1). If you don't mind a lot of collisions, zlib.adler32 is very fast. But what's wrong with hash(str)? `str.__hash__()`
Dear commenter, I have a question: Have you read [PEP 374](http://www.python.org/dev/peps/pep-0374/)? (in other words, did you actually stop do do even a little basic research to see if the answers to your questions were readily available? If not, perhaps you'd like to be VAN LINDBERG'D!)
Markdown please. It's just a blob of text here.
There are also a bunch of hg users internally.
&gt; But what's wrong with hash(str)? I guess it is not guaranteed stable across multiple runs.
Does that mean you shouldn't pickle dictionaries?
Don't think so, they work as far as I know. Can't exactly tell you why.
Nice typo :]
Wait, why wouldn't you pickle a dict? I haven't had a problem...
This one is a 'must' have aside from those specific malware removers offered free by AV firms. *I would like to suggest to poster - 'nekron'* to post this title under subreddit 'computersecurity' &amp; 'netsec', if applicable??
Don't do that. The pages get damp and stick together. Of course pickling dictionaries is fine. Gah.
Theres no problem but may I suggest [shelve](http://docs.python.org/library/shelve.html).
The first one: mystr = "outer" def changemystr(innerstr): innerstr = "inner" print innerstr #prints inner def closure(string): string = innerstr+"closure" return string return closure(innerstr) mystr = changemystr(mystr) print mystr #prints innerclosure and the second one: mystr = "outer" def change_mystr(string, closure): return closure(string) def closure(string): return string + "closure" mystr = change_mystr(mystr, closure) print mystr #prints outerclosure
http://docs.python.org/library/functions.html?highlight=hash#hash works great in a lot of parts of python. Which are you requisites? Security, plataform, ... The XOR function its very fast, but not usable in many requisites.
I am submitting this because I'd love to see more people giving thaughts about theses issues.
Haha, er sagte "Ficker"! ;-) 
To the 8 people who have downvoted this: WTF? Speak up as to why.
wtf is this bullshit?
nmap -PN -T4 -p139,445 -n -v --script=smb-check-vulns --script-args safe=1 192.168.0.1/24
There's not much there to revive.. it's 200 lines of ugly code. Also, if I were doing this for Django I'd use a custom templatetag.