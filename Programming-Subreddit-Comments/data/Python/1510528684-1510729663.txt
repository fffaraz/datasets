I assume the same way everyone gets hit by an elephant--"Failure to yield to a pachyderm." 
Thanks, it has removed the error, but now my spaceship keep going into one direction. How could I make it move with my kew arrows? 
How would one go about pip installing (or otherwise installing) the next version so as to use this code?
I think that these links will help with your use of pip. The first describes virtualenv, a way to isolate python installations. The second shows how to specify dependencies to a python package. https://virtualenv.pypa.io/en/stable/ https://pip.pypa.io/en/stable/user_guide/#requirements-files 
I love that episode of Nova - one of my favorites! 
They probably have a good idea what the Turing award means though.
You could also toss in some convolutional recurrent adversarial neural networks. That ought to do the trick.
What's impressive is someone finding a problem and solving it on their own initiative. It's very obvious when someone just writes a program so they can show it off on their GitHub and try to impress potential employers.
nice vertical shale
Renpy will display across multiple monitors. I'm not sure exactly what you need though? 2 separate screens or 1 combined screen?
Well, the short, short, short version goes like this: when in India, do as the locals do, and give the elephant some rupees in exchange for a gentle blessing... but do not drop the coin down her right nostril. Elephants are not vending machines. Most important life lesson.
Pyglet contributor here. We do have a lack of Mac contributors at the moment. If you're interested in getting involved to help fix this code, let me know! Or anyone else who owns a Mac and would like to contribute, I'm happy to provide guidance. 
* [Github](https://github.com/ashwinvis/caeroc) * [PyPI](https://pypi.org/project/caeroc/)
&gt; earning_est = df[0] #df is list dataframes - we are selecing the 1st on Wau, I can't believe that it is so easy. I need to check this out. I'm assuming, where there are embedded tables, Pandas may be always that easy and useful? You just may of converted me :-) Thank you so much for your help, this really opens my eyes and scrapping may become easier now for me!
This raises more questions than it answers. But I'll take it!
If you have language neutral storage needs use json, but if you are storing pure python objects use pickle. https://docs.python.org/3.1/library/pickle.html 
I just tried it, this is amazing, I get back whole table and then I can just pick what I need, this will be especially useful if I want to get several numbers from say financial statement where there are a lot of numbers. I'm Pandas convert, it is now next on my TO DO / to study list. Thanks again for sharing. Man, I was complicating it...
&gt; PyQt - Mainly requires Python 3.x; broken and limited support for Python 2.x What? It's fine. You can use PyQt4 or PyQt5 on Python 2.7. There's even a wrapper library called qtpy that's let's you use PyQt4/5 and PySide with either the PyQt4/5/Side API. It's written by the folks that write Spyder.
I've always read that pickle should be avoided because of security issues. Players can set their own descriptions, send mail, etc, which means they could inject their own data into pickle.
HR sends me applicants' GitHub profiles every week. I just like to see a good understanding of whatever language you choose, and general adherence to code styles. What I'm looking for is someone who will write code with me that I have to read and modify some day, so I want the code to be readable. I also like to see that the applicant is not afraid to dip into the deeper concepts of the language. For example, one applicant submitted C++ code that included *absolutely no pointers*. I was amazed. Someone who thinks they are ready to write C++ every day should be totally comfortable working with that feature of the language. I've only recently started doing Python at work, but general concepts that impress me in applicant code include demonstration of object oriented programming, use of 3rd party libraries (something that doesn't come with Python out of the box, I need to know you can run `pip install something`), and good code structure, such as spreading the logical weight of the application across light modules instead of depending on one core module that breaks its back with all the logic you pack onto it. In the end, it comes down to showing me that you're someone whose code will not drive me insane when I have to go over it and understand it. Bonus points if you extend out of the standard library.
Javascript is the booming language in America for web freelancers.
This is awesome! The broken part about modern recycling is that waste management solutions just dump everything without sorting, and consumers are responsible for sending the recycling to separate facilities. I hope to see waste management separating recyclables, or a consumer facing solution for automatically separating in-house.
Piggybacking, I would choose a modern JS frontend like Angular or React, and if OP is really bound to Python, put up a Flask server. I found most Python GUI libraries to be really strange to use, but we're in a Javascript renaissance.
You think so? Try installing it. First download it, then try following [these instructions](https://stackoverflow.com/questions/4010842/python-2-7-cannot-import-pyqt4): sudo python configure.py ImportError: No module named sipconfig I don't know what SIP is, so I suppose we'll have to go install that first. Going [here](http://pyqt.sourceforge.net/Docs/sip4/installation.html), we see there's only a pip installer for pip3, so we have to download it, unzip it, and then read this README: &gt; The SIP documentation (including installation instructions) can be found in the ``doc`` directory. Okay, digging through there: &gt; Next you need to configure SIP by executing the configure.py script. For example: python configure.py Okay: python configure.py Which spams a bunch of stuff all over my system and silently exits, so I guess that succeeded. Let's go back to PyQt4 and - python configure.py ImportError: No module named sipconfig ...on and on and on. Meanwhile, I have no idea whether (a) PyQt4 actually runs in Python 2.7 (lots of people complain that it doensn't), AND (b) PyQt4 can actually create fullscreen windows, AND (c) PyQt4 can actually create fullscreen windows on multiple displays , AND (d) PyQt4 can actually create fullscreen windows on multiple displays in MacOS, AND (e) some example code exists, or at least coherent documentation, that will allow me to create fullscreen windows on multiple displays in MacOS without spending two weeks digging through the source code to find the right function calls and trial-and-erroring my way to a result. I have no idea whether that's true, and there are reasons to thin it doesn't, like [this thread](https://stackoverflow.com/questions/3203095/display-window-full-screen-on-secondary-monitor-using-qt): &gt; I use this code for the second display in full screen successfully on both Windows &amp; Linux &gt; This doesn't work longer in Qt5. QWidget is shown on the first screen. &gt; Confirmed not working on Qt5. Moving window after setting fullscreen appears to work. &gt; I think problem with this code is that screen sizes may vary so just dividing full resolution with screencount is a gamble that may work depending on your screen resolutions. &gt; showFullScreen first, then setGeometry. Qt5 tested OK &gt; This actually does not work, WindowState is reverted to NoState when you call setGeometry. No, I can't even contribute to that conversation, because I just spent 20 minutes downloading GitHub repositories and spamming unofficial versions of Qt4 that are supposed to work with Python 2.7 all over my system, and still can't import Qt4. So I maintain what I wrote: Qt4 is broken on Python 2.7. It will remain chacterized as broken as long as even *installing it* remains a shitty experience.
I've been using https://teamtreehouse.com/ and "Learn Python the hard way 3". I've been finding a lot of success just using those two resources. However, I'm still a bit of a noob. Hopefully someone with more experience can weigh in. I'd also recommend going over to /r/learnprogramming. That's where I've discovered all the resources I use.
Made a page with free online resources for coding, cyber security, and lots of other tools: www.ashot.org/links.php All searchable and whatnot.
&gt; Try installing it. You're having an install problem. That's separate from the problem once installed works properly or does/doesn't work on Python 2.7. I install PyQt4 and PyQt5 on Python 2.7 using Anaconda. It works fine. Then I go use my Anaconda Python 3.6 virtual env and test it using PyQt5 and my code works fine. Seriously, Anaconda Python is amazing. Why would you ever want to install something from source? If it's pure Python fine; otherwise just no. I use PyQt4/5 just fine. I managed to link it with a VTK window and render 300k elements of mixed type. It's an open source code and works fine. It supports multiple versions of Python, PyQt4/5 and VTK 5-8. To be fair, Windows is easier. People expect it to just work, so it does.
That's pretty neat! Thanks for sharing.
Looks great. Thanks. I’m in the same boat as you. I’m a noob too but I really want to learn this on my own so the good resources help!
Awesome, mate! Looks really nice :) 
You don't want to implement the wsgi spec. It's deceptively complex (as in, it looks straight forward enough, but it's actually not). Something like Flask or Bottle is probably the right amount of "stuff" you need without dragging in a bunch of stuff you don't (forms, database, etc). If you're feeling adventurous and grok asyncio, there's also aiohttp, but I'd probably stick to just something simple like Flask. 
The following code uses Quartz (which is preinstalled in MacOS) and SDL2 (which isn't, but is reasonably easy to obtain). #!/usr/bin/python import AppKit, Quartz, random, socket, sys, time, sdl2.ext def display_calibration_pattern(): renderers = []; windows = [] # get display dimensions from Quartz displays = [] active_displays = Quartz.CGGetActiveDisplayList(100, None, None) for display in active_displays[1]: bounds = Quartz.CGDisplayBounds(display) displays.append({'x': int(bounds.origin.x), 'y': int(bounds.origin.y), 'w': int(bounds.size.width), 'h': int(bounds.size.height)}) # create windows sdl2.ext.init() for d in displays: window = sdl2.ext.Window("Calibration", position=(d['x'], d['y']), size=(d['w'], d['h']), flags=sdl2.SDL_WINDOW_FULLSCREEN) window.show() windows.append(window) renderer = sdl2.ext.Renderer(window) renderers.append(renderer) # run loop running = True while running: events = sdl2.ext.get_events() for event in events: if event.type == sdl2.SDL_KEYDOWN: running = False if running is True: for renderer in renderers: renderer.clear(sdl2.ext.Color(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))) renderer.present() for window in windows: window.refresh() time.sleep(0.5) # clean up for window in windows: window.hide() sdl2.ext.quit() if __name__ == '__main__': display_calibration_pattern() 
I manage a similar stack in my full time job and I chose to use the tornado framework to implement web sockets for this exact use case. It can be a little hard to get started thinking asynchronously to start with but the tornado docs have excellent examples. You should absolutely use a framework for your project, one of the best parts of the python ecosystem is the vast number of incredible libraries and frameworks that allow you to focus on the real logic of your application without worrying about the lower level implementation (avoid trying to hand roll wsgi at any cost!)
I learned python from (https://developers.google.com/edu/python/). And just today, I come across this [teamtreehouse](https://teamtreehouse.com/) while posting a comment about flask. I might try this site today.
Assuming your data structure holds those player-created elements as primitives (ie bytes, strings, ints, floats, etc) and not *objects* (the player can't create an arbitrary function/method that will eventually get unpickled and then executed), and further assuming that you never **exec**, **eval** or **pickle.load** those strings / bytes directly (ie the player has set their **username** to "import shutil\nshutil.rmtree('/')" and you for some reason think it's a good idea to `eval(username)`), then using **pickle** is *probably* fine. The main risk with it is when someone can directly modify the pickle'd stream itself, not so much the primitives encoded in that stream.
i dislike both the conflation of learning data structures and learning languages, and the presentation of technical learning as videos. (why don't people just write this as text and offer a "read this out aloud" link?)
I love reading from books as it gives detail knowledge. But what I realize is that learning from video is fast and gives benefit of class room type learning from teacher as well as opportunity to revisit.
Ad revenue. I think that's the main reason behind the massive increase of low-quality video submissions here and to so many other programming and technical subs. I mean linked lists in python? Can there even be one legitimate reason to use them instead of a regular list? 
To tell you the truth, it sounds like you're adding complexity trying to avoid complexity. It's a MUD, so I'm assuming your users have to authenticate with a central server, sending their username and (I hope) an **argon2** hash of their password. Now you do what? Look up a **json** or **pickle** file on the server based on their username? So they can never change their username? Or you have to have some sort of orchestrated shuffling of files if they do change their username? Maybe you want to allow them to use either email or username to login (so they can change either separately and still keep a user account)... now you need two copies of every file (or at the very least a file and a symlink), and even more shuffling. This is what a database is for. Authentication and identifying human user -- nevermind payment -- details should be totally separate from their in-game persona and its state, and once authenticated you should be able to look up the ID of their in-game persona(s). From there you could proceed to using **json** in a doc store, or **pickle** or **sqlite3** or whatever for the game details... but your inheritance tree as described looks like a security nightmare.
Then the same is applicable for Java/C#/C++ etc. Learning about data structures and implementation opens up possibility to apply in different scenarios and variations.
Thanks a lot for your reply. Helps a lot. The last 5 lines were just something I was trying out that I found online sorry about that. Your code seems to work fine until i get to the last part. total = 0 for node in g.nodes(): node_value = g.importance(node) print("I({}) = {:&gt;6.3f}".format(node, node_value)) total += node_value print("SUM: {:&gt;6.3f}".format(total)) I get this error: node_value = g.importance(node) AttributeError: 'UndirectedGraph' object has no attribute 'importance' Process finished with exit code 1 I copied what you wrote here and ran it and got this. As far as I can tell this error code shows up when importance is not defined in relation to the UndirectedGraph. But havent we defined it here? def importance(self, node): node0 = 1 / (1 + self.degree(node)) node1s = [1 / (1 + self.degree(n)) for n in self.neighbors(node)] return node0 + sum(node1s) 
Kotlin is basically a less terrible version of Java. It's good in the same places you would already use Java, and much more pleasant to work with, but it doesn't really replace Python for me. 
An advice from someone who wrote a lot of scripts for use in research (both for me and other people) and also used a lot of other people's scripts in research. You have a very simple user interface and Tkinter which comes with every Python installation would suffice. With PyQt you just add a massive dependency and annoyance for anyone who would want to use your script.
Didn't even bother to see what it is. Python 3 support is a must.
It's great even if you're not using one too
I have learned a lot from this great python developer. https://python-guide.readthedocs.io/en/latest/
Have a look at the HTML and see if the form has simple `action` &amp; `method` attributes (if only `action` is there, then the method is `GET`. In that case you can do things easily enough with Requests (assuming too that any login requirements can be similarly dealt with). Otherwise, if the form has a javascript function with an `onsubmit` attribute, you're probably best using one of the other two. Mechanize only works with Python 2.x, so I would avoid that at all costs, unless you're tying into a pre-existing massive Python 2 codebase (and I assume you're not!).
It depends on the site but for interactive forms etc my go-to would be selenium. 
Although I was familiar with python before, I followed the udemy python course (the one that you build 10 apps pm if you can't find it) and it was great to get a quick overview of applied programming. And I got a notification a couple of weeks ago that course material has been updated. So, I would recommend it. 
Point taken. Well this was a hobby project. So PyQt was easy to design the UI. Also slots and signals were handy to make the UI responsive. And now PyQt5 is available as wheels for Python 3, so it is not so bad. I agree TkInter should be enough - however I don't have any experience though. Maybe someone might be out there willing to fix that :) If not in due time.
I am new to python and I need some hands on experience. Can anyone please guide me how to start... Thanks in advance
I used codecademy course. Not perfect, sometimes buggy, but I love being able to practice anywhere, on any computer. "'IDE", exercice and console are all in a same webpage letting you experiment without investing too much time in configuration. And it covers well the basics.
Looks cool. Why silo Quart on gitlab.com?
Wow... takes me back years ago... we used to do similar (although much less detailed) stuff on the Atari ST. Rendering took hours...
You don't need to store the image as a matrix. https://www.wikihow.com/Find-Your-Way-Through-a-Maze
A big part of figuring stuff out it being able to read the documentation. I know it can be overwhelming in the beginning but once you realize how much easier (good) documentation makes things, you'll love it. From the link above: &gt;You can access a pixel value by its row and column coordinates. For BGR image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned.
see: https://www.exxoshost.co.uk/atari/STF/28E.jpg :-)
I wrote a bot for discord. It has some useful functionality, it does a LOT of api calls to different websites to give data to the users, and it even has memes (that don't get pushed to my github). It doesn't seem like much, but I've become extremely comfortable with web form creation, grabbing and manipulating form data, api requests and return data manipulation, data structures (music streaming that allows for every server to have their own voice clients and queues. I needed to design a solid structure of how I was storing everything.), organization skills (all my api keys, client ids, client secrets, etc go into a config.py file, in their own classes.), and string manipulation (complex dice roller such as /roll 3d6+4+2d4+1+1d10-3.). I also try to document the code properly. What the parameters of a method are, what's the return value, what's the purpose of the method. I try to write code that can be reused. If I'm finding myself rewriting the same piece of code, I'll make it a method and call it when needed.
Hi, Since you mentioned about sound output, I bought a raspberry pi 3 model B and tried to build a Bluetooth speaker by connecting my speaker to it. I was skeptical about the output quality as I had heard that the output quality is not good and therefore, thought of searching for audio cards or HDMI (just to compare). But, I don't know why the output seemed to be perfect once I plugged my speakers into it. Do you know what happened here? or is it that this motherboard is better than earlier ones?
Hi, this sounds interesting. Do you have a public repository or something for your project? I would love to see that.
Not yet. Step 1 was my mxm.midifile project to read and write midi files. https://pypi.python.org/pypi/mxm.midifile Next step is mxm.sequencer that will use that to output the sequences with. But it is still completely experimental so not ready to share.
Not yet. Step 1 was my mxm.midifile project to read and write midi files. https://pypi.python.org/pypi/mxm.midifile Next step is mxm.sequencer that will use that to output the sequences with. But it is still completely experimental so not ready to share.
What does your bot do?
Finalizing my own Bot Assistant and Flask.
What library did you use for the GUI?
I'm working on an application that can encrypt and decrypt famous cyphers, right now I'm learning PyQt4 to create a GUI for the app
It's surprisingly fun to program in. I'm really fond of the elvis-operator and the fact that return is actually an expression.
Check out courses on Coursera, edx, and Udemy
Just use ujson as a fastest approach.
Depending on your speaker, it probably has an integrated amplifier, that is able to supply more electricity to the speakers then you can draw from the headphone jack. Does your speaker has a separate power cord or just the headphone jack?
Any idea for not using root? Except suid.
Happy to help! Yeah, I found pandas super handy when working with data grid like data. It is also super easy to save the data to a database using a “.to_sql” method or to CSV by using “.to_csv”. 
This is machine learning stuff. Just explaining the code line by line won't achieve anything, as you don't know how the algorithms in use work. What is your end goal?
Jump into learning Python to play with this code. I have a basic programming understanding so I am not starting from nothing. I just want to see what does what to see what I can easily tweak to change things.
That's a terrible way to start learning. Read a book.
I'm only interested in this one project, I only want to learn what is directly relevant to this.
That's not possible. You're trying to build a car without knowing what a wheel is. If you want a single thing done, pay someone to do that thing for you.
They just recently had a release, IIRC. They had to find new owners for the project because it was basically abandoned for about a year, but it is seeing new development. If you look at [the past month](https://github.com/vispy/vispy/pulse/monthly) of activity there is quite a bit going on.
 def open_second_screen(self): second_window = SecondWindow() As soon as this function finishes the SecondWindow object gets destroyed, because the reference second_window runs out of scope and there is no longer a valid ref. The easy (and ugly) fix is to have a class member, like so: def open_second_screen(self): self.second_window = SecondWindow() But be aware, that you can only have one SecondWindow instance like this. Also be aware that QtGui.QMainWindow is most likely not the base class that you want to use for something that is a secondary (ie. not your main) window.
Ah okay, that is awesome! But you still need to define your own Shaders etc? Or does the high lvl api work? I saw a presentation on youtube from 2015 where they did 2d histograms with plotted distributions on the axes e.g. But I can't find any examples. What is the best way to learn doing these cool plots? KD
I have no clue, I don't actually use it myself because most of it is over my head, and I don't have much use for it. I had been following the project after seeing their 2015 SciPy presentation and being thoroughly impressed, and wanting the speed that it is capable of for my own projects. Most of my plotting is just xy line plots, but it's a lot of data and MPL has a hard time keeping up. I was very sad when they removed the mpl backend, but other than that I don't know how to actually use it lol.
The community appreciates your effort to make it better by leaving it.
Haha okay, yeah I just managed to make a x by y point plot of two pretty large time series. It was surprisingly fast, I have a graphics card in my laptop GL version: '4.5.0 NVIDIA 385.41'. But it would be really cool if it was possible to make some more advanced graphs with labels, zoom, coloring etc. I'll continue searching! Thanks!
I learned Python a month ago, also, I learned PyQt last week. I build a very simple program that let´s you add items to different list, and send it to your suppliers. I made it for my father so he could use it on his shop. You can find it here: - https://github.com/NahuelVarela/ProgramaPedidos
I actually did see it live, and it was quite awesome! I've been to SciPy twice now, in 2015 and this year. It's a really great conference that has been very inclusive with lots of hallway discussions that lead to a lot of really great work. Everyone I interacted with there was fantastic, and the organizers really make the conference a success. This past year I actually ended up hanging out with a guy from Germany for a good chunk of the conference. He was over on a student scholarship, I think. I live in Arkansas, my house is only about a 7 or 8 hour drive from Austin, Texas where it's held. While that may seem like quite a drive, it can be done easily on about 1 tank of gas in my car, and I can easily do it in a day. However, you're actually in luck. SciPy has [European counterpart](https://www.euroscipy.org/) held in Germany which I would imagine would be much easier to get to.
I get how this works for most built in Python types, and how you can use `@customtype` to enforce expectations (positive int) on built in types. But I was not immediately sure whether fully user created types/classes could be as easily validated. My data objects can get complex. Some contain instances of my own custom classes. 
Ah okay cool! Sounds really amazing actually, I just graduated from maths/finance (bachelor+master), and work atm with some data analytics and machine learning. But it's quite easy, and I don't develop as much as I'd like. I mean I have a lot of "free time" i.e. I can do what projects I'd like here, but I'm the only one that is programming and understanding the things we work on.. So I feel that it would be nice to go to some conferences and meet more like minded ppl. I'll definitely look into the conference in Germany for next year! Do you know if it's "easy" to get tickets?
It is a little expensive for some people $25/month but I really liked https://teamtreehouse.com/ for the super basics and some web dev stuff. 
At the US one the tickets have been selling out each year, but if you sign up on their mailing list you'll get notifications of early bird registration and whatnot. I'll say that I've been able to get tickets paid for by my employer with all the red tape that entails, but this past time I didn't get in fast enough to sign up for the all of the tutorial sessions I wanted. The first two days (if you elect to do/pay for them) are tutorial sessions where you sign up for 4 4-hour classes. The popular ones definitely fill up quick.
Ah okay! Thank a lot for the replies! :)
No prob
Probably a bit late to the party for this one- this week I have finally cracked a nut that will make my life a lot easier; I have managed to get some Python bindings for a Golang SNMP library to work. Why? Because PySNMP is slow (and seems to have a memory leak with PyPy) and EasySNMP has underlying thread-safety issues with SNMPv3. [See the code here](https://github.com/initialed85/gosnmp-python)
Per your email: `importance` is a method of the `UndirectedGraph` class, and needs to be defined at the same time as the rest of the class. Adding it after the class has been defined (ie naively cut-and-pasting my code above) will make it a stand-alone function, not a class member function - you need to stick it in after `def nodes():` but before `g = UndirectedGraph()`. I will modify my code to make this more obvious (sorry!).
this is not about book-vs-video, it is about tutorial-vs-video. a video enforces a constant speed. the same text written down allows advanced readers to skim or skip ahead, and slower readers to seek back comfortably. (both is possible with video too, but to a much more limited extent and time consuming. seeking in text literally happens in the blink of an eye.) my point is: this might even make a good tutorial, but is held back by its media format.
Creating a front end for a Django project management app. Mostly JS, but deeply integrated with the app. Django rest framework really
How would you fix it in a non-ugly way? And as for the second part, what other types of windows exist? I find close to None documentation on in. I know there are QWidgets and QMainWindows
At that point make it a command line tool.
Always pass in the parent.
Mechanize is Python 2 only, try https://github.com/MechanicalSoup/MechanicalSoup instead.
Yes.
It looks like it is using method &amp; action so I'm going to try this. Thanks!
So how does that work exactly. Will my P2 code "look" for the P2 install?
If you run `python2 some_file.py`, Python 2 will run. If you run `python3 some_file.py`, Python 3 will.
r/learnpython is more receptive to this type of request.
If you want to run code with Python2 then run the Python 2 program (usually called `python`) and if you want to use Python 3 then run the Python 3 program (usually called `python3`). You can see the location of each python by typing `which python` or `which python3`.
Awesome, thank you.
Thank you.
MechE turned CS dev here; nice job! For my job, I've been working on a project that is similar (PyQt GUI wrapped around some engineering calculations, but mine targets signal processing), and hopefully will be open sourcing soon. Anyway, just wanted to say that I would be happy to contribute, but I would suggest putting some kind of features you would like to implement in your issue tracker. Do you plan on having any kind of plotting in the GUI? Nice work!
PyQt is an optional backend for matplotlib, IIRC. theta-beta-mach curve would be cool, yes. While the functions for shock relations are almost ready, I did not plug it into the GUI though. It would also be cool to visualize how various parameter changes, using 1D data, along the length of a nozzle / duct etc.
Yes, my experience as well. I was really reluctant to step into Java ecosystem but Kotlin makes it a breeze. Actually, my biggest concern is sluggishness of Android studio.
I have the same background :) Fork ahead! I would love someone to pitch in. This was a 3 year old hobby project of mine. I just recently got this baby back into working condition. I did have grand ideas as [I mentioned above](https://www.reddit.com/r/Python/comments/7ck72z/compressible_aerodynamics_calculator_made_using/dpratsd/). But what this calculator needs immediately is to finish implementing Rayleigh and Fanno flows. Plotting parameters is a medium term goal, yes. I already have some form of saving data using pandas - so this should not be so difficult. A long-term dream was to use to use method-of-characteristics using these equations to solve for flow around simple geometries. I can put these in the issue tracker, of course.
I have mostly thought about how one might use this to verify that incoming data, such as json from a web api is well-formed. There is support for fully user created classes in the most basic sense: &gt;&gt;&gt; class A(): &gt;&gt;&gt; pass ... &gt;&gt;&gt; validate([A], [A(), A()]) Let me know if you have any issues or other use cases :)
Yes, it (2.1 speakers) does have a power cord. That explains a lot. Thanks philipp_th.
You are welcome
&gt; do i need a frame work for this ... Strictly no, but there exists frameworks that are very thin wrappers on uwsgi, which you 100% will not do without, that provide valuable convenience. Probably not Django, and if you feel like flask is too much, you can look at [Falcon](https://falconframework.org/) As far as I'm aware, Falcon is as barebones as you get. 
congratulations on the career transition *high five* now if I could only find a CS position where my ME background is of benefit haha. If plotting is on the table, I would highly suggest you consider pyqtgraph instead of matplotlib. PyQtGraph, while definitely does not have the same development backing that matplotlib does; but integrating pyqtgraph into a Qt GUI is pretty trivial, and pyqtgraph is made for user interfaces, not for publications (which is really where matplotlib is strong in). I haven't done much with fluid mechanics once I left school (did some solid mechanics and heat transfer stuff, but fluid flow, outside of simple flow rate calculations is something that I haven't had experience in. If you're just exporting the parameters, any reason you use pandas instead of the built-in csv module?
pandas dataframes can plot columns a.k.a series with ease. Tabular / spreadsheet like data is best stored as dataframes, I felt. I know, it is another dependency, but hey we all are lazy right? PyQtGraph is pretty slick, and I have used it. However it is sad that no updates were made to it to support its PyQt5 backend. I used to like PySide, but the fact that it only supports until Python 3.4, is a bummer.
howdy! I found a good comparison over here: http://charliedigital.com/2017/08/31/identity-as-a-service-auth0-okta-aadb2c-first-look/ hope that helps...
&gt; It’s fine for one file, but when you have a whole ELT pipeline tucked into a Makefile, the duplication leads to fragility and violates DRY. Question: I don't use make. Why can't you put the paths into an import? e.g. `from apppaths import DATA_PATH`
PyQtGraph supports PyQt5 (I know because that's how I'm using it :) ), and will support PySide2 once PySide2 hits PyPi (per email convo I had with the project owner a month back or so). Totally hear you on the ease of plotting dataframes, pandas is like cheat mode haha. I'm not sure how easy it is to integrate those plots with a PyQt GUI (I've done it before, so I know it can be done; and I did it when I was much more of a noob than I am now, so it can't be that hard...) but getting the interaction of the plot (zooming/panning/etc) will be tough. 
&gt; PyQtGraph supports PyQt5 (I know because that's how I'm using it :) ), and will support PySide2 once PySide2 hits PyPi (per email convo I had with the project owner a month back or so). Good to know that these projects will last. &gt; but getting the interaction of the plot (zooming/panning/etc) will be tough. I agree, matplotlib has limited user interactions. In that case +1 for PyQtgraph then.
PyQtGraph is definitely not without its quirks; but I've been working on it enough recently that I feel like I can contribute in a library. If you add to your issue tracker what kind of information you would like plotted, I wouldn't mind giving it a go :)
&gt; I also try to document the code properly. What the parameters of a method are, what's the return value, what's the purpose of the method. I try to write code that can be reused. If I'm finding myself rewriting the same piece of code, I'll make it a method and call it when needed As someone going through the job application process and having talked with a few people who actually read my code on GitHub, I would have to say this is very important. If the person reading you code is someone who may need to work directly with you, they are going to want to see that you can write 'clean' code. Everyone has slightly different ideas on what that constitutes, but they are going to want to see that you can do some basic things like document your code and avoid constant repetition. That said, make sure you know what should be documented, don't just put comments everywhere for the sake of it. i.e avoid this: num_things += 1 # increment total number Try to adopt a standardized method for documenting your functions so that someone can take a quick glance at one of your methods, hopefully understand what it should do from the name, and then quickly get a grasp of what it needs for arguments and what it should return. I find that being consistent in the way you do things goes a long way, you might not have the exact same docstring setup that someone else uses, but if all of your methods use the same documentation style, then it becomes easier for an outsider to navigate your code and read the important bits.
Sololearn &amp; Enki
Sololearn &amp; Enki
I have used both PyQt4 and PyQt5 on python 2.7 and python 3.5+ for the last 3 years. I can assure you there's nothing "broken" about it. If you are having problems installing, that's totally different from just blanket stating that the package is broken. &gt; I don't even know what SIP is, but I suppose I'll have to go install that first. This statement leads me to believe that you have done very little research on what PyQt is and/or how it works. I can make one suggestion, if you use the Anaconda python distribution (which is incredibly easy to setup on OS X) then you can create virtual environments and install pyqt4 and pyqt5 with both py2 and py3 with ease. Obviously I understand that not everyone is in a position where they can use Anaconda, but please do check it out. IT greatly simplifies the installation of many packages. I maintain a PyQt5 application that works on OS X, Windows, and Linux. It works with Py2.7 and py 3.5+, and I suggest that people use Anaconda if they want to set up an environment to use the application, purely because its simple and I know it works.
That often works fine. But, it starts to give off code smell (IMO) when the different ELT pipeline components are more and more decomposable. You end up playing with PYTHONPATH to load a conf.py file or something in a higher directory, or you just hold all of your (isolatable!) code in one large package. A conf.py also increases friction to polyglot code. To use that python config file in, say, some golang code, the easiest way is just to export the config files to the environment, and read that from your other language. That's why PathsJSON has an `--shell-exports` flag. There is an argument that this is all overkill. And, it may be! But, my experience is that there are strong benefits in ELT space for some conventions to facilitate collaboration. 
Adjacent to your question, HIGHLY recommend learning and using [virtualenv](https://pypi.python.org/pypi/virtualenv) https://virtualenv.pypa.io/en/stable/
Yep, virtualenv becomes a really important tool, as soon as you discover that versions of tools and libraries matter.
As someone who has the VT Aero calculator bookmarked, this is pretty neat. I echo the tkinter suggestion
I found Sentdex's youtube tutorials to be pretty useful, especially since many of them have some sort of final objective and are bound to a specific topic. https://www.youtube.com/user/sentdex/playlists
Yes, but get a virtual environment manager, and don't add/update packages in your system Python distribution, as your system utilities may depend on it. I use `conda`, the other popular one is `virtualenv` 
What OS and theme are you using? 
[Automate the boring stuff with Python](http://automatetheboringstuff.com/)
Probably you will have better luck if you subclass `QDialog` for `SecondWindow`. I'm not sure what happens in your current situation if you have two `QMainWindow`s and close one, the event loop might have problems. There's nothing wrong with having long-lived dialogs. Typically I do multiple inheritance of `QApplication` and my generated `ui_???` class, and hold a reference to `MainWindow`in my main class. class BigClass(Ui_Main.Ui_Main, QtWidgets.QApplication): def __init__(self): QtWidgets.QApplication.__init__(self, sys.argv) self.mainWindow = QtWidgets.QMainWindow() self.setupUi(self.MainWindow) # Setup all the slots and other configuration stuff self.mainWindow.show() self.exec_() billsil's advice of passing in the parent is also good. Another thing that you'll really want to learn is `functools.partial` for connecting slots to generic handler functions. Here's an example that just slots values into a dictionary: def updateDict(self, dictHandle, key, funcHandle, funcarg=None): ''' Update the configuration dictionary with a functools.partial assembly ''' dictHandle[key] = funcHandle() and then connect your elements: self.spinbox1.valueChanged.connect( functools.partial( self.updateDict, 'config', 'spin1', self.spinbox1.value ) )
thanks for your response but i will need a database? 
Lol. Arch! And a customized version of Arc theme on Plasma desktop
oh,this looks promising ,i will look after it thanks a lot 
okay,thanks
VT aero calculator is the inspiration. Spot on! Tkinter would be a welcome addition, but I have never coded using it.
No problem, Just to dive a little further: I use tornado for the communication and realtime storage of the data from my embedded clients (thing IOT type devices). Behind tornado I use a redis database (very fast in memory key value datastore) to hold all this realtime data. To expose this data to a frontend/browser web app I use Django and Django Rest framework. Django deals with the long term storage stuff (device ID, remote address, authentication etc) stored in mysql but I also expose the realtime data from redis through my django models. Depending on your use case you might not need all of this and tornado might solve all your goals but it was stupidly easy to pull both sql and redis data through to the frontend with a django model and a few custom properties on the Models.
Thank goodness!
whether or not you need a database has very little to do with the framework. I use bottle all the time without one. I only recently started using a database and even then, it is just SQLite (very low traffic with next to zero database modifications except my one person). Personally, I have been very happy with Bottle though Flask is similar and you'll find more support for it. I just liked the simplicity and single-file nature of Bottle which makes bundling it with my application easier.
I would consider MIT's Intro to Programming class on EdX. However, [How to Think Like a Computer Scientist](http://interactivepython.org/runestone/static/thinkcspy/index.html) was useful. If you're interested in using Python for data analysis, or otherwise, [Data Camp](https://www.datacamp.com/) and [Dataquest](https://www.dataquest.io/) are decent. Also, what cameICase said.
I've used both edx and Udemy and found the platforms decent. There was a Harvard course over on edx, Python for Research, that uses Datacamp for it's hands on work. Udemy, is a little more hit and miss because the people 'teaching' the courses aren't necessarily teachers, or very good at teaching. Having said that, if you keep an eye on some courses you can get lucky and get some of their free offerings. 
Whoops! Udemy is okay since I like the Automate class. I actually meant http://www.udacity.com
What's this title? And why should a loop with range be deserving a video? Loops deserve one and generators do, but nothing that specific. 
just more low-effort, low-quality filler content posted to /r/python in the hopes of making a buck or two
I have a few comments. * **WHY**? How often do you *want* to do expressions like this? * The syntax is still really unclear! It is not clear what the value proposition of using this may be compared to a native python promp. If I have to type `math.cos(10)`, it isn't really a big deal! * If you're still convinced this is worthwhile, make it have a command like interface. First, put `#!/usr/bin/env python3` (more on this later) and, instead of just creating an infinite loop, just evaluate an expression * This code, as it stands is only python3. That is fine, but I would strongly suggest noting it somehow. Either with the shebang (as noted above) or with some comments. * Alternatively, while I didn't test it much, it seemed to work fine with the following at the top. Notice that it is now just saying `python` and not `python3`. It *should* work with both versions code: #!/usr/bin/env python # -*- coding: utf-8 -*- from __future__ import division, print_function More comments: * in trying to figure out the syntax (see my first two points), I made it throw errors. Catch problems. * Why are there two tabs to indent in some places. * Tabs vs spaces is a religious question. But I think all will agree that double tabs is blasphemy either way. * Your examples do not work!!!!! I tried to put in `(root 4 * 4)(3root (atan(3 * 3) ^ 2)) / pi` and I get an error. So I tried `"(root 4 * 4)(3root (atan(3 * 3) ^ 2)) / pi"` and still got an error. I hope this is somewhat constructive.
I would not go that far and say it's low quality, but the TITLE is very CLICK baity if YOU see what I MEAN.
agreed
I use PyGObject (GTK)
HOW TO WRITE A "FOR LOOP" IN LESS THAN 4 MINUTES. Seriously, this barely qualifies to be on /r/learnpython, much less /r/python. 
I think I would prefer to keep a helpers.py and add any functions there as-needed. Your concerns are all valid and I agree with them. I love FP but if we introduced toolz into production code at my job I would be tempted to "FP everything". It also seems like it should be something you start a project off with.
I have this problem too. I solve it by using https://github.com/jaraco/path.py E.g. you can do:: LOG_DIR = Path("/path/to/log") TWITTER_DIR = LOG_DIR/"twitter" file_contents = (TWITER_DIR/"tweets.txt").bytes().decode('utf8')
Seconding what others have said about virtual environments. As a Python noob myself sometime back I found out the hard way why you should use VirtualEnv instead of installing Python code (like NumPy etc) into your system Python as other have suggested. Depending on your Python (there's more than one- I like the free Intel Python) you can have 32 and 64 bit versions of Python 2.x and Python 3.*. But Intel Python (this is from memory about two years ago) installed Python in an area where you needed root access to install anything. That just made things way too messy. Conda is an excellent package installer/virtual environment. FYI. Virtual Environments create a copy of your Python so you can have multiple instances should you wish and you just activate the one you want to use and deactivate it afterwards.
This belongs in /r/learnpython. I can say for a fact because I learned how to do this last week myself. And im no python expert.
Wait what?! I didn't even know something like this was a thing! What are you going to make with it now that you've ordered one?
Would recommend [against using the `place` geometry manager](http://effbot.org/tkinterbook/place.htm), especially since most people looking at your post will already be familiar with the [grid](http://effbot.org/tkinterbook/grid.htm) and [pack](http://effbot.org/tkinterbook/pack.htm) geometry managers. If you convert your code to use one of those, I'm sure that you will get a better community response. 
theyre not outdated at all if you use Python3. They are the best in my opinion for a beginner. Actually I went back and read the book from Apress guy that came out around 2009. Even that was still highly relevant and I learned a ton more. That's after reading much more recent books. Dive Into Python 3 is older than heck and has still been useful. Anyway in short Im saying the Udemy courses are actually still apropos. I'm currently browsing/scanreading Programming Python by Mark Summers and that's such a superdope book. Maybe not as easypeasy as the other beginner books but so amazingly useful and that's pretty old. Anyway I'm just sayin Udemy's Python courses are new enough that they are relevant.
Version 1.2 was just released. Try: pip install --upgrade arcade
Apologies if this is a dumb question, but what's ELT?
I started to look at it recently. It's interesting, and probably the most attractive new language. There is some syntaxic weirdness coming from python, eg: val dict1 = mapOf( "firstName" to "John", "age" to 31, "married" to true ) or for (i in 4 downTo 1 step 2) but globally it's readible. I'm wondering if it's possible to have a numpy-like library and also if kotlin native has a future
Hrm. I like the semantics of path.py. Actually, I think I'll clone a few of the features, so thanks! But, I don't think they fully-overlap. For example, let's say you had this .paths.json file, { "__ENV": { "VERSION": "0.0.1" }, "data_dir": ["$$_IMPLICIT_ROOT", "$$VERSION", "data"], "raw_dir": ["$data_dir", "raw"], "scrape_jsonl": ["$raw_dir", "scrape.jsonl"] } if you're debugging some component (e.g. stage_4.py), you could do, VERSION=debug python stage_4.py to test it, without interfering with any other already processed elements. It also allows Makefile-based dependency updates, and the Makefile can use the path definitions as variables. 
ETL = Extract, Transform and Load. (I transpose the L and T sometimes purely by accident. Gonna fix that one now.) That's really the context of where this code is useful. (Or, at least whee I think it is useful, and why I wrote it.) ETL code tends to be ugly. Data is hard to clean because there are so many violations to your expectations. I like tools that help make refactoring easy in this domain.
Hmm, I did a search for python and got nothing back...
Is there no way you can talk to the developer and collaborate to wrap a Python API wrapper around Shellcheck - or alternatively install shellcheck and call it via a command line process (since it has a command line interface).
Here is what the final plot should look like: https://cdaddy2.imgur.com/all/?third_party=1#_=_
You would be better off searching for programming or coding. There are also tabs on top of the table you can use for quick filters. Places like code school, codecademy, corsera, edx, free code camp,etc... Try visiting some of then to find Python courses/tutorials. I recommend codecademy.
I think I am going to rewrite it in python to go through the learning process as well. So I was hoping for a library that does the dirty job of parsing or an existing project I could get involved with. 
I am working on learning the Pandas and Numpy libraries. It has been frustrating because I am very well versed in Excel, but I am going to keep grinding! I know in the long run I will save time! 
A typo of [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load).
Why? Didn't enjoy xslt enough? 
&gt; A simple python3 library to convert a herpes into AIDS. Oh goodie, where do I sign up?
Thanks for the Python code. My comment is that over the 10,000 iterations, the difference at any given iteration, is much bigger than 0.1229, on average. The difference was computed only at iteration 10,000 in the above Python code. 
So basically dicttoxml.dicttoxml(json.loads(...)) ?
Thanks. I wouldn't have recognised ETL either :-)
I'm not familiar with opencv, so I don't know what of these methods would make the most sense for you. Here are a couple options: * Have one thread doing opencv and one running the web server * Do a fork-and-exec to have children processes * write data to a queue system * write data to disk * write data to a db * write data to a fifo named pipe * open a socket connection between the processes
Been on this server for ages. It's good.
There is a github mirror now, https://github.com/pgjones/quart
Great! Really Great! 
Thanks :)
Literally. But wrapped in try catch.
https://youtu.be/fdibwIkjVZE :)
Shooting from the hip here... In the master thread/script, you have both your flask app, and your opencv thread running. Put each image into self.variable that can be accessed, say, in it's __init__. Then, when the flask endpoint gets hit, have it query the variable within that object/thread. That should work. Your question is pretty vague, but this is the best answer I got considering the information I have. 
Currently: * takes music requests and plays them in a voice channel. * using Blizzard's api, makes calls to retrieve Gama data. * has a pretty in depth dice roller (if I do say so myself) * will roll tabletop rpg characters stats for you with optional flags. You can see more here: https://github.com/davidschaeffer2/casper I don't think I've pushed updates this weekend as I've been sick, so some things may be missing.
generating a peptide mass reader to predict mass spec results 
&gt;Now for some reason, I have a separate OrderModel for every store. Sorry, can we start here. I've never developed in flask, but I have developed a shitload of web apps in Spring and Grails and some lesser-known frameworks. I'm concerned by what I've quoted. Why do you have a separate model for orders from each store? 
Looks cool but I'm usually trying to go the other direction.
Take a look at the selenium web browser automation project. It's exactly what you need.
Kotlin's null safety and functionality make it a good language, especially for Java programmers. From a python perspective, it's fun to program with, but I prefer Python over it any day. 
I knew that someone would stumble upon this and ask about it. ;-) The whole Store / Orders example is an abstraction of a real-world example which has nothing to do with stores and orders. I just used this for keeping the description easier. The real database design behind the mapping uses a separate database for every software product we have. In this setup, some tables have an identical layout for every database/product. So let's assume there is a postbox table in every product and the products are named "Alpha", "Beta", "Gamma". Would you use ModelPostboxAlpha for example? The distinction between those (nearly identical) models is the metadata (for example connection string and some fields which provide database and product information).
I tried writing to disk / DB. But problem is that sometimes flask will try to read an image that's not completely written by opencv. I ignore the error and keep trying to read the image (simultaneously written to by opencv and read from by flask), but i get that flicker effect and it's quite annoying. I'll explore that socket option
This doesn't seem like a versatile enough wrapper. For example, if there's an IO error, why should the code just print the error message instead of propagating it to the user to catch and deal on their own? https://github.com/vinitkumar/json2xml/blob/master/src/json2xml.py#L37
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [vinitkumar/json2xml/.../**json2xml.py#L37** (master → e01a46f)](https://github.com/vinitkumar/json2xml/blob/e01a46fc873cab87ec3dcb89a8ccbc9974eb3733/src/json2xml.py#L37) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Network peers should probably interact using an easily verified protocol using basic data structures; sharing objects would couple the two code bases too tightly. 
 def json2xml(self): if self.data: xmldata = dict2xml.dict2xml(self.data, wrap="all", indent=" ") return xmldata Yeah, looks very useful... 
I'd start looking at PyQt. It's a pretty popular and powerful UI toolkit. However if you want something simpler and built in you should start with tkinter just to get the basics down. There are a few books out there on the subject, and lots of tutorials. There's a lot of material to learn about building UI toolkits, a bit much for me to type out in a reddit post on my phone. Do you have any more specific questions about building UIs? I could probably answer those. 
This is where I'd start. http://zetcode.com/gui/pyqt5/
Funny you mention How to Think Like a Computer Scientist because it has since been rewritten specifically for python and is available as a free PDF, it's called ThinkPython. http://greenteapress.com/wp/think-python/ 
Kivy is also an option, tkinter is good to start off with but is kinda ugly 
But did Jesus take the wheel?
Thanks for your feedback.
Me too. But sometimes you do need the other way and I wrote this for that use-case.
Use a linter tool like pyflakes or pylint on everything you write. Integrate them into your IDE. They will force you to be a better programmer.
Yes. That's basically the crux of it. The library doesn't have to be overcomplicated to be useful, right?
Nothing better than getting in to the habit of writing unit tests to improve the quality of your code. It actually causes you to write better code not just less buggy code because testable code is more modular. Also stop writing classes!
&gt; SAX-like parser Are you talking about this? https://docs.python.org/3/library/xml.sax.html
Could you elaborate on the why one should stop writing classes? I know object oriented code is often done wrong/poorly, and things are turned into objects which shouldn't be...but I can't imagine programming in python without classes. They're everywhere in Django code...
Not sure why this is being downvoted, linters are very important and powerful tools. They aren't quite as good as learning to write code in the first place, but they can be immensely useful for debugging.
Don't call yourself a "Python Programmer" or you'll be a nobody when language trends go another way. Be a "systems engineer" or "prototype developer" or "automation expert" or something.
Why is the main duplicated in cli.py and json2xml.py?
This, but you don't have to be a stickler about the 80 char line limit from PEP8. We have wide screens these days. I find 120 chars to be a nice number.
I would have to second this statement. I'm a systems engineer at a very top tech company and even when we write our scripts we use classes to organize our code a lot better. I just can't imagine not using classes.
This is kind of obnoxious advice. Unless you really do believe no one should ever use classes in Python, then it's just terrible advice. Assuming it's the former, care to elaborate on when/why you think newer coders are abusing classes, so that you aren't just throwing this nugget out there for a bunch of people to believe that the simple act of building an object with a class is incorrect?
Specific checks can be ignored e.g. with a .pylintrc file. 
I find sympy a little bit... intense. It seems to be using it's own variable system, it's own unique way of defining functions... Just a lot of custom ways of doing things. This is a percentage object I can use for a naive-bayes classifier, or other toy machine-learning things, without all of sympy's baggage.
https://youtu.be/o9pEzgHorH0 This video explains it quite well. 
&gt; Assuming it's the latter what's your alternative? Dictionaries or named tuples for every single object? Not the commenter you're replying to, but: people use way too many classes. Sometimes it's because they've come from Java. Sometimes it's because this is their first OO language or even their first programming language and they go overboard with the classes. There are times to use classes, and there are times to use lighter-weight data structures or to just write functions. Going all-in on one or the other is a problem.
OOP in my opinion is just bad. But that's my opinion. Never writing classes is obviously going overboard so I'm not really saying you should never do it. A good rule of thumb is only writing a class if you have a new data type. If you want to bundle data then things like dicts and tuples (esp named tuples) are better. I see people using them when they are not needed and their code would be much cleaner without them. Here's a recent example a saw from a neural network lib. They wanted to create layers which you could then call; class Layer(object): def __init__(self, params): self.params = params def __call__(self, x): # do something with x and self.params People seem to love this pattern but this is maddening to see because *this is a closure.* def layer(params): def f(x): # do something with x and params return f Not only is that shorter its less prone to bugs. So what I should really say is try not to write classes, there's probably a better way.
I agree. I'm looking for the OC to elaborate. I think it's really bad practice to come into an advice post and just throw such an extreme nugget in with no elaboration. It's completely unhelpful. Even just saying there's a time to use it and a time to not isn't helpful. If you can't/won't elaborate to explain your advice in a useable way, then don't bother commenting. No one is forcing a user to give advice here, so if they're going to give it, it should be productive. 
list comprehensions are pretty neat and make your code more succinct!
I'm interested in the "stop writing classes" comment. Could you elaborate on why? Is it just that we should be using the standard built in types, that people tend to not do it properly, or something else? I'd consider myself a solidly "okay" Python programmer but sometimes fall into old habits from my knowledge of OOP in C++ or Java. Tips like these can go a long way for people like me.
Classes in Python *are not for namespaces!* That's what modules are for.
I've seen this video before. This advice is very subjective. I like how all the top comments on this video are all related to making sure you don't stop writing classes lol. Object Oriented is not meant to write less code, but a maintainable one. One can replace 5 classes and 500 LOC with 5 lines compressed in a python function, yes. But that will be completely unreadable. Examples presented in the video are extreme and do not help to support the topic, which has got sense in some cases. 
&gt; I can't imagine programming in Python without classes. This alone should be a warning sign. Writing python without classes (or with minimal classes) is very easy and natural. Try it some time. A lot of things are much, much easier without an object dogma straitjacket.
That's good to hear!
Given the output of layer(params) in the debugger, how do you get back to params?
Yes you are right I shouldn't have been so absolutist. I tried to explain myself better in the other reply
Pickle? Not even once.
I saw, and upvoted the reply. Thanks for elaborating!
Python 4 life.
Random braindump - Use Python 3.6, there are some significant improvements over 2.7 - like enums and fstrings (I would switch to 3.6 *just* for fstrings, TBH) - `.open()` or `.close()` is often a code smell - you probably should be using a `with` block - Use `virtualenv` for every project - don't install python packages at the system level. This keeps your project environment isolated and reproducible - Use the `csv` module for CSVs (you'd be surprised...) - Don't nest comprehensions, it makes your code hard to read (this one from the Google style guide, IIRC) - If you need a counter along with the items from the thing you're looping over, use `enumerate(items)` - If you're using an IDE (as a Vim user I say you're crazy if you're not using Pycharm with Ideavim) take the time to learn it's features. Especially the how to use the debugger and step through code - `multiprocessing`, not `threading` - Developing with a REPL like ipython or Jupyter alongside your IDE can be very productive. I am often jumping back and forth between them. Writing pure functions makes them easy to test / develop / use in the REPL. ipython and Jupyter have helpful magics like `%time` and `%prun` for profiling - Use destructuring assignment, not indexes, for multiple assignment ```first, second, *_ = (1,2,3,4)``` - Avoid `*args` or `**kwargs` unless you know you need them - it makes your function signatures hard to read, and code-completion less helpful
JSON to XML. I hate to tell you this, but you are going the wrong way.
Fair cop. Toned down the advice somewhat.
Calling yourself a "&lt;language&gt; Programmer" regardless of python is unwise, agreed. Express the problems you solve, not the tools you use to solve them. I'm being pedantic here, but I refuse to call python a prototyping language. Plenty of production code! But that's for another day/thread :-)
Not sure what you are asking. Are you commenting on the fact that you no longer have access to params once you get f back? I see that more as a feature, it's now state that you can't touch you know that f won't change because it can't, the state of the object in the other hand can change and cause bugs. Though admittedly this closure is harder to unit test.
virtualenv or containers, I'd argue. Good list too, +1
I disagree. If you follow the 80 character rule you can have two source code files open next to each other. On the other screen you cam have documentation and a Web page or project readme.
A thousand times this.
Please elaborate why you don't like pickle
See my other replies.
Understand the decorator. Become the decorator.
I found myself using pickle in a hobby project recently. What would you recommend using instead?
it'd be cooler tho if carpenters were hammer-throwers
everything you said applies to most python versions, but destructuring requires python3.X (though you said it in the first bullet point).
I can easily have two files open next to each other with a 120 char limit, and a web page, on my modern ~$300 monitor. IMO 80 characters encourages less descriptive variable names and/or artificial breakup of code purely to meet that character limit. 120 chars gives you a bit more room, without making things too long.
security. pickles can be maliciously corrupted and subsequently loaded into memory.
security. pickles can be maliciously corrupted and subsequently loaded into memory.
The is the ninth best quote I've seen on reddit
Why?
I've read this comment last night and just got time to try it out myself. I like it the (concept and the program) and very glad you made it. However, are you having UnicodeEncodeError during running the script? or is it just me? I've tried exception though but stops on the same comment who had an error. 
Python noobie care to explain whats a linter?
when you think you have to write something, check the standard library. if you still think you have to write it, check it again. then check some of the major libraries. then recheck those. python has a fantastic ecosystem where the most difficult part about it is finding the package you need.
My old-timey advice is be really careful every time you want to be succint/expressive/clever. Even if you're only writing software that you will ever read, do yourself a favor and write it to be dead obvious and dead simple.
You can do `a, b = (1, 2)` in Python 2.x, it's the rest args `*` part that only works in 3.x. So it's still useful, as long as you know how many items are in the container, and you want all of them :)
I program sometimes on upright screens. More lines at a glance. 80 Chars don't fit twice then though...
Hmm I am not having that error, do you have a credentials.json file in the same directory with your PRAW API credentials? Maybe try pulling the repo again? I did make some changes. 
I'm no expert, but I find serializing to text (JSON or whatever you prefer) to be ridiculously easier. You can always compress it if you have lots to save to a disk or fit through a pipe.
JSON. You're not restricted to Python if you can use it.
Refactor your code often. That's when you have the time to take working code and make it into good working code.
&gt; Avoid *args or **kwargs unless you know you need them - it makes your function signatures hard to read, and code-completion less helpful This is my evil. I really need to stop this.
https://en.wikipedia.org/wiki/Lint_(software) &gt;Generically, lint or a linter is any tool that detects and flags errors in programming languages, including stylistic errors.
**Lint (software)** In computer programming, lint is a Unix utility that flags some suspicious and non-portable constructs (likely to be bugs) in C language source code. Generically, lint or a linter is any tool that detects and flags errors in programming languages, including stylistic errors. The term lint-like behavior is sometimes applied to the process of flagging suspicious language usage. Lint-like tools generally perform static analysis of source code. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
A few minor thoughts: * Try out `pipenv` to make virtualenvs simpler (among other things) * `concurrent.futures` vs raw multiprocessing/threading (which of the executors depends on your need, no need to be dogmatic which) * try `ptpython` or `bpython` if you’re in a repl a lot. Ipython is great, but the others are an even bigger improvement!
a program that helps you conform to [PEP8](https://www.python.org/dev/peps/pep-0008/).
This is interesting, do you have a link to some code? Looking to do something similar
This is interesting! Do you have speech commands integrated into it? Are you using deep learning for the speech to text?
Pretty rad! 
It really depends on a lot of factors. If you're storing config data `yaml` is a good choice. If you're looking to serialize data and send it down the wire, `json` is usually a good choice.If you just want to write the data to disk to load later, then for small amounts of data `json` is probably a good choice. For large amounts of data that needs to be accessed non-sequentially, an actual sql database is probably the way to go.
The second to last bullet point is a really nice feature. Still have yet to find a convincing reason to use virtualenv. If I have a new project that requires a different version, I just update or downgrade to that version. It just always feels like putting the cart before the horse with the hassle of a virtualenv. 
It is certainly a feature once everything works. However, being unable to figure out what params are when you're stepping through your code in the debugger makes things annoyingly difficult. Although there must be a way to get to them somehow. Python VM clearly knows how to do it. I was just curious if you knew how.
Thanks!
hammer-slammers?
Splitting an IDE into two vertical windows sounds horrible in that scenario regardless. 
Your link is broken. It's also a bit unclear what you're trying to do - what's not working, exactly? Also, check out [xarray](http://xarray.pydata.org/en/stable/) for working with gridded data sets, especially if you're reading them from netCDF.
Of course you should write classes if they fit the problem you're solving, but don't write *unnecessary* classes. Let's start with: don't write singletons. If you want an object available across your project that encapsulates a single set of attributes and behaviors, that's what a module is.
Another reason not mentioned yet is it’s often incompatible across python versions/library versions.
Good talk from PyData Seattle this past summer - "So you want to be a Python Expert" - https://www.youtube.com/watch?v=cKPlPJyQrt4
[TkDocs](http://www.tkdocs.com) is a good reference and tutorial for making good looking Tkinter apps using the ttk library. Also ask your questions in r/learnpython.
Yes, i did the credentials. Alright I'll try pulling it again. Thanks.
I would suggest a different rule. If you have a line that's more than 80 characters, rewrite it to be less than 80 by whatever means works best (including introducing intermediate variables, or shorter variable names if necessary). Forcing yourself to actually write the short version prevents you from being lazy. If the line was better at 100+ characters, then feel free to go back to the 100+ character version, but I have found that 99 times out of 100 the shorter version is more readable regardless of how ok I was with the longer version.
+1 for WITH block for opening file, it just makes the code more predictable
Most good linters actually do a good bit more than just pep8 compliance.
You were probably speaking about the general case, but in the event that you were not... &lt;insert type&gt; comprehensions are definitely idiomatic and considered preferred python today.
* learn the standard library (esp itertools, functools, contextlib) * know https://docs.python.org/2/library/stdtypes.html * read pep8 read lots of code and form opinions. is it pythonic? why/why not?
Alright let me know if you have still have issues. I made some changes so now it stores comments in a sqlite3 database in the data folder. Feel free to contribute too!
Addendum: You'll go through a phase where you just pile decorators on everything. That's okay, but you'll need to understand the consequences. Ditto for when you begin to grok the rest of the metaprogramming toolkit (metaclasses, descriptors, `__build_class__`, inspect). 
itertools and functools are your friends - both modules provide general solutions to a wide variety of common problems. in general, the more familiar you are with the standard library, the better you'll be able to tackle problems in a legible and "pythonic" way.
&gt; They're everywhere in Django code... Classes are best used when they make the _other_ code you write more elegant. In this specific example, Django is actually a library/collection of code designed to make writing a website back-end faster/easier. That said, useful is not the same as exemplary. Django is certainly useful, but its code base is not exemplary. It is clever, hacky, breaks the rules, etc. It's all of those things people repeatedly tell you not to do. ;) 
To add to /u/lolshovels answer, the main linters you might want to look at are `pep8` `pyflakes` (`flake8` which combines those two), and `pylint`. `flake8` is great if you want a fairly lightweight tool that still does a lot for you without a lot of configuration and doesn't generate a lot of noise. `pylint` is much heavier and slower and will generate a ridiculous amount of output by default - it requires a lot of configuration to actually be useful, but can be used to give you much more specific and detailed feedback if you want it. Personally I use `flake8` because I like more or less instantaneous feedback. Both are worth trying though.
I used to spend a lot of time with a command line open to reload and test functions I was writing. Later I changed modes to just write a little unit test once and i just keep rerunning that same test as i write the function/class/whatever. Even if the test doesn’t even actually test and just does a print to start, it’s ready to go when I know what I want to assert. With this defacto coding mode, I end up with a useful pile of unit tests right out of the gate and it doesn’t feel like I added any dev time since i needed to do *something* to see if it works. Writing more tests for their own sake is also good, but the above was my gateway to actually writing tests instead of just knowing that I should.
Seriously - this need to be more visible. Far too many beginner programmers like code that is far too clever for no benefit. A real experienced programmer knows that cleverness that makes code harder to read is actually just stupidity, and that real cleverness is figuring out how to write code that is maximally readable and maintainable.
God no. You can't test that closure. You just made that whole function a black box.
yeah, sorry. that * bit was what i was getting at being 3.X specific.
pycharm does this already
Yep, I usually have file structure plus two files open in Sublime, that 80 char limit is necessary for 1080p, if I had more than one 1440p monitor I could raise the char limit. I feel that 80 isn't just for fitting on monitors, it's for keeping code in an easily digestible amount.
You should start with Python and get the basics before attempting a "hard" language. Read everything carefully from https://www.python.org/ in the "Beginnner's Guide." Switch tutorials only if you feel that you aren't making any progress, because there are a lot of resources out there. If you switch arbitrarily you might find that you're doing more work deciding which to use than actually learning the language. If you want to know what other people have done with Python, I also recommend the https://www.podcastinit.com/ podcast. One of the best things about learning how to program is when you really master the concepts of programming, switching to new languages gets much easier. But you _must_ learn the basics well before jumping to a new syntax.
Mastery comes one mistake a time... 1. Experiment. 2. Have side projects. 3. Break the rules. 4. Prove you're right. 5. Build Metaclasses and Descriptors 6. Know the dunder methods 7. There's always more to learn.
It's called a web server.
80 is pretty extreme. I agree we shouldn't be going nuts. But if I'm putting a log message in a block that is 12 characters indented (not a totally uncommon concept) I have around 60 characters to create an appropriately descriptive log message. Using variables and string formatting gives me actually less space, and isn't as readable as just the raw string, and isn't a good practice if I'm only calling those variables a single time in that log message. Escaping the line breaks in the string is a disaster on readability. And shortening variable names often leads to ambiguous or bad variables. So not making lines any longer than they have to be is a good practice. Having a character limit, I think is generally unnecessary, and so commonly ignored that it's an almost worthless portion of the PEP. 
Even if you're the only person ever to read your code, the you of today is a different programmer than the you of six months from now. I've lost count of how many times I've done a blame to see what idiot wrote some "clever" but incomprehensible code only to find out I was that idiot at some point in the past.
lets get some links 
If you are an experienced dev with professional experience then I do not see the issue, most companies will hire someone who has experience in a different language because the language is just syntax and syntactic sugar, the concepts are what matter the most. Can you do the classic algorithms like merge sort, bubble sort, binary tree sort etc. do you understand OOP principles. Those are the questions, Python vs .NET is just the language difference and can you easily translate between the two. If you have more than a year of programming under your belt then that’s what you should focus on is just making sure you can answer the typical interview coding questions. If you want to show some python experience I would recommend finding an open source package you like using in python and try working towards making a contribution to the package. That can go a long way by showing you are active in the python community. 
Import**
Yaml is way better than json for serializing 
Turns out the locals are stored in 'cells', and referenced in the bytecode: https://docs.python.org/2/c-api/cell.html ``` In [56]: def layer(params): ....: def f(x): ....: print params, x ....: return f ....: In [57]: foo = layer('these are my params') In [58]: foo.__closure__[0] Out[58]: &lt;cell at 0x7fac61825830: str object at 0x7fac6186bc70&gt; In [59]: foo.__closure__[0].cell_contents Out[59]: 'these are my params' ``` I don't see how you'd tie the cell back to the variable name though, so if you have more than one and need to know which is which you might be out of luck.
Pycharm writes all the code that I take credit for these days.
&gt; Escaping the line breaks in the string is a disaster on readability. Generally there's no need to do any escaping. Python naturally continues multiline strings. For instance: long_string = "YOU don't know about me without you have read a book by the name " "of The Adventures of Tom Sawyer; but that ain't no matter. That book was " "made by Mr. Mark Twain, and he told the truth, mainly. There was things " "which he stretched, but mainly he told the truth. That is nothing. I " "never seen anybody but lied one time or another, without it was Aunt " "Polly, or the widow, or maybe Mary. Aunt Polly - Tom's Aunt Polly, " "she is - and Mary, and the Widow Douglas is all told about in that " "book, which is mostly a true book, with some stretchers, as I said " "before." That's perfectly valid python which defines a single string, and is *much* more readable than the single line version would be. No escapes needed. If your string is much longer than the above, I'd encourage you to write it to a file and read it in at run time. As for shortening variable names, I haven't found much conflict there. If your variable name is more than about 15 characters, the sheer length of the variable name is hurting readability, and there's probably something you could be doing better. I've read enough Java to be pretty confident that your 30+ character descriptive variables do *not* make the code more readable.
He's not arguing against `object_ids = [obj.id for obj in objects]`, he's arguing against the drive (which we've all had at one point) to compress something into a single line, whether it's fun to write, fun to show off, or something you just learned: object_ids = [o.id for o in obj for obj in objects_to_check if obj.id &gt; 10] I don't think that's even the right nested comprehension syntax but you get the picture.
I've just taken to writing to JSON instead of a pickle. If you change your code at all, the pickled data might not be valid anymore which is enough to scare me away. Might be other issues though.
I kind of agree with you - except that everyone knows and understands json, and there are good json libraries available on every platform known to man (including in your web browser). With that in mind, json is really good enough for most purposes, and the added compatibility outweighs yaml's superiority. json also has the virtue of being dead simple, and since yaml is a strict superset of json, it is *necessarily* more complex. Simplicity can be a virtue!
FWIW this isn't as helpful as you probably intended. Maybe you could provide some reasons why it's easy and natural. Sorta sounds like you're ragging him for not knowing already.
&gt; Break the rules I suppose learning when to do that comes with experience. Did I get your meaning right?
pipenv and pyenv are part of the newest hotness
In Scikit-learn, what can I do to store the object that makes predictions?
** threading works just fine for dispatch of database queries and many other uses ** pycharm reminds me of Visual Studio too much. I debug in Jupiter. You do need a specialized editor for Python to resolve spaces vs tabs. 
be conscious with print and onliners if you are writing in 2.7 and will be porting to 3.x. map returns list in 2.x but itrerator in 3.x 
Nothing wrong with pickle. If it works for you -- keep using it.
Attached is the error I'm having. (https://www.dropbox.com/s/p3arsnkua4aeybc/reddit-cli.png?dl=0) What I did is add an exception though (https://www.dropbox.com/s/s0x5j60avkwo1p2/Inkedreddit-cli-2_LI.jpg?dl=0), but i don't know if it fix the problem or it just stopped there.
&gt; threading works just fine for dispatch of database queries and many other uses It does, but I don't think many people are writing their own threadpooled database connectors. Even senior engineers, let alone beginners. If you want that specific functionality, use SQLAlchemy. If you just basically want some concurrency, use `multiprocessing` and pool map. &gt; pycharm reminds me of Visual Studio too much. See, I think Visual Studio is a fantastic piece of software. Granted, I haven't used it since 2008. But at that time it was a revelation. It's much harder (and less visually-aided) to sprinkle in some breakpoints and step through code in Jupyter than in a proper IDE, IMO.
Nothing wrong with pickle. It dirty, cheap, gets the work done.
Ditto! Big mistakes have been made. Try and not reinvent the wheel. 
Python without classes is ugly. Do you just shuttle data via global variables? Dozens of arguments?
Good catch. Will fix it.
good bot
That software development isn’t about tricks. It is about process, communication, and application of best practices.
Thanks a lot for the reply it was very helpful
Yeah, lots of speech commands. Can do a variety of things such as stream music off youtube, set calender reminders, alarms/timers, give me the weather, do some math, tell me the news, answer any general question and look up stuff from wikipedia. Fun stuff
* Beautiful is better than ugly. * Explicit is better than implicit. * Simple is better than complex. * Complex is better than complicated. * Flat is better than nested. * Sparse is better than dense. * Readability counts. * Special cases aren't special enough to break the rules. * Although practicality beats purity. * Errors should never pass silently. * Unless explicitly silenced. * In the face of ambiguity, refuse the temptation to guess. * There should be one-- and preferably only one --obvious way to do it. * Although that way may not be obvious at first unless you're Dutch. * Now is better than never. * Although never is often better than *right* now. * If the implementation is hard to explain, it's a bad idea. * If the implementation is easy to explain, it may be a good idea. * Namespaces are one honking great idea -- let's do more of those!
Learn patterns and algorithms and data structures. Learn a dozen other languages. Know C. Know how a computer works.
Python *with* classes is ugly in my opinion :) If you want to structure your data just use dicts. A python object is just a fancy dict anyway. I honestly encourage you to try to write Python without them
I wrote a decorator that validates arguments but has no knowledge of the number of arguments. That seems to be a pretty valid use. Other than that I really hate when I shift+tab in jupyter and there's just a *args, **kwargs signature. How do you use them?
what do you mean by 'code smell'?
If I understand you correctly, consider using `functools.wraps`: it copies the docstring and possibly the signature of the decorated function into the wrapping function.
Follow PEP standards, the best: PEP8
The idea of infix function, for instance mentioned key to value, seems fine to me, though it is weird fot the first look. When I saw it for first time I thought it is strange inconsistency in design ☺ 
Nice! Thank you
I agree Python is the best language to get started with programming. There are many free online tutorials available. For example https://www.codecademy.com/. If you like minecraft game, this web site can teach you Python and JavaScript in a 3D game environment: https://craft.buzzcoder.com/.
I think threads are absolutely fine to be encouraged to use, if you understand their limitations. Any kind of network IO is going to benefit using threads... I have a lot of code that is like: with ThreadPoolExecutor(12) as exe: results = exe.submit(fetch_resource_from_url, resource_ids) etc etc
Not a "senior", but a couple of programming basics: * Honor DRY (Don't Repeat Yourself). A mistake I see a lot on early Python code posts is tons of repetition. If you're repeating anything, assume that there almost *has* to be a way to not do that in Python. Example: if condition == condition1: print(a) if condition == condition2: print(b) # etc...etc...etc... Instead, dicts!: my_dict = {condition1:a, condition2:b} #etc, etc.... print(my_dict[condition]) * Use descriptive naming. Don't do any of this: def gcid(fn,ln): def gcustID(first,last): def customer_ID(first,last) when you mean this: def get_customer_ID_number(first_name, last_name): 
I took it as a warning that the code might be shit, or at least coded to poor standards. He might have meant something else, but that's what I took away from it. 
what if a library you use in project A depends on a feature from dependency B that was deprecated, and project C depends on the newest version of dependency B?
Learning a new programming language can be boring if you don't have a fun project to work on. If you like playing minecraft game, this website will teach you coding in a 3D game environment where you can learn Python or JavaScript by building your own virtual world: https://craft.buzzcoder.com.
I took over a project that used these both liberally, with no tests. Ambitious deadlines and zero tests led to awful code that I just made worse. No tests makes it difficult to refactor the code, so you end up just patching everything and making way too many code paths...
Thanks! I'll be sure to check those out
YAML is decidedly *not* a better choice than JSON. Especially if you are using Python. It is unbelievably slow to de-serialize and there are no optimized parsers available (except the libyaml CLoader, and even that is ungodly slow). JSON, otoh, is fast and ubiquitous. 
Never really happened happened so far. 
&gt; * `multiprocessing`, not `threading` I assume your point here is about the GIL? I'd say there are definitely uses for both multiprocessing and threading, and a good Python dev should know when to use which. I'd also add async to this as well. Either with the Python 3 builtins, or in Python 2 with gevent/eventlet/greenlet.
You need parentheses around that value to get it to behave the way you say it behaves.
Sure except I can serialize objects, numpy arrays, etc. If speed is your concern json isn't your best choice either. Yaml is ubiquitous as well and at least I can make sane schemas from it. Json is a fucking mess because it's so weakly typed. 
&gt; Avoid *args or **kwargs unless you know you need them - it makes your function signatures hard to read, and code-completion less helpful With 3.6 you can at least type-annotate them, which helps clear up their ambiguity. A necessary evil, in a lot of cases (subclassing, etc).
"Code smell" is when you look at a block of code, and while you're not sure what's wrong with it, something about it seems a bit fishy... Basically, it means "probably sub-optimal code".
Code that hints that something is wrong without having to read or understand anything else around it. It gets its name from anything in real that stinks, which you'll smell before you see. `open`/`close` without a context managers will likely result in a resource leak if done outside a `try`/`finally` block. And if you're going to add a `try`/`finally` block, why not make it a `with` statement and save yourself 2 lines of code...
&gt; javsfriptnfeobt ...
Hah thanks. I'll fix it.
I'm in the same situation. I *know* I'm supposed to use virtualenv, and I do at work, but for my personal projects I've never run into this problem. And I'm verifying everything att Appveyor or Travis, so I don't run the risk of forgetting to add a package to requirements.txt, which would otherwise be an argument for virtualenv. 
imo, the _only_ thing YAML is good for is human eyes, and if that is your use case I don't think it's more readable than, say, TOML. In fact all the unclear indentation rules make it kind of hard to parse visually. &gt; serialize objects, numpy arrays, etc. Safely? Only if you jump through all the `safe_load` hoops.. sounds like you aren't if you are serializing numpy arrays. If you are jumping through the hoops, you might as well spend that time writing custom JSONEncoder classes, since YAML is so crazy slow in comparison. I don't mean to be harsh, but many people I've worked with over the years have had a big crush on YAML only for it to cause me many headaches over the years.
Not quite as elegant, but tuple unpacking still works in Python 2 and old versions of Python 3: `a, b = seq[:2]` I prefer this over multiple assignments using explicit indicies.
a linter should be part of your workflow already. We don't allow any code to be pushed unless there are no pylint warnings
Exactly, classes are fancy dicts and that's why you should use them. Classes basically make sure that your data isn't changed in invalid ways, and they ensure that the functions created to manipulate that data stay organized. If it's your project, or you're working on something small, classes might not be worth it. But if anyone else has to read your code, and you don't want to subject them to observing all the states and behaviors of your data structures, you should do them a favor and write your code in a way that is helpful. I absolutely do not want to spend my time figuring out how you organized your data if I don't have to. Give me a function that says "performX(argument)" and I get to skip how the data gets manipulated in the background 
`a, b = seq[:2]` works
What's your goal of creating UI application with Python? While it's fun to build such application with Python UI libraries, the skill won't be very useful. You are more likely to find a job if you know HTML/CSS/JavaScript.
lonely bot
Don't forget to watch Beyond PEP8, making your code more readable, by Raymond Hettinger https://youtu.be/wf-BqAjZb8M
I'm currently using that branched ifs conditions. Thank you for sharing the dict method !
My advice would be to learn to use both list comprehensions and map, and use either one where it is better. I would prefer map(int, list_) over (int(s) for s in list_) But I would *not* prefer map(lambda x: x.__class__, list_) over (x.__class__ for x in list_). However, this is my personal preference, and I would not fault anyone for disagreeing. 
It's fine to be harsh and have a heated debate as long as it doesn't get personal. Fighting it out is educational So .... Is it as bad as getting a schema where some numbers are text and you can't tell if that's intentional? In mean maybe that "1" is 1 or maybe, God forbid, it means True. So now your semantics is in the code because in javascript, button + time evaluates to something but not in python. The weird.indentation rules aren't weird at all to me so the spurious bracketing annoys me. I have to call that personal preference I guess. Finally in regards to performance I don't yaml serialize performance code. There are alternatives like flatbuffers so I don't have an issue with slow yaml in that since. 
Can someone explain when I should use yield instead of return?
How many people develop with a single ≤1920x1200 monitor? I am inefficient and claustrophobic with less than 2 ≈1920x1080 monitors.
Welcome to Test-Driven Development. Pycharm has a setting for rerunning the last test automatically when your code changes, which is useful when using TDD. 
Unless it's for the exercise or fun of it.
&gt; The weird.indentation rules aren't weird at all to me so the spurious bracketing annoys me. I have to call that personal preference I guess. just to be absolutely crystal here, JSON as a human-readable format I do take major issue with. I have to deal with "config" files that are JSON now, and it's a hell I wouldn't wish on anyone. I have a vim plugin that makes it a little more bearable, but yeah.
If you are switching to a different language/stack for more job opportunities, then you should consider JavaScript. Python is a better language than JS, but if you know JS then you can work on both server side (node.js) and client side). Node.js is probably more popular than Python/Django these days. Language itself won't be an issue, you will spend most of your time on the new framework, libraries, tools and so on.
I think closures can be tested just fine. import unittest def foo(n): def add_one(): return n + 1 return add_one class AddOneTest(unittest.TestCase): def test_add_one_increases_value_given(self): add_one = foo(1) self.assertGreater(add_one(), 1) if __name__ == "__main__": unittest.main() You have the same control over the code under test as you would in the class example. Pass in a mock object to __init__ and get an object with a mock inside it or pass a mock object to a function and get a closure with a mock inside it. Either way there's dependency injection and visibility into what's happening under the hood. Far from black box testing.
In Python 2.7 it's the only way to do stuff like keyword only arguments
Sadly functools.wraps doesn't do everything, the decorator module wraps some more details but then you need to add a dependency and sadly Python is still not great with dependencies
When you have several nested if statements you probably need to create a new function to replace some of the code. Naming functions is hard. Functions should be pure where possible. This means if you call a function with an argument then it always returns the same result.
My longest lines are from logging, too. I've tried to shorten them but nothing is satisfyingly readable, so I go back to the more readable long version. The closest I've come to being happy with long strings is `' '.join([...])` or `'\n'.join([...])`, or writing my logging message in triple quotes like a docstring and using `textwrap` and `lstrip('\n')`to remove leading whitespace. Fstrings will help with formatting args `'Reason: {reason}'.format(reason=reason)` is ridiculously redundant. I could get away with `'Reason: {}'.format(reason)` here, but as the message gets longer and has more format variables, using named format variables is critical to readability and not accidentally transposing or skipping a format variable. Formatting using `'Reason: {reason}'.format(**locals())` or some `inspect` reflection seems too hacky.
A missed opportunity
Memory. `yield` creates a generator, which provides the latest result in memory as you operate over an iterator. `return` creates a standard function, which operates over an iterator until the operation is completed, then provides a final result. They’re not always interchangeable, but there are plenty of cases where `yield` will provide you with flexibility and lower operating cost, such as trying to iterate over 1,000,000 rows of data. Fetching all of those rows at once will probably result in a memory error. A generator allows you to iterate over those 1,000,000 rows and only store one in memory at a time.
both of them have a lot of practical use. I personally find them much more readable that chains of if &amp; for
&gt; Know the dunder methods this is a key feature to understand how you an code better in python
Nope. For loops in a nested comprehension follow the same order as if you wrote out indented for loops and took away the whitespace and colons. The return value moves from the end to the beginning in a comprehension, but that's the only thing that moves. It's helpful to know this stuff when debugging in a REPL, but I agree that if you can't reliably **write** it or **read** it and know what it does, it doesn't belong in production code. `for obj_id, obj in dicts_of_objects_to_check.items(): for o in obj: if obj.id &gt; 10: yield o.id` `object_ids = [o.id for obj_id, obj in dicts_of_objects_to_check.items() for o in obj if obj.id &gt; 10]` 
Code complete and PEP8 makes me the developer I ain't. Also , list comprehension is probably the closest thing to witchcraft python can do. Learn that.
Yield is for generator expressions. It is used to avoid storing entire lists in memory. 
It's not about how complicated you can make it, but how simple you can make it.
Rules are there so you'll think twice before breaking them
Do they provide any practical benefit outside of web development?
Are you talking about pytorch? In fact, I found this kind of OOP suitable in the context of neural network programming. It will lose generalizability if it's implemented using functions.
&gt; While it's fun to build such application with Python UI libraries, the skill &gt;won't be very useful. Knowing how to produce an interactive application won't be useful? 
Documentation and code comments. It doesn't matter how clever you are if no one else can understand what you have done.
Narrow files help when diffing / merging on a laptop.
&gt; def f(x): # do something with x and params return f I'm kind of surprised python hasn't added anonymous non-lambda functions yet.
Great I know who put that incomprehensible code into all my past projects... It was you!
Just a word of warning when you refactor... Beware the trailing comma. 
Seek the dunders. Learn their magic. Become a wizard.
Threads aren't really threads, even if you go with threading.Thread its all bullshit. You will almost never notice this with regular threads, but once when you do hit an issue (1 thread just stops executing because the other one is making a blocking call) its a pain in the ass to figure out what is going on. The multiprocessing library handles this in a way more similar to other languages.
red flag
Structure it into a type that has an arbitrary structure. Got it. Functions that pass around dicts and have to keep guessing the key/value contents of the dicts are not better than well designed classes for any project bigger than a single script.
Much better than a owner of a broken bot
When you do a `try: except:`, make sure that you at least except `Exception`, or you could run into weird issues like not being able to stop your program. This is because `KeyboardInterrupt`, `SystemExit` et al are derived from `Exception` and will be swallowed if you don't except them or a superclass. e.g. do this: try: some_risky_thing() except Exception: pass and not this: try: some_risky_thing() except: pass
`pyenv` is a python wrapper which invokes a per-project version of python. It also helps you install them. `pipenv` attempts to make pip and virtualenv seamless. It also leverages `pyenv`.
Don’t use too many clever tricks. Your team will not be enthused. That’s all I’ve got.
Okay thanks ill surely look into it.
Except don’t use “except Exception” and choose a reasonable Exception type for the situation - using “except Exception” is exactly the same as “except:”
Right, that was unclear from your Perl. Here's a variant that calculates it at all the steps. I've used Pi/11 as the seed, but again that incurs an inherent imprecision at step 0, and its perhaps a bit more meaningful it num and den are both ints. Yes, just glancing at it, the deviation due to rounding error grows rapidly, then seems to level off. **Decimal** is much slower, but should be closer to the correct value, as it's not subject to floating point rounding. from csv import writer from decimal import Decimal from math import sqrt, pi def compare(num, dev, fact=0.5, rounds=10000): z = float(num)/dev dz = Decimal.from_float(float(num)) / Decimal(dev) print("Seeds", z, dz) fact = float(fact) dfact = Decimal.from_float(fact) b = 10**50 for _ in range(rounds): z = sqrt(4*z*(1-z)) fixed = int(fact+b*z)/b dz = (4*dz*(1-dz)).sqrt() arbitrary = int(dfact+b*dz)/b diff = fixed-arbitrary yield fixed, arbitrary, diff comparison = compare(pi, 11) with open('compare.csv', 'w', newline='') as f: w = writer(f) for c in comparison: w.writerow(c) That will produce a .csv you can load into Excel to compare. I'd be curious to know if the Decimal's ability to use as much precision as it needs helps the matter.
Multiprocessing has some major issues and is definitely not comparable to threads. :(
Since we're talking about 2.7/3.x wackiness: `//` is the integer division operator in both 2.7 and 3.x. `/` has different functionality in each. In 3.x, it's the float division operator. In 2.x, it's just the "division" operator, and behaves as float division if one or both of its operands are floats, and int division otherwise.
or just import this
While I do not program in any functional language, learning the functional style has greatly improved my coding in other languages. Wherever possible, I try to avoid mutation of state and express things as pure and side-effect-free functions of other things. Functional code does not have to mean deeply nested inscrutable expressions, tons of lambdas or lots of passing of functions as first class values. You can split your code into smaller functions, use local functions or simply assign intermediate values to some descriptive name to keep things readable. It's the functional style that really matters. List/generator oconprehensions are just a very useful tool for writing readable code in this style. 
I only use `threading` for I/O operations that the main thread doesn't depend on, mainly logging.
Watch Ray Hettinger's talks
btw, read more about coding style from Google and CIA Google: https://google.github.io/styleguide/pyguide.html CIA: https://wikileaks.org/ciav7p1/cms/page_26607631.html
Dude just have fun. Also don't use pygame, it'll only break your heart
Be empathetic. Think about the person that will have to use what you wrote and/or read/maintain it. Always ask yourself, "how do I know this works?" That combined with the implicit assumption that you want to write something that works directly leads to testing. Don't write tests because you need to check some checkbox. Write tests because you want to be confident it works and you want to write something that works. Actually, those are more pearls of wisdom than tricks. Tricks... Use a linter. [n]vim + ALE + flake8 is a great combination. Abide by [PEP 8](https://www.python.org/dev/peps/pep-0008/). There's an accepted standard. Use it. https://devdocs.io/python/
&gt; If you need a counter along with the items from the thing you're looping over, use enumerate(items) And if you need to count *and* zip, use `zip(itertools.count(), list_a, list_b, ...)`. :-)
https://eev.ee/blog/2015/10/15/dont-use-pickle-use-camel/
I find a good rule of thumb is to only catch exceptions when I know *specifically* what exception will be raised by my code. If I don't know precisely what exception I will get, I resist the temptation to guess and just leave out the try-clause for the time being. When I trigger the exception later on I will add it. If there are several exceptions that I want to treat the same, then: try: result = getattr(obj, attr)[index] except (LookupError, AttributeError): result = default 
Point 1 example is not a correct DRY example. Repeating statement is programing. DRY is about not duplicate knowledge. And honnestly I also use dict or sometime class with getattr for that. I see people abusing the DRY to 'zip' the code at it extreme, and make it unmaintanable. The DRY principle is stated as "Every piece of knowledge must have a single, unambiguous, authoritative representation within a system". The Pragmatic Programer
* When prompted by a problem that is best solved with something you don't understand, learn it. This includes dunders, itertools, and loads else. * Always be on the lookout for a good library for any task. Be aware that you'll get burned, but you'll also find gems. * I hate most language-native HTTP libraries, but Python is my least favorite I've used. I recommend the `requests` module. * Learn how generators and iterators work. Use them. Being able to use infinite sequences winds up being useful from time to time and elegant code the rest of the time. * Use a linter. I like pylint, but flake8 is a bit easier and more convenient. * Understand truthiness. * Use SQLAlchemy for databases whenever you're doing anything somewhat complicated. * Use SQLAlchemy-migrate if the database is actively under early development. * 3.6 and 2.7 are very different. Keep that in mind if you're working with the one you're less familiar with. * The python standard library is immense. Use it, familiarize yourself with it. * Python is inherently less performant than languages like C++ and Java. If you need the most bang for your clock cycle, look elsewhere. * Despite that, python is excellent for chaining invocations of other software, and acting as a "glue". * Use the best language for the job, not the one you're most familiar with. * Learn other languages too once you're experienced with Python. It'll open your mind to new paradigms and design patterns.
Quick rule I use: If the keys are static it should probably be a class. If they keys are dynamic it should almost certainly be a dict.
If you’re not writing a framework, you almost certainly don’t need a metaclass.
What's with the "docstrings"? XD # ------------------------------- ## # @Synopsis This method actually # converts the json data that is converted # into dict into XML # # @Returns XML # --------------------------------- Also, having lxml as a dependency seems way too much. A library as simple as that installs the following certifi (2017.11.5) chardet (3.0.4) dict2xml (1.5) idna (2.6) json2xml (2.1.0) lxml (4.1.1) pip (9.0.1) requests (2.18.4) setuptools (36.7.2) six (1.11.0) urllib3 (1.22) wheel (0.30.0) xmltodict (0.11.0) Which is waaaaaaaay to much. There are a lot of things that exist in the standard library (such as xml writing/parsing and http requests. Please don't turn Python and pip into nodejs and npm.
I would say it’s _the_ key feature. If you told me I had two hours to make someone way better at Python, I’d spend every second of it on dunder methods and collections.abc.
Work on your programming rhetoric. * Express yourself in a convincing and replicable manner. * Don't beat around the bush. Get to the point with the shortest possible code. Compare with accidental complexity vs essential complexity. * Be sure to name your artifacts properly. Not too long and not too short. No `data` or `items`, except where totally obvious what it is from context. No `items_which_come_from_that_other_server_unless_cached` either. Upon reading, the names need to get into your brain fast. * Read your code as if you never saw it before and adapt it if it is confusing. * Don't shy away from "not invented here". It's mostly a good learning experience. * Don't shy away from throwing your own code away if you find a library of objectively(!) better quality. Read the code before using.
I have [funcy](https://github.com/Suor/funcy) in almost every project. I think the functional stuff mixes fine with pythons mixed style and the various other decorators and things are very handy to have available. 
&gt; Even if the test doesn't even actually test and just does a print to start... Thank you for the tip; I hadn't thought about it that way before! This is gonna make me much better at writing tests I think
Hm, Python has more problem with recursion by itself than really FP. I use heavily currying (with functools or toolz), and accepting callable as parameters of a function lead to nice API without needing object style programming. You can juste include the needed function / the needed module if you wanna avoid real dependency.
They're not the same. `KeyboardInterrupt` doesn't inherit from `Exception` so it won't be caught. `except:` is the same as `except BaseException:`. https://docs.python.org/3/library/exceptions.html#exception-hierarchy However, I do agree it's a good idea to be more specific in exception catching.
I have flashbacks of leftpad
Haha! The comments are pretty old and used some Doctring generator. Good point about lxml, actually it had beautifulsoup from before and it was a dependency for that. Requests is pretty nice and does a lot of things that I didn't want to do using stdlib
Write tests. Python projects often start small and you think you can get away without testing but once they have grown adding tests becomes a hassle. Designing your code with testing in mind makes all code better.
Which books or tutorials I should start with? Take in consideration that I have no experience with GUI at all. 
Use meaningful names for variables. For example, `name` and `age` instead of just `n` and `a`. When there is *no* need to use index, just iterate over the values: numbers = [1, 2, 3] # Do for number in numbers: print(number * number) # Don't for index in range(len(numbers)): print(numbers[index] * numbers[index]) Just my two cents.
Oauth2 is for authorization, not authentication. I would go with any of those, but it's up too you. I didn't work with any of them, but from what I've seen, sanic is much new user friendly as it it inspired by flask. But if you want to dive into more asyncio related concepts, I would go with aiohttp (they also have a nice tutorial: http://aiohttp.readthedocs.io/en/stable/tutorial.html) . For authentication, you can easily implement your own, using a session cookie.
What's wrong with pandas.read_csv
Variable names: **use your words**. * Good: `counter`, `probe`, `product` * Bad: `c`, `cnt`, `prb`, `p`, `prd`, `prdct`, `obj` Additionally, generic names like `object` are too ambiguous. If at all possible, *be specific* when naming things.
Why would I use builtin csv module when I have pandas?
* Get familiar with generators and try to use them wherever possible. * Not everything has to be a class. See https://www.youtube.com/watch?v=o9pEzgHorH0 * Try to use absolute imports when possible. * Understand the limits of threading in python, GIL, multiprocessing, etc. * Get familiar with async io, either python's native one for 3.5+, or tornado if you're working with 2.x * Never use a list as a default argument (foo=[]) in functions. * Be careful when adding 3rd party dependencies, but don't reinvent wheels. If adding a 3rd party library, glance it and make sure it has minimum dependencies by itself and it's in active development. Installing 30 deps because of something small you needed is painful. * Don't rely on pip installations for deployments. Package your stuff properly with virtualenv or containers when deploying. 
Thanks for this. Found some really interesting stuff!
&gt; Use virtualenv for every project - don't install python packages at the system level. This keeps your project environment isolated and reproducible I recommend: https://github.com/kennethreitz/pipenv It makes your life a lot easier, when it comes to virtual environments and package dependencies. &gt; Use Python 3.6, there are some significant improvements over 2.7 - like enums and fstrings (I would switch to 3.6 just for fstrings, TBH) I'd like to add, that 3.5 introduced the [typing module](https://docs.python.org/3/library/typing.html), which got a lot of improvements in 3.6. The *typing* module allows you to add type annotations to your code. If you use it, a good IDE will catch type errors right away and your code becomes easier to reason about.
The only thing i disagree with is using the csv module for CSVs. I've found that using pandas and pandas.from_csv to be much more productive in almost every way.
Are you reading and setting instance variables throughout? I would prefer a clear data flow which is done by passing return values of some functions into other functions, rather than functions that save/load on the instance and expect to be called in a certain order.
Young'uns (young ones) :troll_face:
Apologies for being unclear. My intention was to suggest that it’s better to be more specific because you definitely don’t want to get stuck debugging issues where “except Exception” ends up catching unexpected errors, and that “except:” is about the same level of bad as the former.
it gets me stressed when i have to alt tab 3 times to write a line of code
Didn't know that. Hahaha. Always thought it was young guns.
Don't forget operator !
jq for complex json management, postgresql(psycopg2) for sql(much simpler than mysql), sublimetext if your on linux and want a decent editor that doesn't require you to remember weird keybindings. requests for easy http, Decimal('0.034332')(with the ') for math that works, curio is supposed to be better than async(but i haven't tried it). If you think you have to make an asynchronous app, you might get away with just saving stuff to a DB instead and lifting it from DB as you like. (For example i have a script getting stuff from server, formatting it as i like, then putting it into DB, then i have a separate script that lifts stuff from DB as needed. If i were to put all the code in one script it would be incredibly unorganized and i would have to make everything asynchronous.) oh, and use latest python, it's confusing with all the people still on python 2.7 :P
The line I always remember is someone saying that debugging is twice as difficult as writing the code in the first place. Therefore, if you write code that's as clever as you can possibly make it, by definition you will not be clever enough to debug it.
Well my code is very sloppy (not a developer just self taught) and half the variabels are in Danish. But I probably will put it on github when I'm Done soon.
Need to install a library from pypi on a system you have limited access to? Append the --user flag to easy_install or pip. Sometimes virtualenv isn't the answer or isn't even installed. easy_install --user pip easy_install --user virtualenv Depending on your OS, there is a site_packages path in your home directory. So make sure to add it to PATH. For macos it's: ~/Library/Python/X.X/bin
input() gives you a string. So you need to write: age = int(input()) And then it should work (unless I’ve missed something else)
jq is good to deal with JSON. Don't know what i'd do without it.
When I change the Age = input() to Age = int(input()) --- I get Traceback (most recent call last): File "python", line 7, in &lt;module&gt; TypeError: must be str, not int
What error do you get?
**1)** Use [pyenv](https://github.com/pyenv/pyenv) to help you manage multiple python versions. It allows you set up a global Python version(s), and a local python version(s) on a per-project basis. **2)** f you're dealing with non-ascii text and you have to do a lot of text processing, convert **ALL** strings to unicode strings, then perform all the processing you need, and then encode back to UTF-8 (or whatever encoding you want) at the end. In Python 3, this is already done for you since the default string type is a unicode string. In Python 2, unicode strings have a separate [unicode type](https://docs.python.org/2/howto/unicode.html#the-unicode-type). To make your life easier writing code for both Python 2 and 3, use the [six](https://six.readthedocs.io) module to help you detect Unicode strings like so: import six def isunicode(obj): return isinstance(obj, six.text_type) then encode and decode accordingly. **3)** In fact, checkout [this cheatsheet](http://python-future.org/compatible_idioms.html) for writing 2-3 compatible code in general. Hope that helps :)
If I am going off the paste I originally gave and not the modified help suggestion from Irual - The error I receive is - Traceback (most recent call last): File "python", line 13, in &lt;module&gt; TypeError: unsupported operand type(s) for -: 'int' and 'str'
Haha right, now when you concatenate the strings in print() age does need to be a string. So you can either write str(age), or move the int() to the calculation part
How about `map(operator.attrgetter("__class__"), list)`? ;)
&gt; Don't nest comprehensions, it makes your code hard to read (this one from the Google style guide, IIRC) &gt; How do I nest comprehensions then? Wrap my comprehension in a loop? That's just ick.
That the difference between an intermediate and a senior programmer is mostly not about their ability to write code. "Senior" referrers to responsibility, not to technical skill level. A senior programmer mentors their team to help them learn, keeps them happy and working effectively. A senior programmer works the teams client - be that a paying customer or an internal product owner - to make sure the team has what they need to be able to deliver, and to make sure the team isn't committed to more than is reasonable. A senior programmer works to co-ordinate their team with other teams - testers, analysts, product owners - to keep things running smoothly. To actually answer your question - don't memorise the documentation. I see people getting worked up that they don't know the name and arguments to every function in the standard library - that is not useful. Read the documentation, know what tools are there, but it is more important that you know what tools you have than how every single one works
&gt; Use the csv module for CSVs (you'd be surprised...) People _loooooove_ parsing CSV by hand. "No it's fine I'll just split on commas" - famous last words
Some issues: 1. The Python naming of variables is lower case with words split by _. In that case it is name, age, if you have something that is more than 1 word it looks like player_age. Just note that because most Python developers like to keep a similar style. 2. Don't concatenate strings with +, it's not very nice to look at, instead do "Well {}, what is your age".format(name) {} or {0} (you can repeat the same word in a str if you want) is replaced with the thing in the brackets. 3. You can handle both yes and Yes or YeS or whatever other version that could happen with &lt;str&gt;.lower()
At my company if flake8 reports any errors then you can't submit your code, also if pylint reports more than a couple issues (forget the number) then it's also blocked.
I disagree. People like to split code into multiple vertical columns to open multiple files at once. If it's wider than 80 characters then this limits the number of parallel open files.
Like a spellchecker, but for code.
I think the general issue is that pandas and its Dataframes are heavy
"Python is inherently less performant than languages like C++ and Java. If you need the most bang for your clock cycle, look elsewhere." Maybe less performant than C++, but atleast for GUI programs i think python and QT for example will be more performant than java and whatever gui api it uses. For example pycharm runs like a dog on my computer, but having written relatively complex gui apps with python and QT i know that if it was rewritten in QT and python, it would run a lot faster. And if you really need speed you can use c extensions?
&gt; Prove you're right. I really like this one!
FlukyS answered your problem quite well :)
Bookmarking this thread
Hop onto a few servers with ssh and vi, or take your laptop to work alongside a client. Plenty of reasons to stick with the 80.
I love fstrings, it's just **so convenient**
&gt; Try out pipenv to make virtualenvs simpler (among other things) Also `pew`
Whats the reasoning for using destructuring over indices?
What you're really asking is "why would I need this lightweight, native file parser when I have this 3rd party data analysis library?" to which the answer is pretty obvious. 
It still doesn't hold up. Your example betrays the issue. I can see no conceivable reason why you can't get away with "OrderModel" and "StoreModel" and just make them general classes. If they DO the same thing, the data should not matter.
I'm a pythonist, and I'm only a few years off being able to afford my seniors card (you think that card is free?). I don't think that word means what you think it means... but more strictly **stop using Python2.7** and use pip and keep things up to date. I don't use the with.. for files but I do intent to try. and I do a lot of .rstrip().split() because the line fluff is a pain. learn how to use UTF-8 properly and when and why to use encode() and decode() Python with types. Functional. Think about moving on to another langauge with strong types and FP.
Assign to intermediate variables with useful names - this helps separate the various steps, and more importantly explains why for each. If you use generator comprehensions it's even lazily evaluated, so there's (almost) no cost to this. 
r/pythontips
In general, that second bit of code should probably use my_dict.get(condition, default) in case the condition passed in doesn't exist in the dictionary. Not a senior pythonista either, but I've run into enough key errors by now to know better than to just pass a key into a dictionary and hope it exists.
How do you catch an OSError when you also want to use the with statement? Would you say it's OK to write it as the below? Personally I try to keep my _try_ statements with as few lines as possible: try: f = open(myfile) except OSError: # some stuff # an optional else else: with f: # do something with f
One thing that can help is simply renaming them more usefully. Think for example of this function (not quite the same as the built-in): `sum(*args)` You can sort of guess what it does, but not really. What types does it accept? Can I run `sum('Get ', 'Schwifty')` and have it behave as expected? With the above `sum` function, you don't know. So let's improve the function to make it more obvious that the intent is: `sum(*numbers)` This function works identically to the above `sum(*args)`, but now it's clear that you're intended to use it with numbers.
Wear sunscreen.
Not familiar with generator comprehensions, how are those different from normal comprehensions?
What's wrong with pygame? I've never used it so I am genuinely curious.
Agreed. It handles a lot of things a lot better than the csv module. Plus if you're still stuck on python 2, and your CSV has non-ascii characters -- welcome to hell. Even with the recipe from the docs it turned into a nightmare. 
Why ALE over syntastic? I have been thinking of trying out ALE for a while now.
I want to create a program that dimensionates hydraulic pumps for my engineering undergraduate thesis.
I updated the original post text. It was misleading because I used to models als example. The issue is not about two tables or two models. Its one model relating to two identical tables in two different databases.
Functools is a part of standard library, so what dependency?
Note that Pipenv is currently [hard broke](https://github.com/kennethreitz/pipenv/issues/875). 
Haha, I'd be happy with just: * Write pythonic code. * Pep8 everything before committing. * Detailed and current in-line documentation.
Does `ptpython` or `bpython` support something like the `?` syntax (as in `instance.method?`) in ipython? That's one of my most-used features.
Pickle it and write down its SHA256 on a piece of paper, put that piece of paper in a safe, and verify by hand that you have the correct SHA256 before loading the pickle. At least that's what this subthread has me thinking, lol.
Why on earth would admins hate you for installing stuff in your home directory? That's what you're supposed to be doing on a system you don't have full access to.
For those who don't like nested loops, this can still be salvaged: turn the inner parts into generator comprehensions, use `itertools`, and assign them to variables with meaningful names (omitted for easy comparison): from itertools import chain obj = chain.from_iterable(dicts_of_objects_to_check.values()) object_ids = [o.id for o in obj if obj.id &gt; 10]
The 3rd party "decorator" module, it does a more thorough job of wrapping details of decorated function http://decorator.readthedocs.io/en/stable/
Or doable in just the standard library: xmlrpc.dumps(json.loads(…), allow_none=True)
Provided you're talking about containers, absolutely. Web or otherwise, being able to isolate your dependencies and bins in a container allows you to not only develop locally painlessly, but also know that your code will anywhere else (even with a cli, if I containerize it that could be a way for me to distribute my application. I know it'll run just fine on your machine as a container as well).
added , sep = '\t' at the end, no change in error! 
I stand corrected...
I did think about that one. And immediately discarded it. (-: attrgetter is useful when the attribute name is dynamic, though. 
You get a lazily evaluated iterator, instead of a list/set/dict/whatever. Taking `sleep` as a convenient slow function: def slow(i): sleep(i) return i a = (slow(i) for i in range(10)) # instant b = [slow(i) for i in range(10)] # takes 55 secs sum(a) # takes 55 secs sum(b) # instant The downside is that you *have* to iterate; there's no support for indexing like a list. So why is it useful? If you're processing incrementally this can give you more consistent performance - instead of waiting a minute at the start, you wait a little bit between each. More importantly, you don't pay for values that you won't use: total = 0 for num in a: total += num if num &gt;= 5: break This never calls `sleep(6)` or later, so it's much faster than looping with `b` - just 15 instead of 55 seconds. On the other hand, lists *are* a bit easier to work with, and operations like taking a slice are generally more concise (though you can eg use `itertools.islice` on an iterator!). Use your own judgement, and remember that you code is read by humans as well as run by computers!
You need to put your file name in quotes. Also, /r/learnpython.
&gt;when you think you have to write something, check the standard library. if you still think you have to write it, check it again. then check some of the major libraries. The order of these two things should be reversed. Nobody should be trying to use urllib2 instead of requests unless they have a very good reason. For most of the "batteries included" libraries in the standard library (email, HTML, network, XML, OS path handling, etc.), there's better equivalents on pypi.
A generator expression (not comprehension [1]) is not evaluated until its value is needed, compared to normal comprehensions. &gt;&gt;&gt; a = [1, 2, 3, 4, 5] &gt;&gt;&gt; type([i for i in a]) &lt;class 'list'&gt; &gt;&gt;&gt; type((i for i in a)) &lt;class 'generator'&gt; https://nedbatchelder.com/blog/201605/generator_comprehensions.html
&gt; .open() or .close() is often a code smell - you probably should be using a with block Also always *always* **always** _**ALWAYS**_ pass in an encoding to "text-mode" `open` (the default in Python 3), otherwise Python falls back not on UTF-8 but on `locale.getpreferredencoding(False)`, which may be utf-8 but may also be ascii or mbcs or cp850 or any other sort of nonsense. If you want the user-configured locale (because you're reading user-provided data) pass it explicitly, but you *really* do not want whatever garbage has been configured as the locale's encoding when reading or writing your configuration files. &gt; Use the csv module for CSVs (you'd be surprised...) Also don't use CSVs if you can avoid it, clients will open them in Excel and generate absolute garbage out. Produce and consume Excel or ODF files instead if you can, Python has fairly mature packages to handle Excel data (not sure about ODF). Or sqlite if that's an option (though it usually isn't). &gt; Avoid `*args` or `**kwargs` unless you know you need them - it makes your function signatures hard to read, and code-completion less helpful And if you can restrict your code to P3-only, leverage "keyword-only" parameters (both required and optional) e.g. def compare(a, b, *, case_insensitive=False, locale_aware=False) *requires* providing any parameter other than 1 and 2 by keywords (and works even if they don't have default values), no more: compare(a, b, True, False) # dafuq?
i see thank you!! 
The ideal time to create them is when you start seeing repeated patterns in your functions see that you can use them to DRY out your code. IMHO it's not typically a good idea to pre-empt that process - writing decorators that end up only being used in one place is an antipattern.
`from __future__ import division` fixes this discrepancy (by backporting Python 3 behaviour to Python 2). Also `//` is not the *integer* division but the *floor* division operator, this makes a difference when passing floats in &gt;&gt;&gt; 3.2 / 2.5 1.28 &gt;&gt;&gt; 3.2 // 2.5 1.0 Other subtle differences between P2 and P3: * In Python 3, `round` implements banker's rounding (round-to-even), Python 2 uses away-from-zero (so `round(2.5)` is 2 in Python 3 and 3 in Python 2) * In Python 3, `round(n)` returns an `int` but `round(n, k)` returns a `float` (even if `k` is 0), in Python 2 `round` always returns a `float`.
I don't think I've ever seen a cleanly refactored list comprehension that was less clear than the equivalent imperative equivalent, no matter how complex. My default is that if I can use a list comprehension, I use one. IMHO list/generator comprehensions are clearer than map/filter equivalents but that could just be my bias. I haven't done as many side by side comparisons for that.
Values get named, much more comprehensible than having to know what the fuck [1] corresponds to. Alternative: namedtuples or structures (attrs is good for cheaply creating your own types).
Neither makes much sense, really, you want `map(type, lst)`
Pickle is fine provided the data is 100% trusted. If it goes over a wire unencrypted then you've just built a back door into your software. JSON is good when: * You're writing out data that is going to be read by programs read by or written by other people. It's the standard for REST APIs for this reason. * You want the data to be readable by humans in a pinch. * Your data is just lists, dicts, numbers and strings (or can easily be made as such). YAML (or rather, strictyaml), is good for: * Writing / reading configuration or DSLs that you want humans to be able to edit / tweak as well as read. * Speed isn't such an issue (e.g. it just runs once on startup and there isn't a huge amount of data). * Your data is just lists, dicts, numbers, strings. Pickle is good for exchanging objects you want to re-use between different python processes where the data store is completely trusted. XML is good never. You might *have* to use it to interact with something you want to use but it should never be an active choice to use it.
So I have this simple selenium-based automation for a website that I'd like to speed up by running the task in more browser windows at the same time. Would this be a good case to use any form of the Python concurrency?
&gt; performance improvement The only way to improve Python performance is to replace it with a more efficient language. This stands for all scripting languages meant to use as glue but misused as general purpose languages.
I don't see anything obviously wrong here, but wouldn't it be simpler to just use random.choice from a list?
laptops, for when you're not in the office
My ideas: * make sure your code is readable * measure more, code less * never assume where the problem is, be sure * write code that makes things easier for others, there's always a balance between performance, readability and ease of use
Vue.js, ws4py, and CherryPy is probably the easiest way to make HTML based interfaces with Python.
Hi, I'm going through this right now (maybe we're coworkers lol). Threading doesn't work with selenium, but multiprocessing does. 
What do you think one ought to call the example I gave, then? Code duplication? Whatever it is, I've seen advanced programmers here frown upon it. It strikes me as less readable and less maintainable than using dicts, in this case.
Yeah but you can do just: import json as pickle and your code stays the same. :) Nah, kids, joking: don't do misleading imports. The effort of writing code is nothing compared to the effort of reading code. Don't be tempted by making shortcuts when writing. &gt; Explicit is better than implicit. 
Except PEP8 doesn't limit you to 80: &gt; Some teams strongly prefer a longer line length. For code maintained exclusively or primarily by a team that can reach agreement on this issue, it is okay to increase the nominal line length from 80 to 100 characters (effectively increasing the maximum length to 99 characters), provided that comments and docstrings are still wrapped at 72 characters. &gt; The Python standard library is conservative and requires limiting lines to 79 characters (and docstrings/comments to 72).
That makes sense.
How about no? :)
&gt; Be empathetic. Think about the person that will have to use what you wrote and/or read/maintain it. Imagine he will be a killer who know where you live. :)
attrgetter is actually a bit faster than the lambda version. But it's both slower and uglier than the comprehension version, so I wouldn't actually use it. It has a few niche uses though.
Remember, type-safety is for wusses.
Iirc one question shows the base help, two shows in-depth right? Bpython just shows the help the whole time [0](https://bpython-interpreter.org/images/3.png)
And generator expressions are like list comprehensions that grew up.
Numpy is just a wrapper around C arrays as I understand. I have seen benchmarks showing very similar performance to C code. Of course not all problems are going to be solved by Numpy, but for some stuff that will give you the improvement you need without needing to change language. 
If you are doing anything CRUDy learn Django.
That's true here, and for some of the dunder attributes like `__class__` and `__mro__`, but some of them don't have builtin accessors like `__name__`, `__annotations__`, and `__bases__`.
Honestly don't care about the order, but what you're describing is a code smell indicating the potential for some very WET code. That alarms me a bit.
Still easier to deal with than the missing brace you will get in other languages. 
 try: with open(myfile) as f: except OSError: # some stuff
&gt; multiprocessing, not threading Sometimes? `threading` works fine for IO bound stuff. But now we have asyncio to help with that.
Chaining on iterables introduces new issues and can sometimes hide real problems due to how exceptions are propagated. Not recommended.
Definitely _still_ not a unit test on function`f`.
Interesting thanks for getting back. I've only tested it on linux and mac, so I'm not sure if that's related. 
I meant is there any benefit between that approach and going; `first, second = sequence_var[:2]` Destructuring is fantastic in many contexts, just hadn't seen it applied in this approach.
Awesome! Do you happen to have a github repo you could link me? 
Alright thanks, let me know when you do. RemindMe! One week
I will be messaging you on [**2017-11-21 12:30:46 UTC**](http://www.wolframalpha.com/input/?i=2017-11-21 12:30:46 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/7bddxy/whats_everyone_working_on_this_week/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/7bddxy/whats_everyone_working_on_this_week/]%0A%0ARemindMe! One week) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt; That's true here, and for some of the dunder attributes like __class__ and __mro__ It's true for most of them (e.g. iteration, comparison, …), and furthermore important as the "proper access" takes paths you did not expect (a common pitfall being that they generally access information on the instance's class not the instance itself). &gt; some of them don't have builtin accessors Hence "consider carefully" not "stop and desist" ;)
Idk https://www.youtube.com/watch?v=lydBPm2KRaU
It's private atm, tbh I feel bad about releasing it into the wild since I started this when I was a complete beginner and the codebase is a mess at some parts.
Not to belabor the point, but you cannot gain the wisdom to know when not to break the rules without actually breaking the rules. There's a fantastic [talk](https://www.youtube.com/watch?v=9UnMZYMaosw) about this from Jessica McKellar. She's done several iterations starting in 2014 (?), so that may not be the most recent.
Eh, once I get home I'll polish it a little and throw in some try/catch statements and then I'll make it public. I'll PM you once I'm done.
Thanks! I'm insterested to see what kind of hardware is needed to run it smoothly. I have a couple spare raspberry pi's I might test it on
Have been using these "double underscore" all these years yet this is the first time I see the word "dunder".
1. proper unpacking works with any iterable, slicing only works with, well, sliceable collections 2. Python 3's extended unpacking lets you pick bits at the end e.g. `first, second, *_, last = seq`, and of course you can name the intermediate seq if you want (`first, second, *mid, last`) 3. unlikely to have any effect but the builtin is a single µop (`UNPACK_EX`) versus 3 (`BUILD_SLICE; BINARY_SUBSCR; UNPACK_SEQUENCE`)
If this is senior I must be well beyond senior. But I don't feel it. Lots to go still.
Interesting. Thanks for your help! Will see if I can check that out sometime.
&gt;* Never use a list as a default argument (foo=[]) in functions. Never use a mutable as a default argument. 
It works pretty well on my RPi 3, and the whole plan is to make this a virtual bedside assistant so that I can be even lazier 
How do NONE of the top comments mention this? **WRITE UNIT TESTS!!!** import unittest Familiarize yourself with this, learn about unit testing and why it's important. When you realize that you cannot test big long functions with no clear direction, all of a sudden you'll find yourself writing *testable*, cleaner code, with each function having a clear purpose, entrypoint, and returns.
This is what I wanted to write. GIL just prevents python code from running parallel. All other code is fine. Especially where you have a lot of i/o like files read, http request etc GIL is not making it work worse. 
You need to do the animation yourself. That is, load each frame into a separate PhotoImage and change them on a timer.
[Hammer's Slammers](https://en.wikipedia.org/wiki/Hammer%27s_Slammers)
**Hammer's Slammers** Hammer's Slammers is a 1979 collection of military science fiction short stories by author David Drake. It follows the career of a future mercenary tank regiment called Hammer's Slammers, after their leader, Colonel Alois Hammer. This collection, and other novels and stories in the same setting, are collectively called the Hammer stories, and the setting is called the Slammers universe or the Hammerverse. Each of the stories in the novel follows various members of Hammer's Regiment in one campaign, starting with how and why the government of Friesland raised the outfit as an auxiliary regiment to put down a revolt on a Friesland colony planet named Melpomene, in which Colonel Hammer is the focal character, and who changes the outfit from a Friesland regiment to an independent mercenary organization. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
If you're going with json, I'd recommend using ujson instead. The built-in json library in python doesn't seem to play nicely with non-python json, and seems to carry over some pythonic pickle cruft that is non-obvious to strip out. Plus, ujson is lightyears faster.
Cool, thanks, I'll look into multiprocessing.
I was 100% with you until this comment. I think dicts with known keys should be avoided. Use a named tuple or something if you want a simple abstract data type. Using attributes is a lot nicer than littering string literals all over the place.
How do you debug in jupyter?
Yes! Listen to this guy.
* Do not create unnecessary lists. Most built-in functions accept generators as well. Do `all(item &gt; 0 for item in iterable)`, not `all([item ... ])` * Use virtualenv for every project (already has been said though). * If you faced extensive computations and/or nested looping on top of large lists/array, consider using numpy or numba. * **NEVER** do `from module import *`. * Study standard library. * pytest is your friend. * Use cProfile (or other profiler) regularly, optimize the bottlenecks. * Follow PEP8 (reasonably) * Do not use destructors, use `with` block instead * Create custom exceptions, NEVER use `except Expection`. * Name your functions and variable properly. Python doesn't have static typing (well, latest versions have type annotations, but they aren't popular yet), so verbose names is a good practice.
I'll take a look thanks!
This was my mistake trying to program a collision in pygame with massive lines of coordinate comparisons when the real solution was just one line long and built into pygame. 
That's exactly what you do. I know people don't like to hear this but comprehensions should be generally avoided. They look like shit beyond the simplest​ cases and the performance gain is minimal. Wtf is wrong with loops?
Amen brother that is true no mater what language your using 
Couldn't you acheive that with from typing import List def sum(*args: List[int]): pass ?
When making a change or addition to a project of non-trivial complexity, always take the time to set up a way to test your change with minimal effort. It's a tiny initial investment that will quickly pay off massively. I've wasted an insane amount time having to repeatedly manually create a state to test a particular change only to fall into the trap of thinking something like "I've spent hours doing this manually now so a systematic approach at this point is an even bigger waste of time".
Read this: https://docs.quantifiedcode.com/python-anti-patterns/
Can you give a reasonable explanation for why you would need an anonymous function?
The use of virtualenv and/or containers has nothing at all to do with web development. It's all about isolating your stuff. Both for security and compatibility purposes.
Sadly, Java devs are fanatics. Most of them don't even want to look at other languages or technologies.
I made a video, but it is in Russian. If there are some people who understand it you can check my lecture https://www.youtube.com/watch?v=N0xkFZv2Df0 
Adding to the comment chain just to say that due to the nature of my work I use pandas and pandas.read_csv a lot. I usually end up needing a pandas.DataFrame framework further down the line. However I'm in no ways an expert, so I would like to know if there's a better way (starting with csv and then loading up pandas?).
Jupyter will pick up pdb/ipdb breakpoints
Thank you
&gt; even with a cli, if I containerize it that could be a way for me to distribute my application. Set the entrypoint in the Dockerfile, upload to the hub. Unfortunately (?) you still have to think about explicitly sharing files from the host if your application is supposed to see them - but I think there's an argument that it's a good thing, safety-wise. Jessie Frazelle has a [Github repo](https://github.com/jessfraz/dockerfiles) full of examples of Docker setups for CLI and GUI (yes!) applications.
You are welcome! Ask me questions if you have on youtube. 
And why this library has to deal with requests? It should only care about text conversion, not getting the text from a remote source. 
*raises hand*. My monitor is 1440x900.
&gt; Of course not all problems are going to be solved by Numpy, but for some stuff that will give you the improvement you need without needing to change language. Yes, but sooner or later you'll need to write your own CPU-intensive code and it' so easy to waste cycles and memory doing it in pure Python.
What if I aim to be a wheel inventer? I am working on a linear programming code on Python that uses no libraries other than Sympy which I plan to ditch after midterms. I plan to turn it into a linear programming library with no dependencies on other libraries. And I know Scipy or other libraries already have what I aim to do. So what to do if my aim is to make my own wheel?
&gt; check it again. then check some of the major libraries Counterpoint: be careful what dependencies you pull in, and what's the integration cost. If the library is _truly_ major, then sure, go ahead, you probably even should do it. For a certain class of problems (crypto!) if you lack a library to do something, you probably shouldn't be doing it anyway. But don't pull a dependency maintained by one developer unless you're ready to take ownership of it should it get abandoned. And mind the integration costs. 
An important question is if you really need asynchronicity for a blog. In my opinion asyncio is definitely not the right tool. And keep in mind you'll have a small overhead on DB operations when doing the async.
Yaml isn’t really ubiquitous though. At least not nearly as much so as JSON. To respond to some of your other comments: the most compelling argument you’ve made against JSON is its weak typing. Personally, JSON is pretty human readable (maybe not quite as readable as yaml but not significantly so). Having to worry about 1 vs “1” though, is a nuisance.
I call it a pattern matching. This is something done oftently in in functional programming. The `swith` `case` statements are oftenly used in many language but, in python, there is no swith and you can do `if elif`, `dict matching`, `class inheritence`, ... The DRY principle apply on the knowlegde. So what is a knowledge ? A knowledge may be data or a higher level of algorith than the technique used to do a pattern matching such as an algorithm that validate a vat number and it is easy to fix, a function, a package, a microservice and you are done. And some time it is better to duplicate than add a coupling. The worst it the data. In case it is a data, the simple exemple is the usage of constants. ``` If you are doing. def print_color(color): colors = { 'red': '#FF0000', 'blue': '#FF0000', 'green': '#FF0000' } print(colors[color]) ``` You think you are not duplicate things, but in fact you start to hide 'red', 'blue' and 'green' naming convention in your code in a function. and you will find some `if color in ('red', 'blue')` soon another function. In that case, the color name is the knowledge. The easiest way to fix that is to add constant: ``` RED = 'red' BLUE = 'blue' GREEN = 'green' ``` Then you may rewrite that using classes and one class per color. I hope it helps to get the point 
You want to rewrite it and at the same time find a library for parsing. Write the parser too as it should be the hardest and the most important part.
I do it because I use Python for mathematical applications, try to use no libraries every time, even no 'math'. When does it become "reinventing the wheel" and stop being "learning to invent things"? I know half the stuff I am trying to code is already done by someone else who has it open even for commercial use. Am I wasting my time by trying to make Operations Research or Numerical Analysis codes with Python that use no libraries?
Thumbs up for Flask. Falcon is also a nice choice since its bare bones and it looks like it would fit well in your idea.
If you want to limit what's inside the try make the body of your with block a function call.
If you're already using a try block, you might as well close the file handle explicitly in a finally block, instead of using with.
&gt; If you follow the 80 character rule you can have two source code files open next to each other I don't know about you , but my single monitor is more than capable of displaying &gt; 160 characters worth of pixels in a row.
Or, y'know, catch up to 2014 and use python 3.
I've multiple tables with identical columns but one model. The only difference is the connection string and the product name. That information is set via mixin pattern. If I plug in the next product, all I 've to do is: DeltaOrdersModel = type("DeltaOrdersModel", (DeltaDbMixin, OrdersModel), {}) or if you want class DeltaOrdersModel(DeltaDbMixin, OrdersModel): pass In my eyes, that's not so WET. Well, I just thought about naming and now we ended up with design issues. 
Most of the loops I write are simple loops and it's much cleaner to use a list comprehension as you condense 3 lines of code into one line. Loops are better for more complex functionality though, I agree with that. 
&gt; Be a "systems engineer" Systems Engineering is a very, very wide field of work. In my experience having that on your resume just results in hits for writing requirements, writing messaging schemas, or developing system architecture - none of which would involve any coding.
I, too, underline this. Yes, the best neophytes invariably say, "I'll just split this CSV on commas", and then muddle for *months* before acquisition of the humility to realize that the standard module is the right solution. In the same category: parsing JSON, XML (HTML5, ...), or timestamps by hand. Take advantage of those who've traveled this path before, folks. Yes, your enthusiasm for what a couple of well-crafted regex-es can do is adorable, but believe us that it's misplaced for these domains. I write this while in the middle of committing a two-line update that applies `re` to an XML fragment. I know what I'm doing, though; do NOT take this as an excuse to write your own parser for these standard languages. E-mail addresses are another subject. I'll leave that aside for now. On the subject of good advice: I'm surprised no one has yet brought up SQLite in this thread.
&gt;* Use Python 3.6, there are some significant improvements over 2.7 - like enums and fstrings (I would switch to 3.6 *just* for fstrings, TBH) Until recently I've always made my personal projects cross-compatible, but in the last couple of repos I've just gone py3-only. Had enough of `six` and `__future__`, I just want to write clean, modern python. I can't wait for Django to got py3-only, hopefully the API changes aren't huge and my work will switch up to it.
"Learn Python the hard way 3" Seems very good so far, it's starts off VERY basic but i'm really enjoying the guys teaching style deliberately trying to make you independent while explaining everything clearly is a must for any study guide.
When I say "code smell", part of what I'm trying to express is that there's almost surely a better solution. Bad code is one thing; smelly code might not be overtly *wrong*--in fact, it can easily be in use for years--but its dissonances suggest that a different approach have the potential for radical improvement. Related illustration: part of the reason bare `except`-s are so hazardous is that they communicate poorly with the *human* reader. Someone writes a bare `except` meaning, "if the config file is missing", but a year later the source just says, `except`, and it's become impossible to tell what circumstances are supposed to bring us to that segment. Code smells might not be so much wrong, as less right than they can be. Remember Quintilian, *Quare non ut intellegere possit sed ne omnino possit non intellegere curandum* (which I always assumed was Tony Hoare's inspiration).
I used pylint integrated into VSCode and it hasn't felt noticably faster or slower than when I tried flake8. Maybe a YMMV sort of situation. I will say, while pylint does get excessively noisy over even the most inane PEP8 standards (sorry pep8, but you're wrong: "if len(myCollection) &gt; 0" reads far clearer than "if myCollection"...), it has helped catch a lot more than flake8 did, and I feel like my code is better because of it. 
As someone recreationally writing python, I suppose I should make the jump from 2.7 to 3.6. Learn now in case I want to make a day job out of it again. 
For simple cases comprehensions are fine but more lines is better than long lines.
If you are coding Python in your spare time, it's fine. Actually, I'd encourage it if what you want to do is understand how things work under the hood. However, if you are coding for a degree or coding professionally, then trying to use no libraries is almost always a waste of time. Take calculating the log of a number. It's very simple to just do `import math; math.log(1024, 2)` . Writing your own algorithm to do that is an utter waste of time when you should be spending your time writing code to tackle your main objective. The only exception to this is if your main objective to write a math calculation module.
I mean I'm well versed in functional and declarative paradigms (among others as well, my hobby projects lately are in Clojure) as well, and I'm well aware of when classes shouldn't be used. But to _never_ use them seems unreasonable/excessive, especially in such an object oriented language as Python. I.e. a lot of times, expressing things functionally is awkward at best in Python. It's fine at writing imperative/procedural code, but code written strictly in those paradigms often suffer from a total lack of abstraction.
For a lot of things, pandas is overkill. If you’re parsing each line of a csv and don’t need a picture of the data as a whole, use the csv module. 
That's what I'm saying... the comment said to stop writing classes, dogmatically. But there are plenty of situations in which classes/objects are the correct abstraction to use.
Another example of the subtlety of code smells: I assume we can all agree that `eval`, for instance, is a hazard. If a corpus of source has eleven different `eval`-s in it, I assume that the author has no taste and doesn't understand he's being difficult, not clever. If there is a single carefully-crafted `eval`, though, perhaps used by a dozen other clients, perhaps she has written something with insightful power. "Smell" isn't always about elements in isolation; it can be an aesthetic dissonance across a span of source.
If you look beyond python, phantomjs seems to be a good candidate too :)
Sure, I can agree to this. But you said: &gt; I can't imagine programming in Python without classes. That's completely different. 
Well yeah, to not use classes when objects aren't the correct abstraction is obvious. But never write classes? OOP is done correctly leads to more modular code... but it obviously isn't a panacea for all problems. OOP code can be written pretty naturally in Python, as can most other paradigms. To speak ill of one paradigm without explanation can be damaging to a new programmer. Better to describe the situations which OOP is well suited to (as well as when it shouldn't be used). 
&gt; multiprocessing, not threading Yes! While there are some things that work in threading you have to be super careful since the edge cases suck hard. Even stupid things like threads cannot be canceled should be a red flag for anything but the most trivial use-case. I will add some of my own * VALIDATE ASSUMPTIONS: I recently ran smack into a ["bug" \( unexpected behavior \)](https://gist.github.com/brontide/4e66dce718144005ceaddded679539fc) reported in 2009 against multiprocessing.Queue. I wrote a test program to validate the issue and then was able to work around it. * Don't nest, but do use comprehensions. They are a womderful additional to the language. * If you can't use with blocks or it's too messy remember this is Python just head over to contextlib and grab yourself an ExitStack for a complex function requiring a lot of context aware objects. * Speaking of contextlib you also have suppress. # rather than try: os.remove(filename) except IOError: pass # Use with suppress(IOError): os.remove(filename) # If we don't care about the file being gone already
That's a figurative statement. I.e. I feel most code would be made worse by trying to eliminate classes entirely. Yes I know you can write Python code without classes. But why one would do so dogmatically seems silly to me.
I need someone to talk me through this. I actually led the team that engineered an ancestor technology to `pipenv`. I'm fully aware of how wonderful virtual environments can be. I'm also skeptical of them. Example: I have a customer who has a bag of modestly-sized Python executables that all live on the same host (actually a score of such collections on a couple dozen different hosts, but I think that doesn't matter at the moment). I have **un**-virt-env-ed them in the last year, because I made an engineering decision that we were spending more time synchronizing our virt-env-s than installing host-wide libraries. I'm still a bit tender on the subject; I wonder whether there's some crucial aspect of `pipenv` that I'm missing. My tentative conclusion, though: as wonderful as virtual environments can be, there are a significant minority (?) of real-world situations where they are *not* part of the solution. I invite more detail from anyone who sees virt env-s as more universal than I do.
When working with asyncio, use ```aiohttp``` rather than ```requests```
One can, and one can always use `typing.NewType` for everything I'm about to say, but wouldn't you agree that well-named variables combined with well-defined types would work even better? Something along the lines of: from numbers import Number def sum(*numbers: Number): pass # TODO: stuff Now you know at a glance that the function is expecting a bunch of numbers, the type checker knows it's expecting each argument to `sum` to be a member of a `Number` type. Sometimes, though, you're asking for something more specific. def new_group(name, *args: str): pass # TODO: stuff What am I requesting in `args`? The docstring will surely tell you eventually and I may make a type to clarify, but certainly a step forward would be: def new_group(name, *usernames: str): pass # TODO: stuff Now you know that I'm looking for usernames, without me having to differentiate them with a UserName type.
I wasn't suggesting to do it dogmatically. I was suggesting that if you "can't imagine" not using classes, you should try it, because **that** is dogmatic.
I strongly favour Conda over any virtualenv type thing. It just works
I do 120 char limit with my IDE on a single screen and have two files side by side. It's not often that I need to immediately reference what's in the other file so I just have some key binds for jumping between them and resizing them in PyCharm. `ctrl+alt+page up/down` to jump between them and `ctrl+shift+page up/down` to resize them. Then the same but substitute `page up/down` with `home/end` for horizontal splits.
Let’s start you a GoFundMe, stat. 
Folks consistently find `pylint` heavy, slow, and noisy. I don't. While I'm not sure what that means, the practical significance is this: after doing due diligence on `pep8`, `pylint`, ..., and learning about others' experience, it's still worth fifteen minutes to experience `pylint` for yourself. You might find that it suits you better than research suggested.
Test early, test often. Use the unittest package to construct tests for your code. Run those tests often (automatic CI like travis or circleCI is great for this). Use something like nose or testflo to recursively run all tests in your package and report out coverage, so you can know which pieces of your code you haven't covered. As someone else mentioned, a linter is a good idea. Try to follow PEP8 as much as possible (I know a lot of people are lax on the 79 character limit but you can have the checkers ignore that.
Can someone explain the point about restructuring assignment? I don't know what this means...
In Python 2.7..... nevermind. It's 2017 now and Python 2.7 is irrelevant to me.
This. If you're tempted to make the default argument a mutable, make it None instead and handle it inside the function.
I guess it's because the thread is about senior programmers giving tips and tricks to junior programmers, and writing unit tests isn't a "tip" or a "trick", it's mandatory. If you are a professional junior programmer and you aren't writing unit tests, you are incompetent, end of story. With that said, there are two tips I would suggest with regards to unit tests: * Write unit tests regardless of what you are doing. Unit tests are mandatory in a professional setting, but even if you are writing the simplest of pet projects you should write them. Unit tests and test-driven development are extremely useful if you want to code something but you are unsure how to start. Starting off with a basic test that captures what you want to achieve will often help point you in the right direction. * Use `pytest` instead of `unittest`. Pytest is just so much nicer IMO. There are many benefits, but my fave is that there is so much less boilerplate code involved. It makes it much nicer to write tests when all you need is a top-level function rather than having to write out a class.
You probably want to search "web acceptance testing python". I've used Selenium and its in use for various projects, with support for various languages. While you probably don't need the testing frameworks, they all have browser automation as a common feature. You may be able to simply use the automation features.
It's insecure (a pickle can execute arbitrary code on your computer) It's [big and slow](http://www.benfrederickson.com/images/python-serialization/size.png)
True, but perfect code is just as often useless... gotta take what you can get :) That said, there are much better codebases than Django. I just run into so many Django projects in the wild (I work for a cosultancy) that it makes not working with objects/classes kind of impossible.
Yaml is just json with extra wingdings like comments. There's nothing yaml can do that json can't. 
If you're not sending it over a network ever, then it's probably fine. 
You are not wrong. But when I wrote this library, I had to use it for both cases, read a file and convert directly accessing an URL hence it has methods for that. If you don't want to do either a method to convert directly from JSON text is there too.
Learn what the GIL is, and learn to love it! Most people talk about the GIL in a derogatory way, but it removes entire classes of errors for the sake of flexibility. In the web world, we are usually IO bound. Using green threads we're able to do a massive amount of IO asynchronously with little cost, and very simply because of the guarantees the GIL gives us. For times when you need parallel computation, you can use multiprocessing. If you really REALLY need more parallel computation, then that it's usually for performance reasons, in which case Python might not be the best choice anyway. I just wrote a script that could download, parse, and process 3000 largish (tens to hundreds of MBs) files a minute from AWS S3 just running the script on my laptop using multiprocessing and eventlet. That's pretty powerful for an interpreted scripting language IMO. The code is also easily readable as I don't have to worry about race conditions everywhere.
Share some of your well-beyond-senior wisdom with us?
If you are coding somewhere where you don't have significant constraints on memory and CPU, or the code you write is not significantly time-sensitive, then using Python is just fine. It's important to remember that, what you lose in pure performance from using Python, you gain in "developer time". Developers can write a solution in Python much faster than they could in C, and with developers being an expensive resource, this metric is something that many companies care very deeply about.
&gt; long_string = "YOU don't know about me without you have read a book by the name " &gt; "of The Adventures of Tom Sawyer; but that ain't no matter. That book was " &gt; "made by Mr. Mark Twain, and he told the truth, mainly. There was things " &gt; "which he stretched, but mainly he told the truth. That is nothing. I " &gt; "never seen anybody but lied one time or another, without it was Aunt " &gt; "Polly, or the widow, or maybe Mary. Aunt Polly - Tom's Aunt Polly, " &gt; "she is - and Mary, and the Widow Douglas is all told about in that " &gt; "book, which is mostly a true book, with some stretchers, as I said " &gt; "before." Whoops. Yes. I totally indended to do that!
Thanks man, I'll look into it! 
&gt; - ~~know https://docs.python.org/2/library/stdtypes.html~~ - use Python 3 - know https://docs.python.org/3.6/library/stdtypes.html FTFY
Definitely the former.
Aww wow thank you so much for that little help! That massively improved things for me! I like the ".format()" version other the + version! Only problem I am last having is, I cannot get that old age thing to work and also do the sum! You wouldnt mind just further explaining a little would you please? This is what i have so far! https://pastebin.com/dvdqjq7M
I think a lot depends on how you use your linter. I like to run my linter asynchronously and fix problems as soon as they happen. `flake8` works great for that. `pylint` often takes 1-3 seconds to fully process my changes, which means that it starts complaining about my errors after I've already moved on to the next line of code. Jumping back a line to handle linting fixes every time there's an issue is annoying. If instead I liked to write a chunk of code, run my linter, and go back and fix any issues, I think the speed of `pylint` would be just fine.
This video go into detail when to not uses classes and shows some good examples of bad use of classes. Also it's not to technical or long. https://youtu.be/o9pEzgHorH0 
FYI, selenium automates actual browsers. If it has to launch Firefox or Chrome each time, it is slow. I believe you can use something called Shadow Browser, which is a headless browser and much faster. 
I'm not working on any Python this week, I have 10 days annual leave to enjoy off from my Python job :) 
breaks your heart
&gt; Use the unittest package to construct tests for your code. Actually I'd recommend pytest over unittest, unless the person is constrained to only use certain libraries.
The Zen of Python: Focus on simplicity, elegance and expliteness.
Well said. Thank you.
So try except allows your code to fail in an expected way. Putting something in a try is like saying "hey this could break but I know what I'm doing", ValueError is a specific error thrown by Python when the value being used isn't valid for what you are doing. Converting from a string to an int can throw that specific error if you had something like int('2a') as an example. So the point of: try: old_age = int(old_age) except ValueError: # error handling code here Is to allow for your code not to break if they make a mistake when they input. The way I would do your problem is to put it in a loop, and if they mess up their input to go back to the previous bit, if their input is valid break out of the loop and then handle the rest of the code. I think your level is quite low so I guess the way you have it is fine for what you want I just look at it as semi-incomplete. 
True, still you should know the PEP8 basics. Any of course the other hint is: Watch Raymond Hettinger and Dave Beazly talks on youtube!
From a data science prospective... 1) Research MUST BE reproducible at any point. 2) Don't complicate your code by going out of your way to vectorize something that would be instant in base Python 3) Don't give up on vectorizing an expensive task because you know know vector operations very well. 4) You should be able to show that any given bit of code works with no or little of context/assumptions. This doesn't mean go overboard on tests. An acceptable "proof" could simply be a concise explanation or common sense. If it wake more than a breath or two to explain a line of code it's likely too complicated and needs to be separated into smaller tasks. 5) Not Python related but... Get something working that shows progress ASAP. Might be a web app showing predictions or automated building of a presentation. Make this easy and fast to update and do so often.
Wow that's super not true. I mean, that statement lacks any familiarity with the subject matter.
You are the 1%
I should have clarified. Use whatever you want to run the tests, but in my experience the tests seem to be defined as unittest.TestCase subclasses. [https://docs.pytest.org/en/latest/unittest.html](https://docs.pytest.org/en/latest/unittest.html)
I use pytest mostly because I don't want to use unittest nomenclature to write my tests. Writing tests in the pytest style is often more Pythonic. You are not forced to write classes for tests (you can just use top-level functions) and you use the built-in `assert` keyword rather than `self.assertEquals`.
- Read the Zen of Python (PEP-20) - If you think your code is super clever using magic methods, you should probably stop, go back, and reread PEP-20 - Learn, I mean really learn the logging module. logging.basicConfig is your friend. 
*Eyes twitching*
Just about the only Python feature that I've never used.
If you find code that has DerivedClass = type("DerivedClass", (BaseClass1, BaseClass2), {}) Burn it with cleansing fire.
I don't necessarily disagree, but don't Python 3 best practices discourage the use of map, filter, and the like?
There are things of pep8 to reconsider, but the ~around 80 char limit is not one of them. First, many of use use vertical monitors. Secondly, having multiple files in view at once is very common, and with 120 lines you're almost certainly wasting tons of space.
For best effects, don't be a "Python Programmer". As soon as you are comfortable with the language, get another one to learn, and then another, and another.
The biggest efficiency gain in my team comes from reusing code heavily. We adhere to this principle as much as possible. Unless we are dealing with something very domain specific, someone somewhere has had the same problem.
&gt;But if I'm putting a log message in a block that is 12 characters indented (not a totally uncommon concept) No! If that's common to you, you need to rewrite your code. 12 is an insane amount of indentation.
That sounds like it would be a very very bad idea to do this. But why?
Ale is asynchronous.
&gt; I think your level is quite low so I guess the way you have it is fine for what you want I just look at it as semi-incomplete. This is exactly what I was thinking. I am trying to learn it the correct way, but I literally wrote this from scratch... So I have no clue about the "correct" way that professional people would write it. If you dont mind, and I would thank you massively for this... Would you please be able to re-write my little code the way YOU would do it... And I can compare it to mine. I find this way such an easier way to learn.
I really like functional programming, but... no. That's absolutely terrible, and MUCH worse than a list comprehension. Python's syntax just doesn't go well with some functional concepts. Stick with writing code that fits python's syntax: python is not great for writing DSL:s that needs with a different syntax than Python's own.
Let's find you something from the e-waste bin. I brought one of my 1680x1050 22" widescreens from home until my company provided me a high-density 19" 4:3 as my second display. If my employer didn't provide a second monitor and refused after asking, I'd buy one with my own money. The productivity difference will pay for itself the next time there are performance evaluations.
ew... No, dicts are way worse than using classes.
There is a module for parsing parts of email addresses already.
But surely you can dock that laptop to at least one external monitor when you're in the office, right?
No, because if you have to catch multiple exceptions, now you have to add `file.close()` to every single one. Just let `with` statements work for you. After all, why are you using Python if you aren’t using its features?
What's being chained here?
Actually me doing it for you would be way worse because you wouldn't go research the stuff for yourself. The basic stuff I said is enough really to get started. Go read up about while loops https://www.tutorialspoint.com/python/python_while_loop.htm and about try, except here https://docs.python.org/3/tutorial/errors.html The basic layout of the solution is: Ask them their name &gt; input &gt; go into a while loop &gt; ask them their age &gt; validate their input, if their input is wrong keep the loop going, otherwise break &gt; then work out how many years till they hit 100 (I wouldn't even ask the question. The entire wording you added on is pretty boring mostly
Thankfully I mostly intended this for students with a year or so of programming under their belt.
Or they'll jump right into Pandas to parse the CSV.
Yes. Have a look at: https://github.com/kashifrazzaqui/json-streamer Now your approach is JSON -&gt; dict -&gt; XML. If you use SAX "events", then you could JSON -&gt; XML directly. Then your project would be useful.
That's a generalization to say in the least.
How were you syncing virtenvs?
well I am in between, I use pandas for that. Never thought about the csv module. But maybe putting a requirement on pandas for every little project is not really that much better than writing my own csv parsers which just kinda works for the use case of that project alone.
I have two external monitors in the office. One where I have an editor open, usually with two scripts side by side. Probably 120 chars should be readable side by side. However, if I'm at home or at a conference, I only have my laptop and I wouldn't be able to view two files side by side if there's 120 chars per line. I prefer 80 chars and just use line continuation either implied with brackets or using a \\ if necessary. 
What's that pattern called again? Execute-around?
Yes, this is why I do 120 characters. If you use descriptive variable names your code becomes unreadable due to all the carriage returns with 80 characters. 
Stop writing clever code. Prove your cleverness by writing clean simple code. 
UNIT TESTS. READ COVERAGE REPORTS. Nothing else really matters.
&gt;Am I wasting my time If you are trying to accomplish something, which just happens to use a library, yes. If you are trying to learn how to make a library, or learn how something works, no. For example: I wrote (read: tried to write) my own Vector library compatible with n-dimensional vectors. Has it been done before? Yes. But i used it as an opportunity to learn how vectors worked in the first place. Did i ever use my own library for anything? No, not outside of testing it; that's where you use something that has been tried and tested by hundreds of people before you. Another reason to reinvent the wheel is to improve upon it. Maybe you don't like the structure of some library, find it cumbersome to use, or it doesn't quite meet your requirements. I would say that reinventing some of the wheel here is fair.
Pandas is complete overkill for parsing CSV. The Python CSV module is right there in the standard library. Just use it. 
Good list! Don’t forget to use test-driven development and check code coverage on tests. Pytest and responses make quality of life much better for testing.
I believe the [Zen of Python](https://www.python.org/dev/peps/pep-0020/) speaks to your question. I picked out the lines that I think the "non-pythonic" behavior violates: - Simple is better than complex. I can look at the first example and very quickly grok what you're doing. The second example requires thinking about what the type function is doing, what your arguments are, and what your intent is. - Explicit is better than implicit. In the first. there's no function call and compile time creation of classes. That's an explicit class definition. The compile time creation of the class is far less explicit. For example, I am wondering what the empty dict is for in the third argument to type. I'm going to go look in the docs, but the fact that I have to is part of the issue. A step further is the use of type() in this way seems magical. My gut instinct is that type() would return str, but you're overriding with what is in the second argument, and what's the third argument for again? - Readability counts. #1 is far more readable than #2. It's concise and clear and doesn't require knowledge about the function signature for type. - There should be one-- and preferably only one --obvious way to do it. In [Unifying types and classes in Python 2.2](https://www.python.org/download/releases/2.2.3/descrintro/) the usage of type for class creation is a single line with a note on metaclass programming. All the examples of class construction are explicit. BTW after seeing this, i see that type/1 and type/3 are really two different methods with two different purposes. Really bad decisions were made there IMO. - If the implementation is hard to explain, it's a bad idea. - If the implementation is easy to explain, it may be a good idea. These two go together. Which is easier for you to explain? Just the fact that the third param of type/3 is a dict of methods (eyeroll) makes the second something that makes it harder to explain than the first. Oh and one stupid thing: class DerivedClass(BaseClass1, BaseClass2): """This is a Foo for the purposes of bar""" The docstring can take the place of ``pass``.
&gt; as a Vim user I say you're crazy if you're not using Pycharm with Ideavim OMG, thank you! Any more great plugins?
awesome...
Well I'll say the main reason I was worried about this form is catching OSError unintentionally from some part of code in the _with_ block. Do I actually know all the functions other than _open_ that could raise OSError? Nope😅 So I guess it's just for peace of mind, the way I originally wrote it. Because if an OSError somehow gets raised in the with block then, I'll uhh, know it wasn't from the try block? Anyway thanks.
If you are already using pandas in your code then I agree wholeheartedly (and do so myself). But if you just need to run through a csv file and extract some info then the `csv` module is still worlds better than trying to parse each line yourself (as the OP was making the distinction between).
I always approve of a more data-driven approach. But you may be able to make use of [PyFilesystem](https://docs.pyfilesystem.org) Here's an example: from fs.mountfs import MountFS assets = MountFS() assets.mount('data', f'./data/{version}') assets.mount('raw', 'f./raw/') with assets.open('data/something.html') as fp: process(fp) Bonus points for backing up to a ftp site: assets.mount('upload', 'ftp://ftp.example.org') assets.copy('raw/something.html', 'upload/something.html') Or writing a zip file: from fs.copy import copy_fs with fs.open_fs('zip://backup.zip') as zip_fs: with assets.opendir('data') as data_fs: copy_fs(data_fs, zip_fs) 
just to clarify, I'm already using anaconda for separate environments, should I bother?
The rule I don’t like is never using a single line `if` statement. I just want to use `if stop_condition: break` without any red squiggles under it!
I’ve had a ton of issues with python on windows, not just with installation but even with bugs with functions in widely used libraries (like scipy). That site has saved me a few times.
pycharm auto-does it for me it yells at me about pep8 a lot, less now though
Bare exceptions are generally a bad idea. Other people have summarized why better than I can: - https://realpython.com/blog/python/the-most-diabolical-python-antipattern/ - http://moserei.de/2017/09/20/python-bare-except.html I like this simple summary from https://jeffknupp.com/blog/2013/02/06/write-cleaner-python-use-exceptions/ | Never use a "bare" except: clause or you'll end up suppressing real errors you didn't intend to catch.
There should be an `except` block to go along with the `with` statement. Is there a PEP for that?
This reply is a shameless plug [Queries](http://queries.readthedocs.io) as a wrapper for psycopg2.
It's the usage of the classes where I'd be concerned about the WETness, not the definition. Given the use case it seems highly likely that all the places you need to use DeltaOrdersModel you'll need to use Alpha and Beta too. I'm not 100% sure of this, of course, and this could be entirely the right approach for your use case but I'd still consider it a code smell.
For every new feature of the language you learn, learn when not to use it. Set a high bar for when you use anything you wouldn't have learned in a one-day python course. For instance: - comprehensions of any type - *args and **kwargs - multiple assignment / unboxing tuples - generators - any double-under method - non-core modules - lesser-known core modules - functional manipulation - decorators - metaclasses That said, when it's the right time to use something it makes the code cleaner, easier to read, and easier to maintain. Knowing when to used that non-simple part of the language is one of the defining skills of a good python dev. 
Efficient in terms of time/speed, or efficient in terms of digesting and understanding the language? What is your background like? How much time do you have to devote? There are plenty of resources, namely /r/learnpython ! As you would any other *language*. Start with syntax to get your bearings. Then move on to stringing the syntax together, and then building small functions. Then find a project or an idea you'd want to codify. Baby steps.
Thanks for this great explanation! 
Yeah. Only CPU intensive stuff is affected
Definitely, but even then, it's worth understanding the consequences of what the decorators are doing, especially when you chain them. I made the mistake once of building a pipeline out of decorators. It's neat, just drop a stack of them ontop of a method or function and boom, done, marshaling handled, serialization handled, errors handled. But it's such a damn eyesore that I try to ignore that module because it'll be such a pain to fix. Individually, the decorators are fine and reusable, it's just the pipeline of them.
This is pretty neat, although there are a few gotchas: 1. Users installing sdists (i.e. `python setup.py install` or `pip install --no-wheel`) would need to have setuptools &gt;= 30.3.0. However, using wheels is fine, since their installation does not depend on setuptools. 2. Even if all metadata is in `setup.cfg`, a `setup.py` with a call to `setuptools.setup()` is still needed. I like this a lot, so I made a script that converts `setup.py` to `setup.cfg`: https://github.com/gvalkov/setuptools-py2cfg
I was unclear, sorry. I meant pure python. Obviously 🐍 ‘s ability to use c extensions is a great feature, because it enables high performance for crunching numbers and such. I would suggest that the reason qt it fast is in part because it’s written in C++. 
Ah. Yea I see your point. It seems a bit iffy to me that the contents of a “with open...” block isn’t pure though :P
I'd say more that use of lambda is discouraged. If you've already got a function to do what you need, using map is more clearer than a comprehension. You don't need to scan through `map(foo, bars)` like you do in `(foo(bar) for bar in bars)` to see the intent. However, `map(lambda bar: bar * 2, bars)` is certainly unpythonic over a comprehension. Honestly, I think this is due to the design of the language. It's not a bad thing, but compare this to Kotlin which would use `bars.map { it * 2 }`, which is idiomatic in that language. Lambdas do have their place in python though, like in `sorted(points, key=lambda p: p.x)`.
Quite right!
Great, thanks for the tip. Will look into it.
Ooh, nice, thanks for clearing it up! I'm sure I'll find use for it.
Funny how S3 is named in the middle without a comment but lots of time is spent talking about how github and pypi can be a problem if I get are unavailable. I personally wouldn’t send my artifacts over the internet and then download them back ^_- A question: do all developers use Debian on their desktops? 
Write tests instead of using a REPL. It takes some discipline to stop doing it but it's worth it. Why? Well think of some common use cases of a REPL. * You may be developing code fragments that will go into some larger function/method you are developing. * You may be learning about some API functions. * You are developing regular expressions. These things can be done in tests. So just write tests and capture all of this transient validation work you are doing. If you develop this stuff in a REPL then you are essentially writing tests, but throwing them away. Just treat your test like it is the REPL. Write the test case and put your first guess at how to do the thing you want to do. Run the test and watch it fail (probably). Go fix your function or your test code. Try again, watch it fail again. Repeat until it passes. Now you've taken your REPL workflow and turned it into a form of test driven development. I will write and keep tests that don't even exercise our own code base, just to clarify how to do something specific with some third party API. These kinds of tests are relevant to our code base even though it doesn't exercise our code, it exercises our *assumptions* about third party code. In some ways that can be more relevant than testing your code. It will also let you test your assumptions are still valid if you update to a new version of the API. If you really think these tests are a waste of space and will never ever fail in the life span of your product then you can delete them or mark them to skip. Also to make your life easier, get py.test. It eliminates boilerplate for most simple tests. And it can still run all of your unittest tests. 
This looks great - thanks for sharing!
To clarify why it may not be a good idea to force a particular minimum version of setuptools downstream, consider that the python packaging build rules in many distributions are built around sdists and the individual `setuptools`/`distutils` commands (e.g. [fedora](http://pkgs.fedoraproject.org/cgit/rpms/python-rpm-macros.git/tree/macros.python#n22), [freebsd](https://github.com/freebsd/freebsd-ports/blob/master/Mk/Uses/python.mk#L635)). 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [freebsd/freebsd-ports/.../**python.mk#L635** (master → 463fde2)](https://github.com/freebsd/freebsd-ports/blob/463fde2c20803fbb6a544f7ff851b00f561dedcf/Mk/Uses/python.mk#L635) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
80 is restrictive especially when writing class member functions. I find 100 char line width with a 4 char indentation works nicely.
Understanding interactive application is useful, but building it with Python is not, because very few commercial applications have UI built in Python. I learned UI programming with Win32, and with that knowledge I found it easy to understand basically any type of UI interaction.
Someone below already pointed out closures can sometimes be used instead of classes, and much more neatly. Also, generators can often be used to replace a class with a simpler function.
How in the hell is `__build_class__` used? I understand everything about python except for building extension modules in anything other than Cython and I've spent hours on the Internet and trying brute force in order to get that thing to work. So can you tell me how to use it?
No problem. Thanks for your message.
That's why I asked about your goal. If you just need to build something for a thesis, then it's ok. I wanted to point out that if you are planning to find a software job, then it's better to learn a more popular UI framework.
Super noob here. As i understand it, the with block will remove the need to put a .close argument?
It's idiotic to use multiprocessing with io bound tasks. Python releases the GIL naturally for io and there is massive overhead with serialization in mp while there is none for threading. But yes, for anything else threading is shit. 
Is there a tutorial anywhere on virtualenv that you'd recommend? I've messed with it, but every time I compile I get a mess of errors; which I assume is because I'm installing packages at a system-level :(
&gt; .open() or .close() is often a code smell - you probably should be using a with block doesn't "with" simply do that for you? i choose not to use "with" because i don't like the extra level of nesting it adds. petty but still.
It's a nice idea, but I think it's an example of high level programming that feels like low level programming. Also it just segfaults on OSX sometimes
&gt; defaultdict oh that one is really good. i didn't know .get() could do a default value. i might have to take advantage of that. &gt; suppress guilty as fuck. i will have to use that. but how would i use it in the context of doing a pass on only certain exceptions?
Agreed, f strings were enough for me to switch to 3.6
If you use the `finally` statement (https://docs.python.org/3/reference/compound_stmts.html#finally) you only need to put `file.close()` there. It's intended as a clean-up section, and will be run whatever, even if an uncaught exception is raised.
Avoid recursion...at least in 2.x
Is using their API out of the question?
Well I think that depends. I recently did a project using Twitch's API and I imagine web scraping is a different skillset right? I tried the Wikipedia Python library and that got me the exact result I wanted in 3 lines of code but I feel like I didn't learn anything which is my goal.
Why do people mess with anything besides just creating a virtual environment in PyCharm? Do most people just not use PyCharm? Also what is the difference between creating a separate local interpreter for each project and creating a virtual environment for each project?
Are you doing it to learn and grow personally? Great, good luck, that's a perfectly reasonable thing to do. But if you are doing it to try to make a productive contribution to the community, you should ask yourself a few questions like: * What am I doing differently than those other libraries and why is that valuable to someone? * Is there a realistic reason people would actually want no dependencies? * Would a better contribution be taking over an unmaintained library or filling an actual gap in capabilities? If you want to be an inventor, you can't be a wheel re-inventor. You have to make something *new* or take something a new direction that nobody's done before. You can *start out* by being a re-inventor, but that's not going to make you an inventor on its own. Re-invention is only good as a learning exercise. Eventually, you'll have to actually *invent*, and the wheel is a pretty well-explored subject it's not clear there's much untrodden ground to find there.
Well, in this case it would save you a redundant temp variable (`f`).
Learn your development environment! Really learn it. If you like Vim, great, learn more then just H, J, K, L... If you like your IDE, great! Lean the debugger, learn how to look up function definitions, and more! Linting, debugging, and others are my defining factors for a hobbiest, and a pro. 
Just signed up, thanks!
Unpopular opinion: CPU intensive stuff should be rewritten in C++, and loaded with ctypes.
More general programming advice than Python-specific. Stream of consciousness incoming. * Eliminate failure conditions early if you can. Rather than testing if some condition holds and then proceeding, invert the logic and explicitly fail on invalid preconditions. * Corollary: early return when you can. It saves indentation and improves comprehension. _If a necessary condition does not hold, bail out now._ * Don't use exceptions as a flow control tool. Treat exceptions as truly _exceptional_. For example, if you're trying to open some file and it's entirely acceptable for that file to not exist, don't just open it and trap the exception, check to see if it exists first and proceed accordingly. * Ignore the last rule for exceptional (heh) circumstances. Notable cases include some file operations and Django's notorious `Http404`. The alternative is writing a lot of gross and unnecessary failure-prone logic. * Be judicious in choosing libraries. Go look at the source code. Learn a little about the maintainers and contributors. If the last commit was made by a neanderthal three years ago, you don't want that liability in your application. By the same token, if you see a library getting 20 commits per day, take care to make sure stable releases are _actually_ stable. * Take care to choose libraries that solving meaningful problems. Don't fall into the _left pad_ trap. On the other extreme, don't write your own implementation to solve a complex problem if there's a well-maintained existing solution. Everyone who has ever written their own process pool comes to mind. * Write tests but don't waste effort covering everything. Test to ensure you preserve stable functionality across changes. Don't get wrapped up in testing every single line of boilerplate, especially if it rarely changes and you can spot check it before you commit. Tests for the sake of having tests convey a lot of _data_ but not necessarily meaningful _information_. * Get comfortable with `setuptools` and learn how packaging works. Yes, it's a little quirky. No, it's not difficult. Don't use some obnoxious tool like `pbr` because packaging is "hard"--it isn't and everyone will hate you. * Following from that... use `pkg_resources` liberally if you need to ship resources with your tool/application/library. You cannot make _any_ assumptions about the environment into which your package will be installed, so don't just lazily sling files around.
my go to when I use my old-ish laptop with mint KDE. Feature-rich + lightweight(relatively) = :)
&gt; multiprocessing, not threading I do this, specifically TheadPool because of how freakin easy it is to use, but I can't ever find any good documentation/writeups/explanations for new coders to get them using it. You don't happen to have any good resources for it, do you? 
&gt; because I made an engineering decision that we were spending more time synchronizing our virt-env-s than installing host-wide libraries. I've found that having a local fileserver with a directory of built wheels helps out *immensely* with this. Don't have to worry about: 1. Having each new machine have full compilation capabilities 2. Upstream devs pushing a breaking change with or without a version bump (if you've pinned to a version) 3. Loss of internet connection (can still run on local network) 4. Speed. 
Oh wow I didn't realise that. Sounds great!
Would love to finish one of 'my' project this week by reusing someones code.. and add interface to it using flask or something like that. The code it self is for providing you best optimal FantasyFootball lineup utilizing some prediction scores. While the code works fine and spits out the info print (lineup) .. I would like to get it to work with placing that on page. So far I got to the point where I was able to spit out the print part.. but now I want to make it cute and shiny. 
&gt;No, because if you have to catch multiple exceptions, now you have to add `file.close()` to every single one. Uh, that's precisely what `finally` is for - it executes no matter what (even in the case of handled and unhandled exceptions).
Have you done your research online ? or tried maybe posting this same question in the right subreddit like /r/MachineLearning/ ?
A call to close() yes. It will handle it correctly for exceptions too. 
Thanks I’ll post it in the right subreddit
Threads in C++ = pkill -9 me
Or, repeat yourself maybe 2 or 3 times before thinking about abstractions. Lest your abstractions don't hold up later because you thought you could generalize without having enough information. 
I think this applies to any language but it stands out in Python because of its lovely terseness: * don't write more code than you have to (you'll need to read it later) * don't wrap things that don't need wrapping (this isn't Java!) * don't add flexibility you *might* want it the future (you won't use it) * don't optimize for performance problems you don't have yet (you probably won't have them) Keep it simple, keep it beautiful. 
While I haven't been using python much lately (and don't really count as senior), I've really enjoyed using docker for isolation over virtualenv or the equivalent in other languages. It also helps with thinking in terms of services and I've been making some really nicely decoupled projects with the addition of kubernetes to my workflow. It's been really good for working in teams and growing projects as well and I've found it's been well worth the learning curve. A good example recently was a wrapper around the github API we had to do. I have one pod that deals with the webhooks and another that is the actual interface to our API. Normally I would have just had it bundled in one app, but I've found having them pulled apart like to that to be a big plus for our productivity, since once you get passed the initial mental block, there isn't really a lot of added work and it makes it easier to reason about. Just my opinion though, probably a fairly divisive issue.
Not specific to Python: * Get a proof of concept going and put it into your customer/employer's hands as soon as possible so that they can take ownership and give you real feedback. The customers who don't understand this is just a working draft are either a sign that you need to work on your personal communication skills or are idiots. Either case needs to be fixed ASAP. * Don't optimize without a way to test for improvement/regression. * On that note, use unit-testing when you can. At 0200 when shit breaks, unit-tests increase the odds that you will be able to go back to sleep at 0300. * For high performance systems, I personnally recommend deploying early in the morning. You don't want it to be 5pm on a friday night when a deployment fails and you're explaining to your family and friends you can't go home. Most of the non-tech people will go home which leaves you alone with management breathing down your neck. * If you use an ORM or Domain Model library, learn [Big-O](https://rob-bell.net/2009/06/a-beginners-guide-to-big-o-notation/) and what [cardinality](https://en.wikipedia.org/wiki/Cardinality) means to you. * You CANNOT make a computer run faster (reliably) so aim for your code to do less. If you're building these massive structures in your code only to throw them away in a loop, things have gone wrong. * If you are drinking more than one 8oz caffeinated soda a day, (eg Mountain Dew), that's ~40 grams of sugar a day. 10 cans of Mountain Dew is almost a pound of sugar, per day, everyday. If you don't fall over dead from Diabetes, something else will break. On that note: modafinil, adderall, ritalin are band aids for having poor health and or poor work:life balance. Some of those will increase your chances of developing a serious mental health disorder (psychosis is the big one). Python specific: ========== * Virtualenv isn't just a nice to have, use `pip freeze &gt; requirements.txt` and check that in alongside your code to ensure others can replicate not just your code but also the environment. * Double and triple check the name of the package on pypi you intend to use and what you type on `pip install myPackage` https://www.bleepingcomputer.com/news/security/ten-malicious-libraries-found-on-pypi-python-package-index/ * Django is pretty awesome for making web apps, but don't learn to program just Django, learn Python. The Rails wave was embarrassing in a lot of ways because of how many people knew Ruby on Rails but not so much Ruby. https://www.python.org/dev/peps/pep-0333/ * Read PEP8 and use the pep8 checker, learn how to bury the bodies if one of your coworkers insists on tabs vs spaces. * Optional but something I recommend using are tools like: https://www.pylint.org/ https://coverage.readthedocs.io/en/coverage-4.4.2/ https://docs.pytest.org/en/latest/ with an IDE that can automatically run them in the background. You're not aiming for 100% coverage or 100% no lint warnings but the ability to have control over your own code. * Python 2 is practically dead, it is inevitable as a junior programmer you will be stuck working on them, but generally all new projects should start with Python 3.
Derp. You are correct. However, I think my point about using the features of Python still stands. And using a try/finally block to open and properly close a file is probably more lines of code than a `with` statement.
I replied to the comment below yours: https://www.reddit.com/r/Python/comments/7cs8dq/comment/dptf6cj
I haven't taken a close look at this library. Note that while scikit-video has been recently updated, it is less mature in terms of Github stars/contributors/commits compared to moviepy: https://github.com/Zulko/moviepy I thought maybe the "scikit" label meant something, either in terms of API, conventions, or quality, but maybe not? Anyway, thought others might be interested! 
he was asking senior python programmers, not Newfangled Nelsons!
Yeah I’d scrape a website that doesn’t have an API, seems more useful. Definitely use BeautifulSoup4. There’s tons of documentation on it. It makes parsing a web page super easy. 
Additionally, even if yaml only added comments, that would be a legit reason to use yaml over json for some purposes.
Eventually, you may want to deploy your script/program as an exe, Have fun with it when it carries 200+ MB of numpy, pandas... when you could have csv parsing for just kilobytes. I mean, if you already need pandas, by all means, but including pandas as dependency because you want to load a csv is... too much. 
Sounds like you just need a wider monitor 😋
The 80 character rule is not about display widths, it is about readability. There have been tons of research about the ideal column width for human readability and it is around 50-70 characters. With indention that fits nicely with the old 80 character terminal limit. 
pip install ipdb and: from ipdb import set_trace; set_trace() from IPython import embed; embed() ^ have these snippets on shortcut in editor and learn how to use it. Best thing ever to prototype new method for example. You use it like: def my_new_method(self): from IPython import embed; embed() then you just prototype body as you go and copy what you worked out to editor.
I had no idea they existed... I just looked them up and damn they're nice.
For something really simple, I would personally use the built-in `tkinter` framework.
izpo I have a a few solutions to your problem...: * Install the vendors/modules as a folder part of the project, so rollback is easy :) * If there is an error in the connection or something to GH or Pip the deployment will fail, so what is the issue? * If you don't specify the right version of the package is the developer fault, this is not a pip or GH issue. * I use docker for everything except serverless, no issues to deploy, to test, etc.. and I think you should update your kernel before reach the end of life... (or that already happen?) * Using a deb package maybe is a bit overkill? my artifacts I think they are tar.gz in S3 and there is no problem for export that artifact.
Why do you prefix your project name with scikit? I think that scikit is short for science kit
&gt; Use Python 3.6, there are some significant improvements over 2.7 - like enums and fstrings (I would switch to 3.6 just for fstrings, TBH) And ordered dicts by default.
This is a great idea for a thread, thanks for posting.
Well virtualenv doesn't deal at all with dependencies on shared libraries on the host, so I would really hesitate to blame you. Some have moved to statically compiled wheels.
Yeah. There's a large overhead when using multiprocessing in both process creation (less significant if using a multiprocessing pool) and data communication (every variable passed to and from the process is pickled then un-pickled.) Threading or async (in 3) are great when you're mostly waiting on I/O (disk, networking, database...) since the GIL will release on every I/O operation. Multiprocessing is great when used on cpu-bound tasks.
&gt; Also don't use CSVs if you can avoid it, clients will open them in Excel and generate absolute garbage out. Produce and consume Excel or ODF files instead if you can That may be true if you are doing something user-facing, but in all other cases I would recommend the opposite.
Your comment is a reddit version of "I'm cooler than you"
I would add the *collections* module
Kind of a beginner and just figured this out, lol. I suppose we learn more from our defeats.
I haven't looked at it, but I'm guessing they use the API as well. If it's on github, you can actually look at the code and see exactly how they did everything. If you want to do a scraping project, try something (e.g., a supermarket price list) that doesn't have an API. Bonus if it's horribly formatted with no `class` etc.
&gt; 5. Build Metaclasses and Descriptors But also keep in mind the Zen of Python, and strive for simplicity. If you're not sure if you need a metaclass, you don't need a metaclass.
On the other hand, this is a valuable life lesson. It was trying to parse CSV myself that really drove home the fact that even when it *seems* simple, writing it yourself isn't always smart.
Definitely python can do this. There are many web frameworks, but for something like this and at your level I'd start small like bottle or flask. Django would be fine but I think starting small is a better idea. 
Can you show us how you build your artifact ?
Become proficient at list comprehensions, and how to not write them so they look like you smashed your face on the keyboard.
py2exe
I'm doing the raspberry pi garage door controller. I'm trying to understand someone else's code, learn python and add in some functionality that motivated me to even do it. I got the base level feature that I wanted so that's good. Now I'm trying to grok datetime functions in python.
basically, only use primitive types (int, bool, float, none, string) as default args.
And for the same reason you should loop over lines in a file (`for line in f:`) rather than use `f.readlines()` whenever possible.
https://twitter.com/HarleyKwyn/status/748584408693768192
* Learn the itertools module * Most Python programmers know list comprehensions. Many know generator expressions. Learn their siblings as well: set comprehensions and dict comprehensions. * Learn to create generators with yield * Never manipulate sys.path inside your programs
http://www.imdb.com/title/tt0096487/
If the data is not going to be user-generated, then just use a proper structured format like JSON or whatever.
The only thing I can think of that hasn't been mentioned yet is the many uses of the [underscore](https://hackernoon.com/understanding-the-underscore-of-python-309d1a029edc).
Read [Effective Python](http://www.effectivepython.com/) and [Clean Code](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882), in that order. 
&gt; but how would i use it in the context of doing a pass on only certain exceptions? That's the point `suppress()` is a `pass` on everything, but you can put any exception in the function and it will only `pass` those specific ones and others will pass though. So `suppress(IOError)` will only catch IOError and KeyboardInterrupt will continue up the chain.
&gt; If you're using an IDE (as a Vim user I say you're crazy if you're not using Pycharm with Ideavim) take the time to learn it's features. Especially how to use the debugger, set breakpoints, and step through code If you're on Pycharm (or any other jetbrains IDE) learn about Bookmarks and Quick lists as well. Activate Semantic Highlighting too.
The `yield` statement is not only for generators, but you can do very powerful stuff. For instance you can make a very easy (context manager)[https://docs.python.org/3/library/contextlib.html#contextlib.contextmanager]: @contextlib.contextmanager def tag(name): print("&lt;%s&gt;" % name) yield print("&lt;/%s&gt;" % name) &gt;&gt;&gt; with tag("h1"): ... print("foo") ... &lt;h1&gt; foo &lt;/h1&gt; or separate setup/teardown code of [pytest.fixture](https://docs.pytest.org/en/latest/fixture.html#fixture-finalization-executing-teardown-code)s without using callback functions: @pytest.fixture def transact(self, db): db.begin() try: yield finally: db.rollback()
In the now burned into my brain quote by Chris Eric: "Premature optimization, that's like a fart. Premature abstraction is like taking a dump on another developer's desk." 
Yeah. There's a subtlety here that is part of Python's charm: the language has a design goal of making re-use easy, but simultaneously a different design goal of making coding so easy that re-use often isn't necessary. We _want_ even beginners to say, "that looks easy; I'll just write my own". Sometimes when they do so, they're making a mistake.
## Integrate this into your build and text editor ```pip install flake8 flake8 &lt;path to dir or file&gt; --ignore=E128,E501 # ignores max line width/indentation alignment ``` In sublime this is the `Anaconda` package. Recommended user settings for Sublime Text's Anaconda package under Preferences &gt; Package Settings &gt; Anaconda &gt; Settings – User: ``` { "pep8_ignore": [ "E128", "E501" ], "anaconda_linter_mark_style": "none" } ``` ## Follow Google's common sense naming rules &gt;Names should be descriptive; avoid abbreviation. Give as descriptive a name as possible, within reason. Do not worry about saving horizontal space as it is far more important to make your code immediately understandable by a new reader. Do not use abbreviations that are ambiguous or unfamiliar to readers outside your project, and do not abbreviate by deleting letters within a word. https://google.github.io/styleguide/cppguide.html#General_Naming_Rules ### Read more: [cs01 Python Style Guide](https://github.com/cs01/chads-python-style-guide) [The Elements of Python Style](https://github.com/amontalenti/elements-of-python-style) has lots of good advice. [If I Could Amend PEP 8 - Kenneith Reitz](https://www.kennethreitz.org/essays/if-i-could-amend-pep-8) 
I don't know, I've had a lot of success with `std::thread`.
I assume you're referring to `email.utils.parseaddr`--or perhaps [validate_email](https://pypi.python.org/pypi/validate_email). In any case, when I dismissed e-mail as "another subject", part of my point is that most of the action around addresses is *not* syntactic, in contrast to JSON, XML, ... E-mail addressing tends to have a lot of semantic-pragmatic requirements that is application-specific. "Just use `$MODULE` ..." is less-frequently adequate advice.
For `*args` the `Tuple[]` is implicit, so you just type it as `:int`.
Why are your screen co-ordinates backwards?
Prefer smaller functions. Give every function a docstring which describes what the function does, what it takes in and what it returns. Comment any nested code. Basically, your code should be understandable by any new contributor, co-worker, or future version of yourself on the very first pass of reading it. Spend more time reading good code and writing pseudocode than you do writing actual code. Don't give variables names like 'i', 'j', 'k', etc. Trust Kenny. Lay out functions in a file in a way that makes sense, don't just always write at the bottom of the file. Don't be clever when you have the option of being clear. Don't wrap everything try/except block unless you have a really good reason to. Don't catch bare exceptions unless you have a really, really good reason to. Never, ever, ever, ever, ever, ever, ever, ever trust user input.
Are you working with the drives directly, or have you created a raw image of the drive? Really, your best option is to do the latter using dd. Image the drive first. Then read the image file. dd is already installed on any Linux/Mac system, but I believe there are Windows versions available. Once you have a raw image of the drive, you can read it directly in Python just like any file, seek to locations, parse data structures, etc.
I have experience working with .csv and .xlsx files. What exactly do you need help with? For manipulating .xlsx files I use openpyxl and for .csv files I use the built-in csv module.
Use stdlib `venv`, not `virtualenv`.
As a fellow semi new programmer I feel the need to spam every new feature I learn which I assume results in this conundrum :)
&gt; NEVER do from module import * Not even if your using it to import functions from another one of your scripts?
There are a lot of [toxic substances in PCs](http://smallbusiness.chron.com/toxic-components-computers-monitors-69693.html). So burning a computer with fire could expose you to various poisons and carcinogens. Definitely a very bad idea. Is that not the question you were asking? -------- About the only reason you might want to create a class by calling "type" would be if you were to somehow be writing self modifying code, where the base classes of the DerivedClass could depend on some input.... but you just as easily `eval` a constructed string and accomplish the same thing. So beyond the fact that self-modifying code is itself hard to get right, you just don't need to do this.
+100. This single change to my workflow made my code so much better and pythonic. `pip install flake8` `flake8 &lt;path to dir or file&gt; --ignore=E128,E501` *integrate this in your build* *Sublime users:* the Anaconda package gives visual lint cues. These are the settings I use under Preferences &gt; Package Settings &gt; Anaconda &gt; Settings – User: `{ "pep8_ignore": [ "E128", "E501" ], "anaconda_linter_mark_style": "none" }` (E128 is for line indentation alignment, and E501 is the max line length of 80.) 
Not sure what you mean. Do you mean why are the y coordinates reversed from libraries like PyGame? OpenGL uses a coordinate system that is more like what you learned in math. Y-coordinates go up as you go up. Older graphics libraries often have y get bigger as you go down, because of their historical association with the evolution of text to graphics. (Where we think of row one at the top.) By default, OpenGL puts 0, 0 in the middle. This library puts it in the lower left, so you draw in the quadrant that has all the positive numbers. I like teaching students using this coordinate system because it is what they were taught in math, and I don't have to spend all this time telling them that y is reversed.
dd does not have any "magic" that lets it read raw data from block devices directly. It does not do any integrity checking, at all. There is no advantage in using dd over cp, unless you want to only copy specific parts (for example: 1kb starting at byte 512) or want to use dds translation mechanism. In all cases i have seen dd used, including just pulling a complete image of a drive, cp would do a better job and would be easier to use. OP, as long as you are on a unixy system, you can just open the block device like a regular file, and start reading(or writing). with open("/dev/sdb", "rb") as drive: byte_0 = drive.read(1) 
The point is to do it directly on hard drives. I'm trying to create a tool that can do something over and over hundreds of times. Sure, I can also just open a drive up in a hex editor, find the bits I need to modify, and do it manually like I have a thousand times in the past, but I'm trying to automate some things we do in data recovery.
as long as you are on a unixy system, you can just open the block device like a regular file, and start reading(or writing). with open("/dev/sdb", "rb") as drive: byte_0 = drive.read(1)
Milkshake 
So I tried to boot it! running an oracle VM and unbuntu snap, ubuntu (17? ish) and tinycore. I'm struggling to hook the an XServer onto the screen. Perhaps more clearly (using a tinycore this time), I can turn on/off the xserver - but I'm not entirely sure how to _hook_ your new one. Or any _alternative_ xscreen tbh. When I do try, I receive a black screen - Then I just reboot the snapshot. --- I guess my real question is: Editing the `.xinitrc`, what command to I `exec` at the end of the file? Or if I use `startx` (can I?) whats the windows manager path? --- Thanks in advance for this; I'm looking forward to playing with it. 
If you're dealing with CSV, there's a good chance you're actually dealing with tabular data. [Tablib](http://docs.python-tablib.org/en/master/) not only imports and exports CSV (and JSON, and YAML, and .xslx), but gives you Pythonic ways of manipulating your data once you've imported it.
Or try Tablib.
Well, I can't find a detailed tutorial or explanation on how to use the csv module, or what can be done with it. Do you use an IDE?
Flask (or Bottle) with some simple forms may work well
Yes, but I'm hoping to make this a Windows tool since data recovery equipment generally requires Windows.
Right, but do you copy and paste code to juper to debug or there is some kind of juputer debug tool? 
Cmon, it' like two extra lines to handle encoding...
I do use various IDEs but they don't really make a difference. Here's an easy example. Let's say you have a .csv file with 3 rows and 3 columns (First Name, Last Name, Age) and the file is named people.csv. import csv my_csv = csv.reader(open("people.csv")) for row in my_csv: print(row[0]) print(row[1]) print(row[2]) I will explain each line. First we need to import the csv module in order to use it. Then we create a csv.reader object, this will convert our .csv file into a data structure. Then we iterate over the data structure with a for... in loop. Each row object contains the data of each row of the .csv file. We access its values by specifying the index. The First Name will be index 0, last name index 1 and age index 2. 
B-but 80 lets you do 2-up. I almost always have another file that I want to be looking at when I'm coding.
Take a look at kivy. Should be possible with that.
I recommend looking through Automate the Boring Stuff. [Chapter 12](https://automatetheboringstuff.com/chapter12/) goes through using openpyxl to manipulate excel files. Chapter 14 goes through using the csv module. Pandas is also a good way to look at and manipulate excel files. There should be good pandas tutorials for Pycharm.
pip install pytest-testmon py.test --testmon
 Commenting to save. Thank you :) 
can't you just wrap python around the c++ instead?
Sounds good to me. People seem to confuse "dynamic typing" and "duck typing" with "get rid of types everywhere". If two different functions need to handle the same even vaguely non trivial data structure, having a bucket of keys/values and expecting both functions to just make assumptions about the contents is madness. Make a type and enforce the structure *in the type itself*. Then at worst the functions can use isinstance if they really, really need that type specifically. This is what the Haskell people were complaining about all this time ;)
PyInstaller, you only need this command after you have cd into your project folder: pyinstaller mymainscript.py --onefile
I agree. Just pointing it out for completion's sake. I think Python took some really cool ideas from functional programming, but some ideas like `map()`, `filter()`, and `reduce()` are pretty unpythonic, [as Guido pointed out](http://www.artima.com/weblogs/viewpost.jsp?thread=98196) (not sure I agree with him on lambdas though).
It's not just you. def get(url, params=None, **kwargs): r"""Sends a GET request. From a rather famous library ;)
Agreed. Though you may want to look at asyncio instead of multiprocessing. https://www.reddit.com/r/learnpython/comments/5uc4us/multithreading_vs_asyncio/
Start at r/learnpython for questions such as this. You are going to need some solid understanding of python rudiments, and that is the place to develop such skills. Dont be afraid to take some general python online courses or write simple practice programs to aid in your understanding. The more that you practice understanding python as a language, the easier it will be for you to ask questions better tailored toward achieving your goal.
Pandas has a simple read_excel function that reads an .xlsx file to a dataframe: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html You specify the file path and the sheet you'd like to work with and it is loaded into a dataframe - i.e df = pd.read_excel("my_file.xlsx", sheet="sheet_1"). Provided that a dataframe is suitable for the data you have this makes it simple to focus on the analysis.
All hail the Zen of Python!
you will probably have more success asking this one in r/learnpython . Make sure to include in your question the name of the program or file format that houses the fields you are looking to fill.
I wrote a simple tutorial on the csv module: - https://www.blog.pythonlibrary.org/2014/02/26/python-101-reading-and-writing-csv-files/ But if you want a more in depth tutorial, then you should check out the Python Module of the Week site: - https://pymotw.com/2/csv/ I also wrote a couple of simple tutorials on reading and writing Excel spreadsheets using xlrd and xlwt: - https://www.blog.pythonlibrary.org/2014/04/30/reading-excel-spreadsheets-with-python-and-xlrd/ - https://www.blog.pythonlibrary.org/2014/03/24/creating-microsoft-excel-spreadsheets-with-python-and-xlwt/
I really like wxPython
I strongly disagree with your assessment on threads versus processes. The overhead on spinning up separate Python processes is quite massive, such that if you are calling GIL releasing code, it make take minutes of computation for the multiprocessing solution. We also shouldn't understate the expense of serializing and copying data all over the place. Pickling has some limitations, such as not being able to pickle bound class methods, which when you actually work with `multiprocessing`, becomes really annoying if you're doing object-oriented programming. I would say generally unless a process is going to take &gt; 10 s to finish, it probably is suboptimal to use a process. There are going to be many exceptions to that, but there is a lot of CPython libs that release the GIL. The advice given elsewhere to use `concurrent.futures` is the best advice. With futures you can swap from threads to processes by changing `ThreadPoolExecutor` to `ProcessPoolExecutor` and nothing else. It's a far, far better interface than using `multiprocessing`. 
Learn a statically typed language and you'll spend significantly less time debugging. 
Tests! Write new code at half the speed - maintain, refactor and add functionality 100 times faster! 
Arch all the way, even on my VPS :-)
Try appJar.
I already did the online courses now I want to do something with that knowledge. I just want some pointers what the best libraries are for this
~~Documentation and code comments.~~ Unit tests and readable code.
I expect the downvotes come from some people's perception of linting as nagging, enforcing rules that are now arcane, and adding largely unnecessary clutter to your IDE. Things that a young gun might value highly, but a senior programmer has learned is the lesser evil?
This is me currently. I'm stuck as a database admin and I want to make software. I keep telling myself to just stick out the year.
https://github.com/Catastrio/Wikipedia-Word-Counter/blob/master/wikipediawordcounter.py I've made a lot of progress since I've made this thread! It's likely inelegant and has many flaws but my goal was getting it to do a specific thing. Which it now does. Any suggestions for removing footnotes in the brackets? 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Catastrio/Wikipedia-Word-Counter/.../**wikipediawordcounter.py** (master → 450fcd1)](https://github.com/Catastrio/Wikipedia-Word-Counter/blob/450fcd1824ea09be5e572af01382bf5bc09e7233/wikipediawordcounter.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dptuj08.)^.
I love using Pandas for this.
Read Clean Code by Robert Cecil Martin
Why?
Except that YAML is insane overkill for most situations? JSON is fast, simple, robust, and everywhere. If you really need [9 ways to have newlines in strings](https://stackoverflow.com/questions/3790454/in-yaml-how-do-i-break-a-string-over-multiple-lines) knock yourself out though. 
 $ ipython &gt; encounter exception %debug
Awesome! Well i found a little tutorial on python and google spreadsheet integration. A quick google search should help further narrow down your options/supply ideas. https://www.twilio.com/blog/2017/02/an-easy-way-to-read-and-write-to-a-google-spreadsheet-in-python.html
I believe in unit tests and readable code where feasible but didn't know anyone seriously considered them an alternative to code comments and documentation. I still think they are important.
Probably because there are similar packages like scikit-learn and, more relevantly, scikit-image. It makes sense to stay within that naming convention, given the history of these projects.
You tell'em johnny I read it as Milkshake pretty much the whole time.
And verifying that requirements.txt is not a lie.
Well, it's very easy for me to select/change/update fields in a dataframe than iterating over a csv. For example, for a csv that contains song information such as title, artist, playlist_id, songid etc, I wouldn't have to run a loop to get that information. I'd do something like the following to get all the songs for an artist. if ((dataframe.artist.str.contains(artist, case=False)) &amp; ( dataframe.title.str.contains(song,case=False))).any(): .... There's many different ways to manipulate data from a csv using pandas builtin functions without running a loop (although it can't be avoided in specific situations) and then write it back to a csv, json or whatever format Pandas supports. It's my goto for manipulating csv docs.
Thank you so much. I'll go through all this.
Thanks! Didn't realize that was a sub. 
Like I said, there's a legitimate reason for code comments. Explaining anything about what the code does means your code isn't readable, and they're worse than nothing if they get out of date. Documentation depends on the project for sure, a public library, absolutely. For an internal project, documentation again is usually a massive headache to upkeep and unit tests if done well, provide a capacity for finding issues and understanding code.
Does the [win32_diskdrive](https://msdn.microsoft.com/en-us/library/aa394132%28v=vs.85%29.aspx) interface give you what you want? [Stack overflow question+sample](https://stackoverflow.com/questions/9901792/wmi-win32-diskdrive-to-get-total-sector-on-the-physical-disk-drive)
I think some is starting to get experienced as a programmer when they say: "Who wrote this crap. This is total rubbish." Then read a little more and say. "Oh, that was me." It is an eye opener the first time it happens. :)
Documentation is always important, not everyone who's going to look into your work is skilled at Python, let alone a developer, and it saves a lot of time when someone needs onboarding. There's nothing worse than a dev who finds that everyone else who handles his work is also a dev...
Have you tried reading Windows's block device files the same way? https://support.microsoft.com/en-us/help/100027/info-direct-drive-access-under-win32
That's basically a total rewrite. And Traverso DAW is a desktop application. How will you use it with Django? Once again you're talking about rewriting it entirely as a web application right? Based on those 2 items, this is a considerable project and will be expensive as its basically redeveloping it from scratch.
Watched the video. He really comes across as someone trying garner attention by saying something controversial. The examples are pretty contrived (not wrong examples per se) of things I've pretty much never encountered in the wild except by the most novice of programmers. "Seperation of Concerns, Decoupling, Encapsulation, Implementation Hiding - I haven't used these words in 15 years, anyone who uses these words is trying to pull a fast one on you, it just doesn't come up" Seriously? I've had to bring a couple of these up in the past week! It sounds like he doesn't have to deal much with modular systems where well defined interfaces are key... that's where classes/objects shine. He sounds like a questionable programmer with a personal vendetta against classes for some reason. I mean, a quarter of the talk was about not making new exceptions... which requires creating classes sure, but isn't argument against classes in general. The Muffin example was alright, but even his second version would have allowed multiple connections to the API via multiple connection objects, vs his final version which limited things to one connection, so he lost functionality. And he's lost any concept of an interface to the API in the final version. It's way less code, but it's inflexible design. The original design was bad too, mind you, but it was just crappy programming, not due usage of classes in general. You could still write a fully functional version without classes sure, but that was a pathological example. The Flow example was an abuse of inheritance...not classes. Superfluous inheritance, like exceptions, require writing a class... but it doesn't make for a good argument against classes in general. The examples he brought up were for the most part only related to class usage very loosely. The only good point he made was not writing what should just be a function as a class... which I've pretty much never seen done.
I got turned down from a job by copy pasting a sorting algorithm from SO instead of just using `sort`. :(
Convention between languages is reasonably interesting. Python linters will yell at you if variable names are &lt; 3 chars, even in the case of `for i in range`, whereas GoLang seems to encourage using short vars for anything within a reasonably sized function scope. `for i, c := butts()`
Classes are for what I use them for. That's pythonic.
?? shows the source
Again, that was a figurative statement. So no, it isn't dogmatic.
Are you asking to see what I’m talking about? If so, the 0 is a link to their screenshot that shows the help pop up :)
Well, Python looks like pseudo-code, so sometimes writing pseudo-code ends up writing the code after all 😁
Use `pytest` instead.
Never heard of that kind of rounding, weird to see it as a default, good to know.
no, I'm saying two question marks in ipython asked the source, which it sounds like bpython doesn't do
This is why I love coding using PyCharm: Continuous PEP8 inspection 🙌
You should be importing `*` in your `__init__.py` files and specifying `__all__` in your modules.
Most.
when i'm not at the office I work with only my laptop screen which is 1366x768, surprisingly I got used to it, at work i have 2 extra monitors, one is 1920x1080 and the other is a vertical usb monitor that is 768x1366
Oh my bad, thanks for the correction! I’m not sure if bpython has a good way to see the full function. I usually jump straight to source anyway myself (probably unnecessarily!)
No, that's a case where you can specify what you're importing.
I don't agree with that. Comprehensions are the ideal in legibility even for the simplest case you have defined. People just aren't used to reading `map`.
You would only need one file.close(), in the finally block. The with statement is mostly redundant if you are already explicitly catching exceptions, as it is basically just wrapping your code in a try/finally block behind the scenes. 
I think that's a bit of an oversold ~~excuse~~ reason to not have code comments. Even function/method comments are better than nothing and these are not going to date nearly as fast. I'm not suggesting single code line comments are going to have the same shelf life and I'm not nearly as dogmatic about those anyway. Also your APIs and interfaces shouldn't be changing every 5 minutes, less of an excuse not to document those. Of course PEP8 guidelines help but these don't make documentation redundant. I guess it depends on whether your aim is to make your services indispensable for life or whether you for see someone else ever taking over your project.
And most importantly tuples.
It requires Python 3.6 but the check for that is only done at the end of the ``__init__.py`` -- which means it installs fine on 3.5 but when importing it, it still crashes with a syntax error because f-strings are used: &gt;&gt;&gt; import arcade Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/irmen/.local/lib/python3.5/site-packages/arcade/__init__.py", line 13, in &lt;module&gt; from arcade.draw_commands import * File "/home/irmen/.local/lib/python3.5/site-packages/arcade/draw_commands.py", line 1762 key = f"{text}{color}{font_size}{width}{align}{font_name}{bold}{italic}" ^ SyntaxError: invalid syntax &gt;&gt;&gt; You may want to move the version check up so it is done before importing anything else. Then users (such as me) that try to run it on python 3.5 get the clear error message that you intended to throw 
I believe it's actually not part of the language definition and it's just a cpython thing. Would be fun for them to change it and weird code would brrak.
In other words always use trailing comma.
Json is not really an alternative to pickle in general.
Would you also recommend letting custom exception out of your code? I'd say using some "standard" ones is more appropriate for smaller projects.
Everything!
Yes, but by specifying the individual things someone can use find in the source to know where something is coming from.
Even the `map(int, foo)`? That's perfect example of when to usemap in my opinion.
I fail to see how an example of finding out disk size is in any way relevant to actually reading a block of raw data from it.
Not sure if you're serious here? Have you thought this through? Traverso seems to be a desktop Digital Audio Workstation application, the type of program that typically requires high performance and low latency processing. Something the combination of a web application, written in Python, doesn't generally provide, at all
It's up to you. There's a reason the Google style guide advises against it and that's because everyone knows comprehensions, but not everyone can remember how `map` works, e.g., the order of the arguments.
Yes, and it doesn't work. That's why I'm asking to see an example of a snippet of code that can just read one raw sector/byte/block whatever of data from a drive. I've yet to find any functional code to do this in Windows.
A) It's only one of the many problems with the core csv module. Everyone who uses it probably extends it to add roughly the similar feature sets. (dict handling, type conversion, headers, etc) These are all things that are error-prone and should've been in the base module. B) That really depends on what you're doing and what you need your data to look like. At best, it's 2 lines of something easy for newcomers to fuck up and something that should have been part of core module. I've watched students spend days trying to figure that out in Python. Pandas handles things like type conversion, missing data, writes headers, and handing it back in at least a vaguely dict-like fashion (something you have to use a recipe for in the base CSV module).
I just learned something new (Pycharm feature)
Excellent, thanks for the feedback. I'll work at getting that fixed up.
Curious was to why GTK is not listed?
Project seems to be dead :/
sure thing, I would love to play with this library but don't have the time (nor an idea what to make) but it looks very interesting. 
Evolutionary algorithms
Ah my bad. I had read about it in a HN thread today but the person had mentioned using a variant. I looked at the Google repo and saw the number of stars and obviously didn't compute the time since last update. Anyway, here's another Python html parser I've come across. Frequently updated (in the last week). Fewer followers and contributors but seems to have decent documentation and says it uses a variant of gumbo: https://html5-parser.readthedocs.io/en/latest/ I was not even aware that lxml might have problems with the HTML5 spec. If anyone knows of anything more standard, I'd love to know!
Sorry, unlike last time there's not much new to see on the Python side in this release. PEP-484 type-variable support is still the next big target, but that needs some serious thinking.
Haha no worries, I’ve used html5-parser in the past, it works well.
What I wrote earlier was misleading: pertinent to my application of `re` to XML is less that I "know what I'm doing", as I phrased it then, and more that I am equipped for all the likely fault modes that will result. Beginning automobile drivers more often crunch metal not because they lack information about horsepower and stopping distances and ..., but because the erratic behavior of all those other drivers _surprises_ them.
The simplest GUI for python is EasyGUI. 
What is that one line? I was writing a ninja game to learn pygame not to long ago and couldn't find any collision detection built in
Have you tried Ubuntu Subsystem within Windows?
To be fair, it does say that map is ok when you're not using a lambda. https://google.github.io/styleguide/pyguide.html?showone=Deprecated_Language_Features#Deprecated_Language_Features I've seen map in many languages, and I've only seen it as either `xs.map(f)` or `map(f, xs)`, both of which are pretty logical (to me, at least).
If you want data to be returned as a dict then why not use csv.DictReader?
Mutable defaults can be useful. Using a literal dict as a default lets you create a function-scoped cache. In general, yes, you should use None, but mutables have their place.
Yep. Use pandas. Because you probably are already using pandas, so don't import an unnecessary module.
&gt; stuff like python is used more on servers compared to a regular use PC, okay but we werent talking about what OS is most popular among developers, I said the "most popular outside of the developer community". For someone so damn pedantic you sure as hell cant read well.
I have delved down this path before and tbh neural nets just do better. I haven't found a use case in the real world (healthcare) where these make sense.
qt if you want something professional, otherwise tkinter for one offs.
list[::-1] reverse that list 
Pro tip if you are going to scrape a website. Be nice and put in a random number generator that delays your app every iteration so you don't bomb their servers. Also use selenium along with beautifulsoup and the chrome driver with a good ad blocker extension. Will make your life easier.
I just discovered this this week as well. It makes it so much easier to share the same metadata across other things that require the same metadata, such as Sphinx,
Even though this is an over complication of a simple problem, you would probably get a job if you showed this to a hiring manager...
There is a save function, you know. 
&gt; and I think pycharm can do it too It does.
I don't know if it's improved, but last time I used PyCharm it felt really slow and bloated.
yes, these are definitely important details.
fair points.
Don't create classes unless they make sense (you need to hold data and behavior that acts on that data without passing the data around all the time). If you only have behavior (functions), just make a module. You get the benefits of scope and namespacing without the cruft and ceremony of a class def and having to deal with singletons and other crap. Python isn't Java. Just remember that.
I've been using python professionally for years and years and I still don't understand WTF "batteries included" means.
Meh. i and j are time honored variable names in loops and such.
Are you metaclassing? Then you have no reason to ever use method one.
There's a csv.DictReader ;) I don't talk against pandas (I also use it when not absolutely necessary), but people should at leasr know the stdlib.
Short, honest answer: I don't fucking know. I thought metaclasses and descriptors were black magic. This thing takes the cake as it's completely undocumented. A longer answer: I know there is a correspondence between: class MyClass(SomeBase, metaclass=SomeMeta, rando="keyword"): # body # body __build_class__("SomeBase", body(), SomeBase, metaclass=SomeMeta, rando="keyword") What I ended up with is: _orig_build_cls = __builtins__.__build_class__ def __build_class__(name, func, *args, **kwargs): # do stuff return _orig_build_cls(name, func, *args, **kwargs) I used this to insert a metaclass into the \*\*kwargs that would cause the class to auto-inherit if its name matched something in a registry, so essentially: class AutoInherit(type): registry = {} @staticmethod def __new__(mcls, name, bases, attrs, **kwds): parent = mcls.registry.get(name) if parent: if bases[-1] is object: bases = bases[:-1] bases = bases + parent.__mro__ cls = super().__new__(mcls, name, bases, attrs, **kwds) registry[name] = cls return cls Of course I discovered this while doing the most intense metaprogramming task: Avoiding redefining methods on a class in a presentation. I was building a class iteratively in an IPython slideshow, and needed the old methods around but didn't want to end up exploding the screen with methods I already covered.
Mixin factory would be a reason
Hash some of the fields out of smbios, like SN or uuid or whatever you can get, send them back up to a registration server along with a user key and you can act based in that. Disallow the program if you want, but that might just encourage them to modify your python code to bypass the c library entirely. Or just phone home with the info and act on any account violations with your legal team. If you really want something with a DRM system built in, you aren't going to want the core application code in Python because anyone with a text editor could just bypass your security no matter what you do. 
There's really no trick to being a good programmer. Try to be thoughtful as you write new code and don't be afraid to reevaluate old code. Don't let ego get in the way of a code review. That said, programmers who make use of `context managers`, `generators`, and the standard library produce the best code.
I think what you mean is gradient descent works better. Neural networks can in fact be trained with evolutionary techniques.
Yes i think it's much more effective to treat this on the legal sphere. My idea is pretty much what you suggested. Thanks for the validation. Thanks!
Depends on what you're doing, obviously, but I was able to replace pickle with json easily in a couple of my projects. A little reconstructor function and an extra key or two in the outer dict and Bob's your father's brother. YMMV.
I like this coordinate system as well. It just makes sense. It's dissapointing that Vulkan went with the inverted Y, but that's another discussion I guess. 
use metaclasses everywhere
From what I have learned of the past year or two since I started programming I think this means that Python has a lot of libraries included with it, for almost anything you may need there might be a standard library for your needs.
Yeah neural networks work better on some tasks however they are extremely prone to overfitting even with things like dropout etc. Evolutionary algorithms can avoid such things however they tend to get stuck on local minima. 
I used evolutionary algorithms in my M.Sc. thesis for optimization because the size of the solution space was absurd. Other methods were decent, but didn't touch the EA one.
I really like PyQt. It's not the most simple, but if you learn to use it to make a simple GUI, you won't need to learn a different toolkit for a complex one :) I'm on my phone so I can't make sure this works, but here's a simple example: from PyQt.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QPushButton app = QApplication([]) widget = QWidget() layout = QVBoxLayout(widget) lbl = QLabel('Hello World') btn = QPushButton('Goodbye World') layout.addWidget(lbl) layout.addWidget(btn) btn.clicked.connect(app.quit) widget.show() app.exec_()
Would you mind going a little into detail about this? I'm looking to apply EA to a large solution space as well, any general advice would be great.
woooo! +1
ESPN Soccer Scraper for a teacher's fantasy league
I don't actually understand the advantage of such an approach over providing a command like, say, "python setup.py dump-kwargs-json", which would give something just as parseable by other consumers. Instead, setuptools decided to further extend a completely ad hoc DSL (`attr:`? `find:`?), and this does not help cases where you *actually* need to dynamically compute some fields (e.g. pkg-config for compilation flags) -- something that dump-kwargs-json would actually have been able to expose to other consumers.
But of course!
Wow wat.
numpy, scipy and VFX are the big 3?
Sure, I don't know how useful it will be. I used the book "Introduction to Evolutionary Computing" by "Eiben, and Smith". Basically my project involved using two different image transformations to find an edge in an a set of images. Each image transformation had several parameters to tune, and there was a huge amount of variation between images (quality, exposure, colour levels...). The way it worked was that provided a training example it would tune the parameters of the transformations using an evolutionary algorithm, which was quite simple. I used a tournament method where every child solution had 4 parents with a chunk (I forget what it's called, but basically a start and end point of the array of the individuals parameters were chosen such that the child inherited all parameters between those end points) crossover design and a dynamic mutation factor, such that it was a mixture of simulated annealing and a genetic algorithm. So tournaments took place within a Markov Chain, with the mutation rate 'cooling' as iterations continued. The parameters for the evolutionary algorithm itself were chosen using gradient descent (size of population, mutation rate, cooling schedule ...). Anyways, evolutionary algorithms are reasonably parallelizable so it was able to settle on a reasonable solution really really fast. I recommend EA's because you can often get a good enough answer without too much trouble, and do it quickly.
Absolutely, but it has problems of it's own. I'm all for using the stdlib and most of python is great for that -- just not the csv. It's more headache than it's worth. 
My d&amp;d bone feels this is +4 bastard sword level of awesome. 
To all TDD-knowledgeable devs, I have a few questions. 1. Do you write the test before the result ? 2. If 1 is yes, does it mean that you already pictured your code inside of your head before creating the test? 3. How does testing lower the time of programming? I am currently studying TDD approach, but have a hard time grasping it.
Right, but some libraries are described as "batteries included," which doesn't make a lot of sense.
So it will need to go through a server, no way to do it locally. Thanks!
Well this gives me a lot of motivation to finish our transition to python 3 in my company. It's been a slow process but one I plan to finish by about February of next year. Before anyone passes judgement, I'm the only person who has been converting code for about 100,000 lines of code or so, while still producing new features. I've been working towards it for about 2 years now, off and on. I'm in the final push now. If anyone has any tips I'd by happy to receive them. 
Surely this will be the end for Python 2!
use virtualenv and pip in case of a simple python project. Use anaconda and conda in case of a project that has datascience dependencies like numpy, scipy etc,
When you say "Building a Debian package requires you to be running Debian with dh-virtualenv installed", or will a debian-based OS suffice (e.g. Ubuntu)? 
finally
How about the tutorials and examples for [DEAP](https://deap.readthedocs.io/en/master/)? They have a page on GP.
Good Luck!
haha. And what makes you think I already don't have one and pretty damn good one at that?
I mean, enforcing rules and having a consistent code style is important for senior and junior programmers alike.
Not a senior, but I was told by one to write code as if it would be maintained by an ex-Navy Seal with anger-management issues who has your address
No judgment. It’s not a trivial process. [Instagram had a good write up ](https://thenewstack.io/instagram-makes-smooth-move-python-3/) on their efforts to switch. You’ll get some efficiency increases but probably not worth the cost, sadly. However its something that should be done. 
I, on the other hand, just got why they are called dunder...
https://github.com/jeffshek/betterself/ Adding Mood Tracking Reminders to Send via Text
BeautifulSoup (python library) works well for this.
If you spend more than 2 minutes to solve a bug, spend some more time to think about what you could have done in the first place, when writing that code, to simplify to yourself the finding and the solving of that bug. 
Ditto this - most people haven't used pandas before, but once you get the data in a dataframe, the data cleaning is akin to going from "SUPER DIFFICULT and RANDOM UNICODE FAILURES" to "EASY" mode.
How about using the [official dump files](https://dumps.wikimedia.org/) for practice? 
In the SO post, they are getting a disk size, but, it just about gets you to what you are asking: import wmi disks = wmi.WMI().Win32_DiskDrive(MediaType="Removable Media") for disk in disks: disk_size = int(disk.size) sector_size = disk.BytesPerSector print(disk.name) with open(disk.name, "rb+") as f: #start doing your writing here f.write("no idea what to put here") I left the disk size and sector size variables in there, no idea if you need to seek by sector size or something. The disks call on line 2, its referencing Removable Media, you may need to replace that with something else, i'm too lazy to check what it would be for a hard drive. This page here mentions how to open windows drives with python: https://stackoverflow.com/questions/6522644/how-to-open-disks-in-windows-and-read-data-at-low-level So, it might be as simple as: with open("\\.\C:", "rb+") as f: f.write("stuff") I haven't tried this either, but, i'd give it a shot 
Yes, Python will be the best tool. You could have a three step process: step 1: how do you want to get the data? Stream or at some time interval(historical)? Step2: how do you want store the data? Some data transformation taks might be needed to be done. Step 3: What kind of analysis do you want to make using this data? How often do you want to refresh your report? What kind of tool do you use to build your report? ...Hope this helps. 
&gt; You’ll get some efficiency increases but probably not worth the cost, sadly. The real benefits of Python3 are for humans, not computers: - much harder to shoot yourself in the foot with unicode (ie text) - library support (some already, more soon, most by 2020) - general improvements to language and standard library - type hints can be great for medium to large projects (it's like testing, but free)
There are always trade-offs. Are these services not dockerizable?
There are always trade-offs. Are these services not dockerizable? 