I was excited the other day that I'd have a chance to use Scrapy for something, but then discovered that the site I wanted to scrape already had an unofficial REST API that I could call more fittingly with requests. I was a little disappointed.
Ever since 5.x PyCharm has been a mess full of bugs and performance issues. Please stop adding new half broken features, changing your branding etc, and focus more on delivering an usable product that works as described.
That sounds fair. Awesome. I'd love to help. I remember trying to watch Flake8 a couple months ago when first moving to GitLab, but it seems like it isn't a feature that exists yet. 
They're node.js/js developers. What else do you expect?
Replace the example by format: &gt;&gt;&gt; '{:+&gt;5}'.format('abc') '++abc' &gt;&gt;&gt; '{:+&gt;2}'.format('abc') 'abc' The troll is fun, but you gotta do it right. 
Yes please, update the code and the README. I'm dying inside because I want to share this link so much, but right now it's embarassing. (also read https://pyformat.info/)
Now if someone could add this to pypi: https://www.npmjs.com/package/is-positive-integer 
i actually pull all my header files from the linux github repo at boot time. no more stale headers sitting around doing nothing!
Arf, no github, no link to contact the author, we can't even tell him he fucked up his implementation.
Yes, we would have the same issue as well. Although I'm guessing its much less likely as the python community doesn't go crazy on tiny modules for everything. Requests &amp; Django for example, doesn't have any external deps (or at least they're vendorized).
Any module you publish on pypi will get like 150 downloads almost instantly. Mostly mirrors probably. 
Yeah I was going to say python has it built in.
Neato, thanks for the link 
The Ruby one would also have a name like "Manifest", and have a page devoted to how awesome it is, quotes from people, corporate users, etc.
I wish but no : https://github.com/tjmehta/is-positive-integer/commits/master
Does it bug anyone else that, assuming string concatenation is linear time, left-pad is quadratic? You had one job, left-pad!
You are so out of the loop. I mean, [this article](http://www.haneycodes.net/npm-left-pad-have-we-forgotten-how-to-program/) was posted all the way back yesterday and hit the top of Hacker News last night. What are you doing with your life to have missed this? Actually, what are you doing, because it's probably more interesting than mine? More seriously, javascript, despite being the popular language of the month, does not have much of a standard library. It's popular now because of nodejs, and it allows people to use the same language for both client and server side code. But the javascript that your web browser understands is the same one that node understands (give or take, as not all browsers implement the same javascript). Since javascript doesn't have a standard library like... every other language, people end up writing single function modules that end up getting used by others in their modules, but the actual code is super small. It's the "don't reinvent the wheel" philosophy taken to the ultimate extremes. There is actually an excellent utility library called "lodash" which you could consider a "3rd party stdlib". https://lodash.com/ 
As far as I know, if you wanted to run them natively, your only real option is [Pythonista](https://itunes.apple.com/us/app/pythonista/id528579881?mt=8). I *think* it had lots of modules but I am not 100% sure. I wonder if it is possible to launch an iPython notebook on a local machine and edit it on the iPad. I have no idea how it would format, etc. Others may be able to help more here.
I think there is a little misunderstanding here. I am not talking about a "request" to take down packages, but I am referring to the extremely popular "requests" module https://pypi.python.org/pypi/requests Permanently taking down packages can be done very easily in PyPi. You can do this in a few seconds via the web interface, and there is no undo. My point is that a "left-pad" disaster on PyPi is very realistic and needs to be reckoned with. Disabling the possibility to delete packages on PyPi would be an obvious way to prevent this. Once something is published on PyPi, it is instantly mirrored on hundreds of servers beyond PyPi's control, so deleting a package doesn't really "remove it from the internet" anyway.
Assuming all of your dependencies follow [semantic versioning](http://semver.org/), use ranges. For example, if you need `requests` 2.x, put `requests&gt;=2.0.0,&lt;3.0.0` in `setup.py`. Following this pattern, your package will not need to be updated every time a dependency is updated.
This is really cool!! I have wondered about how to do this for quite some time. I think it could be really useful for a "bill-sharing" type of application. Thanks for sharing Dan!
I feel like this could be a great spinoff of [99 Bottles of Beer.](http://99-bottles-of-beer.net/)
PDFQuery is what I've used for hundreds of thousands of PDFs here at work. And I agree with kephir, the PDF format is total crap and a pain in the butt to work with. I threw this together as an example, it parses the PDF and gather the manufacturer, model, and details (from the last column) into a dict (runs on Python 3): import pdfquery from lxml import etree PDF_FILE = 'C:\\TEMP\\2015-cg-insulin-pumps.pdf' pdf = pdfquery.PDFQuery(PDF_FILE) pdf.load() # uncomment the two lines below to write the xml # of the PDF to a file, helps to find coordinates of data # with open('xmltree.xml','wb') as f: # f.write(etree.tostring(pdf.tree, pretty_print=True)) product_info = [] page_count = len(pdf._pages) for pg in range(page_count): data = pdf.extract([ ('with_parent', 'LTPage[pageid="{}"]'.format(pg+1)), ('with_formatter', None), ('product_name', 'LTTextLineHorizontal:in_bbox("40, 48, 181, 633")'), ('product_details', 'LTTextLineHorizontal:in_bbox("885, 48, 1140, 633")'), ]) #the below line removes any LTTextLineHorizontal with no text, sorts it by y coordinate from top to bottom, # and enumerates what's left so we can get the manufacturer (even line) and model (odd line) for ix, pn in enumerate(sorted([d for d in data['product_name'] if d.text.strip()], key=lambda x: x.get('y0'), reverse=True)): if ix % 2 == 0: product_info.append({'Manufacturer': pn.text.strip(), 'page': pg, 'y_start': float(pn.get('y1')), 'y_end': float(pn.get('y1'))-150}) # if this is not the first product on the page, update the previous product's y_end with a # value slightly greater than this product's y coordinate start if ix &gt; 0: product_info[-2]['y_end'] = float(pn.get('y0'))+10.0 else: product_info[-1]['Model'] = pn.text.strip() # for every product found on this page, find the detail information that falls between the # y coordinates belonging to the product for product in [p for p in product_info if p['page'] == pg]: details = [] for d in sorted([d for d in data['product_details'] if d.text.strip()], key=lambda x: x.get('y0'), reverse=True): if product['y_start'] &gt; float(d.get('y0')) &gt; product['y_end']: details.append(d.text.strip()) product['Details'] = ' '.join(details) pdf.file.close() for p in product_info: print('Manufacturer: {}\r\nModel: {}\r\nDetail Info:{}...\r\n\r\n'.format(p['Manufacturer'], p['Model'], p['Details'][0:100])) Output (Detail cut off to make the comment a little shorter): Manufacturer: Animas Corp. Model: OneTouch Ping Detail Info:Meter remote and pump can each control nearly all pump functions, including delivering a bolus, moni... Manufacturer: Animas Corp. Model: Vibe Detail Info:The Vibe is a pump with built-in CGM technology that uses a sensor to wirelessly transmit continuous... Manufacturer: Asante Model: Snap Detail Info:The Snap pump consists of two parts: a controller with buttons that controls pump functions and a di... etc
This looks neat but is there any documentation? What do all the colors and dots and numbers mean?
PyPI packages break things for users every now and then. It's just part of the deal of external dependencies. I remember a couple months ago a popular package on PyPI stopped installing because it depended on a couple other packages which happened to be hosted on a private host, which went down. 
I've got a 70% score in lastpass :) These are just for passwords that need to be entered dozens of times per day and change every 3 weeks....and just because.
That is spacemacs going crazy...
Uh, why? Can't you already do this with format?
99 paddings on the wall.
That's not a microservice, that's a SAAS. Hello ! Can you take the semantics of padding seriously ? This is important business !
 $ tree FizzBuzzEnterpriseEdition/src/ | grep java | wc -l 90 AKA "code not a metric for productivity" :) 
Sounds like a use for Lastpass. heh. 
Please format your code right, it is a mess to look at it and we can not help you. Add 4 extra spaces before each line of code
PyPi can just put it back if it becomes an issue. The code and binary are Open Source after all.
Consider using tmpnb.org. It's free, there's no registration, and it's pretty awesome.
This software has a bug: &gt;&gt;&gt; left_pad("abc", 6, 'XYZ') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "site-packages/left_pad.py", line 2, in left_pad return s.rjust(len(s) + n, c) Node version: &gt; left_pad('abc', 6, 'xyz') 'xyzxyzxyzabc'
I think it's possible to use a notebook on another machine through the browser, but not exactly fun. Partly because the interface hasn't really been optimised for touch interfaces, partly because programming without a physical keyboard isn't much fun however you wrap it.
I just figured you needed a porn-site password generator...
I like Bokeh--but the emphasis on plotting seems to eclipse the general idea behind creating a web app with it. This might just be me, and I realize that their approach means you need both plots and data binding, but their data binding model seems secondary. With Shiny or Anvil, for example, most of the demos center around how to bind inputs / data on the front end to the server, and whether you produce a plot or print text is a separate topic. I haven't looked at it in a few months, though, and the documentation looks much more extensive (I think?), so I'll definitely have to check it out again.
Ok, that is a good start. But at what point do I go and investigate whether updating to the new major version is desirable or even necessary? 
God, nothing of this makes any sense. &gt; Assuming we would not have a function like len(), what would the method be called? Would it be called x.getLenght()? Or just .length()? Or would it be .size()? Why have it has a method, why not have a property instead called .length. Or .size. Or maybe .Count like in C#. So? And why is len() called len()? Why not size() or length() or getLength() or count() or even just make it an operator like sizeof from C
One way to mitigate this is to host Python modules yourself. Most companies I work for have downloaded the third-party Python packages they depend on and hosted them on their own repository server, then configured pip to pull from that server instead of PyPI. It at least prevents the problem of modules disappearing, which is practically an inevitability on any long-lived project.
&gt;A PHP programmer will not expect this:... &gt; &gt; &gt;&gt;&gt; a = [1, 2, 3] &gt; &gt;&gt;&gt; b = a &gt; &gt;&gt;&gt; a.append(4) &gt; &gt;&gt;&gt; b &gt; [1, 2, 3, 4] &gt; &gt;What's cheap in PHP is not even possible in Python unless you do a deep copy of that thing which can be slow. Huh... First, I'm pretty sure PHP does a shallow copy, not deep. Unless there are some structs shenanigans involved I'm not aware of. Second. `b = list(a)` 
it's probably because you named your file "pygame.py" and python tries to import that instead. Solution: don't give your python files names of modules/packages you want to import. **Edit: also, this belongs to /r/learnpython or /r/pygame**
I actually posted before reading the guidelines and did post there. I also was going off of advice for using 2.7 but I am sure that wasn't my issue. Thank you 
You're focused on the wrong aspect of the discussion. It doesn't matter what the standard name is, so long as there is a single standard. The function ``len`` could easily have been "size" or "count" and those would be just as good, so long as it was a function that corresponds to a special method. Just as ``+`` corresponds to ``__add__``, the operator-method pairing helps simplify the language. The benefit is to standardize the custom containers that you (and other non-core authors) create. Because of your experience with the built-ins and the standard library, you'll know to name your method ``__len__`` rather than "count" or "size" or "number_of_elements". You want to offer the same standard interface that every other collection does: ``len(container)``. [Guido explained his choice of ``len(obj)`` rather than ``obj.len()``](https://mail.python.org/pipermail/python-3000/2006-November/004643.html) on the Python mailing lists. TL;DR: (1) feels like it should be prefix notation, not postfix or infix; (2) always returns an integer, no surprises via accidental override.
Len(array) Len(list) Len(iterable) Len(string) Vs Array.size list.length iterable.length() string.Len() unless it happens to be Unicode then you want string.get_char_length( ) Make sense now?
Can you link the section you are reading? To my knowledge we do not have an FAQ Android.
Meh. It picks on Ruby for changing the meaning of some core functionality, while Python's upgrades are basically the poster-child for how to make a new language version backwards-incompatible. I'm not sure I've ever been bitten by Ruby's or Java's slight changes in semantics, but I certainly have by Python's. And I confess that while I like Python, I never found it to be terribly intuitive. There's lots of things that, on their own, seem to make no sense to me. Usually when I get stuck trying to figure out how to do something, I just ask myself what it would look like in Common Lisp, and then mentally convert that to Python syntax, since [Python seems pretty much like CL with spaces instead of parens](http://norvig.com/python-lisp.html). I know Guido is no big fan of Lisp, but it really does seem like a lot of Python design decisions make no sense except when seen as pretty-printed Lisp.
That is correct, his native language is German.
I decided to build my first web app today and I've been struggling which libraries I should go with, this post will help me a lot, thanks! 
1. This feels like a straw-man against interfaces in a general sense 2. I'd suggest **.shape**
&gt; Are you similarly astonished when min and sorted are able to work with objects they've never "seen" before via the &lt; operator? Yes. And to add to this, min()/sorted() do the wrong thing in certain instances!!! Imagine I have some kind of file backed list-like object where the list is a bunch of ints (or other comparable). 1. Does my object have an iterator? YES 2. Can you compare the elements in the iterator? YES 3. Is the correct way to compute the min, to walk in O(n) time the list comparing each to find the minimum? FUCK NO. The file is many many GB, this could take hours, but maybe the header record for the file contains vital statistics like min/max, in which case min(fileBackedList) should return fileBackedList.min, but it doesn't because min is stupid and always gets the iterator and walks. 
I'm not against interfaces. I would love to have interfaces, the problem is we don't have them.
&gt; Yes. Okay. Well I for one definitely disagree with you. I would *hate* to have to re-implement `min` for every class of comparable objects I made. &gt; min is stupid and always gets the iterator and walks. Sure, I can imagine that happening. A simpler example is that `min(range(1000000000))` takes way longer than it really has to. But the fix would be to make `min` invoke a magic `__min__` function, and fall back to using `&lt;` if that function doesn't exist, which doesn't seem like it has anything to do with your original complaint. Anyway, I suspect it hasn't been done simply because it almost never comes up. Can you point to a single instance of a workaround someone created that they wouldn't need to if `min` didn't necessarily walk the iterator? A single instance on all of github would be enough.
&gt; I would hate to have to re-implement min for every class of comparable objects I made. Well you wouldn't. You would just inherit from the "Array-ish" interface/class where the default "walk the list" implementation of min would be defined. You would optionally override that with a shortcut method where it is sensible to do so. By making min an exterior function that is completely precluded. A magic `__min__` would be in keeping with `__len__` but of course it doesn't exist. If it were added you eventually get to the point where lots of global namespace methods resolve to `__magic__` methods, all in the name of allowing "safe" duck-typing. Which really defeats the purpose of duck-typing. If I'm a duck who incorrectly defines a .len property/method (whatever is choosen), then I'm just a bad duck, and programs using me should crash. That is what duck typing is all about. Guido's argument is a halfway house, he wants duck-typing, but he isn't really committed to it/comfortable with it, so he only wants duck typing beyond a certain point, but not before. I think it is arbitrary and stupid. I'm sure you can find many classes where there is a min() method (or property) [I'm writing such a class right now that will get methods like that]. The point is that all those classes behave inconsistently. You call instance.min() instead of min(instance).
&gt; How should I get the dimensions of a matrix? that really depends on how you are representing the matrix, right? the simplest representation is a list of lists, in which case len() correctly returns the length of the outermost list, just as you would expect it to do for a list. if you have a more complex representation, like for example a user defined Matrix class, then the value returned by len(matrix) is defined by Matrix.\_\_len\_\_ exactly as the Python object data model specifies. That is not surprising at all.
If you have an array `$a` in PHP and copy it with `$b = $a`, that will construct a new array consisting of a copy of the values in `$a`, effectively making it a deep copy - unless `$a` contains explicit references or objects, which are always passed by reference. https://3v4l.org/5I7og Notice how `$v` is updated in both lists because it's a reference, but the new item in `$a` is not added anywhere, and the new item in `$c` is not added in `$b`.
/r/titlegore
&gt; I think it's possible to use a notebook on another machine through the browser Most basic (no security at all) is `jupyter notebook --ip='*'` then browse to your `&lt;ip address&gt;:8888`. But you're right that it's pretty miserable on a touch screen. A keyboard helps, but a mouse is also needed IMO. I know Android supports having a mouse and I've used Android + Jupyter + mouse/kb and it's tolerable, but I don't think iOS supports mice at present. Maybe the pen on the iPad Pro could work as a substitute?
&gt; If you have an array $a in PHP and copy it with $b = $a, that will construct a new array consisting of a copy of the values in $a, effectively making it a deep copy - unless $a contains explicit references or objects, which are always passed by reference. Isn't that the definition of a shallow copy?
Yes `len(matrix)` returns `matrix.__len__()` what is the question? I'm asking what `len(matrix)` should return? Matrices don't have length, they have rows and columns, and returning the number of rows for len is just as wrong as returning the number of columns. You end defining some kind of dim/shape function. Maybe it is dim(index) and returns the length of the index-th dimension similar to Matlab, or maybe it doesn't take arguments and returns a tuple. Everyone ends up picking something different because that is what they are used to and duck typing fails. You can't define a common matrix interface and have to wrap everyone's way of doing this. What `__len__` does is provides a way to establish a limited array like interface, but it leaves the core problem that python lacks any meaningful way to establish and enforce interfaces unfixed.
&gt; I'm sure you can find many classes where there is a min() method (or property) Yeah I'm sure you can, but that's not what I asked. The vast majority of those probably didn't need to be written at all. I asked if you can link to one that did need to be written, given the state of python's `min`, in order to achieve reasonable efficiency. And don't worry, I'm not trying to make you do a huge amount of work, scouring over many examples. Just one is all I ask!
All done in Bootstrap.
I would point you to my own code, but I can't as I don't have te rights to release it. But I work with a lot of large datasets and have proxy access classes that provide basic statistics on those datasets like min.
Python doesn't have interfaces. Why did you bring that up? In a dynamically-typed language, an interface is pretty worthless. An interface exists to define a relationship between a domain (parameters of given type) and a range (return type). Because Python is dynamically-typed, it can't force obedience to what a function accepts or returns.
Now I'm looking at what other functions I might have missed for sets or lists
&gt; that's true but that's how Python is designed so I'm not sure what the objection is I *think* the objection was to OP saying .length is "more astonishing" than len() in some way that is innate to existence. And I agree with that: both are completely arbitrary, and so OP is making an irrational argument.
Not really, because rather than remember the special "length" function for each object, you're required to remember what len(MyObject) *means* for a given object. Personally, I think the latter is harder. If I read len(SomeRandomObject) I don't know what that means. But if I read SomeRandomObject.range() I know what that means. It's all arbitrary. OP was making the argument that one is less arbitrary than the other, which is not true. That's the source of the criticism. Not that one is better than the other, but that OP is full of it by claiming one is better than the other.
Yeah I think he's confusing shallow copy with copy by reference.
If I tell you that "such and such a thing is finite" then I have told you exactly one property of this thing. Note the key word there: property. Length is a property of finite collections. We can disagree if it should be len or length or size, etc... but it is a property. It can be dynamically calculated, but it should be decorated as a property. It isn't some external function we call on objects.
Computableapp was perfect for this but you can no longer acquire it if you hadn't previously bought it/downloaded it. Pythonista is the closest thing now but isn't an ipython notebook unfortunately.
Yes, but everything is cleaner than those two.
If you're using Python 3.4, I'd also suggesting just using the `venv` module: `python3 -m venv ~/.venv/qtproject` Also if you wish this to be for complete newbies, it may be helpful to mention that they need to check that the `pip` they're executing is for the correct version of python they want. I guess specifically for these instructions it doesn't matter too much given you're passing the `-p` flag to `virtualenv` here. 
Just skim down Norvig's page and look at the similarities, which exist in practically no other languages. - Why are anonymous functions created with the word "lambda"? I know the theoretical reason behind it, but I can count on the fingers of one hand [the languages that actually use the word "lambda" for this](https://rosettacode.org/wiki/First-class_functions). - Same goes for map/filter/reduce. When everybody was adding functional programming features to their programming languages, the world basically split into "Lisp" and "Smalltalk" camps. Python is one of the very few that went with the Lisp names. When I need to remember what name Python uses, or what order it takes as the arguments, I just think of what Lisp does. (For example, Lisp: "reduce", function then sequence. Python: "reduce", function then iterable. C#: "Aggregate", on sequence, value then function.) - Why are parameter lists so complex in Python? Sure, it gives you flexibility, but the only language I've ever used that had so many features crammed in there was Common Lisp. Other languages don't seem to mind having much simpler destructuring. - Docstrings being simply the first string of a function (or module) is weird in Python. It makes sense in Lisp because definitions are themselves heterogeneous lists, and because docstrings can be applied to any definition (like variables and constants). In Python where it's just "a string literal in the first line (which is otherwise ignored)", and you can't use them for half the things you want to document, it's just weird. (It's doubly confusing because there's lots of things that come "first" and I always have to look up which one is first-est: module docstring? `__future__` imports? encoding?) Why not a comment (Java does this)? Why not a decorator? I don't know, but it's exactly the same as Lisp, and unlike any other language I've used. Maybe these are all obvious to every other Python programmer, and the problem is simply that I'm not Dutch enough. But having used 10+ languages for real shipping software projects, and seeing a whole lot of overlap between Python and Lisp, and not nearly as much overlap between Python and other languages, this is a remarkable set of coincidences.
Interesting. Couple of comments. He uses the following to see if it's 64 bit or 32 bit. Not sure if there is a better way to do it. if struct.calcsize("P") == 4: I absolutely hate AT&amp;T assembly syntax. I can never get away from it, even from comments it seems... Not a big deal, but it seems to me this isn't the best way to do set register eax to 1. XOR followed by INC takes 6 clock cycles and decreases readability. "\x31\xc0" # xor %eax,%eax "\x40" # inc %eax A simple MOV EAX,1 should take about 4 clock cycles and increase readability. I could be wrong on the clock cycles, but those are the clock cycles for 16 bit registers. So either way, a simple MOV should be faster.
And emojis. I like living dangerously, but this is a little too fast and dangerous for me. 
As others have said, /r/learnpython is a better forum for this type of question. To help you refine that though (since you need to know what to ask!) the two basic steps/tools you're dealing with: (1) getting data from the website -- you might look into the beautifulsoup package for this (2) doing the keyword searching -- this is a pretty low-level problem for natural-language processing (NLP), for which there are several tools. Looking into the capabilities for the NLTK or Textblob packages might be a good place to start. Anyway, hopefully that gives you somewhere to start for what questions to ask.
Maybe we should share code sometime. I've got a mess of ever-evolving Python scripts to check torrent contents and "direct-download trackers" (for lack of a name to call them).
&gt; The language has just as many warts as any other and much mystifying, magical syntax unique to it. I mean, I don't think anyone's disagreeing with that are they? 
Python has `__len__` and a handful of other methods. It doesn't have a generic way too define interfaces. Sure you can say that a class inherits from the abstract HasLen class but there is no advantage to doing that over just trying to access the len attribute, and so nobody does that. In other languages you can say that anyone who implements IHasLen must have a function that takes no arguments (other than the instance) and returns an int. Which is a meaningful contract that implementors can count on. Not only do instances of this interface have a thing called len, but it is a meaningful and recognizable length.
No, I understand that. But no matter how fast an XOR is, you still have the INC instruction to deal with. So the MOV will be faster than the XOR and INC even if XOR is the fastest instruction there is.
&gt;SomeRandomObject.range() What does that mean? I mean, length, as far as I'd guess, is the number of items in the box. Or in other words, I'd expect for i in range(len(X)): print(X[i]) to always work (this actually implies 1-dimensionality). Range sounds more like a slice of something, but is it? Size sounds multidimensional.
Ugh, I hate platform-dependent code.
Hacker real recognize hacker real. I love it when I know that someone can code a mitm proxy from scratch even though that's not the code I'm looking at.
Yeah, so if you assemble that code into a listing, it'll show you the actual machine code it translates to. Here is an example of two instructions. The first column is the line number. In this case it's 164. The second is the offset into the program. How many bytes into the program is xor eax,eax. The third column is the actual machine language. In this case it's hex 0x31C0. 163 0000011D 4D31C9 xor r9,r9 164 00000120 31C0 xor eax,eax
- If your code works on the old version, you don't need the new version - If your code *also* works on the new version, you should declare that in the range in `setup.py`.
Tell that to guido. Get rid of `__len__` and replace it with a len property.
One of the advantages of C++ is that you can go in and implement methods specific to your class. If you want std::map to do something smarter when the template argument type is yourObject, you can actually do that.
Those are some very good reads. Quote from the first: &gt; The best you can do is just a trust-on-first-use style mechanism where you require manual intervention if the key changes. Right. I'm thinking like the ssh system; you confirm on the first connection. If the key ever changes, you're warned &amp; have to manually fix the problem. I definitely see how the issue is complicated, and signatures aren't a panacea. But it seems like it would definitely give some layer of defense against some of these things.
Well, not without entirely rewriting std::map, or am I missing something?
&gt; What does that mean? Thank you for confirming for me that len() is ambiguous when taken out of context. Imagine SomeRandomObject were an object for which "range" means something. Let's say we're talking about electric cars. The .range property/function would return how far you can drive on a charge if you're calling a static function. Or on an instance, it maybe gives you the range remaining. But MyCar.length. What the hell does that mean? I posited this in another post in this discussion. Is it the number of seats? Number of wheels? Length from nose to tail? .length and len() make no sense.
Thank you kindly 
It's the raw opcodes. you can enter it [here](https://www.onlinedisassembler.com/odaweb/) to play around (as "32c0"
does "everything" include perl
That would suck and I don't think he should do that at all. Having len as a (first class) function is really convenient, as it means you can pass it to things such as map and sort. It is also important to separate len and every other property you define as it is a standardized one that is recognized by tons of libraries including the standard one.
Why use apt-get? Why not just `cat http://some.random.site | sudo sh`?
Follow up- is there any way for me to get a more gui type display rather than just the command prompt?
opcodes. That's what I was thinking of.
OK I see what you mean.
&gt; Python's upgrades are basically the poster-child for how to make a new language version backwards-incompatible. That's what a major version bump means, yes.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
To do your own "operators", you'd generally want to use [SingleDispatch](https://www.python.org/dev/peps/pep-0443/#rationale-and-goals) or some other "generic functions" system (MultiDispatch, Reg are the others that I know of that are still alive). Even if you *do* want a function operator, you still don't want it in the builtin namespace. You want something to work like pprint does, living in a module until you import it.
Yeah, they are called opcodes. I actually hate x86 opcodes. You can have two instructions that are the same, and the opcode will be different depending on what registers are used. I think it's a bad design. Mainframe assembly the opcodes are always the same for the same instruction. It's much better.
&gt; That car object should almost certainly not implement __len__ **That's what I've been saying**. I and the guy I was defending were responding to OP, which appears to argue that len() is a function that should operate on all objects, and that this is *not astonishing* according to OP.
Seems like a lot of folks here have used assembly quite a bit (I realize that this is probably no coincidence). Just curious, how and where did you learn assembly? 
It's a required class at my University. We used MIPS specifically. 
Yup, the comments are assembly, but the code isn't.
Most CS students learn it as a requirement. At least they would learn some form of assembly, if not the x86 assembly.
MIPS!
http://stackoverflow.com/questions/5993326/relative-performance-of-x86-inc-vs-add-instruction &gt;Do note that xor eax, eax; inc eax is favoured over mov eax, 1 by most compilers, though. May be due to the fact that it's 3 bytes rather than 5. Well, there's why. I'm not sure why compilers favor this, but seems they do. Maybe they happen in parallel with surrounding instructions, or some sort of intel processor feature might optimize execution of this better or something. It's never as cut and dry as clock cycles these days. But if I were a betting man, I'd put money on the compiler. And [he says the xor doesn't even cost anything](https://www.reddit.com/r/Python/comments/4bu3i5/there_is_inline_assembly_in_this_python_script_%E0%B2%A0%E0%B2%A0/d1cizjb)
Learned MIPS at Uni, learned x86/64 on my own, and did quite a bit of reverse engineering of iOS, OSX and linux SOs at one job. Really fun stuff. It's rarely useful in software development these days seeing as the compiler will kick your ass at almost everything, but if you know something about the nature of your problem and how your processor might accomplish that in a very efficient way that the compiler wouldn't ever use, then you can write that function in ASM and eek a bit more performance out. One example might be use of SIMD instructions in some sort of matrix arithmetic. You can have it add 8 32 bit ints with 8 other 32 bit ints in one go with a packed add and 256 bit floating point registers like an i7 has. Hell, most of what I write is Python. Performance doesn't matter as much as code correctness and maintainability for what I do for the most part. And even if I needed the best performance out of something, I'd use C or C++ or Rust. Compilers and how they optimize stuff is so complicated these days, and I'm not going to pretend I can do a better job than gcc or clang. I've never been in a position where C++ was too slow for my use case. I'm rarely in the position where Python is either... just throw more Amazon EC2 instances at it :)
Likely code size to reduce cache misses. 
Hmm ok. So the code checks if it's 32- or 64-bit, but it's assuming x86 then? This code couldn't run on a Power chip?
But inc isn't faster than constant mov, so they are likely the same. 
Haha, obviously no.
 from copy import copy b = copy(a) You *could* do a very similar thing with b = a[:] or b = list(a), but those have 2 problems. 1) They're not as readable. The programmers intent (to make a copy of an object) is not readily visible in the code, whereas it is in copy(a). 2) list(a) assumes that a is a list. a[:] assumes that it is indexable. These *may* be the case of what you want, but what if you later change it so that a is taken from the parameters of a function call? Will it work with numpy arrays? Sets? Dictionaries?
&gt; The language has just as many warts as any other and much mystifying, magical syntax unique to it. Have you ever used perl? Of the major programming languages (C, java, javascript, php, etc.), python is by a very wide margin less mystifying with less magical unique syntax. There's a few weird things (lists are objects and not arrays--most languages use arrays), which leads to some weird behavior (such as a = [1, 2, 3] b = a b.append(4) print(a) returning "[1, 2, 3, 4]".) But of all the languages I know, python is by a very wide margin the easiest to read for people who don't know that language. 90% of the time the python code itself is the same as the pseudo-code that I would write to explain an algorithm to someone else. Also keep in mind that most of python's popularity comes from people who used to work with perl. Anybody who has worked with perl will easily see the readability difference with python and it's lack of "mystifying, magical syntax". And one of the primary reasons they switched is *because* of those similar issues.
1 Premature optimization is the root of all evil. 2 The needs for an optimized min() function are rare. 3 *If* you need an optimized min() function, you can always write your own. Call it "fast_min()" or something. The fact that the min() function is automatically written for you just by having a LT operator defined is a good thing. You don't *have* to use the default method of doing things *if* there's some need that speed is more important than readability.
no... That's not bytecode. These are the opcodes.
They may have the same execution time, but the instruction size is different. See the assembler output for x86/x86_64: XOR eax, eax -&gt; 0x31C0 ; 2 bytes INC eax -&gt; 0x40 ; 1 byte ; MOV eax, 1 -&gt; 0xB801000000 ; 5 bytes If the instructions consume the same amount of cycles, a smaller instruction size will generally be faster. EDIT: Apparently though, [INC creates false dependency chains](http://stackoverflow.com/questions/19890157/gcc-doesnt-make-use-of-inc) so the second version will perform better.
&gt;Something that comes up incredible often is why Python has a len() function instead of a .length or .size property or method on the object. And by giving that question we already pretty much got the answer. Assuming we would not have a function like len(), what would the method be called? Would it be called x.getLenght()? Or just .length()? Or would it be .size()? Why have it has a method, why not have a property instead called .length. Or .size. Or maybe .Count like in C#. This is a terrible argument. Why is it not `size()` or `count()` in Python, by the same token? The best reason to have `len()` as an unbound function, in my view, is that it provides a spot for enforced (run-time) type checking. That is, we have `len()` for the same reason that we have `iter()`: because *it does more work* than the method that the protocol relies on. &gt;Pass by â€¦ What Exactly? ... It's the same as in Ruby, and except for a finite set of built-in exceptions, the same as in Java. Of course, Java also doesn't give you that nice swapping idiom. Oh well. &gt;Decorators are somewhat of a pain because there is a difference between @foo and @foo(). Agreed. I have additional complaints about decorators - the fact that you're expected to write these ugly nested constructs (and in the parameterized case, you might be tempted to resort to a class that has only `__init__` and `__call__` methods - yecch!), and the fact that generalized decorators tend to lose the original signatures (they get "erased" when you're forced to use `(*args, **kwargs)` to handle arbitrary cases). I'm currently working on some deep magic to address these issues :)
&gt; is perfectly valid. Except that now `len(stupid())` will raise an exception. &gt;we don't have a way to access a collection like objects size as a property of the collection WHICH IS WHAT LENGTH IS!!! I don't think "property" means the same thing to you that it does to GvR.
Learned it at uni and then I worked in an HPC facility for a few years. There's still a lot of assembly thrown around, either due to custom hardware or for optimizing low-level I/O tasks.
I would prefer if it were *possible* to write a custom `__min__` and have it used by `min`, and have `min` default to the existing logic when it didn't find that magic method. Same for the other builtin reduction methods (`__max__`, `__any__`, `__all__`, `__sum__`).
&gt;&gt; It is writing the value directly to the heap (memory) and then attempts to call it as a function. &gt; It looks like it is a Return-oriented programming(ROP) exploit. But... the entire purpose of ROP is to *avoid* having to write machine code to heap memory and then calling it.
Only the instructions are opcodes, collectively all the bytes (inc. data) are machine code.
Z80 and 6502 when I was about 13 ... back in the early 80s.
&gt; So the copyright notices - can I take them out? No. Read the excerpt above. 
I don't see why that is relevant. No difference between generic code that calls through an "interface" like `__len__` and one that just duck types it's way into the len property. You can write either way and both will succeed and fail in the same ways.
I can't answer a lot of your questions - however to make selenium a little bit lighter you can use ghost driver (I use chrome driver when I need to watch it and swap to ghost when script has been finalized). I generally use Requests and Beautifulsoup because I haven't had the time to learn how to use scrapy properly - which results in me having to create my own pseudo-spider with Requests. 
Why would you limit yourself to only half the keyboard?
* If your code doesn't work on the new version, fix that if it's reasonably practical. Otherwise you end up in NodeJS-land, where a project might have several thousand dependencies, of which one is duplicated fifty times across sixteen versions. This has happened to me at work lately, and IT SUCKS.
Why does something with len have to implement random access getters? Where is that stated? Where is that enforced. You can have an object that responds to len, but isn't iterable, and cannot be accessed by random getitem, etc...
Pythonistas know that the language isn't pure and it doesn't stop you from writing bad code in any way, but it does *facilitate* clean code without forcing your hand towards it. That is why we seem obsessed. You can write beautiful code in Python, but only if you know how. So we make sure to explain how. 
I have a feeling that you came to Python from a more Java/C#-esque OO language and you haven't quite given up those habits...
Does it pain you that much to use a free function mixed with methods? Are you one of those people who sharpens all of their pencils at once to make sure they're all of the same length?
That gives you a generator expression. You can then pass it to the `tuple` class. &gt;&gt;&gt; old_tuple = (u'foo', u'bar', u'baz') &gt;&gt;&gt; new_tuple = tuple(x.encode('utf-8') for x in old_tuple) &gt;&gt;&gt; new_tuple ('foo', 'bar', 'baz')
That's cool, ARM is actually used quite a bit these days. I did a little bit with MIPS assembly in school.
Yep, that's how I expect most people to know assembly but many responses here give me the impression that these folks have a deeper knowledge of it than I do - I did a bit with MIPS assembly in school but I don't remember any of it, it was a while ago.
Yes, yes it is. It is very pythonic and I especially love how you can use standard Python operators (==, &gt;, or, etc) for queries Source: using it in a project currently
What's more amazing is how they overloaded nearly all the operators so that it can do what they want it to do. 
I don't really get what people mean by came to a language from a particular community. I've worked in dozens of languages, and they all have pluses and minuses. Would I like to have a strong typing and interface resolution the way C++ does, sometimes. Do I want duck typing and the ease of development that provides at others, yes. The complaint I have is that python is inconsistent. Everything is duck typed except for len/min/max. (I don't mind so much iter because I seldom call it directly, it gets sugared in to a for loop, and iter(object) looks a bit like constructing an iterator from the object which is a reasonable interpretation.) If the concern is: "we don't want people inadvertently defining a length property and confusing subsequent code as to what the object is" well that is just a rejection of duck typing. My doctor class implements a quack method and that is entirely appropriate for the doctor class, and no it does not mean that it is a duck.
GCC compiler with -O2 option. movl $1, %eax So no, GCC doesn't prefer xor eax,eax; inc eax. It prefers a simple mov.
Django has its own ORM. SQLalchemy is more commonly used with flask.
IMO, pyquery (which is built upon lxml, a very slightly faster version of beautiful soup). If you need javascript to be executed on the page in order to read it though, use selenium. I tried scrapy and did not like it.
Ahhh I got confused, I was reading docs for both SqlAlchemy and Django and didn't know why they looked a little different. Would you say that SQLAlchemy is better than Django's default ORM?
That's great to hear--I'll definitely have to give it another look! Seeing the documentation again really peeked my interest..
MS Paint.
It's not ROP at all.
Overloading operators is awesome. It's intuitive, well, at least when it's not intrusive.
I would. SQA acts more like a library. You yell at SQA, "hey, give me some data" via a session object which takes parameters. With django, everything is so ubiquitous, you can end up with db calls where you least expect. i.e. def f(): return SomeModel.objects.get(id=1) def g(): for a in f().giant_collection: print a.id Madness! 
&gt; In a language with classes and @property decorators, we don't have a way to access a collection like objects size as a property of the collection WHICH IS WHAT LENGTH IS There's two things contributing to this. First, `len` as a function predates abstract base classes and properties by quite a long time - properties came somewhere in the early 2.x series; ABCs in 2.6; `len` almost certainly dates from pre-1.0. But the major reason it didn't change in 3.0 (when breaking compatibility was briefly not an automatic wontfix) is because Guido has directly said that he feels `len`, `min`, and `max` read better as prefix operators than postfix. You can disagree with that all you like, but it *is* a reason. There *is* a de-facto convention for multidimensional arrays, that's basically analogous to the sequence protocol - it's called "array like", as in "behave like a numpy array". Numpy's utility functions all take any array like where you would normally give them an array, and one of those happens to be called `np.shape`. 
That's interesting and I looked into it a bit. The reason, apparently, is that INC &amp; DEC [update the flag register partially](http://stackoverflow.com/questions/19890157/gcc-doesnt-make-use-of-inc) which means they will create unnecessary dependency chains, unlike ADD/SUB and MOV instructions. So it seems that while `XOR eax, eax` is still preferred by compilers for zeroing a register, that's not the case for setting it to 1. I think that's just one more example of how extremely hard it is to theoretically predict a modern processor's performance.
Yes it's very good. I also like pyDAL very much, as it's not an ORM at all it's a simple abstraction layer. https://github.com/web2py/pydal People have a lot of hate for web2py in this sub, but seriously PyDAL is really good.
If you're planning to access an existing database, then Django's ORM is out of question, go with SQLAlchemy. Otherwise, it's mostly a matter of preference; SQLAlchemy is probably more sophisticated and complex queries are easier to model. Django's ORM is tightly integrated with the framework, which is convenient as the DB is almost hidden from you. Both can be good choices depending on what you're trying to do.
If you open your command prompt in the folder, then you don't have to type in the full path, just "python myfile.py" To do that, on Windows 10 at least you can open the folder in Explorer and just type "cmd" in the bar with the folder path. Or there's a menu option somewhere in the upper left like "open command prompt here". Or you could make a bat file that just runs your script (make sure to add PAUSE at the end so it doesn't close right away) As for why it isn't importing the other modules, I'm not sure. Problem could be in your code and not in how you are invoking python. 
I posted both ~ for small snippets I appreciate the colors.
&gt; If you're planning to access an existing database, then Django's ORM is out of question, go with SQLAlchemy. This isn't strictly true, Django has the ability to inspect the database and create models. Mileage may vary so depending on how complex the current structure is will determine if Django is actually helpful. 
I have a friend who just ported a bunch of code from PHP to Flask+SQLalchemy and he says it's nothing short of bliss.
Sorry and thank you, I will keep this in mind.
Actually, I just had a look at Alembic and that looks pretty amazing too...It's like Git for your database. Edit: Flask-migrate is Alembic. Makes sense.
I have some "magic numbers" in one module I developed that are specific to linux ( ioctls ) so I import platform and error out if it's not what I expect. import platform if platform.system() == "Linux" and platform.machine() == "x86_64": # ... code here else: raise Exception("I can't deal with this platform") 
Had you just needed across the network I would say Woof
That's what semantic versioning is for, but that doesn't mean people follow it. It's recommended, even if you're not perfect (god knows I'm not). My company is constantly fighting issues of package A we create requires a dev version of package B, but developer C doesn't update frequently enough because then their code breaks. http://semver.org/ Shoot, Python regularly breaks compatibility on minor versions of Python or rather fixes blatant bugs such that not all new code works in old versions of say Python 2.7 (e.g. `struct.Struct(...)` requires a `str` in Python 2.7.6, but allows `unicode` in Python 2.7.7 to be consistent with Python 3; `six` should handle that with the `bytes` method, but doesn't if you have `from __future__ import unicode literals` like you're supposed to) or having undocumented changes from 2.6 to 2.7 because they're so minor (`float(1.023D+0.5)` works in Python 2.6, but not Python 2.7). They're going to bite some people.
This is the correct answer. To those wondering why, the instructions are represented as string data, NativeFunction() calls len() on this data, and then passes the result to VirtualAlloc() to allocate a buffer to copy the instruction data and execute it. If there were null bytes midstring in the instructions it'd compute an incorrect length for the instruction data and allocate too little space. 
The professor used to work for Motorola back in the day and did a lot of assembly stuff there I guess. She refers (present tense) to MIPS as the "Cadillac" of assembly languages. She is a nice lady, but her teaching methods are just trash.
I think there is bittorrent sync now too. I was hoping there was something out there, or that I could build myself with other libraries.
Not trying to hijack this or anything like that but I know the pain of installing pygame. Kivy should have pygame as a dependency and is as easy to install as it gets. It might work maybe
The issue arises that everyone has to remember to do that and keep track of when another source of data hasn't done it.
Well naw, because when I just run the python file it executes fine. It's only when I run it with CMD that it doesnt work because of the module.
The ORM gives you a tool to be used within human run coding standards. An emergency, or negligence, or sometimes missing something somewhere in a far-away call, causes these situations to arise. It's not that the django orm is bad or anything like that. It requires more attention to get right. It's the same situation w/ RoR's callback infrastructure.
What do you mean "just run the python file"? How are you running it when it works? Also, what isn't working when you run it with CMD? Are you getting an ImportError where it can't find your module? 
Would that require opening ports on on a firewall? I would like something that could be used by less tech savvy people.
This is how I understood it. I have a few packages I've written on PyPi but I've never tried to remove them, and didn't even know I could to be honest. I kind of figured once you toss a version up there it's the worlds now and you can't remove it.
Just remember.. ORMs look really magical until they aren't! If you are lucky your ORM has a backdoor to get out of it (which SQLAlchemy does really well).. Sometimes you end up getting rid of ALL of your ORM code, in which case you will end up really made you ever used an ORM. Totally depends what the goal of your code is ;)
Gotcha, I totally understand it now, thanks much. I didn't understand that the bottom lines are calling the function and then putting the values of 4, 5, and 6 into answer. I also didn't know that subreddit learningpython/programming existed, so thanks!
We call it ``Sized``. https://docs.python.org/3/library/collections.abc.html#collections-abstract-base-classes
You can, I just can't think of any where that's the case. And I can't find any either.
This isn't C: `len()` doesn't stop at null bytes. Python strings are stored as length + string data, so embedded null bytes don't have any negative effect.
You can parse the command output
Looks like it isn't an official conda package and someone has just added it to their account. They apparently didn't upload a win64 build, something that is important for conda (I've spent the last several days doing nothing but working with conda build). I would recommend looking at the output of pip -h for the flag that disables wheel installs (might have something about binary in it, I can't remember off the top of my head), and seeing what you can get done that way. Alternately, you can go grab the source from wherever the author keeps it, probably github, and install it by running python setup.py install. 
nope. im not sure if there's a simple way to delete an entire package, but there's definitely a link to remove individual versions. 
To not answer your question, but since you said you're new to python, you might also be new to the web programming world. so I want to ask if you have searched for public APIs for the sites that you want to scrape. or rather, do you know what a public API is? Not to be insulting at all. I just wanted to make sure this isnt a case of the XY problem
Yep https://xkcd.com/353/
I disagree - By attending the talk at a conference you open up the ability to engage with the presenter immediately after their talk, can participate in active discussion on social media during and after the presentation (which typically evaporates well before the video is posted) and you can get a head start on blogging about the topics which can translate to real profit.
&gt; 2) list(a) assumes that a is a list Not necessarily. It just assumes that ``a`` is iterable. This can for example, convert a generator object to a list with the effect of exhausting the generator. &gt;&gt;&gt; def myiter(): ... yield 1 ... yield 2 ... &gt;&gt;&gt; list(myiter()) [1, 2] Strings are also iterable! &gt;&gt;&gt; list('abc') ['a', 'b', 'c'] But yeah... ``list()`` can cause some strange things to happen in your code if you are not aware of what you're passing to it.
i suggest using flask with sqlalchemy. fits like a fist in the eye. 
I don't know if I could have said something more cringey if I had tried.
Have you had any luck with it?
&gt; caching packages you rely on Absolutely. The best way I've found for this is to use wheels when installing virtualenvs. Acts as a built in cache... export WHEELHOUSE=/path/to/wheels export PIP_FIND_LINKS=$WHEELHOUSE export PIP_WHEEL_DIR=$WHEELHOUSE # Build and save everything as wheels pip wheel -r requirements.txt ls $WHEELHOUSE # Later, same env vars, no network required pip install --no-index -r requirements.txt 
It's super easy if you use homebrew. brew install homebrew/python/pygame
Definitely going to look into Django's ORM a bit more. Seems to be a similar philosophy to SQLAlchemy.
Both are trying to be pythonic and both are highly rated. Main difference is SQLALchemy is library (for use with any python code) while Django is a fat framework (the ORM integrates/combines with many other features).
thanks, that's a reasonable idea
If you don't want to open ports, you have a limited number of options. UPnP if both routers support it and something like [UDP hole punching](http://superuser.com/questions/617263/what-is-the-difference-between-udp-hole-punching-and-upnp) for more widespread support. It's not going to be easy.
Lol.... No, Woof is a real file command line to browser file transfer Python program. 
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Nice library, solid implementation and definitely useful. It uses sqlite3 internally. 
I've never used selenium, but I like splinter which is based on selenium
It's awesome ;)
You can remove projects completely from PyPi. I've done this before but usually my packages aren't used by anyone else, or if they were I'd definitely not remove them. There are valid reasons for wanting to remove a package. Like mistakes in naming or accidentally uploading personal stuff. Maybe there should be another hoop to go through to delete packages that are known dependencies to other packages. 
Thanks for the input, I've updated the post accordingly!
I'd go one step further and clone the source repos of your dependent packages into your own private repo. This way, should you ever need to patch any of the packages, you can DIY, and turn things around quickly.
Perhaps a PEP!
That makes it sound horrible.
"You can watch them online. If anyone is going to a conference just for the talks you're wasting your money." In theory, this is true, but in practice I found that I am never able to watch all the talks that I want to watch if I miss a Pycon, and those that I do watch are during an evening when I am tried from a day's work or over a weekend where many other distractions/temptations abound. I actually see and get more out of talks if I am actually there. 
&gt; by_length = dict() &gt; for word in valid_words: &gt; by_length.setdefault(len(word), set()).add(word) I love defaultdict for stuff like this from collections import defaultdict by_length = defaultdict(set) for word in valid_words: by_length[len(word)].add(word) 
You can also be smart about it and write what are essentially SQLA queries, just using the magic `Model.query` property instead of managing the lifetime of the session yourself. I will admit there's part of the Flask extension I don't like (`get_or_404` -- that's madness to me!) which is why I was happy to see my PR for custom base models go in, which brings it more in line with your declarative_base. 
Just don't depend on https://pypi.python.org/pypi/left-pad ;-)
Sorry, I meant to say that list(a) forces b to be a list. Which might not be desirable if someone else calls your function and expects the return to be list-like and not a list.
Anyone have thoughts on how peewee stacks up against SQL Alchemy? I have used it in the past and would be open to moving to another ORM if there are distinct use cases or features that make it preferred 
Actually one of the developers made a comment on the exact same thing and said that it does use pygame but they plan on removing it from "under the hood"
I find SQLAlchemy to be incredibly over-complicated and I'm a bit relieved to be working at a job now that doesn't use it. It's a cool example of what is possible (the name Alchemy is appropriate), but making extensive use of it in a real project leads to more pain than happiness, in my opinion. Software engineering should not be like alchemy. An unnavigable stack trace should tell you that you're not in zen-of-Python land anymore. I more prefer an ORM like Django's. It doesn't pretend to be sophisticated. It makes easy-but-tedious tasks much more streamlined, and when things get more complex, you just use raw SQL and skip the translation layer. I like that approach. Being DB-vendor-independent is a pointless fantasy for most projects anyway.
I thought this said [Firebased](https://www.firebase.com/) and was very curious.
Unless you're punching someone you don't like. Horrible for them, great for you.
Yes. First, understand what clicking the link is doing. 
`pip install requests`
Was this generated by a Markov chain?
http://scrapy.org/
I just told you what to add... 
SQLite provides [isolation](https://www.sqlite.org/isolation.html) between separate database connections. DiskCache maintains separate connections per-thread (and per-process). Each thread that uses a cache object is responsible for closing the cache connection (file handle).
You should however only do this in case of emergency. I've known projects that got stuck in maintenance hell because the original programmers were way to prone to patch their dependencies to suit their needs.
You can maintain your own local copy of PyPI, or at least of the packages you need from it. You also can and probably should be using pip 8+ with package hashes in your requirements files, verifying the hashes prior to putting them in the requirements file, and pinning those requirements to the exact versions you intend to use (i.e., instead of "Django&gt;=1.9", do "Django==1.9.4"; this means you do have to change it when there's a new release, but also means that if someone took over the package name they wouldn't be able to silently install possibly-malicious code simply by pushing a higher-version-number package to PyPI).
To be honest, nom's dependency management mechanism is better then pip now since each package can has it's own version of dependency. But the node community has a mania of npm install which I think is an abuse of dependency management. In theory, if a package like requests or Flask has a big change, other software depends on them could be broken without any doubt. But this just didn't happen, aha!
xpath made my head hurt at first, but it's another thing totally worth figuring out.
I don't have too much programming experience. Usually if I need something I do research and kind of piece by piece small projects together to get what I do need done. I would be willing to learn on my own if its something thats not going to need expert level knowledge of python. Thank you, I'll jump on over the /r/learnpython. :)
&gt; this is not the correct subreddit for questions or hiring. Perhaps /r/SomebodyMakeThis would suffice?
have you tried lmdb ? See benchmarks: http://symas.com/mdb/#bench
And I do disagree with guido.
These particular abcs are very un-pythonish. If you want to know if a class qualifies as Sized you don't `isinstance(x,Sized)` you simply `len(x)`. And from the perspective of the author of a class he does not explicitly state that his class implements Sized he just implements `__len__`. Which is probably why you don't see them in use very often. However I am less concerned about these abcs than I am about the challenge of writing other abcs. Python doesn't emphasis interfaces and so if you want am interface for something more complicated (like a multicollection) you can't really rely on people looking at the ABC you might define for it, nor can you "add" additional double underscore interfaces without polluting the global namespace. 
https://en.wikipedia.org/w/api.php?action=query&amp;titles=Main%20Page&amp;prop=revisions&amp;rvprop=content&amp;format=json
Somehow instead of repo = Stub('repo') calling(repo.get_page).passing(2).returns(next_page) I'd still rather have class Stub: def get_page(self, page): if page == 2: return next_page else: raise RuntimeError('Unexpected page: %s' % 2) repo = Stub() A handwritten stub has more clarity and it's more easy to debug. You can argue that those aren't good reasons but consider these two practical issues: * No support for stubbing operators or anything weird (eg: special methods) * The stub object still works like a mock - it returns sub-objects on attribute access - the same hard-to-debug-and-confusing-problem the `mock` library has. I'd expect an AttributeError. I guess `tdubs` is fine for testing simplistic code but it's still the same as `mock` wrt loose attribute access. 
Maybe not with the pulling from twitter but this may make putting stuff on a map easier, if you can handle just using matplotlib for the graphs instead, it depends on what your after. [here](https://github.com/murphy214/berrl) 
I take property to mean the same thing that the @property decorator says it is. I think everyone agrees on what a property of an object is. I don't really understand that comment at all.
Different perspective here: I'm an EE and had to learn MC86HC11 (Motorola) assembly for a microcontrollers course. I love the shit out of it, but these guys here are leagues deeper in this stuff!
robobrowser is what you are looking for! It combines almost all the necessary modules and has an inbuilt browser that can run headless and combines beautifully requests module with BeautifulSoup. Tried once. Never went back! 
Just because you are root doesn't mean you should not prepend sudo for administrative tasks! Juuuust to be sure. ðŸ˜ Edit. Damn wanted to answer synae. 
Very possible, but the Python standard library is diverse enough that I think we're less prone to it than the js community. 
Don't look to Skype for a good example of how to do anything. It started off mediocre and quickly nosedived into a shithouse where it has since been digging out new depths into which it can sink.
A *k* letter password from an *n* letter alphabet has a brute-force search space of size *n^k*. Dividing the alphabet size by two results in a search space of size *n^(k)/2^k*. For an eight-letter password that's 256 times smaller. With *n=26* letters that's about 208 billion versus 815 million. Of course the attacker would have to know about it in order to exploit it.
I just skimmed over "automate the boring stuff with python" and there's a section dealing with pdf documents.
Yeah, there's definitely a strong case for rolling your own test doubles. I don't think any library will compare if that's your preferred style. The loose attribute access in `mock` has never been a problem for me. It might be if I had branching logic that depended on an attribute value (e.g. `something.is_valid`), but in those cases I prefer a method (`something.is_valid()`).
Sounds like you could make that into a sport.
Thank for your answer i willing to put as much time needed im dedicated so thats not an issue is this "one man job" so i can make this happen all alone and what a bout the messages Users send how they are stored. 
Show us the code 
You just described the CORE FUCKING CONCEPT of Python's duck typing.
https://kivy.org/docs/faq.html#android-faq Not sure whether they talk about the android device or the programm itself I'm pretty new to this so I'm sorry if I confused someone
I personally think it's a decent middle ground for practicality, but I do totally see where you are coming from. You get some interface magic methods for things that show up a lot and that python builtins might need to use, but then duck typing for everything else.
Holy shit this is awesome!!
Im sorry. Im just literally clueless as to what Im doing on this thing. Im only getting by by what tutors have been teaching me. I would have never gotten this far without them hence why Im failing this class. I really have no idea what I am doing here.
That's the entire point of duck typing... A list is list-like. If you want something that looks like a list but isn't a list, you don't want something that looks like a list.
##Are you using the proper version? It took me a while to find it, but to install the current version use: pip install --upgrade google-api-python-client or [download this](https://pypi.python.org/pypi/google-api-python-client/) and run: python setup.py install ##Uploading the video [this](https://developers.google.com/resources/api-libraries/documentation/youtube/v3/python/latest/youtube_v3.videos.html#insert) is the relevant part of the documentation for uploading a video The [sample code](https://github.com/youtube/api-samples/blob/master/python/upload_video.py) seems fairly straight forward, although, as you said, needs to be changed slightly to work with python 3 So there is really only one thing I can see going wrong: * There is no [client_secrets.json](https://developers.google.com/api-client-library/python/guide/aaa_client_secrets) file There doesn't appear to be a help command so the syntax is: python upload_video.py --file PATH --title string --description string --category integer --keywords string,string... --privacyStatus (public, private, unlisted) and only the file parameter is required Edit: removed line highlighting from github link
If the standard library consistently uses `.len`, then so will authors. It is not any different than the admonishment to use `__len__.` You just say that collection types should have a len property and hope that people listen. If someone chooses to implement `.size` instead then it is no different than someone choosing not to implement `__len__`.
The secret to being able to use Google APIs is to work exclusively from the generated PyDocs. I've had to integrate with a couple of Google services, and the pydocs are always more clear and up to date than the long form, pretty documentation. I'm not sure if there's a place you can consistently find the pydoc for the API you're working with, but a simple Google search for "X API pydoc" works 90% of the time. This is the pydoc for the YouTube API, hope it helps! https://developers.google.com/resources/api-libraries/documentation/youtube/v3/python/latest/
Python (3.5.1, haven't checked older versions) uses one process per CPU as the default for ProcessPoolExecutor and and 5 threads per CPU as the default for ThreadPoolExecutor. But as other have mentioned here - the optimum depends heavily on what code you are running, so benchmark and decide.
I didn't want to take a dependency outside the Python standard library so I chose SQLite 3. But I think the performance of LMDB is amazing. It's certainly worth investigating for those who need more performance.
Why not use pip? Sounds like an issue with the Python environment, not the code.
I had to check and make sure that today wasn't April 1. Then I went back and read it again[.](https://www.python.org/dev/peps/pep-3117/#rejection)
Not today ... but look at the date on which it was submitted.
&gt; Additionally, it eliminates the need for a separate type declaration statement, and last but not least, it makes Python measure up to Perl 6, which already uses Unicode for its operators. [2] &gt; &gt; ... &gt; &gt; [2] Well, it would, if there was a Perl 6. &gt; &gt; ... &gt; &gt; which enables Unicode parsing of the source [4] , &gt; &gt; ... &gt; &gt; [4] The encoding in which the code is written is read from a standard coding cookie. There will also be an autodetection mechanism, invoked by from `__future__ import encoding_hell`. Perfect.
&gt; Created: 01-Apr-2007 &gt; 01-Apr-2007 &gt; 01-Apr Nuff said.
youtube-dl just scrapes the website. OP might want to go down that route if the API is too shit. (Though that does have risks of it's not technically allowed)
It's an implementation choice that vastly simplifies the CPython internals and has very little overhead for single-threaded programs, which are the vast majority. Any potential candidate that would replace it has a high bar to clear. Turning a single lock into multiple smaller and more granular locks has been tried, and it resulted in a performance loss for single-threaded code. And for the record, a global local is not at all uncommon. Most implementations of dynamic scripting languages, if they support threading in any meaningful way, use a GIL (e.g. Ruby.) Also, many people don't actually understand the GIL. A common misconception is that it means you can't use multiple cores. That's false; it depends entirely on your workload. If your workload is IO bound then it will be able to scale across cores because all the functions that block waiting for IO release the GIL. Similarly, modules like Numpy can do CPU bound tasks across multiple threads because it can work at the C level. The problem scenario is when you have something that's CPU bound *and* written in pure Python.
I'm trying to understand your perspective. On one hand you criticize duck-typing and state a preference for interface enforcement such as ABCs. On the other, you recognize that duck-typing via special methods is a Pythonic flavor of interfaces. When it comes to other people (including yourself some days or months later) using your custom classes, ABCs are just one of your tools to help manage the complexity of inheritance. If you'd like something more similar to the dunder methods (eg. ``__name__``), you could easily make your own pattern. One option is looking for sunder methods/attributes (eg. ``_name_``). I've stumbled across a few libraries taking that approach. There's also the common prefix technique, such as ``unittest.TestCase`` introspecting for any method name that starts with ``test_``. As for people looking for what you create... there's no guarantees no matter what technique or language you use. Python has as good tools as any language for creating pleasant documentation and examples.
Try posting in /r/learnpython. 
thanks :D 
&gt; you could have run your threads on a single core with exactly the same effect Not without completely rewriting your code (including any libraries that you use) to use asynchronous IO. That's what threading brings to the table â€” the ability to write synchronous code. 
May be a joke, but I like it.
I lost it at InquisitionError
That doesn't inherit from `ExpectedException`.
haha `frozenset â˜ƒ (SNOWMAN)`
I think YouTube changes the pages up a little every so often in attempt to prevent this type of thing. It just means that it could break randomly until the youtube-dl is fixed and updated. 
Yep, an API would be more datable, but you would need to agree to the API terms of service. There's no actual rule that I can see that forbids screen scraping using the website (in the tos of the website).
When compiler coders get bored. They get really bored.
A 4x speed up could change my server costs from $1000 to $250 a month. Edit. I know I know. I should switch to pypi or something 
&gt; when you have something that's CPU bound and written in pure Python Then you write some of it in C.
It's way easier to just spawn an entirely separate process for each core then use something else to redirect the requests. A 1:1 map between python processes and nginx workers should do you nicely :)
&gt; ... the CPython dev team would prefer to keep the codebase simple. It not only simplifies the cpython code base - the simple GIL model keeps C extension modules much simpler, too. This also applies for the choice of reference counting vs. tracing garbage collectors - it keeps C extensions (and the debugging of C extensions) much simpler. The vast library of extension modules is one of the most important things in making the Python ecosystem so vibrant.
That's still not an issue, at least assuming you're processing multiple requests at once (and if you don't have that much load, you're **really** being overcharged with those costs). Like I said, such tasks are embarassingly paralell, and thus trivially amenable to using processes instead of threads, which isn't going to involve the GIL. You'd have an issue if there's *communication* between your processes (eg. HPC, or a game *client*), but for typical server-side stuff it's not really an issue.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
&gt; In a language that uses dynamic typing or that is untyped, the decorations that refer to types cease to be redundant.
For fucks sake absolutely no one give a shit about your politics.
Yes, using it in a strongly typed language is redundant, but it is useful in languages with dynamic typing if you want to know what type a variable is. Hungarian notation *shouldn't* be used in a typed language, that's not the point.
https://doc.perl6.org/language/unicode_entry Oh god. It was not a joke.
[removed]
The Point &lt;-----&gt; You
From 3 months ago: https://www.reddit.com/r/Python/comments/3xi6o9/whats_the_future_of_flask/
Read the sidebar. &gt;Add 5 extra spaces before each line of code.
&gt;If you want something that looks like a list but isn't a list, you don't want something that looks like a list. I think you have something backwards--if you want something that looks like a list but isn't a list--then you *do* want something that looks like a list. The point of duck typing is that it doesn't matter *whether or not it is a list* as long as you can treat it as one--and as such, there is no need to *force* `a` to be a list.
Flask is alive and kicking. Since it's meant to serve as the bare minimum for a web app, there's not too much more to add to it. Armin's still very active in the community though I do wish he'd push out a beta 1.0 release.
It's pretty shitty to be telling people to avoid `collections.Counter` (an O(n) algorithm) in favor of some O(n^(2)) dictionary comprehension garbage. Just because you can do it with a comprehension does not make it better. 
I believe I touch upon this point in the introduction of the article: "All of the tasks presented in the examples can be accomplished with the extensive standard library available in Python. These solutions would arguably be more terse and efficient in some cases. I don't have anything against the standard library." This article is not meant to showcase solutions that are more efficient or terse than what can be accomplished with the standard library â€“ it's meant to showcase comprehensions. I'm not claiming that using comprehensions is more efficient than using `collections.Counter`. Quite on the contrary.
Modern IDEs and type inference have also made it almost completely unnecessary.
Depending on the size of your data, the list.count approach of the article may well be faster despite of the asymptotics, given the overhead of hashing. I don't think performance is the point the author is making though. It seems to be more about getting an intuition for what problems you might solve with comprehensions. We can always profile and optimize later. 
I find that Flask works just fine in Python 3. 
There's a dependently typed functional programming language Agda (http://wiki.portal.chalmers.se/agda/pmwiki.php?n=Main.HomePage) , which makes heavy use of Unicode, as it is used in a mathematical setting a lot: https://gist.github.com/afraca/0c05e14debb86cf07d10 
it does work fine in python3 we have it in production. Thats not what I was trying to say. All I was saying was that Armin doesn't like Python3 and has no intention of contributing anything python3 so how good the python 3 support will be in future as new versions of python 3 come out is unclear especially as flask new releases don't come fast. Also don't think anyone can expect new releases of flask to take advantage of any new python 3 features
Do people trash the GIL? It is something to be aware of, and you can use multiprocessing or cython (it can release the GIL) if you want multithreaded code, so it's not a big deal at all. People who trash it like it is a mistake just don't know what they're talking about.
Curious about this, too, as I'm about to join the Flask world with my new job. Hows 1.0, /u/mitsuhiko? Anything the community can do to help get it ready for release?
[Here's the milestones for 1.0](https://github.com/mitsuhiko/flask/milestones/1.0). I keep telling myself I'll pick up a few to help move it along, but then I get distracted by real life. :(
Devil's advocate: in x86, this allows more common operations to be shorter to encode. What exactly is "better" about adding the external requirement that one instruction must correspond to one opcode? And who gets to decide if two operations are the "same instruction" or not, anyway?
My dad says the same thing about punchcards.
Yes to Android, Windows, OS X and Linux with [Plyer](https://github.com/kivy/plyer). For iOS you'd have to use PyObjus to either call the notifications API or submit an implementation for Plyer. EDIT: Fixed link
Thanks for the info guys, much appreciated. 
I am new to this. I truly don't know what the problem is. I am close to figuring it out, and hopefully someone can help.
As the language has grown in popularity and it's projects have gotten larger and more critical to various endeavors, the language has needed to provide more options for handling complexity. In a small project, you can safely ignore ABCs, multiple inheritance, type-checking, ... you might not want to make any classes at all. As the project gets bigger, your code needs to, unfortunately, become more "sophisticated" -- more complex. For that, you need good taste. In ML, we'd say "there's no free lunch". No single strategy is best for all situations. Thus, Python supports many strategies, so you can pick the right one. The language tries to tuck these complexities a little out of sight, so that a beginner doesn't need to worry about them. It hasn't always succeeded with that effort, but you can see the effort in the way some things are builtins, while others are in modules. In small snippets, what is Pythonic is obvious. In a big application, that's no longer clear. So, I understand if it feels like split-personality when you start exploring your options. On the question of which technique to use, the answer is always "it depends".
A lot of people think about threads useful only to span processing power over multiple cores. But threads are still very useful to a lot of other kind of tasks, even with the GIL in the way.
ooh somebody is upset about the wrong words in the wrong sub big deal big surprise
[link to the Yosai github repo](https://github.com/yosaiproject/yosai)
The CherryPy has been in the same situation for a long time. Once they have reached their featureset, what's left is mostly bugs and housekeeping. This is much less fun for the maintainers and it starts looking like projects are dead. They aren't, they are just mature :) 
This is useless because your mutables are causing side effects. So your cached result would not be the same if mutables have been changed. You should get cached only pure function.
Please don't ask for direct help with homework. And for beginners' issues, go to r/learnpython.
[bottle.py](http://bottlepy.org) is an awesome little web micro-framework that makes setting up a web application (e.g. for hosting RESTful services) as simple as writing a few lines of very simple Python code. But it doesn't do user authentication or session handling. So Yosai could turn it into a very robust and secure little platform. Just an example.
Am I the only one that writes his own SQL?
Sounds like you're looking for [CGI scripts](http://www.tutorialspoint.com/python/python_cgi_programming.htm) which are mostly replaced by more modern frameworks (flask/django/aiohttp/pylons/bottle/etc).
Flask is probably easier to start with :)
I prefer balancing both. I like simple, helper stubs when I just need to get the system under test through to the end. And hand rolled stubs when I need to simulate more precise behavior. I'm also a fan of using [Builders](https://gist.github.com/justanr/8261384d23d4a7b1d0ad) when I need to create some basic objects as well. Here's a more [magical example](https://gist.github.com/justanr/52301d3af774f714a80d) if you're into that, but I've not used it on an actual project, so there's probably issues with it beyond "It's magic!" I really like the fluent style your library exposes, I'll take a closer look at it when I get a chance.
Here's an idea: don't. One of the ideas about using a widget toolkit is having what is called "native" widgets--that is, the widgets should look like what widgets usually look like on that OS. Windows 10, OSX, or various flavors of Linux. This is considered a major virtue, because users don't have to have a different set of visual expectations for each new application they use. PyQT does not use *truly* native widgets (meaning the widget is generated at the level of the OS), but does its best to simulate the look for each platform. wxPython does have native widgets (as well as some custom ones). So, I'd suggest you go with the defaults. All this said, some tasteful layouts and a few other minor decorative elements sometimes give a little pop to an application. Much depends on what it is (you wouldn't expect anything special for a file renaming utility).
My team has had some success with replacing all calls to 'open' with 'io.open(..., encoding='utf-8')'
Do you get an error code from the installer or does it just freeze?
&gt; I have created a python app that outputs everything in html. Just create a folder under your web root and put your generated html there. As to the application itself, do you have ssh access?
I've actually had more problems since I've moved to Python3. I still don't understand the difference between encode or decode and often have to try both. I've noticed Python3 has more problems converting bytes to strings. For some reason, code I've ported from Python2 throws errors for that. So you think it would be reasonable to just convert everything to unicode as it's imported?
Same thing here. I got a lot of reader feedback on a chapter about sentiment analysis regarding encoding errors. I don't have a windows machine and only tested the code on linux and MacOS; turns out only windows user had these problems, and adding `, encoding='utf-8')` to the `open` call solved their problems. If you want to support Python 2, I guess you need to do it via `io.open` though as you suggested.
It's important to always think about what kind of data you are working with. - If the data is just a sequence of plain bytes that is meant to be consumed by other programs, then it's binary data. Typical examples include: raw image/video/sound data, raw machine code or bytecode (executables, libraries, etc). - If the data is meant to be human-readable, then it's textual data. Typical examples include: names, Reddit comments, URLs, source code. Python 2 conflated textual data and binary data, which while it's nice and *forgiving*, leads to lots of subtly incorrect code and caters to bad habits. Especially in this day and age where Unicode is dominant, it can lead to problems later down the road when your users wonder why their ÃccÃ¨ntÃ«d names get turned into gibberish, or why your programs choke on emojis. &gt; I still don't understand the difference between encode or decode and often have to try both. - `encode`: textual data to binary data. - `decode`: binary data to textual data. The term "encode" means to a transformation from some high-level structure into bytes, hence in the context of strings it means converting text into binary data. Q. What are the appropriate data types for textual data and binary data? - In Python 3: - Textual data is `str`, written as `"foo"`. - Binary data is `bytes`, written as `b"foo"`. - The `encode` function only works on textual data, and the `decode` function only works on binary data. - In Python 2: - Textual data is `unicode`, written as `u"foo"`. If `unicode_literals` is enabled, then it's `"foo"`. - Binary data is `str` (alias: `bytes`), written as `"foo"`. If `unicode_literals` is enabled, then it's `b"foo"` - The `encode` and `decode` functions work on both textual and binary data which I find very confusing (what does it even mean to decode textual data??). Note that in Python 2, many libraries return `str` for textual data when it really should've been `unicode`. However, Python 2 libraries are also generally rather forgiving, and will accept both `str` and `unicode` as input. Generally speaking if you write string-manipulation code that works fine on Python 3, the code should work fine on Python 2 with `unicode_literals` enabled (of course, this is assuming you don't use any of the newer features that's not available in Python 2). The reverse is not true. Edit: encoding can fail, apparently, so I removed the comment about encoding not being able to fail.
Oh wow that sounds like a great command, I will try this later. I am not in front of my raspbian OS; I left it in my other house. Also yes I am careful to use python 3, but I tried python 2 as well.
Try this: https://github.com/g00197754/Pysolar
That makes sense, but the issue is that the html that the program generates is based on live information that changes.
Thanks a million! That really cleared up why I'm having issues converting code to Python3. I only work with human readable code, but when I work with some libraries, it comes in as bytes. Strangely enough, the Tweepy library imports some of it's data in bytes.
Are you making a static website or a dynamic website? If output of your program is a bunch of static html pages, open ssh connection and run your program again to recreate the updated pages. Then you can schedule it to run every few minutes. If it pages are dynamic and generated on the fly when user visits a url, it is quite a different story.
In Python 2 the rule of thumb is `str()` is considered very unsafe. If you code has explicit or implicit str() calls, write it with great care.
This may or may not be related: https://github.com/tweepy/tweepy/issues/615
If you don't mind me asking what is the question here? You told us what the project is but I still don't know what the question is and where you would like help or suggestions..
What happens if you just start the Python interpreter by typing `python`? What happens if you try to `import pysolar` at the Python prompt?
Ok, first thing I would go back and install this package using pip as specified below. More importantly, it seems that you could be confusing the usage of a module vs a python script that uses a module. Pysolar is not designed to be a standalone program - it's a module (sometimes called a package or library depending on the idiom of the language). You write your own script that imports pysolar and calls the functions or objects of pysolar, manipulates that data, and displays it or does whatever you want with it. In your case, it sounds like you want to output to the shell first (should be trivial), and maybe eventually you'll want to drive a motor (your solar panels?) or display data on an LCD. Those secondary goals will require other modules (or you could write your own)
I tried to use text.decode('utf-8', 'ignore') on the twitter description field, but it throws an error saying something like 'str has no value decode'. If I leave it out, then I get a bunch of unicode values that cause errors.
Is there a better way to do it? Is there any problem with my approach?
&gt; what does it even mean to decode textual data?? I agree that this is weird and confusing. Decoding textual data performs an implicit encoding using the default (ascii) codec, and then decodes the resulting binary data with the specified codec. This is useless and absurd for character encodings, but python2 includes things like base64 and zip as "str-to-str" codecs which will accept unicode objects. So if you have some base64 text, you can just do: &gt;&gt;&gt; u'Zm9v\n'.decode('base64') 'foo' Alternatively, encoding binary data implicitly decodes into textual data using the default (ascii) codec, and then encodes using the specified codec. So if one could convert a bunch of ascii bytes into utf-16 as: &gt;&gt;&gt; 'super lazy'.encode('utf-16') '\xff\xfes\x00u\x00p\x00e\x00r\x00 \x00l\x00a\x00z\x00y\x00' Disclaimer: I scratched my head for a half hour and poked around before stumbling on this use case, I don't think I would actually ever use it. Explicit is better than implicit, right?
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
&gt; encode: textual data to binary data; never fails. &gt;&gt;&gt; '\xff'.encode('ascii') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode character '\xff' in position 0: ordinal not in range(128) 
Not necessarily, you would need authentication(a username and password). If you are trying to transfer files to other hosts that are not on the same network then I don't think SCP would be the best thing to use.
You'll probably get a better response at /r/learnpython. And also if you put the actual error you get. 
It supports a --shell option. And you can configure it to always use bpython - or whatever shell you may prefer.
So by dichotomizing into typed and dynamic we miss the fact that there is additional metadata about our variables that governs their appropriate usage, metadata that is sometimes useful to encode in the variable name ... I can buy that...
I realize you said you're 'privately' looking, but I'd be down to help out. I tried to do some cleanup the last time it was mentioned on reddit, hacker news, or the issue tracker, although some of those issues (which could be closed) are still open. Also, I know at one time you were planning on moving it from your personal github to an organization (ala, lektor/lektor), is that still the plan? If you're willing to let some random dude from the internet help out, let me know.
In my [resume generator](https://github.com/masasin/resume), I regenerate the pdf if and only if the LaTeX file has changed. I compare the md5 hash before and after processing. Would you be able to do something similar? If not, what exactly are you regenerating, and when? Can you describe the process in detail? If so, please describe it.
ok thanks I'll try there, the thing is there is no error... it just completely freezes 
this. QML &amp; python work very well in tandem. there's a little more learning curve involved i feel than with the good ol' widgets approach, but when you've overcome this there's no looking back. Making GUI's look awesome and behave interesting comes natural to working this way. Take a look at [uranium](https://github.com/Ultimaker/Uranium/), which is a really decent reference project.
Python 2: &gt;&gt;&gt; u'\xff'.encode() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode character u'\xff' in position 0: ordinal not in range(128) Python 3: &gt;&gt;&gt; '\udfff'.encode() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'utf-8' codec can't encode character '\udfff' in position 0: surrogates not allowed (Edited the Python 3 example)
Oo, thanks. What's a surrogate?
This has exposed an inherent weakness in the OC system. I feel that once a contribution has been made to the OC deletes/overwrites (updates as a new version) should be impossible. Otherwise the community could be held at ransom.
I often see people complaining to encoding "problems" in Python, and don't understand them at all. What exactly are the problems? Everything is crystal clear. You have *str* (*byte* in Py3), for byte strings, and *unicode* (*str* in Py3) for strings of characters. You have methods (encode/decode) to convert one data type to another. Everything is standard and easy, what hassle? I don't see at all what is problematic here. But yet, I would not lie: I saw problematic code. It was written by an intern, who did not cared about data type of his values, hoping that Python will somehow magically take care for him. He mixed str, unicode and PyQt's QString freely, and it kind of worked - until the guy named JÃ©rÃ´me try to run the code in his home folder. Fixing it was trivial, but a bit boring; avoiding it is even easier: use the right data type, don't expect magic conversions.
The gif is demonstrating the tqdm progress bar in the bpython interpreter.
may be DreamPie
It saves you from having to write extra boilerplate code.
Why would you roll your own wraoper class when the library already provides it for you? 
Because encoding is hard at the best of time. Actually, no, it's trivially easy if you know what encoding every file actually is meant to use, and you keep a nice, clean separation between bytes and text. But as soon as you deal with actual text files from the wild, where the encoding may be unknown or even messed up, or if you try to combine text and bytes together, things get difficult.
Because bulk operation are 20+ times slower? http://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly Apparently the author also recognizes this, http://docs.sqlalchemy.org/en/rel_1_0/faq/performance.html?highlight=slow#i-m-inserting-400-000-rows-with-the-orm-and-it-s-really-slow
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Thanks, I think 256 bytes should be enough for what I need to send.
bpython it is! [(screenshots)](http://bpython-interpreter.org/screenshots.html) P.S. bpython is ok on Linux, but not so much on Windows
It's bpython, my favorite REPL. Really nice, really useful. Not as rich as ipython but for playing around in a REPL it's awesome.
Nice, I'll have to try this. (Not actually familiar with vagrant or OSX at all) Can you also test GUI applications this way? Is there an equivalent of X server running in the virtual machine? 
\*facepalm* Fixed now, thanks.
&gt; Plyer Whoa.
The uac may be popping up in the background. Check the taskbar or try to alt-tab to it. If that's not the issue, maybe try another python distribution like anaconda.
Thanks for the reply. The website will be static. Do you have any links that would help walk me through opening an ssh connection and linking my program to it (as I am pretty new to all of this)? 
Why not qtconsole?
good lord
&gt;if you're parsing json or html, 99% of the time you want text back, so default behaviour should be to return unicode-encoded strings Totally agree. That's how I assumed it was, and in Python2, it often worked that way, even if it was poor coding to not explicitly know what form the data is. At any rate, it is hard to believe that popular libraries that work with text like json sometimes encode the text.
So many questions in the post. &gt; Does anyone use core library of SQLAlchemy alone Yes
I agree, but that only works for code that you write yourself. As soon as you import a text file (json, etc) you have to verify each file. If you are webscraping, you have to prepare for all the possibilities you will encounter.
&gt; but not so much on Windows This should be trademarked.
No, that is where you are mistaken and while you are having a hard time : when you are reading a text file or webscraping, there is NO RELIABLE WAY to decide the used encoding. So you must provide it, or you end up trying to print a utf8 HTML on a CPU850 terminal, and it can't work. In any language. Python just tells you from the begining it's not going to work. Do that in PHP, and you'll just finish your program, then get giberish and spend 10 days asking why. Now in Python 3, the default encoding is utf8, so it will work 90% of the time. If it doesn't, it means you hit a case where you MUST know what's going on. There is no alternative. No amount of automation and magic will save you there.
&gt; Now in Python 3, the default encoding is utf8, so it will work 90% of the time. for opening files: &gt; The default encoding is platform dependent (whatever locale.getpreferredencoding() returns) also "there is no reliable way", can't detect BOMs now? encoding detection is possible, it exists, it doesn't work 100% of the time, but it does work.
bpython works in the terminal with no gui, and it's super simple, it just adds autocomplete. 
It's bpython
- BOMs are almost never present. - The keyworkd in my sentense is "reliable". - Auto-detecting an encoding and failling at and producing a bad decoding is worst than any other cases. - the best encoding detection solution in Python is Mozilla chardet, which fails 1 times out of 2 (I use is heavily since I live in europe). You can say whatever you want, unless you manually decide the best policy to deal with encoding, perfectly knowing what's going on, you will fail in heterogeneous environnements. And Python HELPS you with that. I've seen people writting stuff in PHP, C and Javascript for lines and lines in their cosy americano-ASCII islande. Then one day a spanish guy arrive, and it goes to hell, because they had no idea what they were doing. But the good news is, on the ASCII islande, Python 3 will work out of the box too. 
"Auto-detecting an encoding and failling at and producing a bad decoding is worst than any other cases." + "I heavily use chardet" Why are you doing the potentially worst-case thing then? 
? unless you're specifically executing raw sql text type, SQLAlchemy Core module already provided that protection. And if by composable you mean dynamically prepending join chains, where statement etc, it's also supported in Core.
I'm not. I use chardet in 2 cases: - debugging corrupted data some customers send us; - suggesting encoding to try to the user. I don't apply them automatically, I just say "since you don't know what's going on, try this first, and see if the result is what you want". Instead of trying to understand your job as a programmer, you are trying to prove me wrong. It's sad. 
Also try /r/bioinformatics
Kudos for the `big_penis()`.
Made for *nixâ„¢
[Here](https://github.com/z/xonotic-video-uploads/blob/master/bin/upload-youtube.py) is a fully working example based on the [API documentation](https://developers.google.com/youtube/v3/code_samples/python#upload_a_video_thumbnail_image)
1. I already want to use pygame for the interface. 2. I want to use the screen shot the user has taken with Windows; I'm trying to integrate, not replace. 3. I need to globally capture a hotkey, the best and easiest way to do this without being slave to someone else's eventloop is with `win32api`. Also for subjective reasons: I hate PIL. I don't even remember why at this point; and I feel like it's useful to know these things. I had fun doing it, after all.
Thank my parents, I guess.
Pycharm has [built in HiDPI support](http://blog.jetbrains.com/idea/2015/07/intellij-idea-15-eap-comes-with-true-hidpi-support-for-windows-and-linux/). With older versions, you have to specify the option in the vmoptions file. ctrl+scroll wheel is not enabled by default. That's under 'Setting -&gt; Editor -&gt; General -&gt; Change font size (Zoom) with Ctrl+Mouse Wheeel'. Note, this will only affect the currently active file. Try adjusting "Settings -&gt; Appearance &amp; Behavior -&gt; Appearance -&gt; Override default fonts by"
Mezzanine has much more than a "remotely strong" community. It originated in Australia, so adoption is stronger in APAC, but it is growing here in the US as well.
Yeah. Old standards are complex.
What's the link to the tutorial in french? Je parle aussi francais.
hum, good question. i think a lot depends on the job at hand, and where you're looking to run it. I use C# a lot to automate a lot of workstation side things that I'm not able to install python on. I've also used IronPython to run some of those same things, but C# has been my go to alternate in windows land. For Linux, I'm not sure there's an alternate for me to Python. It's pretty much able to handle all my needs in that area, along with a lot of server side automation as well. Here's a list of some of the things I've used as a system admin in the past as alternate's to Python when working with Windows machines: AutoIT - kinda like basic but with a lot of nice functions to use VBScript - This was what I started with, then VB Then Python C# - I use this over VBS now as I've become more accustomed to needing something more then VBS can handle. IronPython - ok, this isn't really Python but a version of it. But I've used this to over come a lot of issues, without installing IPY on the client's machine. It's a little bit tricky to get all your dependents compiled into a single dll for use, but it can be done. Jython - I've played with this one, but never used it in production 
I meant only that Yosai provides decorators for authorization, while beaker does not. There is no confusion on my part. Beaker just has a more basic focus. To be clear, I think Yosai looks quite good. I just prefer to see some code upfront. By comparison, I was quickly able to find a full application example for [Cork](http://cork.firelet.net/), which really helps me get a sense of how the library works.
For my kind of grind, there are only two other go-to tools that see the light of day...R (yeah, Python *could* do the job, but R is *soooo* right for me) and Tasker scripting. I suspect that's going to change soon though with the addition of two decent sized Arduino projects next month. C is going to be ruling the roost for a few months then =)
Aye sorry if my comment came out wrong. Was just trying to provide an alternate =)
I would have liked to discuss it in this blog post, but I personally think that it's too big of a topic to lump together with the current tutorial. Depending on how much depth you want to go into, the standard "checkerboard calibration" can easily turn into 2-4 separate tutorials, starting with the theory and then working into the code. Again, I would have liked to include it, but I didn't want to take away from what the core concept of the post is (a simple method to compute object sizes). Plus, it will make for a good "side-by-side" comparison in the future by demonstrating the added benefits of extra calibration.
Yesterday I wasted 3.5 hours to update that pig. No, thanks.
I was working on a project with a dataset that had a certain swiss cheese-iness to it, and there wasn't an attractive way of visualizing it---so I hacked one together in `matplotlib` yesterday. Super interested in hearing feedback on this!
I also find value in seeing complete examples. I'll see what I can do about bringing that to focus. Thanks for the feedback.
I am currently using [Brython](http://brython.info).
No. Hug has been around a very short period of time and already has a strong number of core contributers and users. However, I really like the idea of meeting up with those individuals at pycon, and thought this would be a cool way of making that happen :).
I recently switched to python3. Overall it is much better, but I realize I've been getting away with bad code in this case. 
http://sametmax.com/lencoding-en-python-une-bonne-fois-pour-toute/
I'm working my way through the early access version of Nim in Action myself, but for now when I need speed (and numpy et al aren't enough) I will generally go to [cython](http://cython.org), and pull in some c++ code from there if cython on its own isn't fast enough. By the way, there's a [library now to write python modules with nim](https://github.com/jboy/nim-pymod).
TCSH script. PHP. MATLAB. Depends on what I have to do and what I have available. 
&gt;I've noticed my Python3 code has more problems converting bytes to strings. For some reason, code I've ported from Python2 throws errors for that. FTFY
I use HDF5 with pandas, seems to be a nicer format that allows doing what you want.
Also check out dask when you want to go out of core, distributed or embarrassingly parallel. 
really depends on what the requirements are. what did you have in mind? optimizing for performance? optimizing for type safety? optimizing for flexibility?
this [one](http://stackoverflow.com/research/developer-survey-2016) is more accurate
np, didn't take it badly; just wanted to point out the reasons I used the things I do.
Linux user and I up-voted you, just so you know. :-) Don't know why this got down-voted.
I still do a lot of stuff in perl because I have a lot of legacy code that would take too long to rewrite. In terms of new projects, the other languages that I am usually switching between are R and C++. The key factors include the available libraries and how important speed of execution is.
Python3 is a good alternative.
Neither do Websockets require async, nor is Python 3 required for async programming. This is a complete non sequitur, even regardless of the fact that [there are Flask plugins for Websockets support right now](https://github.com/kennethreitz/flask-sockets).
It's entirely possible for the contents of a file or network request's response to include 'bad' binary that can't be made into an ASCII or unicode string, but it's also quite possible that you aren't looking for a text string when you're reading the file or response. 
what is depicted in the right hand most sparkline column?
Instead of tasking out to the browser to look up something, you can stay in the repl, it's definitely good.
Bash and C
It was for me, and I work with pandas and missing data every day...
Except for the fact that the lamp stack is really easy to get up and running. Why would you use PHP instead of Python?
JS (node) when quick and dirty webapp or simple microservice; Clojure; I've heard great things about Go;
I too would like to know. Specifically for Android.
How do you like Clojure?
boilerplate wsgi is still a pain. There's still /cgi-bin :)
Thanks. I will investigate further!
/u/Kwpolska never said they neglected updates for years. For all you know they might be running VS2k15, which only has one update so far (3.7GiB) not counting the Update 2 RC... Hell, even VS2k13 Update 5 is 6 GB, so even just the one update is a non-trivial download, so I'm not sure why you're making this point.
$10... top kek. I'd say an average Python dev salary is about 86 thousand dollars a year. That's just over $40 dollars an hour. This would have to be a fifteen minute project to be worth $10.
My webhost still uses Python 2.7 And I'd rather use PHP than Python 2.7
Tcl, mainly because it's the standard language for digital EDA tools which is my line of work. As God is my witness, I will never write a line of Perl code ever again.
This is what I'm currently doing but I do it for deletion and retrieval too. I have to do it for those other two since the interface has to prevent the insertion, deletion and retrieval of certain keys. I don't want getitem, setitem and delitem for the base class and these methods for all classes that inherit the base class to do `self._validate` at the start. Is this pythonic or am I overthinking it?
Ditch the class hierarchy, don't use inheritance at all. Inheritance is generally not worth the hassle.
You're not tempted even a little by [perl6?](https://perl6.org/)
&gt; However, not all our results are perfect. This is never the case with any instrument. Hence, many measuring instruments come with error measurements. They allow the user to understand what his possible range of results may be for a given specimen (ex. 2.5" +/- 0.1") IMO, your discussion around measurement and error could've started much earlier in the post: &gt; here are approximately 157 pixels per every 0.955 inches in our image Instead of the "approximately" you could say 157 +/- 1 pixel (or smaller if you want to get into subpixel interpolation, or larger if you want to bring up distortion), and carry the results through to the end... then you don't have to act surprised: &gt; How come the object measurements are not 100% accurate? Furthermore, you can start dissecting the factors that feed in to your error measurements in a quantitative matter. Use some basic geometry to give a first order approximation of tangential distortion. Etc. Again, my opinion, but a measurement without error bars is an unreliable measurement. Why go through all this trouble to produce an unreliable measurement?
Get/set/del item implies you are working with a collection, and generally one does not expect collections to validate, rather the items inside the collection should validate. So that for me is the strangest aspect of what you describe. That could be as simple as implementing comparison/equality/hash methods and then placing the objects inside a set or some other object (if the only constraint is uniqueness). In any case if you can't change things I would lean towards having these as methods of the base over decorators, but both have advantages and disadvantages.
I'd rather eat hot coals than write scalar variables with '$' in front of them. Never again.
Android has support for C++. Look for **NDK**
As a reminder, if you get files from a Windows user, they may be in 'latin-1' instead of 'ascii' or 'utf-8'
Another scientist chiming in: For speed reason i sometimes resort to C or C++, and for some applications CUDA.
Does it have to be python? Just because something like [autoit](https://www.autoitscript.com/site/autoit/) would sure be quicker/easier.
No, it doesnt have to be python. I just see most of the scripts being written on Python here :) Thanks! 
Everything is possible in almost any language. However in this case I'd recommend [AutoHotkey](https://autohotkey.com) since its specifically designed for automation (including looking for stuff on the screen).
I woldn't go so far. There are lots of unaccunted factors here. Ex. JavaScript has poor documentation documentation (compared to python) and lack of a true standard library. This can result in a few orders of magnitude more questions on stack overflow.
Maybe not exactly your use case, but have you considered just sharing a jupyter notebook with the relevant code embedded? This way everyone can slice / manipulate as needed.
Highly suggest Ceylon for the new crop statically-typed languages popping up. It's the only one that really seems to be thinking all of that through, for me.
I have not used the built-in command line script, but I often use the library a bit like this: #!/usr/bin/env python import sys import argparse from sas7bdat import SAS7BDAT import csv # parse command line arguments parser = argparse.ArgumentParser() parser.add_argument("inputFile", help="SAS dataset to convert") parser.add_argument("outputFile", help="CSV file") args = parser.parse_args() # loop through SAS dataset and output CSV file with SAS7BDAT( args.inputFile ) as sasFile: with open( args.outputFile, "w" ) as csvFile: csvwriter = csv.writer(csvFile) for row in sasFile: csvwriter.writerow( row ) That said, if these types of conversions are even a small part of your job, definitely pick up a copy of [Stat/Transfer](http://www.stattransfer.com/). It is one of the first things that I install on any machine, and every day it pays for itself in terms of productivity. It is the only sane way that I have found to work with teams that are using a lot of different tools.
Tell me more.. is it just for people on Anaconda? Virtualenv has serve me well for my django type work.. would Conda buy me anything?
When I don't use CSV I use a SQLite database - if you won't want to select the entire db you can filter using SQL queries to slice. Not sure if this is a appropriate solution for you though.
This sub is for Python news. You want to go to the sites linked in the sidebar under "Python jobs".
You may be right. I'm pretty sure I installed it correctly because the command line script from this package copied right to the scripts folder of my main.py. But this isn't a python script right? Like it's not a ".py" file - it's a CLI command, right? So that being said can I run it right from a DOS command prompt? Do I need to run it from IDLE? DO I open Python in a DOS prompt? And if so what's the syntax for it? Will something like this work? C:Users\georgia.sav\sas7bdat C:\test\file.sas7bdat C:\test\file.csv 
I've done this before posting . I am not looking for freelancers, I want a partner, someone who share a vision, some one who want take part of a great product from its first days :)
Neat cutting edge python! The simple stuff I do is still Python 2.7, but I think Django will fully embrace Python 3 soon (tm).
This looks perfect for what I might need to do. Do I need to define these arguments first? Is this built in to the library? And that Stat/Transfer tool looks awesome. We do a lot of transferring and converting - especially with table type of files so I'm going to look into that.
Well I wont be able to use the "pip3" command without the Graphical User Interface (GUI). I wont have access to the GUI without a Raspbian OS. Or is there another way?
The first thing I did when I installed Jupyter three days ago was check for a dark mode. This is awesome.
below: bash; above: julia
Hi, This is the contents of a script that I have in one of my folders. To run it I type: ./sas2csv myfile.sas7bdat myfile.csv I'm a Linux user, but I would guess that something similar would work under Windows. Do check out Stat/Transfer though. I think they have a demo copy that you can assess. I use it in batch mode all the time where I convert entire directories from one format to another. Good luck. 
What do you mean? Also, aren't you on Raspbian already? You could just use it from the terminal. `pip3 install pysolar`. Maybe with `sudo` or `--user`. Basically, log in, start a terminal emulator, `pip3 install pysolar`. Then, write your script. To test, run `python3` or (I recommend if you have a gui) `ipython3 qtconsole`, which you'll need to install with `pip3` too. Follow the documentation [here](https://pysolar.readthedocs.org/en/latest/). You'll want to use `solar.py`, so you can `from pysolar import solar`, and then you can use commands like `solar.get_altitude(42.206, -71.382, d)`. Note that I recommend you do this instead of `from pysolar.solar import *`, which is what the docs use. That is bad form. Do you need anything else?
Look, pal. No offense, while there are many newbies here, there are many of us who have been through the bs marketing talk time and again and find it insulting. If you want to find someone capable, you have to be honest. Show your credentials, show your idea, tell your readers the gist of your business plan, all in the least amount of words as possible without getting into Twittertalk territory. And as mentioned, do it through the proper channels, /r/python not being one. If you don't do it the proper way it can really work against you, making people feel you're desperate.
I like a lot of things about clojure. It makes you think in a different way. Clojurescript in the browser is better than JavaScript.
Bah! Where is the location on Windows using Anaconda? Every time I want to do something like this I have to go searching for it again!
you're probably looking at a class of problems that could yield a quicker solution.
I go through almost exactly the same moment of horror every time I need to change Jupyter CSS. The fact that the location of the file changed with the splitting of the notebook module certainly didn't help. For what it's worth, mine is at C:\Users\$(user)\Anaconda3\Lib\site-packages\notebook\static\custom\custom.css. There are a few custom.css files floating around, but that seems to be the one which actually causes changes. 
Very happy to have this.
You could get rid of your `x*y`. You're repeating a whole bunch of combinations.
very sweet. I guess the only thing I'd suggest is to add `width:100%` to the `.container` elements to make sure the code blocks make full use of wide screens.:)
It clearly depends on what you have to do. Sadly it is almost impossible to bring clojurescript in any existing big company product, and then it has his pros and his cons. **Cons:** - it's unlikely you'll use it in shared codebases or big corporate - require different training and sadly it's hard to teach functional programming to 50 years old java programmers (especially in corporate when they are all settled and cozy in OO) - tooling, docs and errors still need much work - some interactions with existing stuff aren't natural - importing different libs isn't as easy as it should. **Pros:** - bleeding fucking edge - FP like a boss - if you do react IT IS AWESOME. - can work with node nowadays - can use with react native nowadays
I do like Clojure a lot. It is very powerful and very elegant, it plays well with the JVM, and has a very nice community. Give it a spin, here /r/clojure has tons of guides to get started. You need to be ready to dive into Functional Programming, but if you give it time you'll be really rewarded. 
I'd recommend collecting all her sentences and training this model on it: https://github.com/sherjilozair/char-rnn-tensorflow
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Or sketchy
I just looked at a project where I'm patching a lot of times in my tests - patching `sqlalchemy.session` to make sure an error is thrown in a certain situation - patching into tornado to override the default session handling (get current user) - patching my password hashing shim (I could use Dependency injection here) I don't see those first two as code smells.
This is really late in the game, but thanks for mentioning the gallery. I've actually just updated that page with styles from Matplotlib 1.5 and added better navigation between plots. Also, I wrote a [quick post](https://tonysyu.github.io/matplotlib-style-gallery.html#.VvoAzxIrKV4) about it.
I had the same impression. You want to provide a framework but don't show any code at all in your "what is yosai" article... I was looking through the comment section to find the github link. Why not provide that one instead of this more or less useless article? 
I've tackled a couple projects like this before. The biggest problem (at least from what I experienced) will be the clicking part in purely python. If you're leaning mostly towards wanting to do it in python, one cheat I ended up needing to do was to make a side java snippet that Python could send the proper coordinates to click. (Ex: click_here.jar 357 870) it then can be ported using the os.system() function. :) best of luck!
CoffeeScript all the way. Same simplicity of Python in the only place that Python or bash can't go, the browser. :)
There is no way to make binaries that were built against one version of Python work with a different version. Python major versions are not ABI compatible. If you want to use PyQt with Python 3.5, you will either have to find somebody that is making pre-built binaries available, or you'll have to build them yourself. [Christoph Gohlke offers PyQT4 binaries for Python 3.5](http://www.lfd.uci.edu/~gohlke/pythonlibs/) and [Riverbank Computing indicated that 3.5 binaries will be available when Qt 5.6 is released](https://www.riverbankcomputing.com/pipermail/pyqt/2015-October/036543.html) which [was only released a few days ago](http://blog.qt.io/blog/2016/03/16/qt-5-6-released/). cx_freeze is essentially just a bundler. It takes the executable interpreter and packs it up with all the necessary files. You'll need a 64 bit interpreter installed if you want to create 64 bit bundles, and a 32 bit interpreter if you want to create 32 bit bundles. 
R really kills when it comes to data munging and stats. 
There's dogelang: https://pyos.github.io/dg/ . Despite the egregious name, it's a serious project that's a Haskell-like language that gets compiled to CPython byte-code.
Yes it is. But sometimes it's the only way to test code in an existing environment. And I have rather smelly tests then no tests at all. 
Is there any way to read the labels on matplotlib plots? They end up being black on black and kinda hard to read.
Will this make the codeblocks adapt to my window width? How would i go about adding width:100? Did Ctrl + F on the css sheet but there are lots of matches. Complete css noob here btw lol.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
In my experience, that "narrow and shallow inheritance tree", if you take things to their logical ends, tends to amount to a situation where your class hierarchy has two levels, and every class at level 1 overrides all methods of the single class at level 0. But when you do that, the logical thing to do is make the level-0 class entirely abstract, which makes it a de facto interface. And since we're talking Python here, one might as well resort to duck typing at that point, because in Python, the benefit of an abstract base class (serving as an explicit interface) isn't strong enough to outweigh the boilerplate. As someone who is well versed in many programming languages, I can see why someone coming from a more traditional OOP background (say Java or C#) would want the base class, but again, this is Python we're talking about here. Also, a common pattern you see in OOP code, especially Java-style OOP, stems from how Java doesn't distinguish between modules and classes, so you end up with classes that aren't just data types with some polymorphic behavior attached to them, but actually full-blown subprograms, and many of their methods are pretty much just subroutines of the program that the class represents. If you get rid of that pattern, and instead represent modules as modules and subroutine-methods as module-level functions, the inheritance problem usually goes away all by itself. I haven't read the original code (because none was provided), but I'm fairly sure that if I were to read it, I could come up with a more elegant solution that doesn't require a class hierarchy at all.
Button "submit" on site does not work. As contact with you?
The [Haxe](http://haxe.org/) Language / Toolkit compiles to Python, among many others.
see [here](https://pastebin.com/EUbsn0q4) for the version with the max-width statements. EDIT: a "&gt;" crept in at the very beginning of the paste, you'll have to get rid of that. Sorry.
This is where mine is as well
You're right, those are red flags. Patching a third party package isn't something you want to do for the same reason you wouldn't create a mock of a third party class.
I have experience teaching many, many beginners CV. What about you? There is nothing more insurmountable to an intermediate programmer than having to dismantle 57 layers of frameworks and abstractions, all at once, when they want to solve or understand something that was omitted in their introductory '5 lines to make a face detector' course.
Much better. But I think it should be visually more distinct (maybe a different bg color / text style?) to the rest of the plot. Another suggestion - Can you add a dotted vline on the right hand side that could represent 100% completeness?
But... so? Not everyone needs end-to-end understanding of this stuff. Learning things incrementally, as you need it, is hardly the worst thing ever. It's just a different way to approach things. And no, I don't have a ton of experience in CV. But if it's like any other thing I've learned, engaging people with high level understanding first to build interest in a topic and understanding of the ideas behind it, even if that means the results are a little inaccurate, is a totally valid way of doing things. Especially as your concern is about correction for lens distortion, which is hardly a killer concern for a proof of concept prototype.
&gt; And don't miss the wood for the trees wrt. lens distortion. You understood my point. Evidently I don't.
Anaconda is the solution to a problem that shouldn't even exist ;-p
Hy is really cool, I've been doing some small stuff in it, and I like it a lot, list comprehensions are a bit cumbersome in it, but that's about it for the downsides.
&gt; What is the benefit of these objects? A list has to load all its data into memory before doing anything. These objects just reference the underlying dict, not duplicating anything. This means that they are less memory-hungry and that, if you are apt to exit the loop quickly, you didn't pay to copy everything beforehand. &gt;To me they just seem to introduce unnecessary complexity to my code. It is one more thing to keep in mind, and I share your skepticism about its value. Ultimately, few will share it. FWIW, `numpy.array` does more guessing than your average nice function, and this leads to a lot of stuff like this. I'm not sure that there is a nice API it could provide that didn't have such hiccups sometimes, though. 
I love this but most users use excel and some are familiar with databases like azure. The cool thing is that you can store the dtypes as well and for data I am not updating anymore I can store most dimensions as categories which makes the file insanely compressed and quick. I wish I could use this format more. I would jump to it if tableau ever supported connecting to it directly, right now I can only connect to databases or csv files..
&gt; Using dict.values() returns an iterator No it doesn't. It returns an iterable (that happens to be lazy). It doesn't return an iterator (a thing with a `__next__`).
They used to return lists in 2.x. As of 3.x, they return view objects, which is far superior. Think about it. Do you really want to have to make a copy of all the data? The data already exists inside the dictionary. Why do you need a whole separate copy? Can't you just use the data as it exists? That's what a dict view does. You can always force that copy if you really need it, but not the other way around. 
I found my data that I am working on now is in cp1252 format but when I write it to csv and use utf8 it turns accents and double dashes into symbols which don't make sense. I gave up and I export the data as cp1252 which is basically just avoiding the issue. I wasn't able to figure it out.
Hey, using GUID is actually a very important thing I simply forgot to mention, I will add it right away, thanks! Regarding the 2 separate logs, they are meant for 2 different purposes. an example use case: 1) I want to count the unique ID's of users that entered a specific function today. Now I want to create some kind of regex to that log because the user ID string arrives in many other logs, for that purpose I would like a short and easy to parse log. 2) A user complained that when he entered that function from use case 1 he encountered a problem. in that case I would like to search that user ID and have a detailed log with all possible data. 
Mocks, in proper terms, exist solely to see how something was invoked. There's other, architectural techniques to get third party and IO bound code out of your unit tests. Facades and adapters come to mind. 
Mochi: https://github.com/chajadan/mochi/blob/master/README.md
If you all are willing to take my word on it, I can say that we use python extensively in LIGO, not just for plotting. We also use python to analyze our data. These are the tools we use to search for binary mergers -&gt; https://github.com/ligo-cbc/pycbc. The heavy lifting though is often done by underlying c libraries that we call into using SWIG and ctypes (FFTW, MKL, etc). 
Source Code: https://github.com/SavandBros/badge
We would post offers or promotions or features or mention our company name if the share was for marketing or promoting, the post is from our community forum, an image between backend devs and frontend devs. This is for sure not an attempt for marketing or promoting, If we violated any rules of this subredit or others as well think this is not suitable for this place we'll remove it.
Seems a pity what with pyrsistent already existing. Mochi uses pyrsistent by default though
An important distinction, as itervalues() does return an interator in python 2.7, while viewvalues() (aliased as values() in python 3) returns an iterable. Why is it important ? Well: - an iterator can only be read once; - the iterable returned by viewvalues() (or values() in Python 3) can be provide as many iterators time as you want (so can be read as many times as you want) and has a \_\_repr\_\_ showing you it's content for debugging. Basically, viewvalues() is the best of both world: small memory consumption, still easy to iterate on and debug. The only drowback is that you can't index it (do [x] on it), but you rarely need so on a dict since it's not ordered.
And that reason is....? I know the reason that it's a good and valid idea; solving an isolated problem like making a test to handle hard to create exceptions in databases. 
Why not use pricerunner?
There is a huge number of price comparison website out there, but what make dealy special is that it doesn't compre the price only, but reviews, the average rating of the product and the cost of shippings, and wether the merchant has a good rating ...and return the 10 best results in a beautiful and minimalist way .
As the BDFL said himself in the [relevant PEP](https://www.python.org/dev/peps/pep-3106/#id7). &gt; Do we need more of a motivation? I would think that being able to do set operations on keys and items without having to copy them should speak for itself. Feel free to hunt for the original mailing list discussion if you want more details. Python, like many Open Source languages, has the advantage one doesn't need to post "why was foo so designed" questions on reddit. One can just read the original discussion.
Project author here, looking for some feedback and whether any of you would find it useful. Currently it is probably (just) an overengineered way of downloading files from cdnjs.
"It's less intuitive but more efficient!" is also a great argument for writing in assembly language. My only problem with these classes is that they're basically undocumented, except for a wink and a nudge that they're iterable, and behave sort of like a set. And there's some pseudocode in an old PEP that may or may not be accurate. Would it have killed them to make a "View" ABC, and written a paragraph or two of proper documentation?
`work_reddit_account_` nailed it, if you set that style it [looks like this](http://i.imgur.com/TNfRGMZ.png).
Out of Tcsh, PHP, and Matlab, *PHP* is the one you don't understand? :-)
Is there any particular reason why this is better than something like bower? Or is this just something you did for fun and wanted to show off?
I think the only reason would be that it actually doesn't advertise itself to be a package manager and that it is "configuration free". I.e. there's no "bower.json". With that being said, it's mainly for fun, but also because I needed something like that when making proof of concepts or trying out new things. The JS world is full of tools that just need *so* much configuration and I can't be bothered. So I created a tool to just fetch the damn files and let me write my code.
I think the only reason it's more 'intuitive' for people right now is because they've been using it as a list in Python 2 for years. If you were to look at a new language and see 'dict.items' is a view not a list, then you'd likely accept it no questions asked. I think that's not intuition, but a trained response. And that response can be changed. 
Or, generate the script tags, so you can copy-past that into your index.html and be done. 
Understood. I'd personally still probably just use bower as a force of habit, but that's definitely a cool way to solve a problem. Minimal bootstrapping always helps when working on PoCs.
Conda still problematic if you're working on different platform, e.g dev on mac, deploy on ubuntu. There's no clear way how to have something like requirements.txt that will work on both platform.
&gt;there are some functions that can't handle them. That seems like the real problem, not that Python changed the behavior. Submit a bug to numpy if there isn't one already.
Unless n is above the high hundreds of thousands, it *really* isn't going to matter on a modern machine. Again, if you need to be this anal about your performance you probably shouldn't be using Python.
I agree with views being superior to lists in this case. I just wish the views would print like lists--or rather, like numpy views, which abbreviate after a few items. I realize that this scheme wouldn't work for every kind of view, but it sure would make working with views much more convenient. 
Sure there is! $ conda list -e &gt; req.txt then you can install the environment using $ conda create -n new environment --file req.txt works flawlessly across any platform 
dicts are used internally all the time in python. performance here *does* matter.
That page doesn't even mention the `isdisjoint` function that these views implement. This is particularly strange since the documentation you linked to says: "Keys views are set-like since their entries are unique and hashable." And yet they don't implement ANY of the following: `issubset, issuperset, intersection, difference, symmetric_difference, union` All of which could be implemented for `dict.keys()` since none modify the keys. There are some serious problems with python documentation. The real documentation is almost always best found by using ipython and run `help(instance)`. 
If you worked for me you'd be let go with this kind of arrogance. 
Groovy (JVM based) is my go to alternative to Python. I've been meaning to learn Rust, but have not gotten around to it yet.
First it has been written entirety in Python, no external service dependencies such as shields.io that many projects us in background. Comes with a tiny endpoint that gives all the badges at once: http://badge.kloud51.com/pypi/html2text/markdown/ or http://badge.kloud51.com/pypi/html2text/rst/ Also it can be installed on other machine with running some tiny commands at local machine, thanks to Ansible-badge
Stating that python isn't a good choice for performance critical applications is arrogant..?
Thanks, will do it. :) 
Yes, it's map function. Just in postfix notation. 
I always override the default location where my config files and data files will be located at by creating JUPYTER_CONFIG_DIR and JUPYTER_DATA_DIR environment variables. My setup instructions [here](http://nbviewer.jupyter.org/github/pybokeh/jupyter_notebooks/blob/master/jupyter/Installing_Jupyter_Notebook_Server.ipynb). EDIT: or do this at the terminal: jupyter --config-dir # to find location where config file will be located at jupyter --data-dir # to find location of where nbextensions would be installed 
&gt; anal about your performance you probably shouldn't be using Python The flipside of this argument is why take a potentially huge performance hit when there's an obvious way around it? It's not like you can't just to `list(thing.items())`
Oh man that's awesome. I didn't know that the dict views supported set-like operations!
I think the one time I've used it was when I wanted to test automatic argument parsing in a library of mine, so I patched `sys.argv`
Completely useless without https though, I can't include something from a remote site in my https website (and places like github pages are https only now) unless it's also https. You could also easily generate the SVGs locally instead of using a service. I don't see why someone would rely on an external badge service instead of just doing it themselves or using a library that generates it locally.
It's a large difference in performance in as few as a thousand. Never write naÃ¯ve, foolish code like that when better things are available, because your code will eventually wind up in someone's inner loop with more items than you expected.
Cool, I guess. Is there a reason to not just jump right into http://haystacksearch.org/ ?
is there a way to implement this on a per-notebook basis, as opposed to a global theme? I really want to use this for sandbox coding, but I don't want it to be the look of the .pdf's I produce for presentations etc.
nvm, I figured it out: #set the style of the notebook from IPython.core.display import HTML def css_styling(): styles = open("./theme/ocean.css", "r").read() return HTML(styles) css_styling() This (as a cell in your notebook), along with a "&lt;style&gt;" tag added to the top of the .css files will allow you to theme specific notebooks each time you open them. Won't theme the notebook until you run the cell.
In this case, yes. It's briefly discussed in the [first article](https://qbox.io/blog/how-to-elasticsearch-python-django-part1). Essentially, Haystack is difficult for bleeding-edge cases, for custom uses, and is generally much more difficult to debug than your own code. This is due to all of the classes and abstractions of Haystack. 
Supply your own colour cycler
Thanks for the reply.
Nice suggestion, yes https would be great. We have the Wildcard SSL certificates ready for *.kloud51.com It's an early stage project, having https is a really good suggestion. About places like Github accepting SSL is wrong, on the badge repo we have listed all the badges and they're running with no issue. It generates dynamic badges like getting up2date status and meta data from the external services such as PyPI. How can that be achieved locally ? 
Python is not good. Python is not evil. Python is just a tool. This though... This is evil. Please don't bully this person. If you aren't a fan of her statuses just unfollow her.
Thanks for the reply. Yeah, I know there are probably a ton of tools that can do it, I just want to challenge myself to do it with Python. I'd probably lean toward sending a broadcast packet and sending an alert when a new ip responds. Sorry to be vague, I'm just starting to plan it out so I haven't filled in all the details. I was thinking about just starting with a few of raspberry pis and a switch and scaling it from there. 
Thanks for letting us know *you're the boss*.
You probably need to set up a session object that can store cookies etc. from google.
the paper is here and the other figures look like matplotlib: http://stm.sciencemag.org/content/5/181/181ra50.full How can I do a diagram like this in python?
The inner loop argument is a poor one in general imo. This particular optimization is good because it's so easy, adds essentially no complexity, and is almost always the right thing to do. But if you write all your code worrying that it might be in someone's inner loop one day, that's "premature optimization is the root of all evil".
Actually, I noticed this recently: Python 2.x &gt;&gt;&gt; list1 = ['a', 'b', 'c'] &gt;&gt;&gt; list2 = ['b', 'c', 'd'] &gt;&gt;&gt; list3 = list1 &amp; list2 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unsupported operand type(s) for &amp;: 'list' and 'list' Python 3 &gt;&gt;&gt; d = {'a': 1, 'b': 2, 'c': 3} &gt;&gt;&gt; list2 = ['b', 'c', 'd'] &gt;&gt;&gt; list3 = d.keys() &amp; list2 &gt;&gt;&gt; list3 =&gt; {'b', 'c'} ... so there's that.
/r/learnpython /r/learnprogramming a code snippet class MyClass(object): # whatever an_instance_of_my_class = MyClass() id(an_instance_of_my_class) # returns an integer that is globally unique within this instance of your Python interpreter 
thanks for the quick response. is there a way i can not have the programmer defining "an_instance_of_my_class" because i was planning on putting this in a loop where multiple instances of the class can be created but i can not see a way of not having the programmer defining the instance name.
Devil's in the details. Probably too early to ask the question you're asking.
&gt;Or even just monkeypatching your get_current_user to return a fixed account. That's exactly what I'm doing, I'm patching my own get current user, which is used in tornado, to return a fixed value, using mock.patch.
 instances_of_my_class = [] for i in range(10): instances_of_my_class.append(MyClass()) And then instances are retrieved by indexing the list of instances, e.g. `instances_of_my_class[0]` will get the first instance in that list.
I don't really understand what you're asking or why. Aren't __you__ the programmer here? why do the instance names matter anyway? those are just variable names. anyway, if you don't want to assign an instance of your class to a variable you don't have to MyClass() # returns an instance of MyClass
all the study material i see about class have the programmer creates the class class Myclass(): pass and the programmer defines the instances of the class a = Myclass() b = Myclass() etc is it possible to have the instances be named from user input or the name passed from a variable cus = input("enter name here") #user enters "bob" cus = class() #but instead of the instance being cus it is the value in the variable cus which is bob
How about this? import sys x = range(sys.maxint) If you're on Python 2, your system just ran out of memory and you may need to reboot. In Python 3 you're fine, that operation took essentially no time. Meh, what's the difference right? If you really do have tiny lists, then you can feel free to make a (deep)copy if it improves performance otherwise we should have the default be code which can scale up easily by the use of generators.
these are appropriate questions for /r/learnprogramming I think you'll have better luck there
To add to this: (of course) there is a python wrapper for nmap https://pypi.python.org/pypi/python-nmap Never used it, never tried it but if it works put this in a loop check some global known hosts list and bam
Iteration is O(n), this will have no effect on runtime performance. Memory performance yes, but again I haven't seen anything which shows this to be a big difference in the real world. Membership testing in a list is also O(n), this might come out ahead on average. That said, membership testing a dictionary via .keys() is going to be terrible for performance anyway, you should be testing against the actual dictionary object which ends up being an O(1) hash lookup.
You're getting downvoted, but you have a point. [Fancy algorithms are slow when n is small, and n is usually small.](http://users.ece.utexas.edu/~adnan/pike.html) ^^I ^^personally ^^love ^^iterators ^^and ^^views ^^though.
...with cleverness, patience, and mostly code sections that get jumped past
just use inkscape, it will be faster
I wouldn't assume they used matplotlib. In that specific figure, the arrows remind me of [Inkscape](http://inkscape.org/). If you check the additional material, they used R for part of the analysis. *EDIT*: the (R) code to reproduce the other figures seems to be [here](https://github.com/weiyi-bitw/STM_clearScience) 
They're trying to reuse the cert from pocoo and it's failing. Just go to the non https site: http://www.palletsproject.com/
The only blog entry says "If you discover this right now, this is not announced yet and work in progress :)" http://www.palletsproject.com/blog/hello/ Flask is very important for me so I'll be waiting for more info
Armin was recently on Twitter soliciting suggestions for a "rebranding" of pocoo, and again yesterday announcing he'll "sort out" his OSS stuff this week. It's very likely that this is what he was talking about. Afaik he basically *is* pocoo, which will clearly rebrand as pallets.
That doesn't make them set like. That is an implementation detail. This is something that python is terrible about (caused by the failure to use any kind of abstract interface class in the standard library). Keys objects should be an instance of a nonmutableset (aka frozenset), and should implement intersection/difference/issubset/etc. They don't and that means they are not sets. They don't quack or walk like ducks so they aren't ducks.
The keys and items objects support set difference, union and intersection using the operators (`- | &amp;`), as well as subset and superset tests with comparison operators. The values don't, presumably because they're not so set-like - keys have to be unique, values don't.
 In [3]: {'a': 42, 'b': 54}.items() &amp; {'b': 54}.items() Out[3]: {('b', 54)} Yes, they do :P
Testing for membership in the `.keys()` view is also a hash lookup. And testing in `values()` at least saves allocation. And iterating a view is O(n) while constructing a list and iterating it is O(2n)
Will METAFLASK https://github.com/pocoo/metaflask going to be merged with this?
No they don't `{}.keys().issuperset(set())` yields an error. 
'If I just run it in python'. Do you mean running it with pythons IDLE?
Alright thanks The line graphs are meant to be confusing as they have a trend and if one part spikes or veers away from the trend I would like to know which one
Unfortunately it is impossible for me to get this working in Windows 10. I have tried all possible folders: * C:\Users\$USER\\.jupyter\custom * C:\Users\$USER\\.jupyter\static\custom * C:\Users\$USER\\.jupyter\notebook\static\custom * C:\Users\$USER\\.ipython\default_profile\custom * C:\Users\$USER\\.ipython\default_profile\static\custom * C:\Users\$USER\\.ipython\default_profile\notebook\static\custom * site-packages\notebook\static\custom CPython 3.5 64-bit and latest jupyter version on Windows 10 64-bit
I would use os.path.join () inside open() 
I haven't used celery. I run a py file which calls a bunch of other py files to be run in a certain order though. I'm not sure if this is the most efficient approach but it downloads stuff from an sftp site, checks if all expected files are available, and then uses pandas to process them (12 separate py files in order with some error checking etc). Finally it moves the files to shared folders, emails end users that the updates are done, and creates a.twbx file for tableau. All being called with one py file which windows runs every day at 8. This is the coolest thing I have done because it used to take me more than a full shift to do it in excel and some things weren't possible for me to do. Now it's literally done everyday without me doing anything, even on the weekends. It's been running for 8 months now but I still add new things as I learn them. 
f.y.i. Sets are very similar: &gt;&gt;&gt; s = {x for x in range(10)} &gt;&gt;&gt; s {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} &gt;&gt;&gt; type(s) &lt;class 'set'&gt; 
Thanks!
Thanks!
* C for performance or system stuff * VimL for text munging that can't be done easily in python * Shell tools for times when I need lots of interoperability between different programs * PL/PGSQL - for when I need special checks directly integrated into the database That being said, I've been wanting to try out go or nim (or something similar), but I'm not sure if either can bind directly to any C libraries without any trouble.
I switched to ptpython for that reason
They're referred to as *set-like* because they don't fully implement the `__builtin__.set` interface, but similar operations (intersection, difference, etc.) are supported. They happen to be supported using builtin operators. If they supported the exact same interface, then they'd be sets, not set-like. One can always use the `set` or `frozenset` constructor with a `dict_items` object if there is a need to use those exact same methods.
No, it doesn't. It's essentially trivial to switch between Zappa and normal hosting providers. It doesn't lock you in any more than something like Heroku would.
I'm pretty sure you can pickle them if you're going to be sharing them with another python user. A pickle file will save and load many times faster, and will be much smaller than a corresponding csv. 
Just open a command line and run: python redditUserImageScraper.py But first, make sure you have PRAW installed like it says in the README. 
So is it the source or the python wheel option I should install? 
I'm not sure what you're asking. I think you should just download the files in the Github repository if that's what you're asking about? 
I did, now is there a specific directory the files for the praw should be in for the script to access it ? I know in C and Java all your classes/functions have to be in the same project/folder but Ive never learned python so not sure what to do with the files here
Oh wait, were you referring to PRAW in your last question? Because you should have just installed it using pip. 
Nice. Mochi looks like what Python would have been like had it been designed as a functional language.
I think it will help if I explain: 1) why the package was created 2) what space I see it as filling now. For the first, when I started to work more with Python as a data scientist, I missed the clean chained pipeline style computations from Spark and Scala Collections. `PyFunctional` filled that gap in cases where PySpark is impractical and/or overkill. On the second, the primary goal of `PyFunctional` is to make data wrangling easier using data pipelines. As a result, although there is overlap with other FP libraries like `toolz` and `fnpy`, `PyFunctional`'s focus is primarily on things that make working with data easier instead of pure FP. Hence the recent focus on things like reading/writing pretty much any data format, more SQL support, and eventually parallel computation (perhaps overkill since Spark may be better suited at that point).
I think there is a recently-pyblished 3rd party module that can do the "look for a file in a bunch of dirs", but I can't remember the name (was probably on github). IMHO it's an anti-pattern anyway, it makes sense in an extremely small amount of cases.
Cool stuff, I like it. This would play really well with https://github.com/zalando/connexion and generally with celery based apps. I'll look forward to use it! Thanks
 If the addresses are static-ly assigned outside of the DHCP scope, they will still work and will have to be discovered directly (e.g. arp). Otherwise, I'm thinkin' one of the easiest ways to discover newly joined stations would have to be via its DHCP lease. This could be readily queried on your home router via python http requests module to the correct authenticated url; the one you'd normally go to in your browser to see its leases. Or via SSH to your Cisco router (e.g. show ip dhcp leases). Either way you'll be able to retrieve the MAC and IP, and Lease times (or even hostname depending on the router) without having to troll for the endpoints directly (again which you still may wish to do in case DHCP was not used). For that you might wish to consider arp scanning. Firewalls will typically block ICMP responses by the stations. Passive methods will likely work best... the station will make itself known.
I would recommend you look into / learn ZeroMQ. It has some great examples in Python and its messaging models are the basis for all of the cool applications out there today.
I don't quite agree because I can't see why an alternative interface useful for browsing the code wouldn't be useful for editing it indeed. Maybe that won't be the most important aspect of it, maybe I'd use a normal editor to write code most of the time, but still I'd argue that having the capabillity to edit/refactor code with the help of alternative representations can be quite interesting. Currently I am using Electron / Coffeescript for the prototype. I am planning to either bridge it with python/ruby/&lt;x-lang&gt; clients to support x-lang or to just use native js parsers/code generators for each language (there is a lot of choice because ruby and python have many js implementations, it really depends on what would be the editor goals in the end of the campaign)
On what system and what Python version are you? If you are just having problems importing tkinter, try both `import tkinter` and `import Tkinter`. Tkinter is the old name for version 2, it has been renamed to tkinter in version 3. Many tutorials just assume you are on either of these versions and fail to explain the differences.
My first gut feeling was like yours, that any sequence passed to `np.array()` should produce an array. However, if there is no way to determine the length of the sequence, I guess you would have problems with efficiency (having to reallocating the array as it grows). It would also be quite dangerous since you could fill your memory really quickly in the case of infinite iterations. EDIT: Realized that you wrote `__len__` **and** `__iter__` and not **or**, like I read it. So I guess we are already on the same page here :)
&gt; Afaik he basically is pocoo That's [really not true](http://www.pocoo.org/team/#team), and Pygments and Sphinx (which Armin uses but AFAIK doesn't really contribute to directly) are also under Pocoo. Armin currently has a bunch of projects under Pocoo and a bunch outside of it, he's not rebranding pocoo and it looks more like he's moving his projects under his own "brand".
In German "popo" is another word for "butt". 
I'd just use the standard kernel density plots in seaborn: https://stanford.edu/~mwaskom/software/seaborn/tutorial/distributions.html#kernel-density-estimation
It was added in v2.7.
I'm genuinely curious: does anybody actually use Firebird? What are its advantages over PostgreSQL, MySQL, Oracle, or MSSQL, or the plethora of noSQL options?
Looks like someone is trying to force their own philosophical views onto other projects.
What in the... Brett Cannon is a core developer who's been working on Python for more than 15 years, and PSF Fellow since 2003. What on earth makes you think he's not qualified to have opinions on how Python should work?
Basically the article doesn't offer any good points besides: - it's cleaner; - it's not that bad; The analogy between str/bytes is really misguided here, because the previous (os, shutile, etc) API worked using only text representations. We never converted it to and from any path abstraction and it worked. It's also rejecting the fact that people have been using libs inheriting from str/bytes (path.py, 300K dl last month) in prod for years. So really here, usage shows that not only the issues mentioned were not bothering the users but they actually liked the benefits. If you wish to handle edge cases, make an additional tool that does, but for the 99% use case, make it easy. Eventually, I think people made it clear on the python-ideas list they were not using pathlib because it's a convenience wrapper that is not... convenient. What's the point of having code in the stdlib that people don't want to use? Either remove it, or edit it to match the usage. Or find a compromise. But camping on "it's not clean, we got this small situation here that may not be perfectly handled" is not helping, espcially since the old API is still here to handle this case in the rare situations it's needed. ALSO: making an "open letter" without comments so people can't answer publically next to the article is really not appreciated. 
I guessed right, the new pallet website is made with Lektor, the new creation of Armin https://www.getlektor.com/
If what you want to do is highlight variations from a trend, then what you might try to do is find the trend line (e.g. the mean at each time point, or whatever is appropriate for your data); then identify datapoints that are x amount different from the trend; and only plot the trend line plus the divergent points. Again, without examples, it's hard to be more concrete, but as a rule when you start off saying a graph is "meant to be confusing" it's a sign that you might want to rethink your approach.
I love Brett Cannon, but the fact he is very qualified doesn't mean he can't be wrong. And yes, here, he has a philosophical view about this instead of a practical view. The problem with pathlib is that it appeals more to scripters, testers, and data analysts while the core devs are, well, core devs. So the typical use case for pathlib is something they seldom encounter.
So what? It still doesn't implement the interface.
The article offers *lots* of good points. For example: "You can't concatenate a string representing a path with some other random string and expect to get back a string that still represents a valid path." This means that `p"abcd" + d` (where `d` is some string) will either: - a) sometimes raise an exception (`ValueError` probably) based on the *value* of `d`, which is very bad style: it's reasonable to reject based on the type of the operands, but refusing to add with two operands of appropriate types is gross - b) vary its return type based on the value of `d` (`Path` if the combined path is valid, `str` otherwise), which is obviously terrible because you now need to validate that you got a `Path` back every time you concat a path with a string, making the object next to useless - c) always return a `str` when concatenated with a string, forcing anyone using this "convenience" wrapper to re-cast back to `Path` every time they do this, which is not more convenient than the current behaviour. Here's another good point: "why doesn't `dict` inherit from `str`?" JSON objects *can* be represented in string form, so why shouldn't I be able to pass dictionaries in to objects expecting strings and have the `dict` behave appropriately? The reality is this: paths *aren't* strings. They are structured objects with a well-defined string representation. This applies to many other objects that have well-defined string representations: - URLs aren't strings - IP addresses aren't strings - JSON-serializable objects aren't strings - XML-serializable objects aren't strings - HTTP requests/responses aren't strings All of these things in certain circumstances must be represented as strings and have a well-defined (but not-necessarily-unique) representation as strings, but the operations that are safe to perform on strings are not necessarily safe to perform on these objects. There is no good reason to have these objects inherit from `str` other than "because pre-existing code only accepts `str`". That is a good reason, but I'd argue it's not a good *enough* reason. In all cases it is simple enough to have a method on these objects that provides you with a `str` that can then be safely passed to naive APIs: that is more than good enough.
I think this kind of thing was alluded to in one of his blog posts recently. Basically the bus factor of many of his projects is currently 1, so he's trying to open up the projects to more contributors who could potentially take over for him. Presumably it also might help to have others accepting pull requests and other maintenance tasks. This all seems like a good thing.
Thanks. I'll check it out. I literally just started coding about a week or two ago. Do you think something like this would be too advanced for a first project or do you think this could be a good first one to really dig my teeth into? Thanks for your help. I really appreciate it. 
This sub is for news and articles. Try a jobhunting sub.
Makes perfect sense. Just because you can construct a Path from a str and you can render a Path to a str doesn't mean a Path IS a string. Saying Path should inherit from str because paths are represented as strings SOMETIMES is like saying dict should inherit from str because dicts are represented as JSON SOMETIMES.
Looks like a neat tool! Since you asked for a code review, here's a rather extensive list of nitpicks that I hope you find helpful: * What was the point of making this a package that contains a single module? Why not just make it a module? * What is the point of the lock? I'm confused about what you're actually trying to protect. * (33-34) Declare instance attributes inside `__init__`. Some sensible default (or just None) is usually better than an AttributeError. * (`get`, `set`) There's no need to special-case keys with no dots. Splitting will give you a list with one element. Additionally, I'm not a fan of the `while namespace` plus popping elements style of looping when it seems like `for name in namespace` does the same thing. * (43-44) What are you doing here? It looks like you're masking a genuine failure by returning the default. * (56-57) This doesn't look like it belongs in the loop. Perhaps instead you should loop over `namespace[:-1]`? * (60) It's probably a better idea to just try to get the item and catch the resultant TypeError if it fails, rather than checking for `__getitem__`. * (82) This is a classmethod, so the first parameter should be called `cls`. * (104) Use `cls` instead of hard-coding the class name. * (`__setattr__`) What are you trying to achieve here? It just looks like you're trying to stop people touching your instance attributes. * (117) Maintaining this list is going to be a nightmare. * (120-123) `super(self.__class__, self)` will recurse infinitely if you ever actually subclass this. There's a reason you need to hard-code the class name. These parameters are also accepted in Python 3 so there's no reason for the version test. * (125-126) Why no `__setitem__`?
Except path are represented as string in most languages, and has been, with no problems, in Python, for the last decades. Down the line, everything is a representation. The string representation for a path works, and we would like it to keep working with the new abstraction. It doesn't HURT to keep it. 
&gt; This objection doesn't even make any sense. Sure it does. You need to conceptualise what it means to be a string. Strings are a collection of objects with clearly defined semantics under a number of operations, one of which is addition. My objection is that making `Path` a subclass of `str` means that Path now needs to implement `__add__`, or it breaks this invariant: &gt;&gt;&gt; isinstance(x, str) True &gt;&gt;&gt; isinstance(y, str) True &gt;&gt;&gt; isinstance(x + y, str) True Put another way, inheritance defines a conceptual relationship between two types of thing. Traditionally, in OO programming, when we talk about `class A(B)` we say that "A *is a* B". My argument is that paths *are not* strings: they are subject to constraints. Put yet another way, there are many operations that are semantically well defined on strings that are not semantically well defined on paths. Looking at the Python documentation I see the following methods that make no sense on paths: - `capwords` - `translate` - `atof` - `atoi` - `atol` - `expandtabs` - `ljust` - `rjust` - `center` - `zfill` - `encode` - `decode` None of these are semantically meaningful on paths: that is, either they represent questions you cannot meaningfully ask of paths ("is this path an integer?") or they represent actions that do not meaningfully take place on paths ("please right-justify this path" or "please fill this path with zeroes from the left"). This is what Brett and I are getting at when we say that paths are not strings and should not inherit from them. Paths have string representations, but performing most string actions on paths *destroys* them. &gt; Strings were the base of path manipulation. We used strings to manipulate paths. Do you get it ? Strings. Paths. Yeah, we did. And no-one is saying you can't do that. If you want to, go ahead. What I am saying is that we should not be beholden to the mistakes made in our past. The Python standard library also spent a long time working with IP addresses as strings but it doesn't do that anymore: it uses the `ipaddress` module. But that module doesn't make IP addresses string subclasses because it makes no sense. It is not at all unreasonable to want the utility advantage of having path objects inherit from `str`: I understand the argument. I just don't agree with it: it's a bad idea that sacrifices conceptual integrity, clarity, and safety for saving programmers a few keystrokes when they pass an object to an API that requires a string. &gt; you ignore the fact that libs such as path.py does, and are used with huge benefits with little drawbacks, proving your simply wrong by simply existing and being used widly. I do ignore it, yes. The mere fact of existing does not make something a good idea. The implicit string encoding/decoding of Python 2 existed and was used very widely, and it was *convenient* for programmers who knew what they were doing and used that functionality safely. That doesn't change the fact that it was worth increasing the burden on those programmers for the safety and clarity of the many more programmers who *did not* write their code in that manner. &gt; We want it because we tried all solution in production, and one is better IRL. If that's the case, you can continue to use path.py. No-one is destroying it or taking it away.
That is a problem with operator overloading not the exception type being raised. Strings are not a field. I might as well complain that there is no way to subtract strings. What is the additive inverse of "foo"? \+ becomes concat, and it is entirely reasonable for a.method(b) to throw a value error.
Get your business logic out of your I/O. Does your business logic call into the DB in the middle of a function? *Stop doing that*. Does your business logic make HTTP requests in the middle of a function? *Stop doing that*. The way to make this work is to make your business logic entirely be functions that take data and produce results. They must not obtain data on their own or send data anywhere: they obtain data and produce results. Then, you write glue code around the outside that makes the DB/network calls necessary to send the produced results to where they need to go and to receive the data that the business logic needs. You will always need to write *some* code that knows how this stuff works, but your business logic can and should just be synchronous functions with no I/O of any kind. This is not a trivial thing to do, and it doesn't come naturally to most people, but it can be done. For an example of one way to do it with a quite complex network protocol, take a look at [my HTTP/2 network stack](http://python-hyper.org/h2/), which is implemented entirely in synchronous function calls and can therefore be used anywhere you want.
You can say that's a problem with operator overloading all day, but guess what: that operator is *already* overloaded. We have to live in the world we've made, and in the world we've made `sum(list_of_strings)` works just fine, so `sum(list_of_string_subclasses)` needs to work too.
Yeah, I'm just glad that requests is awesome and was being used in a some what sane fashion. But inheritance saved my ass there. Like I said, narrow/shallow. 
&gt; To make you happy it could overload __add__ to try concat and then raise type error from the underlying valueerror. That wouldn't make me happy. `TypeError` is also semantically wrong here. It has a defined meaning: "Raised when an operation or function is applied to an object of inappropriate type". In this instance it has not been applied to an object of inappropriate type: all the objects involved would have agreed that addition is an appropriate operation to perform on objects of their type. &gt; Nothing wrong with operators throwing exceptions, especially when they are overloaded. I just simply disagree with that. There are lots of things programmers expect to fail in only certain ways. For instance, it's not at all unreasonable to say that `x = y.z` should only throw two possible exceptions: `NameError` and `AttributeError`. But it technically *can* throw any exception you like: property access can run arbitrary code. My policy is that just because you *can* doesn't mean you *should*. Good code aims not to surprise. Addition throwing `ValueError` is, in my opinion, surprising: I can think of no data type used in production Python code that would do so. For that matter, addition failing to work based on the *value* of a type rather than its type is IMO surprising, and again I can think of no example used in production Python code that exhibits this behaviour.
&gt; We have a freshly lib in Python that nobody uses. What's the point? If nobody uses it then it will sit there and die. I don't really care about that. If anything I'd argue for a *smaller* standard library, so on a personal level I'd rather that pathlib didn't exist at all. &gt; The practical point is: it hurt really little to have Path inherit from string, and helps a lot. Ultimately I don't think I see "a lot" on either side of this. I see some minor gains from having Path inherit from string at the cost of conceptual integrity. The cost is, as far as I can tell, that when you manipulate paths you use Path objects, and then when you need to use APIs from the stdlib or other libraries you convert to string. Is that any different from the unicode sandwich model that we use with bytes/str in Python 3?
Haha, alright. I'll try to reapproach the issue, maybe use subplots. Thanks!
Your "gross" idiocy rejects the use of `__div__` for matrices. Think about that for a second. 
http://i.imgur.com/kzW7Ygk.jpg
Yes: there is no way to tell what encoding you need for bytes to get an str. The user must provide it, or provide logic to cope with it. No good solution for automatition. It is for pathlib. Computers should automate things when possible and not dangerous, espacially in Python. It's possible. It's not dangerous. It's not pure, so what ? We are not turning Python into PHP because of this, it's not going to creep everywhere and pervert the code into something unusable. It's just going to make people thinks "hum, str are not path, it's not very clean, but well". Having to call len() on object instead of having a .len method is not very clean. I personnaly hate it. Why did we keep it ? Convenience. With pathlib, it's remotly that bad. You probably won't even notice it most of the time. You will not get bugs out of it. Worst annoyance will be to have to see some string methods on path, and to have once in 5 years to go back to os.path.join because you noticed that pathlib is not going to handle your use case. Not a big deal. 
That *can* work, but this is not what I would use, if you have sparse data. I would look at scipy's `interpolate` module, where there are methods both for regular and irregular grid. Specifically, all the `BivarateSpline` methods can be interestig for that.
Your arguments are stupid. You want different rules for different operators now?! And I could easily give you number systems that don't have a groupoid structure for addition, but do for multiplication. You are just apply silly arbitrary rules of your own personal preference.
/r/learnpython
&gt; Computers should automate things when possible and not dangerous, espacially in Python. Sure, no question. We're not disagreeing on that at all: we're just disagreeing on *how* to do it. Your argument is that you shouldn't have to convert a Path into a string, it should *be* one. My argument is that it isn't and it shouldn't. In the first case, the conversion from Path to string is automated by the Path object. In the second case, it's done by the library whose API is being used. My argument is that we should encourage the second, not the first. =) &gt; Having to call len() on object instead of having a .len method is not very clean. I personnaly hate it. Why did we keep it ? Convenience. [That's not why we kept it](http://effbot.org/pyfaq/why-does-python-use-methods-for-some-functionality-e-g-list-index-but-functions-for-other-e-g-len-list.htm). &gt; You probably won't even notice it most of the time. You will not get bugs out of it. Correct, I won't, but only because I don't and won't be using `pathlib`. None of the code I write manipulates filesystem paths in any but the most trivial way, for which I already use strings and the `os` module: no need for a rewrite. Otherwise, I'd be looking at this as a very subtle source of bugs and would be constructing my tests to ensure that those bugs don't enter my codebase. You're right that it's not a big deal though, which is why I haven't got involved in the argument on python-dev. The reality is that I don't care enough about this to actually attempt to sway the discussion. All I wanted to do was provide the other side of the argument when you asserted that Brett's article contained "no good points". As I said in my first post: &gt; There is no good reason to have these objects inherit from `str` other than "because pre-existing code only accepts `str`". That is a good reason, but I'd argue it's not a good *enough* reason. In all cases it is simple enough to have a method on these objects that provides you with a `str` that can then be safely passed to naive APIs: that is more than good enough. Nothing that has been said in this thread has yet convinced me otherwise.
IIRC only things that can't go into a path in UNIX is / and null. Everything else is game. So, yes, there's A LOT of possible paths that you can't remove with rm in the shell.
Yes but you won't rewrite the entire Python ecosystem.
You could look over the overall design of your system. Mainly your problem seems to be separation of concern. Uncle Bob summarizes some architecture that helps with that here... https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html Also you should look over https://blog.8thlight.com/uncle-bob/2014/05/08/SingleReponsibilityPrinciple.html Basically, if you function/class/method is doing some business logic, it shouldn't be doing I/O also.
The concerns about atoi/translate/center/capitalization/enconding/etc... those make sense, but that seems to me to be more of a comment about how python str does ***too much***. A lot of python primitives just aren't that primitive. There is nothing simpler than a str. It comes down to python really having no object capable of representing a `char *`. You can't even do it with bytes, because `b"bar"` implements all kinds of crazy inappropriate junk you don't need for a path (a lot of it is inappropriate for byte arrays!!), in particular all the centering/justifying stuff you complain about above, but added to that things like `hex()/fromhex()`. Python painted itself into a corner where the only thing that Paths could reasonably inherit from if they don't want extraneous and unnecessary methods is "object." The reality is that we as developers do use str as paths all the time, and the only way to actually build a path is to initially accept it as a str (if you prompt the user for a filename or parse ARGV, you will get an str). And in order for any kind of method to actually do something with a path it will have to convert it to an str at some point. So I don't see a great loss in just accepting that they are strings. Although I would agree it would be a lot nicer if python had an abstract "simplestr" type which was closer to char *, and supported things like `concat`/`__len__` but not things that would be dependent on locale, or might pose interpretation problems for derived classes.
I know there are, and if enforcing Paths are strings prevents me from creating such a file, or interacting with it at all. I think that is great. Force someone to go in and fix the damn things, because it is a bug to have a bell character in a filename, even if the spec allows it. You are just asking for something to blow up down the road.
This is not really practical in reality. You are defining "business logic" in such a way that it excludes code that works out what DB queries to do. In fact, working out what DB queries to do is an essential part of business logic. Further, often business logic routines need to branch on the result of a DB query, and then do different DB queries in the branches that follow. Rewriting this to follow the style you suggest means that you have to do unnecessary queries up front, and pass that data in just in case it is needed. This is prohibitively expensive in many cases. 
&gt; I never said you should be painfully conscious about exactly how much exact time every line takes. That's the implication of the inner loop argument though. If your code is running deep down in someone else's tight inner loop, it would be worth to think very carefully about each line. But such effort is generally wasted time if you don't need to be worrying about things that much. &gt; Remember, later = never. No it's not. Again, this is all more or less the core of "premature optimization is the root of all evil". You write code, profile it, see what parts of it performance actually matters for, and optimize those parts. I'm not arguing against simple, no-brainer changes like using iter{values,items} pre-python3, but the general inner-loop argument prescribes far too much worrying about performance before you know it matters.
Not all files are made for human consumption. It's *not* a flaw for a web cache to store a filename with non-Unicode characters, for instance. It's a terrible, horrible idea to wish Python were unable to interact with standards-compliant files on the local system.
Thanks! Awesome feedback; I'll be fixing these issues ASAP. I made a full package since I have some possible feature adds down the road that will warrant multiple modules (ini support is one). I'm using a lock to support refreshing while config is in use. 33-34 - Yep, definite oversight. (`get`, `set`) - Good point; that's much cleaner. I like your approach to the namespace issue, and can't believe I made such a dumb mistake in super. 43-44 - `config.get('somevalue', 'default')` - I'd expect to get back `'default'` if `'somevalue'` is `None` or doesn't exist in config. I think this is appropriate. 56-57 - builds on your previous point about my approach to namespace, definitely is cleaner code and easier to grok. 60 - EAFP :) 82 - Yup. 104 - :) (`__setattr__`) - I want to steer users away from trying to manipulate the config directly, instead using `get`/`set` methods. This is a horrible way of doing it and I agree maintaining the list of 'allowed' attributes is horrible. Been thinking about the best approach to it. 125-126 - For consistency I suppose I should implement `__setitem__`, though I much prefer `get`/`set` and only included `__getitem__` because I think most people will naturally try to treat config like a normal `dict`. 
&gt; Except path are represented as string in most languages, and has been, with no problems, in Python, for the last decades. With a lot of problems I would say. I've seen plenty problems due to escaping path elements, joining paths, normalizing paths and so on. Furthermore path elements on Linux(as an example) are not strings, they are just bytes. So if you only use strings and not byte-arrays you cannot work with all possible paths.
Where "string" = "list of 8-bit chars", which is not where we find ourselves today. Python2 strings are still more or less this, but Python3 uses Unicode for strings. Maybe a more reasonable question would be "why not subclass 'bytes'?", to which the answer would still be "because paths aren't bytes, even though they're most often serialized as such".
No it is a flaw. Because someday that caching system will break and some poor schmuck is going up have to go in and manually remove the filename, and `rm` will fail, and he will have to resort to tricks with find to actually clean up the shit that your app has intentionally smeared all over the filesystem. Uuencode the string and cache the file in a safe filename. Python is not a system programming language and there are lots of things I expect it to prevent me from doing. Would you write an operating system in python? Would you write a device driver?
A path is a list of nodes in a tree. It's a data structure that can be serialized as a string. You can represent it as a string, but it is not a string. Python has a tradition of being relatively strictly typed for a "dynamic language". I found a serious bug in a PHP stack that we couldn't fix due to somebody's failure to use the `===` operator to prevent numeric strings from being treated like numbers in the comparison. This could never happen in Python because Python will never treat a string containing numerals as a numeric type. The cost is you have to explicitly parse your numeric data with `int()` or `float()` or `decimal()` or something. This is the exact same sort of thing. The cost is a very very very minor inconvenience. The benefit is the elimination of a whole class of potentially serious bugs. &gt; Explicit is better than implicit. https://www.python.org/dev/peps/pep-0020/ *And hey if you really want it to inherit from str class MyPath(str, pathlib.Path): ... **Ditto if you try to pass an `int` to a function which expects a `str` like `join()` or if you try to concat an `int` and a `str`. All throw `TypeError` in Python.
You say you would have it that Python could not interact with such files. That is, you couldn't use Python to go in and clean up the mess that such ill-behaved tools cause. That doesn't sound very useful to me.
&gt; That doesn't sound very useful to me. Useful for what? I don't expect python to be the tool I reach for to handle very low level system problems. Do you routinely change kernel parameters using python? Do you routinely set IOCTL's via python? When you are loading BPF rules do you use python? This is just not how python is used in practice. Its a high level tool, and a path library is a high level library within that high level tool. Its not intended to go down in the muck and mess with stuff like this. So its entirely appropriate in my mind that it should throw errors on some of these things.
The filesystem is also a very high level of abstraction, mapping tree-based based path descriptions to a series of chunks of backing storage, or onto maybe another tree-based information source (like /proc). I'm not sure why you think Python should - by design - be unable to fully interact with such a high-level object.
The [Hacker News guidelines](https://news.ycombinator.com/newsguidelines.html) express something that you should consider when arguing: &gt; When disagreeing, please reply to the argument instead of calling names. E.g. "That is idiotic; 1 + 1 is 2, not 3" can be shortened to "1 + 1 is 2, not 3."
To add on to this, it might also be nice to make distinctions that the file system makes, for instance between directories and files (and symlinks, etc.). If you do this, then you can define operators that combine directories and files but disallow combining a file into the middle of two sets of directories: files may only reside *in* directories and directories may not reside in files. This kind of logic can be enforced by the objects.
I offer this advice as a friendly observer: that language shuts down conversation and makes the other party instantly dismiss anything more you wanted to add, regardless of its merit. You shouldn't do that, not only to spare Lukasa's feelings (although it's always good to be kind to others) but so that your ideas are heard and not immediately rejected without consideration.
You probably will need this pages: http://www.tkdocs.com/
It's not a flaw to have a system that uses, for example, ISO-8859-1 for file names. Not everything is upgraded or replaced every fifth year.
This would be a reasonable argument if the whole word, including Python, for the last 10 years, haven't being using string to manipulate path without. There are errors for casting int to str and vice versa, because they can be representation of very, very different concepts, and the conversion can be ambigous. None of it is true for path: - you can represent most path using a string. We have been doing it since ever. In fact we didn't have an other way to do so before pathlib. By you never raised any argument about "string" != path, because there were no distinction. It didn't bother you at all ! - now it bother you for purity reason, because the distinction exists, but you can't provide common use cases where this would cause a problem while I can provide 10 out of my head for str vs int; - the rules to convert a path to a string, and a string to a path, are well defined and clear. And you know why ? Because we have been using strings for paths during years. - did I mention we are already doing it, people saying they don't want to are still doing it (you are). You are using strings as path. Don't lie, you probably did it this month. How did it go ? Well. As usual. - we have a long experience of practice to tell us autocasting str to int or bytes to str leads to terrible problems. We have a long experience with... wait for it... using strings as path ! - what if people use str functions on Path ? Well, they already do on string representing paths and ... well nothing they do it all the time and it's fine. - Python has a long history of duck typing, not just strong typing. You can do "stuff" * 3 in Python. Do you use it ? I don't. But I would surely like to pass my pass object to this 3rd party lib that doesn't handle them without having to cast it 10 times in my script, thank you. - let's make sure path has a string like behavior so it can be used where we would use string if you don't want to make it inherit from string. 
&gt; Not all strings are paths is easy enough to understand, but what is an example path that could not be represented as a python string? How did you do it before ? Because until now, and before pathlib, people have been doing exactly that: using strings. And it was alright.
If your system is configured for a specific encoding and you write a filename that violates that encoding. I would think that is a flaw. So I don't get your point at all.
It is absolutely practical: it's just not *easy*. For example, you talk about "working out what DB queries to do". This is very different from *actually doing a DB query*, and can absolutely be done synchronously without I/O. Similarly, forking execution based on the results of a query is also fairly simple. Consider this code: def get_first_query(): if case_1: return "SELECT * FROM table_a" else: return "SELECT * FROM table_b" def second_query(result): if some_logical_test(result): return build_some_query() else: return build_some_third_query() def main(): query = get_first_query() result = yield from DB.execute(query) query = second_query(result) result = yield from DB.execute(query) This code cleanly keeps its I/O away from its business logic. This is not an easy or convenient way to write code, but it is absolutely do-able on large scales. You can, for example, write an entire web application in this way, with the server included. I know this because I've done it!
I'm not saying it always does, it's just an example, but at some point it may well happen. And when it does, it'll be too late to fix your shit code. Writing O(n^2) code that should be O(n) and O(n) that should be O(log n) is as sure a sign as any that you don't really know what you're doing. It's not hard to do better. It doesn't take extra effort. It just requires awareness. Actually understanding the problem is never premature.
Looks like those slides are ignoring L2 altogether. Looks like what you need is a client that calls a server API when it first connects to a network. That's one way of skinning this cat...
Why not load bpf rules using python or ioctls for that matter? It depends on the usecase.
The E in ELK is Elasticache. It's a key-value store. Not something one runs a regex against. Most installations use Apache Lucene to run queries against the data in the cache. It seems you're trying hard to convince yourself that machines need to read logs, but I can't understand why. Log files were made for humans. Data stores were made for machines. Why are you averse to using a data store for metrics?
I see. What we need here is `StringMixin`! /s
Well right, but we can't duck-type a string, in this regard. I don't disagree with you, personally. Practicality trumps imo. I find the notion that I should be accounting for their utility class in all of my libraries that accept paths absolutely bonkers.
Not sure if this answers OP's question. At least I still don't understand how your I/O can be async based and your business logic not (meaning the business logic are coroutines). Edit: your example in the other thread clears it up.
Isn't the code in the main function basically synchronous code? Edit: ok, I think I get it. Business logic is in regular functions in between async io calls. The example is just kind of incomplete in regard to the async implementation.
Perhaps you want to learn networking before you dive in to network programming? There's a lot that goes on that is abstracted away from you once you start programming with something higher level like sockets, but it's incredibly helpful to know what that is. The classic *Computer Networks* by Tanenbaum will do you very well. Don't need to read everything right away, just learn the bits and pieces that get you to L3 / L4. After that, you should readily understand the documentation for Python's built-in libraries that deal with networking. As for the patterns built on top, that's where you need to get a little more specific. There are a myriad of tools built on top of a computer network. Protocols for video, voice, chat, telemetry, you name it. Services for messaging, for running jobs, for distributing configuration, for discovering other services. And there are patterns and tooling for each of these. Maybe name a project and we can dive into the architecture?
So what you mean is: use os.stuff to manipulate strings are path. The problem is NOT the fact that path are represented as string, but that people are using tooling for strings to manipulate paths. The thing is, when you use pathlib, you are likely going to use pathlib capabilities, so you'll get it right. But you won't make people use pathlib unless you can pass it easily to the libs that do it wrong without having to think about it.
No python3? That sucks, Amazon 
I don't see what's so hard about casting the Path to a string or updating libs to accept Path objects. I think the benefits outweigh the costs. That is necessarily a subjective judgement. I understand that you have a very strong differing opinion. But hey it's open source so if you don't like it, fork it your own custom pathlib implementation or use one of the other pathlibs out there. Problem solved, for you at least. Standard library is where modules go to die, anyway.
I'm a long-time user of `plumbum` for path handling, and some time ago they went ahead and made their `LocalPath` objects also strings. It works for me. I have no experience with `pathlib`. &gt; . . . `p"abcd" + d` (where `d` is some string) will either . . . So checking this against `plumbum`, the equivalent would either be local.path('abcd') + d which consistently returns a `str`, or local.path('abcd') / d which consistently returns a `LocalPath`. Neither of these ever lead to case `a` (exception) or `b` (varied return type). The `+` operator leads to case `c` (`str` return type), but if the programmer intends to cast it back to a `LocalPath` they can and should use the `/` operator instead. I agree that there are good-enough solutions that don't make paths inherit from `str`s, but I also don't see any problems in the way `plumbum` has chosen to handle this. 
Thanks! Very helpful. I ended up rewriting some code and passing both a filename and path to my open functions.
Are we the 1st of April ?
Most or all of the main GNU tools are already available for Windows. Why would this "surely" not have them? 
how much is 5 + 5 ?
Hi, I encourage you to check out the free eBook [Introduction to Big Data](https://github.com/haifengl/bigdata) written by Haifeng Li. It's quite good, I'm also reading it. I hope people send pull requests for when they find errors or inaccuracies.
Missing: PLOT. Anyone, is there any usecases?
I don't follow you. Strings basically are lists, I don't see why having str be derived from list would be problematic at all? list implements the following that str does not: `'sort', 'insert', '__reversed__', '__delslice__', 'reverse', 'extend',` `'__delitem__', '__setslice__', '__setitem__', 'remove', '__iter__',` `'__iadd__', 'pop', 'append', '__imul__'` all of those make sense if you think of str as list of chars. It would obviously be terrible to implement it that way, but there are no difficulties if the type system claims they work this way. In fact in some ways this might be better. If you for some reason want to sort the letters in a word (maybe you are building a scrabble word engine tool) then `sorted("bar")` doesn't return a string but rather the list `["a", "b", "r"]`. It would make more sense to me if sorting a string returned a string (which is exactly what str.sort() would presumably do). 
That's never bothered me. The classic example is "file-like". It's not an interface in the Java sense. It's more relaxed. Duck-typed. I find it more pleasant. There's theoretical arguments we could have on the merits of formal interfaces. In practice, I find them less necessary than I was taught in school.
because they know how linux is built and maybe a team of microsoft and canonical engineers were a good match for that task
Speaking of cmd.exeâ€¦ I hope Microsoft knows that it's hitherto been a completely pathetic terminal emulator. 
I'd expect they do. But if you wanted to demo it, you'd want to do it with no third-party tools. And cmd is what they have at the moment - I don't think they have a native ssh client. But people will just use putty, or fire up a X-windows environment from their cmd bash shell.
That's the easy part, if the shell is there anyone can add whatever tools they want.
My main guess is that Microsoft are tired of trying to get a good implementation of a shell that's super nice. Sysadmins aren't using GUIs as much, and when you tell them they want to learn PowerShell to script in Windows... hence motivation to bring over bash.
They all know... it's just bogged down in miles and miles of backwards compatibility and technical debt woes, I bet.
This news is breaking all over reddit's tech subreddits. . . it is crazy. Good, but crazy. A couple people at work thought that this was an early April Fools joke. Windows now supports SSH on the client and server (still not fully released though) and now bash. .NET runs on Linux as does SQL Server. . . Strange times indeed. I'm watching to see where this all ends up.
The syntax of the actual shell is totally different. Commands like `for` and `if` are not external tools, but part of the shell itself. Whatever you write for Bash will simply not be valid syntax for the Windows shell.
Any chance this will make installing python libraries easier on Windows? Or using Linux-only machine learning libraries? I'm talking the likes of tensorflow, theano, etc. 
It's called modules. And it's easy. 
Yes, powershell are not neat as it would be. But what that MS will get? 
&gt;Finally As if we haven't [had this for decades](https://www.cygwin.com/).
Something like that anyways. 
They are expecting behavior in one language coming from another language. My guess is they have an in-house language and don't really deviate from that, but, needing to have a client for their service in every popular language, they had to get their hands dirty. And now they're making bold claims that Python's standard library is broken without putting much effort into fully understanding it. It bugs me.
LOLOLOLOLOLOLOL. Only 40 years late.
I haven't compared against pymc3 yet, but I will soon! I have been heard from word of mouth that pomegranate is faster for the things which it can do, by pymc3 has more features in that area. 
"Posix layer" is not the same thing as the GNU tools. Some of the GNU tools may or may not use elements from the POSIX standards, none of them as far as I know are called Posix tools.
No they really are bytes. That is what the C standard library and posix specification essentially say. "Pass me a `char *`, I'll try and figure out what inode it corresponds to." If that is not an str, and its not bytes, then what the heck is it? Honestly it wouldn't make a huge difference anyways as the two types have very similar interfaces. The only differences being that bytes implement `'fromhex', 'decode', 'hex'` and str implements `'isidentifier', 'isdecimal', 'encode', 'isnumeric',` `'format_map', 'isprintable', 'format', 'casefold'`. I can't imagine a valid use for any of those methods for paths anyways, so I'm not seeing a big negative in using bytes as the base class.
So it's basically Gnu/Windows.
Dr. Python Or How I Learned to Stop Worrying and Love the Numpy
no, use diagram https://sourceforge.net/projects/dia-installer/ even faster
I don't really know... why? Unless MS is also bringing all the coreutils, having just a shell doesn't seem like it'd be capable of very much.
Fun story: the whole reason I started using Linux for the first time was because I hated cygwin so much.
Thanks! This has covered a long standing itch I've had with promoters of alternative datetime implementations and random Joe Schmoes saying datetime is broken. It's horribly named, under documented and has a confusing API. It is /not/ broken. pytz &amp; datetime.datetime are a perfect match.
Human sacrifice, dogs and cats living together... mass hysteria!
If windows keep heading this way it will eventually adopt a Unix - based kernel and a lot of their headaches will go away.
There's plenty of free stuff online. Only do paid if you have more money than time.
The Unix way is just so damn good.
Yeah. That's kind of what they have done. 
They are bringing the entire Ubuntu distribution with them. 
Rather: most of
What do you mean by real time? There's going to be some latency in processed audio no matter what tool you're using, how much latency can you tolerate? Your answer here will dictate the technology you'll be allowed to use...
Sure, but I'd imagine there are plenty of engineers at Microsoft well-versed in Unix and how Linux is built, too. They specialize in Windows but surely have an intimate understanding of the architecture of all the technologies involved. I just don't see why they'd need help. But whatever, just kinda surprised to see it. It's cool either way.
Individual elements are indeed bytes, but whole paths are conceptually _not_ bytes but nested data structures that are often serialized and represented as a byte string.
Virtual Box in seamless mode with Mate has changed my life. The only tricky part is setting up shares for host file access and multiple monitors. 
Here too. Cygwin works just well enough that you can do a lot until you can't and have to waste a whole work day trying to get it working. Install a Linux VM and you're up and running in 2-3 hours.
It has `apt`. I don't know if it includes the entire Ubuntu repositories or not, but heck, maybe you can even install Python!
Also has little-to-nothing to do with python, doesn't belong here imo. 
So writing software assuming a bash environment is irrelevant for python development? Compiling natively with cpp on windows. Etc.
If there were an OS out there, that had a standard library where basic file operations were performed by passing in a vector of tokens, then sure I would agree with you. But nobody uses such an OS, and python explicitly adopts the C standard library approach. In C you `fopen(char * filename, char * mode)`, in python you `open(str_filename, str_mode)`. I don't `open(["home", "username", "file.txt"], "r")`. It is expecting a string or byte array, that string is a path to a file which means the argument to open "/home/username/file.txt" defacto IS a path. Which means paths should be strings/bytes. ---------- I don't object if the internal implementation of the path keeps track of this heirarchical structure, as long as it is still at the end of the day, interchangeable with a string, because that is how we use it. Now I will concede that there are some string methods which don't make sense for paths. Things like isdigit/isdecimal/isidentifier/ljust/rjust/center/etc... but my response is to say that these probably shouldn't be in the basic string class. Maybe there should be a `simplestr`ABC that has the more basic things which are appropriate to standard string manipulation, and would make sense in a general context. [It is even stranger that bytes has some of these functions. What does `bytes.center()` even mean? It depends on how the bytes are being interpreted which is something that the bytes class cannot know.] 
I'm gonna be so happy in general when we get Windows 10 at work later this yearâ€¦
Even without Cygwin, Microsoft itself used to have [Windows Services for Unix](https://en.wikipedia.org/wiki/Windows_Services_for_UNIX) and [Interix](https://en.wikipedia.org/wiki/Interix), which included bash. They had deprecated it for Win 8 and retired it for Win 10, but here we are again with something at least superficially quite similar. SFU and Interix were shit though and I hope they have nothing to do with this new setup.
This is literally ubuntu linux on windows. You can apt-get install anything that is avalible on normal ubuntu.
I've found datetime as a library to be really frustrating. So many hoops I have to jump through to move between time formats when I have all the variables. I think I had to write my own helper to move from a timezone aware datetime to an integer of POSIX time. But dates and times for computers are complicated. So really I should just work to improve the documentation or use a library that abstracts it further...
You can't do an FFT in real time. You will ALWAYS introduce some latency. The amount of latency introduced is going to depend on the desired frequency resolution. If you want high frequency resolution, you need a lot of samples for your FFT, which is going to increase your latency. So in essence, if you want low latency, your resolution will be shit.
A couple of things, complexity and inconsistencies. When using Powershell, I need to look everything up because it is just so complex and verbose.
Thanks!
Will I be able to use cron to schedule things?
The headline is kind of shit - they seem to have a good chunk of the other stuff as well. Looks like they essentially made a MS cygwin but with Debian package management. With canonical on board I imagine poets will be forthcoming for most common packages.
No, you do not have to reimpliment anything at all, you can just have mixin classes that encapsulate methods how you want them. This is how PRAW for example is built. The point is to encapsulate smaller types to make larger types. Internals always depend on internals, that does not matter, the largest end of the stick is your users not depending on your dependencies and this is the most important thing to ensure most of time. Its more important to be able to remove code then it is to be able to add code.
You can with Xen, or if you want to be really fancy you can use a separate GPU on a linux host to virtualize windows 10 with dedicated GPU passthrough (so you'd need one GPU for the host and another for your virtual Win 10 instance). What's cool about Xen is that you can virtualize with only a 2-3% decrease in performance, compared to VBox which when used on Windows or OSX usually incurs at least a 20% performance hit.
Considering what a pain Python is on native Windows, yes it does. The title is misleading, this isn't just bash but full-blown Ubuntu. 
So if I was to for example, listen to a note played by a Guitar, and were to process that note, comparing the frequency to a constant, I would then want to be able to act upon that comparison and calculate the difference in frequency, the faster the better as I will be putting the difference to a Servo to aid in a tuning process.
Python is duck typed so sure the actual MRO and inheritance tree don't have to match up with the way things behave, but it remains that paths should be str. If that is purely from a duck typing perspective... whatever I don't care. I could import a class like `numbers` which forces isinstance to return the values I want. Who cares about that. So sure mixin a str is fine by me. An example of why this might matter: suppose I have some kind of storage device that only accepts str as keys (which is popular in some nosql models). If paths and urls and the like are not str's then I cannot use them as keys in this database, I instead have to explicitly ask for a serialization. Which is silly because they are strings, that is how the user enters them into the system.
I went the route of using the shares option and making an auto mount share. It's not immediately obvious that to use those shares you need to be part of the proper user group. I'll look at yours too though, because I really need to get some experience in samba.
And improve Wine for actual Windows programs? That would be heaven. I was already considering using Windows on my Macbook because Windows is best supported OS on a Macbook (and Mac OS X sucks donkey balls)... and running a VM in Windows to run Linux on it (which is the actual OS I want to run on my Macbook but Linux has terrible support for Mac hardware so can't do it natively). But now nothing will stop me from doing that. Anything else is just bonus.
I'm assuming that by "live feed" that you mean from a microphone or direct input to the soundcard, and not an internet stream or something like that. There are two libraries that I know of that do this, [PyAudio](https://people.csail.mit.edu/hubert/pyaudio/) and [python-sounddevice](https://github.com/spatialaudio/python-sounddevice/). Both are bindings on top of the PortAudio library which is written in c, so they're pretty low-level. The latter actually has an [example](http://python-sounddevice.readthedocs.org/en/0.3.2/examples.html#real-time-text-mode-spectrogram) on how to build a live spectrogram that you might find relevant.
Keyboard shortcuts are an abortion. Because it is Java PyCharm is the *worst* OS X citizen on my machine. Cmd-up arrow should take me to the top of the file. It does not. Nor does down go to the bottom. Even when using the "OS X 10.5+" key map. Cmd-w to close a window does not always behave properly: if the last place you have focus was to a panel it closes the panel. That is absolutely the wrong behavior *on the mac* but Kava, and by extension JetBrains, *does not care*. I have all reformatting of strings on paste disabled and yet pasting a line longer than 80 characters automatically PEP-8s my code. Worst OS X citizen I have to deal with. I don't know why I immediately bought the updated license but I did. I regret led it immediately, especially since I had 8 months left on my existing license for 5. 
I use Virtual Box, it runs like a charm on windows. MacOS should be pretty decent unless you really want to have fun. For that I'd recommend Kali Linux. 
* I still don't think this needs to be a package. I'll write 1000 line modules before I even consider making a package. The standard library seems to take a similar approach. The `decimal` module is over 6000 lines. * I don't see the point of the lock. If someone is using this in a multithreaded scenario and are simultaneously setting values and refreshing the config, they're likely to start dropping things. Ultimately all the functions only access `_data` once each, so they're all about as threadsafe as they're going to be anyway. * (43-44) I would think that's fine, except that `default` defaults to `None`, so now the user has to check the return value every time to see whether the value was really there. This is analogous to how `dict.get` works though, so I'm not sure what approach you want to take. As it stands, I'd be more likely to use `x = config['a']['b']` all the time instead of `x = config.get('a.b'); if x is not None: ...`. * Regardless of how you feel about the above point, `if not temp: return default` is going to replace any falsy value that was actually present. * (`__setattr__`) Don't bother. Naming a variable with a leading underscore says "this is an implementation detail, don't touch it", but nothing is truly private. The user may touch any "private" variable they like, but the mess they create is their own. I would just delete this whole method and optionally add leading underscores to anything you want to protect that doesn't have one already.
Parting (screen)shot: https://twitter.com/shanselman/status/695738082209853440
It's really not worth it unless you're super paranoid about windows having root access. Tek Syndicate has a pretty good video on how to do this. Tbh I'd recommend dual booting with separate SSD's, wayyy more simple than virtualizing with a hardware passthrough.
This neat trick adds draws a yellow border around a cell which is running. div.cell.code_cell.rendered.running { border: 2px solid #FFFF00; width: 900px; }
I use Virtualbox on Mac OS X now too to run Ubuntu... But I want to use Microsoft's own hypervisor on Windows... which I assume is much better than Virtualbox. I don't know about Kali Linux though. I'll stick to Ubuntu LTS.
Definitely know what you mean haha. VBox is great, but it's not *that* great. 
Incredible if true. I have a kind of tangential question. So this isn't really different from what cygwin does, right? Except with cygwin we build everything from source but apparently Microsoft will be making it possible to get binaries with mere apt-get. Does this mean Windows will be natively supporting ELF?! The implications are a bit mind-bending but to be clear, assuming a complete syscall translation layer is already in effect, how big of a leap is it from there to running let's say a totally statically linked ELF binary natively? From what little I understand of these formats, it now doesn't sound much but then I wonder why it isn't already possible with cygwin.
Canonical has all the Linux user-land software packaged and ready for distribution. Microsoft just supplies the Linux-compatible ABI. They could have rolled their own "Linux distribution" (without the kernel) but that would have taken time. Why reinvent the wheel?
It includes apt Source: http://blog.dustinkirkland.com/2016/03/ubuntu-on-windows.html?m=1
Ports aren't even required. It's like Cygwin but built into the operating system. The program's don't have to link to a special DLL (a la cygwin1.dll) or be packaged as PE. Windows will now natively load ELF binaries and know how to handle Linux syscalls. Binaries compiled for Linux should just run. The full level of compatibility is yet to be seen though since Linux is really a complex web of interdependent components outside the kernel. 
Fair enough, I stand corrected. I'd not read much since the first story earlier today.
Does this mean we can grab a linux distribution of GCC rather than use cygwin or mingw? That would be so awesome!
The issue is late binding of lambda expressions. a = [lambda: i for i in range(5)] for func in a: print(func()) Should print "4" for all four. This is fundamentally what your listcomp looks like, so your lambda is returning only the last protocol generated. The workaround is just create them one at a time or capture them in a closure using a different function (the way you have). 
Oh man those are great points! I'll edit the post to reflect those for coverage. It is python 3, but some people might not be able to deduce that so it needs to be said. Debugging was mostly the reason. I was told that the file was throwing an error when being import into Microsoft SQL Server so I was encoding it to ascii to be certain that everything goes in fine. /shrug. Thanks for your input!
Google it, you will be amazed.
Python packages not being released for humans...crazyness.
I am with you on this one.
Is this basically an ubuntu VM running on windows?
Confirming Ubuntu is the Windows of Linux distros.
They state it's not a VM, but rather a "Linux subsystem".
Agreed this has impact for just about anything Unix-like that you can do on Windows. EDIT: I've been using Python for over a decade and quite a bit on Windows actually. While Python does run on Windows, it's still more "native" on Unix platforms IMO.
Cygwin's already there
But the main issue is that vim (and most `$EDITOR`s) need to use stdout as well. What do you suggest? The obvious solution around that is to perhaps use a GUI editor like ST3 or MacVim. **UPDATE:** remembered `/dev/tty`. Currently a PR is made to the [python-editor](https://github.com/fmoo/python-editor) library that `takeit` uses to use tty instead of standard stdout.
At least OS X is *nix. Windows is painful to use purely command line. That said, I'm running Elementary OS on my Macbook Pro and it runs very well.
OK so I wrote the script and I imported solar, it seems to run part of my script and it imports the modules (which I am very excited about) but it says that the function "GetAzimuth(latitude_deg, longitude_deg, d)" is not defined. I don't see why I get this error. Also, I changed the import command form: "from . import constants" to: "from constants import *" and I stopped getting errors from modules, so this seems to be a step in the right direction. Let me know what you guys think. click here to see updated files: https://goo.gl/9jckCi
Still wouldn't. Sounds like a way to make Windows users not feel guilty about not using Linux.
From what they say it's actual linux binaries supported and executed by a linux (ubuntu kernel) running as a windows subsystem. My best guess.
&gt; That means the class of things which are paths are a subset of the class of things which are python str's, and for typing purposes that means you should have paths as an instance of str. Much like [`Square` should inherit from `Rectangle`](https://programmers.stackexchange.com/questions/238176/why-would-square-inheriting-from-rectangle-be-problematic-if-we-override-the-set). Hell no, you shouldn't be able to say p = Path("/my/path/to/something") newpath = p.replace("path", "other") and get a new path. (because for example you could do `p.replace('m', '/')` and now you've broken everything. So any string operation on a path can't return a path, it has to return a string. Which is fine, but then you aren't gaining anything from path being a string as long as it can be coerced into one. p = Path("/my/path/to/something") newpath = Path(str(p).replace("path", "other")) is a lot more expressive. Furthermore, there's no guarantee that `str(x) == str(Path(str(x)))`, whereas `str(x) == str(str(x))` for any string x. as an example, &gt;&gt;&gt; x = '\//\/\//\/\//\/\/\/' &gt;&gt;&gt; y = pathlib.Path(x) &gt;&gt;&gt; x == str(y) False Or even more obviously, on windows any number of forward slashes is coerced to a single forward slash in a path. 
That's how I interpreted it too.
Saw a presentation on this today. Feather is an exact representation of what the data should look like in memory, which is according to arrow's optimized format. So there is no translation that needs to occur. This is fast for loading but also means you can read it by anything that understands the format.
As a noob, what is Bash and why is this a big deal?
Anaconda is fairly problem free on Windows these days.
Linux ELFs are loaded and executed natively by the NT kernel, system calls and all! It's actually pretty similar in theory to the way FreeBSD implements the Linux ABI
It's a translation layer that maps all sys calls to NT kernel equivalents. It allows bit for bit identical binaries from Linux to work in Windows. Not everything works yet. Being a little pedantic, but it should be clear that this is not Linux, because it's not using the Linux kernel, and it's not full blown Ubuntu for the same reason. It's closer to GNU tools being ported to Windows. It's extremely awesome, but I just want to clarify that point. Since we're all engineers here, we can do away with the marketing line.
It's not running the Linux kernel. Everything is translated to NT.
/u/jorge1209 is referring to this: &gt;&gt;&gt; {}.keys() | set() set() &gt;&gt;&gt; {}.keys().union Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: 'dict_keys' object has no attribute 'union'
yes that is true and it will likely not change anytime soon. Outside of reddit people usually do not care about the version as long as it does what its supposed to. How much C(++) code do you find thats not the latest standard?
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Ah, that's led me down a rabbit hole. So, I'd have expected that `{}.keys() | set()` would work because of `set` defining the or operator and python trying both `__or__` and `__ror__`. However its not. Now a fun question: what will be the result of these (some may throw errors) {}.keys() | set() {}.keys() | {}.keys() set() | [] [] | set() {}.keys() | {} {} | {}.keys() {}.keys() | {"a": 1} {}.keys() &lt;= {} {} | [] set() | {} {}.keys() | [] {}.keys() | {}.values() # for fun Honestly this behavior makes very little sense to me. Its not well defined at all. A pep indeed.
Right now I'm testing against 2.6, 2.7, 3.1, 3.2, 3.3, 3.4, 3.5, pypy &amp; pypy3. I'm looking to confirm that I don't need to support 3.1 &amp; 3.2.
&gt;I feel like I keep finding snippets of code in 2.x, are most people still using legacy code on this version? Most people still use 2.x.
No. "WINE, but backward" is what I've been seeing a lot. 
It's not just the shell. What I've been seeing a lot of people saying is that it's like WINE, but backward, with Ubuntu as the other OS in that equation. 
You could try audiolazy https://github.com/danilobellini/audiolazy 
Oh, didn't know that. Thanks dankfully.
Honestly, I get sick of doing awk and sed hacks and redirecting stdout stderr screen scraping grepping, worrying about spaces in filenames and the like. What I am getting at, is that it would be nice to have real data types between programs. JSON or http://msgpack.org/ would be fine. Windows PowerShell actually provides something closer to real data exchange than UNIX does at this time. It would be really cool to have `ls` `du` and all other UNIX commands to have a `--json` or similar argument and be able to process those in Python and other higher languages. Honestly, if this happened, I think shell scripts would almost be obsolete.
If you are into web development look at https://www.fullstackpython.com/ which is in the sidebar.
These are great resources. I wanted to supplement them with the following two as well: This explores, in detail and in Python, how to decouple various parts of a function: http://justanr.github.io/exploring-code-architecture And this is a parallel, slightly simpler look at Clean Architecture: https://www.youtube.com/watch?v=yTkzNHF6rMs By combining these ideas, it should be possible to decouple your IO code and business logic. I also wanted to second u/Lukasa that this is indeed very hard to do and I don't personally know of any person that could get this right the first (or second, or even third) time - it usually requires a bit of refactoring and time to think.
pypy3 is python 3.2.
So MS don't have to do the distro bit. It looks like there's a minimum package that gets you bash, apt-get, and other standard tools, and you apt-get the rest. Canonical produced that package, and apt-get is pointing to their repos.
I'm starting to see more and more your side of view. After spending a lot of energy trying to convince people to inherit from str, I just realized it was easier for me to either let it go and use path.py or cast to str than discuss. And if it is, it means that it was not that big of a deal.
&gt; what about emacs? [Here's a blog](http://www.hanselman.com/blog/DevelopersCanRunBashShellAndUsermodeUbuntuLinuxBinariesOnWindows10.aspx) from an MS dev who had to close the emacs window because he couldn't figure out how to exit ;)
https://www.youtube.com/watch?v=L0ag9Sll6RI
What, like [a Python script with inline assembly](https://www.reddit.com/r/Python/comments/4bu3i5/there_is_inline_assembly_in_this_python_script_%E0%B2%A0%E0%B2%A0/)?
I'm going to annoy *literally everyone* by calling Win10 "GNU + Windows".
No, and I will explain the difference. A VM is pieve of software that runs and makes it appear as if a while new computer now exists that you can interact with. The host has dedicated a portion of its resources to allow that virtual machine to run as a standalone unit, completely independent of anything else happening on the host. In contrast, what is happening here is that your same machine has had its instruction set extended so that now it can natively understand the syscalls that it couldn't understand before. Windows is able to Natively execute these Linux syscalls as long as they are issued to the new Badh software being released, because that is where the dictionary lives that explains how to interpret the Linux calls. We are not, however, running a completely new kernel or anything, just building am extension of the existing one.
Indeed as this appears to be a huge part of the reason a lot of technical people use OSX. They should have done this a long time ago but OSX beat them to the punch mostly. If you go to Pycon or a lot of developer conferences and look around the room you see Macs. That's not by accident. 
Backwards compatibility? 
Old people having old people.
Conical knows it better as you said plus to my understanding it includes a few things beyond bash like apt which conical already has all set up and maintained anyway. So splits costs, labor and leads to faster turn around. Tech community is happy and this wins all around except for Ubuntu/Windows haters who would hate them both no matter what.
Honestly I think this a push less about end user tools and trying to bring Windows servers back. While yes it allows more end user friendliness the market Windows gets most destroyed is server.
But why doesn't `utcnow()` return a timezone-aware object? Is it just because it doesn't know which timezone library you're using?
The thing is, your primary logic function is now the function `main`. It might be called something like `get_user_documents` or something. It is therefore definitely business logic, and it is definitely doing IO (unless DB.execute doesn't actually execute DB queries?). So I don't see how this achieves the aim of not doing IO in business logic functions. EDIT: Alternatively, your main function is actually meant to be some kind of entry point, but it is now embedding in it part of the logic that actually belongs in a `get_user_documents` function - the details of the business logic are not included, but the structure of the computation is. Either way, you don't end up with a `get_user_documents` function that encapsulates business logic and doesn't do IO. To have functions that don't do IO but encapsulate business logic properly, you have to do something like the interpreter pattern, which is quite a lot more work (Haskell has a lot of help here with the Free monad interpreter pattern, but it is still a lot of work). It also has the same effect on your stack of code as the transformation to async does - everything has to be rewritten, because the return type of business logic functions return has changed.
I can only recommend pyo. 
so with bash comming to windows, what will be a good way to learn the command line?
Dr. Venkman, you were always my favorite Ghostbuster.
Not only backwards compatibility... It can be universal across all windows Devices...
Whichever version of python you need the library for, if you are doing python 3, typically 3.3 or 3.4 and up is easy to support (with exceptions). Obviously you rely on a feature not in older versions dont support them, if your users care enough they can port to legacy python themselves, save yourself the effort of that and just put your effort into making your library as good as you can for your useage.
/r/learnpython If you're asking for help with code, posting all your code in a [github gist](https://gist.github.com/) or a [pastebin](http://pastebin.com/) will massively improve the chances that you'll actually get an answer.
I don't disagree that Macs are a good way to get bash, but why not just use a Linux distro?
&gt; The thing is, your primary logic function is now the function main. It might be called something like get_user_documents or something. It is therefore definitely business logic, and it is definitely doing IO (unless DB.execute doesn't actually execute DB queries?). So I don't see how this achieves the aim of not doing IO in business logic functions. It's hard to communicate with this small example, but strictly my primary logic is not in `main`, my *data flow* is in `main`. The flow of data through the program is definitely something that you would struggle to divorce from I/O. The data flow is related to your business logic, but ideally should contain fairly little of your business logic. It should be possible, in essence, for you to fairly rapidly rewrite `main` to work in any other I/O paradigm without having to change any of the functions that it calls. &gt; Either way, you don't end up with a `get_user_documents` function that encapsulates business logic and doesn't do IO. Agreed, but I'd say that such a function was very poorly named. `get_user_documents` quite obviously *should* do I/O, it has `get` right there in the name. The key thing is that you shouldn't be writing this (and this is a *very* simple example, you'd want to imagine it quite a lot longer): @coroutine def words_in_user_documents(): documents = yield from db.execute("SELECT * FROM user_documents") words = Counter(x for x in document.text.split() for document in documents) total_words = sum(words.values()) yield from db.execute("INSERT ? INTO word_counts", total_words) return words This necessarily "infects" your business logic (which is manipulating counters and doing addition) with your I/O paradigm (in this case asyncio) because the two are inline right next to each other. Your identification of Haskell as a language that makes this easier is very prescient: to achieve this you need to write as much code as possible with a hard rule that it *must not* do any I/O. In this instance, it helps to think of your functions as being "pureish" (obviously not pure, classes to store state in memory are fine). Your classes and functions should not be grabbing or storing or sending data "under the covers", because that forces your I/O paradigm to infect your program. At some point you do have to write some code that glues together your non-I/O code and the actual I/O, but that layer should be as high up as possible and should be free of most problems. Its responsibility is getting data from the network and handing it to business logic, and then putting data onto the network when returned from the business logic. That's it. This will force you to rewrite *some* code if you want to change your I/O pattern, but much less than if you naively write code with your I/O blended in.
Can't say I ever had the need for this but this is quite a fun project to explore actually. Nice stuff.
It sounds like you're using Windows, so I'd suggest checking the Start menu.
The set abc seems to really have this backwards. The long form method should be what the set must implement. The binary operator should be the extra sugar, because it isn't always clear what those things should mean. Not the other way around. I realize the bitwise operators are stolen from bitflags, and cannot think of an explicit example where they might naturally mean something else, but I'm not convinced there can't be one.
&gt; OSX beat them to the punch mostly OS X was already Unix, so this helped immensely. I've heard OS X has been more difficult these past few releases for command-line dev, so it might be the right time for Windows to reclaim some dev base.
Yes but I want to schedule Unix tasks not windows tasks. 
Yes square should be a rectangle, and if you want to change the width of a square it would either return a rectangle or throw an error. What would happen if you tried to `setWidth(0)` on a rectangle? Or -1? Seems a straw man, and if you object to squares being rectangles you should object to pythons standard library `numbers` module. Most of the sets it defines add a class hierarchy are not closed under the operations defined on those objects.
https://www.reddit.com/r/learnpython/
Because a great number of these people still want to use closed software like microsoft office as well. 
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
It's the de-facto linux shell, which have won the popularity war over decades there. Which is pretty neat, since the windows shell, even PowerShell who tried to fix that, is pretty bad. However, this is even better, as this is a full linux API layer and can run linux programs natively, and have the full linux command line stack. Which moves this from neat to over the top awesome and incredible!
It's definitely a mess, and a nuisance to have all the functionality you need spread over so many different packages. First datetime, but if you want timezone support, you'll need pytz, but if you want to find out your local timezone name, you'll need tzlocal, then if you want to parse dates you'll need dateutil, then if you want to truncate a datetime to the nearest day/month/year you'll need arrow... All of which have different APIs. Gets a bit tiresome.
I can see that. I'm interested in what is behind the decision making here. I like the decision because it'll make working on my gaming desktop much easier, but I'm curious what the end goal is here. Part of me wants to be paranoid and assume more EEE, but part of me wants to be optimistic and assume that they'll essentially leave bash itself alone and take a similar approach to Mac. 
&gt; Also has little-to-nothing to do with python, doesn't belong here imo. You're wrong, try to run the unit-test for Tftpy on Windows, it will fail, because the python os.fork() command doesn't do crap on Windows. If I can now fire off that same Python unit-test on a bash prompt, from the linux python executable, then I've just saved an immense amount of time. Not everyone is allowed to install virtual machines at work, so this is very welcome, and yes, it is relevant to Python.
maybe if you're running Linux Python instead of Windows Python. Maybe. 
This doesn't make sense. Why would Windows Python start to use Linux syscalls? You'd have to install and use Linux Python instead, and then it will likely only use Linux calls, which might not always be optimal.
Probably not, no, unless using a Linux compiled Python. 
There is Start menu in Windows 8.1; it just takes all screen space. There is search function there, and there is "All programs" button (hidden by default, located in bottom left part of the Start screen, looks like a down arrow).
Or, for fucks sake, just pcap libraries. I was rather annoyed when I figured out that I couldn't use any python libs outright for packet capturing, and had to re-create my VM imagines to include even more 3rd party libs. Linux and OSX needed zero changes to do everything needed for my automation suite, but windows became the bane of my existence. It can't seem to do a damned thing on it's own without some custom libs or configs, yet is the most bloated of the 3. Go figure. 
Pay them per project and not per hour?
You keep saying it would be impossible to deal with these files at all in python. I I've said rather clearly that I don't see that happening, you could always use the low level os library. I'm just don't see why this path library should support them. Along those lines: 1. Can you actually give an explicit example of a filename that you could not manipulate. Because I'm ultimately not sure what the hell we are talking about. 2. Explain how you would manipulate sick a file today. To the extent that current practice is to just pass str's around I'm not sure how one is able to consistently manipulate these files with the existing python libraries.
Found it! Thanks!
If apt-get is there, as easy as: ~$ apt-get install python-pip ~$ pip install -r requirements.txt
&gt; if you are doing python 3, typically 3.3 or 3.4 and up is easy to support (with exceptions) Also, thanks to pep-3134, with _nested_ exceptions! ^(sorry, couldn't resist)
Support for parsing iso8601 datetimes.. Which you'd think would be one of the most common things folks needed to parse!
like java! Lololol
Lets take ext3 as an example. File/Directory names on ext3 are only byte-strings. These byte-strings can contain any bytes except \0 and '/'. UTF-8, which is used for strings in python3, is a subset of byte-strings, there are numerous byte-sequences that are invalid in UTF-8. So UTF-8 cannot store all file names that are valid file names in ext3. 
For me, the decision to use a mac is a combination of bash, hardware design, hardware quality, customer support and reliability. I use Ubuntu on one of my machines at home and I seem to be constantly having to debug something. I'm a data scientist who's not particularly interested in managing systems, so when it comes to my profession I just want my machine to work reliably.
Oh, so it's literally reverse wine 
Enforce coding standards? Don't merge their edits until they comply. This may sound harsh but they'll pick it up quickly once they have to rewrite code.
I would think this would make anaconda more simplified. Anaconda uses MINGW/MSYS under the hood for linux. They could basically remove all that and have the same installer for linux and windows now.
Yea, that's basically why I said: &gt; fire off that same Python unit-test on a bash prompt, from the linux python executable No need for Windows Python to change, if I can execute it on a bash prompt. I'd probably be running Sublime Text out of bash as well (as opposed to running the Windows binary like I do now at work). That basically makes all my Sublime Build Environment configs identical between Windows and Linux, which is like, built environment unity at last, for those of us forced in to running MS Windows at work, or having to support Windows on some cross-platform application. I really hope this isn't an early April Fool's joke, I'm pretty excited.
So how is this going to translate into Linux package support on Windows? How many of my Linux packages will run on Windows?
You didn't actually explain how Python prevents infinite recursion, just that it does. For those interested, Python limits the stack depth to 1000 frames by default. You can inspect this with `sys.getrecursionlimit`. You can even *change* it at runtime with `sys.setrecursionlimit` but I wouldn't recommend it.
I think you should be able to by just prefacing your task with 'bash.exe' or whatever. Eg `bash.exe echo 'test' &gt; out.txt`
&gt; 2.x is only going to get more and more obsolete 2.7.11 was released 4 months ago. 3.5.0 was released 7 months ago.
if i upgrade to 3.4 wont I lose pygame?
Hopefully I didn't spoil any surprises!
You must use the same version as what your Python is. On 64 bit Windows you can install either x86 or x64, but the wheel must match what Python is.
Nothing wrong with some pedantry when you're 100% right. That's a lot better description than what I said. 
Could you actually try and answer the questions? I assume your concern is that I might want to craft a file named file "GauÃŸ.txt", and I do this by passing a unicode str (I'm in python 3 where things "just work") to `open`. Presumably the python interpreter serialized this as a utf-8 encoded `char *` and makes the relevant syscalls. But now somebody with a different locale opens up python. What do they see? How do they open this file. `os.listdir` returns a list of str's... so how does this filename come across? How is this not already broken?
there's a presentation online about the meaning of "import this". Show it to them, hang it on the wall, and demonstrate how it should affect their code style. And as u/k3ithk suggested, hold them to that new coding style.
&gt;c++11 Alright grandpa, it's nap time. 
https://en.wikipedia.org/wiki/Embrace,_extend_and_extinguish
Thanks for the help. I was able to install pip 8 with 3.5. 
You make great straw men. If you know you will be implementing a square class then you might not want to implement a setWidth class, either that our accept it fails. Just as the polygon class that rectangle implements shouldn't implement an add side method. If the ultimate argument here is that str implements too much, I would agree. There is lots of shit in str that shouldn't be there. There should be as simplestr that maps better to the semantics of `char*`.
Support for 2.6 will limit you a lot. Better to stick with 2.7 as a minimum.
I don't see how this is a straw man. Its a violation of liskov substitution. Take this function: def convert_string(s1, s2): new_str = s1.join(s2) return new_str.count("/") The result of this is different for Strings and Paths (if path inherited from string), a violation of Liskov Substitution, meaning Path isn't really a child. You could fix this by making Path.join throw NotImplementedError, but that's just admitting that they are different.
Set your environment variable PATH. Or just use linux like the rest of the developed world.
Python 2.7 is not getting any new features. Bug fixes do not make it any less obsolete. And you are ignoring Python 3.5.1, which was released two days after 2.7.11.
Why did they switch to Python? The answer will help figure out the right way to convince them.
This may not be a direct response, but I suggest speaking (and thinking) in terms of concrete pros and cons, not reciting Python dogma about consenting adults, asking forgiveness, and being "Pythonic". Python is not the end state of software engineering nirvana, especially for large teams or large codebases. I'm sure I would agree that some of the code they are writing is ugly, but in other ways my perspective sounds different from yours: * Python is a traditional OO language. The first was dynamically typed Smalltalk, and classes were added to Python [early on](http://python-history.blogspot.com/2009/02/adding-support-for-user-defined-classes.html). Relative to functional programming, anything emphasizing implementation inheritance is traditional OO. * Early validation prevents undefined behavior later. There is such a thing as too much, but this is a core engineering principle. * Guido added a static type system to Python 3 because duck typing has downsides, especially on large codebases. * Monkey patching is almost always bad. 
Yep, it's BNF (Backus-Naur Form) â€” think of it as an ASCII (EBCDIC?) right arrow, indicating a production (aka "rule") in a grammar.
Add react support and you got yourself the hype you deserve! Love it, and I will try it right away!
This should be done in every project, independent of programming language. It is not as if there are no standards in C++ projects. 
Why is Python not a traditional OO language?
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Cygwin is shit if you have a choice
I am not sure it is fair to say that microsofts tools suck. But open source, and server people has for many reasons chosen *nix based tools. Far from all reasons are techological. And *nix has won over time due to the network effect.
Been looking for something like this since chrome stopped allowing me to play video files in the browser. That Videostream plugin has never worked for me.
Make them use Gerrit so they feel miserable
&gt; How can I sway them to becoming more Pythonic? You're assuming you need to sway them. Pick your battles wisely, provide lots of great example code to demonstrate your case, and if you don't win, don't sweat it. Micro-managing your team could create a much worse environment than a little bit of less-than-ideal code would.
You should file a bug as the int class violates your Liskov property. `int(1.0)==int(1.1)`. THE HORROR two different arguments to a constructor return identical objects!!!! Anyways, I give up, and you need to learn some German.
Thank you for putting this together! The latency doesn't seem to make sense to me, so I must not understand what you're showing there. Some other data-points that might be interesting: * python 3.5 * pypy It looks like the Jython implementation performs at about 12x or so of the Python implementation. Can you identify if you used a synchronous or asynchronous and why you chose that? Thanks!
Windows fag
&gt;You should file a bug as the int class violates your Liskov property. Well, no. Liskov substitution is independent from overloading. That's not the problem and you continue to misunderstand (or intentionally misuse, I'm not sure) basic OOP principles. The issue is that if I have a function def join(str_one, str_two): return str_one ~ str_two # where ~ is + or /, so assuming that path subclasses str. If I do `str(join(x, y))`, what do I get? There's no guarantee that `str(join(x, y)) == str(join(str(x), str(y)))`. That violates a basic OOP principle. You're changing the behavior of the base class in the subclass. That's Bad^^(TM). As an aside, [constructors also don't obey LSP](https://stackoverflow.com/questions/5490824/should-constructors-comply-with-the-liskov-substitution-principle)
You can still use flask. The build works good. Or you can use the [github repo](https://github.com/pallets/flask) (last commit 4 days ago).
Good point, and true!
Exactly constructors don't obey LSP. So your complaint doesn't make any sense to me as you have "constructors" all over the place. Granted that `str(x)` technically calls `x.__str__` it is effectively a constructor. Not only does it return a new immutable object, but it looks and acts like a constructor. How do I construct an instance of class `FooBar`? I do so by calling `FooBar(arguments)`, and so `str(x)` is an `str` constructor. So for class `Base` you are claiming the property that `Base(func(x, y)) == Base(func(Base(x), Base(y))` but that if the arguments x and y are of class `Derived` this fails. But you have constructors all over the place!!! If you remove the outermost constructors you have the statement: `join(x,y) == join(str(x), str(y))` So if x and y were `p"/usr/"` and `p"/bin/"` it would be that `p"/usr/" + p"/bin/" == "/usr/" + "/bin/"`. The LHS evaluates to `p"/usr/bin/"` and the RHS to `"/usr//bin/"` and now we are asking if the derived path "/usr/bin/" is equal to the string "/usr//bin/" which would call `Path.__eq__`, which would compare to the string and return True. Hence the comment about int. If `func` is `x/y` then `int(func(x,y)) != int(func(int(x), int(y)))` for a lot of different values of x and y (try x=4.1, y=1.9).
As long as .py is associated to the Python executable. This is afaik the default setup in Anaconda.
I think it's way better than those syntax diagrams from the free pascal docs (yes, I learned Pascal at college), those things were terrible to read.
Go for pyramid - if you like flask you will feel at home. And it doesn't use globals + its fully 3.x compatible. If you know one you can very easly use another.
Yeah, I spend my time doing something other than reading every tech feed, blog, social media platform, and a few non-tech specific sites as well.
Specifically, it is read as "is defined as". The thing on the left can be replaced with the things on the right, or the things on the right can be replaced with the things on the left. (Doing this without giving rise to incomplete parsing requires using an actual CFG parsing algorithm.)
Thanks! What you mean with "react support"? Do you mean JSX support? You can use react already, If you have any more concrete idea, why don't you open an issue on the project?
Different than? https://github.com/balloob/pychromecast
&gt; OS X was already Unix When did Mac become Unix? I think System 6, 7, 8, and 9 were not.
The next announcement will be Linux 4.x replacing NT you can laugh all you want but I'm certain of it. It won't get me back as a user but it will surely move the whole industry foward. Why does Apple seem to be falling behind as of late?
Depends on the job. Currently I write a ton of scripts that telnet or ssh to a device's CLI and interact with said device. For quite a while the telecom industry standard for this was tcl with the Expect extension. So, my order is as follows: 1. python 2. tcl/Expect 3. bash with my favorite unix tools (sort, grep, sed, cut, dc, tr, ls, etc.) 4. COBOL (ok .. only joking on the last one) 
Thanks! 
Depends on implementation You give me a path str and I have a business rule that says paths on this system are lowercase, and user an underscore instead of a space. Currently that is a simple `.tolower()` and `.replace()` to enforce. Now if your path library accomplishes the same with no changes then I have no problems. But if I have to instead call `Path(str(file).tolower())` then I'm not interested. If the inner `str` is optional but the returned object is no longer a path, then the library is useless as these things will silently convert.
(Sorry for being late to the party, and I apologize in advance for not knowing much about Python.) You make a good point. For simple one-liners there isn't much difference. However, the pipe operator can be very nice for readability. Just look at the last three pictures in [this blog post](http://theburningmonk.com/2014/12/being-visually-honest-with-f/). The pipe operator allows you to chain functions so that code can be read from left to right and top to bottom, like reading a paragraph. The pipe operator is used all the time in F# code. You could assign a new variable each line, but that has some drawbacks. C#'s extension methods work nice, but I don't think there is an equivalent in Python.
Learn Python the hard way by zed shaw and more Python programming for the absolute beginner Jonathan S Harbour are 2 good books. I would start with learn Python the hard way first.
&gt;You give me a path str and I have a business rule that says paths on this system are lowercase, and user an underscore instead of a space. Currently that is a simple .tolower() and .replace() to enforce. Then you subclass `Path` and add the business logic once in your constructors and it doesn't matter that you're having to write str a few extra times because you do it a few extra times exactly once. Usage is then p = MyPath('some complex PaTh/file.txt') with open(p): ... and you don't care what the underlying implementation is because its been abstracted away in the context specific subclass. The business rules become part of the class.
I suspect your example issue is because of the shell expansion of "~".
Yes, you could probably run rootless X.org, Wayland, or Mir, and a whole DE this way. This is like having a chroot of Ubuntu on another distro minus the requirement for the Linux kernel but stay tuned for that.
So one line becomes 10 and I can't use any of the functionality of path. Why is that better? 
That is what I was specifically referring to as being vague as to what they actually do. Was going to experiment a bit when I get a chance, but deciphering french documentation and my general assumptions regarding anything that doesn't give a specific "Look how easy it is" example doesn't fill me with hope.
I can't really help with this but the folks at r/learnpython are more like to be able and willing to help you.
What are you talking about? you were saying that Path(file.tolower().replace()) every time you want to create a path is alright, that Path(str(file).tolower().replace()) is too much work, but that subclassing Path such that all instances of the first become SysPath(file) is *also* too much work? How does that make sense unless you only need to apply the business logic...twice maybe across the enter system? Otherwise the repeated `tolower().replace()` is both more work and a larger vector for mistakes than class MyPath(pathlib.PosixPath): def __new__(cls, p): return super().__new__(cls, p.lower().replace(" ", "_")) now you have your special system path and don't have to manually lower and replace each time (and PosixPath and friends do stuff in new, not init, hence the strangeness).
OK thanks I'll post it there too.
Also the whole posix path doing things in new not init is an implementation detail I do not want to know about. You seem to keep coming up with negatives about path. I never want to write a new method. NEVER EVER. If I wanted to see how the sausage was made I would be writing in C.
I learned from https://pragprog.com/book/gwpy2/practical-programming while in the middle of nowhere in Alaska. This is always my first recommendation.
True, but I don't think it's too hard to suss out. Playing around for a couple of minutes, I was able to get to the meat of an epub book: In [27]: from ebooklib import epub In [28]: book = epub.read_epub('/home/ryan/Downloads/Nim_in_Action_v1_MEAP.epub') In [29]: for item in book.items: ....: try: ....: print('item has', len(item.get_body_content().split()), 'words') ....: except AttributeError: ....: print(item) ....: ('item has', 19, 'words') ('item has', 34, 'words') ('item has', 141, 'words') ... &lt;EpubItem:page_css&gt; &lt;EpubItem:css&gt; &lt;EpubImage:cover:cover.jpeg&gt; ... 
If this thread isn't dead yet I'm just gonna post one more time to say thanks. This learning set off a chain of events.
True. And I could be very wrong, but I feel like these kinds of things (made with government budgets) are public property anyway, so it makes sense to put the code out there. But I may be very wrong on that. Anyway - neat. Think they'd accept PRs?
I'm not sure about this agency...but I've submitted to other government repos (18F) and have had them accepted. CFPB is just as forward thinking as 18F so I'd assume they accept PRs. 
I think you'd like https://18f.gsa.gov/ President Obama put this team together for the exact reasons you stated.
Thank you!!
Some one told me conda avoid duplication of packages. It always try to do a symbolic or hard link to them. But, how does it manage different versions of the same package then?.
But the why would they release the DirectX 12 after a long wait... 
Looks legit. Wonderful reminder that April 1 comes sooner for some than for others.
What is this? 2.7+3.5+ the fabled 2.8 that some called for? That would get us to version 9 instead? 
Includes a script [cast.py](https://github.com/piedar/pychromecast/blob/cast/cast.py) to cast local files and remote URLs.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Most ebook formats are either RTF or HTML in some sort of wrapper.
Yep for 2 days every year about this time, I just have to turn the internet off.
Does that actually convert the characters? When I open the csv in excel some characters are clearly messed up for accents 
This should do the trick. Doesn't check the last char since there is nothing to compare it with. for x, y in zip(my_str, my_str[1:]): if x != y: num_diffs += 1 
I'm on a Windows 8 machine. Import tkinter worked. Thank you all so much! 
You probably want index &lt; len(state) - but I don't think you need the while loop at all. The for loop should do it all. and in your for loop you want to enumerate state... for i, s in enumerate(state) if s != state[i + 1]: num_diffs += 1 If I get a couple of extra minutes before I go to bed I'll try it out.
That depends on what encoding was used to decode the characters in Excel. The code I posted opens the file as CP1252 and saves the file as UTF-8. If you open the UTF-8 file in Excel but import it using the wrong encoding, you will get mojibake.
Thanks for the feedback but unfortunately everyone's code is doing the same thing. All showing back 1. 'TAAATTATATTA__TTAA' has 10 differences. TA, AT, TA, AT, TA, AT, TA, A_, _T, TA are the differences. So the code should run through and count each instance of differences to return the total. All the code given so far only returns 1 difference =/
You almost got me ;) 
 def count_diffs(state): num_diffs = 0 for x in range(0, len(state) - 1): if state[x] != state[x+1]: num_diffs += 1 return num_diffs print count_diffs('TAAATTATATTA_TTAA') When i run this I get 10-- maybe you didn't copy my snippet properly. $ python test.py 10
please see my response at the bottom of the page
Almost nothing. Everything I said is ACTUAL news. I don't mind a few harmless jokes during the day. But the massive and widespread misinformation on sites I normally go to to see the news is annoying. 
I've edited my main response up top to address your question!
Wow: Windows partners with Canonical to bring Bash natively to Windows 10... http://www.theverge.com/2016/3/30/11331014/microsoft-windows-linux-ubuntu-bash That is news! Lots of other good Windows stuff right now too... you weren't kidding!
OS X was a unix operating system called Next Step. From Steve Jobs second computer company called Next. That is why libs are prefixed with NS.
Thank you for sharing, the need to pass a context object being undocumented is a serious flaw.
Are you using numpy/scipy/matplotlib? If so, might this function suit your needs? http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.savefig
Argh, do you want to work from home for one employer, or you want to freelance from the home office? These are two different things, and it's not clear from your question what interests you. On the aspect of working from home for one employer - there are presumably a lot of companies today hiring people to work almost exclusively (or exclusively) from home, not as freelancers but as full-time employees for them. I did this between 2000. and 2008., so situation today is even better (again, presumably). From the "big names" in Python world, Red Hat comes to mind - when interviewing for a job there I was offered to either go into the office or work from home, and all of the tech interviews I've did I did with people who interviewed me while working from home offices. I've even considered similar arrangement myself last year but gave up in the end. Here is what seems like useful resource in a search for such a job: https://github.com/lukasz-madon/awesome-remote-job Good luck!
Update: it is now Python 2 (or at least, python 2.7.x) compatible.
&gt; awesome-remote-job nice
I'll have a more in depth look, and I'll tell you on github.
If you would like to learn webprogramming you should look ant Django or Flask. But, if you would like to build a simple UI for your App, an UI accessible remotely like a website, then you can do it faster with [RemÃ¬](https://github.com/dddomodossola/remi). For help you can join the related gitter chat.
It's funny because it depicts nicely what a foolish decision Guido made in making Python 3. Python 3 and "Python 8" both commonly have an incompatible change which might sound good for some people but surely is not worth the incompatibility. In addition to that, they both might sound good but are actually not. Obviously it is preferable to follow PEP8 generally though it shouldn't be forced because it is just a guideline which implies sometimes breaking it would be better. As such, it does seem right at a glance that every string should be handled as a Unicode. But it actually isn't right. There are numerous cases where strings just don't fall into Unicode. Text-based network protocols, Linux file names, etc.
Why did they spend 10 years developing the Windows Presentation Foundation only to abandon it? Same reason, open standards can surpass closed ones and reach critical mass. Old MS would stick with inferior standards for years just to perpetuate vendor lock-in. This new MS isn't as stubborn or realizes that those tricks won't work forever and adapts. I still don't trust them but they're making a lot of positive changes by admitting that their own dog food didn't just have a secret recipe but was non-nutritious and tasted stale.
And it seems like a non-trivial change for a joke lol. Nice work!
https://github.com/wooey/Wooey can do that for you automatically. Enjoy! :)
Lemme try... &gt;&gt;&gt;Python 2 ** Python 3 Python 8 The math checks out.
I could also use + and raw str's and I haven't lost anything. What is this path library doing for me. And I'm not repeating them, I've got one instance of each rule. And I do that manipulation at the point I use the filename, and not in some weird class declaration elsewhere in the script or off in some utility module of filename manipulations. It's a lot easier to debug an open call when you can see the exact construction of the str directly above the call sight.
&gt; https://github.com/wooey/Wooey Interesting. I never saw that before.
Considering April Fools day started way back in the 1500s, I'd say it's taking a pretty long time to get old.
They skipped right past Python 95.
Today is April 1st.
Can it be faster than translating Brainfuck to C, compiling it, and running it? 
To answer your question: I could not represent a path that consisted of a directory called 'Ã¤' encoded in latin1 containing a file called 'Ã¤' encoded in UTF-8 if I was using python3 strings. But I could if I had a path library which used bytes to store path elements. &gt; But now somebody with a different locale opens up python. What do they see? How do they open this file. os.listdir returns a list of str's... so how does this filename come across? How is this not already broken? I think we all can agree on the fact that linux sucks at filenames, no surprise there. Since ext3 is only storing bytes you can also create several files in the same directory that will appear to have the same name by using combined characters. But I don't think that's a reason for making a path library incompatible with the current situation by using strings for path elements.
**TL;DR**: The author is at best unaware of how TLS works, and at worst being actively misleading about the result of their tests. This document has some severe problems. Leaving aside the remarkably confusing box chart (does a tick mean the certificate was accepted or rejected? I had to read the text quite closely to work it out), I'm not confident the author entirely knows what he's talking about. Problem 1: &gt; In my tests, Requests failed to reject a self-signed or expired certificate under Python 2.7.6 (which is a supported version according to the Requests documentation). Firstly, for the expired test case the author claims to be using "https://qvica1g3-e.quovadisglobal.com". As far as I can tell that's untrue, at least for requests on Python 2.7.6, because I just tested on my Ubuntu 14.04 box and Requests happily rejects that cert. However, a glance at the test code reveals there's a *second* expired url. Let's assume that's what the author used. Both the self-signed and expired test case use badssl.com: specifically, https://self-signed.badssl.com/ and https://expired.badssl.com/. The problem is that all of badssl's tests are served from the same server listening on the same port. This means that you need the SNI extension to tell the server what hostname you wanted to speak to. If you don't have it, the server will fall back to use its *default* certificate for the port. In BadSSL's case, that default certificate is valid for `*.badssl.com`: that is, the certificate you see for either of those domains *without SNI* is *valid for those domains*. In this instance, that means that **requests was correctly validating the presented certificate chain**. The problem is that requests was unable to correctly request the domain it wanted. The author does not explain what version of Requests they were using, but since requests version 2.9.0 in December of last year Requests will emit warnings that explicitly call out that SNI is missing, and since 2.6.0 (released more than a year ago) will emit warnings claiming that it is unable to properly enforce security policy. Both of these would have fired on Python 2.7.6, and could have been resolved by installing the optional dependencies required for proper security that those warnings suggest. Problem 2: &gt; All programming language implementations fail to check if a certificate is revoked. It is broadly accepted that checking for revoked certificates using anything other than OCSP stapling is a [waste](https://www.imperialviolet.org/2012/02/05/crlsets.html) of [your](https://www.imperialviolet.org/2014/04/19/revchecking.html) precious [time](https://www.imperialviolet.org/2014/04/29/revocationagain.html). Currently requests cannot support OCSP stapling because OpenSSL provides no good support for it. As and when that support is present, we'll use it. On a personal level, I'd also like to congratulate the author on their crappy behaviour. The author clearly believes they've discovered a security problem in Requests ("In my tests, **Requests failed to reject a self-signed or expired certificate** under Python 2.7.6", emphasis in the original) didn't deign to notify us *at all*. That's a pretty lousy way to behave for someone who appears to care about security. It's not like it's [hard to find our policy](http://docs.python-requests.org/en/master/community/vulnerabilities/).
Sorry for not answering for 2 days. I searched a little bit on sessions, requests and cookielib, but im not sure how to implement those to my code. Could anyone give me any examples?
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Check out flexjobs.com they have lots of work from home stuff. I've seen a lot of Python jobs there.
Which makes me wanna learn c# even more....
Same here, it's a really good move. 
I tried it and get this error : &gt;&gt;&gt; import php &gt;&gt;&gt; php.echo('saeed') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "L:\Python27\lib\site-packages\php\__init__.py", line 31, in call_php_function return json.loads(out) File "L:\Python27\lib\json\__init__.py", line 326, in loads return _default_decoder.decode(s) File "L:\Python27\lib\json\decoder.py", line 366, in decode obj, end = self.raw_decode(s, idx=_w(s, 0).end()) File "L:\Python27\lib\json\decoder.py", line 384, in raw_decode raise ValueError("No JSON object could be decoded") ValueError: No JSON object could be decoded
Do you have to be based in the United States?
In addition to what /u/billsil said, you need to ask more specific questions. "How do I make my simulation better?" is too general, and is really more a question for your prof. If you can ask more straightforward questions, like "How do I best do XX in Python" then you'll get lots of suggestions. 
~~Ah, yes I'm assuming that the PHP functions will have a return value (and then using JSON to communicate back and forth between Python and PHP)~~ Fixed! python-php now supports echo, print, var_dump, and print_r
This is going into Python 8 right?
&gt; Since ext3 is only storing bytes you can also create several files in the same directory that will appear to have the same name by using combined characters. But I don't think that's a reason I come to the opposite conclusion. I see this as a potential security issue as well as a usability issue. I don't want users of my tools to be able to accidentally pick the wrong file because there are multiple files that (via clever use of unicode tricks) appear to have the same name. So I would like a tool that enforces discipline on filenames. It would probably need to be configurable, but I don't want these files to be created by my tools, and I assume that any other process which does create files like this is doing so either by mistake, or maliciously. &gt; But I could if I had a path library which used bytes to store path elements. Deriving from bytes is mostly fine. There isn't much you can't do with a bytes object that you cannot do with an str (at least according to `set(dir(str)).difference(set(dir(bytes)))`). The bigger headache is going to be using things like the regex library against byte-like paths. Checking that filenames match a regex is a fairly common practice, that needs to "just work" and re doesn't accept bytes objects. One of the reasons I would argue for a str class is that you could then rightly complain if some other method (say `re.sub` silently downconverts back to `str`), but if you are only "string-like" in that you behave like strings, but don't actually claim to be a str, then you cannot expect libraries that accept str to preserve your typing information. The end result would be paths that are silently converted into plain strings which seems rather awful to me. ----------------- Another interesting thing to point out that came up in another discussion on this is that the current PosixPath shell expands the path "~", but nothing in the Posix Spec says you have to do this, and some shells don't. So for me the argument that pathlib should support all paths (including those with funky non-printable chars) seems a bit silly given that we don't support the literal path "~" (and you have to introduce special case code "./~" to get around its shell expansion). 
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Oh, I'm sure they'll add it to the standard library
For the same reason that publicly funded research should be publicly available, so too should any publicly funded work (excluding defense, top secret, and stuff like that).
Thank you for correcting my misperception. Let me go ahead and import it. 
C# is really nice. The ecosystem it's in could use a lot of work
But does it support PHP 7 features? Also do you plan on adding support for JS and/or Brainfuck?
It needs winamp versioning! Python 2 Python 3 Python 5 = 2 + 3
My python 8 wish is to remove significant white space from the syntax. I guess this is the perfect time to suggest altering random stuff I don't like alot about python while the ball is rolling :)
I did that originally but occasionally ran into problems with the content escaping. Saving to a temp file was easier to debug and gets around any potential problems with max length limits with command-line argument and very large parameters.