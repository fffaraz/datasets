Interesting note, Matlab uses Java for all of it's ui, and is fully compatible with java. 
https://pypi.org/
Thanks. Looks like a work in progress but definitely one step closer.
Well....I started a new blog on Beer. So HA!
So I have you guys to blame for my ban :(
TIL. Also: I posted the wrong clip... I guess I got caught up in the excitement. Have a look at the other clip... 
From your description, Task Scheduler is probably your best option. In my experience it's not that it's unreliable but 1) hard to set up right and 2) hard to debug. It's hard to set up bc the runtime environment is minimal and hard to debug bc it swallows stdout and stderr. It takes some getting used to. If you are spawning off stuff within another python process (e.g. an event loop or listening on a socket), you could take a look at APScheduler.
I never figured out - is it a reddit wide ban or just a sub ban?
... sub ban.
Lame. Zero-risk.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
I'm still getting the same reply as i did earlier. In addition got a lot of error messages when trying to install such as include/dmlc/threadediter.h:231:3: error: 'mutex' in namespace 'std' does not name a type or include/dmlc/threadediter.h:316:31: error: 'lock' was not declared in this scope please help
Yeah I think the consensus from this post is that I'm probably not setting it up correctly. To give you an idea, I have a daily script that works 80% of the time, but the other 20% it'll fail with a 0x1 error that I haven't been able to debug. I've always assumed that it's just because task scheduler is unreliable because that's what I've been told previously. Do you have any suggestions for resources?
So your suggested route is schema per tenant Many bigger apps have moved off that. Random example off google: https://influitive.io/our-multi-tenancy-journey-with-postgres-schemas-and-apartment-6ecda151a21f Thinking of a current app I have with 100 tables and 1000 tenants. Running migrations would be a nightmare! I cannot imagine doing that. Your suggestions for the filtering key are spot on. I would suggest going that route for 99% of apps. If you want any other route, you really need to justify it.
Work in progress?
/r/learnpython
If you're talking about the memcache server error, also not legacy code. Reddit uses a fleet of memcache cache servers under a slightly customized version of mcrouter to handle cache. Sometimes the cache server can time out when getting or setting something, albeit rare.
The official documentation is very good, but sometimes it is terse to the extent that it is difficult to absorb at first reading. In particular, it is some times difficult to recognize that something is useful to a specific problem. Even after using Python for around 20 years, I still find new content. I don't mean to dismiss the "Python¬Æ Notes for Professionals" out of hand. In a biased pseudo-random sampling of interesting looking chapters, I did find interesting and perhaps useful content, some of which I may try to incorporate into my current projects. The origin of at least some content from a defunct Stack Overflow project suggests that that content is, to some extent, orphaned. I did not notice any indication of a mechanism to contribute to the book, although there is a mailing list for notifications about changes.
Just go get started man. Read something on it, try it, repeat. You‚Äôll get it down if you‚Äôre serious.
Normally I would check if x: pass But here I wanted to emphasise that in JavaScript you would rather check the value with triple === to also match the type.
urgh... I just won't say anything any more... 
Many people use https://conda.io/docs/download.html for Data Science projects.
I have been through ‚ÄúAutomate the boring stuff‚Äù, written a web scraper, coded in Django and written a chatbot. That means I am a little bit beyond the learn Python stage. Here is an example. I want to go to a single location to get available libraries for the ‚Äústatistics‚Äù category or ‚Äúnetworking‚Äù category. Where do I look? Right now, that involves guessing, stack exchange and google searches.
Thanks. This is a useful resource and meets an immediate need. I made the shortsighted mistake of installing Python 37 on my Mac and that worked until I started getting into pandas and numpy and some of the more fun stuff. The package dependencies were miserable. Should have started with anaconda and virtualenv.
You should just Google for the library you need. Of note, that is also the case with CPAN. The search quality is much higher when you use Google.
Yeah, I looked at CPAN after about a decade and it is much worse than as I remembered it. Guess time smooths all memories. I will follow your advice.
https://github.com/xXAligatorXx/Infinity-Gauntlet
...do you know what piano piece is playing in those two clips he linked?
Probably not but a super, super more basic version (not caring about actual ban notes or anything, or cache, or cache crashes, etc, because I'm lazy to look up the method parameters, and I haven't had to do this off the top of my head for more than a year) from r2.models import Account, Subreddit, SubscribedAccountsBySubreddit from random import random sr = Subreddit._by_name("thanosdidnothingwrong") for col in SubscribedAccountsBySubreddit._cf.xget(sr._id36): if random() &lt; 0.5: sr.add_ban(Account._byID(col.values()[0]))
Beethoven's Moonlight Sonata?
I'm a reddit archive encyclopedia, not a music memory national finalist :(. I know he typed out the name of one song in the stream, though.
Shhh bb is ok. If anything I'm worse off for actually knowing this and more to the point some could call it an obsession.
&gt; col.values()[0] Surely that's not the best way to do that - couldn't we just index the `col` field? I mean, would that even work in modern Python given that `values()` returns a generator? Not to be too critical, that's still impressive code if you just rattled it off the top of your head.
A good introductory to Celery wouldn't hurt. Especially for somebody that might respond to thei post with: what is Celery?.
Is there a way to see the banlist, or do you just find out if you're personally banned by not being able to hit the sub?
Xget returns a generator of columns from pycassa, where a column in this case is a dict of {userid36: datetimeobject}. So we need to get the first key (yes I know I first said value, made a mistake) of each dictionary. Of course there are more efficient ways to do this, such as, say, update a reference dict a certain amount of times (ex 100), then just get the `keys()` of that, giving a list of 100 user ids per time, which can be retrieved at once reducing overhead calling the Cython smart cache fetcher. Also reddit is written in Py2, and so is this script. If it was Py3 was involved, yeah, values/keys would have to be cast into an indicable object such as a list.
I love how PyGame is mentioned before Unit Testing üòÇ. Absolutely terrific resource at first glance, each chapter covers a small part of the language. That way, you can easily scan for chapters that you think is interesting/useful.
Insightful and interesting! Also mildly upsetting that Reddit is Py2 based :)
Python docs ug me out
The mods can release the banlist afterward from the sub, although it would take them a long time to go through (max 1k per page, 400k bans, ish, 400 clicks of "next", each getting slower than the last because of the way reddit does db queries and being EAV). Or the admins can fetch the output lists and post them somewhere after it's done.
Do you mean sungle db, single schema? That has really weak isolation guarantees. Migrations are def a pain in multi schema or multi db, but because it's automated and migrations for tenant don't lock other tenants, I find that acceptanble. 
Reddit was rewritten from Lisp to Py2 many years ago, eventually settling on the Pylons web framework. Pylons, while they were supposed to add Py3 support, gave up before the final release and focused on Pylons' spiritual successor, pyramid (which personally I feel is a massive downgrade from Pylons because of code-infrastructure but oh well). For reddit to make the switch to Py3 would be quite a feat-- first they need to upgrade all libraries to those that are Py3 compatible, such as using pika instead of amqplib-0.8 and haigha, datasax's own cassandra driver rather than pycassa (which they have been experimenting with for a while, unaware of how far they've gotten), and swap out a lot of string based code. And that would just be Python2 pyramid to Python3 pyramid, going from Pylons to Pyramid, with a large app like reddit's, is arguably a lot more difficult because reddit makes use of the globals config object that Pylons provides, whereas pyramid instead has a configurator with config attached as an attribute, which itself is attached to the registry, which is attached to the request object, which means they have to fake a request context when dealing with their rabbitmq queues. Tldr i doubt it happening anytime soon.
&gt;Or the admins can fetch the output lists and post them somewhere after it's done. This is pretty much what I was thinking. Something either searchable or greppable.
Well from what I understand they pre-chose the sacrifices and put them through a unix pipe, piping that to the script, then to /tmp/outputXX With a prefix of "snapping". So yeah, search/greppable because it's extremely simple text output.
It would really suck for subreddits to be able to enforce site-wide bans.
You get a PM.
When Beethoven wrote the Moonlight Sonata, I'm 99% sure this is exactly what he had in mind. 
Obviously, but I think they meant if the Reddit mods were doing this
Survived the ban. I am not a son of Thanos.
Where was it stated that this is the source code?
The twitch stream post.
Indeed. 
That's not the script that was used. That was the initial script made by a user before admins were involved. Admins used a custom script that integrates with the reddit Pylons shell, and thus doesn't have to go through the API
Great to see this release. The changelog section about packaging seems to imply python 3.6 support. Is this the case?
Woof.
Ooh, I saw my name!
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
...sigh, they used `random` not `secrets`. Ultimately doesn't matter, just feels a little less fair.
Ok thank you for the suggestion! I was looking for a way to automate the process through python but if this is easier in the long run I will definitely check it out
I began looking into OCR because some of the files were png's, so I explored a little into running that through OCR. The layout is a variation of tables and paragraph text so that's where most of my difficulty lied in converting it to a csv file since I wasn't quite sure how to tell the program what goes where in the csv from the information on the page. Thank you for information on how to use the commas and reference to the stream writer, I had never heard of that and will check it out! I'll also cross post on those subs as well, thanks again!
I hope they will remember me...
If you're using flask, check out flask-restful (https://flask-restful.readthedocs.io/en/latest/). It's pretty well-documented and seems to be actively updated.
I'm building a control interface for a multi screen dashboard system, the dashboard are based on Smashing.
&gt; One of the problems designing a language or large graphics system is that early decisions, which at the time seem OK, can become a problem later. For example, print statements in python 2. Undoing these questionable early design decisions can be slow and painful, if they are undone at all. Absolutely! My "favorite" example in Matplotlib is a thing that predates contextmanagers: [`FocusManager`](https://github.com/matplotlib/matplotlib/blob/734c19448d75d03ddf9ac7ee4dae0574cf13f180/lib/matplotlib/backends/windowing.py#L26-L31) can be instantiated and assigned to an unused variable, and after the function returns the instance is garbage-collected and thus runs the cleanup code. Obviously this is terrible and has recently been replaced with a real context manager, but there's a large codebase and many such bizarre things. &gt; To this date, matplotlib developers have seen no need to change. This is unfair - rather, it's that the Matplotlib project has no resources whatsoever to spend on "engineering" projects like cleaning up technical debt, and essentially all their contributions (bugfixes and features alike) are from scientists who are *not* software engineers. However, a glance over the [milestones](https://github.com/matplotlib/matplotlib/milestones?direction=asc&amp;sort=due_date) (especially [3.0](https://github.com/matplotlib/matplotlib/milestone/23)) will show that there's no shortage of work - more than 200 open pull requests and 1000 open issues - just waiting for someone to actually fix it. Or, yes, just replace matplotlib with an alternative plotting backend such as Bokeh.
Yep. First movement. Sounds like it's in a different key, though.
There are multiline comments. Use """triple double quotes""". 
Python is spectacular for mangling text files. It's astounding how wrong many other languages get it.
 Use """triple double quotes""" Not good advice as the "comment" you get is executable code that must be executed and the result thrown away. Better to use your editor/IDE and add `#` to the start of each line in a block of code. Using a string as a "comment" adds about 15% runtime in a small loop.
I thought it was about banning people who just post "/r/thanosdidnothingwrong" every-fucking-where, I'm disappointed.
Are you using numpy arrays? It's a pretty simple method that they use for mating. It really should be fast.
You think that's bad? Go mess around with the real, largely undocumented matplotlib API. It's necessary for large data arrays and steaming.
‡ºº „Å§ ‚óï_ ‚óï ‡ºΩ„Å§ GIVE SOURCECODE ‡ºº „Å§ ‚óï_ ‚óï ‡ºΩ„Å§
Nay, we ARE Thanos on this blessed day.
I second the VSCode recommendation. 
what exactly does this mean? From my exp in c python and java printing to console slows down what I'm doing heavily. 
Yes exactly. Thank you :)
That was not the script I use. That's an effort by a community member from before we hopped in to help out.
Mind give a reference to this behavior?
It's still c# minor
IDLE and Komodo Edit are both "code editors" or "IDEs". [There's tons to choose from](https://www.reddit.com/r/learnpython/wiki/ide), and the best one is the one you feel the most comfortable in. Python will not care which one you use. That said, if you are very new to coding it may help you to see the same thing that your tutorial shows. Also, many code editors have special fancy features to help you code. Some are universal, but not all. If your tutorial will cover some of those you will need the same editor to use them. If you get stuck come visit us in /r/learnpython. 
Thank you so much
I hope they called the banhammer Mjolnir
Hello! I'm a bot! I see someone has already suggested going to r/learnpython, a sub geared towards questions and learning more about python. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
[This](https://unix.stackexchange.com/a/182541) give a better explanation than I could.
There isn't really. PYPI is just a very simple front-end to the library database, but it isn't the place to read the library documentation. On the other hand, there's https://readthedocs.org/ but it's not ideal either. The quality and availability of documentation will very much depend on the programmer developing the library. Some library developers ignore this site and publish their documentation elsewhere, mostly on their own sites.
Another step closer to PHP... this assignment creates the expectation that the result from the operation will always be correct, as opposed to the assignment, then checking if the output is valid. 
They originally wanted to create a bit to do the band and name it "Banos"
Hey sorry! I actually made the mistake of recording times wrong and the issue was that for ex: children = map(tools.clone, parents) is EXTREMELY long with time. Trying to figure out why.
Why don't you put a breakpoint in `launcher.py` on line 128 and try to figure out what file is missing?
We're slowly breaking parts of reddit out into their own services, and most of those new services are being written in python3
https://www.udemy.com/the-python-mega-course/
Multiline comments are discarded by the compiler. &gt;&gt;&gt; import dis &gt;&gt;&gt; &gt;&gt;&gt; def func(): ... a = 1 ... ''' ... multiline ... comment ... ''' ... b = 2 ... return a + b ... &gt;&gt;&gt; &gt;&gt;&gt; dis.dis(func) 2 0 LOAD_CONST 1 (1) 3 STORE_FAST 0 (a) 7 6 LOAD_CONST 2 (2) 9 STORE_FAST 1 (b) 8 12 LOAD_FAST 0 (a) 15 LOAD_FAST 1 (b) 18 BINARY_ADD 19 RETURN_VALUE &gt;&gt;&gt; &gt;&gt;&gt; There's not trace of the multiline comment in the resulting bytecode. 
This is a guide for Python Beginners. **Basics** 1. [https://automatetheboringstuff.com/](https://automatetheboringstuff.com/) 2. [https://developer.mozilla.org/en-US/docs/Learn/Drafts/Python](https://developer.mozilla.org/en-US/docs/Learn/Drafts/Python) 3. [https://www.tutorialspoint.com/python3/](https://www.tutorialspoint.com/python3/) 4. [https://www.youtube.com/watch?v=abrcJ9MpF60](https://www.youtube.com/watch?v=abrcJ9MpF60) 5. [https://regex101.com/](https://regex101.com/) **Practice** 1. [http://www.practicepython.org/](http://www.practicepython.org/) 2. [https://www.codewars.com/](https://www.codewars.com/) **Full Stack Development** 1. [https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django](https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django) 2. [https://docs.djangoproject.com/en/1.11/](https://docs.djangoproject.com/en/1.11/) 3. [https://simpleisbetterthancomplex.com/2015/11/23/small-open-source-django-projects-to-get-started.html](https://simpleisbetterthancomplex.com/2015/11/23/small-open-source-django-projects-to-get-started.html) 4. [https://www.udemy.com/](https://www.udemy.com/) **Data Science** 1. [https://www.anaconda.com/downloads](https://www.anaconda.com/downloads) 2. [https://www.youtube.com/user/sentdex/playlists](https://www.youtube.com/user/sentdex/playlists) 3. [https://www.kaggle.com/competitions](https://www.kaggle.com/competitions) **Keeping You Updated** 1. [http://pyvideo.org/](http://pyvideo.org/) 2. [https://www.pythonweekly.com/](https://www.pythonweekly.com/) **Reference** 1. [https://docs.python.org/3/](https://docs.python.org/3/) 2. [https://github.com/vinta/awesome-python](https://github.com/vinta/awesome-python) 3. [https://github.com/trananhkma/fucking-awesome-python](https://github.com/trananhkma/fucking-awesome-python)
def async = make function a coroutine await = give control to a different task until whatever is being await-ed finishes, then come back and continue Not sure if that helps but I gave it a shot
If you are looking an English tutorial than hope [this](http://learnopenerp.blogspot.com/2016/03/welcome-to-python-3-programming.html) will helps you...
With the following code, I see anything from a 5% to 20% slowdown, depending on the version of python used and platform it's run on (macOS, iOS or Linux): import time LOOPS = 200000000 start = time.time() for _ in range(LOOPS): """a comment? A longer line in a string that some think is a comment. An even longer line in a string that some think is a comment. """ pass delta = time.time() - start print(' string comment: %.2fs' % delta) start = time.time() for _ in range(LOOPS): pass delta2 = time.time() - start print(' no string comment: %.2fs' % delta2) percent_diff = 100*(delta - delta2)/delta2 print('String comment takes %.1f%% more time' % percent_diff)
Yes, I tried that. Yet test code shows a slowdown of from 5% to 20%. Probably depends on the version of python used and the smarts in the optimizer.
why would you use secrets for something that is inherently a random process, not a secret key? Seriously, how would secrets make that any better? Also, the secrets module is pretty useless. Or rather, there's absolutely nothing there that can't be implemented easily without it. I don't see the point in it, to be honest.
The whole point is that it was *balanced*. You are part of the balance. Both sides are.
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 50.0% out of the 2 submissions from /u/Duportir appear to be for Udemy affiliate links. Don't let spam take over Reddit! Throw it out! *Bee bop*
Is this for real? I don't like that site nor have I ever mentioned it. 
regardless of slowdown or not, docstrings are not the same as comments. @rzzzwilson is correct that '#' should be used on each line. here is some light reading on the differences [https://www.reddit.com/r/learnprogramming/comments/2mwjqy/docstrings\_how\_are\_they\_different\_than\_comments/](https://www.reddit.com/r/learnprogramming/comments/2mwjqy/docstrings_how_are_they_different_than_comments/) [https://www.quora.com/What-is-the-difference-between-comments-and-docstrings-in-python](https://www.quora.com/What-is-the-difference-between-comments-and-docstrings-in-python)
Yes I will do in next release. 
Nothing wrong. It doesn't suit my way of doing things. Additional set of files/commands ...
Yes, the slowdown is a red-herring, whether it's real or I'm fooling myself. To promote strings as a multiline "comment" is wrong on two points: * depending on an undocumented optimization to not incur overhead seems crazy. And is a string optimized away in CPython? Perhaps yes, for later versions. How 'bout Jython and IronPython? * After multi-decades programming C and C++ I *stay away from multiline comments* as they are too error prone when nesting. Give me the "comment to end of line" comment every time, especially when any editor worth using handles commenting and uncommenting blocks of code without any problem.
VS Code is very good in JavaScript. With Python+Flask I think it's a good fullstack IDE (replacing my previous Python IDE Emacs)
Yes, python3.6 (and even 3.7 although we don't have a windows wheel for that‚Ä¶ yet), is supported, personally i've been packaging all my apps (for windows) with 3.6 since the beginning of the year. 
I have more questions now so time to Google
The isolation guarantee is as good as your code. Have good code and good tests, and single schema single db is fine. The other three options add a TON of work and problems down the road at scale, and are frankly pretty silly. Its weird to say needing to use a fk consistantly is low isolation gurantee, but needing to use a schema in every query is stronger. 
They *could* have used random.SysRandom, which is exactly what secrets uses. By calling `random.seed()` right off the bat they *probably* established pretty much the same apparent randomness -- IE good enough for the work of a demigod -- but there's no guarantee they did. The only benefit to secrets is it sets up SystemRandom for you, but I'm sure more will be added over time.
&gt;Admins are banning half of the users of a subreddit for ~~a meme~~ advertising purposes. Fixed it for you.
Unless I missed it, I didn't see a single "pm_me_your" whatevers.
&gt; The isolation guarantee is as good as your code. Respectfully, I don't agree. There are two reasons. 1. Littering you code with `.filter(tenant=...)` is suboptimal. All the other approaches allow centralizing the tenant isolation code. 2. The second reason is more important though. With schema/db/container isolation I can make DB level performance guarantees. I can set a tablespace/query timeout param on a per tenant basis, something you can't do with FKs. I used this when we allowed automated data loads by tenants and a query builder for reports could generate long running DB queries. If FK works for you, by all means use it. Its definitely the simplest. However, there are many cases where it is the wrong architecture.
*Python minor
When you print something from Python, you're not writing directly to stdout or to the screen. You're writing to memory. That's fast. When it becomes a problem is if you're writing a whole lot to the screen quickly. The output is buffered for speed internally, but it still has to flush that buffer to the screen eventually, and when it does you have to wait for that to finish. If you're writing a couple lines per second it's not an issue, if you're writing a hundred lines per second you will probably spend most of your time waiting for the stdout buffer to flush.
Use the logging library and log **everything** relevant to file.
I don‚Äôt believe you. 
Any chance you want to publish that code, or as much of it as you can? Or maybe submit a post about it to this sub? -- a PyCurious redditor
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
If the site doesn‚Äôt support a API, your left with screen scrapping (parse the HTML). Which is crap, since when something changes your likely to update your code. 
With Java + Apache Httpclient you can login to facebook
Selenium works great for this sort of thing. It has a Python API.
It's a good book and a great starting point if you know nothing about python. You learn to build several useful applications and that keeps things interesting. But you never really take a deep dive into python programming language itself. Don't try building every single application mentioned in this book (unless you really want to) and move on to something intermediate when you think you are ready.
r/learnpython 
r/learnpython
A robit?
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
Zsh huh? Hmmm
assholes
Just resize the Tkinter window and elements will appear.
Yes there was a "sacrifices" file that the ban list was created from, so said file/db exists
It's good for learning how to write scripts and automating basic work/office tasks, but it falls short of the real heavy stuff like learning object-oriented programming which is needed to build out full-fledged applications.
They should write to log then -tail the log in another window.
Snek minor
Testing out Luigi and Airflow currently. Just wanted to mention. 
Have you worked for a real company at scale? No one is doing schema per user.
When you say parts of reddit, do you mean library things like plugins / services like the activity or websockets services, or do you mean the actual web app?
Try Selenium
What was wrong with the click library?
Why use random at all? Why not just ban every alternate user? That still achives the same goal and if the list is not sorted is basically psudeo-random. As I understand it the point of using `random` is to seem unpredictable and `random` does a worse job of that than `secrets`. As with enough information about the script environment it would be possible to predict it's outcome. If you're writing in pure Python and you need to generate randomness for something secure (tokens, keys, passwords, etc.) I'm not aware of any other module that's suitable other than `secrets`, so I'm pretty sure it's not useless.
I doN't have DEAP handy, but that is not vectorized. For a large number calls that could be why. That's a bit odd though given the module being pretty good. What is your population size?
Is there an alternative? I'm running bash on windows and it seems like a hassle to get it to work.
r/learnpython
You know the site is using JSON API to perform the search, that you could use too. Just check the request (headers, query parameters, API token) and the response you get with your favorite browser (Chrome - Developer Tools) ;)
Yes, I have. I have been paid to program for last 15 years. You had a different opinion, and I provided technical justification of my choices. How does insulting me help what you make your technical point? &gt; No one is doing schema per user. Of course, no one is doing schema per `user`. But lot of people are doing one schema per `tenant` which is entirely different thing.
I watched it live last night and saw a couple.
Convert it to datetime: d = datetime.datetime.fromtimestamp(...) And then convert to desired format: d.strftime("%d/%m/%Y")
‡ºº „Å§ ‚óï_ ‚óï ‡ºΩ„Å§ GIVE SOURCECODE ‡ºº „Å§ ‚óï_ ‚óï ‡ºΩ„Å§
Assigning a value to a variable is 'storing the data'
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
Assuming you know how to use chrome inspect, just crack open the panel and target the AJAX call instead of the html. 
Idk if you're a spammer or affiliate, but for everybody else. You don't need to PAY to get started coding. Here's my personal list of FREE books to get started: https://blog.rmotr.com/the-3-python-books-you-need-to-get-started-for-free-9b72a2c6fb17 And if you're looking for a video course, Python for Everybody is probably the best out there: https://www.py4e.com/
I was wondering if there is a function built in for this but I guess there is no way rather than doing this trick. Thanks bro 
Thank you 
Do we know what the default size of the buffer is? Sometimes on pet projects I get slowed down and I can only assume it's because of the buffer being both large and nearly full.
It was just a baby bot
Why not using the logging module and write to file instead if stdout bottleneck is an issue?
Spyder is really really good now. I do feel like finally it past the point of being a true IDE replacement compared to matlab. The plots are a different story though.
I would just start with the Unix epoch time (00:00:00 January 1, 1970) and then add the seconds something like this: unix_epoch = datetime.datetime(1970, 1, 1, 0, 0, 0) new_date = unix_epoch + datetime.timedelta(0, 1531227646) And then just extract the month from the datetime. I'm not the most proficient in python, so there might be better/more pythonic ways to do it.
Some of the builtin date stuff is kinda poopy.
&gt; the only downside I've seen so far is the lack of multiline comments """ hello butt head """
I agreed, some are complicated to understand 
This would make the process little bit longer. Thanks anyway bro for your help
Yeah spyder is my main IDE :) But still, matlab's IDE is/was the one to beat.
You want r/learnpython
Thank you
r/learnpython
Regarding WSL: What version of Windows are you using? WSL is only available on Windows 10. Earlier versions of Windows 10 require extra steps to enable it. JetBrains IDEs should simply prompt you for a username and password for a GitHub account when accessing a repository that requires one. You can optionally allow it to save your credentials. &gt; Next I tried to get some sort of keychain like functionality to bypass using the Git Bash program. I followed this Jetbrains article and I can add a Putty generated key to Pageant but Github is not recognizing it as valid. And I can add the key generated in the git bash terminal to Github but Pageant won't recognize it. [The reply by 'Richard Brockie' may help you here](https://intellij-support.jetbrains.com/hc/en-us/community/posts/115000114504--Solved-Git-SHH-Private-Key-PAssPhrase) 
That's awesome jsonathan! ^(*I'm an experimental bot. I can make mistakes.*)
Doing nothing!
It's 2 lines. Write your own function.
Nifty. Can these be rendered as man pages &amp; viewed with the `man` command?
You want to make it with only 3 symbols? This is not long, my friend.
After knowing that its not there in the package, I did my own function. 
That's because _time_ is complicated.
This is the need for packages, if they don't do what you want, innovate. this solution is proposing that I change unix\_epoch with my value. but the thing that is not mentioned: how I know that this amount of seconds = new date (10-07-2018 00:00:00)? that was my comment.
assessing a 2500-point GPX (GPS logging) file that a friend got from somewhere to plan a motorcycle ride. To see if the point order makes sense, I'm drawing a line from each point to the point with the next timestamp, then I'll measure each line to see if any are odd (If there are a few over 100 feet while the average is less then 20 feet, something isn't right.) Then I'll try to put them in the correct order.
This is my 5th project in Python (the largest so far) and I always get a new boring errors with time and arrays (list, Dict...). Their function names are wired especially for *time* 
Are you sure it's not the garbage collector? 
I agree about writing to a file, although the standard library's logger isn't exactly fast.
I did not. So there is balance. 
What is the meme? 
This appears to be the actual script used. https://github.com/ArionMiles/InfinityGauntlet At least this is the script linked to from the community made script.
That depends on what sort of proxy is there. You'll have to speak whatever protocol the proxy itself speaks.
It listens on http and https, so how do I make the magic? 
if you read the other comments has been discussed before. The main issue for me was not being able to use groups in an easy way
You need to send an HTTP request to the proxy itself. https://tools.ietf.org/html/rfc2616#section-8.1.3
So I need to connect to the proxy server and tell it I want to contact Google. Ok, but how can I implement it with raw sockets?
Have a look at the [requests module](http://docs.python-requests.org/en/master/), and [this stack overflow question about logging in to a website](https://stackoverflow.com/a/17633072/54557). If they don't have an API you will need to find the URLs of the particular pages where the actions you want are exposed -[ beautiful soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) might help with interacting with the site. It sounds like it could be a lot of work though.
By sending the right bytes to the server, as specified in the RFC I linked.
Working on @NanoTipBot on Twitter (nanotipbot.com). Adding spam prevention and offloading work to an external peer to improve performance.
Why is there a semi-colon? Almost no-one does this in Python and it took me a second or so longer to read this code than normal. Hiding a mutation behind a semi-colon is how bugs happen.
Beginners reading this: Please don't compare None with equals. it breaks under weird situations. Test for None with "is None".
Also a PyCurious redditor. This.
i had this thought as well because const void \* point class right above initPointClass. Clearly, the professor in comp sci who wrote this understands something here that we don't. Since this has nothing to do with python, PM inbound.
I just added the ability to dump local scope into [AREPL](https://github.com/almenon/AREPL-vscode). This is a big enhancement - one of the main drawbacks of AREPL is that it could only show the state of global variables at the end of the program. Now by calling dump() the user can inspect the state of variables wherever and whenever they want. It's like print debugging on steroids. https://puu.sh/AU57c/091d3076a8.gif It starts getting messy if you have a bunch of dumps() - but at that point you should move your code over from the scratchpad to your main program and debug it.
You can't time both in the same program because of state in the interpreter. If you disassemble with dis, you will see that the multi-line comments are not compiled in.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
cPython optimisation is basically non-existent. It removes comments, pre-computes constant expressions and loads compiled modules (from .pyc files) on import. Some of those might not even be optimisations from a compiler writer's pov.
In general, no, the main bottleneck with webscrapping is the connection. Now, of course there are certain things you can do to speed the process up: * Download only the information you need. Images, css, JavaScript files may not be necessary at all, so depending on your library, there is probably a way to disable those if needed * Run in multiple processes. Webscrapping is usually an easily paralelizable process, so it's worth the effort. Just beware of the Python GIL - you'd probably want to use multiprocessing, not multithreading. * Take your time to investigate whether you can get the same information from fewer pages (or an API). It's not always easy (depending on the website this may require quite a lot of reverse-engineering) or even possible, but it's definitely worth a try. Good luck!
source? that, admin used a custom one? I thought thats the script which was used
Started off with some simple notes and programs, and currently working with BeautifulSoup to scrap a webpage to receive the 7-day forecast. I figured it would be a good introduction to web scraping and get some practice in.
19
Time/date is a problem in any language. It's completely weird, and you always run into corner cases that break your code. Writing an accurate calender app is actually hard, which sounds crazy since they're ubiquitous.
Vscode editor support, and here I don't mean linting on save, I want live editor support where suggestions are enhanced by the interface definition, like you get with typescript.
I got snapped
What's the fucking purpose
Somebody wanted to make a bot that has Tourettes except instead of spouting obscenities it spouts nice things. I don't actually know.
This is really cool. I hope to find a use for sets!
Why would the second bullet help if it's a connection bottleneck?
The most important thing with sets is how fast they are for when you need to find if something is 'in' the set. The 'in' sets serch is about 100 times faster than a 'in' list search, but iterating over all the elements of a set is a little bit slower than a list. So pick the one that best suits how you are going to use it.
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
The example of list(set([1, 2, 3, 1, 2, 3, 4])) is dangerous. Sets are [unordered](https://docs.python.org/3/library/stdtypes.html?highlight=set#set-types-set-frozenset) collections of objects, so if the order of the list must be maintained, a set should not be used.
Unless you are downloading a website where each request is &gt;50MB, you usually have to download many many small objects. Downloading them in parallel is faster. All browsers do that.
Network programming isn't my strong suit, so I don't mean to sound like I'm correcting you, but isn't connection speed limited by things outside of your computer, like your router? If that's not the case, then why do I always experience faster speeds with a "better connection"; wouldn't the speed of one of my processing cores bottleneck it at some point?
Each process will be its own connection to a unique page. Which will result in the processes co-operating to gather all the desired pages. 
I just published report-on-interval: [https://github.com/dusktreader/report\_on\_interval](https://github.com/dusktreader/report_on_interval) It's a little utility that I used in one of my work projects and decided to peel it off into the world of open source. Give it a look-see!
If you're doing any kind of simulation and want repeatability on a random seed, be careful with sets. If you have a bunch of objects (say, instances of a class), the result of `list(set())` won't always be in the same order. For example: class Thing: def __init__(self, val): self.val = val def __repr__(self): return f"{self.val}" a = [1, 3, 2, 1, 4, 6, 3] a_t = [Thing(x) for x in a] list(set(a_t)) &gt;&gt;[6, 1, 1, 2, 3, 4, 3] Then immediately do: a_t = [Thing(x) for x in a] list(set(a_t)) &gt;&gt;[4, 6, 1, 2, 3, 1, 3] That's because Python [will use the ID of the object](https://docs.python.org/3/glossary.html#term-hashable) to help hash it. Those IDs change each time, so you won't get consistent behavior. A simple way to overcome this behavior is implement `__eq__` and `__hash__` on your class: class ThingHash: def __init__(self, val): self.val = val def __hash__(self): return hash(self.val) def __eq__(self, other): return self.val == other.val def __repr__(self): return f"{self.val}" Note that it's terrible practice to use an attribute as a hash value since that attribute can change value during the lifetime of the object. I'm doing it here for illustration purposes only. Now we'll actually get a unique set of `Thing`s based on the hash: a = [1, 3, 2, 1, 4, 6, 3] a_t = [ThingHash(x) for x in a] list(set(a_t)) &gt;&gt;[1, 2, 3, 4, 6]
I tried reversing the order of the functions and calls in the one file, with no real difference. What I don't understand is that `dis` shows the string "comment" removed in python3 but I'm still getting a slowdown that I can't explain. Python2 shows slowdowns of around 20%, so I guess there's no optimization there. Still, this is incidental to the main point.
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
It's not 100x faster. The difference is O(1) lookup for sets and O(n) lookup for lists. Consider the following largelist = [i for i in range(10**5)] largeset = set(largelist) smalllist = [0,1] smallset = set(smalllist) %timeit None in largelist %timeit None in largeset %timeit None in smalllist %timeit None in smallset results: 1000 loops, best of 3: 1.97 ms per loop 10000000 loops, best of 3: 130 ns per loop 10000000 loops, best of 3: 160 ns per loop 10000000 loops, best of 3: 133 ns per loop Nearly no speedup for the small one but HUGE for the large. And nearly no difference is speed for either set method
Make naughts and crosses using this setup 1 2 3 4 5 6 7 8 9 
Reddit API's are rate-limited so it's unlikely that the print is actually a bottleneck that you'd need to worry about for performance reasons.
I think you need to learn what a figure of speech is
Admins = work for reddit. Mods = volunteer for a subreddit. So "reddit mods" and "subreddit admins" don't exist. Just a clarification for anyone reading this deeply!
not every server has the same quality of connection or bandwidth. running them in parallel will prevent a long-lasting/poor connection from blocking everything else
Do you mean tic tac toe?
This is software engineering, not debate club. 
And they are indeed unordered, but that example has nothing to do with the order of the elements. It's just to show how easy and performant are sets to remove duplicates. 
It's implied that removing duplicates from a list one by one and doing list(set(l)) are equivalent, which is incorrect.
\&gt;.&lt; I forgot to put that the elements wont always come out in the same order, didn't i? i will add that for sure, thx!
This site says that pop() removes arbitrary elements. It appears to me to only remove them from the top of the set. In their example running s1.pop() would produce 2 and then 3 if they ran it two more times. Am I missing something?
It‚Äôs not clear what the problem is with the line of code from your explanation 
But sets aren‚Äôt ordered anyways so why would that matter?
1: google "python blockchain examples" 2: /r/learnpython 3: read the sidebars 4: yes, you can do that on mobile
separate your page retrieval from your scraping. have one task mindlessly downloading the pages one after another to somewhere (filesystem, ram, database, message queue, wherever). have another task that waits for something to parse/scrape. like others have mentioned, much of this can be parallelized. if speed is utterly crucial, python might not be your best choice considering the GIL 
They do come out in the same order, but it's what that order is based on that can change during runtime. If, for example, we ran a = [1, 3, 2, 1, 4, 6, 3] a_t = [Thing(x) for x in a] res1 = list(set(a_t)) res2 = list(set(a_t)) you'd see `res1` and `res2` be the same in the same run. But if you restarted the kernel you'd get different res1 values between the two separate runs.
&gt; pop() &gt; Remove and return an arbitrary element from the set. Raises KeyError if the set is empty. [Python 3 documentation](https://docs.python.org/3/library/stdtypes.html#set)
I think they mean synchronous downloading is a bottleneck. Not OP though. 
If you wanted a faster or more pythonic way of getting intersections or differences between lists. This is a trap I fell into because I wasn't thinking about sets as unordered, but rather as efficient ways to get unique values and do set operations. 
&gt; wouldn't the speed of one of my processing cores bottleneck it at some point? no, at this point in history, i/o will almost always be your bottleneck. CPUs mostly sit around waiting
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
Right but it doesn‚Äôt seem to actually do that. I tried it out in a python shell. s1 = {1, 2, 3} s1.pop() 1 s1.pop() 2 Etc, etc... so when would I see it produce 1 &gt; 3 &gt; 2 instead of always popping the elements in order? 
Iterating over a list and removing duplicates as you come across them maintains the order of the unique elements (as first encountered). Doing list(set(l)) does not guarantee anything about order. unique_list([4, 3, 2, 4, 2, 1]) # --&gt; [4, 3, 2, 1] unique_set([4, 3, 2, 4, 2, 1]) # --&gt; [1, 2, 3, 4] (perhaps) In general, converting from a set to a list doesn't make a lot of sense because a list is an *ordered* grouping and a set is *unordered*. If order matters (one of the only reasons to use a list), then you shouldn't use a set to store the data during processing. If order doesn't matter, why convert it to a list at all?
what?d sorry i don't get it
1) Because I was lazy to press enter and hit space 8 times on my phone keyboard? 2) Reddit is written in Python2, so was the core code and the code that did the ban (as shown in stream when the script got a memcache timeout error sent to it). If reddit was written in Py3, or was compatible with Py3, I would have written it as if it was Py3.
Thanks for the extra details :) I lazily typed my post on the phone.
Wrapping C api with Boost.Python, using it in Kivy app and deploying on Android. Lots of fun stuff, but I'm stuck at library inclusion in the executable so on the phone it does not throw at library import :)
I'm working on figuring out why this little bit of code: https://imgur.com/a/GKp6AIw Sometimes works as intended: https://imgur.com/a/gT5KGr2 But often acts strange: https://imgur.com/a/yhcoUBN 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/e0VqUqC.png** **https://i.imgur.com/pjztGQB.png** **https://i.imgur.com/v1XcjAO.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e24zty9) 
mmm try to use a larger set. If is the same, then you have found a bug!!!
Sets are unordered, which just means that there's no guarantee in the language that the elements will be removed in the order inserted (or any order). Try your same code with `s1 = {3, 2, 1}` and see that the elements are likely popped out of insertion order.
...I assume because taking out the print statements decrease the time the script takes quite significantly. Which makes it a safe assumption. Profiling is not always easily available in every environment, but sure I could I suppose. Don't see whats with the seemingly confrontational remarks over a non critical thing.
When you compare two functions and say "this one is faster and takes less code", it should be explicit if the two functions are not equivalent. Especially when the test input for the two functions is such that their outputs are the same.
depends on what you do with the responses. If you have to parse json or xml and do stuff then you will have some cpu. If you just store it in disk then yes its 100% io
To start off, the problem you're having is with sychronous programming. You might have a single method with a sequence of code that retrieves, parses, and returns. Well what if you could separate those processes? Suppose you have retrieve(url) and parse(page). Then you had those running independently, with your main thread feeding URLs to `retrieve`, and `retrieve` feeding the pages to `parse`. This kind of programming is called concurrent. You can accomplish it through the `threading` or `multiprocessing` modules. You can now allow many pages to retrieved at the same time. You now have to have a way to feed their returned `page` to `parse`. You can do that with a data structure. A basic one would be `queue`, which is synchronized in Python, meaning you can have multiple threads access them at the same time without funky things happening (unless you're doing funky things but whose fault is that). If i were to describe a queue as if it were a list, you would have limited use of accessing and inserting items. To get an item, you will always get the first one, index 0. To add an item, you would always append to the end. So you will always be popping the first item out, and pushing new items to the end. This is a FIFO or first in first out queue. Using a queue here would mean pushing your page to the queue. You would have some method or loop on the queue to pull from it. Once you get a page, `parse` it. This could be done in a separate thread too. Now, operations like networking are called IO. These hand off operation to the kernel, but in Python are "synchronous" or "blocking". Meaning, your next line of code wont execute until the current line finishes. Its blocking execution. **in this thread only**. By allowing for concurrent execution, another thread like `parse` can continue working while your network request is going on in the background. Now Python isn't waiting at all, it will switch between threads and continue doing work while IO operations are handled by the OS. Python itself is limited to a single process. If you're interested in learning about why, look up "Python GIL". But the implication of this is that only a single core on your computer will be doing work. You would need multiple processes in order to allow all your cores to partake in this scraping party. This can can done with the `subprocess` module or the `os` using the `fork()` and `execv` functions. The first holds your hand much more than the latter. However with multiple processes you now need a means of communicating data between them. This can be done with RQ, a simple Redis module for Python, or cooking up socket listening or other things, but simply put Python doesn't support multiple cores, or **parallel** programming from a single process. Now im on mobile so if you have any questions after let me know ill try to get back to you. 
as far as I know, the gold standard for OSS web crawlers is Apache Nutch. But in the python world, why not checkout https://scrapy.org/?
network traffic is I/O
Calculate a knights Tour on a chess Board of any size or shape
You can use multithreading with a Queue. 
When you do 10000 requests to a website the total time will never be just "downloading" those. There is some time for establishing connection and server processing before you start receiving a reponse. Lets say that its 50ms for 1 request. If you had to download 10 urls one after the other then you would have to wait for the 50ms x 10 = 500ms + the time to download the files. If you queried those 10 urls in parallel then you will have to wai5 50ms + the time to download the files. The download speed per file will be smaller but in total it woule be the same. In my experience, however, I usually see even faster total speed.
ask this in r/learnpython
Really useful, be careful with the sets!
Selenium 
When you hit reddit.com right now, that request may send you to r2 (old.reddit.com) or to the redesign (new.reddit.com). To pick the more complicated case, if you get the redesign you get a node server that ships you some JS and that JS makes a request from your browser that hits an API gateway (a service cleverly named `gateway`). To do its work, gateway may hit the listing service, the thing service, it may even internally hit r2 (which may itself hit one of those services depending on what it's doing). Some other services include chat, search, the ML service, the service associated with push notifications, and several others. The number of them is increasing. These new services are mostly in python3 and for the most part are built on our services framework [baseplate](https://github.com/reddit/baseplate) and communicate over Thrift (but there are exceptions to both). The general approach has been to build new stuff in new services, and to actively break stuff out of r2 only where it's necessary to accomplish something else. For instance, the Thing service gives other internal services access to data that previously was only accessible to r2 itself including fundamental data like Links and Subreddits; soon r2 won't own that data and will instead access it through the Thing service like the other services do. Messages are the first data type whose ownership has been fully moved to the Thing service. Some other stuff like building comment trees is still fully owned by r2 and there isn't a specific roadmap to specifically break it out, but if we rewrote it tomorrow for some reason we'd presumably build it outside of r2. This is part of why the main open source repo was such a pain to deal with just before we archived it: we tried to keep all of these new services as optional dependencies as much as we could so that open source folk could continue to run it all, but it's very quickly becoming a much more complex beast that fundamentally requires this stuff as the shape of the backend changes. Something that's interesting to me about it, having never worked at a multi-hundreds-employee company before this, is that not all of the motivation for it is technical. There's a little bit of that, like organising your software this way means that you can break part of the system without breaking the whole thing, but a lot of this kind of reshape emerges when trying to wrangle a lot of _humans_ working on the same codebase. Smaller monolithic codebases are great when you can keep the whole system in your head, but once no person can do that any more it's useful to break it into chunks that people _can_ keep in their heads. Even if that comes at the cost of some efficiency or duplicated work.
r/learnpython
Great. Thanks a ton.
Shameless plug for Go here. Goroutines are a breeze for parallel programming compared to Python. @op see me response in regards to how to use Python for this though. 
Good bot.
Hey I saw my name! I was apparently early in the ban process.
i know, im just saying that its not uncommon that you have some parsing of the responses on your script that downloads stuff, which could lead to some cpu usage
This is fascinating! I expect that cities with more consistent orientations of streets would see fewer accidents, since there will be fewer confusing intersections. 
im not trying to be disrespectful at all, but i genuinely don't understand why you're saying what you're saying
This is the way I understand it. Please ignore any spelling or grammar errors. I've just finihsed work. Imagine you are going to get a takeaway. Sometimes the roads are grid locked and it takes you 20 minutes to do the round trip (bad/slow connection). Other times it only takes 5 minutes (good/fast connection). Sometimes there is a long queue (Website's server is slow) and sometimes the place is empty (Website's server is fast). These factor in to how quickly you get your food back to your house (download the website data). Now imagine you have 10 friends over and you all want food. Trouble is your memory is rubbish and you can only remember one order at a time. You would have to make 11 trips to get everyones food (download 11 webpages). If your friends go with you in their own vehicles (more processes), they can each pick a different queue at the takeway and all get servers around the same time and get back to your house around the same time. Sure, you might have put more traffic on the road meaning a few of your friends are lagging behind (Your connection is the bottle neck) and you may have put the takeaway under some strain (the webpage data is servered to you slowed) but utimately you are saturating more of the resources and getting your food faster (can you tell i'm hungry?). Now imagine it with 100 friends. Maybe the takeaway can only handle 10 customers at one time. You want to be sure that as soon as a server becomes available you or a friend is ready to give your order (request the webpage). This would be much faster than if you had to make 101 trips yourself. The more friends with vehciles (more process) the more you can get done at the same time (in parallel). Now this could other problems. If all 101 of you left at the same time the roads would be gridlocked (you saturate your connection and it either slows down or stops all together). If you all ran up to the counter at the same time and started screaming your order the takeaway wouldn't be able to hear who is shouting what and not take any orders (denial of service). So there will always be a bottle neck in the proccess but it's always faster to do things in parallel providing you don't go overboard.
&gt; CPUs mostly sit around waiting lazy bastards 
1: /r/learnpython 2: research the APIs for each of those services 3: failing that, selenium 4: don't be a creepy stalker
Boston and Charlotte look reasonable, as a European (I'd love to see this for London!). What sort of OCD-ridden maniac designed Miami and Chicago?
They come in handy frequently. It seems pretty frequent, too, that they could be handy if only they were ordered - don't let that one bite you.
My boss tasked me to do this, don't think wrong. Thanks for the help!
fwiw I didn't take it as confrontational. I think they were legitimately asking why you don't verify. To which "I just don't care enough" is an acceptable response.
Okay, I will try to explain it again. If I don't manage to explain myself then just forget it :) In my experience, I have seen many cases where I (or someone else) had to download a list of urls. Scraping always (or not?) has the same goal: get information. It is very likely that once you download an html/json/csv/whatever you have to parse it and extract the specific information you are looking for. I have seen that almost everyone puts the 'downloading' and 'parsing/processing' in the same script, because that's the easiest and fastest thing to do. Usually, when this process takes too much to download+process then it's when you parallelize your work (download and parse stuff in parallel with multiple processes or just doing it asynchronously). When you are downloading a list of websites, you are never downloading at 100&amp;#37; of speed and using 100&amp;#37; of your network capabilities because there is time "lost" establishing connection, waiting for server to process your request, etc... Parallelizing will help the downloading speed, but since you will parse the responses, the CPU start increasing significantly (depending on the number of parallel processes you run). However, if you just download files, then the CPU will be negligible, of course. Hope this makes sense now
Ok. I will feed the trolls... Figure of speeches aside, my heartburn (hey, that's a figure of speech!) with "100x" is not pedantry. It is *important* technical detail. In computer science, there are many, many different ways to quantify "speed". One is to say, for example, "10x faster" which means, every operation that used to take X amount of time now takes ~X/10. This usually comes from optimizations of the process, and often in the python world, moving certain work to C or Rust, etc. Another way to quantify speed is algorithmic complexity where it is an asymptotic scaling analysis. This is often much more useful when it comes to choosing the right algorithm, data structure, etc. My objection is not pedantic for two reasons. The first is that there really and truly is a difference between 100x and O(n) vs O(1). Its not a "you know what I meant" type thing because both have very real, but quite distinct meanings The second is that the speed up really isn't even close to 100x. In my example before it is 15153.8x faster. Or, 1.23x faster. Why is it so different? Because it is a complexity change!
Open file descriptors also have a buffer, don't they? Not to mention potential overhead of logging.
Nice! I saw it on Github trending today and installed it straight away
I bet Indian cities will be like Charollete 
Working on a small pet project this week, a utility for creating the initial package structure for a new Python project. Check it out here : [Alacrity](https://github.com/vishnuvardhan-kumar/alacrity)
Are you doing string concatenation in prints? I don't mean to be confrontational. When an engineer of an instrumentable system says they assume that something's happening, it's just good practise to ask them why. It's more common in interpreted langs because the interpreter does a lot of magic that's hidden from the user.
okie
Ask your boss not to be a creepy stalker? :D
I just got about the same: https://bpaste.net/show/6a7d821dce0d
I had no idea about this until i actually got to see it in action in one of the problems i solved on projecteuler. When i used lists program took about 30 seconds but with sets it was under half a second to solve.
Hi, it's just a concept but speed is looking pretty promising! [https://github.com/xvzf/asyncspider](https://github.com/xvzf/asyncspider)
Changing old threaded code to asyncio (well, twisted, but you got the idea) \\o/
And if you're not an Inuit then what? ;)
SA2
Ye from the uk sorry lol
I also think that's illegal by the GDPR. So if you scan people in Europe you will have headaches. Also learn basics in Python and there is a simple way to scrap data from sites.
For a given ticker, scrape Bloomberg for that ticker's company description.
HahahaüòÇ
Oops I thought I posted it there itself
Sets have tons of uses in python programming. For python datatypes, `str`, `list`, `dict`, and `tuples` are used almost ubiquitously for everyday tasks. A tad less frequently (but still very common) I use: * `set` - whenever I have a collection that never has repeats and I need to test for membership in collection or just add/remove keys to it, * `collections.defaultdict` - a `dict` that starts with a default value when you access something not previously present -- note makes code more concise by not having to consider initialization case, * `numpy.array` - an array for fast vectorized math operations; e.g., if you have a million numbers in an array and you'd like to multiply all of them by a number -- note this is the only one of these not strictly built into python, but numpy is very commonly used . Finally, there the data types I occasionally use when the situation arises like: * `collections.OrderedDict` - a `dict` where keys are kept in a sorted order, * `collections.Counter` - a quick way to count up occurrence in an iterable (e.g., `Counter("abracadabra")` yields `Counter({'a': 5, 'r': 2, 'b': 2, 'c': 1, 'd': 1})`) Finally, there are built in data types that I never use in my programming, unless maybe I was trying to take an algorithms course and they say do something with a specific datastructure: * `collections.deque` - a double ended queue -- e.g., can act as FILO stack or FIFO queue) * `heapq.heap` (heap; basically a partially sorted list that you manipulate in a way to maintain the heap criteria, so it's easy to get a largest element without sorting the entire array), * `bisect` - module for finding/adding/removing things quickly (O(lg N)) to a list that started sorted, * `frozenset` - a non-mutable `set`, * `array.array` (a python list where everything has to be same specified type). * `collections.namedtuple` - a tuple that allows you to assign names to fields (basically aliases), * `collections.ChainMap` (new in py3 - a way of combining grouping together `dict` or similar mappings so you can look for a key through them sequentially). That said I probably could (or should) use `namedtuple` more frequently using tuples more readable, but I don't. Also probably could find uses for bisect or frozenset or deque, but almost never think to use them.
Attempting to explain the virtues of good software engineering to a self thought AI _'scientist_'... #pain
Building a script to poll the next 12 hours of wind data from dark sky that sends me a text using twilio if the wind will be above a certain speed. 
Arbitrary != Random
It is hardly complicated in to achieve the same result more cleanly in python. https://news.ycombinator.com/item?id=11328314
Find out if your server connectuon or your code is the bottleneck. If it is your server then start up a machine in the cloud to do your connections. If it is your code, then use pythons asyncio. It is made for use cases like yours.
So it looks like if I do {3, 2, 1} or even {3, 1, 2} it will always sort them numerically back to {1, 2, 3}. In that sense, does unordered mean that no matter what order I put information into the set, it will always get sorted however the set class thinks it should be sorted? I can't order things in a custom way in a set == unordered?
I need to reconcile three different reports where the dates might be of, and the amount might be the same - with no proper identifiers.
I was expecting a street orientation vs. Python comparison. 
Or maybe more, because we would be too comfortable with the signaling and stop relying on our senses as much as in more "confusing" layouts. It's very counterintuitive, but I remember an experiment was done in some nordic city. Don't have the link, sorry :)
Exactly the solution I had in mind. Setup a producer queue of websites and content and consumer queues - one for getting content and another for parsing it. Process the queue in a multi-thread or multi-process manner and you achieve significant improvement.
It's not as straightforward as that.
Yeah i always do that for my scripts when i have tons of page to scrape.
WrapAPI may be what you're looking for, or at least something to look into. -- IT Would create an API for the site that you could use to access fairly cleanly. They change something on the site, you just have to change your endpoints.
Nothing ever is, but that doesn't mean that there isn't some plausibility to the idea worth exploring.
Interview? What for? :-) def palnum(x:int) -&gt; int: return str(x) == str(x)[::-1] With the new controversial PEP for assignment in expressions, you don't need to do str(x) twice. No need to error check as it'll throw. Did I mention that I'm lazy? Please use /r/learnpython in future for "how to" questions.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
You can always store the outputs in an array and then initialize the dataframe as : `df = pd.DataFrame({'score': array_score, 'other_column' :another_array}) `
Thanks! will do. I'm interviewing for a Tier 3 position and some python knowledge is required. I'm trying to do it in the fastest manner possible.
Thanos is a Marvel villain who who is known for a storyline where he collects a bunch of powerful stones and then killed half of all living things with a snap of his fingers. He did this because of something about not enough resources in the universe. This was in a movie called Avengers: Infinity War. the subreddit Thanos did nothing wrong wanted to emulate him by banning half of their subreddit. That's the meme.
&gt;it will always get sorted however the set class thinks it should be sorted Exactly. No guarantees about how the data is organized.
The trouble is that the string of num is "(1, 2, 1)", including the punctuation. When you step through it with `for x in`, you are trying to get the integer of the elements of the list `['(', '1', ',', ' ', '2', ',', ' ', '1', ')']`. It chokes on the non-number elements.
If you just want a reproducible order of set for multiple executions you can set an environment variable like this `export PYTHONHASHSEED=0`
I can read the sidebar on mobil? How?
It's been explored. [https://www.tandfonline.com/doi/full/10.1080/01944363.2011.536101](https://www.tandfonline.com/doi/full/10.1080/01944363.2011.536101) [http://journals.sagepub.com/doi/abs/10.1177/0739456X12468771](http://journals.sagepub.com/doi/abs/10.1177/0739456X12468771) [https://www.ncbi.nlm.nih.gov/pubmed/21376865](https://www.ncbi.nlm.nih.gov/pubmed/21376865) [https://link.springer.com/article/10.1057/udi.2009.31](https://link.springer.com/article/10.1057/udi.2009.31)
Ah thank you very much, that fixed the issue. Now i can work on the other errors.
Literally central to the experimental process lol.
Beginner to beginner/mid level. It's a good start and intro. For more mid to advanced resources checkout my recommendations page: [https://developpython.com/index.php/2018/07/05/resources/](https://developpython.com/index.php/2018/07/05/resources/)
Very interesting article. You don't really think there is a need for non-developers to have a high level understanding of the types of systems. 
Well I‚Äôve finished making a math game Took me 1 hour to do so Not really proud of it 
Sorry, should have mentioned Windows 10, up to date. I'll look at the comment when I get home, thanks!
Thank you so much!
Yo asyncio/twisted aren't even close to the same thing
I mean Florida is just flat. There are no curves or hills. It‚Äôs very boring driving. The main obstacle in Tampa for instance is the interstate and a river. That‚Äôs it.
Just [published](https://github.com/PhantomInsights/prep-2018) a Reddit Bot that syncrhonized every 15 mins with a JSON file containing the latest results from the Mexican Presidential Election. I used Requests, PRAW and Matplotlib. All the source code is included and commented and also all the data collected.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
Other than the guarantee that you don't get to pick it yourself! Thanks for the info. I know this isn't /r/learnpython so I appreciate the info y'all have all shared here.
Thanks, good read. 
This is very good and super helpful. I have been looking for something like this. Thanks!
Look at the pypi homepage, there's a "browse packages" link right there for ya Once you click it there's a very-clear "Add filter" button which has the option to filter by certain topics
Also, make sure you're reusing connections. 
I am not the guy who said 100x faster but I personally thought it was clear hyperbole, which is why I said it was a figure of speech. O(n) vs O(1) is a massive difference such that hyperbole would be warranted. A larger number like saying a million times faster would make the hyperbole more obvious. The points you made are all valid but I thought it was clear that he didn't mean 100x literally
I did do that but maybe I come from a different world. I am an old man, a manager of managers who codes just enough to understand the t coming home my teams are using. For Java, there are three sources - Official JDK, Apache and Spring. For CPAN, the package name of the library provides the categorization. I did not find such grouping on pypi. Given the downvotes, the sentiment is clearly against me, so I will adjust my time expectations.
**Celery + asyncio** Asynchronous code in tasks, and regular tasks but called from coroutines. Also, I wish to be able to do something like \`await celery\_app.send\_task('foo')\` and get the result or a timeout. Any idea ? **Simplest celery setup** Setting up a full separate system as a message broker and another one as a result store can be overkill for a lot of projects. I don't want to setup redis on my raspi, and the SQLA backend has issues. Any simple setup to share ? **Celery + SQLA** Not as broker/result store, but about good practices on using SQLA models in tasks.
In your defense it's possible that the people who've downvoted you know nothing but Python and so aren't aware of how pypi's way of doing things sizes up to other languages' offerings
Not when you have 1000s of tenants, which is not that hard to get to.
I‚Äôm just as green as you are, probably greener. My answer... points to your own answer. Install the same version of python on your new computer and point the path to the old hard drive? Test it out and see?
Can you describe what you want to be more efficient with? CPU time? Bandwidth usage? Sequential copies vs. parallel? 
&gt; bog down when I encounter a large amount of files the bottleneck is probably not your program but the filesystem
What a phenomenal way to display this data! Love it.
I'm improving(and mostly cleaning) my pacman code i wrote for last semester programming lesson and after that I want to start writing stock-exchange simulator.
Sorry, let me clarify. I'm looking to improve copy time. These are files from an animation project that are backed up on a separate server and need to be recovered and copied to our main server for user access. They included, scene files (1 file but large file size), rendered frames (lots of files, smallish file sizes), and cached data (lots of files, mid-sized file sizes). The number of files doesn't seem to matter as long as the file sizes are small. But moving those large files just bogs things down. So I'm assuming that I just need to find a method to copy those large files faster. 
I'm currently reading [https://www.obeythetestinggoat.com/](https://www.obeythetestinggoat.com/) before working on a call events calculator for a dummy billing project.
Isn't there an intersection in England that has no marking and no sign, making it the most confusing intersection, yet one of the safest ones? I think I saw a Tom Scott video about that not too long ago.
Sweet! Love the Udemy coupon on the page to go with the book. I just went to the book store the other day looking for this one only to find they were out of copies. 
‡ºº „Å§ ‚óï_ ‚óï ‡ºΩ„Å§ GIVE SOURCECODE ‡ºº „Å§ ‚óï_ ‚óï ‡ºΩ„Å§
Lol same
&gt;I'm trying to do it in the fastest manner possible. Then you should avoid strings and lists. Working with numbers and basic math operations should be quite a bit faster.
I'd expect `shutil` to be a pretty thin wrapper around system calls, but if not, `subprocess.run(["cp", source_path, target_path])` will probably be as good as you can do.
Cool, thanks I'll give the subprocess a try and see how it fairs.
And Chicago literally burned to the ground and they moved fucking building around.
Premature optimization assumption alert. Palindromes are defined by the nature of character order. In this case, they're digits which come from calculating a base-ten separation of the integer. Which is faster: interpreting a hand-written Python loop to divide the number by 10 a bunch of times, or to use the decades-old well-optimized low-level code which Python already includes to divide the number by 10 a bunch of times? Which is faster: interpreting a hand-written Python loop to compare very small ints one by one, or to use the decades-old well-optimized low-level code which Python already includes to compare two strings?
I was wondering what makes Detroit have two clear orientations. I figure it out. The river Saint Clair, that runs through downtown, follows a diagonal path. So, the old town follows this orientation. As you go away from the river, the city turns to a more common N-S and E-W orientation.
Now someone needs to write a PyOpenCV script to consume the twitch video and reverse-engineer the list of banned users -- for science.
[removed]
Might as well mention that [frozenset](https://docs.python.org/3/library/stdtypes.html#frozenset) is available if you want it.
They also raised a bunch something like 14 feet up!
Cars, probably. My midwestern city is made into a grid with only neighborhoods deviating from the grid. It‚Äôs very efficient for directions because streets north/south are numbered, and only east/west streets need to be memorized. 
I ran the notebook code for Manchester and (Greater) London [https://imgur.com/MgWqfjG](https://imgur.com/MgWqfjG)
Does Vanilla python have a preferred looping order for 2d arrays? I know with numpy you can choose between C and Fortran memory layouts. I'd assume that python would prefer the C style of looping?
#2 is the real issue and sanic is no where as mature as WSGI based python frameworks (e.g flask, Django)
I agree. 3.6 is very mature and I‚Äôve been running multiple apps in production. Plenty of packages are available for it, and with 2.* approaching end-of-life, I would highly encourage moving to 3.x. Sanic is relatively young. I wouldn‚Äôt run critical systems on it yet.
Note - if stdout is attached to a console, it's only going to be line buffered (ie. the buffer will be flushed every "\n"), so it definitely will have a noticeable slowing effect. Line buffering gives only limited performance improvement (it's as if your buffer is only as big as the average line length, which might only be 20 bytes or so), but it's generally what you want in any interactive scenario. Obviously it's still a lot faster than ifit had putc() every character you wrote, but flushing that frequently can still be significantly slower than a buffered IO (ie. only writing when you've filled a multi-kilobyte buffer). You can see this if you redirect stdout to a file, where python will notice it's not attached to a tty and switch to being fully buffered (ie. only flush when the buffer is full / the file is closed). This can be an order of magnitude faster sometimes.
To be fair this is like saying that one should be careful about tuples because they're not mutable. Sets as an abstract concept are inherently unordered and the python set API never states anywhere that there are any guarantees on iteration order. I don't even understand from where one would get that impression?
Boston and Charlotte can go fuck themselves for this mockery of a city infrastructure. 
OP is a bit misleading here in saying it's buffered (see my [reply](https://www.reddit.com/r/Python/comments/8xi8tf/rthanosdidnothingwrong_banning_people_with_python/e25ounk/). When it detects its attached to an interactive console (ie .isatty() is True), Python is only **line** buffered, meaning it flushes every "\n". This can still be a lot slower than only writing when it fills a full buffer as will happen for a file on disk. &gt; can only assume it's because of the buffer being both large and nearly full. No - there's no degradation really with the buffer getting full - even in full buffering, buffers are usually relatively small (4-8 kilobytes is pretty common, as there's diminishing improvements for larger sizes), and they fill and empty pretty commonly. If you're seeing progressively increasing slowdown, it's unlikely to be buffers (at least, not *python's* buffers), but it might be something external. Eg. if your console preserves a large amount of history so you can scroll back to it, it might be struggling with recording thousands of lines. 
What does it mean that more roads go north than go south? One way streets?
I wonder what the external issue is then, because whether I write to a log file or output to a stdout, my scripts (can, depending on the amount of logged data) slow down significantly, anywhere from 30 to way over 100%. This is only for pet projects again. It just so happens that my pet projects tend to be filled to the brim with numerical data that on first run I print to ensure I didn't majorly fuck something up.
I'd go with Flask for this, it's been proven and can scale. 3.6 shouldn't be an issue.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
I heavily appreciate the insight. And I think many would have appreciated the insight when you announced reddit would no longer be open source, because regardless of the weight this had in that decision, it makes it seem much more reasonable. May I ask though, roughly speaking, what percent of r2 has been ripped out and separated into services. As in, starting from the last open source version, disregarding the non open source anti spam code, how much of that is still owned by r2 and not factored into say, media provider service, tdb service, templating service, cache service, etc, and not counting any *new* services, like chat, or the circle of trust stuff, or whatever else?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, this post has been removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
Thanks
One possibility for that kind of thing can be memory leaks. Eg. if your script keeps allocating memory, it might end up bloating up to the point where it triggers a lot of swapping, slowing things down. That's pretty easy to check for though - when you notice it's slowed down, check how much memory it's using (or if anything else is using a lot for that matter), and if it's unreasonable, look at stuff you may be inadvertently keeping alive past the point it's needed. Alternatively, it might be something in your algorithm that's accumulating extra work as time goes on. Is it definitely specific to logging? (Ie. if you disable all logging, whether to file or not, it goes away?) (Though one issue of course is detecting this without logging what progress is made, so maybe use a few sparse print statements instead, so long as your logging system isn't involved). If not, it might just be something incidental that gets worse over time, only correlated with logging because you do more of that over time too. Otherwise, it might be a similar issue in your actual logging system (Eg. something somewhere is doing something dumb like reopening and re-reading a file when writing new lines or something) (though admittedly, something like that'd probably show a lot more than just 30-100% slowdown). Finally, there's always using an actual profiler, though this can be more awkward for issues that only manifest after some time has passed. Though you could maybe do some more ad-hoc approaches like tracing activity with strace (on unix) or process monitor (on windows) to see if there's anything obvious (eg. IO buffer issues will often show like a lot of low-size write() calls).
Erlang?
While cool, would be better if all the rings were the same for each city so the comparisons are more useful I think.
I have no clue... I‚Äôve yet to ask the guy lol
As a resident of Atlanta I feel like I‚Äôm missing something. Out streets make no damn sense. 
Boston and Charlotte are that way because they are both collections of colonial towns which grew together. I suppose European cities are also conglomerations of small towns which grew slowly together. 
Working on a character for Strip Poker Night at the Inventory.
I think San Francisco‚Äôs famous Lombard Street has the most similar orientation to Python. /s /grammar-slam
All objects are dereferenced ASAP. It always seems to be specific to logging, regardless of what logging solution I use. Could be coincidental, totally. If it is though, at this point my coincidence factor is extremely high and I'm unlucky. To give the worst case scenario example I have had so far, to create and make use of 240,000 data sets, of what I would call a reasonable size. Single thread/process, on my best machine, it takes ~3 hours no logging. With a "reasonable" amount of logging, either to stdout or to disk, it takes 8-14 hours. Could theoretically be line size of the data, because I've noticed in multiple cases different programs seem slower when opening text files that are, say, many characters but a few lines, vs many lines of many of the same characters. Though it's never been annoying enough to warrant profiling, which is why I haven't done it.
&gt;That's because Python will use the ID of the object to help hash it. Also worth noting that this is true even for some things for which it *doesn't* use the ID of the object (eg. strings), though for a slightly different reason. This is because python will deliberately perturb the hashes of these values with a random seed generated on startup, so that the hashes are not predictable to potential attackers who could otherwise potentially cause DOS attacks in some cases by providing lots of keys that they know will hash to the same values, triggering O(N^2) performance when inserting/retrieving them from a hashtable. Also, incidentally this is no longer true for dicts, since now their iteration order is no longer dependent on what bucket they're in (and hence the hash value). Instead, they are always iterated over in insertion order. (Though it's still generally not something you should be relying on, as someone making a code change that happens to reorder some things could change the order, and that's not really something you'd expect other code to be relying on.
I am doing an elo based system to rank players in 1v1 billiard games. So far I have the actual system and a Tkinter Gui working, as well as data storage. Now I will put a tournament bracket builder and some statistical analysis and call it a day.
Based on my coworkers in the IT field in Charlotte, many feel right at home here.
No - this won't do anything to change the issue OP is talking about. The `id()` of created objects will still effectively be random, PYTHONHASHSEED only controls the **extra** perturbation python applies to stuff like strings to protect against certain attacks, which is different.
&gt; .OrderedDict - a dict where keys are kept in a sorted order, Note - actually this is a dict where keys are iterated in **insertion** order, which is not the same as sorted order (ie. the equivalent of `sorted(list(the_dict))` And this is somewhat redundant in recent versions of python, since the default dict implementation actually now preserves order by default, and in Python3.7 this behavior was made part of the language spec.
Magnifique! Did you take into account the length of a street when counting it towards the histogram? Let's say we only had two streets, one NE-SW and the other N-S with a respective length of 1 m and 1 000 m, the second one would be almost the only one perceivable in the plot if done this way.
"top of the set" is not really a well defined criteria. Eg. any set resize (which could be triggered by inserting an item, even if you immediately remove it again after) could completely reorder the whole set, changing the "top". Because of the way sets are implemented, the way it picks the first item to show when iterating (which is used when printing the set too), and the way it picks the item to pop happen to be the same, but note that **both** of these are arbitrary. That's not the same as random, it just means there are no guarantees you should be relying on. Something could change the internal structure of the set (eg. a resize), and the item it'd pick would be completely different. Likewise, future python implementations could change the mechanisms of one or both of these, so they happen to return different results. "arbitrary" just means there's no *reason* to the pick (at least, not one you the client should care about or rely on in any way - there may be performance/simplicity reasons to implement it the way it is of course).
Cool read!
&gt;In general, converting from a set to a list doesn't make a lot of sense because a list is an ordered grouping and a set is unordered. That doesn't follow. Eg. one might want to convert to a list because: - one wants to sort it (ie. **impose** a certain order on the unordered data. (eg. call `l.sort()`) - Use another list property than ordering. Ie we may not care about the order of the data, but we do want to be able to have random indexical access to it (or pass to an interface that requires indexing, rather than just iteration). - Use less memory (eg. we don't care about fast membership checking, and don't want the expense of the hashtable associated with the set). Only really an issue for really big lists, but the hashtable overhead can be several times the overhead of the list. Ie. just because sets are unordered and lists are ordered doesn't mean that that's the **only** difference between the two, or that lists aren't sometimes the better data structure to use to hold some unordered data in some cases. 
All fair uses of lists, yes. All I was really trying to get at was that the example was misleading, and that suggesting, intentionally or otherwise, that converting between lists and sets only removed duplicate elements without any other side effects was incorrect.
Love the visualization. Though I personally hate cross oriented cities. So unnatural, like living in an alien place üëΩ The cows in Boston have better sense üòÄ 
Forgot the great for .. else loop.
&gt; would have appreciated the insight We said exactly this. The top comments all said it was bullshit ü§∑ &gt; what percent of r2 has been ripped out and separated into services [...] not counting any *new* services Not a lot has been *removed* yet. We're early in the process and for a lot of it we run them side-by-side for a while. I'm very familiar with the search case where we only recently actually removed the cloudsearch code after running in in parallel with new search for a while so we could have confidence in it before cutting over (and wanted to give some time between the deprecation and the API breakage). But much of the removal/rerouting to new services occurs in very core functionality, like computing your front page.
The map for Denver doesn't look right. About half of downtown is at a diagonal to the rest of the grid (~50 streets), but I don't even see a trace of that.
This describes Indian cities really well. Each neighbourhood started out as an independent village/town and got absorbed into the city as it grew. 
First time actually sitting down and learning Python. In an hour I wrote a password generator. I am going to be writing some Cisco and other network based automation for deployment and information gathering at scale. Pretty cool learning something completely foreign. Takes me back to when I first started learning Cisco. 
While you guys did say you were splitting up reddit from monolithic to service oriented, I don't believe anybody put it like you did-- my consensus and the consensus of others was the provider system of r2 and the plugin/service system of having importable packages (like the thrift activity service), not chipping away at old "main" library code and putting new things which would seemingly be put into r2.lib / r2.lib.public into a new package altogether, and interacting with it. That said, you will still get people thinking that argument is bullshit. Is it, isn't it, no one knows outside of reddit and no one will trust those inside of reddit, for obvious reasons.
Oh, I've maybe been misunderstanding you - I thought you were saying it started fine, but slowed down after a while when logging. If it's just plain always slower with logging enabled vs not, the above post might not be too relevant. It does sound like something's screwy there - unless you're logging gigabytes of data, I wouldn't have thought it'd make *that* big a difference. Unfortunately, nothing obvious comes to mind. Though for a quick and dirty approach there's always the "poor man's sampling profiler" method. Ie. start it a few times and just control-c after a few seconds and look at the stack trace. Repeat a few times and see if there's any place that's showing up a lot (especially if in logging code), then look there and see if you can figure out why it might be spending time there. &gt;I've noticed in multiple cases different programs seem slower when opening text files that are, say, many characters but a few lines, vs many lines of many of the same characters. Mostly this is because they're programs that organise the data into some line-oriented structure rather than process it as a stream or something. Ie. they're doing the equivalent of python's ".readlines()", which needs to not only read the data, but also find the linebreaks and split into strings on them. **Writing** logfiles shouldn't trigger anything like that though, unless there's something odd happening. 
My guess is that if you zoom out enough most streets are north-south. I see what you mean though, the actual heart of Denver isn‚Äôt north-south at all. 
Just take Peachtree, you'll get there.
What?
I'm with pocketstories on this one. üëçüèº 3.6 in production (since release). Very good package compat. Sanic is cool - but very young. 
I changed that example to another one for having less misunderstandings.
And reversed the direction of the river!
On rereading, I see how my word choice was bad. I meant to state the dict keys when iterated are kept ordered and used the word "sorted" to imply they will not come out in a random order, not that they will come out as if the keys were lexicographically sorted by key, but instead sorted by "first key" comes first, "second key" comes second, etc.
Thanks for running it and showing your results. After looking at the bytecodes (first thing I did) I expected no difference under python3. But I still see differences, sometimes small, sometimes large under python3 and macOS and Linux. I know it *must* be an artifact, but I haven't found the cause yet. On iOS using pythonista I see no difference, as expected. Pythonista is fast(ish) and surprisingly complete as a python system. I'm impressed, though the soft keyboard limits the system.
I ran the same thing and the first one was faster than the second...
What does the code do with all the roundabouts? 
Exactly
I have the greatest respect for Trey Hunner's Python writing but to me this [Loop like a native: while, for, iterators, generators](https://www.youtube.com/watch?v=EnSu9hHGq5o) is the ultimate for Python looping.
Manhattan isn't a city.
Misspost. Carry on.
With emacs python-mode.el, TAB is mapped to "py-indent-line" which cycles through possible indentation levels. I miss this behavior. I couldn't find it in Atom and now I can't find it in VSCode. Are there extensions in modern text editors that provide this behavior? Do I need to port the py-indent-line function in order to get this behavior?
Went to check the docs and sure enough they're called unordered. But afaik the builtin set and frozenset use the same bucketing strategy as dict which is now insertion ordered. 
I mean, tab/shift+tab?
I mean, that's probably close enough. I didn't think of shift+tab. I still like how I can toggle the indentation in emacs no matter where my cursor is located in the line. Thanks.
If you were using virtualenv and git, it‚Äôd be as simple as committing on one machine and pulling on the other. They way you‚Äôre doing it now, you‚Äôre toast if that hard drive fails. 
For this task is easier use wget, a cli with lot of options. I do that some years ago with the website of one course. I don't remember the options but it's really easy to use. 
Wait for the ASGI standard to be finished if you can. 
I figure I should explain the stream writer if you've never heard of it--so as to explain why I recommend it. Stream writers allow you to "purge" stuff from memory to disk--which is really useful when dealing with larger input.
Vim can do it with some options that i don't remember. But I guess that coming from emacs you want something different. 
What is it then? A portal to hell?
Machine learning project. Trying to get a network to generate novel interpolated audio samples using many multiple audio samples as training sets. Hard part is converting sound into something the networks can understand. I had to create a unique way to create a 3 dimensional representation of sounds that contains all frequencies across the human hearing range, each as a temporally coupled input to the input layer. I modelled this after the way the human ear is interfaced with the brain, in hopes that modelling biology will produce desirable results. 
Netherlands can into Nordic
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
Sublime text does it with ctrl+[ and ctrl+]. It can also toggle any lines you have selected.
Visual Studio code can do it if you use the Vim mode plugin.
/r/Surveying
Models in production. Fast code is cool, but can you put you model live, accepting new input data, without it breaking randomly. Accepting new information real time is hard to do.
I suggest looking at eve http://python-eve.org/ I used it when creating my rest API and done it really good.
TLDR: "Generators are iterators. And iterators are single-use iterables. They're like Hello Kitty Pez dispensers that cannot be reloaded." - Trey Hunner 
Oh great! I‚Äôll look into it! Thanks!
Zip them up? For files across a network, cp is faster than windows remote desktop. Making o e big file is also better than many files. However, things time out.
could use a little help...trying to come up with a method to perform load combinations and transient load patterning. without patterning it's fairly simple: `list of load results = [[d],[t1],...,[ti]], where [ti] = transient load result as a numpy array = A` `list of combos = [[1,0,....,0],[0,1,....,1], [dfi, tf1,.....,tfi]] , where tfi = code load factor for transient load = B` `in python this works as` [`numpy.dot`](https://numpy.dot)`(A,B)` so my issue arises where: `list of load results = [[d],[t1],.....[ti]], where [t1] = [[t11]......[t1i]] for i pattern possibilities and [t1i] = numpy array` so I have a nested array within another array and want to multiply by a matrix of load combinations. Is there a way to implement this in one matrix operation, I can come up with a method by looping the pattern possibilities then a dot product with the load combos, but this is computationally expensive. Any thoughts? Thanks
I've used this \[Flask + Rest\]([https://flask-restful.readthedocs.io/en/latest/](https://flask-restful.readthedocs.io/en/latest/)) . It also has swagger built into it some decorators and you have a swagger interface that is useful for the other developers.
Flask-Rest and Cherrypy are both very minimal, simple, and extensible. We use Cherrypy for building internal services at work and it's easy to maintain!
When a speedup by a factor of 100 is possible and even a reasonable result, it's not much of a hyperbole. You and I know the difference, but someone unfamiliar with these concepts may not. 
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
Trying to figure out why the hell the same exact process can take a vastly different amount of time when run repeatedly. Also trying to figure out how to use multiprocessing to effectively stagger that process efficiently, so far I haven't been very successful
Chicago burnt to the ground, which is why it‚Äôs called The Second City, and they made the grid and that‚Äôs also why Chicago has alleys. 
great input, thank you!
great idea, thanks!
I've never used huey but comparing the two and migrating to Celery sounds very interesting. thanks
I'll have to do some research but I'll do and will write about it. thanks
I'm not familiar with how `conda` works, but it _seems_ to me that what's happening is that it first tries to install from source, but discovers that you don't have CMake (a program needed to execute build scripts of the package, most likely). Once it discovers that, it _seems_ like it tries to download a binary wheel of that package, which seems to cause it to create a mess of your environments (lots of packages being downgraded). Maybe try installing CMake and re-installing your packages?
you are right, you are right, it does not affect hash of normal objects [python docs](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONHASHSEED) &gt; If PYTHONHASHSEED is set to an integer value, it is used as a fixed seed for generating the hash() [str, byte, datetime]
It sounds like you're trying to scrape a lot of web pages. (sorry, your original post seems to have been removed) For big scraping jobs, consider using a framework like Scrapy (https://scrapy.org/), which is designed specifically for web scraping It's built on top of an asynchronous networking library called Twisted. `scrapy bench` (https://doc.scrapy.org/en/latest/topics/benchmarking.html) on my machine reports that it can crawl around 2900 pages per minute, assuming you're running a rudimentary spider that only follows links. 
Just don't use Zip. Zip archives each file individually: this may be good for extracting individual files from archive later on, but is a poor solution for transferring multiple files together. Use something like Tar + some more modern compression, eg. bz2 or 7z. Here are some infographisc to show the difference: https://askubuntu.com/questions/236598/best-compression-method
tab and shit+tab are pretty standard
Awesome video. Thank you for sharing.
If it's not for production, just use [flask](http://flask.pocoo.org/docs/1.0/quickstart/)
Zip actually performs quite well on that chart. It's not the smallest, but it takes the least amount of time and is a respectable 615 MB. The goal is not necessarily smallest size, but rather quickest file transfer inclusive of compression time. It's definitely better to zip ifiles up and send them across a network (less file fragmentation) vs not. Is it better to save 150 MB or save 10 minutes? I'd go with the zip file in that case.
Working on a text-based RPG discord bot with a lot of random generated elements to it.
Doesn't Python look down upon tab indentation? I thought they recommend space indentation. Or, are you saying it automatically switches tabs to preset spaces?
I would love to see the Jupyter notebook code for this, if you can share.
Yes and no. Some are towns that just expanded into the countryside with no real towns around it (like Oslo). London, on the other hand, swallowed up lots of smaller towns. There's lots of streets in London named "X High Street" that are usually the Main Street (in US terms) of a town named X that was swallowed up. Clapham High Street is one example.
He clearly talks about keys not characters.
I'd try httrack I think you can tweak it to do that.
&gt; Here are nine lectures walking through the internals of CPython, the canonical Python interpreter implemented in C. They were from a dynamic programming languages course that I taught in Fall 2014 at the University of Rochester. The format isn't ideal, but I haven't seen this level of detail about CPython presented online, so I wanted to share these videos. &gt; &gt; Philip Guo (Assistant Professor of Cognitive Science - UC San Diego ) &gt; &gt; http://pgbovine.net/cpython-internals.htm
Forgive me for this take on simplicity, but... You probably want to learn Python, but if the book is meant for Applications in R, why not use R instead of Python? Or why not switch to a book about statistics on Python if you want to work with Python? If you're still learning the basics, don't over-complicate things by trying to implement stuff that's meant for a different language. 
Uh, idk about Boston but this is not true for Charlotte. What is now Charlotte was mostly farms before they became subdivisions. Charlotte complete lack of a grid outside of uptown is mostly due to a complete lack of city planning for most of the period when Charlotte was expanding.
`Ctrl+]` to indent, `Ctrl+[` to outdent. https://code.visualstudio.com/docs/getstarted/keybindings#_default-keyboard-shortcuts for reference
I get that. But, as for refresh tokens, they inherently do require state. The JWT **access token** is stateless. That is not stored anywhere (except perhaps by a client). And, as is its point, expires at a given time. However, refresh tokens do not expire and "is a string representing the authorization granted to the client by the resource owner." https://tools.ietf.org/html/rfc6749#section-1.5 Furthermore, "[refresh tokens] are usually subject to strict storage requirements to ensure they are not leaked. Nevertheless, they can be blacklisted by the authorization server. ... Refresh Tokens are long-lived. This means when a client gets one from a server, this token must be stored securely to keep it from being used by potential attackers[.]" https://auth0.com/learn/refresh-tokens/
Thank you for replying! Actually I have a data-set: [this](https://www.reddit.com/r/datascience/comments/8vp03r/learning_datascience_by_myself_need_some_help/) , I am learning everything to implement on this project. I don't know any good book about statistics on Python so, I was using this book and keep moving forward.
As I know, There is no such thing than vanilla 2d array : at most nested iterable. Each "row" can contain arbitrary object, iterable of variable length, so the "C" or "F" order is not really relevent.
In Pycharm it is tab and shift+tab. You can also use ctrl+‚Üë or ctrl+‚Üì to move line into loop indentation, it also works with multiple selected lines :) 
Check out r/learnpython
I think this is something similar to what you want, maybe you can use it as an example: https://gist.github.com/frxstrem/4487802
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
Sure
There is no best programming language. 
That depends on what you mean by "best programming language". Python is already one of the most widespread languages out there.
I was searching for something like that actually, thanks! 
No options. Just &gt; for tab or &lt; for shift+tab
Cognitive Science, hmm.
Editors and IDEs allow you to map the tab key to spaces or tabs
I already had CMake. After I rebooted pip worked...
The "variables" my\_word and other\_word are not defined anywhere. They are input parameters to the functions they are defined in. Consider the function def print\_word(my\_word): print(my\_word) print\_word('hello') prints out 'hello' to the console and print\_word('goodbye') prints 'goodbye' to the console. Thus, my\_word is just a placeholder for whatever input is handed to the function.
So? 
So that's an unusual pairing for this topic, I wonder what's the deal here.
Nonsense, quite clearly [CORAL 66](https://en.wikipedia.org/wiki/Coral_66) and [Monk](https://docs.oracle.com/cd/E18867_01/SRE5.0.5U2/Monk_Reference_SRE.pdf) are the best. No guesses which I've used in the past :-)
**Coral 66** CORAL (Computer On-line Real-time Applications Language) is a programming language originally developed in 1964 at the Royal Radar Establishment (RRE), Malvern, UK, as a subset of JOVIAL. Coral 66 was subsequently developed by I. F. Currie and M. Griffiths under the auspices of IECCA (Inter-Establishment Committee for Computer Applications). Its official definition, edited by Woodward, Wetherall and Gorman, was first published in 1970. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
\&gt; 3.0.1 I'm just curious, why did you decide to "mess with" and old Python version? Why not choose a newer one?
E.g. artificial intelligence and linguistics are part of cognitive science.
I recommend you to try to use flask and flask_restful with swagger.
If you want to integrate API Server with database, SQLAlchemy would be a good library.
I've been toying with Sanic on some testing sites... I wouldn't use it in prod yet. It's still a moving target, and I've had my share of both keeping-up-with-current and issues with running it. Stay boring. Python 3.6 though, I've been using in testing since release and in prod for more than a year now. It's been perfectly solid for me, and I've had no issues with it other than wanting to cry when I had to go work on older systems that hadn't yet been scheduled to move. Python 3.7 already in testing, zero problems hit so far, that metric is meaningless given the amount of time I've had it out there :)
Desktop micro benchmarks are quite random because you don't own the OS. Could be time for Windows to defrag or something. Wouldn't surprise me if iOS is more consistent.
Wow! some months ago I found something like this
Also I'm providing the link to the PDF urgent help needed. [https://trainings.internshala.com/uploads/python/downloads/project/v\_1/Python\_FinalProject\_ProblemStatement.zip](https://trainings.internshala.com/uploads/python/downloads/project/v_1/Python_FinalProject_ProblemStatement.zip)
Also the link to the .docx file. [https://www.scribd.com/document/383648541/Python-FinalProject-ProblemStatement-docx](https://www.scribd.com/document/383648541/Python-FinalProject-ProblemStatement-docx)
Nice idea. Love it. Thanks for making open source!
That's super interesting. I hope you keep us updated on how it goes!
An excellent video, Loop like a native helped me get my head around Generators.
It was the one on my computer, but I'll do it with 3.7 too..
My mind just got blown, twice.
It's the best one for Android still.
No, kivy is bad choice. It gives more problems than advantages. You can consider something wrote on javascript. ReactNative, Electronjs or something like this. if you know C# - Xamarin
Please tell me you aren't pressing space-space-space-space and your tab key is inserting 2 or 4 spaces?
IMHO, the question is what do you want to optimize with Sanic, response times of individual calls, or number of handled requests per second? First I'd do some tests to see whether flask isn't enough for you. Behind uWSGI and nginx, you can maybe get 2K responses per second on a normal VM with let's say 4 CPUs. (This of course depends on the complexity of the calls themselves). Maybe that would be enough for your use case? Also, if the API usage is very high, there are other possibilities like load balancing between multiple machines, or automate it via Kubernetes, etc. With Sanic you can probably optimize the response time of individual calls, but do you need that? 
No, my IDE intellij has a setting to add four spaces when I hit TAB.
This material is great. I‚Äôve known about this for some time but its good to see it posted/re-posted. The tails of distribution is such that there‚Äôs an over abundance of beginner material and a shortage of high quality material. 
The length in the plot is based on the frequency of streets with that particular orientation, not the length of the street. I believe in your example each line would be the same length. 
Thank you for that break down. That helps a lot! 
Am I missing the portfolio portion? I see the links to Github, LinkedIn, and email and that's about it.
I'd like to know more about python internals but is there anything more up to date with python 3.x?
Sorry kiddo, you're gonna have to do your own homework. Use PyQt.
Good! Here's mine Flask, Jinja, Boostrap : saavento.com
Instead of just linking directly to your GitHub, you could put little cards or something with descriptions for your more prolific projects that link directly to the repo. That way they can see at a glance some of the stuff you work on and just follow the link if they want to know more. It looks nice and clean though.
There is a lot of blog posts describing specific parts of CPython.
It is too easy to miss a dependency on the order of elements. Consider this: class Foo: def __init__(self, a, b): self.a = a self.b = b # Will always print the same: print(min([Foo(i, j) for i in range(3) for j in range(3)], key=lambda foo: foo.a).b) # May print 0, 1 or 2 print(min({Foo(i, j) for i in range(3) for j in range(3)}, key=lambda foo: foo.a).b) The result here is always correct, but not consistent.
Feedback for what? The page is empty. 
That's what I'm looking for. Thanks!!!
In the same way everything is part of philosophy. That doesn't mean professors of philosophy teaching detailed courses on highly technical STEM subjects is terribly common and not at all interesting. I don't think this is very relevant to linguistics (other than the "linguistics" one might find in e.g. The Dragon Book) or at all relevant to AI. It looks like a plain computer science or software engineering class, and fairly advanced too. if someone is teaching it they are usually a CS professor. Apparently people don't like my comments, but I'm not sure why. I didn't mean any animosity and I certainly didn't express any.
Kivy send to be dead for a while now. My best experience was with pyqt. Haven't tried wxwidgets yet. Could also be good.
This seems more like an attempt to get eyes on your site than asking for feedback on it.
&gt; Kivy seems to be dead for a while now. It really isn't, in fact we just completed a new release.
[Bottiquette](https://www.reddit.com/r/Bottiquette/wiki/bottiquette) &gt; **Blacklist certain users on request** &gt;are always users that do not want to be part of your bot. If your bot is not explicitly "summoned" by the user, create a way to opt-out of the bot's services. &gt; **Allow users or moderators to communicate with the creator/maintainer** &gt;Some subreddits will probably not like your bot or would like to either make a few suggestions or want your bot removed from the subreddit. Either list your username or a dedicated subreddit in the bot's replies. --- Honestly it's so annoying how many useless bots there are running around. Really wish Reddit would either add official support for them, including the ability to completely ignore them all and an official method of reporting them
&gt;I didn't mean any animosity and I certainly didn't express any. \&gt; Cognitive Science, hmm. Oh yeah, not like it sound contemptuous, hmm. 
Why wouldn't you just use GitHub Pages for this? But regardless, if you're going to run an entire webapp to serve a single page, you should at least have a real 404 page...
 ^(*I'm an experimental bot. I can make mistakes.*)
And? It's not a 'mistake' by the bot to leave out the information I referenced from the bottiquette. 
To me it doesn't. It might be a cultural difference, but I've checked a couple of English dictionaries and apparently "hmm" is not contemptuous by default in English either.
I only wonder how much time it would take to see the entire video
Great material, it really helped me a lot, thanks for sharing.
Would you mind explaining why it "gives more problems than advantages"?
The problem with using these visualizations to make a statement about a city's infrastructure, is, in my opinion, that it doesn't distinguish between "downtown" and "suburbs." Looking at a map ([link](https://www.google.com/maps/place/Charlotte,+NC/@35.2080909,-80.8881418,11.25z/data=!4m5!3m4!1s0x88541fc4fc381a81:0x884650e6bf43d164!8m2!3d35.2270869!4d-80.8431267](https://www.google.com/maps/place/Charlotte,+NC/@35.2080909,-80.8881418,11.25z/data=!4m5!3m4!1s0x88541fc4fc381a81:0x884650e6bf43d164!8m2!3d35.2270869!4d-80.8431267)) makes this easier to visualize: from a zoomed out view, you can clearly see that the streets are, for the most part, laid out radially like the visualization suggests, with the downtown as the center. If you look at just the downtown area, though, (which is more or less the area enclosed by 277, [link](https://www.google.com/maps/@35.2253335,-80.8426294,15.5z)), you can see a much more grid-like pattern. 
Oh nice. I always liked kivy. Only problem I had was that instead of having the native style on every platform you had the kivy one on all of them. Which of so a good solution to the multi platform problem just not the one I prefer.
&gt; 'hello' to the console and print_word('goodbye') prints 'goodbye' to the console. Thus, my_word is just a placeholder for wha So when do you need to define the parameters vs just using ()? 
Hey, you got a minute? I can't seem to get my code working properly. It runs as expected the first time but the second time the GUI crashes.
You're welcome!
Sometimes it's best to go to the professors page on a university website or their personal page to get a better understanding of them: &gt;Philip Guo is an assistant professor of Cognitive Science and an affiliate assistant professor of Computer Science and Engineering at UC San Diego. His research spans human-computer interaction, online learning, and computing education. He currently focuses on building scalable systems that help people learn computer programming and data science. Philip is the creator of Python Tutor (http://pythontutor.com/), a widely-used code visualization and collaborative learning platform. So far, over 3.5 million people in over 180 countries have used this platform to visualize over 50 million pieces of Python, Java, JavaScript, C, C++, and Ruby code. http://pgbovine.net/
This is super neat.
Sure, that's what I did. Interesting dude.
I am relying upon memory here but if I recall correctly, you don't install Anaconda with conda (partly because conda is inside Anaconda). You install the Anaconda distribution straight from their website as a normal software install (download, run, approve, approve folders, customize as an option, do you want the icon on the desktop?). That installation includes Navigator and you use Navigator to install additional libraries that aren't already included in the primary distribution. Once you install Anaconda you may never use pip or conda again (although you might). Go to https://www.anaconda.com/distribution/ and read their instructions.
&gt; nt to go to a single location to get available libraries for the ‚Äústatistics‚Äù category or ‚Äúnetworking‚Äù category. Where do I look? Right now, that involves guessing, stack exchange and google searches. Congratulations! That looks like nice progress. I've done that and more and still learn from /r/learnpython. I thought you might be able to get more help there since this is a sub for news. Good luck googling stuff!
Probably about 10 hours. 
I'd say roughly 600 minutes.
I love Flask so I'm clearly on one side, but I just developed/deployed my first complete website with zappa and it just felt good and easy. I had a little problem with env variables (sometimes my lambda didn't had env after the deploy), but this is the only issue I had. If you are going to use that in production, and if you plan to have a lot of requests, check the startup time after each call. This is the main point IMHO in serverless computing.
I'd say around 5/12th's of a day.
Credit to /u/jsonathan for inspiring me with his project statcode that was posed a few days ago.
You'd never know 
If you have an antivirus check it hasn't nixed it- kaspersky is particularly fond of doing this in my experience
thanks for sharing.
I think the main reason getter and setter methods are not considered pythonic for an API is because there is a pythonic way of implementing them via properties where they are appropriate. While it is also true that you should directly access an attribute where possible (as there is some small overhead for any function call), getters and setters are obviously useful and totally appropriate in many cases, but should be implemented as properties. If you aren't familiar with properties, properties in python are basically getter/setter function calls disguised as attributes. Getters are called by simply referencing the attribute, and setters are called by assigning to the attribute. As an example of an appropriate use case, if you have multiple attributes which are derived from an original attribute set by the user, it doesn't make sense to write a bunch of convoluted code to keep those properties in "sync". Instead, you can either write a setter method for the original property that updates all of the derived properties when it is set, or you can make getter methods that read the original property and return the derived properties each time they are called. You can choose which depending on your specific priorities and objectives. Doing things this way gives you the power of getter and setter methods, but hides those specifics to make the API more consistent and more pythonic. On the other hand, however, I've also heard properties referred to as a bit "dishonest". I don't necessarily share that view, but it does make it less obvious to someone using your library that they are actually making function calls when they access the property. Whether or not that matters depends on what the library is doing.
I'm unable to understand the layout part. It's really difficult.
At a certain point you have to stop and ask yourself *why* you are using python. If you need strong typing, access modifiers, interfaces, etc. etc. then python is simply the wrong tool for the job. You pick python *because* you need something simple, concise, and flexible. If those aren't the factors driving your project, then python was the wrong choice. Once you start manually adding custom non-standard features the language like "final", or building type-checking frameworks, or coming up with crazy contract schemes for classes, etc. etc. you are just adding complexity at the cost of flexibility without *actually* reaping any of the benefits of a language+syntax actually designed around those concepts and features.
Ok, that explains things. Thanks.
after a night's sleep I answered my own question, and adding the solution here in case anyone has the same problem down the line (the documentation is not too clear on this point). The key is to use DatetimeTickFormatter not axis_type, and to set the format to match the datetime used for the x data, so for the example above, the following works: from bokeh.models import DatetimeTickFormatter xformatter = DatetimeTickFormatter(formats=dict(minutes=['%M %h %a %b %Y'],hours=['%h %a %b %Y'], days=['%a %b %Y'], months=["%b %Y"], years=["%Y"])) plot.xaxis.formatter = xformatter 
iOS isn't really a multitasking OS, so nothing gets in the way.
Working on a program for a statistical procedure. It's the first time I'm writing something with TDD. I've stuck to it and written a test for each piece of functionality first, coded the feature and watched the test pass. Also the first project I've been religiously linting. It's not done and I have a lot of refactoring to do. Writing code that's easily testable doesn't always go well with writing nice code...
There is no memory sharing in NumPy - the Python objects simply wrap a C struct.
I wrote a simple, easy to use password generator! Here's the link to anyone that offer me some constructive criticism : [Password Generator](https://github.com/DeveshChande/Simple-Password-Generator).
I think Javascript with Brython is a great option you should look into. It works amazingly well.
This post is better suited for r/learnpython 
Thanks all, informative posts. 
I have experience only with Android platform: 1. Problem with building 2. Problems with libraries capabilities 3. Problems with community 4. Problems with python3 (Android MacOS) 5. For python2 problems with https requests For windows: 1. Problems with compilation
/r/learnpython is your best bet for this sort of thing. `==` compares by value (uses the __eq__ method) `is` compares by id, tells you two objects are the same object. for integers you need to understand that the interpreter creates singletons of the integer objects when it starts for a small range, and creates ones outside the range on the fly.
You can accomplish indent/dedent regardless of cursor position by using Cmd/Ctrl+] and Cmd/Ctrl+[. This hotkey also works in various other places e.g. some word processors such as Google Docs.
With `is`, you check is they are the same object. With `==`, you check if they have the same value. [docs](https://docs.python.org/3/library/operator.html#operator.is_)
One for every direction of exit, just like the other intersections. The roundabouts themselves don't count as anything, like the middle of an intersection.
Keep env vars in S3 and in zappa config point to that bucket. During deploy &amp; warm up calls Lambda function will read from s3 bucket and set up all the values. This worked for me. 
 &gt;&gt;&gt; a = 1 &gt;&gt;&gt; b = 1 &gt;&gt;&gt; a is b True &gt;&gt;&gt; a = 500 &gt;&gt;&gt; b = 500 &gt;&gt;&gt; a is b False
I like boost-python: https://www.boost.org/doc/libs/1_67_0/libs/python/doc/html/index.html Here's some small example to get you started: https://github.com/michaelgugino/boost-python-test Or you could consider pybind11: https://blog.conan.io/2016/04/12/Extending-python-with-C-or-C++-with-pybind11.html There's also the plain-old python C api, which is quite usable as well.
Thanks for sharing this :)
== is an operator that tests equality. 'is' the keyword in Python is a much more specific test. The two sides can't simply be equal, they must literally be the same object. That's why the c,d = 500, 500 makes c is d true, while the previous example, c and d are equal, but not the same object. 
BS is pretty amazing. I'm currently scraping a number of sites and emailing me when information I'm interested in comes up. I had never done anything like it but it wasn't too bad to figure out how to break down the site in BS and extract info that you want. The real pain is when a site changes and breaks everything. If you can find the actual source of the data that often won't change, there may be a json file, php database connector or other data source behind the website front-end that you can scrape instead of scraping the formatted web page which can change often.
Her is a good resource about what's happening https://stackoverflow.com/questions/132988/is-there-a-difference-between-and-is-in-python
A distinction without a difference? If they'd used the more general term of "settlements", your comment would be moot, because a settlement can be a single building with a farm around it, or a small collection of buildings denoting a small community or town.
I‚Äôll keep this in mind. I think my next project will be to scrape stats for players off of basket-reference whenever I type in a specific name of a player
 return d @ p @ d Woah, never seen the @ symbol used for matrix multiplication. 
lol
correct, 1 is a singleton created at startup. 500 isn't.
Might be because of the influence of the recent hmm meme. You also sounded contemptuous to me. Could be it. 
For those that might be interested in switching or are needing a way to convince Matlab using coworkers to give python a shot - there's a white paper and webinar regarding the subject of swapping from Matlab to Python [https://www.enthought.com/white-paper-matlab-to-python/](https://www.enthought.com/white-paper-matlab-to-python/)
Lol I've actually used that website a lot. Feels really weird in a way. 
Try: webbrowser.open(url + term, new=0)
I think you need to decouple some of these concepts. The application layer (layer7) will see little difference between the technologies. FaaS or Serverless is more or less an opx way to mitigate cost and maintain good "BCDR" etc. If using say Lambda, or other FaaS services this makes sense. There are many integration points etc. If the choice is self-hosted Zappa vs self-hosted Flask you are not gaining anything. The whole idea of Serverless is so you can put the load on others. Running EC2 with Zappa instances could also make sense. Simply put; what do you want to have responsibility over?
Making a self driving bot for need for speed rivals following the "sentdex's python plays gta v" video series he switched from using computer vision to machine learning for the bot after some videos. but my cpu is not so GG for machine learning so i'll continue with computer vision ...
All I see is a login page?
It's a totally different animal than Kivy, but [BeeWare](https://pybee.org/) looks very interesting. 
Interesting. In the python 3.6.4 interpreter, \`c,d=500,500; c is d\` gives True, but in 3.7.0 it is False. Any idea why?
I wonder too, why psycopg2? I'd that even an abbreviation? 
Is there a way to programmatically identify whether a class is final? Like isinstance(obj, Final)?
Some integers get cached, but that's an implementation detail you can't rely on. Try doing the same with really big numbers for example.
This is a really neat project! I'm not sure if you've got the time, but someone recently [asked a question](https://www.reddit.com/r/learnpython/comments/8xw2c2/i_need_help_animating_the_fourier_series_with/) on /r/learnpython that you might be able to help with, since your project seems exactly like their question. If you can't no worries, just seems uniquely applicable. Keep making fun projects! 
Pyqt on mobile is a shit show.
Grasshopper
Works fine with really big numbers. I submitted a python bug, since it seems to be related to python 3.7's handling of tuples of constant literals. This gives False: `a=(500,500,()); a[0] is a[1]` This gives True: `a=(500,500,[]); a[0] is a[1]`
Why would something like this be useful?
I'll take a look at it! 
I listened through a lot of maybe a previous version of this? It was quite enlightening, esp. if you actually open the cpython source files in another window. But it is all Python 2.7, and we are now at **3**.7 with many internal changes -- ordered dicts, async, fstrings and on and on -- which he can't cover.
Obviously he can't cover everything rather than commenting over here get an idea of source from these videos and try to explore python 3.7 yourself that would be a great use of your time..
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
Good to know, thanks!
Just finished up the first part of a project I call [Quorper](https://github.com/dob9601/quorper). It allows for a user to login with their Quora account details and get answers from their feed in the form of dictionaries containing: - Answer author - Answer question (the question the answer is for, yet to be implemented) - Answer body (in the form of HTML as of now) - Answer views - Answer upvotes 
That's rather odd, The behavior I was expecting is what 3.6 does here: &gt;&gt;&gt; a = 500000 &gt;&gt;&gt; b = 500000 &gt;&gt;&gt; a is b False &gt;&gt;&gt; a = 5 &gt;&gt;&gt; b = 5 &gt;&gt;&gt; a is b True Small numbers get cached so they return true, big numbers don't so they return false. Same goes for long/short strings.
It gets weirder: &gt;&gt;&gt; a=(500,500); b=(500,500) &gt;&gt;&gt; a[0] is b[0] True &gt;&gt;&gt; a[0] is b[1] False &gt;&gt;&gt; a[1] is b[0] False &gt;&gt;&gt; a[1] is b[1] True
This
Also wondering about this
I remember seeing this a while back, thank you for sharing again. I love this. 
It seems like equal constants in the same expression get optimized into a single constant. e.g. &gt;&gt;&gt; 50000000 is 50000000 True
Short, sweet, useful walkthrough for pipenv initial setup and basic usage.
Wow, did not realize that Boston and Charlotte were so similar. This is awesome, super fascinating. 
Is there any GUI framework that offers that on mobile and desktop?
That chart is somewhat misleading because all of the programs are compressing one file (although very big). What I was saying is that Zip is both an archive and compressor, but it isn't terribly good at either job. However, if you combine Tar (which is just an archive), and something like 7z / gz / bzip, you get better results. This is because when compressing all files combined, if you have repeating segments across files, Zip will not be able to exploit this, but two-step archiving and compressing will. Also, one should obviously calculate the throughput and compare it to the speed of compression. Typically, compression speed is on an order of magnitude higher than the speed at which you can send the data, so, even though 7z is slower, having to send 2/3 of the data may still be a noticeable win. However, none of this may be relevant if the kind of files you are sending is something like, say, JPEG images... because they use compression which is more aware of the kind of content of the file, so, compressing them again with a general-purpose compressor may even increase their size.
The pg part is for postgres, the 2 is for version 2 of the python db api as defined in [pep-249](https://www.python.org/dev/peps/pep-0249/)
That's just one of the mysteries we will never solve
It is a a mix of python + postgreSQL but I don‚Äôt know how they choose the order
Well, kinda. I think the scope is a call to \`compile\`, which can be an expression, a line in the repl, or a module. It's not just literal constants, either (\`500 is 250+250\` is True, since Python evaluates the addition as part of its optimization). It seems like this optimization is just flat out broken with tuples though. &gt;&gt;&gt; import operator &gt;&gt;&gt; operator.is_(500,500) True &gt;&gt;&gt; operator.is_(*[500,500]) True &gt;&gt;&gt; operator.is_(*(500,500)) False
Fundamentally, people can make up names, not everything has to have meaning. /shrug
True
If \`you want quick and dirty, there is always \`from pylab import \*\`.
You want to first `round()` the number: `round(area(6), 3)`. With `3` being the amount of decimal places. Then, format it: `print("... {}".format(round(aread(6), 3)))`. (Perhaps even better, extract the `round()` and put it in a variable for better readability)
https://pyformat.info/#number_padding function result is just a number, you can pass it to `format` method
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
Thank you! I got it figured out!
Thank you! I got it figured out! 
Why `if it's not for production`?
Thank you! I got it figured out! 
/r/learnpython
http://geoffboeing.com/2018/07/city-street-orientations-world/ (If you had read the article wink wink) Charlotte is worse than Rome!! üòÇü§£üòÇü§£ Actually, I honestly didn't know it could be different.
Agreed.
Python 3.6 worked great on my computer just a few weeks ago. I factory reset my Macbook and just installed a fresh Python 3.7 and got a weird bug where mouse scrolling in either direction resulted in IDLE scrolling only downwards. I didn't think much of it so I just uninstalled and reinstalled again and am now dealing with this crashing issue. I thought maybe it's the new version of Python so I uninstalled it again and installed Python 3.6 and it's still crashing. Hopefully one of you can shed some light on this problem! Thank you!
Also super ironic that Rome, of all places, has disorganized streets. No culture has ever had a bigger reputation for building things in straight lines.
It gives an error and when I change the "find_all" in the loop to "find" or I put an [0] it works but the result is just the first result repeated multiple times, which is not what I want .
This post is better suited for r/learnpython 
This post is better suited for r/learnpython
This post is better suited for r/learnpython
This post is better suited for r/learnpython
This post is better suited for r/learnpython
Thanks!
This post is better suited for r/learnpython
This post is better suited for r/learnpython
Use a virtual environment, or at least `pip install --user`.
This post is better suited for r/learnpython
Aren't most of the people in r/learnpython beginners in python?
--user fixed it, cheers!
Not here to do your homework. Check out graph pathfinding algorithms.
"Sharing memory"? Generally anything that is in Python can not be pushed to the lower level without heavy transpilation. However, Python has a C api, which means C and C++ can be used for extension modules, and therefore Rust, since it mainly just uses an LLVM compiler to go to C, can also be used. But be warned about the object behavior-- behavior in Rust may be different in C, and therefore when Python accesses it it can have an issue. For a language that compiles into C, such as rust, a wrapper would exist when the need comes, and so, [rust cpython was born](https://github.com/dgrunwald/rust-cpython/)
It‚Äôs a simple challenge for people, nobody‚Äôs asking you to ‚Äúdo my homework.‚Äù 
&gt; Prior to implementing the program, present a design to your mentor that describes the algorithm you intend to use to enumerate the keypad paths. &gt; your mentor Please tell me more about how it's not your homework.
My original plan was to use Lambda Apigateway and Cognito to deploy pure API calls (mostly backend integration with other platforms that expose Restful or SOAP, may later on try a few Alexa skills). I came across Zappa and liked it mainly for the packaging and deploy feature (auto deploy apigateway , roll back , other settings like keep warm etc..) But again my impression is Zappa was built to help create serverless flask web apps and it isnt exactly what I need in this case hence Im trying to learn a bit more about advantages of doing this via Zappa vs just stick with Serverless
With this new trigger, do you think this actually makes Lambda cost more? I was previously planning to rely on Cloudwatch and other stuff to ping Lambda and SQS every 5 minutes to get batches of unprocessed SQS messages .. but to move to SQS trigger , will it constantly pump Lambda?
Okay thanks
Flutter
I‚Äôm in a mentor program and we‚Äôve written this challenge for our new hires. Figured someone would enjoy a cool little exercise challenge. Please tell me more about how I‚Äôm asking you to do my homework. 
For such cases it is easy. You have one Loop, which iterates SQRT(x) times in worst case. Your complexity is therefore O(n) = SQRT(n). This condition in the loop doesn't change the complexity, because in a lot of cases(all prime numbers) it will require SQRT(n) iterations. 
Because flask alone is not meant for production. Their web server is a single interpreter. You'll want to use tom cat or apache
This post seems better suited for /r/learnprogramming This isn't really related to Python
Thanks! I‚Äôll post it there instead
oh wow so sorry, for some reason thought I was posting there. had the wrong tab open I guess, My bad
Why?
[This article](https://read.iopipe.com/the-right-way-to-do-serverless-in-python-part-2-63430131239) (part 2, contains a link to part 1) was posted here just a day ago. Why don't you start with those two articles?
This has been posted on the reddit before. I saw it and it is great material. I learned a lot from it, It gave me a better understanding of how Python works and I even used some of the ideas on my work in other languages. I wish there was an updated Python 3 version of this. 
What is `unless` even supposed to mean? `not if`? Cool start but pretty useless.
The object oriented approach is fine. It is more zooming in and out, interactions, data tips, panning. That kind of thing
This is a relatively simple example I wrote for a C++ library that wraps a god-object with the Python C-API, and then wraps the exported C-API Python object with a cleaner Python layer: https://github.com/robbmcleod/pyfastnoisesimd/tree/master/pyfastnoisesimd 
Why not?
Alright fair enough
While this is extremely interesting, I honestly just want to know if this is a mac issue or a python issue-- did you try an external mouse?
Exactly what I thought. Terrible pizza!
Is there any tutorials? I could not find how I can create slide-menu or something like this.
why not make a bot that contextually replies with a ML on the backend to analyze incoming data and serve the bot the response to post. would be entertaining 
I have the comments in json format. I want to post 250 comments with that data. 
yes but hard coding things in isnt any fun, make it dynamic! pretty sure what you're looking for is `with open(fname) as ifile: for hard_coded_message in ifile.readlines(): postComment(hard_coded_message`
Shows an external mouse at the end of the video. 
How does your interpreter handle integer overflow? I ask because my python brainfuck interpreter doesn't at all, which causes various programs written for other interpreters to just not work. https://github.com/djmattyg007/bfinterpreter
It is useless but if it was useful it would have already been in python, people at psf are smart..
Aaaaaand thats what i get for clicking away before the end.
Are there any crash logs for the idle in ~/Library/Logs/DiagnosticReports ?
why don't you break out of the inner loop if the barrier is reached after setting out=True?
I see what you did there. Pretty smooth. ;)
Saved - ya know, for when I have 10 hours
I've found brainfuck to be pretty fun to implement -- I used it to teach myself Rust. Your code is pretty good for a first whack at it, but I bet you think the runtime is tad on the slow side. A few things you can do are multiple passes at it. 1. Parse the raw inputs into symbols. `+` becomes an AddToken, `[` becomes JumpForwardToken, etc. 2. Optimize the symbols by collapsing like ones together, e.g. `+++--` looks like five separate instructions but it's really just `AddToken`, `+++` becomes `AddToken(3)` This saves on having to look up and execute `self.add` multiple times. 3. Look for patterns and remove those: `[-]` will *always* set a value to 0, so just set it to zero and move on. Like wise `[&gt;+&lt;-]` is a move from one register to another, so add the current register to the target and set the original to 0. A more complex example is `[+&gt;+&gt;+&lt;&lt;-]` or `[++++&gt;&gt;-&lt;&lt;]` where you're increasing a series of registers or multiplying a register by another. Being honest, I've only ever implemented the zero out check because I'm lazy. 4. Map the remaining jumps into a dictionary -- you're doing this already, but you have to do this after removing extraneous tokens otherwise you jump into random code. Other things I've found helpful: `+` and `-` are complimentary actions, so are `&gt;` and `&lt;` and they can be represented by a single token each. `+`/`-` become `Incr(int)` and `&gt;`/`&lt;` become `Move(int)` where the sign on Move dictates if it's a left or right movement. If you're curious what my interpreters look like [here they are](https://github.com/justanr/rustfuck) there's a couple of rust ones of varying quality (`bf3.rs` is the most performant -- even with the extra overhead of tracing executions) and `bf.py` was when I realized I didn't know my ass from a hole in the ground when it came to writing interpreters, it includes bonus uint8 overflow handling (but only mostly right)
You can just modulo the new integer before storing it. e.g if you're working with uint8 cells, you'd run `self.memory[memptr] = (self.memory[memptr] + value) % 255`
This is bad and you should feel bad. 
"Writing code that's easily testable doesn't always go well with writing nice code" Would you mind elaborating on this? I'm starting to work on writing tests for my code and I'd like to better understand why testable code might conflict with "nice" code. 
A little project that scrapes all the IETF rfc's and writes them to a database. They can then be searched and read using a 'less' pager. 
What's strange? It just looks like in the second case they're printed in scientific notation. Did I miss something else that's different?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython or for the r/Python discord: https://discord.gg/3Abzge7. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community and the r/Python discord are actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. **No matter what level of question you have, if you are looking for help with Python, you should get good answers**. Make sure to check out the rules for both places. Warm regards, and best of luck with your Pythoneering!
What you mean? ASCII text arts are already string? 
Good advice. Numbers 2 and 3 are what compiler guys call "peephole optimization." Inasmuch as there's very few actual brainfuck programs out there, there are also not very many idiomatic patterns you could expect to find and optimize, but there are a few.
Sorry. my goal is to decode ASCII text captcha. Is there any possible approach that I can try ?
Interesting, I have this issue. This is personally what I have come about to. I like to take a little time before writing code. This is the trick (for me) rather than just oh I need this functionality and begin writing which is what I was doing. What you do during that time is up to you. * write comments out in whatever way you see fit outlining what you need how you will acheive it, where you might place it and how it might interact with the rest of the code base. * if applicable write functions with arguments and pass rather than writing many lines right away. * plan out multiple ways of doing it if necessary and sometimes the act of doing this clarifies your intention and a clear winner in terms of implementation arises on it's own. * choose an implementation and write it and then do an optimization pass. It's instinctually difficult for me because I'm always wanting to focus on the goal and getting to three or four steps down the road by the end of the day and being productive. However I think as we all know the time is takes to refactor and refactor until you have it how you want it is inefficient in a way that is least equal or worse than taking the time to contemplate. This doesn't eliminate refactoring for me but it does cut it down. I tend to write code once more often than not. But the progress seems to slow slightly but in the end if you add it all up I think it's negligable.
stop with the gifs. it's not facebook or instagram. 
Working on implementing dask-jobqueue for LSF https://github.com/dask/dask-jobqueue/pull/78 and i'm almost there
There's a few that I used for bench marking. https://github.com/justanr/rustfuck/blob/master/bfprogs/ZtoA.bf https://github.com/justanr/rustfuck/blob/master/bfprogs/mandel.bf They both take for ever to run on my python interpreter, but the rust one is reasonably quick. I think about twenty seconds on the mandelbrot when it's compiled on release mode and a few microseconds on the reverse alphabet. I included traces, outputs, ast and raw translations of the mandelbrot in the repo too. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [justanr/rustfuck/.../**ZtoA.bf** (master ‚Üí 2d6ea3f)](https://github.com/justanr/rustfuck/blob/2d6ea3ff0df3dfa9eae240416f1e33adf4c49bbb/bfprogs/ZtoA.bf) * [justanr/rustfuck/.../**mandel.bf** (master ‚Üí 2d6ea3f)](https://github.com/justanr/rustfuck/blob/2d6ea3ff0df3dfa9eae240416f1e33adf4c49bbb/bfprogs/mandel.bf) ---- 
[https://github.com/kivy/kivy/wiki/List-of-Kivy-Projects](https://github.com/kivy/kivy/wiki/List-of-Kivy-Projects)
Proof that Python 3 is Turing complete after all!
Same
Honestly, i don‚Äôt know if i have ever used idle. Whats wrong with the terminal repl? If you want an IDE with some muscle use Pycharm. 
It's a long video and i can't use the audio. Can anyone tell me how it works (if it's simple enough).
I mean, it literally says right there that you‚Äôre using an unstable version of Tcl/Tk and to visit https://www.python.org/download/mac/tcltk/. It has several bugs there listed under that version for input. Not to sound crass, but it might be a good idea to either using the command line or get a real IDE such as PyCharm. I used IDLE when I was starting out, but once I moved away from it, my efficiency and proficiency skyrocketed. 
:( I like pizza hut.
I prefer selenium, but hear BS is better. Should I give it a go?
Cool. Is there any reason this is posted? Because it doesn't really contribute to the discussion. This PEP has people at arms from both sides and making this post after the whole thing is done and over with the only minor change being the SyntaxError becomes a specific subclass of SyntaxError, and this title doesn't reference changes at all-- just the acceptance which happened relatively ages ago, is like pouring gasoline on the fire of the argument which is already settling down.
Not strange, just scientific notation. From [`np.set_printoptions`](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.set_printoptions.html), &gt; suppress : bool, optional &gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;If True, always print floating point numbers using fixed point notation, in which case numbers equal to zero in the current precision will print as zero. If False, then scientific notation is used when absolute value of the smallest number is &lt; 1e-4 or the ratio of the maximum absolute value to the minimum is &gt; 1e3. The default is False. The data is still stored in the same manner with the same level of information. It just so happens that the description above sometimes occurs. And yes I hate this too at times because of floating point precision causing things like 1.00000000000000000001 which forces things to be shown in that form. But I find it more useful on than off.
All due respect, does he actually have shitty views or does he just have different views than you?
save the graph (using I think `.savefig()` method) and then open it in putty (you may have to set the file type to match a program on your computer) or drag it locally and open it that way. I don't think mathplotlib has any terminal rendering capabilities. 
Sql injection vulnerability just fyi
I recently keep hearing the use of Boost-- is this some new fangled thing or not, and if not why is is seemingly suddenly popular instead of just writing the simple Python C API/Cython boiler plate?
Haven‚Äôt messed with selenium so I couldn‚Äôt give you an opinion, but I might have to check that out. If I do, I‚Äôll let you know which I like better. But I‚Äôve heard great things about BS.
/thread
I'm surprised they gave this to a sole intern.
I didn't orriginally like this and I'm still not convinced. Arguments about how ugly and unreadable it could make code no longer sway me, as many people have pointed out you can already write ugly unreadable code but there's a strong culture and community about readability. For example this is perfectly valid code in Python 3.6: _0_:0_0=0o0 And now the idea of assignment expressions have been floating around in my head I find myself wanting to replace little bits of code like: for line in file: if line == 'END DATA\n': break # code logic With: while (line := file.readline()) and line != 'END DATA\n': # code logic It puts the logic of the control flow in the line that defines the control flow and let's you immediately start the code logic. That said I'm still not sold on the idea of having to teach a new concept to begining Python programmers, and something that could be a real gotcha if used incorrectly and only adds a little. Because I've been writing Python for a bit I tend to start think it's all simple, but when I put a small script infront of someone who's never wrote Python I realize quickly how much I need to explain. But the decision is made so I look forward to Python 3.8 and whatever it brings!
Agreed, but its been assigned and I'm looking to get any help I can get.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
I'm not sure what it contributes to Reddit but the linked post is Guido officially accepting it, until now it was only officially in draft form. So it's a fairly irreversible step in the process.
We already knew Guido accepted/was guaranteed to accept this 1.5 weeks ago. The actual changing the status of the proposal from draft/proposal to accepted is redundant and gives us no new information.
6 months should be enough time to get it done. Have you got the e-book "Test Drive Development with Python"? It's free now. A lot of what you'll need can be covered in that book. It should take you 2-3 weeks full time to do the entire book. After then, you can easily spin up the website and incorporate their requirements.
I don't understand the whole "teaching beginners" argument. Beginners aren't taught a *lot* of Python notation, notably things like bit shifting, the nonlocal keyword, and more. If the issue is "it's one more thing to learn", then you can say that about anything and no new features would ever be added. If the issue is "it's one more cause of confusion for beginners", then tell beginners it is a more advanced feature.
Sounds like you need to add an index to the table composing of 3 fields which reduce to that particular value. 
Thank you, I do not have the book. I see it is free to read online, is that what you were referring to ([http://www.obeythetestinggoat.com/pages/book.html#toc](http://www.obeythetestinggoat.com/pages/book.html#toc))?
Really tired of this as well. Is quite annoying see this ‚Äòbuzfeed‚Äô trend everywhere 
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
farm the work out to someone in India and enjoy the paid vacation!
Maybe? Give me terms to google and I'll read up on it. The main problem I'm encountering with self-learning is I don't even know the right terms to google most of the time.
You'll need to enable X window forwarding. Step 1) You'll need to download an X Window server. VcXsrv is what I use for this. It basically sits on your computer, and listens for inbound connections that are set to display graphics. Step 2) Configure your Putty connection for X forwarding. I don't know how to do this as I use SSH through a terminal to connect to ec2 instances, but it's probably possible. Step 3) You might need to install some libraries on the ec2 instance. Not sure. Depends what it comes with. I know that isn't a whole lot of detail in the instructions, but maybe its enough to get you started. 
How did you go about doing this?
I used to do that. I learned doing TDD took me from: * 10 hours dev, 50 hours troubleshooting and rewriting code to * 20 hours dev, 1 hour troubleshooting and rewriting code Go and learn TDD and SOLID, you'll become a MUCH better programmer.
No worries, I said the same thing to myself when it happend! lol
You should definitely evaluate industry proven Django, Django Rest Framework with swagger. Your consumers of apis will thank you.
I usually use ST but I had just fresh installed python again so I went to see if it was working. So I opened IDLE and moused over to the window and scrolled up to close it down and it instantly vanished and I thought 'wow that was fucking strange, what just happened'. That's why I opened it back up to test it and found the bug! lol
I don't think so. None of the file have idle in the name but some have pretty weird names so idk lol
IDLE is good for light editing and for beginners to learn to code in python. Without any help on the autocompletion.
Hmm. This is some non trivial stuff, I hope they're at least paying you well to do something they should by all rights pay a professional consultant to do. I also hope they're not just trying to get cheap labor out of you. In my experience internships are more about an extended learning process for both you and the company, solid deliverables are always secondary to the learning experience for the intern. Especially considering you are the only person who does software there, sounds real iffy to me. That being said, if you're happy with they pay, it could be a great learning opportunity for you. But were it me, I'd look at this "internship" as purely transactional, "What can I learn, while getting paid, and how will that prepare me to work for a company that actually gives a fuck for decent software developers"
You actually see this a lot in c. e.g. while (c= getchar() != EOF) { /* do something */
Django + django rest framework + django rest auth for your backend. For your frontend React is pretty awesome if you need a very powerful dynamic webapp. Django has some packages to play nice with React. React also let's you easily package up a mobile app. If you need a simpler frontend the django and it's templating engine will be more than enough. 
‚ÄúHmm‚Äù is often used in a sarcastic way. In your original comment, it gave the impression that you felt that the professor being in ‚Äúcognitive science‚Äù somehow meant that they were unqualified to be making these lectures. For what it‚Äôs worth, Philip Guo is exceptionally well-known in CS academia. His statement of purpose is the go-to reference for PhD applications, his papers are widely cited, and he‚Äôs involved in CS in practically every subfield. Check out his Twitter [@pgbovine](https://www.twitter.com/pgbovine). I see him interact with one of my former professors, John Regehr (well-known in compilers and operating systems) pretty regularly.
I'm more curious just because of this weird behaviour. I have ST to work with.
They better be paying you for this. Holy hell. You need to start looking for and applying for jobs asap. 
This question comes up again and again in many similar shapes. I think, this is because there isn't really a good solution, if you are looking for a single installer / distribution that can accomplish all you want. I would look into `setuptools`, specifically, into commands like `bdist_wheel`, `bdist_rpm`, `bdist_msi`. You will probably have to extend them, especially because you want to also install third-party packages, but, this would be my approach to the problem.
Sounds like you need to create a real database. A dictionary isn't a database.
Be as realistic as you can. Write down your requirements, draw up some mock ups, get some feedback before you code too much. Be as transparent as possible. These sorts of things tend towards scope creep if you're not careful where, at the end of the project, no one's quite happy. Set some milestones for every week or every two weeks over the six months to personally gauge your progress. If you're falling behind, say something. If you're ahead, say something. Make sure you do the bare requirements before doing any of the extra fluffy stuff. This sounds like a pretty difficult project for an intern; however, it's going to be an incredible learning opportunity! Take your time and make sure to budget some time for re-writing. One last piece of advice: commit to having the project in 6 months; however, personally budget having something 90% there by 5 months to give yourself room to polish and buy fix. Good luck and have fun!
Sound hard, but possible. I would take this opportunity to get the experience and polish my methods. As a single developer and not experienced, you should have solid methodology of _how_ you going to do it, before (at least as soon) you start coding. My advice, do it in (very) small steps, make sure you add small feature every day or two, with a good test suite you can run on each commit. And for last, UI (AKA front-end) can drain your time and energy. Try to seperate it from your main work process.
It does have a method call. It calls `__len__()`. See [the documentation](https://docs.python.org/3/reference/datamodel.html#object.__len__). Unless you mean "why is `len()` a standalone function instead of every class implementing a public `.len()` method", and the answer is: because. It's been that way forever. Some people hate it with the fury of a thousand burning suns; some people like it for not cluttering the public namespace of classes that want the behavior; some people just don't care one way or another. Also, `abs()` turns into a method call, too. It calls `__abs__()`. Again, [see the documentation](https://docs.python.org/3/reference/datamodel.html#object.__abs__).
This is much harder to do than it initially appears as the majority of captchers are designed to minimize the ability of text recognition algorithims. You could try using a python text recognition library such as tesseract ocr if the text is fairly clears to read.
https://docs.python.org/3.7/c-api/capsule.html this is the simplest way by far: just store the pointer to your object in the "capsule". Obviously, simplicity comes at a price: all this gives you is a way for Python to hold on to your memory and, eventually feed it back to your C++ / Rust library. You can also implement custom Python types in your extension: https://docs.python.org/3/extending/newtypes.html but doing this by hand is... well, tedious and very error-prone, so, you might be better off using Cython or SWIG, or boost-python or Rust CPython etc. as has been suggested earlier.
This ... 
There's no argument against that-- it happens in a lot of languages. Python is one of the few where normal assignment doesn't return the assigned value.
!RemindMe 2days
I will be messaging you on [**2018-07-14 06:14:52 UTC**](http://www.wolframalpha.com/input/?i=2018-07-14 06:14:52 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/8y5s4x/drawing_a_binary_tree_nicely_using_networkx/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/8y5s4x/drawing_a_binary_tree_nicely_using_networkx/]%0A%0ARemindMe! 2days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Ah, I think I get it. Len isn't called as a method, because it will automatically be called to the dunder method every time unless actually defined in your own custom-type class? I'm referring to a sentence such as this: "len is not called as a method because it gets special treatment as part of the Python data model, just like abs. But thanks to the special method \_\_len\_\_, you can also make len work with your own custom objects." 
Sorry for causing the misunderstanding, im not trying to read text from an image. But instead, the text art (see below) forms a captcha. The difference is that instead that they are available/shown in .jpeg or any image file type, they are actually a bunch of ASCII characters that forms as a CAPTCHA texts Example of ASCII text art are as below (note, this is just an image as example, in real case they are actually characters/text):
Pretty much. If you're familiar with operator overloading, that's what's going on here. You can implement methods with `__dunder_names__` on your own classes in order to provide behavior for Python's operators and some built-in functions like `len()`. The documentation I linked gives you the full list of stuff you're allowed to implement in Python classes to achieve this.
[The author talks about it in pycon (30 mins)](https://www.youtube.com/watch?v=qaPzlIJ57dk)
If you enable the Do Not Track option of your browser, Medium won‚Äôt load them. 
The 2 represents a full rewrite of psycopg. The 1.x codeline was also written for DBAPI 2.
According to the readme in the 1.0 release, psycopg "was written from scratch with the aim of, being very small and fast, and stable as a rock." I believe psyco is a reference to https://en.m.wikipedia.org/wiki/Psyco. The "pg" refers to Postgresl and 2 is the major version number.
**Psyco** Psyco is a specializing just-in-time compiler for Python originally developed by Armin Rigo and further maintained and developed by Christian Tismer. Psyco runs on BSD-derived operating systems, Linux, Mac OS X and Microsoft Windows using 32-bit Intel-compatible processors. Psyco is written in C and generates only x86-based code. A follow-up project to Psyco is PyPy, which incorporates an interpreter and a compiler that can generate C, improving its cross-platform compatibility over Psyco. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I made something years ago that might be useful. https://github.com/derricw/asciisciit You can render the text to an image like this: &gt;&gt;&gt; from asciisciit.conversions import ascii_to_pil &gt;&gt;&gt; pil_img = ascii_to_pil("your text goes here") &gt;&gt;&gt; pil_img.save("render.png") Then you can use an OCR library like https://github.com/madmaze/pytesseract to extract the letters from the image. 
Selenium and BS are quite different, selenium isn't really a scraper its a test kit which can be used for browser automation, where as BS is a pure scraper and html searcher
You should look into graphviz, you could generate the dot code yourself or try one of the graphviz python libraries.
Without wanting to just regurgitate stackoverflow links, this likely answers your question: https://stackoverflow.com/a/11484144. By default most graph libraries use force-directed layouts, which isn't suitable for tree structures! TL;DR is: use directed graph, use graphviz_layout to calculate node positions, pass those positions to nx.draw. If that doesn't work you could write your own method to calculate the coordinates of each node given its location in the tree, but try graphviz first!
You're spamming this all over reddit and have been for weeks -- your submission history is lousy with it.
This
Why not write out the data for the plot, Scott it and run mathplotlib locally to generate the image?
&gt;import webbrowser &gt; &gt;url = 'http://google.com/?#q=' &gt; &gt;term = "google" &gt; &gt;webbrowser.open(url+term) Its still opening in different tab every time I run it.
Hello! I'm a bot! It looks to me like your post might be better suited for r/learnpython, a sub geared towards questions and learning more about python. That said, I am a bot and it is hard to tell. I highly recommend posting your question there. Please follow the subs rules and guidelines when you do post there, it'll help you get better answers faster. Show /r/learnpython the code you have tried and describe where you are stuck. [Be sure to format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) and include which version of python and what OS you are using. *** ^(this bot is written and managed by /u/IAmKindOfCreative) ^(This bot is currently under development and experiencing changes to improve its usefulness)
I second this, I think this is the easiest option. If you save the figure on the server and download the image then it won‚Äôt be an interactive plot. If you download the data, then you can interact with the plot and quickly replot it if you want to change your visualisation. The other option of setting up remote x-server seems like overkill and unnecessarily complicated if you have not done it before.
Silly question. I don't have any user inputs. How can there be any sql injections here
Can somebody tell me why am I getting downvoted so much? I don't know what I did wrong
False. [https://www.youtube.com/watch?v=p33CVV29OG8](https://www.youtube.com/watch?v=p33CVV29OG8)
He explains the process here, worth a read: [https://www.reddit.com/r/FormerPizzaHuts/comments/8y0kfi/i\_wrote\_a\_program\_that\_finds\_images\_of\_former/e272x38](https://www.reddit.com/r/FormerPizzaHuts/comments/8y0kfi/i_wrote_a_program_that_finds_images_of_former/e272x38)
I honestly don't know what's more surprising, that someone went to so much trouble to solve a meaningless problem, or that there is a subreddit for exactly what that problem solves.
I'll keep that in mind, thanks.
PuTTY has a checkbox to enable forwarding in the connection settings. You can also use MobaXterm which contains an X server so VcXsrv is not needed. OP: Using X11 forwarding will only work if your remote server has graphics libraries installed. Otherwise matplotlib will not be able to open a window. Try to open a simple program like xterm, gedit or something to verify that remote X is actually working if matplotlib still does not work
so you're saying that PEP official status is redundant and we can all just relate to discussion threads here and there? 
Is it painful because in the sense how do i package it or is it frustrating in the sense of getting it working on others computers? I don't really know any C and have now compiled an extension with cpython &amp; gcc. I sent it to a friend and it seemed to work there. Can i expect it to work on anyone's computer or do i need -- i have heard -- to compile it on an old linux version, to have it working automatically on everyone's computer? They obviously need to have the same architecture but is there something else i need to be thinking about? Please don't talk about why am i compiling.
It feels more like a learnpython post than a python post.
The rules suggested learnpython if it was a question. I was confused too since this wasn't a question, I guess I should post to learnpython itself. Thanks :)
Oooh. But flask can still definitely be used on a production server. You just shouldn't deploy it using the development server that comes with flask.
The issue we are facing is to bundle known, tested versions of Python packages, possibly with binary dependencies (e.g. BLAS or SSL libraries) that can be installed on client computers, running a variety of operating systems. 
Thanks for your reply. I think going the Anaconda (Miniconda) route might be relevant for us, as well as possibly using Anaconda Enterprise.
I watched it. But toga has few widgets and elements, that would work on android (mostly linux and ios). For example slider and scroll-list don't work on android. You can use [VOC](https://pybee.org/project/projects/bridges/voc) and use native java-widgets. But you need to know java and mobile development on java.
Good bot
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://pybee.org/project/projects/bridges/voc) - Previous text "VOC" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
ELI5 please
About to go to bed, but check out igraph‚Äôs tree layout. If I have time tomorrow I‚Äôll try to update this comment.
Employer: so why should I hire you? What makes you stand out from the other candidates? PyFuck creator: well I have this nifty little project up on GitHub, Google search 'pyfuck' Employer: I think I've seen enough
There sure is! If you're using Python 3, try: ``` import codecs ``` ``` ... ``` ``` df['colname'] = df['colname'].apply(lambda x: codecs.apply(x, 'rot-13')) ``` `apply` lets you run a function on each value in a Pandas series. `lambda x: codecs.apply(x, 'rot-13')` is a lambda function which will apply rot-13 to whatever gets passed in -- we need to use a lambda rather than passing in `codecs.apply` directly, as `codecs.apply` requires a second argument too specify the encoding we wish to us.
That's some sweet code! However, this won't work with a lot of BF programs ("a lot", as if there are many anyway :P), because you use integer input as opposed to character input. Congrats on finishing it, too. I started writing one in C, but it doesn't work so I still need to make add all the debug functionality to find out what's wrong :|
Thanks a lot. I will test it out
Hey, it seems like pip install asciisciit isnt working hmm
You probably meant `% 256`.
If you have programmed in Python long enough, for sure you have struggled with exceptions. Something goes wrong, your data disappears, your devices become unresponsive. Learn how to (and not to) handle exceptions with Python. Also, how to raise your custom exceptions and some useful patterns when you are developing packages.
I am not sure I understand the question? It sounds like you *really* need to take some tutorials if you don't understand something as basic as defining and using functions. Try googling "defining functions python" and read through some of the results.
This is a great opportunity for you and there are multiple directions you can go with it. 1. Position yourself project manager by convincing the management that they need a small team of devs to build this and maintain this long term. At the very minimum you will have to hire a frontender with some design skills (or optionally both a frontender and a designer) and a backender with some devops skills. 2. Make sure the data model is done right. This is critical. Alternatively do it all yourself and work your ass off. You'll be working 12-14 hours a day for the next few months, but you will get it done. And you'll become indispensable for the organization, if you make sure your efforts are visible. Or just outsource and ~~chill~~ (easier said than done, managing a remote project can be hard).
This is by far the best solution, IMO. The setup shouldn't take long and is far less fiddly than scp-ing images/data files over. 
Strongly disagree, static typing (strong typing is not static typing) in Python has been on Guido's mind for a over a decade. It's disingenuous to claim static typing isn't Pythonic. Furthermore, and more fundamentally, I hate it when people put down others for experimenting with pushing the boundaries of the language. You might say attrs is too implicit or gets too complicated. But dataclasses likely wouldn't exist as it is today if it weren't for attrs. Same with async. Async is harder to think about, and it was originally built on coroutines. But now we asyncio and a thriving async community. So please stop gate keeping on how to use Python's flexibility. 
good spot, it's fixed now - thanks a lot!!
You need a style, but it takes time to develop. When I have data like this, I use a lost comprehension. When it's too complicated, I don't. My line.split() will be named sline. I capitalize like this. I write a docstring for numpydoc because default sphinx is cryptic. You still gotta refactor to simplify code, add more cases, generalize variable names, and add tests but not all that much.
That 30K limit bothers me. Couldn't you instead set a constant `MAX_CELLS`, and then increase the array by 1 every time the data pointer goes outside the array to the right, and stop if it goes above `MAX_CELLS`? Seems cleaner in that it doesn't waste lots of unused cells, and at the same time more flexible.
Thanks The articles do help I guess part of me is still wondering : is it worth learning Flask with Zappa or just stay serverless.. why bring in flask / another layer of complexity ontop of what I already know (python and serverless) Having said that , I think i will pass on zappa
1. It can be challenging to setup the build system, but in our experience, so is it for other alternatives, because these targets move fast and require quite a lot of supporting tools and code, once you got it working though, it should be smooth sailing. 2. All pure python libraries (depending only on stdlib) should work out of the box, other things will require a recipe, most recipes are simple to do, but it depends a lot on what you need. 3. Not sure what to say there, we try to be welcoming, but we certainly are not as big a community as other frameworks, and you may not get answers very fast, it depends a lot on where you ask. 4. our new release should really simplify it for osx, (and windows), things can still be improved for Android though. 5. don't you mean python3? in python2 there shouldn't be any issue, on python3/android you need to use a specific version and it can be bothersome, but it should be resolved soon. 6. for windows compilation, there is now a wheel for all supported python versions on windows (2.7, 3.5-3.7), if you are talking about compiling for android from windows, multiple users have reported success with WSL on windows 10, we just need to include that in the documentation.
What game is it? What tech did you use?
You have to reexamine your CS knowledge.
Says AttributeError: module 'codecs' has no attribute 'apply' Is there anything I can do? I'm using python 3.7
Derp, sorry!!! I meant `codecs.encode`, not `codecs.apply` :) 
Thanks for the fast response. Works like a charm
The same old problems: binary compatibility between extensions compiled on different platforms, with different compilers. CPython in its recent history changed compiler version it compiled the interpreter four times (on MS Windows). This means that if you want to support different versions of Python interpreter you need to compiler four different wheels for MS Windows alone. But then the interpreter can be 64-bit or 32-bit, and now you have eight versions. But there's also Anaconda, which compiles extensions with MinGW. They are smarter than CPython in that sense they try to compile binary extensions on MS Windows rather than downloading binary wheels. But, still, you can run into problems with different versions of MS C runtime DLL... Not to mention a bunch of ifdefs you need to scatter around your code to make sure it works on multiple platforms. Add to this some "intriguing" details such as "how do you distribute DLLs that aren't essentially part of my project, but the project depends on". Again, on something like Linux, you can just tell people they need to apt-get / dnf / pacman / emerge whatever library you need, and all will be honky-dory, but on MS Windows?.. to make the experience somewhat tolerable, you'd probably want to bundle the DLLs with your application. Oh, and now you also want to build all of this in CI, and keep track of bugs that crop in in different versions... Remember, there's also that part where you need to produce MS Windows builds in CI? Lots of fun.
Semi related, has anybody played around with azure ml workbench? What do ye think of it? 
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
I recommend looking at the "conda" package management tools (used by the Anaconda python distribution). You can build your own "distribution" using miniconda, if you need. The Anaconda web-site will let you upload your packages (including dependencies) such that users can "conda install" from there.
Hm, that's bad for the company : the task is hard but do-able, yet it will certainly fall apart when you will leave. 
You're right. Mixed up the modulo and bitmask values. It's `x % 256` or `x &amp; 255`
The spec for brainfuck specifies an unlimited tape, since it's a literal reading of what makes a Turing machine. But in practice, everyone assumes it's a 30k length array of either uint8 or uint32. 
 red = request.form.get('red') green = request.form.get('green') blue = request.form.get('blue')
You joke, but my rust brainfuck interpreter caught one company's eyes (for some reason, it's fairly hideous). They are out of state for me though and I have no desire to move or remote (at least right now). 
Here's the word from the BDFL himself: http://effbot.org/pyfaq/why-does-python-use-methods-for-some-functionality-e-g-list-index-but-functions-for-other-e-g-len-list.htm 
I'd never heard of SOLID but I love it, thanks!
Doing some Django stuff
I have been struggling with this the last couple of days. I have been using Homebrew to install and keep python 3.6.x updated. The after an upgrade Python was upgraded to version 3.7 and despite the option to switch to version 3.6.5\_1 pipenv refuses to use the activated Python and sticks to the 3.7 version resulting in pipenv errors. There is no easy (correct) way to downgrade to version 3.6.5\_1 without risking to break my Python setup any further... So my current setup (until Python 3.7 is more widely used with updated packages (like psycopg2-binary that currently doesn't work on Mac with Python 3.7)), will be Pycharm -&gt; pipenv -&gt; docker-compose and then do my dev via docker. Perhaps I should move my dev setup to be inside a vm...
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 80.0% out of the 5 submissions from /u/wizonimo appear to be for Udemy affiliate links. Don't let spam take over Reddit! Throw it out! *Bee bop*
Didn't know that the Anaconda website let you upload your packages, thx for the tip
Yeah I was joking, I'm sure any employer would hire you at the drop of a hat with skills like that
More to 'most required' libraries for data Science For 'best' in visualization I must suggest the excellent [Altair](https://altair-viz.github.io/), way better in every sense to matplotlib
All those are post variables. User can't enter his own variables in them if I am not wrong. Sorry I am still confused
&gt; except abs it doesn't have a method call. It instead reads from a C struct array but I'm wondering how is that not a method call? &gt; [..] &gt; I'm referring to a sentence such as this: "len is not called as a method because it gets special treatment as part of the Python data model, just like abs. But thanks to the special method __len__, you can also make len work with your own custom objects." OK, this refers to a very low level detail that could only be understood with a low level explanation. On the C level, python classes are instances of a same large structure containing various pointers to C functions. https://github.com/python/cpython/blob/master/Include/object.h#L346 Python objects begin with a same small structure containing a reference counter (for memory management) and a pointer to the class structure, everything else (including instance dictionary) is optional. https://github.com/python/cpython/blob/master/Include/object.h#L106 When you call `str(obj)`, the str function (written in C) gets the `obj-&gt;ob_type-&gt;tp_str` pointer to a C function and calls it, passing obj as the parameter. That function should knows the actual layout of the instance structure and how to compute the string representation. `len` works the same except it goes through the optional `ob_type-&gt;tp_as_sequence` substructure which contains the `sq_length` pointer. Oh, and if the class doesn't have that pointer, those functions go up the class hierarchy (`ob_type-&gt;tp_mro`) and repeat. So this is pretty simple and straightforward (in my opinion) and the much more interesting question is what is an _ordinary_ method call? First of all, a method call = attribute lookup + ordinary function call, all interesting stuff happens in the attribute lookup, `a.x()` is always equivalent to `_tmp = a.x; _tmp()`. Second, attribute lookup just goes and calls `obj-&gt;ob_type-&gt;tp_getattro(obj, name)`. That's a C function that does all the heavy lifting and for usual objects it points to the predefined PyObject_GenericGetAttr. It tries to find the attribute in the class hierarchy, if found and it's a data descriptor (implements `__set__`) then it takes precedence and is returned (so we can have @property), else it checks the instance dictionary (if present), if found there then it is returned, else the class attribute (if was found) is returned, else `AttributeError` is raised. All that works with ordinary Python objects, not raw C pointers of course. Oh, and methods are actually non-data descriptors, so they can be shadowed by instance attributes (`obj.f = lamda: 10`) but when they are found in the class hierarchy, their `__get__(obj)` method is called and it returns a copy of the function object with the instance bound to the first parameter. Oh, and guess what happens when you implement `__len__` in your class? Your Python function is stored in the class's dictionary, under '__len__', while in the class objects's `sq_length` slot is stored a pointer to the special C function that gets your Python function from `class.__dict__['__len__']` and returns a copy bound to the instance. I believe this process is called "Anal Touring", in honor of the father of computer programming! --------- Python is actually an extremely complicated language under the hood.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [python/cpython/.../**object.h#L106** (master ‚Üí 9e9b2c3)](https://github.com/python/cpython/blob/9e9b2c32a34594e901b5b9a03c561a2a2bf63ece/Include/object.h#L106) * [python/cpython/.../**object.h#L346** (master ‚Üí 9e9b2c3)](https://github.com/python/cpython/blob/9e9b2c32a34594e901b5b9a03c561a2a2bf63ece/Include/object.h#L346) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e29272e.)
love it @ http://www.naijaonly.com
I was more thinking of a beginner looking up example simple python scripts. Things like bit shiftinf and nonlocal keyword don't really appear that commonly. But core syntax like, assignment, basic data structures, list comprehensions, yield keyword, classes, functions, etc. are everywhere so it's something you must explain. In 10 years assignment expressions will also be everywhere.
I'm having American Pie flashbacks.
Thanks, bot!
&gt; In computer science a fundamental law is that if I have one Turing Machine I can build any other Turing Machine. If I have COBOL then I can bootstrap a compiler for FORTRAN (as disgusting as that might be). If I have FORTH, then I can build an interpreter for Ruby. This also applies to bytecodes for CPUs. If I have a Turing Complete bytecode then I can create a compiler for any language. The rule then can be extended even further to say that if I cannot create another Turing Machine in your language, then your language cannot be Turing Complete. If I can't use your language to write a compiler or interpreter for any other language then your language is not Turing Complete. &gt; Currently you cannot run Python 2 inside the Python 3 virtual machine. Since I cannot, that means Python 3 is not Turing Complete and should not be used by anyone. it's a quote from the author of [learn python the hard way](https://learnpythonthehardway.org/book/nopython3.html), who said he stated it as a joke referencing how the python project stated that it is impossible to support python 2, meaning that they broke python 3 making it not turing complete. &gt;In the previous version I trolled people by pointing out that, if what the Python project says is true and it would have been "impossible" to support Python 2, then they broke it and Python 3 is not turing complete. Obviously Python 3 is turing complete, but Python project members frequently claim something this basic is "impossible" soooooooooooo alright. I even had a note after the gag saying it was a gag, but everyone is too stupid to read that note even when they do elaborate responses to my writing. Even more telling was when people said this was stupid, I'd feign ignorance further and ask, "Wait, so why doesn't Python 3 support Python 2 then?" This then sent them down a logic loop death spiral of simultaneously trying to defend the design decision and also state that Python 3 is fully capable. It was pretty funny to watch, but after a while I guess I have to straighten this out and simplify it so here you go. 
elif is the alternative code that is run if the "if" condition is not met. however, unlike an "else", elif also has a condition
It is literally like this: It gets two random ints from 0 to 10 Then it gets the signal for the operation, based on another random int If it‚Äôs 0, it makes a addition If it‚Äôs 1, it makes a subtraction I made it wait a random time between 1.5 to 3 seconds to give a little suspense Just that. Made it to my 6 year old sister as a little gift I‚Äôve started programming with python this week, so even though it‚Äôs not amazing I‚Äôm happy it works 
PyQt is really good.
Unfortunately she's getting the opposite feedback in the blog comments: &gt; A little feedback from my side, your gifs are awesome :D 
So your point is you may have to go and grab some other data in some kind of permanent storage that will be IO bound and you're already async ... so why not? Fine.
Why would you think that? [That's extremely basic to do](https://i.imgur.com/kTfoegL.png) I mean, what you see in the picture is over kill. You're literally just using hidden inputs for the values. All you'd have to do is just [edit the value field](https://i.imgur.com/FutQOBy.png)
No. I'm saying being told "okay guys, it has been accepted", twice, is redundant.
TL;DR, if you can avoid MS windows, good for you xd Thanks for the reminder of why you only want to support MS windows if you really need to.
[PySide2](https://wiki.qt.io/Qt_for_Python)
You can always do it in the browser with Flask.
In the website you linked there was a way to what you‚Äôre looking for via a lib called infrapix. I would love ok at that, and if you want to roll your own, use it as a jumping off point. You‚Äôll likely need numpy and an imaging lib such as pillow or OpenImageIO. 
I wish simple exception-handling was taught earlier in programming curriculum. It's such a useful thing to have a new programmer tell the computer to "try" something and fail more gracefully.
Set up and use remote version control now, gitlab or something else but set up a private remote repo now and do not commit any secrets to it. Then go read 12 factor app website 
Python 2 only
&gt; I believe this process is called *"Anal Touring*", in honor of the father of computer programming! I mean, I know \*I\* would feel honored to have my first name turned around and made into the body part through which we all excrete waste. Like he didn't get enough of that as a kid!
I wouldn't use `it.cycle`. Instead, `get`/`put` to a [Queue](https://docs.python.org/3.6/library/asyncio-queue.html). Have all your workers attempting to `get` from the Queue. If they can't, then all proxies are currently in use and they wait. Once your worker is done with the proxy, `put` it back into the Queue so that it is available for the next worker.
This question gets asked about once a week. Search reddit/google for past discussions. **Too Long, Didn't (bother to) Search**: Most common recommendation is PyQT. Every other framework will have their proponents. Tk is more-or-less built in. Web (Flask, etc) is also a good option
Overall this seems like a good introduction to exceptions in Python, but I have a couple criticisms: -You almost never want an 'except' block that doesn't specify an exception type. lt will catch literally anything, including a lot of things you don't want: system exit, keyboard interrupt, out of memory errors, and more. -You rarely want to catch 'Exception', except possibly in top level code, for similar reasons. You should only catch the errors you're prepared to handle, and let higher level code sort out anything else. -Exception handlers that just print a static message are close to useless for debugging. Exception handlers that only print the error message aren't much better. You generally want to print the error type, message, any debugging data included with the error, and stack trace. Some of the articles in the example print the first three, but the stack trace is arguably the most important one since you'll see exactly where the error happened and what the call stack looked like. -Minor complaint - instead of this: try: file = open(...) doStuff(file) finally: file.close() Do this: with open(...) as file: doStuff(file) Or if it was a contrived example for readers, at least mention the better way to do it. :) 
+1 for building web GUIs. This makes your code more-or-less cross platform.
Or even how to raise your own. It's not an uncommon thing to want to write a function, and have some means of communicating failure besides a canary return (false, instead of an integer for example)
Some people also have sex using it though.
Basic producer-consumer-pattern.
Lets assume for a second that a proxy will be used at the same time, that's completely ok. We're more concern with the aspect of ensuring they are evenly used, compared to if two or more (100's is even ok) using them at the same time. 
that would be great :) cant wait to try it out! Thanks man!
If you need help, I'm more than willing to contribute. Note about me: I build python web apps for NASA, but I don't use Django lol
Yes
Personally, I use to use Zappa, but I've switched to [Chalice](https://github.com/aws/chalice) because I find it very familiar as a Falcon API guy.
`import antigravity` &lt;3
Thanks a lot for pointing that out! I actually oversaw that on the site but now i‚Äôm working on getting it running üëçüèº
Thanks for the criticisms. In the very first section I discuss why you shouldn't use the bare `except` giving as example the use of `readfile()` which is not a known attribute. Maybe I should have made a stronger case. I tried to point out the risks of not being specific while handling exceptions. I also show that you can catch all the exceptions that base a common exception (for instance, to catch all the exceptions coming from a specific package), which extrapolates to just catching `Exception`. In my experience, (helping mainly physicists), I have come to realize that the approach varies from developer to developer. When you are trying to quickly analyze data or grab an image from a camera, sometimes you don't really want to go to the details of which exception was raised, you just want to be sure your data is stored or plotted. I agree that if you are developing a package or code that someone else is going to use, then you should be more careful. I tried to address some of the best practices. Bear in mind that the website is **pythonforthelab**, which aims at a specific type of readership. Indeed, I could have added the **stack trace** to the output; I will improve the article ASAP. I skipped the `with` on purpose, because it was on my plans for a future post. The opening of the file was one of the clearer examples that came to mind in which, for instance, if you run the same code twice you can get two different exceptions. Thanks for the feedback!
Probably for the best in the long run, but definitely a bit sad. Thanks for all your hard work Guido!
Why? Why will assignment expressions be everywhere if it is treated as an advanced feature, just like bitshifting is?
The Python interpreter contains a lot of abstractions that make assumptions like this troublesome. I had do duplicate image detection, using the phash algorithm, where you convert both images into a 64-bit binary number and count how many binary digits are different. To cut a long story short, here is a summary of the fastest code I could write to do this: def phash_diff(p1, p2): r1 = int(p1, 16) ^ int(p2, 16) return r1.count("1")
Dropping the mic 
Use a Queue with maxsize=1 and have a separate thread constantly feed it by cycling through the proxy list in the same order. The feeder thread will pause until a worker pulls the next proxy from the queue.
A little sad that he's going, but if it's really over PEP 572, maybe it would have been easier to just cede to popular opinion then instead. Definitely would have been better for the language.
you selected not updated library. Did you consider potentional security problem with software, not updated for 2 years? If you have any active project, keep using actively developed libraries... 
This is easiest if you are doing this as a one-time thing. But if the OP is going to be working using ec2 servers as a computing environment on a daily basis, then it's much better to set up X forwarding. 
Why would you think it would be treated as an adavsnced feature? I can't think of any language that has it where it's considered advanced. I suspect seeing this type of code everywhere: if foo := bar(x): print(foo)
What part of "For Life" did he miss :( I have great respect for the man, I think we've been lucky to have him guiding pythons development over the years.
Anaconda is a python distribution which has a complete ecosystem. It is a virtualized complete python distribution. 
This both sucks and is extremely silly. Firstly, he's not stopping being the BDFL-- he just won't excersise his rights as the BDFL, indefinitely. That said....why? He didn't have to fight for 572. He could have said "fuck you, that's why", and accepted it without any discussion. He could also have decided that "benevolence requires listening to all" and then not accepted it. So personally I think this whole thing is some kind of PR thing for Python and I don't like it.
Probably for the best. PEP 572 is a terrible choice, and represents a turn away from simplicity. He should have listened to the community, but it's better that he step down now. 
Nice :)
Yeah, I feel like the bare except is worth pointing out separately because of the extra risk it carries - "except:" and "except Exception" look the same to a new Python programmer, but they have very different implications. It's true you made a good case for specific error handling, but you continued to catch generic exceptions in later examples so it ended up feeling like a bit of a mixed message. I've never worked in a lab, so your conditions may be different, but I try to make all my scripts fairly robust - far too often my "one time use, for myself only" scripts have ended up being used many times and/or by other people, sometimes in ways the original script wasn't meant to handle, and sometimes they caused corrupt data that had to be cleaned up. That's why I try to err on the side of caution. 
If you don't care about how many proxies are in use at one time, then `it.cycle` should work fine. If you're at all worried about shared resource access (not sure it matters in this instance), `Queue` still gets you where you want to go as long as you .. 1. get proxy from Q 2. create the URL for the request 3. put proxy into Q 4. await the request There's a possibility here though, that if you pull through the queue fast enough, that you could be sending out 2 requests to the same proxy within a second of each other.
&gt; That said....why? He didn't have to fight for 572. He could have said "fuck you, that's why", and accepted it without any discussion. He could also have decided that "benevolence requires listening to all" and then not accepted it. Because the point isn't that he forgot he could make an arbitrary decision, it's that he wants to do a good job and engage with everyone. That involvement is important to his role, but it can clearly be tough and draining. It isn't especially surprising that he doesn't want to do it forever, and I think this would have happened soon enough even without PEP 572.
‚ÄúNow that PEP 572 is done,‚Äù good riddance. PEP 572 being accepted is a blight on the language, what a joke.
Anaconda is a distribution with a package manager and default packages: "the whole anaconda" A module is one file: file.py A package is a collection of modules file1.py, file2.py, ... with an __init__.py module. This allows importing modules from the package, like " from package import file1" 
mathologer just posted on this subject a few days ago: https://www.youtube.com/watch?v=qS4H6PEcCCA
Fine-tuning a little script I use at office for automated downloading, editing, printing and processing of some pdf-documents from a web application. I'm rather new to programming, so I'm quite satisfied this thing actually worked and is saving me time :)
In that case I hope the article was useful! 
I am more than sure it would have happened soon enough, but the language used makes it seem like 572 *was* the root cause. He didn't *want* to be engaging of everyone-- and that's clear because he accepted it even with a gigantic amount of opposition. I *like* 572 but even I accept that this situation is ridiculous. He wanted 572, he excersised his right. He didn't have to excersise his right, he could have easily said "you know what, there's lots of opposition, so to please the majority I'll excersise my right to postpone/deny". The issue here is his excersising of his right went against the majority, and that left a bad taste in his mouth. Whether or not it should have, it shouldn't have affected his piece of mind on it, because it *was his right*.
I wish Guido all the best with his well-deserved break. It's a shame that there was so much bile thrown about regarding PEP 572. While I'm not a proponent of adding assignment expressions to Python, it won't affect my existing code, and it's certainly not anything to get upset about.
"Hey Mr God thank you so much for everything" "Okay. Now, lets give you a coccyx that can shatter when you fall on your ass" "Wtf god I hate you eat shit and die" It's one bad thing for you, out of many good.
This is really sad, and really doesn't bode well. I don't understand wtf is happening with Python leadership but it feels like people are either asleep at the wheel or paralyzed by infighting. Stuff like `asyncio` feels like PHP in its lack of design, and lacked a firm hand making it performant, easy to understand and use. 
Just curious, why do you think this? I personally think it will clean up my regex code a lot, but I did just read the PEP for the first time 5 minutes ago.
&gt; but the language used makes it seem like 572 was the root cause I guess we won't really know unless Guido writes something more specific, but I read it as 572 more being the last straw that happened to push him to make the decision now, also in the context that he probably anticipates this kind of controversy only becoming more common (I guess this is a result of Python's still-increasing popularity?). I'm sure he's been considering when to make this step for a while - as he notes, the bus factor has to be dealt with sometime or other.
Personally I don't think it should be. But this argument is cyclical: * its bad because it is confusing to beginners * okay, make it an advanced feature * why should it be advanced, its simple and common in other languages * it shouldn't, but I'm using your point of it being confusing. But...if it is so simple and common in other languages, why do you think its confusing to beginners * because it is new and strange and complicated * jump to point 2, or continue * if its strange and complicated because it is new, than nothing new would ever be added * its not, jump to point 1.
People were up in arms about f-Strings as well, now everybody loves them (as they should, they're awesome). I'm pretty hopeful that the same will happen with 572.
Can someone ELI5 PEP 572? I read the pep but I don't really completely understand the significance or why it is so divisive? Seems like it's just a potentialy useful little shortcut but are people saying it goes against the ideal of maximum readability?
I still think as would have saved us all this bother.
You misunderstood. PEP 572 is accepted and well on its way to Python 3.8. Lots of people (me included) think it's a positive addition to the language (much in the same way f-strings were). It's just a case of practicality beats purity. 
f-strings are useful. People weren't up in arms because they thought it was bad, but because it was adding new syntax on a minor release. Assignment expressions, in most cases, are an anti-pattern. They encourage less readable code. Template strings and f-strings do the opposite.
The cost should not change, because you are still doing the same operations on the SQS. I recommend to be based on SQS trigger because it has better mechanism of.message delivery (Retries, DLQ, ..). You can define the batch size on the trigger to be bigger then single messages.
It will. Honestly, I think it's time we rename Python 3 as just "Python", and Python 2 as "Curmudgeon". It seems like there's a dedicated pack of luddites who hates that new features are being added - even ones they can completely ignore (like PEP 572) - and swear that each one will be our doom. Or they'll cry that the new features fracture Python, as though Python 2.7 was just a performance patch on 2.5 or something and we've never actually added new features before. Personally, I've had it with that whole line of thinking. Hate all the new stuff (that you don't have to use unless you want to)? Stick with 2.7 and have fun with it forever. The rest of us are going to enjoy all the cool new innovations and won't look back!
No, you're 100% correct. It's a nice (optional!) feature that will make some idioms a lot easier to express. I've literally not heard a single plausible reason to oppose it being available to other developers.
You resd 572 being the final straw, I read 572 being the unexpected heart attack. Not to mention, this email commentary is very, very unofficial. He can still jump in and say "no" on anything at anytime, he will still be the BDFL until he appoints a successor or creates a policy officially (ironically, probably through a PEP) on how to handle things indefinitely/ until a successor is actually appointed. And even then, until he actually says "I am no longer involved", he can still jump in and override anything. FL is FL, unless he decides to completely leave. "Permanent vacations" are never actually permanent, in experience. And yeah, there is a human element. But he *decided* to go against it by accepting. You can't have things both ways in this world.
FWIW many of the core Python leadership has been using the language for an insanely long time, e.g. Tim Peters (who also liked PEP 572) is also the author of the Zen of Python, Nick Coghlan has been a CPython dev since 2005, and Barry Warsaw first encountered Python when his company hired Guido van Rossum in 1994. It's not necessarily this outside influx as some people portray it...
I read part of the PEP and to me the most compelling case was that it eliminates re-using an expression in a case like this: result = apples.get('fuji').color if apples.get('fuji') else None
The less readable thing is extremely debateable, and a large argument about assignment expressions is a "new syntax for beginners to learn in a minor version".
On the other hand, while I like the new features, I dislike the lack of forward compatibility, which historically was always acheived with future statements in Py2's lifetime. Lack of forward compatibility screws over library maintainers.
Well, suddenly it's another language feature. It doesn't allow us to do anything we can't already do; it potentially has some complexity around scopes and effects inside comprehensions (I haven't read the pep in that depth to know how they resolve that). The things that it does allow are, I think primarily opportunities to make mistakes or write confusing code. 
Nothing. He's not stepping down. He's taking a permanent vacation
Thought the same thing when i first read the syntax. You already have as in import and context managers.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
But you don't need to reuse an expression there. It's purely trying to reduce line count. How is result = x if (x := apples.get('fuji')) else None more readable than x = apples.get('fuji') result = x.color if x else None The only real use case I have seen for this is that it allows you to make more complicated list comprehensions. But I would say if you need to have assignments in your comprehension, you should be expanding it into a full loop anyways.
To me that was the least compelling case.
That‚Äôs a pretty good point about future imports, but is there any reason a library maintainer can‚Äôt code against, say, 3.4 and have it work in later versions?
Thats more of an argument for None aware operators, not this.
I think they needed a clearer succession plan, but I think it's very sad to see this... Part of what I have always loved about Python is that it is consistent in approach because while there's an open system for proposing improvements, in the end, it is all in the eyes of the _benevolent_ dictator.
That's true. Such an operator would be nice. 
I am so fucking worried right now
 def quit(job) as failed syntax: print job := wtf
I don't think I can justify why I prefer the former over the latter. I just think it looks nicer. Perhaps that's a bad reason to support the PEP. 
Thanks for building a strawman argument but it's not the point I'm making. My point is it's another thing to teach beginners without adding a lot. It adds to the overall weight of learning the language. Is that bad for beginners? I'm not sure. Is that more for teachers to explain? Definitely.
Perhaps common knowledge... but if you are interested in this you might like: * The maybe monad in haskell - this is a nice simple example of monads. * if-let in some lisps.
Mostly it's bad because they let the scope get out of hand. If they had limited it to things like: if x as some_func(): and while x as some_func(): it would solve the vast majority of the cases it wants to get, while not encouraging bad code practices. Most of the complaints that people have are that it breaks left-to-right readability. You have to scan ahead to find what definitions will be within a statement. Another complaint that people have is that adding another operator doesn't make much sense here. Most would like to have used `as` to avoid confusion about which assignment should be used normally. Some would have liked a transparent `=`.
&gt; Definitely would have been better for the language. You state that as a fact when in reality it is an opinion. Get off your high horse.
Thanks! I've been exposed to if-let in Swift, which (I assume) is similar. 
I would say that the concrete reason I dislike the former is that it breaks left-to-right readability. There are only a two or three cases in Python where that is the case, and most of them have limited scope. This one can be done anywhere, and you need to read more carefully because of it.
Wouldn't it be while some_func() as x:
&gt; How is this more readable * All on one line * Natural eye movement of reading tells what x is. "x.color..." What is x? "x :=" a that is what x is . I guess this is kind of an argument for reverse order of definitions x = y + z where y = blah z = blah But it kind of depends on how you are reading things. If instead of x you had a meaningful name the assignment could provide you with information that could be ignored when reading.
Oops. Yes, you're right, I just had a brain fart. I'll go fix that
With two or three exceptions, Python is readable entirely from left to right. This adds another case where that is not true. That seems like a bad thing, in my eyes.
I don't blame Guido as much as PEP proponents. It's kinda similar to famous kdbus debate in Linux kernel, but there kdbus people had decency to back off seeing huge backslash (and they had Linus at their side). 
If you read 572, it has actual real world examples of places where assignment expressions make code more readable. The pep is very clear that these should be used sparingly, but that there are some legitimate use cases where it makes for cleaner, easier to understand code. And those use cases are why it was presented
is it still working for you? I'm trying to retrofit this script here: [https://keithselover.wordpress.com/2016/10/10/algorithmic-trading-part-1-backtesting-an-rsi-strategy/](https://keithselover.wordpress.com/2016/10/10/algorithmic-trading-part-1-backtesting-an-rsi-strategy/) he was using yahoo for data but I understand it has been discontinued. Im trying to adopt another data stream but Im kind of at a loss.
I'm more willing to blame the decision maker than the people who put forward new ideas. We need them from time to time. And I would be arguing very strongly in favor of something like `if as` and `while as`. But Guido and co. rejected that version, so here we are.
Too late. He already ruined Python by pretending Python3 is just a newer version of the same language. Imagine a similar push for Perl6 combined with a sabotage of Perl5...
I've seen those examples, and I don't think they are enough of a use case to justify adding a new syntax feature with such a wide scope. The places where they show the biggest improvements would be done just as well with `while as` and `if as`.
There's plenty of things that can be right to left in Python as it is.
I don't love them. Embedding expressions in f strings is nasty (especially with escaping and whatnot) while putting nameless expressions in str.format was very neat. The one benefit to f strings (not having to write o, r, m, a, t) doesn't really seem worth it to me.
Part of me wants to say, "I'll never use it, but if others want to then they should be able to." However, I'm going to have to read that and I don't want to.
I know it was a simplified example, but I figured that this would already be easily solved by something like `result = apples.get("fuji", {"color": None})["color"]` Perhaps a bit less readable, but still functional without adding new syntax and without the reuse
I'm worried about large entities leveraging themselves to disproportionately influence the language now.
3.4 code will work in newer versions, but there's lots of syntax and builtin functiionality introduced in 3.5-3.8 with no future statements to show for it. This limits features the maintainer can add, limits the contributions people can make, and leads to hacky, extremely ugly and inefficient yet feature compatible code (the latter is especially relevant when it comes to asynchronous context managers and generstors). In Py2 practically everything syntactical had a future statement at least 1 minor version before being implemented by default. That mindset stupidly went away with Py3.
I certainly get what you mean. There are certain parts of the language I don't like to see, either (eg '%' for string formatting instead of `format` or f-strings). However, I can deal with reading assignment expressions in other people's code (provided that they aren't abused, etc, etc).
This would work if `apples` contains dicts as values, but if there's an Apple object, it wouldn't necessarily be a valid method to get the `.apple` property. 
Do you really think that this reductor = dispatch_table.get(cls) if reductor: rv = reductor(x) else: reductor = getattr(x, "__reduce_ex__", None) if reductor: rv = reductor(4) else: reductor = getattr(x, "__reduce__", None) if reductor: rv = reductor() else: raise Error("un(shallow)copyable object of type %s" % cls) More clearly shows the logic of what is happening than this? if reductor := dispatch_table.get(cls): rv = reductor(x) elif reductor := getattr(x, "__reduce_ex__", None): rv = reductor(4) elif reductor := getattr(x, "__reduce__", None): rv = reductor() else: raise Error("un(shallow)copyable object of type %s" % cls) Because it sure as hell doesn't seem more clear to me. Just because you don't want to use them in your code doesn't mean they are a universally bad addition to the language. 
&gt; It's a nice (optional!) feature .... I've literally not heard a single plausible reason to oppose it Remember, every single "optional" feature in C++17 made sense to someone at some point in time. If you want backwards compatibility you can't just keep kicking old features off the boat (e.g. Python 2 -&gt; Python 3), you are stuck with them for life. So when you are adding complexity to a language (especially one so wide in scope as a new operator), you need REALLY solid justification. Not "sometimes it will let people write 2 lines of code in 1 lines (and arguably in a more confusing fashion) The nice thing about python right now is that you can easily fit the entire syntax into your brain easily, and it lends itself easily to writing legible, self-explanatory code. Adding complexity simply for the sake of "nice shortcuts" is the long-term path to hell.
But my point is proven-- you're cycling. Complaining about it being bad for beginners is solved by teaching later. Hell, bit shifting is the same as powers of 2, why have that when we have `**`? Being more for teachers explaining cycles back to "nothing new should be added". Every new feature in a language is more for teachers to explain.
I'm also pretty skeptical that the whole "eh, let's see if an organization structure emerges out of this" will work out well. Though maybe a structure already kind of exists and will just end up being codified in some way.
So is the ":=" symbol the final decision for PEP 572? I know that this symbol is used in a lot of pseudocode and other languages but using it in Python code looks messy in my opinion. They must have also considered using the "as" keyword instead which is what I would have preferred but I can't find any documentation for their reason. [My post almost a year ago](http://www.reddit.com/r/learnpython/comments/73fjqr/is_it_possible_to_check_if_an_object_is_not_none/) was about this but most were against this idea.
It adds side effects to otherwise side effect free expressions. The problem is that doing so makes it more difficult to reason about what the code is doing. This tension between minimizing side effects and language expressiveness is something that needs to be carefully balanced. Go too far in one direction and you get perl and an unmaintainable mess. Too far in the other and you get haskell and the code is beautiful but it's very hard to get actual work done.
I think that `let` in generator expressions would have covered the most compelling and uncontroversial use case (and then we could start looking lustily at the rest of LINQ), while the rest of the stuff (getting value and condition out of "any()" or "re.match()" could be done differently or not done at all. Like, there's a new C++17 if-with-initializer approach, but honestly it doesn't make much sense for Python because ifs don't introduce a scope, so you can declare and check the variable(s) as usual. 
I had a boss who used to say "hope is not a strategy"... seems applicable in this case.
They chose to fight the battle, though. Could have just acknowledged how much some people hated it and decided it wasn't worth it. 
Okay, so then it's just kind of a knee-jerk reaction to any kind of new language features? 
The problem is *because* of context managers and exceptions using as here would create arbitrary limitations or be hard to syntactically parse and make decisions on, or worse, both. That's why using as failed.
Copy of the link if you can't get to it for whatever reason. Note that he doesn't say "stepping down" he says "giving myself a permanent vacation from being BDFL". If you don't know BDFL means "Benevolent Dictator For Life". ----- Now that PEP 572 is done, I don't ever want to have to fight so hard for a PEP and find that so many people despise my decisions. I would like to remove myself entirely from the decision process. I'll still be there for a while as an ordinary core dev, and I'll still be available to mentor people -- possibly more available. But I'm basically giving myself a permanent vacation from being BDFL, and you all will be on your own. After all that's eventually going to happen regardless -- there's still that bus lurking around the corner, and I'm not getting younger... (I'll spare you the list of medical issues.) I am not going to appoint a successor. So what are you all going to do? Create a democracy? Anarchy? A dictatorship? A federation? I'm not worried about the day to day decisions in the issue tracker or on GitHub. Very rarely I get asked for an opinion, and usually it's not actually important. So this can just be dealt with as it has always been. The decisions that most matter are probably - How are PEPs decided - How are new core devs inducted We may be able to write up processes for these things as PEPs (maybe those PEPs will form a kind of constitution). But here's the catch. I'm going to try and let you all (the current committers) figure it out for yourselves. Note that there's still the CoC -- if you don't like that document your only option might be to leave this group voluntarily. Perhaps there are issues to decide like when should someone be kicked out (this could be banning people from python-dev or python-ideas too, since those are also covered by the CoC). Finally. A reminder that the archives of this list are public ( https://mail.python.org/pipermail/python-committers/) although membership is closed (limited to core devs). I'll still be here, but I'm trying to let you all figure something out for yourselves. I'm tired, and need a very long break. -- --Guido van Rossum (python.org/~guido)
&gt; What specifically defines a method call from either being one or not being one With len, IMO of which i'm open to being corrected, the thing here is that its not an attribute of the class. Quoting [wikipedia](https://en.wikipedia.org/wiki/Method_(computer_programming)): &gt; A method in object-oriented programming (OOP) is a procedure associated with a message and an object. len() is not a method because it is not associated with an object. It is a globally available function.
Yeah I can understand that point of view. It's kind of playing code golf at the expense of simplicity and readability
They considered as but it was * potentially confusing in some cases (context managers and exceptions) * hard to parse in those cases * hard to decide precedence in those case * if they all said "okay, remove those cases", it introduces arbitrary limitations on that syntax.
Your submission has been automatically removed. Accounts must be older than 2 weeks. This helps prevent spam. **If you need help with Python** see r/learnpython or r/learnprogramming. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*
I would rather have if dispatch_table.get(cls) as reductor: rv = reductor(x) elif getattr(x, "__reduce_ex__", None) as reductor: rv = reductor(4) elif getattr(x, "__reduce__", None) as reductor: rv = reductor() else: raise Error()
Can I get some examples? Because I can only think of two, and *think* there's a third. `a if cond else b` `[expr for x in expr2 if expr3]`
Oh okay. That was very stupid of me. Thank you so much. I will fix that ASAP. Any other suggestions?
There are clear leaders on almost all aspects of Python, if everyone bands around them concensus mechanisms might manifest naturally.
&gt; (I haven't read the pep in that depth to know how they resolve that). Then why are you commenting negatively about it?
Better still: result = apples.get("fuji", {}).get("color")
one of the most appealing things to me about python is that it often reads like english pseudocode. using `as` instead of `:=` seems WAY more pythonic to me.
It's pointed out in the PEP (and *over* and *over* in the email threads) that a more limited syntax restricted to `if` and `while` statements loses out on a lot of places that expression assignments could be used. It doesn't even support its own limited space very well! For instance, you can't translate this code to a limited syntax without going back to "loop and a half": pos = -1 while (pos := buffer.find(search_term, pos + 1)) &gt;= 0: ... If you're going to add new syntax, it had better be useful! A limited `while ... as` doesn't meet that bar. The PEP also makes it pretty clear that Guido doesn't like the reversed order of assignments using `as`, even if the serious syntactic issues it has could be avoided. I think lot of his frustration with this whole situation is that arguments like yours would not die, and the same points kept getting made by different people who had not read the previous debates (or the "Rejected Alternatives" section of the PEP). The PEP really did address most of this stuff, especially after its first few revisions!
Modern day equivalent of exile.
This will be unpopular opinion but the moment I tried async stuff I knew BDFL went crazy. It is very unfortunate.
Call me a unicorn, but I do like the % string expressions! Of course, the `format()` version is really cool too, but for a quick formatting work like: "There are %d days in a year." % 365 The % does a much better job than a verbose format(): "There are {} days in a year.".format(365) Its all down to individual preference, of course.
Probably good /r/learnpython material. When you say this is a dictionary, you mean a python dict? If value is not None: apply a filter This should be very simple to do. You don't need a case for each combination of values. You need a single if per input.
Sad to see you depart patriarch Guido, your contributions to the open source world have been remarkable and you'll always be celebrated as the Python guy! Best luck on your next projects and ventures.
asyncio definitely doesn't feel like the rest of the language... Most python features are extremely easy to learn, reading one or two paragraphs of the official docs are usually enough to at least understand how to use them in some simple ways. Synchronicity might be a more complicated topic than most features, but still, I understand fairly well Javascript's async, I've read a few articles/tutorials about asyncio, and I still can't get my head around it...
 # first get user inputs into variables a, b, and c # in this case I'm presuming the value is None if it wasn't entered # i'm leaving it to you to normalize the data to that point # assuming my_dict holds the object reference of your dictionary filtered_dict = my_dict if a is not None: filtered_dict = {k:v for (k, v) in filtered_dict.items() if k['a'] = a} if b is not None: filtered_dict = {k:v for (k, v) in filtered_dict.items() if k['b'] = b} if c is not None: filtered_dict = {k:v for (k, v) in filtered_dict.items() if k['c'] = c} return filtered_dict 
His initial message doesn't appear to be using a SQL DB. Or any real DB engine at all.
But not every "leader" is a good one, unfortunately
Then you've also been exposed to Haskell's Maybe monad through Swift's option types, which are one of the greatest features of the language, in my opinion.
So we are going to see a python4 vs. python3 non-backwards compatible split after all! Python4 will have assignment expressions and python3 will retain all the trolls and naysayers who though this minor addition was going to kill their favorite language completely. /s This is a sad thing to have to see a man who has worked so passionately for so long to lose faith over something as trivial as this. 
Yeah, thanks for the clarification. "Stepping Down" wasn't really the write phrase for the title but don't think I can edit.
I too like % formatting expressions. But the reason why they aren't my favorite is the inconsistency with single item vs tuple/dict unpacking vs tuple/dict as a single item. On the other hand the new format specification (`format` and f strings and all else) not only solve that inconsistency but also extend the default definition, *and* allow for creating custom extensions to the spec (if wanted). Though honestly they could have kept the % C/Java syntax rather than make a new one. That decision was a weird one for me.
Except that the `as` in `with`and `except` statements work differently than it would in an assignment expression, and you'd need to define how they interact with each other in a weird way or break backwards compatibility with a ton of existing code. Neither `with foo as bar` nor `except foo as bar` do a simple assignment of value of `foo` to `bar`. The former calls `__enter__` on `foo` and assigns the return value. The latter assigns an *instance* of `foo` (or some subclass) to `bar`, but only if one is raised in the preceding `try` block. The key problem is that `foo` can be any expression, possibly including an assignment expression (which would use `as`, if you got your way). That breaks everything unless you accept horribly ugly warts in the syntax. Is `with foo as bar as baz` ambiguous, or merely very confusing? Would `except (foo as bar)` behave completely differently without the parentheses? The other issue is simply that Guido doesn't like the reversed order of the `foo as bar` assignment syntax. Python has defied the conventional argument order in some other expressions (notably the ternary operator `a if b else c`), but he didn't want to do it again for this one. I trust Guido's judgement on this one, but maybe you don't.