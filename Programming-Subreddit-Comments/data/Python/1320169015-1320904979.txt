Guess you're talking about [this post from 2008](http://i.imgur.com/mjdxf.png).
No. I haven't got to that yet, however if I can't figure out a dead simple way to do it, I probably won't add them. The aim for this series is simplicity, not completeness.
Thanks for your input! I'll definitely take a look at the links. I understand the code partially, but would you mind giving a brief explanation of it? 
infocide. apparently it's something he's done (albeit on a smaller scale) before.
This project is actually a port of my [Scheme in Scheme](http://nickzarr.com/blog4/series/lispy-in-scheme/) series. Thanks for the link, I'll add it to the list of Scheme implementations on my page. 
Both books aim at novice programmers. I think that LPHW is much better for novice programmers. The problem with DIP is not because it aims at novice programmers. The problem with DIP is because it provides outdated information about Python (note: latest revision seems to be in 2004) and it is not as well thought out as LPHW.
Thats the one. Looks like he must be on the backpack stage.
I have delivered a Python application that runs 24/7 for years without failures, I've even discovered a bug in `pyserial` in the process, and, well, I don't think there are any silver bullets besides _being very damn conscious_ about what you do. Read and re-read your own code a lot, when in doubt what some function expects don't be lazy, go and check, think about edge cases, maybe have some strategically placed asserts here and there, always extensively comment all non-obvious decisions and assumptions down to every little detail, explicitly describe your state transitions, and so on. Most of all try to keep your code as simple and straightforward as possible. Basically, I approached it in the same way I approached my C/Assembly stuff for embedded devices, where when something went wrong I had nothing to stare at except the impenetrable surface of the chip (and my code of course). That kind of gives a certain discipline, you see =) And of course use `logging` and don't forget to wrap your top-level function in a try/catch block (then think if it's possible to automatically restart it -- and how the program should be written to not choke on inconsistent state left from the previous run). Things you talk about, like running tests automatically with every commit, sound too much like wankery to me. Just write an integration test suite and use coverage to see that you exercise all your code. Going beyond that would contribute more to you feeling good about yourself than to stability of your code.
"def" is the keyword for creating a function in python. pigheaded linked to a number of modules within Python's standard library. Each of those will need to be imported ("import csv", "import os") before use. To call makedirs in this way, you would actually call "os.makedirs(path)" You'll actually need to create a csv reader from a file handle, which you can get this way: "f=open('/path/to/file.csv','r')". Check the documetnation on "csv" for more details. That should be enough to get you started. Feel free to ask more specific questions should you have any.
He's off shooting his autobio pic, Mark Pilgrim Vs The World.
In case you keep with Python, make sure you use [coverage](http://pypi.python.org/pypi/coverage/) and, at least, you either: * have 100% branch coverage. * REALLY understand why your tests did not covered some lines/branches.
&gt; Like, it doesn't happen "rarely", nor "extremely rarely", nor even "maybe a couple of times in my career", but never. Now we've heard from the ideologue, for whom such a thing [never happens](http://mail.python.org/pipermail/tutor/2007-January/051903.html) ... [not ever.](http://stackoverflow.com/questions/492387/indentationerror-unindent-does-not-match-any-outer-indentation-level) ... [even once](http://stackoverflow.com/questions/4878369/python-indentation-error). I could go on for hundreds of easily accessed examples, but what's the point? They never happen. 
This wasn't a thread about which book you like or which one is better. It's specifically about Dive Into Python. Your opinion on other books is not relevant here.
I've never seen this either, in real code written by experienced programmers at work. But I did see it [in a beginner's program on r/python just a couple of days ago](http://www.reddit.com/r/Python/comments/ltgr4/what_did_i_do_wrong_simple_text_adventure_game/). So I think it's a matter of whose programs you spend time reading. (Of course, programmers who can't indent their Python yet would have even less chance of getting their Haskell to compile...)
This is really great advice. In particular, I hadn't really thought about using coverage yet, so I'll definitely keep that in mind. It's possible that going all-out and testing with every commit may be overkill, but the downside of doing that is only a little wasted time. I'll have to think about it some more before I decide if it really serves an important purpose.
very cool, I've been trying to learn pygobject. thanks for sharing :)
I've encountered a very few indentation problems with Python, usually involving multiple people using different editors to edit code. One person uses spaces exclusively, and then the other person carelessly edits the code and introduces some tabs. Usually it's not a big deal, though.
100% branch coverage would go a long way towards helping me sleep at night. I imagine that it must be hard to achieve though.
I really like your idea about clearly separating validation methods and methods to take already-validated data. That definitely seems like an important strategy for reliability. At the same time, that idea suddenly strikes me as the sort of thing that a type system would be ideal for... I wonder if anything interesting has been happening with those Python type annotations?
What have you got so far?
Aye!, On the scale of underwear on head/pencils up nose I guess shagging swedish tourists is the good option.
I've got def most_frequent(s): for i in s: x = i.count(i) print x 
Look at collections.Counter. http://docs.python.org/library/collections.html foo = "hello world" c = collections.Counter(foo) print c.most_common(10)
That's why I'm asking for help. That's as far as I got, and I couldn't figure out what to do. Do you have any suggestions?
Not even if you say "wibble"?
If I was a professor and my student used this, it would prove that he's read the documentation of the language. My student could then look at the source of the module to see how it does what it does.
You should check out [r/learnpython](http://www.reddit.com/r/learnpython).
 import collections def most_frequent(s): count = collections.Counter(s) common = count.most_common(len(s)) print common When I print common, I get a None value. Why doesn't common hold the list value?
If my own code base is representative at all (along with what I consider to be "hard")... yes, it is quite a challenge, but it's not actually achieving that 100% what helped me the most, but to pursue it (I'm not actually sure that is properly expressed, but I hope you'll understand, and forgive my self-taught English). Working my way to get that mythical number allowed me to improve my tests, understand that parts of my wonderfully, general code were not really adding anything over a simpler version (thus avoiding corner cases, complicated logic, etc.). That, and trying really, extra hard to not foul myself into thinking that those lines/branches not covered are bug free, and understand why I can live with them. On the other hand, on the handfull of subpackages where you actually get that 100%... man... feels like a cold beer in a hot summer evening! :-D
http://www.diveintopython.net/ There you go.
what a dick move. close up shop, delete your facebook, etc, but why do it in a way that a) causes lots of people to worry for your well-being (to the point that the police were called, and then he complained about being bothered by the cops) and b) causes tons of valuable information to be lost/forces people to waste time reloading stuff from archives. 
I would recommend splitting it into two loops, ie the first loop generates the tally, then you sort it, then a second loop does the sorting/printing. I assume this is a homework question, what sort of things have you learned so far in terms of Python data structures?
Thanks. I just posted it over there.
As I said, I don't use tabs.
You don't want len(s) you want len(count). Also, try returning?
Well, it's just that you sounded a bit too fascinated with all these ideas, to be honest. I've been there, it's too easy to spend altogether too much time on a super-duper awesome framework which would send you an email when you broke a test, before you've written a single line of actual useful code. Also, I want to add that I don't know if my way of doing things is transferable at all, in the form of advice. The core idea is that when I'm a single developer and my project is not very big (say, 1-3 KLOC), then after paying a certain amount of attention to the code, improving, documenting and generally thinking about it, _I end up memorizing most of it_. Literally! So that I look at some incorrect behaviour and think: "Aha, it's probably that pesky comparison in such and such function". It's a lot of effort, requires a certain skill, and might be not the most efficient way of writing robust applications. But it works for me. (_edit:_ also, since my memory isn't actually any good, this perfectionist drive to get all the code into my head pushes me really really hard to make it as simple and straightforward as possible, and add a lot of comments that describe my ideas about how it is supposed to work. So I don't end up being [Mel the Real Programmer](http://www.cs.utah.edu/~elb/folklore/mel.html), contrary to what one might expect!)
Thanks for helpful response. I've gotten started on the program, but I am stuck and not sure of how I should go about implementing the next step. Here's the program:: &gt; import csv import sys import os import errno &gt; # Create top level dir, other folders will reside here &gt; try: os.makedirs('project_site') except OSError, e: if e.errno != errno.EEXIST: raise &gt; # Read CSV file and create respective folders &gt; file = csv.reader(open('de_site.txt', 'rt')) for row in file: **Stuck here** &gt; So far, I've verified the top level folder is created, I can print the output of the CSV and verified that it's all correct. Now, however, I'm stuck at the part where I should take the values from inside the CSV and create the respective directories for each. Help/advice? 
Good thing Pythonistas are less interested in drama and his contributions weren't glorified as much.
The worrying thing was more sad on the part of the random people flipping out and calling the police on him. Leave the guy alone. You're going to call it a dick move for him to do what he wants with the resources he created? Get real.
I'm sure his family knew exactly what was going on. It's just the hordes on the internet who didn't.
I have 2, 3, 4 and 5 covered. But then I don't have my own house so everything I own is already in one room, and I've never had a credit card.
That's where pigheaded's response comes in. He presented a function (mkdirs) that would take a root path (your working folder) and a folder name (he passed in the address, you might need to clean yours up if the address contains invalid filename characters). His function then joins the root folder with the new folder name and creates that folder. Finally, his function takes a sequence of folder names (a list is a sequence) which would be each of the folder names you're creating under each address folder and iterates through them ("for x in y" will perform some action on every value of the iterable y. A list is also an iterable). It then joins the base and the new folder similar to the parent folder, and creates the folder the same way. Did that help?
I'll be honest, I understood very little of that. I probably need to read more code to fully understand what you just typed and how to properly understand the code Pigheaded wrote. What would go after **for row in file:** ? Contextually, I'm having a hard time visualizing the code already written by Pigheaded and how everything fits together. I guess this is the part where I say: "Explain it to me like I'm 5"? lol. I appreciate your patience and help! Thanks! 
He is hanging-out with [_why](http://en.wikipedia.org/wiki/Why_the_lucky_stiff).
Based on your logic, then, why is your comment relevant here? I recommended a book which I thought was better. If you don't like it or think it's not useful, downvote.
The disparaging remark relates to *how* he did what he did, not *what* he did. There is a difference between just taking your ball and going home and *announcing* you're going to take your ball and go home beforehand.
Why should he have done it any other way? He wanted himself removed for whatever the reasons may be. As other posts have shown, this was apparently part of some other grand plan. He should do with his things what he wants, and he clearly wanted them to just up and disappear. That's what he wanted, that's what he did - good on him for moving on with whatever his plans are. I don't get why people think they were owed some type of announcement.
It's only a flesh wound.
Seriously, why did this get so many up votes? This happened last month, people. It's not like a "golden oldie" that gets up votes again and again after the fact like Folklore.org or something. It's a thing that happened recently that we should all still remember.
One of my favorite things to read on the internet is people justifying their derogatory remarks. Thank you for that.
Uh, because no man is an island. A lot of people out there relied on his work, and--assholes that they are--cared about him as a person. Announcing "Hey, I'm sick of the internet; I'm leaving next week," would be a considerate way to think about the feelings of the people who are counting on you, instead of pulling the rug out from under them.
If I were teaching computer science, I would try to focus on making my homework assignments something other than re-inventing the wheel. 
Why is this here? He packed up and left months ago. The sites are mirrored, he decided he didn't want to do it anymore. Let it rest.
See if this maybe of use: http://merciless.sourceforge.net/tour.html 
If you're prepared to wrap things in function calls, you can just "return" to escape the function. Other than that, nothing that I know of. Well, technically, you can use ctypes to segfault the process so it dies instantly. But deliberately causing segfaults makes baby Jesus cry. And anyone who reads your code is liable to come after you with a pitchfork. Why is raising an error a problem? If you just want the code to exit, an uncaught error doesn't really matter.
anyone who reads it already will........ basically its recursive and every level of recursion gets a new answer and prints that. Once it gets to the end, I want it to simply STOP. removing the exit call makes it do weird stuff that ends up giving errors that don't make any sense in the context of the code. It has to be a clean exit because of the way the console writes. it must exactly equal the right output/answer so the error shows up and that's not part of the answer
wait...... 'return' may work with some tweaking. Thanks! Unless you know any other ways...
When you insinuate, totally apropos of nothing, that the Ruby community is "interested in drama", (and get upvoted for it) what do you think you are implying about the Python community?
Well, you could raise an error, let it bubble up all the levels of recursion, and have a try/except block at the top level to silence it. But I suspect that's probably not necessary if you get the design right.
&gt; Why should he have done it any other way? Because politeness and consideration still matters, even on the internet.
the design is... choppy at best and probably couldn't be worse. But as it turns out, 'return' works just fine! Thank you very much, kind sir!
I believe that `os._exit(exit_code)` will end the process without performing various cleanup tasks like closing file handles cleanly. I'm guessing it just calls the `_exit()` libc function which *I think* should circumvent `SystemExit` altogether. Or you could `signal.signal(signal.SIGKILL, os.getpid())` to violently terminate yourself. If you're writing to the console then you may want to `sys.stdout.flush()` (and/or call `.flush()` on other file handles, or just close them) before performing either of these options if you notice any issues with truncated output.
Not all exceptions are errors.
Your comment doesn't add to the conversation, plus Dive Into Python isn't aimed at complete novices and Learn Python the Hard Way is. So your whole post was pointless and doesn't add anything relevant.
The Python community is boring?
It takes a true programmer to use the assertive 410 status code.
"Python" on its own is a language, which is not the same thing as its most popular implementation, CPython. The speed of this language is dependent on which implementation is used. Below is a link to a highly experimental hack that was created by Armin Rigo, a lead PyPy developer. All of the calculations are handled in real-time by python (ideally using PyPy), aside from the Xlib interface which was implemented in 62 lines of C. https://bitbucket.org/arigo/arigo/raw/default/hack/3d/ I'm not saying that this is widespread, and it is certainly not ready for prime-time yet. But having a JIT available to python is quickly changing what is possible and challenging the conventional notion that interpreted languages are slow. Languages are not slow, but their implementations can be. **TL;DR Python != CPython**
If you're interested, see my response to Nimbal above: http://www.reddit.com/r/Python/comments/ltb8h/suggest_a_python_3d_physics_library/c2waavw
Schadenfreude?
&gt; removing the exit call makes it do weird stuff that ends up giving errors that don't make any sense in the context of the code. This means that your recursive function is buggy. That's the problem you should be trying to fix, at least in principle.
 def make_baby_jesus_cry(): import ctypes ctypes.POINTER( type('x' * 2 ** 25, (ctypes.Structure,), {}))
Use a dict to hold a map from letter to count. Loop over string, count letters. make a list of tuples using zip() that contains (value,key) from the dict. call lst.sort(). Print list. Good luck with the rest of your life. 
First world problems
&gt; The requested resource is no longer available at the server and no forwarding address is known. This condition is expected to be considered permanent. Clients with link editing capabilities SHOULD delete references to the Request-URI after user approval. I never thought that context could make an RFC so poignant.
*hordes, but wtf. They aren't just hordes, they are also people. 
re-inventing the wheel can be useful. It takes away the magic from these things. Why do we make network protocols in networks class or try to hack on a old broken Linux kernel to build in functionality that was developed years ago. Its the process of thinking through the problem that matters, not what you are assigned to do. 
That's inspiring. Except I might stop at around step 6 or 7... not sure I'll ever be ready for something as hard core as step 8. 
thx for the links. known about diveintopython for a long time. just decided to learn python, only to find out that the site is gone. so yeah it's kinda sad
Good riddance.
*knew
this is the what happens when you have a fight with wife and lost. "BITCH I AM OUTTA HERE !!!"
What you say is true. In dynamic languages you have to rely on strong unit-testing practices and building off of community-vetted libraries to achieve to stability. In Haskell, HM and Quickcheck can eliminate most of the common bugs to much higher degree and with far less effort. If you have program reliability on one axis and effort on the other then Haskell is linear, Python is exponential.
Most of this is in [Jellyfish](https://github.com/sunlightlabs/jellyfish) and C optimized so it should outperform the pure Python implementations.
 echo(~)$ python Python 2.7 (r27:82500, Sep 16 2010, 18:03:06) [GCC 4.5.1 20100907 (Red Hat 4.5.1-3)] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! 
And that's why you always leave a note.
Your explanation has something in common with your program -- neither of them is clear enough to know what's wrong. For us to know what is wrong, we would need to know what the program is supposed to do, but you don't say. I suggest that you do this: 1. Say what the program is supposed to do. 2. Then say what it is doing instead. 3. Then very clearly say how (2) differs from (1) By the time you are done, you will already know what the problem is. &gt; The problem seems to be that when the if statement is evaluated, if there are two values of matrix[i][0] that are the same. I don't know about your program, but there is definitely a bug in this sentence -- it's missing an essential phrase. But to reiterate, say what the program is meant to accomplish, and how your code falls short of that goal. Having done that, someone will solve the problem by writing the program over for you. That will be quicker than trying to sort out what your code won't do. 
SO often, the easiest way to troubleshoot a block of code is to try to explain the problem to another coder. can't even count the number of times that i cut my explanation of the problem short because i had talked myself into the solution.
I changed the way the algorithm works slightly. It gives the desired result. I feel that the problem may be with the fact that the variable "i" is not updated in the compare correctly. Here the source-- Python (ver 3.2) matrix = [[4.0, 1.0, 532.0, 0.076792222],[4.0, 2.0, 669.0, 0.133467327], [3.0, 2.0, 722.0, 0.051783073],[3.0, 4.0, 196.0, 0.184216793], [0.0, 1.0, 907.0, 0.125563734],[0.0, 2.0, 291.0, 0.217457185], [1.0, 3.0, 24.0, 0.208844158]] maxsize = len(matrix) for i in range(0,maxsize): node = matrix[i] for each in matrix: if node[0] == each[0] and node[3]!=each[3]: print(each[0]) print(each[3]) -- Sorry I couldn't be of more help in debugging your algorithm. Happy Programming. If you need any help with this just post back 
Another note I would add...Nested for loops are OK for small data sets. However, as the data set grows, the time the algorithm spends searching will increase exponentially. 
tl;dp: sideboob
&gt;because apparently you can't use semicolon after a function that way? Not matlab. It is these little differences between matlab and python that can be a bit frustrating, but Python is free and matlab sucks.
 for t in range (0, 50): print "*" * int(40 * (lambda a,x: -a * x * x * x + (a+1) * x * x)(5, t*0.02)) FTFY so it works in one line edit: or : for t in range (0, 50): f= (lambda a,x: -a * x * x * x + (a+1) * x * x); print "*" * int(40 * f(5, t*0.02))
Not even then Darling!
NSFW? Where the hell do you work?
Lol, well, it wouldn't be NSFW for me because I'm in a pretty lax environment (hey, it was my boss that realized it looked like a boob in the first place) but there might be other people who work in... I dunno.. monasteries? 
 from __future__ import print_function; b=map(print, ['*' * int(-1.6e-3*x*x*x+9.6e-2*x*x) for x in range(0,50)])
It's not a contest. I think you missed the point. If you do like most people, you'll end up with lots of commitments and lots of stuff soon enough.
Also, if tabs do get into your space-indented code somehow, it's pretty trivial for a tool like Pylint to spot the problem.
This is 
You should define your terms. Your question is vague: &gt; What things can I do that the resulting application will be rock-solid? And by "rock-solid" you presumably mean "reliable". Now then, what does it _mean_ for your program to be reliable? * Does that mean it should be proven to be free of bugs? * Should it seamlessly pick up its processing where it left off after a clean system reboot? * After a power failure? * Will it have to deal gracefully with filesystems that have run out of free space? * With disks that are dying? * Does it use networking? * Can it assume that the network is always available? * What if it's flooded with network requests? * Will it matter if the system clock returns the wrong time? * What if the CPU is very busy doing some other thing? * What if system memory is full? * What if the kernel's OOM killer shoots your program down? * Etc, etc, etc. From the rest of your question, you seem to be thinking along the lines of testing and type checking. That seems to imply that you want to "rely" on the program not having bugs. You can test many things with unit testing, but at every test case you should then consider what external edge cases like the things I mentioned above will do to your code. Also, if things like this matter, read up a little on [Erlang](http://en.wikipedia.org/wiki/Erlang_\(programming_language\)).
I suggest you try the tutorial before going further. I'm a learning-by-doing kind-a-guy but you need to grasp some of the basics such as defining function and how to use a for-loop. Once you got those down -- it really only takes a few hours to go through the [tutorial](http://docs.python.org/tutorial/index.html) -- you should be able to make progress by yourself. If you get stuck again, come back here. Good luck!
Does this work with Interbase also ?
Languages are not slow, and their implementations certainly can be, but how easily optimizable the implementation is, that's another question :) Let's not generalize. PyPy surely looks interesting and I have been following its progress closely, but I clearly wouldn't point a newbie in the direction of PyPy saying : "Oh sure, you can implement a realistic 3D Physics library in Python that won't suck, just use PyPy!"
I definitely agree. I thought I would be able to understand the code, but I can tell that I need to practice more and become more proficient before continuing on. Thanks!
This is known as 'rubber ducking' and works wonders
That's Captain Darling to you. I'm so utterly sorry for this off-topic circumdickerence (dicking around).
On a related note (please keep in mind that I'm relatively new to this): Why are databases (MySQL, Oracle etc.) the industry standard when I can simply serialize and save? Is it speed?
I thought about this for a good deal of time trying to answer your question. But, your question is so fundamental any way I tried to answer it would take a dissertation. So, yes, it is precisely about speed.
Fast, centralized, friendly to complex queries (I am new too)
Mostly for speed and scale. If you have two independent tiers, app &amp; db. You can scale them in isolation. Need more DB power? shared and/or replicate. Need more app power? throw more app servers behind the load balancer. The truth is, most hobby projects probably could get away with starting with a file system and a handful of JSON files to store the data. In fact if your app models your data this way, you could leverage a distributed k/v store like Riak in the future to scale it out. 
Imagine what would happen if two copies of your program were trying to access and update the file at the same time. The one that took longer to complete would overwrite the results of the one that finished first, and you'd lose data. Or imagine if one program was updating the file by writing to it and the other started reading it at that same time before the write finished -- it would get garbled results. Or imagine if a program needed to update two different spots in the file at the same time, because the data would be wrong if only one change was made. One of the other copies of the program running at the same time might catch the file just as the first update had been made but before the second and conclude that the data was wrong and corrupt. Or imagine if you had 100GB of data but only needed to access a small amount of it somewhere in the middle of the file -- you'd still have to read the whole thing starting at the beginning until you found your data, which would take ages. Or imagine if you wanted to change a string somewhere in the middle of it so that it was a few characters longer -- you'd have to move everything else in the file back a few bytes to make room, which means reading and writing potentially hundreds of gigabytes. Some of these problems you can fix with a locking protocol, some you can fix by adding an index, some you can fix by deliberately allowing slack in the middle of the file so that parts can expand without needing to move everything. And so on. By the time you added all of these things, you would have written a database. 
relese notes http://mercurial.selenic.com/wiki/WhatsNew
This [r/python post](http://www.reddit.com/r/Python/comments/lxqn7/python_serialization/) compares encoding/decoding speeds of a few different libraries using 300+MB data sets. It also includes the test script used which may be more useful to you than the comparison.
&gt; Is there a better way to write this file? Certainly, but the way depends on your data. If you can split the json document into distinct chunks that are uniform (not in size, but in structure), you could try a streaming read. You could also look into BSON from MongoDB.
There are many reasons why someone would use a database versus serialization. One is atomic transactions. Lets take a banking program as a simple example. Say there are two deposits into an account at the same time. The program opens the the file deserializes it. There is $50. At the same the program opens the file again for the second deposit. It sees $50. The first deposit adds $100 for a total of $150 and saves the file. The second deposit then adds $5, but it doesn't know that the total is $150. It still thinks there is $50 in the bank account and that the total is now $55. It then saves the amount of $55 to the file over writing the $150 total. You have just lost $100. Another ability is indexes. Say you want your library application to be able to search by an author or a title. With a proper database you can tell the DB that you want to be able to search by those two columns. Then all you have to do is SELECT * WHERE "tolkin" in author. With serialized data you would have to load and deserialize every bit of data you have. That being said every data situation doesn't need a database, and sometimes serialized data in a database can be useful too. For example I have an application that allows people to add more fields and reorganize those fields. It proved too difficult to shoehorn the application into using an SQL DB. The data is serialized and then put into Redis to overcome the lack of speed. It proved to be a good fast solution, but I'm having to work around some CPU bottlenecks. Hope that was helpless (and accurate).
I'd consider that relational databases weren't designed to store "objects", they store rows. Relational algebra then allows for individual elements of these rows (*tuples*) to be independently accessible as well as to be combined together into tuples of other configurations (i.e. joins of tables, subqueries). None of this applies very directly to "a Python object in memory", which has entirely different behavior. The rationale for persisting "objects" into relational "tuples" is so that the same data can be represented in two different ways, each with its own set of utility. Other reasons relational databases are prominent is the client/server architecture, transactional behavior which includes atomicity and configurable isolation, replication, sharding. But these features can also be addressed, in different ways and to different extents, by non-relational databases, including so-called NoSQL stores as well as object databases. You don't hear much about object databases these days as they never caught on, but document and/or key/value oriented stores (i.e. NoSQL) are fast taking over a significant segment of the application space. In that sense you might call "serializing to files" the ultimate poor-man's NoSQL store.
Please Darling, There are ladies present!. Don't make me stab you with a sharpened piece of mango.
&gt; I have total control over what is written to the dump. In that case, yes, the linewise approach you described might help. Especially if you can discard the return value of json.load after each iteration. Are the dictionaries you save nested? Because if they are flat, you can pass an *object_hook* to [json.load](http://docs.python.org/library/json.html#json.load) where you can insert your logic. I'm not sure if it is legal to return *None* from that in order to save memory, though.
Why waste time finding where to put something in a filing cabinet when you can just place it on top of a large pile of papers? :)
Do you have to use json? You could try using shelve for your data.
Thanks, never heard that term before! The [wikipedia article](http://en.wikipedia.org/wiki/Rubber_duck_debugging) on this is pretty entertaining. Well, mostly the picture. I've only ever used coworkers for this, might have to start talking to my Yoda USB stick instead :D
I haven't used this myself, but you might look into [Enthought's Traits](http://code.enthought.com/projects/traits/) From the site: "A trait is a type definition that can be used for normal Python object attributes, giving the attributes some additional characteristics: initialization... validation... delegation... notification... visualization." Sounds like just the kind of thing you might be after.
Hmm, I hadn't heard about 'graft' before. I predict *a lot* of very silly flame-wars over graft v. rebase in the near future. 
Include in your test the Google Proto buffers: http://code.google.com/apis/protocolbuffers/docs/pythontutorial.html 
&gt;Hope that was helpless (and accurate). Please don't take this personally but this was not helpless at all. It was very helpful even.
Agreed, but that doesn't mean reinventing the wheel is good as _homework_. It's good as an in-class exercise. For homework, you should do something at least sort of new-ish.
MongoDB and other document databases are practically arbitrary serialized data with atomic updates and indexing. 
http://python-gtk-3-tutorial.readthedocs.org/
If i'm understanding you correctly, I do the same thing. In my _run_ i have a while loop where the variable can be changed externally.
I find it odd that I keep having to bring this up with Python people, since they're so undramatic, but here it is: Bringing up other people's drama without invitation is, well, _dramatic_. I have personally heard far more about Ruby drama from r/Python than from all other sources combined. If that's how r/Python is going to roll, fine, but let's not pretend that loudly and publicly comparing Drama Quotients does anything other than raise ours.
How so? They do something completely different. As mentioned in the release notes, graft is similar to transplant.
The flag variable should be located externally, not within the thread. The thread should read an external flag -- the outside world shouldn't have to set a flag that's in the thread's address space. Do you see why? Your while loop should periodically check the state of a flag located in the main process thread's address space, not its own address space. That way, the thread can safely exit without colliding with an external attempt to read (or worse, write) its own variables. 
Sphinx outputs LaTeX out of the box. Learning curve is mostly in learning [Sphinx flavored RST](http://docutils.sourceforge.net/docs/user/rst/quickstart.html) which isn't hard. Building is very easy: $ sphinx-quickstart # write your rst $ make latexpdf Not sure what you mean by scalability, but a lot of very large documents have been written in Sphinx. The [Scipy documentation](http://docs.scipy.org/doc/scipy-0.9.0/reference/tutorial/signal.html) for example
I think I understand what should be done: Pass the parent object at initialisation of the thread and change the parent object's variable.
No. CGI is a perfectly valid way to deliver functionality over the web. Whether it is appropriate or not entirely depends on the application, it's load, the server it's running on and a myriad of other variables. It certainly isn't the most efficient way of delivering a web application because it spawns a new Python interpreter for every request - however if this doesn't really impact the usability of your application (maybe because it doesn't have a massive number of users and doesn't need to scale to many simultaneous users) then there's no reason not to use it if it works for you. I would recommend you learn a bit more about object oriented development however, it may provide you with more flexibility in packaging your functionality for re-use - also it will make life easier for you when you eventually need to move beyond CGI, probably to WSGI or similar as the next step. Also have a look at some of the web frameworks that exist - Django, Twisted etc... You may choose not to use them, but you will see how many other developers solve exactly the same problems you will have had to address in your CGI app (e.g. dispatching requests, data management, authentication, templates etc...) and will learn a great deal - you will then be able to make an informed decision when you need to build something new - i.e. should you build from scratch (in a CGI) or use someone else's tried and tested code. No right answer I'm afraid. Certainly, you should take with a giant pinch of salt any developer who tells you that you should be using a particular technique or framework. At least CGI forces you to understand how things really work under the bonnet. 
*Still* using? I never did that in the first place. Take note that I first started doing web scripting in late high school, some 7 years ago. If you're just doing simple little things like that, you might take a look at minimal little frameworks like [web.py](http://webpy.org/). Honestly, though, if what you're doing works... stay with it. I'd never do raw CGI because I don't want to deal with the extra stuff (headers and whatnot), but if you've already got a library to deal with that, you're fine.
Thanks, Dr. Strange. The last time one of my projects was getting a lot of traffic, I started looking at apache's mod_wsgi, which aims to solve the problem of respinning the interpreter for every page. Luckily for me, my functions could pretty easily be modified for this, but the problem I ran into was the os module. I bind user IP addresses to their session cookies, and os.environ['REMOTE_ADDR'] is giving me their remote address. It was possible to port this functionality to mod_wsgi, but ended up being more trouble than I needed (because I survived the traffic). Thanks again for the response!
I don't think this is what you're looking for, but [pycco](http://fitzgen.github.com/pycco/), the Python port of Ducco, is pretty badass.
...huh. The headers that you speak of are *trivially* easy. You can pretty much do: print "content-type:text/html\n" and be fine about 99% of the time.
I now keep a rubber duck by my desk for this purpose :)
FYI: a good rule in Python is "avoid lots of allocation followed by deallocation". This isn't just because of OOM issues, but because of how Python allocates and deallocates memory. In this case you effectively circumvented your problem by performing all necessary processing on one line before moving to the next one. Do yourself a favor and look into the itertools module. You may find several methods here which make your life far easier.
What framework do you think would be best to learn?
Yet another one!?
Thanks -- I think you've convinced me on Sphinx... I will give it a try. 
There are two areas where CGI can get you into a true dailywtf-type of web app. 1. Code re-use: This is a good thing, but as your re-usable modules grow in size, and especially if you have re-usable modules relying on other re-usable modules, then the amount of code that needs to be parsed and interpreted can get very large. 2. Initialization tasks: Opening database connections, parsing config file, opening logging filehandles. All of this stuff can add up and needs to be done for every request in a CGI environment. A long-runnning process, like all Python web frameworks run under will only do this once when the server is started up. I've watched a CGI-based project spiral into a dailywtf-type of project by putting an excess of focus on code re-use (while not being careful about the dependencies between the re-usable code) and also by tacking on more and more frivilous tasks during the initialization. This application has a response time of 1.5 to 2.5 seconds to initialize per request (generally over 1/2 million lines of code are parsed/interpreted with each request ... it's pretty mad). It's an internal-only app, so performance isn't at a premium, but even on a good day it's embarrassingly sluggish and pokey. For those portions of the app where performance is at a premium, they are just careful that they don't re-use any of their re-usable code. Also, this application used the classic "if/elif/elif/else" method of deciding which function to call for a given view and this section of the code grew into a 3000 line long monster if/else statement. All Python frameworks give you some organized/sane way of dealing with routing a given URL to a given View/Controller (well, with the exception of how Zope 2 used acquisition when looking up the view, which was not sane). 
I still use CGI for apps if they are very small, if they don't need much by way of performance, and if I can't justify the expense of a long running process. However, you may be missing some important things like XSS and CSRF protection. Even if you are not vulnerable, it may take you a lot more effort than if you were using an appropriate framework or library. You may also be missing some really useful things, like template inheritance, which can make your HTML much easier to understand for someone else and much easier to extend. And session frameworks etc., rather than doing this by hand every time using cookies etc. However, with Python, once your project gets above a certain size, startup latency could kill you if you are using CGI, so not learning a framework could be limiting your ability to write bigger apps that have more dependencies. I would recommend trying something like flask or bottle, which are small enough that they can be deployed via CGI using wsgiref.handlers.CGIHandler. These frameworks give some structure to your code, and help avoid things like mixing HTML with other logic, which leads to maintenance nightmares. From there, you are in a position to be able to use bigger frameworks, because the concepts are similar, but with the micro-frameworks you don't sacrifice the sense of being the boss and only using what you need.
Have a look at [manuel](http://packages.python.org/manuel/) also.
Doesn't seem like enough for a 2.0 to me. -shrug-
Home page: http://pytools.codeplex.com Pyvot: http://pytools.codeplex.com/wikipage?title=Pyvot PyKinect: http://pytools.codeplex.com/wikipage?title=PyKinect 
That this has so many upvotes worries me. For the next year or two is this article going to repeat every couple months when a new batch of people discover that diveintopython is gone and post about it? Seems like we may have a lot of dupes in our future if it's repeating so soon.
Sure. It is currently the only way to run Python on shared hosting.
You know there's at least *three* variants of the Pickle format, right? And it defaults to the least-efficient, text-only output? I imagine Pickle might do a little better if you passed `protocol=pickle.HIGHEST_PROTOCOL` to `dumps()`.
protip: don't write apps to the CGI API. even if you have to deploy under CGI, write a WSGI app and run it with flup or whatever (after explaining to your boss how goddamn slow it will be).
I got bored, and decided to write a simple script that would act as a transparent http proxy, flipping all images that it proxied. It also allows you to run a DNS server to route all the hostnames to your computer. Simple usage: 1. Run script with DNS server, listening on port 80, using a custom resolver to a legitimate dns server 2. Modify your router's DHCP settings to set your computer as a DNS server. 3. Profit as you annoy everyone on your network. (http://i.imgur.com/ERsre.jpg) Obviously, this is just a gag, and will piss off anyone trying to reach anything that's not on port 80...
But this is just documentation? Can you extract code from Sphinx docs into a runnable program?
I'd be interested in this too. For C I use noweb but it's difficult when mixing up code and documentation to track formatting of the code blocks as they fit together so I've been hesitant to try it for Python, but [apparently it can be done](http://www.python.org/workshops/1997-10/proceedings/zukowski.html#NWD2). Noweb is pretty awesome, has an emacs mode with interacts nicely with Autex, which I think is a very nice mode, it supports latex of course but you do have to run pdflatex yourself, I usually just make a simple makefile that tangles, weaves, convert and compiles in one command.
Yes, but not from the child thread. Flag in parent process, child thread only reads, parent process only writes. You may be saying this but I can't tell. :)
short answer no , migrate to firebird :)
I wish I could be this helpless.
It depends on what they do, but nesting loops naturally leads to polynomial time algorithms in most cases.
This is the best answer in the whole thread. OP has not even clearly defined 'stable' to himself, let alone us.
If you don't handle events, the app can't know where your mouse is. Events are how the operating system tells the app where the mouse has moved to!
CGI is fine so long as you're not trying to serve a large number of connections per second. Have a look at 'bottle', though, you might like it. Very minimalist. The IP address thing is maybe a bad idea though ... every now and then you'll find a single user who keeps flipping back and forth between a couple of addresses due to proxies. 
well, the thing is, I'm not doing anything with the events: I'm just flushing the event queue. So I don't understand exactly what is happening here: does pygame need to call pygame.event.get() to update the position of the mouse ?
Using sphinx behind the scenes, you can use [Pweave](http://mpastell.com/pweave/). I guess that by the name you'd have guessed that it is an equivalent of sweave. It converts stuff to sphinx ReST, so you can convert things into HTML, latex, etc.
Learn Bottle.py or Pyramid.
When you get the event from the queue, it handles it internally, as well as giving you the object to do whatever you want with. If you don't want to do anything with the events, just use the pump() method so it can do its internal management. http://pygame.org/docs/ref/event.html
that's not a subreddit, its a page from afpy.org ...
http://www.reddit.com/r/PythonFr/ here's the subreddit link
That first screenshot should really be captioned, "How NOT to use UltimateListCtrl". It's just hideous.
I just want **record** reimplemented in TortoiseHg
the afpy page is because I have added a CNAME in the options of the subreddit. so we have a neat reddit.afpy.org (afpy.org = french python user group)
It embeds an iframe to reddit. That manages to find my login, though there is no subscribe button (might have to do with the clickjacking potential of iframes). 
merci.
ah well. Maybe using that feature is not the best idea. I had some weird behaviors too
I use mouse.get_pos() for _drawing_ cursors, myself. mouseup/down events for clicks, sure. I have no idea why, though.
Yes, I think the nice thing about Sweave is that you don't have to move the output from the interpreter and the actual figure path to the document yourself (though you can if need be). This actually looks great -- thanks for pointing this out.
I started in ubuntu also, I would highly suggest you check out fedora. I am very happy with how up to date their packages are and yum is quite easy to pick up.
I've packaged a program that uses sqlite + SQLAlchemy with py2exe. It was easy. I've packaged a program that uses PyGTK + Twisted with PyInstaller. It was easy, once I found the right docs. So it's a viable goal. I personally like PyGTK a lot, and it does play very well with Twisted, but it's a time of transition in the PyGTK world (PyGTK has been end-of-lifed and its replacement PyGI isn't really ready for prime time yet), so it's not the easiest time to pick it up.
Obligatory Flask Mention!
I've had some small indentation errors, but honestly, even VIM fixes them for you (and generally does a good job of it). Python isn't the perfect language, but I don't think that indenting blocks is the chink in the armour.
record should be in all mercurial GUIs.
"Chief sumo?" You should refer to yourself as "the Yokozuna."
&gt; even VIM fixes them for you That isn't possible, and you should know it. Two syntactically correct Python programs, with different purposes, will have different indentations to reflect their different purposes. Without block tokens, an indentation algorithm cannot know what was in the mind of the programmer, and it would be foolish try to to second-guess him. &gt; Python isn't the perfect language, but I don't think that indenting blocks is the chink in the armour. Only for students, which was my original point - people with little experience, and while using a plain-text editor that won't catch obvious errors for them. For people with programming experience, this is not really an issue. But again, an editor cannot possibly "fix" indentations in Python. In most languages the indentation might conflict with the block tokens, so it can be fixed ("beautified") deterministically. But in Python, the indentations *are* the block tokens. All an editor (or a "beautifier" algorithm in an editor) can do with Python source is find cases where the indentation doesn't follow the general pattern of indentation -- five spaces where multiples of four is the norm, for example (which is how [my Python "beautifier"](http://arachnoid.com/python/pybeautify_program.html) works). But it cannot possibly locate indentation errors, because there's no such thing. I'm sure you were just not thinking about this deeply enough. Yes? 
Django
I'm sure that I was expressing what works for me. Highlight the troublesome block (denoted by the error) and hit '='. It's simple and works most every time (for me). And when it doesn't, the results are quite obvious. As for five spaces, that's simply wrong. Like an improperly leaving off a curly brace for multiple expressions following a 'for' statement in C. The code may function, but doesn't follow convention in Python. Further, additional spacing becomes increasingly obvious when one uses a proper mono font, which should be necessary in programming. This is particularly true in larger blocks of code of the same depth. Perhaps you have an express bias against significant whitespace: &gt;&gt; I regard this as an abomination... And perhaps I read enough poorly formatted C to enjoy enforced block indentation of code so I'm biased towards whitespace. I have no trouble discussing the issue with you, and understand that we may not be discussing the same points, but there's no need to deride or show a lack of respect, yes?
mouse.get_pos() isn't guaranteed to get the right position unless you pump the event queue as well. Some implementations might implement mouse.get_pos() via a direct poll of the device but others might require the movement messages to work. Look at the newest comment in the docs here: http://pygame.org/docs/ref/mouse.html#pygame.mouse.get_pos Notice how the commenter sees his mouse position not changing, and how he's not polling for events? That's no coincidence. :)
I wonder where did you get your idea from http://www.ex-parrot.com/pete/upside-down-ternet.html :)
&gt; json in a text field You, sir, need some NoSQL love. It is very easy to get started with MongoDB.
Can someone explain why I'm getting downvotes? I only just heard of this subreddit, and I looked at the rules in the sidebar and I didn't think I broke any of them. I'm learning python, and I asked a question about learning python, yet I didn't get much help. I got downvotes instead.
&gt; As for five spaces, that's simply wrong. Yes, and as such, it's the only thing that a Python syntax checker can correct. But if the programmer wants to use five-space indentation, the editor can only compare one indentation with others. Python doesn't care (and shouldn't care) which specific indentation is in force as long as it's consistent. &gt; I'm sure that I was expressing what works for me. Highlight the troublesome block (denoted by the error) and hit '='. It's simple and works most every time (for me). And when it doesn't, the results are quite obvious. This is absolutely false. VIM CANNOT "correct" a syntactically correct Python program. Two Python programs with different purposes have different indentations (actually any number, not just two). The editor cannot know what was in the mind of the programmer. Program 1: import sys for y in range(1,13): for x in range(1,13): sys.stdout.write('%4d' % (x*y)) print '' Program 2: import sys for y in range(1,13): for x in range(1,13): sys.stdout.write('%4d' % (x*y)) print '' How can an editor possibly decide on its own that the programmer wants this output: 1 2 3 4 5 6 7 8 9 10 11 12 2 4 6 8 10 12 14 16 18 20 22 24 3 6 9 12 15 18 21 24 27 30 33 36 4 8 12 16 20 24 28 32 36 40 44 48 5 10 15 20 25 30 35 40 45 50 55 60 6 12 18 24 30 36 42 48 54 60 66 72 7 14 21 28 35 42 49 56 63 70 77 84 8 16 24 32 40 48 56 64 72 80 88 96 9 18 27 36 45 54 63 72 81 90 99 108 10 20 30 40 50 60 70 80 90 100 110 120 11 22 33 44 55 66 77 88 99 110 121 132 12 24 36 48 60 72 84 96 108 120 132 144 -- and not the syntactically correct alternative that prints one number per line? &gt; but there's no need to deride or show a lack of respect, yes? Point out where I have done this. If I had not said "... and you should know this", the absence of that comment would have insulted your intelligence. I have no such intention. &gt; when one uses a proper mono font, which should be necessary in programming. I certainly agree with this. Not our topic, but I agree -- and no tabs. We recently had a case here where a Python program read one way in an editor but executed in a different way, to the frustration of the student programmer. It turned out that there was a tab hidden in the source that was being interpreted one way by his editor, but another way by Python. Another case where whitespace undermined the programmer. 
You should most likely use the **json** module unless you want backward (previous Python 2.6) compatibility.
Hmm well I'm using an API called Tweepy and that is what is calling simplejson.
Let's all meet at one place.
In that case, you should contact the author of that library with your problem.
Cool. Alright. I'll keep letting VIM fix my indentation and you can keep telling me that it can't be possible. I don't use VIM to correct syntactically correct indentation, why would I? It's no longer a spacing issue, it's an issue with inclusion of statements into one block or another. I understand what you're saying, and your example is apt, but the reality is that I rarely run into those issues. Just as I don't ask my editor to correct such things in C, I rely on myself to place expressions in the correct block in Python, or I stick the curly brace where it belongs to express what I wish to express. &gt; I'm sure you were just not thinking about this deeply enough. Yes? There. That was the statement that shows a lack of any respect, no matter disagreement. The very fact that I don't think of the issue in the same way you do doesn't mean I didn't bother to think about it. I simply believe that you're attributing to significant whitespace issues that can be more validly attributed to other issues. They're still issues, sure, but we differ in our opinions as to what to blame. &gt; It turned out that there was a tab hidden in the source that was being interpreted one way by his editor Then don't mix tabs and spaces. Then use a decent tool that doesn't have these issues! Do you wear rubber boots with holes in them? Me either! They don't work!
Okay, will do. How should I explain it? That simplejson is deprecated?
You're exactly right. I really just wanted to see how easy it would be. This one allows you to do it with out running the dhcp server on your computer, or use squid.
Yes. But it should still work regardless. Pro hack, put it at the beginning of your script. import json, sys sys.modules['simplejson'] = json I think simple json and json share the same API.
If you actually studied, you wouldn't need a cheat sheet. 
Write down any syntax that you felt like you needed to look up when doing any coding projects. Maybe write up sample algorithms of various runtimes for complexity analysis (thinking up the samples will help you study, too). Write down some code that you know works, so you can use it as a reference if you forget some small syntactic things during the test. If you don't know the concepts, notes won't help, but if you're worried about forgetting exact details it can really help.
This subreddit is not meant for shit like this. Please do everyone a favor and delete your post.
Why disable UAC on Vista/7? 
nein !
simplejson has a C extension to speed up its operation, and it's [actively maintained](https://github.com/simplejson/simplejson). I would prefer it over the standard library's json: try: import simplejson as json except ImportError: import json 
Learning C/C++ will teach you about memory management and compiler-related things. It's definitely both useful and challenging. It's also nice because [you can write python modules in it](http://docs.python.org/release/2.5.2/ext/intro.html), so you can easily write projects that integrate both languages.
How about the [Python cheat sheet](http://www.addedbytes.com/cheat-sheets/python-cheat-sheet/)? Good luck! Edit: [Here's](http://devcheatsheet.com/tag/python/) a few more to choose from.
Seconding C for something useful. Try Scheme for something that will expand they way you think about programming: http://mitpress.mit.edu/sicp/
Do something completely different. Like Haskell.
I recommend both C and Haskell.
Web.py or Tornado (Similar to Web.py but with a load of other asynchronous goodness) Django is OK, but I find it moves too far away from Python, you end up writing 'Django' apps rather than 'Python' apps, Web.py both supports WSGI so it's pretty trivial to get an app set up with Apache, Tornado uses it's own event-loop based server so you'd probably want to stick it behind NGINX.
As mentioned, C is a good language to get down to the metal in and understand how things work at a low level. You can also extend Python with C modules. If you like developing games, Python is good with frameworks like PyGame. Lua is also a very popular languages for scripting games - it's C-like and quite fast, but higher level than C itself. It's easy to hook into existing apps for scripting purposes. If you're into web programming, learn Javascript. Good for frontend and playing around with Node. If you're looking at expanding your programming horizons, I would look at a functional language like Haskell or a Lisp (clojure, scheme) to gain the ability to look at problems in a different way. You can apply _a lot_ of what you learn in a functional language to Python!
I'd recommend C.
I recommend checking out [Practical Common Lisp](http://www.gigamonkeys.com/book/). It's a great (and free) ebook that totally changed the way that I thought about programs. It won't take very long to work your way through it, either.
any support for vim keybindings? aspects of spyder sound appealing, but i need me some vim.
C or SQL. SQL's not really a "programming language" in the purest sense, but becoming proficient in at least one major database's SQL dialect is definitely useful for working with datasets large or complex enough to store in a relational database.
That would be pretty nice.
it's my problem with any ide i come across. lack of vim keybindings is a dealbreaker for me at this point. hell, i use abiword for regular document handling if it is anything requiring any amount of time + formatting that can't be handled by vim because it has limited vim keybinding support.
Yes, thats what it is. I got the idea from Pyro which is a TCP based server that does not really support SSL connections so is insecure to use over the web. As well I wanted to be able to host it on any webserver. This started from a project where I needed to have the server do much of the work but I still want native Python objects.
Well, I'm only gonna answer from my perspective, generalising to the rest of the developer workforce isn't really my forte. That said, I would say generally that I'm the kind of guy you'd like to hire (except for the moving requirement). At my level, I'm interviewing you as much as you're interviewing me, and I'm looking for the answer to a number of questions: 1. Is the location ok? 2. Is the money right? 3. Am I going to be happy? Ignoring the top two because I'm not even in the right place or available, the last one is important. When you say "no quadruple-screen-only programming divas please", what I hear is "We tell you what tools to use". This is frustrating, I don't mind aligning myself to your work process, but some of us are just big-monitor people. I'm not a programming "diva", I'm simply good at a lot of things: * I can write code from kernel drivers up to client-side web apps * I can spec, order and build servers from components * I can install, secure, customise and manage linux systems * I can operate Juniper SRX and ScreenOS firewalls and Cisco switches * I can set up cloud services and provide maintenance, security and monitoring * I can run packet dumps on your VOIP solution and replay your calls to you * I can understand designers, I know about kerning, alignment and contrast and why they're important. * I can do pen-testing, I present well to clients, I can advise on a wide range of technical issues, I have strong networks to other capable individuals, I can do technical evaluations, write documents, build demonstration and technical mocks, manage other coders and testers, the list just goes on. I'm a startup veteran and when push comes to shove I can fulfill almost any technical role where there's a weakness and make it work. But I can't tail logs and write code at the same time on a tiny laptop. I can't fire up a VM and compare design outcomes on IE8 and Chrome and Firefox and Safari easily on a tiny laptop. I can't...the list goes on. More pixels is better, more efficient, my eyes move faster than my fingers. By making some bizarre assumption about the usefulness of screen real-estate to me, you're basically telling me you want someone who is not adaptable, not familiar with a broad range of technologies, and when things come to a massive crunch and you find yourself trying to work around some vendor-generated madness the night before launch, you want me spending all my time switching windows instead of getting work done. My kit is worth $10k+ easily, I am a highly experienced professional developer and I use professional gear. I can do work on a tiny laptop screen if needed, I have a macbook pro for that, but I'm going to be *slower* and you're going to be paying money for me to do nothing but wait. That's just stupid, and wherever possible I don't work for stupid. Finally, after reading the rest of your ad the truth is you're conveying fuzzy thinking. I don't like this, you're writing an ad where it isn't clear what you want, you're not conveying details well, and you appear to have irrational and self-harming prejudices. From reading that, I worry that when I join up with you and you start putting together spec for some feature, you're going to hand me a bunch of useless fuzz. I want to work with people who a brilliant thinkers, not fuzzy thinkers. I know vision people can be big picture and that leads to a lot of holes, but if you want to hire someone like me then you need to get someone else to write your ads, someone who understands that details are really important to me. You need detail people just as much as you need big picture people, and right now you seem to be acting as if that isn't true - as if you can just fuzz your way past problems. As for culture, you're talking to the wrong guy. I don't give a shit if you're happy-go-lucky or whatever. You be who you wanna be, but if you think your culture is more important than creating a great experience for your users, then I have no interest being involved. I will work my ass off to make you successful, and I'll hang out and play pingpong if we've got time, but when push comes to shove I am all about the product, the service and the users and I don't give a rats about anything else. 
You need a few years in the trenches before you start to see (or at least worry about) the uncountable and horrible ways any single line of code can break, and to value defensive programming. This is also why programs should be short. This is one thing that Java did well. Checked exceptions are a royal pain in the ass, but if you think about what it means that this harmless method you call can throw an IOException, you see that we make unwarranted assumptions all the time. Such as _"I can write a line of text to this file and my program won't terminate because of it."_ News flash, the universe is a cold and unforgiving place, disks can get full and if you don't catch the exception your "unreliable" program will spit out a stack trace and die.
Honestly the issue I have is, having "vim keybindings" is better than nothing, but then I just wish I was in Vim the whole time..
Javascript is pretty cool when you learn how to chain protoypes. 
Haskell
Downvoting C++, that is a tarpit crossed with quicksand. Everyone should know C. Refuse to say the same for C++, and C++ isn't C incremented by 1.
Dutch. 
Upvoted for C. C++ is... nope, not going to finish that sentence. Learn C, don't learn C++ without a specific reason. 
downvote for haskell... could never understand that shit for the life of me. And it's entirely theoretical-- what could the OP **do** with it?
Start functional programming in Python. That's what I did after learning Scheme. And a powerful type system is kinda fun... "Java, I said powerful, not retarded".
If the question was for Ruby, Japanese would *actually* be a good idea.
C++ means "increment C by one and use the original value"
You should explain why, especially in a thread where people are trying to learn about languages. I don't even disagree with the claim, but you'll get your voice heard better.
Seconding Scheme here for the same reasons. It was the first language I learned and I've always been glad I did.
This is ridiculous groupthink bs. Knowing C++ opens up so many high quality libraries. I agree c should be higher on the agenda but c++ is still a tremendously useful language to know. 
Linus Torvalds says C++ is bullshit and suddenly every other programmer out there is bashing it to shits. Funny coincidence, I'd say. You should give several languages a try, just to get a contrast to python and see how things are done elsewhere. I'm no expert programmer, but I've done Python, Java, C, C++, C#, PHP, Perl and Javascript, and feel like every language has expanded my vision in one way or another.
HTML
Suddenly? You haven't been in /r/programming very long have you?
C++ is one of the hardest and ugliest languages, I say this a C++ programmer. I would also recommend C. And Objective C. However, here's my waring: If you ever *have* to learn C++, it will be much harder if you already know C or any C and C++ like languages. So I guess what I'm saying is, C++ is like a dare. Do you dare to try and learn C++? 
Nope, sorry. I'm the new guy, and like said, not an expert. All I know is that there are a lot of elitist geek pricks out there who criticize everything about everything, and Python is probably the only language I've never read anything negative about.
Can you give a quick reason why? C seems so.. convoluted and full of "magic functions." I don't know enough about either to say one is terrible, but I don't understand what the problem is with C++?
For useful: learn Javascript, or better yet Coffeescript For challenging and forces you to think in a different way, learn Haskell Python doesn't force you to check the types of your variables. If you learn Python and then Java, you'll think that strong typing is idiotic and thank goodness Python frees you of it. Haskell does strong typing *right*, and it's well worth wrapping your brain around.
There's basically three main programming paradigms, procedural, object-oriented and functional. Everything then becomes a matter of syntax after that, which is the boring part. Python can actually do all three to various extents. C is an obvious choice - well-known and in common use, its procedural, and the primary Python interpreter is both written in and can be extended via C. If there's some part of your Python program slowing down your Physics calculations, chances are you can rewrite the slow bits in C to overcome that obstacle. Another option particularly if you have more of a maths brain is a functional language like Lisp, Scheme or Haskell. The language itself has nothing to do with Python, but comprehending the functional programming methodology can help make your Python programs more readable, e.g. you'll use list/dict/set comprehensions instead of nested for loops. One easy, practical way to get into Haskell is to run Xmonad as your window manager on an X11 box, it's totally written and hence configured in Haskell. 
I really appreciate the ideas behind Haskell, but the blatant abuse of operator overloading that goes on (particularly if you're working with xmonad) has always put me off it. Are there any similar languages which don't have this problem? OCaml maybe?
Wow, a bunch of downvotes and no explanation. I don't feel javascript is a good *complement* to Python because they're so similar. List and dict syntax are virtually identical, closure-scoping, passing around functions, and (gasp) monkeypatching work similarly, etc. The biggest differences, as you say, are prototypal inheritance and the way anonymous functions are frequently (ab)used.
Oh, there are bad things about Python. It's interpreted, so refactoring is a pain, and there are some really silly errors which don't get caught which would be caught if you were using a strongly-typed, compiled language. As long as you're under a couple thousand lines of code, you probably won't have massive problems, and the many benefits of Python will heavily outweigh them, but for larger projects - or projects where I am working with multiple people - I definitely prefer a compiled language. C# tends to be my weapon of choice for those, though I've done group projects in C, Java, PHP, Javascript, and a couple other things before. That said, I love Python.
Skimmed the first chapters, book looks awesome, thanks!
Javascript is pretty cool when you realize that a) you almost never need inheritance in duck-typed languages*, so stay away from it, since it's a hack in Javascript, and b) it is actually a functional language in many ways. Also, objects don't need classes. *It's odd, actually. I can think of several places where a duck-typed object system could use inheritance (mostly code sharing), but in practice I've never run into them.
I think it's a great complement because HTML with Javascript is an awesome front end for Python programs. Just make a path with Bottle or CherryPy, and you got a SaaS going.
I'm not sure what you mean by "magic functions". Do you mean things like "printf"? If so, that's just part of the builtin library, which every language has, more or less. If perhaps you mean things like printf accepting different number of arguments, that's a standard part of the language, if slightly esoteric. I recomend learning ANSI C rather than K&amp;R C. I like Harbison &amp; Steele's book, but that's a good specification, perhaps not a good primer. Let's see. The most important thing I ever learned about C is that it doesn't have arrays, it has pointers and preallocated sequences. Once you understand that, which I probably haven't helped much, you'll avoid many pitfalls. I realize I haven't answered your question. I don't really want to get into the problems with C++. Perhaps it helps to mention that 99.99% of C programs are legal C++ programs, which means C++ has all of C's flaws and complexity and then layers its own on top. PS: Both C and C++ rely on the "C preprocessor", which is huge problem in it's own right. 
&gt; I'll keep letting VIM fix my indentation That's not what you said. Here is what you said: &gt; Highlight the troublesome block (denoted by the error) and hit '='. You're shifting ground, now that I have explained that only indentation errors are correctable, not program errors. And I already covered that ground -- the only indentation errors a program can catch are those that involve using something other than a multiple of the agreed indentation value, not the wrong indentation for the program's purpose. Your claim was the VIM caught program errors -- it cannot do that. You are deliberately clouding the issue. &gt; Then don't mix tabs and spaces. Okay, enough. You can't seem to stay with a given topic. Obviously what I described would have no effect in a language with block tokens -- that was the point. The original topic was students, people who might not recognize the problems created by tabs -- or whitespace in general. 
I feel like learning C or C++ wouldn't be as cool unless you were using it for an embedded system or something. Learning how stacks and heaps work is great (and actually pretty important to know), but writing programs with it is such a chore. I switched to Python because it's fun to program, but I can't deny the fun and awesomeness of embedded systems.
I'm just going to point out that knowing languages has little to do with taking MS courses, completing a PhD, or algorithms (well actually there's certain cases where languages and algorithms intersect, specifically with FP) unless the specialization is in languages.
Just for your reference, that is not the purpose of the downvote arrow. See: Redditquette. 
&gt; I want something that will be useful, challenging, and **forces me to think in a different way than Python does.**
Try GO
You should play around with a lot of languages, but since you asked specifically about **complementing** Python: - **C** - as others have noted, this will get you closer to the metal, and since it's what's the main Python interpreter is implemented in, you could conceivably hack Python. Python also interfaces with C nicely, so if you need more performance you can write parts of your app in C or use C libraries/etc. It's a really elegant and simple language. **This is my top pick** - **JavaScript/HTML/CSS** - This will allow you to write web-apps with Python on the backend and JS/HTML/CSS on the front end. Yes, JS won't be a huge departure from Python...but it definitely will teach you some unique things. **Second Pick** ** Runners Up:** - **Clojure/some Java** - Lisp will change the way you think about programming. Clojure is a very modern and practical Lisp. You don't need to learn Java to learn Clojure, but it helps and if you learn some Java you can leverage that when working with Jython. - **Haskell** - Haskell is a really interesting langauge. It will bend your mind in ways different from Lisp. The strictness will be an interesting departure form Python. The declarative style it enables can be a lot of fun. - **F#/ somce C#** - F# is a .net language, but it is fairly open and available on Linux with Mono and Mono Develop. It's in the ML family, and it's interesting because it is a multi-paradigm language. Like Clojure on the JVM, the fact that it runs on the CLR makes it very practical...allowing you to leverage a lot of existing libraries etc.
This is incorrect, I, like my brother, learned c before c++ and it was really easy to pickup. Knowing C, made learning C++ easier. Most of my C experience is under gcc and embedded systems. Also, Objective-C is a terribly ugly language. I'm not disagreeing that C++ is ugly though. I'm not saying to disregard Obj C, just you have to see that it's just as ugly as C++.
Completely off topic, but doesn't it just seem natural to *downvote* Dr. Hank Pym? (I didn't actually downvote him, though. Javascript seems like a reasonable choice.)
ocaml
R. Great for statistical and data analysis.
Another vote for Haskell, much much rather than Lisp.
&gt; If you ever have to learn C++, it will be much harder if you already know C or any C and C++ like languages. Why is that? I haven't learnt C++ yet, but my understanding was that it was C with classes (and other things like multiple inheritance, etc.).
C and Haskell.
surprised there isn't more SQL. certainly not a "programming language" but necessary if you ever plan to interface with nontrivial data
Honestly the things that scare me, and what I called "magic functions", are things like: static CYTHON_INLINE size_t __Pyx_PyInt_AsSize_t(PyObject*); What the fuck is a size_t? Note that this is just the first .c file I could find, and it's a python module so it also has things like PyObject and Py_ssize_t. This kind of thing makes me very nervous about C.. it seems like it's full of all kinds of magic types (which, I don't even know how you create in a non-object-oriented language? Are they structs maybe?). There are many others that I'm having trouble finding examples of right now.that seem to come from nowhere. They probably come from some library I don't know about, but it's hard to tell Basically, when I look at C code I can't make heads or tails of it because of so many weird types and functions when you're new to it :) edit: oh, and what the hell is CYTHON_INLINE? Why does this function seem to have two types? Maybe it's some type of preprocessor directive? 
Came in here to say that.
Exclusive file locking could solve the first problem. But if the file contains all the accounts, you wouldn't want an exclusive lock on the entire file each time you do one transaction for one account. (And, obviously, you wouldn't want to open and read such a large file for each transaction.) 
size_t is the data type that is used to represent "object" sizes. It is architecture independent and is ultimately mapped to some real numeric type, like unsigned int. CYTHON_INLINE is a macro that probably expands to "inline" or "". Meaning you can choose whether the function is spit out inline in the code or not after preprocessing. this is just a guess. static in this context means that the funtcion is only visible in this particular file, and nowhere else.
Is there a reason you need the JSON format? If not, I suggest just [pickling](http://docs.python.org/library/pickle.html) the data. 
I don't know if Python's spoiled me, but whenever I look at C++ code now, I'm almost disgusted. Certain tasks require such convoluted code. Function pointers, for example: C++: void myFunc (int x) { ... } //If the parameters ever change, you have to change this call too. void (*funcPtr)(int) = &amp;myFunc; Python: def myFunc(x): ... f = myFunc On the flip side, I do love how finely tunable C++ is compared to Python. I know I'm probably contradicting my point but sometimes the things you can get away with in Python almost makes you feel like you're cheating. edit: I do have to give C/C++ credit for giving me the memory/data management discipline that's so easily disregarded because of automatic garbage collectors and whatnot. 
Oh come on! -- a complement should show you different concepts, make you use different parts of your brain, show you something different about computing. Assembly language, people! Learn how a list or a dict or an exception handler is actually implemented. What it means to actually manage memory instead of having it magically tidied up when it goes out of scope.
Ahh, I actually assumed I knew what static meant, but I was thinking of the static that makes a class method callable on the class itself (rather than an instance). Is there somewhere I can learn about those things? And the other weirdnesses that real C programs use? Is it more that I'm just a complete noob and reading a book will introduce me to many of these libraries?
I for one hated C++ before hating C++ was cool. 
You're thinking of the difference between static and dynamic typing. Python is dynamically typed, but also strongly typed.
the static *could* mean that, hard to tell with this line in isolation. If it's inside a C++ class, then your assumption would be correct. For all C-only related topics, nothing beats this: http://www.amazon.com/Programming-Language-2nd-Brian-Kernighan/dp/0131103628 
If you're thinking of a masters in CS, most people would recommend learning a low-level language like C to gain an even larger understanding of memory management. C also gives you the unique ability to pull your hair out AND shoot yourself in the foot, all at the same time!
Ah no, in this case it's not inside a C++ class, I believe this file is pure C. I just didn't even realize "static" existed outside of C++, it's interesting that it means something different. I will look into that book, ty!
&gt; If the parameters ever change, you have to change this call too That's really just a feature of strong typing, though. It's a good thing, even if C++ doesn't express it well.
No, I'm not shifting ground. That's exactly what I do in VIM. Python tells me I have inconsistent indentation, so I let VIM fix it just as I prescribed. Jesus fuck, do you want me to make a video of it? This is exactly what I do: v (visual) } (until block is highlighted) = It's just that simple. Indentation errors, and only indentation errors, are magically gone. Poof! Except for where VIM guesses incorrectly (rarely) and I have to hit a whole two buttons to fix it (&lt;&lt; or &gt;&gt;). I'm not claiming that VIM catches my programming errors (though it does with lint (syntax errors)), I'm saying that it fixes my bloody indentation inconsistencies that may not be otherwise obvious. I'm not clouding the issue as you claim, I'm correctly attributing the blame that you desperately wish to pin to significant whitespace. Why? I don't bloody know, you already proclaimed your bias. Aside from the hidden tab (shitty editor error, not Python's fault), the same exact things can happen in any other language: including code in the wrong block. You'll cry "shifting ground," but the question is tangential: many students have difficulties conceptualizing recursion, is that a bad feature? If your students have an issue with whitespace, teach them better, mine do not. I make it clear from day one that whitespace is significant and the means by which blocks of code are set. Most enjoy this feature, others pine for their curly braces, none struggle with the concept. These are students that struggle to produce the 'fizzbuzz' program. And they get it. So! I'm sorry that I didn't explicitly say that it corrected inconsistent indentation and not semantic errors. I just seems so ridiculous to think that anything could correct a semantic error that it didn't seem worth noting more explicitly. Also, the sky is [generally] up.
And there are some definite benefits to strong typing.
Yeah, I do appreciate that about C++ as I've mentioned but sometimes it can get out of hand, you know?
static has *three* meanings. Only one is C++ only, which is what you're talking about. In both C and C++... For variables and functions declared *static*, it means they have file scope. If you are inside of a function, and you declare a variable as static like this: int foo() { static int bar = 0; bar++; printf( bar ); } then everytime you call foo, it will print 0, 1, 2 ,3 .... it remembers from the previous time. Note that the initialization to 0 only happens the **first** time the function is called. *static* is an abused keyword, that's for sure!
Static typing can be awfully nice. I went from C++ to Python a few years ago, and now I'm getting into Scala. Type inference definitely makes static typing more bearable. 
Oooh You're right! I actually knew about that usage too, but had forgotten it. Well ty again for the help :) I guess I'll try to get a copy of that book.
In order of natural progression from current position. Not in order of relevance: Cython Go Haskell
I just wrote a ray tracer in it. OP could write a ray tracer.
&gt; my understanding was that it was C with classes (and other things like multiple inheritance, etc.) That's the old way to think of C++, and is the way that is likely to lead to memory management hell. Unfortunately, many C++ books and courses just sort of bolt OO and so on onto elementary C. If you learn arrays and pointers in C++ before learning how to manage your own class instance data members, you can easily end up with buggy habits. The key difference between C and C++ is that allocating memory in C++ also initializes it by calling constructor functions. Well, if the memory is for a primitive such as `int` or `double` or `char`, it doesn't get initialized, but it does get initialized for anything else. So, even just "declaring" a non-primitive variable `x` on the stack in C++ also initializes it with a constructor function. Let's say the constructor function allocates (and initializes) some memory on the heap, such as with a dynamic array allocation. Your `x` has no control over that memory on the heap. That's *good* in C++. But whoever wrote the class which allocated the heap memory had better make sure the class knows how to clean up itself when your `x` goes out of scope. Edit: Another important difference between C and C++ is operator overloading. Almost everything you do in C++, even if it looks quite C-ish, automagically calls one or more functions under the hood. Even dereferencing a pointer can cause a function to be called. That's another reason to defer learning about arrays and pointers in C++ until you start to get the hang of defining your own classes. 
In my few years of studying computer science, it's that the "elitist geek pricks" are the ones you have the most to learn from. I hope to be one myself some day.
Do. It's a wonderful book. 
Well, C is also very useful if you ever want to work on the linux kernel or to interface with parts of it. In general it is very useful for doing low level work. I think that is why it is a great compliment to python.
C++ typedefs also make static typing more bearable, but in a different way. (Just sayin'.) 
web2py includes a Bayesian classifier (to populate database for testing) that works exactly as you describe and can be trained on arbitrary text. This is the source: http://code.google.com/p/web2py/source/browse/gluon/contrib/populate.py Here you can see some generated text (for fun, makes no sense of course): http://web2py.com/textgenerator 
That's a feature of static typing, not strong typing. Python is dynamically and strongly typed. C++ is statically typed and more strongly typed than C. 
The type system of C++ isn't particularly strong either. 
Sorry for the drive by but I didn't have time to elucidate my bumper sticker. The complexity cost to payback is too large to be an auxiliary language for Python. While being able to parse, fix, and use C++ libraries is an important skill (far below what I consider being fluent in C++ would me), I wasted too much time in C++ before moving on to a better abstraction stack. C is amazingly powerful and compact. One can get reasonably skilled in it in a short amount of time. It is a shallow language. The same cannot be said for C++ and energy spent learning C++ could be better spent learning Haskell, Ocaml or better structuring existing applications to use the right mixture of low level and high level code.
Python is also duck typed!
Thank you for asking this question and thank you everyone else for great responses. I found this thread very useful.
Prototype is a huge difference; the rest of the stuff you listed is syntactic sugar.
Disabling UAC is just needed for the stand alone version. Most people on Windows install it along with python-(x,y) I can't really tell why UAC has to be disabled. I haven't used Windows in a long time.
There is an open issue for that but there are not plans to implement it anytime soon.
A size_t is an integer suitable for storing the size of something (often something systemy). It's defined by some kernel-ly header ("interface"-ish) file if I recall correctly. C has a concept of aliasing types ("typedef") that is absent from most of the other languages with which I'm familiar. It's a pretty nice abstraction once you understand it and its limitations (primarily that the new name is *just* an alias rather than a sub-type). I have no idea what CYTHON_INLINE means. It's not typical C. Best guess (but just a guess) is that it's really a directive to some Python integration tool, which is pretty close to your guess but that might just mean we're both wrong. I strongly suggest you find some C code that does regular simple C-like things, not parts of Python. I'd point you at some if I knew of any, but that's not where I've worked for quite some time. 
Yeah, but low level work is *boring*. I'm curious, how often do you guys write in C? Is that really your second favorite language?
So..... how'd it go?
Learn a functional language - Scheme or Haskell
To help wrap your head around Haskell, I definitely recommend the [Learn You a Haskell for Great Good](http://learnyouahaskell.com/) book. It's aimed at people who have programming experience, but lack experience in a functional language.
sh.
&gt; JS won't be a huge departure from Python Why do people keep saying that? It's prototype-based and event-driven. If anything, C is not a huge departure from Python.
The native json module also gained a C extension version in Python 2.7. simplejson is much faster than built-in in 2.6, [but that appears not to really be the case in 2.7+](http://j2labs.tumblr.com/post/4262756632/speed-tests-for-json-and-cpickle-in-python). There are also other third-party json modules, like [ujson](https://github.com/esnme/ultrajson), that are faster than either.
You can extend python with c and c++. Alternatively, you can embed python within a c or c++ program. Python was developed originally using C. Frankly, if you need speed, you should look at what you can develop in c or c++. If you don't have an issue with the speed, then use python. One caveat, though... Python is going to get slower and slower until either the BDFL decides to allow an implementation that doesn't reference count (or does it differently) or PyPy becomes the default implementation. Right now, Python doesn't really run any faster on a multicore processor than it did on a single core processor. And this is a growing issue since within just a few years, we're probably going to be running almost everything on a multicore. C and C++ give you a fine enough control you can get around that problem, though it's still a heartache. All that said, it really depends upon your domain and use. C and C++ have a lot of headaches associated with them because it's a compiled language. There aren't that many languages
It was removed from TortoiseHG. http://permalink.gmane.org/gmane.comp.version-control.mercurial.general/25431 I haven't checked the latest version though.
Marking a function static is actually far more complicated than that when inline is involved (which is what the CYTHON_INLINE macro expands to if so configured.) Remember that C is compiled a file at a time, and the compiler only ever knows^[1] about what's in the current file, never about anything outside of it. If you mark a function as static, it means that the function cannot be called from outside of that file, which implies that the compiler has at its disposal every call site. If there is only one (or a small number) of call sites, then it can choose to instead inline the function at all call sites and pretend it never existed (i.e. not emit a function body.) This is generally extremely desirable, because it means you can separate a large function into a smaller function and a bunch of helper functions, but without any of the overhead of function calls. Without 'static', it could still inline the function but since it has to be visible in other compilation units it would have to always emit a function body, even if it was never needed, which wastes memory. But also note that with 'static inline' the choice of whether to inline is still up to the compiler. If there are many call sites or the function is long, it will choose not to inline it and still emit a function body, but one which is not visible to other units. "static inline" is actually one of three related declarations. "inline" and "extern inline" are the others. They all have slightly different meanings, [which this post outlines](http://stackoverflow.com/questions/216510/extern-inline). To make matters worse, gcc changed its semantics starting with 4.3 to be aligned to what the C99 standard says, so if you're compiling with `-std=c99` or `-std=gnu99` with gcc &gt;= 4.3 you get true C99 semantics, but if you're compiling with `-std=c89`, `-std=gnu89`, or gcc &lt;= 4.2 with `-std=c99` or `-std=gnu99` or you're using gcc &gt;= 4.3 but used `-fgnu89-inline`, you get the old semantics. gcc &gt;= 4.2 helpfully defines one of the preprocessor symbols `__GNUC_GNU_INLINE__` or `__GNUC_STDC_INLINE__` so that you can write macros that behave correctly regardless of compiler version or options, which likely explains why `CYTHON_INLINE` is a macro and not just the word "inline". [1] There are some newer technologies like LTO that let the compiler have whole-program knowledge at link-time, which allows for some sophisticated optimizations that have previously been unavailable, but for the most part this is still a true statement.
Fair enough, but I would say the switch to static typing, manual memory management, etc is more of a change or at least a more jarring one. Obviously it's somewhat different, that's one of the reasons it's worth learning...but compared to my other suggestions I'd say it's the one "closest" to Python. Those are the two things new JS programmers struggle with sure, but prototypal inheritance is fairly easy once you grok it, and I think someone coming from a dynamic language like Python won't have too much trouble with it (as opposed to some other languages). If they have any experience with event-driven programming in Python that will obviously help, but even if they don't already being familiar with first class functions from Python will help there as well. 
I write in C all the time... I'm trying to get into kernel development because I find low level work to be exciting. C is elegant. Its actually my first favorite language. I also like Python, partly because it interfaces very well with C. 
I know, but I still need to know more than one language well
Thanks for the performance analysis. I hadn't checked the 2.7 speeds. They enhanced the C extension `_json` (it's part of 2.6, too) with `make_encoder` and `make_scanner`. 
Java, duh. Python is a GC language so why not stick to that paradigm? If you want to get elbow deep, learn C++.
I agree that it's exciting to compile C to a physical chip, but that's where it ends. Though, unless you don't have a chip or board or kernel to design around, it's kind of hard work gone to waste.
I think this is an ideal combination. C teaches one a bit about how the machine works. Haskell makes one a better thinker. Python is incredibly useful.
C/C++ /thread
Another good book... http://www.amazon.com/C-Nutshell-OReilly-Peter-Prinz/dp/0596006977/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1320386935&amp;sr=1-1
At an SF Python meetup today: "Show of hands. Who's hiring or co. is hiring? 60 hands go up. Who's looking? 2 lucky hands!" - https://twitter.com/#!/zzzeek/status/132299699070836736
Memory management is important in all programming, but some applications require *manual* memory management like mobile devices or Linux kernels. If that's your goal, go for it! The functional aspect is what I think really complements Python, and because it's prototype-based, you start to see data relationships differently, too. Inheritance is overrated.
Me too!
The Head of my (astrophysics) department always says FORTRAN is the language of the Gods. Between Fortran and Python I have been able to do anything required of me. How this would hold up in the real world I do not know. Anything of the real world I do not know. 
Top level static variables have scope "compilation unit", not file. That means if you put one in a header file, you will get a copy of the static variable in every file you compile that includes it, recursively. 
Irony is a lovely thing.
Is inline part of ANSI C now? 
&gt;On the flip side, I do love how finely tunable C++ is compared to Python. It took me a long time to get over this, but finally I got it through my skull that this almost never matters, and where it does, the time you spend tuning allows another generation of machines to come out, so you don't need the tuning after all! Obviously, there's a degree of exaggeration here, but C++ tuning is much like inline assembly - almost never called for, and a real hazard to leave to any maintainer, yourself included.
If you think C is bad for "magic functions", wait until you see C++.
What abuse are you talking about? Edit: you should consider them to be nothing more than functions, e.g. a+b is the same as (+) a b So it is just a non-alphanumeric function name. 
I love C++ because it's so horrifically byzantine I can now code circles around anyone else who attempts it, simply because I've spent so many hours (years) banging my head against the language's many idiosyncrasies, they have somehow found their way inside my skull by process of osmosis. With that said, Python is by far my language of choice and all I use on a day-to-day basis anymore.
Fuck you and your bullshit dare. 
Don't read cython generated c it's not for human consumption. Read c written by a human. 
&gt; No, I'm not shifting ground. Yes, you are. I said that there are no changes a program can make on its own except change indentation, and I gave as an example a program I wrote that does just that. Your reply was that you could use VIM to detect errors. Now you realize that what VIM is doing is changing indentations where possible, not correcting errors. And you obviously haven't thought this through. Let's say you have chosen an even-numbered indentation (2 or 4 spaces are the most common). Now let's say further than you make a typing error and type an indentation that lies precisely between two legitimate indentations. Now try to claim that VIM will know what to do, that it can decide on its own. But before you do, think. 
Attempting a different explanation of size_t just to make it a little clearer. size_t is typedef'd to an unsigned integral type which can store the size of something in memory; this can differ between architectures. Consider two computers, A &amp; B. A runs x86_64 code, B runs i386 code. A can address a 64-bit integer's worth of memory. That is, it can refer to 2^64 different addresses. B can only address a 32-bit integer's worth of memory (2^32 different addresses). In both x86_64 and i386, the addressable unit is a byte, so A can theoretically address 16EB, while B can theoretically address 4GB. In both these cases, a size_t will be the same as a uintptr_t (an unsigned int large enough to hold an address). These types are different, though, because the C standard doesn't assume that to be true for all architectures. See [wikipedia](http://en.wikipedia.org/wiki/Size_t) for some more.
&gt; Memory management is important in all programming, but some applications require manual memory management like mobile devices or Linux kernels. If that's your goal, go for it Sorry, I'm not quite sure what you're saying here. You asked if JS was really not such a departure from Python. My answer is that while a useful departure, C and others are going to be more of a change. &gt; The functional aspect is what I think really complements Python, Sure. Though I wouldn't say JavaScript is *that* much more functional than Python, especially compared to some of my other suggestions. (If you're talking about what is idiomatic, then I would say yes...idiomatic JavaScript tends to be a bit more functional than idiomatic Python, but even then if the goal is functional programming experience, I'd look elsewhere) In terms of how much it JS **complements** Python, I think we agree that it's a good complement. I think so because it's similar to Python in many regards so, OP will be comfortable there...but different in others so OP will get some experience with new things. Additionally it's practical because Python + JS let's you write web apps.
How I would teach university languages: 1. Python - Learn programming though process, algorithms 2. C - Learn memory management, hardware interaction 3. ASM - Learn what compiled code is doing 4. Haskell - Learn how to think about problems differently
Learn something as different as possible. Python is dynamically typed, interpreted, procedural, eager, object having, and imperative. Since haskell is statically typed, usually compiled, functional, lazy, not so object having, and declarative, go with that.
&gt; That's really just a feature of strong typing, though No its not its a feature of explicit typing. There are plenty of strongly typed languages that use type inference to eliminate all the unnecessary types from your code. For example take a look at [Scala](http://www.scala-lang.org/). 
C is good to know from an engineering perspective. It uses physical addresses to structure data. That's great if you want it to run on a specific device, but like most languages, that physical memory management is handled pretty well by an interpreter. Programmers should learn C at some point in their life, and they should also learn assembly and how C compiles into assembly. They should also learn about the Von Neuman architecture in computer systems and how a program counter interacts with a data bus. Honestly, I don't see how any of that complements Python except for the fact that CPython was written in C. 
Seconded on CoffeeScript. It gives you JavaScript (the platform) without feeling like you're using JavaScript (the language). It feels a lot like Python, in fact. No more being stuck in wacky command-line tools or wackier PySide apps that don't package up correctly. When I connect a CoffeeScript frontend to a Python server, I feel like I have superpowers.
Well I'm thinking of a more broad manner of "complementing". I think you're thinking purely in terms of practicality. &gt; except for the fact that CPython was written in C. That's a pretty big deal IMHO. For one, it means you could one day hack Python, or at least peak at the implementation to understand it better. Also, C is a very practical skill for Python programmers because they can write modules in it, and it's easy to call C from Python and vice-versa. This is true of some other languages, but as it is now CPython is still the main event in the Python world. So these mean it complements Python skill on a practical level. In a more broad sense, it complements it because it "completes" the programmers knowledge/experience. If you only have experience in a high-level dynamic language, there's a lot of things that you only understand conceptually or intuitively. Your understanding may be broken. Using a lower level language forces you to confront those things and develop a truly working understanding of them. You can then take that knowledge with you when you go back to the higher-level dynamic language. 

Python is a type of snake!
Yes yes it is. [5].
I like golang a lot. However, I feel like the development is still moving so fast that you shouldn't quite bother yet. Things change drastically and frequently. Right now learning it will probably invite you into the world of brainstorming how to create a practical language; that could be what you want though.
We are all here too. But sometimes we have french-specific links or stuff like this to post. If we post them here, they get downvoted because they are in french.
If you are interested in C++ but afraid of it, consider the [D language](http://www.amazon.com/D-Programming-Language-Andrei-Alexandrescu/dp/0321635361/ref=sr_1_1?ie=UTF8&amp;qid=1320399944&amp;sr=8-1). Unfortunately it arrived too late so it's not well-known.
couldn't agree more
I've been using Go for the AI Challenge and it's been a great experience. I wouldn't use it for anything long-term yet though.
Because Ruby is amazingly popular in Japan (I'm there at the moment, and the existing code I am using is a mixture of C, C++ and increasingly more Ruby) and Japanese tend to dislike speaking english, so by learning Japanese you can profit from the Japanese Ruby community. That has changed since Rails, but before it got so popular it was actually hard to get useful english ressources on Ruby.
After Python you'll be pissed off with the others.
Indeed. Strong typing means that adding, for instance `2 + '2'`, raises a `TypeError` (unsupported operand type(s) for +: 'int' and 'str'). Dynamic typing means that any name can hold any type of value (and can be reassigned to another type if need be).
If you're going to learn one system language, one functional language, and one dynamic scripting language. C, Haskell, and Python are in my humble opinion the best of those three worlds.
For most things Python does, a single core is still perfectly adequate, and probably will be for the foreseeable future. Where you do need more power, there are tools like multiprocessing to take advantage of extra cores. It's not that big a problem.
Because everyone wants to pretend that JS is a class language instead of a prototype language. I'd say 90% of the libraries for JS make it mimic a class based language so developers don't have to learn prototype.
oh the irony.
Parseltongue
If you use Emacs, there is Elisp. Elisp looks so different from Python. You'll be rewarded with easier customization for your editor. Elisp confuses me sometimes. i can't get my head around when to quote or not. I've got no choice but to learn it well. I mean, you can't make Emacs commands with Python, Haskell or other fun languages. JavaScript. Again, I've got no choice but to learn it. If only bookmarklets and other client-side stuff can be made with Python, Lisp or other fun languages. Stuck with JavaScript and Elisp. I'm also stuck with LaTeX, with lots of mess around it. But I guess you don't have to learn LaTeX.
C is the straightforward answer, but I would say Go. It's the closest thing we have to a modern version of C. Also, it shares some concepts with Python, like iterating over lists with *range*. Haskell and possibly some assembly could also be nice. I would not recommend Python &amp; C++ in any way or form, since Python &amp; C covers the same things, only better.
Please, the Arduino code isn't C++, have you used it? It's C++ for babies.
2500 years of the history of religion &amp; philosophy disagree with you
So true, there is no way that a link with some French content make his way to the front page.
It's not like we submit a link here or on the French one. If the content is in French, we just don't submit the link at all, because there is no point to do so.
If you want to learn javascript and python (or you already know one or both) then drop by [pyjamas](http://pyjs.org)
I realize that FORTRAN (formula translation) is still in use (marginally) but I just cannot agree with spending time learning it. Java or C would be better. God I was programming FORTRAN on punch cards in the 70's. Yuck.
If you're going into acedemia, you may wish to learn Matlab, or its open-source alternative, Octave. Also, for those in academia outside of CS, I hear the language R is quite nice.
erlang :)
Tunable when you need it to be, but I agree. Python provides an abstraction that just lets the programmer program, at the expense of performance, which, arguably, doesn't matter that much in most cases since computers are getting faster and faster. Unless you're building large scale servers processing millions of data at a time, you won't see or care about the difference. 
Since you asked for something that could complement your Python knowledge I think only C / C++ would make sense, since it would allow you to write native extensions for your Python code, making it the perfect complement. It has nothing to do with whether they are the best languages or not, it just makes sense to know them if you are into Python.
No, the fact that it has a declared typed at all is static typing, The fact that it has to change with the function signature is strong typing. I.e. it's strong because there isn't just a single 'function' type. Unlike static/dynamic, though, strong/weak is a continuum, and this is less strong than other languages because it could be cast to a different function type.
Indeed, it still lets you cast with wild abandon.
I'd recommend SQL if you're building record-oriented applications. Dialects don't matter much, since the differences are small enough that it's trivial to go from one vendor's implementation to another - the differences are usually just minor extensions. Though I'd go with Postgresql or SQLIte, just because they're great free databases that put high priorities on portability. Note that the existence of ORMs doesn't really reduce the value of knowing SQL - I've worked with quite a few developers who are incapable of writing adhoc SQL. Which is like working on the unix command line and having to write java code instead of using bash. 
Yes, these are exactly the things that I'm doing. These exactly. I capitulate and prostrate myself 'fore your onslaught of wisdom and superior wisdom. &gt; And you obviously haven't thought this through. Let's say you have chosen an even-numbered indentation (2 or 4 spaces are the most common). Now let's say further than you make a typing error and type an indentation that lies precisely between two legitimate indentations. Just tested it. VIM fixed it. That's six spaces prior to the print line (I use multiples of four). I now highlight it and let VIM work its magic. If it didn't, Python would at least tell me the line causing issues* so that it would become a trivial task of tracking down the issue (given a halfway decent editor). def dump_connections(log): for airport, connections in log.items(): print("{}:\n \t{}\n".format(airport, '\n\t'.join(map(str, connections)))) Holy shit, did that just happen? def dump_connections(log): for airport, connections in log.items(): print("{}:\n \t{}\n".format(airport, '\n\t'.join(map(str, connections)))) Do note the corrected indentation prior to the print statement. Note it and weep. It's also worth noting that I'm not downvoting you. I'm pissed off at your obnoxious asshattery, but I make it a point not to downvote those people I'm having a discussion with. Now, I'll be fair, this won't work everywhere. It wont work perfectly everytime. I've admitted these things previously. But despite your increasingly stringent qualifiers to my claims of "magic," I've found an example that works perfectly. The point of the original discussion indeed was your claim that students can get tripped up by whitespace. I've disagreed and pointed out the real reasons for the issues you've cited, such as simple confusion as to the bock of code a line should belong to. I have correctly asserted that this is an issue with the student, and that no amount of curly braces (or editor) will tell someone that their return needs to be inside the for loop rather than outside (the sky is up). Further, you claim that invisible tabs are causing problems. Well don't use fucking broken editors. VIM won't do this. Emacs wouldn't jerk you around like that. Notepad++ wouldn't even do it! Hell, I doubt plain ol' notepad would. Students have trouble learning a lot of things (my example of recursion), shall we remove each in your preferred language? Tell me, do you like Java? You seem the sort to enjoy protections from potential pitfalls. * `File "routing.py", line 33`
Actually I "learned" C++ in University, and didn't see as much craziness in it. But.. I probably just didn't see enough of it :)
Hmm was that cython generated? If so I apologize, though I did state in my first comment that that was just the first .c file I could find lying around. Those are the same issues seen with human-written C. I will try to find some better examples today and explain some of the other things that scare me about it.
Interesting. So I would use size_t when I need a pointer that can point to an object? And it would be replaced with the correct size type at compile time, based on architecture?
Actually, having worked with a multi-core processor on an older, non-upgradeable linux -- it is a problem. What you will eventually see is that python becomes increasingly slow because it cannot remain competitive with other languages that do have the built ins. And multiprocessing is still not addressing the problem, which Jesse has mentioned a few times. Also, multiprocessing utilizes C. It's not a native python solution nor is it in the python standard library. Consequently, at least in my embedded realm, it's not an option to utilize.
The sys module is built in within Python. See http://docs.python.org/library/sys.html .
Please create a better title for whatever this may be.
If you mean that you're looking for .py files that implement that functionality, then there aren't any. Not all of the python library is written in python, some of it is directly implemented in C. The proper way to learn about the standard library is [through the documentation](http://docs.python.org/library/sys.html), not by poking around looking for files. 
Thank you for this! I have been wanting to do something of the sort using Flask for a while, but haven't had the time.
Looked at this page multiple times...I guess when I read "This module provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. It is always available." the last part didnt register correctly to me. I had looked into the import command, and one exercise had me make a fibo.py (fibonacci sequence with 2 def's in it) and then use import to call those def into another script. This made me think that sys.py existed somewhere. I see my error now. thank you!
Just a small observation. Every time you see a weird library, go ahead an run the code (if it's trusted!). It might be part of the standard library and you don't know. If it doesn't run, only then look it up.
Isn't that what http://pypi.python.org/pypi/chishop does? How does yours compare?
I disagree, modern C++ is easy to write without casts (unlike C which needs casts, and Java's generics which introduce run-time casts yet are not expressive enough that you can forgo compile-time casts). C++ is the mainstream language with the most expressive type system.
It's important to note that any module can be implemented in C even if the documentation says nothing about it exposing internal interpreter values or whatnot. For example, the [datetime](http://docs.python.org/library/datetime.html) module is written entirely in C. You can write things like `from datetime import date` but there is no corresponding datetime.py file anywhere that is read; instead, python simply loads the compiled binary dynamic library (datetime.so or datetime.dylib or datetime.dll). 
See this [list of Perlis Languages](http://blog.fogus.me/2011/08/14/perlis-languages/) and the author's follow-up with [notable languages of the last 5 years](http://blog.fogus.me/2011/10/18/programming-language-development-the-past-5-years/).
The issue with operators is that they give you almost no information about what you are doing, unless you have a lot of context.
If you do want to look into the sources, download and untar the [sources](http://python.org/ftp/python/2.7.2/Python-2.7.2.tgz), for example. In that directory there are two main subdirectories of interest: **Lib** contains most (all?) of the Python modules that make up the standard distribution **Modules** contains C implementations, where required, backing up the Python modules in **Lib**. It looks like the `sys` module is so deeply embedded in Python that it lives in the **Python** directory which looks like it contains core run-time specifics, probably including the interpreter itself (though I haven't spotted it yet).
Nope. From wikipedia... *Static global variables: variables declared as static at the top level of a source file (outside any function definitions) are only visible throughout that file ("file scope", also known as "internal linkage").*
You're welcome :)
I didn't know about that one yet. I'll give it a spin and let you know...
It's a great combination. Have you ever tried to debug a program written in a weakly-typed language? Little logical errors are more frequent since you can add, say, an int and a string, without being explicit. Static typing adds a lot of arguably needless casting and other type conversions.
some_obj.blah() What does this do? Oh, wait, you need context to answer that? Operators are functions. 
SQL is absolutely a programming language. Especially once you get into things like stored procedures, etc.
Hmm... my first impressions, by just looking at the web-page/code: - It does not explain how to install in a `virtualenv`. Which I find essential - It's been around longer, and looks more complete. This also means it's more tested. This is a huge plus! - It's written on top of django instead of flask. Whether this is good or bad, is a matter of personal preference. I'll let you be the judge of that. I prefer flask because it's smaller, simpler. Good for this kind of app. - It seems to have an admin interface, based on django's admin views. This could be useful... I guess... But I don't really see the use of this myself though. You can always update a package by re-registering/uploading it. Being able to remove a package is not a good idea in my opinion. You never know which application may still depend on it! Especially if you decide to make your repo public! Which is conceivable. Consider packages that you would like to make publicly available, as sort of "open alpha/beta" using a staging area that is *not* the official cheeseshop. - I prefer my code (by comparing [chishop's request handling][1] with [mine][2]) I haven't installed or run it yet. So I cannot say anything more at this point in time. Also, while it's not quite there yet (it's still alpha, not yet `1.0` ;)), I pride myself in extensive documentation. And I always try to keep it as complete and fool-proof as I can manage. Currently, `chishop`'s documentation seems to consist of one web-page and one `README`. Source-comments are also at a minimum. Compare the installation instructions for both, and judge by yourself. [1]: https://github.com/ask/chishop/blob/master/djangopypi/http.py#L19 [2]: https://github.com/exhuma/mypi/blob/master/mypi/server.py#L65
That does not contradict what I said. I stand by my statement. Perhaps thinking of the C preprocessor and the C compiler as independent helps clarify the situation? In many ways the C compiler's "source file" is the output of the C preprocessor, which *will* duplicate the header file static declaration whenever it is included. I can't imagine this situation is common for C, but it's fairly common for C++ as an idiom to ensure static initialization of a compilation unit. Or was, anyway. 
Most of the smaller Python programs I write live in a single file. You only need to split things up when you want to organize things better. [Here](http://docs.python.org/tutorial/modules.html) is what the Python tutorial has to say about modules. Java requires classes to be in their own file, as far as I know. There is probably some trickery to get around it.
I don't think python stops you, but it is difficult to wrap your head around a project when it is all in one file. I expect you'll find that having common subroutines in a separate file makes it easier to write the 2nd program. And then if you want to use someone else's code, you might want to keep it apart from your code. So soon you have things in many files.
&gt; Just tested it. VIM fixed it. You didn't use an indentation example such as I carefully laid out above. A colon line with no following indentation is always an error, but it's not an indentation error. Instead, something is required, something is missing. That's something all programming editors do, [including mine](http://arachnoid.com/arachnophilia/index.php). Your participation in this thread has been one deception and misleading example after another. Get Vim to fix this "wrong" example: for y in range(1,13): for x in range(1,13): sys.stdout.write('%4d' % (x*y)) print '' And turn it into this "right" example: for y in range(1,13): for x in range(1,13): sys.stdout.write('%4d' % (x*y)) print '' Automatically, without user intervention. And do try to follow the conversation. 
There is no valid reason for a language to force you to make this choice (compiler can deal)
So many people say C... Looks like that should be what I check out. Edit: What books/etc should I check out?
Definitely looking at C, what would you reccomend, bookwise, for both those?
Te laat.
I actually did write a ray tracer in the intro to compsci class I took. Which I dropped because I can't Haskell.
I've done that really simple [SQL course](http://www.sqlcourse.com/index.html "SQL 1: IT'S NOT THE SEQUEL") before. Nice stuff, for sure.
You can define more than one class in a Java file, but only one can be declared public. This is commonly done for inner classes and anonymous classes (especially event handling.) A Python module can contain any number of classes. I typically group a set of related classes in the same module for convenience. I like to separate the module (or modules) from the main program. This is especially true if you are building classes or functions that could be re-used.
&gt;&gt; That does not contradict what I said. I stand by my statement. So serious!! Yah, you're probably right.
&gt; Why is that not the convention? Because in large projects with multiple participants, it makes more sense to have a reasonably large number of source files, rather than a single source file that must be synchronized with many small additions over time. Even for one programmer, having independent source files for each class or namespace simplifies maintenance and development. &gt; Am I an idiot for even asking this? It's a perfectly reasonable question. People who have worked on large projects always know the answer from experience. 
For many modules, you can look at the \_\_file\_\_ attribute to see *where* it is (sys and some others are exceptions): &gt;&gt;&gt; import os &gt;&gt;&gt; print os.__file__ /usr/lib/python2.7/os.pyc &gt;&gt;&gt; import r2 &gt;&gt;&gt; print r2.__file__ /home/kemitche/reddit/public/r2/r2/__init__.pyc If it's a .pyc file, you can look at the .py in the same directory to see the code. If it's a .so, you'll have to find the source somewhere, or rely on other documentation, but you'll at least see where the module is loaded from.
&gt; Java requires classes to be in their own file, as far as I know. In Java, public classes must be segregated by file. There are many examples of private and/or embedded classes within public classes. 
In Python, it's recommended that you group together functionally related classes and helper functions in a single file. Of course, when this gets more than a few hundred lines of code, it can get inconvenient to edit. At this point, it makes sense to split into different files - again along functional / logical lines. A hierarchical organization based on the file system is useful in many cases. Of course, it's not enforced the way it is in Java. You can put everything in one monster file if you want.
&gt; C++ is the mainstream language with the most expressive type system. Ha-ha-ha
(I'm sure I'm just echoing the others, but whatever :-) Yes it is possible to have your entire program in a single .py file... and many times you will want to do that. The real question as to whether it's a good idea is *"how big will my program be?"* If it's small, then it likely makes sense to have it in a single .py file. For example, I have a small Mercurial plugin [which lets me munge timestamps in Hg](http://dev.samhart.net/mrpeabody/) and it is a single .py file. There's no need for anything bigger because it's a silly, small program. However, I have another program which is a larger, cross-platform daemon/service that manages systems in a cloud computing environment. It will be many thousands of lines of code once it is fully complete. If I jammed it all into a single .py file maintaining it (and even *reading* it) would be a nightmare. Thus, for my larger program it makes more sense to intelligently split it out into multiple modules. Really, the decision comes down to a maintainability one.
Another fun tool is the [inspect](http://docs.python.org/library/inspect.html) module, which will do things like print the source code of an object or function. (As long as it's written in Python, so doesn't really apply to sys)
Absolutely you could do file locking. There is a magnitude of things you could do. In some cases atomic transactions don't even matter. Just let there be the occasional problem. The benefit with the traditional DB comes in that you don't have to worry about the problem. It takes care of it for you. As an example SQLite has 1,117 times as much test code as production code. I am confident there are gotchas that I have no clue about. If I have an application where I cannot have those gotchas, it may be a good choice to us a well tested database verses me rolling my own. That being said, if I didn't need a full on DB I might still use file locks.
But beware: you'll learn that Common Lisp is both the most powerful language there is, and the most impractical. The holy grail exists, and you'll never use it.
C: [The C Programming Language](http://www.amazon.com/Programming-Language-2nd-Brian-Kernighan/dp/0131103628?tag=duckduckgo-d-20) Haskell: [Real World Haskell](http://book.realworldhaskell.org/)
*Most* of the time, I guess, although I generally want to send other headers as well (gzip, for example). Even if it is just one line, I don't want to have to remember it. \*shrug*
Java. At least treat yourself to the book _Effective Java_, which shows that Java solves things your language hasn't even thought of (e.g., in Python, how do you defend against attacks where the malicious code is running in the same VM and might subclass or even monkeypatch your objects at leisure?). Java is a lot of typing, it's bondage and discipline, but it has big advantages for large projects too. Then learn Javascript by means of _Javascript: the Good Parts_. Because it's a fantastic language, dammit, just don't learn about the bad parts :-) Prototype-based OO is an underused idea. And Javascript is going to be absolutely everywhere in the coming decade. And C or C++. Understand those well and you'll be way ahead of most people in the field.
Absolutely! There's no reason not to, if you're writing something monolithic. Code sharing aside, having other modules can make it easy to avoid problems in global variables, and make it easier for you to hold discrete areas of concern in your head. Until your program gets to be a few hundred lines, you're probably better off with one file.
Agreed with all the other posters: you should split up classes into modules based on whatever hierarchy makes sense.... ...with one exception I can think of. Sometimes when you're distributing your program it's nice to have it in a single file. In this case you may want to lump it all into one file even if that's somewhat less readable. SQLite (written in C) is distributed as [one huge file](http://www.sqlite.org/amalgamation.html). This can make it easier for people to incorporate it into their own projects. They don't have to unzip anything or worry about directories, they just drop the file right in.
If you are going to stay in physics, find out what the people in your field, especially the ones doing work in what you want to specialize in, are using. They may be using Lisp, assembly, Scheme, C, or lo and behold Fortran (which in physics and other scientific fields, is in use for far more than those who aren't in science like to admit, kinda like just how much Cobol is still in use even though cough cough "real programmers" try to ignore it). I have a few friends at Sandia, LANL, and ORNL whose main programming languages are C, Fortran, IDL, Matlab, and R. So ask the people in YOUR field what is useful.
1 file for every 100 lines.
I know astrophysics loves FORTRAN, and I hear it's not terrible from my friend going into grad school for astrophysics. I'm mostly into laser and biophysics, so if anyone knows what THAT entails...
As long as the Grail will kill Nazis, I'm ok with it.
I find that tends to be a reasonable (loose) rule of thumb.
Maybe this could be handled with xml.dom?
Please don't do this. Break up files for structure, not for arbitrary sizes.
I knew someone would be a smartass, should've added a disclaimer since we're in a programmer zone. Of course I don't mean you'd cut a function in half if it reaches line 101. I just mean that a project of 5,000 lines would optimally have 50 files (of varying sizes). 
Too small for my taste, if you have a total over a thousand lines. Personally, having something like 3000 lines spread over half a dozen around 500 line files makes sense. Especially if that corresponds to a good partition, like a central body and five functional/data groups. 
What's your "particular system"?
Sorry for leaving that out. I've got a Mac, running snow leopard (is that what you're asking?)
Yes. Can't help you first hand, but try just googling. First hit lead me to the Hitchiker's Guide: http://guide.python-distribute.org/installation.html
There's absolutely no reason why not to, when it makes sense. If you're writing a one-off tool for a specific use case, or even a first version, it can make sense - a single file to copy around, a single file to use vim's "#" command to quickly jump to all the references of an identifier, run pydoc on, and so on. However as a design grows, so does the need to identify logical groupings of functionality, in order to introduce some abstraction to parts of your program. For example a "one off" tool that applied some schema changes to a MySQL database might be enhanced to also work with MS SQL or PostGres. At which point, some common functionality relating to database access *should* fall out of your design, and hopefully be naturally generic enough to live in a separate module, a module independent on the rest of the program, that can be reused in new programs. Similarly for any other kinds of abstractions that appear, your goal should generally be for them to be independently reusable. This leads to a trend of breaking things up into modules for increased long term productivity, which is probably why most big programs look like this.
thanks. checking it out right now.
Definitely too small, but 1,000 is definitely too big; if we're looking at orders of magnitude, 300 lines feels a comfortable splitting point. Looking at some of my projects, files with less than 100 lines are only that small for a reason, files with more that around 600 lines feel a bit too large. Interestingly, the same rule of thumb seems to hold for my C files: mostly 200 to 400 lines, the occasional bigger file, and quite a scattering of smaller files.
Try the recommendation here: http://catb.org/~esr/faqs/hacker-howto.html ..awesome resource..
$ wget http://pypi.python.org/packages/source/p/pip/pip-0.7.2.tar.gz When I enter this into terminal it says:-bash: wget: command not found 
Why dont you just generate that svg with bunch of &lt;image/&gt;s? You can use any templating solution for that (mako, jinja, lxml).
Sometimes serialization means you're not looking at things right :) import ctypes,mmap mm = mmap.mmap(-1, 4096) a = (ctypes.c_int * 1024).from_buffer(mm) 
I'm not that stupid and wasn't being a smartass, but ok. Why do line numbers matter when it comes to the number of files? The other day I wrote a little 500 line utility script that is one file. I can think of zero reasons why it should be more than one file.
My first pass at a problem is always one file and almost entirely functional programming. Pass 2: Once I have a good concept of what I can do and have an idea of what I want to do I split the functions up over a class or two so I can pass around that object later. At some point I will do a third pass and I will move the multiple classes into files when I want to group them as a module. The only time I go back to a single program is when I absolutely must maintain portability. However that also generally means I am refactoring the code in some manner. And then the cycle sometimes restarts.
You want to generate a raster image with the composite or a composite SVG?
use virtualenv-burrito: https://github.com/brainsik/virtualenv-burrito Let me summarize quickly for you: * Open terminal * type in: curl -s https://raw.github.com/brainsik/virtualenv-burrito/master/virtualenv-burrito.sh | bash * source ~/.venvburrito/startup.sh * mkvirtualenv --no-site-packages virtual_environment_name * workon virtual_environment_name * pip install nose Now you have all the things you need and you can start working. Once you are done, you can deactivate the virtualenvironment with command "deactivate"
They should call it "Learn Python the ridiculous way" ... On topic: You should use whatever package manager macos has to install them. I heard there's macports ...
Organize your code as you like - put reusable code in importable libraries; put single-purpose code (regardless of functional, OOP, etc methodology) into a single file. Python gives you the flexibility.
The end result will be a png
Thats actually a pretty interesting idea 
Thanks so much. This was very helpful.
Chishop has been replaced by https://github.com/benliles/djangopypi how does it compare to your version?
There's a few advantages to using several source files instead of just one. 1. Sometimes you'll want to have two different variables with the same name. However, in a long file, you might forget that you've already used that name, and then you might run into trouble when you try to access that variable later because you've accidentally redefined it. 2. Scrolling to a section of the file becomes frustrating when it gets too long - you have to hunt around to find things. Searching becomes more frustrating as well because you have to type longer keywords to find what you're looking for. 3. You can implement individual test cases for each separate module. At the end of the file, you just write *if \_\_name\_\_ == "\_\_main\_\_"* and then your test code. Then, after you modify the code, you can run it to verify that there are no errors and do performance testing if you like. This is convenient because you don't have to wait to test the entire application, you can just quickly test that one component. Also, keeping the test at the bottom of the source file makes it a handy reference for how to use the code. You may not care if you only have 2-3 modules but with a large project that has thousands of lines of code that you've written over months or years you *will* forget how to use your own code and you'll appreciate a quick and simple refresher. 4. Keeping code in separate modules helps you focus on writing reusable, general-purpose code, and allows you to conveniently reuse that code by simply importing any useful modules.
C, as almost high level assembly, is very readable in that it is easy to envision what the machine will do based on the code. C++ can look a lot like C but IT IS NOT! Craaazy shit can stem from a "simple" line of C++. If you don't know C, you'll naturally never trust C++, but knowing C might lead your mind to assume certain things. 
Every program should probably start in a single .py file. There will come a point where you have a really big class that's well segregated from the rest of the code, or a bunch of utility functions, or something like that, and then you'll easily see a natural way to start structuring the program in multiple files. I think it usually isn't a good idea to guess ahead of time what the structure should be.
The best tools are rsvg and libcairo. But they aren't easy to get a hold of, even on Ubuntu. But I've used it before to do this. Another method is to use Inkscape, which has a command line interface.
I don't know how widespread or accepted it is, but I would say let the program/problem/your working style dictate the structure. If you'll be maintaining or developing the code, maybe if you end up leaving it alone for a week you can come back and see how you feel like it's organized. You'll have a better feel for that when it's not all fresh in your mind, but you won't have forgotten everything, either, so it shouldn't be too hard to clean up a bit. Maybe it's a throw-away and you don't expect to maintain it at all--then why bother splitting it? 
 curl -O http://pypi.python.org/packages/source/p/pip/pip-0.7.2.tar.gz
Sure, you COULD do it, but ask yourself why you would want to. Do you want to scroll through thousands of lines of code to find that one function thats 20 lines long? Do you want someone who looks at the code after you to scroll through thousands of lines of code to find that one function thats 20 lines long? You shouldn't have to ask more questions than that, if the answer is "no" to either one you should split your program into multiple source code files.
Thats what I do, but I dont hesitate to use library/module files. Its just a matter of doing whats most convenient.
I do this all the time, but mostly because the libraries for python tools are so extensive, writing much more than 500 lines to build an app or tool has yet to be necessary. However, I'd probably break things in to more individual files if I maintained an app for wide distribution. Patching one huge file just doesn't seem right, even if the individual components are so specialized no one will ever thing to use them. For me it is easier to pull apart object relationships when I'm looking at the same file, pulling things up and down the page, rather than jumping between open file tabs/pages.
NumPy and SciPy packs are popular for Python. You may also may want to look at Maple, Scilab, and Root.
&gt;whatever computer stuff they want ...except a decent screen size? :P Seriously, any decent programmer would prefer to be working with a multi-monitor setup (and a decent keyboard and mouse, as well) than on a laptop, and it doesn't make them a "diva". Hell, even a single monitor setup is better than a tiny laptop screen. If you need them to work mobile for some reason, sure, mention it. But no reason to try to make a virtue out of necessity.
Instead of worrying about how many lines/classes/functions/whatevers are included in each file, how about using files to separate related code. E.g. In the django world, your data models go in a models.py file, your url definitions in an urls.py file, etc. Sure sometimes they can get large but at least they are logically organized and you always know where to look in any django project. 
chishop works fine in virtualenv
This statement is basically looping through your CSV file and returning one row at a time. The next line would be an indented statement (because you want it inside the 'for' loop) that does something with the values in that row. In pigheaded's example, the row's address field is passed to the mkdirs() function that then creates the directories. As a start, try "print row" instead so you can see what data you're getting from the csv file. It is always a good idea to test your csv reader with "print row" so you can ensure you're getting the input you expect from it before doing something crazy like creating directories on a live filesystem. 
I'm not going to jump in on the discussion about what is or isn't "right" or accepted, but I will point out that it's something that does happen in python. An excellent example would be the Bottle web framework: http://bottlepy.org/docs/dev/index.html Essentially it's an entire well built MVC web framework in a single file (bottle.py)
Honestly, I'm a certified Haskell-hater, but if you want to learn a new paradigm to improve your Python, it's where you gotta go.
To better understand this it helps to know that Python modules are just objects that you can create and manipulate dynamically. All that import does is call __import__, which will locate the module name within the local or global scope and then find the attribute on the module.
You could write an entire book in one long piece of paper too. That should answer all your questions.
&gt; It's a perfectly reasonable question. It reminds me of the question: "Should I use source control even if I'm working on a project by myself?" The answer of course is: yes. It's one of those things that you just acquire through experience. All the tools and techniques you use for multi-programmer teams generally scale down to a team size of just one. Of course, there's also the corollary that if you adopt these practices then you can easily scale out to a multi-programmer team if your project becomes successful.
Good article!
Hey, scrolls are pretty cool!
Interesting. Saved for future tests.
Please tell me Im understanding this in the wrong way. Adding a class ShelfHandler, /without/ actually doing anything with it, will change the behaviour of a BookHandler object?! That somewhat violates the principle of least surprise...
When we add the ShelfHandler class, it does change the behaviour of BookHandler. However, it is the fact that ShelfHandler is a subclass of BaseHandler with the model attribute set to Shelf that makes it so do, rather than the naming of the class or anything really weird. I agree it is somewhat surprising, but what would you prefer instead which wouldn't involve having to update the Piston handlers alongside the Django model code?
At the moment, I can think of three ways to improve the current situation. The first is not really better, but would reduce the surprise levels (and should not be hard to implement), the other two are actual ways of making things slightly more explicit. 1) make implicit Handler classes for every model accessed. Then, at least, there is no difference between having /no/ handler defined and /an empty/ handler. As noted, this does not solve the more fundamental problem of 'wtf, why does adding a class here change behaviour there'. 2) explicitly note down handlers to use within a certain class. i.e. class BookHandler(BaseHandler): model = Book handlers = [ShelfHandler] 3) explicitly register handlers: piston.register([BookHandler, ShelfHandler]) or: BookHandler().register(); ShelfHandler().register() as this allows you to put a breakpoint on the register() function, instead of on __init__ . And it makes changing global state explicit - I would not expect __init__ to change global state! P.S. ffs, why does every site need its own formatting syntax &gt;_&lt; 
I like (1) very much, and (3) would also be pretty good. (2) would mean having to update that list whenever I add a related model to `Book`, which I don't like. I should note that I have nothing to do with developing Piston, I just happen to have been using it at work and thought that disseminating the knowledge would be useful. :)
It's always good when people document surprising behaviour ;-) In general, I think a combination of (1) and (3) would be the best: let the library provide sensible standard functionality, and let the user override it, but only explicitly.
You're looking for backticks for inline `code` formatting.
It is entirely possible in Java As well. Ever Class would be an inner class to one big class. One instance of the Outerclass would be needed to create objects but that just gets to be messy. Python projects are usually separated into modules that provide different functionalities... one for parsing json objects, one for creating sockets etc. Each module would have inside it the required Classes functions etc used to carry out the functionalities it provides. 
I tried this and it worked with two pretty simple SVGs from Inkscape, but you may have to adjust some things. import shutil import xml.dom.minidom # copy a to c to leave a untouched shutil.copyfile('/Users/Derp/Desktop/A.svg', '/Users/Derp/Desktop/C.svg') # create list of elements from b, i just added the 'g' tag here, could be refined # but g also includes groups and layers, so it should be enough elementListB = [] docB = xml.dom.minidom.parse('/Users/Derp/Desktop/B.svg') for node in docB.getElementsByTagName("g"): elementListB.append(node) # find top element of c and append all the elements from the list of b docC = xml.dom.minidom.parse('/Users/Derp/Desktop/C.svg') top_element = docC.getElementsByTagName("svg")[0] for element in elementListB: top_element.appendChild(element) # write stuff back f = open('/Users/Derp/Desktop/C.svg', 'w') docC.writexml(f) f.close()
the parsing of file data is that complex because of something with distutils. Can't remember what the issue was.
If you are distributing your program, just use distutils/setuptools.
As a non-programmer who makes futile attempts at coding, I run into this problem a lot. I'll write a small script to do something and then extend it over time to include more features, and I'm left with a giant, poorly coded and sparsely commented source file. I never learned how to "do it right" the first time. The best way to tell whether one of my programs did what it was supposed to do was to check and see if it finished without catching an error and exiting.
and that is how you make mediocre programmers, who know jack shit about maintaining consistent environment. you can make it work, but you don't know what came from where. What if I want to different versions of library used by python. how about two different python versions.
I wish everyone would do this. In fact I wish an option for this was built into every OS or graphics driver. I hate white backgrounds so much, but especially at night. And yes I know a few OS have "inverted" mode but that generally inverts the color too which just makes everything look weird.
Hey. Thanks for the information :) I guess, this will be a problem that will appear in my application as well. As said in my previous comment. Your app is a good deal "older". Which usually increases code complexity. Do you have any idea if the submitted values are documented somewhere?
This would be pretty simple, use convert from ImageMagick to combine the images to png. But my XML-related solution from above (updated with example) is more elegant. 
Useful, but really ugly looking.
you can do it on Linux with a whole ton of different themes, both in GTK and QT, and on Windows, changing the default theme into Windows Classic, and a dark colour scheme.
Yeah in practice that sucks though, there are so many applications that don't support themes or intentionally choose their own colors, or half-support themes and so you end up with a black background with black text. And then there's images and logos, which are almost never modified by themes and often have white backgrounds. Also webpages by definition have their own color schemes and no amount of OS themes will change that. What I want is a completely authoritarian approach from the OS or graphics where if any program tells it to draw a pixel in white or light colors, for any reason, the OS instead draws it in black or dark colors with the program never needing to know anything about what just happened to its carefully chosen color. And of course, it would also reverse black pixel requests into white pixels. Do that for everything.
If declaring a variable bothers you, you can use the conventional throwaway variable "_": for _ in xrange(repeats): "run the code" I doubt it is more pythonic than the original code, but it could save you a couple of warnings for unused variables in your IDE or test suite.
for _ in xrange(repeats): "run the code" :D but really, you could do something like: map(function_to_run, iterator)
I didn't even know there was an official throwaway variable name. I'm glad I asked this question already, thank you!
Not really, since xrange generates a list, and to properly iterate, you need to assign a variable to each element in the list. Instead of for, you could use while: while repeats &gt; 0: do code repeats -= 1
That would be perhaps a little cleaner, but map would still require that I put "x" or "_" as the function argument, unless I'm misunderstanding. Otherwise I get "func() takes no arguments (1 given)"
To be honest I only recently learned about that when I needed to unpack a tuple and only keep some parts, eg.: a, _, b, _, c = (1, 2, 3, 4, 5)
In an interactive session, '\_' references the previous result. Running code with an '\_' variable breaks this feature until you "`del _`". But I doubt many people care about this.
xrange doesn't generate a list.
You could do it with map, and you'll need to declare something to hold a variable. Like this: ''' &gt;&gt;&gt; def f(_): ... print 'Hello' ... &gt;&gt;&gt; map(f, xrange(3)) Hello Hello Hello [None, None, None] ''' If it really bothers you, you could do it with list comprehension, as so: ''' &gt;&gt;&gt; def f(): ... print 'Hello' ... &gt;&gt;&gt; [f() for _ in xrange(3)] Hello Hello Hello [None, None, None] ''' Both ways seem a little bit silly. It's probably better to just use a for loop. 
er yah, you're right, generates an object to generate the range on demand. Forgot about that. But my comment about using a while loop stands!
The while loop splits one line of code into 2, so it has more potential for bugs. Plus it has to decrement a counter in bytecode (xrange is compiled C).
That's true, another reason why using _ is problematic is when it comes to code that touches anything in the i18n area: http://www.markus-gattol.name/ws/python.html#underscore_gettext That being said, I am not exactly sure what you're trying to do but if you want to get results conditionally and be as lazy as you can then why not do lazy evaluation with a generator expression (even better than using a list comprehension): `(expression for i in range() if condition)`. That would yield an iterator if (and only if) condition is true. http://www.markus-gattol.name/ws/python.html#generator_expression
This is beautiful
The way you did it was right. There is no more Pythonic way. You don't declare a variable. x is implicit here. Using "_" only really works in the interactive prompt and shouldn't be used in modules.
That's a stupid way of doing it though since while loops are slower than for loops and he's iterating over a range. An implicit loop variable isn't a bad thing it's a common idiom of Python to do something like for i in xrange(1000): print i ** 2 
What if "run the code" is 20 lines? Does the extra line matter? And how does it have more potential for bugs? They're both loops for the most part. However while is slower. Over 500,000 iterations on this somewhat hefty box, while was slower by ~33%: $ time ./for_loop.py real 0m0.147s user 0m0.135s sys 0m0.009s $ time ./while_loop.py real 0m0.217s user 0m0.209s sys 0m0.006s about 35% @ 50,000,000 iterations as well. So for loop on xrange is definitely the more optimized of choices if you're looping that many times. But on smaller scale either will work.
I would update your code to look something like: repeats = CalculateIterations() while repeats &gt; 0: do code repeats -= 1 This seems less elegant than: for _ in xrange(CalculateIterations()): do code
Well, this is a silly solution, but.. If you could implement a recursive solution, you could use the stack frame to count for you. So, something like import sys import traceback def silly_solution(repeats, init=True): if init: sys.setrecursionlimit(len(traceback.extract_stack()) + repeats) # set the recursion limit to current plus number of repeats try: "run the code" silly_solution(repeats, init=False) except RuntimeError: sys.setrecursionlimit(1000) return
It's easy to forget that decrement at the end; then you end up wasting time figuring out what's broken. Maybe (probably) you're less error prone than I am.
This looks to have a lot of potential. Thanks for posting it!
 for iteration in xrange(repeats): pass That's as understandable as it gets. And understandability is the only thing that matters.
You could declare any number if static child classes, if you really want to. It would be stupid to organise it like that though.
TIL that Inkscape has a command line interface. Awesome.
There's nothing unique about it compared to `a, t, b, t, c = (1, 2, 3, 4, 5)` aside from the fact that no one uses _ as a variable name.
If anything, your solution was quite entertaining.
To my knowledge it's not official and it doesn't work differently, it's just a convention for telling other people who read your code that you don't care about the value.
&gt; I just mean that a project of 5,000 lines would optimally have 50 files (of varying sizes). That's not in any way a better suggestion than your first one. In my experience the optimal module size is highly project dependent and is, typically, in the 500-1500 lines range. There were, btw, formal studies on the issue, e.g. take a look here: http://www.faqs.org/docs/artu/ch04s01.html That study gives 400-800 physical lines as an optimal module size range.. I would not be surprised, if advent of larger monitors and better text display techniques (folding, auto-indexing, etc) would result in further optimal size increase (the study was done in 1997).
Hmm, while I agree that a public pypi probably shouldn't allow deletion, an actively used *private* one is probably getting packages pushed to it by the continuous builder, and *should* have an expiration mechanism, though the actual mechanism is a policy choice (I could see something like "keep all incrementals until two named/numbered releases have gone out" being a good start...) Thanks for the comparison, and for the effort you've put in on documentation.
at night, consider https://launchpad.net/redshift as a less dramatic alternative...
[f.lux](http://stereopsis.com/flux/) is another alternative. I've used it for around a year now and love it.
Of course. "_" can be read as "move along, nothing to see here". Using "t", "temp" or any other variable name might prompt someone to ask "huh, is this used later on?"... A matter of readability.
Right, but in terms of syntax and language mechanics, `_` is equivalent to `t`.
Its a point worth mentioning. Upvoted.
&gt; aside from the fact that no one uses _ as a variable name. Except the interactive interpreter, including IPython. And code that uses internationalization. I like markusgattol's suggestion of using `for each in range(23)`, I think I'm going to be using that. Not sure what would be better for tuple unpacking though.
You mean _ does *not* work in the interactive prompt. Well, it would work, but you'd be overwriting the automatic last result containing magic the _ variable normally has in the interactive prompt.
I'd recommend storing the old recursion limit instead so that there are no bad side effects from someone else changing it. To make the silly solution saner, I guess.
from copy import copy a = [1,2,3,4] b = copy() You could also use deepcopy(obj) for compound objects. 
please don't do this. \_ is the canonical name for the name of the function that translates between languages during internationalization. It comes from [GNU gettext](http://en.wikipedia.org/wiki/GNU_gettext), and the convention has been repeated in a variety of languages and platforms. This convention is followed within the Python community, as mentioned in the documentation for the Python standard package [gettext](http://docs.python.org/library/gettext.html), as well as the Django documentation for [ugettext](https://docs.djangoproject.com/en/dev/topics/i18n/internationalization/). Yes, \_ is a miserable function name, but it does have a widely-accepted meaning as an identifier.
What are you using it for?
Here's a performance comparison of slice, list() and copy(): Python 3.2.2 (default, Sep 5 2011, 04:52:19) [GCC 4.6.1 20110819 (prerelease)] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import timeit &gt;&gt;&gt; for x in [10, 100, 1000]: ... s = timeit.Timer(setup='a=list(range({}))'.format(x), stmt='b=a[:]') ... l = timeit.Timer(setup='a=list(range({}))'.format(x), stmt='b=list(a)') ... c = timeit.Timer(setup='a=list(range({})); from copy import copy'.format(x), stmt='b=copy(a)') ... print('{} {:.2f} {:.2f} {:.2f}'.format(x, s.timeit(), l.timeit(), c.timeit())) ... 10 0.22 0.33 1.22 100 0.56 0.63 1.55 1000 5.97 6.12 7.08 Even though [:] is fastest (in this one simple case...) I agree with the author that list() is much more readable than [:]. Edit: Updated to include results for copy.copy()
Anyone have any insight as to whether there'd be a performance difference between these two? Edit: teoryn basically answered this question ten seconds before I saved my comment
http://www.clifford.at/stfl/ might be a good source of hints - it's a curses toolkit, with support for lots of languages, that also has "expose this as a WEB UI"; doesn't help exactly, since you're starting from legacy c-curses code, but might have some useful components...
I agree, `copy.deepcopy()` is certainly the most pythonic way &gt;&gt;&gt; import copy &gt;&gt;&gt; some_list = [] &gt;&gt;&gt; id(some_list) 140650742141440 &gt;&gt;&gt; id(copy.deepcopy(some_list)) 140650742825832 &gt;&gt;&gt;
deepcopy is important as soon as you have nested lists.
surely you want you compare copy.deepcopy() not copy.copy() since the latter is semantically different to list() and [:]
care to elaborate? We are merely talking about how to do a *real copy* as in *create a different object* so I do not see the connection to whether or not a list is flat or nested. What we are after is: &gt;&gt;&gt; some_list is copy.deepcopy(some_list) False &gt;&gt;&gt; 
No, list() and [:] do not perform deep copies: &gt;&gt;&gt; from copy import deepcopy &gt;&gt;&gt; a = [[], []] &gt;&gt;&gt; b = a[:] &gt;&gt;&gt; c = deepcopy(a) &gt;&gt;&gt; id(a[0]) 3817304 &gt;&gt;&gt; id(b[0]) 3817304 &gt;&gt;&gt; id(c[0]) 3829352
I know that it does blah to some_obj. If blah has been intelligently named, I already have a pretty good idea of what it does, and if it's not terribly important right now I can skim over it and come back later. On the other hand, I have no idea what the hell `some_obj ||| dyspepsia` happens to do.
 &gt;&gt;&gt; a,b=[1,2,3],[1,2,3] &gt;&gt;&gt; c=[a,b] &gt;&gt;&gt; d=c[:] &gt;&gt;&gt; a.append('blasphemy!') &gt;&gt;&gt; d [[1, 2, 3, 'blasphemy!'], [1, 2, 3]] To some people, a "real copy" of a list implies a copy of all its contents. This is an unfortunate feature of the word real, as the word real is notorious for being arbitrary and context-sensitive.
Meh, strikes me as being overly handwringing. Slicing is a pretty important part of Python. Even if a noob gets your code, they should know what `[:]` does. It strikes me as a case of "don't be Perl!" run amok. On the other hand, I do suggest avoiding using `else:` with `for`. A shockingly large number of Python programmers either don't know about it or have the wrong idea about what it does (the `else` block runs if the loop finishes without a `break`).
 def dotimes(n, func): for _ in xrange(n): func() dotimes(repeats, lambda: "run the code") Or perhaps: def repeater(...): def _foo(...): ... return _foo @repeater def my_code(bla, bla, bla): ... my_code(bla, bla, bla)(5)
I didnt know you could program in python2.x for android devices. I thought it was all java.
I have actually seen code bases separated based on sizes. The files were literally named proj1.c ... proj9.c, each roughly 10KB in size. There was absolutely no way (at least for me) to guess which function logically belonged where. It's fun to tell as a "war story" now, but back then I wasn't laughing...
Piston: great at generating REST APIs for CRUD operations on your models, as long as you don't mind a few bugs. Not really useful for anything else.
Server-side cookie handling. But that's only because I couldn't think of anything better to do with it. 
&gt; Slicing is a pretty important part of Python. Even if a noob gets your code, they should know what [:] does. Even understanding slicing, it takes a minute to see what the purpose of that construct does, much like the first time I encountered Ruby's `!!` (an idiom for converting a value to a boolean).
http://code.google.com/p/android-scripting/ gets you "Python, Perl, JRuby, Lua, BeanShell, JavaScript, Tcl, and shell"; I've used it for python in particular. http://code.google.com/p/python-for-android/issues/detail?id=10 looks like it covers python 3 support...
Maybe get a job? Or try freelancing, there are quite a few websites which let you hire yourself out for small sums of money.
Lots of timing numbers, IMO slightly easier to read, includes PyPy: http://paste.pocoo.org/show/503672/
&gt; Isnt it better No &gt; less cryptic Barely &gt; and more pythonic? I don't see how.
oh yea the android scripting env. I meant like really APKs and stuff you can put out on the market. I thought there was some python api for making apps and they also figured out a way to convert it to java and install on android systems. 
 for no_use in xrange(repeats): pass
How about an internship? Maybe at a startup (probably the best compromise of performance and fun)? 
the list constructor just calls the slice operator anyway. the added time is that the argument is cast as a list. each of the methods (slice operator, list constructor, copy, deepcopy) has their own use case, see my comment on HN discussing this: http://news.ycombinator.com/item?id=3201895
Especially as the Python manual recommends using the slice operator to copy shallow objects: http://docs.python.org/faq/programming.html#how-do-i-copy-an-object-in-python Each of the copy methods (slice, list, copy, deepcopy) has its own use case - it is important to understand all of them.
&gt; How to make small amounts of money? Why compromise? Why settle for second best? I can teach you how to make no money at all! In all seriousness, to make money with Python programming skills, you don't start by asking other people how to make money. Your readers either don't know how to make money using Python, in which case their advice is worthless, or they do know how (and aren't about to reveal their secrets) in which case their advice is worthless. Welcome to reality. 
&gt; The thing is "x" is a completely throw-away variable and is totally unused. Then don't do it that way. Do it this way: exitCondition = false while not exitCondition: (do something that may or may not reset the exitCondition flag) Once the task is complete, set exitCondition = True and the loop ends on its own. 
&gt; And understandability is the only thing that matters. So wrong. import this
I'm not sure I concur with not using a language feature because other programmers aren't familiar with it. Each language feature will have a number of engineers not familiar with it. Where do you draw the line? Better to explain to them what else: does on a for loop, and it won't be an issue from then on. 
I think the author is a relative newcomer to Python. I like the idea, but there is so much wrong in this line... if data.has_key("webDefinitions") is False: And this... for i in range(0, len(bunch['entries'])):
I would be glad if you do a code review. I will improve it. EDIT: - Can you recommend a source to read so that I can read from it and know about all the details of the language? I know there is manual which I do refer but... - [Original Script](http://sprunge.us/gDKj?python)
I would be obliged if someone tells me about the wrong coding style I used &amp; any non-pythonic code.
It's mostly idiomatic issues. If the code works it works, but I'd make some changes for the sake of maintainability. This line works, but 'is' should only be used to test for object identity. Not for equivalence. if data.has_key("webDefinitions") is False: It works only because there is only one False and one True, but it doesn't expression your intentions. It should really be: if data.has_key("webDefinitions") == False: Which is better, but can be written more concisely as: if not data.has_key("webDefinitions"): Although, it should probably be written in a more idiomatic way, using the 'in' operator... if "webDefinitions" not in data: Your 'for in range' loop would be better using enumerate. Explicit indexes tend to be harder to mentally parse, and are generally consider less 'pythonic'. So this would be better: for i, _ in enumerate(bunch['entries']): Finally, global variables are rarely a good idea. And calling them 'globalVar' is an even worse idea. It fails to communicate what it does, and doesn't use the lower case and underscores convention. This is pretty old, but I think still relevant: http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html Failing that, its always worthwhile perusing code written by experienced Pythonistas. 
I agree with you on globalVar thing. Actaully, I mistakingly uploaded the wrong script. I was using that script just for testing as I needed the value of data in main's scope [As I was using python2 -i myscript.py &amp; then playing with data variable using globalVar]. I did't intend to use it in final version, that's why the stupid name too.. Thanks for other suggestions. EDIT: I have edited the code as you suggested.
The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. **Readability counts.** Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! 
When are the two *not* equivalent?
I actually agree that [:] is a bit cryptic, if you don't know that idiom, you don't immediately see what the intention is. It was one if the very few things I stumbled over while learning Python. I am not saying that using list() makes it clearer, but something like l.copy() would definitely more pythonic, being explicit instead of implicit about the intention.
And figuring it out from the context isn't that difficult. I mean, for-else - what else is it gonna do?
Not really. It has occasional use in C for this purpose but practically no other mainstream language uses it like that. Many languages are now converging on using _ as the null/throwaway variable. You shouldn't cross pollute your language idioms.
Reality is not black and white.
ITYM reality is neither black nor white. In any case, if you think people who are making money writing Python code will tell someone how to do it, it's you who needs a reality update. 
&gt;How to make small amounts of money? I'll tell you. Become proficient in python. Sign up for a youtube account and make some programming videos. Code itself is hard to do in videos, but a video on work flow or something like that would be better. Get enough views that you are offered partnership on your video(s) and accept. You will make **small** amounts of money. TL;DR my answer is *almost* useful. If we really stretch the meaning of almost.
There's probably better examples, as this is kind of contrived, but: class KindOfListish(object): def __getslice__(self, a, b): return [1] notalist = KindOfListish() print notalist[:] # prints [1] print list(notalist) # errors because KindOfListish is not iterable
I'm not sure why you sort of dismissed web development, when that's the best advice for making small amounts of money. Get yourself a client and make their website using Python.
Good luck trying to find new exercises for the million or so people learning how to program each year. They have to learn how to do something, it doesn't matter that other people have already done it before.
Some people are against help on homework on principle.
Is there any reason you did the online course as opposed to reading the book? Did you get more out of it?
[org-babel](http://orgmode.org/worg/org-contrib/babel/) would be perfect, if you happen to like emacs It supports a bunch of languages, and org-mode can export as LaTeX, HTML etc http://orgmode.org/worg/org-contrib/babel/intro.html#literate-programming
I think it could be natural to assume that means "if the list is empty, run this."
Okay, but this is not a list. I guess for lists, there is no difference.
I took a quick look (not that proficient myself, it's just to learn from others) and it didn't work at first. Had to switch to opposite logic (if NOT 'webDefinitions' in data:). Also, I don't know what you intended when you find primaries. You build up a means list, but it's not returned. Cheers
Do not use list() for copying unless you have established, that it's a list. It will otherwise break subclasses. 
Except that _ is usually used as the name of the translating function when doing i18n with gettext. E.g. from django.utils.translation import ugettext as _ is the convenctional way to import it.
I've never seen i18n in Python that _didn't_ use _ for this purpose.
&gt; First we need to understand how Python manages objects &amp; variables. Python doesnt have variables like C. In C a variable is not just a name, it is a set of bits; a variable exists somewhere in memory. In Python variables are just tags attached to objects. Lisp (Elisp) seems to act like Python. (setq a (list 1 2 3)) (setq b a) (setf (car a) 11) (assert (equal b (list 11 2 3))) (assert (eq a b)) Is there a name for the category of languages that act like Python in this regard? 
I do... and I do use org-mode to export to latex for lots of things. But I guess it's a manual construction of the document. Pweave is looking pretty good in that respect...
whoops, nevermind. at least with R, looks like it's pretty well integrated...
* Cron script are hard to maintain: you should always check your crontab during deployments &amp; updates rather than just restarting celeryd * You can use celery to run non-periodic, one-shot background task * Cron task would spawn new process to do some stuff, while celery would do it in a worker. * If you are using django, standalone script would be trashed with setting up django environment and settings, while celery implementation would be simple * You can always transform you background task to foreground one just by changing `task.delay` to `task.apply`.
Any thoughts on this dumb idea (other than it's dumb)? new = [].extend(old)
I don't get it. Python programmers should drop a common and simple idiom because newbies may be confused?
If a developer has trouble managing multiple source files, what business do they have embedding SQLite? 
If you're writing a cron job to pick up pending tasks, you'd end up replicating a lot of the Celery functionality. With Celery, it becomes really easy to take more functionality in your system, realize that it doesn't have to be synchronous, and just add another task to take care of it: no need to extend your homebrew solution. Celery will also handle things that you probably won't handle in your own code: what if a job fails? What if jobs are coming in faster than they can be processed? What if jobs don't get processed for a long time and there's a backlog? My experience was that Celery was a bit of a chore to get running, but once it was going, it has been really nice.
That's used in C, too: In C everything not 0 is considered true. Any boolean expression evaluated to "true" will return 1. If you want to force the output of any expression to be either 1 (if it is "a true") or 0 (if it is false), you prepend it with !!.
&gt; I actually agree that [:] is a bit cryptic, if you don't know that idiom, That may be true, but it is redundantly so, because it applies just as much to i = 0 because *everything* is a bit cryptic, when you do not know the idiom. &gt; something like l.copy() would definitely more pythonic Not necessarily - it would just be more obvious to those who are not familiar with the language. It remains to be shown that what is not obvious is *always* less pythonic. If that *were* true then for i in range(0,len(names)): do_something_with(names[i]) would qualify as more pythonic (being more familiar to non pythoneers) than for name in names: do_something_with(name)
using cron, you'd be reusing a time tried and functional technology while centralizing your periodic tasks in one location with celery you're adding yet another scheduler to your system, thus increasing the number of places you have to check when trying to figure out just HOW that script is getting started. you're also introducing yet another syntax to do the exact same job 
Something else!
I've seen that convention mentioned in this thread a couple of times, but it seems kind of weird. I guess it's because you can't really run django from the interpreter?
For both of your examples it is quite obvious what the intention is, because it is explicit. You would not have to think twice about what the python style loop does, even if you are more familiar with the index-style.
Well, you could use more loops and reuse more code. A principle of good code design is to solve a problem once and apply the solution to many cases through use of functions. In this section: try: a = int(a) except ValueError: print "a is not a proper integer" try: b = int(b) except ValueError: print "b is not a proper integer" try: c = int(c) except ValueError: print "c is not a proper integer" try: n = int(n) except ValueError: print "n is not a proper integer" You repeat four times what you could accomplish in one function. A single function has the advantage that, if you think of a better way to do it or if you discover an error, you only have to recode once, instead of five times. Like this: def test_value(n,s): try: return int(n) except ValueError: print '"%s" is not a proper integer.' % s return False Call it like this: test_value(a,'a') test_value(b,'b') And so forth. Then create a loop for the tests by putting all your variables into a list and scanning the list. Such changes would make your program much shorter than it is, and easier to understand. This is not meant as criticism, except the constructive kind. 
Another problem with the code (apart from [what lutusp mentioned](http://www.reddit.com/r/Python/comments/m2c8j/i_did_a_short_exercise_on_checking_fermats/c2xjl0e)) is the entire supplyargs function. You are calling it from the checkfermat function. Why? In the supplyargs function, a while loop would be better than calling supplyargs over and over because eventually it will crash if this is done too much. Something like... &gt; string = None &gt; # ask for input &gt; while not string: &gt; # ask for input &gt; # proceed as usual
primaries was the term used by google to signify its various forms like adjective, verbs, noun, adjective etc.. And its returned &gt;return all_meanings If you look at the code, &gt;means = all_meanings['primaries'][bunch['terms'][0]['labels'][0]['text']] I used means just to access the dictionary easier. Please note that I am working on dictionary so I have all_meanings &amp; other means (which points to part of the all_meanings). And other was typo, after [willm](http://www.reddit.com/r/Python/comments/m28sz/commandline_dictionary_using_googles_dictionary/c2xhh4l) pointed out, I updated the blog code &amp; forgot that "not".
&gt; * If you are using django, standalone script would be trashed with setting up django environment and settings, while celery implementation would be simple No. Django cron scripts should be written as manage.py commands.
What's with the manual type checking?
Computer, load up Celery Man please. 
&gt; This is confusing for beginners and should be avoided. Blanket statements always come up on things like this, but they're almost never relevant. If I'm posting in r/learnpython maybe I wouldn't use slicing, or maybe I would but I'd have a good comment on it. If I'm writing code at work, "what a beginner would think about this" would never even come up.
That was published before [PEP 3333](http://www.python.org/dev/peps/pep-3333/).
Why? Their docs explain how to setup the django evironment in your script ~3 lines of code at the top).
No, it's because it's the common convention for using gettext, regardless of the language. It doesn't really matter for the shell (I do regularly test Django stuff from the shell), because I'm not usually interested in translating strings while I use the shell.
You can install your cron-scripted application to any Django environment and expect it to work. Hardcoding the environment into the script might work sometimes, but the boilerplate for a manage.py command is also about three lines (plus a directory structure).
Why not while True: do stuff break then there's no variable at all, when you're done, you just break 
Recently I faced this same decision and went so far as to get the solution working with both Celery and cron to get the best feel for them both. I chose cron this time, but hope I get to work with Celery someday. The question can only be answered in the context of your needs, existing stack and architecture, and other factors specific to your team or organization. Celery does more than cron but comes with more complexity, maintenance, and risk than cron. The choice is simple in the abstract. You only need to measure the added costs (complexity and risk) of Celery against its added benefit. One should intuitively feel larger than the other. If neither does, always err on the side of the simpler choice. In this case, it's cron. If you think cron won't work, it was never a decision in the first place. As your gain experience you'll get more accurate and confident about this sort of comparison. You can't avoid making some of these decisions wrong early in your career. But making those mistakes are how you learn better judgment.
Yeah, installing system-wide tools like pip, virtualenv and distribute in a virtualenv ... that's silly and you should go troll someone else.
Let us know when you get muttweb running.
I use celery for tasks that are part of the application. For example, I want to hit an API and load up some data into my local database every ten minutes. That would be a celery task that is part of that application. That way when you deploy the application somewhere, you won't forget that task. I use cron for anything that is system level such as backing up the database or rotating logs. These reasons are completely for the purposes of organization. Cron works just as well for periodic tasks. 
I'm using celery to perform a computationally expensive calculation requested by the client in an asynchronous manner. So i tell celery to do some hard task that could take up to minute or more. If I eventually get thousands of users all requesting this computation, celery should be able to queue it up and handle them in an orderly fashion. I don't think I'd be able to do this in cron.
Two remarks: First, explicit type-checking is usually frowned upon in the Python community because you can't use the function with other, but compatible data types. On the other hand, Fermat's theorem is only valid for integers, so in this case, I think type-checking is warranted (although it might prove prohibitive for performance reasons eventually). BUT, only printing a warning and continuing with the execution makes the check pointless. It's better to inform the function's user of his mistake by throwing an appropriate exception: try: a = int(a) except ValueError: raise TypeError("Could not convert a to integer") See also lutusp's suggestion of using a single function for type-checking. Second, printing out information for the user should usually be done outside of the actual logic. Try refactoring your program so that check_fermat only checks the condition and returns a boolean whether the theorem holds. Let the caller decide what to do with this information.
However, if you are already using celery for other purposes, then using it also for background tasks makes a lot of sense.
But you said: &gt; And understandability is the **only** thing that matters.
I don't see anything there that conflicts it.
Over the last while I've been using NodeJS, MongoDB and Google's App Engine. Everything seems to have MapReduce functionality and frankly I was missing it when I went back to do some work in plane old Python. This is a nice short example of how it can be done.
Okay, maybe English isn't your first language. I'll explain. You said "understandability is the only thing that matters." That statement means that nothing matters except understandability. The Zen of Python is just one example of a style guide that explains that many other things matter, not only understandability. That's what I was saying was "so wrong".
Since you never return from either function, they are mutually recursive, which means that your call stack just continues to grow without bound. Eventually, if you input enough numbers your program would crash. That's really no way to write something that loops: you can't just keep calling the function to restart it without ever returning. Calling a function is not like a "goto" that just causes execution to move to a different point. A function call has to record and save the location on the call stack so that when the function returns, execution can continue where it left off. FWIW, this is how I'd write it. I use a dict for the values because it's easier to work with without having to repeat things: import re def supplyargs(x): while True: print 'values are:', ', '.join(k + " = " + str(x[k]) for k in sorted(x.keys())) instr = raw_input("type a,b,c, or n followed by a dash and the number, or type 'ready': ") if instr == 'ready': return x m = re.match(r"([abcn])-([0-9]+)$", instr) if m: x[m.group(1)] = int(m.group(2)) else: print "Invalid input, try again." def checkfermat(x): lhs = x['a'] ** x['n'] + x['b'] ** x['n'] rhs = x['c'] ** x['n'] print "a**n + b**n = ", lhs, " c**n is: ", rhs if lhs == rhs: print "This case proves fermat's theorem wrong!" else: print "The theory holds." return x x = { 'a': 4, 'b': 5, 'c': 6, 'n': 3 } while True: x = checkfermat(supplyargs(x)) 
Can I get a hat wobble?
If you're writing software for others on your team who may be the next to have to maintain it, then I'd say that a consideration of their skill level &amp; familiarity is more important than yours.
Edit: Whoops, didn't see that order is important but I'. If it wasn't you could use sets: http://docs.python.org/library/stdtypes.html#set a = set(some_list) b = set(another_list) a.issubset(b) You could try using the index method somehow. So use list2.index(list1[i]), checking if the indexes are incremented by one. The optional start parameter would be useful. This has been asked on Stack Overflow too, check the answers there: http://stackoverflow.com/questions/2250633/python-find-a-list-within-members-of-another-listin-order. The third answer looks good: http://stackoverflow.com/questions/2250633/python-find-a-list-within-members-of-another-listin-order/2251638#2251638
English isn't my first language. I understand perfectly what you mean. Python has been developed around a culture of understandability. Every added feature is evaluated not only for their usefulness, but for whether they handle as expected in every situation and whether they manage to actually make code more simple. In my opinion, every line of The Zen of Python is directly related to that philosophy. And there certainly isn't anything to conflict it. I might as well have highlight most of the text, but chose the most relevant line instead. My bad. More than that, it's a personal philosophy. Incidentally it's also being followed by a great deal of software engineers working today.
As someone who's done both I'd definitely stick to management commands from now on. If nothing else it means everything is contained in a cleaned, organised and portable structure. It is a case of each to their own, but I've had trouble with using external scripts and moving things around to different boxes with different setups, whereas management commands seem to be more likely to just work.
Nice, thanks for posting a very concise and illustrative example. 
I'm not aware of any difference in behaviour between.. a = [1, 2, 3] b = a[:] # or b = list(a) However if you have a function which needs a copy of an argument, it's not unreasonable that someone might pass something that acts like a list, and would be confused by getting an actual `list()` back, e.g: &gt;&gt;&gt; import numpy &gt;&gt;&gt; npa = numpy.array([1,2,3]) &gt;&gt;&gt; npa[:] array([1, 2, 3]) &gt;&gt;&gt; list(npa) [1, 2, 3]
ya, and may be i should. because you go out and corrupt out the system libraries, for every new website/app you want to run.
&gt;plane old Python Might want to change that before the grammar nazis come and get you. 
thanks, done
Great job on the article itself though.
Breaking isn't as desirable as having a flag that controls the exit. Imagine that you open a file during the loop, or have try ... except error trapping code. Or both. With such things in place, it's harder to know what the break will actually do, and you might end up with open file handles and dangling resources. With a flag, the exit is cleaner and easier to understand. 
As always, it depends on your use cases. It also depends on your queue. **Concurrency** Say you run a cron task every minute. The cron task pops one or more jobs from the queue and executes them. What happens when one job hangs and the cron tasks start taking longer than a minute? What happens when two overlapping cron jobs (multiple workers) read from the queue? How do you manage simultaenous enqueues? **Privilege Separation** If it's in /etc/cron, it should probably be sudo'ed to a user without write permissions on your codebase. **Atomicity** If you need to make sure that every task is executed exactly once, you're at the mercy of the queue's persistence. Say a disk or the AC fails in the middle of executing a stack of 10 tasks: where did they go? Filesystem journaling won't solve for that. You could maintain a list of tasks and their execution states, but then you'd just be reimplementing Celery, which may or may not be the focus of your project. **Rate Limiting** Say you get 100 task-enqeueing requests in one second. How many should be executed at a time? If your cron job only processes one task every minute, that 100th request is going to be waiting over 100 minutes before the task even executes. Even if each task only takes a few seconds to execute. **Task Variance** Say you have 5 types of tasks with varying average execution times, and one 4-core server. You could run 5 cron tasks every minute, but then you'd basically be implementing celery workers. And you still wouldn't have all the other great features of http://github.com/ask/celery . 
Borerline related, but here's a cron gotcha, that's caught me out more times than I'd like to admit: If you're using the 'date' command in your cronjob, you need to escape % symbols if you're using them. The thing about cron is, if you're running it as a user without permission to the cronlog, you can't see why your job has failed. Absolute paths, and anything else you might need to escape, even though it works in the shell can be a nightmare if you're unfamiliar with cron.
Concurrency: Can't this be solved by putting an ampersand at the end of all your commands?
also see my answer, i advocate to use virtualenv-burrito, it is not installing a system wide tool, they are put at a convenient location ~/.virtualenv &amp; ~/.venvburrito. please understand how to setup a sandboxed version of python. please.
Judging from all the responses, I'm completely amazed by the intelligence of five year old redditors! 
I'm siding with this post. When I set up a cron job and it doesn't run, I immediately wonder what I did wrong. Only twice in my 25 years of unix sys admin did I question crond, and I was wrong both times.
If your machine's policy is configured to log failed authentications, you could use [pywin32](http://sourceforge.net/projects/pywin32/) or possibly [wmi](http://timgolden.me.uk/python/wmi/index.html) to get the event logs.
Why do you hate haskell?
I believe that might be referred to as "Resource Exhaustion"
http://www.linuxpromagazine.com/Issues/2009/103/Security-Lessons/%28kategorie%29/0
Check out kivy.org, not python 3, but you can make apk for market and some fancy UI (render with openGL an has great support for multitouch). As added bonus you app will also run on Linux, windows, and osx without modification (and soon hopefully is too)
I'm trying to access the security event log folder with pywin32 but I keep getting this error : error: (1314, 'OpenEventLogW', 'A required privilege is not held by the client.') any idea how I can fix it?
Celery is crunchy?
Yup kivy that is what I was trying to remember. Thanks! 
You probably need to run your command prompt as administrator to get the required privileges.
Gotcha. Thanks. EDIT: It worked. Thank you.
You know what, I've got better things to do (as evidenced by my lack or response over the weekend). If you want, you can tell everyone that you won and not one damn shall be given. You don't like whitespace, and nothing I do will change it.
Use a finite state machine to keep the session -&gt; backend mapping correctly and detect if either end gets into an invalid state, so you can kill or get the problem back to a known state. Pyparsing is _awesome_ tool, Its considerably more useful and I hope to never use regex again. If your interactions with the app are very well defined (ie you can map out query/response for every screen) you can perhaps only send input in bulk to the application. If you're "doing it right" you can skip a lot of the keypress -&gt; app integration and just pipe entire lines to the remote end via ajax. If you can validate it client side, (and server side before handing it off to your app) you should be able to remove a lot of the delay for processing.
This is pretty cool, ~~however, audio isn't working... I just went to pandora.com to make sure that it wasn't a different problem, and the audio played just fine.~~ EDIT: looking at the output from the logger, it appears the "peer closed the connection" is happening after every single song tries to load.
I don't see any argument in your post. It's not helpfull at all. It just shows that you feel offended, which was not my intention. The OP is not asking for the ultimate business idea to make a fortune. In that case you were right. It's unlikely that someone knowing how to do it will tell everyone on reddit. But the answers so far prove that people are willing to help a newcomer taking his first steps.
&gt; I don't see any argument in your post. Yes. As intended. &gt; It just shows that you feel offended ... Not at all. &gt; The OP is not asking for the ultimate business idea to make a fortune. It's all on a monotonic scale. "How to make small amounts of money" is on the same scale as "How to become a millionaire." It's a difference of degree, not kind. &gt; But the answers so far prove that people are willing to help a newcomer taking his first steps. Are you implying that my reply wasn't helpful? Believe me, I know this business up, down and sideways (references [1](http://en.wikipedia.org/wiki/Paul_Lutus), [2](http://en.wikipedia.org/wiki/Apple_Writer), and [3](http://en.wikipedia.org/wiki/Arachnophilia)). My advice was spot-on. It just didn't fit the conventional mold. 
&gt; Are you implying that my reply wasn't helpful? No, your first post was certainly helpful and was backed by arguments. As is your last post. 
Very nice! In class we were given [mrjob](http://packages.python.org/mrjob/) to use as our MapReduce library, but yours requires nothing by the standard libs. Obviously yours doesn't automatically connect to EMR or Hadoop, but it's quite succinct.
My take on using celery for cron jobs is the task now sits in your project and is managed automatically. This makes it so your not having to make changes to the cron. The other thing to think about is that celery can be used in a distributed manner, while cron I'm assuming isn't designed for a distributed setup.
you will code yourself into a corner if your mentality is so absolute to think readability is the *only* thing that matters, sure it's very pronounced in python but it's not the only thing
Thanks for the feedback. I'm having a hard time reproducing the bug, but I'll do some more poking around If anyone else is also having a similar problem, please update here: https://github.com/amoffat/pypandora/issues/26 Thanks!
Code myself into a corner by using descriptive names? I didn't think such a thing was possible.
1. A preiodic cron script runs on a single server, so all your tasks will be running on 1 server. 2. Cron isn't a queue, you will just be running all your tasks at once every time your cron interval hits, so you are wasting all that time in between intervals. Celery will queue up and execute them as soon as possible.
Very cool. Demonstrates the power of python.
There are a couple ways to list all the available modules, whether standard library, other installed stuff, or your own Python scripts: pydoc 'modules' # from command line help('modules') # within the interpreter Be sure to put quotes around the word `modules` when you do this. Anyway, these techniques won't tell you where the modules exist on your file system, but they do list everything that can be imported. To list the names and paths of all the modules you have *already* imported, do this: from pprint import pprint import sys pprint(sorted(sys.modules.items())) Some modules, such as `_codecs`, `exceptions`, `sys`, and `zipimport`, are "built in" to Python and have no path: ('sys': &lt;module 'sys' (built-in)&gt;) Others are compiled C code: ('itertools': &lt;module 'itertools' from '/usr/lib/python2.6/lib-dynload/itertools.so'&gt;) And the rest are compiled Python: ('glob': &lt;module 'glob' from '/usr/lib/python2.6/glob.pyc'&gt;) 
How to set up a development environment for Google App Engine, Python2.5 in Ubuntu 11.10.
Hey again. I am currently trying to install `djangopypi` for a more thorough evaluation, but I don't get it to work. I did a `pip install djangopypi` but I don't know where to go from here. Is there a `wsgi` script somewhere to run it through `mod_wsgi`? I am currently trying to decide whether I should continue developing my application, or help out with `djangopypi`. But so far, I don't understand the install instructions... :/ Can you help?
It's really easy, the APK will install just a launcher and the script will put in /sdcard, then when you launch the program, it'll call python yourscript.py instead
Like you're five? Okay. If you eat cookies all at once, you'll get a tummy ache. But if you eat one cookie every once in a while, by the end of the day, you'll have gotten to eat a lot of cookies! Edit: Christ you people are boring.
Celery is *not a cron replacement*, but it can be used as one. That can be convenient if you already use Celery, or you have lots of cronjobs that changes often. 
There is a name for the behaviour: reference semantics.
&gt;If I'm writing code at work, "what a beginner would think about this" would never even come up. The idea is that "Would a beginner understand this?" is often held as the gold standard for "is this code as readable and as simple as it ought to be?".
Python programmers should drop a common idiom because its only claim to idiomatic status is that it propagated well. There's even an argument to be made that because "explicit is better than implicit", we should really use `copy.copy` to clone the list.
&gt;&gt;less cryptic &gt;Barely [:] is cryptic in that you have to realize that slices create new lists, rather than views. &gt;&gt;and more pythonic? &gt;I don't see how. By using `list()`, we indicate that we are constructing a new object by *using the constructor for the type*. It's hard to get more Pythonic than that.
If we want to be explicit and frame our creation of the object as copying, we can use the `copy` module. That's perfectly Pythonic as well. I don't think that experience in other languages is relevant to the question of whether something is "obvious", really. Iterating indirectly via indices isn't "obvious" to new students of C or C++ (ones without experience in other programming languages) at all, and the entire concept of arrays often needs ridiculous amounts of explanation (especially because you want to be able to explain certain quirks away by saying "they're not first-class objects", but then you'd have to explain what that even means).
"It can be done this way" is a recommendation?
BTW: You can write `not not ...` in Python and it works the same way, but isn't considered idiomatic in the slightest. Presumably because if you really needed to explicitly convert to boolean, the obvious (and actually shorter) way is `bool(...)`.
PandoraException: com.savagebeast.radio.api.protocol.xmlrpc.RadioXmlRpcException: Access not allowed due to licensing restrictions for your country :(
Don't split things up just for the sake of splitting them up, and don't join them together just for the sake of having them all in one place. My personal rule of thumb is to start looking for natural ways to split a file if it reaches 200 LOC, and start freaking out about it being too long if it reaches 500 LOC.
&gt; Python programmers should drop a common idiom because its only claim to idiomatic status is that it propagated well. Who is claiming that's its only reason to be?
According to [http://www.pandora.com/restricted](http://www.pandora.com/restricted), "we can no longer allow access to Pandora for listeners located outside of the U.S." Great, if you don't live in the US, you don't exist. It's a pity, I wanted try this script. I have never heard of Pandora before.
I am, now. I'm not especially well prepared to defend the claim, but it's an expression of how I see the situation.
That wasn't the point, you made an absolute statement and a person called you out on it. I agree that the example you showed in the top-most comment is probably the best one, but that is far from having anything to do with "understandability is the only thing that matters"
Fair enough. I just tried a totally unreliable study at work with two of my colleagues whom I'm "teaching" the basics on Python and I asked them what [:] did. One of them already knew but the other didn't and, indeed, failed to get "at first sight" what it did. However once I explained to him slicing and how you could benefit from it to copy the list, he seemed to find it so easy that he felt happy enough about it. I really consider this one to be a simple enough idiom that can't cause any harm once you've been told about. In fact my colleague didn't like the copy.copy(l) way because it felt it was too verbose ;)
Celery has a clean API, but orchestrating communications between celeryd, ( Django / Flask / ... ) , and RabbitMQ can be a real pain. If you're like most people and don't need to do async callbacks or webhooks on your tasks then just use cron.
&gt; [:] is cryptic in that you have to realize that slices create new lists, rather than views. You find that out when you find out what slices do in the first place. &gt; By using list(), we indicate that we are constructing a new object by using the constructor for the type. It's hard to get more Pythonic than that. That's all fine and well, but it's not significantly more Pythonic, at least not obviously so. You've taught the person a less versatile construct primarily because it looks more English.
doesn't having your import inside the inner loop slow down copy needlessly?
It depends on if the purpose of the course is to learn Python, or to learn to design algorithms.
1. When using cron, you make your user wait up to 1 minute without any reason. With Celery the tasks start as soon as possible, as opposed to starting task in the nearest starting minute. 2. When using cron, you need to introduce locking (flock()) if there's a chance your tasks execute for more than 1 minute. By introducing locking you make it impossible to execute a few tasks in parallel. Your alternative to locking is marking tasks as "in progress", then you have to handle all the corner cases (fatal errors etc) and you're not using time tried technology anymore, you're rewriting celery. 3. Cron doesn't help you if you outgrow single server's processing power. Celery does help with concurrency, in cron you need to add even more control logic to support it properly.
With cron job you add more and more corner cases and in the end you end with a poor man's celery substitute that has more control logic than business logic.
Neat script, can't wait to try it out when I get work. Just a suggestion. I know it is awesome to be able to say 'a single python script', but putting in the compressed webpages and javascript obfuscates the code a bit (and doesn't quite make it pure python ;) ). Breaking some of the classes out into their own files, and leaving the uncompressed js and html, would make it easier for people to contribute. Cool stuff nonetheless.
web2py provides two mechanisms for running background tasks. A cron like mechanism (which does not rely on os cron) and a task queue mechanism (which does not rely on celery). They are different. The cron based one guarantees that tasks run when you want them to run whether or not the tasks that started previously have completed or not. This means that if a task takes longer then expect and requires access to the database, it may lock the database for another instance of the same task. This means that cron guarantees start time but does not guarantee constant resource consumption. The queue based system instead is distributed and designed to guarantee constant resource consumption. A worker only picks up a new task if the worker is available. This means that tasks that are scheduled but do not find resources available are delayed and may even be skipped (under certain conditions). This latter approach is safer. Celery is a possible way to implement the second approach described above. EDIT: In fact there is a "web2py_celery" plugin but nobody has had a need for it since we have never encountered a case where the distribution of tasks is the bottle neck (running the tasks is).
It's been there for at least four years now. To bypass this I successfully used [hotspot shield](http://hotspotshield.com/) few years ago. Didn't try it since though...
What do you mean by 'dynamic, automatic'? I don't know web.py (did you mean web.py or web2py? I didn't know web.py had its own ORM but I digress). With Django South, which I'm most familiar with, you change you model, run ``schemamigrate`` command of ``manage.py`` with ``--auto`` (or ``--initial`` for the first) then run ``migrate``. Is that 'dynamic, automatic' or are you looking for something that like detects any change in your models and updates your database schema automatically?
You don't need to submit everything from your own blog every time you write something.
Yeah, which is why this comment at the end of the article concerned me: *"90% of the time [:] could be replaced by list(). Of course it wont work for everything since the two are not strictly equivalent, but it is worth trying"*
Yes I did. And in this case, it's the only thing that matters. Do you really think that in the case of a simple for-loop you should exchange understandability for being more "pythonic"?
A nifty bit of code, unfortunately one which I wish didn't exist. If you like Pandora's service using tools like this only makes it harder for them to stay in business. The only way they can afford the license fees for streaming music is by selling subscriptions and selling advertisements. Making an end run around their ability to making advertising revenue while at the same time maximizing the ease with which you can stream music is certainly not going to keep them around any longer. It's especially lame since they recently did a full site redesign to use html5 exclusively which should pretty much guarantee a nice consistent cross platform experience without going through the gyrations of writing and/or using something like this. 
Web2py, yes. Thanks. And that's exactly what I mean: change your model, restart (or run a migrate command), and changes are detected and the schema is updated.
Don't know what exactly you mean. For me sqlalchemy-migrate is too much work. So I've 3 servers, dev, stage and production. On dev I always recreate all tables. Then I generate a change script using apgdiff. Run that on stage, see if everything worked and finally run it on production. 
I updated my post to offer a bit more explanation. Ideally, if I change my models, on restart (or command), the change would be automatically recognized and the database schema would be updated. I agree on too much work with sqlalchemy-migrate. I'll google apgdiff right now. Thanks.
Umm, from your description it sounds like you talking about [Reflection](http://www.sqlalchemy.org/docs/core/schema.html#reflecting-all-tables-at-once). Or are you looking for the reverse of reflection, where you want to be able to change your (python-defined) schema, and have SQLalchemy update the database schema to match? If it's the latter I would recommend against it. It would be wiser, I think, to get used to modifying your database with SQL, then have python automatically reflect those changes. Much simpler and less prone to problems.
Well not sure about this scriot but i use pianobar from the console and it uses the login of my Paid account. I had nothing but problems with flash. After a few hours i have to shut the entire browser and be sure to kill off any seperate processes. Having it in the console is a life saver. If you pay there are no ads anyways ad far as i know.
The import is in the setup statement which is executed before the timer is started.
Yup, use a for loop. map should be used only if you care about the return value.
Some reasons you might prefer to do it through your ORM is that it ideally maintains your database agnosticism and allows you to easily reverse the migration. How does reflection work with custom ``__init__`` and added classmethods and such?
It would be nice if they noticed this, and hired ifyouwill to write a sponsored client.
I don't see how this is better than using 'i'.
Using "_" works everywhere.
Can you post a concrete example where one of the problems you described occurs? I would imagine that if you code your loop using a break, you will also take care of dangling resources etc (which you have to do either way). 
Why? A while loop is more verbose and less readable.
since documentaton is sparse here is nice example rom net http://jon.oberheide.org/blog/2008/10/15/dpkt-tutorial-2-parsing-a-pcap-file/ and http://jon.oberheide.org/blog/2008/08/25/dpkt-tutorial-1-icmp-echo/
Not sure actually, I don't use it myself, although I should. I use sqlalchemy-migrate, which does maintain agnosticism and also allows you to reverse the migration, however unless you also use reflection with it, you have to modify your schema in two places which is a bit irritating. sqlalchemy-migrate + reflection seems to me like it would really handle both issues nicely.
For my workflow, I would like to make changes in the ORM, and have those changes migrated to the database automatically. Again, I understand the risks, but, for simple things like adding columns, automatic would be nice. But you're saying that the reflect function can create python objects based on the database schema? I suppose that would a workflow that would be simple and efficient.
I imagine the majority of users are not of the paid variety. But, the ones who are aren't the problem, imho... Although iirc pianobar also allowed things like unlimited track skips which could be problematic in that it could allow users to subvert the skip limits which, I'm fairly sure, exist to allow for Pandora to operate under a statutory license as a "non-interactive" streaming service. If a user can skip an unlimited amount of times and the audio is fetched via http then it is only a very small programmatic jump to write a client which just downloads tracks at a rate much faster than they could be listened to. I'm just a guy who wants decent music services to stay in business...
This looks similar to [scapy](http://www.secdev.org/projects/scapy/), but less flexible...
&gt; Can you post a concrete example where one of the problems you described occurs? No, but I will say that "break" breaks out of the immediate controlling block, and for a function written with multiple nested blocks, where the "break" goes is sometimes difficult to sort out. It's an issue of clarity, sort of like avoiding "goto"s and labels, more for the benefit of the programmer than the program. It's just another obscuring factor in coding, best avoided when possible. 
Perhaps it's significantly faster? Then it might still be useful.
ah, indeed. never mind then :D
It is not difficult unless you have countless lines in each loop. It is very straightforward actually, and in my opinion often easier to read than keeping track of the loop flag.
[Instructions on using Python 2.7 in App Engine](http://code.google.com/appengine/docs/python/python27/using27.html)
I believe a large chunk of PIL is implemented using CPython. PyPy has alpha/beta-level support for the CPython C API. You will need to recompile PIL for PyPy. See http://pypy.org/compat.html for more information. From my understanding, even if you manage to use PIL C code with PyPy, you will only get the benefits on the part that is coded with Python. PyPy is good to improve performance of Python code. It is not meant to improve performance on C code. In the link you provided, PyPy is used to improve the performance of Python code that does the image processing. If you want to improve the performance of your existing project, I would suggest you look at traditional tips that are still very good for everyone: http://wiki.python.org/moin/PythonSpeed/PerformanceTips . I would pay close attention to the *Profiling Code* section.
Chickenbut!
It already does download 'nd tag. 
Answer: There sure as shit should be! It's sad that us Python programmers have to resort to using these clunky semi-proprietary ruby tools to do configuration management. Python would be awesome for configuration management and it looks like there are some promising projects being started but nothing has really gelled yet. To the Ruby community at large: We don't need no stinkin Ruby DSL. I get along with my programming tasks everyday without Ruby DSL's and I think the SCM problem is no different. Come on somebody get pumped and write that awesome Python SCM tool. I'm too busy to do it, but someone out there should! :) 
I've been thinking about it as everyone is asking me so I might build something into alembic for this. It really isn't nearly so complex as people seem to keep thinking.
It won't do what you want. `extend` mutates the list and returns None, so this will create a new list, append the items in old, then throw it away and set `new` to `None`.
I completely agree. They are the only languages I use for anything serious.
When I listen to Pandora, I do so with pianobar. I don't have a paid account. I'm perfectly fine with listening to advertisements. I just despise Flash (I had no idea they just changed to get rid of it) and prefer to have a small little UI in one of my terminal windows. Spotify, imo, is doing is right. I don't like their player interface, but that's cool, because Clementine now has Spotify support. Direct support, because Spotify allows API access to people with the super-paid accounts (I forget what it's called). So, I pay $10/month simply to have their music integrated with the rest of my music, in my preferred music player. Pandora could, I think, do the same. As with drug legalization, openly providing information to developers allows you more control.
While some of rst's features are a bit irksome, I find the sphinx tool extremely powerful and love it for the quality documents that it produces (with a tiny bit of effort). Kudos to Georg!
Why even mention `easy_install` when `pip` is mentioned later and even with a bold heading saying it's better?
It's used (once) to install pip.
thanks, it'll be useful when pasting some source code in HTML
You could skip `easy_install` all together and use any of the methods [here](http://www.pip-installer.org/en/latest/installing.html).
Thanks, I didn't know that pip had its own bootstrap installer script. Still, you need distribute as a prerequisite, which creates easy_install. I think that some people find it simpler to just easy_install pip instead of dealing with pip's bootstrap script.
Boto is a good library, though I have always thought it was pretty messy compared to python-cloudfiles, another library I have used. Boto is very actively developed with lots of contributors, including myself. I recommend it if you need to talk to AWS with Python.
Try [PyFFmpeg](http://code.google.com/p/pyffmpeg): &gt;We have recenlty performed a complete rewrite of PyFFmpeg. Now, PyFFmpeg can work with NumPy, Python Imaging Library (PIL), and Cairo. It supports video and audio decoding. It also supports reading from internet streams. I haven't used it, but the [examples](https://github.com/tranx/pyffmpeg/blob/master/examples/playvideo_qt_alsa.py) show how to set a callback to get track data in a NumPy array as a clip is played. 
ah cool thanks, seems that on closer inspection there are numpy bindings in the source.
Reading the code is not to be underestimated. Reading code is definitely not an improper way to learn the standard library.
Look up something called the log function. Log base 7 of your number is the number of management levels
... I think you're off slightly. Pretty sure (also medicated) that log base 7 of *x* would show you the number of management levels necessary to manage *x* lowest tier workers, instead of *x* total workers including managers.
i'm in the same boat as earthboundkid, and he's right. it's hateable because it does everything right but doesn't deliver. it does open your eyes tho
If you want the total number of workers, it's just 7^levels . 
Again wrong for the same reason: Let's make this simple. A span of 3 employees under a manager (For simplicity I'll assume the top of the tree is not starting with a single president [otherwise we'd start with an exponent of 0]). Tier 1 = 3 ^ 1 = 3 (3 managers) Tier 2 = 3 ^ 2 = 9 (3 employees under 3 managers.) Total Employees is the sum of both tiers. (3 ^ 1) + (3 ^ 2) = 12
Right, okay, so it's really sum{n:1-&gt;levels}{7^n }. I guess the point is that it's still a closed-form solution that you can calculate, there's no need to write a program to simulate anything. 
That mirror's my thought on this challenge. -- If anything write a few convenience functions so you can experiment with some numbers and formulas to see the outputs. TotalEmployees(numLevels, span). EmployeesOnLevel(curLevel, span). Maybe play around the idea of ``span = (currentLevel - 1) * growthRate`` But you're not going to find an exclusive solution to this problem if you're going to allow the span to increase, because then your going to have to ask yourself what defines the growth rate for each span is it incremental, is it exponential, is there an upper limit? 
It's probably sufficient to just have 2 spans: a broad one (say 10) for the lowest level, and a narrow one for everything above that (say 5). This seems to reflect my experience in which organizations tend to reflect natural product, sales or other divisions - which often interferes with a more broad division of labor. 
What would the workflow for migration with such automaticity built in look like? 
What do you mean it doesn't "deliver"? (Sorry, I'm a programming newb.)
There are no major projects in Haskell in mainstream use. It's unfortunate, and seems incredible. http://www.reddit.com/r/programming/comments/l5n8e/monoids_in_python/c2q1hg8 After all the effort one can put into learning Haskell, you are left amazed at what can be done, but unable to actually do anything useful. It's my belief there's an impedance mismatch between how computers and fundamental libraries work, and how FP wants to work. Computers are *not* functional, and are all about state. That said, since you are a noob, Haskell will enable you to learn a lot about clean code, it makes state difficult, but concurrency, strong typing and clear thinking very easy.
That was very good written. 
Yup, a very common misunderstanding. 
Why is sort a class?
so alembic works at a superficial level like migrate, where you make new "migration" files: alembic revision -m "upgrade the new accounts table" that will create a new file with an upgrade() and a downgrade() method: """upgrade the new accounts table Revision ID: 2b1ae634e5cd Revises: 3512b954651e Create Date: 2011-04-21 15:43:04.368999 """ # downgrade revision identifier, used by Alembic. down_revision = '3512b954651e' from alembic.op import * def upgrade(): pass def downgrade(): pass my idea is to add a flag, `--include_auto_upgrade`, which will expect that the migration environment (this is a set of scripts alembic provides upon init which allow configuration of pretty much everything that occurs when it runs) includes a reference to a `MetaData` object (or several, if you customize it). The `MetaData` will be run through a function that, in conjunction with a target `Engine`, will compare the list of tables currently present to that in the `MetaData`, producing a collection of "create"/"drop" commands, will compare the list of columns in each table, producing a collection of "add_column"/"drop_column" commands, and further into each column to inspect the type and NOT NULL constraint. Other features such as CHECK contraints, foreign keys, and indexes can also be added to this system. The commands then are provided into the `upgrade()`/`downgrade()` functions when the file is generated: """upgrade the new accounts table Revision ID: 2b1ae634e5cd Revises: 3512b954651e Create Date: 2011-04-21 15:43:04.368999 """ # downgrade revision identifier, used by Alembic. down_revision = '3512b954651e' from alembic.op import * def upgrade(): # generated by alembic revision create_table( 'accounts', Column('id', INTEGER, primary_key=True) Column('name', VARCHAR(50), nullable=False), Column('description', NVARCHAR(200)), ) add_column('organization', Column('account_id', INTEGER, ForeignKey('accounts.id')) ) def downgrade(): # generated by alembic revision drop_column('organization', 'account_id') drop_table("accounts") so you'd get the usual revision file, ready for editing, but already populated with "simple" changes. You can then tailor the instructions as needed, add in extra moves of data in between steps as needed, etc. **edit**: this is basically writing the spec on reddit, so if anyone has suggestions/adjustments to this scheme let me know. **edit**: [Alembic Documentation, Initial Version](http://readthedocs.org/docs/alembic/en/latest/index.html)
Ah, you're right. I Thought through it and the log only works on binary trees (2 workers per manager). You were actually a little bit off with the numbers you posted below - you left out the president, which is the 3^0 term. Also, with the span question, just change the last term in the sum calculation to be spanA^(n-1) * spanB instead of spanA^n. To generally support arbitrary spans, you need to keep track of the number of managers at the previous level, and multiply that by the span of the current level.
If you use the same trick as you used for invatomicmasses, you will find an error in your data: You have two elements with a symbol of 'Ru' in symbols, ruthenium and rodium.
1. I have no idea what you're expecting `break` to do outside of a loop in your `__init__`. I assume you logically require either a file or a url to proceed. The Pythonic way to handle that is to take a single parameter, use some kind of try-except logic to figure out whether it's a file or a url, and read the data accordingly. If you can't construct the object, raise an exception of some kind. 1. There's no point storing a `file` attribute for the class, since you already parsed the data. In general, open file streams/file handles make poor class attributes. 1. Don't tell Python how to accumulate lists. It knows already. In fact, you don't really need a list here, just a generator that can feed into the set: def actives(self): #here converting to a set removes duplicates return list(set( active.text for active in self.xml.findall( "//{urn:hl7-org:v3}activeMoiety/{urn:hl7-org:v3}activeMoiety/{urn:hl7-org:v3}name" ) )) 1. Extract a common helper function that does the date parsing and formatting, and then use it for both `start_date` and `revision_date`. The only difference between the two methods is the determination of the `date_string`, which would be a parameter for the helper. 1. For the remaining functions, there is no point in assigning to a variable first. Just `return` the expression result.
PIL works fine with PyPy: just create a virtualenv with PyPy, and pip install PIL. As remyroy points out, only the Python part of your code will be sped up by PyPy, but it seems that in your case it should be enough.
You could do something like this: from xml.etree.ElementTree import ElementTree import urllib from datetime import datetime def normalize(path): return '//{urn:hl7-org:v3}' + '/{urn:hl7-org:v3}'.join(path) def findall(xml, *path): return xml.findall(normalize(path)) def find(xml, *path): return xml.find(normalize(path)) def parse_date(node, attrib): return datetime.strptime(node.attrib[attrib], '%Y%m%d').date() class DrugLabel(object): def __init__(self, src): xml = ElementTree() xml.parse(urllib.urlopen(src)) actives = set(active.text for active in findall(xml, "activeMoiety", "activeMoiety", "name")) self.actives = list(actives) self.start_date = parse_date(find(xml, "effectiveTime", "low"), "value") self.revision_date = parse_date(find(xml, "effectiveTime"), "value") self.label_type = find(xml, "code").attrib["displayName"] # etc for other attributes. if __name__ == '__main__': d = DrugLabel('http://www.accessdata.fda.gov/spl/data/d313c9f7-af11-4c2c-a374-cba1e1b2e842/d313c9f7-af11-4c2c-a374-cba1e1b2e842.xml') d2 = DrugLabel('test.xml') #local copy print d2.actives, d2.label_type, d2.revision_date, d2.start_date 
I would try loading PIL and getting my image data to a numpy.array structure and the implementing an algorithm on top of that. Getting each pixel using PIL structures will be slow (a lot of C/Python crossing using an innefficient bridge). Feel free to discuss this on #pypy IRC
Out of honest curiosity, why single page "architecture"? 
I too thought it was an odd choice of wording. (I did not write this article)
Rather than storing all the data in the script, you might want to load it from a file, probably a CSV file. This would make it easier to check, or to add another column. A few more suggestions: * sort() could just be a function, not a class. And you could give it a clearer name. * That "finally: pass" in the middle isn't doing anything. * Testing "type(float(decision)) == float" is a bit odd - if float(decision) doesn't raise an error, it will always produce a float. It works, but it's an odd way to do it. * When you call sys.exit(), you give it exit code 1. By convention, we use 0 when the program is closing down normally. Good luck!
This is an incredible abuse of classes. Python is not Java; your code is not expected to go into a class just because. `sort()` makes more sense as a plain function. There is also no need to forcibly `exit` the program (and especially not to wrap that up in another function); just `return` from `sort()`, and you're done. Actually, `sort()` is a bad name, as it doesn't describe what it does at all. To be honest, there isn't really a need to extract this to a function, for the simple reason that there's so little else going on. The explicit type coercions and checks are also incredibly awkward. For example, `decision` must be a `str` already, and converting it to a `str` after checking that it's a `str` (which will always succeed) is redundant. That code could also go in the `except` block, to get full use out of it. print "Input one of the following: \n\nExact atomic mass\nAbbreviation of element (with first letter in caps)\nFull name of element (no caps)." while True: print "\n" user_input = raw_input("&gt; ") if user_input in ('exit', 'end'): break try: # By the way, this sort of lookup should not be counted upon to work. # Floating-point numbers are strange beasts. symbol = invatomicmass[float(user_input)] print "The element with the mass %f is %s, and is abbreviated as %s." % (user_input, inv_symbols[symbols], symbols) except KeyError: print "No element has that mass." except ValueError: # must not have been given a floating-point value. try: if len(decision) &lt;= 2: print "You said %s, which is also %s, and weighs %f." % (user_input, inv_symbols[user_input], atomic_mass[user_input]) else: print "You said %s, which is also %s, and weighs %f." % (user_input, symbols[user_input], atomic_mass[symbols[user_input]]) except KeyError: print "No element has that name." print "\nThanks for using the Python periodic table search engine!" 
Any Python 2/MySQL book should be pretty much the same thing, so I'd start there.
What about that superfluous finally statment?
It fucks with my graphic's drivers settings when I turn it off, *so annoying*.
this is really not a right place to troubleshoot, but I see a couple of issues with your setup. First, did you install virtualenv using pypy or are you trying to use CPython's virtualenv? You need to create a separate one. Second, this means you won't have /python27/lib anywhere on your sys.path, otherwise stuff gets confused.
I rewrote it removing the recursion hope this helps: http://pastebin.com/GCYigYpY
&gt;The holy grail of web application architecture is not the single-page application. It is the single-page application that works as a multi-page application if you dont have Javascript enabled. it is?
Wow, you guys are awesome. This was my issue number 1 with Plone and you just solved it!
Is there a lot of stuff that you need that you couldn't write simply by yourselves? [pyBrain](http://pybrain.org/) might offer something, but might not be the kind of A.I. package you're looking for.
Thanks for the link. We had a quick look at it and I'm not sure it's exactly what we need. The agents in the project have some basic knowledge and can learn through the user and/or other agents. So i think Machine Learning in this sense is slightly off (or just too evolved, it's only a "small" project). Overall our goal would be to not have to recreate stuff already created. Particularly, we would also like to be able to do "ai stuff" using Python instead of Prolog. In the end we might just use some Prolog bridged to Python using the above mentioned pyswip ; but if we could somehow find a Python way to do things similar to what Prolog does (without having to mess up with Prolog ;) ) it would be great.
I'm extremely interested in what your project. Will you be posting results?
Heh, sure why not ;-) If you want the full subject i can PM you the suject but it's all in French.
as fijal said, you need to create a virtualenv specifically for pypy, while from the message it seems that you are trying to use a virtualenv created with cpython. Try virtualenv -p /path/to/pypy http://doc.pypy.org/en/latest/getting-started.html#installing-using-virtualenv
I wasn't entirely sure if this belonged in /r/python, but I was wondering what people thought about this approach. 
You should check out [AI Challenge sponsored by the Goog](http://aichallenge.org/starter_packages.php) While not an existing framework, it will probably give you some good ideas on how to start. It's got examples in multiple programming languages too.
I would probably store the data as an dictionary of lists: elements = {'Ru': ['rhodium',102.91, 44], 'Pd': ['palladium',106.4, 46]} elements['Ru'] elementName = elements['Ru'][0] good luck and have fun! * edited for formatting *
for getting started with agent based modeling (what you're describing) i'd recommend [netlogo](http://ccl.northwestern.edu/netlogo/). if you really want to stick to python, there's [simpy](http://simpy.sourceforge.net/) but i've never used it edit - [this list on wikipedia](http://en.wikipedia.org/wiki/Comparison_of_agent-based_modeling_software) might be helpful too. edit again -- it seems that python can be used with [repast](http://repast.sourceforge.net/) too
while in sauna ;)
Pretty good for a first try. Just one remark: print "You said",decision,",which is also %s, and weighs" % (inv_symbols[decision]), atomic_mass[decision],"." Mixing concatenation and string formatting is a bit confusing, use one of the other
What is it you actually want to learn? If you just want to learn how to SELECT and INSERT data the [DB API 2](http://www.python.org/dev/peps/pep-0249/) documentation should be sufficient. You'll need a MySQL python driver. I'd suggest either "MySQLdb" (old, lots of old web pages referencing it) or "oursql" (strongly pushed by the people in #python the last time I visited, which was admittedly a while ago) If you want to learn generic SQL and how to use Python with SQL, and the MySQL part is just because it's free/easy, I'd recommend [Head First SQL](http://www.amazon.com/Head-First-SQL-Brain-Learners/dp/0596526849/ref=sr_1_1?ie=UTF8&amp;qid=1320783763&amp;sr=8-1). It doesn't cover python at all, but the DB API 2 driver is extremely straightforward If you want to learn something else .... what is it you want to learn?
Regarding c:if you're intention is to use it to speed up your python code, interface it with c/c++ code and learn about pointers, memory management and static typing (i.e. staying closer to the metal), Cython might be more usefull than c. Cython is basically python but with the option of bolting on the stuff of c to python. So you can start with a python code, run it as cython code and then adding all the goodies of c where you need to make it run as fast as c. 
My group participated in the Multi-Agent Programming Contest this year. We used pyswip and it worked wonderfully for us. The main perceive/act loop was implemented in python, as was percept xml processing and communication among agents. pyswip then asserted all knowledge and called prolog for for the reasoning part.
I've done agent-based modelling in Python before and really had no use at all for the libraries that are available. If it were a linguistic model you were investigating, I'd highly recommend NLTK, but for an agent system, there's no advantage in using a framework; you are not going to get around describing the world, agents, and states anyhow.
What is the difference between this and MySQLdb?
PyMySQL is written in pure python and intended to be API compatible with MySQLdb. MySQLdb is written in C and requires that you have MySQL headers available to build.
Agreed. But when I tried to decision via formatting, it would round my numbers for some reason. 
Pandora could probably provide API access to paid users, but that is aside the point. Their choice to not provide that doesn't give you any right to effectively steal their service. You are confusing an argument for free (as in freedom) access to justify theft to get free (as in gratis) access. If you disagree with the way the service works, then don't use it.
Is the one written in C faster?
Almost certainly. But really, I have no idea, but that's a good question. My money is still on "yes" :)
Probably, but the pure Python version has promise for use with PyPy.
&gt; The holy grail of web application architecture is not the single-page application. It is the single-page application that works as a multi-page application if you dont have Javascript enabled. No.. just no. Just stop right there. I will not support clients that refuse to run Javascript on the client. I don't care. It's silly and stupid and I would (and I have) told them that in so many words directly. If you don't want Javascript to execute in your browser apps, then don't do browser apps - go with fat client instead. Seriously, life is too short for this crap. 
It's based on the premise that full page refreshes are the spawn of Satan and should never, upon forfeiture of one's soul, be used in a REAL web application. It's kind of stupid in my opinion. I'm not a fan of apps that use a full page refresh for each and every little action (Oracle Financials and JSF 1 are horrible for this), but it's more than sane to let the application direct the user to discrete pages which load from scratch upon invocation, but then don't do a full refresh until the next redirect/transfer. That gives you the possibility of easily dealing with deep links and also avoiding annoying the users with all the freakin refreshes.
It's worth discussing and the examples used Python, so you can't go wrong there. In this case, I'm not a fan of the approach (see my other responses here), but that's just me.
Some code off the top of my head. class Element(object): def __init__(self, number=0, symbol='', name='', mass=0.0): self.number = number self.symbol = symbol self.name = name self.mass = mass def __str__(self): return 'Element %(name)s has atomic number %(number)d, mass %(mass)f, and symbol %(symbol)s.' % vars(self) def __repr__(self): return repr(vars(self)) def __hash__(self): """Ensure elements are unique by atomic number.""" return hash(self.number) def __cmp__(self, other): """Order by atomic number by default.""" return cmp(self.number, other.number) class PeriodicTable(object): def __init__(elements=()): self._data = set() for e in elements: self.add(e) def __iter__(self): return iter(self._data) def __contains__(self, element): return element in self._data def __getitem__(self, element): return self._data[element] def add(self, element): assert isinstance(element, Element) self._data.add(element) def number(self, number): """Finds element by atomic number.""" for e in self: if e.number == number: return e raise KeyError(number) def symbol(self, symbol): """Finds element by symbol.""" for e in self: if e.symbol == symbol: return e raise KeyError(symbol) def name(self, name): """Finds element by name.""" for e in self: if e.name == name: return e raise KeyError(name) def mass(self, mass, error=0.25): """Finds element whose atomic mass is within error limit.""" for e in self: if abs(e.mass - mass) &lt; error: return e raise KeyError(mass) h = Element(1, 'H', 'hydrogen', 1.00294) he = Element(2, 'He', 'helium', 4.002602) li = Element(3, 'Li', 'lithium', 6.941) pt = PeriodicTable([h, he, li]) But takluyver is correct; your data should be read from a file, probably [CSV](http://docs.python.org/library/csv.html). 
Good suggestions! Thank you! I'll be implementing all of that, save the the penultimate point. I'm doing that because I'm using raw_input(), which is always a string, which is why I've got float(decision) under a try, with a ValueError exception. I want to be able to give the function the full name, abbreviation, or mass number and have it know what to do with it, **without** raising an error. Again, thanks a ton for the input. I really appreciate it!
Thanks for the idea! I had never thought of that! I'll be trying that.
That is also a great idea! Thank you!
How would I call that? elements['Ru'['name']]#?
I like the idea! But how would I use that in another script? Is it possible to import a script with the argv module? How would I pass the arg to the imported script? Thanks!
Eh, late night programming, not thinking straight. It should be a function.
I thought the try statement required the finally statement! That was my workaround. I am mistaken.
Thanks for pointing that out! That would have caused problems later on.
Thanks for example script. It was a bit harsh, but helpful criticism nonetheless. Thank you!
Eh I dont like that I want to a installer so I could eventully put it on the market and not have to learn/deal with java. But Kivy is probably the best way to do it right now
I'd prefer a JS-less site over one that blocks me from middle-clicking on absolutely any link to open it in a new tab. In fact, I might just prefer a JS-less site.
I'd prefer an application architecture that isn't a half-assed Frankenstein of document oriented technologies that have been twisted beyond all recognition all in the name of user interface portability. But until that mess is fixed, I don't think either of us is going to be happy with the web really.
They did it as a generic installer, like Kivy: they have a generic installer that can launch all app, and they also provide a way for you to create a installer/launcher for your own app, but the process is mostly the same: they installer the launcher into system, and leave the app in sdcard. I thought Sl4A have this, too, like Kivy
Just have to say, as a Django and Python newbie, this was extremely extremely informative. If you are similarly new to Django and have set up at least one or two projects and started delving into sessions/auth, I highly recommend giving this a read. Perhaps not surprisingly, it's highly upvoted but didn't generate a lot of discussion; it is written in clear, concise language and is packed with information.
Yes, it is. But you can use it with PyPy or use gevent for async connection :)
Let a = "span of control" and let n = "Top Tier", then the total number of employees is just: a * (a^(n+1) -1) / (a-1) edit: reddit needs a space to terminate a super script
But I'm assuming just 1 person as the top tier - the CEO, and so this won't work due to division by 0.
I don't actually want the total number of workers, I know that number. I'm looking for the total number of levels.
Good luck grading homework where the answers can be googled.
Too much purity of essence.
That is really well written. I can't truly say that I fully understand what is going on here, but from the looks of it it's pretty impressive. It's pretty to look at. Stylish, even. I'll definitely look into CSV files. I have my data in another python script at the moment. It's a dictionary within a dictionary, with the root keys being the symbols (Cl for example), and the value dict has descriptive keys and then the values. Thanks so much for this. This is excellent food for thought for me. Programming thought.
Here is the script again, version 2. I re-wrote it from the bottom up. Edit: Some values in table.py have just 0 in them. This is because when I wrote down the periodic table I didn't enter them for reason. from table import * print "Successfully imported periodic search engine module!" print "Type help() for help." def integer(decision): sym = inv_pro[decision] print elements[sym]['name'] return elements[sym]['mass'] def string(decision): if len(decision) &lt;= 2: print elements[decision]['name'] return elements[decision]['mass'] if len(decision) &gt; 2: sym = symbols[decision] print elements[sym]['name'] return elements[sym]['mass'] def floater(decision): sym = invatomicmass[decision] print elements[sym]['name'] return elements[sym]['atomic'] def find(decision): if type(decision) == int: return integer(decision) if type(decision) == str: return string(decision) if type(decision) == float: return floater(decision) def help(): print "Run find(x) module by giving it one of the following arguments:" print "\tx: Integers (atomic number)" print "\tx: Floating point numbers (atomic mass)" print "\tx: Element names (abbreviation or full name)" print "\nAll of these will return the atomic mass of the element, except for floating point numbers." print "Those will return atomic mass." Here is table.py: elements = {'Ru': {'mass': 102.91, 'name': 'rhodium', 'atomic': 45}, 'Rb': {'mass': 85.468, 'name': 'rubidium', 'atomic': 37}, 'Pt': {'mass': 195.09, 'name': 'platinum', 'atomic': 78}, 'Ni': {'mass': 58.71, 'name': 'nickel', 'atomic': 28}, 'Na': {'mass': 22.99, 'name': 'sodium', 'atomic': 11}, 'Nb': {'mass': 92.906, 'name': 'niobium', 'atomic': 41}, 'Bh': {'mass': 272.0, 'name': 'bohrium', 'atomic': 107}, 'Ne': {'mass': 20.179, 'name': 'neon', 'atomic': 10}, 'Li': {'mass': 6.941, 'name': 'lithium', 'atomic': 3}, 'Pb': {'mass': 207.2, 'name': 'lead', 'atomic': 82}, 'Re': {'mass': 128.207, 'name': 'rhenium', 'atomic': 75}, 'Tl': {'mass': 204.37, 'name': 'thallium', 'atomic': 81}, 'As': {'mass': 74.922, 'name': 'arsenic', 'atomic': 33}, 'Ra': {'mass': 226.03, 'name': 'radium', 'atomic': 88}, 'Pd': {'mass': 106.4, 'name': 'palladium', 'atomic': 46}, 'Ti': {'mass': 47.9, 'name': 'titanium', 'atomic': 22}, 'Rn': {'mass': 222.0, 'name': 'radon', 'atomic': 86}, 'Te': {'mass': 127.6, 'name': 'tellerium', 'atomic': 52}, 'Po': {'mass': 209.0, 'name': 'polonium', 'atomic': 84}, 'Ta': {'mass': 180.95, 'name': 'tantalum', 'atomic': 73}, 'Be': {'mass': 9.0122, 'name': 'beryllium', 'atomic': 4}, 'Fr': {'mass': 223.0, 'name': 'francium', 'atomic': 87}, 'Xe': {'mass': 131.3, 'name': 'xenon', 'atomic': 54}, 'Ba': {'mass': 137.33, 'name': 'barium', 'atomic': 56}, 'Hs': {'mass': 227.0, 'name': 'hassium', 'atomic': 108}, 'La': {'mass': 0, 'name': 'lanthanum', 'atomic': 57}, 'Db': {'mass': 268.0, 'name': 'dubnium', 'atomic': 105}, 'Bi': {'mass': 206.98, 'name': 'bismuth', 'atomic': 83}, 'Tc': {'mass': 97.0, 'name': 'technetium', 'atomic': 43}, 'Fe': {'mass': 55.847, 'name': 'iron', 'atomic': 26}, 'Br': {'mass': 79.904, 'name': 'bromine', 'atomic': 35}, 'H': {'mass': 1.0079, 'name': 'hydrogen', 'atomic': 1}, 'Cu': {'mass': 63.546, 'name': 'copper', 'atomic': 29}, 'Hf': {'mass': 178.49, 'name': 'hafnium', 'atomic': 72}, 'Hg': {'mass': 200.59, 'name': 'mercury', 'atomic': 80}, 'He': {'mass': 4.0026, 'name': 'helium', 'atomic': 2}, 'Cl': {'mass': 35.453, 'name': 'chlorine', 'atomic': 17}, 'Mg': {'mass': 24.305, 'name': 'magnesium', 'atomic': 12}, 'B': {'mass': 10.81, 'name': 'boron', 'atomic': 5}, 'Sg': {'mass': 271.0, 'name': 'seaborgium', 'atomic': 106}, 'F': {'mass': 18.998, 'name': 'fluorine', 'atomic': 9}, 'I': {'mass': 126.9, 'name': 'iodine', 'atomic': 53}, 'Sr': {'mass': 87.62, 'name': 'strontium', 'atomic': 38}, 'Mo': {'mass': 95.94, 'name': 'molybdenum', 'atomic': 42}, 'Mn': {'mass': 54.938, 'name': 'manganese', 'atomic': 25}, 'Zn': {'mass': 65.38, 'name': 'zinc', 'atomic': 30}, 'O': {'mass': 15.999, 'name': 'oxygen', 'atomic': 8}, 'N': {'mass': 14.007, 'name': 'nitrogen', 'atomic': 7}, 'P': {'mass': 30.974, 'name': 'phosphorus', 'atomic': 15}, 'S': {'mass': 32.06, 'name': 'sulfur', 'atomic': 16}, 'Sn': {'mass': 118.69, 'name': 'tin', 'atomic': 50}, 'W': {'mass': 183.84, 'name': 'tungsten', 'atomic': 74}, 'Cr': {'mass': 51.996, 'name': 'chromium', 'atomic': 24}, 'Y': {'mass': 88.906, 'name': 'yttrium', 'atomic': 39}, 'Sb': {'mass': 121.75, 'name': 'antimony', 'atomic': 51}, 'Os': {'mass': 190.2, 'name': 'osmium', 'atomic': 76}, 'Se': {'mass': 78.96, 'name': 'selenium', 'atomic': 34}, 'Sc': {'mass': 44.955912, 'name': 'scandium', 'atomic': 21}, 'Ac': {'mass': 227.0, 'name': 'actinium', 'atomic': 89}, 'Co': {'mass': 58.933, 'name': 'cobalt', 'atomic': 27}, 'Ag': {'mass': 107.87, 'name': 'silver', 'atomic': 47}, 'Kr': {'mass': 83.8, 'name': 'krypton', 'atomic': 36}, 'C': {'mass': 12.011, 'name': 'carbon', 'atomic': 6}, 'Si': {'mass': 28.086, 'name': 'silicon', 'atomic': 14}, 'k': {'mass': 39.096, 'name': 'potassium', 'atomic': 19}, 'Ir': {'mass': 192.22, 'name': 'iridium', 'atomic': 77}, 'Rf': {'mass': 265.0, 'name': 'rutherfordium', 'atomic': 104}, 'Cd': {'mass': 112.41, 'name': 'cadmium', 'atomic': 48}, 'Ge': {'mass': 72.59, 'name': 'germanium', 'atomic': 32}, 'Ar': {'mass': 39.948, 'name': 'argon', 'atomic': 18}, 'Au': {'mass': 196.97, 'name': 'gold', 'atomic': 79}, 'Mt': {'mass': 276.0, 'name': 'meitnerium', 'atomic': 109}, 'Ga': {'mass': 69.72, 'name': 'gallium', 'atomic': 31}, 'v': {'mass': 50.941, 'name': 'vanadium', 'atomic': 23}, 'Cs': {'mass': 132.91, 'name': 'cesium', 'atomic': 55}, 'Al': {'mass': 26.982, 'name': 'aluminum', 'atomic': 13}, 'At': {'mass': 210.0, 'name': 'astatine', 'atomic': 85}, 'Ca': {'mass': 40.08, 'name': 'calcium', 'atomic': 20}, 'Zr': {'mass': 91.224, 'name': 'zirconium', 'atomic': 40}, 'In': {'mass': 114.82, 'name': 'indium', 'atomic': 49}} symbols = {'krypton': 'Kr', 'copper': 'Cu', 'rubidium': 'Rb', 'iodine': 'I', 'rhenium': 'Re', 'gold': 'Au', 'radium': 'Ra', 'neon': 'Ne', 'calcium': 'Ca', 'cobalt': 'Co', 'germanium': 'Ge', 'titanium': 'Ti', 'seaborgium': 'Sg', 'zinc': 'Zn', 'astatine': 'At', 'arsenic': 'As', 'hydrogen': 'H', 'fluorine': 'F', 'platinum': 'Pt', 'niobium': 'Nb', 'hafnium': 'Hf', 'lead': 'Pb', 'sodium': 'Na', 'thallium': 'Tl', 'chromium': 'Cr', 'selenium': 'Se', 'tantalum': 'Ta', 'technetium': 'Tc', 'cesium': 'Cs', 'meitnerium': 'Mt', 'tin': 'Sn', 'actinium': 'Ac', 'tellerium': 'Te', 'osmium': 'Os', 'sulfur': 'S', 'helium': 'He', 'lithium': 'Li', 'hassium': 'Hs', 'beryllium': 'Be', 'mercury': 'Hg', 'yttrium': 'Y', 'nickel': 'Ni', 'polonium': 'Po', 'ruthenium': 'Ru', 'potassium': 'k', 'francium': 'Fr', 'bohrium': 'Bh', 'dubnium': 'Db', 'strontium': 'Sr', 'bromine': 'Br', 'argon': 'Ar', 'antimony': 'Sb', 'rhodium': 'Ru', 'boron': 'B', 'tungsten': 'W', 'carbon': 'C', 'palladium': 'Pd', 'silver': 'Ag', 'chlorine': 'Cl', 'phosphorus': 'P', 'rutherfordium': 'Rf', 'bismuth': 'Bi', 'scandium': 'Sc', 'aluminum': 'Al', 'oxygen': 'O', 'vanadium': 'v', 'nitrogen': 'N', 'lanthanum': 'La', 'gallium': 'Ga', 'zirconium': 'Zr', 'manganese': 'Mn', 'radon': 'Rn', 'silicon': 'Si', 'molybdenum': 'Mo', 'iridium': 'Ir', 'cadmium': 'Cd', 'magnesium': 'Mg', 'iron': 'Fe', 'xenon': 'Xe', 'barium': 'Ba', 'indium': 'In'} invatomicmass = {0: 'La', 1.0079: 'H', 69.72: 'Ga', 6.941: 'Li', 114.82: 'In', 121.75: 'Sb', 39.948: 'Ar', 54.938: 'Mn', 226.03: 'Ra', 79.904: 'Br', 268.0: 'Db', 112.41: 'Cd', 22.99: 'Na', 272.0: 'Bh', 271.0: 'Sg', 276.0: 'Mt', 118.69: 'Sn', 207.2: 'Pb', 127.6: 'Te', 92.906: 'Nb', 195.09: 'Pt', 87.62: 'Sr', 180.95: 'Ta', 206.98: 'Bi', 35.453: 'Cl', 51.996: 'Cr', 204.37: 'Tl', 12.011: 'C', 58.933: 'Co', 65.38: 'Zn', 88.906: 'Y', 74.922: 'As', 83.8: 'Kr', 58.71: 'Ni', 18.998: 'F', 265.0: 'Rf', 44.955912: 'Sc', 190.2: 'Os', 72.59: 'Ge', 196.97: 'Au', 50.941: 'v', 30.974: 'P', 102.91: 'Ru', 15.999: 'O', 20.179: 'Ne', 10.81: 'B', 4.0026: 'He', 47.9: 'Ti', 126.9: 'I', 63.546: 'Cu', 9.0122: 'Be', 32.06: 'S', 210.0: 'At', 40.08: 'Ca', 91.224: 'Zr', 95.94: 'Mo', 183.84: 'W', 85.468: 'Rb', 78.96: 'Se', 28.086: 'Si', 222.0: 'Rn', 223.0: 'Fr', 97.0: 'Tc', 200.59: 'Hg', 227.0: 'Ac', 131.3: 'Xe', 106.4: 'Pd', 209.0: 'Po', 26.982: 'Al', 39.096: 'k', 24.305: 'Mg', 137.33: 'Ba', 178.49: 'Hf', 192.22: 'Ir', 132.91: 'Cs', 128.207: 'Re', 55.847: 'Fe', 14.007: 'N', 107.87: 'Ag'} inv_pro = {1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mg', 13: 'Al', 14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'k', 20: 'Ca', 21: 'Sc', 22: 'Ti', 23: 'v', 24: 'Cr', 25: 'Mn', 26: 'Fe', 27: 'Co', 28: 'Ni', 29: 'Cu', 30: 'Zn', 31: 'Ga', 32: 'Ge', 33: 'As', 34: 'Se', 35: 'Br', 36: 'Kr', 37: 'Rb', 38: 'Sr', 39: 'Y', 40: 'Zr', 41: 'Nb', 42: 'Mo', 43: 'Tc', 45: 'Ru', 46: 'Pd', 47: 'Ag', 48: 'Cd', 49: 'In', 50: 'Sn', 51: 'Sb', 52: 'Te', 53: 'I', 54: 'Xe', 55: 'Cs', 56: 'Ba', 57: 'La', 72: 'Hf', 73: 'Ta', 74: 'W', 75: 'Re', 76: 'Os', 77: 'Ir', 78: 'Pt', 79: 'Au', 80: 'Hg', 81: 'Tl', 82: 'Pb', 83: 'Bi', 84: 'Po', 85: 'At', 86: 'Rn', 87: 'Fr', 88: 'Ra', 89: 'Ac', 104: 'Rf', 105: 'Db', 106: 'Sg', 107: 'Bh', 108: 'Hs', 109: 'Mt'}
Obviously in a case like Facebook, a document oriented architecture where you're trying to maintain a file-system like hierarchy would be ridiculous and a lot of unnecessary work. In other cases, a URL structure might be useful along with UI enhancements. We're seeing technologies misused all over the web now, but hopefully moving forward it will be a matter of developers looking at problems case by case and using what works best. 
&gt; The Pythonic way to handle that is to take a single parameter, use some kind of try-except logic to figure out whether it's a file or a url, and read the data accordingly. I agree that this is a common way to solve this problem. It's done that way in many standard library classes. Maybe I need some more time to get used to it, but currently I don't feel comfortable with it. And neither with the way the OP is solving the problem by providing two different args as two alternative entry points. I'd prefer one arg of a well defined duck-type, e.g. a type implementing the file protocol, and a factory function for alternative args, e.g. an url.
As much as the author's approach may be useful, if anyone says that something is "the holy grail" of anything... I probably wouldn't take that part of the argument too seriously, particularly in this field. 
Don't get me wrong - I don't hate everything about the web. It works great for document oriented problem sets. A great example is Wikipedia. Or Project Gutenberg. Etc. Usually I'm not working on document oriented systems. I'm normally working on OLTP systems with complex rules around validation, complex workflows, user interfaces we used to consider running only on fat client, etc. Tools like Ext JS (which I'm currently using via Ext.Net) help A LOT, but really they don't solve the problem. They just give us another, bigger, more complex, and ultimately leakier abstraction to try to wallpaper over the fact that we're really doing these kinds of systems wrong to begin with. But.. that's just me. :)
No - you'd use a pointer type. This gets a little more complicated, but here we go: There is a difference between an address and a pointer. An address is a location in memory; this can be represented by some unsigned integer type (a uintptr_t is always large enough to hold it). A pointer is a language construct which carries semantic information about what it points to. This information is compiler metadata; that is to say, it exists only during compilation, and is not a feature of the runtime. This information is used for things like pointer arithmetic. A concrete example of this: On a machine where the minimum addressable unit is 1 8-bit byte (practically speaking, anything), a uint8_t will fit in 1 addressable memory unit, and a uint16_t will fit in 2. This means that if I examine memory at 0x10000000 for a uint8_t, that's the only address I'll read from, but if I read a uint16_t, I'll also read from 0x100000001. When you do arithmetic with pointers, this type is taken into account; so, given type_t *x, (x+n) and (x+n+1) (alternatively x[n] and x[n+1]) will be sizeof(type_t) bytes apart. If type_t is uint8_t, this will be 1, but if type_t is uint16_t, this will be 2. This feature allows array access and incrementation on pointers, instead of having to modify with size knowledge explicitly. C also provides a pointer type without this information - void *. This is the pointer type which can hold any address, and so increments by the minimum addressable unit. size_t would be used when indicating an allocation size. In practical terms, this is going to be sized the same as a uintptr_t on modern systems, but the use is specifically for indicating the number of addressable units occupied by an object in memory. There are a few other special types with similarly specific uses. ptrdiff_t, for example, is a signed type able to hold the difference between any two legal pointers. The size of any of the types mentioned here (with the exception of uint8_t and uint16_t) are architecture dependent, and yes, the correct types are substituted at compile time; but that doesn't mean exactly what it sounds like. If a pointer is 32 bits, then the equivalent of a uint32_t will be used for a void * but the end result of compilation is machine code. The instructions generated will tell the processor to manipulate the registers and memory addresses as if they contained entries of that size, but they will refer to words, half words, double words, etc. That is to say, the compilation will determine *what* to generate based on the types, but the resulting instructions will have no concept of type, only operand size.
I totally agree. The web was not built for the things we're doing with it now, and tools we build and use are trying to cope with that. It's messy. If there are better solutions, I hope we find them. 
I was glad when I found PyMySQL a few months ago. It can be hard to find MySQLdb binaries for windows. Good to know it's active.
Ow, my eyes.
This is the equation that gives you a + a^2 + a^3 + ... a^n+1, if you want just one CEO then replace n+1 with n and add one. BTW, with a=1 you do not get divide by zero. On the real line, as a-&gt;1, the top will approach 0 as fast as the bottom and you get an answer of n.
Yo dawg, I've heard you like PHP and XML...
Yay for Georg!
Web crawlers?
If you are unlucky enough to need to, it's massively easier to get this working on Windows, because it doesn't require compiling anything, unlike MySQLdb.
Looks like a Python version of PHP. Yuck.
First page shows an example of mixing html and python? WTF? Did I wake up 10 years in the past or is this a joke?
I'm going to have to agree with Husio and earthboundkid but more politely. I am glad to see a python web framework with support for python 3, but this is in my opinion going against python conventions and aiming to be more of a PHP clone. A good python web framework doesn't have to be Django or Pyramid or Flask. But it shouldn't *require* xml style configuration. The component classes *shouldn't* use java style accessor methods and executors (getParams(), do_GET()). While my opinion of the template format in Pylatte is religious, I don't see why Pylatte couldn't use an existing html template language that supports Python 3.
You can control how the number is formatted by using something else than %s e.g. %f for float
there's a great o'reilly book that was recommended in another python thread on the subject... it's titled "collective intelligence" and feel free to PM me if you want the .pdf
thank you!
No, it only requires the except clause. Please for the love of God though, do not use a catch all except statement (except arguably for your main loop) here it's not a problem but in a bigger setting a huge except statement might impede debugging to a hair removing degree.
&gt; Their choice to not provide that doesn't give you any right to effectively steal their service. I didn't say it gave me *the right* - I'm just stating my motivations. It's like with movies and tv shows - I want to watch them in a non-annoying, lazy-ass way, and will do so whether it's legal or not. That's it. If it happens to be illegal, I'll agree with you that it's morally wrong - I just don't care. My point was that there are a number of people who, like me, just *don't care* about justifying their usage, so if you want to take advantage of them as users, you'll might as well just sanction what they're doing anyways and turn it into a benefit for your service.
...but I like Mako! Being able to use Python to manipulate data for presentation purposes at the template level is so convenient.
config in XML, big no-no... I do appreciate a serious stab at Python 3 though because literally any other Python web framework I know of relies on 2to3 or doesn't have any Python 3 support yet at all. It's sad because I get the impression that in order to get excited these days you need to look at things like [salt](https://github.com/thatch45/salt) or zmq in general... five years ago it was web frameworks.
Holy shit it's PyHP!
It is, so are global variables and copy/pasting code. It has it's place, but it leads to messes and isn't best practice for good reason. It just doesn't seem like something you want to use to advertise or introduce (and set the tone for new developers) on the front page of your "modern" web framework.
It's mostly because of the work needed on the lower level libraries to port them to python 3 and to work out the details (and get them right so there's lots of discussion). As to being sad, I get it but web frameworks aren't *that* hard of a problem. The rapid pace couldn't keep up forever and it lasted pretty long. Maybe I don't feel it as strong because I have to temper that feeling. I do web stuff professionally and can't ethically follow every "shiny new toy!" impulse. That's what hobby projects are for (thanks for the link to salt by the way, I hadn't looked into it before).
having used netlogo extensively, I can vouch for both its simplicity and its surprising versatility. That said, if you want something more serious, repast is quite extensively used for agent modeling, and in many cases, methinks python would be far too slow, given the number of iterations required for non-trivial sims (unless you can vectorize the calculations and dump them into nympy)
It just you :-)
Apart from things like libs (e.g. m2crypto) there are ideological things such as when you want/need to support RHEL5 and therefore your code needs to run on quite an old version of Python. But it's true and I agree, having popular thus more or less big web frameworks, rich with features, is good but on the other hand creates quite some inertia too.
bring me a shrubbery!
the fragile. sonic masterpiece of an album. nice screen shot.
Not quite. You might have legacy databases created when mysql was the best free option out there (say, 2001). Or are stuck with MySQL because that's all a development team, hosting facility or application will work with. 
Probably nothing, but you'd have to look that up in change logs. I think you're thinking too far into it. The *language* changed between 2 and 3 - that doesn't mean *libraries* made drastic changes between 2 and 3 (a great majority did not).
I remember hearing about this project years ago, and for some reason just thought of it today. Looking at the website and watching the demo videos, it looks pretty neat but has basically been comatose for years now. It seems like the kind of thing that could have a great mobile client.
Yeah, it's kinda popular to pretend systems older than last week simply don't exist any more.. ;)
Probably because the dev(s) got a new job, had a kid, picked up surfing, simply lost interest, or any number of other things that happen in real life. Open source projects live and die by the contributors.
http://www.dreamingincode.com/
http://www.joelonsoftware.com/items/2007/01/21.html edit1: also: http://discuss.joelonsoftware.com/default.asp?joel.3.441947.18 edit2: also http://lwn.net/Articles/218618/
Not quite. def greenScreen(pic): a = loadPicture(pic1) b = loadPicture(pic2) for pA,pB in zip(getPixels(a), getPixels(b)): r = getRed(pA) g = getGreen(pA) b = getBlue(pA) if r&lt;10 and g&gt;240 and b&lt;10: pA=pB savePicture(a,'mynew.png')
Comments: Your should iterate over the pixels in both images simultaneously. your "green" detector was wrong. Yours simply looks for pixels whose green content is more than its red or blue content. Not enough. You were replacing the pixel value with black (0,0,0) rather than with the contents of your replacement pic's pixel. Also, you'll need to actually find those helper functions getPixels, getGreen, loadPicture, etc. Try [openCV](http://opencv.willowgarage.com/wiki/PythonInterface)
This project had a lot of time, money and manpower thrown at it. The actual story is more complex and interesting than your generalisation suggests. Read Dreaming in Code. It's a great read and a good case-study in doomed projects.
Although the choice of Python was good IMHO, they mainly used former Java programmers to write it. Java requires a [lot more boilerplate](http://www.eclipse.org/Xtext/xtend/) and results in lots more lines of code. That is [pointless](http://dirtsimple.org/2004/12/python-is-not-java.html) in Python. In general the amount of time to write code, the number of bugs, the complexity and most other things scale with the lines of code. These guys wrote a lot. They should have been working out how to write the least amount possible. I visited them once as I had Python code that talked to the cell phones of the day. I came out astonished - they all seemed to be a bunch of architecture astronauts [1](http://www.joelonsoftware.com/articles/fog0000000018.html) [2](http://www.joelonsoftware.com/items/2008/05/01.html). 
That's fine with me! I've been migrating over to PyPy anyhow.
Interesting, I don't recall hearing much about this before and the site isn't particularly impressive so I figured it's story was similar to the myriad of other abandoned open source projects. Thanks for the tip.
based on the fact that the OP never used the word "agent based modeling" but was clearly describing agent based modeling, i think netlogo would be a good introductory tool
Finally! Been waiting for 2.8 since like, 2.7! w00000t!!!
That's great, but 2.x is dead anywhere you go, so this is kind of a red herring. It's not like PyPy exists to carry on the 2.x line.
I've been using structured.py for a lot of dict-to-xml and xml-to-dict stuff in some test reports I've been generating. It relies on ElementTree to work. https://github.com/hudora/huTools/blob/master/huTools/structured.py
The thing is it is not a benefit to their service for you to listen to music which they have to pay royalties for. That is why it is stealing, the API argument is completely irrelevant.
I can quit 2.x any time I want, *just you watch me*.
&gt;Release Schedule &gt;================ &gt; The current schedule is: &gt; - 2.8 final Never
Pypy's goal is to evolve the runtime, not the language. It is unlikely they'll try to sprout off 2.8, and they've started working on 3.x support already.
Enterprise-class use of Python may imply that there will be a 2.7.39 someday, with a stable set of libraries and a stable API/ABI. (Wait! I'm not even using 2.7, my distribution is still at 2.6 and I still can use numpy, Cython, django and lxml! What a relief.) Actually, I like the stance that the Perl people are using: "Perl 5 and Perl 6 are two languages in the Perl family, but of different lineages. If you are looking for production ready code please use Perl 5." Aka: There are enough things from Python (2) missing that I wouldn't use Python3 just by default, and there are enough things from the ultimate utopian image of Pythonic things missing (*cough* type inference *cough*) that I'm not excited enough to actively want it. (Type inference, and optional type declarations, may not be useful for speeding up things, but they would on one hand act as testable assertions, i.e., you would get a ValueError at the right place instead of some weird error three levels down, and on the other hand they have the potential to really improve IDE autocomplete support, which does not sound like much but is sorely missed by people coming from Java). 
This comment is blowing my mind. Not sure if you've read the OP and not sure if this is a joke as well. 
*wooooooosh*
Yeah it was a joke.
As a newbie to Python (only officially started learning since this summer), is the transition really going to be that hard? I mean, from what I've seen, which is mostly from the Python Essential Reference 4th ed., the core changes seem to be more syntax related (print() and xrange() being the main ones I remember) rather than anything else. Any examples of changes that piss everyone off? (FYI, I have not really touched Python 3 and have only worked on Python 2.6 and 2.7)
I truly believe that any kind of static typing, inferred or explicit could help the language, it could be an optional flag thing? Would be nice to try it out, just for kicks.
I really wish this wasn't the case. Today I was writing a decorated method which ended up being: @functools.wraps(caller) def wrapper(obj, *args, **kwargs): if obj.ui.actionToolbarEdit.isChecked(): obj.disconnect(obj.ui.tableWidget, QtCore.SIGNAL( "itemChanged(QTableWidgetItem*)"), obj.rewrite_db) caller(obj) if obj.ui.actionToolbarEdit.isChecked(): obj.connect(obj.ui.tableWidget, QtCore.SIGNAL( "itemChanged(QTableWidgetItem*)"), obj.rewrite_db) return wrapper Now, if I peek at the functools.py, I get that it imports everything from _functools.py, how am I supposed to read the implementation details without a hefty google session?
Precisely! I've learned a lot just by importing a module and thinking "This is magic, I should go read the module!". To be greeted with an opaque C module that I must go scour the web for the true source is not a good learning experience, and in *fact* is un-pythonic by definition since it is neither readable, easy to grok or user friendly at all. Ce la vie, there need to be *some* caveats to using such a glorious language.
I found such huge, glaring red flags just perusing the home page, and so many of them, that I just can't bring myself to look any further. Maybe there's some interesting code bits in the back end where things are glued together, but if I catch anyone actually using this thing, I'm unfollowing, unfriending... uneverything-ing them. 
The article's been updated slightly, a short TL;DR has been added and at the step where you are installing pip, it suggests the possibility to skip easy_install and use the pip bootstrap script from the link in your reply below.
Cute Easter egg, but ewwwwwwww Subversion. You have my sympathies.
Hi! I work on the SimpleCV open-source python package. You can download the package at SimpleCV.org. I solved your problem using SimpleCV. You can see the results here: http://imgur.com/a/01aow This code ins't perfect but it is pretty close for a few lines. Basically your error is working in RGB space. You really should use a the hue/saturation/value space which makes it much easier to pick a certain color. Once you find pixels of a color you create a matte that tells you which image, either the green screen, or the background, to use. Here is the example code: from SimpleCV import * gs = Image("./../sampleimages/greenscreen.png") background = Image("./../sampleimages/icecave.png") matte = gs.hueDistance(color=Color.GREEN, minvalue = 40).binarize() result = (gs-matte)+(background-matte.invert()) result.save('result.png') You can get the code on github here: https://github.com/ingenuitas/SimpleCV/blob/master/SimpleCV/examples/GreenScreen.py
From what I see there are two main problems: 1) Unmaintained or poorly maintained libraries that are not compatible and may never be. These will need to be, in some cases, rewritten from scratch if the licence is not sufficiently permissive. There is constant progress on this front, but it is slower than many would prefer and there remain many significant libraries that have not been ported. While few of them are of huge significance on their own, it's a case of "you won't miss it until it's gone... then you'll miss it a lot". 2) A lot of stuff with binary data has changed. It is no longer acceptable or in many cases, supported at all, to store such data in strings. There is a new "bytes" type for binary data, which is only loosely interchangable with strings. The very clear line drawn between bytes and strings makes software that dealt heavily with strings containing binary data (which in the past was the standard way of dealing with binary data) have a fair bit of work to do to get their data to fall on the correct side of that line in all cases.
I am... confused by the white space shown in the screenshot.
You guys are awesome. This is just another example of why.
Have you looked at Cython? http://blog.behnel.de/index.php?cat=11 
You may want to tighten the binarization to binarize(10) or so. That might clean up the outline a bit.
It doesn't seem to be working.
To do proper chroma keying, you need to base your function for computing the output alpha on an euclidean distance metric between the color of each input pixel and ideal green (which will give you nice feathering, no hard edges), then post-process with a seperate spill-removal function to subdue any green-tinged edge-pixels. A sample python implementation follows below. I've [uploaded the result](http://imgur.com/08mtb) of applying it to kscottz's dataset from elsewhere in this post. Here's the code: #!/usr/bin/python import PIL import Image import sys import math if len(sys.argv) &lt; 3: sys.exit('usage: gs.py &lt;input&gt; &lt;output&gt;') input_filename = sys.argv[1] output_filename = sys.argv[2] input_img = Image.open(input_filename) output_img = Image.new("RGBA", input_img.size) for y in xrange(input_img.size[1]): for x in xrange(input_img.size[0]): p = input_img.getpixel((x, y)) d = math.sqrt(math.pow(p[0], 2) + math.pow((p[1] - 255), 2) + math.pow(p[2], 2)) if d &gt; 128: d = 255 output_img.putpixel((x, y), (p[0], min(p[2], p[1]), p[2], int(d))) output_img.save(output_filename, "PNG")
&gt; IDE autocomplete support, which does not sound like much but is sorely missed by people coming from Java Have you tried PyCharm? http://www.jetbrains.com/pycharm/ 
I was hoping someone would point me to that when I was typing, I kind of guessed it would have static typing.. does it have static typing ala C?
 # ------------------------&gt; UnlockEasterEgg() function &lt;------------------------- Comments like this make me rage.
Never gonna give you 2.8
Hey, Thanks for the tip. But we prefer to stick with Python because we already know the language and neither of us is planning on continuing in the IA domain, so this added to the fact that we would have to start from scratch in netlogo seems a bit overwhelming. Plus I don't think the project is big enough to be worth such an investment ;)
Indeed, it feels like our teacher just took the main ideas from the project, toned it down a bit and released it as our project subject :P 
It looks like it, but I haven't had to live with it, so YMMV.
Hey, thanks I think our project will be in that spirit. So far we are planning in doing just that, probably minus the xml.
Interesting, I mean, I've never had a need for it but still would be cool to see what could really be done with it in Python.
I sincerely hope you aren't a library maintainer. 
:trollface: No, but I'm kind of in the same spectrum, I'm a *user* which is probably worse for the necessity of change.
Because Matthew Perry keeps choosing bad roles.
I have tried PyDev (it's kind of useful in a mixed Java/Jython project) and was kind of disappointed with the code completion; found the indent/dedent operation quite useful. Is PyCharm worth the money if you're not doing Django stuff?
fair enough. maybe check out [this tutorial for using simpy](http://heather.cs.ucdavis.edu/~matloff/simpy.html) -- it seems straightforward enough
But then you'll get green outlines around everything. I guess good steps forward would be, in order of decreasing effect and increasing effort: * use target luminosity as well, so that #001100 would not be mistakenly considered to be a part of the background (the major source of artefacts in the GP's image). * use non-binary alpha and, as you get closer to pure green, gradually replace the extra green component with transparency, so to speak. * mark and process only the pixels near to sufficient portions of what is detected as the background. That could be neatly vectorized, I think.
It depends. How much money do you have flying around? I found it useful, but results may vary. Unfortunately, Swing/Java have a conflict with XMonad.
I think so. I still prefer to use vim more just because it can run in a terminal but PyCharm will run on nearly any OS and, imo, beats out every other IDE and I still use it for larger projects or if I have a new library or something and I want code completion to browse about the code a bit as I write it. edit - I don't think it's *that* expensive either.
I doubt it's supposed to help you understand the function and instead just marking the beginning and I suspect one for the end. Is it necessary? Maybe not but at least he's trying to make it easier to skim the file and fine the beginning and end of big functions quickly.
&gt; The thing is it is not a benefit to their service for you to listen to music which they have to pay royalties for. I didn't say it was a benefit for them. &gt; That is why it is stealing Yes, it is. *I don't care.* If they want me to not steal then they need to make the action that I'm doing no longer stealing.
PyPy is written in [RPython](http://code.google.com/p/rpython/), which is a statically-typed subset of Python. Edit: I should also mention that [there are](http://stackoverflow.com/questions/1275646/python-3-and-static-typing) some ways to add type checking in Python, and also that [BOO](http://boo.codehaus.org/) was designed to essentially be a statically-typed Python.
+1 for PyCharm. It's the shit. Best IDE I've ever used for any language.
I'm an academic, so I'd be able to get it for a reasonable price. I also use XMonad, though. Is it worse than other Swing programs or does the usual workaround fix that?
Did Cython grow type inference? Having typed things for speed in Cython is great, but the Pythonic thing would be for types to appear magically (aka be inferred) with very few (if any) declarations in the code.
If it is any help I am one of the developers of SimpleCV. Here is the haar wavelet calculation and the actual wavelets if you want to steal them. Also I used Orange to create my decision trees. You may want to use this code for verification or just to get a feel for what is going. https://github.com/ingenuitas/SimpleCV/blob/master/SimpleCV/Features/HaarLikeFeature.py https://github.com/ingenuitas/SimpleCV/blob/master/SimpleCV/Features/haar.txt https://github.com/ingenuitas/SimpleCV/blob/master/SimpleCV/MachineLearning/TreeClassifier.py Please let us know about your results using pypy, we would love to see what you are working on. If you open source it and it is relevant to SimpleCV we'll include it. For reference I ran the Haar decision tree generating code for OpenCV with a 2500 image dataset where the images were fairly small. With that dataset and a fast machine generating the trees would take overnight. I really don't think you're going to squeeze out more performance unless you find a way to pipe your stuff to a CUDA card. 
Gotta get down on 3.0.
Let me get this straight. You're using a library for server-side cookie handling for server-side cookie handling?
Hey thanks, I never thought about it like that. Python 3 makes a wonderful sponge to absorb any further crazy pouring into what was once a beautiful little language (IMHO anyway ;). My sweet spot was around Python 2.3, maybe 2.4. (2.3 got sets, generators, datetime, enumerate, logging, csv, and bool, 2.4 got decorators, genexps, subprocess, and a bunch of other crap I could live without)
I don't use Django but I do use PyCharm, and I've done Java for many years with IntelliJ IDEA, from the same company. They simply make the best IDEs, hands down. It was only with PyCharm that I finally made some progress with Python development - never really got going (even) with MacVim. Also, it's not expensive, and it's alright to pay for quality software you know. 
looks interesting, but I only see python --&gt; xml functions, not any xml --&gt; python
Whenever someone sais "python is not java" and bangs out some fugly dict-list crap I get abit upset, you however took the time to do this properly in pthon.
Nice job! One issue on Chrome for OS X, the dropdown would not allow radio station changes. Change station worked fine on Safari.
You have the [documentation](http://docs.python.org/library/functools.html) which defines the public interface. Anything not in the documentation is an internal implementation detail and is not part of the public interface. Therefore it's an error if your program depends on any implementation details. They are private for a reason. Peeking into library internals unless you have a specific reduced testcase that exposes a bug is generally not a good idea. 
You can't do type inference on Python, at least, not meaningfully. Look up Cannon, 2005 for more info.
Most programmers who need to find the function are going to search for the function's name with built-in text editor functionality, not visually grep for such a header.
Wait, I'm in a subreddit for a specific **programming language**, and a comment saying "wow, I dislike X **version control system** *on principle*" is getting upvoted? Really?
Ah. Thanks. I knew mostly about #1, but not at all about #2. Gonna look into that more.
Principle has nothing to do with it. I'm forced to use subversion at work every day. It sucks.
Check out [lxml](http://lxml.de/)
Thankfully python3 has started complaining about this tab and space mixture by default.
I am a little late to the game but I wanted to give this a try. I got my algos from links on the [wikipedia article](http://en.wikipedia.org/wiki/Chroma_key). I used [here](http://www.cs.utah.edu/~michael/chroma/) and [here](http://gc-films.com/chromakey.html). They recommended using YCbCr for the image mode. Please critique me as I am a python novice. Stole my images from kscottz, [output looks like this](http://imgur.com/a/C3yQl). import Image from ImageChops import subtract import numpy import math def GreenScreen(infile, inbg ,outfile='output.png', keyColor=None, tolerance = None): #open files inDataFG = Image.open(infile).convert('YCbCr') BG = Image.open(inbg).convert('RGB') #make sure values are set if keyColor == None:keyColor = inDataFG.getpixel((1,1)) if tolerance == None: tolerance = [50,130] [Y_key, Cb_key, Cr_key] = keyColor [tola, tolb]= tolerance (x,y) = inDataFG.size #get dimensions foreground = numpy.array(inDataFG.getdata()) #make array from image maskgen = numpy.vectorize(colorclose) #vectorize masking function alphaMask = maskgen(foreground[:,1],foreground[:,2] ,Cb_key, Cr_key, tola, tolb) #generate mask alphaMask.shape = (y,x) #make mask dimensions of original image imMask = Image.fromarray(numpy.uint8(alphaMask))#convert array to image invertMask = Image.fromarray(numpy.uint8(255-255*(alphaMask/255))) #create inverted mask with extremes #create images for color mask colorMask = Image.new('RGB',(x,y),tuple([0,0,0])) allgreen = Image.new('YCbCr',(x,y),tuple(keyColor)) colorMask.paste(allgreen,invertMask) #make color mask green in green values on image inDataFG = inDataFG.convert('RGB') #convert input image to RGB for ease of working with cleaned = subtract(inDataFG,colorMask) #subtract greens from input BG.paste(cleaned,imMask)#paste masked foreground over background BG.show() #display cleaned image BG.save(outfile, "PNG") #save cleaned image def colorclose(Cb_p,Cr_p, Cb_key, Cr_key, tola, tolb): temp = math.sqrt((Cb_key-Cb_p)**2+(Cr_key-Cr_p)**2) if temp &lt; tola: z= 0.0 elif temp &lt; tolb: z= ((temp-tola)/(tolb-tola)) else: z= 1.0 return 255.0*z if __name__ == '__main__': #keyColor = [151,44,21] #Y,Cb, and Cr values of the greenscreen #tolerance = [50,130] #Allowed Distance from Values #GreenScreen('testimg.png','testbg.png','output.png', keyColor, tolerance) GreenScreen('testimg.png','testbg.png') 
I'm very bummed about this. Mitch Kapor worked on Lotus Agenda around 1988 - which seems more advanced than any PIM available today.
His face looks a little too red/purple.
I think the workaround will work. I was having trouble getting the change to work.
http://boo.codehaus.org/
Everyone said the same thing about CVS when Subversion was new(ish).
Oh, really? Shoot, I'm sorry about that, then...I was really wrapped up in getting my XML out of the code; I hadn't dug into it to see if there's an opposite method in there. What about building some sort of string parsing method/methods that just read in the XML as if it was a text file, then use .split() and/or .replace() while searching for the headers you need in the XML?
This is revolting.
You think he has a whole lot to chose from?
I think what got me thinking about this was an interview with David Allen that I listened to recently. He was interviewed by Leo Laporte and in the interview he mentioned that he still uses and likes Lotus Notes. I hadn't heard of Notes in years and that probably caused me to think of PIM's from the past and then Chandler.
Man, we got downvoted to hell.
some pieces of python are very well documented but with every language and every api i've used i run into places where i need clarification on edge cases and ambiguous language in documentation, i always go straight to the source. 
So, progress?
I was one of the few users of Lotus Agenda back in the 80s and I really liked it. And I do like the scheduling in Notes, and integration of messaging with mail &amp; calendar is kinda cool. But the maze of menu options is a train wreck.
Basically, yes.
Can't you show some code and test cases, so we can reproduce your slow results? 
Some said the same thing about Subversion when Subversion was new(ish).