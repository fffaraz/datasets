My reading of the PEP: GvR basically found a syntax he liked ("Alternative 1" with possibly adding "Alternative B"). The trouble was in the semantics: specifically, "when do you freeze the dict". Personally I liked "Option 3". But I guess there was too much that would have been surprising / confusing about it. Ultimately I suspect GvR was -0.1 on it and let the 2007 PyCon keynote audience take the rap.
No, but then why build the one-liner?
Plus, Twisted just released 12.1 which is the last version to support 2.5. Once that is gone, the road to Python 3 becomes much easier.
if you're worried about speed, worry more about code than hardware; just get fast hardware and if possible run on pypy.
&gt; He implemented the first one in optimised Fortran running on a Cray-1 Holy crap, he had access to a cray just to run a proof of concept algorithm test on?
&gt; VPython is an oddity in that regard. No, it's not. That's standard for OpenGL.
What are you using pypy for?
inlining my obscenely large call trees &gt;.&gt;
Okay, that's understandable. I've done the same in the past, but gave up trying in Python. Really, the language is built to implement state machines, it's best to just use tools that are built for the task. I'm working on scheme. The explanation helps me understand the "why" and to relate to your experience.
I'm not familiar with the fine details of the cPython compiler or its byte code, but on a general basis I'd say that one almost never should consider efficency when choosing between a comprehension and a map/filter-combination. They're essentially the same thing. In this specific case, I can't see any significant difference. (Ran http://pastie.org/4033246 on three different systems; the difference is never more than +-10%.) However, using map with lambdas seems to be somewhat(~2x) slower than using a comprehension. Btw, this problem is discussed in depth at Stack Overflow: http://stackoverflow.com/questions/1247486/python-list-comprehension-vs-map 
I started hacking on [some Emacs solutions](http://static.matthewlmcclure.com/s/2012/06/05/emacs-tramp-python-virtualenv.html).
Well, in C, when you do a switch case, you do so with constants. in an if else chain, you introduce variablility. a compiler can compile different versions based on what's in the switch. say you have case 1-10, all the odds do one thing, all the evens do something else, and the defaults do yet a third thing. so instead of having a call myFunc(), it can internally call myFunc13579, or myFunc24680, or myFuncDefault. it can further simplify things out if you are passing constants to the methods, and eliminate the branching all together. so myFunc(4) becomes a myFunc24680()
This example is actually one of the reasons I wish python had a switch statement. Your two examples produce different behavior. For example, suppose case was 2. Your python code will only print 'an even number' since execution of the elif chain stops once it matches something. E.g. &gt;&gt;&gt; case = 2 &gt;&gt;&gt; if case in [0]: ... print '0' ... elif case in [2]: ... print 'First' ... elif case in [2,4,6]: ... print 'Second Block' ... First whereas with the switch operator and its fall-through behavior, n = 2 will print both 'n is an even number' and 'n is a prime number'. Edit: &gt; In C-code, switches are a translation to an if-else chain and a convenience of syntax. Not always. Depending on the number of cases, spacing, etc., a switch statement may be compiled into a jump table. See [Switch statement](http://en.wikipedia.org/wiki/Switch_statement#Compilation). This can be significantly faster than if/else chains.
I also don't have the answer the OP was looking for, but would recommend something like this. If you don't want to use the filesystem [Berkeley DB](http://en.wikipedia.org/wiki/Berkeley_DB) might suit your needs.
So, add a new syntax for something that is readily accomplished with an existing mechanism, but is less flexible and would only exist to save some typing? No wonder it got rejected. 
Something about giving docstrings functional importance always rubs me the wrong way. If it looks like a comment it shouldn't effect how my code works...
Awesome, thanks!
Well that's cool. You prefer x += 1 over x++?
I would argue that your example behaves exactly as it should. It doesn't make any sense at all to have two outcomes for a switch statement; this would make the language ambiguous. There should be one and only one way to drop through an if-else chain. I understand the jump optimization. I would argue that it is incredibly complicated to optimize something like that at run-time.
[cocos2d](http://cocos2d.org/) looks pretty close to what I want - it lacks a scene editor among other things, unfortunately. It would definitely be a good jumping-off platform, though. That being said, I'd prefer if there was something like cocos2d, but PyGame based - it would be really nice if I could painlessly port any games I make to Android via [PyGame Subset for Android](http://pygame.renpy.org/).
Any suggestions? I haven't found any good inverted index library, other than the one in Lucene and (based on Justinsaccount's pointer) perhaps xapian. You'll also see the closest things I've found have been C++ libraries. 
I've got it installed. I'm trying to figure it out. The documentation is pretty meager, and I can't find examples of anyone using the inverted index directly. For example, how does one construct a raw query based on boolean terms?
Quoting Apple: "The maximum amount of SDRAM [I] can install in the computer is 16 GB." One solution of course is to use an Amazon node with a lot more RAM. I'm not there yet. For one, I'm trying to figure out how to manage the data nicely, since it currently takes a couple of minutes to load from my flat file format. (Although part of that might be swapping.) In any case, the research I linked to shows that a dedicated library should be faster than using Python's generic set using integer objects. There's no good fit to the distribution. It's not Zipfian, it's not logarithmic. See http://www.dalkescientific.com/writings/diary/archive/2011/12/25/unique_fragments_in_pubchem.html for some pictures. I do plan to special-case the 1 million or so features which exist only once, which will help some. I'm still trying to find a realistic query data set; for now the lookups are a sampled subset of the targets.
I hesitantly say yes. In many languages incrementing and decrementing come in both prefix and postfix forms that change the variable either before or after its evaluation in the expression (++x and x++). In many cases it does not make a difference but I can subtly introduce bugs. One the whole I just like how x += 1 forces me to move the side effect into another explicit line. I say this hesitantly however because in my humble opinion one can do away with the need for incrementing/decrementing by reconsidering the problem. I also feel the same about switch. To me its not a problem of long conditional chains are difficult and switch statements can help with this problem, but that the need for either of those is a sign that you should be reconsidering how you are solving the problem on the whole. This explanation does not really do justice however, so I am working on an in-depth brain dump that I can forward to you. Thoughts?
Because there isn't enough of a benefit over if,elif,else to justify a whole new keyword, in fact in many cases switch is worse (readability of fallthroughs vs explicitly starterd if,elif chain)
Most of what I'm doing is outlined in http://www.dalkescientific.com/writings/diary/archive/2011/12/23/inverted_index.html . Although I did that examples based on letters in words, and not chemical substructures in a molecule, the code is equivalent. One thing missing in your code is the equivalent for set.intersection(*(inverted_index[bit] for bit in features)) , that is, the set of identifiers which have all of the features I'm looking for. Here I used set syntax. If you use arrays, as you do, then the better solution for when new items are rare is to keep the items sorted. In that case, the multi-set intersection is probably best done with a binary search. (See the second of my linked-to research papers.) Doing it efficiently is more complicated than I would rather think about, which is why I'm looking for an existing library. I do intern my integers, and you are right for pointing out that easily overlooked subtlety. The feature patterns (in a subset of 22,371 records and 72,131 features) looks like: 0:14,1:6,2:14,3:15,4:16,5:16,6:16,7,8:2,9:2,10:4,11:2,12:4,13:4,14,15:2,16:2, 17:4,18,19:4,20:4,21:4,22:4,23,24:2,25,26,28,29,30,31:2,33,34:2,35:2,36:2, 37:2,41,42:2,43:2,47:2,50:2,55:2,57,58:2,59:2,60,61:2,62,73:2,74,75:3,77:2, 78:2,79,83:4,87,89,97,98:3,103:4,118:5,122,124:3,127:4,129:3,131:4,134:3, 135:2,136:4,137:2,140,146:4,148,149,150,151:2,156:3,157:2,159:2,160,162:2, 164:2,165,166:2,167:2,169:2,170:2,171,172,181,184:3,185,186:3,187:2,188, 193:3,194:2,198:2,199:4,202,205:2,207:2,208:3,212:2,218:2,226,231,232,238, 241,242:2,243:3,245,251,252,253,289,290:2,292:3,295:2,318:4,331,338,359:2, 383,387,402,408,414:2,461,488,498,526:3,529,556:2,563,565,580,594:4,598:2, 600:2,623,647:2,651:2,661,663:2,666,681,692,713,714:2,721:2,857,937:2,993, 1019,1047,1066,1069,1072:5,1095,1100:2,1108,1141:2,1145:2,1159,1172:2, 1180,1236,1264,1294:2,1301,1317:2,1329,1333,1338,1348,1352:3,1357,1362, 1363,1372:2,1416,1434,1435,1447,1448:2,1452,1454:2,1464:2,1466,1478:2, 1485,1522:4,1523:2,1592,1598,1607:2,1612,1633:2,1685,1693,1695:2,1699, 1715:2,1823,1853,1857,1864,1870,1871,1872,1884,1940,2025,2028,2029,2034, 2200,2520,2577,2651:3,2683:3,2688,2694:2,2812:3,2816:2,2937,2978,3099,3135, 3199,3307:2,3354,3520,3675,3708:3,3732,3821,3892,4126,4207,4298,4384,4514, 4726,4743,4747,4819,4889,4893,5011,5026,5045,5232,5351:2,5490,5554:2,5700, 5732,5733,5915,5919,5992,5996,5998:2,6121,6123,6199,6202,6210,6211,6214:2, 6460,6470,6476,6590,6810,6844,7084,7096,7241,7438,8750,8764,8964,8968,8975, 8979,8980,8989,9126,9128,9148,9176,9423,9638,9958,10216,10603,10754,10757, 10904,10905,10907,10908,10929,11060,11084,11095,11570,11573,11582,11607:2, 11694,11835,11838,11840,11866,11904,11906,12118,12271,12550,12597:2,12633, 12665,12685,12722,12728,12778,12867,12873,12918:2,13014:2,13057:2,13074:2, 13391,13407,13421,13466,13498,13537:2,13566,13575,13582:2,13741:2,14876, 14893,15060,15063,15354,15363,15587:2,15603,15607,15634:2,15828,15833,15912, 15923:2,15960,16423,16608,16669,16901,17008:2,17121,17143:2,17150,17173,17177, 17223:2,17353,17418,17471:2,17495:2,17511,17587,17615,17666:2,17926,18018, 18210,18213,18262:2,18273,18367,18395:2,18575,18592:2,18640,18750:2,18753, 18763,18768,18781,18810,18844,18847:2,18872,18924,18958:2,18970,19027,19029, 19051,19057,19071,19101,19115:2,19125,19128,19132,19176,19222,19223,19227, 19807,19850,19873,19888,19901,19936:2,19978:2,20008:2,20547,21700:2,23080, 23097,23101,23205,23223,23237:2,23241,23245,23312:2,23331:2,24068:2,24434, 26382:2,26509,26570,27344,27475,27637,28024,29125,29283,29478,29581,29670:2, 34436,35807,36491,36511,36526,36559,37585,37622,37868,46736 If a comma-separated term is of the form "N:M" then the feature N occurs M times, where M&gt;1. (The ":N" term is not important for this current analysis.) 
 def __init__(self, db): self.database = xapian.Database(db) def do_search(self, words): enquire = xapian.Enquire(self.database) query = xapian.Query(xapian.Query.OP_OR, words) enquire.set_query(query) matches = enquire.get_mset(0, 2000) results = [] for match in matches: doc = match.document.get_data() results.append(doc)
The indexing is not the problem. The problems are 1) keeping the data in under 12 GB of memory, 2) having a fast way to bring the index in from disk, 3) support for fast multiple set intersection. Database and pickle solutions provide 1&amp;2 but not 3. Python sets provides 3 but not 1&amp;2. Redit, PostgreSQL, and other database servers provide 1, 2 &amp; 3, but add a layer of complexity I would rather not deal with if a simpler solution does exist.
&gt; One thing missing in your code is the equivalent for set.intersection(*(inverted_index[bit] for bit in features)) , that is, the set of identifiers which have all of the features I'm looking for. It's still there, you just spell it: set.intersection(*(idents_for_feature(bit) for bit in features)) Given the size of the sets, I don't see much point to sorting. You could time it both ways, of course. &gt; I do intern my integers, and you are right for pointing out that easily overlooked subtlety. The even more subtle bit is that my approach actually didn't *need* to intern any integers, because apart from the identifier_ids dict, it doesn't actually store any integer objects. All the integers are stored in arrays, which use "unboxed" raw C integers instead of Python int objects. But I didn't realize I could skip the interning till it was basically written, and since I'm doing your work for free anyway, I figured, "what the heck," and didn't bother stripping the interning back out. ;-) I'm pretty confident that what I wrote is perhaps the most memory-efficient data structure you could create in Python, and very close to what could be had in C. About the only improvement I can think of at this point would be reducing fragmentation by replacing the list of arrays with a big array and using linked lists (with "previous" pointers in another int array). That would keep from allocating and reallocating lots of short arrays that could result in fragmentation waste and copying overhead. It's hard to think of a data structure in C that could improve on this for the use case, really. (Barring lots of pre-passes to pre-compress some sort of exotic hash table structure, or making use of some regularity in the underlying data that isn't obvious to me from your examples.) 
[rabbyt.](http://arcticpaint.com/projects/rabbyt/) Maybe not exactly what you're looking for, but it's at least a step up from raw pygame. 2d on a 3d canvas, so it's hardware accelerated.
The argument is that it doesn't have popular support. What's the problem?
That's cool. We're all entitled to our own opinions and if anything, it shows how something like language design is fuzzy and ambiguous effort. I agree that the difference between ++x and x++ is confusing, I suppose I'd like it if Python allowed x++ but not ++x but that might be nightmarishly difficult to parse. . . I can see with switch how it would very quickly become confusing if it accepted all immutable values (like tuples) which looks and sounds Pythonic. The fact that Python has neither of these constructs is not that big of a deal to me.
You need a "sorted(... key=len)" there because the smallest set should go first. Ideally the set with the smallest intersection to the first should go second; using the second smallest set is okay. I've had success with algorithms which try to improve the test order dynamically, to get an extra 5% or so performance out of the code. If the lists are sorted then it takes O(log(k)) time to check if a value exists. It takes O(k) time to check if a value is in the unsorted list. My own tests using a list of 234936 elements found the breakeven point between bisect and "x in list" was at element 46, so it is possible that one is faster than the other for this case, depending on the length. The analysis isn't that simple, since there are adaptive optimizations you can do with the sorted list that you can't with the unsorted one. Eg, the low mark for the binary search range is always increasing, so successive searches get increasingly faster. My intuition suggests that sorted lists, alternatively a B-tree, will be faster. Sorted lists give other advantages. For example, they can take less space by using deltas and Elias gamma coding or something similar for compression. I would expect that a good inverted index package would do this for me. The 13 year old book "Managing Gigabytes" contains an excellent description of how useful compression can be, and it is guiding my ideas of what my desired library should be able to do. These techniques are well known and no longer considered exotic. The Lemur Bitmap Index C++ Library is an example of a library which does compression of this sort. My attempts at writing Cython bindings to that library have not yet been successful. I implemented a realloc-based array and a linked-list-of-block-with-special-support-for-sizes-0-and-1 version for a project last winter, and never found that linked-list version to be measurably faster. It was, however, more complicated. My code, based on sets, needs interning. My comment was meant to praise your decision to remind me of it. 
That works - thanks! (Though I used OP_AND instead of OP_OR.) I've been loading my data set for the last couple of hours. The first 1/2 of the data set took 30 minutes, I still have 10% to go. Any idea of what's going on? Here's my loader: import xapian import sys from collections import defaultdict db = xapian.WritableDatabase("pubchem.x", xapian.DB_CREATE_OR_OPEN) def sync(q): for id, names in q.iteritems(): try: doc = db.get_document(id) except xapian.DocNotFoundError: doc = xapian.Document() for name in names: doc.add_boolean_term(name) db.replace_document(id, doc) q = defaultdict(set) for lineno, line in enumerate(open("pubchem.counts"), 1): name, ids = line.split(":") ids = ids.split(",") for id in map(int, ids): q[id+1].add(name) if lineno % 1000 == 0: sys.stderr.write("\r%d / %d" % (lineno, 462406)) sys.stderr.flush() if lineno % 10000 == 0: sys.stderr.write("\n") sync(q) q = defaultdict(set) I do partial writes because I can't store everything in memory. Also, I'm having to rebuild the document from my data file, which is stored as an inverted index. That's why I had to updated existing documents if I find that it contains additional feature keys. 
Researching now, LevelDB manages a dictionary-like data structure. I'm interested in a set-like data structure, including set operations. Specifically, given three existing sets (e.g., {1,2,3,4,5}, {2,4,6,8}, {2,3,5,7}), how do I use LevelDB to find the intersection of the sets? It doesn't appear to have intersection as a built-in operation, and I suspect building my own in Python would be a lot slower than the current set.intersection built-in. My estimates suggest that I should easily be able to have all of my data be stored in memory, with plenty of room to spare. The raw data is 275 MB, uncompressed. It's the combination of Python's object overhead and data structure overhead which are the likely bottlenecks... and I think the 8 byte PyObject* pointer overhead doesn't help, given that the actual values need only three bytes of data.
&gt;I understand the jump optimization. I would argue that it is incredibly complicated to optimize something like that at run-time. My guess is that a switch statement for python would just be syntactic sugar for a dictionary based method. The point is that such methods require only a single lookup rather than evaluating each comparison.
It's certainly a step up; not 100% what I wanted, but definitely a step up. I'll keep it in mind - thanks :)
Compared to flat SDL, you're right - but PyGame leaves a lot of stuff up to you to implement, like: * a map editor * physics * a render loop PyGame is just abstracted at way too low a level for my liking. The low level of abstraction does help with flexibility, but nine times out of ten a higher level of abstraction is more beneficial in the long and short run.
If pygame is too low-level for you, I think you'd be better off with [Blender](http://www.blender.org/) or some such.
[FIFE](http://fifengine.net/) might be something like you're looking for. It's written in C++ but uses Python for all its scripting. There might be a little more fiddling to do on your part if you're intending to not do isometric. And God help you if you want to compile it for Mac.
There's no reason you couldn't abuse it for 2D games. Or you could just use PyGame.
Yes, because they're definitely the only two options. 
I will send you a cowboy hat soaked in robitussin if you pull this off.
You can use external libraries for this sort of thing. For instance, for map editing, you can use something language-agnostic like [this](http://www.mapeditor.org/), and then write or find [some code](http://silveiraneto.net/2009/12/19/tiled-tmx-map-loader-for-pygame/) to use it in Python.
&gt; If we are reimplementing syntax that is already available, what did we gain? Why have for each loops (or for loops in general) when while loops implement the same functionality? Or, say in C, why have while loops when the same functionality is provided by goto's. Can it be done already? Yes. Do I think a switch is easier to read than the following (or equiv. using defaultdicts): def zero(): print 'You typed in zero' def p_sq(): print 'a perfect square' def even(): print 'an even number' def prime(): print 'a prime number' def default(): print 'Only single-digit numbers are allowed' switch = {0: [zero], 1: [p_sq], 2: [even,prime], 3: [prime], 4: [p_sq,even], 5: [prime], 6: [even], 7: [prime], 8: [even], 9: [p_sq]} try: for f in switch[case]: f() except KeyError: default() Yes. Maybe it's because I learned C first, but I'd rather have a switch statement than the dictionary (even if the implementation of the switch was the dict).
Having code like pje has supplied is *much better* than having a module if it ends up working, because it is simple and fully open to your modification. In general you will end up spending much time ironing out the idiosyncracies of any particular module; not always true, but a general rule. Based on you mentioning that the data is 275MB and most of the space is Python overhead, this should be plenty memory-efficient for you. If it is, test the speed. By the way, you should probably test it before discarding it for theoretical inadequacies. Most of all do not fall into the pit of premature optimization. You do not want God's gift to the programming world. You want something that *works*. So try the damn thing and throw it away if you have to, but stop looking a gift horse in the mouth.
With an orthographic projection and a constraint on one axis, the blender game engine suddenly becomes 2D. See [sparky](http://www.indiedb.com/games/sparky) for an example.
I would be much interested in a framework for 2D games based on PyGame!
If you measure simplicity by the number of lines then I think you can cut out some boilerplate and blank lines. Although I have to admit that word 'Simple' in the title might be a bit misleading.
&gt; Is there an IDE that's kind of like it, allowing you to run code directly &gt; from it, maybe with some syntax highlighting and auto-complete The Zeus editor can do this: http://www.zeusedit.com/ &gt; and debugging features Zeus can do Python debugging using gdb. 
Remember that pygame/SDL is all software-side (except for the hwsurfaces, but those don't tend to help a lot), so it's very slow. You can't do anything fancy with it like having lots of moving things on the screen simultaneously or rendering at high resolutions. In particular when you want things like per-pixel alpha blending to move around semi-transparent sprites you'll be very restricted on what size of sprite you can use and how many. It's most well-suited to writing 8-bit style retro-games that have alpha-key transparency and run at low resolutions like 800x600. If you want to build something that runs at really high resolutions and looks fancy, possibly with many moving parts to it, you might want to look into some of the other libraries that render via OpenGL.
ZODB's BTrees implementation could handle this nicely.
`x +=` mutates if `x` has an `__iadd__` method though, which is confusing.
A sane switch statement auto-breaks (for example, Go), so at least you don't need `break` for every case.
The dict values are inside of lists because a switch would have to support calling an arbitrary number of functions, not just one case to one function. This way, the construct may iterate over every function assigned to that case. 
If you need this, take a look at the PyPy sandbox - nedbat and I got it down to 1s startup, and it's plenty safe compared to eval.
If eval or exec are dangerous, then why are this function exist?
Well you're not suppose to do stupid shit like eval rm -r. Or open am important system file and mess with its content. My point is scripts/program are about as dangerous as the user who wrote the logic underlying it.
Actually it's quite easy to show that the more conditionals you have, the harder your code is to either test or to prove correct, meaning a greater chance of bugs. So in an ideal world you avoid unnecessary conditionals, and encode necessary conditionals within language-provided constructs (such as polymorphism, dictionary dispatch, etc) where possible.
Which can be done in python too: print eval('x+1', { 'x': int(userInput)}, {}) [example](http://codepad.org/VuDDZfrH)
That would be perfect
There is this new thing called *functions*: def f(x): return x + 1 print f(int(userInput)) 
I think you are missing the point. The author of the script didn't put "rm -rf /" into the script. The author accepted strings from users and eval'ed them, and a malicious user put "rm -rf /" into the input.
I would say sanitizing the user input includes using facilities of your backend (variable binding, prepared statements, whatever). I simply meant "don't leave user data untreated", not "write your own regex validator/sanitizer"
[kivy](http://kivy.org/) is also worth checking out. It's still pretty low level, but the APIs are really nice and well documented.
Isn't this common sense? This isn't even Python specific. It should be general programmer knowledge. Water is wet. Sky is blue. Grass is green. Eval is dangerous.
C++ streams are also slow because of their default behavior, especially if you print to them frequently. I remember reading awhile back that you can change the default behavior to be optimized for short, frequent prints, but by default they're optimized for printing very long strings. Many people simply skip these optimizations and use printf, which is substantially faster in many cases.
It is altered in the sense that it doesn't appear literally in the query string that is ultimately seen by the SQL engine.
It was meant as a simplified example. 
The query string isn't part of the user input.
Sometimes I feel like people make up names when talking about Python builtins; it's like I discover a new module everyday. CPython is incredibly feature-rich.
This is really exciting stuff. I'm just getting ready to deploy a large scale project in Tornado -- should be good :) thanks so much for your hard work!
Audio processing/analysis noob question: Do you by any chance know of a library or easy way to get certain audio metrics from a file? I've been really wanting to do some analysis on my music and get things like beats per minute, frequency range, etc, though I haven't been able to find a clear explanation of how to do it programmatically.
They're dangerous when used with untrusted input. Is all input untrusted? In web applications certainly most forms of input are. But still not all. Maybe you want to eval a certain critical bit of code in a text field in the database, where it can be changed on the fly across thousands of instances. And it can be quite possible to trust the program user's own input when working outside the web development world in some situations. If the user is running the program on their own machine which they have administrator access to, why does your program care if they creatively bypass your sandbox to run their own programs, or even format their own hard drive? That's their decision, it's their computer. Note that these things are kind of frowned upon, possibly because I'm not good at coming up with examples. But the point is you can trust some input.
such as?
I didn't consider it particularly bad, just a bit unwieldy. I certainly agree that the alternate version with a comprehension is much better.
I prefer `map` for cases where the transformation can be expressed with an already-defined function; creating a lambda in-line to use `map` with is a sign that you really want a comprehension instead.
The general finding IIRC is that map is somewhat faster when used with builtins, but significantly slower when used with user funcs.
Anything functional or OO. (Let's say Haskell, CL with CLOS) Pattern matching and Type dispatch are the big ones here. Being able to specialise methods on particular values as well as types works very well.
Eval can often produce a *better performing* result, but you are correct, anything you can do with eval, you could equally do with reflection and function composition. 
&gt; Doesn't the backend ultimately have to put the data into some sort of query to insert it? No. The parameters to a parameterized query aren't treated as part of the query, they're treated as parameters, which never get executed. Incidentally, this is another good reason to parameterize your queries: if you run the same query with different parameters using a dynamic-SQL approach, not only are you risking SQL injection, the query optimizer has to be re-run each time. If you create a single parameterized query and re-run it with different parameters, the DB can cache the query plan.
I remember a great IRC session where some guy in #python-forum on FreeNode had a bot which implemented a Python interpreter, and thought he could keep it completely safe. We invited a load of guys in from #python to try and break it, and after a while, some guy did manage to exploit Python's internals to circumvent every protection this guy has put in place and access the builtins. I wish I still had the logs of that session; it would be a great educational experience to post here, because for me it really drove the fact home that you can *never* trust eval to be 100% safe. Even if you think that you have taken every precaution under the sun to prevent your code from being exploited, there is *always* some guy out there who knows something you don't. Simply put, if you ever use eval() on untrusted input thinking you have put in place enough safeguards to prevent abuse, you are operating on the assumption that you know more about Python than anyone else in the world. This is almost certainly not true.
http://www.panda3d.org/ Panda 3d
*Batteries Included* after all :)
Your description matches almost any new feature. For example, the with statement. 
I already made a ticket and submitted an alternative implementation. The maintainer just closed with the words: &gt;The current version is clear and maintainable. There is nothing unholy about using exec. Earlier versions used other approaches and they proved unnecessarily complex and had unexpected problems. It is a key feature for named tuples that they are exactly equivalent to a hand-written class. &gt; &gt;I appreciate your effort but am rejecting it flat-out. http://bugs.python.org/issue3974 Current version: http://hg.python.org/cpython/file/bbe2223e3750/Lib/collections.py#l165 The exec version is indeed a tiny bit faster. I just hope that this argument won't be used in more cases. Hard coding with exec is of course a tiny bit faster than looking stuff up in a dict. I guess we could speed up even more generated classes in the stdlib with this idiom... 
I din't even know that Tornado was the new twisted
C++ programmer here, who does love the language... ++ is a terrible idea. The trouble is that it does two things - it has a side-effect, _and_ it returns a value. Right away this is ambiguous on its own - do you increment before and after? - so C has pre-decrement and post-decrement, already alarming... But then what happens if you have multiple ++ in a statement - what order do they occur in? (And if it's just a statement - why bother - you save two or three characters over x += 1 - for what?) I can't think of any other "punctuation" operators in Python that have a side effect. 
Sure, that's how it works in C++, I propose that in Python that it not return a value e.g. x++ is OK, but y = x++ isn't. You can currently say x += 1 but you can't say y = x += 1. Also, that would remove the ambiguity with the incrementing before or after the return value. I totally agree that the way it works in C++ is yucky. BTW, I'm not losing any sleep over this, for me, it's a nice-to-have.
Like the OP, I'm looking into switching to a python static site generator. Pelican looks okay, but I'm not getting the rules for permalink customization to work. I see you use: &gt;ARTICLE_URL = 'posts/{date:%Y}/{date:%m}/{date:%d}/{slug}/' &gt;ARTICLE_SAVE_AS = 'posts/{date:%Y}/{date:%m}/{date:%d}/{slug}/index.html' The Pelican version in the PIP doesn't seem to support his jet. May I ask which version you use?
I'm using 3.0 from git master. &gt; The Pelican version in the PIP doesn't seem to support his jet. "jet"?
A, a 't' dropped there: 'this jet'. In PIP version 2.8.1 is the latest, so I think that may be it. Thanks!
We wanted to start with web scenarios just because they're pretty popular and Django is the most popular web framework for Python so we picked that. We also have IPython up and running in the cloud as well, and we want to add "worker role" support in the future for more general computation. Of course we're an open source project so if someone wants to add support for another web framework we're open to that too. There's not much that is Djagno specific to running in Azure so it probably wouldn't be too difficult.
`eval` is the tool to use if you are actually prompting a user to type in code that they want to run. The problem is when you have a program that will run code on the behalf of someone _other_ than the person running the program. Avoiding `eval` except when you explicitly want the user to type in code reduces the risk of this happening.
it's an automated theorem prover developed by Microsoft, it has built in equality and arithmetic, and a Python interface it seems. an automated theorem prover can be used to recognize **tautologies** and **contradictions**. *tautology* : something which is always true (aka theorems). *contradiction* : something which is always false. (negating one will give you the other) it's easier to see with a boolean example; this one states that *p is true or not p is true* (in Python `not p or p`). ¬ p ∨ p if p is a boolean proposition: this is a theorem. p only has two possible values *true* and *false*, and either one will give the entire expression the same valuation (*true*). we can negate it and end up with this expression p ∧ ¬ p which is a contradiction (p and not p); to verify that this is a contradiction you can use a theorem prover (for instance Z3) like this: p = Bool('p') solve( And( p, Not(p)), show=True) 
I haven't had a chance to try it yet, but I hope Flask, Jinja2 templates and virtualenv support is available, or coming soon. I typically dev Python on Mac, but have some other developers I work with could use a good Python IDE in Windows.
thanks I meant code snippets, some functions for this and that.....
Google. That nearly always returns a link on StackOverflow.
Flask isn't supported, and isn't anything that we've really even thought about to date. Jinja2 would be awesome, and given that it's similar to Django templates I could see it being something we (or someone else) could easily add - but again, not something we currently support. It'd be great if you could open feature requests on [codeplex](http://pytools.codeplex.com) for these. virtualenv is again something we don't support but is something we've discussed internally and are very interested in supporting - even if it doesn't yet [have a lot of votes](http://pytools.codeplex.com/workitem/691) so please vote on it. It's even more important now that PEP 405 is on the standards track. So while this isn't something that will show up in our 1.5 release I hope it's something we address soon. Anyway, sorry for the mostly disappointing response, but as I always say we are an open source project, and we'd love to see people contribute features like these :)
I bet it's possible to define a metaclass which the `collections.namedtuple` function then uses to define the class. That's what metaclasses are for: defining classes. `Point.__mro__` can still be `(&lt;class '__main__.Point'&gt;, &lt;type 'tuple'&gt;, &lt;type 'object'&gt;)`. I think the only difference is `type(Point)` would return `&lt;type 'collections.NamedTupleMeta'&gt;` instead of `&lt;type 'type'&gt;`. 
[SymbolHound](http://www.symbolhound.com/) searches StackOverflow for symbols Google can't handle. 
DuckDuckGo. Always.
What example would you use to teach this?
Thank you for this!
I like how it ends with something like *they're both good, just use whatever works; HTTP is agnostic, so use an SOA approach.* Which is not as antagonistic as the title of this port or the presentation itself.
For a language the values simplicity, Python gives you a good number of little obscure attachment points that let you implement all kinds of dark magic. (I'm thinking of things like metaclasses and descriptors here.) In the right hands, it can make frameworks that are really beautiful, but in the wrong hands the result can be a confusing mess where nothing works the way you expect it to and there's a lot of confusing "action at a distance" happening. 
please correct me if i am wrong, but the numpypy status is same as in the last release?
I'm a big fan of context managers aka the with statement, but in this case I have to disagree with you. This urllib.urlretrieve(url, "code.zip") beats this in "code elegance" r = requests.get(url) with open("code3.zip", "wb") as code: code.write(r.content) in my opinion. Only if it really is only about downloading a single file of course. For everything else that has to be more robust a context manager can provide awesome things that the one liner can't. 
Generally slow, like doing *mere* 10k of payments per second?
Packaging sucks. ([But is getting better](http://guide.python-distribute.org/))
The transition will be barely noticeable, you probably wont need to do anything special to smooth it. You *could* cross-fade from one to the other, but try without first.
[ 'omg this ' for i in range(100) ]
If the camera only ever looks perpendicular to the texture, you can use trilinear filtering. If the view may be at an angle, you'll need anisotropic filtering to make it look good.
Disclaimer: Feel free to correct me on any of this, r/python :) Python is great, but some of its features are trade-offs, so they do come with a down side. My main gripes are with writing production-level code, i.e. making it resilient to run-time failure. Most of that is due to the dynamic typing and interpreted nature of Python. * Python makes it hard to give guarantees that arguments will be accepted -- duck typing is encouraged, so if a function requires a list, I can give it something that looks like a list. Except that I can't know which properties will be required exactly, or in the future when the function implementation changes. What's worse, your function implementations can bail halfway on a simple, say, a.append(b), if a did not provide an append method. It's hard to write readable code that actually recovers from that properly, so most don't. * Python needs 100% code coverage in tests, because every line can bail on some type error etc. While 100% coverage is nice, it's less of a strict requirement for other languages, in which untested lines at least compile properly. * Python offers flexibility by simply hiding tough edge cases, failing on them at run time where other languages fail on them at compile time. For example, casting between classes is implicit in Python (you don't have to cast). That does not mean that bad casts just disappear -- they simply cause errors at run time instead of at compile time. Python tends to constructions like that, which makes it easy to write functional code but hard to get it fully correct. Apart from those, there are a few other gripes: * Python's variable scoping sucks, ranging from 'local' and 'global' keyword hacks to list comprehensions leaking their iterator variable. * Python is a lot slower than compiled languages (although a lot faster than most interpreted languages). This is because all of the indirection (JIT, every object is a pointer, etc) that will swamp your CPU with cache misses. * Python 2 vs Python 3 is just a mess, to the point where we can't even be sure that Python 3 really is the future. 
Well, the first example in the "warts" one is quite stupid: &gt;To get the number of elements in a collection in Python you have to use the len() function. I would prefer a length property on collection classes. The only difference between a function and a property in this case are a couple of parentheses. If you want to use "length" instead of "len" you can use "length=len". The second isn't much better either: &gt;range() &gt;Instead I would propose an API where the first (optional) argument is still the starting index, but the second argument is the number of elements. Well, that would lead to off-by-ones again, wouldn't it? All in all as opinions these are okay, but in no way objectively useful. **EDIT**: The rest I agree with.
&gt; For example, casting between classes is implicit in Python I'm not sure what you mean by that. If you mean what I think you mean, you're dead wrong. &gt;&gt;&gt; "1" + 1 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: Can't convert 'int' object to str implicitly That's pretty obvious though. So what *do* you mean? &gt; Python 2 vs Python 3 is just a mess, to the point where we can't even be sure that Python 3 really is the future. If Python has any future it's 3. If 3 fails, the language will fail with it.
the link is the same, but we don't have a copy of the last one (you can probably fish one from the history somehow). There were definitely improvements over the last release.
In a nutshell, I'd say Python is an excellent "good enough" language across the board, but it falls short of best-in-class almost everywhere if your needs really do go further. For example, as you've noticed, Python has good support for common operations with structured data, including well-supported built-in arrays, sets, dictionaries, and various types of comprehension and generator. On the other hand, if you need to use more advanced data structures, including anything graph-like (even common linked list variations), Python's support out of the box is weak compared to many other languages. Similarly, the "batteries included" libraries are good for basic stuff, but a large proportion of the not-quite-basic stuff is poorly documented or just downright awful. For example, Python should be a great alternative to shell scripting or Perl, but a combination of awkwardness in the more advanced file system and related libraries and a horribly overcomplicated standard library for running other processes negates most of the advantage you might gain from Python's neat code and good basic expressive power. Some of this can be fixed by installing additional packages, and often for simple problems a `pip install foo` will do just fine and get you everything you need. However, once you start trying to manage more complicated dependencies, Python's packaging systems (there are about 17,245 of them this week) are absurdly overcomplicated yet woefully underpowered. In performance terms, Python is fine for everyday tasks that aren't processor intensive, and it has decent enough integration options for some external high-performance libraries. On the other hand, for serious number crunching that isn't something you can completely "outsource", native Python is at least an order of magnitude slower than mainstream compiled languages, it offers little support for concurrency and parallelism, and the various alternative interpreters/compilers and the mechanisms for calling down to low-level code all come with significant drawbacks of one kind or another. In short, Python is excellent for everyday tasks in the "80% zone". It's also a fine choice if your problem falls into a "10% area" where your needs are more demanding but an established third party library can already do almost everything you want (web serving, NumPy, etc.). For anything in the last 10%, where you have more demanding requirements and there isn't a combination of canned libraries available that collectively do most of the job before you start, Python is somewhere between COBOL and Whitespace on my preference list. :-)
* Packaging sucks * No repeat..until statement or equivalent * list comprehensions leak variable names * no full unicode support in re module regular expressions 
In that case casting is still implicit, it's just used immediately and breaks immediately. But I had OO polymorphism in mind actually. For example, in C++, if I do A a; B &amp;b = a; only compiles if A can be cast to B (upcasting). Similarly: A a; B &amp;b = dynamic_cast&lt;B&amp;&gt;(a): will throw a bad_cast exception if at runtime 'a' did not turn out to be castable to 'b' (downcasting). In Python, you'll typically just do b = a and the cast is implicit, as in, you'll start to call member functions of the class that you assume the object to be (compatible with). That allows for easy coding and is correct in most cases, but in reality, the cast is still there semantically. Python just does not know about the cast and won't warn you in case of errors. Instead, the code will break further down the road when object "b" is called with a method it does not provide. That's a feature in some cases (it's closely related to duck typing), but makes it a lot harder to harden your code against errors. Also, debugging is more of a pain if an error condition is triggered nowhere near where the code is wrong.
The analogy that helps me understand it is that the "else" clause is the alternative to the "if .. break" statement inside the for loop: http://nedbatchelder.com/blog/201110/forelse.html
Do we really need a repeat/until statement ? I am curious what you can do with repeat/until that while can't do. Repeat/Until lets you run code first, test later, so you have at least one trip thru it. It looks like it can be spelled like this in Python: # Repeat while True: # your loop code goes here yourCondition = True #Until if yourConditon: break What am I missing here? 
 def is_circular(prime): for i in range(len(prime)): if prime[i:] + prime[:i] not in primes: return 0 return 1 You should have not filtered out the "None"s in your list and done if not primes[int(prime[i:] + prime[:i])]: return False Much faster than looking through your whole list. Also returning 0 and 1 rather than True and False isn't very pythonic for readability reasons, despite them being equal. Edit: Just timed it. real 0m1.172s user 0m1.009s sys 0m0.114s def generate_primes(end): primes = range(end) for i in range(2,len(primes)): if primes[i]: for j in range(2*i,end,i): primes[j] = None if i**2 &gt; end: return primes def is_circular(n): for i in xrange(len(n)): if not primes[int(n[i:] + n[:i])]: return False return True primes = map(lambda n: str(n) if n else None, generate_primes(1000000)) print filter(is_circular, filter(None, primes)) 
That is just a wrong way of looking at it with Python. In C++ you are telling the compiler `a` is some object A, and `b` is some object B converted from `a`. The compiler determines (or runtime, as your second example shows) whether the polymorphism is allowed. In Python, `a` and `b` are just labels for *some object*... there is never any check whether they have any relationship at all. So saying `b` is `a` is just placing another label to the object `a`. This is vastly different than casting, where type metadata is used.
In any discussion of programming languages, it's not a question of what you *can* do. All mainstream languages can perform the same operations. It's how elegant and easily understood the code for that operation is. If you didn't have for loops, you could make do with while loops, but `for` is still useful. So the question is: is repeat/until useful often enough to be worth adding syntax for it? I'm not sure; I've wanted it a few times, but not very often.
pandas and statsmodels are up and coming libraries in this area as well.
It's probably best to keep in mind that Python is not C++ or any other language. With just a quick read of your post I can see you haven't taken in that Python has **NO VARIABLES**. Yes I know its similar and seems the same etc.. It isn't the same. There is no casting going on in the background. You just assigned an object to a different name. Everything is an object, objects have types ( they type defines its default methods ), and objects can be assigned to a name. &gt; Python just does not know about the cast and won't warn you in case of errors. Instead, the code will break further down the road when object "b" is called with a method it does not provide. Python has no concept of 'cast' but it has a concept of TYPE. It is a language of consent not enforcement. If you are calling a method on an object of the wrong type you will get a nice traceback, when the error occurs. In c++ there is a compilation step in Python you just execute code. Python isnt psychic and it CAN"T know about errors until you execute them. If you want to make sure a method exists in the object you are calling use introspection ..hasattr() or make sure you have the right type(). Hope that helps it can be confusing at first.
.. It works on 64-bit. Are you talking about a Windows 64-bit JIT?
Ah I didn't even think about how that is faster, I suppose that makes the filtering of the non-possibles out not very important.
Python really shouldn't be used for anything that needs speed anyway. And most of the time, the speed isn't that noticeable. If speed is the main goal, picking Python is not a wise decision. It's similar to picking a limo for a street race. While it's nice, it's not right for the job.
I can see your point and at times I have wanted a do/while loop which is the same as repeat/until. At the core of it Python is based on some simple idioms and adding repeat/until would be bad because it would be just as easy to justify switch/case when really that is just as easy to do with if/then, etc. I want to keep the core language sparse and there is danger with adding to much syntactic sugar. Perl is a great example of a lot of awesome individual features that don't add up to an easy to read and parse language. To paraphrase Larry Wall - Perl is worse than Python because people wanted it worse. edit: accidentally left off words
You could also just use a set (which is faster). real 0m0.875s user 0m0.738s sys 0m0.110s def generate_primes(end): primes = range(end) for i in range(2,len(primes)): if primes[i]: for j in range(2*i,end,i): primes[j] = None if i**2 &gt; end: return set(primes[2:]) def is_circular(n): for i in xrange(len(n)): if (n[i:] + n[:i]) not in primes: return False return True primes = {str(n) for n in generate_primes(1000000)} print filter(is_circular, primes) 
&gt;\_\_del\_\_ is F***ing useless. I disagree. While I have yet to use it, I can think of some uses for it.
I'm sad to report that I haven't seen any improvement from PyPy in my code whenever I try it. In fact, sometimes it's slower. One particular program was doing big (mixed text/binary) file parsing, and was not I/O bound (C++ rewrite could manage the same workload in a fraction of a time). Maybe it has something to do with my code structure, I've made some tweaks, but ultimately did not stick with Python version long enough to find out. Lesson: you can't make blanket statements that PyPy is faster until you time *your own* code. **TL;DR** PyPy is not magic pixie dust. 
&gt; Python code is generally written such that the duck typing works for you rather than hinders you. Generally, but not always. eg. Accidentally pass a byte string where it expected a unicode string, and 99% of the operations you perform on it will succeed. But at some point it'll go boom - maybe not in the first function you pass it to, maybe not in the 2nd or 3rd - maybe a week later when the value is read back from the database and your XML parser chokes on it. eg. pass an integer instead of a floating point value to into a class that works with numbers (eg. a 2d vector for geometry). Everything will appear to work perfectly, including equality tests, range tests, etc, until you perform a division operation, and then your values will come out wrong. eg. pass a tuple to a class that stores lists for query and mutation. Iteration and membership tests will work perfectly. You'll only hit an error if and when you ever try to remove something from the list and find that it's not actually a list. If you passed a set instead of a list, again iteration and membership tests will work perfectly, as will removal in this case, but if you ever try to add to the list you'll find that 'append' doesn't exist. These are real problems that have come up in production code for us, all because it's easy for a stored object to have just enough of the right interface to get stored but not enough of the right interface to always work correctly. Once found, the easiest fix is to add isinstance() checks to catch the problem early - sure, this will annoy purists who would like the ability to pass a "list-like" object in future, but in practice I rarely need that capability as much as I need to be able to stop bad data getting in.
I've never found a need for an else statement on a loop in my practice.
Yes, but it is an argument to not include pypy into your list of "general python interpreters". But, entirely depends on you whether you want to count it or not (i.e. whether it's usable for you or not.) It's probably not a huge turndown for many people (compared to some of the other problems that might come with pypy), but python 3 *has* been out for almost 4 years now. 
That would leave only cpython as I don't think Jython or IronPython do Py3k either.
**1) Comprehension is so nice, I miss it on Python's regular for loop** I can do the following in comprehension: [i * j for i in xrange(10) for j in xrange(20) if j &gt; 10] But I cannot do the same in regular for loop: result = [] for i in xrange(10) for j in xrange(20) if j &gt; 10: result.append(i * j) Instead, I have to resort to this: result = [] for i in xrange(10): for j in xrange(20): if j &gt; 10: result.append(i * j) Making regular for loop syntax == comprehension syntax will make Python more consistent and cuts down unnecessary indentations. This alone will supremely reduced number of LoC in any projects. **2) Another minor squabble, semi-related to comprehension syntax. Noticed that comprehension can end with "if j &gt; 0"?** In Python, assignment cannot end with if statement: awesome = 5 if sauce &gt; 10 But it can end with else (because that's how Pythons' ternary works): awesome = 5 if sauce &gt; 10 else 9001 **3) I supposed you guys can deal with another complaint, right?** I can do this: any(user['email'] == 'bro@gmail.com' for user in users) But I cannot do this (not finding it in itertools): first(user for user in users if user['email'] == 'bro@gmail.com') This almost conveniently work: [user for user in users if user['email'] == 'bro@gmail.com'][0] # for first(), but bombed if list is empty [user for user in users if user['email'] == 'bro@gmail.com'][-1] # for last() I love comprehension so much, my Python looks a little lispy.
Can you elaborate on the "no full unicode support in re module" part? Is there something that `re.UNICODE` flag does not support?
I agree that you're more than welcome to disagree :-) &gt; I can think of some uses for it. That's what I thought, too. Just remember this: it is not guaranteed to be called, at all.
I recently tried to find any "all uppercase" words in a sentence. In ascii, that would be [A-Z]+. But what if we go beyond ascii? Eg. Ä or É or Ç? There are unicode extensions for regular expression, where I can express that as \p{Lu}+ (see: http://en.wikipedia.org/wiki/Regular_expression#Unicode), but the python re module does not support them. Note that python's str.isupper can distinguish unicode uppercase characters correctly. There is work in progress on a replacement for re, which does support this. You can find it at: http://pypi.python.org/pypi/regex 
&gt; I'm an experienced programmer and [have a very large penis], but ... in some situations I simply don't give a single fuck about error handling. More likely you don't know HOW to deal with error handling, because you fill you code with elegant one-liners like the above. Ah, but I see you don't refer to yourself as a *professional* programmer, so there is no need to say anything more.
Yes, this avoids the ugly break statement, and you can use a descriptive name for the condition to help the reader understand how you code works.
Yes, but the vast majority of libraries and production code are still python 2 only, which would indicate that it's python 2 support that is a better indicator of prime time readiness, not python 3 support.
certain*
Wow, I apologize in advance for the rant, but this just goes to show how Python is already *not* Pythonic, and why nuanced control structures should be legitimately considered in the language. "Tail recursion will conguse or surprise some folk, so it's not Pythonic" says Guido and others. "But what about loop-else? WTF is that? "Oh, that? It's a little, elegant way of doing searches and such". It's considered "intuitive" because they're already familiar with it, when there is no objective "intuitiveness" to it. There can't be, because good programming practices are built on he knowledge of decades of earlier programmers; they followed their intuition (globals, gotos, dynamic scoping), learned from the mistake, and built less intuitive, but *better*, tools for us to use. Python used to be adventurous, inventive. Maybe I just wish I could have been there, then. But now... The Pythonic way is, sometimes though rarely, used as a defense for ignorance. Sorry. This is actually a really nifty control structure. Thanks for sharing. 
So you are trying to count how often a character occurs in a string? Try str.count(character), where str is your variable and character is the character you want to count.
For free in one sense, at a great cost in another, I've written about some of the issues with using LLVM here: http://www.quora.com/LLVM/Is-LLVM-not-good-for-interpreted-languages-Why
I wouldn't really call that a shortcoming. It is a really cool and nifty little feature that can be abused, but it has valid use cases. 
Haha, nice troll attempt. I almost bit.
I don't think break is ugly it seems pretty descriptive you are breaking out of a loop. Really its a matter of taste , but in the end it doesn't matter Python has for and while as loop constructs not repeat/until or do/while or foreach or loop , etc...
You scare me.
 for p in primes: if n % p == 0: break else: primes.append(n)
['omg this'] * 100
yup just that thanks =]
Well, if you want a functional programming like way to get first/last, I guess this will work: first: reduce(lambda x, y: x if x else y if y['email'] == 'bro@gmail.com' else None, users) last: reduce(lambda x, y: y if y['email'] == 'bro@gmail.com' else x if x else None, users) (both return None on failure to find any match) Not very efficient though, as the iteration doesn't stop once it's found a match.
No it runs on 64bit system, using 32bit binary. It just can't use more than 4G per process I think
It is, but that has a few side-effects: 1. Code fails at run-time, not at compile time. Code coverage is needed to check for these things. That's more expensive than a compiler checking it for you. 2. The developer cannot tell what the interface of the function is. How good is 'good enough' for duck typing is hard to say in advance, especially if the function calls other functions using the original arguments (which isn't all that unlikely). (Edit: 3. Such errors can leave the object in an undefined state as it is unwieldy to guard against them. Broken objects are nasty to properly recover from if your program cannot afford to abort on error (interactive programs, etc).) It's just a different set of trade-offs. In say, C++, you know you have your types right but are less flexible. In Python, you're more flexible but don't always know whether you have your types right. It all depends on what you need in your code base. I love Python for many reasons, but that's not what OP asked :P 
You're quick to judge ;) I know Python's system and it very much has its appeals, especially when code needs to be very flexible in its input. Writing the zillionth operator&lt;&lt; in C++ gets tedious fast, for instance, just as a simple example. There is indeed no casting as such in the interpreter, but there is on a semantic level to ad-hoc interfaces -- the developer of foo(bar) will have requirements for bar, but they are implicit in the code, not explicit in foo's interface. This has great advantages and allows us to write generic code in a fast and natural way, but it still is one of the disadvantages compared to most compiled languages that Python can't check the types before you run your code. Python thus allows you greater flexibility, but can help you less to write correct code. 
ooooooo.... that opens up possibilities. But that iterates the loop twice, yeah?
I've used it many times. It's quite practical. But it's an oddity, and many people forget it's there.
Most people also think the GIL is no problem at all and it's there for a reason. (I have no statistics to back up my use of “most people“, but neither do you.)
The stuff I need R for are things like phylogenetics programs, microarray and gene expression analysis, and other specialized tools. Pandas and pystatsmodels are still pretty cool though.
Oh, wasn't expecting that kind of stuff. Thx for the answer.
&gt;Python 2 vs Python 3 is just a mess, to the point where we can't even be sure that Python 3 really is the future. What makes you say that?
at the moment there are two non-obvious ways
I was intentionally being statistically vague. What proportion is "many", anyway?
After a few years of Python development, I still consider whitespace delimiters to be a pain in the ass. It's much too easy to get tab/space problems, and any block &amp; copy operations are bound to cause problems.
What's the difference here? for x in [1,2,3]: print x; else: print "Done"; and for x in [1,2,3]: print x; print "Done";
Using memes in slides make me discretely leave the room.
The problem with this syntax is that both "No" and "Yes" are evaluated, even if you're only going to use one of them: &gt;&gt;&gt; def f1(): print 'f1' ... &gt;&gt;&gt; def f2(): print 'f2' ... &gt;&gt;&gt; [f1(), f2()][0] f1 f2 &gt;&gt;&gt; [f1(), f2()][1] f1 f2 Better is: &gt;&gt;&gt; f1() if True else f2() f1 &gt;&gt;&gt; f1() if False else f2() f2 
So many packages supporting just Python 2.. Python packages but also packages that use Python. It just keeps on existing and being used. Python 3 is almost 4 years old. Python 2 was the most recent for 8 years. Python is unique in many ways, but also in this. That's worrisome. Python 2 was/is really good, and already offers a solid standard that promises wide support and thus potential adoption. Python 3 not being backwards compatible makes using or depending on it require extra effort. There are many tools, but it's still a different language to consider. The emergence of the web and thus a big pile of old Python 2 examples (and programmers) that just don't go away probably doesn't help either in that respect. Python 3 will probably prevail at some point. There's no other viable outcome. It's just worrisome and I get a bit pessimistic sometimes. Especially when discussing gripes :) 
While I agree with you, I'd like to vouch for 2to3. It works wonders. There's been maybe only one or two cases in which it didn't fix everything for me.
What counts as an oddity in your book? Javascript "with" that extends the local variable scope with fields from an object? 
But that's suggesting most is not many. If the sample size is three, then "most people" perhaps isn't many. On the other hand, "most of the population of the world" clearly is many people. I don't think you can define "many" in terms of percentage of sample size.
Using an editor that has decent tab/space support really makes or breaks Python development. It's horrible to develop in something like vim, then switch to notepad for a quick change, only to realize there is no such thing as "Press tab for 4/8 spaces" in there.
&gt; But that iterates the loop twice, yeah? No. What happens is that for each inner iteration, an (i,j) tuple is made inside the generator and yielded to the outer loop, which unpacks it to the outer scope's i and j. Essentially, the code I wrote translates as follows: def _anon_genexp(): for i in xrange(10): for j in xrange(20): if j&gt;10: yield (i, j) for i, j in _anon_genexp(): result.append(i*j) So, no, it does not "iterate the loop twice", it just adds some extra assignment overhead to each iteration.
 &gt;&gt;&gt; def f(): for x in [1,2,3]: print x; else: print "Done"; &gt;&gt;&gt; def g(): for x in [1,2,3]: print x; print "Done"; &gt;&gt;&gt; import dis &gt;&gt;&gt; dis.dis(f) 2 0 SETUP_LOOP 33 (to 36) 3 LOAD_CONST 1 (1) 6 LOAD_CONST 2 (2) 9 LOAD_CONST 3 (3) 12 BUILD_LIST 3 15 GET_ITER &gt;&gt; 16 FOR_ITER 11 (to 30) 19 STORE_FAST 0 (x) 3 22 LOAD_FAST 0 (x) 25 PRINT_ITEM 26 PRINT_NEWLINE 27 JUMP_ABSOLUTE 16 &gt;&gt; 30 POP_BLOCK 5 31 LOAD_CONST 4 ('Done') 34 PRINT_ITEM 35 PRINT_NEWLINE &gt;&gt; 36 LOAD_CONST 0 (None) 39 RETURN_VALUE &gt;&gt;&gt; dis.dis(g) 2 0 SETUP_LOOP 28 (to 31) 3 LOAD_CONST 1 (1) 6 LOAD_CONST 2 (2) 9 LOAD_CONST 3 (3) 12 BUILD_LIST 3 15 GET_ITER &gt;&gt; 16 FOR_ITER 11 (to 30) 19 STORE_FAST 0 (x) 3 22 LOAD_FAST 0 (x) 25 PRINT_ITEM 26 PRINT_NEWLINE 27 JUMP_ABSOLUTE 16 &gt;&gt; 30 POP_BLOCK 4 &gt;&gt; 31 LOAD_CONST 4 ('Done') 34 PRINT_ITEM 35 PRINT_NEWLINE 36 LOAD_CONST 0 (None) 39 RETURN_VALUE 
Python 3 and bumpy support are their current priorities, but yes it's not really ready for primetime yet. Numpy is one of my most used libs so I'm still waiting for Pypy to be usable
Sweeet... time to parenthesized my loops.
I still think it's criminal (Okay, maybe not criminal, but at least naughty!) that tabs aren't just treated as another layer of indentation. Logically, that's what the user wants, so why not? On the other issue, copying and pasting code from web sites is a major pain, you nearly always lose indents. Know what Python code without indents is called? "Time for a re-write".
Biopython is great, there are some up and coming ones too like Trappist. I look forward to the scipy conference to see what else is new.
For sprite rendering, I'd go with either [rabbyt](http://arcticpaint.com/projects/rabbyt/) or [pyglet](http://www.pyglet.org/). Both libraries are hardware-accelerated via OpenGL, so they should easily be able to handle your requirements. For math, I'd say Numpy is the way to go, like you said. Now with networking, things are a lot less clear. You see a lot of suggestions for Twisted for things like this, but it's my opinion that higher-level libraries like [legume](http://code.google.com/p/legume/) are better for game development.
Ooooh, I'd never considered using a dictionary with functions - thanks!
Far above my experience level, but thanks for the contribution!
Wow, that's great to hear. :)
Thanks for an interesting and informative reply! I spent a while trying to implement graph visualisation during my final year computing project at Uni - in the end I decided it was more trouble than it would be worth! I had a feeling that performance would be an issue, though thankfully my own tinkering with the language has been amateur, and of low enough intensity that speed has never been an issue. Could you recommend a more efficient language that I could try branching out into? I've heard that C (or a variant thereof) should be in every programmer's toolbox, but I've never taken the plunge...
I always do this with either Mechanize, Selenium, or just used the post function in wget
map + various builtins can be fun: Sum of the lengths of all elements in a collection: sum(map(len, iterable))) Sum of all values in a new line separated file: with open(file_name) as f: sum(map(int, f)) Write the intersection of two files of floats to a file to stdout: with open(file1) as f1, open(file2) as f2: intersection = set(map(float, f1)) | set(map(float, f2)) consume(map(print, intersection)) Where consume is something like: import collections def consume(iterable): collections.deque(iterable, maxlen=0) That brings me to one annoying thing: consume is not a builtin or itertools class. It is, however, listed as an itertools recipe.
rabbyt offers collision detection out-of-the-box, while you have to code your own collision detection with pyglet. Depending on how complex/exact you want collision detection to be, that might not be an issue. Other than that, the only two real differences (code-wise, the libraries are almost identical for the most part) are 1) rabbyt is typically used together with PyGame, whereas pyglet is a standalone, pure Python library, and 2) since pyglet is pure Python, your users need nothing other than Python to run your application, whereas rabbyt is a mix of C and Python and must be compiled. All things considered, I'd go with pyglet unless I saw statistics indicating that its pure Python nature was too slow for your application. 
[wxPython](http://wxpython.org/) is worth checking. I find that [XRC](http://wiki.wxpython.org/XRCTutorial) and sizer based designs work really well for me. I haven't found any compelling reasons to move to [PySide](http://www.pyside.org/) but I'm sure it works just as well for building GUIs!
Well, I listened to a podcast about EVE lately, and it's built using Python. It uses a version of stackless python, of course. I'm familiar with Qt, and there are a number of GUI tools for building your interfaces. Depending on the complexity and requirements of your game, Python has a few game frameworks that might help. Not my area of experience, but it doesn't seem a poor choice.
yep - no doubt this gets debated ad nauseum in the python community, but as an occasional dabbler in python I'm amazed at how sluggish the shift to 3.x is. Very frustrating. I understand the one-f*ing-little-library-means-I-can't-go-3.x effect - but are there no tools to at least semi-automate conversion?
I think the main reason for PySide is the licensing. It's almost a drop in replacement for PyQt, except for signaling, lambdas and class constructors. (It's an extremely minor change, IIRC.) I looked it up anyway: http://qt-project.org/wiki/Differences_Between_PySide_and_PyQt But I am thoroughly guilty of using PyQt with PySide's docs. PyQt works extremely well with PyInstaller right out of the box. Almost no fiddling required to make real cross platform 'executable' files. The boilerplate is shitty, but a few scripts and bats solve that easily.
Nothing. Loop-`else` without `break` is pointless. There was talk about making it an error at one point, but it seemed like a waste of time.
Does this help? http://bazaar.launchpad.net/~robey/paramiko/trunk/annotate/head%3A/demos/forward.py
They refer to another article that uses selenium at the end of this blog post, but it's worth making this explicit here (since I struggled with it for a while): mechanize and request are _not_ good if you need to interact with javascript on the website. The best bet I've found there has been Selenium, although it's not nearly as elegant with the browser window popping up.
Sorry to hear about the project, but I think it's pretty normal and nothing to worry about. If a project is becoming too big, it can't be done alone in sparetime. Also, usually you have to do it twice anyway unless you're really experienced. Just skimmed over the cute_iter_tools module ... I wonder why you've implemented your own product() method instead of using the one in itertools? Also, normally I just would use len(list(iter)) instead of a function get_length() that iterates over the iterator in the background. Well, memory could be an issue, but I guess then I wouldn't feel comfortable with the fact that I need to know the length of an iterator.
You are being irrationally defensive. Python's main interpreters are frequently "fast enough" for the tasks put to it. But relative to most other popular languages, it is generally slower. If this does not interfere with your particular use case then more power to you. But that does not change the measurable fact that most Python interpreters are slower than e.g. C#, Java or even JavaScript runtimes. In a thread on Python's weaknesses, this is an obvious one.
That's why I only use spaces for indentation. I press tab in my editor and it writes 2 spaces.
I'm a little confused about the second point. It makes sense for a comprehension to end in `if j &gt; 0`, since this is just constraining the things being generated. But what would awesome = 5 if sauce &gt; 10 mean? Comprehension is about generating things, and assignment is about labeling things. It makes sense to say "give me a list of all the numbers greater than 20 and less than 10", since that's just an empty list, but what is going to be labeled `awesome` if `sauce &lt;= 10`?
Ah, that's a good point. If statement in comprehension acts as filter for things guaranteed to exist. When doing awesome = 5 if sauce &gt; 10 that variable may or may not exist yet. I previously thought "well... Python should create awesome variable and assign None if sauce &lt;= 10" but that, albeit convenient, opens a different can of worms. 
&gt; fact that most Python interpreters **without JIT** are slower than runtimes **with JIT**. FTFY
OK, here is the trick: In `if` clauses, `else:` behaves like **else**. In all other cases (`for`, `while` and `try` clauses), it behaves more like a **then**.
There are a variety of packagers; some of them make a complete stand-alone, while others end up requiring you to also supply PythonXX.dll (where XX is a version number). If your audience has the necessary technical savvy, you can distribute source, or even .pyc files.
&gt;But I cannot do this (not finding it in itertools): first(user for user in users if user['email'] == 'bro@gmail.com') You can, actually, and you don't even need itertools. It's just that, perhaps confusingly, it's called `next`. The `next` item that you get out of an iterator, in the situation where you haven't previously gotten anything out, is the first. Getting the last element is a whole other kettle of fish, and you need to loop manually (you can't index into a generator) unless you want to build a list (which temporarily takes up a lot of memory). There's no getting around evaluating every element of `users`, though. But on the plus side, you can wrap that loop into a function in call it `last`. :)
But you *very rarely* actually have to do that. Almost all of the time the JavaScript on the page simply leads to loading a URL, so pop open the Net tab of Firebug and see what that URL is, and you can scrape the site without having to mess with any JS whatsoever. 
Even if that were true, it would not negate my point. The most popular implementations of python (by a long shot) are cpython 2 and cpython 3. Just for accuracy's sake, I'll mention that AFAIK Jython is still slower than cpython and jruby despite being JITted. Iron python is also no speed demon. So why dance around the truth: most Python interpreters are slow relative to most popular languages, but PyPy is much better.
thanks, captain obvious. what i wanted to say with it is that ckaili’s dictionary switch is exactly the same kind of dirty hack like the one that was used before the trinary existed (this designated hack which i demonstrated above) that means that if we can learn from the past, a switch syntax should be introduced, sice it adds the exactly same amount of clarity and DRYness to the code that the trinary did.
&gt; Loop-else without break is pointless. You'd be surprised! for i in (): print i else: print 'else' (also see my reply to nedbatchelder)
That prints 'else' the same as it would if you had deindented it. Pointless. 
Hm, OK, you are right.
Thank you! I needed a good Python based OCR engine. I've been thinking of automating the process of digitizing receipts, it'll save me so much time. Now all I have to do is try to build a sorting and scanning machine of some sort. Does anyone know how I might go about it? I was thinking of buying a cheap scanner and maybe re-purposing it for the process. I just don't know how I should go about automatically sorting through thousands of paper receipts.
Nice. I attempted to train Tesseract a few weeks ago but the process is quite overwhelming. Will be giving this a go.
That sounds fantastic! I was wondering what IDE to use. Do you happen to know if it works with both Python and Ruby? I've been told Ruby is a bit more user-friendly than Python.
Honestly, it's better that these features exist. Inexperienced programmers will always use things wrong. That's never a reason to not have these powerful features. All we can do is try to discourage their abuse.
Python isn't a high-performance language. It's not intended to be used for tasks that might need something like massive parallelism with lots of memory sharing. The GIL is an optimization to make single-threaded code run faster, nothing more.
&gt; I've been told Ruby is a bit more user-friendly than Python. Hahahaha.... no. Ruby lends itself to "DSLs" better than Python. That is, you can use it in a way that makes your code look more like a purpose-built configuration file. For actual programming, however, Python tends to be more readable because readability is the focus of both the language development and the common coding style. Ruby is about fun for the author (and let's you express yourself), Python is about painlessness for the reader (and "fits in your head"). Neither is "better", they just achieve very different results.
Is it going to be open source? If so, I might want to help you, I love these sorts of games.
So is jerky behavior more common among men? It seems to me that a female jerk would have had the same effect on the class.
Did u get laid tho?
Define "with Python." The trivial answer is no, of course you can't, because Python doesn't give you direct access to things like memory, registers, IO ports, etc. and it's impossible to implement a kernel without that. It might be possible to implement the bulk of the low level stuff in C and expose it as modules as is already done for large parts of the Python standard library. And it would almost certainly be possible to embed a Python interpreter in an existing kernel, allowing to e.g. write a scheduler or filesystem in Python. But I don't really think that's what the question is referring to. 
Well, Python has to run in an interpreter, which has to be in machine code. On the desktop, you are probably running CPython as your interpreter, which is implemented in C, so that would be cheating. PyPy can compile Python into machine code, so it should be theoretically feasable to use this as your interpreter (actually a compiler, not an interpreter). Initializing all the hardware will require some pointer arithmetic and bit fiddling though, which is not exactly Pythons forté, what with it having no pointers and such. That said, actual modern OSes do require a kind of performance that is hard to achieve in Python, even with PyPy. A toy project should be possible though. In the end, coding an OS in Python might be technically possible, but Python (or any so called 'scripting language') is certainly the wrong tool for the job.
Is inline C and thus linline asm not valid c and then calid python?
You could make something like andriod, having a linux kernel and a python vm to run ontop of the linux kernel and code everything else in python. 
Eclipse would run on a system like this, but not very smoothly, that's a sure thing. Topic: I'll give the IDE a try, although I missed a little bit of explanation (or sound in general) in the video. Do you know, whether there is a version for Linux available, too? (:
I've made a benchmark set available through http://dalkescientific.com/writings/diary/archive/2012/06/10/inverted_index_library.html . It's 1/200th of my complete data set, and 7zip compressed takes 37 MB. The data files contain fields I don't use for the benchmark, so should really be smaller than that. This suggests that it is possible to put the entire dataset into under 8GB of memory, so long as I didn't care about performance. For reference, my small benchmark takes 2 GB of space when stored in sets, and 166MB using array.arrays. I knew that neither the set nor array versions would work. It's very easy to show that the numbers I described (100 features/record * 35 million records * 4 bytes/record = 14 GB) require more memory than the 12 GB of RAM I have. (As it happens, there's 300-400 features per record in the benchmark I assembled; my memory of '100' was a bit off. I would need about 42 GB of RAM to use pje's approach.) For this to work on my desktop requires compression, of the sort that's well-described in the literature and available in several different existing C++ packages which I described in my intro. This should be bog standard, and nothing to do with "God's gift to the programming world." My goal was to find if someone else has already done this work, or has experience with any of the tools I listed, or a similar one. Otherwise 1) I'll have the boring job of writing bindings myself - I'm not even getting paid for this work, and 2) I can't tell which is appropriate for what I'm doing so I'll probably end up implementing a couple of bindings. Which I've already tried, and failed to date, because now I'm at the point where I'm trying to figure out Cython in order to implement bindings to C++ libraries in an application domain where I have little experience, in order to do the actual research I want to do on sparse fragment cheminformatics fingerprints. 
So you know, the initial load time is about 30 second per file, which is somewhat slow but it's a one-off event. The search time is about 5-10x slower than using Python sets, but it's acceptable. I'm now looking for any tuning options, since I'm fine with letting it use more than 80MB of memory if I can get it to go faster.
Technically a desktop environment rather than a full OS but still one to throw into the conversation: Sugar, as used in the One Laptop Per Child project: http://en.wikipedia.org/wiki/Sugar_(desktop_environment)
It would require more than just a simple port to c code. The innards of a kernel and it's modules and drivers deal with bare metal devices and the interaction at that level is far removed from what python gives a user. That said some of the high level functions could be implemented but at that point it's not worth running an os at that level. Of course if someone exposed a model of the hardware to python then someone could potentially write a virtual operating system that would only run on that virtual machine. Completely impractical and only worth doing as a science experiment.
I don't have the money for a new machine. (Also, things are more expensive here in Sweden.) What I really need to do is find a company which is interested in funding me for this. The admittedly poor marketing I've done for the idea hasn't panned out. My thought is to get a working demo to present at a conference a year from now. Thanks for pointing out other things I should evaluate. I'm not sure that adding to the list is a good thing or a bad thing. ;)
I've only recently had to get into packaging, but to be honest I've found Python's setup quite convenient. Creating a single setup.py takes you most of the way towards packaging for most mainstream Linux distributions, and even allows you to create an MSI for Windows (and similar for Mac, though I haven't tried that). Out of curiosity, what is the problem with packaging in Python, in your opinion?
The talks themselves are interesting but the presentation is absolutely terrible. They should put some work into getting practice talking infront of a large crowd.
he likes it but doesn't know how to fit well with the language
I don't see women behaving like this outside of software, either.
Are you using iTerm 2? If so, see [this](http://stackoverflow.com/questions/9355089/iterm2-printing-out-a-null-character) Stack Overflow thread.
this might help: http://plumbum.readthedocs.org/en/latest/api/remote_machine.html#plumbum.remote_machine.SshMachine.tunnel
Yeah, some of our servers still run 2.5... it's a little sad, though.
That was it. Thank you very much!
Also learnt that keyloggers are 5 lines long in python so be careful.
They're mainly derping pretty hard but still I appreciate it. They are good at what they are doing. I don't really expect them to be good public speakers or presenters.
The trouble is that sites that have snippets like stackoverflow typically have shitty search... so just google, and if needed add the site:example.com param to limit it to a certain site. 
Not to mention ++ could be ambiguous, what if it's a string, what if it's an object, etc etc... it would make it really hard to figure out exactly what was getting incremented. 
How does this differ from python's bindings for [gpgme](http://www.gnupg.org/related_software/gpgme/), if at all? Note: I'm presuming Python has bindings for gpgme....
I'd just like to point out that preventing simple param='; drop table students; -- stuff is just the tip of the iceberg, and people should generally NOT write their own sql protection functions... use something that's been vetted. 
It would have made sense to import the `finally:` from `try/except` instead of `else:` from an `if` statement. They missed a golden opportunity to change this for Python 3. EDIT: Except apparently finally will execute no matter what which isn't what we want. Hmm, I guess `done:` would be the only way then.
Thanks, I'll check it out.
This is almost entirely written in c, not python. The python that is included is trivial at best.
Until today, I thought the title told me to NOT use a cryptographic signing module because it's dangerous.
[There is a good discussion.](http://news.ycombinator.com/item?id=4090710)
It's pure Python, runs on all platforms Python runs on.
Are you on a 64bit platform?
Out of curiosity, how are other "scripting" languages dealing with concurrency?
Man, I'm so sketched out about using my own scripts in Diablo, does anyone know the chances of being banned or whatever for this?
FYI Jython is quite a bit slower than CPython. 4x refers to PyPy-no-jit-no-stm vs PyPy-no-jit-but-stm, so it's a bit irrelevant to compare with CPython or Jython at all.
people who really want ++ could just have it as an editor macro that expands to += 1 
the name argon is really confusing...how about commandArgs?
I think adding an external dependency to your program so you can download a file, when this is one of the things that urllib2 does just fine, is overkill. Requests may well be a better choice for a program that has to interact with the web, but for something as simple as downloading a file I think the stdlib works just fine.
i like my GIL. if you don't, either don't use python or wrap some swig code. it's possible to get around the GIL, but doing it in pure Python will just slow down your code.
Use sets: BAD_DIGITS = frozenset('024685') SPECIAL_VALUES = '2', '5' def other_rotations(string): return set(string[i:]+string[:i] for i in xrange(1,len(string))) def circulars(numbers): circs = set() strings = set(str(n) for n in numbers) for s in SPECIAL_VALUES: if s in strings: strings.remove(s) circs.add(int(s)) while strings: s = strings.pop() if frozenset(s) &amp; BAD_DIGITS: continue rots = other_rotations(s) if rots.issubset(strings) or (s in rots): strings.difference_update(rots) for r in rots: circs.add(int(r)) circs.add(int(s)) return circs clt1M = circulars(primes_lt(1000000)) print len(clt1M), sorted(clt1M) 
Seems fairly simple to change it to use a different hashing algorithm such as SHA256. It's a single line of code.
This isn't related to the game nor does it interact with the game in any way so there is no chance Blizzard will care
This post is nearly a year old. A lot has changed in the last year. The most important bit in this post is go test it for yourself on your program.
Hm. When I hear "signature", I usually think of a signature in a public-key system. I'm not used to hearing MACs called "signatures." Is this a weird use of the term "signature", or am I just wrong there?
I don't think that the "len" problem is a matter of naming or parentheses, as you do. I think the author considers is a *design* flaw. Personally I'm on the fence; I would have agreed with the author on that count a year ago but now I'm not sure.
I'd like to apologise if you found my comment offensive, I was more trying to offer some constructive criticism. I really do appreciate the work that's been done on Pypy, keep up the great job!
This article goes the whole way through calling `__new__` a static method when it is a class method that is special-cased for you. And to toggle IPython's output, type "`%doctest_mode`". The line numbers are a distraction when reading snippets since they have no meaning from one snippet to the next.
I smell a bit-flip ...
Sorry for hijacking this thread but, why are there so many [mocking libs](http://wiki.python.org/moin/PythonTestingToolsTaxonomy#Mock_Testing_Tools) out there? May I ask the wisdom of the crowd which one to select once and for all?
No offense taken, thanks!
Just use **mock** since it will be a _de facto_ standard from 3.3 (it is now included in the standard lib). PS it is also a great mocking library, with a nice doc and a nice dev!!!
Very misleading without looking at docs.
No. They ca be frightening if you are somewhat new to Python (they were when I was), but once you have declared 3 or 4 \_\_init\_\_ you will love it.
Wouldn't it be `dispatch[raw_input()]()` since `input()` uses `eval` on the given input while `raw_input()` returns a string?
There's no way you're getting the entire standard library into one cheatsheet wallpaper. Not unless your monitor is 3m wide. ;-) One of the bits I always have to look up is string formatting - both the `%s` kind and the `{}` kind. It doesn't need every format code, but a few well chosen examples would be really handy. E.g. `"{:.2%}"` - number as percentage, 2 decimal places. Showing `enumerate` might mean less people do `for i in range(len(x))`. And list comprehensions/generator expressions would be good. I'd skirt round the differences between Python 2 &amp; 3. If you're interested enough to get a cheatsheet, you probably already know `print` and `input()` anyway.
I wouldn't say I'd love it, I'm more apathetic to it. Just sort of a thing you deal with in some methods in Python.
I did some tests: $ python -m timeit -n 100 -r 5 -s 'import itertools' 'for i in itertools.repeat(1, 1000): pass' 100 loops, best of 5: 17.4 usec per loop $ python -m timeit -n 100 -r 5 'for i in xrange(1000): pass' 100 loops, best of 5: 26.6 usec per loop $ python -m timeit -n 100 -r 5 'for i in range(1000): pass' 100 loops, best of 5: 34.3 usec per loop The tests reflect your statement. In support of your comment, I also found that the difference when iterating over small sets (I tested &lt;100 items in this case) is trivial, with only a one to two second's difference and no obvious correlation between the three methods. Please tell me if there's a flaw in my testing because I am not very clever and I just woke up.
How is it a design flaw if the only actual usage change is a set of parens? I mean this just seems like grasping at straws. It would be _a little_ more consistent with the entire OOP thing if it were a property (not that python forces you to use OOP), but in daily use I don't notice it and I suspect most people don't.
A single underscore would have done that too.
Single underscored methods are protected, not private.
To answer your question in a data-driven way, and as an excuse to write some Python, you could code up something that analyzes a corpus of Python programs and produces a frequency-sorted list of modules imported, methods used, etc., then go through that list by hand and choose things that are commonly used but seem to require frequent documentation consultations.
why would you need something like that when ipython, bpython and your favorite editor/IDE already has doc navigation built-in?
what exactly has changed? I would not mind writing a 2012 version if enough has changed to warrant that.
Single on both sides `_this_` would work just fine, while `_this` would be "private." Even so, as the private status is only convention, do we care if we call it private/protected? If we do care, I would think that the first is correct as protected implies that something is being done to keep the name safe (as in `__this` (name mangling)). To be sure, I've no issues with double underscore surrounds, I just wish we had a better way to say it. I feel retarded everytime I say "dunder init."
Whilst perhaps a good excercise in basic Python programming, I don't think there is ever a time that someone would want to use this script. `rsync` provides a far better alternative. This script also has a lot of opportunities to break. For example, a user's home directory does not have to be at `/home/user`; you should be using `os.path.expanduser("~")`. Is there a reason that you build `results` instead of just printing things as they are done? You also shouldn't rely on the system providing `cp`, use `shutils.copytree()` instead. On a stylistic note, you shouldn't really be importing things midway through your code.
It's taken directly from Django's source code, which uses it for cookie signing. I can't comment on its current form.
those look really lame (Drupal cheatsheet? the fuck?) having said that I admit the [vim cheatsheet](http://www.viemu.com/a_vi_vim_graphical_cheat_sheet_tutorial.html) really helped back then
What I'm saying is that the only protection provided by Python is to attrib/method names prefixed by two underscores. These names are mangled so that children classes cannot override them (as I understand it). The rest is just unenforced Python convention. Nothing stops me from calling a single underscore prefixed variable, as Java would with private marked methods and members. Only convention tells me that attribs marked as such shouldn't be considered a part of the API (similar to your "viewing internals" mindset). In the larger sense of OOP, yes, it is important to make distinctions between protected and private, but as Python doesn't enforce these distinctions, I think that it's less important. A variable or method is private if it has any underscores prefixing it, and I shouldn't call it explicitly from outside of the class (and minimally inside, ideally). If one were to make a distinction in Python, I would suggest that only double underscore prefixed names are "protected" in that Python actively protects them (doesn't include double underscore surrounded names as these can obviously be overridden). protected (by Python) = `__this_gets_mangled` private (by convention) = `__init__`, `_private_func`, etc
I see your point. But many people understand the name mangling not as a "soft security enforcement", but as a feature: while inheriting a class and overrriding a private method (say, \_\_dosomething() ), you can still (thanks to name mangling) call the parent's private method from your (son) object (with obj.\_\_ParentClass\_\_dosomething(), or something like that). I personally feel that if you need to do that, you are doing something wrong. About active protection: I personally neither like Python's (passive) approach nor dislike it. But I see many people dislike it.
But JavaScript is. Right?
That's pretty much the same testing I did.
I don't think the wallpaper thing is too useful, but a pdf that was like 5 pages long would be fantastic. First page could be just an overview, and the rest could be more in depth review.
What would you prefer?
I rarely program in python, but when I do it is always for file related things. Stuff like reading and writing to files or going in a directory or something like that.
And freeciv gets boring, the AI only wants war and it's not a very fun War Game. Do you know Hearts of Iron?
How about Lua? One interpreter per core? and what about V8 javascript? 
Title is wrong (I think?) they didn't program an FPGA to run Python Bytecode, they programmed a compiler to take Python syntax and compile it to VHDL or Veralog which could then be passed to an FPGA.
The Hack-A-Day article was a bit awkward in explaining the cool new thing. [MyHDL](http://www.myhdl.org/doku.php) is not that new, I remember toying around with it a couple of years ago. What is new here is the first link which goes to [PyCPU](http://pycpu.wordpress.com/) which is a CPU that executes a limited subset of Python bytecodes directly on an FPGA. PyCPU design was done using MyHDL.
I have used `Fabric` for small projects, it is easy get things done with fabric, but `salt` needs extra configuration when compared to fabric, for larger systems `salt` is the choice. 
The two have little to do with each other. Fabric is an orchestration tool, it excels at coordinating commands on multiple machines. Salt is a configuration management tool, it handles things like installing packages, config files, etc. Yes, libraries exist to make Fabric do these things, and similarly you can fit a square peg in to a round hole if you just bash it hard enough. As for Salt itself, I would say use Chef, the Python support is far better (disclaimer: I wrote much of it).
Wow. A lot of work went in to that. Not sure I see point though. If the author is listening, maybe he can expand on a use-case?
I just keep all the files in a folder, and then when I need to reference it I know where it is and can pull it up.
&gt;I've been told Ruby is a bit more user-friendly than Python. Whoever told you that was lying.
Is there any reason not to contribute them directly to Mock?
The new site should: "Boast a modern design and experience" This is the first point. No. Why? The python web site actually works. It may look dated, but it works well. You really want to screw that up for the sake of "design"?
I imagine that point is first because a new look is the main *change* they're looking for. It's natural to put that before the "and don't break stuff" points.
I'm not so sure on this; I handed Salt over to a junior admin and got results within hours. It tends to scale stupidly well, whereas Fabric tends to struggle past a certain point.
For most professional deployments with more than one machine, you are going to want Salt. It was built for the purpose of performing remote execution and managing your hosts in a sane way. Remote execution can include your deployment, ie: pushing your app's tarball or pulling a git repo. On top of that, you can use a state tree for config management. I use this extensively for deploying Django and other servers. For example, if you are spinning up a new VM you can bootstrap your nginx, redis, celery, write to all your configuration files while using the templating engine of your choice. It is incredibly flexible and much faster than what you can do over SSH using Fabric. You should use Fabric if you want an opinionated way to run SSH commands over less than a dozen hosts. It is probably the lowest barrier to entry to run a set of scripts on a few different machines. It is not nearly as flexible with regard to targeting the hosts you want to run commands on, and no real assurance that the machine you are bootstrapping is in the state you want it in.
not familiar with it, i'll google it when i get home from work :)
Now that I got rich selling this, I do not need money any more. This is the 4th edition which was made available one year ago. There are some typos. We are in the process of fixing the typos and we will release a new version with web2py 2.0 coming out soon. I sincerely thank all those who have purchased the PDF (despite always being available for free in html) for their contribution to the project.
Only the 3rd time this link has been posted!
You critically failed your humour check and take 3 damage.
[Python QuickRef](http://rgruet.free.fr/) 
Also, Guido's old article about ["new-style" classes](http://www.python.org/download/releases/2.2.3/descrintro/) is still informative. 
i rather they work on the layout of the documentation and how it is structured, its god awful. Searching for String methods (str) gives you the str module, and you have to find the magical link buried in it to get to the actual string methods. Trying to find the methods that work on lists and dicts and all that are harder then they should be, etc etc
what a crock article. suggesting that oop and tdd are essential is rubbish.
If memory is a concern, then sum(1 for item in iter) is another possibility. On Python 2.7, len(list(xrange(1000000)) takes 30 msec per iteration while sum(..) takes 122 msec. On the other hand, with PyPy 1.9 those timings are 196 msec and 13.9 msec, respectively.
You a good coder?
The link is taking a multi-threaded approach? :) ...ducks...
Yeah, I can't think of a great use case for this. It seems to me like just about all of the data types can pretty much be emulated in regular old JSON.
&gt;Now that I got rich selling this I lost right there
Putting the markmin source of the book on github would be *awesome*.
I'm pretty sure that the developer of CFEngine created puppet to address some of the limitations he ran into with CFEngine.
TIL mixed case is frowned upon in PEP 8. I've been using it since 1992.
Started using salt stack. Its working great ! Thanks everyone
Sorry, I didn't mean the Python site. I just meant that a lot of sites to do with science, engineering and computer science are renowned for being needlessly complicated, dated and difficult to navigate. It's kind of funny you mention it though, because the pre-2006 Python site design is actually in many ways *better* than the current one!
Thx for the answer. héhé, it was in fact an db error while registering the serial on battle.net. Problem is now resolved :) Thx. Ps : https://github.com/khertan/KhtBMA a Simple UI for python-bna for Nokia n9 and n950.
Everyone's recommending twisted for networking. I'm going to go against that, and suggest using gevent. It offers fantastic performance with a far less intrusive interface. You'll spend more time doing what you want and less time figuring out the framework, but you'll get the same asyncronous performance benefits. 
What do you think is essential then?
When can we expect to see a release of Web2py 2.0 and what goodies will it contain?
For larger projects it's easy to point to PEP-8 and say "follow this". It may not have been made with the intention of being a code style guide for every Python project but I tend to think the more projects that use it-- the better. Although, it's not comprehensive so for true code consistency you might have to supplement your own code style guide. I used to be a tabs-only coder as well but after contributing to a few projects that had PEP-8 rules I was broken and now prefer spaces. It's all invisible to me when using a good .vimrc anyway.
flake8 gives you pyflakes, pep8 and mccabe
My last python project got entirely out of hand. My next (and all future projects) will have pylint (or equiv) be part of a git commit hook. Its not terrible if there is only one developer, but once there were multiple developers on the project you can have compounding bad style. It isn't irrecoverable, but takes a chunk of time to fix/refactor when other people expect features to be added.
Thanks for providing a free manual.
Mark Burgess created Cfengine. He still drives development and its road map today. Puppet was created by someone else but, it was inspired by Cfengine.
What is different between pymark.module and pymark.struct?
I'm looking forward to 2.0. Web2py has come a long way.
i find `get_all_attr_names` to be the most readable. the camelCase one looks just unsteady and my brain needs only insignificantly longer to parse `allattrnames`, while the underscore variant is read as fast as normal text with spaces.
Sorry for the dupe: I should know better than to simply rely on reddit's dupe-checker for something hot like this. FTR, though, I blame the people who post the same content to multiple different URLs; just give me a redirect to the canonical source, already.
The online book is editable so typos are been fixed there. Periodically we will generate an updated pdf. 
I really like using pylint, customizing it, etc. But I'm pretty bummed about how it gets confused with meta programming stuff - using locals() for string substition may get it to think you aren't referencing a variable, etc.
the manual does not show the explicit negation operator here - http://screencast.com/t/iveFhDAC42B
Orange text on #1d1d1d is fucking sublime and I wished more people knew that sweet, sweet combo.
This exactly this. Metaclasses are perfectly acceptable. Provided they are heavily documented internally to developers needing to be aware of their features. For example, metaclasses make creating beautiful API's a cinch (see: Django) and having this work completely negated by some pedantic style checker is annoying. PyLint is really good for straight up code which doesn't use advanced features, kwarg 'magic' and cross-module decoration. PyFlakes is pretty awesome at mimicking a slightly 'static'-y compile phase but misses out on somethings that PyLint does and the pep8 checker is somewhere in between. Also, Django-lint is available for those who want to check the Django-nicity of their Django projects. It's got some interesting style choices but I find they make sense enough to adhere to.
That looks good, I'll add that to my list.
I really liked Learning Python to actually.... learn Python. 4th Edition is best edition. If you already know Python and want to focus on a framework, get the highest amazon rated book on that framework. I really like Doug Hellman's *Python's Standard Library By Example* simply because it quite literally is the only thing I've ever needed to find out what the stdlib contains and how to use said modules.
Excellent, I'll add those to my list of books to consider.
JVM startup is much more intense than pypy's startup, but I never meant to imply Jython was fast. From what I understand, a lot of the slowdown is caused by all the locking to simulate Python's atomicity guarantees w/out introducing a GIL.
It's not a physical book but I just finished..at least got to the end of.. Zed Shaw's eBook/Udemy course "Learn Python the Hard way" http://www.udemy.com/learn-python-the-hard-way/ It was a good way to get me off the ground when I had 0 Python experience before I got going. 
Sorry, didn't get the joke )))
+1 for *The Python Standard Library by Example*
Yeah, it's just *that* good. Most (all?) is available online as it was a weekly column he wrote (Python Module Of The Week) but having a dead tree to-hand reference is great. Also, it's fun to thumb through it and find out about a neat module I never knew existed.
I'll find your email and send a mobi file to you. But I actually think the markmin source on github would be extraordinarily cool. Would also show of markmin :-) Edit: I have sent you a message via reddit mail :-) 
Not quite what I was looking for but thank you :)
What's better IMHO is unit tests, linters catch code written for humans which is fine and dandy and you can run those linters at will and berate people for being non-conformist pigdawgs. I say unit-tests because you can have server-side hooks for your git repos and fire off the test suite server side and send a "u dun borked the build" e-mails to the offender. This is what I use at work: Git repo which is shared access with commit rights for all devs, then some of my own commit hooks which aren't shared across others then a small script which fires off the Python test suite whenever there's a commit. This way, it doesn't stop people from committing but there's at least some way of knowing that a commit broke and more importantly *which* commit broked a build. Git really is such an awesome tool when it comes to stuff like this.
I'll check it out, cheers :)
Lutz's work is lengthy, but of the highest quality. It manaces with spikes of Python. I'd suggest *Programming Python* in addition to a +1 for his *Learning Python*.
I decided to investigate. Lisp, Dylan, CSS, and XSLT allow hyphens in names, and seem to prefer them. Hyphens are not allowed in identifiers for C, C++, [any] Perl, PHP, Java, Javascript, ActionScript, Python, Lua, etc. The reasoning seems to be the prevalence of infix operators. There's no way for these languages to know if `first-name` is a variable or a subtraction operation between two variables. Lisp gets away with it due to its prefix notation. CSS and XSLT - I think - don't support subtraction operations. Dylan started out scheme-like, then transitioned later to a more algol structure. It *seems* (I couldn't seem to pin it down, though) that operators in Dylan need spaces around them, so `first-name` would be a variable, and `first - name` would be an operation.
I am a python 2 guy, but I see no reason why not to use 3 instead. It's bound to make python 2 be obsolete at some point, anyways.
I find the [Python Essential Reference](http://www.amazon.com/Python-Essential-Reference-4th-Edition/dp/0672329786) extremely useful.
Depending on what you're looking for, the Visual Python module will probably do the job. It is used a lot for physics demos in education. It comes with tons of examples and the documentation is pretty good. Link: http://vpython.org/ 
I really liked Dive into Python. Also Learn Python the Hard way is quite good.
2.
Cool technique! I didn't know it was that easy to access python internals from gdb. A similar technique should be able to output a python stack trace from a core dump, eg if your python program calls C/C++ which then crashes. I wonder how much of this would work with a regular production (non-debug) version of python. 
Anyone using Erlang for anything neat? I've been really interested in picking it up lately but not totally sure I want to add it to my toolbox yet.
all languages should be taught using python as their pseudo code.
Count your blessings my friend. You don't get to choose the language you use everywhere.
Ericsson invented it specifically to do massively concurrent and distributed real-world tasks like running phone switches, and it is used extensively for this. Similarly, a lot of chat servers are implemented in Erlang, most notably Facebook's Chat system, based on ejabberd. A lot of database systems are written in, or using Erlang, as well: CouchDB, Couchbase, Riak and Amazon's SimpleDB. There are some more examples [here](http://en.wikipedia.org/wiki/Erlang_\(programming_language\)#Projects_using_Erlang) and [here](http://www.erlang.org/faq/introduction.html). Basically, Erlang does one thing Python kinda blows at really, really well. I think the only language that comes close in ease-of-concurrency/parallelization is Go.
it's ok for a newbie to go for java or c++, if he's interested it can't be bad taking a look at it at least ... as for the future of python, well apparently it's the future, i live in the present so i'd go for 2 since more libraries are available, the changes from 2 to 3 aren't that huge and at the end he'll be able to say "i know python (2 and 3)" 
Actually, I signed on this morning to remedy that. I erroneously said 3rd when I actually meant 4th. Thanks!
Ahh! I forgot about CSS, I actually use it quite a lot with CSS.
Python 3 is buggy? How so? Can you mention some specifics? In the contrary, I'd think that 2.x is full of bugs (or surprising behavior): * str is not a character string class, `str is bytes` * `len('ä') == 2` * `len(repr(10**i)) == i+1` does not hold for all i * Classic classes are just confusing, `class X: pass` is not the same as `class X(object): pass` * Without all the [`__future__`](http://docs.python.org/library/__future__.html#module-__future__) imports, 2.x is even stranger (and there is a curious `x/y == x//y` identity). * Quick question: How do you write `b"a"` into a file in 2.x without leaking the handle? What if it's a tarfile? For these reasons, I'd **strongly recommend learning Python 3**, which is a sane language. You can learn the idiosyncrasies of 2.x later if you really need them.
I'm going to be perfectly honest with you. A description of the books cover isn't helping me narrow it down very much :P
I certainly am counting them. I've two projects and though I could have chosen Python for the 2nd I chose PHP (it's giving me a huge appreciation for Python) as someone else is more likely to have to maintain it and there's more PHP knowledge in the company.
Thanks, adding it to the list to look at.
I'll add this to the list for review too.
My personal favourite: `"€".encode('utf-8')` will give you a `UnicodeDecodeError`. Look closely: you call *encode* and get a *decode* error. There's a logical reason, of course, but it's horribly confusing.
I'm using it to run a chat server, as well as some other smallish services like a personal SMS relay, a websocket-to-normal-socket proxy and such. I've also made a few commercial apps with it, like a log processing and broadcasting system for some dutch ISP that takes log-messages and sends them to various devices (like mobile phones) for monitoring purposes.
That does look promising, cheers :)
Your explanation of why you dislike python2 is unhelpful to someone new to python. It merely muddies the waters. There are certainly corner cases for both versions. If you pick through the list of bugs, you'll find them: http://bugs.python.org/ You must not be in an environment that maintains legacy code on aging systems which currently don't have the latest python software. I cannot imagine that my business is unique in that regard. Upgrading 100s if not 1000s of scripts is incredibly painful to the point where the only reason I'd move to a new version of python (which broke backwards compatibility) is because I need the community support and most everyone has moved to python 3. In this scenario, it's more likely that I'll be looking at python 3 once it hits version 3.5 or 3.6. That means that over the next 4-5 years, I'm looking for developers that have and know python 2. Again, I cannot imagine that I'm unique in this position. More importantly, I have enough technical knowledge and skill that if I needed some of the more recent python updates, I can port the patch backwards to 2.x. This will extend my legacy code. At some point, I'm sure I'll bite the bullet and go through a major upgrade of the software. But at this point, I'm more than content to live with the idiosyncrasies of python 2... because I have a system that works right now. And if I haven't already encountered something peculiar about python 2, I probably won't. 
I experimented with this a while ago and found that it was often slower for simple functions. Also there's [python toolbox](http://pypi.python.org/pypi/python_toolbox/) (which the author posted here a few days ago that has a more full featured cache functionality. That is, it offers support for keyword arguments, which as you've said might increase CPU load (I don't know, I haven't tested it). 
I love videos about programming. When people speak in video, there is a *lot* of body language being conveyed. This is very useful if you are learning about something completely new and don't have any "feel" for the subject, when someone comes along with opinions and personality, it can make you more comfortable because you suddenly have feelings. Know what I mean?
`assertTrue` is how it's spelt it unittest, which is part of the standard library. Why that doesn't follow PEP8, I don't know, but don't blame the author of this post for it.
It's great for evolving neural networks if you're into that kind of thing. Gene Sher has come out with some extremely interesting papers in this area and has been programming in Erlang.
The variation might be related to the time for Python to start up and load libraries, which the system `time` command can't separate out. If you use IPython, there's a `%timeit` magic command for this sort of thing. Here it is with `lru_cache`: In [6]: %timeit fib(35) 1 loops, best of 3: 8.6 s per loop In [7]: %timeit fib_cached(35) 1 loops, best of 3: 1.91 us per loop EDIT: Of course, the 'best of 3' means the answer gets cached on the first try, and it's almost instant next time. If I tweak it to only try once (`timeit -r1 -n1`), it takes 126μs the first time.
This is not worth my time arguing over. I have said my peace, and I am moving along.
I truly apologize for being a dick about it. It's something I need to work on. 
&gt; Why that doesn't follow PEP8, I don't know The unittest module was (iirc) written before PEP8 and was aping a java library
The author of unittest did follow a convention, namely the cross-language convention of xUnit libraries. It was originally a Java library and since then the same interface has been ported to many different languages. Only later was it added to Python's standard library.
That's fine until you actually have to integrate with any enterprise app where their devs only grok SOAP. Good luck with that. 
There was a link somewhere showing that SOAP had been created by tool vendors as a way of selling tools. Don't suppose anyone knows what I'm talking about.
Just build XML/JSON and send it. Instant webservice. To recommend more we would have to know what you are trying to interface with. To that end, anyone giving you a recommendation is just pushing the hammer they use to attack every problem.
Dive Into Python has a chapter about talking SOAP. It uses SOAPpy. http://www.diveintopython.net/soap_web_services/index.html N.B. That is an old book but good. You can probably update many idioms for the latest Python 2.7 / 3.2.
tastypie. It's awesome and lets you version your apis.
Just wanted to upgrade my skills to improve career prospects. Seems like every architect and his dog is deploying SOA, Web services in the enterprise these days. I dont know Java so thought I'd find some tutorials and put together a request/response type system at home and learn.
SOA and Web Services do not require SOAP by any stretch of the imagination. If you're working in an environment that's heavily tooled for SOAP (Java, DotNet) then they're fine. If you're doing a lot of integration with other environments, steer far clear of SOAP-based services and stick with JSON-based RESTful services. You'll have more hair at the end of the day. ;)
Never forget that it is just data. Most of these wrapper's don't accomplish anything special. It is perfectly fine to send arbitrary XML in response to an http request as long as it is properly documented. The mechanism you use to get the http request and respond with XML depends more on what you are talking to than anything else. Its a simple answer to a complex ecosystem. Complex because there are so many wrapper formats. My short answer is that they are all crap, and you don't need to learn the format itself until you go to use it, as it often is just a library import away from working.
Depending on what you are really trying to accomplish SOAP is entirely too bloated and most of the libraries don't really get you much other than a translation layer into objects. If you are just trying to learn SOA, I would probably start by learning more about REST and then work on how to apply the concepts to building web applications in python. O'Reilly has a decent book on RESTful web services[1] to get started. I am currently using Pyramid[2] to build RESTful web services that use JSON as a serialization format. It seems to be working pretty well for me thus far. [1] http://shop.oreilly.com/product/9780596529260.do [2] http://www.pylonsproject.org/
A few things are happening in the near future that will make Python 3 more attractive: - Python 3.3 is due out in August, with various new goodies. - The top 3 [most requested](http://python.org/3kpoll) packages - Django, matplotlib &amp; wxPython - all have Python 3 ports on the way. - Ubuntu is pushing to use Python 3 on the desktop for the next release.
One read, which I'm currently reading, The Python Library by Example. A massive read, but it details all included modules within Python to use to it's fullest advantage.
I seem to remember that story. No idea where to find it or even begin searching for it, though. It was enough, however, to make me swear to never deal with it (if I can help it).
I hear you on that. Although every year we get through the drum for SOAP becomes a little quieter.
Or better yet, where you have an enterprise app implemented in Python and the *clients* only grok SOAP. Trust me, that's even more fun than consuming SOAP services in Python :)
I'm new to Python and going through Mark Lutz's *Learning Python* which is focused on Python 3 as it damn well should be. After covering a concept in the book, if it differs from Python 2 he will show how and how to achieve the same result. All I have to say is seeing how the old way is, I never want to go back to Python 2. It's time for the world to move on. What is taking so long??
Avoid SOAP, as it is terrible--there's a "standard", but the numerous implementations don't necessarily follow it. xmlrpc is awesome, consumable by all sorts of things, and included in stdlib. [PyMOTW writeup](http://www.doughellmann.com/PyMOTW/SimpleXMLRPCServer/index.html) 
Rather than learn the ins and outs of a particular toolset, I'd focus on understanding web services at a high level. [This article on RESTful web services is a good example](http://www.ibm.com/developerworks/webservices/library/ws-restful/). You can create a REST service in like 10 lines with [Flask](http://flask.pocoo.org/) and it's built in `jsonify` method. It's understanding what makes for a great web service architecture and why that will make you valuable.
What is the difference between these services and just running an httpgetreguest? Doesn't it essentially just return the same thing?
This subreddit is awesome. So much good info. Upvotes for everyone!!
I have this as my "local settings" import. try: import debugsettings except ImportError: pass else: locals_ = locals() for var in dir(debugsettings): if var.startswith('__'): continue val = getattr(debugsettings, var) if var in locals_ and isinstance(locals_[var], tuple): locals_[var] += val else: locals_[var] = val I should feel bad for that code but it serves me well. (It merges tuples together.)
Hmm. Thanks.
Your positivity inspired me to up vote yew!
Lua is used for scripting elements in the games industry all the time. It's probably exactly what you are looking for.
Not quite on topic, but terrific - goes through the basics of network programming, gets around to web services. [Foundations of Python Network Programming 2nd edition](http://rhodesmill.org/brandon/2011/foundations-of-python-network-programming/)
I'd just use Python as the scripting language. If the game is written in Python things are dead easy. If the game is written in C or C++, its reasonably straightforward. If its in another language, perhaps one of the JVM based implementations would let you integrate Jython. Or you separate the modules by streams/pipes/sockets and each module can be in whatever language as different processes (on different machines?) 
I like the `yes no | python manage.py syncdb`. Clever! 
meh
If a post is called "getting started with Python Mock", it should start *explaining* what mocking is...
Welcome to /r/python. This is normal here.
Why not let the user code access files? Perhaps the user's code needs data or configuration or something you haven't thought of. Just restrict where the module can access. Leverage the OS to block access outside the game's part of the file system. 
Some sandboxes provide memory limit and CPU time limit for instance. I know [PyPy sandbox](http://doc.pypy.org/en/latest/sandbox.html) does this.
Would you mind sharing that bit of code? :)
Cheers.
Excellent, that sounds like something I'd really benefit from then.
I remember when I wrote code like this. You're doing pretty well. Nothing outstandingly bad. Next, try using functions. Encapsulate your geometric equations in functions. Your flow control will start to look a lot neater.
Excellent, cheers.
Flask-enterprise = Support for the industry standard enterprise protocols SOAP, WSDL and XML-RPC with wsdl auto generate: * http://massive.immersedcode.org/2011/staging/projects/default/python/flask-enterprise/
We should switch off downvoting then like some other subreddits. 
It would be interesting to see someone do a "phases in the life of a programmer" type of thing on this. Start with your example, show a version using functions, a version using classes, a version with insane extensible metaclass-based plug-in system, … and back to the simplicity of the original.
* Function and variable names shoud start with a [lowercase letter](http://www.python.org/dev/peps/pep-0008/#function-names). * Use [urllib](http://docs.python.org/library/urllib.html) instead of httplib. * "Parsing" HTML by splitting Strings is ... unusual.
* don't put everything under the same "try", deal with the exceptions accordingly. some of those things don't return exceptions when they fail * don't use httplib for something as simple as an http get, take a look at urllib or urllib2 * avoid using str.split() for this, take a look at Regular Expressions you might want to take a look at this: http://code.google.com/p/python-weather-api/
&gt;Web Services, WSDL, SOAP etc... You messing around with SharePoint? 
Never fucking use REGEX for parsing HTML. God dammit.
On a serious note, for stuff like this, checkout the [cmd module in the standard library](http://docs.python.org/release/3.2.2/library/cmd.html). It's pretty amazing. Try the [turtle example given in the docs](http://docs.python.org/release/3.2.2/library/cmd.html#cmd-example).
Don't use exec and try and sandbox it yourself. Python's just too dynamic.
[I know](http://stackoverflow.com/a/1732454/128682) but what he's doing is just has bad
I'm looking forward to it! I don't know why but wxpython seems to fit my brain better than PyQt. 
two things, first the PROJECT_DIR should be: PROJECT_DIR = os.path.dirname(os.path.abspath(__file__)) otherwise you won't get the actual absolute path and you may want to add os.path.realpath too if you're dealing with symlinks. and the inclusion of local_settings.py is best done with `execfile` instead of import, that way you can read and update the values from settings.py like by example if you want to append values to INSTALLED_APPS
is there a way to download this videos so you can wath them offline? 
Here's a script: https://gist.github.com/2929272
Thus it behooves us to not make a mess in the first place.
nice! it works smoothly! you guys are awesome, thanks! :) 
When you pickle something, you set it into a container (file container, or glass jar) to be stored safely (either in brine water, or in a format that you know you can safely/easily reconstruct the data format from) Pickling is the easiest way to preserve food, and data
I'm going to start a competing module called 'jerky'. :D
Neat! I still prefer CDLL, since it allows me to load a pre-existing library into Python, but this is good for quickly trying things out.
Nice. didn't think of it that way, have an upvote
You can't use something like this? import re a = 'Ä' print re.match(r'\w', a, re.UNICODE) Not saying that you can't or that it's perfect for all situations. To my naive eye, though, it looks like a pretty good solution. Where does it break down?
Do you never, ever block and copy code from websites? Because that's when these two problems occur. You see a nifty piece of code on a site and want to try it out, then you paste it into your editor and suddenly you've either got some tabs mixed in or else you've got no indents at all. Happens all the time.
And now that I think about it, one major benefit of dying food is it takes up less volume, so your module should probably strip out anything that won't be necessary or relevant in the future, then jerkify that smaller dataset. I can actually see this becoming useful and quite popular. 
For getting the last, efficiently: next(user for user in reversed(users) if user['email'] == 'bro@gmail.com')
not on the first day the first few interactions you want to be able to get easy feedback
those bastards
It came from ... pickles. o.O
I found a PDF off the 3rd edition of "Learning Python." Thanks for the recommendation. While it's long winded, it's very easy to read.
And pickles taste so much better than cans! :) 
I'm not very educated about the matter, but in what is this different from weave ? Or how is it better ?
For most learning, going as close to the metal as possible is unhelpful. Beginners don't start writing code in assembler. What's important is picking the right level of abstraction - high enough to handle unimportant details for you, but low enough that most users will never need to look beneath that abstraction. That's what good API design is about. For instance, when you make an HTTP GET request, there's a lot of protocol details implemented for you. That abstraction is useful, because most programmers using HTTP will never have to think about the lower layers of the protocol.
I work in digital curation and preservation. If you can figure out which parts are going to be important later and which aren't, I've got a job for you! 
Note: DO NOT USE THE TICKLE MODULE IF YOU CAN AVOID IT. It's basically a workaround for not writing your own data format. If you need something like it, try the json module - doesn't have the deadly open-endedness that pickle does, and is a cross-language compatible format.
but... pickle is a far sillier module name then json :( but seriously, i dont have any intention of using it, but should i need to do something like that in the future i'll remember this
If you decide to go the Lua route, take a look at [lupa](http://pypi.python.org/pypi/lupa/).
As others mentioned, BeautifulSoup would work great here, but so would python's built-in xml parsing. I actually very recently wrote something much like your module for getting weather at the command line, but I used ElementTree to parse the xml. https://github.com/smithje/pyWeather/blob/master/Weather.py 
Store a seed per thread, do not allow thread scheduling to impact the use of random numbers.
This is a good solution. Alternate answer: use a shared OS-level resource for random numbers that doesn't know/care which threads or processes are calling it. http://docs.python.org/library/os.html#os.urandom
Why would this be any faster than using ctypes?
why would you want to create one more file format? i don't see how it's such a big disadvantage that anyone can load it in and you can always encrypt it...
I honestly don't know the details. My statement that it will be fast comes from asking about it recently in #pypy on freenode - apparently ctypes has all sorts of special cases that make it incredibly hard to optimize.
depends on what you're storing and why. in most cases, it's more of a data structure problem; pickle is a workaround to allow you to just use the same data structure as your program uses, while json usually requires some rearranging of the structure before you can dump it.
https://github.com/alex/yaffi/blob/master/docs/ctypes.rst#speed
I do paste in code from elsewhere, but I have vim set up not to use tabs, ever, so it never creates problems. I'd have thought this is possible using other editors, I'm just using the one I use as an example.
Yes, but the data will be very tough to get through later.
The soda jerks of the 50s did it.
I just noticed you're using `input` instead of `raw_input` in Python 2. Not best practices! ;-)
I use 'wet code' to talk about code that contains a lot of unnecessary repetition/duplication of information, because it violates the [DRY principle](http://c2.com/cgi/wiki?DontRepeatYourself). "Drying out" a system means making sure that every piece of information has a single, unambiguous, authoritative representation. But doing that automatically would take some pretty heavy-duty static code analysis, if it's even possible.
Which type of PDF? A *wink wink* pdf?
yes
you missed the point again - pressure and no cleanup time end up generating mess at practically all times as humans we are flawed beings that cannot possibly hope not to end with a mess sometime thus cleanup is necessary, and without cleanup we just start to pile up more mess, cause if mess is left alone it tends to grow
I have a project template that does a few of these things and what I believe to be sane defaults and practices. http://amccloud.com/post/14689947527/django-1-4-custom-project-template 
Nope! Should I be?
Do not use `jumpahead`, it will pass eyeball tests, but then: http://codepad.org/T2CWrgi5 (it is fixed in the 2.7.2, but if you or somebody else runs your code on an earlier version, you are screwed). Initializing to consecutive seeds is perfectly sufficient, calling a bugged function in addition to that is unnecessary and dangerous (what if someone decides to "fix" the code by doing `Random(seed)` + `jumpahead(rank)`?).
In addition to some other adjustments mentioned already, another small one is to replace all the adjacent prints with a single print with a multi-line string. (http://pastebin.com/GtZgZGuy) Also, hate to be *that guy* but *cubes* have same length/width/height. I think you want to redefine what you have as a *rectangular prism*.
Google changes the search results page very often and they will eventually block your app, automatically. Here's the libs you should look for anyway: * requests * beautifulsoup
Google has a search API which gives you 100 requests per day: https://developers.google.com/custom-search/v1/overview And also an old search API (which is deprecated, with unknown limits): https://developers.google.com/web-search/
Skipped in the presentation though, the envoy module is awesome. too.
how does Google know the search is not being done by human ?
the same way reddit knows the difference between bots and normal users. in other words: they do it somehow, but they don't tell us.
Read this: http://wolfprojects.altervista.org/changeua.php
This is a good idea. The only concern [and it is a very mild one] is that it is, from time to time, useful to be able to reproduce the exact same results. I could write the urandom number to file and then pass it back in.
I'm not sure exactly what you mean, but each thread is doing the same thing. I need to create, say, 1M events of a certain type, and I split it up into 4 threads. Each group of events is identical, and then I pass certain properties back to the master and they get analyzed, plotted, etc. there. So each thread is identical except that #0 also collects and plots and saves and stuff. Does that address your concern?
hope so, says it was released september 2009, which is when the 4th edition was released, but no information as to the edition. we'll see when it arrives eh? 
Oh well, if we're linking our favourite modules from the standard library then...
For salting passwords?
Start learning about webscraping, xml, and filling out forms (google search bar is a form). Also, learn how to make yourself seem like an old granny on IE 5 with the mechanize library to trick Google. Check this video out, and right when you get to a portion you don't understand, look up the terms online and get to know them. Then return to the video: http://www.youtube.com/watch?v=52wxGESwQSA When he gets to xpaths, learn them. They're not difficult. Useful libraries are: urllib/urllib2 (standard with python), mechanize, and lxml. import urllib2 url = "http://google.com" url_open = urllib2.urlopen(url) html = url_open.read() print html Try to find the form field. Try to find out how to make that nasty "soup" look more presentable. That should get you started. /coffee rage
I'm pretty sure custom search only supports a single site, as it's a site-specific search tool. Scraping arbitrary search results is against their TOS.
Great, it used to be random douches who were too lazy to read APIs and tutorials and related documentation, but now it includes people doing dissertations. :|
Unfortunately, Google does not have a true web search API, though they used to. I've resorted to simply scraping the regular search results page and passing along a legit useragent and my Google session cookies so they don't think I'm a bot. Bing has a full-fledged search API, but I think it's limited to 50 or 100 results per query.
Actually my understanding is that pseudo random number generators can really mess up stuff like Monte-Carlo simulations if they aren't random enough. That being said, I don't quite see what this addresses. Whatever RNG you use, how does it matter if successive calls are to different threads or even different processes?
I thought I might get this. I am absolutely planning to do my own reading of the tutorials and related documentation. But there is an avalanche of available resources, enough to bury you without a bit of guidance. So my main goal is to hear views of experienced programmers on which tutorials and other resources are best, not to have someone do anything for me. See the difference?
No, but they could read tutorials and related documentation, while referring to the API for more specifics when needed.
Eh i still feel that if you are storing data locally, its still ok to use pickle, but having it come over the network it is probably a bad idea. In my above whoosh example, i believe it's main data format is a btree, and if you have local access then you can maliciously attack that (or any data format) 
Does it need to be exceptional? It's exactly what you're looking for!
and they came here to figure out where to start with those. there's nothing wrong with that.
This is awesome. Thanks. I'm checking it out now. I suppose I can mention that my project involves first starting with a set of users I've already defined, collecting all of their followers, uploading them to a matrix/spreadsheet, collecting the friendships between the users in the matrix. Second, I'll be tracking the retweet-based ties and retweet cascades from my defined set of users. Lastly, I'll be collecting location-based tweets around trending topics in my community.
Thank you!
&gt; But there is an avalanche of available resources, enough to bury you without a bit of guidance. I'm not buying that horseshit. No one's ever been buried by an avalanche of resources while reading that standard documentation at the main Python site. &gt; So my main goal is to hear views of experienced programmers on which tutorials and other resources are best I don't buy this bullshit, either. It does sound good, though. The reality is that there is no best or set of best resources, and that you appear to need to learn the basics, for which you certainly don't need the very best resources on the entire internet. If you'd stop being lazy and just go look for things, you'd find plenty of great material. It sounds like you just need to know enough Python to use the Twitter API. That would obviously not require a huge amount of Python. You could learn it in a matter of hours, most likely all by yourself. You could have started learning the material and asked a question when you got stuck on something, needed clarification on a specific item, etc.. But you don't even try. That's the reason it's so transparent that you are just being lazy. You don't even try.
I would absolutely be interested in corresponding about it, yes. When you ask about my methodologies, are you wondering about my data collection methodologies or my planned data analysis methodologies?
For my uses, the built-in RNG is sufficient. I'm just asking about threading. If you send out 4 RNG's to 4 threads and if they all pull their seeds from the clock and they all start within the same second my sample size will only actually be 1/4 as large as I think it is. If you change the seed for each one seed(seed+rank) [where rank is the thread number] or something like that, they should all follow different paths and not overlap. I'm just not entirely sure about that and so I figured I'd ask to see if anyone knew more on the subject than I did.
please spare me your bullshit. you don't need to go to a forum to find out where to start with the main Python documentation. you google it and you start reading, if you aren't a giant, lazy ass.
don't take him too seriously, he's a regular troll.
Ah. I would have just had 1 RNG that each thread grabs numbers from.
I'm in Canada.. I'll PM you my email address. :)
I've given up using urllib and do this instead: com="wget -q -O temp.html -U 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:12.0) Gecko/20100101 Firefox/12.0' %o" com=string.replace(com,'%o',url) os.system(com) 
Ok, good luck. Miyagi: Now, ready? Daniel Larusso: I guess so. Miyagi: [sighs] Daniel-san, must talk. Man walk on road. Walk left side, safe. Walk right side, safe. Walk down middle, sooner or later, get squished [makes squish gesture] just like grape. Same here. You karate do "yes," or karate do "no." You karate do "guess so," [makes squish gesture] just like grape. Understand? Daniel Larusso: Yeah, I understand. Miyagi: Now, ready? Daniel Larusso: Yeah, I'm ready.
This goes a long way as well, even if you don't follow PEP8 while writing on a whiteboard, you can mention "normally, I'd have a triple-quoted docstring describing the method here" and so on. It's also a huge advantage if you can find out what their stack is, exactly. So you can offhandedly mention you are familiar with the testing, build, etc tools they are using.
What if the URL is "; rm -rf /"?
I've seen that movie more times than I can say. And I hear you loud and clear. Consider this post the beginning of me diving in with a big yes.
&gt; This is awesome. Thanks. I'm checking it out now. Not a problem. Just add me as a co-author, and we can call it even :P
How do you know? Edit: Oh! Nevermind, it's a project started by [Armin Rigo](http://pypy.org/people.html), of course it will work with PyPy. 
That makes sense. For those of us who haven't learned what software engineers have already learned, I think we need more than Google. The pointers I've gotten here are exactly what I needed to get pointed in the right direction.
If the URL contains a single quote to close the first quote you prepended, the same attack still applies. See [StackOverflow](http://stackoverflow.com/questions/35817/how-to-escape-os-system-calls-in-python). I recommend [shlex.quote](http://docs.python.org/dev/library/shlex.html#shlex.quote). **Don't use the shell if you don't have to!** Also, use the [built-in string formatting operations](http://docs.python.org/library/stdtypes.html#str.format).
But the Google search form uses get and not post so there's no need to submit the form. If you want to search for Python just go to : https://www.google.com/?q=python. Altough, going directly to the url might tip of Google that it isn't a human doing the searches so depending on how often you want to scrape Google it might be a good idea to submit the form. 
Python's default PRNG is the Mersenne Twister and has been optimized for use with Monte Carlo simulations.
Something often overlooked is the power of using Python interactively. It is unbelievably awesome, especially for learning, since it makes trial and error quick and fun! I highly recommend using the [DreamPie](http://dreampie.sourceforge.net/) interactive environment to begin with, since it is simple and intuitive. Some online resources I think are most useful forlearning Python: The #python IRC channel is probably still alive with people who will gladly help you with any problem you run into. It's the best resource when you're getting started with Python and have a lot of novice questions, since you can get answers very quickly. [ShowMeDo](http://ShowMeDo.com) has quite a few Python video tutorials, if you like video tutorials. StackOverflow is a great resource for programming in general and Python in particular, but it isn't appropriate for all questions, and knowing some jargon really helps finding answers there. Finally, see if someone has blogged about using the Twitter API via Python. Blogs usually contain explanations as to why things are done a certain way, which really help in learning. And working examples which you can play around with are the best.
Python is a general purpose language and there are lots of tools and frameworks that make developing for the web painless. Anything you could accomplish in PHP you can accomplish in Python. Both languages have strong and weak points, though in my personal experience I find Python to be more approachable and robust. For a simple project like you're describing, though, it comes down to preference and familiarity. PHP is definitely more "c-like," though I wouldn't consider that fact as something particularly in PHP's favor.
There's [PyCurl](http://www.angryobjects.com/2011/10/15/http-with-python-pycurl-by-example/) too. Here's a wrapper that makes it more Pythonic: [human_curl](https://github.com/Lispython/human_curl).
&gt;For all I care you could go with selenium, they'll eventually block you anyway. Please do explain. If OP makes a simple console program that lets the user type in a word and then do a search on google and then parse the response and prints the result in a list, how would google be able to distinguish that from a regular web browser? 
I've never coded anything like that, but I would say that both languages have their merits and you achieve your goals using either. Is this game in the browser? I highly recommend checking out the [Flask web framework](http://flask.pocoo.org/). It's a mini framework that is really great for building smaller sites and prototyping big ones. I think it's also a good introduction to using Python for web programming - you need a minimum of setup to get up and running.
I love python! The tweepy library bassdread mentioned seems to be the way to go. I'm not familiar with parsing twitter (or twitter at all honestly) but if you have any specific python questions I'd be more than happy to help. I do research too so I know what it's like to pick up something foreign from scratch :-) And PS, when I started learning python from scratch I read through [python tutorials](http://docs.python.org/tutorial/) and just made notes/flash cards to get a grasp of all the natural functions/syntax for python. It's nice to know all the functions/tools available in the language before you set out.
The basic concepts are the same, it's just a different interface. In a traditional text game, your I/O layer is a terminal. In the game you're proposing, the I/O layer will be a web service. I would suggest looking in to Flask, as handsomeransoms suggests. Your game could output HTML and receive input as HTTP POST requests. The game logic exists behind that I/O layer just like a traditional text games' logic resides behind a terminal I/O layer (like ncurses or whatever :)
OP: please start here, the tweepy library is very intuitive, and has a few (somewhat less documented) features that will make your life a lot easier, e.g. caching and nice results-cursors. Combine this with e.g. mongodb to persist the JSON-responses, and you are set to go.
cffi is a foreign function interface weave looks like a way to inline c/c++ extension modules inside of python code (which seems rather strange to me)
Not sure if this will cover _exactly_ what you're looking for, but Udacity is offering a course called "crunching social networks" starting on June 25: http://www.udacity.com/overview/Course/cs215/CourseRev/1
Yup, I've been coding more or less strictly to pep8 for the past year or so so I should be good on that front.
This is great, thanks. 
You might actually check out [twitter-tools](http://mike.verdone.ca/twitter/). it's written in python, but comes with standalone versions of things you can use from the commandline (which might be easier for you to tinker with). For example, to grab all of my tweets into a text file, I'd run something like: twitter-archiver -o japherwocky and things all Just Work.
how about pep20? I'd say that's much more important ;)
Wow, that is a spectacularly terrible way to do it.
Another good web module is `requests`.
What? Why did you use bs4 to parse tweets, if you use the API you get json back
True but you can't measure it quantitatively, so as much as I'd like to think that I follow pep20 it's more subjective.
pep20 is about design. while, yes, you can't measure it algorithmically, it's well enough defined for humans. The people interviewing you are going to care how nice your code is; I've found that really trying to take pep20 pretty literally is really useful. 
oh, a phone interview. I missed that part ;)
Since you're Dutch, this sounds like a project related to Antal van den Bosch or Hans van Halteren. Am I right?
I did my own PhD research on social networking analysis. You might be better off using an existing dataset of tweets. Generally you need to analysis more than one dataset anyway forbyour results to be taken seriously. Try infochimps for data, also quora has a nice list of sites for data. I'm on my phone right now or in would link there for you. Good luck! 
The best way to do this is to use a headless browser. Unfortunately their are no good ones that are Python based. The best solution I have found for this problem is casperjs which does allow native coding in coffeescript. Casperjs has samples that will show you how to scrape Google. It is dead simple.
&gt;While you may have a point when developing a web app It needn't even be a webapp itself. It could be a background service that just happens to have a storage location writable by a webapp (eg. it indexes uploaded files for searching, but stores its indexes in the same location). This is why it's particularly dangerous in a library designed to be used by other programs - because you can't predict where it'll be used. &gt;Furthermore, who the hell executes every file in a directory Like I said, laziness, or even just an unconsidered bug. Say, you want to be able to search over multiple datastores, indexed on different schedules. You'll want multiple index files. Now, it'd be safer to have a config file that lists these everywhere that uses it, but suppose some newbie programmer thinks "Why bother specifying this in two places, when I could just have my search client automatically find the index files produced by the indexer and search all of them". Alternatively, there could be a bug that allows greater control of the uploaded filename than just the extension, and the attacker could overwrite an *existing* index file. Very often, exploiting a series small bugs like this are exactly how an attack escalates his privileges. Read [this](http://blog.chromium.org/2012/05/tale-of-two-pwnies-part-1.html) to see how far people can go with this. It all comes down to the fact that for good security, you can't assume that the rest of the program is coded in a perfectly safe way. You should code under the assumption that there *will* be unexpected bugs and minimise the damage it could possibly do under any circumstances as much as possible. &gt;they could just as easily change my proprietary xml But the point is that this wouldn't allow them to execute arbitrary code. It'd allow a DOS attack on your searching, but they wouldn't be able to take control of your entire server. Hence the advantage of the principle of minimal privilege - when things go wrong, the damage is minimised. &gt;encrypt it before you dump it to the file That's better, but still worse than it not being able to invoke code at all (it's still an elevation of privilege from knowing the key (requires just read access to the code/keyfile), to being able to *execute* code on the machine). And really, it adds similar complexity to just using a different serialisation format (python doesn't have a builtin crypto library either). 
I'm currently using Aptana Studio with the PyDev plugin. PyCharm seems to integrate with Django a lot better, I will check it out. Thanks!
PyCharm by JetBrains http://www.jetbrains.com/pycharm/ Supports buildout (virtualenv?), git, pypy. Best python IDE on the market.
The following tools are fantastic for debugging Django apps: 1) django-command-extensions is an app that lets you execute a shell from directly within the browser at any point in your stack traces on error pages - amongst doing some other nice things. 2) django-debug-toolbar is an app that provides a lot of information about your requests from in the browser. Including reporting on database queries, template context processors, request variables, and much more. These apps reduce the amount of time that you truly need to debug a django application in a real debugger. For those times, it is generally useful to use pdb or pydev - however, pdb leaves something to be desired and pydev doesn't seem to work well on my Mac with Django. I came across the editor, PyCharm - which makes it a breeze. It is a commercial product, however. If you aren't interested in purchasing a commercial product, you are most likely stuck with pdb and the apps that I suggested earlier. 
I would go as far to say that: * You don't have MySQLdb installed. * If you do, it's not on your path. Import errors are a simple fix and I'm not entirely sure why you'd need a full blown debugger for something like that.
whatever editor you already know
emacs
Pycharm has full on integrated PDB and built in django tools, it has a trial or free for open source work. It beats all other IDEs ive tried out of the water
What in your opinion Aptana Studio is missing?
I do have MySQL installed as my dev server is working properly. I'm pretty sure it has something to do with the path. When I set up MySQL and Django I had the same error that the debugger is giving me when I debug as Django project. I remember pulling my hair out when the error occured as I was first setting up my dev environment, so I thought if I just use a different debugger(since it only gives me that error when I "debug as") it might work. Turns out PyCharm is giving me the same error... ps I completely forgot how I solved the problem originally Can any body help me fix this error? http://imgur.com/sQb9r
i thought it was readable, if you click on the image it will enlarge to a readable size. anyways, here is the pastebin http://pastebin.com/WqqSW3fc
&gt; The #python IRC channel is probably still alive Yes it is and I'm very thankful to it when I started couple of years ago. &gt; StackOverflow...some jargon really helps finding answers there. what do you mean ?
Thanks for the suggestion. I am not quite sure what django-pdb is, reading the description, it seems like it is a easier way to invoke pdb without using import pdb; pdb.settrace() or something?
yeah agreed, ... I think it's a pitty that python 2 stuff isn't compatible with 3, i don't mind using 3, there's just somethings i use who still aren't available for 3, so time will tell
Go into your REPL and `import MySQLdb`.
Ya I can exec "import MySQLdb" perfectly fine in my regular python repl
`echo $PATH &amp;&amp; echo $PYTHONPATH`
pyramid doesn't need any ide support. it creates a wsgi application, you serve it, the script you use to serve it is what you debug. 
ok but I can't execute anything in the console after the error message
I wrote this module in Feb 2010, and I'm not sure the Twitter API supported JSON at the time (or I may not have known about it). I had 2 days to write this module, so I did whatever I could to get it up and running. The Twitter API was really awful when I wrote this module.
It's just about readability. When I enlarge to readable size, some lines don't fit on my screen, so I have to scroll back and forth to read it. Worse, a couple lines don't fit on your screen, so no amount of scrolling on my screen allows me to see all of the potentially relevant information. This isn't just you, in fact this is one of my big pet peeves as a professional django programmer. Testers and users will get an error and take a screenshot of the debug page, which cuts off most of the stack trace. It doesn't matter how much I tell people click "switch to copy paste view" and send me the content, most people still just want to send screenshots. It looks to me like you're missing some C dependency of MySQLdb, but I don't know enough about python development on OSX to know for sure.
No, echo those environment variables into your terminal.
it also makes it easier if someone wants to copy and paste something from your debug script into Google
Shouldn't you have `../site-packages/` on there somewhere? (I'm a little ignorant of the set up on MacOSX.)
Ah ok makes sense
I am too tbh... I followed a bunch of tutorials to get it setup properly, it REALLY was a pain in the butt to set up Django, and MySQL, if you asked me to do it again I would not be able to. I can't remember where I installed python.
"learn how to make yourself seem like an old granny on IE 5" best way to describe un-suspicious behavior I ever saw xD.
cffi is using c syntax to declare structures and functions is not using c syntax for code
Do you have the DYLD_LIBRARY_PATH environment variable set? I had the same issue with PyCharm on OS X at first. To fix, go to preferences &gt; console &gt; Django console. See if "DYLD_LIBRARY_PATH=/usr/local/mysql/lib/" appears in the "Environment variables" field. If not, add it by clicking on the "..." icon. Yeah, PyCharm's interface is clunky in this regard.
~~Isn't the trick of these services that they'll hijack the domain once enough interest has been accumulated?~~ see below
AWWWWWWWWWWWWWWWWWWWWWWWWW YEAH!!!!!!!!!!!
I'm just posting this here just as a way to see if I can get help with a problem I'm having by the community. As for the blog itself, I am for 400 days going to learn how to program and for the first 50 days I'm learning Python. This blog is a daily update on my progress, documenting my thoughts, new things and struggles. Pretty unique, I think.
ok
(I co-founded Domainr) This is called [front-running](http://en.wikipedia.org/wiki/Domain_name_front_running), and we absolutely do not do this.
&gt; Mind if I mirror your copy of Babel on github? Not at all! Go ahead.
thanks for your help.
Yup, i implemented the rotation matrix you linked to. I'm not really sure I understand what you said then, so I'm going to be really cheeky and ask for a more detailed explanation? Sorry. heres another pic. http://puu.sh/BGRv 
Another issue is that `int(float_val)` does truncation not rounding, which will result in artifacts.
Better, sure, but still quite pointless to link the official documentation ...
why would one need to search by symbols ?
The reason the ball isn't moving is that you're not updating x and y. Add the following line before you blit the textures to the screen: x, y = x + movex, y + movey
You can look into my works [http://kracekumar.com/post/19556427690/n00bs-epic-research-on-twitters-streaming-api-on](http://kracekumar.com/post/19556427690/n00bs-epic-research-on-twitters-streaming-api-on), [https://github.com/kracekumar/sachintweets](https://github.com/kracekumar/sachintweets), my sites which built with twitter data www.sachintweets.in, www.iplsaga.in
We use docutils’s Python equivalent of rst2html, and then pass the result to WeasyPrint with a custom CSS stylesheet. WeasyPrint supports absolute positioning and a lot more that is hard or not possible to do with rst2pdf. (Of course sometimes the reverse can be true.) http://weasyprint.org/
did you submit a bug report? I'm sure they would appreciate it.
Curious thing is that CPython's `bool` doesn't override `int.__format__()`, that determine how the value will be formatted by `str.format()`. However `int.__format__()` formatted the boolean value `True` into `'True'`! WTF?! See below the CPython's behavior: Python 2.7.1 (r271:86832, Jun 25 2011, 05:09:01) [GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2335.15.00)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; bool.__format__ &lt;method '__format__' of 'int' objects&gt; &gt;&gt;&gt; bool.__format__(True, '') 'True' and the PyPy's behavior: Python 2.7.2 (0e28b379d8b3, Feb 09 2012, 18:31:14) [PyPy 1.8.0 with GCC 4.2.1] on darwin Type "help", "copyright", "credits" or "license" for more information. And now for something completely different: ``"ah, just in time documentation" (__ap__)'' &gt;&gt;&gt;&gt; bool.__format__ &lt;unbound method bool.__format__&gt; &gt;&gt;&gt;&gt; bool.__format__(True, '') '1' 
Hi. This sounds like a cpython test suite fail. After all bool inherits from int, so it seems reasonable to use int.__format__, unless some tests specifies otherwise. Besides, reddit is a *really* bad place to submit bug reports. What are you trying to achieve? bugs.pypy.org is by far a much better place. It doesn't have the point system or what was your goal? Cheers
Not yet because I haven't used PyPy bugtracker. I'll try to report it later. Thanks.
I issued this bug: https://bugs.pypy.org/issue1180 I tried to explain it well but I'm worrying about my poor english... Thank you.
also see https://github.com/gyllstromk/python-timely/
They will do anything, but to implement the Python C API. 
Thanks for the reply: I'm a bit unsure as to how an anti aliasing filter would help. As far as I can see, the problem is my transformation matrix might give me a coordinate like (4.6, 3.2) which rounds to (5,3), and therefore the pixel at (4,3) is left uncoloured resulting in these dots. One thing that reduces the 'black dots' massively is by running the entire rendering method twice. The first time I round using math.ceil() and the second time using math.floor(). This gets rid of most of the weird effect but makes the program run very slowly. If I colour each dot + or - 1 on the x and y axis red as well, then it completely solves the problem, but the edges of my box are 1 pixel wider than they should be and the corners look blurry. Also in a practical sense this method is completely unusable because it takes so so long. If I used pixarrays or surf arrays and tried each pixel for its colour first I could probably speed it up though so im not too worried. I'm definitely going to research low pass filters though, it looks pretty interesting. Cheers!
Yes pygame has all these functions built in, I am just trying to learn about transformation matrices and using pygame as my playground.
[Komodo Edit](http://www.activestate.com/komodo-edit/downloads)
it's not poorly designed, it's just too entrenched in cpython model. emulating it is both hard and prone to raise hard questions and performance problems.
I would even do anything, but to use CPython C API (it's not a Python API btw, it's not a part of the official language spec)
They have implemented some of it, as cpyext. It's slow. Nobody knows how to make it fast.
You might want to fine-tune your package searching system. Your third result (by download) is pyramid_debugtoolbar ! Does not flask have a trove classifier ?
actually it just searches pypi for "flask". I take your point.
Nice, I just started looking at Flask. http://flask-ahoy.com/package/Flask-Restless/0.5 500's, just FYI.
timeit.default_timer uses the timer with the best accuracy on the host platform. On Windows, time.clock is much more accurate.
WTF is principals?
I'll add that the 2nd edition is even better. It was updated/re-written by Brandon Rhodes, who [talks about the process on his blog](http://rhodesmill.org/brandon/2011/foundations-of-python-network-programming/) (for example, none of the major web frameworks that are out today were available at the time the first edition came out, and the one that was--Zope--wasn't mentioned). Can't recommend that book enough.
+1 for being pragmatic!
This is one of the highlights of my conference season. PyOhio is awesome.
Hmm, I have not seen an FFI like that. Looks pretty cool, though.
Thanks :)
I think that the way you are trying to do it is in fact impossible. Imagine a square, where each corner is the center of an image pixel, then rotate that square 45 degrees and move it so that its center is aligned with the center of some screen pixel. The corners will fall into the four pixels around that one, and nothing will go to the pixel itself. That's the reason why most texturing algorithms operate on screen pixels: you determine how does your shape look in screen coordinates, then iterate over all screen pixels and determine the colour, either by finding the nearest image pixel, or by finding the four nearest image pixels and interpolating between them proportionally (bilinear filtering), or adding mipmaps and using the nearest mipmap + bilinear filtering, or interpolating between the two nearest mipmaps (trilinear filtering), or in case of a 3D application making even more probes (anisotropic filtering). Oh, and also you must have a very pedantically defined rules for rendering edges, so that you don't have missing pixels between neighbouring polygons. By "very pedantically defined" I mean that there are papers about doing it right published in peer-reviewed journals. You try to do it backwards, by working from image pixels. That's not _entirely_ impossible if you approach it in the correct way -- by realizing that you are trying to render a particle system. Then each of your particles (image pixels) should distribute its colour (and alpha) to (at least) four screen pixels, proportionally, and it would work. But it's not the way renderers work, it's very computationally intensive (especially in pure Python, without numpy) and doing stuff like that is usually reserved to cases where you really want to render a particle system. I advise you to read some stuff about rendering before trying to reinvent the wheel (badly). When I was into this stuff the go-to tutorial was NeHe, but it's more about doing higher-level stuff with OpenGL (though you will pick a lot of intuitions about lower-level stuff in the process). If you are more interested in the gritty low-level details of software renderers, I don't know, I guess there are tutorials for that too, I vaguely remember people doing walk-throughs through the Doom code, and maybe even Quake software renderer. Though I must repeat: the part about rendering edges correctly is a brain-killingly boring, it's edge cases after edge cases (pun intended), I just don't understand why anyone would want to subject themselves to this when people have already implemented it.
 &gt; I'm a bit unsure as to how an anti aliasing filter would help. As far as I can see, the problem is my transformation matrix might give me a coordinate like (4.6, 3.2) which rounds to (5,3), and therefore the pixel at (4,3) is left uncoloured resulting in these dots. This is why i said i look at it a little differently. I'm actually an electrical engineer, a recent college grad, and focus primarily on communication theory. When i say low pass filter, i really mean some sort of averaging function, which could also be interpreted as a smoothing function, it all depends on you background and how you look at the problem. One thing i forgot to say in me previous post is that my coefficent table that i said yto use should be applied after you apply your transform matix. so the math looks like this: For an image I and transform T, and matrix filter H, J(x,y) = T(I(x,y)), and finally K(x,y) = J(x,y) * H(x,y) , where * means convolve with. OK this is where i stop, introducing even more complex terms is probably a bad idea at this stage. 
I don't even have NoScript yet I don't see `pointer` either. It's just poorly written. `pointer` doesn't even show up on `a` tag on some parts because `href` part is missing.
If you're trying to detect collisions between circles, why does it matter that pygame doesn't accept floating-point positions? Just use floating-point numbers to represent the locations of your circles, and convert them to ints when you need to draw them. Any difference in position will be less than the width of a single pixel, so I don't think it will be a problem.
Interesting, I would've said it's just a generator. Nice to know the Python devs made it a reliable stand-in for `range`.
I would like to add that if my proposal is accepted I will be giving an all day in-depth bootcamp on modern Django development. Just one more reason to donate to this amazing conference. Good on you and Eric and the entire PyOhio team for putting on such a great conference.
I believe you already got your answer, I just wanted to let you know that it is "integers" not "intergers". I'm sorry if it was just a typo, I don't want to be an ass... just wanted you to know.
Isn't it the same ? He said about funcionality, then xrange is generator. It's like talking about a car or a box with engine and four wheels.
Ahh, somehow I missed that in your article --- my bad!
lolololol
Can someone explain to me how this is different than ctypes? EDIT: For anyone else wondering this, the simplest way to see the difference is to look at the example in the docs: http://cffi.readthedocs.org/en/latest/index.html#simple-example-abi-level
I think that the point is that all that you need to know is how to write C code and a couple of function calls to do everything that you need to do to call arbitrary C code from Python. By contract, ctypes requires that you learn how to use the library in order to translate your C specifications into ctypes library calls, rather than letting you type the C specifications in plain C itself.
ok the html5 is dodgy. I'll have it fixed. Thanks for the input all.
It would be nice to have collections or recommendations for similar extensions on each extension page. Or perhaps a comparison matrix of features for similar extensions. For an outsider starting or triying Flask it may be hard to evaluate which extension to use to build a REST api or which way to integrate mongo or redis into a project. There are several options for each of these... Also I can see a login button at the top but is not clear what do I gain by logging in.
The limitation of ctypes (another API to learn) seams rather weak to justify starting a work like that. I guess that people as smart as Armin Rigo and Maciej Fijałkowski do have better insights on ctypes limitations. Any pointer to a more elaborated documentation of the motivations behind the development of a ctypes alternative (e.g., why not improve ctypes if it has known limitations)? 
Oh and by the way the flask snippets pages are a great help for your middle point. http://flask.pocoo.org/snippets/
xrange returns an **object** that generates numbers in a range **on demand**. for a loop, it's slightly faster and more efficient. 
In the examples, there it says "int printf(...);" - how do I access that "int" from Python? And what if the function returned a struct - how would I access that?
&gt; The limitation of ctypes (another API to learn) seams rather weak to justify starting a work like that. As I understand from the announcement and from working with ctypes a bit myself, the main limitation is that *it is another API to learn*. Your functions and structures end up being represented in three forms: the C form, the Python form, and the ctypes definitions, which can get quite involved with passing stuff by reference and lifetime considerations. Which in a sense is an opposite of "limitations", but rather something you need to express all you can express with C -- but then it requires a lot of RTFM, which is a limitation of a kind. This project aims to remove the need for the third representation by generating it automatically from the C definitions (which you supposedly already have). And it seems to work perfectly at least for simple cases. And you don't need to learn ctypes of course.
Probably not a typo: it's both in the title and the post.
This is a great competition! I did it in 2006. It's also how I learned to program! 
http://www.reddit.com/r/Python/comments/mvjij/alembic_010_is_out/c3482h5
Kind of off topic, but why did you choose TypeError for the argument error and to convert a ValueError into a TypeError? (Personally I wish there was an ArgumentError in the python std lib)
If that's the case I'd still go with rotating the vertices. After you have your vertices rotated into screen space you'd want to look at texture mapping techniques as you work across each scanline of the destination to find which pixel(s) of the source image to plot. For a good but old read on the subject try Michael Abrash's Black Book of Graphics Programming. He's released it online for free now: http://www.gamedev.net/page/resources/_/technical/graphics-programming-and-theory/graphics-programming-black-book-r1698
The reason I asked is because I'm never really sure which exceptions to use. I often end up using ValueError for anything argument related.
What mitsuhoki said just make me realize : don't search for "flask", search for "flask-".
- Kivy is a library framework, similar to Tk/Qt/Gtk, but focused for NUI (New User Interfaces). - Kivy have its own graphics engine, written in Cython (enhanced Python compiler), using only the GL API compatible with GLES 2. All the graphics and widgets are built over VBO/Shader. - I only heard that it was the case at the start, but it's not anymore. You cannot just dynamic load libraries, or execute code from the internet. If you ship everything in your app, their is no issue with validation (We have 2 applications built with Kivy available on iOS: Deflectouch and ProcessCraft). - You raise a point i never thinked of before. And i'm a little lost with your question. Is statically link code change anything about shared approach?
Well, yes. It's not a real rule, obviously. Just a hobby horse.
You can see an explanation of what each of the built-in exceptions is for at http://docs.python.org/library/exceptions.html. `ValueError` is used when the value is inappropriate (eg a step value of 0 in `xrange`); `TypeError` is used when the type is inappropriate (eg a step value of "abc" for `xrange`).
FWIW I am using the passlib module (http://packages.python.org/passlib/) in a flask app I am currently developing, and it is both flexible and easy to use.
Okay, fair enough. I forgot that the version I had was compatible with Python 2.5 (hence using `u()`, `b()` functions etc.) so I pushed up changes which drop 2.5 compatibility, and use the `unicode_literals` import. The current version has no `u()`, `b()` functions and passes all tests on 2.x and 3.x (tested with 2.7 / 3.2).
what's 'GLES' ?
GLES is OpenGL for Embedded System: http://www.khronos.org/opengles/
What is NUI?
Agreed, thanks to the OP for correcting his post.
You could also consider the MPL or one of the devices derived from it. The effect is pretty similar to the LGPL but without the requirement that the user be able to re-link the application to replace the covered work. Of course, at this point you have to start considering the compatibility of whatever license you chose (plus whatever additional permissions you grant such as a static linking exception) with the compatibility of all the other bits of software you depend upon (Python, gstreamer, SDL, etc). The result is... complex to say the least, and sadly you need to get proper legal advice if you want the result to be usable by anyone else.
from what i understood its impossible to do a good jit for ctypes and ctypes generates lots of gc pressure **citation needed**
&gt; need to get proper legal advice if you want the result to be usable by ~~anyone else~~ commercial entities with a lot to lose.
love microsoft eh ?
Me? Hell, no. I just mentioned those products because they are well known. At least Microsoft Kinetic is for sure but maybe not Surface, that old fancy coffee table that you can't find anywhere :D
I have a raspberry pi (http://www.raspberrypi.org/). I'm very interested to know if kivy can be built on the RPi using it's opengl-es libraries. At the moment, X is dog-slow on the RPi due to no graphics acceleration whatsoever and a fairly weedy cpu. Kivy looks like a nice basis for building an interface while taking advantage of the gl-es acceleration on the RPI.
How complete is iOS support? Did you guys port the entire Python standard library to it?
Interesting. Any plans for python3 support? I was going to give this a go for some interface work i ned done for a small program but its in python 3, so no go =/ also, looking through the api, i see a lot of 'these are experimental and might change!" messages on the provided for you widgets.... is this meant more for custom UI's then actual desktop programming?
No Python 3 planned yet. Some of our dependencies are not compatible with it. But anyone who will give a shot will be welcome :) About our widgets, some are put in experimental because we always doubt if the approach is ok, and if it's ok for production. I should give a new pass to remove that warning.
yeah, its chicken and the egg problem with a lot of things. So, is this meant for game UIs or 'novel' desktop UIs? (like metro or something), I'm not really understanding what the use case is here
Oh my. I had not thought about the effect small integer caching would have on the timing of `ord()` calls to unicode strings. Have to go make sure I haven't used a timing-independant comparison function at a point that could be affected by that. That said, not sure if I immediately see why encoding everything to UTF-8 bytes wouldn't fix that problem, if the attacker can only affect the charset of one of the two arguments. (As always, it's both fun and disturbing to see the stdlib getting made, much like sausage and government. my thanks to the folks who are keeping it going so well).
Links to presentation files: * [Chaco (PDF)](https://github.com/enthought/pygotham/blob/master/chaco/chaco_talk.pdf?raw=true) -- interactive graphing library * [Clyther (PPTX)](https://github.com/enthought/pygotham/blob/master/clyther/Clyther_PyGotham.pptx?raw=true) -- OpenCL in Python * [Data analysis in Python (PDF)](https://github.com/enthought/pygotham/blob/master/data_analysis_with_python/slides/data_analysis_with_python.pdf?raw=true) -- a specific problem &amp; solution walk-through * [Disco (PDF)](https://github.com/enthought/pygotham/blob/master/disco/pygotham-disco.pdf?raw=true) -- MapReduce framework * [EnaML (PDF](https://github.com/enthought/pygotham/blob/master/enaml/EnamlPyGothamTalk.pdf?raw=true) -- great new UI markup language
I'm curious; how does this improve over the daemonize package in pypi?
Gar, i can't change the size of the window! Though shall use fluid layouts and not disable maximize on my windows!
**edit: forgot to answer the last question** Tutor is probably a better word than teach, I’m not a school teacher, just someone who volunteers (okay, they pay me now, but I’m not doing it for the money) to try and make the world a better place. &gt; High school students? Yes, about 15 enthusiastic students, mostly juniors. &gt; I wish I could have had a computer programming class. This is exactly my motivation for doing it: when I was in high school, we had a pretty crappy curriculum: Year 7 was basically "how to use MS Office", nothing in Year 8, and then some okay but obviously outdated subjects in 9–10 and 11–12. When you started programming (QBasic!) in Year 5 for fun, it doesn’t take long to realise that drawing flowcharts for every program you write is rather pointless. &gt; Is it a Python class or is Python just a section of a more general class? I basically want to teach them Python (so they can write cool &amp; useful programs) and CompSci (to give them an idea that you can tackle harder problems, and also promote studying at a tertiary level). Python stuff (roughly in order): print, raw_input, strings, ints, floats, if/elif/else, lists, for, while, dictionaries, import, functions. CompSci stuff: searching (linear + binary), sorting (bubble, insertion, selection, quick, merge), and with the more capable kids, trees and graphs. I’m sure they won’t retain much of the CompSci stuff (it’s can be a little too abstract for them), but I hope that they at least remember that this stuff exists. And of course, you get some prodigies who just suck it all up! &gt; What is the most involved program/project the students do with Python? At the moment, they’re writing some games: Noughts and Crosses, Scissors-Paper-Rock (where the computer chooses randomly!), text adventure games, Connect 4, and the like. I’ve also previously done a thing where they write an AI for [Snake](https://en.wikipedia.org/wiki/Snake_(video_game)): I built a pyglet application, and they write a function which takes in the current state of the board and their position, and returns one of 'L', 'U', 'D', 'R' to determine where to move. **Related plug**: if you’re a high school student in Australia interesting in learning programming, go register for the [NCSS Challenge](http://challenge.ncss.edu.au/): it’s run by a bunch of friendly people who want to help you learn Python!
I guess this guy would appreciate any corrections. :) I have been told he writes as badly in his native tongue as in english. 
haha. i'd definitely have used someone elses if it did what i needed :) 
You don't even mention the parts I use: docs.python.org almost exclusively with occasional visits to pypi.python.org/pypi/. The single ***worst*** thing about python.org is the completely lame search box in the docs. Go into it with almost any search and you will either get no result or you will get voluminous irrelevant results. Demonstration: you want to remember how to specify the encoding of a file. Search on the two-word string *file encoding* and you get the voluminous irrelevant result of finding all instances of "file" and all instances of encoding. To put salt in the wound, note that these are sequenced by dictionary order of the section number (1, 10, 11, 11.1...) which means you will scroll a hell of a long ways before you see anything from section 5, 8 or 9 where the real info is. Now put quotes around the search string: *"file encoding"* -- you get zero results. Do whatever you want with the main pages, but please don't neglect docs. 
IDLE. Trying to get anything installed on their school computers is a PITA: there's no automation of software installs, so just getting the same version (aka, 2.x) of Python on it is a difficult enough task in itself. When I learnt Python, my path was IDLE, PyDev (Eclipse), vim.
The issues you have are with Sphinx and I'm 99% sure they won't be addressed by what Massimo is planning to work on.
Ooops! I had put the same question on stackoverflow, and got no answer, so posted here, just copied and pasted, and I htink something went wrong withthe copy! *removed it now - Thanks.
It's easy enough to sanitize for a lot of the potential execution paths if your know what you intend to find in your pickled data. For instance it is easy to introspect the deserialized data using hastattr, isinstance and just del any unexpected objects with __call__ or not matching a known object profile. The only time that pickle becomes dangerous is when it is used in such a way as to allow objects to become dangerous to the scope of the function that has deserialized the data.
But the kind of attack I mention above bypasses *every* means of sanitation. User data going through the pickling process isn't the attack vector, instead it's modifying the pickled state itself. Getting there requires a bug, or a misconfiguration at least, but it's not a terribly uncommon bug, and needn't even be in your own code. What pickling does is transform a very weak attack into one that can be fully escalated into remote code execution. Like I said, "Secure so long as there are no bugs" is not the goal we should aim for - we need layered security so that even when something goes wrong, the damage a component can do is minimised to the level of only the operations that component actually needs to do its job.
Disco looks very interesting, especially since the presentation touches topics that I'm about to tackle...
Not any better than the official documentation...
For fun, using a decorate/sort/undecorate sort of pattern: sorted_keys = [k for claimid, k in sorted(v['CLAIMID'], k for k, v in mydict.iteritems())] (edit: removed v from the decorated tuple, not needed)
I like web2py mainly because it has great [documentation](http://web2py.com/book) but it also seems to have all you need. It's easy to automatically run commands on application start, or other scheduled times, which you could use to sync the servers when reconnecting. It includes various template languages for users to easily develop documents with like markmin, sanitized html, etc. It has tons of helpers to make form and other interfaces development easy and fast. Do note: "The ability to work with CSV and/or Excel files to import lists." Any python framework will do for this, because there are tons of python modules to do this including in the standard library for CSV.
The main reason why it would not fix the problem is "did you read all the C code involved in the process and made sure it's not time-dependent"? I tried and I kind of failed even for the ascii function. In fact I spent quite some time doing the same with pypy looking at (optimized) JIT traces. I claim there are timing attacks even in the ascii-only function just because noone made sure there aren't.
Have you tried Geany?
South already has great documentation - so, why not make poor documentation to replace it?! Yes, I think that will be great.
As Brian stated below, it is my understanding that is not part of the RFP.
Really good advice. Thanks.
Ill make it re-sizable asap. (Forgot my password for the main account, and had no email for it, and now i cant recover it :( omgwtfbbq) EDIT: its a little bit more challenging than i thought. 
looks like a worst case combination of python with concepts of concatenative languages
That depends on where the character originally comes from. If it's from some binary data or other nonsensical string, it shouldn't matter too much. If it's from a text of natural language, yes, the average performance should increase, although the optimal order will depend on the language.
Nice. The performance seems to be on par with frozenset.
Thanks for the feedback. There's an on-going [Call for Syntax](https://github.com/ikotler/pythonect/wiki/Call-For-Syntax) - I'd love to see your proposal
I haven't heard of it; it has never appeared in Google searches. I can check it out.
here's another solution for you: `not (ord('A') &amp; 32)` C:\Python27&gt;python.exe -m timeit -s "" "not (ord('A') &amp; 32)" 10000000 loops, best of 3: 0.0586 usec per loop C:\Python27&gt;python.exe -m timeit -s "caps=frozenset('ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "'A' in caps" 10000000 loops, best of 3: 0.0296 usec per hmm.. still slower than frozenset, and doesn't work for unicode either. I think in a compiled language this method could be faster though..
Code to reproduce: replace 'X' with the character of your choice. Repeat for a few different characters (e.g. 'A', 'M', 'Z' for begin/middle/end of alphabet) And yes, as I said, I have not tested lowercase. This expectation is purely based on my understanding of how the algorithms in question are written. I have looked in the CPython sourcecode at how the string/list search is implemented. The ord &amp; 0x20 solution is faulty, that'll be true on all sorts of characters (such as space). 
Or, if you're already sure it's an alphabetical character, just "bool(32 &amp; ord('X'))" (I have Python 2.3 here, though; not sure how to time that).
Thanks, I was already wondering how PyPy would perform! In advance, I expected the first two solutions to be fastest. Apparently CPython's overhead of everything being an object and comparisons running through \_\_le\_\_ and such makes hashing faster than comparison.
For natural language, certainly. My personal use case involves an ascii encoded custom format, so I guess I would have to create a character frequency table then from sample data.
 import string "A" in string.ascii_uppercase Actually not the fastest, but you don't have to type the whole alphabet out. :p
there is also ide2py: http://code.google.com/p/rad2py/wiki/ScreenShots
Good catch. Updated.
Added!
Note that all results are usec, which is an ascii representation of μsec, which is microseconds.
I'm writing a parser for SGF (Smart Game Format) http://www.red-bean.com/sgf/sgf4.html#ebnf-def The format uses identifiers (PropIdent) that are supposed to be all uppercase ascii.
This is actually the solution I used in my specific use case, because although it is not the fastest, it is the most readable. :)
If you use a regex often you should compile it, which give it a speed boost: $ python -m timeit -s "import re; e=re.compile(r'[A-Z]')" "e.match('X')" 1000000 loops, best of 3: 0.275 usec per loop $ python -m timeit -s "import re" "re.match(r'[A-Z]', 'X')" 1000000 loops, best of 3: 0.893 usec per loop 
I didn't because Python is supposed to cache previously used regular expressions. So much for assumptions :) Interestingly, if I use re.match(e, 'X') instead of e.match('X'), it is *not* faster...
First of all I think using Python and then doing micro optimization is a bit retarded. I believe your attitude is compatible with Google overall. Most of what they do they are interested in high level languages and more into algorithmic part of programming. Yes there are some projects like for example their core search engine is in C, but then only selected few have even access to the code in the first place. Anyway, I have opposite attitude to yours, I like to keep my code optimized by knowing how the underline architecture works, I'm not so much interested in high level programming and I know that Google is not a good fit for me. Based on what you wrote I don't think you should worry that you don't fit them.
Hm... Star-Imports and Old-Style-Sginal / Slot Usage! Perhaps you should change that ;-)
Another funny bit is that if you do two separate comparison instead of one, it's actually faster: $ python -m timeit -s "" "'A' &lt;= 'X' and 'X' &lt;= 'Z'" 10000000 loops, best of 3: 0.0592 usec per loop $ python -m timeit -s "" "'A' &lt;= 'X' &lt;= 'Z'" 10000000 loops, best of 3: 0.0955 usec per loop But not if you use ord : $ python -m timeit -s "" "65 &lt;= ord('X') and ord('X') &lt;= 90" 10000000 loops, best of 3: 0.111 usec per loop $ python -m timeit -s "" "65 &lt;= ord('X') &lt;= 90" 10000000 loops, best of 3: 0.0919 usec per loop 
I highly doubt that, actually. The frequency of letters in code is, I'm sure, VERY different than the frequency in a novel.
websockets?
I'm not entirely opposed to using PyQt but I've just heard Qt can be bloaty. I remember seeing demo applications with advanced widgets but I wasn't sure how easy it would be to extend widgets and add animations to them. OpenGL isn't required but I was just describing a hypothetical cross-platform framework for clarification.
This solution, using defaultdict, seems to beat the frozenset and the dict solution on my computer. $ python -m timeit -s "from collections import defaultdict;caps=defaultdict(lambda: False); [caps.__setitem__(x, True) for x in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']" "caps['x']" 10000000 loops, best of 3: 0.0395 usec per loop Here are the frozenset and dict programs running on my pc: $ python -m timeit -s "caps=frozenset('ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "'X' in caps" 10000000 loops, best of 3: 0.0433 usec per loop $ python -m timeit -s "caps = dict((c, True) for c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "'X' in caps" 10000000 loops, best of 3: 0.0416 usec per loop **EDIT:** Testing some randomized code yields different results: $ python -m timeit -s "from random import choice; from collections import defaultdict;caps=defaultdict(lambda: False); [caps.__setitem__(x, True) for x in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']" "caps[choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')]" 1000000 loops, best of 3: 0.565 usec per loop $ python -m timeit -s "from random import choice; caps = dict((c, True) for c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ') in caps" 1000000 loops, best of 3: 0.541 usec per loop $ python -m timeit -s "from random import choice; caps=frozenset('ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ') in caps" 1000000 loops, best of 3: 0.51 usec per loop 
You should take a look at: * [Clutter](https://clutter-project.org/) * [Kivy](http://kivy.org/) * [libavg](https://www.libavg.de/site/) A good place to watch: http://wiki.python.org/moin/GuiProgramming
Semi related to this thread I was wondering if one wanted to make a GUI application with python what are the best tools? I just started a GUI application and am using PySide along with the Qt Designer. Whoever downvoted me... why? 
&gt; The ord &amp; 0x20 solution is faulty, that'll be true on all sorts of characters (such as space). The point was that it a) passes all the tests you posted and b) you never specified what the output should be for space, etc and so I was making use of undefined behaviour.
Wow, I didn't even think about units, I thought that since timeit switches to nanoseconds, it's faster. I ran some more and my ``True`` is around 50 nanoseconds, while ``0`` is around 22 nanoseconds. This is CPython, not Pypy, mind you, and is indeed slower than the uppercase example on my machine. I realized the irrelevance of my comment and ran the same things in pypy: $ pypy/pypy -m timeit -s "" "True" 1000000000 loops, best of 3: 0.00113 usec per loop $ pypy/pypy -m timeit -s "" "0" 1000000000 loops, best of 3: 0.00115 usec per loop $ pypy/pypy -m timeit -s "" "'A' &lt;= 'X' &lt;= 'Z'" 1000000000 loops, best of 3: 0.00114 usec per loop $ pypy/pypy -m timeit -s "import random; c = random.choice('ABC')" "'A' &lt;= c &lt;= 'Z'" 100000000 loops, best of 3: 0.00323 usec per loop $ pypy/pypy -m timeit -s "import random; c = random.choice('Aa')" "'A' &lt;= c &lt;= 'Z'" 100000000 loops, best of 3: 0.00316 usec per loop The last two are there to see just how far the optimization goes (ie, if you really knew that `c` is randomly chosen from a list of uppercase letters, you could optimize it away to `True`, but that's unreasonable). The lesson here is, make sure your benchmark benches the right thing!
Well, probably not bloaty, but huge :-) ... the learning curve is steep, but once you've mastered it, almost everything can be done quite easily (animations, custom widgets, opengl integration, stylesheets, ...). If the other suggestions like Kivy meet your needs, you're probably faster up and running with them. But if you should have the need to go further with UI development of desktop apps, PyQt/PySide is the way to go. Performance is awesome, by the way.
The first sentence addresses the reason why he mentions Google... the same and only sentence he 'mentioned' Google as well.
Yes, optimization is only for when the puzzle needs some speed-ups. The squeaky wheel gets the grease. And Google is no different. No one needs to optimize all the little details if it works fine already. But if you are in this situation and the program hangs or you need the UI to run smooth when it's not, then you're going to need to tough it out for the job. j_lyf, it's like any other programming puzzle in that regard.
I specified that I want to determine whether a character is an uppercase ascii character. Space is not an uppercase ascii character, therefore it should return false.
PyQt is more mature and more optimized (i.e. slightly faster). Also, it "invented" all the Python-specific features you'll find in 4.x bindings, like the "new" signal/slot connections, which PySide adopted later, so there's always a bit of a catch-up effort for PySide. Also, Riverbank is a small and solid company which basically lives on PyQt and related tools. PySide was a Nokia project from the days when their strategy revolved around "Qt everywhere", so its future is quite blurry at the moment.
I was under the impression that a majority of Google code is C++/Java. Python has a presence but it isn't nearly as large.
Let's check it out with the `dis` module. **Setup:** In [1]: import dis In [2]: test_two_str = lambda: 'A' &lt;= 'X' and 'X' &lt;= 'Z' In [3]: test_one_str = lambda: 'A' &lt;= 'X' &lt;= 'Z' In [4]: test_two_ord = lambda: 65 &lt;= ord('X') and ord('X') &lt;= 90 In [5]: test_one_ord = lambda: 65 &lt;= ord('X') &lt;= 90 Just to make sure they all work, let's verify them: In [6]: test_two_str(), test_one_str(), test_two_ord(), test_one_ord() Out[6]: (True, True, True, True) Now, let's break out `dis` and check out `'A' &lt;= 'X' and 'X' &lt;= 'Z'` first (7 opcodes) In [7]: dis.dis(test_two_str) 1 0 LOAD_CONST 1 ('A') 3 LOAD_CONST 2 ('X') 6 COMPARE_OP 1 (&lt;=) 9 JUMP_IF_FALSE_OR_POP 21 12 LOAD_CONST 2 ('X') 15 LOAD_CONST 3 ('Z') 18 COMPARE_OP 1 (&lt;=) &gt;&gt; 21 RETURN_VALUE Compared to `'A' &lt;= 'X' &lt;= 'Z'` In [8]: dis.dis(test_one_str) 1 0 LOAD_CONST 1 ('A') 3 LOAD_CONST 2 ('X') 6 DUP_TOP 7 ROT_THREE 8 COMPARE_OP 1 (&lt;=) 11 JUMP_IF_FALSE_OR_POP 21 14 LOAD_CONST 3 ('Z') 17 COMPARE_OP 1 (&lt;=) 20 RETURN_VALUE &gt;&gt; 21 ROT_TWO 22 POP_TOP 23 RETURN_VALUE The complex comparison ends up having to use the stack since it has to load three values, swapping them around to do the comparisons -- it ends up with two return points, too. Now, using the `ord()` pair, checking `65 &lt;= ord('X') and ord('X') &lt;= 90` In [9]: dis.dis(test_two_ord) 1 0 LOAD_CONST 1 (65) 3 LOAD_GLOBAL 0 (ord) 6 LOAD_CONST 2 ('X') 9 CALL_FUNCTION 1 12 COMPARE_OP 1 (&lt;=) 15 JUMP_IF_FALSE_OR_POP 33 18 LOAD_GLOBAL 0 (ord) 21 LOAD_CONST 2 ('X') 24 CALL_FUNCTION 1 27 LOAD_CONST 3 (90) 30 COMPARE_OP 1 (&lt;=) &gt;&gt; 33 RETURN_VALUE This is more complex than the other two because it's using a function call -- that's the `LOAD_GLOBAL` and `CALL_FUNCTION` opcodes. It has to call the function twice. If the first one failed, like we were testing `a` instead of `Z`, the second function wouldn't be called -- but the bytecode is still generated for them regardless. In [10]: dis.dis(test_one_ord) 1 0 LOAD_CONST 1 (65) 3 LOAD_GLOBAL 0 (ord) 6 LOAD_CONST 2 ('X') 9 CALL_FUNCTION 1 12 DUP_TOP 13 ROT_THREE 14 COMPARE_OP 1 (&lt;=) 17 JUMP_IF_FALSE_OR_POP 27 20 LOAD_CONST 3 (90) 23 COMPARE_OP 1 (&lt;=) 26 RETURN_VALUE &gt;&gt; 27 ROT_TWO 28 POP_TOP 29 RETURN_VALUE This one is quicker than the first one with `ord()` because it only calls the function once and stores it on the stack. `ord()` is very fast; so it ends up very close to the speed of #2, but still not as fast as the first one (mainly due to stack opcodes). It's a bit faster than the char-based #2 because comparing integers is faster than comparing characters: python -m timeit -s "" "1 &lt; 2" 10000000 loops, best of 3: 0.039 usec per loop python -m timeit -s "" "'a' &lt; 'b'" 10000000 loops, best of 3: 0.0489 usec per loop 
that is one thing that always seemed cumbersome to me was packaging. Granted I'm still in 2.x land but it seems far more difficult than it should be when I want to package up a simple script so it can be pip or easy_install'd. All the package libraries seems to be geared for and used more by libraries (which is good) but very few end-user scripts seem to use it. Don't know if packaging in 3.x is going to fix that but right now it's kinda messy.
ah. this would be great, cause those things are really hackish (putting pth files all over your library directory), things not working with one or the other, so i'm glad they are trying to fix this
You are correct, sir. Would using "QueryPerformanceCounter()" make sense for Windows systems? It looks like a monotonic clock...
So, can I just get the materials online and pick through this myself?
i do not think it will work out nicely with some larger changes python has a imperative bias, the concatenative concepts that can express flow seem very foreign when they are just mixed with normal python syntax if you don't already have, i'd suggest learning factor - it has a strong bias on data flow and might help as inspiration
The only problem with Kivy is that it doesn't support old OS'es (read: actively used by businesses) like WinXP. Otherwise, a great framework to look out for.
Ooh, didn't know bool had a default value. Python built-ins just get cooler and cooler.
If everything uses random.choice, the overhead shouldn't matter.
`.isupper()` or you're wasting your time.
str.isupper() may return true for non ascii characters like Ä, e.g: &gt;&gt;&gt; u'Ä'.isupper() True So it is not correct for the original question.
You can use WPF with IronPython.
With random.choice, all the results are close together, because the loop spends most of its time generating random numbers. So instead of one result being 5x faster than another, it might now be 10% faster. Unless you find a way to factor out the time spent doing random number generation, you no longer get any clear idea of relative performance.
Scumbag Submitter: Knows course is 16th to 21st. Submits link to course on 20th. 
I just learned yesterday that all of the course materials are free and up on the web. Sorry. Better than nothing eh? I think there will be a video, but I bet it will be buried in some IEEE website. The talk is following the slides pretty closely. 
Triggered by a comment by kosievdmerwe, I tried a looping approach through all ascii codepoints: $ python -m timeit -s "chars = [chr(x) for x in range(128)]" "for ch in chars: 'A' &lt;= ch &lt;= 'Z'" 100000 loops, best of 3: 14.2 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]" "for ch in chars: 'A' &lt;= ch and ch &lt;= 'Z'" 100000 loops, best of 3: 11.6 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]" "for ch in chars: 65 &lt;= ord(ch) &lt;= 90" 100000 loops, best of 3: 17.9 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]" "for ch in chars: 65 &lt;= ord(ch) and ord(ch) &lt;= 90" 100000 loops, best of 3: 19.9 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]; iscap = [65 &lt;= i &lt;= 90 for i in range(128)]" "for ch in chars: iscap[ord(ch)]" 100000 loops, best of 3: 13.7 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]" "for ch in chars: ch.isupper()" 100000 loops, best of 3: 15.6 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]; caps = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'" "for ch in chars: ch in caps" 100000 loops, best of 3: 12.4 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]; caps = set('ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "for ch in chars: ch in caps" 100000 loops, best of 3: 8.34 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]; caps = frozenset('ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "for ch in chars: ch in caps" 100000 loops, best of 3: 8.11 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]; caps = dict.fromkeys('ABCDEFGHIJKLMNOPQRSTUVWXYZ', 1)" "for ch in chars: ch in caps" 100000 loops, best of 3: 7.95 usec per loop $ python -m timeit -s "chars = [chr(x) for x in range(128)]; caps = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')" "for ch in chars: ch in caps" 10000 loops, best of 3: 75.6 usec per loop $ python -m timeit -s "import re; chars = [chr(x) for x in range(128)]; e = re.compile(r'[A-Z]')" "for ch in chars: e.match('X')" 10000 loops, best of 3: 66.8 usec per loop $ python -m timeit -s "import re; chars = [chr(x) for x in range(128)]; " "for ch in chars: re.match(r'[A-Z]', ch)" 1000 loops, best of 3: 229 usec per loop 
cx_Freeze - like py2exe but supports Python 3: http://cx-freeze.sourceforge.net/ EDIT: cx_Freeze collects all the files you need to run a program, and makes an exe to start it. You can distribute them in a zip file, or it can make an MSI installer for you. It doesn't have a single-file exe mode, though.
It's what I did for [http://pypi.python.org/pypi/timer](http://pypi.python.org/pypi/timer) (I couldn't tell you how great that library is or any super great details about clocks...I just wrote it one day while reading about QPC and I was on a C-extension kick.)
Gmane link: http://thread.gmane.org/gmane.comp.python.devel/133585 (slightly easier to follow)
Just learn how to use Sphinx and it'll enforce some basic requirements of function documentation on you so that there's a consistent set of documentation to go along with your modules.
I just put a docstring under each declaration explaining each argument and the return value/change to object/whatever it is said function does. The @param thing makes shit look like java and the ugly confuses my poor brain, so I generally just do one argument per line unless it's extremely extremely obvious (def make_list_from_dict_keys(inputdict):, or something idiotic like that). 
Agreed. Check out flask for a good example of sphinx documentation.
I [ran](http://www.reddit.com/r/Python/comments/vbqxi/fastest_way_to_find_out_whether_a_character_is_an/c53qd1f) terminator's loop version through pypy for comparison, and it does optimise the compares pretty well, though there is now a noticable difference between the straight string compares and the versions that convert to a number with `ord` first (about twice as fast).
There is a PyQt Itunes style carousel widget available as part of Calibre, but I think it has to be compiled to run. http://calibre-ebook.com/
Great! Many thanks!
How is this a shame? Sphinx is an open source project that thousands of projects use so I don't know why it would be included in the scope of a website rebuild. It's not under the control of the PSF anyway, and the PSF isn't going to be paying to fix another project when the main website is the focus.
I heard there was a cx_Freeze hack somewhere that merged all the files into one executable
Easy solution: set a timer on all authentications that is based on smething like 99th percentile response times for the code path.
PyCharm was recommended to me by a guy at work. I think it's the leading contender right now. I've also seen IronPython come up a few times, but don't really know what it is.
I use Notepad++ with a few Python plugins. I used to just use IDLE but I got sick of the lack of line numbering, lack of line indentation markers, not being able to collapse functions etc. Notepad++ is great if you just want a nice simple text editor. The plugins I use for it are: PyNPP, Python Indent and Python Script. They're all available inside the program from the plugin library.
I've never seen a programming language Notepad++ can't program in, and its themes are *beautiful*. http://imgur.com/a/ORgpn
&gt;I used to just use IDLE but I got sick of the lack of line numbering, lack of line indentation markers, not being able to collapse functions etc. Notepad++ is great if you just want a nice simple text editor. This was my experience too.
What makes you use WingIDE? It looks really polished but I've never heard of it. Where'd you you hear about it and why do you like it?
whatever editor you already know. bear in mind nothing is going to have the level of autoblahblahblah that VS has for C#.
IronPython isn't an IDE, it's an alternative Python interpreter running on the .NET framework. There's [Python Tools for Visual Studio](http://pytools.codeplex.com/) for IDE functionality.
IDLE isn't supposed to impress expert programmers - there are far more powerful IDEs. IDLE makes it easy for new programmers to write and run code, without lots of advanced functionality to confuse them.
Eclipse with PyDev works great for me. It has pylint integration too, one feature that I haven't seen from other IDEs.
I've used successfully pyinstaller when cx-freeze and py2exe didn't work.
Haven't used and don't know if it'll work for you but Enthought had a 3d project called Mayavi. Not even sure if it's current but it's something. Good luck. 
oh my god...I must make sure never to tell anyone about that feature b/c then i'd have to fix their broken code. i left perl for python, time to switch to fortran where you can do almost nothing, but at least you cant do THAT!
I finally settled on [Aptana Studio](http://aptana.com/) (essentially Eclipse with PyDev baked in, and a bunch of other stuff I don't use), and I've been really happy with it.
lol. been there, done that. it's like learning freshman calc in college. the point is to only have to do it once to "learn". :P
"Seasoned" programmer here. I run a Linux machine so you being an obvious Windows user may not have the same experience (unless you're willing to switch :) ). PyCharm: using this almost exclusively for the past year. Likes: * VCS baked in * Support for setup.py (newest version) * Good file template support * Django support FTW * Keyboard shortcuts Dislikes: * A little heavy performance-wise * Keyboard shortcuts not vi unless you use the vi emulator (hate on plugins - hate, hate hate) vi: use vi/vim for everything from PHP to Perl to bash to script editing to LaTeX development Likes: * Highly configurable * Available on any box you have access to Dislikes: * Highly configurable - sometimes too many plugins can be a bad thing * Steep learning curve (see above) PyDev/Eclipse: Used this for a couple of months Likes: * Minimal configuration out of the box Dislikes: * Eclipse based, i.e.: memory hog (this was a couple of years ago, so maybe it's been fixed by now) Komodo Edit: Used this for about six months. This is the editor (and free) version of their full-fledged IDE Komodo. Likes: * Free, uses full-Komodo plugins * Fast Dislikes: * Not a lot of native functionality, might as well buy the full version (which is **expensive**)
Wing101, really neat for beginners doing small development
[pyinstaller](http://www.pyinstaller.org/), which you can also use to make linux and os x executables from the same code base.
Yep, IDLE is pretty terrible. It's basically notepad with a "run" hotkey.
The original question is wrong. In what world is Ä not uppercase?
There is no such elitism against Python. I have a masters degree in robotics system engineering, I can program C,C++,Java, Javascript and Python very well i would say. I have programmed robots, vision system, embedded system, virtual machines, AI algorithms etc. However the language I most enjoy developing in is by far Python. I am a lot more productive doing Python and if you know what you are doing you can really get some very flexible and elegant code. If other developers are hating Python it is because they have to spend 6 times as long doing the same thing in C++. I really wish I could find a Python job.
Detrimental to programmer productivity? Have you *seen* Scala?
I'm obviously talking broadly, with a focus on languages that generally cause people's big egos such as Java/C++. Whilst I agree that there can be statically compiled type-safe languages that are productive (I've absolutely become enamored with Go) I still think that the dynamic languages have an order of magnitude lead when it comes to productivity. 
OP asks for an IDE recommendation, gets recommended text editors. Interesting. Anyway, my personal preference is PyCharm as an IDE.
Fair enough that anyone who only knows Java and/or C++ and has an ego about it is likely to be a bad programmer. But I don't think static typing is entirely to blame, so much as the lack of type inference and polymorphic typing. Here's the triangle numbers under 100 in scala: scala&gt; Stream.from(1) map { x =&gt; x*(x+1)/2 } takeWhile { _ &lt; 100 } toArray res5: Array[Int] = Array(1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91) Now picture that in Java! Or python, for that matter... r = [] c = 1 def t(c): return c*(c+1)/2 while t(c) &lt; 100: r.append(t(c)) c += 1 print(r) ==&gt; [1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91] I'm sure there's a neater way to do it with generators, or map (ha!), but sometimes a statically typed language can actually be quite succinct :)
Emacs.
Once. They laugh *once*.
Hi, they've been putting up the talk videos lately, [Disco](http://blog.enthought.com/python/discomapreduce-pygotham-talk/) just today. Enjoy :)
Why make three identical functions (start, checkpoint, stop)? Why bother keeping all results in a global array and reallocating memory every 20 calls? Why not just returning floats?
Fuck the haters. Python 4evar. That's all. 
Given that I've never heard this and other posters say the same, this would seem to be just the people you know or the area you work in. I'd guess that you are working with people who learnt their skills twenty years and are scared that easier to use languages will make them obsolete. It's a defence mechanism.
Geany! It's all I've ever needed.
There's none on Reddit, but many, many other places on the internet mock it and mock Python programmers frequently. 4chan /g/ is a big one. Of course, these people usually either have never even written any Python and just scream "FORCED INDENTATION?!?!?!?!!?", or are otherwise completely ignorant. I've not seen any *professional* mockery of Python, personally, but there are tons of jabs from amateurs.
Mayavi should be up to date. It is built on top of vtk and includes a wrapper for vtk called tvtk that makes it easier to use (if you don't mind using Enthought's traits). I used to work for Enthought and worked on an application that used MRI images. We used mayavi/tvtk. 
There's [a PEP](http://www.python.org/dev/peps/pep-3142/) to have "while" included in list comprehensions and generator expressions. However, it appears to be in limbo.
Don't forget Stackless too (although I've never used it).
IMO it's not really a culture of "real" programmers only use static languages etc. it really depends on what you are trying to achieve and in some cases static languages are objectively better because they provide compile-time assurances and make it easier to reason about your program. I like Python but prefer statically-typed languages because all the type checking is done for me at compile-time. If you had a Python function with type constraints you would have to include code to check for it at run-time. Why not just let the compiler do it for you?
I don't know, but it's better than people who offer me condolences when I say I'm a perl programmer.
Agreed. However, HR has never learned that, and they're a huge influence on hiring us.
Language war using trivial numeric examples? No way it can proceed without some surprise haskell! takeWhile (&amp;lt; 100) [x*(x+1)/2 | x &amp;lt;- [1..]]
++vote for surprise Haskell. 
To be fair, if you're applying to work for a company with a large C++ codebase, it may not be *entirely* unreasonable.
i'd suggest the hate is driven by a lot of single-language, or single-paradigm half assed programmers that don't like having to deal with yet another language. in particular javascript and java programmers have more reason to dislike python than many others as it's a real pain to break out of their respective frameworks.
you accidentally an extra "r".
&gt; There's a culture in programming that [fill in just about anything] is 'better' or somehow much more [whatever] way to do stuff then [fill in just about anything else]. FTFY. Really. I got laughed at recently, because I "still use technology from the seventies", being my highly optimised vim and customised shell. I shrug and consider the one laughing to be puny and uninformed. Knowing that for about every possible pixel and combination of ones and zeros there is a holy war being fought out on the internet somewhere. But really. ZOMGWTFBBQ What is it with you guys and these spaces? Geez (Ruby dev here ;) ;). 
I'd definitely second this, writing python in sublime text 2 is lovely. 
Ignore them. Python is your secret weapon for getting stuff done better and faster than those colleagues, who are your competitors for jobs.
I generally dislike perl and Java and bitch about them frequently but was recruited fiercely recently by several companies. I of course admit that Java and perl have their uses and have even done some stuff in both languages, I just prefer not to use them if at all possible. 
I just finished going through [Learn Python the Hard Way](http://learnpythonthehardway.org/book/advice.html) and Zed Shaw's postfix was awesome and inspirational: "Which programming language you learn and use doesn't matter. Do not get sucked into the religion surrounding programming languages as that will only blind you to their true purpose of being your tool for doing interesting things."
C++ has had templates for a long time and recently C++11 introduced keywords like auto and declspec. 
What they don't realize is forced indentation is amazing to code organization, and while it may prove to be a PITA when you have to add a for loop in, it still helps to make code that much easier to read/write. These amateurs tend to be Lua kids who think that their language is so much better because its used for games. I don't think they see the fact that a lot of enterprise development is done in Java/Python/C++, and Lua is rarely found outside of their basement.
why the hell are you on 4chan in the first place? If you are taking derision from 4chan seriously, you've got bigger issues. back to the question at hand: python is awesomely legitimate as far as languages go. We use it for psychophysics experiments, data mining, and generally for just about anything that doesn't require top-notch performance (and even then, with numpy, that's often not a problem). It is used in applications everywhere for serious work. In fact, were it not for the fact that PHP had a first-mover advantage in webdev, python would probably be the go-to platform for web development today. in fact, usually the elitism is *from* pythoners, rather than against them. As Eric S. Raymond's famous article, ["Why Python"](http://www.linuxjournal.com/article/3882) states, there's good reason.
I work for a company that uses mostly Python and C++, with some projects written only in C++ (few), most of them in some combinations, some entirely in Python. Idea was that someone who knows C++ will learn Python quickly. I've seen people quit in their first week when they realized how much time they would spend in Python. Actually, in a company that works like this, you get a lot of rubbish hacked-together Python code written by the beginners (fresh graduates with no python experience), so it's not very nice (though it works). It gets better by the time. But still, you get more respect with C++. And even for me it was quite funny to see a grown man typing some Python code with a serious expression on his face. 
There are many, many things I like about javascript, and then there's scoping.
The memory foot print of eclipse + pydev has decreased drastically in the past 2 years. 
I've been a programming professional since '79 and during the last 7 years I have specialized in python-based web frameworks (mostly Django but most recently Flask.) I agree with this post but have a few quibbles: -- understanding O(n) notation comes up more in interview rooms than is real life. Having said that, designing scalable systems is a nice skill to have for those times when you latch onto a successful project that needs to scale. -- understanding functional languages is not generally useful for web-apps. Understanding javascript, on the other hand, is vital. -- 'Design Patterns' should really be better known as 'workarounds for Java'. There are some useful ideas here, but knowing these ideas are available so you can look them up when you need them is perfectly adequate. -- SQL knowledge is becoming less and less important as ORMs improve and NoSQL options mature, but I would still treat it as fundamental knowledge for a real programmer at this point in time. Do not skate on this one. At this point is perfectly fine to base your career on python as long as you are expansive about it. Don't get stuck with only one web framework. Learn the most import extensions modules and associated technologies thoroughly: python standard libs; rabbit/celery; javascript/jquery; HTML5; WSGI; cloud APIs; Fabric and/or other deployment automation tools; continuous integration tools. There is a lot to master! 
I remember my first encounter with a coworker who dogged python. I was in school at the time and we got on the subject of python being my primary focus. I was in IT and he was a dev. He looked at me crazy and said that my first language shouldn't be python because then ill always be a python programmer and nothing else. Thinking about it now I realize he was probably talking about python being loosely typed and he only used strongly typed languages. I did however learn java at the same time which was useful because I learned the differences between the two.
I am still searching for an IDE but have recently dumped Note Pad ++ for coding in favor of Free Komodo Edit
I'll have to remember this thread next time someone takes a jab at VB or .net stuff ;-) The point stands though. Languages are just tools for communication. Some are more effecient than others, but I suspect in most cases your design of a solution will affect the effeciency far more than a certain choice of language. 
Yall bought into a link-bait title.
I absolutely love Pycharm as well but I also would like to recommend another tool I spend a lot of time working with especially when using a module I'm unfamiliar with. Ipython console is a great tool to have because it is like the regular python console but has a ton of cool builtin features including code completion. The console aspect of Python is such a powerful way to test out little snippets a code and get immediate feedback. Ipython just stepped their console up a notch by adding a notebook component to their console which loads the console in the web browser and lets you create "code blocks" that you can add reload whenever you make changes. It's hard to explain so here is a video about it here. http://pyvideo.org/video/640/ipython-python-at-your-fingertips You may find it handy to check out ipython because tackling a new IDE and language at once can be a lot to bite off at once imho. At this point I probably sound like an Ipython salesman, I am not I just really like it :) 
This is my point exactly. There are languages aimed at certain things and there are languages where they fall down in certain areas. I myself prefer to prototype in languages like Python and move to something static when my head can't easily fit it all in. This way, the compiler takes the burden of basic sanity checking (like you mentioned, the typing of function arguments).
And I love that in Go, concurrency is syntax (&lt;-ch&lt;-). It's a really lovely language to work with.
I'm an Emacs user myself, so I totally know where you're coming from. I think there's a fundamental divide between people who see programming as a job, nothing more than a way to punch a clock and collect a paycheck and there are those that tinker and play and push all the way through life and getting paid for it is merely a side-effect. Those who are just plodding through are often those that stick to the answer on the first hit on google and never go any further than that.
I see "I am a python programmer" as a bit of pre-emptive optimization. He is stating he is a programmer, while also answering the possibly next most obvious query about the technology he's most familiar with.
In my workflow, I usually track my own projects with a git link in my PIP requirements file. I reckon I could start submitting to the Cheeseshop if people were interested.
I think some accountants actually enjoy their jobs.
Because if you only consider yourself a python programmer, you're not a good programmer. A good programmer would code in more than one language.
Depends who's laughing. 
Yes, when it's done properly. compare Groovy and PHP (I work with PHP, but I love Groovy)
correct me if I'm wrong, but there is no scoping (at least for class members) in python. and x = 0 def foo(): print x or var x = 0; function foo() { console.log(x); } behave the same. def foo(): x =0 print x or function foo() { var x = 0; } console.log(x); behave the same. so *shrug*
sigh If you want to help, check out the Python-dev thread where this is being hashed out ad-infinitum rather than flamed to death: http://mail.python.org/pipermail/python-dev/2012-June/120430.html - for the tl;dr crowd - yeah, things have problems, want to fix.
They are also apparently not so swell at detecting people who know the difference between "worse" and "worst".
I enjoy programming in Java (if only with a decent IDE because it IS verbose). And I hate php/javascript even though I get payed for it. That being said I wish I had the time to step up my python experience. :)
They are not laughing at python, they are laughing at the fact that you call yourself a "web programmer."
&gt;What people forget is that; the aforementioned languages, whilst granting enormous speed benefits, are detrimental to programmer productivity. I'm really surprised you mention Go in your response, because I went from Python to Go and I feel just as productive. What extra time I spend writing my code to be more precise I save in a great reduction in the amount of time I spend debugging my Go code as opposed to my Python code. My current Go project is nearing 6k lines and the massive improvement in stability I'm finding in Go over Python is making me far more productive in Go than I was when coding Python projects of this size. The reality is that I program Go because it makes me *more* productive, over the lifetime of the project, than I was in Python. The speed thing is just a bonus. of course, I've had to reinvent a lot of wheels along the way, but that's symptomatic of new languages in general because the ecosystem is just barely pupating.
I'm sorry, but I'm not a native speaker, so I may make some grammar mistakes once in a while. But thank you for pointing it out. I corrected my mistake. Just try to be more polite next time.
I use [PyScripter](http://code.google.com/p/pyscripter/) for IDE and [Dreampie](http://dreampie.sourceforge.net/) for the shell. Both are free and open source. Pyscripter is exclusively for Windows and has a 64-bit version if that's the Python interpreter you prefer.
It's almost like Python is the new *Visual Basic*, isn't it?
I think you've struck something there. The reason that Python (and the others you mentioned) may also get looked down on is the fact that it's very easy to get caught in an abstraction loop whereupon you're no longer even interacting with a computer but you're making gigantically abstracted concepts which have no logical underpinning to the workings of the bare machine. Maybe that's why people closer to the metal may seem hostile to their high-level language friends; simply because they feel that they are missing out on a large portion of key knowledge?
Maybe it's not that you're a python programmer. Do you have a silly looking face?
Another vote for Pycharm. Just recently started using it, and am perfectly happy with its performance (3.4ghz iMac w/16G RAM).
&gt;Go is essentially static Python when all is said and done. most of the time. The error handling is way different, and concurrency is sooooo much better, and the reflection is way more cumbersome. However, function literals in Go are REAL closures, not that half-assed shit you get with Python's crappy lambda support. Struct literals (anonymous struct definitions) combined with type inference allow you to do some nifty things that you couldn't do in other statically typed languages. &gt; I can feel safe in the knowledge that my cavalier attitude to types and errors with Python (and the nuanced Go approach to exceptions) will be saved with the compile time checks. this is definitely true, but the one gotcha is the following: func Whatever() error { ... // doesn't matter } func main() { Whatever() // whoops, you ignored the error value; something awful will probably happen at runtime. } it's definitely got some warts, but I've found them to be worthwhile. I started programming it last fall and I'm using it full time now. I'm using it to write a json server for a mobile startup, and, in the process, basically writing my own framework. Problem is, it's still really unstable and I change the API regularly as I improve as a Go programmer. When I feel that it's stable enough to be used comfortably by others, I will release it and put up an announcement on /r/golang (which I recommend subscribing to). The single best learning resource I've found is the #go-nuts channel on Freenode. There's a handful of people that hang out there regularly, and it's a very helpful little community. Other than that, I typically learn by reading the source to the standard library and the following libraries that I've used on my projects: * [mgo](http://launchpad.net/mgo), the MongoDB drive by Gustavo Niemeyer. Gustavo is probably the most prolific non-googler programming Go. He's employed by Canonical, where he works on a variety of open source Go projects. * google's websocket library: code.google.com/go.net/p/websocket * google's go-graphics library: code.google.com//p/graphics-go/graphics * [blackfriday](https://github.com/russross/blackfriday), a markdown processor for Go. I haven't actually used this since the release of Go1, so YMMV on that one. Other well-known projects that I can't personally comment on: * [web.go](https://github.com/hoisie/web) - a web framework that doesn't seem to offer a lot that the standard library doesn't already do. * [gorilla web toolkit](http://code.google.com/p/gorilla/) - a set of webserver tools that seem to be the most widely used, that I haven't tried. * [falcore](https://github.com/ngmoco/falcore) - a framework by ngmoco that is structured almost exactly how I structure my own application. I took a lot of design queues from their high-level concept, but I don't use it because, in all honesty, I tried to and I couldn't understand how to use it. * [vitess](http://code.google.com/p/vitess/) - Google's MySQL front end. This actually sits in front of the MySQL cluster for YouTube, so some portion of YouTube trafic is handled by Go (not sure how much, never looked into it). * [doozerd](https://github.com/ha/doozerd) - a distributed data store that was written at Heroku. I haven't tried this yet, but I plan to. This is probably the single most substantial standalone project that didn't come from Google (mgo not being standalone since it's useless without mongo itself). Other than that, I use the net/http package in the standard library a LOT. I have primitive API consumers for a few social networks, but they're not really stable and I've only implemented the endpoints that I'm using. I'm [jordanorelli](http://github.com/jordanorelli) on Github, but I don't have much worthwhile Go published yet, mostly because I'm too busy building features on my product to really polish the core libraries. Some people have been using it for years, so there are a handful of very experienced Go programmers, but, for the most part, the community is relatively young, so I've seen some SO answers are that are, simply put, bad advice. Programming Go means having to figure out a fair amount of stuff on your own, but the documentation is very good, and with the right attitude, it can be very fulfilling. I enjoy it very much, but I would only recommend it to people that understand what they're getting into and are excited by the idea of being in relatively uncharted waters and don't expect every problem to be solvable with a friendly single function call. Now, with that said, extracting parts of my application and turning them into standalone daemons that are controllable with RPC calls over network sockets was sooooo much easier in Go. Concurrency is sooooo much easier. There are certain things that are way, way better. You just have to take the good with the bad. Oh, and one thing that nobody told me, that's really poorly documented, is that you should always have this running: godoc -http=:6060 run that, and then visit `localhost:6060/pkg` to see the documentation for all of the packages you have installed. This is why Go will never rank high on the Tiobe index: Go comes with it's own http server for documentation, so nobody googles for the standard library documentation because we just all run the doc server locally. You can also find packages at the following places: * [go project dashboard](http://godashboard.appspot.com/) * [GoPkgDoc](http://go.pkgdoc.org/-/index) * [cat-v.org](http://go-lang.cat-v.org/pure-go-libs) ok, I think that's everything I know. 
What do they code in?
Thanks for all the advice. I've been using Go for around a week and a half all said and told. I've been through Gotour and the Effective Go, I also bought and read The Go Phrasebook, which is essentially Effective Go with some sugar. Hells yeah for http/net. I've implemented a small webserver which has the possibility to dispatch to different addresses and really super basic authentication. [Link to server](https://github.com/AeroNotix/qtsqlviewer/blob/master/settings_server/settings_server.go). I'm *really* happy with the balance that Go brings. Criticism welcome on the link. I looked at `web.go` first, because it seems like a relatively well put together framework and it's conceptually very similar to Django with how the URL dispatch works. I stopped using it once I had actually seen the `net/http` documentation and finding out that it was *considerably* slower than using the method I have above. I think we're doing relatively similar projects. My aim is to create a service which sits on top of a MySQL (and possibly more in the future) and dishes out access rights and serves metadata about tables. Which will then serve as a reference API to people wanting to make clients to it. So far writing that single module has been a blast. 
More like we have people "choosing the right hammer for the job" but that choice is predicated on a lack of knowledge and insight about the platform. I disagree with the idea that it's "simple" or that the code abstraction at the python is any more complex or abstract than some of the code running near the hardware. This isn't completely fair, but... Linux can fit inside of 4MB and run a similar size of RAM. Yet we see platforms that utilize GB of RAM and harddrive space and the general consensus is that the abstraction provides for better maintainable code, higher quality... at the cost of performance and size and understanding. Maybe all of that abstraction is just unnecessary for most things and programming with a statically or strongly typed language gives better understanding of the platform so you can produce the right hammer for the job. 
I usually just use vim, but lately I've started using [chocolatapp](http://chocolatapp.com) more (when doing flask/web stuff)
I met someone very recently who was commiserating with me and they scoffed about how the team wrote python scripts for feature X. I was blown away. This person probably prefers `bash`/`perl`/`csh`, so it's not a case of them preferring statically typed languages. There was a time around ~9-10 years ago where I thought Python was inferior because of its (apparent, at the time) lack of power/capability and (again, at the time) had a problem with Python's treatment of whitespace. I eventually gave it a fair shake and was an instant convert.
&gt; The biggest problem probably was that it was build on Python's idiotic import system but there is only so little you can do about that. What's wrong with Python's import system? I personally think it's great.
I do like the generators feature its very interesting. &gt;Probably the same reason frontend developers laugh at you when the see &gt;you use var one; var two; Really need to chill with the assumptions. Can you assume how my day is going to go? I need to know its not going to rain again today.
Zero comes before one. You must surely be one of these uninformed f1nboys. 
Ninja-IDE 2.0 will be released July 2nd
They're confusing it with Perl.
Same. I hear jokes at the expense of PHP, Java, .NET, C, C++, Ruby, Perl and Lisp programmers frequently; never Python.
Uhh, I am pretty sure he was using the word "you" in the non-specific sense of "other people in general", not making specific assumptions about *you*.
\o/
Not sure I agree. A great programmer can learn a language in a month to match an average programmer... Any career job has several months ramp-up before you're 100%, and within that time, a developer can have a rock-solid grasp of language X as well. Additionally, I can't think of any field where you're so heavily specialized *after* you have a specialized degree in that field. A 4-year degree and 10 years experience in the field are worthless if I'm applying for a C++ job? A good software engineer is worth more than a head-down language expert.
Oh my apologies, I read that wrong.
python has function level scoping _by default_. JS has global level scoping _by default_. some people insist on lexical scoping (which JS has but not by default), but that degenerates when you have closures (i have learnt this the hard way), which both languages have and they are great.
I presume you followed the link? In the first paragraph it says, "any version of Python since 2.2"
Can someone explain what this would be used for?
I hope you didn't sell your soul to Java. ;)
i'm glad you asked. no i did not :)
 class Foo(metaclass=FooMeta): def __init__(self, spam:int=42): self.spam = spam def __call__(self, a, b, *, c) -&gt; tuple: return a, b, c I haven't been working with 3.x at all, so I'm a little baffled by the type hinting, `*` param and return type hinting. Is that a part of 3.3 or this PEP?
&gt; logging for a long time was heavily underdocumented Well I thought it was fairly well documented, though the initial organisation of the docs was perhaps sub-optimal (because of the large amount of information; that's now been rectified with two tutorials and a cookbook in addition to the reference). Of course it's a matter of continuous improvement, and I'm generally quite responsive when specific gaps are mentioned (plus on e.g. Stack Overflow when logging questions are asked). &gt; many people tried to replace it due to a lack of understanding If by "replace it" you mean "use something else" then I wouldn't know how many people did that; if you mean "offer alternatives", then AFAIK there were you, Peter Fein and Zachary Voase. At least some of the motivation was aesthetic rather than related to functional concerns - "I don't like shared state", "it's not Pythonic enough" etc.
&gt; If by "replace it" you mean "use something else" then I wouldn't know how many people did that; I saw too much Python code that has its own logging modules.
Notepad++ is often recommended, but I would instead recommend [SciTE](http://www.scintilla.org/SciTE.html) which is built from the same core as Notepad++ but works better. It's easier to configure (just one text file with all the config, plus another one for each language), less buttons on screen and most important: there isn't a massive spacing between each row, which is what ruins notepad++.
&gt; Well, it's a simpler interface to the method signature, And what is the 'method signature'? I find the PEP surprisingly unclear in clarifying what a signature exactly is. 
Do you have a source for that?
Outdated information. For example --no-site-packages is by default now, and most people use virtualenvwrapper if they're working with several projects. Also, why would you use easy_install in your virtualenv when you have pip right there?
No, it would not be useful, for one thing, you can lie: &gt;&gt;&gt; def f(a:int): return a * 2 ... &gt;&gt;&gt; f("hello") 'hellohello' You can also pass random nonsense: &gt;&gt;&gt; def f(a : f): return a ... &gt;&gt;&gt; f(2) 2 &gt;&gt;&gt; f.__annotations__ {'a': &lt;function f at 0x7f34d85ff5a0&gt;} 
Are you the author?
I randomly opened the radar example and found something weird on line 24. I'm sorry to say this but that's ugly.
Interesting point. I agree, but it is that way for a reason. I used to "while not(done)" or "while done", but I found at the point in the class where I introduced students to that concept it was a stumbling block for many. As a result, in the sample code I write the while loop in terms that new students are more likely to understand, so that they can concentrate on the important part of the code. Students are required to understand the "proper" way of doing it (See test #1, question #5), but that takes some practice before it feels natural.
Good point. By the way, the weirdness in that piece of code is that you use a flag to get out of the loop when you could call pygame.quit() immediately. Not sure if it makes the code more readable. Isn't 'while True' pretty straight?
Or use a variable called not_done, makes it look more natural.
It is to me, but not the 'struggling' students in my class. The top-half of students don't have a problem with it. I prefer to exit out of a loop, then call quit. I'm one of those people that don't like calling 'break', 'return' or some kind of quit in the middle of a loop. Just a style thing, not that important in reality I think.
This seems like a nice PEP, but I consider Python3's function annotations to be a poor idea altogether ([PEP 3107](http://www.python.org/dev/peps/pep-3107/)). I accept them as they have GvR's blessing, however there are some huge flaws with the creation of this facility, IMO. The problem only arises when you consider that at some point in the future, there may be more than one use case for function annotations (as the PEP suggests). For example, let's say that in my code, I use function annotations both for documentation *and* for optional run-time type checking. If I have a framework that expects all the annotations on my function definition to be docstrings, and another framework that expects all the annotations to be classes, how do I annotate my function with *both* documentation *and* type checks? Basically, there is a lack of a standard for layering function annotations. It's true that some standard for this could organically form in the community. For example, one could imagine tuples being used for this. If an annotation expression is a tuple, than every framework should iterate through the items of the tuple until they find an item of the matching type. However, this won't always work: what if two frameworks are both expecting strings, or two frameworks are both expecting classes, with different semantics? If we used dicts, this could be avoided since you could do something like this: def foo( *args: {"doc": "arguments", "type": list}, **kwargs: {"doc": "keyword arguments", "type": dict}): \ -&gt; {"doc": "a bar instance", "type": Bar} but isn't this getting very ugly, very quickly? Lots of boilerplate, poorer readability, seems un-pythonic to me. My personal opinion is that the function annotation syntax is very, very ugly, and will quickly clutter function definitions so as to make them totally unreadable. If you compare how annotations would look using the PEP 3107 syntax to the kinds of 'annotation decorators' you find in the [Pyanno project](http://www.fightingquaker.com/pyanno/ ), you can see exactly what I mean. So, though this seems like a nice PEP, it seems mostly written to make it easier to introspect functions, so that you can introspect function annotations. But I think function annotations are a bad idea, so I'm generally -0 on this PEP :)
I suppose some kind of "use strict" could theoretically be implemented as an optional statement that enforces type annotations, but at that point Python would be diverging from its original philosophy, probably.
One big thing that's improved scientific computing in Python since that was started: the IPython notebook. The introduction suggests using IPython, but doesn't currently mention the notebook at all. It might also be useful to produce richer examples, with inline plots etc.
Oooo this is cool!
"while done is False" is the generally-accepted way of testing a loop condition, compared to "while done == False". I recommend the former style whenever the condition you're testing is a boolean.
By "Terminal" I think they mean PowerShell.
Well I already got Powershell open, I hope that's what they mean.
Where is the view all downloads button?
Well, Python isn't *statically* typed, so it's more about the number, name &amp; kind (keyword, positional, or both) of the arguments. (Though you can annotate the argument with text, generally with a type, this feature isn't used very often) edit: corrected myself, python is typed, just not statically typed.
http://sourceforge.net/projects/pywin32/files/pywin32/
just install git for windows: http://git-scm.com/download/win it comes with preconfigured mingw which includes BASH and a bunch of useful unix tools
And PowerShell is shitty exactly how (compared to cmd.exe or command.com)? Oh noes, we must type on keyboard to actually accopmlish something - gasp!
I like the pygame examples but the encryption samples scare me a little bit.
Get Python(x,y) from code.google. It includes (almost) every lib package you can think of, plus iPython and a console to run it in, or the Spyder IDE if you prefer that. 
Is it possible to change? TechTalkAdvice or GivingTalks does get the point across a lot better.
I just created /r/GivingTalks, because you're right. Will put it up in /r/TechTalks and see what happens.
google doesn't index special characters, so if you need to look up a symbol (for example, find "&gt;&gt;" on StackOverflow), you could use SymbolHound
What does this emoticon mean?
Powershell is awesome! I've really enjoyed it. I was referring to him saying "go install Powershell," then "so open Terminal" in a tutorial that was supposed to be about attention to detail. Oh noes, we must read for context - gasp!
Yes, that would be the location for Debian packages. /usr/lib/python&lt;version&gt;/dist-packages, if I recall correctly.
And what is this iPython notebook you speak of? I'm an avid IPython user (in fact, I'm one of the few in my lab refusing to use spyder), but I somehow seem to have missed the memo on this one...
**Full-featured IDEs:** - Ninja IDE - Spyder (if you're doing scientific computing) **Epic text editor:** - SublimeText2, with the sublimelinter package installed.
Itertools is the bees knees.
I totally understand - when I started out programming, the concept of "while x is true" made intuitive sense, whereas the shorthand of "while x" was confusing. Only later when I really 'got' boolean expressions did the short version sink in.
It is pretty important in reality - code is easier to test and verify correct if you reduce the number of possible paths through it. It also helps with maintenance later. Imagine you refactored out the middle of the loop into a new function. If you used to use return to get out of the loop, that will no longer work. If you used pygame.quit(), someone using that function in a different context may be surprised to see the application 'crash'. So yeah... carry on as you are!
what os are you using?
primarily ubuntu 12.04, but also os x 10.6, and (yes) xp, as installed by my IT dept
[This](http://ipython.org/ipython-doc/rel-0.12.1/whatsnew/version0.12.html) page gives an introduction to the notebook, which came out in version 0.12
This made me chuckle
"while going:" is what I use in pygame examples. It reads nicely, and people seem to understand it.
I use sublimelinter with sublimeText2 as my editor. My coding style has inproved tenfold...
Sounds like, ideally, Wikipedia deserves a real entry for 'method signature' and not merely a redirect. We need a volunteer who either cares enough or is sufficiently overcaffeinated.
It's the Steve Holt emoticon.
Oh, the whole pymodules/pyshared/etc. thing? I vaguely remember interacting with those systems when I was manipulating some packages. It was... not a treat. I'm sure the Debian project has some good reasons, but Arch's approach is much easier. I maintain a few packages for the AUR (Arch User Repository). For most packages, the crucial build command is simply: python setup.py install --root=$pkgdir/ --optimize=1 It's very simple and easy, though it makes packages somewhat inflexible in terms of multiple versions of Python.
http://code.google.com/p/pyprocessing/
http://nodebox.net/code/index.php/Home
I've tried eclipse/pydev in the past, but it frustrated me so much that i switched back to textpad (a pure text editor). WingIDE is soooo much better than eclipse. I just wish i could edit my shortcuts...
NodeBox predates node.js by five years or so.. the name collision is unintentional.
bastian1343 is blaming you. &gt; You got me all psyched for a node implementation...
You asked about this and didn't bother linking the PEP... &gt;:| http://www.python.org/dev/peps/pep-3142/ http://mail.python.org/pipermail/python-dev/2009-January/085230.html
Nodebox for OpenGl: http://www.cityinabottle.org/
That is great thank you so much. I tried goggling something like this but processing is a bit generic of a name.
PyCharm is a really great IDE for Windows and Mac systems.
sorry for the late reply, was watching the England match. Thanks for the tips, will be trying them out later today. Again, thanks a million!
Can you explain it?
Wow, that's news to me. I thought that Kivy was officially unsupported on Windows XP. Gotta give it a try now! :)
u''
Lots of [nice features](http://docs.python.org/dev/whatsnew/3.3.html) including: * Reworking of OS and I/O exceptions * Built-in virtualenv * yield from (proxy generators) * Old Unicode literals allowed (but no-op)
as someone that programs Python professionally and Processing recreationally, I strongly advise you not to look for a way to emulate Processing with Python. The Processing community is quite strong, and the language itself is only part of the ecosystem. The rendering engine is more important than the syntax of the language. Plus with Processing JS (and upcoming natively in Processing 2.0), you can export Processing to the browser. There is a massive community of people making art with computers, and they largely start with Processing (and often go on to use OpenFrameworks or Cinder). Throwing that community out will not help you make better art. I don't understand these projects; these projects that are more concerned with the specifics of the tools than the result of the outcome. Nobody will ever look at your art and say "how pathetic; he didn't write it in a purely functional language, it's trash". You will learn much, much more about using code to draw by reading this book than by obsessing over having to do everything in Python: http://www.amazon.com/Processing-Programming-Handbook-Designers-Artists/dp/0262182629 if you started to use Processing to be creative, but got distracted by language details, you just jumped off the creative train.
Really cool. Almost no lines of code to have this beautiful result.. I start to like Python.
almost no brain used for this experiments since google and stackoverflow leads you to the optimal solution :) That is more important than python itself. But yes python is fun. And stack overflow is really informative. PS: I should be shameful for auto posting, but I was the first amazed and liking the results ... so I wanted to share it badly. It was so much fun \o/ 
In order for the user interface to be responsive, the message event loop has to be running. If you write code that ties up the event loop waiting for something to happen, it can't respond to events and your UI is frozen. There aren't magic pixies that animate your UI -- your program has to do it. If you make the main thread block, it can't do that. The solution is to not block the main thread, by doing the work in a separate thread or by using asynchronous programming. 
Am I the only one that read the last line of this and got irritated by someone saying that interest in programming and programming itself are not creative?!!! GRR.
different forms of creativity. If you are sculpting something, you may not want to make your tools from scratch. 
I'd just like to plug my processing.js editor where you can write sketches with coffeescript. It's not python, but it's not java or javascript either. [http://pcsedit.appspot.com](http://pcsedit.appspot.com)
Wanting to solve a problem is a well-worn and honorable path towards learning to program.
[Goggling](http://img.dailymail.co.uk/i/pix/2008/05_01/cat2804_468x564.jpg)
!@#$ing awesome, man. That made my Monday.
It's actually the same concept... in both cases the "signature" is a short number of bytes generated based on the message and some secret key, which can be regenerated to prove the author possessed the key and the message... i.e., that they "signed" it. The main difference lies in how the signature is verified. For MACs, it's generally based on a shared private key, so the recipient would also have to have the secret key, which they'd use to regenerate the MAC signature. For public-key systems, the signer generally digests the message (via sha256, etc) and then encrypts the digest with their private key... the verification process therefore requires decrypting using the public key, and verifying the resulting digest. Only someone who has the private key should be able to encrypt the digest correctly, thus proving they had the private key to "sign" the message. **tl;dr** In both cases, a "signature" is just a proof the author possessed a particular key, and applied it to a specific message body.
Awesome! I will have to experiment with this soon!
Can you please help me understand why people don't "get" this immediately, and how to help them?
Why did you assume I can't program. I prefer programming in python then in java. I could go into why but I'm not going to waist any more time with an asswhole
You said it your self its just an means to an end. Programming in python is easier then in java. You can do things faster. adding two arrays or running a function across a whole array is so much easier with python. Regardless the pyproccesing solution is so slow which is what I was expecting. I think I'll take a look at cinder tho thanks for mentioning that.
Than != then, and waist != waste.
[networkx](http://networkx.lanl.gov/tutorial/tutorial.html#drawing-graphs) has support for plotting graphs.
graphviz might be useful. 
Even better, install the Github for Windows [client](http://windows.github.com/)
hmm. This looks excellent. Thanks!
I still think that posting your your own posts on reddit is like liking your own fb or G+ status, or like high fiving yourself in public, it's pathetic ... unless ... other people like it. It's quite a gamble. ^_^ Since some persons liked it, it was ok (thanks to the readers). But I think in the absolute I still deserve boohing and to be coated in tar. 
And once you have the dot file, there are multiple graph programs you can feed it to and output in many output formats. Good stuff.
Definitely agree about python didn't think you were bashing it. I will also definitely take your advice with processing and stick with it.
You could use what this guy used. http://www.youtube.com/watch?v=lHoWfeNuAN8
Well I have been experimenting with compressing the base64 representation of the code, to try and make it even smaller, and illegibal 
&gt;There's none on Reddit, but many, many other places on the internet mock it and mock Python programmers frequently. 4chan /g/ is a big one. Misc chans don't just mock python, they have a strong tradition of hating python. And there's a reason for that - many wiping bots for chan sites are written in python. This is a known fact and is enough to trigger a huge amount of inadequate hate towards the language, not towards the silly script kiddies.
It would wear its name correctly then ;)
I'm one of these developers who hate code. Code takes time to write, to execute, code has bugs, code must be stored, read, documented, maintained... The less I code, the happier I am. So I'm really tempted to use other people's libraries. But then, I realize that the library's documentation suck, that it bugs, that it steals my main loop, that it's not in a .deb and I have to compile it myself, or that it'll make the distribution of my code a dependency nightmare for non-linux users. Tough life :/. 
So... Is it a terminal emulator ?
Well, there might be code you only want to run if the context finished without raising an error.
What about the simplification of import hooks? I'd say that's pretty big, too.
&gt; The UI is only capable of doing one thing at a time to make it simpler to use. More generally, software does one thing then the next. Executing the command is one 'thing', updating the graphical display is another.
One does not merely read a tutorial to do threading. (Imagine a Sean Bean as Boromir image here if you like.) Sharing data across multiple threads is very error-prone and requires a fair bit of reading to understand the best practices in the area. It's usually more advisable, where possible, to either make the operation return sooner, or time-slice it (ie. perform parts of it on a regular basis, via a timer callback, until it's complete).
What are you suggesting? I mean I can try making some sample programs but I can't just crank out a bunch of programs for weeks to try and learn this. I'm trying to understand threading and also looking at wrapping because I may or may not want to use some C/C++ code in another program.
Hm, I could actually use that for the ui of my games' servers; curses is overkill and doesn't like windows. Nice :).
PHP addict here (with little Python non web app dev experience, C++, .NET). It is shit like this why many programmers write code in PHP, not other languages. I tried to dive into Node.js and everywhere there is written that this shit will cut down programming time, it is very fast (much faster than PHP) and other bullshit. In reality Node.js has the same story about publishing stuff to production as Python has (but even worse). Stuff on production will work slower if You don't tweak configuration or use fancy tools. For example a while ago I spent many hours to find out how to set up Trac with Apache and why my Trac installation was as slow as dead horse. Stuff just does not work without additional configuration.
At the very least, a link back to shoebot.net would give a little more context to the project. Looks good though, I'll check it out.
Added some info... if you get stuck with anything just ask on the ML, it's quite motivating for me to get back on it :)
It's sometimes pain in the ass to run mono because of incompatible versions of mono and Your programs...
Awesome. I wish I knew this thing when I was at College!
[Example Usage](http://pygments.org/docs/quickstart/#example) or use [highlight.js](http://softwaremaniacs.org/soft/highlight/en/).
For basic image processing, [`scipy.ndimage`](http://docs.scipy.org/doc/scipy/reference/ndimage.html) is a great start. You'd be surprised at what you can do by gluing a few basic components together. In your case, a simple sobel filter may be enough. On the other hand, as other folks have suggested, ITK is more specialized for medical image work. If you're working with MRI images (instead of, say, 3D seismic data) you'll probably find it's perfectly suited to your needs.
The ideal is that you use libraries, and help to improve them so everyone benefits. ;-) If that doesn't work, so long as the license is suitable, you can just crib code from the library. You still have to maintain it, but hopefully you have something well tested to start with.
I use it daily, and I approve!
If you want simple, fancy graphics (in 3d) - http://vpython.org/
only if you want the person to learn vim! and not python i would say pydev is much better or geany if you want something smal and fast.
For one or another reason, i was also taught it was "interger", but that quickly changed in a humiliating scene at school this year... (been using it for years) I think there probably is a python documentation site refering to it as "interger".
Oh c'mon, it's pretty easy with Queue.Queue. Spinning up multiple threads/processes doesn't entail tangling directly with shared memory and locks.
Don't delete it, I enjoyed this post. Have an upvote.
Added instructions: Try it out: Upload $ cd PACKAGE $ python setup.py sdist upload -r http://index.pythonpackages.com Install $ pip install PACKAGE -i http://index.pythonpackages.com 
Name something mainstream that's exclusively available in C++ that people would want to use from another language.