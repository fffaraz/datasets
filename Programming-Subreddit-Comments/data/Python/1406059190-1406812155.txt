Absolutely. Feel free to either reply here or PM me if you run into problems.
 :) Note that the relationship class here is very, very similar to the "Edge List" that Theoretician described.
Maybe have an "other" option with a text box for more specific entries. I don't think many people really care about insane accuracy for their cron runtimes though, so that would probably be a *very* special case
Calculate prime numbers: [2] + sorted(set(xrange(3,max,2)) - { x for step in xrange(3, int(max**0.5) + 1, 2) if step %3 or step==3 for x in xrange(step * 3, max, step * 2)} )
Write code that I can easily/quickly understand later on. :)
Personally I just love every time I can do list comprehension. Collapses many lines into one and once you get used to it I think it actually makes it easier to do things logically.
Not in just one line, you can't... :P
We tried that once, we got sendmail out of it.
Sweet! I hadn't used Cron before so you even taught me something.
You can skip the imports by doing `__import__('mod')` :-) 
My favorites: "python3 -m http.server" # Starts HTTP server to serve current dir And: "python3" # Starts Python interactive shell :-)
Nice work. A quick suggestion would be to use a multi-select for things like month. This way you could select both March and June or whatever combination you'd like.
Right, though to be fair it's not hard to use a normal matrix. Let's say we have matrix `M` which is of the following format. M = | aa, ab, ..., an | | ba, bb, ..., bn | | ..., ..., ..., | And let's assume that `M` is square, with its dimensions equal. We can define an 'edge' function that flips the indicated edge (in other words, sets a zero edge to one, or a one edge to zero). def flip_edge(m, i, j): """ Sets the edge between i and j in matrix m """ m[i, j] = int(not m[i, j]) m[j, i] = int(not m[j, i]) return m # depending on the mutability of m Similarly `set_edge` and `unset_edge` functions can be created.
I've really given up on Peewee and have instead opted to use native SQL queries. One frustrating fact about Peewee is that I had to rely far more than I like on irc chats or stackoverflow because the documentation fails to mentions important items. Just use SQL queries and python drivers for specific databases, it's far less hassle than trying to figure out the syntax of some arcane ORM library that is poorly documented, if you know what you are doing with SQL.
If I understand your post correctly, you can just `import` the main script (i.e. the one with the application logic) and call your functions from there. Preferably have a `main` function you could call from the other script.
&gt; One frustrating fact about Peewee is that I had to rely far more than I like on irc chats or stackoverflow because the documentation fails to mentions important items. I'm the author and I would really appreciate you letting me know where you found the documentation lacking. If you don't mind taking the time, can you tell me what important items were missing or poorly documented? Feel free to PM me or [put them in a github issue](https://github.com/coleifer/peewee/issues/new) if you'd rather.
Same exact error. If you aren't using a command line, IDLE, or an IDE that supports it you can't have any inputs. Scan your code for any and all inputs and just put in the values you want to use. 
Okay so I make one file called commandline.py where I define the commandline arguments, """ Usage: Options: """ from docopt import docopt if __name__ == '__main__': arguments = docopt(__doc__) Then I have one file script.py with my scripts. Then I have one file called main.py Now when I execute script.py, it calls main.py, including the main function, which accesses all the functions in script.py But that leaves me with the issue that I don't know how to access the command line arguments. If I define them in a separate file, how will my command line know how to use them and where will I parse the arguments?
Congratulations! This looks simple and useful. Two questions: 1. Are you actually using jQuery? Because I can't see it in the template. Maybe you could drop it altogether? 2. How about ditching that submit button and show the info changes in real time? Also, nice secret key.
What I was going for was: --- `main.py`: ... def main(args): ... `commandline.py`: ... from main import main if __name__ == "__main__": args = docopt(__doc__) main(args) And then `commandline.py` is what you actually run on the command line. (You might want to consider renaming.)
Going to tag along and give my own answer here, hoping OP will see this. The place I work at won't allow this kind of thing and we also have an NTLM authed. proxy that does man in the middle SSL decryption. This causes some major problems with PIP and SSL most of which can be fixed or worked around by: * Take the company CA root cert and something like the Mozilla CA bundle and create a ca bundle of your own by combining the two. * Setup your PIP configuration file to use this custom certificate bundle. You're essentially adding trust for the MITM proxy server, you unfortunately don't have much of a choice here. * In addition to the custom certificate bundle, also include your proxy server in the config too. The reason for doing this here is different software will handle the http[s]_proxy environment variables differently. Also, don't include your creds in the config because it's not only bad practice but that doesn't work at all for NTLM proxies (which is what it sounds like you have). * Write a script using PyCurl to handle the NTLM auth. process. When you get 407 errors with pip, or it's an SSL related problem, run the script again to perform NTLM auth then retry running pip. The only downside is the errors pip will produce often don't make a lot of sense because of the MITM w/NTLM auth. Whenever you encounter issues it's probably because the proxy needs you to reauth to continue. Of course, if you don't have a man in the middle SSL proxy server you're lucky and can skip about half of the above. Regardless, you can still use the NTLM auth parts.
Nice! I've gotten it to work now actually, by defining a string in an otherwise unused file and then importing that string, but your solution is so much more elegant. Thanks a lot. I'm still learning and this drove me crazy :)
Ah, so: you're a troll.
Write one easy to read and concise line of code that doesn't do anything too complicated by itself. Repeat this for as many lines as it takes to complete project.
Or just use something like Vagrant? http://vagrantup.com
Raymond Hettinger tweeted something like ' you should read "for: else:" as "for: nobreak:" '. That always helped me remember.
So no-one has brought this up yet, but you really should disable debug mode. https://github.com/ThaWeatherman/cron_app/blob/789aeaffff307d8dcc813924e245abff6ce5fc67/app.py#L36 If I can cause an exception anywhere in your application, it will give me a debugger that I can use to run arbitrary python on!
 import webbrowser; webbrowser.open('breadfish.co.uk')
Guido and many others have made it clear that they don't want a lot of this in the standard library because it ties the release schedules together and adds unwanted bureaucratic overhead. The best thing for `requests` is to stay standalone, not because it's bad but because it's *great*. --- I think it's a shame that CPython doesn't officially support (and thus recommend) external projects though.
Maybe this is not in the spirit of the question, but I find pretty printing json from the command-line to be helpful. echo '{"key": "value"}' | python -m json.tool or use curl while debugging curl -s http://www.reddit.com/user/mrefish/about.json | python -m json.tool 
ITT: We learn why you should never cram code into a single line
What did your find most valuable in learning flask? 
`swapcase`
You want Kivy. Play nice on osX, Windows, Linux, iOS &amp; android. It's also quite simple and has pretty defaults.
I'll jump in and root for wxPython before someone advocates (understandably) for PyQT/PySide. wxPython is native widgets (meaning widgets look like what they are specified as by the operating system...so Mac buttons look like Mac buttons, etc.) aside from some generic widgets and libraries. PyQT is not native, but apparently it comes very close. The wxPython community is great. On the downside, wxPython is not quite fully ready for Python 3, yet, though, since only the very developmental branch, Phoenix, is able to do that, and not all sub-libraries have been ported there yet, though the main widgets have been. Also, I've found that though it is supposed to be cross-platform, strictly speaking there are minor tweaks you have to make to get one codebase to run nicely on all three major platforms, but they are not too bad and there is a wiki on how to do this. 
No, I'm pointing out that there are two major camps of developers: those who develop on Windows and those who develop on Unix (of some sort). While tools *may* be ported to the other camp, they will always be better supported where they originated, and complaining about Python support on Windows is like complaining about C# on Linux - sure, it should probably be fixed, but you should probably rethink your development platform if you spend a lot of time there.
It's cool as a "toy" or "look what I can do" but if I ever saw that in production code, you'd be fired.
Here's what I did: __author__ = '' # Example of input data # ITERATION: 0 -114.962300280542 -114.962240779211 -114.962288381208 -114.962266674976 # -114.962239329422 -114.962231022881 -114.962190348205 -114.962025319196 -114.961395525249 # -114.960347303699 -114.958998838224 -114.957048513513 -114.954341263129 -114.950379665641 # -114.949060791247 -114.949591487492 -114.949396412830 -114.949404063108 -114.949953123817 # -114.949966691202 -114.950132089913 -114.950137299434 -114.950023242734 -114.950159645430 # Example of output file "iteration_0.txt" # ITERATION: 0 -114.962300280542 -114.962240779211 -114.962288381208 -114.962266674976 # -72087.0721715 -72087.0669629 -72087.0414578 -72086.9379764 -72086.5430641 # -72085.8857768 -72085.0402215 -72083.8172704 -72082.119689 -72079.6355693 # -72078.8085692 -72079.1413422 -72079.0190207 -72079.0238178 -72079.3681063 # -72079.3766137 -72079.480327 -72079.4835936 -72079.4120744 -72079.4976057 # Open the file in a safe manner that will automatically close the file when done with open("iteration_list.txt", "r") as file: # Going to have to make a new file for each new iteration file_name = "" # go through all of the lines in the file for line in file: # just seeing what the initial input looks like #print repr(line.lstrip().rstrip()) # If "ITERATION" is in the line we need to make a new file if "ITERATION:" in line: # Make a new file_name # # line.split() = ['ITERATION:', '3', '-114.962300280542', '-114.962240779211', '-114.962288381208', '-114.962266674976'] # Therefore line.split()[1] means list[index = 1] or in these kind of lines the iteration number # file_name = "iteration_" + line.split()[1] + ".txt" # Make a new file and we will append to it as we go on # # Start the new file now because we don't want to modify the numeric values on the lines that have "ITERATION" # with open(file_name, "w") as write_file: #write the first line (containing ITERATION) with unmodified values then add an end-line write_file.write(line) # "ITERATION" is not in the line so we need to modify the values and add to the current file else: # Convert the line of text numbers into a list of text numbers text_numbers = line.split() # list comprehension is awesome but a full explanation is kind of out of scope # # this basically takes in each text_number, turns it into a float, multiplies by 627.05, # then reconverts the result back into a string, then finally adds the result to a new list modified_numbers = [str(float(number) * 627.05) for number in text_numbers] # then convert this new list into a string that will be added to the current file new_line_to_write = "" for number in modified_numbers: new_line_to_write += number + " " # strip trailing space, just being lazy new_line_to_write = new_line_to_write.rstrip() # open file_name in append mode with open(file_name, "a") as write_file: #add the new line to write to the current file write_file.write(new_line_to_write + "\n")
It's not an optimized solution by any means but I tried to make the logic super obvious for someone who might not be very familiar with python. (Ie doing the append rather than accumulating the data then dumping it all at once.) Anyways, hope you learned something. Edit: Also, is this like a new type of /r/theydidthemath ? heh 
After looking at Kivy, it looks great, however the .dmg that I downloaded and followed their instructions here: http://kivy.org/docs/installation/installation-macosx.html And subsequently the .dmg didn't include Cython which led me here: https://groups.google.com/forum/#!msg/kivy-users/OHlwNvOuA6Y/oRDSPyduL2YJ Attempting to solve via ChrisB's solution, but to no avail yet. I downloaded Cython independently, but how do I make it play with Kivy so I can run "make" and finish the install on Kivy?
Single-line functions aren't about being easy-to-read, or being concise. That's what actual code is for. Like programming golf, it's a showy demonstration of a deep understanding of what you want to do.
I did a pretty fun one today, actually. To be fair, the setup for this one line took quite a number of lines, but the solution to the problem I had only took one. &gt; from collections import Counter # A relatively large and complex data structure that I needed to analyze &gt; data = { "key1": [("Foo1:Bar1", 1.23), ("Foo2:Bar1", 2.34), ("Foo1:Bar2", 3.45), ... ("Foo1:Bar16", 7.89)], "key2": ..., ... "keyN": ... } &gt; for key in data: data[key].sort(key=lambda x: x[1], reverse=True) &gt; &gt; {key: Counter((name.split(":")[0] for name, _ in data[key][:8])) for key in data} That last line was the one that I thought was so powerful, it allowed me to find patterns in my data that showed me precisely were my problem was. It showed me that I had clusterings of `Foo1`s in my highest valued data points. I can't think of a single programming language that would let me do something similar in such a small number of characters. Even Haskell, which I consider to be a very terse and efficient, can't do something like this so easily.
woot, I've taken two of his classes and that is where I've learned most of my Python. He's great.
I am constantly using the collections and itertools modules. These modules contain very useful classes and functions for doing complex data transformations efficiently and easily. Particularly itertools can be a bit difficult to learn at first, but it's worth it.
Hey, I know it's small but that's some surprisingly clean Python code for a "first" app. Good job! 
I greatly prefer [arrow](https://pypi.python.org/pypi/arrow/0.4.2) to datetime.
Btw, the sphere is Earth here. So the points on it should be longitude, latitude sets.
Those clusterings of Foo1s are what haunt us all.
... or just use an upper triangular matrix.
&gt;I've given up trying to do "pip install mysql-python" . There is always either a dependency problem or it crashes because it can't find some visual c dll duck me whatever. &gt;If you want to python, use Linux. And never ever try to create an executable (.exe). It's not worth it. I don't find either of those to be an issue at all, although of course my experience is purely anecdotal and shouldn't be taken as an attempt to invalidate your own. It may be that as a dev-ops, one man show in a highly heterogenous network environment I've just become too used to nothing ever working exactly as you would expect or the documentation describes.
More of a dynamic input. Hoping to sort of get answers on the fly when I come across various problems, or at least a good enough 'starting' point to where I can tweak it more if need be.
Yea, most of bootstrap is doke with some well written, complex CSS. I imagine it's sort of a project goal. 
It doesn't work on my machine
reddit turned all of the exponentiations into bolds. Use the source of my post instead of the post itself. 
updated ;)
 import this I know, it's not very impressive, but I like it.
Error: BufferOverflow
PyPy is a completely separate implementation of the Python runtime, not a fork of CPython.
Maybe I didn't relate my thoughts well. Personally I've used Python a lot and really only have minor complaints about the language. It is a very good high level language to know! As for colleges using it in CS courses I would have to say that is misguided in my estimation. Note I said CS courses it may be a different story for an intro to computing course for other majors. In any event if you really want to learn to progrma I see the bottom up apporach as the better path to follow. That means a lowish level language like C++ or something similar where you learn the basics and actually do things like implement your own arrays, link lists and other simple structures. The idea here is that you gain a bigger appreciation for things like C++'s Standard Library and Python. The problem I've seen with Python, Visual BASIC (especially) and other high level languages, is that people implement programs without understanding what it is they are using. Note these are languages often used by engineers with little formal programming training. I've seen this at work many times, Python and similar solutions can lead to unfortunate results or code in the hands of a poorly trained user. I guess what I'm trying to say is that yes Python can be very useful in your career but formal computer science education would be even more useful. 
"I'm sorry sir, we don't allow snakes on the corporate network."
I posted the original comment because such comments often generate considerable debate. Personally I'm not sure it it is a good idea or not. However the little bit of programming I do do would have went better if it wasn't for the indentation problem. In one case an incorrectly indented bit of code lead to a nasty hard to chase down but. In another case code from another editor brought into some cide I was working on in Eclipse messed everything up. There was consistency in the way indentation was handled. I've been around for a long time, some of my first programming was in Pascal and Modula 2. Begin &amp; end where part of my life? Begin "{" and end "}" are actually easier to read for me. That may be years of training ones self but the sentinels do stand out. 
Nice, thanks!
Wahoo! If you're interested in writing a case study for the PyPy blog, please let me know.
LPTHW is a good introduction book of sorts. That is, if we can call it a book. On the other hand, Learning Python is a comprehensive book which can teach you finer nuances of Python. If you feel that time is against you, read only those parts you deem important. You can always go back and pick up on the other chapters later. 
I figured... Code was way too clean for a newb. As your first web app, you're a little spoiled now at how easy the flask structure is :) It's a micro-framework and awesome for what it does, but there's a popular opinion that it doesn't scale as well as Django. If you're building a large web application, you'll have more luck with Django for most of its building blocks. It's not that flask can't do it, but it might be a bit more difficult to put something together that's robust, maintainable, and able to scale to thousands of requests per second. My point is, enjoy it but consider learning Django if you need to scale massively! Cheers
My favorite is the simple True, False = False, True
numpy.
I had a really stinky one-liner that walked a filesystem, renaming files that matched a pattern recursively. It took some balls to run that one the first time. Here's a basic example minus the grody regex, spaced out for legitibility (and requires os module): import os [ [ os.rename( os.path.join(root, fn), os.path.join(root, '%s.text' % fn[:-4]) ) for fn in files if fn.endswith('.txt') ] for root, dirs, files in os.walk(".") ]
Urgh. Out network admins want to implement a MITM SSL proxy soon. Definitely looking forward to these kinds of issues... /s
So should i add a feature that makes it repeat the process 100 times or what? 
That won't do anything. There's nothing that you can implement that will result in a DDoS from a single machine. 
+1 for the HTTP server. I often use this trick to quickly share big files like video files with others.
Okay thanks
I don't believe such a tool would work very well, too many ways to solve a problem... maybe after the singularity :) Seriously, learn Regular Expressions! It's one of the most valuable things I've ever learned and I cannot imagine living without them for longer than a week :) There are tons of Regex editors out there, even some that understand Python dialect: https://pythex.org/ obligatory xkcd: https://sslimgs.xkcd.com/comics/regular_expressions.png
I would think daemons would be happy with something dead....
 $ python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ...
Wondered what the "2.8" T-shirt was about, but I presume that's trying to push BDFL to change the plan for future Python?
This. Regular Expressions are too useful to not learn them. I recommend "Mastering Regular Expression", it's a classic on the topic.
Are you specifically trying to install the dev version? The stable version shouldn't need compilation, everything is ready in the dmg and should be runnable via kivy.app.
I'm just learning but list comprehensions are cool when I recognise where to put them. Usually just anywhere I'd throw a map function at the moment. 
Try the search bar in the top right, this question is only asked at least once a week. 
It's both shockingly fast and shockingly slow. I think it still has a fair ways to go before I'd consider it overall better for most purposes. Still, I like it and try to ensure that any libraries I maintain support it.
When checking out arrow some time ago I also stumbled across [delorean](http://delorean.readthedocs.org/) which is also really cool. Probably my favourite non-stdlib module is [Fabric](http://www.fabfile.org/) 
What problem does this solve? Sending mails in Python isn't that hard to begin with. And what's with the "for Humans" moniker? It is (ab)used too often. Actually, Envelopes does the same as this library, and is also "for humans": http://tomekwojcik.github.io/envelopes/
I sit on the fence on that issue, but I wear the t-shirt to troll people.
Agreed, also I'd rather use a built in library knowing that if there's a bug found it would have greater support and not having to track additional library updates where possible.
Hi - I wish there was one too. All I know of is https://github.com/simlmx/pyau (which could be a starting point for a livecoding library) and http://boodler.org/ (a soundscaping tool.. not really for livecoding though).
&gt; I've found the built in libraries are already really easy to use Thanks for injecting a bit of "sanity" in to this one. ie. No swipe against the publisher, here (these look nice)... it's just oftentimes nice to know what some may overlook in the standard library.
There's always the good old ini format and [configparser](https://docs.python.org/2/library/configparser.html). JSON or YAML might be good options as well.
Huge thanks to the EuroPython 2014 organizers. I've never been at a conference where the videos were posted so quickly. Great job!
I think what "for humans" really means is that your using flasks sphinx theme for your docs. An author claiming their work is good/genius/for humans is really tacky. This comment is a work of genius by the way. 
I store my app settings in a json file (settings.json) , which is checked into our source control system. When we stand up a new environment a settings.override.json file is created (excluded from source control to prevent merge issues), on startup the application generates a config file from the base settings.json file and merges overrides and additional information from the override file. All environment specific information is stored in the override file. I've found this to be a pretty clean and easy way to handle environment-specific settings. 
But in reality, the problem is that *we* are the Foo1s.
It's true they aren't that hard to use. But I always end up wrapping sending email with some simplified layer, which is a good sign its more complex than it needs to be. It's not *Requests*, but it is a modest improvement over stdlib, IMHO. from sender import Mail, Message mail = Mail('smtp.gmail.com', port=587, use_tls=True, username="login@gmail.com), password="gmail-password) msg = Message('Test Subject', from_Address=("Mr. Turtle", "turtle@gmail.com"), to=("Receiving Email Guy", "reg@mailinator.com"), body="This is the content of the email") mail.send(msg) 
We are not Perl
I wanted to capture the similarity between: if any(&lt;condition&gt; ... &lt;collection&gt;): ... else: ... And: for ... &lt;collection&gt; ...: if &lt;condition&gt;: ... break else: ... 
only in the wheel format using pip3-for-humans (windows only)
Not very impressive? What do you expect? The Spanish inquisition!
Or because they find vim/emacs productive.
Check out Wikipedia on list comprehensions and you will find that they are both based on set builder notation. They copy the mathematicians notation.
wow i like it!
From the stdlib is csv Non-stdlib is XlsxWriter
What happens with configparser?
hmm id say its not really user friendly compared to other standard modules. 14 lines for sending a simple email, when it could be as simple as: send_mail(from, to, subject, body, attachments). I bet that most of you guys have a wrapper function for sending emails. I do. That is a symptom that the standart procedure is too complicated for the 99% usecase. Like urllib2.
yessss
Since you seem to be asking about location, you probably want [appdirs](https://github.com/ActiveState/appdirs). &gt;&gt;&gt; user_config_dir(appname) '/home/&lt;username&gt;/.config/&lt;appname&gt;' For actual configuration, I use [profig](https://bitbucket.org/dhagrow/profig) (disclaimer: 'cause I wrote it).
Hmm. So what if a library is designed specifically to be simple to use, in turn sacrificing functionality or focusing on simplifying a particularly popular or common use case path? Should they not write "for humans"? Because in those cases that would be an accurate description of the design target.
As many psychologists have noted, human beings are frequently human-unfriendly. We need Humans for Humans. Someone get on that. (yes, I think 'X for humans' is getting pretty stupid.)
 "they" can do whatever. I'll still think it's tacky like Quentin Tarantino movies. this comment is for humans
There's always one of those guys in the forums.
Most likely yes, assuming they do anything web-related.
I think this misses the "for humans" bar for a clean api. Why is the subject the first positional parameter, when all the other headers are keyword parameters? It would make more sense for the body to be positional, and the subject to join its fellow headers as a keyword argument. Moreover, a message without a subject is a sensible thing, but a subject without a message is not. Also, the attachment api is clunky. with open("logo.jpg") as f: attachment = Attachment("logo.jpg", "image/jpeg", f.read()) msg.attach(attachment) I want to be able to say "attach this file," and be done. with open("logo.jpg" as f): attachment = Attachment(open("logo.jpg")) The file object already has the file's name stored on the object (`f.name`), and there are libraries to sniff a file's type. The user should be able to specify those things if desired, but not required. with open("logo.jpg") as f: attachment = Attachment(f, name="google_logo.png", mimetype="image/png") Don't get me wrong. This looks like a nice library, but if you want to call yourself "for Humans," the API needs to be awesome.
&gt; Moreover, a message without a subject is a sensible thing, but a subject without a message is not fwiw, I send way way more of the latter then the former (as a form of instant messaging. e.g. "Coffee? (n/m)")
This is very interesting. Thanks.
Save at your application path. :)
Sure, but many external libraries get added to the standard eventually.
Haha, good to know the inner workings when you're in sec. See you at Defcon /blackhat ;)
could you expand on this? I've never seen that before... 
The for humans thing makes it sound like any generic toothpaste commercial. It's getting annoying. Apart from that thanks for sharing.
I think you did a fantastic job. Could you share the source of the data? This also gives me more motivation to start using IPython.
Thank you. I'll write a post about that part, because I'm not sure how much trouble I'd get in if I shared the data :)
Well, there's data analysis... you know ... my livelihood. ;)
 print(__import__('os').getcwd()) 
if it's web dev, then yes
I remember learning haskell just so i could read the paper on transactional memory years ago.
If it's the sort of application that should be easy for end users to install, then you probably want to look at ways of building native packages or installers, rather than relying on pip. Projects you might want to look at are cx_Freeze and Pyinstaller (cross platform tools to make executablse), and Pynsist, a tool for making Windows installers (disclaimer: that's my project). I wrote more details [in a blog post](http://takluyver.github.io/posts/so-you-want-to-write-a-desktop-app-in-python.html) recently.
Thanks all, I do not like the idea of learning Javascript..
You do realize that built-in libraries will only get updated when new versions of Python are released, right? External libraries, if well maintained, will actually have a shorter release cycle and can adapt to problems/changes more quickly than built-ins. Remember, the stdlib of any language is where features go to die.
Instant SMTP email debug server. python -m smtpd -n -c DebuggingServer localhost:1025
You should use $XDG_CONFIG_HOME instead of ~/.config directly (even if most of the time it will value to ~/.config).
I'm not sure that that would work: - If database queries take some time, the database engine is probably working as fast as it can, in which case, sending the queries to it together instead of one at a time won't make it go any faster. - Even if that's not the case, it doesn't look like cx_Oracle supports any kind of async mechanism. You might be able to run queries in parallel using threads, though.
I'm wondering if this is more of an issue with the database queries and their needing to be optimized. The `cx_Oracle` library doesn't seem to support async polling internally. So, as /u/takluyver advised, putting the queries into threads and then using something like ZeroMQ's [task ventilator/worker/sink](http://zguide.zeromq.org/page:all#Divide-and-Conquer) pattern to perform the work in multiple threads would work fine. Here's the paramount question: how fast does it need to be? 
Well get excited! Learning a new language can offer you a new way of thinking! JavaScript is no python, but its certainly fun! take a look at [paper.js](http://paperjs.org/) after you read a little bit and see the fun stuff you can do with a little JS!
People will run the script on demand and wait for results so I would like it to be as fast as it takes to run the longest query instead or what it does now which is the sum of the time it takes to run each query.
the queries still take the same amount of time. that will not change, but if it executes the queries in parallel it should only take as long as it takes to do the longest query.
I used to be in this boat, handling middleware services in python. It is out there, but know your data structures/algorithms.
Ahh, I like this idea. I'll just, like you said, keep the config structure in the program -- and can then fill in path/environment related values programatically -- to generate to disk and load when it's there. If it's not there, don't overwrite it because the values might have changed. Thank you very much! If you comment on SO I'll accept your answer ;)
You can never fully appreciate Python until you do some JavaScript ;-)
Thanks djds23 for the link. Good sample code.
EuroPython has done that for a few years in fact!
I do - job is about 90% python 10% JS. I don't think JS deserves a lot of the flak it gets and is easy to comprehend coming from python.
Here's a question. Why wouldn't you want to use Javascript? Or is this more of a not-feeling-proficient-in-making-pretty-interfaces thing?
&gt;Is Front End knowledge a required for most Python jobs? For jobs related to web dev, yes.
I've been doing this a lot with video games recently.
In my experience, javascript has a high standard deviation, so to say. It can go from very deep pits of hell even satan is scared to enter to actually very, very enjoyable code - and I have a tendency to hate all code, even my own. 
My first time at the conference so I didn't realize that.. regardless, props to them for keeping up with it each year. I hope more conferences follow the trend.
I'm guessing it's drawing a parallel to the requests library, whose tagline is "HTTP for humans".
We're too small to be packaged on linux. At the moment I have a script for dependencies and another one that creates symlinks inside a virtualenv. The maintenance burden is a bit of a pain though, since I have to test different distros. In short - I guess I should just not include those other things in the requirements.txt
Could you at least share the data scheme?
If the speed is limited by disk IO, then it can't get a significant speedup by running them in parallel.
If you're not familiar, [pyvideo](http://pyvideo.org/) is a great resource. They link all the Pycon, EuroPython, etc. videos and keep a searchable archive.
this is wonderfully done. would you mind sharing the csv. thanks. 
Haha! So true! :)
Systems Administration, assuming your tooling is Python based. I work with web servers, but I don't write front-end code for the most part.
Oh this is brilliant. I always struggle with using pandas and matplotlib. I've learned a lot. Thank you!
I am using OrientDB with bulbs/rexter. Also I am working on a project called "OrientEngine" an "ORM" for OrientDB using the liborient (C). 
Use coffeescript, makes the js more bearable.
What if you are doing Python against a system with a pretty good API and nasty internals like Django? You'll learn all the wrong lessons.
Working without list comprehension is like losing an arm, and generators simplify a ton of problems. On the other hand, though, every time I context switch back to Python I stumble across how horrible its closure and async support is. Honestly, it's kind of wash, and once there's good Harmony support, the generator and comprehension thing will probably tip the usability over in JS' favor. Except for context managers. Those I always miss. 
&gt; whose tagline is "HTTP for humans". which was a stupid presumptuous tagline then too but it was first so it was kind of cute if that's what you look for in libraries. "For humans" would mean more coming from an unbiased user rather than the author who thinks their shit smells like jasmine and assorted berries. 
the above comment is for geniuses with a sense of humor. ie: not for your average redditor. 
Unfortunately.
I know that, but I would love to see whatever makes it so very fast rolled back in; if possible. 
What are you using to host the app?
Man can not live with just one language! It is like having a wife without a girl friend. Seriously though this is specially important if you are a professional. However your question, like many in this Reddit, isn't possible rouse fully answer. There is a whole world (worlds) of Python development that never sees the web. 
Very cool! I have to give a +1 to IPython. Been using that at work for exploratory data analysis and it is truly amazing. Being able to render the plots inline right there with the code is a huge advantage. Check it out!
I was under the impression that most of the widgets under [wx.lib](http://www.wxpython.org/docs/api/wx.lib-module.html) had still not been ported yet. But the wx core widgets are there. 
UPDATE: here is full download http://downloads.outbrainreview.com/Python
It's not possible. PyPy is not only written in a completely different language (RPython, vs C), the main feature that makes it so fast (the JIT) isn't portable.
It's literally the same thing, wrapped in "Convenience Classes". You have to pass all the same arguments. I don't see the point of relying on a third party library so I have to make, what, three less function calls? And we all know you're just making the same function calls under the hood.
Nope, not true at all. You can do that, but you still have to access the server, login, create the message, etc. You can't get around that (even with a library).
I've heard some people say that map and filter statements are Unpythonic. When you think about it, list expressions give you a map and filter all in one.
Use Coffeescript. Trust me.
Yeah, Envelopes solved this (hardly existent) problem a long time ago. I do actually find Envelopes useful for any code that needs to manage attachments, HTML text, or MIME though. Saves a few lines.
x-post from where...? Wherever this came from, I need more of that in my life.
like i said, make it simple for the 99% use case. Which in the case of sending an email it would be something like: send_email(server:'smtp.gmail.com:587', user:user, password:password, subject:subject, from:from, to:to, body:body, attachments:[])
http://www.reddit.com/r/paintball/comments/18ctft/fully_automated_paintball_sentry_gun_awesome/ 
Neat, have you ever heard of DigitalOcean? Same price for a starter package, but you get a whole Linux VPS!
Do you not know Python syntax? Your function is terribly designed. Are you saying every time I want to send an email, Python should re-connect to the server, re-login, and then send the message? The current interface is modular because it works for **all use cases**, while still being very, very simple. Your function is extremely bloated and naive. You can't just have an "attachments" list. What will be in it? Filenames? And should the Mimetypes be auto-guessed? What if I want to send an attachment located in memory? So it's not filenames? Is the body HTML, or just plaintext? If it is plaintext then your email content is extremely limited?.Do we want the user to think that emails are sent with the Subject, From, To, and body fields separate? What if someone just wants to send something with a subject. What if someone just wants to send an email with a body? Do I have to pass all those arguments each time? You do realize that's the exact same thing, in one long, bloated, frustratingly designed function.
If you work in web development, you cannot avoid using JavaScript, regardless of what other languages/technologies you use. 
Thank you all for answering question. Well, my conclusion is this: Javascript is a most tool to have in your toolkit. Thank
I downvoted cause : No Python is not about one line scripts. One line scripts are nothing but show offs. No Readability , No Reusability. We avoid writing one line scripts in python, which had plagued Perl and Nobody in my team ever want to maintain it. So you should too.
Not mentioned in the article is what kind of code to read. Whether it's from a good programmer or a disorganized one. I guess in a work setting you have no choice. But for the purpose of learning a new language or improving your skills I think it's recommended to read good code exclusively. It's like hanging-out with good friends versus bad ones. Eventually you'll pick-up the language patterns and culture of whatever group you are in.
Once wise man saids: Use the SOURCE , Luke. I would recommend reading source code of tornadoweb for starters. I learnt a lot of async from reading tornado. https://github.com/tornadoweb/tornado
They love reaping children , especially. Good parenting rule for daemons #666 "Thou shalt be a merciless parent: always reap thy children when they die" http://www.cim.mcgill.ca/~franco/OpSys-304-427/messages/node72.html
When I first saw this project several years ago he mentioned that it was written in C#, not Python. Still a cool project though.
Thats generally a bad practise. You should store configurations always in the appropriate place. Every system i know has appropriate folders for per user and per machine configuration 
Nothing happened to it. People just seem to ignore it 
You can do it by sending 'create table' commands to sqlite3, it's included in python. But do think of your other responsibility as a programmer. Just because you can store the customer's fingerprints doesn't mean that it's a good or safe idea or that the customers will like it. There's an ethical and business-strategic component to engineering too, besides just the technical. 
yeah i thought about that too. Well I'll tell my friend that Thanks for your help :D
This isn't a good idea in unix-like systems (the user doesn't have privledges to write to it) nor in windows. I believe this was standard practice some time ago in windows land, where the "program files" folder was used and abused for this purpose. Nowadays the user doesn't have access to directories such as the "Program files" one. Nowadays Microsoft (again) copied a page from the unix playbook and directs developers to save app-specific data to a dedicated application data folder ([source](http://msdn.microsoft.com/en-us/library/ms995853.aspx) ).
I've started doing it, but since I was still devoloping the visualization style and measure calculation, I moved to final as it made more sense to do it now. Doing this on weekends only and watching most of the matches didn't allow me much time to be an armchair analyst :) That is the most impressive football match I've ever seen though, so I plan to revisit it. Hopefully do something a bit more advanced, particularly of that infamous 7 minute period.
When I use javascript after python my brain blows up
This would be much more impressive if it didn't use an automatic gun. Not that it isn't cool, I'm just not sure how much of this is accuracy and precision and how much is spray and pray. 
Funny - I'd conditioned myself so much against this that I didn't try it!
Did you just suggest an automated sniper?
The idea is very simple. If you have a web server and want to handle requests in parallel for example you just handle them in different threads and use one global lock that you acquire when you receive a request and release it after you have sent the response. If you do that without STM, all of these requests will be serialized and handled on after the other. If you do that with STM, the requests will be handled in parallel and only if there is a conflict (checked after you release the lock), one of the transactions will have to be performed again.
You can check on the laptop screen where its aiming. The aiming should be relatively simple math.
I just d/l the trial and its a windows exe (not sure if its even C#). So what is this post doing at /r/python? Btw: Something similar should be possible with OpenCV.
I can't see anywhere where it says it's written in Python?
Are slides available somewhere?
Thanks, that's it. Last commit from 2012 though :(
Hmm, since I couldn't attend this year I also spend my evenings watching the videos of the dayâ€¦ I watched that one, but even if I liked most of what was said, I still ended up thinking it was a "meh" video. If you don't already use flake8 or such, you should. If your project doesn't enforce (at commit time) some compliance (let's say, with pep8), you might think about it. But monitoring the number of errors, I'm not really convinced; and doing so via a non-local thing (landscape.io) sounds even worse (I want immediate feedback, even when there is no network). So, yes to the principles, but nothing really new here for me.
I've checked appdirs and it appears to do quite nicely. It's also the way to go, if a user wants to access or store more data than config settings. Here's a link to appdirs' pypi page: https://pypi.python.org/pypi/appdirs/
&gt; &gt; &gt; For actual configuration, I use profig (disclaimer: 'cause I wrote it). Regading profig, in the pypi page it is said that it has built-in support for Windows registry. What's profig's policy for storing data in the windows registry?
One thing I like about tools like landscape or travis, is that they are public for open source projects. So they allow me to quickly get an impression of the state of the code of other projects. For your own serious projects you'll certainly want to automate this locally though.
awesome job ...
Alexey just made presentation at EuroPython "How Pony ORM translates Python generators to SQL queries": https://www.youtube.com/watch?v=xjikvIHjvHs
I certainly do. JavaScript is very nice language, not unlike Python, and you don't have a choice anyway if/when coding something serious for browser. On a related note, I do think that single-language, single-paradigm specialization is Java-v1-esque feature, a thing of the past, when trees were big and dinosaurs roamed. Today's developers need to know more than one thing to get stuff done, and JS is certainly a good option to consider.
You can learn from the nasty stuff as well. Hopefully why it was a bad idea and why not to do it.
The slides were made from the IPython notebooks. If you want to serve a live slideshow, just navigate to the tutorial directory (`skimage-tutorials/scipy-2014`) on the command line, and write: ipython nbconvert --to slides --post serve 0_color_and_exposure.ipynb This should work for the first 3 notebooks (notebooks prefixed with 0, 1, and 2); the rest were delivered directly from the notebooks. If you have fabric installed, you could also use fab slideshow from inside the `scipy-2014`directory; that builds all 3 slidedecks and opens the first in a browser. 
Read this: http://thedailywtf.com/Articles/Cracking-your-Fingers.aspx Fingerprints don't work at the gym. Also people really don't appreciate you storing their biometric information.
I wanted to write that :) Seriously, great job with your lib. it's not requests, but it does try to follow its philosophy.
it was an example. Ideally you woud set up a Mail() object (just like this module does), and then just Mail.send_mail(). That way you only need to instantiate the Mail() provider (with server and auth parameters) once, and then just send emails providing the relevant parameters (from, to, subject, body, attachment). I could say that sklearn is easy to use but that is because i have used it extensively. Same logic seems to apply to you Sir.
neat idea. i might start using that for these SimpleHTTPServer type problems.
For travis, I completely agree, but for landscape I feel that I'd want much more immediate feedback. Of course, providing it for everyone is still a great move, if some people find it to fit in their workflow, that's fine!
Someone better wash that jeep.
What a superbly relevant link; the internet still never ceases to surprise me.
It's time to start using [other discussions](http://www.reddit.com/r/Python/duplicates/2bjw9w/xpost_automated_paintball_sentry_gun_software/) and stop relying on that silly "X-Post" notation.
Currently it will store your config at a path relative to HKEY_CURRENT_USER: import profig cfg = profig.Config(r'Software\&lt;appname&gt;', format='registry') It is also limited to types directly supported by the registry (str, unicode, int, None), but support for all types is in the issue tracker. It's a relatively new feature, so I'm interested in recommendations and use cases.
To install the anaconda distribution you can now: pip install conda conda init conda install anaconda Before you had to download anaconda via [the website](http://continuum.io/downloads) and execute the shell script.
This is one of those projects where if you have to ask for help, especially with such basic tasks, you really shouldn't be attempting it. Dinking around with it on your own for funsies and to learn the ropes? Sure, knock 'em dead. Trying to implement a customer facing system that needs to work flawlessly? Not so much a good idea.
Wow, that is actually a very interesting feature. Thank you for pointing that out.
Got any fun learning projects to write using tornado? I always like to gain a bit of intuition before I dive into the source.
I started with Tkinter (I'm on a mac). Apps look great, use native assets, etc. Can't vouch for any of the other frameworks here, but I found theres plenty of documentation, it was straightforward to get going with it. It's got great support for basic menu-based, simple GUI stuff, but also support for drawing/image manipulation via canvas, which made it easy to write simple games. Also, I haven't hit the limit with what I can do with Tkinter yet, which I love, but will probably check out what other commenters are recommending later today. http://effbot.org/tkinterbook/tkinter-index.htm is a great starting point.
Well, I like the convenience of having all the slides in one place :)
Just tried this on a Windows laptop that had both "vanilla" Python and Miniconda installed. Here's the steps I took: -uninstalled Miniconda with its built-in installer, it uninstalled cleanly -uninstalled "vanilla" Python with Revo Uninstaller -uninstalled PyQt with Revo Uninstaller -installed "vanilla" Python 3.4.1 with (mostly) default installer options -ran the following from a command line: pip install py2exe cx_freeze conda I got the dreaded "error: Unable to find vcvarsall.bat" message. Conda requires pyyaml, requests, and pycosat. It will try to install them if they are not already installed, and pycosat is the one throwing the error. I did not feel like messing with a compiler in Windows. So I tried pip install pycosat and got the same error, as I expected. Then tried easy_install pycosat and still no luck. So I downloaded the unofficial binary pycosat installer from http://www.lfd.uci.edu/~gohlke/pythonlibs/ and ran it. That worked fine. Opened back up the command prompt and did pip install conda and it saw that pycosat was already installed and completed without error. Then I tried conda install dateutil lxml pyodbc pillow pyqt and got Error: conda is not initialized yet, try: conda init oops... conda init conda install dateutil lxml pyodbc pillow pyqt that worked. Then created my Scientific environment with conda create -n scipy_stack pyyaml requests dateutil lxml pyodbc pillow openpyxl xlrd xlsxwriter numpy scipy sympy ipython ipython-notebook pandas matplotlib nose spyder That also worked. Many arguments in that last command are unneeded, e.g. numpy would have been installed automatically anyway because it's a requirement for scipy. I think I'm all set now.
okay lets say without the fingerprints what tools and what do I have to know to be able to make the Database with name and payment info?
What does this solve that other package managers don't. Do we really need another one?
Continuum have put a lot more effort into providing binary compiled packages, which you can't generally get yet with pip (e.g numpy)
Not to dwarf Continuum efforts, but scipy and numpy are installed from binaries by default on OS X if you use pip - they started to provide wheels not a long time ago. I believe there are win64 wheels for numpy/scipy available from a third-party (nipy?)
parking the bus? Can someone enlighten me?
That's the answer I was looking for. Thanks!
That's a terrible argument. If you were creating a multipart message (like the guy using SMTPLib did), your code would be about the same length.
Hope that's an issue they can fix easily. BTW, anyone know what conda does with pycosat? I imagine it's for dealing with complex dependencies? 
I've heard conda works better on Windows compared to pip. If so, this would be perfect for some of our needs.
You might be interested in this [PyCon talk](http://www.youtube.com/watch?v=GAoheEUiwwY).
Yes, conda uses pycosat for resolving dependencies.
Hi, this is Audrey Roy Greenfeld. I have admin access to pyladies.com. regebro is correct, it's lack of time. Those who have had the time to write tend to be the ones who are into conferences, it looks like. But it doesn't have to be that way. Let's change things. To women reading this, do you have stories about your Python programming experiences? To men or women, got any stories about women's Python libraries, women's Python open source contributions, women Pythonista role models, etc.? Or any of the above mentioned in this thread? Writing a post is as easy as submitting a pull request here: https://github.com/pyladies/pyladies/tree/master/www/_posts I also do want to acknowledge that there's a lot of truth in this entire thread. Rather than getting defensive and ignoring the problem, let's acknowledge that a problem exists, then try and fix it together. Let's work together as women in the Python community, and as men who want to help make Python programming friendlier and more inspiring to women. I encourage everyone to flood the Pyladies blog with posts that are about all of the things mentioned. Don't be shy, just submit. If anyone has trouble submitting a blog post, feel free to ping me or another admin. Pyladies is about more than just conferences. The blog isn't currently doing a good job of expressing that. Let's fix it.
Don't write simple applications just for fun. Find something you want a computer to do, and make that happen with a Python program. Make it nice, and robust, and customizable, and easy to install (pip install YourProject). Make it work seamlessly on *nix, Windows, and Mac. Give it a user-friendly and intuitive frontend. There's no way to master a language unless you use that language *extensively*. There is no getting around it.
a very defensive style of play. If there is a bus (read: a lot of players) in front of the goal the opponents cannot score because they will always hit the bus (read: there will always be someone clearing the ball).
Answer questions on Stack overflow related to Python by reading the source code, Python C source is probably some of the cleanest stuff I've read ( in comparison to OpenSSH or PHP ). Read the source on how Python implements the modules themselves. Have mad science projects, stuff that when you try to explain it, you get a response like - https://www.youtube.com/watch?v=7G5F8ObYgjI
This is a good place to start leaning pro scientific computing in python. Not sure if it's excatly what your looking for http://software-carpentry.org/
To do Geodynamics/Earth system/Climate system modeling, if you are interested. It is very complicated.
Conda is the only that just worked for me on Windows.
You realize that's exactly what SMTP does, right?
&gt; I would like to be able quickly implement any idea - but getting to know various 3rd party libraries isn't that interesting Well, you could always reinvent that wheel. Maybe that would be interesting. Write your own GUI toolkit, web framework, async library, or whatever. But no, don't do that. Does everything have to be so "that interesting"? Can't somethings *just work*? And allow you to get the low level stuff out of your way so you can actually *get to the interesting stuff that you have in mind*? &gt; (plus they change every day). Not enough to matter much at all. Would you prefer that they didn't slowly improve? These both strike me as excuses that don't make much sense. There has never been a better time to be a Python programmer, and the quantity and quality of tools to help that along is amazing. Just target some project and do it. 
Thank you, soon we will start working in new extrations.
Xpost is a simple way to let you know there are other discussions. Its a way to slightly front load work for the submitter to save tiny amounts of work from every reader. Its still a useful habit. 
If you're itching for more, this is an extensive tutorial by Christopher Fonnesbeck from this year's SciPy: https://www.youtube.com/watch?v=vOBB_ycQ0RA
From the information about the data you've shared, it looks like JSON should provide a fairly easy option. A database is another option--sqlite is in the stdlib and is really nice, and saves you a lot of hassle. If you provide some more information about what your data really look like and what the specific operations you want to do are, someone might give you a hand figuring out your schema if you need it--exactly how you handle the lists of things (for example) depends on how you want to search for stuff. Relational databases are a great tool to have in your quiver and sqlite is a great introduction to them. (Setting up another SQL database or setting up mongo is a hassle you probably don't want to bother with for this sort of problem.)
Continuum also packages numpy with mkl which is both incredibly awesome and a huge pain in the ass to do yourself.
Given what you've got at the moment, I'd recommend starting with [JSON](https://docs.python.org/2/library/json.html?highlight=json#json).
I will just say this from experience: persisting data *sucks*. Every database, every index, every document store out there is going to make you suffer in its own way. Give them as few opportunities to make you suffer as possible. Redis isn't designed for the kind of lookups you want; it's designed for fast, simple, short-lived data structures. PyMongo might be the closest to the interface you want, but then you will have to spend literally months learning to avoid MongoDB's gotchas. KUMBZI's recommendations are good. The thing that will save you is that you *don't* have a lot of data. Make Python data structures in memory, and save them by pickling them, or write them to JSON if you need them to be more portable.
Since you're already using dictionaries with string keys, take a look at the [shelve](https://docs.python.org/3/library/shelve.html) module in the standard library. I made some test with it a while ago, and it seemed fast enough, but I didn't had nearly as much data as you have, so, YMMV.
No to mention it uses inconsistent names to specify sender and recipient: from and toaddr.
What's the best way to persist large datasets with Python? sqlite, postgresql? How's shelve for general use?
You're probably much better off with JSON. Then you can parse it with anything. import json some_dict = {'anything': 'at all', True: False, 'x': [1, 2, 3]} with open('file.json','w') as f: json.dump(some_dict, f, indent=4) ... with open('file.json') as f: some_dict = json.load(f) # all there! 
Since 10,000 is barely any data at all, use JSON! import json some_dict = {'anything': 'at all', True: False, 'x': [1, 2, 3]} with open('file.json','w') as f: json.dump(some_dict, f, indent=4) ... with open('file.json') as f: some_dict = json.load(f) # all there! 
Massimo - Thanks a ton for web2py !!! &gt; You can change the order in which they are imported by providing a list. In fact you can also conditionally run models based on the controller and action. This is good to know (Not that not knowing this till now was a problem) Can you point to documentation on how to do this ?
I am replying to publicly thank web2py google group. I t has NEVER failed me. I typically post my question at (my) night, and in the morning I have it answered. (i.e. less than 8-10 hours) People are really friendly and helpful. 
I personnally learned a bunch by playing with Boost.Python and look a bit a the Python C API. Also David Beazley's talks are excellent, especially http://pyvideo.org/video/1716/python-3-metaprogramming, I have no words to say how much I loved that talk.
I agree. Use JSON or Redis or both.
I would use flask until I discovered that it was a real bottleneck. Otherwise you are optimizing prematurely.
Best response ever!
Everyone here is recommending JSON. Let me throw a different hat into the ring. Pony up and model this stuff relationally. Draw a diagram of your top level object and decide whether it has one-to-many or many-to-many relationships with everything else. Every time you have a list against an object, you have a one-to-many. If you have lists-of-lists, this is nested one-to-many. Recursively repeat the process until you run out of relationships. Even if you don't use a relational DB, that's a useful process. Hopefully you learned something new about the way your data are structured. If you didn't, then you got a confirmation that your model and/or your understanding is already good. Win win. Modelling everything is a pain and is brittle to changes, but hot damn if you want to ask difficult questions about obtuse relationships, an RDBMS will eat it up. Postgres is commonly used among Python folk. 
And it's done. Awesome.
The moment I find a link I add them to the session page on the EuroPython website. So if you find a talk without sildes but know where to find them online, please tweet at @zerok :-)
Ah, that's why it didn't work two days ago when I put it up... it wasn't implemented yet :) 
This is a good opportunity to learn databases. Sqlite is fine, and built into the stdlib. Unless you know that it is exactly what you need and you are already familiar with the pitfalls, stay away from Mongo.
Raymond Hettinger would agree with you. 'for' loop has implicit 'if' in it, 'if I am not done with this loop'. So the 'else' clause makes sense that way. 
I tried to pip install Nikola (which isn't available on conda), and it automatically began to pip install Pillow. After a couple of hours of compiling, I gave up and tried conda install Pillow. took me 30 seconds.
For the love off god, don't roll your own format. Also don't tie yourself to a database the requires a sever process to be running, because you don't have *a lot* of data. Everything under a few hundred gigabytes is not *a lot* by any means. Use sqlite. There are reasons. Many. http://www.sqlite.org/appfileformat.html
you can add mine : https://bitbucket.org/pypy/extradoc/src/8fe97fa6f2122fd09877e973e41b67e620029a73/talk/ep2014/status/talk.pdf?at=extradoc and Armin's : https://bitbucket.org/pypy/extradoc/src/8fe97fa6f2122fd09877e973e41b67e620029a73/talk/ep2014/stm/talk.html?at=extradoc
With e installed you can do things like python -me os vim to open the source file of the os module from your current environment in vim. Richard Jones mentioned this in a recent lightning talk at Europython 14 http://www.youtube.com/watch?v=MqMlfNgBmKU&amp;feature=youtu.be&amp;t=39m6s
Keyword *generally*. conda will give you a working numpy regardless of the platform you're on (mac, linux, windows).
I feel like this package really needs to have version number 2.718. 
&gt; ... planning on performing the analysis by pulling data out of the store, just looking for a good way to hold it over time. I had a similar situation, where I needed to collect about ~30k datapoints + metadata, and generate matrices for analysis while collecting. I went with Redis + python bindings, and stored everything in hashes/lists/sets. Then with Pandas I could easily pull out the needed observations, and generate the required adjecency matrices. At some point however, with Redis you need to write a lot of custom code to do basic validation checks and more complex queries. So now I'm reaching the point were it might pay of to dump the data into another storage solution. So it depends on your requirements, and if it pays off to start with a more basic solution, instead of aiming for the perfect-but-possibly-overengineerd database. The datastructure and regrouping/query requirements certainly fit with MongoDB, and I found that datamodeling and queries with [MongoEngine](http://mongoengine.org/) are sometimes more intuitive then SQL. However, for long term storage, a properly set-up SQL DB is still more safe. One thing to also consider is the amount of "work" you can offload to your analysis-step and the software you use for that. 10k records is not that much, so e.g. Pandas + IPython can load it in memory while you manipulate it, reducing the need for more complex datamodeling and query support on the storage side.
Nice. Though `python -me ...` is still quite a lot to type. I'm on Windows and have a batch script in my PATH called c.bat (for **c**alculator"), with the following contents: @python -c "from __future__ import division; print %*" So from any command line I can do things like: C:\&gt;c 1+1 2 C:\&gt;c sum(n for n in range(100)) 4950
Great App! :D
Maybe it's converging?
Hey, how it works? What all python libraries you using?
Sorry, I should have said. The frontend is built using Flask, RethinkDB and RQ + Redis. The backend uses ffmpeg, some C code for fast DSP (identifying where one track ends and another starts - not currently running in production as it's too intensive), and pyechonest for the actual song identification.
Is this only going to support YouTube?
&gt; pymongo will be harder on the setup front than any reward it gives Can you elaborate? It was very easy to setup for me
It's pretty neat, but I would change the byline "Shazam for Youtube." I would be surprised if they don't have a problem with that. If Shazam doesn't take some action against trademark infringement then they can lose their trademark, so even if they are really cool about it they would need to send a cease and desist. ---- Could you give us an idea about how it works? It looks like probably Flask + Bootstrap. [Echonest](https://github.com/echonest/pyechonest) looks pretty cool. 
Nice! Thanks for the info!
Some that come to mind: * If you add an index after you've already added a lot of data, your database will be locked for an indefinite amount of time, possibly days. You're better off starting over. Always add indices before data. * Your data will have a lot of overhead. In my experience, a MongoDB is 10 to 100 times bigger than the data it contains. * You *need* a 64-bit operating system to run it properly. This is becoming less of an issue, at least. * ObjectID references are a bad idea. * If you try to use any of the sharding or replication features, your database will be locked for an indefinite amount of time, at various times, for completely incomprehensible reasons. Typing the wrong command that seems like a good idea at the time may make your database permanently unusable. Also, you [may lose data for reasons that are comprehensible but complicated](http://aphyr.com/posts/284-call-me-maybe-mongodb). Funny thing is I still do use MongoDB sometimes, when the data fits it. But I'm never happy about it.
/r/codeprojects could use some love. Also anyone know of other similar reddits?
looks really cool. I actually bookmarked it a few weeks back. Didn't get to check it out yet though.
The Bitcoin tip for a beer (5.832 mBTC/$3.33) has been collected by *ShinyCyril*. [ChangeTip info](https://www.changetip.com/tip-online/reddit) | [ChangeTip video](https://www.youtube.com/watch?v=_AnfKpypMNw) | /r/Bitcoin
+1. Maybe my experience isn't typical, but I thought this was something that devs need to do at least a few times a year. Model the data, import it into a database, and do whatever you need to do. If the data is pretty simple (seems like it), you can just get by with psycopg and some raw insert/update statements. For more complex data sets, you can use an ORM like sqlalchemy and treat things like python objects. Yes, it has a learning curve, but you should probably know an ORM anyway. 
Hey, I noticed that it only accepts complete URL's, like with http:// and the works. It would be cool if just www.&lt;etc&gt; or just youtube.com/&lt;etc&gt; would work as well. Great app by the way, definitely bookmarking for the future. :) 
It's definitely your elevator pitch but, yeah, it can't be your slogan.
A bit off-topic, but since I've used all of these tools except RethinkDB, I wonder, how do you like it? Have you compared it to mongoDB or CouchDB?
Docker recently had their 1.1.0 Release. I think one could deem it at least ready for staging, if not production. But I agree with DantesRequiem in that one should culture a healthy caution around such young projects.
RethinkDB was my first foray into NoSQL land so I'm afraid I can't compare it to Mongo or Couch. It's a joy to use - both the web frontend and easy scaling are brilliant. Especially the data browser which lets you execute queries with tab completion. I'm not a heavy DB user however - my usecase is rather simple.
Thanks for checking it out. Yes, I should certainly make it easier to enter data - thanks for the suggestion!
Very kind - thank you! I am hoping to write some articles in the future on how the track marker placement and identification is done - so hopefully some people will find that useful. The code definitely needs refactoring before it's ready for public consumption ;)
Yes you raise a good point, do you think something simple like 'Identify YouTube songs' would work?
Thanks for the pointers :)
 return set(x).issuperset(y.split()) Edit for some explanations : The intersection of a set with something is a set thus it has no duplicates, while y.split() is a list and contains the duplicates. Compare "dog dog".split() type("dog dog".split()) with set("dog dog".split()) type(set("dog dog".split()))
Where the hell can you buy a beer for $3.50? 
Name that Youtube Tune.
+/u/dogetipbot 5000 Do you use a library to recognize the songs?
Switching from Python to Javascript, I keep finding myself using "and" instead of "&amp;&amp;".
The student union ;)
Great idea and work, however, the one thing that kind of drove me nuts, was when I pressed that big green button to identify the song. The video on the next page just auto-plays and I did not see any volume button (unless I am just blind!). But other than that, good stuff!
Youtune
How about youtune?
Did.. did you send someone on reddit a beer?
Alternatively, as to what's wrong with your original, you could make a set of the input and then compare it to the intersection for equality (or compare its length). The key insight is that sets don't have duplicates. 
 def match_words_string(word_list, word_str): word_set = set(word_list) for word in word_str.split(): if word not in word_set: return None return word_str 
Cool idea, but was only 1/10 for the videos I tried. Does it only work on music videos?
I liked [Mastering Object-oriented Python](http://www.amazon.com/gp/product/B00JVQ14UO/ref=s9_simh_gw_p351_d2_i4?pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_s=center-2&amp;pf_rd_r=1THH3GZRKBA5HPZV3FE5&amp;pf_rd_t=101&amp;pf_rd_p=1688200382&amp;pf_rd_i=507846) by Lott and [Python 3 Object Oriented Programming](http://www.amazon.com/Python-3-Object-Oriented-Programming-ebook/dp/B005O9OFWQ/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1406312583&amp;sr=1-1&amp;keywords=object+oriented+python) by Phillips
Thanks! I'm glad to know how to get that done
Hmm that's disappointing! It should work on anything with a clear audio track in the background. I plan on experimenting with filters to bring the music above the noise floor.
&gt; sentinels do stand out. And indentation doesn't? 
Textbook pricing has never relied on logic. Just enforced demand.
AutoTune?
Cool app idea. I did some work with echo nest a couple years ago and it's great fun.
Have a look at *Pro Python* by Marty Alchin (if you're learning Python 2), or [Python in Practice](http://www.amazon.com/Python-Practice-Concurrency-Libraries-Developers/dp/0321905636/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1406331270&amp;sr=1-3&amp;keywords=Mark+Summerfield) if you're learning Python 3.
Which database adapter are you using? Is it caching results to disk somewhere?
If you're interested in math, go master the scientific python stack. Pandas, scipy, and scikit-learn will blow your mind. 
&gt; The advantage of map is that it works on more than just lists. It generalizes to fmap, which works on any Functor. This includes not just most containers but also things like the optional type (Maybe), monads, and applicative functors. With [monad comprehensions](https://ghc.haskell.org/trac/ghc/wiki/MonadComprehensions) enabled you can use list comprehension syntax for any monad. There are some other nice extensions for that sugar.
Thanks -- given that I like using flask, rq, redis, ffmpeg and pyechonest(!), I'll look forward to trying out rethinkdb. I have used mongodb for a very simple db and it was good fun -- a bit buggy at the time. 
This is my pyechonest project if you're curious: http://songgraphs.appspot.com/
If it's not interesting to you then save yourself the time and don't do it. Most of what you'll do involves 3rd party libraries. You have to be interested enough in a project to be willing to invest the time and effort it takes to improve your skills. There is no magic tutorial or book that will turn you into an expert, it takes years.
You could write a [reddit bot](http://praw.readthedocs.org/en/latest/pages/writing_a_bot.html) that reads youtube-music-video-centric subreddits like /r/music and the myriad of gopro-filled sports subs. "This video features $song by $artist. - Learn more about YouTuneBot(link to your site)" Or you could go to the dark side and do copyright enforcement for small labels :(
Very cool I love it! I'm close to getting my webapp finished who did you end up doing the hosting with?
"Type" in this context means static type. Typically, again in this context, the data you retrieve with a function like `type` is called a "tag". If you're interested in learning a bit more about how those things fit together [I tried writing an overview](http://tel.github.io/2014/07/08/all_you_wanted_to_know_about_types_but_were_afraid_to_ask/). Or, if not, just know that "type" doesn't always mean the same thing.
Also, once you buy one choice of syntax (either one, `for`/`in` or `(&lt;-)`) then you're *much* better off using it repeatedly instead of introducing loads of keywords.
Perhaps improper connection/transaction sharing ?
Haskell didn't invent the offside rule. ISWIM did back in 1966. At any rate, Haskell diverges surprisingly little from ML. It certainly makes ML better, but it's really a dialect of ML in my opinion. I do love me some partially applied functions. Python needs those, it'd be fun.
i just spent 24 hours chasing down a bug where // in urls kept turning into /. lo and behold uswgi was the culprit
it will be open source?
Let's turn the question around: What are the advantages of a document NoSQL database (MongoDB) over a simple solution using JSON file(s) to store persistent data on the drive that you parse with python code within your application. Python data structures and functions can take the place of the functionality of the database and its (foreign) query language, so when would you use it over the simple JSON file solution?
Thanks! I ended up hosting with Digital Ocean (I've been nothing but impressed with their service and have about 10 VPSs there). One $5 VPS is running the frontend and database, and then I have four worker nodes. I need pure compute, so the $5 VPS is perfect. However I'm looking to move the compute nodes to Amazon EC2 in the future. Good luck with your project :)
That's a really good idea! Time to get coding...
I feel that uncluttered syntax is as important as the feature, at least where Python is concerned: adding type annotations after every parameter reads hideously. Haskell's type signature is much cleaner to read -- it sits on another line and is sequential.
I've got a list of all the videos that failed - hopefully I can reduce it!
Possibly in the future - for now the code is a messy spaghetti I wouldn't wish to inflict on anyone :p
It would be super easy to build with scrapy and BeautifulSoup. Less so for PDF files because they're fucking confusing. I don't know of a similar page, but spend a bit of time with Python, build a template script, then adapt it to whatever site.
You can download the scraperwiki library and run a script off your local machine. Or you can use BeautifulSoup. Or try a GUI-based scraper over at kimonolabs.com
Or maybe /r/sideprojects
I would kill for native ($) and (.) operators in Python.
Yes, they all were https://www.youtube.com/watch?v=36bKE_JsHZs&amp;list=UUadZ6_NWdCN6YolgQdfV8Pg
If you used `entry_points` you could install it as a script so that you wouldn't have to use `python -m`, which would be vastly more convenient.
That talk: https://www.youtube.com/watch?v=36bKE_JsHZs ?
Whoops, let's try this again... /u/changetip drinks for /u/Leporad
The Bitcoin tip for 1 drinks (8.397 mBTC/$5.00) has been collected by *leporad*. **[What's this?](https://www.changetip.com/tip-online/reddit)**
Or you could simply do `alias e="python -m e"` in the shell instead of polluting /usr/bin with scripts.
Well, things like MongoDB are actually really bad at aggregation. (When a database's documentation suggests "you can do this using MapReduce", read that as "you can't realistically do this, but LOOK A DISTRACTION".) The big advantage of a database over Python data structures is loading time. Python data structures have to be reloaded from disk, and unpickled or un-JSONed or whatever, every time you start the process.
Spelling: "prefect_related" should be "prefetch_related". (But "prefect_related" is a super funny name for a function! :P )
and here are the pictures! https://plus.google.com/u/0/b/105528689027070271173/105528689027070271173/posts/ESTdqedcp4V
You could but that would need to be done on the user's end rather than automatically. Besides I see no issue with putting one script with a small, uncommon name in `/usr/bin`.
Maybe take the content from that and start a new site?
The classic scraperwiki links to https://morph.io/, which seems useful.
You might have to use something like [pdfminer](http://www.unixuser.org/~euske/python/pdfminer/) for PDF files.
So I'd really like to actually use a relational database, but I'm not sure how to do nested datasets. Every tutorial I've read has just had examples using a flat dataset (phonebook, students and test scores, etc...). For example, suppose I have a list of cars. Each car has attributes such as make, color, license plate, etc... Each car also has a list of gas stations that it has filled up at. In python using simple datatypes I'd make each entry a list of elements of the form: {'Make': 'Toyota', 'Model': 'Prius', 'Color': 'red' 'Gas_at': ['Station1', 'Station2', 'Station3', ...]} The first 3 attributes can clearly be columns in the top level table, storing each element. How would you go about storing the 'Gas_at' attribute? Is there a way to store a reference to another table? Is that even how it's done? The documentation is strangely lacking in this.
Yeah. I'm more just looking for a fault tolerant way to store the data. I'm pretty sure all analysis can be done in memory.
It's actually not all that similar. -fdefer-type errors just defers static type errors to be displayed at run-time when that code path is hit. It doesn't give you optional dynamic typing since the way the types are checked is still static. For example, you still don't have heterogeneous lists with -fdefer-type errors, and putting an int and a string in the same list will still result in an error. The only difference is when that error will be displayed.
I wrote a hack to test composition via Â´.Â´ out by overloading Â´_ _ getattr_ _Â´ and it was pretty disappointing. The problem is that things don't curry and functions can expect or return multiple values. Do you unpack the tuple or treat it as a single argument? It's a pain to manage.
You obviously didn't follow the link.
Is this real magic internet money? :O
Not sure why `vars` is used. You can do without it, and use e.g `args.verbose` rather than `args['verbose']`
Bingo, bango! I learn best solving problems. Especially when I make a simple mistake that takes a lot of understanding and digging to figure out.
You are right it's easy to use but you aren't mentioning that the above example is for Python 3.4+. A lot of people still use version 2.7.8. Syntax from 2.7.8 version isn't compatible with the above example.
Thanks a lot! Was searching for a similar tutorial. 
Anaconda causes pain too. It is far more beneficial to work on gaining a general understanding about how installing modules actually works, why there is a difference between 64 and 32 bit... etc. I have a youtube channel where I give a ton of python tutorials. I find people have quite a few problems using custom python installation like anaconda just as frequently as users having trouble installing things on windows. The solution is just understanding what is actually happening rather than just trying to rush through the installation process as fast as possible when you are starting out, and setting yourself back every time.
&gt; Windows: where nothing is ever uninstalled and lives like a ghost in the registry. Good explanation.
My gym uses barcode on a key fob thing. Cheap and reliable.
&gt; Well, my conclusion is this: Javascript is a most tool to have in your toolkit. you mean "must" tool ? Huh ? How the heck did you come to this conclusion ? unless you forgot to add the context "...in web dev" 
I teach classes on introductory programming, where students grapple with the idea of variable assignment and if statements. I get a couple hours per week for only a semester. I should devote time to 32bit vs 64bit architecture when all I want is my students to have a local programming environment? Web based ones only get you to the 10x code level, after all.
If that's the case, you can just use a simple web-based solution, like pythonanywhere.com. If you are just teaching introductory things like if statements and variable assignments, sure, you don't need to teach architecture... but then I must ask, what is the problem that you are encountering installing Python? Who is having trouble installing just plain Python on Windows?
This is just evil. It won't work in Python 3, though, because `True`, `False`, and `None` got promoted to language keywords.
I switched from Windows also, because of Python, but I still have ended up using Anaconda on my Ubuntu machine. It's just so much quicker to spin up virtual environments without needing to compile a billion packages. I also teach Scientific Computing, so I've had to use Windows just to make sure everything works, and I agree it's not perfect. I used the Software Carpentry approach of using the Git Bash shell in Windows, but you can't activate from there. It does work from the "Anaconda Command Prompt" though. I haven't yet run into the x86/x64 issue. As for binstar, I had trouble with it too. I even uploaded some of my packages to it, only to find that something went wrong when I tried to use them. I forget what the issue was but I gave up on it. Some advice for people on Linux (maybe Mac OSX?). Whether or not you're using conda, I recommend using [pew](https://github.com/berdario/invewrapper). It's a much cleaner alternative to virtualenevwrapper. It works fine with conda if you remember two things: to always do `pew ls` after creating a new environment, and pointing `WORKON_HOME` to the anconda envs directory. Here's how I set it up: # First, install miniconda3, choose "No" about modifying the path. mkdir -p ~/.local/bin # This is where pip --user installs shell scripts, I use it too. export PATH=$HOME/.local/bin:$PATH echo 'PATH=$HOME/.local/bin:$PATH' &gt;&gt; ~/.profile # you only want this to be run on login shells. ln -s ~/miniconda3/bin/conda ~/.local/bin export WORKON_HOME=$HOME/miniconda3/envs echo "WORKON_HOME=$HOME/miniconda3/envs" &gt;&gt; ~/.pam_environment pip install --user pew Then you can use `pew workon` (I alias it to `workon`) to launch conda environments, instead of `source activate`. The subshell approach is so much nicer than the shell variable approach.
I wonder how best to do this in Flask - no nesting needed
Or, just install Linux...
Nice tutorial, thanks. I believe [Click](http://click.pocoo.org/) is also worth mentioning.
If path is too hard then why programming?
&gt;Python on Windows causing you pain? Try Linux FTFY I honestly don't see the problem with "moving away from Windows." Seems like they improved their quality of life significantly. E: Seems this wasn't obvious, since we're in a programming forum talking about a programming article... but, I'm talking about a programming point of view here. Windows can be good for a lot of things, but programming/development isn't one of them in my opinion.
...Really? You're allowing remote arbitrary code execution from a completely unsecured connection? I mean it's cool, but there were about a million different better way to handle that than the way you did.
I am aware that this is dirty, but I must admit I have no idea how this could be attacked (unless someone highjacks my Twitter account). Could you elaborate ? How would you attack it ?
Lately, I've been loving me some docopt. [https://github.com/docopt/docopt](https://github.com/docopt/docopt)
For my purposes (mostly data analysis but also interacting with Windows-only hardware drivers/libs), I've found Python(x,y) easier on Windows. However, there isn't a Python 3 version, but it's on the road map. I like Anaconda on Linux. 
That's cool, hadn't seen **docopt**. Nice way to turn it around, right the documentation first and let it parse that for args 
This says "4[(n-1)! + 1] + n == 0 mod n(n+2).". Won't 0 mod x = 0 for all real x?
I'd have a dictionary with predefined commands and argument lists, something like: cmds = { "reboot" : ['reboot'], "play-music" : ['mocp', '-p'], "stop-music" : ['mocp', '-s'], } Then check for your command flag in tweets and only allow execution of the allowed commands through `subprocess.call` (rather than Popen). You could also probably figure out an easy way to intersperse predefined arguments with tweeted arguments -- say you're running utorrent and you want to downloads the latest version of Mint, you might tweet "cmd: torrent http://torrents.linuxmint.com/torrents/linuxmint-17-cinnamon-64bit-v2.iso.torrent" (despite being longer than 140 characters, you get the idea). Much safer, far more secure, and no more accidentally deleting your system when you get drunk and tweet "cmd: sudo rm -rf --no-preserve-root"
While I agree that it makes the best experience I've had with python on windows, I don't seem to see what you mean about conda environments. Here is some text from console: http://pastebin.com/raw.php?i=R7xkhFJr
This always annoyed me. You can do it natively with `pkgutil` and some [Unix-foo](http://superuser.com/questions/36567/how-do-i-uninstall-any-apple-pkg-package-file) or with some third party programs, but you shouldn't have to. All the stuff to do it is there for the most part, but not really well developed. I never understood why Apple didn't flesh it out into a proper package manager, considering a lot of developers use Mac OS.
Everything can and should be easier.
Well, I think it's easier on Linux yes, but it's still not ideal. Especially when you start mixing packages installed with apt/yum/pacman etc and stuff installed with `pip`. Or when someone writes their Python app to require Python 2.x but uses `#!/usr/bin/python` as the shebang. Which of course breaks things on distros like Arch where `python` is Py3k. Whether that's the distro or the package's fault doesn't really matter to me, it's still annoying.
Oh sure, I didn't do that for the sake of shortness, it's just a blog post. I liked the idea of the terminal command: one line of code, endless possibilities. Note however that as long as the script doesn't have superuser rights, sudo commands won't work (the terminal will ask the password and wont get it). You can still delete files, though.
Unsecure : Yes! Useful : Yes ! I like this kind of stuff, thanks.
I'm still using optparse just out of habit. 
Linux seems to be severely lacking in the entertainment side of things, I think that might be putting some people off, it's the main reason I came back to windows. Under linux I can play very few games, unity web player just doesn't work at all, netflix needs a lot of work doing to get it working properly, it just can't hold up outside of a working environment. Setting up a c++ compiler on the other hand was a breeze, doing that in windows was a complete and utter pain in the arse.
Thanks for the clarification.
I would still put `__init__.py` files in unless I wanted to use namespace packages to allow different things to install modules into the same namespace. It's easier to understand when a package maps directly to a single folder, it makes it clear that that folder is meant to be used as a package, and it means that `import package` works - with namespace packages you have to `import package.mod` or `from package import mod`.
Thanks. Many people are recommending WinPython, maybe I'll give that a try too.
And to add: Many popular tools like Photoshop aren't available on Linux (I know you can use Wine, but it's never as good as running it natively). I use Scrivener for writing, and for a long time it wasn't available on Linux. Even the tools that are available aren't that well tested, mainly because there are fewer people using them. Linux systems are great for programming. Other things, the jury's still out. 
I use linux + wine to build python apps that I also use in windows. Yes it can be a pain to set up, but for me that is far better than the pain of actually having to use windows directly for development (there are many things I actually like windows for, this is not one of them.) So far I've only done this for python2.7, but I do want to create a similar setup with python3. I'm hoping that by already having this separation layer I won't have to worry at all about conflicts between python versions, I just boot up a virtual machine that has whichever version I want to use as a base.
Yea i looked into Cygwin but meh maybe i should give it more of a look over. I looked into Vagrant &amp; Virtualbox but when i was using that with laravel i still had to SSH into it using iTerm to do certain things so surely if i used Vagrant &amp; Virtualbox on Windows i'd still have to use cmd.exe to SSH in? Or would you recommend just getting a virtual Linux installation or Dual booting even and going that route?
I guess I'll have to try WinPython, since so many people are recommending it
I think installing it isn't the issue it's setting up the PATH. But, the last few times I've installed python with official installer it was set automatically and just needed to reboot.
Yeah, the major source of problems is when you install something that depends on a Python package, so you *have* to install the distro package to satisfy dependencies.
I'm writing an internal tool at work used for monitoring and administrating a multi-os datacenter with 100's of VMs; working on getting the core open sourced when we're done. Anyway, I really like the method of putting the chart as its own endpoint. I think I'm going to start doing this instead of relying on streaming db data to a javascript charting library in every scenario.
Oh, no, I have a Windows install at home for gaming and stuff. I definitely was not saying "Windows is total and utter shit and there's not ever any reason to use it." Development, though? *NIX hands down. Windows is silly stupid for development.
Yeah, rendering visualizations client-side means sending all of the requisite data to each client. Rendering and caching static images (dynamically) using matplotlib on the server is a great way to go.
The only improvement I've found for windows dev is installing codeblocks, that's stupidly difficult for *nix.
I'll have a look into that all thanks :)
Thanks for the tip!
True. People do dumb shit though. 
&gt; Windows is silly stupid for development. Visual Studio? All things considered its probably the best IDE in existence. Assuming you're doing Windows-centric development, of course.
 def match_words_list(words, s): if all(w in words for w in s.split()): return s
You learn to stand before you learn to walk. I'm wondering who wants to learn to program computers but doesn't know how to install a compiler or set a path variable.
 sudo checkinstall make install Done. Now you have it listed in your package manager and you have a .deb file if you ever want to install it again without compiling.
Yes, Anaconda has problems, but it is far easier on Windows, there is really no comparison for beginners. If you're not going to be using packages with C extensions, I see your point, but otherwise I'm skeptical. I teach Python to scientists and if I have to spend the whole first week explaining modules, packages, C extensions, PATH, etc., my students are going to say it's not worth it and go back to Matlab. Some of them do anyway, for various reasons, so I really have to make it as easy as possible. In short, for some groups there is value in rushing through the installation process as fast as possible. I do try to get to the details later for those who seem like they would benefit, but that's a small percent. Then there's the handful who I've convinced to switch to Linux, they get all the info :)
Does installing python packages, using a method other than installing with your `pkg-ver.exe` really mess with the registry?
Yeah, sure you can. I use Arch as my primary OS, which is even more do-it-yourself than normal, but that doesn't mean that I wouldn't prefer it to just work without hassle. It's a fair point, though... I do at least know *how* to fix it when it happens.
&gt;Windows can be good for a lot of things, but programming/development isn't one of &gt;them in my opinion. You don't happen to know of any good articles or web sites that could help sway Windows programmer die-hards who still think there's no task too trivial that it can't use a GUI, do you? I've seen a pay video about the subject of "using the whole Linux OS as an IDE", but that's it. 
&gt; I've never had any problems with it other than I wish I could resize the installer window and they need a Python 3 version The 2 GB of RAM limit is a bit of a joke. 32-bit Python is a kid's toy.
&gt;And to add: Many popular tools like Photoshop aren't available on Linux And many popular tools aren't available on Windows, and many aren't available for OS X. That doesn't mean that comparable tools don't exist. When you think about it this complaint really boils down to "Windows-only software only runs on Windows." I remember one person telling me she'd love to switch to Linux but she "couldn't sync her iPod with iTunes" over and over. I had to explain that Linux users don't use iTunes. They do, however, use Banshee and Amarok and gPodder and lots of other software that will sync just fine with her media player. &gt; Even the tools that are available aren't that well tested, mainly because there are &gt;fewer people using them. Much of the software available for Linux is cross-platform because it's open source. It's also often supported by corporations and/or academia. You apparently don't know of the infamous example of spreadsheets' statistical functions being tested by academia and lots of errors being found. A spreadsheet with only a handful of developers, Gnumeric, had a few errors and fixed them all within a few weeks of being informed. Microsoft Excel, however, began a comedy of errors. In some cases they fixed things in ways that introduced other errors, they claimed things were fixed that weren't, and in many cases a lot of the bugs took TEN YEARS to finally be fixed. Tiny little Gnumeric, however, was passing all the tests with flying colors year after year. Statisticians eventually put out a warning that no one should use Excel for statistical work! They even recommended Gnumeric or OpenOffice over Excel: http://biostat.mc.vanderbilt.edu/wiki/Main/ExcelProblems http://www.csdassn.org/software_reports/gnumeric.pdf &gt;Linux systems are great for programming. Other things, the jury's still out. I tried using desktop Linux once a year since 1999 and always ran into problems of one sort or another. My first attempt with a commercial distro resulted in my sound card not working, 2D-only graphics, either no ability to read Windows partitions or no ability to write to them - I forget which, and no software. Someone told me "There's 5000 packages!" to which I replied, "Yeah, and 4000 of them are text editors!" Fast forward to 2010 when a screwed-up XP partition made me evaluate my options of installing XP from scratch, upgrading to Windows 7, or switching to Linux (lots of work any way). I'll leave out the details, but after testing all the options - and choosing the right distro - the Linux option ended up to be the best and easiest of all! It helped immensely that I'd had a rule for two years previous: "When all else is equal, choose cross-platform; if all else is still equal, choose open source." This resulted in most of the software I was using being available on Linux, and out of what wasn't I actually found better alternatives on Linux. July 18 marked 4 years for me of using Linux 8 hours a day every day for my work (and home use). I believe that today the jury is no longer out and I honestly bristle at speeches that begin "You know I'd love to use Linux but it just isn't ready because...." as a way to stifle legitimate comparison. Windows is a perfectly valid desktop option. So is OS X. And so is Linux. In Tom's Hardware tests of a Ubuntu distro vs. Windows 7 Linux won whether you based the winner on number of wins, number of important wins, or margin of wins. Among the more impressive results, Ubuntu's ext4 file system could copy gigabytes of data around a hard drive fully 20% faster than NTFS! Add in the security, customization, package management, cost advantages, etc. and it's quite capable of going toe-to-toe with any desktop OS. Open source software such as Firefox, PostgreSQL, Apache, NginX, SQLite, LibreOffice, XBMC, and of course R and Python today not only stand out as examples of commercial quality open source software, many either are considered more reliable than their commercial counterparts and/or actually are considered best-in-class above their commercial counterparts. All of the big data solutions today are open source and open source dominates cloud computing and virtualization as well. We're truly in the golden age of open source right now.
You often get settings files left behind and what-not. Although my understanding is that the leftovers you get in OS X aren't nearly as big a deal as registry cruft. 
There's still a lot of things one needs to add to a Windows box to equip it for development that are already present in Linux. Recently on a forum a group of primarily Windows developers began a discussion about what software they used to produce diff files. The lone Linux developer piped up "Um... 'diff'" and explained that it was bundled with Linux. :-) 
I already knew that, it looks like there will be a corner turned relatively soon but as it stands for the most part, unless your game runs under wine, you are shit out of luck. I've used linux, ubuntu specifically on and off for a number of years, I do realise it has its upsides but there are certain areas where it is currently not up to snuff, it's great that they are trying to change that but right *now*, they are not even close.
Isn't this dancing with Twitter's terms of use quite a bit?
Hope you have a strong password on your Twitter account.
Depends how curious/determined someone wanted to be... a proxy could inject HTML, for instance.
It's 1234. Same combo that's on my luggage 
Nice, how long did it take to implement &amp; how much Python experience do you have?
Sweet nice to know
+/u/Dogetipbot 4900 Doge verify
Every single person taking a programming 101 course who hasn't already taught themselves. In other words, a lot of people.
I've only been working with Python since the beginning of the summer for physics research purposes, but I've had fun figuring out how todo stuff like this. It took 2-3 hours for me to learn and implement, but if I knew what I was doing beforehand it would've probably gone a tad faster. :P
You're missing the fifth digit.
I would recommend against it. Missing init files are causing subtle different behavior that can break some libraries.
Only if the thing you installed doesn't have an uninstall target, but that's not really an *installer* problem because you compiled it from source and didn't package it.
This one does it for me when I have to use a Win box: https://github.com/babun/babun
compare-object (can be invoked with just 'diff') :) I'll admit, though, there's a culture problem. Even though many of the tools exit in Windows, most people don't know about them.
Python on Windows causing you pain? Get the fuck off Windows!
Really depends on the kinds of data you have an what kind of charts you one. One reason I prefer JS charts over static images is because I want my charts to be zoomable, adjustable ranges and to allow things like disabling values. Not that images are not useful just not the only or best solution. JSON arrays of your data are not particularly big so its. Not like you a shcleping a lot of data around (usually)
&gt; Windows can be good for a lot of things, but programming/development isn't one of them in my opinion Exactly. At work I run Debian for development. At home I'm running Windows because I game (although SteamOS may push more linux gaming), and fire up a Debian VM when I need to do some dev work. It's all about using the right OS for the job!
That's a many-to-many relationship. Each car can fill up at many stations, and each station can fill many cars. With one-to-many, you add a column to the "many" table which contains a reference (a foreign key) to the "one" table. You associate multiple things with an item in the "one" table by having several rows reference it in the "many" table. You can't use the same approach to model a many-to-many. We'd want a single row to have a reference to multiple records in the other table, but the database will only allow a foreign key to be one reference. Instead, we model the many-to-many as a pair of one-to-many relationships. Using your example, this means creating a new table "refills". Each car has many refills, and each gas station has many refills. To make things more concrete, the tables might have these columns: cars: id make model gas_stations: id name refills: id car_id -&gt; cars.id gas_station_id -&gt; gas_stations.id `id` is what's known as a surrogate key. A key is something unique and unchanging about each row, like for example the car's `model`. In practice it's very difficult to find something about your data which *never* changes and is *always* unique, so lots of people throw their hands in the air and use a surrogate key. These are very often just an integer which counts up with each new row (whichever database you use, it will have an "auto increment" feature for this), or sometimes a randomly generated UUID. Anyhow, with that out of the way, you make a relationship to another table by referring to it's key (as I have crudely notated above). Well I've been typing for a while now. I'm going to stop here, but let me know if you need further help :)
At least there's Homebrew.
Brilliant i_am_cat!
The fact that there are tons of options for any given functionality in Linux is often touted as a benefit. Now you're saying that Windows having many options for diff functionality is a bad thing? Can't have your cake and eat it too ;-)
also i want to make a game so i know i need Pygame and PyOpenGL
I have some scripts to modify. :D
&gt; All args after first: " ".join(sys.argv[2:]) Try again. ;)
Presumably by "a text file," you're referring to [get-pip.py](https://bootstrap.pypa.io/get-pip.py). You need to save that file as a Python script, then run it with Python. When I click that link with Firefox, I'm prompted to download it automatically. Your browser apparently does not do this. Try pressing Ctrl+S (Command+S on Mac) after loading the page. Once you have pip installed, it's trivial to install whatever other packages you may need.
I didn't like Celery since it seemed to require the node that creates the tasks to have the same code as every worker node. You might also want to send messages to non-Python applications. If either of those things are imaginary problems though please let me know.
thanks!
Click (http://click.pocoo.org) isn't *awesome*, it's **epic**. I love it. Suddenly writing command-line tools isn't a pain anymore. It's easy. In fact, I'm writing more and more of them. It's easy, intuitive, does everything I want. The API is what I wanted it to be, even before I could imagine it. It's infinitely easier than anything else, including *docopt*. That library has always felt fragile to me the same way doctests do. Click is stable and nice and easy and great and awesome and epic. I could toss in more compliments, but you get the picture. Yes, I'm gushing like every time time I meet GvM, but I'm doing it with **just cause**. Doubt me? Try building a little script with click and you'll understand my raving fanboy-ism for this library.
http://click.pocoo.org is the new hotness. Easier to use and doesn't feel like it's as unstable as docopt.
You should look at bokeh: http://bokeh.pydata.org
I like this, it's so reddit to completely ignore the fun and novelty of something and just say something negative like 'I hope it's secure' when you know this was just for fun.
Thanks for the gold!
I used python rq for a bit but then opted for celery. There's a huge misconception that I had about celery, that rabbitmq was over kill, it was difficult, it was tough. Once you install celery flower, it was so easy.
Anyone who doesn't actually want to learn to program but needs to learn to program to help them solve problems they do care about. Given that pretty much any field of science now uses math or at least statistics â€” biology, anthropology, linguistics, you name it â€” all these people need to program computers to help them in their fields.
I'm curious about your opinion of [SageMathCloud](https://cloud.sagemath.com) ... it's centered around mathematics, but you actually have several programming languages, plain editors and a standard linux bash in a terminal. There are tons of libraries already installed.
I figured some people learning Django (or curious about it) might want to see how basic a simple project might look that's very functional. This is super simple, but as you will see it works great. Needs pagination, but I'm posting it before I go to sleep. You don't actually upload images with this, just post links. I don't want to be bombed by file uploads, but it would be easy enough to patch it in. This is just a basic starter app to kickstart any similar project you have in mind. Deployed example: http://pychan.nuclearviking.com/ bitbucket repo: https://bitbucket.org/johannestaas/pychan cheers! upcoming features: * ~~show summary of last few posts for each thread in home page~~ done * throttling... don't kill my VM guys :P #Edit \&gt; You can greentext now ###Edit Fixed large image issue that may crash browsers. Quick hack - lots of refactoring and cleaning to do still
Give Winpython a shot, it doesn't have the ITK bindings but it's otherwise very similar to Python(x,y). It also has 64-bit and python 3 support. Also, it doesn't automatically write to path, you have to go into it's internal control panel and set to path. (This could be good or bad depending on your set up)
Depends what you want to use programming for. I started on science programming using Matlab/R and didn't bother with things like Path variables for quite a while.
This is true, however it still leaves some config files on your system. If you want to remove an app completely I always advise to check out [AppCleaner](http://www.freemacsoft.net/appcleaner/). It's completely free and will also remove files associated with the app you want to delete!
True but again, more than likely especially in a Windows environment you're going to get in a PATH situation sooner or later. People "in the know" can find and resolve an issue in 10 minutes which may take someone with no experience hours or a day depending on their google-fu. To me, that's a lot of wasted time. Not necessarily without its purpose if the person learns, but still.
No it doesn't.
Or just learn how to solve problems in any environment.
want to install curl? Sure, just download 4GB of system libraries first.
* How would check_kill() work with multiple workers? Not to mention it would take a while to run when a lot of data is present * Submitter ID should probably be a UUID rather than a hash of the post 
Gotcha, thanks!
Though you're perfectly right, heterogeneous lists are perfectly possible in Haskell (see HList) though rarely needed (I don't use them much in Python either) and more awkward than normal homogeneous lists.
Is this a joke? Are you a troll, or actually trying to sell a script a fifth grader can design? 
Man it took me way too long to figure out that jew-ping wasn't some slang I'm unfamiliar with.
 1. Stop abusing functional style views. 2. Don't use global variables. 3. Any tests? 4. Use factory boy for random data populating. /thread
What's wrong with the docs?
Don't forget to add it to your environment variables too if you're on windows. (Does linux and OSX have environment variables?)
Why bother with Windows anyway? Mac is Unix-based and so is Linux, Windows is not.
what is the talk about ?
How would you compare the simplicity of click to cement? https://pypi.python.org/pypi/cement
I started out with rq and I didn't like it because the scheduler wouldn't work like cron. And I found that there examples were lacking. The celery documentation and search results are way better. I use redis with celery and I think it wasn't that hard to setup with the amazing docs. The hard part for me with celery was setting up the init script for the different environments dev/staging/prod.
Sorry that so many of the images are broken--I tried using [ipython nbconvert](http://ipython.org/ipython-doc/1/interactive/nbconvert.html) to convert a notebook to html and then copy/paste it into tumblr but clearly there's something deficient about that approach. Anyone know what might be wrong w/ the source of my post that prevents the images from be displayed?
I personally use GitHub, but usually the answer to why BitBucket is usually free private repos. 
ES6 is Harmony. However, unlike Python, at the moment, the "current" widespread, real-worldâ€“usable version of JS doesn't have those shiny things. Harmony is kind of like Python 3 â€“ very cool, possible to use, but not practical to use. Except that I predict that Harmony will be real-worldâ€“usable in the next few years, while I think Python 2's energy and community won't survive the transition to 3, so it'll effectively never happen. I kind of have a hunch that Harmony/ES6 may in fact supplant Python 3, but that's just wild speculation. 
Read up on Pandas and IPython Notebook
You need to be more clear about your options.Option A is continue with Physics in your home state, option B is out-of-state comp sci and C is a German comp sci. The answer is: it all depends. I would seriously consider posting your question with the options spelled out more clearly to /r/machinelearning as they are very good on this type of thing, especially regarding who gets hired and which skills are needed, and closer than a lot of Python programmers who can sometimes just be web programmers. Speaking of that subreddit, I recommend you read the thread/interview with the Facebook machine learning guy. He said he doesn't hire people for his lab without PhDs. Not unreasonable for one of the top AI labs in the world to require a PhD, but keep it in mind that at the top end in both universities and companies a PhD and a publication record is vital. There are plenty of other positions in scientific computer that don't require more than a MS though, so don't do it if you feel it's too long as it will grind you down. Physics is well respected everywhere for the mathematical difficulty. My impression is that someone with a Physics degree who can demonstrate application to other areas through a small job or a github repository will have no problems. It's claimed by some, not sure if it's true, that in some instances like finance physics is in demand more than CS. Physics would certainly put you closer to the other sciences if you want to shoot for scientific computing roles. The bottom line is that CS is not software engineering, so physics people don't have too much difficulty muscling in on CS because it's all just theory and maths. But a lot of it would depend on your topic and capacity to shape that topic towards the statistical skills you want. So option A isn't a bad thing, especially if money is an issue. It's not clear to me if you can do a MS in Physics with funding instead of the PhD in Physics with funding, or if it's one then the other and you can drop out once you have the MS, clarify that. Option B and C both require money, you are the judge of that. With C there are some well regarded institutions in Germany, and some very good research that's almost all in English as well as the masters courses. German institutions frequently are detached from universities so both the universities and the institutions don't rank as well because they tend to be specialised. They are weak in rankings that average over all areas, just like the Microsoft, Google or Facebook research groups would also not present on university rankings even if they were counted. There is also a historical dimension that Germany as we know it was only "recently" formed and the regions and regional capitals are all equally powerful so there isn't a logical center which gets all the grant money. All that said depending on the institutions the Germans are actually quite formidable and cutting edge (although the Swiss and the British are likely better, it all depends on the sub-discipline in question). Any slight loss you might get, versus option B, from not having brand name recognition when you are back in the states you will make up for with the wonderful experiences you will have with real beer, real bread and excellent people in another culture. Life is only lived once and it is difficult to put a price tag on such experiences. The USA still has the top institutions though, without knowing all the other variables if the option B you are looking at is a CS top 10 it's probably better to get the premium from the brand and the research community that will be there, if the place you are looking at is a top 20 or top 30 in the US, it's still great but a good German university masters is close to that weight class and will not only be respected but will have a good research community. 
If you cared about this project you'd make a pull request instead of sniping at the project in reddit comments. OP took the time to build something he thought was useful and share. Is it perfect? No. Is software ever? This trend of the dev community tearing each other down instead of being constructive gets us nowhere
Browse pypi.python.org for packages to install via pip. You can also use `pip search` but the site may be more intuitive when you're starting out. pip looks to this site by default
He's not really sniping, he's providing information. It's not delivered nicely or detailed at all, but it's miles better than saying 'its shit, gtfo'. If he got rid of the arrogant `/thread` bit at the end, and rephrased it more neutrally, it'd be great feedback, if unspecific. You're not wrong in general, this is just the wrong comment to explode on, is what I'm saying.
Pandas (and numpy, scipy and statsmodels) covers off a fair chunk of R, Dplyr and Reshape2. IPython notebook (along with its nbconvert functionality) covers a lot of RStudio and Knitr. You'll probbaly want matplotlib + seaborn for plotting, but there's also a ggplot library for python if you prefer that syntax. If you do any machine learning related work then sklearn is also worth getting. Potentially you can just grab Anaconda from continuum.io and install seaborn on top of that to get everything in one go with an easy install. Oh an if you are at all interested in efficiency you will want to look into numba and cython, for which R has no equivalents that I know of.
Yeah, and next you'll tell me that 2015 is the year of the Linux desktop. 
I see your point, but I don't think unspecific feedback can ever be great, or even good. This is only another comment to skip over while you're looking for some useful discussion. `/thread` is not just obnoxious, it's arrogant. My point is that we should be more supportive to our fellow devs - it can be easy to get discouraged.
To add to /u/imcinne's answer, you might want an IDE in addition to the IPython notebook (but try the notebook first), I recommend PyCharm. The notebook is great for interactive data explorations interspersed with text, while PyCharm is more like RStudio. Python is a bit lacking in terms of statistical tests compared to R, so if you do exotic statistics you may occasionally want something that's not in scipy, statsmodels, or sklearn. In which case it's nice to be able to call R right from the Python interpreter. Two options for that are rpy2 and pyrserv. The former also has helper functions in pandas and the IPython notebook. I also highly recommend Seaborn, especially if you use linear models. There is a ggplot clone that will be more familiar, but Seaborn is more polished and its Pythonic syntax may help your transition. Finally, regarding knitr, depending on what you do with it the IPython notebook may be enough, but there is also pythontex which I think is closer to knitr.
&gt; arrogant shitty code is shitty code
This is [youtube-dl](https://github.com/rg3/youtube-dl/) is packaged - I was pretty impressed when I first saw it.
Yes, I've had quite a bit of experience with Django... Worked with it professionally for a while as well as lots of side projects like this. Using it at work now too. I really don't know it as well as I'd like to and as well as I should. There's so much functionality that I keep finding out about that I've never seen before. My reason for making this was partly just to show how easy it is to get into though. There's really not much there and it's a fully functional image URL board. But, when you dig into it there's always some new template context, middleware or plugin that everyone else uses that would make your day easier.
I have a lot of mercurial repos so I ended up migrating all my github repos over just to consolidate them. I have one github repo named "PLEASE_CHECK_MY_BITBUCKET_ACCOUNT"
Wait. What? Would somebody be kind enough to give me a 'for dummies' explanation of that fizzbuzz one-liner? What's the forward slash, what's the asterisk, and I guess while you're at it, what's the minus tilde? Can't be remainder of twelve divided by three-halves, and the 2*"Fizz" is not print Fizz twice. I tried typing `12%3/2*"Fizz"or-~12 ` into the shell and got back 13. So there's another thing. I quoted the line in Google, apparently everybody in the world has pasted it onto her website, but didn't see any explanations. edit later: ? Answer is too obvious to explain? 
Its an image embed board
Well, if there's no image appearing in a thumbnail, it's safe to say you probably don't want to click it, but there's a few things I need to test. For one, I don't want to have the code check the data of links. I don't want someone to be able to submit me a link, then have that trigger me to make a request. That could be bad. Otherwise, I'd check the first 32 bytes or something and use filemagic. It does check via a regex client and server side, client-side just to prevent it from happening from user error. So, it has to at least start with https?:// and end with jpg|gif|png|jpeg. However, that's certainly not enough for really knowing it's safe, I agree. I strip tags out of user input. I've tried XSSing it and I couldn't get anything useful to happen. [Check here](https://www.owasp.org/index.php/XSS_\(Cross_Site_Scripting\)_Prevention_Cheat_Sheet). It follows "RULE #2 - Attribute Escape Before Inserting Untrusted Data into HTML Common Attributes", but yes I am still wary of how it's doing what it's doing. I've tried to break it without success though. But there's still the case that a malicious user is serving an evil binary at http://evil.com/notanimage.jpg. If so, it links to in the href="$link" and &lt;IMG src="$link". I don't believe it matters for the src attribute, but for href it will cause a user to initiate a download if they click it probably. Maybe even the server could redirect to something else? In any case, those links are not guaranteed to link to images, and are in effect, just posted links. It will take you clicking on them to initiate anything bad, so if you don't see an image that's your verification at the moment.
did not know python could run zips straightforward
criticizing tool choices is classy 
very classy
Command-line developer tools are 130MB, and that includes C compiler and tons of other stuff. Just about the same size as on Linux.
Well. I found one exploit. Embedding huge image files like for example images found on this [website](http://visibleearth.nasa.gov/view_cat.php?categoryID=1484) can result in a browser crash when visiting the website.
Thanks! There's a few really awesome CLI libraries out there, but I've never found argparse to be difficult, and since it's included in the standard library I usually gravitate towards it. Whenever it's been a while since writing a CLI, I always end up opening the documentation and Finding my way through it. This cookbook should come in handy.
[Anaconda](https://store.continuum.io/cshop/anaconda/)
Thanks for sharing.
&gt; If you want more popularity projecting your ideals on others.... also very classy. 
Don't do it! Use iPython to mix R and Python. For statistics, 2d plotting and tabular data manipulation, R is better than Python, whereas Python has the advantage for lots and lots of libraries for everything. Use R for core data manipulation, and Python to tie it to everything else.
you mean like the assumption that you made that the author is motivated by popularity and should thus use a tool that you suggest for it's popular power? the author made something, you shit it on it and criticized the tool choices. classy
I would say Python 3 Object Oriented Programming http://amzn.to/1xltKoR
Pandas is incredible for data wrangling and replaces dplyr, reshape2 and lots of core R, like data.frame. The IDEs available aren't quite as well adapted as RStudio for data analysis, but PyCharm is great in general for writing scripts, and IPython Notebook (or JuPyteR colaboratory as I think its supposed to be called now!) is fantastic for presenting your workflow transparently. If you use IPython, you can always use [R magic](http://nbviewer.ipython.org/github/ipython/ipython/blob/3607712653c66d63e0d7f13f073bde8c0f209ba8/docs/examples/notebooks/rmagic_extension.ipynb) to call R with your python data if it would be easier.
Could you elaborate on how I might mix the two languages?
Could you explain what it means to "call R" or "call python"?
Spyder is the python equivalent of RStudio. I actually prefer IPython notebook for a lot of uses.
Will anaconda auto-update all the packages/libraries for me?
IPython has special syntax to work with a Python module called RPy2 such that in a "cell" you can actually have python interface with R, pass data to it and then collect the results of the R code and convert it back into python data structures. Thus if you are in the middle of some analysis and have some obscure statistical test that no python module supports by R has you can do that one step with R code right in the notebook and have the results come back for further analysis with Python.
Something is seriously borked with your design. When I open up a single webpage, 3 GB of memory shouldn't evaporate, my CPU shouldn't jump to 100%, and inuse pages of memory shouldn't start being paged to disk. So I have to ask: is your code creating thumbnails with the images users are posting, or is it just serving up the original images and forcing the web browser to resize the images? My guess is that your code just serves up the images without creating thumbnails. Combine that with that hi-rez NASA photo someone posted, plus whatever else is there; the result is that a single user can cause a denial of service attack against anyone wanting to use your site.
I've generally found pandas to be great for tabular data manipulation in python -- better than R in many ways: you need DPlyr and such to be able to do comparable things in R, and even then the python/pandas is often quicker. What tabular data tricks are you missing from R? Perhaps there's things that I'm missing out on because I never realised I wanted them ... 
&gt; Some things have been added to bpython recently - and it's probably very broken! Isn't that what tests are for? I run a large open source project (150k+ lines). I'm terrible about writing tests, but the ones it does have are kept working. It sucks, but you gotta do it.
All of our tests are passing, and we're making progress on the test coverage front. I know testing is never easy, but we're finding interaction with various terminal setups particularly hard to test. You can be sure we'll add a test for anything broken you find!
A good first step would probably be, to whitelist a number of domains. If you only allow images from let's say imgur, you will have a lot less to worry about. You should probably also remove the settings.py file from bitbucket. Users should generate their own settings.py file as it contains a secret key which is supposed to be unique and well, secret.
You might like to take a look at http://www.firedaemon.com/ . Run any .exe as a service. It's not as good as having it rolled into the stdlib but it works for us - have been using it for several windows-centric clients for a number of years. 
That's been my experience as well. Several times I tried to switch entirely to python and have not been able to do this. Though each year pandas improves significantly. But still plyr, dlyr, and ggplot2... not to mention the occasional invocation of lattice (e.g., splom). 
I gave your deployed example a try. The first thing I noticed was one of the thumbnails was loading somewhat slowly (5-10 seconds). I then noticed something even more strange. It was a HUGE image. 21600x21600 - 40MB. Pretty sure I started downloading that, rather than a thumbnail when I hit the page. 
Yeah, R base R is definitely awkward without dplyr, but not as awkward as base python. The libraries make any language. I just mean that if you already know R, its best to stick with R for its strong points, and start out learning python just for where its needed. 
python, like json, is also human readable. Except you can also include comments. Comments on code and their data structures work really well together. Good luck.
&gt; some libraries just do not work with windows. for example the signal module. That's like griping that the winsound module doesn't work with Linux :)
Checked it out, this is really cool! Opened [one](https://github.com/bpython/bpython/issues/319) issue for you. One other thing I noticed, the keyboard shortcuts down the bottom weren't displayed for me like normal bpython. Is this to be expected?
Yes. Let's all use perforce and svn. No. Git only. 
You don't need a C compiler to install curl on Linux though.
Captain, I can't see shit!
Thanks! Haven't pushed the changes yet because this unearthed a lot of problems with input. I removed the status bar a while ago because it didn't make as much sense for a non-fullscreen app, and I wanted to ape the vanilla python prompt more. It still comes up when you pastebin (F8) for example - I just got rid of the welcome message because it felt weird to have it appear and then disappear. This definitely hurts discoverability though - I'm not sure how to get that feeling of immediately knowing how to use the tool back.
I know ipython is great at graphing, you might want to look into that.
What about implementing a help command, '?'. You could have a one line message at the start as simple as 'Enter ? to access help' and then a super simple commands page with more help. By the way, is there any way to change the editor you use for F7?
For your post view you can split the business logic out to your model. Then you have a flow like this: * View takes a POST request. * View calls out to model code to instantiate an instance. * In the model you check if you have to create a new thread and do your validation, throwing an exception if necessary. * Your view returns a representation of the new instance or an error to the user. This way you can test your model and view independently more easily. It also makes it easy to independently change your model and view as needs change. Google "MVC in Django" to see some examples of this in the wild.
oh shit.. [edit, update etc!](https://lh6.googleusercontent.com/-iJtmZ7SriJ8/U9V9zQN_85I/AAAAAAAASr8/EdkM1TCSH7E/w753-h565-no/20140727_233035.jpg)
I also cannot see your example, but matplotlib is one of the go-tos for graphing in python, maybe check that out.
[here's the example](https://lh6.googleusercontent.com/-iJtmZ7SriJ8/U9V9zQN_85I/AAAAAAAASr8/EdkM1TCSH7E/w753-h565-no/20140727_233035.jpg) I forgot to post the link! cheers I'll have a look into that. 
&gt; !/usr/bin/env python FYI: not a shebang line.
Speaking of which, curl comes preinstalled on OS X. It's wget you should be bitching about. 
Sure, so its worth noting that that's more than a one liner, its a codegolfed one liner, intended to be as short as possible (as in, that bit of code is the shortest possible "FizzBuzz" in python2), so lets talk about it, also sorry if this comes off as too simplified: for i in range(100):print i%3/2*"Fizz"+i%5/4*"Buzz"or-~i So lets start by breaking things down for the problem which is normally phrased as "print every number from 1-100, but replace any numbers divisible by 3 with "Fizz", any divisible by 5 with "Buzz" and any divisible by both 3 and 5 with "FizzBuzz". #a "normal fizzbuzz" for i in range(1,101): if i/15==0: print("FizzBuzz") elif i/3==0: print("Fizz") elif i/5==0: print("Buzz") else: print(i) Ok so this is obviously not a one liner, but its very easy to understand. Now comes the fun part, rolling things up. First, lets talk about integer division. In pthon 2, "/" defaults to integer division (if both the dividend and divisor are integers), in python3 this was changed so that you need to use // to integer divide. Integer division is in essence repeated subtraction, def int_divide(divisor, dividend): quotient = 0 while divisor &gt;= dividend: quotient +=1 divisor -= dividend return quotient What that means is that in the code, `i%3/2` is really (i%3)/2 (because mod and divide are equal precedence) and we need to keep in mind that in python, 0 is falsy and anything else is truthy. So saying `if i%3/2` is the same as saying `if i%3/2==0`. So, when exactly is `i%3/2==0`? Well, this is integer division, so when you divide by 2, it will be zero if the value is less than 2 (right, like 1/2 is 0 remainder 1, and 0/2 is 0 remainder 0). So that is really saying `i%3 &lt; 2`. And similarly, `i%5/4` is really `i% &lt; 4` So why is that relevant? Well lets look at it again. We want the numbers from 1-100, but `range(100)` as is used in the golf example provides 0-99. We can more or less convert `i%3 &lt; 2` to `(i+1)%3 &gt;0` right, when i=3, then i%3 &lt; 2 and (i+1)%3 &gt;0, for 4, 4%3 = 1, which is less than 2, and 4+1%3=2 which is greater than 0, for i=5, we finally get that 5%3==2 and (5+1)%3==0, so both are false. The two are equivalent. The fun part is though, because of those falsyness rules, so we can though this see that `i%3/2 &gt;0` and `(i+1)%3==0` are functionally equivalent, but the first can be shortened to 5 characters (`i%3/2`) while the second is 9. So lets use what we know, working from the "normal" example. First we change range(1,101) to range(100) and then switch the if statements to use the new numbers we have. for i in range(100): if i/15==0: print("FizzBuzz") elif i%3/2: print("Fizz") elif i%5/4: print("Buzz") else: print(i+1) So this is an improvement, but those pesky if statements are causing trouble and using lines. Enter string multiplication. In python, `4*"hello world"` is "hello worldhello worldhello worldhello world" So that means that `0*"some string"` is the empty string "". Well, you know what 0 or one of something is a hell of a lot like? That's right, those if statements. So lets use that new knowledge. for i in range(100): print (i/15==0)*"FizzBuzz" print (i%3/2)*"Fizz" print (i%5/4)*"Buzz" print(i+1) #well now this doesn't work So now we can eliminate the first line by adding the second and third ones together to get the final result string, like so for i in range(100): print i%3/2*"Fizz"+i%5/4*"Buzz" print(i+1) #still not working :( Now another bit of python magic, empty string ("") evaluates to false as well, so saying `if "": print "hello world"` doesn't print anything. Furthermore, in python, you can have the syntax `X or Y`, which is shortand for `if X: X; else: Y` Using that bit of knowledge you get to for i in range(100):print i%3/2*"Fizz"+i%5/4*"Buzz"or i+1 So now that last bit, the `-~i`. That's all for a gain of a *single character*, you completely change and over-complicate this bit of code to make it 1 character shorter. Lovely. The ~ operator in python is the bitwise inverse. Essentially, given a bitstring like `10011010`, `~10011010 == 01100101` (that isn't python). For integers, the bitwise inverse is basically `~x == -(x+1)`. So if you do `-~x`, you do `-(-(x+1))`, which is just `x+1`. And because of the way things work, you can do `or-~i` instead of `or i+1`
Windows is deficient in that it doesn't implement POSIX; that's why your signal module doesn't work. Another good example is the default event loop doesn't support subprocesses - so your code using asyncio has to put in nasty-looking workarounds like: import asyncio, os if os.name == 'nt': loop = asyncio.ProactorEventLoop() asyncio.set_event_loop(loop) else: # work normally The right thing to do is for developers to refuse to support the odd one out &amp; demand adherence to industry standards, however IT is the one vocation where anyone can get away with calling themselves (or being called) an 'engineer' without an engineering qualification and similar such governance failures, so its not likely to happen. 
Not to diss the effort that's gone into writing them but I found that celery's docs obfuscate how simple (distributed) task queueing really is. Check out sidekiq's docs (the ruby equivalent): http://sidekiq.org/ Or Flask's: http://flask.pocoo.org/ Now check out celery's: https://celery.readthedocs.org/en/latest/ Celery's a great library, I think it just undersells itself.
How would you get banned if you arent logged in?
Why use Celery? I have one run one task each time a mesg gets sent to a queue. I figured pika would be the simplest to get going. 
This is great, and looks way more useful than even ipython. I hope this project gains more popularity.
&gt; I didn't shit on it, I offered constructive criticism. that's debatable. &gt; Even so, you shouldn't post something if you can't take people shitting into your nostrils. right, I don't like your shitty comments, and I am criticizing them. can you take it? 
Post your code and the full error/exception message you're getting.
Code: http://pastebin.com/V7zjp1yA Error: http://prntscr.com/470tq9
craigslist does IP bans, also it's kinda a dick thing to do to any person who explicitly doesn't want that happening on their site.
Fixed! Just pushed to master, so if you `pip uninstall bpython curtsies; pip install git+git://github.com/bpython/bpython curtsies` help and raw_input should work better. I did a new release of curtsies to fix the bug, so be sure to reinstall that.
This is an incredible wealth of resources. Thank you! I especially like the scikit machine learning map!
...just use the RSS feature built in to the site?
Get used to using google. Search for "python x" and you'll find a python library for x. You didn't need us to tell you about matplotlib, which an extremely widely known package. Also /r/learnpython
Thanks. What are you entering as the IP address? I suggest using 127.0.0.1 (loopback) which is always a valid IP address. You probably already know this but: 1. Spamming someone's IP address with random traffic falls somewhere on the spectrum between annoying and illegal, depending on where in the world you are. 2. Python is a slow language so you're unlikely to be saturating your upstream connection with this code. To do this you would need to be running multiple threads/processes and using async IO. 3. Even if you're saturating your upstream connection, you're unlikely to be saturating the target's downstream connection as many residential connections are asymmetrical. 4. ISPs tend to block any incoming unsolicited inbound traffic to residental IP addresses so the traffic likely won't even be reaching the target, if the target is residential. 5. This is not a DDoS attack because the attack is not distributed. This is a DOS attack, and not a very good one at that.
Hey another question if you don't mind. So my project involves a website and a separate instance for an API on a different port with different authentication (session on website, OAuth2 on the API). I've also got 2 databases on the backend. I'm planning on running the 2 websites from the same apache host and the databases from another server. Explain the worker nodes, are they for redundancy? Is the 5$ for the VPS a monthly cost and then kicks up if you usage goes over similar to all the other players? I'm not actually used to this hosting situation I use dreamhost currently and I have about 15 VMs spun up at home all running debian.
Are you definitely passing an IP address to socket.send and not a hostname? I would assume socket.send is calling socket.getaddrinfo to resolve a hostname into an IP address which is failing.
 is_new = False for post in current_posts: if post in seen_posts: pass else: is_new = True return is_new This would probably better be expressed as for post in current_posts: if post not in seen_posts: return True return False or just for fun, as a oneliner return any(map(lambda p: p not in seen_posts, current_posts)) 
I don't think your situation is unusual. I've been using Python for years and looked up the solution for this. It makes sense to me only because I've been reading code for a while. These kind of problems almost never come up in most day-to-day programming; they're just sort of brain teasers to help you grasp concepts. Programming is hard; working well on a team is harder - but if you like solving problems stick with it and it can be very rewarding.
idk if you saw the edit or not but it has been resolved :)
Good catch.
I'm a professional programmer and I get flustered as fuck with the prime number stuff. I've looked up the solution and it's confusing to me too. I just never bothered to try to understand it. Don't worry about it. It's incredibly common to suck at programming. Pretty much everyone does. Even the best of us suck at 95% of programming tasks, and it's that 5% that they *don't* suck at that makes us employable. For the most part, unless you're using Python primarily for numerical analysis and theory, you're not going to be doing that shit. It gets a lot more fun than that too.
Yeah, I tried setting myself a hard limit on the video at 3 minutes, but had to push it to 4--even with a trivial (virtually no-op) example. I made a follow up video here: [Scraping w/ Celery in 6 minutes](https://www.youtube.com/watch?v=-ISgjBQDnhw&amp;index=2&amp;list=PLtLImFco1g8YrtOLKQeg47jJpqV6_R507)
Celery is batteries included-- you don't need *anything* to get it set up, you simply write your function like you would normally write it, and attach a task decorator, then call it with `.delay`. Celery will handle scheduling, a free synchronous mode, and all kinds of cool things out of the box. With pika, you have to specify your exchange, your routing key, the message values; there's a lot of implementation details that celery just handles for you. I would argue that pika is harder to get going, it's a much lower lever of abstraction than celery is. tldr; pika is to urllib2 as celery is to requests, and more.
vim ftw! Python is the perfect language for vim. No real need for autocomplete and everything can be done efficiently through the command line.
That's sick. I actually check out the source of modules pretty often. pydocs only help so much. I was about to ask if I could see other parts of the library, but just tested: python -me flask.views vim and it worked as expected! Awesome module, thanks.
The masters programs at Aachen looks good. If you haven't travelled I'd recommend it, tourism is nothing like staying in another place for a period of time. Germany is pretty safe and similar in the sense of things will likely work how you expect them to work, so there no bribes to get things done like in other places and the officials aren't massively corrupt. It's also close to a lot of other countries. English use is pretty high, but I'd recommend learning as much German as you can. I lived in another country for a few years so I say you'll only get out of it what you put in, but there is a good degree to be had and a lot of cool experiences. Even if it's a mix of likes and don't likes you come away from it knowing who you are a bit more. There are other chances to do things like this, but if you start a career then a family you might only ever do quick holidays and tours and never get a good chance to live in another place for an extended period. Any network you develop will not be transferable to the USA. But it's more of a serious qualification than a MBA so I am not sure how good the network would be from a one year masters in the USA anyway.
Programming can come in many parts. There's the super sciency part, and just the app building part. There's plenty of people who can make applications, but they make them shitty and bad but it doesn't matter they work well enough for the situation. The sciency part is much tougher-- and prime numbers and efficiency is part of it. Prime numbers not necessarily something useful on a day-to-day basis, only useful if you're studying cryptography &amp; security. You should learn to make things work first, then work on making things work well next.
Glad to hear it!
&gt; throttling... don't kill my VM guys :P Why not use HTML caching like a chan board does? 
Although, what makes it bad? my DStat server shows very good results and my dos nulled it out.
overall great post though - super accessible and clearly laid out
Yes, though I'm not sure which package I've seen it in. I was working with enthought and the project had 3d visualization and an interactive terminal. Don't know what part of enthought provides it though. Maybe it was Maya? If you look and can't find anything, let me know and I'll look into it.
That's what we have proxies for
It could be used to generate valid CSRF tokens.
Try using raw_input()
Are you sure you're using python 3.2? I ask because this is exactly the kind of error you would get in python 2.x. You can find out what version you are using by stating python and typing the following: __import__('sys').version They changed the way the `input` function works in python 3. Before that you would have had to use the `raw_input` function to get the same result: &gt;&gt;&gt; s = raw_input('--&gt; ') --&gt; Monty Python's Flying Circus &gt;&gt;&gt; s "Monty Python's Flying Circus"
Cool. I just wrote this [very efficient polygon simplifier]( https://github.com/Permafacture/Py-Visvalingam-Whyatt) and was wondering who else might find it useful. Check it out and maybe it would help you add really serious zooming/rescaling.
When it comes to stuff like that it may be the math that is making that task difficult. Just give it some time. Stuff will eventually come to you and programming will be easier. Don't worry, most people suck at programming (especially in the beginning)
This is actually wrong for the task. You wont be making prime numbers. There is no formula to generate the prime numbers. For this task you would search for prime numbers. So, if you want to break it apart, it would be something like: What are prime numbers? How can we check that a number is prime? How can we check several numbers in a row? How can we count the prime numbers we have found?
Think of it this way every number that is not prime is dividable by the prime numbers that came before it and you start with the prime number 2. That would be the brute force approach at least. And most of us suck compared to a bunch of other people so join the club, also the entry level MIT courses are tough they are meant to weed out the weak especially in math as much as they are meant to educate. So an MIT or Stanford level course may be a badge of honor or masochism but isn't the best way to start learning something you have no exposure to. There are lots of other places to start like The new boston channel by Bucky Roberts on Youtube. 
Break the problem down into parts. Which of these two parts is giving you trouble? * Test if a number is prime * Find the thousandth item that matches some test
Great work man! Will definitely try it out.
I think if you looking a good book on python in general you should check out this one: [Writing Idiomatic Python](https://www.jeffknupp.com/writing-idiomatic-python-ebook/) 
To protect you from IP bans, or prevent you from being a dick? I think using proxies only solves one of those issues.
Well, yeah. I just wanted to point out that it was in fact against their terms of use. Obviously if you don't make an impact, it'll likely go unnoticed.
Thanks for the explanation. 
It only solves the first one.
It would be a very serious vulnerability to leaf a CSRF token, as it allows attackers to run a CSRF attack (from the browser of the victim) and to submit his own POST requests. Leaking the SECRET_KEY does not really expose the CSRF token. SECRET_KEY is used in `get_random_string()`, used in `CsrfTokenMiddleware` : if not using_sysrandom: # This is ugly, and a hack, but it makes things better than # the alternative of predictability. This re-seeds the PRNG # using a value that is hard for an attacker to predict, every # time a random string is required. This may change the # properties of the chosen random sequence slightly, but this # is better than absolute predictability. random.seed( hashlib.sha256( ("%s%s%s" % ( random.getstate(), time.time(), settings.SECRET_KEY)).encode('utf-8') ).digest()) return ''.join(random.choice(allowed_chars) for i in range(length)) There are other sources for the token than the secret key, so it won't be exposed (but still, the token will be weakened, as 1 of 3 the sources will be compromised). However, SECRET_KEY is used as-is in Django's cryptographic libraries, so by leaking it you don't actually know what vuln you open : it could be in any 3-rd party app you use. And it's not actually "opening in vuln", but "shooting yourself in the foot", because this is not a flow in the 3-rd party app : it is normal to assume that the SECRET_KEY will be kept... secret. EDIT: In fact, no need for 3-rd party apps. I ran a few greps in the Django source code and leaking the SECRET_KEY compromises : - Password reset tokens (directly predictable if SECRET_KEY is available) - Protection against "message" tampering in cookies (uses signing) - Session tokens (enables session stealing) - Session signing (enables session tampering)
Old user here, did you added list reloading to storm-indicator? Love the app. Regards 
Would love to get it to work with hylang.
Tyvm!
I've also found out that even the simplest math problems are much harder in code than in paper. I think it's because mathematical notation is so much more expressive that your typical ASCII on a plain text file.
Or with good 'ole comprehensions: return any(post not in seen_posts for post in current_posts) 
Try another path, there's lot of courses. I'm also new and I'm following the one of coursera, python for everyone. It's great. I also think you don't suck at python, you suck at numbers, just like me. Not big deal. 
The worker nodes carry out the audio analysis on the video. There's a $5 monthly cost for a 512MB VPS which goes up if you exceed your monthly bandwidth allotment.
There is a github repo for the code that was developed at the tutorial. Unfortunately no videos for the tutorials (the one by Radim on Topic Modeling and the scikit-learn tutorial by GÃ¤el were brilliant). https://github.com/1000mercis/ep2014_zeromq
Whats the benefit of pyzzer over PEX?
I also have a blog post about it [here](http://pythonadventures.wordpress.com/2014/01/05/python-equivalent-of-java-jar-files/).
The fix you made is not perfect though. It only checks the image when the link is created. A user could link to a small image file when the link is created and afterwards just change the file to something else. And you also might still be vulnerable to "decompression bombs": Empty images with a huge width and height which have a small file size but when loaded become very large.
Doesn't run on non-wimdows systems.
I have a really stupid question: what is the eqivalent to 'run' in ipython in bpython?
yes google is great... when It's something unfamiliar it's often better to ask people with experience the best direction to go though. Googling something unknown in a familiar field is more practical as one has some kind of foundation in the area. Thanks for the sub link
How does this compare to the other generators?
ooohhhhh personal attacks..... so very very classy. 
deleting your shitty comments is the classiest. 
Eve seems to be "just" a REST-Framework, whereas Flask is a Web-Framework. That includes a Template-Engine and the (primary) intent to send back an HTML-Page rather than just JSON-Data (which of course is also possible). I wonder why they used Flask instead of just Werkzeug - the WSGI base of Flask. So probably one can also use easily all the Flask-Stuff within Eve. If you are more about creating a dynamic Web-Page, then Flask is sufficiant and imho the right choice, as you wont use any added value of Eve. If a RESTfull API is the most important thing for you, obviously Eve should be a good option.
anyone know why I am getting this error? (python 2.7 on osx) &gt; &gt; Traceback (most recent call last): &gt; File "craigslist.py", line 79, in &lt;module&gt; &gt; results = parse_results(TERM) &gt; File "craigslist.py", line 17, in parse_results &gt; search_url = BASE_URL.format(search_term) &gt; AttributeError: 'tuple' object has no attribute 'format'
http://bipython.org/
To make sure I understand, `%run` runs the lines of the file as though you typed them in, vs importing which keeps the symbols in a separate namespace? Edit: Ah, it seems to run the module, then update the environment with those symbols. Run appears to be basically globals().update(__import__('module').__dict__) This seems limiting for interactive development in a few ways to me (disclaimer - I don't know that I understand run correctly yet): 1. that module's imports aren't rerun if they've changed 2. the results of multiple runs are confusing because symbols from old runs aren't deleted 3. you might not want all the variables dumped into your global REPL namespace Number 3 is a matter of preference, but 1 and 2 are I think good reasons not to implement something like `%run`. My workflow in bpython is to import the script and use functions from it, and when I make a change to the script I hit F6 which reruns the entire session in a fresh interpreter, after clearing `sys.modules` to make sure we reimport everything. I don't mean to come off as dismissive though - I know a lot of people really like `%run`. How do you use it?
If you can, switch to Python 3.3 (or better yet 3.4). If you need some library that hasn't been ported to python 3 yet, at least update to 2.7.
Here's a great video that details the motivation behind creating Eve and some solid use cases - https://www.youtube.com/watch?v=PeQiM7ii_3o Slide deck as well - https://speakerdeck.com/nicola/developing-restful-web-apis-with-python-flask-and-mongodb As far as flexibility, there is active development on a SQL version in a separate branch - https://github.com/nicolaiarocci/eve/tree/sqlalchemy Hope that helps. Check out https://github.com/tomchristie/flask-api too!
Because the code is buggy. BASE_URL is defined as a tuple, while it should be a string like this: BASE_URL = ('http://chicago.craigslist.org/search/' '?sort=rel&amp;areaID=11&amp;subAreaID=&amp;query={0}&amp;catAbb=sss') 
Honestly, I haven't used or paid attention to anything besides mynt for the past few years so I don't really know how to answer that question anymore. If you're current setup has any pain points feel free to share and I can let you know if mynt would handle them any better. Otherwise, I'd recommend skimming through the quickstart guide and see if anything grabs your attention.
Whoops, last minute change by me introduced that one. Should be fixed now.
&gt; Whats the benefit of pyzzer over PEX? The benefit depends on your exact use case. pyzzer is a lot smaller and simpler, does not need installing as a library, is packaged as a runnable zip - eating its own dog-food :-) - and provides Windows executable support, which AFAIK PEX doesn't. However, I'm sure PEX does things that pyzzer doesn't (e.g. embedding eggs) - pyzzer is intended to just bundle up a set of Python packages and modules (not PyPI distributions) into an executable zip, and is not designed as an "enterprise" tool.
I'd suggest going further. Since these are for checking presence, use sets current_posts = set(x['url'] for x in results) ... seen_posts = set(row['url'] for row in reader) Then what you already have will work just fine (`for post in current_posts...`) Or you could replace the check with return len(current_posts.intersection(seen_posts)) &gt; 0 Or return current_posts.intersection(seen_posts) != set() And then we could split it into `new_posts` and `has_new_posts`, so you can easily extract a list of the new posts: def new_posts(results): ... return current_posts.intersection(seen_posts) def has_new_posts(results): return len(new_posts(results)) &gt; 0
Try, try, try, try, try, try, try, try. Keep trying. That's programming. MAKE SURE you are working on a real project. It's fucking hard. It continues to be fucking hard. It's so hard you'll feel like a moron. Keep going. Eventually you'll start to accumulate knowledge. 
We'd love to have your feedback on the Anaconda mailing list to make it better: https://groups.google.com/a/continuum.io/forum/#!forum/anaconda One common source of frustration on binstar (for me at least) is that it isn't easy to notice (except through the GUI) that a binstar package was uploaded for osx-64 instead of linux-64 or vice-versa. If you try to install from the wrong platform the error message is that the package doesn't exist -- not that you are on the wrong platform. I run into this problem when I switch between linux and OSX. What does pew and virtualenvs do that conda envs lack? I don't ask this to be argumentative but to understand what is missing in conda. 
Agreed. This was running once every *10* minutes.
Thanks for the long answer! I think %run is mostly used by people who used matlab before switching to python. In science and engineering you often write scripts which calculate some number and then display or save them. 90% of my workflow is exactly this: i have a script/program open in a text editor and then if i want to see results I just run the script. After the script ended I can then examine the data which was created during the run by plotting it. The reimporting stuff is not that important because i usually use run with finished libraries to caclulate values and data. So it does not matter if the modules are not reloaded. When I am developing modules, I just use ctrl+. To restart the interpreter. So the short version: in my opinjon %run allows a matlab like workflow of first running scripts to crunch data and then to work with the results in the repl. At least thats the way I use it and that's also the reason why bpytbon is not interesting for me. Sorry, i am on mobile, otherwise i would've written mkre detailed.
I'm a programmer. I've been one for, uh, 7 years now. But I suck at math. Really, I'm terrible at it. My IT teacher (when I was learning Pascal many, many years ago) would tell us to find all the prime numbers or something. I didn't even know what prime numbers were, at the time. I'd write the entire code, the whole thing, and then where I was supposed to put the algorithm, I just wrote "PRIME NUMBER ALG HERE". Did not receive full credit, of course, I look at project euler for example and while it's great, I still feel like solving math problems, not programming problems. And I suck at that.
The only way to get good at something is to do it repeatedly, and find ways to do it better each time. There is no shortcut. Do the work.
Sounds good, I'll try to reproduce the error. I think it had something with dependency tracking across binstar and PyPi. &gt; What does pew and virtualenvs do that conda envs lack? I don't ask this to be argumentative but to understand what is missing in conda. pew is actually a separate approach from virtualenv, or I guess a wrapper on top of it. So actually it is something that virtualenv lacks too :) The idea was fleshed out here: [Virtualenv's `bin/activate` is doing it wrong](https://gist.github.com/datagrok/2199506). In short, instead of using the more fragile activate/deactivate approach, pew starts a subshell, like ssh, and you can return to the parent shell with Ctrl+D. Not all the criticims of virtualenv apply to conda, but I was used to it so I figured out how to get pew and conda to work together. I'm also not such an expert on shell stuff so I don't know how feasible this is cross-platform, or whether there are backwards-compatibility issues, etc. 
this is trivial using ipython notebook with pylab x1 = np.linspace(-5, 0, 200) x2 = np.linspace(0, 5, 200) plt.plot(x1 , (1 / x1**2) - 5, c='r') plt.plot(x2 , (1 / x2**2) - 5, c='r') [plot](http://i.imgur.com/zyCv2Jo.png?1) if you try a line plot over the interval [-5, 5], matplotlib will connect the line where the asymptote should be... 
http://www.celeryproject.org/
Thanks for the replies everybody, I will check out the classic code. But I was really looking for a community that is writing high quality and re-usable scrapers: of course I or anybody can write a scraper for whatever site, but it is a lot of duplicated effort, people solving the same bugs (or not), testing, etc that should not have to happen.
I hadn't imported the modules properly... but even doing so I get an error flag for division by zero error : Warning (from warnings module): File "/home/tri/Desktop/untit.py", line 6 plt.plot(x1 , (1 / x1**2) - 5, c='r') RuntimeWarning: divide by zero encountered in divide Warning (from warnings module): File "/home/tri/Desktop/untit.py", line 7 plt.plot(x2 , (1 / x2**2) - 5, c='r') RuntimeWarning: divide by zero encountered in divide &gt;&gt;&gt; code : import matplotlib.pyplot as plt import numpy as np x1 = np.linspace(-5, 0, 200) x2 = np.linspace(0, 5, 200) plt.plot(x1 , (1 / x1**2) - 5, c='r') plt.plot(x2 , (1 / x2**2) - 5, c='r') 
This is cool. 
You can still use pyInstaller...it's not literally an exe
Do you know if pgs4a still maintained? I've used it in the past, but the current versions don't seem compatible with the Android SDK and fail when running *python android.py installsdk*. I tried pgs4a versions 0.9.6 and 0.9.5 and both have the same problem. After download the Android SDK automatically (android-sdk_r20-linux.tgz), the script errors out because he can't find the following file: &gt;Traceback (most recent call last): &gt; File "android.py", line 66, in &lt;module&gt; &gt; main() &gt; File "android.py", line 40, in main &gt; install_sdk.install_sdk(iface) &gt; File "buildlib/install_sdk.py", line 225, in install_sdk &gt; get_packages(interface) &gt; File "buildlib/install_sdk.py", line 160, in get_packages &gt; with open("android-sdk/extras/google/play_apk_expansion/downloader_library/project.properties", "r") as f: &gt; IOError: [Errno 2] No such file or directory: 'android-sdk/extras/google/play_apk_expansion/downloader_library/project.properties' Looks like the pathing in the SDK changed a while back and pgs4a never updated. Did you have this problem? I would contact their support directly, but the maintainer contact info isn't listed and their support page just points to the forum which is "down due to massive spam". I have no idea how long it's been down or how long the pathing has been broken, but the last release was 2013 and aside from your post I can't even tell if the project is dead or not. 
Craigslist doesn't have an API?
Nope.
I agree. I think this is the same challenge with the logging module, or SQLAlchemy: there's enough edge cases that the documentation for the simplest 20% can be harder to work with than it should be.
&gt;Is it common to suck this bad at python as a newbie? Yes. &gt;I have zero experience in programming...but I'm wondering if my learning curve is going to be steeper than most. Yes. Stick with it, OP. The most difficult things can be the most rewarding.
you need to import matplotlib correctly or start ipython with the flag --pylab=inline import matplotlib.pyplot as plt 
Interesting you are getting the error, I hadn't ran into that.. But try changing the 0 in linspace from 0 to something really small i.e .00001 should fix the problem
Its good to see them compred, but lookig at say Pyramid, the models file looks way more complex than Django, but from what I understand, SQLAlchemy is a lot more powerful than the Django ORM. So more relevant to simple web apps rather than "serious" data reporting. 
I've used supervisor for managing services (daemons) on a Linux machine and was happy. If you want to pursue "continuously running" tasks I'd recommend it
Thanks for the description! Plotting (inline at least) is pretty solidly outside the scope of bpython - we've got (awesome, Sloan foundation funded) IPython for that. But I recognize this use case (I once wrote a lot of MATLAB code myself). bpython does has `bpython -i yourscript.py` (like IPython) which will run the script and then start a REPL in that namespace. It does mean you have to restart the interpreter each time you would just `%run` your script in IPython. You can also `from yourmodule import *` and use F6 to reload the module, though that behavior isn't quite the same as being in the module.
That's intention on behalf of the designers. We never got an ML-style module system like OCa*ML* did, but Haskell is very much inspired by Lazy ML. [[source](http://www.scs.stanford.edu/~dbg/readings/haskell-history.pdf)]
Yeah I now just read the TOU link below. Ok then. Pretty clear.
People always seem to recommend [Python the Hard Way](http://learnpythonthehardway.org/book/) which is incredibly thorough but isn't very good for referencing later. I would suggest it for learning but not so much for using as a guide when you are in need.
&gt; interaction with various terminal setups particularly hard to test. Can you quickly resume how you manage implementing these tests ? (bpython looks very promising BTW, keep up the good work !)
[Python for Data Analysis by Wes McKinney](http://shop.oreilly.com/product/0636920023784.do) Might be easier to start picking up Python from R's domain. One month is totally possible, though I don't know what they mean by proficient and if they require you to prove by participation or projects in it. If so, try porting one of your R programs to Python this month.
I can highly recommend [huey](https://github.com/coleifer/huey), it's similar to celery, but a lot more lightweight and doesn't require another service running in the background.
Maybe I should have been more clear. I meant that I would like to have the console window show up, but after it finishes doing what I want it to do, I would like it to hide the console window. 
I sort of feel the opposite way. R's advantage is the multitude of libraries it has, for every sort of statistical technique under the sun. But Python's data structures are light-years less awkward than R's in my experience.
Thanks - just bought it on your recommendation!
data frames are fine, and most statistics make sense in table format, but when people decide to invent their own data structures (I'm looking at your, bioconductor), things can get awkward
As a recent Python enthusiast, should I not be a newbie attending something like this? Or will it give me a huge knowledge boost and help me decide which direction I want to go. 
I was there too! Had a great time and talked with a lot of interesting people
I'm not sure what solution you are looking at but the one I have been using is fairly basic. First we define isprime(x) which returns a True or False def isprime(x): for i in range(2, x): #Iterate from 2 to your number if(x % i == 0): #Check: is x divisible by ANY number below it return False #If so return False break #And break so it doesn't return True return True #Return True if not divisible by any number below it Then once I define that getting prime numbers you could do what I did and make a list of all of them, this makes this useful in more than one way primes = [] #create empty list for x in range(10000): #iterate up through whatever range (I chose 10,000) if(isprime(x)): #Do the check. If isprime(x) returns True it will continue primes.append(x) #If it returned True than append to primes list Now you can either print the entire list OR to solve your problem you can print the thousandth prime number from the list length = len(primes) number = raw_input("Which prime number are you looking for? (upto " + str(length) +"): ") value = primes[int(number)-1] print("Prime number #%s is %s") % (number, value) This asks for the number (upto the length of the list of primes), pulls the correct value from the list (subtracting 1 because we start at 0 on list iterations), and then prints it in a nice format. __________ EDIT: Thinking about it now you could even theoretically change the x in line 2 to x/2 for faster calculation. if you divide by the number that is as big as half of the number and it doesn't work than that would rule out the smallest integer you could use (2) and anything past that would end up within the range(2, x/2) for example 21967/2 would yield 10983.5, 21967/3 would yield 7322.333 etc. They can only be as large as half of the value to even try to calculate a prime number. EDIT2: You could even go a step further and change line 9 to range(1, 10000, 2) so you would skip over any even numbers which would make it even faster. EDIT3: So I have been playing with this for the past like 30 minutes trying to find the fastest way to calculate prime numbers and I got a method that is 46% faster that before C: def isprimeeplus(x): for j in range(2, 9): if(x in small): return True break if(x % j == 0): return False break for k in primes[5:len(primes)/2]: if(x % k == 0): return False break for i in range(2, x/2): if(x % i == 0): return False break return True
Oh yeah, I can imagine. I haven't encontered that myself. More so on the "regular programmers" (i.e. not scientists) side of things, I do think there's an overuse of classes in Python when simple data structures will work great and be more interoperable.
I would recommend using the Pandas library and also Ipython notebook. The 2 of those combined are very valuable tools for stats in python from my experience. 
I'd recommend http://www.openbookproject.net/thinkcs/python/english2e/
Rstudio =&gt; spyder https://code.google.com/p/spyderlib/ ggplot2 =&gt; ggplot https://github.com/yhat/ggplot (still under heavy development, some features still kinda buggy) Dplyr, Reshape2 =&gt; pandas http://pandas.pydata.org/ Knitr =&gt; IPython notebook http://ipython.org/notebook.html
Thought this was /r/asmr for a moment with that title...
When I did that book i did [Think Python](http://www.greenteapress.com/thinkpython/) along with it for referencing.
Thought it would be cool if it worked for [this TomT poster](http://www.reddit.com/r/tipofmytongue/comments/2bxxyx/tomtsongwhat_song_is_this_its_for_a_huge_surprise/), but it looks like it doesn't work well when the song is in the middle of the video.
I've done something very similar but using LLVM. For those who are interested: [project](http://shine.readthedocs.org/en/latest/introduction.html#what-is-shine), [post about project](http://pyevolve.sourceforge.net/wordpress/?p=2353).
This is the route I went with. Thanks a lot!
Go for it - you work your butt off for a month, and even if you don't end up with a new job you'll still have learned something useful. You'll probably learn a lot about R from learning python, and python may become useful for some other tasks in the future. You may also want to just be able to speak to the scalability of software too. I remember hearing/reading that at Google they'll test out their algorithms in R but try to scale up with Java/C/C++; prob not python but python does fit into the workflow as a glue language/web framework. So that may be why they're asking for it.
I find Kevin Shepard's [Introduction to Python for Econometrics, Statistics and Data Analysis](http://www.kevinsheppard.com/images/0/09/Python_introduction.pdf) a good free resource which covers basic Python as well as more advanced topics related to data analysis and number crunching. You ask about trees, hash tables, etc. These topics of course fall under general computer science more than Python. Maybe it is something like [Data Structures and Algorithms in Python](http://wiley.com/WileyCDA/WileyTitle/productCd-EHEP002510.html) you are after? As I haven't read it myself I can't say if it is any good. I am however currently reading [Data-Driven Security: Analysis, Visualization and Dashboards](http://wiley.com/WileyCDA/WileyTitle/productCd-1118793722.html) and even if security is not your topic of interest, the authors are running code examples in R and Python next to each other meaning that it's fairly easy to see how to do things you might be familiar with from R in Python. It is not a programming tutorial *per se*, but send me a PM if you are interested in the contents. Edit 1: Links Edit 2: Also, go and have fun with CheckIO (under programming challenges in the left column). Learning by doing! 
Thanks, I'll check it out :)
It was the second part that was giving me a hard time. Eventually I figured out that when a function returns a 1 or 0 it reads as True or False (right?), and that helped clear things up. 
Use ctypes.windll to open User32.dll and call EnumWindows/FindWindow/ShowWindow or whatever you need.
Haha, I didn't keep track of my time, but this is probably pretty accurate. Except instead of Daft Punk it was Netflix playing in the background. I'll keep at it. Luckily, this problem kind of forced me to take things one concept at a time. 
I &lt;3 IPython and pandas.
You can use 1 instead of `True` and 0 instead of `False`, but it's better to just use the literal values `True` and `False`. If you already have a function `is_prime(n)`, you can use the "generate-and-test" method to find the thousandth number that is prime: found = 0 i = 2 while found &lt; 1000: if is_prime(i): found += 1 print i You can even use the fact that 2 is the only even prime number to skip all the other even numbers: found = 1 # we "found" 2 already. i = 3 while found &lt; 1000: if is_prime(i): found += 2 # next odd number print i
Thanks for that - nice looking wrapper
Well, you chould simply do random.shuffle(WORDS) and then print the WORDS list again...
Figure what out?
Wouldnt the effectiveness of the DoS attack depend on the internet connection? like a home connection versus a fast connecting server?
If you just need a reference, the standard [language](http://docs.python.org/3/reference/) and [library](https://docs.python.org/3/library/index.html) docs are both really good (the latter more than the former).
:)
Summing up the shitty parts of this thread.... "Why did you not use &lt;tool i'm familiar with and think everyone is using or should be using&gt; and why did you do things in &lt;a way that i'm not comfortable with and react negatively too&gt;" Everything else is awesome including the OP, keep creating and fuck the haters cuz they are assholes who can't create anything anyway. 
I made something in another language before I started using Python. It was for a live draft and it was a "who's on the clock" countdown timer and it would show the next person's name when the time expired. It featured a "snake" draft order and if someone picked before the clock ran out we had a manual advance option. It was fun since we do the sticker thing and no computers during our drafts.
SQLAlchemy is great, but you're doing a lot of shit by hand. It feels like less of an abstraction from the DB than Django's. If I'm working on a web app, I prefer to let Django take care of all the crazy backend work, come up with migrations for me, and create tables and maintain them. I can focus a lot more on the webapp and barely any on the DB and building queries.
$150 early bird tickets? Count me in! Pricing schedule: * Early bird: $150 * Student: $150 * Individual: $200 * Corporate: $300 The [talk selection](http://pygotham.org/talks) is really good! I have a friend nearby so I'll sleep on a couch. All I need to do is budget for travel and food.
Yes, definitely. To completely saturate a server's bandwidth and deny it the ability to serve legitimate clients, you would have to be hitting it with more requests per second than its downstream bandwidth can handle. Say the server is on a 100Mbit downstream connection and you're DoSing it from your home cable internet connection which is 25Mbit up, 25Mbit down. Even if you're completely saturating your upstream, you'll only be taking up a quarter of the server's downstream so it will still be able to serve other clients and your attack has failed to achieve its purpose. This is why a distributed attack is required. If you have 100 "zombie" home machines at your disposal and they each have a 25Mbit upstream connection then you have a combined 2.5Gbit of traffic to do with what you wish. That's more than enough to saturate the connection of the server we're talking about, even with a fraction of the total traffic.
Thats what I would run my script on. a fast connecting server.
Thank you! Sorry for the wrong subreddit
So random.shuffle Is a command that just shuffles the elements within the list?
trying to get apache (top code) to work with the python cgi-bin and turn the light on via pl.createPiLight(255,255,255)
I don't know celery but I suspect you are not acknowledging your rabbitmq messages.
Undoccumented feature?
Makes sense. However if you are often toggling a block of code you should probably consider making an if statement and a global boolean at the top of the script or something.
Pool of workers is set per one worker, so for one worker it remains unchanged until it will be restarted with new parameters. I don't know about possibility to auto spawn new workers. But i think You can do it manually by monitoring status of queue (redis or what do You use as a task broker). If, for example where are to many tasks in one queue, You can spawn new worker for same queue.
Yes, this is absolutely true (I almost added a note that this can promote bad coding practices), but for temporary changes when testing or bug hunting it's still handy.
Why should it be a bug? It complies with the definition of long strings (all characters until the next triple quote lose any special meanings, including #) and the definition of one-line comments (all characters after # lose any special meanings, including quotes).
I was just going to comment "what the fuck?" but I like your version better.
Interesting but I don't know if I would want to have large chunks of code "commented out" of my projects If anything, they should be removed
Finally a tip I can use every day!
Have you tried just applying to the job anyway? 7+ years strong programming in R might make them happy enough, especially if you're actually good at it and don't just "code like a statistician" (if you know what I mean). 
This looks an awful lot like Matlab's [block comment operators](http://www.mathworks.com/help/matlab/matlab_prog/comments.html), and how they were designed to be easily tweaked from block start and end markers to line comments.
Sometimes you want to debug and need to only execute part of the script to test if it actually works without running the rest. Commenting out chunks of code makes sense and his trick will indeed save me lots of time later (I used to scroll up and down to place/remove the """ like an idiot)
What about splitting the code in two scripts? Have the first one launch with the terminal window and when it finishes let it launch the second script without terminal.
Totally agree. This is just a side effect of the syntax. 
How about R's cpp which is like cython?
In most projects that I do it tends to be reasonable to use a @disable decorator or such. Much easier and in production if it sees any of those its an instant error, @disable or my other debug decorators should never touch production! This is of course if you are using reasonable code segmentation and not giant functions or such.
In addition to the books and websites suggested by others, please checkout /r/pystats!
Been doing the same for years. And for C-like languages too: //* //*/ thought it's common knowledge... 
could someone make a basic example of this? I've never really used decorators but this could be something worth learning
&gt; [...] I found that celery's docs obfuscate how simple (distributed) task queueing really is. Except that it isn't really. And Celery is a rather complex machinery. So I think it's fair enough that its docs try to explain the concepts first. And then you have the [*First Steps with Celery*](https://celery.readthedocs.org/en/latest/getting-started/first-steps-with-celery.html) which show more or less exactly what you did in the video. **EDIT** Also, as usual, pull request for docs are always more than welcome ;)
I was working on a web app and needed a break so I took a stab at this. I checked the result against wolfram alpha and it is correct. primes_list = [2,] prime_canidate = 2 prime_count = 1 while prime_count &lt; 1000: prime_canidate += 1 for prime in primes_list: if (prime_canidate % prime) == 0: # print(str(prime_canidate) + " is not prime") break else: primes_list.append(prime_canidate) prime_count += 1 # print( str(prime_canidate) + " is prime; prime count = " + str(prime_count)) print( str(prime_canidate) + " is prime; prime count = " + str(prime_count)) One interesting thing that I am noticing is that with any of the print statements inside the while loop uncommented I have one core pretty much maxed out but with the print statements commented the process is spread across all 4 cores. *improved version based on the observation that the only even prime is 2 primes_list = [3,] prime_canidate = 3 prime_count = 2 while prime_count &lt; 10000: prime_canidate += 2 for prime in primes_list: if (prime_canidate % prime) == 0: # print(str(prime_canidate) + " is not prime") break else: primes_list.append(prime_canidate) prime_count += 1 #print( str(prime_canidate) + " is prime; prime count = " + str(prime_count)) print( str(prime_canidate) + " is prime; prime count = " + str(prime_count))
You'll likely find that the server will hit 100% CPU usage before it will hit 100% network utilisation, due to the overhead involved in the Python runtime and the single threaded nature of your script. This is easy to test- run the script on the server and run `top` simultaneously. This will let you know whether you're pegging the CPU at 100%.
You must download the [source files](https://github.com/tweepy/tweepy/tree/master/tweepy) and put them in a folder named 'tweepy' in the home directory (i.e., the same directory as your app.yaml file). It'll work then. As a side note, the only libraries that app engine supports without you having to use the source are listed [here](https://developers.google.com/appengine/docs/python/tools/libraries27). Libraries that are not in this list must be pure python in order to work with GAE. Hope this helps!
I'm sure the gym owner knows he would be getting his money's worth. Not everyone has to have five nines.
I programmed in MATLAB for 5 years and never knew that there were block quotes. Not having block quotes bugged me to no end. Thanks!
What about http://www.sandman.io/?
Naive and mostly useless example: def disable(f): def disabled(*args, **kwargs): pass return disabled @disable def do_stuff(): print "Hello World" You can do more useful stuff if you want, like printing the function name and arguments for debugging.
The point of the article is how to create it your self, and modify it to your own need without much abstraction and admin-extensions set-up, and without using service that cost money(hint sandman) :) 
My example in C somewhere below can be translated to python too, you can toggle between two different implementations like this: #""" print("this") """ print("or that") #""" By removing/adding the dash at the first line you can toggle between those parts. Helpful sometimes when you want to do a fast binary search of an output or rewrite a function without having tests ;)
The problem is that most programmers are bad, and given the choice will use every feature available to make their code as complex as possible. That's why restrictive, dull languages like Java are actually really good. 
RCpp seems to be closer to scipy.weave -- interface with C/C++ inline in a relatively nice way. Cython lets me just mark up the straight python code with a few annotations. I did only skim through RCpp docs so I would well be wrong. Can I simply tell it to compile actual R code into C and thence onto machine code, or do I need to provide the C?
Ok my bad. Yes RCpp is for inline interface with C/C++; I had the wrong impression of cython that it was similar... I understand it's possible to call R libraries from C but I guess that doesn't help with the scaling part.
Okay, and what is the problem?
But they do need at least one nine. If OP can't even manage to google "installing a database server" followed by "creating a database in &lt;server&gt;" then I highly doubt implementing any kind of biometric ID process and tying it in to a billing system is going to go very well.
That's definitely what I was missing. Pardon my inexperience, I've just recently started to work with GAE for Python. Thanks for the help!
It may just be missing from the UI. If you file a bug against PyCharm in the JetBrains issue tracker chances are they will fix the issue. I've filed plenty of issues and most of them have been taken care of or if it was my mistake they have usually been pretty helpful to get me on the right track.
I use java and enjoy it for Hadoop, but programmers love to over complicate that language too. Abstractfactorysingletonbean bullshit everywhere.
&gt; But they do need at least one nine. You get more than one nine by fread/fwriting data around alone. That's well covered right in the first lessons of any intro to programming course. Even interacting with sqlite through the command line interface gets you more than that. You're greatly overblowing the complexity and the requirements for this sort of task.
Just so you know, this book is primarily (almost totally) a primer on the Pandas library, which is the go-to library for anything data related in Python and something you will definitely need to learn. It isn't really all about the whole world of data analysis in Python.
Never even considered this use of decorators, but I can already use it. Thanks for sharing.
PyQt Here is an example application that does exactly what you described: https://github.com/biolab/orange3
You might like IPython Notebook, which has something quite similar to code sections. 
Code sections were pretty cool, but for the work that I did, I didn't find much of a need for them. I did mostly small data processing stuff, and it was rare that I would only need to run a small section of code. This was as a student, by the way. And then I moved to Python.
Scroll? If you're using vim, you can use marks to quickly jump someplace (m a; ' a); I assume other worthwhile editors have something similar.
Why don't you simply try it out and see for yourself? 
Now that you mention it, I have no idea.
Hello ! Yes it optimizes the individuals and this is very great due to the amount of different passes that LLVM provides, it is like applying an "clang -O3" equivalent to individuals. Unfortunately I also came to the conclusion that these passes also takes time, so this approach is **VERY useful** when you are executing your individuals **on lots of data** but it not so much useful when you are just executing it on small amounts of data because the time to optimize, JIT the IR and then execute it will be greater than the time to just evaluate it using a visitor pattern or something like this. You can also provide feedback to the GP engine about the equivalencies between individuals, because after optimization, even different individuals will assume the same form after the passes, but note that it will also need to optimize and this takes some amount of resources. I started to write a paper about the results of this approach when I started but since I was working only on spare time I had to abandon it due to the lack of time =( using LLVM to optimize and JIT the individuals is very cool because when you start to use the IR representation you get lots of advantages, like: * Begin able to JIT on different platforms (like arm); * The LLVM passes works very well (you are bringing the compilers state-of-art optimizations to the GP world); * The execution speed of native code; * You have [lots of frontends](http://en.wikipedia.org/wiki/LLVM#Front_ends:_programming_language_support) for LLVM and since they generate IR, you can use this IR to merge with your individuals IR in a way that your individuals can call anything you can imagine; * You also have the entire LLVM framework to create the IR representation of individuals; * You can implement your own passes over the IR * and many other possibilities... 
Vim has this feature, but it requires you to use visual mode unless there is some other code feature you can use to detect the end of a block. The way I use vim I'm almost never in visual mode so this is a nice alternative, plus it keeps everything readable, unlike 30 lines with #s at the front.
You da real MVP
Yup, that is basically what mine is: def disable(f): if config.debug: def disabled(*args, **kwargs): logger.debug("disabled: %s"%(f.__name__)) #other logging stuff, but does nothing return disabled else: raise ProductionDebugException("@disable deco executed in production!") @disable def do_stuff(): print "Hello World"
I think the difference here is that `"""` is not a comment delimiter, but a string delimiter, and not every Python programmer knows that you can have a string hanging around in code like that.
If readability is important, delete the unused code instead of commenting it out.
For anyone using Sublime Text, you can comment/uncomment a block by selecting it and pressing Ctrl + /. It's very useful!
I would love to be able to watch certain talks after the fact if possible.
Ive tried testing this program on my home connection, its a shitty PC but when I try to DoS my server(of course nothing happens on my server and end up DoSing my internet) my cpu always hit at around 38-47% from 26% normally.
I find it hard to believe. I'm not a python programmer and only use python as helper tool and I knew that. I mean it's the first answer to googling "multiline comments python".
 &gt;&gt;&gt; l = [1, 2, 3, 4] &gt;&gt;&gt; import itertools &gt;&gt;&gt; itertools.permutations(l) &lt;itertools.permutations at 0x2692410&gt; &gt;&gt;&gt; [p for p in itertools.permutations(l)] [(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2), (2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4), (2, 3, 4, 1), (2, 4, 1, 3), (2, 4, 3, 1), (3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2), (3, 4, 2, 1), (4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3), (4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)] &gt;&gt;&gt; [p for p in itertools.permutations(l) if p[0] == 1] [(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2)] &gt;&gt;&gt; [zip(p[::2], p[1::2]) for p in itertools.permutations(l) if p[0] == 1] [[(1, 2), (3, 4)], [(1, 2), (4, 3)], [(1, 3), (2, 4)], [(1, 3), (4, 2)], [(1, 4), (2, 3)], [(1, 4), (3, 2)]] 
Look at itertools.permutations
 for i in range(len(iterations)): process_iteration() f_name = 'processed_file{0}.csv'.format(i) write_file(f_name) This will just create a new file name for each iteration. Is this what you're asking? If you are looking for ways to process the file (assuming it's a text file) you can read each line of the file as a string and create your data structure whenever you see the word "ITERATION: " Then, append each number to its list (doesn't necessarily have to be a list). Stop when you see a blank line, create new list, repeat.
&gt; celery is to pika what request is to urllib2 There, fixed that for you.
Yeah fine in every language having a preprocessor like C/C++ but won't work in generic C-"Style" languages.
&gt; How would I construct a program to read from the file, and pipe out a new file for each iteration? So if I have 100 iterations, I want to pipe out 100 files named 1, 2, 3, 4, 5 etc. All I'm going to say, is if I see this python program writing 1000s of ~1k sized files to my filesystem, I will kill you.
This is a good suggestion but there are some special cases where commenting out code is better. Specifically, if you have to do large refactorings in static compiled languages, it pays off to comment out the code, leave a mock interface to satisfy the linker, and then step by step move the code around. 
i fixed the issue, it was my task which was doing some funky stuff with the global variables. i got rid of it and it works.
is it recommended to have large pool for a 512mb system? should you have one concurrent process for each core? i figured out how to do the auto spawning of new workers. I need to have a service which constantly polls the celery queues, and set some threshold to spin up new celery workers when needed. how im going to create a service that constantly performs celery inspection is another problem im trying to figure out.
Yeah, absolutely, you can't avoid it
I use this. Very straightforward. Just select the lines you want to comment/uncomment and press the shortcut. No typing required!
That does not happen to me :I
Wait what? Into JavaScript? Why? Get started with writing CLI programs: output things on the console. You'll have a lot to worry about, so better keep the UI as easy as possible. Once you've built some Python skills, look into some web programming libraries, if that is what interests you. Flask is simple and minimalist, yet powerful; Django is probably the most popular full-blown web framework; and there's a bunch more still. None of that involves JavaScript however: your Python code runs on the server, and it produces HTML which gets served to the client as if it were a file. Your web app can also send other types of content, such as stylesheets, images, and javascript source code. The latter gets executed on the client, but your Python code on the server doesn't do anything with it except hand it to the client - on the server, that script file is just another file you're serving.
[The json module](https://docs.python.org/2/library/json.html) I use `import simplejson as json` as it worked in more edge cases for me.
Totally off-topic, but when I work in PHP, I often use that trick to toggle between two code blocks: &lt;?php #/* echo "this"; /*/ echo "that"; #*/ Adding or removing the pound sign on line 2 will toggle which code is commented-out... &lt;?php /* echo "this"; /*/ echo "that"; #*/ 
I'm also interested in this. The most natural seem to be server-sent events, but not every browser supports that. The situation with websockets is similar. What remains is polling from the frontend. For serving stuff from Python, I like [Bottle](http://bottlepy.org/docs/dev/index.html). You get the conversion of data to JS for free. `mod_python` seems to be mostly dead. Python 3 comes with a nice wsgi server, actually.
What's the upstream bandwidth of the server you're testing from? Are you definitely maxing it out?
Same in PyCharm.
in Sublime Text you can highlight your code and hit Cmd + / to block comment chunks out
it doesn't execute the commands from the HTML (HTML &lt;input type="radio" name="lighton" value="on"&gt;On&lt;br&gt;) On pl = pilight.PILIGHT() pl.createPiLight(255,255,255) (HTML &lt;input type="radio" name="lightoff" value="off"&gt;Off) OFF pl = pilight.PILIGHT() pl.createPiLight(000,000,000)
Aw yeah, love me some Django.
every browser except Internet Explorer support Server-Sent events Websocets are supported by all browsers (IE, Chrome, Firefox, Opera, Safari) for server deployment, use [gunicorn](http://gunicorn.org/) or more awesome [uwsgi](http://uwsgi-docs.readthedocs.org)
This works
Awesome, think this is what I am looking for.
dunno exactly but it can output more than 6gb/s
That's an incredibly high throughput, what are you using to determine that number?
The Interval is set to Hours, so that's ~47.5 GiB uploaded in an hour, or an average of around 100Mbps. Sounds like your server has a 100 megabit link. That's still nothing to sneeze at, but you won't be taking down Amazon.com any time soon ;-)
Fix your formatting, if you don't mind. So testing is good for at least two things: a) Writing new code that you know works at least as well as you're testing. b) changing code that has tests written for it without worrying that you'll break existing code. Once your tests are written, you'll never have to worry whether you'll break it later on. This isn't important when you're writing scripts a few hundred lines long, but when you get in the thousands it's really helpful to know you're not breaking anything.
So the tests are more for putting boundaries on the coding. "If you don't color inside these lines, the tests will tell you." In the tutorial example, whatever parameters you're going to add/chg/del, the test will ensure that the end result keeps the parameter of "future dated polls don't show as a current poll" 
I don't have many time writing tests for Django, and in general. I have used it more for TDD, but what I extracted of the whole thing is that unittesting, with TDD is mainly for blueprinting the next steps you are taking with your code. The real thing that, for myself, defines a good undestanding of said cycle is the length of the test itself. Is hard do a tiny bit of code, test it to see it fail, write a tiny bit of code to make it pass and so on. Write a complete feature of test code and then write the complete code that make it pass is faster, to my understanding. Obviously, this is taking into account test isolation and no overlapping, the code and the test must be designed to work like a unit, hence the unittest.
You should post this question in /r/devops. 
This made me LOL. 
Yeah I had tried the MIT intro EE course and got a few weeks in and realized that the math was too much for me and I just didn't have the time to make it up. I think I could have completed it but it would have been a full time job.
&gt;the test will ensure that the end result keeps the parameter of "future dated polls don't show as a current poll" Basically, yeah. You can be sure that so long as your test is passing, you'll never have a future poll listed as a recent one. The problem with testing is that it goes against human nature and our inability to think ahead. All we see if the immediate cost of writing the test, instead of correctly realizing that it'll save untold times in effort.
You can also just map it to &lt;leader&gt;something.
This is a great resource for learning Python's scientific/analytical stack: http://scipy-lectures.github.io/
I'm still fairly new to Python so this could be the blind leading the blind here and it's a little hard to tell what's happening without the proper indentation. But here it goes: This is what you have. import random raw_input("Ready?\n") counter = 0 while True: counter += 1 if counter &lt; 100: heads_count = random.randrange(2) if heads_count == 0: heads_count = 0 elif heads_count == 1: heads_count = 1 print heads_count if counter &gt; 100: break raw_input("\nPress the enter key to exit.") Basically (I think) you need a variable to store the heads and tails tallies in so you can print those out. What I would do is initialize 2 variables before your while loop, say heads_tally and tails_tally. For each cycle through the loop, if it's heads, you want to increment the heads_tally variable by one (like you're doing with your counter variable), if it's tails, do the same with your tails tally. So your code might look something like this: import random raw_input("Ready?\n") counter = 0 heads_tally = 0 tails_tally = 0 while True: counter += 1 if counter &lt; 100: heads_count = random.randrange(2) if heads_count == 0: heads_count = 0 heads_tally += 1 elif heads_count == 1: heads_count = 1 tails_tally += 1 print heads_count if counter &gt; 100: break print heads_tally, tails_tally raw_input("\nPress the enter key to exit.") Something to think about here too is what your loop is doing and how it's incrementing as well. Hope this helps!
A few things: 1. You have a formatting issue with your loop as it should be indented one more level. Most likely it is just a copy and paste error 2. Instead of using `while True: .... if counter &gt; 100: break` you can use `for _ in range(100)` 3. You really only have to count the number of heads or the number of tails. To get the other just subtract the number from 100. So if you got 30 heads then you got (100 -30) = 70 tails. 4. Look at your if/elif condition in your loop. If heads_count is equal to 0 you are setting it to 0. If it is equal to 1 you are setting it to 1. Not very productive. So one way to write it would be: heads = 0 for _ in range(100): heads += random.randrange(2) print("Number of heads", heads, ". Number of tails", 100 - heads)
Has anyone attended prior PyGothams? I can't find anything about it online. $200 is reasonable (early bird registration appears to be over) but I can't find any reviews on the event.
So the Worker picked up the Task ? Did the Task even run or it ran and failed? I'm curious to know how you tracked it down the cause and how this "funky stuff" cause the problem. 
I saw some slides and videos of prior talks from prior years. Seems legit. Dunno if it'll be worthwhile though. I've never been to a tech conference before.
Thanks!
I appreciate you taking the time to write this out. Thanks.
With all the django admin "reskins" coming out, I wonder when the core devs are going to catch on and redesign the outdated admin?
Again, pool have nothing to do with memory, its all about CPU. Processes number in the pool must be equal to cores number (physical or virtual). You CAN spawn more processes, but it will give You literally nothing. Yes
Sounds like a job for cron. 
As other said, avoid the while True: ... counter += 1 approach.
It lets you schedule commands/scripts at certain times/dates ([Wikipedia](http://en.wikipedia.org/wiki/Cron)). You could have a cron job that runs your page-switching script every 5 minutes.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Cron**](https://en.wikipedia.org/wiki/Cron): [](#sfw) --- &gt;The software utility __Cron__ is a time-based [job scheduler](https://en.wikipedia.org/wiki/Job_scheduler) in [Unix-like](https://en.wikipedia.org/wiki/Unix-like) computer [operating systems](https://en.wikipedia.org/wiki/Operating_system). People who set up and maintain software environments use cron to schedule jobs (commands or [shell scripts](https://en.wikipedia.org/wiki/Shell_script)) to run periodically at fixed times, dates, or intervals. It typically automates system maintenance or administrationâ€”though its general-purpose nature makes it useful for things like connecting to the [Internet](https://en.wikipedia.org/wiki/Internet) and downloading [email](https://en.wikipedia.org/wiki/Email) at regular intervals. The name *cron* comes from the Greek word for time, Ï‡ÏÏŒÎ½Î¿Ï‚ [chronos](https://en.wikipedia.org/wiki/Chronos). &gt; --- ^Interesting: [^MÃªlÃ©e ^\(band)](https://en.wikipedia.org/wiki/M%C3%AAl%C3%A9e_\(band\)) ^| [^List ^of ^Teen ^Titans ^characters](https://en.wikipedia.org/wiki/List_of_Teen_Titans_characters) ^| [^Chris ^Cron](https://en.wikipedia.org/wiki/Chris_Cron) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjbswnh) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjbswnh)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Thanks guys, this proved to be very helpful 
Or even more elegant with a generator expression: heads = sum(randrange(2) for _ in range(100)) :-)
OMG... quiete unefficient approach! Lines 2 and 3 each will have a complexity of O(n) as Big-O Notation. For solving this problem one only needs to touch each result of the n results exactly once. Your solution touches each element 3 times... not so good, isn't it! ;-) (Think abaout, how ``list.count`` works!) If you really need to evaluate the results separatly, for example for a Laplace experiment, consider to use a ``defaultdict`` or ``collections.Counter``!
If you want to count things, use `collections.Counter`: &gt;&gt;&gt; from collections import Counter &gt;&gt;&gt; from random import choice &gt;&gt;&gt; Counter(choice('ht') for _ in range(1000)) Counter({'t': 507, 'h': 493}) 
If your target system only has python installed and nothing else is allowed (sometimes those restrictions apply with customers), then you are now lucky to keep your existing haxe environment and just build the python target.
Thank you for sharing.
Awesome. Do you intend to do a smarphone app where you take a photo of the sudoku and it solves it ?
- Read and follow PEP8. You are missing whitespace all over the place. - Don't write your own `findFreeFilename`, use the `tempfile` module in the standard library. - This is [horrid](http://www.reddit.com/r/learnpython/comments/22a82w/python_27_is_format_preferred_over_str/cgkzv25): string = "| "+str(su[i][0])+" "+str(su[i][1])+" "+str(su[i][2])+" | "+str(su[i][3])+" "+str(su[i][4])+" "+str(su[i][5])+" | "+str(su[i][6])+" "+str(su[i][7])+" "+str(su[i][8])+" |" print string.replace("0", " ") Consider: print '| {} {} {} | {} {} {} | {} {} {} |'.format(*su[i]).replace('0', ' ') And likewise for all the other `str()` stuff. - Get rid of all those `global debug` lines. You only need that if you want to assign to a global, not if you just want to read the value of a global. - This is horrid: subprocess.check_output("tesseract "+tesinput+" "+tesoutput[:-4]+" -psm 10", shell=True) Avoid using `shell=True`, it's a giant security hole. This is how it should be written: subprocess.check_output(['tesseract', tesinput, tesoutput[:-4], '-psm', '10']) - Instead of all these `sys.stdout.flush()` littered about, write an output function that does the flushing for you. (If you were using Python 3, you could just write `print(..., flush=True)`. 
That is so weird. I literally had this idea last week. I've tried it before but the project died before I even wrote the solving algorithm, nice work! edit: looking at your code, it could probably benefit from some refactoring. Those are some long functions that are doing a lot of work.
Also I would like to add that they should list imread as a dependency since it was not installed on my system. 
&gt;Lines 2 and 3 each will have a complexity of O(n) as Big-O Notation. For solving this problem one only needs to touch each result of the n results exactly once That's actually still O(n). This is just more inefficient by a constant factor, rather than being a different compleity class. 
Problem 1: Redesigning the admin while keeping backwards compatibility is impossible. Problem 2: Django contributors are rarely designers or front-end developers. I couldn't find any redesign/refactor ticket in https://code.djangoproject.com/query?status=!closed&amp;component=contrib.admin 
I think it's stupid to delete an object using a GET request, because it's vulnerable to CSRF.
Perhaps you are right, this is what happens working late at night, thanks for the advice.
This solver is going to take ages on any non-trivial sudoku. I wrote [a solver](http://www.garshol.priv.no/blog/178.html) years ago that uses some tricks to speed this up dramatically.
I've found passing JSON data to a JavaScript method to be a bit unintuitive in Django and Flask. I usually just put a small script in my template like this: &lt;!--load the JS function--&gt; &lt;script src="{{ url_for('static',filename='js/javascriptFunction.js') }}"&gt;&lt;/script&gt; &lt;!--pass data to JS--&gt; &lt;script&gt; flask_data = {{ data|tojson|safe }}; javascriptFunction(flask_data); &lt;/script&gt; I'm not sure if this is the cleanest way. I'm sure someone will point out how this is wrong. Bear in mind that you should be careful using unvalidated data this way. I only use it for validated data that users cannot modify.
&gt; Problem 1: Redesigning the admin while keeping backwards compatibility is impossible. Why would it be impossible? Change the markup and css and you have a modern admin. And if you don't change existing URLs, nothing breaks. &gt; Problem 2: Django contributors are rarely designers or front-end developers. True.
It's pretty neat, good job. Consider moving on to an OOP aproach though, it makes your code much more manageable.
It's really bad at extracting sudokus from images. I [tried](http://flywithmonkey.com/wp-content/uploads/2012/12/Sudoku_0002_Layer-2.jpg) [a](http://1.bp.blogspot.com/_rOARxrOIIrs/TTW1Ki7zUYI/AAAAAAAAAQ0/cI_T3xKkcq8/s1600/PB170001.JPG) [whole](http://www.octavarius.com/wp-content/uploads/2010/01/051.jpg) [bunch](http://ivanahorvath.files.wordpress.com/2013/10/pict0797.jpg) [of images](http://flywithmonkey.com/wp-content/uploads/2012/12/Sudoku_0002_Layer-2.jpg), but none of them worked. Most returned no numbers at all, one of them returned a 1 in a blank cell. Guessing that's tesseract doing that or something.
You are asking as a participant or a person who lead the workshop? It depends which of the workshops would you like choose. PyCon PL 2014 offer prelections and workshops for all Python programmers with different programming skills. Feel free to ask us about the details.
I will assume that you have python 3.4 installed. If you are on windows then download kivy for windows and python 3.4 from here http://www.lfd.uci.edu/~gohlke/pythonlibs/#kivy other way would be to install python 2.7.6 and then from PyCharm settings set python 2.7.6 interpreter as your default one.
Wow, this is crazy good. Solved [this puzzle straight away](http://www.telegraph.co.uk/science/science-news/9359579/Worlds-hardest-sudoku-can-you-crack-it.html), but took 14 seconds to finish for some reason
Xlwings is fantastic. It lets my less code fanatic colleagues continue working in Excel and I do the magic with Python!
Maybe I'm misleading you. When I wrote "runs through all the possibilities" I meant all the possibilities that analysis of the board hasn't excluded. So there's no magic speed code, we just avoid checking things which obviously can't be right. If you read through the blog post I explain (nearly) all the tricks that are used. It's actually pretty simple if you just take the time to walk through it.
Was trying to keep from exploding the head too much ;)
To explain Problem 1: If you want to reskin the admin properly, that means refactoring. Refactoring means rewriting, moving and removing templates, styles and scripts. This means that if site owners extended the admin, they assumed a certain state for templates, styles and scripts. If that state changes, things will break a little (unstyled content) or a lot (template does not exist).
1. Shouldn't be that big of a problem since templates can be overridden. 2. They made Bryan Veloso (a designer for GitHub) a core dev for this very reason. Unfortunately he's the only one since then. Still, it's a precedent. I guess it's something that would have to be brought up on the mailing list. I'm just surprised that it hasn't been bright up. 
We mostly haven't managed. There are a variety of [manual tests I use in the terminal wrapper](https://github.com/thomasballinger/curtsies/tree/master/examples) that bpython-curtsies uses that I try in iterm, terminal.app, with and without tmux, in terminals with different encodings, etc. The terminal issues I'm talking about are mostly there. I'm [looking into using pexpect](https://github.com/thomasballinger/curtsies/issues/17) to automate specific regression tests for bugs, but exercising bpython-curtsies in different terminals is most of what we're doing currently.
So the Task did run, you're just not getting the expected result ? Note to self: do not reference Global if possible
I never denied that - i wrote ***each*** ;-) Of course the class remains the same as that just sums up, but imho the constant factor indead matters if you easily can avoid it...
I have been meaning to write programs like this for sudoku and boggle and didn't really know where to start. Thank you so much for sharing this!
I like that you offer alternatives for most of the criticisms. Thanks for that.
I see downvotes here, and I too cringed at the thought of a cell class and a row class and a box class and a column class and the typical oo exponential expansion circle jerk shit that so often is taught. And we all agree that just a few helper functions and modularity would probably clean this code up right away. But for the sake of discussion and learning, what is a good balanced oo approach to a Sudoku solver that doesn't have oo getting in the way of itself (you know, before you can do anything you need an object and before you can get that object you need a factory and you need a factory factory so you can facade rhe visitor who will give the interface of the object you need to keep it singleton to then create the first cell object and put number is a digit is a value is an entry is 9 into the first cell) 
Wow; thanks for the feedback! I knew the `str`s were ugly as shit, but I didn't have internet at the time to look up how to do string formatting in Python 2 (only did 3 so far).
`imread` is part of cv2, which I listed: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html#imread
The head exploded.
I'm aware that the solver is by no means perfect. This was more about getting to know OpenCV and trying some different things with images for me. Maybe I'll implement a smarter solution some time.
I've always done /**/ Uncommented /**/ -&gt; /** Commented /**/ I think it's prettier!
To be fair, solving the OCR aspect is way harder than solving the actual puzzle. :)
The only two libraries you'll need to install are listed [here](https://github.com/tweepy/tweepy/blob/master/requirements.txt). Install both these libraries in the directory containing app.yaml, and import them in your main.py file. Should work after that, as long as both of them are pure python libraries.
Easier than reading and following PEP8... just run flake8 and follow the instructions it outputs.
PyCharm is far and away the best Python IDE I've ever used (currently using with IdeaVIM for Vim keybinds). Although I've only used it on Linux and Windows, I expect it would be just as great on OSX. https://www.jetbrains.com/pycharm/
I would probably just have a SudokuGrid full of SudokuBoxes, there is no need to go any deeper. Overuse/abuse of OO is a programmer choice. It's not mandatory. If you don't want it, don't do it. Some people seem to see trivial examples of OO objects used for explanations and tutorials, and assume that the converse is also appropriate; that since trivial concepts have been used for examples, that in real world code all trivial concepts must also be represented by objects just like they were in the tutorials. That makes about as much sense as assuming that because all tutorials start with print "Hello world", that all programs must contain print "Hello world" at some point. They're just tools, to be used when you feel it is appropriate. If you do not feel it appropriate in your situation to use an object, or a factory, or a factory-factory, then don't.
It sure is ;)
PyCharm/IntelliJ if you want a full IDE. Sublime text with various packages if you want something lighter.
I started implementing the exact same thing in C# couldn't be bothered with a framework for analyzing images. Turned out to be to complicated. 
I ended up using your solver to make a website interface, using that as the backend! After spending some time ironing out some kinda major bugs, it's ready! http://sudoku.blha303.com.au If you encounter a 500 error please let me know :) Open-source upon request, but I haven't spent any time at all making it pretty or idiomatic. I did make some changes to the solver to make it a module I can call from the Flask web server, so that's pretty cool. edit: It solves [hexadecimal Sudoku](http://en.top-sudoku.com/hexadoku/print-hexadoku.php) as well, by the way. http://pastebin.com/SAAjYTCZ
well i dunt want to c:, although what you u mean by residential IP? I DoS my friend down the road for 3 min and it worked, just for fun tho, he didnt care
&gt; until Django Rest Framework admin tool is finalized. REST admin tool? In core? Do tell...
I must admit I am a bit sad that this has to be explained.
1. learn python
on my way ^^ thank you
this seems cool and all but im having determining why i would do this vs just letting skype, google voice or some other service handle it for me. 
I like that you're caching solutions. Useful if a lot of people submit the same puzzle (like from a newspaper or book).
the thing here is that in this course they just expect us to know python..they don't teach it at my uni hence the question. Was just looking for some help since now i have a hole year time till the next time the course will be held.
Why wouldn't I?
What if you wanted to solve an 8-dimensional sudoku puzzle? It's going to be so difficult unless you're already singletonized your facade and factoried your visitor.... just kidding. As /u/cecilkorik mentioned, some programmers abuse OO but the majority don't -- it's just not as interesting making a blog post about someone who's done OO *right*. They make these really cool object-oriented hybrid row/box classes called a "two dimensional list". That would be my first approach. TBH I might wrap it in a class anyway, if only to add some helper functions for isolating each sub-grid (so `sudoku.grid(2)[0][0]` might be the same as `_inner_grid[4][0]`), but there's no need to reinvent the wheel.
I like pyDev for eclipse myself....just what I'm used to.
So I guess the main advantage here is that you can embed it into a website - you don't need to load up skype, which can take minutes, in order to make a voice call. It all runs through webRTC, in-browser!
Well, you have a point, you should love it, but not everybody does ^ ^ 
&gt; It runs through all the possibilities to check if there is more than one solution This is from memory but if you *just* want to know whether there are n=1 or n&gt;1 solutions, when DFS-ing the search space, bias left the first time and bias right the next. If you get the same answer then n=1. Here's my PostScript version! https://chris-lamb.co.uk/posts/sudoku-solver-in-postscript
VIM has a steep learning curve and takes some time to ramp up to equivalent productivity (compared to sublime text etc) However I would argue strongly in favor of vim for several reasons: 1) VIM is everywhere. Most platforms have vim or vi installed by default. 2) VIM prevents RSI. After about 3 months of using VIM you will notice a sudden distain for your mouse. As far as I can tell this only grows over time. I know that many people shift to completely mouse free environments as a result of prolonged VIM use. Even if you keep the mouse, being more keyboard based makes your wrists feel great. 3) Eventually you can do more and do it faster with VIM. It takes time to get there but I definitely have noticed a speed increase comparative to sublime text. Keep in mind this is without YouCompleteMe (vim autocomplete plugin) 4) VIM puts you in programmer flow faster. It takes awhile to ramp up to a good "flow" with sublime text and other IDEs. With VIM I find myself in the flow almost instantly. It is my personal opinion that VIMs interface forces you to think like a programmer and thus jumpstarts the brain If you want to get started with VIM I recommend copying another programmers config files and then going from there. I highly recommend syntastic\flake8 as well as tmux\slime and NERDTree as some starter plugins. There are also "sane" defaults to set for python programming (which can easily be googled)
Pretty sure you've already seen [this post](http://opencvpython.blogspot.com/2012/06/sudoku-solver-part-1.html) but maybe it's interesting
[This sudoku solver by Peter Norvig](http://norvig.com/sudoku.html) might also be relevant to the discussion.
There's no hate, just ignorance. PyCharm didn't come up in any of the research that I did for the talk, and isn't commonly used by developers that I know. I intend to do a bit of research into what PyCharm can do, and if its analysis can be used in a CI context outside of the IDE, before the next time I give the talk.
There's no sense in writing something like: foo = re.compile(regex).findall(text) `re.compile()` is only useful if you're going to save the resulting compiled regular expression, which is impossible if you use the above form. Instead: foo = re.findall(regex, text) 
I use a virtual machine. This is incredibly valuable when doing development for windows because it is difficult to always know the state of your windows machine, something that is trivial with a VM. But it is also useful for linux. I do agree it is an extra hassle, but very worth it because it lets you easily try out anything.
Is this always true or just often? Now I want to do the math, but it's beyond my level.
You're right, it's unneeded. It's a bad habit. Since findall calls re._compile anyways, I don't think it makes any difference performance wise.
There's also a cache of compiled regexes that's automatically maintained, so you can be reasonably confident in using `re.findall()` (or `re.search()`, etc.) in the body of a loop without worrying about having to compile it before entering the loop to avoid recompilation each time. 
Would using the `slice` object work for you? &gt;&gt;&gt; a = range(0, 20) &gt;&gt;&gt; b = slice(10, 15) &gt;&gt;&gt; b slice(10, 15, None) &gt;&gt;&gt; a[b] range(10, 15) &gt;&gt;&gt; list(a[b]) [10, 11, 12, 13, 14] &gt;&gt;&gt; b = slice(10) &gt;&gt;&gt; list(a[b]) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] *edit) just read the last two lines .. add formatting in there son ;)* 
Using OpenCV is a great idea. The first thing I did in Python was a sudoku solver using the Donald Knuth Dancing Links algorithm: http://cavernum.net/dlsudoku/ Sudoku is kind of interesting, because brute force is generally good enough but there are a ton of tricks you can do to speed up the solving.
They are mutable. You could subclass them and implement ``__hash__()`` on your own if you can ensure that they never change.
It's not going to be in core, but from all appearances, it's going to be powerful and useful enough to replace it. Since DRF is the defacto standard for Django REST, I'm going to guess the incoming DRF tools are going to become the defacto standards as well.
How can you mutate a slice? &gt;&gt;&gt; a = slice(2,5) &gt;&gt;&gt; a.start = 3 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: readonly attribute 
Seems I misread the question, I thought he was talking about the sliced array. Anyway, why slices are not hashable: http://bugs.python.org/issue1733184
I don't know where I said "residential IP" but residential internet connections are the ones going to houses. They tend to have limited speed and blocks on a lot of outbound/inbound ports so you can't host your own stuff from home. A business grade or enterprise grade connection will generally be very fast and have no blocks whatsoever so you can do whatever you want with it. If your connection is 50 Mbps up and your friends connection is 50 Mbps down then yes you could DoS him because you have the capacity. Large websites such as amazon.com or microsoft.com likely have 50+Gbps connections so even if you hit them with your full 50Mbps they wouldn't even blink. Plus proper organisations like that have equipment and people watching for DoS attacks- the instant one starts they just put a block on your IP address and all of your traffic is dropped.
I like Emacs. It makes debugging so much easier with PDB.
Well, believe it or not, slice values can be anything, including mutable objects: &gt;&gt;&gt; x = [0] &gt;&gt;&gt; y = slice(x) &gt;&gt;&gt; y slice(None, [0], None) &gt;&gt;&gt; x[0] = 42 &gt;&gt;&gt; y slice(None, [42], None) The idea here is presumably that by allowing generalized objects to be used rather than requiring integers, libraries can use slices in novel ways. So it's kind of a general container for (up to) three arbitrary objects. However, it would make more sense if its hashability was dependent on the hashability of the objects it contains (as is the case with tuples, the more popular fixed size container of arbitrary objects) rather than being unconditionally unhashable. I did a little software archaeology and it appears that they've always been unhashable from day one, and nobody has really given it much thought. I did uncover [a bug](http://bugs.python.org/issue800796) in which they were accidentally hashable under certain circumstances, which was corrected, so it seems this is entirely intentional. 
I only ever use the spanning slice (i.e. ':') so this might actually be a good idea, I'll make that object into a constant and bind it to the symbol _, so i can denote it as M[_,'circle']. I'll have it hash to hash(":"), because it's neat.
Sorry, I'll work on that.
/r/learnpython. Might get more help there. 
Thanks!
There are a couple of profanities in the game.
What operating system are you using? What do you want to do with Python?
I love questions like these. While I don't have an answer off hand, this might be a good question for https://codegolf.stackexchange.com/.
I use sublime text; works great for all languages i use.
hey man I like your video on Celery too
I'm on Windows 7 64bit and I basically want to learn python as something to do when I'm bored or feeling inventive. I also want to pursue a career in IT so a coding language would be great for a CV. I know my ideals aren't the best, but I do want to learn python. The little bit I did learn was quite interesting, and like to continue with it.
so with Celery &amp; RabbitMQ - is Pika needed ?
If it was me, I would start with Active State Python. http://www.activestate.com/activepython/downloads It installs easily for windows and comes with a lightweight IDE. They have 2.7 and 3 versions. If you don't have to maintain any code, I would go for 3 as it is the future of python. If you need to maintain existing code, it wouldn't hurt to use the 2.7 branch. I actually have both versions installed on my machine for existing and new projects. Good luck, and happy hacking.
don't belong here, sorry
but OP is already "fairly advanced"
New to Python? Start with 3. It's the future. With whatever you remember from 2, you will probably not notice any difference between 2 and 3.
did you google ? try "flask"
You can probably achieve a speedup by using [`operator.itemgetter`](https://docs.python.org/3/library/operator.html#operator.itemgetter): from operator import itemgetter def permutation(order): return itemgetter(*order) In my quick testing with a series of 1000 elements, this is roughly 29% faster. YMMV. As to the second part, consider making a lookup table to avoid the linear scan: def order(original, permuted): lookup = {val: index for index, val in enumerate(original)} return list(itemgetter(*permuted)(lookup)) # drop the outer list(...) if you're okay with a tuple, which you probably are Again, in my quick testing with a sequence of 1000 items, this appears to be about 47% faster. 
I recommend using Anaconda over a VM. The distribution is self-contained and if you're working across multiple platforms, there will be consistency in your python environment.
Further, the second function is slow because it's O(n^2 ) in the length of "permuted". Does original get tried over and over again with different values of permuted? If so it might be much faster to precompute a hash table for the original: orig_d = dict((v,k) for k,v in enumerate(original)) and then "solve" for the permutation with a function that returns [orig_d[i] for i in permuted] each time -- this should run in linear time. This is just a high level suggestion to hopefully put you in the right frame of mind here. Beyond this I am sure there are tons of low level tricks that also make a big difference and depend on specific details of your application (e.g. the size of the lists you're trying to permute) Btw: Keep in mind both your original function and the one above only work if each element of "original" is unique. edit: yes this is much faster if the dictionary orig_d doesn't need to be rebuilt. mine: In [69]: %timeit order3(orig_d, sigma) 10000 loops, best of 3: 47.1 Âµs per loop yours: In [70]: %timeit order(original, sigma) 100 loops, best of 3: 9.34 ms per loop
Cool story bro. U mad? I jelleh. Nice to meet you.
4. Use Docker
Alternatives to Sublime: vim and emacs. Both have excellent python support. 
Celery actually uses pika to interface with rabbitmq, it just exposes a better interface. 
Because slices can be made with mutable objects: &gt; x = [1, 2, 3] &gt; y = [4, 5, 6] &gt; s = slice(x, y) &gt; s slice([1, 2, 3], [4, 5, 6], None) &gt; s.start[:] = s.stop[:] &gt; s slice([4, 5, 6], [4, 5, 6], None) This is intentionally so that you can overload slicing with more interesting behaviors a la NumPy tuple slicing (I know tuples are immutable, but it's an example where default slicing was extended).
Can confirm, got here by clicking reddit's Random subreddit button
I'm surprised that you raised several very relevant points, but forgot to mention that `import *` is a bad practice.
I hope I can answer most of your questions: First, the core library solves the problem of there not being a way to use the Django template language (or Perl's HTML::Template) in C++; Synth contains fully self-contained, header-only implementations of those, which did not previously exist. Second, the Python bindings expose that functionality to Python users; clearly, there is already a Django implementation in Python, but there isn't one for the other engines. Synth allows you to easily use SSI in a standalone manner, for example. Third, the Synth implementation of the Django template language is both faster and architecturally cleaner than the original one, and is not tied to the non-template infrastructure in Django, which is much more than just a template system. Fourth, bear in mind that micro-benchmarks are often a fool's game and difficult to get right and to be representative; nevertheless, preliminary testing suggests Synth is around an order of magnitude (10x-15x) faster and more memory efficient at parsing and rendering than Django. I'll upload the benchmarking code I used shortly. Fifth, there is no comparison matrix because Synth aims to offer a complete replacement for the original implementation. Still, as I mentioned in my post, you can peruse all the specific features implemented in detail by looking at the [README](https://github.com/ajg/synth#django-engine). Lastly, I can't tell you what's "in it for you" because I don't know what problem you have. If you are not in need of a way to parse and render templates in various formats from either C++ or Python (with more language bindings coming soon) then Synth has nothing to offer you. [Alvaro](http://alva.ro) 
Please don't announce in a post that you're downvoting other things. Just downvote and move on. Preferably link people to a proper subreddit in an effort to get them into the right place.
Check this out. I did something similar as my first python project. https://github.com/dodecatheon/sudoku-password-card
Load the data into a numpy array and do a fit. Once you've done so, you can use this: http://docs.scipy.org/doc/scipy/reference/interpolate.html 
dude... this is great. I'm using this in code that runs this operation like 10e26 times in a small problem, 1% would have been fantastic, 29% and 47% is phenomenal. Thank you. 
Actually, the \_\_init\_\_.py is no more required since [Python 3.3](http://legacy.python.org/dev/peps/pep-0420/)
I'm betting your "4-core" MacBook is actually a 2-core machine with hyperthreading, so it presents itself as 4 virtual cores to the OS. The same goes for your iMac. [There was a bestof'ed ELI5 recently that talked about this.](http://www.reddit.com/r/explainlikeimfive/comments/2bhxfr/eli5_my_seven_year_old_laptop_has_a_22ghz/cj5lx55)
cool as hell, but wtf do I need here? Please do a `pip freeze &gt; requirements.txt` in the future. Makes pylife a lot easier. $ sudo pip install pyopencv Downloading/unpacking pyopencv Could not find a version that satisfies the requirement pyopencv (from versions: 2.0.wr1.0.1-demo, 2.0.wr1.0.1, 2.0.wr1.1.0, 2.1.0.wr1.0.0, 2.1.0.wr1.0.1, 2.1.0.wr1.0.2, 2.1.0.wr1.1.0, 2.1.0.wr1.2.0, 2.1.0.wr1.2.0-demo, 2.1.0.wr1.2.0) Cleaning up... No distributions matching the version for pyopencv Storing complete log in /root/.pip/pip.log 
pandas
in the open-source light, you may consider to add/submit the code through a pull-request. /user/KoffeinFlummi can just merge the pull request. then he can avoid "Maybe I'll implement a smarter solution some time." why re-writing the wheel ?
You should almost ever avoid recursion (line 189) in Python as it does not offer tail recursion and so you will risk a stack overflow! It is in most cases quiete easy to transform a recursive function into an iterative one; mostly by using some kind of stack.
if you dont mind me asking, how are you profiling this python code? I've looked into using various ipython magic functions and other time modules but they always lead to inconsistent results.
- Linux live CD ... comes with Python pre-installed. Developing on Linux is a far more pleasurable experience anyway.
Noooooo! I would not recommend ActiveState. They really messed up my system. Nowadays, I recommend people use Anaconda on Windows. Reasoning here: http://pythonforengineers.com/stop-struggling-with-python-on-windows/ http://pythonforengineers.com/python-on-windows-causing-you-pain-try-anaconda/ 
Yep. It's faster than the one I wrote. It's also linked to in the comments under my blog post (the one I link to above).
If what you need is interpolation, numpy.interp1d is what you need. If you need to concatenate things and sort according to x, then just concatenate and sort :)
Dude, why is it on pastebin, and not Github? Pastebin isn't permanent, afaik. 
Can you please elaborate on why Docker would be preferable to say, a VM?
Both Anaconda and VM are good options. A Linux VM gives you a full fledged Linux box and all it's associated advantages (a built in package manager, for example). If you'd rather stick with Windows, nothing beats Anaconda.
Install Ubuntu, and you will have loads. Seriously though. I use Aptana, which is a version of Eclipse configured with various web programming plugins, including a Python one. I think it is available for Mac also. 
Can you say some more about the context of this? It doesn't make any sense to me. Doesn't "order" take as an argument a list that's the same as the one you need "permutation" to output? If so, can you just copy that list?
No, it's a fair question. The reason is that it is a best practice to have properties and methods defined on the model they belong to. Decoupling them and putting them in the views is less DRY. Compare having a single method for checks implemented on a model compared to ad-hoc checks in views. I wanted something that could do "Does this user have an expiration date after today? Does their subscription plan allow the current action?". This is much better to implement on the User model and then call it in templates, rather than have to calculate it in every single view you want to check it in. The alternative, implementing it on the user model and calling it in the view and passing the result is just extra code.
somehow I'm all about starting over with Python 2.7.x over 3.x.x Simply because the sheer volume of packages available for 2 over 3. As far as learning on the go, codeacademy should be fairly decent to get you up and running. I'm sure there are others like it too. search, have a look around.
The second seems like odd behaviour- shouldn't the first line just produce an actual tuple, rather than a generator? Would it be any different if it were in square brackets?
Generators are fun. In your example, it only iterates until the value is found. It does not exhaust the whole iterator. &gt;&gt;&gt; def myrange(num): ... for x in range(num): ... print('yielding', x) ... yield x ... &gt;&gt;&gt; s = (val for val in myrange(10)) &gt;&gt;&gt; &gt;&gt;&gt; 1 in s yielding 0 yielding 1 True &gt;&gt;&gt; 5 in s yielding 2 yielding 3 yielding 4 yielding 5 True &gt;&gt;&gt; 
Say I sorted a list, and then passed it through map, and now I want to permute the results so that they correspond to the original ordering, this is exactly what I want. Why? Because I have an incredibly large (combinatorial) problem space whose symmetry I can exploit in this way to drastically lower the time complexity. 
The first line sets s to a [generator expression](http://legacy.python.org/dev/peps/pep-0289/#the-details). It's fair to say that it looks like an obvious analogue of the list comprehension, but it does produce a generator. Generator expressions are really worth knowing IMO, I personally use them way more than full generators because you get the primary benefits (lazy generation and memory efficiency) with additional niceties (inline syntax) and without any significant need to think about 'I am writing a generator here'
If we are talking about py3 then - no, because range in third python gives also generator. But, if we are about py2 then - yes, cause in python 2 range returns list.
For python2, would i in xrange(10) Work?
Programmatically yes, functionally no. A more interesting example that cannot be replicated with 'X in range()': &gt;&gt;&gt; 49 in (x ** 2 for x in range(10)) True &gt;&gt;&gt; 50 in (x ** 2 for x in range(10)) False &gt;&gt;&gt; 64 in (x ** 2 for x in range(10)) True &gt;&gt;&gt; 63 in (x ** 2 for x in range(10)) False
Yeah, if you specifically want an iterator. If you don't care, either range or xrange will do. Note that range[py3]/xrange[py2] are special cases, as they are their own object type, which provides an iterator, but also has it's own specific \_\_contains\_\_() method. Consequently it's much faster than pure iteration. (IPython syntax) # __contains__ based version %%timeit l = range(10000) 5000 in l 1000000 loops, best of 3: 325 ns per loop # iterator based version %timeit 5000 in iter(range(10000)) 1000 loops, best of 3: 368 Âµs per loop (Note that the second timing was given in microseconds, while the first is in nanoseconds. The second figure converted to nanoseconds is 368000, which is about 400 times slower than the \_\_contains\_\_ based version. This list-based version: %%timeit l = list(range(10000)) 5000 in l is slightly faster (325 Âµs) than the iterator version, but not enough that you should ever use it unless you have to.)
If I'll use a text editor without a built in interpreter, how do I run the script? using Terminal?
There is no need for: s = (val for val in myrange(10)) Since *myrange()* is already a generator, you can simply write: s = myrange(10)
Yes, this is true. I was just trying to show what was going on in his example (by printing the values that were yielded) when he created the generator expression from range().