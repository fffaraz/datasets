hooray, now I can pretend I was actually there.
Ha! you are correct sir. I knew something was missing, thanks.
David's GIL talk was awesome, and I would always recommend watching the lightning talks.
Grr... blogspam. Here's the real link: http://pycon.blip.tv/
Thanks! I was actually going to go but I got really busy at work and I couldn't take time off.
Irony: if submitter took the amount of time they would spend learning how and then creating a ratio-faker and instead just left their torrents seeding, they'd end up with a better ratio. Also, you suck, leech. 
It's actually = \_("Name") and \_ is a function.
This can't be done. You have to have separate processes to have separate modules and paths.
_ is used for translations http://docs.djangoproject.com/en/dev/topics/i18n/deployment/#topics-i18n-deployment The name "_" is just a shortcut for easy typing. Look at the top of the file something like "from .... import ugettext as _"
according to the python docs it's a translation function http://docs.python.org/library/gettext.html#gettext.gettext
You'll see the `_()` function/macro in many different languages. As others have said, it's for translating the string into other languages.
There is only one 2010 PyCon video there ?
escape your underscores with a backslash.
I'm actually taking that now, just recently joined /r/python to hel expose me to real-world coding applications. I'm still trying to figure out where poeple learn about the libraries they need, but i'm sure the class will address that at some point. But yeah, the MIT intro to CS is doing a good job teaching python. That and all of the awesome free python texts they recommend.
\_ is just a character that can be used in normal identifiers. Note that interactive python defines \_ as the last thing returned to the interpreter main loop. As in: &gt;&gt;&gt; 1+2 3 &gt;&gt;&gt; _ 3 In django's case, it is just used as the name of the string translation function. 
If you want this, you probably need a compiled, reference counted (non-GC) lanuage. I don't see this changing any time soon.
It's worth noting that most `gettext`-based l18n bindings use `_` as their translation function, since that's the tradition for the C library itself. You'll not really find any other `_` functions :)
&gt; Note that interactive python defines _ as the last thing returned to the interpreter main loop. Wow, where is that documented? I knew that Lisp environments use `*`, `**`, and `***` to refer to the most recent three things retured to the repl, but not Python's `_`.
That's only listed as common use, as in the example _ = gettext.gettext # ... print _('This is a translatable string.') where it's just been defined explicitly. 
pretty badass. i like the idea of having an editable chunk of code i can go back and mess with more than bpython's rewind option. ...but i keep going back to ipython because it uses gnu readline for input. my fingers are hardwired to push esc-shift-I to go to the beginning of the line, etc
apparently and for the moment, yes, only one pycon2010 vid.
The best of those 'interactive debuggers' is by far IMO reinteract with its in place realtime editing, but it's not 100% python compatible. 
&gt; Wow, where is that documented? No idea. I found that one day when I was bored and went trough builtins with dir() and help().
Thanks for putting into words what my instincts (17 years development) told me. I couldn't quite put my finger on it, but, "Oh well, I guess I'll wait until most people move to Python 3." Your steps 1-4 define very precisely what the problem is.
It's defined in http://docs.python.org/dev/tutorial/introduction.html, near the end of section 3.1.1: "In interactive mode, the last printed expression is assigned to the variable \_." Also here: http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html#interactive
Another curious fact about Python's REPL is: &gt;&gt;&gt; for i in range(3): str(i) '0' '1' '2' The `POP` opcodes (used to discard the results of expressions-used-as-statements) are converted to a special opcode that prints `repr` (not `str`!) of the result. That's why, by the way, `None` is never printed implicitly in REPL: because every toplevel function call would then litter the output with Nones. This thing is kinda useful when writing doctests.
django has explicitly imported (u)gettext as \_ for a while now
Its not about ratio, i just wanted to make an useful program. You got me all wrong. Anyway, ive changed my mind, maybe that isnt such a good idea.
I'm a bit curious how easy it would be to write a 3to2 conversion tool, which would mostly solve the stated problem. E.g. the with statement whould be easy to emulate, as should dropped support for e.g. old-style objects. Not sure how well the string format changes will translate, though.
In the long term Python 2 will become the ghetto. Yes the 2.x line will continue for a few more releases, but development so far has mostly been in the form of bug fixes and backports from 3. The future of Python is in the 3.x branch. That doesn't mean that 3 is always going to have the library support you want right now, but it will. These things take time.
Linux app, its a gtk client for tumblr.com
Im going to try this one, thanks!
A 3to2 conversion tool was written as a SoC project and featured in the October 2009 issue of Python Magazine.
If Python wants Python 3 to succeed, they should realize that they need to aim as many programming resources as possible (Summer of Code hackers, new volunteers, etc) at one thing: porting libraries. Yes, they've ported all the standard ones, but they need to port the ones they don't traditionally support, such as NumPy and Django. Most of the Python projects I encounter have a dependency on one of those two, in fact. There is simply no way to develop a software ecosystem on Python 3 without them. Django seems to be making progress on the transition, but NumPy needs serious help.
Interesting. If the tools works for older versions down to and including 2.4 and doesn't impose any unreasonable limitations, the main article author shouldn't have anything to complain about except insufficient information.
Talk about riding another blogger's coattails. Get yourself your own catchy blog post title.
I think it will be interesting to see if: 1) The speed improvements Unladen Swallow is supposedly bringing to the table will be noticeably faster than CPython as it stands today. 2) If people will be more gung-ho to adopt Python 3 on a more permanent basis given a 2-5x speedup.
http://launchpad.net/
You're doing it wrong. There are hundreds of thousands of bug reports, and you don't seem motivated to find those to fix them. You have to scratch your own itch, or else you will lose interest or not know where to stop. Find something that annoys you and fix it.
Agreed. I would love to switch to 3, but libraries seem stuck in 2! As the big projects go, so (I hope) will the little ones.
What does gunicorn offer over Spawning, Tornado, etc ?
Or use backticks: The name `_` is [...] Becomes: The name `_` is [...]
 from django.utils.translation import ungettext, ugettext_lazy as _ The definition of _ is directly at the top of the file you're reading. 
I will admit that I was unaware of the 3to2 project, I'm still a little bit weary about relying on it to generate code for 100% of my user-base. As it stands now 3to2 is a third-party tool that the author [is trying to get included into Python 3.2](http://www.startcodon.com/wordpress/?p=242) to make it more standardized, like 2to3. I'm personally hoping his work is merged into the standard Python distribution, it looks like a good way to make the jump to Python 3 much easier
Ok, it translates and sometimes finds equilibrium. Now what?
Depending how much you love Python it might be worth contributing some spare time to improving the Python wrapper around OpenCV ...
People should be writing their code in python 3 and backporting it to 2? Makes more sense to me than using 2to3.py
Thanks for this app, this is a really useful function to figure out how to code python 3 properly. It seems that backporting from 3 to 2 is alot more feasible than 2 to 3. Python 3s benefit for internationalization by using unicode is nothing to sneeze at. Frankly... its amazing!
Yes. We use an all-free-software-setup using a tool called dvswitch, a piece of hardware called a twinpak, and a whole bunch of other things.
Now the developers of 2to3.py and 3to2.py have more data to work with in refining their tools, and now you (perhaps) have a little more exposure to how the tools do their thing. Now you don't have to go on stackoverflow and ask "Can 2to3 handle the &lt;&gt; inequality operator?" and I don't have to go on stackoverflow and answer you.
I see your point. It would be excellent if 3to2 would get full support of the CPython devs, since that would hopefully make it at least an option for lib writers to make Python 3 their main development version.
 def spam(): ham = 0 def eggs(i): nonlocal ham ham += i return bar This is an obvious example that doesn't work correctly. 
IMO, almost all uses of enum in C really ought to have used something else -- which is whatever the enum indexes over. For example, if some code switch()s on the enum to select different code to run, pack those pieces of code into functions, and replace the enum values with function pointers. If the enum is switched upon to choose one of several variables, replace the enum values with a pointer to one of these variables. If there are multiple choices over the same enum, replace enum values with a structure containing all of those choices (e.g: resembling a vtable). Only when the enum indexes over something in a code-open way (an unbounded amount of code might use the enum to index over stuff) or when some external specification defines the constants (e.g: Wire protocols) would I use an "enum".
I prefer simply: lambda x=x: x
I wouldn't expect 3to2 to fix busted code, but I would expect it not to create python2 code that bombs out with a SyntaxError on the nonexistent keyword nonlocal.
It’s not clear that there’s any mechanical fix for this though. Should it do list boxing or something?
Reading the Python-dev list makes it sound highly unlikely that there will ever be a Python 2.8. They’re pretty committed to stopping at 2.7. 
Escaping the underscore with a backslash will cause Reddit's back end to generate the underscore in plaintext like this: \_, while wrapping it in backticks will cause Reddit to render the underscore wrapped in an html `&lt;code&gt;` tag, like this: `_`. Different browsers will treat the `&lt;code&gt;` tag differently, but they'll all output the plaintext underscore the same. If you use Chrome, you'll notice that hovering over the plaintext underscore does nothing, while hovering over the `&lt;code&gt;`-wrapped underscore will outline it in a box. edit: [screenshot](http://imgur.com/2IpuO)
TIL. Of course a lambda can take keyword arguments, and this does the necessary rebinding. Thanks! :)
Well, actually I would prefer for it to do that over just producing something that won't even make you aware that there is a non-translatable piece of code.
It would be nice if either the entries weren't sequential (random id) or if there was a way to delete and/or not retain them. This way someone who's somewhat hesitant to paste in their code either has a way to delete it post-paste or a way to ensure it's not easily found...
Indeed. The backtick is for inline code, and given the `_` is a bit of code, this seems sensible.. The backslash thing is useful, however (for \*'s and such)
&gt; to figure out how to code python 3 properly Bear in mind 2to3 doesn't necessarily produce the best code - for example, there may be a new feature or library that does something much more cleanly than the auto-translated code
&gt; If Python wants Python 3 to succeed Google doesn't really want Guido to want Python 3 to succeed. Google is firmly rooted in the 2.x series.
It's as quiet here as it was after my Testing-in-Python BoF talk. :)
I know just enough about Python3 to be dangerous, but I've heard that the print call was changed from a simple print 'hello world' to being an actual function. print('hello world') The fact that there is a change at all means that there was some other back-end stuff that makes Python3's implementation significantly different from Python2's.
The primary issue with Marhematica is its proprietary nature, which is not acceptable for a educational institution. As good or as bad as you think Mathematica is, it is this issue that should disqualify it for consideration. As to Python it is a good choice but the department shouldn't be so damn ridgid. This is Physics not a comp sci program. Besides I could make an arguement that ADA would be the best choice for long running physics experiments. Dave 
[sourceforge](http://pyqrcode.sourceforge.net/)
Thanks, really appreciate the help. I swear I just couldn't find when looking through Google, you can imagine how many results have a "_" in them! :) 
Awesome history there. 
Thanks guys, it all makes sense now! I wondered why all form templates were importing l18n custom tags. 
There is some risk that Python3 shares the same fate as Perl6. My biggest gripe with Python3 is the disappearance of the print statement. This may seem innocuous but the print statement is the best debugger ever invented!
I'm more of a self-study kind of guy, so here are some places where you can learn on your own. The [official Python docs](http://docs.python.org/) tend to be well-written and easy to understand. I recommend starting with the [Brief Tour of the Standard Library](http://docs.python.org/tutorial/stdlib.html) section of the Tutorial. [Dive Into Python](http://diveintopython.org/getting_to_know_python/index.html#odbchelper.divein) is also a good place to start. The book is [available for purchase](http://www.amazon.com/Dive-Into-Python-Mark-Pilgrim/dp/1441413022/), but the author makes it freely available at his website. 
I learned Python by developing webapps on Google AppEngine. If you have any programming skills already then program in Python is a bliss, except the braces part which I personally can only get used to it rather than like the idea. After foreplay, you may try out those fabulous libraries/frameworks out there. (django, pylons, etc.)
I've found books to be by far the best way. I tried the online thing for a while and just ended up with less knowledge than buying my first true oreilly 'learning python' book. I even read the first 10 chapters on the stuff I already knew and found out some additional stuff. I've been told the python cookbook is a must have too...
Everybody is busy trying to find adorable goat plushies to compliment their django ponies
Yeah, the syntax for print has changed a lot, and the 3to2 translator doesn't handle it very well yet. This simple snippet (print the number 1 with no trailing newline) causes a crash when moving back from 3 to 2: print 1, 
I'm a bit confused about the string handling. 2to3 switches from byte strings to unicode strings, e.g. py2 "foo" becomes by3 "foo", but 3to2 does not switch back, e.g. py3 "foo" becomes py2 u"foo". Not sure which behavious is the better, but it's subotimal that they differ.
I think this is understandable. Strings in python3 are all unicode, and behave differently from bytes objects (eg. they print differently, won't compare equivalently to unicode strings etc). The closest in behaviour to a python2 (byte) string *is* a python3 (unicode) string. You'll also lose less going from 8 bit to unicode - the only case you'll have problems is if you're using actual binary data (eg. checking a file contents that you explicitely open in raw mode), and even then you should get a hard error in most cases. You can explicitely mark them as byte strings in both streams when this *is* what you want. The 3to2 behaviour is neccessary so that you won't lose information. Your code may *rely* on unicode behaviour, and is more likely to break things when this is all removed. Ultimately I think this is the best behaviour possible. **[Edit]** Actually, having said that, I just tried it out, and in fact `print b"hello"` ended up losing the byte marker on the translation back resulting in an equilibrium of `print u"hello"`. This will only occur with multiple back and forth, but I think it's probably a bug in 3to2 that it doesn't preserve the annotation, even if just from a communication of intentions perspective.
Making the python interpreter support actual multithreading is _hard_. I don't doubt that, not at all. But seriously, the GIL is slowly transforming from a simple lock to a complete scheduler/threading implementation, which is significantly harder to do. This way, we get all of the complexity, and none of the scalability. For the love of bog, stop this turd polishing and start working on actually removing the GIL instead.
It finds equilibrium, but the code would no longer work: http://www.pythontranslationparty.appspot.com/4350/ Not very useful.
Actually there is a comment there stating that one way to work around this may lie in setting OS thread priority, not in doing that prioritizing work in Python. And actually you can not polish a turd, you can only roll it in glitter. That's exactly what new-gil was supposed to do. If you are interested in a turd-free cake though, then please bake it. The community will surely call you a hero. I would.
I second Dive into Python for anyone with some programming background. that book got me up and running in a few hours. Guido's official tutorial on python.org is also terrific. Python is a powerful language but its also quite simple, try the online resources before spending your hard-earned money on a book you might never read more than the first 5 pages of. 
&gt; But seriously, the GIL is slowly transforming from a simple lock to a complete scheduler/threading implementation, which is significantly harder to do. This way, we get all of the complexity, and none of the scalability. Yes, all [250 lines](http://bugs.python.org/file15967/newgil-2.7.diff) of pointless complexity.
Sorry that was a typo. I didn't copy-paste. It was originally working code with ham, not a.
Im not downvoting you, but I would like to see a bibliography please. 
Agreed. Don't waste time with online classes. You can pace yourself by using books instead. In addition, it will be cheaper.
truth ^
 def print(*args, sep=' ', end='\\n', file=None) [Is a function all that bad ?](http://www.python.org/dev/peps/pep-3105/)
Dont blame it on the flash.
*Sure...*
 import subprocess def shell(cmd): p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) return p.communicate()
Yeah I saw that one, but it looks overly complicated for what I want to do. Simple encoding, no decoding. I'll give it a shot regardless. Thanks!
Wtf why is that hard to believe?
&gt; For the love of bog, stop this turd polishing and start working on actually removing the GIL instead. That was one of the stated goals of Unladen Swallow. But IIRC given their requirement that it not introduce backwards-incompatible language changes, it was too difficult/impossible.
I .... well, I guess it is believable
Wait, hold on, so he kicks a ps2 controller and it deploys his website? 
There's a definite market opportunity there.
I will give the dive a shot. This looks pretty good and I'm stoked to see it's free online.
I would be more interested in AppEngine, but I just can't think of anything worthwhile to really make for it...
Thanks! I had forgotten about this comment.. I'm gonna order an NXT set today and see what all I can do. This sounds like a lot of fun!
Dive Into is pretty good, but you should still take a look at the official docs. The Brief Tour I linked above will take you through getting some real work done with the standard library -- how to copy a file, how to use a regex, etc. The [Library Reference](http://docs.python.org/library/index.html) is also a good read, covering things like [strings](http://docs.python.org/library/strings.html), [data types](http://docs.python.org/library/datatypes.html), [file and directory access](http://docs.python.org/library/filesys.html), [cryptographic services](http://docs.python.org/library/crypto.html), [IPC](http://docs.python.org/library/ipc.html) and many others. Python tries to go for a "batteries included" distribution, so there's an awful lot of functionality available in the standard library -- it's good to be familiar with it. 
Yep, exactly. There's no need for a whole module for this. Though I'd rather: return (p.wait(), p.stdout, p.stderr)
Nope. It should bomb out and tell you your code cannot be automatically converted. You're using a pattern that doesn't translate readily, and should refactor if you're going to support a dual-version code base. The nonlocal keyword is one of the more incompatible changes that was made. Or 2.7 should grow a `from __future__ import nonlocal` directive.
The author's name is on the bottom of the page. File a feature request. 
Sounds like a bug to me. Report it here: http://bitbucket.org/amentajo/lib3to2/issues/
That is to say, it seems like the py2.7 version should have a `b""` annotation.
Yup. Shadowing builtins has always been a bad idea. This is another reason why.
Looks like a fascinating piece of software. However I can't seem to figure out how I would use it. Does the OP use it? If so, could you give me an example use-case scenario?
[Here is the video of the talk](http://pycon.blip.tv/file/3254256/)
Awesome! Watching it right now. :) Update: Finished watching. Good stuff.
So it's emacs?
Good to hear a concrete counterexample to complaints about python's scalability and performance; a follow-up on how you're dealing with the recent site lags and outages would be cool too.
&gt; And actually you can not polish a turd... Myth Busted! http://dsc.discovery.com/videos/mythbusters-polishing-a-turd.html
&gt;Welcome to the secret box Haha, didn't work out did it ;)
Funny you should ask. We're actually working on that today. Our first test was to add 5 more application servers on each application server. So far we've been able to handle more traffic with almost no increase in load. We might add even more. We still don't know what caused that outage. I have a meeting with Amazon later this week, so I'm going to try and find out there.
No! At first I was a little annoyed, but then I realized the video guys have a really hard job and are volunteers, so I can't really complain. I should instead be thanking them for the wonderful job they did!
Thanks!
Happily, your empirical therapy does seem to be working; but if the etiology emerges from that Amazon meeting that'd be nifty to hear. 
As we should be for your job! Cheers.
Cool. Can you post your slides, especially that architecture diagram?
How about a scaling PostgreSQL talk too?
Slides are here: http://us.pycon.org/2010/conference/schedule/event/148/ The arch diagram is in there.
There was [a good talk on database scalability](http://us.pycon.org/2010/conference/schedule/event/28/) that pretty much covers everything we are doing. It looks like the video isn't up yet, but I'm sure it will be soon.
Why is shadowing builtins a bad idea? Except that it breaks with 2to3.
i learnt python by python cookbook. It was tasty.
Cool stuff! Out of curiosity from a Python out-sider: did you ever try alternative Python impls (Jython, IronPython, etc.) or is this just infeasible for this kind of codebase?
Right on, thanks.
not all of them are 2010 right?
Yeah, it seems that 2009 and 2010 videos are all lumped together. The pycon side has a list of talks from this year, with downloadable slides. http://us.pycon.org/2010/conference/talks/
You say up to 2 comments per second. How many votes are there per second?
Thanks. I'm on the video team at pycon... all the editing is done live using a program called dvswitch. It works out for the best generally because post-recording editing just *doesn't happen*. I wasn't in on this session but I'm assuming the person doing the recording just didn't notice that you wanted them to put the video over the box... they were probably concentrating on your slides and trying to figure out where to best put the picture-in-picture as in terms of *empty space*. As far as I can tell, you're the first person who's ever made a "marker" in their slides. Usually when I work on it I just try to find the space in the slide that has the most whitespace to put the box. Once the video is recorded, that mixing is already done though and can't be altered, so that's how it goes! Once again, if we didn't do it live, it wouldn't happen at all.. trust me on this, it's what was done in 2008, and that's why the videos never made it up (well one of the reasons anyway... the other issue is licensing... we didn't get permission to release the videos, and sent out a bunch of forms asking people to agree to let their talks be uploaded and freely licensed. Now that's built into the signup portion). Anyway, it's how we manage to get editing done without stretching our volunteers too thin and making volunteering completely and totally boring. It's also a lot easier to tell where to edit and put boxes in realtime, believe it or not. Most "professional" recording groups don't even do both presenter camera recording and displaying the slides, so I think we are doing a pretty good job! On a side note, I'm the one who mentioned that I knew your brother from Barat. Say hi to Ryan for me. :)
&gt; add 5 more application servers on each application server. yo, dawg, I herd you like application servers...
No, seriously, how's this development effort best spent here rather than in Emacs proper?
Probably Python fanaticism causing fear of Elisp.
TIL! Awesome!
I had the same questions, but I answered them for myself poking around. Here is what I found: Literate programming for Python: http://webpages.charter.net/edreamleo/intro.html Personal testimonials: http://webpages.charter.net/edreamleo/testimonials.html I imagine one could use it as a replacement for OneNote and other note taking software, but the learning curve for it is definitely steeper. 
Why would a Python programmer who wants to use literate programming in an editor that supports the practice, want to mess around with elisp? Seriously? Emacs is great if you're using lisp, otherwise not so much.
because Emacs has lots of other support already that doesn't need to be replicated here. Reading through the documentation gives me the impression it could as well be a mode like any other in Emacs that is perfectly able to co-exist.
It would be nice if you could load leo in emacs if you're already hacking Python there. But not everything needs to be an emacs mode. 
Try the RSS feed: http://pycon.blip.tv/rss much easier to search sadly there are no videos for these but they looked interesting: [threading is not a model](http://us.pycon.org/media/2010/talkdata/PyCon2010/100/Threading_is_not_a_model.odp) [metaprogramming](http://us.pycon.org/media/2010/talkdata/PyCon2010/096/metaprogramming_pdf.pdf) [maximize your program's laziness](http://us.pycon.org/media/2010/talkdata/PyCon2010/032/Slides.pdf) [the mighty dictionary](http://us.pycon.org/media/2010/talkdata/PyCon2010/012/presentation.html)
But the secret box is missing!
You'll just have to watch the video. I already deleted the deck with the secret box. ;)
I don't really understand how extending emacs with elisp prevents you from using it to write literate Python. I use emacs for... everything. I used to be a one-tool per job sort of person, then I realized that each of these tools would be best if I could make them work together. I switched to emacs on a recommendation from a friend, and now, 5 years later, I'd never, ever go back. There's just something awesome about being able to do every part of my workflow in one place, in a way that works well together. And no, I don't write code in lisp. Mostly PHP and JS these days, excepting of course the elisp extensions I write for myself. Before this I was using Emacs to write PS3 and 360 games! I'm sure there must be a way to do literate python in Emacs. I do literate Haskell in emacs now. Not to mention the slickness of doing snippets with org-mode for writing documentation...
&gt;meeting with Amazon Ahhh! Don't do that! You can rupture the shear fabric of space and time by bringing such forces of awesome so close together!
&gt; I used to be a one-tool per job sort of person, then I realized that each of these tools would be best if I could make them work together. All well and fine, but why should everyone else work in elisp/emacs just because there are folks out there who want to use emacs for everything? I think what complicates these discussions is when an individual forms a philosophy of sorts around tools in general. Then they expect the rest of the world to conform to that philosophy and anyone that does it differently gets frowned at. The world just doesn't live in emacs, sorry. If you should write a emacs replacement for Leo with full support for cloning, I'd love to see it, but don't expect a huge wave of adoption, even by current Leo users.
I didn't say that everyone should work in emacs, someone else did. Has nothing to do with 'philosophy' but everything to do with practicality and expedited work flow. I don't waste nearly as much time yak shaving as I used to.
About 10 per second at peak.
What a small world! I tried finding you later that night, because I texted my brother and found out that it was you whose wedding he went to in Chicago, so I wanted to say congrats. And all of that stuff about live editing makes a lot of sense. I know I never get around to editing my vids either. Next time I'll make sure to let my video guy know ahead of time. :) Thanks to you and the entire video team for your efforts!
What is this secret box? :(
We've looked at the other ones previously. At the time they weren't really mature. It will probably soon be time to look again. Having Unladen Swallow merged in looks really promising.
It's a secret. Well, it was supposed to be. Watch the video and look at the bottom right corner of the slides.
Ah, ok. I semi-noticed that at random points, but not at the beginning where it said it was the secret box. By the way, I know you're not allowed to disclose your total revenue, but can you answer whether reddit makes an overall profit after all of the costs are taken into account?
It would be awesome to see a series of blog posts on how this stuff was all put together, perhaps with examples and stuff. I find it insanely interesting, but lack the time to familiarize myself enough with the Reddit codebase to see how it all works (and would likely misunderstand some of it).
What other videos would you recommend watching? Interesting about how much it costs to run reddit. Hope you didn't get in trouble for it ;p Edit: I mean what other vids/talks did you enjoy watching.
I'd like if you can point me to one of these (backwards incompatible) SQLAlchemy API changes you're referring to, especially if you're not even using the ORM which is where most of the API changes happen. Particularly within a "major version", which for us is like 0.4, 0.5, 0.6, etc.
http://blip.tv/file/3257303 PyCon 2010:Scaling your Python application on EC2 (#191) Jeremy Edberg
nice!
2010 videos have "pycon 2010" in the title. The ones in OP are 2009 videos.
I can't view the video as I'm stuck in my hotel room at the Hyatt and their "Business Grade" wireless internet is friggin' woeful, but did you let the AV recording person in your room know you wanted that bit covered up? And the comments paroneayea make below are accurate; the mentality behind the whole pycon AV recording workflow is to minimize any post-production to the point where we're doing cuts during editing and only basic chopping/automated audio normalization/etc after the video is recorded. The pro means videos are released rapidly; the con is that we can't do any post-editing outside of completely chopping out sections of a talk. We don't retain individual video feed files (VGA output, cameras, etc) but only the final mixed content.
&gt; but did you let the AV recording person in your room know you wanted that bit covered up? No, and that was my fault. I just assumed the box always went in the lower right. Next year I'll make sure my video person knows that. :)
&gt; but can you answer whether reddit makes an overall profit after all of the costs are taken into account? Well, we're still here, eh?
It really depends on what you are interested in learning. Check out the [schedule](http://us.pycon.org/2010/conference/schedule/), read the descriptions, and then find the videos on the [blip tv site](http://pycon.blip.tv/).
True enough...just checking. =P
You mentioned replicating your various PostgreSQL databases; what are you using for replication? Slony? Londiste?
Londiste.
You mentioned you might replace paste in future. Can you share what are you thinking as replacement? 
&gt; PostgreSQL is the fastest key-value store we tried. I know Tom Lane is an evil genius, but are you comparing it to things like redis, memcachedb and bdb? In that case, some numbers would be nice :)
etiology is the *study* of causation, not causation itself...
shadowing builtins is a bad idea because it surprises the reader of your code. builtins are "hard coded" in the programmers brain; when there is a len(whatever), you are not used to lookup "hmmm, first check if len is overwritten somewhere", but rather "that is the builtin len and it is good". There must be really, really, really good reasons to overwrite them in exchange for the possible readers troubles. And I recommend to comment EVERY use of an overwritten builtin with ##!!! len is overwritten to give time of day as a quick hack to work around IE bug 18131 or similiar
Wrong /r/ ?
&gt; shadowing builtins is a bad idea because it surprises the reader of your code. builtins are "hard coded" in the programmers brain; For every identifier, function or not, you are supposed to check from what scope it is coming anyways. You can't make all the names in modules unique over all libraries, so if you see a call to escape() you will have to check where that came from. And that is even worse, because it is an import. If you fail to spot a local shadowing a builtin in a 10 line function, you have more things to worry about than a shadowed builtin. Fact is: the builtins have generic names, that are better used for keyword arguments. `filter`, `map`, `file`, `compile` are all names that make a lot of sense to be used for keyword arguments, function and method names or local variables. Furthermore new builtins come with new Python versions and nobody will go over old code, rewrite identifiers because new builtins appeared.
How does this course differ from [6.001 Structure and Interpretation of Computer Programs](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-001Spring-2005/CourseHome/index.htm)? Based on the course numbering alone, I'd say that this course is more introductory in nature...
So I read about [rabbitmq](http://www.rabbitmq.com/) and about [AMPQ](http://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol) and I still don't get it. Do all high volume websites need a queue?
$250K a year to run reddit is really really cheap. I dunno why that guy from the audience thought it was expensive.
I've answered to your comment on my page.
OpenHatch is something I work on. Lovely to see it posted here! Over the weekend, I ran an open space at PyCon where we found an open source project to contribute to. We all ended up choosing the Python programming language ("CPython") itself -- and two of us wrote documentation patches. Mine even got merged in! (-: (and hi David!)
If they have any slightly-long running processes, yes. Anything that can't be returned in a response quickly (even under load) is a candidate for offline processing. Some sites that have simpler requirements just spawn a thread to handle it within the web server, but that's not ideal and harder to monitor.
Awesome. I'm a fan of defensio. It started off a little rocky, and every once in a while stuff slips through, but it's oodles better than Akismet.
Who is this "python" of whom you speak? The python community most certainly has supported Numpy and Django. That's why they exist.
Perl6's fate is that it doesn't exist. Python 3 exists, is in use, and is getting cooler all the time. (Unladen Swallow and the unittest refactor are prime examples) It does have some risk of not taking off, but that doesn't seem highly likely, given the energy going into it, but that's different from being perpetual vaporware. $ sudo aptitude install perl6 Reading package lists... Done Building dependency tree Reading state information... Done Reading extended state information Initializing package states... Done Couldn't find package "perl6". Python 3 shipped, and is packaged on most any os you care to name. 
What? Dude, python-mode.el + ipython.el alone constitute a ridiculously powerful IDE. I'd argue up until Pycharm nothing even came close to the experience (and Pycharm is still in beta). You don't have to touch elisp at all if you don't want to. And if you want to extend emacs, and want to avoid elisp then install pymacs. 
Does IronPython have proprietary incompatibilities from CPython?
&gt;"I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you." Ouch.
So far it's been embrace and integrate. Basically only useful in Windows/Mono though, so there's not going to be much extinguishing going on.
IronPython is licensed under the MSPL, which is essentially a BSD license. 
I learnt by going through the Django tutorials, then reading: Dive into Python, finally Python cookbook.... 
Incompatibilities yes. Proprietary, though, not really, because it's open source. 
I just don't see why one would want to use a cross-platform language on a single platform. But to each their own I guess
What does that have to do with "embrace, extend, extinguish"?
I think part of the attraction is gaining full native access to the entire collection of Windows APIs. They may not be terribly elegant in many cases, and they're certainly not cross-platform, but they also give an experienced Windows programmer unparalleled functionality and control. No other toolkits can really match it, assuming you're only interested in Windows to begin with. That's my take on it anyway. I haven't used much of the new .NET stuff, I jumped ship to Linux, so maybe I'm wrong.
These differences are well documented and quite reasonable: http://ironpython.codeplex.com/wikipage?title=Differences
The existence of incompatibilities removed Python's portability, well documented or not.
Ahh of course, it's Microsoft... This *has* to be a *bad thing*. Right? Right!?
You're pretty much right. Also you get to use Visual Studio, which is far from the worst IDE out there.
Long running processes like what? Database backup or vote tallying? I'm sorry, I don't know/understand which web task one might require introducing a messaging subsystem which I'm guessing has it's own complexity, latency and what not.
Yeah, look at the ones from 2.0. Well documented my arse.
The GIL is the biggest wart I'd ever seen in python. Everybody nowadays has multiple cores and handicapped threads aren't threads. One day this GIL will get what it deserves and no, it's not a makeover. I do appreciate the work on improving the situation but even if it were a perfect GIL I'd still be restless.
If you're programming for .NET, you might want to write your code in Python. I write stuff in Python that runs on *nix. I don't use Python for portability, I use it because it's a nice language.
How many us lowest pingpong on GBit Ethernet?
actually ironpython IS portable(mono project), but he's basically trolling, so..., never mind.
What do you even mean by asking "How does this course differ"? This is an introduction to programming, SICP is a course about general software engineering and CS concepts (resp. an introduction to the principles of computation, as its official description says).
thank you
I asked because that SICP course used Python for its assignments, and I was wondering whether I was missing anything by going through that course instead of OP's suggestion. But yeah, I guess the course description was clear enough. Thanks for your reply.
Link to the paper: http://cs.haifa.ac.il/~rotemn/papers/systor09-python.pdf
Holy crap that's a whole lot of Python to do what &lt;1k lines of C [code](https://trac.fysik.dtu.dk/projects/gpaw/browser/trunk/c/mpi.c) and a makefile does. I'm however amazed that you don't need to create a custom Python interpreted to initialize MPI, but rather, that you can simply run: $ mpirun -c 2 pupympi_test1.py
A big part of using MPI is interacting with other code, often in different languages, that also uses MPI. For practical use, I recommend [mpi4py](http://mpi4py.scipy.org/docs/usrman), it offers complete bindings to the low-level stuff (lots of which is missing in pupyMPI) and includes a high-level interface (analogous to pupyMPI). The interface is just as nice to use as pupyMPI, but it's much faster and interoperable with libraries in other languages.
It's a pretty rich implementation, from my quick skim. Also there's tons of comments/docs. Perhaps the portability of python is a big plus, especially given how HPC environments tend to use more varieties of CPUs.
I haven't watched it yet, but I heard nothing but good things about David Beazley's [Understanding the Gil](http://us.pycon.org/2010/conference/schedule/event/76/) talk ([video here](http://pycon.blip.tv/file/3254256/)). I was also pretty excited about the upcoming changes to unittest in [New *and* Improved: Coming changes to unittest, the standard library test framework](http://us.pycon.org/2010/conference/schedule/event/138/): ([video here](http://pycon.blip.tv/file/3263882/))
Anyone here knows how Defensio compares to [TypePad AntiSpam](http://antispam.typepad.com/)? TypePad's solution is free and API-compatible with Akismet, so it's easy to plug into something that already supports Akismet. I'm using it with Trac and it more or less works, but is far from perfect...
I am not an expert in cryptography but I think the method is not insane. Any expert is welcome to review the algorithm.
HPC environments tend to build the Python interpreter from scratch anyway, so building a custom one which links with and initializes the MPI library isn't a big deal. I'm not sure what you mean by "rich" implementation... you basically only need send/receive/reduce to handle numerical data and barrier to maintain synchronization (throw in higher-level combinations hereof and you've got the full API). edit: Also, I've never heard of HPC clusters with different CPU varieties... it's just not feasible due to load imbalances and binary incompatibilities, but maybe I'm misunderstanding your comment.
What I'd **really** like to see is Microsoft adding Python (CPython) to Windows itself. Like Linux, BSD, OS X, and basically any sensible OS.
Using the [outside view](http://lesswrong.com/lw/jg/planning_fallacy/), it's clearly insane. You don't write your own crypto. Don't make me sic [Thomas Ptacek](http://chargen.matasano.com/chargen/2009/7/22/if-youre-typing-the-letters-a-e-s-into-your-code-youre-doing.html) on you.
&gt; I've never heard of HPC clusters with different CPU varieties I didn't mean a heterogeneous cluster. I suppose I should have said "...tend to use non-mainstream/non-x86 CPUs".
XOR is not strong enough for pretty much anything. It's considered a pretty trivial cypher, and falls to pretty trivial cryptanalysis. pycrypto is already in the PyPI. It uses solid algorithms, appears to be well maintained, and written (as far as I can tell) by people who understand cryptography. Don't use hashxorcypher. Install pycrypto and use blowfish or AES or some other well tested cipher if you want cryptography. Even if all you want it for is something silly or trivial.
I've written this just because in some scenarios it is not practical to use a big package, and I am really using the python standard hashes. This code is short and simple and it is easy to check there are no 'nasty hidden things'. Not that I want to get into cryptography software myself.
Oh, you're right on the money with that one. However, getting Python to build on non-mainstream platforms is a pain anyway... and Numpy... the horror!
This is insecure. As far as I can tell, if you encrypt two (or more) strings with the same key, I can XOR the first block of any two cipher-texts and I'll get the XOR of the plain-texts. This is because the prevBlock is initialised to an empty string at the start of each encryption. This is why you don't make your own crypto! It's easy to make a mistake.
&gt; XOR is not strong enough for pretty much anything. It's considered a pretty trivial cypher, and falls to pretty trivial cryptanalysis. If I XOR bytes generated from a completely random source with a plain-text the resultant cipher-text is unbreakable. This is called a one-time pad. The reason everyone doesn't use the one-time pad is the key distribution problem is a nightmare. You need a key byte for every byte you transmit. And you need to make sure that you exchange these key-bytes in advance of any communication. One way around this is to have a program that generates random looking bytes that nobody can predict. You choose the precise sequence of random bytes generated by having something called a "key". We call this a streamcipher. This key should be chosen at random. In a sense, the program simply "stretches" the much smaller random key to cover whole plain-text. You can then XOR this string with the plain-text and the result will be a (hopefully) unbreakable cryptogram. So XOR is not the problem here but the fact the program this guy came up with is insecure, in the way I describe further down the thread. &gt;pycrypto is already in the PyPI. It uses solid algorithms, appears to be well maintained, and written (as far as I can tell) by people who understand cryptography. &gt; Don't use hashxorcypher. Install pycrypto and use blowfish or AES or some other well tested cipher if you want cryptography. Even if all you want it for is something silly or trivial. I completely agree. Do exactly as this guy says.
The key for the first block is the hash of the pass-phrase. The key for the next blocks is a hash of the previous block. Which hash to use is determined by the previous block or pass-phrase. The pass-phrase is used only once (hashed) and each key should be unique...
Hear hear. Although they won't ever add cpython, now that iron python has support for .Net interop. That would be good enough. 
&gt; The pass-phrase is used only once (hashed) and each key should be unique... The library should be secure by design. If you make a library that exports an encrypt routine, people are going to use the same password twice. If they do this, they will suffer a serious security failure. It doesn't matter how well you document it. People will still use it incorrectly. It's an easy enough vulnerability to fix. Just include an IV. Here's how I would do this: * Pick a random integer between 0 and 2**128. Call this counter. * Compute Hash(passpharse || counter). * XOR hashed bytes with plain-text block. * Increment counter * Go to 2 until plain-text is completely encrypted. * Output initial counter || ciphertext. Where || is the concatenate operator. This has the following advantages over your scheme: * If two plain-texts are encrypted with the same key they don't encrypt to the same value. * If the same plain-text is encrypted with the same key, it doesn't encrypt to the same value. * The period of the cipher is know. It is 2**128 blocks. For extra credit, I'd have a message authentication code computed on the cipher-text to detect tampering. That is left as an exercise to the reader. 
Using a block cipher in [counter mode](http://en.wikipedia.org/wiki/Block_cipher_modes_of_operation#Counter_.28CTR.29) has the same issues. You're not wrong, but I think whenever you're dealing with security, you ought to look into what use cases you're trying to protect yourself from and the limitations of whatever security algorithms you're planning to use. Under limited conditions XORing is secure.
The code does not just xor data with the pass-phrase. That would be too weak. I think since it just uses a hash of the pass-phrase once and then uses a hash of the previous block of the data itself (that is not available to the cracker), it should be safe. Each key is unique and used just once... Also the data should be compressed before encrypting to improve the xor security. To increase security the hash function to use depends on either the passPhrase or the data in each block...
I see your point now, thanks. That's why I released this code: a sanity check. I'll fix that. EDIT: fixed. Instead of incrementing the counter I use for step 2: compute Hash(pass-phrase || salt || previous block). I do it that way to be able to select a different hash method for each block in a way that depends on the data. This should make it safer, right?
Vote tallying could be one example. A backup, probably not -- that's not initiated by the end user. Consider a report system, where you run an expensive SQL query and return a large csv file, probably .zip'ed. While this might finish in time for a web request, you definitely don't want to run it more than once, since the query is expensive and the file large. Instead you put a job in the queue and return the http response; the web page refreshes to check whether the job is done (or polls w/ ajax), and when it's down presents the finished download. Easier on the web server, and more reliable.
Fixed vulnerability (http://www.reddit.com/r/Python/comments/b6ext/hashxorcypher_a_lightweight_encryption_module/c0l6lgm) Now the code uses a random 32 byte 'salt' to append to the pass-phrase. Also the key for each block is a hash of the pass-phrase ++ the salt ++ the previous block of uncyphered data (being '++' string concatenation).
&gt; However, getting Python to build on non-mainstream platforms is a pain anyway... But if you can get someone to do the heavy lifting for you (Fedora ppc, e.g.), then you can get away w/writing your python code once.
The easiest way to get started may be django with whatever relational db you're familiar with. I say that mainly because there's a ton of documentation for that sort of setup. Once you have a working prototype, then worry about scale.
To say that SICP is about "software engineering" is a diminishment of what it really is.
That's certainly true, but portable doesn't always ensure that you will be able to actually use it because of icky things like patents; however, I'm guessing that most of the people who are reading this article are either stuck on windows or not concerned with patents.
What makes starting in Django easier than web2py? I'm trying to get the Python version of it as much right the first time as I can. I've already got a rough prototype done up in PHP and MySQL, but it's currently an unscalable security nightmare. At first this was supposed to be the "real" code, but being the biggest thing I've ever done, I didn't realize how much of a headache PHP was going to be, and decided it would probably be easier to rewrite in Python instead of fix the PHP.
What I meant to say was (core) software engineering concepts (and CS concepts). It surely has some valuable things to say about program design / software architecture.
The biggest problem with a framework on AppEngine is that, on a low-traffic site, the framework is loaded every time someone visits the site. It adds a few seconds to your initial load time. The next time I do any serious engineering on my AppEngine app, I'll probably replace Django with a simpler URL-mapping utility. I use Jinja for my templates, and AppEngine's datastore for my models, so the only things I'm getting from Django are URL mapping, debug pages when things break, and a painfully obtuse code structure. (I'm not really sure where the appropriate place to put files is, and it seems many share that confusion - the app metaphor isn't for everybody).
&gt; If I XOR bytes generated from a completely random source with a &gt; plain-text the resultant cipher-text is unbreakable. This is called a one- &gt; time pad. Yes, but that is not what he's doing. It appears he's creating a simple initial vector for the first block from the key, XOR'ing that and then doing something like CBC on later blocks. This isn't strong encryption. Knowing the algorithm, if you can crack the first block then the whole thing crumbles. 
Amen to that. The last thing the world needs is another PHP codebase.
A cracker simply needs to crack the first block, and the whole thing falls apart like a house of cards. This means an attacker needs only search a space of at most of 64 bytes, given the bizarro variable blocking this thing does. More importantly, since the hash selection is based on the key, it's probably possible to guess what it could be. Your key, regardless of how long it is, is not more than 512 bits of actual information, and probably less. I'm pretty sure with some time spent thinking I could blow a hole right through the hash function selection idea. Regardless, even if this were the most brilliant cipher ever devised, it has not been cryptanalyzed by professionals. It has not been published in a journal. It has not stood the test of thousands of the most brilliant minds in cryptography beating on it. Blowfish, IDEA, AES and other have. And they're readily available today and fast enough for 99.999% of all applications.
That was pointed in other comment. Now it should be fixed since I am using a random salt.
Since the pass-phrase is hashed the search space is the length of the hash, that depends on the actual hash used. Say it is 16 bytes (the worst case). That is 2^128 combinations to test. It might be a good idea to not use all the hashes and limit to sha256, sha384 and sha512, at least in the first block. This is not supposed to be brilliant or extra-safe. It is supposed to be simple and reasonably safe, and not dependent on external packages.
To me personally, the interesting thing is the ability to sneak Python into shops which ordinarily wouldn't use it. The same is happening with Jython and Java already -- you can write applications in Python with, say, Django, and then there are utilities which will build it all down into a dependency-less WAR file deployable the same as any other Java app. Being able to do the same in an MS shop (and I expect there will eventually be a "turn this Python web app into a DLL" option) would be a big win.
A salt does not matter. You have to provide the salt in order to decrypt it. You wrote it to the file. So I know what the salt is. There is no added benefit here. (as far as the security of a single message...) Knowing that the first block is at most 64 bytes long, and that it is XOR'ed with the key is enough for me to begin an attack. I can make one of three inferences if I want to break this algorithm: * The information is compressed with a common algorithm. Almost all of these have a common first stanza. Since I have a suspected known plaintext, I can unravel the first block pretty easily. Once I've done this, I can decrypt the rest of the file as the hash is now known to me. At the very least, I can reduce the complexity of my search by several orders of magnitude. * The text is not compressed, but is plain text. This falls in a very very narrow band. I can trivially compute what bytes can possibly fall in my band of 60 or 70 or so valid characters in my plaintext. * The plaintext is some sort of other file format, possibly binary. Again, most binary file formats have a known first block. (JPEG, GIF, PNG, MOV, AVI, MPEG, executable binaries.) If I know this, I can exploit it. In fact, unless I know absolutely nothing about the plaintext (which is unusual), I have a significant chance of being able to crack this encryption. And, further, I only need to crack the first 64 bytes (possibly less.) But I can do better. I can attempt to decrypt the first 16 bytes and use that to decrypt the next "block". If that works, then I'm done, and I've won. If not, I can attempt to crack the next 4 bytes, and so on an so forth until I figure it out. Since I can do this incrementally, 64 bytes is the worst case scenario. These are the sorts of weaknesses I can see for a casual perusal. I am not a professional cryptographer. A real cryptanalyst would surely see even better attacks.
I strongly recommend Django. I've used web2py and the two are quite different. I found the way web2py did certain things to be convoluted and contrary to how I might do them in Django. Disclaimer: I have far more experience with Django. Also, the docs for Django are great, the IRC channel is great, the templating engine is awesome, and there is a lot of momentum with the project. Suggested setup: Nginx + Apache2/mod_wsgi.
web2py is easier and better for easy ajax, django has more tutorials/3rd-party plugins/professionalism. If you like Rails, I would go with web2py. But I would really go with Rails. I've used Django for a newspaper CMS, and Rails for a more full-featured site, and it was definitely easier and faster to develop with Rails.
I'm have written a bunch of apps in web2py. I like it. I have not deployed a app engine app yet. A couple of my projects are just running the cherrypy server. It is a good framework.
for light url mapping maybe look at the new bobo http://bobo.digicool.com/
Not that I am aware, but as someone else who's also locked into epytext I'd would love to know if you found something. And if you didn't I'd be willing to help if you decided to implement something on your own. 
The salt is there to avoid revealing the passphrase by xor-ing together the first block of two different files crypted with the same passphrase, as pointed out in other comment. It doesn't matter it is included in the file since the key is a hash of the passphrase plus the salt. You are right only the first block needs to be cracked, but considering the search space is at least 2^128 I'd say it is quite safe. You can't really use information about the original data because the key is quite random (that is the purpose of the hash). See http://en.wikipedia.org/wiki/One-time_pad . It might be simpler to try to guess the pass-phrase but that is the same for any pass-phrase based cypher. Regarding following blocks, the key is a hash of the passphrase, the salt value and the data in the previous block, so the passphrase is needed. From what I've read about block cyphers this is pretty standard. This is an interesting read: http://en.wikipedia.org/wiki/Block_cipher_modes_of_operation EDIT: I think the key point of this code is that the keys for each block are quite unique and evenly spread thanks to the hashes, and cracking involves guessing the passphrase. Say the data is plain text, and the key is simple (i.e. 'hello'). The hash of the key + salt is going to be at least 16 bytes long, random looking. XOR-ing this with the first 16 bytes of plain text is safe because it is a 'one time pad'. The next block is going to use as key a hash of the first 16 bytes of data, the pass-phrase and the salt, giving another 'one-time pad'. The attack is to guess the pass-phrase. Knowing that the data is plain text means the cracker still needs to reverse the hash function to get the pass-phrase. I know many hash functions have been cracked but here I am using them to randomise the block sizes.
&gt; What makes starting in Django easier than web2py? I'm trying to get the Python version of it as much right the first time as I can. Lots of pluggable apps, very good documentation and a good community. [Many](http://www.curse.com/) [high-traffic](http://revver.com/) [sites](http://bitbucket.org/) are using Django, so getting it "right" or not is not about the framework, but about how you write it. I'd suggest to use Django if you really want to simplified the development ("get it done next week!") and don't have [NIH](http://en.wikipedia.org/wiki/Not_Invented_Here). I've found that if you do things in Django way, you will end up with a very maintainable code in surprisingly little amount of time. Then again, if you're SQL purist and thinking N+1 queries are violation of galactic law, using agnostic frameworks (e.g. [Pylons](http://pylonshq.com/), [Repoze.bfg](http://bfg.repoze.org/)) with [SQLAlchemy](http://www.sqlalchemy.org/) will give you less headache than optimizing Django SQL queries. But if you really want to run it on Google App Engine and don't want to worry about getting locked-in when your app scale beyond GAE can reasonably handle without having to rewrite the code, then [web2py](http://www.web2py.com/) is your only choice. I have few (non-serious) apps running on Google App Engine and found that its limitation (no C modules, 1MB upload limit, startup time, etc.) simply not worth it. Running it on [Linode](http://www.linode.com/) is much better in a long run. 
This is great, nice find. Theres also grok - http://grok.zope.org/
Sorry, what is MPI?
I'm not really as interested in third party plugins as much as I am with what's included to begin with. I did really like Rails, and the free things that came with it, like fairly easy AJAX and the speed of development, and that is a big reason I'm looking more at it, though Django might offer similarly easy AJAX and I just haven't seen it yet. I did consider going with Rails it self, but I'm more comfortable with Python and my only experience with Ruby at all was my time with Rails. 
It's certainly not pretty as is, so I'm probably doing the world a huge favor by throwing it out.
But the app engine is free. Just poll it from another computer to keep it loaded. I've done that before with cheap hosting. Get what's yours, man.
The web2py founder has a few screws loose in the head.
I'm not complaining about AppEngine - I'm giving him advice on how to choose a framework. Heavy frameworks like Django don't mesh well with the GAE model.
I've written an URL mapping system called Traject that might be interesting (though perhaps only inspirationally): http://pypi.python.org/pypi/traject 
&gt; Django might offer similarly easy AJAX and I just haven't seen it yet It doesn't. Generally, the Django community considers that the javascripty stuff shouldn't be included in the web framework, you do what you want (or use Django applications with an opinion on JS libs)
Are you thinking big or something basic? ps: what's up with all the downvotes?
I must disagree. Having lurked on forums for a number of frameworks for some time, I've found that the web2py community (and mdipierro in particular) are responsive, thoughtful, and polite. They exhibit a level of professionalism, both in their regard for long term maintainability, and their clearly explained, intelligent design decisions, well beyond what can be found in the communities surrounding most other web frameworks.
&gt;I asked because that SICP course used Python for its assignments I thought they used Scheme. Did this change recently?
http://en.wikipedia.org/wiki/Message_Passing_Interface
web2py is an excellent choice for 8 out of 10 of the projects I can think of on my plate. It is easier than PHP and has better practices than PHP (MVC, security). There are a couple cases when you want full control and might be doing things to break out of web2py more than you are coding into it. You also might be interfacing with an existing data model. For these cases, I think Pylons makes the most sense as you can plug in the components you need.
I leave this here, with no comment: http://code.google.com/p/web2py/source/browse/gluon/import_all.py
&gt; That's really what I'm basing my decision on is simplicity of development. Then web2py is a good choice. Unlike probably most of the people pushing Django here, I've personally used TurboGears, Pylons, Django, and very recently, web2py. Having said that though, I question whether basing your decision purely on simplicity is wise. &gt;hoping it will eventually require pretty good scalability. Scaling has much more to do with Python itself, your environment, and your database rather than which particular framework you use. But to some extent, tightly coupled frameworks are more difficult to scale than loosely coupled ones. So your "ease of development" and "easy to scale" requirements are opposing forces.
I'm pretty much starting from scratch, so I don't need to make any external parts fit in. Currently my plans don't call for anything too drastically custom that I would really need to take full control. 
 o_O
I always believe the best way to learn something is to set certain challenges for yourself, such that you are forced to learn in order to meet those challenges. For example, take a simple set of problems (like [this MIT programming course](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2008/CourseHome/index.htm)) and solve them using python. Along the way you'll be forced to learn the language.
It's too bad their accompanying source code is fairly low quality, also it appears to not actually make use of any guards to ensure the semantics of Python are maintained, further inlining works by having the programmer specify which functions to inline, not by any actual heuristics. All in all, a little disappointing.
Regarding web2py's lack of support for legacy data models - what are the challenges? * need surrogate primary keys for every table? * need surrogate primary keys named id? * ? If you've already got surrogate keys and just need to rename them from customer_id to id, that's easily done via a view. Any other serious challenges?
When I was a game developer, we had a bunch of tools written either as windows DLLs or .NET DLLs. IronPython was a nice, easy way to script our toolchain. Certainly there were other ways we could have exposed our DLLs to python, but with IronPython we pretty much got it for free.
If you are shooting to do something on Google App Engine, web2py couldn't have made it easier. You just drop the web2py directory in the google_appengine folder, change one line in the app.yaml file in the web2py folder, and then point the Google App Engine launcher at that directory and you are good to go - ready to deploy once you have your app working. I have done a few apps that way already, and have been pleased with how easy it was. 
Glad to hear it will be an easy deployment if I decide to use GAE.
&gt; Generally, the Django community considers that the javascripty stuff shouldn't be included in the web framework There's a good reason for that.
Possibly data types. The DAL hides a lot of the underlying complexity which makes for easy development, but for instance it stores booleans as char(1) and all integers are 16-bit. If you are developing from scratch, things like this probably wont affect you, but if you have a carefully laid out schema and exploit the finer points of your RDBMS I can see running into some problems.
This was explained. That file is required by the p2exe packaging method. You can use it in production to pre-load all modules in memory to make sure all requests are served as fast as possible. It checks that modules that are supposed to be there for apps to work are in effect there. If you do not include, web2py uses less memory and everything works. Can you suggest a better method to achieve the tasks above?
web2py provides URL mapping via routes.py
Absolutely true. Why else would he bother lurking around here while he is attending a Physics conference in India.
Just a piece of advice. Even if web2py provides a Database Abstraction Layer that works on both GAE and RDBS (I am not sure if any other framework can do that today), in practice the coding style is different and you use different optimizations (like JOINS and nested selects on RDMS and ListPropery on GAE). My advice is design your app to work for a RDMS (for example SQLite) and encapsulate queries into functions. When your app does what you want, modify those functions to include GAE specific optimizations. EDIT: one strength of web2py to consider is that for 3 years we never broke backward compatibility and we promise our users that we will not do so in the future. We think of this as one of the main features.
Django has been around longer therefore has more users. True. web2py has lots of free [plugguble apps too](http://www.web2py.com/appliances) and I think they are easier to plug.
[This is no longer true](http://groups.google.com/group/web2py/browse_thread/thread/5ffe30dc1912a37a) although the new feature are still undocumented. You can rename the id key and for some of the supported databases you can specify other primary keys. You can also define custom types to map web2py types into any native type. Finally we are about to release a complete rewrite of the DAL (it has been around for 2 months but we are testing it) which is backward compatible but more modular. This will make it easier to add adaptors for other RDBS and NoDBs.
Wouldn't really care as long as it could get my team off of epydoc. The 3.x release broke all of my old extensions (I built a small set of modules which checked the epydoc comments for errors that got run with our unit tests) and gave up porting as the changes actually made it harder to extend. 
True. If you want javascript with Django, you've got complete freedom to devise whatever twisted or brilliant scheme you want. Of course the flexibility comes at a bit of a price, but after you've done it once, it's no big deal the next time.
Thanks for the examples. I don't use Windows very much, so you have to forgive my ignorance.
Slide 13 is titled "Python 'Duck Typing' System". It then proceeds to show an example of monkey-patching. Wrong animal. :(
maybe let "import" work normally ? I was curious and searched all around http://www.py2exe.org/ for any kind of advice suggesting that an application should immediately load all Python modules that might possibly be used all at once - I didn't see any such advice. It guarantees a huge memory footprint and seems quite wasteful and needlessly complex. If the point is to reduce the tiny amount of overhead the first time a module is loaded, I would think that most apps would end up loading most of what they need upon startup anyway, at least a Pylons app certainly does that naturally with no bizarre hardcoding of every module name. We used to do the "load the modules you need upfront" back in the mod_perl days, since it meant your perl modules would be present in the parent and not be loaded per fork. But Python doesn't work that way in webapps, and even in the perl world you certainly didn't load *every possible module* unconditionally.
About scaling Django, this article just got out http://djangoadvent.com/1.2/scaling-django/
Damn. I forgot about the MIT online courseware. I'm going to check that out too. They seem to hit on the valid points and explain things well.
You are reading it out of of contaxt. import works normally in web2py for those modules listed in import_all. This is not executed in the users's code context. These modules are not visible to users code unless imported as you would normally do in python. This is just done so that py2exe knows which modules may be imported by user apps (using the normal import process) and bundles the source when making the web2py executable. This is necessary because the web2py executable is built before you "plugin" applications into it therefore py2exe does not know which modules the "plugged in" app may import. In particular apps may be developed and deployed in web2py without ever restarting it. web2py is the only framework to allow this therefore it may seem strange.
web2py has a trick for that. It caches all user code after bytecode compilation and keeps pinging the server to keep everything hot. This feature is disabled by default but there is a flag in gaehandler.py. 
web2py already provide an app.yaml. You just have to edit the app name in this file and run the deployment command: appcfg.py web2py If your app does use joins it will work out of the box. Caveat: you have to run your app with dev_appserver first and make sure any select in your program is executed at least once so that it creates the index.yaml file automatically. This is now web2py specific, this is true for any web framework that runs on GAE.
Look into SQLCustomType and db.define_table(...,primarykey='...)
Here is [some documentation](http://www.web2py.com/book/default/section/11/12) about scaling web2py on RDBS. there are some more specific solutions about GAE and EC2.
Of course, but there are also reasons for doing it the other way around.
If you want something scalable, try Werkzeug. http://werkzeug.pocoo.org/
He is just enthusiastic about what he does. 
web2py packages jquery and some additional js tools in the scaffolding app so that by default (so that all date/datetime fields have a popup calendar, you cannot type non-numbers in numeric fields, flash flashes, etc.). We also provide [web2py plugins](http://web2py.com/plugins) based on jQuery ones. There is no JS/jQuery code in the framework itself because there are advantages in having the serverside agnostic. Serverside it just provides API to expose functions as json/jsonrpc/xml/xmlrpc/amfrpc services to better interface various rich clients.
Great video and an excellent speaker. I love the guy at the end who clearly hasn't read Smart Questions too.
disclaimer: My main job is not to to work with web frameworks all day long. I compare these two frameworks from the perspective of person who needs to integrate interesting stuff with web with minimum hassle. I don't do customer projects. What I look from framework is extremely fast webapp development that can be used to create working demo fast and then allows enough tweaking room to make it run as in real production environment. My experiences: 1. It's insanely easy (= even easier than with Django) to begin development with web2py, IMHO it's the most "Python like" [non-minimalist](http://webpy.org/) web framework there is. If you have to bring other people to the project who are not as experienced with python and web frameworks, this is huge win. 2. Framework is well designed and simple. 3. In popularity it's behind Django, so there is fewer "[appliances](http://web2py.com/appliances)" and plugins but it seems that web2py is getting momentum behind it. 3. Support and documentation seem good, but it's not as settled as with Django. This is understandable because they are in growing phase. Thus far I have never needed to ask help online. Sometimes I have implemented stuff that was already under development. I think you should choose between Django and web2py. In my opinion web2py is conceptually better (benefit of learning from Django I quess) and solves more things directly out from the box, but Django is the current king that sets the standard of good quality framework. 
Could Django + Pinax suit your needs? Pinax is basically buch of social media oriented building blocks on top of Django. Just modify/create specific parts your site needs. http://pinaxproject.com/
A view can also recast a table column type to another type. And you could also embed your query in a view, but that is a pretty limited approach. It would be much better if you could bypass the DAL and just use native SQL when the DAL doesn't meet your needs.
If this is true, then why have Google representatives [proposed merging Unladen Swallow into Python 3](http://www.python.org/dev/peps/pep-3146/)?
Why there are already such wonderful alternatives built in?[!]
I think I am in a process of switching from the "pre-built" frameworks to Werkzeug. There is always something that's a real show-stopper for what I want to do and a part of the framework has to go. Basically adapting to the framework is painful. Although the obvious problem for is that the "pre-built" frameworks will be more secure than the one I roll.
also this:http://www.learningpython.com/2009/02/23/iterators-iterables-and-generators-oh-my/
Thanks! I'd thought about getting this to go through with my teenage son and $10 sealed the deal.
Learning Python, 4th Edition $20.50 Immediate Download $9.99 Shipping Charges $0.00
Is this a better learning resource than Dive Into Python or Think Python?
It works! No, I won't email it to you.
Why post this in /r/python? It would be more useful for the folks over in /r/ruby. ;-) I kid... I kid...
Is this down to the [harsh Slashdot comments](http://books.slashdot.org/comments.pl?sid=1558922&amp;cid=31236018)?
this one is *very* comprehensive (1216 pages !!!)
Don't worry, you are not stealing anything.
A while ago. http://danweinreb.org/blog/why-did-mit-switch-from-scheme-to-python
I'm getting this on the UK cart *Promotional code is not valid. Please check your code and try again. * and this on the US cart *We're sorry, but your promotional code was invalid.* Did the code expire already?
O'Reilly, I'd buy a lot more of your books if they were ten bucks.
I don't know why anyone would pay for a Python textbook at all. There are plenty of free ones ([Dive into Python](http://diveintopython.org/), [A Byte of Python](http://www.ibiblio.org/swaroopch/byteofpython/read/), [How to Think Like a Computer Scientist](http://openbookproject.net//thinkCSpy/), [Thinking in Python](http://www.mindview.net/Books/TIPython), etc) and the Python docs are very good just by themselves -- I taught myself Python just from the official docs and tutorial and now I get paid to teach and code in Python (among other languages).
I'm really liking pfaide a bit better in terms of design when it comes to upcoming IDEs, this one really has that same 1990s toolbar look, and while functional, really tires my eyes after working with the pfaide ribbon. Although feature-wise, it looks amazing ;)
Cool. This is how I learned both Python and how to program.
I bought it for the same reason.
Considering how much their Java IDE excels, I'm confident their Python one will as well. Their code "awareness" in Java is second to none. I'm really hoping they bring that to Python since most of the IDE's I've tried so far haven't been very good at reliably determining an object's type and offering code-completion/inspection/error-highlighting from that.
From my tests, there's potential but they're not anywhere near done yet. Inspectors report many false positives, the refactorings are lacking (far behind Rope) and the IDE in general is nowhere near as smart as the Java version.
Yes, it is expired now I'm afraid. Should have mentioned there were only six hours left on the deal when I posted it
This is exciting news! I spent the entire day yesterday getting eclipse/pydev set up, and I'm still horribly underwhelmed by it's functionality. I'd be happy to blow money on a decent IDE, but nothing I've tried has been any good at all. I still use Notepad++ for 90% of my python work. thantik mentioned pfaide, and that looks excitingly awesome as well. I've been looking for python IDE's for ages and never heard of these. Are there any other hidden gems out there?
I'm trying to learn it and man I sure could use the book. Web2py is great and deserves more attention... or maybe this is the result of a massive web2py revolution?? I hope its back up soon.
i think they host the site on a toaster running freebsd.
well, how else will they get the masses to buy a copy of the book? notice it is not included with the offline documentation :) im just sayin..
well thats what I call scalability
as of this post, the web2py.com site is back up.
Cause it's built on web2py ?
mdipierro (one of the /r/Python moderators) is the web2py guy... ask him.
isn't it [webpy.org](http://webpy.org)?
nah, that's something else bro
s/free/net/
ding ding ding ! [Retracted](http://www.reddit.com/r/Python/comments/b792t/why_is_web2pycom_often_down/c0ldpe2)
He never replies 
&gt; I just don't see why one would want to use a cross-platform language on a single platform. Because cross-platformness is not the only feature of Python. &gt; But to each their own I guess Yes. That's why. Because different people have different requirements. 
I was planning on giving it a go but it died as I was looking at it. I think I'll be taking a look at Pylons instead.
This smells like a troll.
I was really digging the metaprogramming talk. I was totally watching it on [video](http://blip.tv/file/3261354), though! Same with "maximizing your program's laziness," though I didn't really get too far into that one.
Yeah because he is down.
This trick avoids the extra step to `strip` whitespace on split strings.
That's web.py, not web2py.
They need to upgrade to the four slot model.
Looks like the slides are missing the graphs of ping times (p11 of the PDF) Talk was very interesting, thanks
cosign
:(
In software, we use the word "bug" to describe problems. We write the ones down we find, so we know the quality of things. You should search for "foo bugs" and you'll find a whole slew of known problems for program 'foo'. I hope that helps.
You might want to try [Stack Overflow](http://stackoverflow.com) for this.
Thanks
http://pypi.python.org/pypi/unittest2/ for getting the shiny new bits now!
django
u cant go wrong with pylons my friend.
&gt;u cant go wrong with pylons my friend. Does the use of pylons make a programmer unable to spell "you" or "can't"? If so then I would advise steering clear of that particular module.
So does your mom, but we're not about to post that on reddit.
Congratulations, you win king of the internet for the next hour!
I found Apress' book Beginning Python From Novice to Beginner 2nd Edition was a much better book for learning Python, but this book is also quite good. 
I would advise steering clear of sticks, but you clearly already have one up your ass.
http://docs.python.org/library/struct ...15x skips 15 bytes; 6l returns 6 long's (integer python type). Whitespace is ignored. It's all in the docs under the format section. Heck x is the first one in the table.
It's probably related more to the way it is deployed than to the framework itself.
ohhh stupid monospace! I thought the last was 61 not 6l :P many thanks :D
It suffered a DoS attack which resulted in multiple sysadmins having no toast with their morning coffee. 
This doesn't really make sense, but I still upvoted you.
I don't know why, but this made me instantly think of materia.
I wonder if NumPy/SciPy/Matplotlib work?
If he has a stick up his ass, he could probably steer himself with it.
Interesting follow up [blog post](http://www.dabeaz.com/blog/2010/02/revisiting-thread-priorities-and-new.html) on the priority idea
This is all I can say. I have been traveling in the past 48 hours and I did not have access to the server. I checked it now. It is up. According to the log it was never down but it received no requests in between 6am-12pm on Saturday. My guess is that the hosting provider had some issues during that time. If this happens again I will move to a different hosting server.
Why, Python? Why do you have to keep getting awesomer? Now I'll have to consider switching over from [nose](http://somethingaboutorange.com/mrl/projects/nose/0.11.1/).
You wish! According to [the logs](http://web2py.googlegroups.com/web/network_graph.png?gda=WuydGkMAAAAmC7xtA4lvu0QW3LAH6EdjAgcGjqEzk0PVzzxxPcGC5w5iDS_GwVWihe8aeuSUKVsytiJ-HdGYYcPi_09pl8N7FWLveOaWjzbYnpnkpmxcWg) the server was never down but it received no requests in between 6am-12pm on Saturday. My guess is that the hosting provider had some issues during that time or perhaps it was a dns problem. If this happens again I will move to a different hosting provider.
The server is apache+mod_wsgi. Until February we run on Virtual Machine at the DePaul without trouble. Then we moved to EC2. That worked fine but too expensive. Then we moved to VPS.net. The OS is ubuntu. We may move again. 
Spawning and Tornado are evented servers based on non-blocking IO loops. I don't know much more than that as I've never used either. That said, gunicorn is a simple blocking pre-fork server architecture designed to handle only fast clients. Basically that means that its designed to have something like nginx sit in front of it and buffer slow clients. This way gunicorn can remain extremely simple in implementation and still perform extremely well. Reading the entire implementation shouldn't take more than a couple hours assuming some familiarity with the Posix API. Other benefits are that your app code doesn't have to worry about concurrency control and should generally be easier to reason about.
What about Google Groups? They even have it [available for google apps](http://googleblog.blogspot.com/2009/12/join-this-group-google-groups-joins.html), so you could use your own domain.
&gt; Today, we're happy to announce the launch of Google Groups to Google Apps Premier and Education Edition users. You have to pay for that service unless it's for an educational organization.
Zed Shaw has an awesome hosted mailing list site called http://librelist.com/ It's using the backend he wrote called [lamson](http://lamsonproject.org).
Change `gcd(b, a%b)` to `return gcd(b, a%b)`. `return` won't break out of the entire chain of recursive calls, it just returns the value to the previous step in the chain. Since that function isn't returning anything, the value is discarded.
Only if you want to use it on your own domain. You might also be able to talk them into considering some open-source projects as educational, which are probably the biggest uses of mailing lists 
thanks
I've been using Site5 for about a half dozen lists. It's $5-$10 a month depending on the plan you get, and you get unlimited Mailman mailing lists. It's been reliable - only one real outage lasting about a day in the past two years. If you're also planning on hosting some domains, this would be a fairly cheap way to go. I'm sure that DreamHost and other hosting companies offer similar services. I can't give my personal experience with those, though.
Awesome. Totally useless but awesome.
dude. stackoverflow.com for such questions next time man.
Are you sure? Is it that bad?
Google is [very picky](http://www.google.com/support/a/bin/answer.py?hl=en&amp;answer=72223) about who it gives Education Edition status to. If you're not a school, you need to be a 501(c)(3) organization, and that's a ton of overhead--way more than most open source projects can tolerate. 
Not totally out of the realm of possibility, however, I don't want everyone to have to go create yet another account just for the mailing list. That's why I like the Mailman system. The last time I used Google Groups (admittedly, it's been a while), you couldn't just add an email address, you had to have a google account. Plus, while this isn't anything specifically "top secret", it's not public either.
I've had a look. Do they have a mailman specific hosting plan or is it a general web hosting plan that supports mailman?
You can create private groups, and people can use non-gmail addresses.
If you can spend $10 a month, why not just get a VPS somewhere and install Mailman on it?
thanks for the link. I just figured reddit would be where some of the smartest programmers tend to
General web hosting. It's unlimited bandwidth unlimited storage with unlimited mailing list hosting. 
ROFL you should read the whole thread
So I actually just went and checked this out. Not bad. This might solve my problem. It's got the mailman-like features I'm looking for and, for all intents, it should be transparent to my end users. I don't mind paying the $50/year for Google Apps Premium. It's well worth the cost to *not* have the headache of administering a mail server and this will make having email address on this domain much easier. Why the hell didn't I think of this sooner? I guess it takes the collective Reddit wisdom to set me straight.
Those eyes!
Because they know there is no way in hell it would get merged into Python 2.
I find pycassa more intuitive to how I understand the Data Model of Cassandra, but digg.com uses Lazyboy, so it's proven. Looks like Eric Florenzano just updated Twissandra with pycassa: http://github.com/ericflo/twissandra
An easy argument to make: Lots of external libraries, particularly scientific ones, depend on at least Python 2.5 by now. This also happens to be an argument against Python 3, which you mentioned in your title. Lots of stuff can be backported to Python 2.3, after all, but almost nothing has been ported to Python 3 yet.
Thanks, that's a good point. The assignments they've given in my classes have been very sophisticated, so SciPy would be dead sexy. I guess I'm trying to adopt Python 3 in my work as a matter of principle to break out of the the chicken and egg paradox of waiting to use it until the libraries are made by developers waiting on users.
troll
Is anyone else having trouble seeing some pycon videos? For example http://pycon.blip.tv/file/3263942/
About a year ago, I did a project for some classes that [designed four-bar linkages](http://github.com/jesusabdullah/super-four-bar-explorer). Pretty much ever since, I've been kinda meaning to come up with a good way to specify mechanical linkages* in general and then solve for positions, paths, degrees of freedom, etc. using a similar technique combined with analytical solutions based on ideal bases (which I don't know the first thing about, but let's not worry about that!) ...anyways. Just been busy with life is all. And shopping.
I like controls. I only had an introductory course in it, though, so I'm not too hip on bode plots and the like. You may enjoy http://www.youtube.com/watch?v=o0mho63pJDA, which is from a project where I simulated a mass/spring system, with the mass dragging on a friction belt and a forcing function Asin(wt) . The vertical axis is velocity, while the horizontal axis is position. In the video, I show what happens to the mass for different frequencies for w---the cool thing is that, for certain frequencies, CHAOS results. Cool!
Ponies are pretty but goatse gets the job done.
ponies have more pulling power, but goats scale hills better
The spice must flow!
Encouraging authors to write tests is not completely useless - not sure about the "Failure" and "Error" achievements though. Must fail tests, need "Epic Fail" achievement.
We're at least using 2.6 at my uni :) But screw Python 3. The wealth of libraries is a big part of what makes Python awesome to develop with. Why would you give that up for some relatively minor language improvements? Especially when Python 2.6 is such a nice language anyway.
I used to work at a company that kept 1.5.3 around for comparability reasons. For some reason a lot of their scripts only worked on that version. It's common to see 2.3 and 2.4 still around especially if used in production flow. If it still works, no one wants to change (update) it.
Thanks for reply. Someone suggested to ask you in private but I thought others would want a reply too, since after the book came online I see a lot of interest from many like me. I said "often" in my question because in 2 other occasions in recent past the book was almost unusable due to slow traffic. The problem was lasting for 1-2 hours and then it was getting normal again.
suggestion #1: Go ahead and spend some time with either of them; much more productive than this post.
Been so here at work when I startet. We're at Python 2.4 now and it's great. In fact, Python 2.4 is so great that I even had to re-implement the min() and max() builtins to properly work with Decimal() instances! :)
Maybe overkill, but WebFaction will provides mailing lists as well.
Expecter Gadget? I have no idea what that lib does, but I'm going to use it.
Maybe you can install a more recent version in your home directory?
We are still running on very limited resources (one server and only 256MB Ram). Ram is the main issue since book chapters get cached in Ram. I have been busy traveling but I hope to be able to increase the ram this week or the next. Meanwhile I have changed some settings that should speed things up a little. Sorry about that.
LOL
LOL Bravo! I take back anything negative I ever said about you
&gt; **Heisenbug** &gt; Make a passing suite fail without changing anything. Oh my.
&lt;mdipierro offers miles_g a smoke peace pipe&gt;
Python 3 is definitely still transitioning in, but the improvements are not what I would call minor. Especially now that Unladen Swallow has gotten the go-ahead from Guido to merge with python 3. Python 3 has some great features. Library support is not there yet, but it's ramping up. Django has a transitional roadmap. There's a python 3 driver for postgresql in the works. Right now the best course of action is either to write in python 2, and aim for python 3 compatibility by testing with the python -3 switch, so you can run it through 2to3.py, or code in python 3, and backport to 2 using 3to2.py. 
API-wise, both look like they are pretty much basic wrappers around the Cassandra Thrift bindings. I'd prefer lazyboy over pycassa though, given that firstly, it's being used in production right now at Digg, and because it looks like lazyboy's connection code is more featured than pycassa.
They make you feel better about your failure. :)
FYI you want Python 2.6 not 3.x, else NumPy (hence SciPy, Matplotlib, etc.) won't work.
And they never will be. Statically typed languages are much easier to write this kind of thing for. Python and Ruby are too dynamic to do the sort of stuff Resharper and IntelliJ does.
So how is this used in a hosting environment? I know i can use it in EC2, but it's for testing purposes only.
&gt; And they never will be. Won't be as smart as Java IDEs (if only because money goes into Java IDEs in order to replace Java monkeys), but Smalltalk's environment (the first refactoring IDEs, among other things) proved that you can get quite a damn lot done even in a dynamically typed language. &gt; are too dynamic to do the sort of stuff Resharper and IntelliJ does. Not quite.
Maybe he actually wants 3.x, because I think the thread title specifically asks about 3.x...
&gt; What are the best reasons I can give in support of their upgrading to **any** later Python version? Sounds like he was open to anything more recent than 2.3. 
What about Psyco? Is it completely dead now?
oops, my bad. Thanks.
Psyco isn't totally dead, Christian Tismer has been doing some work to update it, but it's a dead end in terms of keeping up. One of the PyPy lead devs is Armin Rigo, who's also the author of Psyco. One of the big motivations of PyPy is to be more flexible and maintainable than Psyco.
*all* python packages need a MANIFEST.in when setup.py doesn't explicitely covers all files to be included in a source dist. If you use the setuptools automation (it grabs the list out of the .svn, etc.) you depend on the versioning system (which is bad if you change your VCS at some point) and you can include files by mistale, you didn't want to see included in the first place in your release, just because they are in your repo.. -- Explicit is better than implicit 
The best course of action right now is to follow the migration plan laid out for the python community in general, and make your code work for both 2.X and 3.X. Keep your code clean, and check that it translates with the 2to3 utility. 
I'm not saying they can't get some decent refactorings. But how would you expect an IDE to handle the method popup for a class variable whose type cannot be inferred at compile time? Things like that.
 list =['a', 'b'] x = 'a' list.remove(x) list ['b']
works for me, there is something else wrong with your code. &gt;&gt;&gt; x = ['c','a','t'] &gt;&gt;&gt; x.remove('a') &gt;&gt;&gt; x ['c', 't'] &gt;&gt;&gt; a = 'a' &gt;&gt;&gt; x = ['c','a','t'] &gt;&gt;&gt; x.remove(a) &gt;&gt;&gt; x ['c', 't'] &gt;&gt;&gt; 
Well thing is, in most cases the class variable and its type can be inferred statically. In some cases it can't and it's generally more work than doing it with a statically typed language but it can be done.
here's one of those "teach you to fish" moments: [StackOverflow](http://www.stackoverflow.com)
The lazy talk is up now, http://pycon.blip.tv/file/3259746/.
&gt; It turns out the much-maligned "plus" method of string concatenation is actually the fastest by a pretty wide margin. Has it been improved considerably since the Python idioms were determined or am I just doing something wrong? It in fact has been improved considerably. Also, for a small enough set obviously + will be faster; `a` is always faster than `''.join([a])` (just to give the degenerate case where it is obvious); the tests he gives are only for very small lists.
Yeah actually i didn't realize that x was a list for me of one element and not x[0]. Thanx a lot!
Thank you!
Thank to you!
I couldn't view that one either. There is a comment below the video that says it's not working. Maybe they will fix it :(.
Isn't 'tcp' pretty important?
Does anyone know how much RPython is sped up? I wouldn't mind writing my code in RPython (the restrictions aren't **that** huge) if it meant 50-100x speedups...
rpython can be as quick as C. But believe me, you don't want to code in rpython, because the tools are not designed to be user-friendly. The usual way we deal we rpython errors is to dig up 10-20 levels inside pdb after an exception has been raised inside the translation toolchain. C++ template errors looks straightforward in comparison :-)
By RPython errors you mean compilation errors? Because, since RPython is a subset of Python, I imagine you could just run your program in Python to verify accuracy and then compile it. Also, can RPython make modules? I've used shedskin recently and it was great, the speedups were huge and compilation was straightforward.
It's called a ping. No productive person would sit on reddit and wait for a response. Why not help someone make an educated decision instead of trolling?
Thank you for pointing this out. The connection code seems to be much more suited for use in production (use of auto pooling, auto load balancing, integrated failover/retry, etc.)
You can verify the correctness of your code by running rpython on cpython, but the translator can be very finicky and you have to restart translation everytime you find and fix an error. And no, no modules at the moment.
RPython is a subset of python in the sense that every rpython program yields the same results when compiled by PyPy or executed by CPython. But you can't take an arbitrary python program and compile as it were rpython.
Well yes, that's what subset means :P So which errors are hard to debug? Compilation or runtime?
Oh hmm, I see... It should be a fantastic tool for speeding up Python when it's more mature, though. Thanks!
I may be missing the point here but this seems very verbose to me. In web2py you do (complete code): # controller default.py questions = ['how old are you?', 'married?', 'with children?'] def index(): match_password = IS_EXPR('value=='+repr(request.vars.password),error_message='no match!') form = SQLFORM.factory(Field('username', requires=IS_NOT_EMPTY()), Field('password','password', requires=CRYPT()), Field('password_confirm', 'password', requires=match_password), *[Field('q'+str(i), label=q) for i,q in enumerate(questions)]) if form.accepts(request.post_vars, session): session.answers = form.vars redirect('thanks') return dict(form = form) # view default/index.html {{extend 'layout.html'}} &lt;h1&gt;Registration form&lt;/h1&gt; {{=form}} The form also displays errors if submission does not pass validation, implements a locking mechanism to avoid accidental double form submission, and hashes the password before passing it to the app. It automatically makes a js calendar popup for date/datetime fields, clientside pre-validation of numeric fields, dropdown boxes for reference fields. (I am trying to compare apples with apples but in web2py it would be easier to [customize Auth](http://web2py.com/examples/default/tools#authentication) and use the [built-in registration form](http://web2py.com/welcome/default/user/register) which supports recaptcha and multiple authentication methods: ldap, pam, gmail, twitter, facebook, rpx, etc.)
We don't ever intend for it to be used for that. It's meant for writing interpreters in only. The JIT is for pure python speed.
Aw :/
ah sorry, forgot to answer that part of the question :-). Compilation time errors are hard to debug. For the runtime errors, you can (you are even supposed to) run the program under cpython, and compile it only when it's "correct", as you suggested
our motto is: "we write rpython so that you don't have to" :-)
There's no way PyPy will speed up my code 60x though, is there? Shedskin did do that for me, and I wouldn't mind doing a bit more work to provide the compiler/interpreter/JIT with tips to help it give me those massive speedups...
Simple. Python 2.3 doesn’t have decorators or generator expressions. Those are a pretty important and basic features.
Hmm yes, that would make it hard for people to write in RPython... Thanks for the info!
You probably want Cython. It compiles (true) python to C using the Python API quite generally. You can then add type-declarations in time-critical sections to get massive speedups (by by-passing the Python API).
well, no. Shedskin did not speed up your code, but it speeded up the code you wrote explicitly for it and happens to be syntactically similar to Python. It's a bit like saying that gcc can speed up java :-) Btw, I have an example of pure algorithmic code that is speeded up 57x by pypy-c-jit. But I agree that for most code you currently don't get such speedups
I've tried that, it takes quite a bit of time to write the correct types and then it's not as fast as pure C. Shedskin infers types on its own and converts the whole program to C++ (but you can't access the entire stdlib). It depends on your use case, I guess, but both are good alternatives.
No, not really, it sped up my exact Python code, I didn't have to make any changes. I don't expect such increases for, say, I/O bound code, but for pure algorithmic code they should be possible (and it's amazing that PyPy gets them). I haven't played with it recently, how stable is it? Can I download a binary and play around, or do I need to compile it (I remember compilation taking a while). Is it in a mature state?
no binary, sorry. You have to compile it by yourself, and yes, the compilation takes a while (30min-1h depending on your cpu). We are currently in "release mode", the plan is to release 1.2 in march. PyPy is supposed to be stable, but not all the programs are speeded up by the JIT
I might actually try it, it sounds very interesting. What's "release mode"? When is the point where PyPy becomes available for use in production and enters the software repositories and other channels? Thanks for the info!
in "release mode", we stop adding new features and concentrate on finding and fixing bugs. No clue for the repositories, but in theory 1.2 could be already used in production, as long as it fits your needs. The problem is just that not many needs are fit by pypy currently :-)
Ah, I see, thank you!
So basically we should go back to building forms by hand? Like in the 90s? I much rather stick with declarative form definition, thanks.
Yeah, definitely think about Cython for speed ups on the CPython interpreter. It can gets some massive improvements. However, it does add a compilation step and an extra dependency (Cython compiler), so it's not suitable for every project.
HAVE NOT WATCHED A SINGLE DJANGO TALK :P lots of good ones this year... [the gil talk](http://blip.tv/file/3254256)... my take away was, there is hope [meta programming](http://blip.tv/file/3261354) so many interesting ideas in this one. I tend to shy away from meta programming stuff, but it seemed like throughout this talk I kept going "oooh I want to try that" or "ooh that looks handy" [designing to scale:shootq](http://blip.tv/file/3261344) always interested in how people get things to scale... [what every developer should know about databases](http://blip.tv/file/3261223) ... everything I've come to understand over the past 5 years boiled down concisely into this talk. very well done [scaling reddit](http://blip.tv/file/3257303) also very interesting for a variety of reasons. [the speed of pypy](http://blip.tv/file/3259650) i wish i was at least a 10th as smart as these dudes. [interfaces, adapters and factories](http://blip.tv/file/3258221) probably the BEST explanation of adapters and indirectly (zope.interface and why it might be useful) I have seen yet. much enjoyed. [pynie](http://blip.tv/file/3263792) this was surprisingly interesting to me for a number of reasons. #1 some good information on parrot and how one might go about writing a language for it. for one 
Write tests.
If you've got a suite of 1000 tests, all failing, and you *don't* have a canary amongst them, you've done something spectacular. Now if one of them is a canary that tests the environment, then yeah, it's not as fun.
This ranges from saying blatantly obvious things through being not so useful to just plain getting it wrong. There's nothing really enlightening here. &gt;Proximity is often used in graphical design, if text is grouped together we assume it is related. Be sure to use this. Here is an example of good use of proximity. And then they show a blatant DRY violation. :( &gt;You can avoid writing big, multiple lines logical expressions by using boolean variables. Be sure to give descriptive names to those variables. Doesn't help much when your "descriptive" name is about as long as the portion of the expression it replaces. Although it's often a good idea to name these things anyway (or even extract the calculations into functions). &gt;You should always put more common (or normal) cases first, and less common cases and exceptions later. Unless of course you're writing in guard-clause style. Not to mention that the **real** problem with their "bad example" is the needless double-negative logic. &gt;your code will even be optimized better since python will have to check uncommon cases less often. Um, the conditional is evaluated either way. I think they've gotten confused with advice about how to order the parts of a binary condition for an if to take advantage of short-circuit evaluation.
Tips on good python coding style should be [PEP 8](http://www.python.org/dev/peps/pep-0008/) compliant IMHO. This unfortunately isn't.
Just a few questions, how does PyPy JIT works ? It does some optimization before or some instrumentation while running like LLVM ? It's a new JIT from the zero or are you guys using some part of LLVM ? What platforms is it supporting right now ? Congratulations on your work !
Based on the headline, I was going to write this off as sensationalist crap. Then I saw it was Ian Bicking's blog. I still see it as sensationalist crap, but now I wonder if it's because I'm missing something? What does form validation have to do with "throwing out your frameworks?"
Can we please avoid posting this stuff, it's clear from the mail (which doesn't even have any replies) that this is only an idea. In the meantime, mere mention of "unladen swallow" on Reddit results in front page spam for me. Post the release notes, not every last microdecision on the road to a release. :)
&gt; However, it does add a compilation step and an extra dependency (Cython compiler), so it's not suitable for every project. So how is RPython not an extra dependency?
The PyPy JIT is fairly complex. Basically a normal interpretter is written, and then a tracing JIT is generated and applied to the interprtetter. The JIT generator is built from the ground up and doesn't use anything like LLVM. Right now it works on X86 only (the VM itself runs on basically anything), but the backends are nice and pluggable so someone should be able to write one for x86-64, etc.
I don't know what you are doing with this: `IS_EXPR('value=='+repr(request.vars.password),error_message='no match!')` but it scares me. Use of repr() like this makes me think there's an eval somewhere in there. If so, I don't believe that's acceptable, even if it is justifiably safe in this context. I personally find dissecting the output of that form and figuring out how to affect it to be unnecessary; the HTML is relatively verbose but it's a canonical representation where declarative definitions are derivative of the real requirements (because the real requirements of a form are ultimately UI).
Do I detect a hint of desperation? This project is long, slow, and hard, they'd be forgiven...
Perhaps you like it better this way: def index(): def match_password(form): if form.vars.password!=form.vars.password_confirm: form.errors.password_confirm = 'no match!' form = SQLFORM.factory(Field('username', requires=IS_NOT_EMPTY()), Field('password','password', requires=CRYPT()), Field('password_confirm', 'password', requires=CRYPT()), *[Field('q'+str(i), label=q) for i,q in enumerate(questions)]) if form.accepts(request.post_vars, session,onvalidation=match_password): session.answers = form.vars redirect('thanks') return dict(form = form) 
Oh my goodness. I figured it out as soon as I posted this. Code makes me feel stupid because it was so simple. I ended up using s = input("Type your social security number \n") for c in s: print(c, ':', int(c)*c) However, thank you so much for your reply nonetheless. I was at my wit's end. :) Thanks
This sorta look like what you have. Why did you use %? What's the purpose of that? I'm new to python.
It's used for [string interpolation](http://docs.python.org/library/stdtypes.html#string-formatting-operations). The values to the right of the `%` get substituted into the string on the left.
No, it's not just an idea, it's already landed: http://code.google.com/p/unladen-swallow/source/detail?r=1110. However, it's still not a extension module in the way psyco is.
`length()` method?
I was referring to packaging it as a module, not the project itself.
% string interpolation is sort of old fashioned nowadays though. The future is `"{0}: {1}".format(i, i * int(i))`. Works in Python 2.6+. Based on yiz426 writing `input()` and `print()`, s/he’s using Python 3.x, so `.format` is more appropriate. 
Reddit is not a homework help group. Talk to us if you want to do something outside of class.
Thanks for the typo report. Fixed.
This looks interesting. However, it's not clear from the docs if the signal receivers execute synchronously and, if so, what happens if they block. If the receivers execute asynchronously, it's not clear how the dispatch loop operates and on what thread (there's no reference to a "mainloop").
No, PyPy as a fast Python implementation has been a long time coming, but its scope is **far** beyond that, just look at proxy objects, the thunk object space, and PyPy's extensive features for developing dynamic language interpreters, like nearly free jit-ing. Of course this ignores PyPy's ability to translate to platforms *other* than C, such as .NET or the jvm (I believe currently those are the *only* back-ends still alive).
I'm taking a python class in order to learn. I'm for once taking a class that I enjoy and want to learn something from as oppose to just going to class everyday. What's preventing me from using all tools from various sources. This does not mean I get a homework assignment and go straight to reddit. I value reddit for what it is. (And I ended up figuring it out on my own which I am quite proud of.) However, I do not think you should berate me for going to reddit for help.
All these questions are based out of curiosity since the assignment has already been completed. Concerning the last part: int(c)*c or in your case i*int(i) How does that make sense? The output is what I want it to be but why does it work? Does it work because it's the nature of python of having a string multiplied by an integer? Logically speaking, how can a character multiplied by a number? Why does it not turn out to be say 3*3 end up as 9 as opposed to 3*3 ending up as 333? I'm not sure if I'm phrasing this correctly.
An extra dependency compared to just regular Python code. ;)
Non-en submission with intrusive voice flash ads? No, thanks.
In what way does it differ?
1. Writing idiomatic Python may be hard if you're new. Lazy evaluation needs more highlight. 2. Some stuff fits generators, some does not. Stream processing does, sudoku board processing does not. Also nesting generators may not be the best solution there is. 3. Forking generators may be non-trivial, but you can always use `itertools.tee` or create an iterable class and move its instance state around when needed. Doable and hardly difficult.
His example is way more verbose and less maintainable than it would be using django's "by the book" implementation, AND he says that we should be doing this in preparation for HTML5... which frankly, i don't think is going to be ubiquitous for 10 years.
Nothing to read here
x86 is not the only backend supported by the JIT: there is also the CLI JIT backend, which emits .NET bytecode at runtime instead of x86 assembler, although currently it works only in a branch but not in trunk
Where do you specify your form's design? Where do error messages go, for example?
That's too bad. I'm quite sure RPython would make a fine language for some projects if some efforts were directed at creating decent programming tools for it. I for one would definitely use it.
If they block the calling thread will block. No magic involved.
That depends on what sort of application you're writing. For example, if you're serving up static files over HTTP, once you get past the header, your bottleneck is purely a matter of TCP and I/O throughput. On the other hand, if you're just serving up static content over HTTP, use nginx and/or throw a cache in front of your application; in many other cases, it's the protocol or application code that is the bottleneck, not the "put some bytes in a socket" code. Heck, if you're just serving a file off disk, you can call sendfile() and cut your code almost completely out of the loop, since all the work is happening in the kernel. That's not to say that 'tcp' is completely unimportant, but it's probably not that interesting to most folks.
So then it would be better to run Django (for example) on PyPy?
web2py provides many levels of customization. When you specify the field types `Field('name','type')`, web2py picks a default widget for the field or you can pick a widget explicitly: Field('name','type',widget=....) When you display the form with {{=form}} You get a table containing label1, widget1, extra stuff... label2, widget2, extra stuff... ... each widget is responsible for displaying its own errors. If you do not like this arrangement you can arrange the individual widgets. For example: {{=form.custom.begin}} &lt;ul&gt; &lt;li&gt;{{form.labels.username}}:{{=form.cutsom.widget.username}}&lt;/li&gt; ... &lt;/ul&gt; {{=form.custom.submit}} {{=form.custom.end}} Each widget is still responsible of displaying its own errors but this can be disabled. If this is not enough you can also replace any widget with html as long as the TAG name attribute is the same as the field name (and the class should be the field type for pre-validation): {{=form.custom.widget.username}} with &lt;input name="username"/&gt; All default widgets are CSS friendly and have some JS pre-validation. We have widgets for ajax auto-completion and extensible select/options.
Can someone explain real-world application for signal dispatch, or link to a good, simple article?
I know. It's amazing, it was amazing before anyone had ever heard of Unladen Swallow... But thats my point, Unladen Swallow is now planned for merge into Python 3 and their devs are paid. The PyPy devs have had funding at points but in comparison to Unladen their work has had little recognition (that I can see), and is far from over. The blog post in the OP is a rather incomplete benchmark, and a suggestion that you contact them if you're looking for a specialist...
See the reference manual: http://docs.python.org/dev/reference/expressions.html#binary-arithmetic-operations . """ The * (multiplication) operator yields the product of its arguments. The arguments must either both be numbers, or one argument must be an integer (plain or long) and the other must be a sequence. In the former case, the numbers are converted to a common type and then multiplied together. In the latter case, sequence repetition is performed; a negative repetition factor yields an empty sequence. """
True!
No, No, Trickos does bring up a valid point. 3 short paragraphs with little context. Actually, it is 2 paragraphs if you remove the first one which boils down to "Hey, did I mention I am awesome because I use Haskell?". This blog post, dare I say.... *generates* little interest?? Ezyang, I would like to see you flesh this out more into something substantial. It is interesting, but your blog post left me wanting more details. [Here is a song for you guys to listen to instead](http://www.youtube.com/watch?v=erb4n8PW2qw)
It installs a specific struct, automatically at runtime, that the VM knows to look for. This struct contains a series of function pointers to various JIT functions that are rather specialized to unladen swallow. by comparison psyco actually replaces the function pointer to the VM loop with it's own implementation.
Do you know other (programming) languages, or is Python your first?
It would be worth benchmarking, at least, assuming Django will run on PyPy.
["Dive into Python"](http://diveintopython.org/) is the suggestion that gets thrown about a lot.
I already knew a few languages before but I found this book to be pretty darn good. http://www.amazon.com/Python-Programming-Absolute-Beginner-3rd/dp/1435455002/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1267542178&amp;sr=8-1
I took a year long AP class in High School on Java. I know it but am not a master of it. The idea of coding in Java never really excited me. And I plan on majoring in Comp Sci next year so I want to get a head start soI am want to learn and code in Python. edit: also it has been about 6 months since i have actually seen java so a little refresher on object oriented ideas could never hurt.
Should I start with Dive into Python or Dive into Dive into Python 3?
Do you want to learn, or do you want to write production code? Python 3 is cleaner and nicer (and it's where progress happens in the stdlib), but most third-party libraries haven't been ported there yet, so if you're trying to do big stuff (websites, GUIs, ...) it's not very usable. Python 2 has all the libraries you might want for anything you might want, but it has more rough corners and ugly things. Also, I'd suggest starting with the official Python Tutorial (on the Python doc site) and only then reading Dive.
http://inventwithpython.com/chapters/ 
After becoming proficient with Java from [Head First Java](http://oreilly.com/catalog/9780596009205/), I learned Python from [Learning Python](http://oreilly.com/catalog/9780596158071) and had a blast. There are probably better ways, but this worked for me.
I run into this problem quite often. I forget whether some function requires a sequence or any iterable.. and I pass in a generator and get an exception. I remember reading somewhere that part of the migration to 3.0 includes modifying std lib modules to be more iterable friendly...
If all your tests are passing all the time, it's either because 1) your code is perfect or 2) your tests suck. I would assume, in many cases, it's 2 and a "Failure" or "Error" achievements might encourage authors to write more critical tests.. 
Right. I haven't thought about the implementation of critical tests, but rather imagined someone *intentionally* breaking tests. Have a nice day and test away!
1) Download python 2.6 from http://python.org/ 2) Run python.exe 3) Type print 'Hello, World!' 4) Press [Enter]
To be honest, I agree with the testing evangelists but am naturally lazy, so anything that encourages me to document and test is a good thing. Maybe we need a similar achievements for documentation!
Good idea!
5) [learn how to google for](http://tinyurl.com/yjguw2p) [questions](http://wiki.python.org/moin/BeginnersGuide) [that](http://www.learningpython.com/) [have](http://python.about.com/) [been](http://pythonlearn.com/) [asked](http://diveintopython.org/) [a million](http://www.youtube.com/watch?v=QHTx7QhXxCU) [times](http://en.wikipedia.org/wiki/Multiplication) [before](http://stackoverflow.com/questions/1969159/my-path-to-learn-python-django)
I'd propose to start with simple projects in Django. I know many people who start learning Python because they want to use Django. Some other reasons in favour of this decision: 1. Quick and good feedback. You will start to create useful (or at least interesting) things quickly. 2. Great documentation and examples 3. Good python style and programming idioms. Guido van Rossum (Python creator) [said](http://www.djangoproject.com/weblog/2006/aug/07/guidointerview/) that Django is the most elegant and powerful web framework. 
When you're done with Dive into Python (or while you're reading it), do some problems on [projecteuler](http://projecteuler.net). Thats how I learned Python. 
Then you have some experience. I'd strongly consider Dive into Python. I would strongly recommend three sources: * Dive into python. Great book that explains things very well. And teaches by example. * Beginning python by Magnus Lie Hetland. If you think like an engineer, and you like to see a problem and then see it solved. Learn by doing things, and learn by seeing tools in action then you'll like this book. * After you have a feel for Python from the above two books I would chcek out the [Code like a pythonista](http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html) page. You'll find it useful at that point. Lastly, a lot of people like the Learning Python book. It's not my style. It presents a lot of information but mostly in simple "rule" form. ie "this is how this acts, that is how that acts...etc.". I can't develop a strong intuition from that. However, when first learning, I did use that book as a reference or when I needed to get nitty-gritty details on some aspect of python (eg when I was coding up something funky with classmethods vs staticmethods learning python had a description about the differences. I should say that there were possibly better descriptions online and beginning python almost certainly has that information too.)
[MIT OpenCourseware: A Gentle Introduction to Programming Using Python](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-189January--IAP--2008/CourseHome/)
Thead Head First series has a "learning how to program" general book that uses Python for all the code. I'd agree that's it's a better idea to start with Python 2 than with 3. edit: [link](http://www.amazon.com/Head-First-Programming-Learners-Language/dp/0596802374/ref=pd_sim_b_10) for the book. Also, for something a bit more serious and quite complete check out "Core Python Programming" by Wesley Chun.
I second the suggestion of Project Euler There's also http://www.pythonchallenge.com/
I think in a year I would suggest DiP 3, but for now I'd start with the older one.
If you want a head start in computer science I would strongly recommend [the MIT 6.00 course](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2008/CourseHome/index.htm). It has good video lectures, lots of extra information, and excercises. If you have trouble with the syntax in python or some basic programming stuff you can always use [this free book](http://openbookproject.net/thinkcs/python/english2e/). That's the way I prepared myself before I went to study CS this year.
&gt; but it has more rough corners and ugly things. That is only relatively speaking. It is still the nicest shit I have ever programmed in.
Django runs on PyPy, the template language is regularly benchmarked under PyPy, with the results (as well as many other benchmarks run nightly) available here: http://buildbot.pypy.org/plotsummary.html
I usually use this style of signals to loosely couple components together. For example, a persistence layer or ORM might signal that it has objects ready to commit to the database; specific business logic listens for that signal and does some special action. In that scenario, the ORM doesn't need to know anything about the business logic, it can just focus on being an ORM. Another example is debugging and tracing. If an application emits signals at interesting points in its lifecycle, instrumentation functions can listen for those signals and do some detailed logging.
I loved Python too once...
If you know Java, then basically install python and mess around on your own converting some of your old Java homework into python. Google things if you need help. That's how I learn the basics of any new language.
No one has really asked what you want to do with Python. Of course, you can do practically anything with it, but if you want to do web stuff, then you really can't go wrong reading the [django tutorial](http://docs.djangoproject.com/en/1.1/intro/tutorial01/#intro-tutorial01). Even if you don't end up using django, it explains the whole process pretty well in a step by step way. I also recommend starting with Dive into Python. I did the two things above when I first started, and it all seemed pretty straightforward.
Well yeah, it's relative to Python 3. Involving other languages in the discussion makes it far more difficult (for instance Python is super nice compared to Java or Visual Basic, but it's downright terrible [as a language, such things as standard libraries are another axis of comparison] compared to Smalltalk or Haskell)
The books that have been suggested are good, but if I were you, I'd simply start with the official python tutorial.
Does not matter, as long as you start
Upvoted for being biased in the same way I am.
For some fun: http://pythonturtle.org/ &gt;PythonTurtle strives to provide the lowest-threshold way to learn (or teach) Python. Students command an interactive Python shell (similar to the IDLE development environment) and use Python functions to move a turtle displayed on the screen. An illustrated help screen introduces the student to the basics of Python programming while demonstrating how to move the turtle.
If you want to start learning Python along with your kids, this is a great resource: http://www.briggs.net.nz/log/writing/snake-wrangling-for-kids/ Generally to slow for a programmer that is just picking up Python. But good for a non-programmer to learn it.
I went into writing this post expecting there to be three, four things you'd have to keep in mind when writing code that is generator-friendly, and realized that, no really, there's only one thing you have to keep in mind when writing code that uses generators. I feel like this is better than purposely inflating the post with Joel Spolsky style stories or whatnot (and I'm still guilty of that. Hopefully the mailing list post made you laugh at me). It's simple. If you're good at Python, you know these things already. There's an orthogonal issue of how generators are not quite lazy streams (this has nothing to do with Haskell; laziness is one of the first things, for example, you hack up a scheme interpreter to do), but [people already talk about this](http://stackoverflow.com/questions/961848/python-generator-what-not-to-use-it-for).
I did DiP3. My reason for choosing it over DiP2 was: It was my 2nd book-for-n00bs (first one was [BoP](http://www.swaroopch.com/notes/Python) I just wanted to get basic syntax and ideas so I figure the latest version would be better as computer book authors change their style based on feedbacks. 
not for newbies, imo....not enough example.....basically it's fucking pedantic.
IMO, that's a daunting book for beginners, it's like a fucking phone book
Java programmer here who loves python... ...Your experience in java may actually *hurt* your learning in python. I would keep an open mind and not relate it to java.
Download BPython (or DreamPie if you are on Windows) and python's own IDLE. Dropping into a friendly completing console is very helpful.
I don't think there's (need for) any bias one way or another in recognizing the deep beauty of such languages as Scheme, Haskell, Forth or Smalltalk. And Python's corresponding failings.
Python 2. Once you learn python 2, 3 should come easily :)
Please be more specific so the rest of us know what you are takling about. I use Python 2.6 in my job and Haskell for fun, and I don't really have much problems with the Python stdlib. The documentation makes the difference for me. Python docs come with a clear language and usage examples. After reading the Haskell [reference for Data.Graph](http://cvs.haskell.org/Hugs/pages/libraries/base/Data-Graph.html), for example, it took me quite some while until I figured out how to build a graph.
The python.org tutorial is pretty good. Then look at DiP if you want more.
I would start with ["Dive into Python"](http://diveintopython.org/) as has been suggested by others. After that (or concurrently) you should start a small project, for personal use that you find interesting, you will learn a lot if you do that.
i would like to learn and in the near future i have a big project idea for python so eventually writing production code
at the beginning
I do not think Dive Into Python is good place for a beginner. It spends too much time on things you do not need to know. Start with the tutorial at python.org. Then, find a book that suits your taste. I think Learning Python is excellent for a wide variety of people.
&gt; I don't really have much problems with the Python stdlib Of course not, at no point have I been talking about stdlibs (quite the opposite in fact), let alone documentation. I'm talking about the cleanness and poesy of the languages. The expressivity of Haskell's type system (especially in the hands of madmen like [Oleg](http://okmij.org/ftp/Haskell/)) or its seeming lack of syntax (even though the parsing rules are actually quite complex), the cleanness and flexibility of Scheme's macros and uniform syntax, Smalltalk designer's uncanny ability to express [every-fucking-thing](http://en.wikipedia.org/wiki/Conditional_\(programming\)#Object-oriented_implementation_in_Smalltalk) using just objects and messages to them (and their building of a language made to do exactly that) or the malleability of Forth's lack of syntax, getting programming to be less about "coding" and more about building vocabularies in which programmers can express themselves (and their problem) instead. Meanwhile Python has ugly statements everywhere, a highly rigid structure (and thus limited flexibility available to the language's user) and tends to be extended not by removing that which blocks the extension, but by [piling](http://www.python.org/dev/peps/pep-0343/) [more](http://www.python.org/dev/peps/pep-0308/) [syntax](http://www.python.org/dev/peps/pep-0318/) [on](http://www.python.org/dev/peps/pep-0342/) [the](http://www.python.org/dev/peps/pep-0380/) [heap](http://www.python.org/dev/peps/pep-3142/) Make no mistake, I like Python a lot and it's a highly practical language (in the wider sense in this case) with a terrific community, a fantastic stdlib and a very nice third-party ecosystem. But if we're talking solely about the looks and semantics of the language it's not very good. Above average on some stuff, but not that impressive at the end of the day.
Start with video lectures on Python: [Learning Python Programming Language Through Video Lectures](http://www.catonmat.net/blog/learning-python-programming-language-through-video-lectures/)
Dive Into Python is great, but each chapter is very dense. [Think Python](http://www.greenteapress.com/thinkpython/thinkpython.html) incorporates a bit more "air" between concepts and might be a good alternative if Dive Into Python daunts.
Thanks for your reply. Generators are something I am aware of but have not used exhaustively. ..Also, the song, you like?
&gt; However, I do not think you should berate me for going to reddit for help. I’m not berating you; it’s just that this problem is so artificial, I don’t see why anyone would be interested in solving it, except as a homework problem. As for why Reddit can’t become a homework help group, a) in some instances, it may constitute academic dishonesty (not this instance though, probably) b) most of us reading /r/Python are interested in advance Python techniques, not basic stuff (there are subreddits for new programmers though) c) there is an endless supply of people who need homework help, and it could easily flood the channel if we let it.
It never hurts to fiddle around in the interactive shell if you have a question. The basic thing is that Python treats `3` and `"3"` completely differently: &gt;&gt;&gt; type(3) &lt;class 'int'&gt; &gt;&gt;&gt; type("3") &lt;class 'str'&gt; &gt;&gt;&gt; 3 == "3" False `3` and `"3"` are different types, so to make them comparable, we’ll have to convert them to the same type. (Note, if you are used to languages like Perl, PHP, or Javascript, the behavior of Python is a bit different. Those are so-called “weakly-typed” languages, so they don’t always distinguish between integers and strings.) &gt;&gt;&gt; int("3") 3 &gt;&gt;&gt; str(3) "3" So, we can convert from one type to the other by passing something as an argument to the type we want to convert to. If we do this, then the two different things become comparable. &gt;&gt;&gt; int("3") == 3 True &gt;&gt;&gt; str(3) == "3" True If we leave the types different, then we can’t do addition, because string addition gives 33 and integer addition gives 6, so it’s not clear what answer we want. &gt;&gt;&gt; 3 + "3" Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unsupported operand type(s) for +: 'int' and 'str’ To add them, first convert to a single type. &gt;&gt;&gt; "3" + str(3) '33' &gt;&gt;&gt; int("3") + 3 6 Multiplication, however, is unambiguous: create a new string that repeats the first string n times: &gt;&gt;&gt; 3 * "3" '333' &gt;&gt;&gt; 3 * "yo" 'yoyoyo' &gt;&gt;&gt; "yo" * 3 'yoyoyo' 
Until the accident?
Works the other way around as well so...
I suggest *Beginning Game Development with Python and Pygame* from [apress](http://apress.com/book/view/1590598725). Making things move around the screen is a bit more rewarding than sorting lists for no good reason.
&gt; a highly rigid structure (and thus limited flexibility available to the language's user) While it's convenient at development time, the total cost of software is mostly driven by its maintenance costs. At maintenance time I completely prefer languages with highly rigid structures. EDIT: grammar (again)
In my opinion, the looks of Python is unsurpassed. Nothing else is as readable. Also, I have very rarely been limited by the some kind of rigidness in the language. I would argue that Haskell is much more rigid. The Haskell syntax really needs some getting used to until you can read code, and even then it is a little troublesome. Don't get me wrong, I love Haskell for its expressivity and all the things it taught me. But only looking at readability and even producitivity, I would prefer Python.
[I found these videos to be very helpful, just following a long. Great for getting the basics quickly](http://www.youtube.com/watch?v=4Mf0h3HphEA&amp;feature=SeriesPlayList&amp;p=EA1FEF17E1E5C0DA)
6) then choose an obsolete answer from googled result 7) then ask, "why can't we create and maintain FAQs for our subreddits?" EDIT: formatting
Ah. You've worn a stillsuit before? 
Another very good python book for a new programmer is ["Hello World"](http://www.manning.com/sande/)
Yea, I thought about mentioning that too.
I was working in the lab ... 
**1.)** Get a reference material - the python docs site is decent, as is Dive into Python (mentioned elsewhere) **2.)** Then start *doing something with it*, like playing this game: [Project Euler](http://projecteuler.net/)
&gt; In my opinion, the looks of Python is unsurpassed. Wow... &gt; I would argue that Haskell is much more rigid. You'd be wrong. &gt; The Haskell syntax really needs some getting used to until you can read code, and even then it is a little troublesome. Uh... no. The tendency of Haskell's community to use operators everywhere might take some time getting used to, but the syntax is downright trivial to read.
I started learning Python simply by doing a Django project, with Dive Into Python occasional support. Today considering myself as semi-advanced pythonista, doing asynchronous apps, multiprocessing etc. Oh, and having my bills paid ;) Reading Django source code will definetely give you answers and hints. I'm assuming you know objects and shit.
I take it you're a happy ADA camper?
Upvote for Code Like a Pythonista. I've been learning python for the last couple months and have already seen the tutorials and free books that are typically recommended. That's a new one for me.
&gt; Wow... ... &gt; You'd be wrong. Very constructive work, thanks. 
 print 'hello world' Done.
This is how I learned Python, by learning Django.
Thanks for the mention, krugua. I'm the author of "Invent Your Own Computer Games with Python" aka "Invent with Python". I'll say that it's a good book if you don't know programming at all. But if you already do but just want to learn Python, go with "Dive into Python" It's made to be understandable by teens &amp; kids as young as 10 or so, but it is not "4 kidz" so adults can find it readable as well. It's also free under Creative Commons.
My book, [Invent Your Own Computer Games with Python](http://inventwithpython.com) is for the same audience, and provides source code for small games and teaches programming from those examples. SWfK is good too though. Both are free online.
Yes, because &gt; the looks of Python is unsurpassed. Nothing else is as readable. Is highly constructive isn't it?
...late one night?
FYI, there's a subreddit [here](http://www.reddit.com/r/MITocw600/) dealing with the MIT opencourseware lectures. Its pretty new, we're only as far as lecture 3, so you should have no problems catching up.
Maybe we misundestood each other. With "looks" I mean readability. I assumed that you knew that Python is generally considered to be a very readable language (you know, pseudo code that runs yadda yadda) and hence that it was clear what I meant, namely, that I agree with this. Sorry for the bad wording on my part.
&gt; With "looks" I mean readability. Well yeah, you quite clearly said "nothing else is as readable". &gt; I assumed that you knew that Python is generally considered to be a very readable language I do know.
So what I said was still constructive after all. I stated my opinion, what it is based on was clear. Anyway..
Thanks. Bookmarked.
I tried to check this out the other day but couldn't find video's of the lectures(which are basically the only thing I would want from the course, not sure how other's might feel). Am I just being a moron? Where are the lectures?
You want the Python Cookbook: http://code.activestate.com/recipes/langs/python/
Nah, that's too much for me But many, many years ago saw XBase catastrophes caused by too many ways of doing the same thing. Then saw Clipper 5 fix that. Later on I saw many Perl catastrophes caused by too many ways of doing the same thing. Then Python fixed that. Now I see that Ruby has many ways of doing the same thing. I'm bracing myself for maintenance issues as we bring more people onto a particular RoR project. Not sure what the solution will be.
This is exactly the sort of thing I'm talking about. After some skimming though, most of the scripts seem fairly "low-quality"/useless IMO.
&gt; So what I said was still constructive after all. Uh... no.
They are not useless at all. Many of my 'daily script' are composed of this recipes. The cookbook is the first book I used to learn python and am still using it for a lot of quick reference.
While certailnly a good start, I feel that you left out a bit too many details regarding subjects like lambdas, closures, metaclasses and a few other subjects that advanced Pyton programmers should know. Perhaps you could expand your tutorial with a second example?
&gt; the python docs site is decent Could be better. php.net is better.
Technically speaking this is all you need to _start_ learning Python...
Anything that has everyone's snippets will seem like that ;)
Well, I shouldn't have said useless. Most scripts are overly short, "simple" though. I guess you just have to look for the more interesting stuff. The book seems interesting though, maybe I should check that out.
Haha, that's probably true :D
My recommendation is always the (Python Tutorial)[http://docs.python.org/tutorial/]. It's short enough to work through in a couple of hours, and is remarkably well written.
Hmm, I suppose I should go to the beginer subreddit. Do you know the /r/ for it?
I really liked the showmedo.com site. 
It's a text based course with lecture notes (pdf), assignments and solutions, and projects. 
Project Euler is great. Practice, practice, practice. Project Euler is not good for teaching design, modularity, and maintainability. The nature of Project Euler is "code up a quick and dirty solution to a given problem".
You may find [this discussion from /r/linux useful](http://www.reddit.com/r/linux/comments/b2hcf/asklinux_which_distros_best_for_scienceengineering/). They mostly recommend Fedora/RH distros, and less with arch and almost not at all for Scientific Linux, though I didn't ask about python in particular.
it doesn't look like all the lecture notes are there.
When my eyes beheld
**USE OPEN SOURCE** One other source that I didn't mention in my first post (and no one else did for that matter). But, it's a **really** good one, and I think all really good programmers use it. Read other people's code. That's how Bill Gates (at the very least and probably nearly everyone else) became really good. It's like sports: if you want to get better you have to play with people who are better than you. If you do this, you will address an area that Project Euler practice cannot: design, scalability, and building maintainable systems..... Where do you find these examples? Welcome to the wonderful world of open source! Python is used **so** much in Linux distributions that it's **really really** easy. Additionally, because Python is an interpreted language **everything** that a program needs is right there on your Ubuntu/Fedora installation. There is no compile cycle, no library linking compiles, or whatever.....the code you see on your computer is what's running it. This is a great advantage over something like C for learning. To find programs on your linux distribution, go into /usr/bin where you'll find the main executable module. That module will, no doubt, not have the main bulk of logical code. However, it will point you to where that code is. If you want a real challenge (but not necessarily a pythonic code base), check out the reddit source code. It's all Python. Uses the Pylons framework. I wouldn't recommend it for learning anything other than Pylons though. It's pretty convoluted and complex. I'd really recommend you start out with desktop systems code.
It should, this question gets asked *a lot*.
Along with all of the tutorials, I would suggest finding a small OSS python project (I found gwibber and hacked on it some) and reading through the source and try to fix a few bugs.
http://www.reddit.com/r/learnprogramming/
profile the code http://packages.python.org/line_profiler/ second google result.
Is OSU's CSE department still running Solaris 8?
From what I can tell a profiler will not let me step through the code line by line... unless it is an undocumented feature?
I'm learning python right now through MIT OCW. The course you want is [6.00 Introduction to Computer Science and Programming](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2008/CourseHome/index.htm). The lectures are awesome, and the [texts](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2008/Readings/index.htm) are basically what everyone here has been posting. This is a full on course. The website includes videos, links to online textbooks with readings associated to lectures and even assignments. If you want to be able to submit assignments you can participate in the [crunchcourse](http://www.crunchcourse.com/class/mit-opencourseware-600-introduction/2010/jan/) for this class (it's grown kinda stagnant but I'm working on getting more classes posteed). The 'gentle introduction' class isn't even a real course; it's only 4 weeks.
This is probably it: http://docs.python.org/library/trace.html Need to check some more to be sure.
For getting started you could check out http://www.trypython.org/
a very good place to start
Won't get too far if he doesn't know much number theory...
looks like php-ish code written in python, IMO
Dude, you're one cool cat. Way to be humble and not self-promoting. It just makes me want to read your book more.
Don't forget to study the [PEP8!](http://www.python.org/dev/peps/pep-0008/)
Learn 3. Almost everything about 3 is easily adapted to writing good 2 code. You just have to take the parentheses off your `print` calls and deal with decoding file input in a somewhat more cumbersome manner, but other than that, it’s not very different. Plus, diveintopython2 will teach you bad habits for a Python 2 programmer, since it was written so long ago that it’s out of date, even as a guide to Python 2.
An eerie sight
Java killed my desire to program. Python rekindled it! I could never remember how to open a file in Java, so I always just copy-pasted from old projects. In Python, it’s `mytext = open("filename").read()`. Beautiful!
Make it compatible with 2 and 3: `print ("Hello, World!")`
Yes, you'd have to write your own hook (unless you can find one, maybe on the Python Cookbook?), but it should be pretty clear how to write your own with a trace.
If you already know a programming language, diveintopython is the way to go. Be sure to skim over the tutorial after you're done though, because some of the newer stuff that simplify your life (looping techniques, properties, using object as the base class) aren't covered.
So they are! In fact, upon logging in one is treated to this friendly message: Sun Microsystems Inc. SunOS 5.8 Generic Patch October 2001
As someone who went down the same path (coming from PHP) and read the suggested tutorials, the most important thing you need to lean a new language, is a goal.. what are you going to build? Take it from there..
http://docs.python.org/library/pdb.html
The SPAM sketch is good, then the ministry of silly walks sketch, then Life Of Brian.
[pudb](http://pypi.python.org/pypi/pudb) &gt; PuDB is a full-screen, console-based visual debugger for Python. I do not use it that often, but it really is a handy tool when print statements are not enough. It does exactly what you want, you can use the "s" key to step into a function call and examine the underlying module step by step. There is a screencast on the linked page. (FYI It is in the Debian/Ubuntu repos)
Was it a snake?
[Byte of Python](http://www.ibiblio.org/g2swap/byteofpython/read/index.html)
hadnt seen this before ... looks awesome, I sometimes have to demonstrate pieces of code to people with only a passing involvement, this will be perfect.
Heh, until I learned Haskell :-)
Can you pastebin the first function? There seems to be nothing wrong just from what you've given.
This has to go up more. PEP8 is really important and a lot of developers avoid it. If you want to be true python dev, start with pep8
OK, if you want to run them concurrently, you'll have to use threads. Google up on how to do threads with python. However, the fact that function two doesn't run after function one indicates that function one is doing something to terminate execution of the program (e.g., `exit()`). You should look into that and iron out those problems before dealing with threads.
If you're looking to do this in a (fairly) user-friendly manner in a graphical user interface, then try Eclipse with the PyDev plugin. It basically wraps pdb and lets you step through your program line by line, showing what goes on. And it's visual. And very easy to use.
You can leave the parentheses on the print calls.
[WinPDB](http://winpdb.org/) is also a pretty good debugger. You can also use it to attach to remote computers -- this works pretty well for debugging web services and such (you need to run WinPDB on the server computer, you can't just debug some random web service, but if it's your server...).
I still prefer Glenlivet.
Ardbeg
You can redirect stdout such as: import sys sys.stdout = open('wat.log', 'w') print "shit " * 400 # gets written to wat.log # restore original stdout (2.6+) sys.stdout = sys.__stdout__ *YEAAAAAAAAAAAAAAAAAAH!!!!!!!* 
Because you are *better* than regexes. 
I have found http://python.net/crew/hooft/follow.py helpful in the past, but it could do with updating to work better with newer pythons.
Lagavulin
The two truths of testing: - any testing &gt; no testing - automated testing &gt; manual testing The rest is preference.
Laphroaig
No. Something else. It seemed harmless at first... 
Thanks... lots of useful suggestions from people here -- and it gives me some terms to search for in google if I ever need/want to. :)
Do either of these use pre-emptive multitasking? I was looking for green threads for Python that used pre-emptive multitasking, but most solutions I've found require a yield.
No, both of these use cooperative multitasking.
Both use cooperative multitasking, but they don't require a yield, switching occurs when a blocking function is called (like socket.recv). In some regard this is better than pre-emptive multitasking as you don't have to protect your code with locks because switching cannot occur at random places. 
Only if either you `from __future__ import print_function` or you’re only ever printing one thing at a time. 
import pdb; pdb.set_trace();
Wouldn't it be great if reddit had a ranking system so that people could simply downvote content they didn't feel was worth reading. Oh.
I've created monolithic import scripts (even sometimes hidden behind "if False:") for the benefit of py2exe before. The py2exe modulefinder logic is far from infallible.
Really don't like the interface, the garish colours and the font sizes are awful. Also, a purely client-side solution would be much faster. Better off downloading Kiki which is far superior. Phillip.
`import pdb; pdb.pm() #in live sessions, post-fuckup.`
What about libev and pyev? I am using them in a project where i need events for all major three platforms.
But * good testing &gt; 100 * bad testing So, anything that helps to make better test is welcome.
How would you implement a Python regex interpreter on the client side without writing one yourself in Javascript? Just tried Kiki, which is indeed faster and looks better.
This is just plain neato. Thanks for building/posting this.
+1 - pdb doesn't support watches (though you can kind of fake it) - and I love stepping through code with pudb and seeing the values on local variables updated.
You can use the trace module via the command line: $ python -m trace --trace myscript.py
The problem is mention of Unladen Swallow, which has sadly been strongly associated with Google and therefore indirectly Jesus, since obviously being a project of a Googler it's going to save them from performance Satan, etc. etc. So people just blindly upvote. You don't need to take my word for it, do a search. It would be nice if Reddit dampened this effect somehow (or e.g. presidential candidates during elections, police brutality, ...), but sadly there are limits to how much information can be extracted from the application of a few operations to 3 integers (ups/down/time). In the meantime, wish PyPy got more airtime. Going by recent blog posts, they are kicking performance ass.
upvoted for vim but I have no idea what's this all about
Yeah, I read that on the stackless website... although I don't have personal experience as to why they said that. Unfortunately, what I wanted to use it for would actually be ideal for pre-emptive since there is little issue with having to worry about locks, race conditions, etc.... BTW, I think it is possible to enable pre-emptive for stackless, but I didn't really want to use that. :)
Have you heard about pdb ? It's a Python debugger.
Tried it today, it works well but is a bit slow. The worse part is that it screw up your buffer once you've stopped debugging (keybinding are still pdb ones). There's some room for improvement but it's a great start.
What about it? While it looks to be a useful library (I had not previously heard about it), I'm not sure it fits in the same conceptual space as these greenlet libraries. It didn't get a mention [here](http://nichol.as/asynchronous-servers-in-python), anyway. It seems like it probably falls into what Eventlet calls [hubs](http://eventlet.net/doc/hubs.html), so you could probably write an Eventlet plugin that uses pyev/libev. 
Hi guys! I've mentioned this course a couple times here and thought I'd post it as a topic for those interested. I didn't create the course, but the creator let the course go stagnant so I had the owner of the site up my perms so I could create new classes (don't worry, all the material is MIT; new classes means people can continue to post HW). I'm kind of concerned those who joined in the beginning might not check back, but I thought I might try to stir up some interest here! This class is great for anyone who wants to learn Python and targeted towards people with little to no programming experience. You will learn Python as a vehcle for learning computer science/software engineering topics in general. See ya there!
oh nice thanks for the info, I didn't knew I don't use debugger but maybe it's a good opportunity to give it a try along with the related article.
Wow, this is pretty neat! I don't know when I would have the time to do these but cool, thanks! I foresee a summer project in the works.
wowzers, I am jumping in CANONBALL!!!!
Thanks, I've been looking for info to learn python. Just signed up for the class. 
I just want to thank denis (and the pre-fork authors) for Gevent. I'm using it with great success on a very high volume network application. I prototyped it initially in Gevent, Tornado, and Concurrence, and found Gevent to be my favorite solution.
I am learning Python at the same time, but I will not be learning it with you--I'm taking my own class already.
Right, unscrewing the buffer is the first thing we need to tackle. On my machine, speed is really good, except for the Down command. Can you give some information about your configuration as a hint to what is slow ?
you're welcome :) Please consider replying to the poll on mailing list http://groups.google.com/group/gevent/browse_thread/thread/4de9703e5dca8271
I noticed you can join some other people who are taking the online 6.00 course [at this link](http://www.crunchcourse.com/class/mit-opencourseware-600-introduction/2010/jan/)
&gt; includes modifying std lib modules to be more iterable friendly... Which itself is prompted by many standard constructs returning iterable views instead of lists (`dict.keys()`, `dict.values()` and `dict.items()` perform the equivalent of the current `dict.iterkeys()`, `dict.itervalues()` and `dict.iteritems()` for instance), so many stdlib modules expecting actual lists "broke" (in the sense that if you didn't call `list()` around `dict.values()` it wouldn't break, note that 2to3 transforms `dict.keys()` into `list(dict.keys())` and `dict.iterkeys()` to `dict.keys()`).
&gt; Lazy evaluation needs more highlight. Lazy evaluation is also not very well integrated into Python as a whole.
And there's always [this subreddit](http://www.reddit.com/r/MITocw600/)
Looked nice. Until it required Curses (and a unicode-aware terminal for the bar at the top of the article, and doesn't have fallback to raw ascii characters). Then it looked a tad less nice.
This one is quite a bit more flexible: http://pypi.python.org/pypi/progressbar
Is the API as nice as the one I linked to?
The author looks nice. (Sorry.)
I released 0.3.3 where key bindings are reset. Lemme know if it works for you.
A similar module (but more established IMO) is Louie: http://pypi.python.org/pypi/Louie/1.1 Also there's a multiprocess proxy that lets you dispatch with Louie over TCP or twisted: https://spideroak.com/code
Not yet really present in batteries included*? Yes. Genexps can not reference themselves like Haskell comp-exps? Yes. Currying is only so-so? Of course. But what do you mean by ,,Python as a whole''? It's not a functional language after all. \*) I don't mean itertools/functools here, I mean stuff actually using lazy evaluation.
&gt; It's not a functional language after all. So? If it can have generators, why couldn't it replace lists by generators?
I'll be in my bunk.
I was about to say. Nice to see more girlie-girls in CS.
&gt; So? If it can have generators, why couldn't it replace lists by generators, so I'd have to write list(generator) every time I need to have that whole genexp as a list in memory? FTFY ;-) Well maybe because generators are not meant to replace lists? It's not a data structure, it's a language construct.
Who could ever downvote a Firefly reference?
I use python to access IBM DB2, through ODBC. Works fine, but you cannot set your access type (e.g. uncomitted read). What do you want it to do?
Have you seen pymssql (http://pymssql.sourceforge.net/)? It's a DB API2 compliant interface to SQL Server.
&gt; Well maybe because generators are not meant to replace lists? It's not a data structure, it's a language construct. Fundamentally, generators are nothing more than dynamically generated lazy lists (or a subset of those). There's nothing problematic with replacing strict/eager lists with lazy ones (not completely true, but close enough). That's why generators are mostly bandaid (Python's version also has the issue of not being repeatable: you can only exhaust a generator once, I believe in C# you can iterate multiple times on a given enumerable)
At my place of work we are exclusively Microsoft and therefore only use SQL Server. I have (very covertly) been using python relatively often for various applications and data manipulations on our SQL Server (2008) database. I have used various db libraries to communicate with the db including pyodbc and pymssql (these two work the best in my opinion). Currently I am using sqlAlchemy (very cool and it makes things very easy) with pymssql. If you decide on python sqlAlchemy you won't regret it. It is quite easy to learn and very powerful. That being said, you will probably be needing to execute stored procedures (you mentioned a legacy database). IMPORTANT : If you need to execute some relatively large stored procedures go with pymssql. Especially if you require return parameters from them. I spent many hours delving into the source of the various db libraries (pymssql, pyodbc and sqlAlchemy) trying to figure out why it's not returning my parameters. I finally found a nice hack that works and I have been using this method for a while as our db is also largely a legacy system with many, many stored procedures and weird quircks. I can write a nice post on some python/SQL Server caveats if people would want to hear more - but I won't promise anything. I've been working for 12 hours straight now and it seems like my work load decrease any time soon :( Maybe over the weekend. As far as scaling goes I don't think you should have any problems, but I don't have any specific data to back this up. Most of the python/SQL Server libraries are pretty established and stable (excluding the stored procedure related functionality) and should work quite well. It depends on what you want to do with it, I suppose. Seeing as I have some experience working with sqlAlchemy I can highly recommend using it. If you need to write a web app using your SQL Server there are many python webframeworks that use sqlAlchemy to choose from (pylons, turbogears - or just use google to search, there are many). Alternatively, I can also recommend web2py. Its built in database abstraction layer will work with a legacy db provided you are willing to make some modifications and also supports SQL Server natively so it might be worthwhile to check it out. The web2py team has made some progress on support for legacy databases - but I might be a little out of date. I am going to eat now as my tummy is trembling tumultuously and my mind melting malevolently.
I've been meaning to teach my wife python. Maybe this will help. 
I have used Python to regularly manipulate an SQL Server database. There are Windows only drivers available for Python. Though there should be no particular issue with using ODBC
&gt; It is quite easy to learn and very powerful It's darn powerful. But the documentation is a bit haywire. It seems like there are three or so ways to do everything.
yes.
well ... it is for a company which has a legacy site (very popular site) that uses sql server. They say that they are moving to python, but they say they don't think odbc will perform (i don't have much experience with odbc, and zero experience with mssql), so they say they want to write a data access layer in java and talk to it from python through services. Maybe this solution would perform just great, but, it also (imo) makes the programming work less attractive because you lose the ability to use a nice orm like sql alchemy, or even the django orm. So, my first inclination is to make sure that they are correct in that odbc would be problematic, or wouldn't scale in some way.
I saw her give a talk a PyCon. Way cute + sexy accent.
I wrote a wrapper around pyodbc to deal with all the internal MS SQL databases at my work. I've been happy with it. One hangup with pyodbc was executing stored procedures. I found a hack around that and built it into the wrapper so I don't have to worry about it. It's as fast as I need it to be, no complaints here.
um, I use the python sybase module with no problems.
I don't understand the question, sorry.
Several ways I can think of offhand: * Copying this program to your local machine. * Command-line app that you pass the regex to * Program that watches a files for new saves and runs when save is detected * GUI Python app * An html solution, using a Python web server that passes any regex to Python itself, runs it and returns it back to the page. Of course, you wouldn't want to use javascript because it's regex might work differently.
Oh, you mean run it off your local machine. Sure, that's obvious. I though by client side you meant a webapp that parsed python regex purely with client-side code.
I had no issues using pymssql with SQL Server for moderate data volumes. What exactly are you trying to do?
\_\_gotcha, what version of python are you using? The capture functionality didn't work for me on 2.5.2 until I modified debugger.py methods capture\_stdout and stop\_capture. pdb.py writes directly to self.stdout, which is replaced with sys.stdout in capture. I had to modified capture/stop to replace self.stdout with StringIO, and then restore it back to sys.stdout in stop. Once I did that, the feedback buffer came alive! I was also messing around with highlighting and was able to highlight the current line, and put visual indications on lines with breakpoints! Cool stuff. BTW, awesome project!
I suppose there's a lot of desktop window-managed terminals that are Unicode-aware these days; it's nice to see more Unicode art in terminals rather than just ASCII. I think though, that having an ASCII alternative is still essential.
Timely. I used nose for the first time a few months back. I like its function discovery a lot since it always seemed vaguely un-Pythonic to have to define a class to hold unit tests. I will keep my eye on unittest2, nose2, etc. Has anyone tried unittest2? Thoughts?
another lesser know odbc module is ceODBC. It hasn't had an official release in quite a while, but I have been in contact with the author recently and he is still actively developing it and is planning a "2.0" release in the near future which will also support python 3. I have used both pyodbc and ceODBC extensively and I can say that ceODBC is MUCH faster for executemany operations involving large data sets. I have encountered bugs with both, but the bugs with ceODBC have been less serious generally and the code base seems a bit cleaner. I also don't like the way pyodbc uses a special "row" object instead of plain tuples for returning result sets, which is very unconventional in the world of python db api modules.
Python is easy. Getting it up and running on a windows machine for development is the hard part... (I'm still not there!)
I develop on 3 machines, Windows 7 at home, and 2 XP (Desktop/Laptop) at work. I have Apache (xampp) set up on them all for PHP development. I have IIS and SQL Server light on them too for .NET development. All this is working nicely. However, getting Python to work is driving me nuts! Maybe I am doing it wrong. I don't want to dabble with the Python shell. I want to install python frameworks, AND use casual scripts. I've tried mod_python with xampp, and I have now mod_wsgi working (sort of). But mod_wsgi support for Windows Apache is appalling, I have to restart apache for every code change. So it is back to mod_python. But I have other issues with mod_python. First, the pre-compiled x86 libraries are out of sync with Windows Python install. Do I really have to load everything into MS Visual Studio and build it from scratch? I hope not. tl;dr; version: 1. Are mod_python and mod_wsgi combatible? Will I get into trouble if I use one one the dev machine and the other on the server? 2. Is using Apache with python modules overkill? Can I develop using the python web server? Again, will I get any troubles when I deploy the application on the server? I'm done with dabbling, I want to do some real Python work, please help me. 
&gt; it always seemed vaguely un-Pythonic to have to define a class to hold unit tests How so?
If your deployment target is going to be in Linux environment, I recommend installing VirtualBox, I assume that your PC is powerful enough since it can run Windows 7. I don't deploy to Windows machine, but during development I, if I was only Windows only machine, I do `paster serve` which run Python based web server to serve Pylons apps, there's also Django equivalent.
Have you looked at IronPython? It's .Net...
I like it.
Yeah - PyPy seem to be making fantastic progress. They seem to have *finally* got to the point where PyPy is ready for real world usage. It's only going to get better too.
* `mod_python` and `mod_wsgi` aren't compatible, and you just shouldn't use `mod_python`. * If you are just developing, it's totally fine to use a Python web server. * `mod_wsgi` can be a bit more picky about things like print statements. But you can turn that off with a setting, and you can just try to be careful and do regular staging deployments (maybe to a virtual machine).
Just go to activestate.com. Google would have told you that (6 or 7th link for "python for windows"). 
Just run virtualbox, or get a cheap vps somewhere. Use something like fabric to deploy.
Not sure what you are asking but web2py has a [windows binary distribution](http://web2py.com/examples/static/web2py_win.zip). It includes a single executable file (web2py.exe) that does not requires installation and includes web server, sqlite and various web based development tools. It does not require Python preinstalled and if you have that does not interfere with it.
One of Python's strengths is its terseness. If I am testing a program written in a functional or procedural style, it seems like a test class is extra boilerplate. That's not to say I think one *shouldn't* create test classes---I do in object-oriented Python programs, and nose allows both approaches---I only meant that *requiring* a test class seemed strange when Python is organized around modules.
Understood
My Python/Django dev setup on Windows 7, simple as can be: 1. Install python for windows: [Python 2.6.4 Windows installer ](http://www.python.org/download/). 2. Install SQLITE for windows: [http://www.sqlite.org/download.html](http://www.sqlite.org/download.html) 3. Replace the windows console: [http://sourceforge.net/projects/console/](http://sourceforge.net/projects/console/) 4. Install Django: setup.py install --&gt; Complete details [here.](http://docs.djangoproject.com/en/dev/topics/install//) 5. Use *python manage.py runserver* to get a simple webserver. 6. Install [Notepad++](http://notepad-plus.sourceforge.net/uk/site.htm) Hope that helps. Let me know if you need more details.
I am totally using this for automated deployment.
I actually found the documentation very usable (maybe that's just me :) ). If you need to use SA for legacy stuff (I forgot to mention this in my first post) you should use [SqlSoup](http://www.sqlalchemy.org/trac/wiki/SqlSoup). It's really wicked cool. From the docs : &gt;SqlSoup provides a convenient way to access database tables without having to declare table or mapper classes ahead of time.
I think PEP8 favors: __version___
Thanks for the feedback! Let me know if you find any issues at all, and I will look to fix them.
Uhm, yeah obviously, since you are the author :-)
The Python API examples link from the documentation is broken :( Does anyone have some other examples to show off?
Where have you found the broken link? This link works for me: http://knipknap.github.com/exscript/api/ The Git repository contains two more examples (I should add some more): http://github.com/knipknap/exscript/tree/master/demos/
Or you could use [Fabric](http://fabfile.org/), which does a whole lot more (and is designed specifically for deployment tasks).
Ok... this sound like a plan. I'll try this over the weekend. I think I'm over-analysing my dev setup. :)
The link [here](http://wiki.github.com/knipknap/exscript/documentation) - The Python API -&gt; Examples
Ah, Thanks! It is fixed.
Yes your best option. Note that PyEclipse works like a charm. Another solution is to deploy a colinux on your machine (kind of linux running on windows, sorry for the poor description ;) ) A friend of mine is using this configuration for his dev, ubuntu colinux on his windows, and he made a samba on which he's working with his Eclipse. 
colinux is probably enough is a shell access is all that's needed. 
Every good karma whore knows to mention Dive into Python every time beginner python is mentioned ;)
how do you see that helping jonr?
&gt; I'm done with dabbling, I want to do some real Python work, please help me. Then you need to site back, take a breath, and accept lots of dabbling will be coming your way. For this hurdle however: You are trying to setup a production environment to develop in, this is wrong. Django's manage.py runserver command solves your problem here btw, it will re-load upon saving your new code. I believe turbogears, webpy etc have similar dev-friendly environments. 
http://pythoscope.org/dont-use-pickle-for-object-serialization I'm no expert on the pickle module but this sounds relevant.
What, so my opinion doesn't count all of a sudden? Sheesh. :-)
The whole boilerplate being a class definition line? Never bought that argument.
Yeah - I did Django development on Windows as part of my last job (now doing Django dev on Mac OS X). I prefer Wing as an IDE and I don't *think* I replaced my console - but I can't argue with the advice here. I would be tempted to add: use virtualenv for all Python development. Possibly a bit of a learning curve though, it's not essential just makes things easier for keeping project dependencies isolated.
You need to use mod\_python *or* mod\_wsgi for deployment. You shouldn't have a problem having both installed (?) but you'll only be using one of them. I would recommend mod\_wsgi. For *development* I would just use the builtin django dev server though. 
Your code's a bit confusing there, as all `self = pickle.load(f)` is doing is binding a new object to the local `self` reference - it doesn't change the object returned by `__init__`. I assume you meant to do this somewhere like `__new__` instead. However, the reason you're getting the error you are is because pickle resolves references by name. It's got some data that says it deserialises to a class named "PickleDecorator.bar", so pickle looks at the object named "bar" in the "PickleDecorator" namespace and finds that it's a completely different object - some instance of something called a "mydecoratormodule.PD" class (ie your PD decorator), and so refuses to unpickle. To deal with this, you'll need to make the object at that name **be** the class being unpickled. You could do this with a decorator that creates and returns a subclass of the argument, but there are still a few problems this way (for instance, that pickle actually calls `__new__`. I think you may be better off using a metaclass here, rather than a decorator. Here's a quick conversion of your code: class AutoPickleMeta(type): def __call__(cls, *args): t = (int(time.time()) // 10000) * 10000 h = hash(args) fn = '%s/%s-%i-%i.pickle' % (gettempdir(), cls.__name__, t, h) if os.path.exists(fn): # File exists, so load the cPickle and return with open(fn, 'rb') as f: try: return cPickle.load(f) except cPickle.UnpicklingError: # If error occurs assume cPickle file is corrupt, # and create a new object f.close() return cls._do_pickle(fn, args) except EOFError: # File appears empty, return a new object f.close() return cls._do_pickle(fn, args) else: return cls._do_pickle(fn, args) def _do_pickle(cls, fn, args): # Create object, and return o = object.__new__(cls, *args) o.__init__(*args) with open(fn, 'wb') as f: try: cPickle.dump(o, f, cPickle.HIGHEST_PROTOCOL) except: # If anything went wrong, delete the pickle file and re-raise # exception f.close() os.remove(fn) raise return o class AutoPickle(object): __metaclass__ = AutoPickleMeta Usable as: class bar(AutoPickle): def __init__(self, x, y): ... Alternatively, you could go even simpler and just use normal subclassing from an object that has a classmethod factory method. You'd need to create objects like: &gt;&gt;&gt; b = bar.create(1,2) But it prevents you and pickle tripping over the same python object construction protocols, so if you can live with it, it's much simpler under the covers. 
Just use web2py, www.web2py.com
Looks decent enough, but if it's statistics and it's not in R, it's not for me.
Some great stuff in here, particularly fond of &gt; Power Features &gt; &gt; ▶ Avoid these features.
thanks.
i'm not 100% sure i follow why you'd ever want to do this, but i think you want to be decorating bar's init method, not the entire class. (how do you do inline code markup? apparently __ does bold?)
By the way, it looks like Python installer started adding .py to PATHEXT, so you don't need to write "**python** *your-script-name*".
You are trying to be clever! Remember the Brian Kernigan's words: *"Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it."* -- that's exactly what have happened to you, and you are lucky that it happened even before the code was finished, rather than half a year later. Do not be clever, especially don't try to sneak in important functionality implicitly (via inheritance), especially if you don't quite grasp how Python object system really works, it is much more complex than you think, probably. Simple explicit function call or a decorator would be more than enough. obj = cached_call(MyClass)(arg1, arg2) Take [this](http://pastebin.org/101775) and use it as you will. It also needs `from itertools import chain` and stuff from pickle.
This reminds me, I should set up a stackoverflow account.
I disagree that the extra one line to declare a class is objectionabal terseness. However, I 100% agree that people shouldn't be forced to use specific paradigm.
&gt;how do you do inline code markup? Use backticks (\`) to surround the code.
That is good advise, but I never planned doing anything with this code, certainly not putting it into what I'm currently writing. I expected that doing this would be very difficult, which is the main reason I tried it, so I could learn some more about python. Plus, its a Friday afternoon and it was a nice distraction from the boring physics.
Python works fantastic on windows I prefer the python.org install and add the win32 module. Eric4 IDE is based on pyqt4 even if you don't write pyqt apps it has a great threaded debugger, I have ran grok and web2py in eric4 the stack view is great. Insert sys.breakpoint() in your code and eric4 will break there every time that code is called. Oh I do most my coding in VIM. I have found that the pyqt code that I have written (if you detect the os and set the paths etc.) Can run on all platforms that I have the environment setup I just bundle up the with py2exe/py2app and inno.
The reason I wanted to pickle my class, was so I wouldn't have to re-generate the class each execution (something particularly painful when actually developing the code). The class isn't particularly complicated, but alot of maths goes into generating ~5million geometric planes, which are stored in a dict to reduce run time. Basically I've sacrificed memory for execution speed. However, I myself don't know why you would really want this functionality as a decorator, but I thought it'd be fun.
Why is that? I've heard this before but I'm not a statistician and I don't know enough about R to understand why I would do something in R over Python. Is it just a matter of the built ins in R?
Thanks for your answer, it helped clear a few things up. However, with regards to your first point: &gt; all 'self = pickle.load(f)' is doing is binding a new object to the local self reference - it doesn't change the object returned by `__init__` As I understood things, object instance creation starts by first creating an empty object (lets call this A) with all the classes methods.The class' `__init__` function is then called, passing A as an argument (hence why you need self as the first argument in `__init__`), which initializes the object to a certain state. In short, `__init__` does not return your class, it modifies an empty object to be your class. To quote the python tutorial (section 9.3.2): &gt; The instantiation operation (“calling” a class object) creates an empty object. Many classes like to create objects with instances customized to a specific initial state. Therefore a class may define a special method named `__init__()` So when I do: self = pickle.load(f) I'm in effect throwing the empty object A (and hoping the garbage collector will find it), and replacing it with a new object B created from the pickle. No doubt things are a little more complicated than that, but as my first example code works (not the linked one) I'm happy Also: note my change to the example in my comment, slight typo 
No, 'A' in your example is not garbage collected, because a reference to it created when you do my_instance = MyClass(). Try this- class A(object): def __init__(self): self.foo = 2 self = 1 b = A() print b.foo Outputs 2. As GP stated, 'self' is just a reference to the object, not the object itself.
Most argument I have heard is that R has a huge set of statistical library and it is THE language for statistical computing. Though I personally find R to be extremely annoying to use as a general purpose language. 
Not quite. Your `__init__` method is passed a reference to the empty object as `self`, but this isn't the only reference - the code calling into `__init__` obviously has its own reference too. Changing self doesn't change this outer reference, it just rebinds the local reference to a brand new object which gets discarded as soon as it goes out of scope. Nothing outside knows or cares about this rebinding - it has no effect on the object that gets returned, since that's already been established by the code calling `__init__`. In essence the construction of an object does the following: obj = SomeClass.__new__(args) # Create empty object obj.__init__(args) # Call __init__, passing the new object as the self parameter return obj # Return the constructed and initialised object. (You'll see something similar being done explicitly in the metaclass solution above, since I'm hooking in at that level). If you want to actually change the object that gets returned, you need to either override `__new__`, or use a metaclass to override the behaviour of calling the class. I did the second, since pickle will also call `__new__` too when it loads objects, resulting in an infinite loop if I try to load it via pickle again (there may be other ways to prevent this - eg. overriding the pickle hooks).
bitnami has a preconfigured django stack with installers / vm's for all major platforms: http://bitnami.org/stack/djangostack 
Almost anything that I have ever wanted to do in terms of data analysis has already been written in an R package. It's not always the most elegant solution, but it's all there and you can tie it together quickly and easily (if you're used to R). It's also a good enough general math language, that I use it for prototyping, too.
Agreed, as a language, R sucks.. It's up there with Perl in it's level of inconsistencies.. but from a practical perspective, it can often be awesome, right up there with perl. If there's a R package that does exactly what I need, then I stick with that, otherwise, it's python!
just pickle/unpickle the dict instead of the whole class, much simpler.
It has taken a long time, but they are finally starting to deliver the results promised at the start.
The IronPython open source license specifically grants patent rights.
For anyone interested, you can [view the PDF online](http://docs.google.com/viewer?q=cache:gLyFa5uBHqUJ:www.petertessin.com/TimeSeries.pdf+http://www.petertessin.com/TimeSeries.pdf).
Yeah for vi mode !
Looks cool. It would be nice to have something similar for Windows. Right now, I use [Putty's](http://www.chiark.greenend.org.uk/~sgtatham/putty/) [plink](http://the.earth.li/~sgtatham/putty/0.53b/htmldoc/Chapter7.html) command, but since that only allows one command line to be run per invocation, I put a deployment script on my server and use plink to call that.
You can use [RPy](http://rpy.sourceforge.net) to solve this issue. The not-yet-released version 2.1 truly rocks, as you can import R libraries and use them as if they were modules.
Django becomes a lot less constraining if you start thinking of it as a required core abstraction (view functions / request and response objects / URL dispatching / middleware), some extremely useful optional components (templating, the ORM, forms, caching) and a bunch of use-them-if-you-need-them pieces (the stuff in contrib e.g. auth, admin etc). You shouldn't feel at all cautious about ignoring the optional stuff if it's not exactly what you need for your project, provided you're willing to give up on the benefits of being able to easily integrate with third party Django apps. The auth module is probably the least flexible / most coupled part of Django right now. I've ditched it in a few of my projects, but doing so does dramatically reduce the number of reusable apps you can take advantage of. I don't use that many reusable apps in my projects (at least not the ones that provide their own models and views - I love using other people's middleware and plugins) so that doesn't really bother me too much, but it depends on what you're trying to do. There's been some talk of addressing this problem on the mailing lists, so it might end up on track for 1.3 or later. Personally I think the answer might be for auth / users to be an abstract interface rather than a concrete model, to make it easier to swap in alternative implementations. There are a few ways you could go about building multiple sites that share models. If you want those sites to also share data, you can use django.contrib.sites - it's a pretty basic concept (have a "site" ManyToMany field on any models that might be shared) but it's a pretty decent approach. If you don't want to share data, you need to remember that a Django "application" is just Python code that sits somewhere on the python path. To use the same app in multiple sites, just import it. Each individual site should have its own settings.py and urls.py files, but there's no problem with them importing each others code. Little-known fact: the admin can be decoupled entirely from the standard User model by overriding a small number of methods on the ModelAdmin and AdminSite classes. If you want to use your own user model / auth scheme, it's not a lot of code - but you do have to dig in to the admin module to figure out what to override.
+1 - Learned something new today
It's hacky because it requires JOINs all over the place just to add a few extra user fields. A far better solution would be to make the User model itself a setting - say `AUTH_USER_MODEL` - and use it with a function like `get_auth_user_model()` to drop it into reusable apps. An abstract base model could also be included with the baseline functionality required like `is_authenticated()`. You could then customize any way you want. If I could have one thing fixed in Django contrib.auth would be it - it's far too generalized and constraining for real-world use. I think the hack is because model inheritance wasn't available when Django first came out and people have a common need to add their own user fields without monkeypatching. It should really be deprecated.
Its possible to subclass auth.User and force django to use your custom subclassed version wherever possible. Google can help you find the details of how to accomplish that. I've built a similar site with different user types, and at the time I also used AUTH\_PROFILE\_MODULE which I agree was a little hacky-feeling than it needed to be. 
OK. I'll explain my desired usage a little more clearly. Imagine that I am selling a hosted white-label newspaper package. I have the following user types. * Super users, who can manage the white-label accounts. * White-label admins and editors who can modify content and manage users within their own CMS (including granting permissions to users). * End users, who can post comments, vote, etc. on the frontend of a single white-label site. These three user types are completely seperate. They will never, ever interact. Trying to shove them into the same model is just ignoring data integrity for ease of use. My problem with the contrib.auth module is that it provides heaps of helper functions and views, but in doing so decided that user authorization, sessiong management, authentication and management were all exactly the same thing. Ideally I'd like to be able to say "Here is my user model. The login and password fields are x and y" and immediately be able to use the supplied views and forms. Likewise I should be able to say to the authorization layer that "x is my current User" and have the authentication layer query that object whenever a check needs to be made. Based on simonw's comments I think I might just scrap the auth modules and write my own user logic. It just seems like a shame to scrap all of the contrib.auth module because only a few things don't work
That works for your own case, but not if you want to use it with 3rd party apps. For example, you have something like this: from django.contrib.auth.models import User class SomeModel(models.Model): user = models.ForeignKey(User) As most 3rd party apps will do this, you lose one of the selling points of Django - the app ecosystem. Instead you could have: from django.contrib.auth import get_user_model class SomeModel(models.Model): user = models.ForeignKey(get_user_model()) or even better: from django.contrib.auth.fields import UserForeignKey class SomeModel(models.Model): user = UserForeignKey() The user model would be by default auth.User but could be overriden in the settings. 
&gt; The auth module is probably the least flexible / most coupled part of Django right now. That's actually reassuring to hear. Given it was one of the first modules I encountered it made me stop and wonder if that was how *all* of Django is put together. I did see the contrib.sites module, but it's not really what I'm looking to. I explained to druski my requirements a little more. I did manage to extract my models into a seperate modules, so that part of the puzzle is solved for me. 
In your case, I think I'd keep django.contrib.auth and use it just for the super users, then roll my own auth scheme for the other two categories. You're obviously determined to keep the actual models completely separate, which is a perfectly reasonable thing to want - I'd personally probably use the same model for all three and use Django's Groups to distinguish between them, but I understand why you would want to have separate code paths for them.
They claim: from Foo import Bar makes module dependency tracking difficult. I agree about import *, but the above is fine.
For multiple sites, have separate Django instances with separate settings files, URL conf and SITE_ID, serving different parts of the URL space, but sharing the rest of the Python code. If you need multiple auth schemes, implement multiple auth schemes. (I have done so in one of my projects). The provided functionality gives a head start to common functionality that many people can use out of the box, but it is not intended to cover every possibility.
Thanks. I was getting the impression that's what I needed to do. It would be nicer if the components were more losely coupled. It seems to be a little bit of a bait and switch: "Look how easily you can build things in Django. Oh, you want to customize it? You'll have to build your own components from scratch."
It's like LaTeX :)
Maybe Pylons might bette suit your need.
That's not really fair. There are a huge number of options for customisation - just look at the number of keyword arguments in contrib.auth.views, for instance. And look at all the re-usable components in contrib.auth.forms. The auth.User model is admittedly a sticking point, but it is kind of inevitable - database structures are not as flexible as code. And designing a genuinely flexible and completely generic interface for a user model is harder than it sounds. 
Port it to NetBeans, damnit!
Fair enough. I did have a look at the forms and views. I was under the impression that they seemed to be tightly tied to the models. For example from what I can see the password reset functionality is not usable because (for example) PasswordResetForm references the User model directly. Some could be salvaged though. I'll have to see how much customisation can be achieved with load_backend(). 
I love NetBeans, but what will become of it now that Oracle has it?
I hope it'll become better :(
Understanding what you should be customizing requires to you realize that auth falls under contrib and not core. There is a reason contrib exists :)
You can specify models in "app.modelname" format as well, so something like this should work. from django.conf import settings user_model = settings.USER_MODEL if hasattr(settings,'USER_MODEL') else "auth.User" class SomeModel(models.Model): user = models.ForeignKey(user_model) Then you can just put USER_MODEL='myapp.CustomUser' in your settings.py
As far as frontend/backend sites are concerned, you can write some middleware that switches between multiple sets of urlpatterns based on a user's authentication status (or anything else for that matter) rather than implementing multiple sites.
I mostly agree with you. It depends on how vague/generic the naming is. Using their example I agree that import sound.effects.echo is preferable over from sound.effects import echo. I also wouldn't do something like from os import path... path could mean a lot of things, so there it is better to be explicit. But yeah, most of the time you're importing modules with clear, obvious names. There's no way I'm going to type PyQt.QtCore.whateves like that.
I wish I could use PyDev on something other than Eclipse.
all monolithic frameworks have these drawbacks.
Sure - but having a function or custom field to abstract this would go a long way to encourage its use with developers of 3rd party apps. 
Overloading the user class is a good way to start customization for a simple reason: it keeps the old User class around for third-party tools to use. Since those parts only know about the old User model anyway, it's not a big loss. Throw in a custom authentication backend to return your overloaded OwnUser model instead of the User model and you get most of what you want by still keeping most of the contrib stuff available. With Django I often discover that the most important thing is to know when to cut connections to predefined things and roll your own parts. So even if you discover that you can't live with even the overloaded User model, no need to despair, since many functionality can be salvaged - and the rest can be easily rewritten. Django is an opinionated framework, so some itching is to be expected when you do complex projects - but then, it's core abstractions are good enough and loosely coupled enough to use them to roll your own higher-level parts. 
&gt; the whole boilerplate being a class definition line? Class definition line and an extra parameter to test functions and an extra indentation level and having to structure your code in a very unnatural way. &gt; Never bought that argument. Try doing testing with py.test or Perl's Test::simple
I am also very baffled at how bad the auth module could be built in such a non-extensible way. I copied the code and basically modified it to something similar you need (base user, derived users/profiles). I also replaced django's url mapper and made an own database backend derived from the mysql backend to extend it with custom filters I need. This could also have been made more extensible, maybe it will in one of the next releases. Last, but not least, I replaced the whole contrib.admin because it is too restricted. Now I have a superset of contrib.admin, including custom filters, ajax update, a basket to select items and do stuff with them and much much more. So you see, Django gets in my way quite often. On the other hand, it is still worth it due to its integrity/consistency and other useful built in stuff. 
Good to hear that it's not just me struggling. Sometimes praise which follows the form "It's good, but ..." is more useful than hearing "It will solve any problem you'll ever encounter".
Good point.
I don't remember what the exact reasons were, but I also had to ditch this approach. One problem might have been that I needed the email address to have the properties unique=True, null=True (first one is just for integrity, the second was absolutely necessary). I also remember AnonymousUser breaking some stuff.
Why?
... if you treat them as a monolithic framework. As I answered elsewhere, the trick is to know when to roll your own pieces instead of using the stuff that comes in django.contrib. That's the difference between using a framework like Django and something like Drupal or WordPress, which make the required bits much harder to swith out.
Have you looked into the authorization framework? You can define custom permissions, &lt;http://docs.djangoproject.com/en/dev/topics/auth/#id2&gt;, and then do permissions checks, &lt;http://docs.djangoproject.com/en/dev/topics/auth/#django.contrib.auth.models.User.has_perm&gt;.
Yeah, that was what sparked my initial post. The auth module bundles models, an authentication system, user management and permissions and presents it as a take-it-or-leave-it package. You can't pick and choose components. I couldn't, for example, implement my own user models and authentication and then use the supplied permission management, because the permissions system makes the assumption that it is always working with the `django.contrib.auth.models.User` model, which doesn't fit my needs. Other commenters have presented some solutions, but the concensus seems to be that for more customised solutions I'm better off rolling my own.
What?
This is a really cool little framework. Reminds me of other great projects that are churning out like [node.js](http://nodejs.org/) and [sinatra](http://www.sinatrarb.com/). Kudos to the author. 
I just started using Django a couple of months ago here's what I did to make my life easier. 1) I took the auth module, rewrote parts and made it stand alone. A requirement of my project is that the email address is the log in username. So, I either had to use the auth or write my own.... But I also wanted it to still work with the admin (or at the time I wanted to). So I went with an auth partial re-write. 2) I have generic site config stuff in the settings file and created a site_settings file with all site specific info. This allows me to have different db settings, etc. 3) I put the templates for each module under each module. So under my improved auth dir I have a templates dir. Then I just hook that back up in the top level settings file. 4) I don't use the admin stuff. It's more trouble then it's worth IMHO. My goal is to keep everything as 'drop in' friendly as possible. So, if I start a new project I can just copy over a directory and do some minimal configuring in the settings file. I have to say one thing I don't like about Django (coming from 4 years of Rails) are the Forms and the template language. The template language is too constraining and I always feel the Forms are mainly duplication of the Model with some extra stuff. I'm a big fan of the ActiveRecord pattern vs Djangos ORM. But one thing I do like about Django is that it is not this huge monolithic beast that tries to give you the power to make a site in two lines of code and then switch how the world works every 6 months (I'm looking at you Rails).
Django's positioned right on the line between a monolithic framework and a toolkit. I use it a lot and try to keep things as vanilla as possible, but as other posters have said, you can replace components more easily than with most other integrated frameworks. That's why I keep using it-- it generally does more than 80% of what I need out-of-the-box. When it doesn't, I use something else, like Werkzeug or Pylons. So there are options if you really feel that the shoe is pinching too much. I'd strongly urge you to be systematic about understanding how much customization to Django is needed in order to meet your requirements, and trying to find the design alternatives that are more out-of-the-box wherever possible. One example of that emerged in the discussions about your user model-- there's often more than one way to accomplish something, and some of them will require less tweaking (and will be more maintainable) than others. So it's a mini-case of software engineering: you need to be really hard-assed about knowing when you've reached the point where your chosen solution doesn't meet enough of the requirements to make the constraints of the off-the-shelf solution worthwhile. Custom's always a better fit. But that doesn't imply that its total cost of ownership is the lowest.
From the page: &gt; Bottle runs with Python 2.5+ and 3.x (using 2to3) 
The one file is a nice feature. Now I wish there was session / auth ...
I like the paths as decorators. It's much more intuitive than urls.py in django, although the use named urls in django templates are nice.
To see the magic happen ... cd /tmp curl -O http://github.com/defnull/bottle/raw/master/bottle.py curl -O http://dist.schmorp.de/libev/libev-3.9.tar.gz tar zxf libev-3.9.tar.gz (cd libev-3.9 &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install) sudo easy_install fapws3 cat &gt; server.py import os print 'kill -9 %d' % os.getpid() from bottle import route, run from bottle import FapwsServer @route('/') def index(): return 'Hello World!' run(host='localhost', port=8080, server=FapwsServer) python server.py
Requests per second: 5345.35 [#/sec] (mean) ab -n 10000 -c 100 http://localhost:8080/ 
I made [this](http://imdbapi.poromenos.org/) with bottle. Barring a few database errors I can't trace, it's great, I like it a lot.
Missing sessions seems to be a thing in new frameworks. There is no session support in Tornado, too. There's a FAQ for bottle, though: [How to implement sessions?](http://bottle.paws.de/page/faq#how-to-implement-sessions) &gt; There is no build in support for sessions because there is no *right* way to do it. Well, there's no right way to implement a template system, but bottle has one. But the FAQ has an example of how to solve this with beaker.
FUCK YEA.
Just a side note: What's the benefit of using 3.x?
I remember that, I came across it a while ago. Didn't know it was made with Bottle.
This is with the "select" backend, with epoll or kqueue it's probably much faster but I could not figure out how to config that. Looks like it's libev that decides. static PyObject * py_run_loop(PyObject *self, PyObject *args) { char *backend=""; ev_io accept_watcher; ev_signal signal_watcher, signal_watcher2; struct ev_loop *loop = ev_default_loop (0); switch (ev_backend(loop)) { case 1: backend="select"; break; case 2: backend="poll"; break; case 4: backend="epoll"; break; case 8: backend="kqueue"; break; } 
Anyone has an idea how it compares to Werkzeug?
It was, it's really simple so I didn't want to use full-blown Django for it, and bottle was the one I decided on after playing a bit with juno et al.
&gt;What's the benefit of using 3.x? using 3.x
This is pretty impressive. Someone should run with this (i.e. make a better IMDB)
Thanks! I made it for people (myself included) to use with video renaming scripts...
Kudos on writing the episode renamer. Something I've been meaning to do for years now and will definitely use.
Thanks! Please report bugs if you find any!
It's more a micro framework like web.py 
[sigh](http://instantrimshot.com)
I use Django at my start-up for API's, web interfaces, back- end administration, and the website, and it is amazing. Everything you need is there, and built into standardized places. Don't forget it is all just python in the end. If you want to use model between apps, then just import them. The auth is just so there is standardized auth between apps so they can share it. You can write your own for an app, it's easy to do with middleware. I have used everything there is. Java everything, .Net, rails, PHP, nothing does the job like python and django. All the built-ins are amazing, the ORM is amazing, not using them is just as fine. Stick with it.
&gt; i.e. make a better IMDB They're trying. http://www.themoviedb.org/
how does is compare with web.py?
It doesn't seem like a good idea to me. Surely it's a good idea to have one place that you can see your entire URL scheme?
No need to compare. They are both designed for pretty different tasks.
Looks a lot like [Juno](http://github.com/breily/juno).
Have you used some of the more bare-bones frameworks? It's probably worth your while to give them a try. You may find something better suited to your tastes, or you may discover that the grass is not really greener, and appreciate Django more for all of the stuff it helps you with.
Eric4 looks very interesting, will give it a try. Thanks!
Bottle absolutely rocks as a super lightweight embedded webserver/framework. I just used it last month to add a simple web front end for a console app of mine and it was so quick and easy. I think it was just a few dozen lines of code and presto, my app was web enabled. Many thanks to the author! As someone else mentioned, the fact that it's just a single python file with no other configuration files is really nice. If you're looking for a full-blown advanced framework then you're best looking elsewhere (django, web2py, whatever). If all you need is handful of relatively simple routes/urls/pages, though, Bottle could save you a lot of time and hassle. 
And to CherryPy? 
Except that Juno seems to be dead. 
 @route("/foo") def foo(): return "foo foo foo!" Instead you can define `foo()` somewhere and then let `route()` wrap it. Like so foo = route("/foo")(foo) Now put all `route()`-Parameters and functions in a convenient data structure/collection and you have all your URLs in one place. 
Werkzeug seems to be designed to attack users and maintainers of other web frameworks. But maybe it's just web2py … 
You can always query the Route object at runtime to do this (say in main, or in test functions, or a sitemap generator). Me, I prefer to be able to write code in one place to do one thing, and to be able to find out where a request is going by using grep instead of having to bounce through multiple files looking for it. Not to mention understanding object/method/argument style routes which lead to Javaesque code where the object has no reason to exist ...
same thing again, then I'll repost my answer: have look at http://www.cubicweb.org which addresses your problems (and, I guess, the getting-out-of-the-defaults problem monolithic frameworks have) 
A numbered list would be more readable.
In web.py you define all your routes in an array, as the first argument to the web.application method. Each route also gets an associated class. In Bottle, each route is defined by a function decorator and is associated with a function. You could see that by comparing the front pages of both web sites.
Thanks. I guess I was wondering what the advantage or specialization is
&gt; I expect that there probably other code or tests that are broken as well. I can't trust this review.
If you just have some basic functionality or api you want to expose via a simple web interface then Bottle's simplicity is perfect. To borrow the example from their homepage, this is really all it takes to web enable a function in your program (in addition to adding the "bottle.py" file to your codebase) : @route('/hello/:name') def hello(name): return 'Hello, %s' % name Then add this one line to your main: run(host='localhost', port=8080) If you're doing a whole website or lots of pages and forms then bottle is probably too simple and you'll need a "real" web framework.
Eek! Another framework. I'm still trying to look at web.py, web2py, CherryPy, Pylons and of course Django.
Werkzeug is not really a framework, but a library. You could write your own Bottle using Werkzeug in, like, 50 lines. I &lt;3 Werkzeug.
And you are basing this on what?
Well, if by attack you mean 'show up' then maybe...
I would very strongly argue that structuring your 'code' in an object oriented way is not at all unnatural. In fact I know quite a few folk who use py.test but still use an object oriented style for testing.
I don't understand how your comment is relevant to the development of this Python application. Torpia ToS does not prevent the writing of such things, only their use.
Too true, sir. Too true.
Multiple encounters of fights, negative remarks whenever web2py is mentioned (last time in a German language Python newsgroup, a few days ago), and http://www.reddit.com/r/Python/comments/ahm50/a_crash_course_in_w2p/c0hrwr3
i think i was quite explicit about me not representing werkzeug or its community making anything else out my personal reasoning/opinion (which tends to be at least harsh) is just dishonest
You mean like '25 ways to distribute Your Python Application?'
It already has vi mode long time ago. What impress me mostly is Code Auto-completion ability and It's Debugger.
Ronny is not a contributor to either Jinja or Werkzeug. (except for very few patches maybe)
So, in summary: distributing python source applications still sucks and requires external invocation methods and/or special command-line arguments. I'll stick with freeze, py2exe and py2app thanks. (by the way, source is still available in those options, it's just a little harder to get at.)
Just because people have negative opinions of web2py doesn't say anything about werkzeug...
Not a good excuse. It'd be very nice to implement authentication using decorators.
Because of *one* typo in an unedited blog post? Or is this some of that irony/sarcasm business?
wait a minute, I don't know about wordpress, but in drupal land you can write your own or use a plethora of plugins that might do the job. That's not unique to django. And largely I agree with you, you are right, the trick is to know when to build vs. borrow/buy. I was saying that that is the drawback of monolithic frameworks. that's not to say that those same frameworks don't have other benefits however. 
Don't hate me, but I'll add one more thing to your list - Werkzeug, which is a library that allows you to build your own framework, easily.
&gt; who use py.tes but Use an object oriented style for testing. That's quite all right. As long as it is the programmer (as opposed to the testing framework) who decides what's best for him. The problem with unittest is that it forces the programmer to use Unittest's objects and rely on specific sequence of calls for something which ought to be much simpler. I guess we'll have to agree to disagree.... 
Who cares? It's one example among others. Like http://news.ycombinator.com/item?id=175694 
It's mostly from the werkzeug people/users. As in the newsgroup I mentioned, as in http://news.ycombinator.com/item?id=175694 etc. 
I feel like the distribution of python applications needs to come together and follow item 13 on [The Zen of Python](http://www.python.org/dev/peps/pep-0020/): There should be one-- and preferably only one --obvious way to do it.
Oooh, I like this. Thank you.
I used [gui2exe](http://code.google.com/p/gui2exe/) on a project a while ago and it worked wonderfully. 
Not a single werkzeug developer wrote anything on that hacker news submission.
You yet have to show me something from an actual Werkzeug developer (which would be me). I am not doubting that you can find something, especially from very early when web2py came out where I did not show much respect for web2py, but those are examples based on actual facts. And that btw has nothing to do with Werkzeug, just with some really ridiculous design decisions made by mdp very early. Some of that probably got fixed, but I am not convinced enough to even closely consider web2py. On the other hand: I consider pylons and Django nice frameworks, what does that tell you?
The downside of the decorators is, that you have to import all the views before the server runs for the registration to kick in. The advantage is that the URL rule is closer to the function.
 * Author doesn't understand tuples and have seemingly ignored the `SyntaxWarning: assertion is always true, perhaps remove parentheses?` message you get by doing that. * `!= None` is bad form. Do `is not None` instead.
That looks quite interesting. I've been playing with Pylons and CherryPy, and leaning towards the simplicity of CherryPy. Have you used Werkzeug? What are it's advantages/disadvantages over something like CherryPy (and is there a "starter" app I could download and experiment with without having to build a framework stack from scratch?)
&gt; You yet have to No, I don't have to. Play your games elsewhere. 
You might also be interested by http://github.com/benoitc/gunicorn which might be easier to install (albight unix-only) and as fast as uWSGI.
Well, if you're not into Eclipse (though, I'd like to know why Eclipse is bad. I've been seeing a lot of people put Eclipse down for some reason), have you tried [Eric](http://eric-ide.python-projects.org/)?
stesch, you said the negative opinions are "mostly from werkzeug people/users". Well, you can't blame Werkzeug if it has some users who don't like web2py. Now, as for werkzeug "people" (developers), as mitsuhiko points out, he doesn't see any comments there from from Werkzeug devs. 
Thanks, I'll take a look. 
OK, this: http://www.python-forum.de/topic-13752.html#92081 
I said "Multiple encounters of fights, negative remarks whenever web2py is mentioned". This is my observation. And I don't bookmark everything in case I could use it later. These are silly games. Last time I mentioned web2py in a German newsgroup, somebody gave this link: http://wiki.python.de/Web-Frameworks#web2py On this page are three links http://www.python-forum.de/topic-17057.html http://www.python-forum.de/topic-13752.html http://www.python-forum.de/topic-17145.html with Werkzeug fans and mitsuhiko. Later in the thread Georg Brandl took part. He is mentioned together with Werkzeug on http://dev.pocoo.org/ Thread starts with `&lt;0T6ma672I4e4Nv8%stesch@parsec.no-spoon.de&gt;`
FTR, I wrote a relatively simple library that makes choosing between locality of reference and import-time-side-effects-required a little less painful: http://docs.repoze.org/venusian/
The Web-Frameworks page does not even mention Werkzeug except for naming it as not being a framework in the pretext. So how is that related to Werkzeug? python-forum.de: First thread, not a single pocoo guy involved, second thread, yes I did complain about web2py, based on the problems I still have with the code [exec for modules, database schemas being re-evaluated each request and more]. Third thread, not a single pocoo guy involved either. If you start picking me for not liking web2py, what about asking Ben Bangert, Ian Bicking, Jacob Kaplan-Moss or any of the repoze guys about their opinion about web2py ...
Is this better that running with FastCGI? Why?
I coded under that standard for almost five years, and I initially chafed under that rule, but later decided they were quite right. The big advantage is that if you see an unqualified variable, one with out a something. in front of it, you know you're dealing with either a local variable, or a global variable... and global variables will be in UPPER_CASE and hopefully quite rare too. There are other advantages too - it helps avoid variable collisions, for example, and it makes searching for all calls to a module much easier. The amount of extra typing is tiny - and you save all that time the very first time it saves your ass in debugging.
I don't even know you. I see web2py bashing, I see werkzeug. That's all. 
gunicorn is event driven (relies upon the os for the poll the non-blocking asynchronous calls) and not thread based. According to this french blog, a simple hello world WSGI app runs three time to four times faster on gunicorn than flup and takes a lot less memory when you have a lot of concurrent connections: http://geekfault.org/2010/03/01/nginx-et-python-le-perfect-setup/ I let you google translate it yourself.
Typical Django apps are like "hello world" examples nowadays? 
Great idea, I can really see this helping with code reuse and legibility.
also this makes urls more readable for people not used to regex. like it.
I have not tried CherryPy. But I recently started with Werkzeug. The werkzeug manual comes with a tutorial which pretty much builds a simple stack. Some things you'd have to figure out, like how to get auth working with it. It is definitely harder to use than a full-stack, because you have to learn and know more. But learning more is why I switched to it (that and finding the other framework I used to be a hell to bend to my needs). I think it'll pay off in the long run, since I'm the boss and know exactly what is going on.
The syntaxwarning was only added as of python 2.6. Not really fair to assume he's just ignoring the error, plenty likely he's running an older version. Though it is pretty dumb it was being ignored. I remember running into this as a newb running python 2.3 a few years back. It makes total sense when it's explained, but it's easy not to realize on your own especially since the assert appears to be doing what you expect (not failing on valid values), then you get stuck debugging some code that *should* be triggering an assert error and it doesn't. Pain in the butt. I'm really glad the warning was added.
It makes them more readable for everyone.
agreed.
While I don't think your library addresses mitushko's downside, I appreciate the clarity with which you have explained why non-mutating decorators are desirable. OTOH I don't see the startup cost of a bunch of imports as significant (especially vs failing fast), and decorators like this can be used as functions in one location if you want to build up routes in one place, so it's win-win-win!
Thanks, man! Email me at rich@anomos.info we can chat more!
I find the regex more readable :/ Rather, not more readable, but more precise. I don't know what "slug" entails, but I do know what A-Za-z0-9 does...
In bottle, you can add new routes at any time, even from within a callback while the server is running. If you want to define your callbacks first and add the routes later, you can use the decorator as a normal function: def func(): return "Hello World!" ... bottle.route('/url')(func) It is possible to simulate the web.py or django behavior (routes stored in a list) with __import__ and a simple a for-loop, if you really want that.
The bottle.route() decorator returns the callback function unchanged. It stores a reference to the function object, but neither wraps nor manipulates it. Venusian still is an interesting tool, thanks for the link.
You only have to learn what "slug" means once.
I wrote a simple template to get started with Werkzeug+SQLAlchemy apps that might be of use to you: http://pypi.python.org/pypi/satchel/0.1.6
as a python and programming beginner i found the need to use regular expressions for url mapping in django quite a pain. there is definitely a need for a more readable syntax... nice to have it with django-selector.
While I don't have to learn anything new to parse a regex.
Ever heard of "return on investment"?
It might be a good idea because it makes urls more readable for some people. However it might be a bad idea because it adds a level of indirection (one must know the patterns to understand such an url) and thus makes it more difficult to read for other people. Obviously the author doesn't like regexps -- two of them are wrong, i.e. do something else than the descriptions say (namely *number* which allows even "p4" or "4z3" and *chunk* which doesn't only forbid "/" and "." but also "^").
Yeah, besides testability, the docs should probably concentrate equally on the fact that you can get locality of reference without requiring that all participating modules be imported by the user. Thanks.
The ROI for learning regex is far greater than learning some framework specific magic keywords. That said, if this can be used in tandem with regex then it's a positive contrib; options are always a good thing.
The downside he expressed was "you have to import all the views before the server runs for the registration to kick in". I think venusian does address this. If you use something like venusian, the user doesn't need to remember to import every module that potentially has decorated objects in it; he just needs to run a scan against a package, and venusian will find all the decorated objects in the package and all subpackages. 
Everyone new to django-selector will have to look up the docs in order to define an url. Even if you know django-selector, you will most likely not remember what built in named patterns you have. 