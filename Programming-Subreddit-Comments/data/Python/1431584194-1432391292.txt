Mixed with Haskell lenses.
ok :)
It will be. Got swamped with moving. Will ping you when it gets there ;)
Take a [look](https://github.com/lihaoyi/macropy#examples).
This little tutorial is calling for a github repo &amp; some pull requests :) 
I made a repo, but it quickly evolved into much more: https://github.com/cslarsen/crianza I'll update the post with all of the suggestions here, though!
or you're on python 3, I love not having to state the encoding in each file anymore
Actually, not just code but comments as well, which is the biggest problem when you are teaching programming in non english speaking countries. Anyway, most students will want to print() in their language at some point, and Python 3 is so nice for that. 
Their 2.5.1 release targeting python 2.7.6 is "production ready." Their STM and mult-core progress, not so much. Haven't used PyPy3 yet because most of my development is in Windows. [These pages](http://speed.pypy.org/changes/) will show what you're looking for.
Yeah and it sucks. Python was already "slow" and it doesn't seem to ever get faster.
This is very cool. Does it also work when I import seaborn just for the better style of the matplotlib figures? I sometimes lose the background with some export options. I will definitely try this out. Thanks.
One huge reason Python is slow is because of its very dynamic nature. Type Hinting one part of the way to fixing this. It will enable better code to be written, and it will allow more optimisations at runtime. Type Hinting is being actively worked on. In the meantime, are you actually having trouble with performance in Python or is this just window shopping? We can probably help if you can show some code. One of the "problems" Zend has is that HHVM could one day become a hostile fork, and it could pick up a big enough following to seriously screw them if it does. EDIT: Because people can't read: One day, at some future time, when you sit down to build an optimiser of some sort, are you likely going to find the type hinting helpful? That was the point of the phrase "type hinting will allow some optimisation".
A web based IDE was released recently called [rodeo]( https://github.com/yhat/rodeo/blob/master/README.md) that you may like. It is taylored for data analysis.
No, I didn't. And why don't you stop repeating yourself and start explaining how to do it properly? 
Its funny that python is also helping make php faster [and creating competition with zend] http://hippyvm.com/ php vm implemented in python via rpython/pypy.
I think part of it is just perceived difference. Take a gander over at https://www.techempower.com/benchmarks/ to see how common web stacks compare. You'll notice that PHP frameworks tend to be pretty slow - the only good results with PHP tend to be staying close to the metal using as little PHP code as possible and just calling C extensions. Similarly, Rails tends to have fairly lack-luster performance, even with JRuby. You'll notice Python tends to be a bit faster, such as the Bottle library. Anecdotally, I think part of the reason for continuous improvement on the PHP side is because it was fairly inefficient in the recent past. As recently as PHP 5.2, when I was doing quite a bit of PHP, a standard variable box would take 144 bytes of memory. Because of this, a 3000x3000 element array of integers would exhaust 128MB of memory! While I haven't seen big improvements in Python performance since I started using it, it has seemed overall faster and more efficient than PHP and Ruby. JS and Lua are the two dynamic languages I've worked in that seem significantly faster, but both are far less feature-rich. It all depends on your use case.
The problem with PHP isn't the speed, it's all the irregularities with the languages and how features feel bolted on. Until they get a 10x speed increase and compete with Java, it's not a big enough factor to be a major reason to choose PHP over Python or Ruby. In your f normal en app, your biggest bottleneck it's still going to be the database written in C.
There's the Dropbox-sponsored [Pyston](http://blog.pyston.org/) project: *Pyston is an open source Python implementation that aims to be both highly compatible and high-performance. It uses modern JIT techniques on top of LLVM, and natively supports many CPython C extension modules via a recompile.* *Pyston is sponsored by Dropbox, and is pronounced “piston”.* [Pyston GitHub](https://github.com/dropbox/pyston) [Pyston mailing lists](http://lists.pyston.org/cgi-bin/mailman/listinfo)
A library or your own impl.? I'm also very interested in that topic
I've now updated the post with your suggestions. Thank you all so much! The code's also available at https://github.com/cslarsen/python-simple-vm
I guess it depends on your use case. I've been working on a PDF parser recently and I get about 20% better performance from 3.3 than 2.7 and 3.4 is about 25-30% faster than 2.7. New features in the 3.x branch can help improve things also. As I've been working on some crypto stuff, the addition of int.to_bytes and int.from_bytes in 3.2 improves performance since you don't have to write a loop to do it yourself.
&gt; I think running search-and-replace on code non-interactively is really dangerous honestly. Why is it dangerous? You have type checks, unit tests, integration tests, simulation tests, user acceptance tests, linting, code reviews, and a solid release strategy in place, right? The automatic edits aren't designed to be perfect, I just want them to cover 98% or so of the cases, and then my build infrastructure spits out the parts that stop working, and I fix those. It means I'm still automating 98% of the workflow. If you need to manually look at every change, then you have a pretty serious problem IMO.
Javascript V8 has a JIT. It should be compared with Pypy and not Cpython. Unusual that your emotional state is relevant to the facts of the argument. Can we discuss this rationally or will your emotional issues take over? :-) A dynamic language isn't going to be a quick as a statically typed one, at least on current hardware and all other things being equal. Hence Python is slow due to being dynamically typed is a valid argument.
Javascript is fast DESPITE its dynamic nature because browser vendors spent millions of dollars just to optimize it. Now the Python community has very (very : http://pyfound.blogspot.fr/2012/01/psf-grants-over-37000-to-python.html) little money to pay anybody to work on it. Since making a dynamic language fast is **hard** and we have few ressources, it's a very good argument I'd say. It's not a low handing fruit.
Pypy's usually faster than node.js, in my experience.
Login to pypi and delete the current version. Then upload the corrected package.
Yes I tried, and the old version release has been deleted, but the server still responded "Package is existed".
Web is slightly slower in Python 3 due to changes in strings. When discussing Python in the context of comparison with PHP, web's quite important since almost no-one is using PHP outside of the web domain.
I use PyPy at work for ad real time bidding, and have to micro optimize everything because of stringent response times (think 300k requests/second at peak, each each response handled &lt;30ms). PyPy definitely helps here.
I must have imagined that is what I did in the past but its been quiet some time ago.
You were able to do this in the past, but apparently the only thing that ever happens to PyPI is that it gets worse over time.. this ability was intentionally blocked about 3 months ago. There is a distutils-sig thread discussing it IIRC. I think it relates to how their CDN works.
type hinting is not going to be used for optimization or ahead-of-time-compiling. its primarily intended to make tools like linters more powerful.
Note: I haven't made the python3 switch yet so some of my advice might be obviated... You can write straight to b's variables if it subclasses object, so: b.Acard = easygui... I am guessing you're asking how to get the result from the gui choice as an internal variable to b. I would personally have cards from a flyweight class (think singleton factory based on a parameter, such as a card identifier). That way you don't have multiple copies of the exact same object floating around. I would also bake the card logic into functions in b. Sort of a "player" interface. Such that: b.setChoice(easygui...) But I didn't see you instantiate b. Is importing it retrieving b? Is b an instance? I would also personally run the player class for b as a singleton type of think, kind of like how logging works where you can get a specific logger anywhere by requesting it.
Ah thanks!! when I first answered I was 100% sure I did it like that but it was more than a year ago if not two. When OP says it did not work, I started to doubt myself LOL.
For now. Of course, now it's here, people will ask for more. Wait for the 3.6 debates on the Python-idea then python-dev mailling list. My guess is the hot topics will be : packaging, multi-core, more asyncio stuff, mobile support and... making the VM optimize code using the type hints.
One day, at some future time, when you sit down to build an optimiser of some sort, are you likely going to find the type hinting helpful? That was the point of the phrase "type hinting will allow some optimisation".
One day, at some future time, when you sit down to build an optimiser of some sort, are you likely going to find the type hinting helpful? That was the point of the phrase "type hinting will allow some optimisation".
No plans yet, but it may have benefit one day, or to a different interpreter.
Mmm that's a shame. I personally really like the Matlab notation.
I think you've missed the point. The reason you are not seeing OOP and concurrency together is because they are essentially orthogonal. Functional programming has risen because of its inherent proclivity towards concurrency.
This is really great news! I've always hated the functional notation of numpy, this will make things way nicer!
I have interpreted your answer as "This is the stupidest question eva", which is the correct answer so I have added a point back to adjust for the dumbass who subtracted one in his absolute indolent ignorance while pursuing his futile attempt at a meaningful life.
If 484 is accepted, there will be debates on how to gain runtime performance from using it. There's no doubt in my mind about that. However, until 484 is accepted, it's a moot point to talk about 484 as anything other than an IDE hook.
This is discussed in the linked PEP.
&gt; I'm not a fan of the @ symbol for multiplication It just seems 'wrong' to me. What do you think of the bullet instead? A • B 
r uses %*% for matrix multiplication.
They do. numpy has a `matrix` type. If `A` and `B` are of type `matrix` then `A*B` will do matrix multiplication.
Why do virtual box again? Just to be able to move it to servers? You know you can clone environments with [virtualenvwrapper](https://virtualenvwrapper.readthedocs.org/en/latest/) or [pyenv](https://github.com/yyuu/pyenv)? You dont need to run all that overhead to simply isolate dev environments.
Read semver.org, there is no problem whatsoever to bump the third digit and re-release – that is that the micro version is for. Release versions are supposed to be *unique* identifiers.
Posting code to this subreddit: Add 4 extra spaces before each line of code n1 = raw_input("Choose any number") ... Tell us what errors you are receiving. This should be posted in [r/learnpython](http://www.reddit.com/r/learnpython) Lastly, you seem to be enclosing many of your [variable](http://www.learnpython.org/en/Variables_and_Types) names in single quotes. If you ran this code you would be getting "Can't assign to literal" errors, because a string is not a variable and can't be assigned to.
They considered it but decided that including unicode operators was probably a bad idea.
That's basically what I was saying. Whenever I hear the word liberty, I always hear the lyrics to team America.
That was brought up in the PEP but since Python already has the convention of * for elementwise multiplication we would either have to siwtch its meaning (and break all existing code) or do the exact opposite of matlab where * is elementwise and .* is matrix multiplication. The first option is obviously not possible, and the second option would have been very confusing.
&gt; If 484 is accepted *When it is accepted*, given how Guido is acting. &gt; there will be debates on how to gain runtime performance from using it Which will be shot down. There are no feasible improvement that can be made in CPython and the PyPy maintainers have stated in unambiguous terms that they can't do squat with it.
I suggest you to switch from PySide to PyQt. Its community is active and has better documentation.
Not so related question, is numpy matrix multiplication as fast as matlab?
&gt;I can't accept that type hinting will have zero effect on future code optimisation. *That's not what I'm saying.* I'm saying, as written, PEP 484 only talks about using function annotations as IDE Hooks. That's it. There's no runtime optimization, type enforcement or cross-compilation *as proposed*. PEP 484 *isn't even accepted yet*, so going on about how it'll be the future of Python optimizations is jumping the gun a bit. If someone wants to build a Python-to-C transpiler, that's great. But that's outside the scope of 484, even if it's leveraged.
I know Guido recused himself from accepting the PEP himself, but I'm unfamiliar with Mark Shannon (BDFL-delegate) and his stance on type hinting in Python. But I doubt he's completely opposed to this proposal.
Offtopic but I'd love to see what that code would look like in a language such as haskell.
Matlab comes with MKL, numpy can be linked to it. Not sure if there's a special case for small matrices, but for large ones, it won't matter. 
Do your users a favor and bump the version. Having versions with the same version that aren't in fact identical will cause headaches for those users who are less familiar with your package than you are (i.e., all of them). Nothing wrong with updating the version for a small fix.
This is exactly what I was trying to do. It was a learning exercise
I wasn't trying to find the best way to download all of the xKCD comics, I was trying to learn about web scraping and make a neat script for myself that would be useful
I didn't know that Pastie links expired! That's another reason that I'll be posting future projects exclusively to GitHub
And it's good to remember any PEP can be discarded at the last minute from the release. The proof is that TransformDict (PEP 455) has been removed from it just a few hours ago.
https://github.com/Vault-Hunter/xKCD-comic-Downloader/blob/master/xkcd_update.py
"Speed" has to be defined better. Are you referring to speed of **development** -- e.g. the quality of the standard library, cheeseshop, etc. -- or **execution** -- e.g. how fast a given piece of code runs? As the growth in developer salaries far outstrips the growth in energy consumption, I'm going to lean towards the platform that's faster to develop with.
Using class `matrix` is discouraged though. And though it has matrix multiplication via the \* operator, it requires a method call for elementwise multiplication, so it's basically the opposite of the `ndarray` class, not better than it.
By sharing it, you are allowing other people to critique it. This can be extremely useful if you are new to Python, or if this is your first project. My advice: If this is a hobby project of yours, go ahead and share it. Someone else might get some use out of it.
How is polymer going?
I'm really liking it. Since I was learning flask, I attempted to do the web gui with flask templates but I really didn't enjoy them. Completely separating the REST API and front end is nice and the data binding in Polymer isn't too difficult - though I am admittedly not incredibly far along with the frontend as the backend has proved to be trickier than expected.
Get thee a github account and upload that sucker.
It's so pip can cache all packages locally
what about kivy
How does java/c# support concurrency while being OOP ?
&gt;And though it has matrix multiplication via the * operator, it requires a method call for elementwise multiplication, so it's basically the opposite of the `ndarray` class, not better than it. And although use of the `ndarray` class has element-wise multiplication via the * operator, it requires a method call for matrix multiplication. Pick your poison.
thanks for taking the time dude! 
By offering libraries named "Threading" and "Multiprocess" (these are just guesses at the *literal* names), and by having the concept of an 'object' in the language. You can spawn a thread that only operates on functions and 'primitives' or non-'object' data structures, or a thread that uses objects. Or the thread can do both. (As I understand it, Java actually forces EVERYTHING to be part of *some* object). Same with spawning worker processes: the worker processes could contain code that is 'object oriented' or it could be 'functional' code. tl;dr the concept of orthogonality is very important to understand. The color of your car and the manufacturer are *orthogonal*. You can have a red Ford, or a Red Chrysler, or a black Ford or a black Chrysler. A language's parallelism capabilities is basically 100% orthogonal to whether the language uses objects, pure functions, or whatever other paradigms there might be.
Upload it to github and make sure to license it. http://choosealicense.com/ has some helpful tips on licensing your open source project.
Json API for streaming music. It's no spotify, more of a winamp for the web. Actual API is mostly functional, I just gotta tangle with building a UI now. D: I'm also considering building a little tool for streamlining my ipynb -&gt; pelican -&gt; github.io blog. Right now it's a simple bash command, but it's pretty sloppy 
In the last week and a half I've had two personal projects in Python that I was working on. 1. A small script to do some network analysis on the Ticket to Ride board game. I ended up using the NetworkX library to generate routing information for the different tickets in the game to see which routes were most useful on the whole. 2. A small program to keep track of daily activities in the MMO Guild Wars 2 via a checklist that resets itself automatically each day. I used Tkinter for the GUI side of things. I'd have to say that my most interesting recent project was making a small program that downloads data from the Weather Underground API and displays a bunch of different weather data. At some point I want to get a small screen that I can connect to my Raspberry Pi and have that running on the display constantly. 
You mean character encodings for email folder names ? Yes, i know that Imap uses modified UTF7 encoding for folder names but you don't have to worry about that. The lib does all the conversion behind the scenes, so if you need to do something with a folder, you use it's "human" name like "Inbox", "Important" or "Входящие". I hope i'll finish adding more examples with samples of code by tomorrow to show the benefits of using the library.
To be fair, it's not exactly *wrong*, it's just less pythonic than range(samples).
I spend most of my time as a ColdFusion programmer.
This does sound like something numpy would be ideal for. At the very least, getting the data into that format would be easy. numpy_array = numpy.ndarray((rows, cols)) for x,y,z in [row.split(',') for row in open(filename,'r').readlines()]: numpy_array[y,x]=z That should be the basic structure to turn x,y,z CSV data into a numpy array with the z as the value and xy coordinates in the array. I'm not positive if numpy has any built-in slope analysis functions, but it's entirely possible that it might be a thing. 
Ah, I see. Imapy uses Python native libs to parse raw email data, so i haven't invented anything here. The goal of Imapy is to provide correct and easy communication with imap server. Correctness of email parsing was not under my watchful eye, however i haven't had any problems with that. I mean email parsing is tested, but not as thoroughly as imap-related operations. Under no circumstances does it mean that i am going to tolerate incorrect email parsing, but as I've written, i haven't encountered any problems with that.
That's all entirely reasonable. But none of it backs up your original statement: &gt; Not really. If anything we're getting slower at the moment. For us to be "getting slower at the moment", 3.x releases would have to be getting progressively slower. They are not, they are getting--again, ever-so-slightly--faster.
Just bump the patch number (&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;) It won't cost nothing. 
I'll keep looking for slope analysis functions, but that should be easy to do once the data is properly arranged. Would your suggested code work when both x and y values would be repeated? For example, a grid of 1 2 3 in x and y would resemble: 1 1 z 1 2 z 1 3 z 2 1 z 2 2 z 2 3 z 3 1 z 3 2 z 3 3 z as an xyz file
Upvoted because I'm actively searching for an IMAP wrapper for my latest pet project. I'll definitely check it out. Thanks!
Thanks for the note, blowjobtransistor
Thank you! You can email me if you have any problems or questions on use.
Yep. Basically what it does is split each line in the file into a (x,y,z) tuple and makes a big list comprehension out of them, then it iterates over that list and assigns the cell value defined by x and y with the value z. 0,0,a 0,1,b 0,2,c 1,0,d 1,1,e 1,2,f 2,0,g 2,1,h 2,1,i 2,2,j comes back with [['a', 'd', 'g'], ['b', 'e', 'i'], ['c', 'f', 'j']] Remember that arrays start counting at zero, so you need to make sure your indexing accounts for that. (I also used a chararray for letters, but a ndarray should be what you need for elevations) One thing to notice is that you need to assign things in [y,x] format into the array (like I did in the initial example) if you want the grid to come out properly when it's printed (when you're accessing it via indexes it doesn't matter, as long as you're consistent). That's because of the way python prints things, because each row is a different list, so you want that to be your outer dimension (which y in [y,x]). 
does anyone even play you anymore
/r/learnpython
If you are so desperate for speed that this become an issue, you should probably just be using C directly and implement your own custom container. If that sounds like too much work you likely don't need the speed as much as you think :D
If you're concerned with these kinds of performance improvements, you probably shouldn't be using Python, and you *definitely* shouldn't be using CPython.
Thanks :-) You can delve into the source code on GitHub if that's your thing. I'm somewhat interested in knowing how well the source reads.
I still disagree. Python 3.0 came out more than six years ago, December of 2008. It took a big speed hit, and was dramatically slower than Python 2.7. Since then, each successive 3.x version has been faster than the one before. And, again, conventional wisdom is that Python 3 achieved performance parity with Python 2.7 somewhere around 3.3 or 3.4. I simply don't see how you can contort those facts into justifying the statement "If anything [Python's] getting slower at the moment". Any reasonable interpretation of that statement would conclude it meant the latest release (3.4) was slower than the one that came before (3.3), which is simply inaccurate. If you had said "Python 3 is still slower than Python 2 for my workloads", okay fine. But a blanket statement that Python is currently getting slower? Nope.
This should go to /r/learnpython, but try: from setuptools import setup, find_packages [...] packages = find_packages() [...]
Thanks, I'll try there.
&gt; Python 3.0 came out more than six years ago, December of 2008. It took a big speed hit, and was dramatically slower than Python 2.7. Since then, each successive 3.x version has been faster than the one before. And, again, conventional wisdom is that Python 3 achieved performance parity with Python 2.7 somewhere around 3.3 or 3.4. Conventional wisdom is that people run Pystone to figure out performance and there has been no improvement: $ python2.7 -c "from test import pystone; pystone.main()" Pystone(1.1) time for 50000 passes = 0.36754 This machine benchmarks at 136040 pystones/second vs $ python3.4 -c "from test import pystone; pystone.main()" Pystone(1.1) time for 50000 passes = 0.473492 This machine benchmarks at 105598 pystones/second &gt; If you had said "Python 3 is still slower than Python 2 for my workloads", okay fine. But a blanket statement that Python is currently getting slower? Nope. I already understood that you disagree with my statement. I don't think there is any point in dragging this discussion on. I'm not here to argue semantics. At the very least Python 3 is no clear performance improvement over Python 2.x and slower in many aspects, and in the discussion about PHP 5 vs 7 this is entirely opposite because PHP 7 has a rule to not degrade in performance *anywhere*.
As long as the data is accessible in some form of regular format (some kind of URL or something like that) and has sane formatting, you can most likely pull the data into Python in some way. Some systems might take more work to interface with than others, but it can almost always be done. I'm pretty sure Google has json APIs for most of their data that they make available. If so, it should be stupidly easy to pull in the data with Python's json library. 
Thanks a lot. This is very constructive and much appreciated. I was trying to get the syntax highliting right but eventually WordPress won (could not fit neither markdown nor restruct into WordPress). If you see this as a readme on bitbucket, you will see that the syntax is correctly (mostly) highlighted. I should probably provide a better synopsis for this and the follow up posts. Thanks for this tip. 'zope.interface'-wise I am really not attached. I used something familiar to achieve an interface. The goal of this interface to make sure that I can have multiple adapters in order to plug them into whatever is implementing interface. Purely enforcing the contract between the port and the adapter. I should have left it to part two probably... The only reason I am using Python is that I am familiar with it. It does actually stand in a way a bit as it is not entirely made for contracts and interfaces. Will make changes tomorrow.
I tried to use bokeh server in the past (having never used node, npm, gulp, bower, etc.) Man, was I over my head.
I'd say the lesson to be learned from this example is less about the performance improvement than it is about understanding how your code is *actually* running on the machine's hardware. There is a whole world of misinformation out there that can be avoided by simply knowing what your machine is doing with the ones and zeroes.
The scientific community has adopted Python 3 much more than the web based community. We have fewer dependencies.
&gt;If you need to manually look at every change, then you have a pretty serious problem IMO. If you can change your code programmatically then it's too redundant. 
Touché.
How do you type that on a keyboard. Also, that's the dot operator.
I'm on windows and I never knew that (it works). What's confusing is you need a keypad to do it.
The reason I prefer the first one is based on how we have array slices. A single array slice does different things based on what arguments we pass it: arr[start_index:final_index-1:stride] arr[3::] arr[:4] arr[::2] I like the question.
&gt; What's confusing is you need a keypad to do it. I'd bet that it's just some hold over from the old days. I think it's issues like this that made the Python team skip over the bullet as an operator. Too bad, because it's perfect typographically.
You talk like a person who haven't used imaplib :) Imho, it is so low-level, that "for humans" actually makes sense. Although i agree, the phrase is a cliche. 
PyPy or Jython can give ~7x speedup, for many benchmarks.
A container is anything which holds data, usually involving multiple 'contained' variables like Python's list class. A list was originally the solution for when programming languages required all variables to be declared at the beginning of a block of code, and in order for that amount of memory to be increased you needed to use memset functions to acquire pointers, which are unwieldy, bug inducing nightmares (no easily understandable way to properly name or convey them en masse, and once forgotten they introduce memory leaks - dropped or forgotten pointers basically *are* what a memory leak is). If you wanted a collection of 20 things, you could use an array, which is effectively a long pointer - it points to my_collection[0], and then you move through it with [1], [2] etc. But if you wanted to make it an array with 21 things? Too bad, so sad, off you go to pointer land. Array sizes were set permanently at the beginning of your code. Along came the linked list, which was a struct (a class with no methods) which pointed either to another struct or nothing. To add an item you changed the 'nothing' reference at the end to a new something, which might point to a something or a nothing. At its core, that is for the most part what all containers in all languages have looked like ever since (you can make the argument that trees and hashmaps are different, but you'd be wrong, they are just different ways of making a linked list). You still have to deal with pointers, but now you only need to worry about remembering the first one - from there you can recursively delete all the way down. (Incidentally, this recursion with linked lists is a HUGE reason recursion is still taught so heavily - you used to have to use it every day, now you can go an entire career without needing it outside Fibonacci fizzbuzzes). And so we get to Python's 'lists'. They are a smart implementation of linked lists, but that intelligence comes with a processing cost. Because Python doesn't know wtf you want to do with your list, it implements everything. I don't know the raw details (mostly because I don't need to know to use them - the whole point of upper level languages) but it would include things like doubly-linking the list so you can go in reverse, there's probably some form of indexing and look-ahead going on in there someplace to optimise the most common use cases. So usually Python's lists are faster than home-grown solutions, and much, much quicker to implement. But if you have a single use case, with rigidly defined rules, requirements etc, you can get rid of all of those helper functions and features, and make your own linked list which is faster *for the very specific case you have*. It is only a step or 2 behind the bleeding edge of optimisation though (the final stages involving assembler code, bitshifting instead of ordinary arithmetic, and probably teams of mathematics PhDs and electrical engineering scientists) and you should probably make sure you don't have something silly in your Python code like unnecessary loops before making that jump.
&gt; Conventional wisdom is that people run Pystone to figure out performance No, conventional wisdom is that benchmarking in Python is terrible, and Pystone is the worst of them all. You are literally the first person I've ever seen backing up performance claims by citing Pystone. Slightly less bad, but still not great, is the Unladen Swallow test suite. In my opinion the least-terrible is the PyPy benchmark suite--but I'm not sure we have a version of either of those that runs under both Python 2 and Python 3. As always, the most relevant indicator of performance is to benchmark it yourself with your own workload. &gt; I'm not here to argue semantics. Perhaps not. But when you make a blanket statement that is simply wrong ("[Python's] getting slower at the moment"), then attempt to justify your statement by redefining your terms (e.g. "at the moment" really means "when you compare the current version to a five-year-old implementation of the previous version of the language"), you should hardly be surprised when *other* people show up to argue semantics. In any case I'm not trying to change your mind. Rather, I wanted to ensure that other readers in the thread were not misled by your statement. Is Python "getting slower at the moment"? By any conventional definition of the terms in that statement, no, it is not.
Python lists are (fancy) arrays, not (fancy) linked lists. The key difference is that arrays have O(1) access and O(n) insert/delete, while linked lists have O(n) access and O(1) insert/delete.
`append()`'s complexity is `O(1)` It just modifies the original list, it doesn't return a new list. 
From [*Problem Solving with Algorithms and Data Structures:*](http://interactivepython.org/runestone/static/pythonds/AlgorithmAnalysis/Lists.html#lists) concat 6.54352807999 milliseconds append 0.306292057037 milliseconds comprehension 0.147661924362 milliseconds list range 0.0655000209808 milliseconds
http://norvig.com/spell-correct.html
I tried to run the same tests and could not duplicate your results. In my testing, Python 3.4 was as fast or faster than Python 3.3. Just for grins, I also ran the tests with Python 3.5.0 alpha 4, which was faster still. I did find that Python 2.7 was usually faster than any version of Python 3. The one exception: in my testing, Flask was faster under Python 3.4.3 and 3.5.0a4. So, for your workloads, Python 2 is still often faster, a fact I'm happy to concede. (Well, "happy" is probably the wrong word. But it does appear to be true.) In each case I ran the test suite either with "make test" or "&lt;python&gt; run-tests.py". All were best of three runs. To ensure it was as apples-to-apples as possible, all software was *freshly* built from source. All testing was on my desktop machine (Ubuntu 15.04, x86-64). Click 4.0: * 2.7.9: 94 passed in **0.17** seconds * 3.3.6: 94 passed in **0.22** seconds * 3.4.3: 94 passed in **0.20** seconds * 3.5.0a4: 94 passed in **0.20** seconds Jinja2 2.7.3: * 2.7.9: Ran 328 tests in **0.445s** * 3.3.6: Ran 310 tests in **0.469s** * 3.4.3: Ran 310 tests in **0.469s** * 3.5.0a4: Ran 310 tests in **0.462s** Flask 0.10.1: * 2.7.9: Ran 226 tests in **0.572s** FAILED (failures=3) * 3.3.6: Ran 226 tests in **0.584s** FAILED (failures=3) * 3.4.3: Ran 226 tests in **0.571s** FAILED (failures=3) * 3.5.0a4: Ran 226 tests in **0.525s** FAILED (failures=3) To reiterate: for Python 3, in no case did I find a newer version ran a test slower than an older version. Python is not getting slower. Maybe you *are* very unlucky.
You could create a Markov chain to create a spell checker, which would use less resources.
Worst case is O(n) though, as you might need to copy the array. 
But it's still O(1) amortized, due to geometric resizing. 
Pretty stupid in my opinion.
[This](http://sowingseasons.com/blog/mining-for-credits-web-scraping-with-requests.html) was posted the other day too. Used the same technique.
You are looking for Julia. Its going to be the new python. Better syntax than python, faster than go, going to have static binaries, beautiful multiple dispatch and type system, hygenic macros. Multithreading, async and coroutines. Its not just be for scientific computing, but that is it's initial foothold. 
Or Cython.
And Cython beats both of them.
There are a few things to worry about -- both exploits and just really large or recursive zip files. Make sure to check or limit the expanded size so someone can't fill the disk. I'd say using subprocess to run gunzip as the user nobody, writing to a random named temp file is a good start. What sort of processing? For extra security you could run this inside a VM or on another machine, but it's a tradeoff for complexity, and what threats you are trying to protect against and what sort of data is on the server.
Could you tell me where you get these knowledge? I think this is really helpful if someone wants to be an expert in Python
SQLite in-memory database. 
I'm not familiar with Mac OS X's text-to-speech so I can't really weigh in on how good it is. Ivona sounds quite nice though and, in my opinion, the Brian voice would be perfect for a Jarvis-like assistant. In addition, Ivona is cross-platform which may help if you're planning on distributing your software.
Yup. For a language to allow the dynamism of code like: &gt;&gt;&gt; x = [1,1,2,3,5,8] &gt;&gt;&gt; for collection in (list, set, tuple): c = collection(x) print(type(c), 'has length', len(c)) &lt;class 'list'&gt; has length 6 &lt;class 'set'&gt; has length 5 &lt;class 'tuple'&gt; has length 6 the most natural way to do it is with the constructors `list`, `set`, `tuple`, etc to be ordinary functions that must be looked up and can be assigned/overwritten/etc. (Even though its most certainly bad practice to do something like `list = [1,2,3]` where you shadowed the built-in `list` function with a reference to the ListArray with value `[1,2,3]`.
yup, you're right, will do, thanks!
Mostly just from doing Python for a long time and reading stuff. If you want to know about all the fun optimizations in Python's dictionary implementation, there's a chapter on it in "Beautiful Code". The source code is also pretty well commented. Python's sorting algorithm, "timsort", also is well-documented. The integer-allocation thing, I don't remember when or where I learned about, but you can find out about it by searching "Python small integer allocation". And the parts about knowing what's done in Python and what's done in C are in most good Python optimization guides. In fact, I'd say that if a guide *doesn't* talk about that, it's a strong indication that it's not a good guide.
Hi, talking about PyData stack on OSX I ended up with the following: 1. pip; 2. (multiple) python virtualenv: a. one with the Python 2 version of the stack (up to date); b. one with the Python 3 version of it (up to date); c. ad-hoc virtualenv(s) for those projects which required a specific version of a particular library; 3. homebrew (for system wide tools); p.s. I have been (and still am, when I have to work on other people's windows machines) an Anaconda user. 
In order to see how you can use Python in studying electronics, and signals, take a look at these IPython Notebooks: https://github.com/unpingco/Python-for-Signal-Processing http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb
A matrix at minimum has a 1 for a dimension (e.g. nx1). The minimum for an ndarray is (n,), which means that it can multiply oddly if you don't resize it. Many functions (at least they used to) return ndarrays regardless of input type. The big difference is just what the default operator is for `*` either matrix multiply or element-wise multiply. After having programs that tried to support both have all sorts of problems, my company more or less dropped support for matricies. They're actively discouraged, so why should we support them? If you want to multiply matrices with ndarrays, just make sure you don't use (n,) ndarrays or you'll run into bugs at some point.
&gt; Well, that would be valid if: &gt; - Python 2's unicode support was actually complete &gt; - People didn't use str as the primary text container That is a criticism of people, not Py2. The type of person that thinks `str` is appropriate for text in Py2 is the same type who ends up with loads of unnoticed surrogate escapes blowing up their Py3 programs. Regarding Python 2's Unicode support: it may not be complete, but I've never missed anything in Py2 that Py3 has, and Py2 has the distinct advantage that when you have a `unicode` object, you can at least be sure the fucker won't explode upon encoding. &gt; This means that when receiving arbitrary text, you can't decode it And this remains precisely as true in Python 3. The only difference between 2 and 3 is that Py3 goes ahead and "decodes" the text anyway… &gt; (because you don't know how - or even if - it's encoded). All text is encoded. As you said yourself a couple of posts ago, there's no such thing as a Unicode stream. &gt; What, you'd want Python to automatically normalize all your text for you? If it's going to decode it for me, then yes, it should normalise it, too. Or be smarter about Unicode comparisons. I don't think this should happen (OS X): &gt;&gt;&gt; import os &gt;&gt;&gt; name = 'Übersicht.txt' &gt;&gt;&gt; open(name, 'w').write('hello') 5 &gt;&gt;&gt; filename = os.listdir('.')[0] &gt;&gt;&gt; filename, name ('Übersicht.txt', 'Übersicht.txt') &gt;&gt;&gt; filename == name False Obviously, this works no better in Py2, but I normalise the text when I decode it. &gt; Well, preferably you'd use the encoding defined by the protocol. Again, no difference between 2 and 3. &gt; But the point is that needing to have new features and wanting to have new features are very different. And my point is that I neither need *nor want* any of Py3's new features enough for it to be worth the accompanying hassle. &gt; But, as I've said, you're dealing with it in a pointlessly difficult way. And as I've said, that isn't how I'm dealing with it. For the love of Guido, *please* stop trying to explain to me how to do whatever it is you think I don't know how to do. You haven't said a single thing I don't already know (apart from the C++ bit, obviously). Can you please let go of the whole "this guy must simply not understand Python 3" thing? The problem I have with Python 3 is not that I don't understand it. It's that I *do* understand it and it is not attractive *to me* in its *current state*. For a variety of reasons, in the code I write, I have to dick around with encoding/decoding in Python 3 just as much as, or more than, in 2. This is not open to debate. And for me, it's just *easier* with Py2. On one hand, it doesn't give you much help with encoding/decoding text, but on the other hand, it doesn't give you the kind of "help" with encoding/decoding text that mangles the input in such a way that it's dangerous *and hides this fact from you*. 
Well excuuuuuse me, Mr. Smarty Pants.
Got it, thanks!
Yes, I chose the versioning scheme, thanks!
Thank you all the same!
But it lacks library support. Or am I mistaking projects?
So far I've had the best results with using the boost::python library in C++, but it might be use-case dependent wether boost::python or Cython is faster.
I modified the test runners to run the tests multiple times in a row as the variance is too high when you run it only once. If you don't want to do that you can also run it as `time (for i in 1 2 3; do make test; done)` which however factors in the interpreter startup. I also ran the tests on 64bit OS X. The versions are all the reference downloads from python.org, not self compiled. &gt; Python is not getting slower. Maybe you are very unlucky. So now it's word against word? How do you explain that it's running slower for me? //EDIT: if you want to test this, add this to conftest: def pytest_addoption(parser): parser.addoption('--count', default=1, type='int', metavar='count', help='Run each test the specified number of times') def pytest_generate_tests(metafunc): for i in range(metafunc.config.option.count): metafunc.addcall() And then invoke with `py.test --count=3`. I ran each test multiple times and averaged out the results then as they vary too much. Also if a test failed on a certain platform (in case of Flask) I disabled the test. All tested from latest master.
Thanks for the link. The problem for me is that my C function takes in a python function. I would like to be able to pass any callable thing to it. Using the method you provided I can pass an object instance but have to know the name of the method on it to call.
Also, [Zato](https://zato.io/docs/) is a middleware, API and backend application server utilizing a couple of the frameworks listed in the article linked to.
[heavy breathing]
"bookmark details of firefox" ~ useful to me, I have hundreds. Github/Bitbucket.
There should be eli5 for this as I don't understand a bit. But anyway, cool project
That exactly demonstrates what it is all about - the implementation detail, which may even change in future version of the same environment. Something one should not care and waste time, with the exception of very special and determined cases, where environment won't change a bit and all main optimizations (algorithms, use of optimized external libs, settings) were already done. 
I'm currently using pyratemp (tiny template engine with support for control structures and LaTeX escape support) and pyplot to generate some reports in LaTeX.
Thankfully it's serverside only and I can pre-generate all the speech files. Actually I'm planning on using Japanese. The OSX Japanese voice is very good, probably also because it's much more phonetically predictable than English.
RIP Mathematica T_T
Interesting. I always thought morse code had a huge potential for blind and physically disabled people. Because you enter text using one key, and don’t have to navigate a keyboard, some users would find it much simpler. Another advantage is that you can read morse code in a high-noise environment. Think of that awful beeping of forklifts, etc, and how you can hear it in a noisy metal shop full of machines. Morse Code is an alphabet, you spell out words. I always wanted my iPhone to talk to me in morse code, and it would be ideal for miniature computers that don’t have the processing power for voice synthesis. For old people like me who need lenses to see anything closer than arm’s length, a morse code speaking computer would be a great invention. I’ve often thought the best way to learn morse code is through curiosity. Most people say to themselves “I want to learn morse code”. This is wrong. People who actually hear morse code beeping away first think “what does it say?”. If for example, you were to hear the time beeping away in morse code at regular intervals, it would be easy to learn just out of subconscious repetition and curiosity. However there is no such computer that does it and morse code is in all respects a dying art form. The downsides, one is that it takes learning. Most adults are unable to learn a new language like morse code. Even if it would be hugely more efficient than voice synthesis and there was a need for it, you are not going to be able to get adults to learn morse code as a popular way of communicating with machines. I should say that morse code uses a brain function that is largely underutilized. I would even say languishing away. People who have strong auditory talents can learn it fast. Musicians for example seem to have a talent for morse code. Another downside is that making noise is more power demanding than powering a visual display. On a device like iWatch you may not have enough on-board power to run a beeper for normal communication. Having said that, I would imagine the most functional use for morse code would be a bluetooth device that would be portable and beep out any text sent to it, with possibly a capacitive touch pad for input. If you do build some sort of morse code device, it is critical that you make it sound like music. This involves “shaping” the sound envelope in the most esthetically pleasing way. This is very important, because almost all morse code you hear hurts your ears because it is straight (square-shaped) beeping, so people eventually find it annoying. This is not because they don’t understand “the code”, but rather because the beep subconsiously hurts their ears and they don’t know it. The iPhone, for example, doesn’t have enough speaker control to deliver a proper morse code sound, so all the iPhone morse code apps are hideous. Proper wave-shaping is really done with analog electronics. In the amateur radio world, the TenTec transmitters were legendary for having the most recognizable and pleasing waveform. If you want to make morse code accepted as background noise, it will have to be like music, enjoyable to listen to instead of painfully obtrusive. — K5ZN
&gt;&gt; Python is not getting slower. Maybe you are very unlucky. &gt; So now it's word against word? How do you explain that it's running slower for me? Of the three benchmarks you posted, two were close enough that the difference was less than the margin of error (flask and click). It's not reasonable to claim that Python 3.4 is slower than 3.3 based on those numbers. (Indeed, click was actually slightly faster.) Only one was markedly slower under 3.4 than under 3.3, seemingly to a statistically significant degree, and that was jinja2. So I'll concentrate on that. The "conftest" thing you posted above is only relevant to click, so that doesn't help here. To try and drown out the margin of error, I changed jinja2/testsuite/__init__.py so it ran unittest.main(exit=False), then changed run-tests.py so it ran main() 100 times, then kept the best of three wall times. My results: % time python2.7 run-tests.py &gt; /dev/null 2&gt; /dev/null 42.05s user 0.37s system 99% cpu 42.590 total % time python3.3 run-tests.py &gt; /dev/null 2&gt; /dev/null 40.32s user 0.26s system 99% cpu 40.713 total % time python3.4 run-tests.py &gt; /dev/null 2&gt; /dev/null 40.21s user 0.24s system 99% cpu 40.591 total % time python3.5 run-tests.py &gt; /dev/null 2&gt; /dev/null 40.64s user 0.23s system 99% cpu 41.008 total Mildly interesting: this time 3.5 ran slightly slower than 3.4 or 3.3. But this variance is *still* within the margin of error--the slowest run of 3.4 was 40.8s of wall time, for example. To get rid of that variance I'd really have to reboot and make sure my system was as quiet as possible, which for now I'm not bothering with. More interesting: Python 2.7 is now consistently slower. It's slight but statistically significant. Most interesting of all: Less than 1% of this test's run time was actually spent in the Python interpreter. 99% of the time is spent in system. This suggests that variation in the behavior of the system calls will drown out performance changes between Python 3 versions. (What is it doing in all that system time? I don't know. My first guess was, it was I/O bound. But iotop says it's only writing 40-80k/sec, and even if that were all blocking I/O written one byte at a time I'm not sure that'd explain it.) I really couldn't say why your Jinja2 run under Python 3.4 was measurably slower than it was under Python 3.3. However, given the above, one plausible explanation was that your system was otherwise busier during the 3.4 runs, like your email client was checking mail or something. You might try rerunning the benchmark for longer (maybe 30+ seconds?), and on a quiet system (perhaps after a fresh reboot with as few programs running as possible). It'd also be really great if you compiled all the Python executables yourself, fresh from scratch, to ensure you were using the same compiler, so it's all as apples-to-apples as possible. It's possible 2.7 was compiled with GCC and either or both of 3.3 and 3.4 are using Clang, which still produces slightly slower code on x86-64. On to the larger point. You're hardly the only person who cares about Python performance. If Python were getting slower for lots of people, they'd all scream bloody murder, just like you're doing right now. I haven't seen complaints like that on the bug tracker or in the Python newsgroups. I do see occasional performance complaints, but it's generally specific microbenchmarks. Also it's usually 3.x vs 2.x, as in something that got slower in 3 and hasn't been (or can't be) addressed. Can you cite other people who complain that Python 3 is getting progressively slower on their workloads? Furthermore, it makes sense that Python *should* be getting faster, if only by small degrees. A lot of core developers are concerned about performance and they continue to contribute optimizations. Python 3.0 was a major regression in performance for many reasons, the main ones being the switch to Unicode strings and dropping the native int type. Since then I'm not aware of any major checkins to Python where we *expected* it to get slower. I can cite loads of performance enhancements where we expected it to get *quicker*. Can you cite performance regressions we introduced in 3.1 or after, where it's reasonable to expect Python got slower? It's completely legit for you to say "Python ran slower for me for some of my workloads on my laptop". I'm sorry you're having this experience, and it'd be interesting to figure out why it's happening. But it's irresponsible for you to extrapolate that out to your statement, "[Python's] getting slower at the moment". One benchmark of three on your laptop running slower is not a reasonable foundation for a blanket condemnation of Python 3's evolving performance. p.s. I did a little googling, and did find a single other person who quoted PyStone as if it were a reasonable benchmark. However I think the guy was a troll. http://www.reddit.com/r/Python/comments/272bao/python_34_slow_compared_to_27_whats_your_mileage/ I also found Brett Cannon's talk, where he did the work of benchmarking Python 2.7 vs Python 3.3 with a reasonable test suite. He found that the two versions were roughly equal in performance. He used the Unladen Swallow test suite, bolstered I think with some stuff from PyPy's test suite. https://speakerdeck.com/pyconslides/python-3-dot-3-trust-me-its-better-than-python-2-dot-7-by-dr-brett-cannon
Oh gosh... I'm going to have to switch to pyqt then..
This is where toolz (and cytoolz, a Cython implementation of toolz) excel: https://pypi.python.org/pypi/toolz https://pypi.python.org/pypi/cytoolz They implement the *sine qua non* of functional data analysis and work well on Python's builtin data structures. They are also very lightweight dependencies and aim to be well-tested, well-documented, and very stable.
Will all these new features hit IntelliJ Idea Python Plugin?
This has been around for ages.
[What's new](https://www.youtube.com/watch?t=162&amp;v=AZFCPmcoGkk) Impressive stuff.
Thanks for the suggestion
I have updated the details of the post
There is a sqlite database where firefox stores the history, the analysis I want to do for myself is which sites I visit on a per hour basis, there is a pattern, after coming from office I visit, reddit, gmail, hacker news then after dinner: facebook, and rarely quora. i want to check my productivity, but I won't be doing a category to the site and show it, I will show the website and let the user know if it was time well spent
The problem is a lot of code is already written using `*` as `.*` (element-wise multiplication). So we can't really change the meaning of `*` (unless numpy suddenly changes the fundamental object to be a `numpy.matrix` instead of `numpy.array` where `*` was overloaded to be matrix multiplication. Then we could introduce `.*` and just deprecate `numpy.array`.
Gonna give a shoutout to rust for writing speed dependant stuff for python
Can you give some examples of how they'd apply to this case?
Natural habit. It's likely not needed. When I wrote the script I automatically put in the referrer because a lot of sites I've written for will ignore the request if the referrer isn't set on POST requests.
Which parts of the code involve ImageMagick? I've already downloaded a shitton of software today to figure out this damn problem, and I think I could work around it.
There is less and less things that don't work at all, so its not a big issue in many cases. There is still a lot of things that work slower under pypy than cpython, and that prevents me from switching.
For simple projects, the builtin csv module and its DictWriter and DictReader methods are my gotos for reading / writing tabular data. As such, my structure *de jure* is lists of dictionaries. Indexing for row access, generator expressions for row access. If you're not married to your filesystem, though, named tuples are fun and pretty damn pythonic.
ImageMagick is for text generation (it makes beautiful texts). Here is an alternative where I use PIL (or Pillow) to generate the text (it's faster than my previous solution, but you don't have the esthetic quality of ImageMagick) import datetime from PIL import Image, ImageDraw, ImageFont import moviepy.editor as mp from moviepy.video.io.bindings import PIL_to_npimage date = datetime.date.today() date_string = "%d/%d/%d"%(date.year,date.month,date.day) # Define a custom font (optional) fontname = "/usr/share/fonts/truetype/freefont/FreeMono.ttf" font = ImageFont.FreeTypeFont(fontname, 24) def add_timestamp(video_frame): im = Image.fromarray(video_frame) # transforms the Numpy image into a PIL image draw = ImageDraw.Draw(im) draw.text((2, 2), date_string, font=font) return PIL_to_npimage(im) # transforms the PIL image back to a Numpy image clip = mp.VideoFileClip("video.mp4") timestamped_clip =clip.fl_image(add_timestamp) timestamped_clip.write_videofile('newvideo.mp4', bitrate='8000k')
Love the new debugging icons for Step Over, Into, Out. :)
Do you know of any videos/guides that show how to use the debugger with Django based development? I hear alot of awesome things said about the debugger but it's something i've never been able to utilise :(
Eventually they will. We've released Python plugin for IntelliJ 4.5 build 141.82 that contains some of the features and we'll bring more features in a few weeks.
I tried this but get for places.sqlite: databaseerror: file is encrypted or not a database. Ok, I closed firefox but now I get OperationalError: no such table: moz_historyvisits. Firefox 2.9 portable.
Yes they're the same. In java they're called "Arraylist". 
You need PyCharm 4.5 Professional Edition for that.
&gt; The second one only holds true on Linux for correctly **normalised** and encoded bytestrings `os.listdir()` may give two strings that normalize to the same thing, but it will never give two strings which are equal. If it normalizes, it could give two strings which are equal. Which is exactly why normalizing is a terrible idea. &gt;&gt; Normalizing strings would break the semantics of the system. &gt; &gt; It would on an FS where filenames are bytes. It makes sense on a filesystem where they're text. &gt; &gt; In point of fact, it works perfectly on OS X. You completely missed what I'm saying: **OS X does not prevent normalization from breaking these guarantees because it only performs a nonstandard subset of the normalization.** Supposedly this subset even depends on the filesystem version. If you normalize carelessly, you *will* introduce bugs. &gt; I think that a filesystem that treats filenames as text is right to do so But normalizing is *still stupid* because, like with OS X, there is no sane way to update the normalization as the unicode standard evolves. Which means any system that doesn't normalize will be confused and any system that does will break. &gt; What's equal and unequal is a matter of perspective. If `str1[10] != str2[10]` yet `str1 == str2`, the system is broken. 
There is a small section on debugging Django apps in the [PyCharm Overview](https://www.youtube.com/watch?v=iutkLjeGc6w) video.
[JetBrains youtube channel has a lot of demos](https://www.youtube.com/user/JetBrainsTV/search?query=pycharm)
Is the application a web app served over the internet or is it a native desktop application?
No this is completely different. It lets you add breakpoints and step through your code line by line. You can pause it mid-execution and open up the console and work with objects that exist in the current scope, etc. (P.S. I develop in Flask)
Most of the features of PyCharm 4.5 are available in the free and open-source Community Edition, but not this one, unfortunately.
Ah, gotcha -- so like the Visual Studio step-through debugger with a REPL attached to it!
Is it possible to use Python libraries with Cython? I figured it would be since I am pretty sure Cython is a superset of Python.
Why not look at the data that the program is sending with [wireshark](wireshark.org)? You should be then able to figure out how each items information is being requested and write your own helper functions to request the information though Python. 
Yes, the in-line debugger and the debug console are included in the Community Edition as well.
Here is a basic introduction: http://docs.cython.org/src/tutorial/cython_tutorial.html
You can open the debug console by switching to the Console tab of the debug pane and pressing the Show Python Prompt button.
HAPPY BIRTHDAY!
I don't think I've encountered code written by misuhiko that didn't elicited this response.
I agree. This is some magnificent python code!
Happy birthday!!!
esp201 for breadboard
But all that beautiful reference...
What do you like about it? Can you give any specifics?
Not beautiful, but cute: [Lib/types.py](https://hg.python.org/cpython/file/56c6a4bce996/Lib/types.py) (the beginning through line 43 or so) 
I think [PyToolz](https://github.com/pytoolz/toolz/) has some incredibly sensible code - straightforward and fast and useful.
You to keep in mind the end goal, to have a Docker image that can run your site. Once you have a Docker image that can run your site, you grab the image on the host and run it: docker pull glueon/mysite docker run -d -p 80:80 glueon/mysite Other than having Docker installed, there is nothing else that you need to install on the server. The Docker image or images contain everything you need to run your site, so you don't have to worry about install Python and Python packages on your server. Now to get this magical Docker image, you need to make a Docker buildfile. In the build file build file you will need to: * set environmental variables to customize settings * install Python and Pip * pull your code * pip install requirements.txt * run django management commands * setup a HTTP server like Gunicorn Finally, when you want to develop against a Docker container. Mount a volume to your local machine. You can edit files locally and they update in the Docker container. If you need to you can run commands ad-hoc with `docker exec -d my_site pip install package`, just make sure you add the package to your requirements.txt.
I'll state the obvious: the filenames are an attack vector, so don't use os.system() or subprocess.Popen(..., shell=True), etc., while including any filename. And don't include the filename straight onto your web page either, you have to escape it - either cgi.escape or a nicer tool like MarkupSafe.
As a package user I need absolute guarantee that when I download version x.y.z, production server downloading the same version will get *exactly* the same thing. Blocking reuploads is the right thing to do. 
gdb had that for C in the eighties.
Tracebacks are how a real man checks his code (says /r/learnpython).
&gt; Wow, the inline debugging is amazing Welcome to ~~1995~~ 1983! We've been waiting for you. :P edit: This wasn't meant to be rude, just a statement of how long ides with inline debugging have been around. Thanks for downvotes though. Anyways, I was wrong, first inline debugger (that I could find in a few minutes) was in 1983, turbo pascal. mb. I believe the first GUI based IDE with inline debugging, for windows, was visual basic in 1995. Not sure what mac had at the time. Even QBASIC had it. edit: apparently the ancient term "inline debugging" in this context means watching variable states inserted at the end of the source line. thanks for the downvotes to help clarify my misunderstanding of the term that was apparently changed today.
&gt; I've only been using print statements to debug thus far This is such a strange trend in the Python community that I'm trying to understand. We've had IDEs with inline debugging for &gt; 20 years now, why didn't you try another IDE or something like pdb? The worst part about printing is that you have to make sure to print everything that *might* be wrong, but since you don't know *what* is wrong, you end up having several run cycles just to print the right thing. It's pretty crazy how quickly you can find the errors with a proper inline debugger.
There seems to be a massive number of people that still do everything in command line, rely on debugging with print statements, and tracebacks for syntax errors. I think the python community could use a few reminders that these tools exist independently (pdb, pylint etc) and in a ~~20~~ 30 years old integrated concept of an IDE. /me waits for "vim is all you need" responses.
Not a troll, my friend. Do you mind taking back your (abusive) words? It looks like every time someone points out a flaw in Python 3, he's immediately tagged as a troll, particularly on this subreddit. Pretty shameful. Regarding the Unladen Swallow test suite, Brett Cannon himself says that there is no actual overall performance improvement in Python 3 and in some areas it's still slower that Python 2.7, which backs Mitsuiko's point: Python's not getting faster in general. And you may even find Python 3 is much slower depending on what you're doing. 
Thanks for your input. Yes the problem with live editing I solved by adding a volume to my container. So now when I finish my work I run: * docker save -o app_image web (where web is the name of the container with my app) * Copy that image to my host * docker load &lt; app_image * docker stop web &amp;&amp; docker run app_image ... I did not know docker has a new docker registry 2.0 which allows to have private docker repos. I am thinking that maybe I should deploy in such a manner: * When I finished testing I run `git push stage` * git hook build an docker image and pushes it to my local repo * Then on the stage machine I just run `pull` and `docker-compose up web_app`
Python 2.
Thank you!
Thank you!
Ya I love ideavim, one of the best vi plugins
Pretty nice, though it could use some blank lines. Or maybe I'm just used to chunking stuff a bit more. 
I always forgot when my favourite TV series was going to air an episode, so I wrote a python script to remind me at boot time. https://gist.github.com/thewhitetulip/7c33b3477e5a9c392e7c Also I had a bunch of honest trailers and daily I used to watch them but couldn't decide which ones to watch since all of them are awesome, so I wrote a script that randomly plays them but doesn't repeat either. https://github.com/thewhitetulip/SamplePythonScripts/blob/master/video.py
I'd say everything in the scikit-learn library, just browse through some of the modules in the [GitHub repo](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn), it's all highly efficient, well-documented, PEP8 compliant, perfectly refactored, well-tested etc.
Edited. But, every IDE that I've ever used including QBASIC. Debugging is a required part of the definition of an IDE, and, if the IDE is of any value, the debugging is inline. Even excel VBA has it. There seems to be some anti IDE/lack of IDE knowledge in the Python community for some reason. And, rude comments rarely end with. :P
There was word of it, but I just see a poorly rated Docker plugin. I hope Docker gets the Vagrant treatment soon.
Most everything he's done is quite elegant
"Is it just for attribute access" kind of, its like a small, light-weight immutable object. The collections module is not meant to be revolutionary, instead they are just shortcuts its very useful in this situation, as it preserves col order (dicts don't), while still allowing access by the name of the col (tuples don't), without any needless memory usage (dict's don't). They are very un-useful with other situations however, but can still have value (`x[0]:x[1]` vs `x.key:x.value`) - - - "(for those familiar with javascript)" This is a bit no, in javascript you can't access attributes by index, and the objects are mutable. javascript objects are closest to dicts, even with dicts lacking attribute access (they work the same way, except when it comes to JS stupidity like iterating over numerical keys for example) to get something like how JS deals with keys/attributes: https://github.com/Socialery/BuiltinExt/blob/bbde5e8e3d/builtinext.py#L10-L21 , but you will be shot for using that in any professional code
That has been around since PyCharm 3, the only thing new is that the values of local variables now show up in-line on the screen when you hit a break point.
Also another handy tip, run with the `--restart=always` flag so you containers will come back up if your machine reboots.
Nice. I've never used the pyquery library, looks good for quick access to certain elements. For fun I wrote a variation using lxml, requests and pandas. Pandas is mainly used for staging the data just before storing it but comes in handy with validation tasks as well: import pandas as pd import numpy as np import requests import datetime from lxml import html class FlightScraper(object): headers = { 'User-Agent':('Mozilla/5.0 (X11; Linux x86_64)' 'AppleWebKit/537.36 (KHTML, like Gecko)' 'Chrome/41.0.2272.64 Safari/537.36'), } def __init__(self, headers=None, token=None, *args, **kwargs): self.base_url = 'http://bristowgroup.com/clients/flight-status/' self.session = requests.Session() self.session.headers = headers or self.headers self.token = token self.bases = {} def post(self, base, date): if isinstance(date, (datetime.datetime, datetime.date)): date = date.strftime('%d-%m-%Y') payload = { 'csrfmiddlewaretoken': self.token, 'base': self.bases[base], 'request_date': date, # '15-May-2015' 'submit':'submit', } return self.session.post(self.base_url, data=payload) def begin(self): response = self.session.get(self.base_url) self.start_page = html.fromstring(response.text) # raise here if not response 200 etc def set_token(self): selector = "input[name='csrfmiddlewaretoken']" token_element, *_ = self.start_page.cssselect(selector) token = token_element.attrib self.token = token['value'] def get_bases(self): option_group, *_ = self.start_page.cssselect('select#id_base') options = option_group.cssselect('option') for option in options: base_name, base_id = option.text, option.attrib['value'] if not base_id: continue else: self.bases.update({base_name: base_id}) def get_table(self, base, date): response = self.post(base, date) parsed = html.fromstring(response.text) table_element, *_ = parsed.cssselect('table#results') thead, *_ = table_element.cssselect('thead') thead = [th.text_content().strip('\n ') for th in thead.cssselect('tr th')] tbody, *_ = table_element.cssselect('tbody') table_rows = tbody.cssselect('tr') table_data = map(lambda tr: map(lambda td: td.text_content().strip('\n '), tr.cssselect('td')), table_rows) none_to_nan = lambda s: np.NaN if s == 'None' else s return pd.DataFrame(table_data, columns=thead).applymap(none_to_nan) def scrape(self, base, date): self.begin() self.set_token() self.get_bases() return self.get_table(base, date) if __name__ == '__main__': flights = FlightScraper() df = flights.scrape('Hammerfest','15-May-2015') #df.to_excel(), df.to_sql(), etc...
Very exciting- the language of python's concurrency has been esoteric for a long time. 
Yes, like hack a game, but i did not want to do it, i just want to know how ir works!!
I'll look into it, thanks for telling! Also isn't firefox 2.9 a little old or does the portable version follow different version numbers?
The github page says the WiFi functionality isn't implemented. It is a shame I'm probably not smart enough to help :-\\. In my view the ESP8266 loses a lot of its appeal if you can't use the WiFi, because what you are left with is a machine with a much more limited use space. I am looking forward to WiFi working (or better yet - someone telling me I'm wrong and WiFi is working!)
 &gt; Not a troll, my friend. Do you mind taking back your (abusive) words? I'm not trying to pick a fight here. But it sure as hell seemed like you were trolling in that thread. I say this not because you "pointed out a flaw in Python 3", but because of antics like giving Lennart an insulting nickname ("Throll"), putting words in people's mouths ("Can you please stop implicating that I'm lying?", "and the first thing I'm being told is that I'm a lazy troll"), impugning other people's behavior ("you rushed to fix the benchmark to try and squeeze out as much juice as you could"), and generally insulting people ("You really don't get the point, do you?"). Certainly you will concur, you didn't take the high road in that discussion. But "trolling" implies a specific motivation: that you joined that conversation with the specific intent of pissing people off, and that you never really cared about the subject at hand. And no, I can't claim for certain that I know what your motivation was in that thread. So you tell me. What was your motivation in participating that thread? It sure seemed like you were really just trying to get a rise out of people, and you weren't actually interested in learning anything. And, more to the point, why are you replying in this thread? You certainly seem to have made your mind up about Python 3. Why bother discussing it?
It's more the OS than Python, read how to do it in VC++ and port it to ctypes or CFFI.
 def love_me(): pass if __name__ == '__main__': while True: love_me()
List of dicts for super simple applications (emphasis on super simple), otherwise Pandas dataframes are amazing to work with.
[That's undefined behaviour.](https://docs.python.org/3/library/functions.html#locals)
[tablib](https://tablib.readthedocs.org/en/latest/)
They've also been faster to port, IMHO, probably due to a lack of churn from the `str`/`bytes` change.
[Light Table](http://lighttable.com/).
Probably never. Tying it to Python's release schedule is probably a bad idea.
A real man doesn't check his code. He writes his code once, then uses his intelligence and strength of character to convince everyone else that those aren't bugs but rather features, such as "rapid exit to desktop".
flask is small and quite capable
&gt; Because Python is the new Excel? LOL 
dude, stop screwing around with dropbox download - use paste board
[Minibelt](https://github.com/sametmax/minibelt) has some beautiful stuff. E.G: from collections import deque from itertools import islice def window(iterable, size=2): iterable = iter(iterable) d = deque(islice(iterable, size), size) yield d for x in iterable: d.append(x) yield d This let you iterate with a sliding window : for win in window('abcdefghijkl', 3): print('-'.join(win)) a-b-c b-c-d c-d-e d-e-f e-f-g f-g-h g-h-i h-i-j i-j-k j-k-l But the really neat thing is that it works with lazy iterables such as generators, and infinite iterable such as network streams.
Not exactly. You can do chain() with yield from, but you can't do a lot of things yield from do with chain().
Why does that show a different length for the `set`? Is that a typo or am I missing something? On Python 3.4, they're all the same length.
Yeah, that makes sense. I love using Python tools at work.
&gt; But the really neat thing is that it works with lazy iterables such as generators, and infinite iterable such as network streams. *homer simpson mouth watering gif*
&gt; Say you have some directory with the files `a = '福'` and `b = '福'`, for which `unicodedata.normalize("NFC", a) == b`. (From the question.) Now there is no way to write to the first file using the unicode API, and os.listdir() gives you two value-identical strings, both of which are b. Got you. It took me a while to figure that out because `a` and `b` look the same in my terminal ಠ_ಠ No, that wouldn't be an appropriate thing to do. &gt; Further, I think that when wanting to count graphemes, you should actually count graphemes. Expecting the number of code points to equal the number of graphemes is admirable but unrealistic. I don't expect the number of code points to equal the number of graphemes. &gt; One way of doing that in Python is with the `regex` module What I'm asking is, wouldn't it be more sensible for Unicode string comparisons and methods/functions to use graphemes, not code points by default, instead of having to use `re`? Would it not be useful to have a type that behaves like text, not a sequence of code points? Is it possible to make a `text` type that knows 福 and 福 are different but that `b'u\\u0308'` and `b'\\xfc'` are the same? 
Most baller tutorial.
Docker is on our radar.
The integrated debugger has been a part of PyCharm since 1.0. The new thing is the in-line debugger that displays the values of the variables next the their definitions inside the source code. It's just a matter of visualization.
Since VB3 in 1990 at least
Whoops, yeah. Brainfart. Thanks!
I heard Guido uses print statements most of the time. Don't know if it's really true. The last one in this list: http://hairysun.com/blog/2005/02/19/guido-van-rossum-building-an-open-source-project/ I also use gratuitous log statements, which prints to console and log file. It helps tremendously from a deployment standpoint. Sure you can pdb or inline during development all you want, but when the customer calls, it helps to see what **they** were doing. Immediately after creating a function, I add a simple log line including any parameters and their types. Now I can capture what the customer did and I have an added bonus to see what's going on during development. If stuff gets tricky I can pdb in.
Google uipath. Should be what ur looking for. Expensive though, but might check out their trial. 
This generates PEP8 warnings and is a bad example.
Is this a free upgrade? I just got the last version
If I wanted to swap the location of two keys in a SortedDict what would be the best way to do that?
Sorry version 37.0.2
This thread is strangely inspirational to me. Going to book mark a lot of this stuff. 
Also bin is "bine"ary and usr is "youser". WGAS.
What does this mean for the asyncio module? Is there any reason one would keep using it when async/await is a built-in feature?
Once they port these to VS Code, I'm sold.
A lambda to me indicates a temporary or throwaway function, which is exactly what is happening here. Def is for something that will be used in multiple places/functions.
A quick look shows that your return statements are in the elif blocks, so you never return a value for half the code paths. The return statements should probably be outside that block. It's a common mistake for people starting with Python if they have come from non whitespace dependent languages. 
You were faster. :0) Also importing Decimal and not using it... But with second look there are other problems... Too many problems...
`x` was the first Fibonacci numbers (`x=[1,1,2,3,5,8]`), where 1 appears twice. So the `set` has 5 unique elements.
This is probably just a personal thing, but I've never gotten the hang of debugging Python from a command line. I use it all the time in PyCharm. 
Great explanation.
asyncio module is over-engineered and just awful. I should be replaced with something more pythonic and lean.
Working on it :) Edit: Wooh, fixed.
Thanks!
You should probably change your twitter credentials so someone else doesnt use them.
Yeah man, whoopsie. Thanks.
&gt; What I'm asking is, wouldn't it be more sensible for Unicode string comparisons and methods/functions to use graphemes, not code points by default, instead of having to use `re`? I agree that things like iteration and probably even indexing should use graphemes. *However*, I think you should still be able to access the code points, which puts pressures on what you can make equal. The problem is basically that other systems in common use don't use a normalized encoding. If they did, it would likely be a normalized unicode encoding, which is not forwards compatible and leads to the problems OSX has. It is possible to make a forwards-compatible, normalized encoding, but it's useless without strong industry support. 
Pretty much. I have a build server setup so when I git push code it automatically builds the image, runs some tests against it and if it works then it ships it out to a real server. But the simplified version is as you described. Commit code, build image, put it onto a registry, then pull it on your server(s) and restart. I keep everything stateless on the app servers and only use volumes in development for app code.
I'd just make a module level function. 
You're free to write a better library. It will be gladly accepted to the stdlib. And *if* you have any concrete examples of "just awful" things in asyncio - please open an issue on the bug tracker. Same for "over-engineered". It will be fixed.
First concrete example: There are two different classes in asyncio module (Future and Task) to represent pretty much the same thing (a suspended coroutine). They can be even used interchangeably in some asyncio functions. What's the difference between these two? Why do we need both of them? Second concrete example: asyncio.Futures are named the same as concurrent.futures.Futures. But these are two completely different kinds of objects!
I'm running OS X but it *shouldn't* make a difference.
What's the point of commenting on a post that no one is paying attention to anymore ? 
I do not get prompted with the /users/username/.virualenvs... instead i get the list of error messages. Did you manually type in the location or did you run as is?
you can ignore that, it's only applicable to older versions of Python not using pyOpenSSL. &gt; Certain Python platforms (specifically, versions of Python earlier than 2.7.9) have restrictions in their ssl module that limit the configuration that urllib3 can apply. In particular, this can cause HTTPS requests that would succeed on more featureful platforms to fail, and can cause certain security features to be unavailable.
Thank you! fixed my settings and now its working. Hope you have a nice day.
Thank you! Hope you have a nice day!
Thanks for the writeup, this is a problem I'm encountering a lot lately
Post the code. Every time you make a change, post the code. Trying to describe your changes to us is useless.
Could you share some details (scripts example) you use for your setup or that's private?
Please do! And show me what you come up with if you can :) 
to teach you at least about paste board
Great writeup, thanks for sharing the solution.
There's a few ways you could do it. The best way, in my opinion: api.update_status(status="The current temperature at is {} degrees".format(read_temp())) A way in the same method you were attempting: api.update_status(status = "The current tempurature at is " + read_temp() + " degrees.") Or the old string formatting way: api.update_status(status = "The current temperature at is %s degrees." % read_temp())
what about multi-tenancy Nick? You are addressing a lot of the functional aspects of building SaaS apps, but multi-tenancy is a fundamental infrastructure requirement that if not implemented properly will lead to scalability issues -- i.e "performance at scale" when there are several tenants (customers) using the system. Just a constructive piece of criticism on what I think is a worthwhile endeavor. Good luck!.
This is a frequently asked question, but the short answer is that either is fine to start with, and switching between the two usually requires a few minor changes. I use 2 almost exclusively, as I standardized my department on it a while back, and attempts to migrate have been... challenging. You may as well learn 3, and switch to 2 later on if needed. 
2 is still in common use, but it is no longer supported by the Python developers, and won't be seeing any future improvements. Python 3 has really god unicode support for strings by default, which is really important in the modern web. Python 2 is still a good language, and it definitely has more library support. If there's something specific you want to accomplish and you know there is no library built for it in Python 3 and there is one in Python 2, then use Python 2. However, since you're just starting out and want to learn from scratch, I have to say definitely start with 3. source: https://wiki.python.org/moin/Python2orPython3
I start all my new projects/scripts with Python3 and usually write it to be backwards compatible. That said, as a new person to the language and frameworks - you won't run into a lot of the incompatibles for a little while. When you do - enough others have hit that where a quick search clears it up and as you learn the language more - you can see the language feature changes made and why. That said, there aren't big enough differences a typical newb will hit for a while so choosing either won't put you into a bad spot! Most of the larger web-frameworks support both (django, flask, tornado, etc.). A few things to read: * [Python Wiki Article](https://wiki.python.org/moin/Python2orPython3) * [What's New in Python 3](https://docs.python.org/3/whatsnew/3.0.html)
I don't understand though, other than the counts what's the difference. Counts are useful in automatically finding repetitive content maybe, but typically if you're scraping something you go in chrome dev tools and see what the parent looks like and just do parent &gt; children.
gdb doesn't let you really play with your code. You can't add a breakpoint and then create a new function and run it in-scope at that breakpoint. Also what people are talking about here is the "inline debugging" that puts the value of variables next to them as the debugger runs. If that doesn't make sense check out the release video, it's pretty cool. That said, gdb is awesome. You can even call existing functions from within gdb using the 'call' command (but can't define new ones). 
I mean it's not perfect, but I was using for a class project for some language processing and I had a pretty beefy data structure, and watching it grow and shrink and move around (even if most list variables went off the screen) was really cool. It's not revolutionary, but I think it's a really cool addition that will assist me in debugging stuff by making life a little easier, time will tell. 
The only way that's possible (that I'm aware of, at least)is if you either have changed the permissions on /usr/local/bin (unlikely) or you are still using 'sudo pip install xxx' Some more info about how you setup your virtualenv and the exact commands you are issuing would be useful....
I really don't see this shit you are talking about. 
You deserve a Nobel Prize....or at least some donuts and a coke :) 
( ͡° ͜ʖ ͡°) What kind of coke? Edit: I'm allergic to diet. 
So if it's used once, but can't be represented as a lambda, you make it a module level function to further obscure the fact that it's used once? That doesn't seem like a good idea.
I saw your PR, thanks for contributing :)
This was my issue for a solid day haha thanks for this nugget of information ;] Huzzah!
nope it was sudo .... thanks a bunch, i should have realized.
Your article would really benefit from being an iPython notebook. [See here](http://nbviewer.ipython.org/url/norvig.com/ipython/TSPv3.ipynb) for a cool example.
Diffing the count results for different pages would often help too (though not if they all give the top n links). I'd like to try something that looks at lower level tags, say to find a table with lots of td tags even if they're divided between several trs. Divs in arbitrary places can create this kind of problem where no node has too many children because of consistent branching. Treat each node as its tagname path from the root, then do the counting and sorting. For added benefit, treat each node as either its tagname or its id to find a specific table with lots of tds instead of merging all the tables. So you'd have all of these: &lt;table&gt;&lt;tr&gt;&lt;td&gt; &lt;table id=0x12345&gt;&lt;tr&gt;&lt;td&gt; &lt;table id=0x12345&gt;&lt;tr id=0x23456&gt;&lt;td&gt; and use some scoring criterion to figure out which is more interesting from their counts. Adding number of children as a pseudo attribute would give a good hint about structure, as would hashing the union of the child tagnames. &lt;table id=0x12345&gt;&lt;tr nchild=4&gt;&lt;td nchild=1&gt; 
freeze
You're right, one of the problems I have with iPython is that it doesn't output in markdown (unless I'm missing an update). 
Use pynsist. It is really the easiest way of doing packaging for Windows.
When you say py2exe "doesn't work", how doesn't it work? It works for many people. And I don't understand what you mean when you say "countless external modules to execute properly"...py2exe and PyInstaller don't have that AFAIK. I can't even imagine what you could be talking about. 
The point in iPython notebook is not to output as markdown; it's to have a real python kernel on the server side where your readers can run, mess with, extend, and play around with your code.
Right, I was thinking that in my head a little bit after I replied last. I guess what I meant to say was that I haven't really considered using ipython because I'm building my own static blog generator for fun. I'll look into what's possible with ipynb when time permits.
Well, when I copy everything exactly from an example code, and run it, an error always comes up saying 'no such file or directory exists'. After diving deeper, I found that a certain part of a module doesn't exist. And by external modules, I mean I have download additional modules just to convert a program into an executable. Doesn't Python have a built-in way of doing it without haveing to get outside help?
I don't use Ansible. I used to, but not in combination with Docker. docker-compose declarations just unwind into standard docker commands. You run the raw commands but in the context of a service manager.
http://dpaste.com/3EBGP4S unfortunately the dict themselves waste a bit of space (yes I know its a bit biased against dicts, but it is still a significant difference regardless)
What about using external modules like py2exe?
Adding to the advantages of rst: its user-definable roles and blocks make it incredibly flexible.
Woah! Code in movie that actually *does* something!
Very nice. I don't even code in .py but this was a good read.
I can't get your page to load over https Edit: why a downvote? The site wasn't loading so I am informing OP
Huh? I've never seen a living notebook that didn't need auth to use... not for casual readers to have access to. Do you mean it's easy for them to download?
Not a bash script. A systemd script, or runit/monit/supervisor + initd/upstart/etc. script depending on what preference you have for service management utils. Yes, you would keep them in sync in that case. Volumes are pretty rare in production though. You would tend to set it once, let's say for a postgres database maybe and never touch it again.
Thanks man. Works perfectly.
Found my own problem, it was a typo in WERE. WERE is supposed to be WHERE
That all depends on the code of the program you're compiling to EXE. Regardless, if you want to plot a graph, write a C program that calls Graphviz, which is a program you could bundle with yours and would actually plot a graph into any number of file formats for you. http://www.graphviz.org/ I mean, if you *have* to have it as an EXE, that is. If you want EXEs, Python isn't really the programming language for you.
Thanks for doing this! I've been using Diffbot for my web and mobile speed reading RSS apps, [Glance](http://glance.wtf) and have been looking for a Free replacement for a while, so this is awesome. Any change you'd want to turn this into a free network service?
I remember not being able to find a Python 3 version of PyInstaller. Is there one now?
this error comes when the script doesn't find the `places.sqlite`, the script prints the path for sqlite file, can you please verify by going to the directory it points to?
py2exe works a priori quite well, but my question is why do you want to create an exe? For distribution? You can create installers easily with distutils. For code obfuscation? I prefer compiling my python modules using the Cython compiler and distributing the resulting dlls. py2exe does note compile code. It bundles the python interpreter and all the dependencies so that you distribute each time python itself. I prefer the solution of having my installer detecting if python is installed on the host computer and installing the right version automatically. With Innosetup to generate the installer, it is not that difficult to achieve. Best wishes Thierry
No problem! Honestly, at this stage of libextract, no. It's mainly because this library only extracts the HTML nodes and does no cleaning (so I see it getting mixed reactions as a free service). That and also the cost :/ But if we do end up producing a viable data cleaning lib, I'll consider doing it! 
It's still under development. You'll have to check it out from the `python3` branch on GitHub if you want to try it.
Dear god, if I can finish undergrad I will. These side projects are distracting. 
You can convert notebooks to various formats, including markdown and html, using [ipython nbconvert](http://ipython.org/ipython-doc/3/notebook/nbconvert.html). When you choose HTML, images are by default inline with data URLs, with markdown image files will be created.
This is a great opportunity to ask the same. I know a fair bit of python 3 and wanted to expand my knowledge. If anyone is willing to walk through and/or start a project with me that would be awesome.
For websites that have a JSON api for their information ([like reddit](https://www.reddit.com/r/Python/comments/3664fx/hi_rpython_4_months_ago_i_created_a_tiny/.json)), I'd use that over a scraper, but this can apply to so many sites, thanks :)
Your title is awful, you need to indent each line of code by 4 extra spaces on reddit for the formatting to turn up, and you should post questions in /r/learnpython. /r/python is for news and releases. Good luck with your project though. ♥
[If you've not been using this for a LONG time, you're missing out](http://i.imgur.com/zDw03FZ.png).
What A CS class will teach you is tools, techniques and a mindset for solving a group of problems, you could use any programming language, it is like discussing what pen and paper is good a writing class. 
I used their web lectures some time back (2011, if I remember correctly) as an introduction to computer science, and I really liked the lectures. They used Python 2.7 back then too. However, my understanding is that the main goal of the course isn't to teach you how to use a specific programming language, but give you a notion of computational thinking and how to solve problems using computers. The course regards the language more as a tool you may use to solve your problems. Then again, I don't know how the current course is structured, so they might focus on other aspects of CS.
OK, so you have a systemd has an action 'update' I guess, which recreates a container? How do you deliver container from a build server to production server? load + save or using a registry? I hope it's my last question. I understand that answering such questions eliminates the need of your screencasts :)
Yes, but it did not say what he was compiling. I just figured he was talking about compiling the knowledge base to a form which could be loaded onto one of the Tetraval machines. The Python interpreter is only a couple of megs of code and nowhere near "several terabytes". Even a full blown operating system (Chappie runs Linux by the way) with multiple language compilers and interpreters is nowhere near "several terabytes". As for the Python code, I thought it looked like Chappie was writing it as he explored his environment.
It doesn't come close to eliminating them. I don't have an update action specifically. I have the systemd service configured to understand that when a process stops, it should automatically restart it. I use a registry.
Well said. 
Yeah it takes some practice. When debugging remotely (in situations where PyCharm's remote debugger won't work), I've found pdb to be perfect. Usually I add `import pdb; pdb.set_trace()` in a couple of places then use `n` (next line) or `c` (continue to next break) to navigate around.
"an experiment to replace ez_setup and setup_requires with something that works the provided mechanism adds a python path where very recent seupptools and setuptools extensions can be installed" ...what? what should this do? what does it do better than setuptools? How is this related to wheels?
basically this makes setup_requires use pip instead of easy_install and even supports installing a recent setuptools version to use for installation it tries to use wheels for installation
&gt; on the level with matrix Careful now.
Maybe you should specify what kind of project you are interested in :) I would be happy to help python beginners if the project is also interesting to me. Sadly I don't know much web to help OP
It's easy to code in Python 3 when you know python 2, since Python 3 is Python 2 but easier, with less traps. Don't worry.
Decorators are good, and ``-m`` is useful, but sometimes I don't want to wrap every single function in your decorator. I think it would be useful to also provide custom codec - so your preprocessor will do the job on import time without any decorators (it should also work on module scope, not only on something that can be decorated). Here is an example of mypy custom codec: https://github.com/JukkaL/mypy/tree/master/mypy/codec
You don't really need this now that pip installs in topological order, just make sure to put all the requirements in install_requires and import them lazily in setup.py extensions
Nice work. This is pretty similar to what I do for the very first step of my (currently-being-published) Web Data Extraction algorithm for social data. Most approaches instead do probabilistic matching by comparing trees in some way to allow some leeway in tag structures, which handles parents with variable children (ie. a &lt;div&gt; containing any number of &lt;br /&gt;'s). Not sure if you've read much about it (I didn't before creating mine), but here are some refs if you're interested: Jindal, N., &amp; Liu, B. (2010). A Generalized Tree Matching Algorithm Considering Nested Lists for Web Data Extraction. In SDM (pp. 930–941). SIAM. Retrieved from http://epubs.siam.org/doi/pdf/10.1137/1.9781611972801.81 Miao, G., Tatemura, J., Hsiung, W.-P., Sawires, A., &amp; Moser, L. E. (2009). Extracting data records from the web using tag path clustering. In Proceedings of the 18th international conference on World wide web (pp. 981–990). ACM. Retrieved from http://dl.acm.org/citation.cfm?id=1526841 Zhai, Y., &amp; Liu, B. (2005). Web data extraction based on partial tree alignment. In Proceedings of the 14th international conference on World Wide Web (pp. 76–85). ACM. Retrieved from http://dl.acm.org/citation.cfm?id=1060761 
many of my packages have requirements that are only needed for setup.py execution, and not for actual installation or installation via wheel, i dont want to impose those dependencies on users
*Ex Machina* worked so well because of the minimal setting, the claustrophobic sets, the small number of characters.
It's an english phrase that roughly means: "I agree" or "I also recommend this suggestion". When voting on a committee someone will usually put forth a proposal and they need a second person to agree with them in order to proceed, the more formal way of saying that is: "I second the proposal".
I think the preferred way to have permanent information available is to put it in the sidebar, and there's already a link to "Should I use Python 2 or 3?" on there. People will always ask this, if they can't find the official recommendation on the Python site or in the sidebar than they probably won't notice a sticky, either. You can downvote or use the "hide" button if you don't want to see those posts.
Attempting to make a remake of Cookie Clicker using pygame. It's my first project since I have just started Python not to long ago. 
&gt; you didn't take the high road in that discussion. I didn't start calling names, Lennart did start insinuating I was a troll (if you just bothered checking): http://www.reddit.com/r/Python/comments/272bao/python_34_slow_compared_to_27_whats_your_mileage/chx0kol &gt; that you joined that conversation with the specific intent of pissing people off I **started** that thread (if you just bothered checking) by posting the numbers of my pystone tests and asking for other people's experience. If that makes me a troll... &gt; What was your motivation in participating that thread? See above. I started that thread (facepalm). &gt; why are you replying in this thread? Because you referred to me as a troll even though I was not part of this conversation. Plus aren't these threads public? If you go to a public space and start calling a person names, then wouldn't you expect that person to retort? 
I would think C for writing Cython code or R for getting access to sweet libraries.
I think Python, Java, C is a good combo of mainstream languages for job marketability. Expand on that by learning different types of language. My usual first suggestion was a Lisp (Scheme/Common Lisp), but I've been wondering lately if Haskell is a better choice, given that big companies are now putting some serious effort into it (e.g. [Facebook definitely is](https://code.facebook.com/posts/302060973291128/open-sourcing-haxl-a-library-for-haskell/)).
&gt;The code is very obfuscated What about this code is obfuscated? 
I feel like the speed of development in Python and the speed of execution in C are pretty complementary. If you need to write something, use Python. If you need to make it faster, translate some pieces to C. That said, Python is a wiiiiiide open market right now. Depending on where you are, you can get a real nice job with just effort, willpower, and a comfort in Python.
As a language that works well with Python, I would suggest C or C++. These can be used for writing python extensions, which is useful for binding to other libraries or writing efficient code. As a language that complements Python well and will teach you a lot about how to better use Python, I would recommend a functional language, my choice being Haskell. F# is a good alternative, and I find Scala to be a practical but bloated language (in terms of its type system). Learning Haskell has taught me how to use the functional tools available in Python much better, and when writing Python I often am able to write efficient and clean code the first time around, rather than writing sloppy, slow code that needs to be reworked later. It's quite fun to be proficient in a scripting language with dynamic OO typing and a compiled language with static Hindley-Milner typing.
So what exactly is your problem? The small bit of code you present seems to be correct. 
Awesome work man. I was thinking about something similar for a while (but I was thinking about implementing custom import hook). Also you may want to change preferred extension because .pyx is already used by Cython (.xpy maybe?)
This is /r/python, not /r/compsci.
As mentioned C is a good choice unless you want to do web dev in which case (and this really pains me) Javascript, it's simply unavoidable in that sphere and *is* very marketable.
My professor insisted that we must have two while loops, one for the entire program and then one for the whole add item / ignore item / display list thing.. Anyway, thanks for that, I figured that's what it was but it still wasn't working, but that's because, for some reason, the cont is defaulting to "a" or something after the second menu I haven't created the display list function yet. I was going to work on that after I got the loops working. http://i.imgur.com/ONCKfGH.png Me hitting "i" should ignore the item then loop back to the second menu again, but it just goes into the additem function 
Please reconsider this directory struture. It's stupid. You're probably going to have circular imports everywhere and end up tying yourself in knots. Perhaps you could explain this use-case? You don't need to mess with `sys.path`. Assuming that the root of your package is somewhere in the path then all the modules under it will have a name that you can import with. Just use that. Example: # file: mainFolder/subFolder1/ClassA.py # importing: mainfolder/ClassA.py # absolute import: from mainFolder.ClassA import class_name # relative import (may need __future__ IIRC): from ..ClassA import class_name
The i is actually an L in your code, and even if you did type l, it still wouldnt work because your while loop is going to have the same value for cont on the next loop around unless you catch that return value from secondmenu in all those if statements. Taking a closer look, you're calling secondMenu inside of additem, so that you can display text. It would be a lot better to put the display part and the getting the users input in different functions. No reason to return value when you only want to display text. 
Yes but SQL can't do everything and certainly can't do a lot of things easily. Simple string manipulation comes to mind. Python can execute the query and then clean and organize the data in a myriad of ways, and then output it as needed. Perhaps saving it to a JSON file or sending it to the front end to be displayed in a browser.
This is awesome! I wonder if it could be used to write React isomorphic apps in python 
You're going to have to go into detail as to the problem you're trying to solve and why this is desired. The last time I did something like this, it was because I was using Python in place of a DSL and defined my own loading and execution semantics anyway.
However, `json.dumps` outputs the keys as strings even when they're not: &gt;&gt;&gt; stuff = Tree() &gt;&gt;&gt; stuff[6][1][2] = 'hello' &gt;&gt;&gt; stuff[6][5][1] = 'world' &gt;&gt;&gt; json.dumps(stuff) {"6": {"1": {"2": "hello"}, "5": {"1": "world"}}} 
For practicality: * C/C++ for optimization and native modules, as well as embedded * JavaScript for client-side web (with Python as the server) For well-roundedness: * Scheme/Lisp for how they approach syntax and language * Erlang for parallelism and error handling * Any functional language just to bend your mind into new shapes
Same for me here in Saudi Arabia (edu.sa). And it's not often that things work like a charm here...
UK here, .ac.uk works.
Good. If things work like a charm there, charms are considered witchcraft and someone will lose their head. :-(
What about schools that don't issue student emails, is there a different option for those? Edit: How I read FAQ?
[Here is the JetBrains student FAQ](https://www.jetbrains.com/student/#faq)
This seems similar to what /u/ingolemo suggested: &gt; from ..ClassA import class_name Can you explain the compile() and eval() functions?
You get an awesome polished IDE, instead of an editor. Try it out, check some blogs / videos about what it can do and then decide what kind of workflow works the best for you.. :)
I would love to do data analysis and robotics. 
Wut.
All true, thanks a lot. In our case, we simply wanted a version of SQL we could install easily, and we're Python people so chose that. Most of our users simply want to use SQL at work to download data in spreadsheet format. But a few are interested in basic data science, so we thought the Python interface would introduce them to a useful tool they could use later. Maybe there's a better approach, but that's what we did. Wut! 
I agree. I teach Python in a class at University and strongly suggest PyCharm.
Actually I moved everything to a separate directory so I don't have to close Firefox. Here is directly accessing the DB: C:\temp\ffox&gt;sqlite3 places.sqlite SQLite version 3.7.10 2012-01-16 13:28:40 Enter ".help" for instructions Enter SQL statements terminated with a ";" sqlite&gt; .tables moz_anno_attributes moz_favicons moz_items_annos moz_annos moz_historyvisits moz_keywords moz_bookmarks moz_hosts moz_places moz_bookmarks_roots moz_inputhistory sqlite&gt; .schema moz_historyvisits CREATE TABLE moz_historyvisits ( id INTEGER PRIMARY KEY, from_visit INTEGER, pl ace_id INTEGER, visit_date INTEGER, visit_type INTEGER, session INTEGER); CREATE INDEX moz_historyvisits_dateindex ON moz_historyvisits (visit_date); CREATE INDEX moz_historyvisits_fromindex ON moz_historyvisits (from_visit); CREATE INDEX moz_historyvisits_placedateindex ON moz_historyvisits (place_id, vi sit_date); sqlite&gt; .dump moz_historyvisits ...... INSERT INTO "moz_historyvisits" VALUES(2653,0,68689,1431714932525000,1,0); INSERT INTO "moz_historyvisits" VALUES(2654,2652,68690,1431714936377000,1,0); INSERT INTO "moz_historyvisits" VALUES(2655,2654,68691,1431714936687000,1,0); CREATE INDEX moz_historyvisits_placedateindex ON moz_historyvisits (place_id, vi sit_date); CREATE INDEX moz_historyvisits_fromindex ON moz_historyvisits (from_visit); CREATE INDEX moz_historyvisits_dateindex ON moz_historyvisits (visit_date); COMMIT; sqlite&gt; Hope that helps 
No homework please
That's brilliant! Thanks!
In Python the first string in either a module, class or function is called a "docstring". It is meant to hold documentation of such an object. Tools like Sphinx can extract those and generate HTML/PDF/... docs from them. For reference, a "module" is just a Python file. In Python lingo, a module is a file with a .py extension, and a package is a folder containing a `__init__.py` file. So, to be concise, a "module docstring" is the first string inside a `.py` file.
Sorry I cannot let this go. I manually ran the first command and it worked. C:\temp\ffox&gt;sqlite3 places.sqlite SQLite version 3.7.10 2012-01-16 13:28:40 Enter ".help" for instructions Enter SQL statements terminated with a ";" sqlite&gt; select url, title, last_visit_date from moz_historyvisits natural join m oz_places where url like '%http%' and last_visit_date is not null order by last_ visit_date desc; https://www.google.com/|Google|1431714914029000 http://www.reddit.com/r/python|Python|1431713593913000 http://www.evilmilk.com/|Funny Pictures | EvilMilk|1431614083958000 . . . sqlite&gt; So I cut the script down to: import sqlite3 sqlHist = """\ select url, title, last_visit_date from moz_historyvisits natural\ join moz_places where url like '%http%' and last_visit_date is not null\ order by last_visit_date desc; """ sqlite_path = 'c:/temp/ffox/places.sqlite' print(sqlite_path) connection = sqlite3.connect(sqlite_path) cursor = connection.cursor() print sqlHist cursor.execute(sqlHist) cursor.close() and got: C:\temp\ffox&gt;python test.py c:/temp/ffox/places.sqlite select url, title, last_visit_date from moz_historyvisits natural join moz_plac es where url like '%http%' and last_visit_date is not null order by last_visit_ date desc; Traceback (most recent call last): File "test.py", line 14, in &lt;module&gt; cursor.execute(sqlHist) sqlite3.DatabaseError: file is encrypted or is not a database C:\temp\ffox&gt; 
Could anyone please tell me the difference between using IntelliJ IDEA ultimate edition with the python plugin and pycharm? I am currently starting to learn how to use python along with Reddit's API and I am using IntelliJ.
It uses the same engine as Intellij IDEA, one of the most popular and highly praised Java IDEs, and it shows.
ha! I can assure you this is *not* homework! I've been out of college for twenty years!
https://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html
It would be really interesting to find out how React tags everything up and see if it can be reproduced in a stable way from something like this. The down side is you'd then have the same stuff declared in Python &amp; JS which doesn't seem ideal really.
Yeah, I noticed the Cython collision. Thanks for mentioning it. I thought to go with 'pkd' but it felt so ugly and I wanted something with 'py' and the 'jsx' link makes sense. I thought maybe it wouldn't matter as the uses wouldn't overlap but I guess it is still a source of confusion.
PyCharm is legitimately the best Python development tool I've encountered. Off the top of my head, some of my favorite features include: * top-notch code editor * good syntax highlighting and code completion, including for non-Python languages * built-in linting/"inspections" that you can customize to your liking * automated, intelligent refactoring (ex. you can pull out an expression into a constant or variable, rename variables and functions in a context-aware way, among others) * handy interfaces for debugging, build management and deployment, database management, etc. * integration with popular frameworks like Django, Flask, etc. * error highlighting * type checking * you can jump to a function or class declaration/implementation in one keystroke * unit testing integration * runs on Windows, OS X, and common Linux distros There are a lot of others but those are some of the big ones I can think of. Even the community edition is really awesome, if a bit more limited in features. I will say there are two big downsides: First, like any IDE, it tends to hog RAM and CPU, so slower machines will struggle with it. Second, once you're used to it, developing in a traditional text editor or non-JetBrains IDE feels a lot clunkier.
Ok, I got it. My python 2.7 installation had version 2.6.0 of sqlite3. So I downloaded from http://www.sqlite.org/download.html sqlite-dll-win32-x86-3081001.zip and unzipped sqlite3.def and sqlite3.dll In ../python/DLL renamed sqlite3.dll sqlite3-old.dll and copied in new version. Reran full script to get: c:/temp/ffox/places.sqlite https://www.google.com/; 2015-05-15 11:35:14 {'url': u'http://www.reddit.com/r/python', 'rev_host': u'moc.tidder.www.', 'last_visit_date': 1431713593913000L, 'frecency': 1530, 'title': u'Python'}, {'url': u'http://www.evilmilk.com/', 'rev_host': u'moc.klimlive.www.', 'last_visit_date': 1431614083958000L, 'frecency': 1053, 'title': u'Funny Pictures | EvilMilk'}, . . . YAY 
I don`t think that the code must be written by anyone special to be cool! Moreover, I think that the great success of Flask, is because he is open, or else it would be just a web.py improved. 
Yeah I remember the preview looking much different than the result. It seems like you could do a simple version of that by providing a popup when clicking on a function name with a certain modifier key.
This looks promising. You're right about the price, though.
I am going to try this with fiddler. Thanks for the suggestion!
Intercepting the network traffic seems to be the most promising of the methods people have suggested so far, especially considering the availability of free tools out there to be able to do this.
/r/learnpython please
meh, should be free regardless. not worth much value as it is, but good that .edu works for now.
Folders are used to define packages. Modules are files with python code. Classes are defined inside modules. Classes, modules and packages are different concepts, not related hierarchically [*]. You can have: mainFolder ModuleA.py folder1 folder2 folder3 ModuleB.py And have ClassB in ModuleB, and ClassA as as subclass of ClassB in ModuleA. Or viceversa. So, if your class hierarchy is going to grow, you don't need to store the subclasses in submodules, or even in the same package. [*] Well, not enterily. A subfolder is a subpackage. Modules inhabit inside packages. 
The FAQ implies some of this, but specifically: * The plugin lags behind Pycharm in features. They come out in Pycharm first, plugin within a few weeks or so. * Project setup is way more complex in IntelliJ, with lots of irrelevant options for Python. * Ditto menu options, lots of irrelevant stuff. * IntelliJ has a few extra features. Think Project Templates are in IntelliJ but not Pycharm, last I checked, for example. I've never tried using them with the Python plugin, though. The biggest reason to get IntelliJ, though, is if you want access to jvm languages like Java, Scala, Jython or JRuby; or you want two or more of the following: Python, Ruby, PHP. At the point you'd be buying Pycharm -and- Rubymine, or Pycharm -and- PHPstorm (god help you), etc., you're at the price of IntelliJ. You may as well spring for the JVM-based language capabilities too and the somewhat richer plugin repo. On the plus side, they all support JavaScript, so Webstorm is pretty much unnecessary.
Well for one, don't call them all classA. How about classA, classB, classC for starters? I'd suggest knowing exactly what your layout is, otherwise you're going to have to use metaclasses, which given that you seem like you're new to Python, I strongly recommend against. Classes always have the ability to extend infinitely, but there has to be a base class. Also, you're going to run into issues with calling the proper class, so avoid it.
Wanted to buy a board, but was a bit discouraged by the lack of community, resources and examples. It's still a budding project though, perhaps in a year or two it will be ripe enough for me
Yeah, I used my university's email which doesn't end with .edu, and it worked fine.
Can confirm for Ireland. 
Well the reason why I want to have it as an exe, and perhaps this is not the solution, but I want to produce a graph from a text file without having to open up Python.
I've only just started using it with my &lt;1k line project, and it's having trouble determining what my class method is returning, if I'm not in the same file. Is there a setting somewhere that lets you boost the prediction strength or something? In Wing, you can at least go into debug and it uses perfect completion, but in Pycharm, it's still not coming up. The debugger panel correctly identifies the variable as a list, but I can't get completions for it.
Wow, thank you and JetBrains.
Actually I think I got the answer to the problem, you are running the script in Windows env, the path of sqlite is configured according to a unix env, I am sorry :) I will fix it now, I was going to but I don't have a windows machine with me, and the ones which I have access to don't have firefox installed in it! Edit: I just added a few lines which I hope fixes the problem you are having, but I need to ask you this, when you run firefox portable, does it store data in the default path it is somewhere in apps\data\Roaming in windows or does it store that data also in the firefox distribution itself?
Thanks, I was able to test it on a virtual machine on [pythoneverywhere](https://www.pythonanywhere.com) very quickly.
by the way, if you did some changes to make it work on windows for portable, it would be awesome if you can provide a patch or a pull request!
We are particularly interested in feedback from other Python communities that use method chaining (outside of pandas/scipy). * Have you encountered or addressed the problem of extensible method chaining? * Would the pipe protocol be useful to you? * Is it worth the complexity of allowing objects to override how they are called by defining `__pipe_func__`?
I did this with my Gymnasium (high school) e-mail. It took about a day, and after that anyone else from there could sign up without having to do it again.
good！learned a lot，thanks
More than alright! I'm teaching myself these things so your example was pretty much what I did/started to do. Also if you ever post an update about your progress I'd gladly proofread it. Your response to "have you thought about arg maximization?" made me smile.
It’s so sad it doesn’t work on Python 3. [I filed an issue.][1] [1]: https://github.com/Alexis-benoist/eralchemy/issues/3
That seems like an extreme statement. Do you know that or just get that sense?
That's gotta be a TOS violation. 
Pretty sure they have a filter for this because people do it the old fashioned way. Now take the following as purely hypothetical without any sort of endorsement: if you have multiple accounts to load balance and spread them out over a long enough time interval... Or wrote a bot to trigger when he comments.. Again. Not an endorsement. I actually think they are both horrible ideas. They are just the feasible ones.
Is Python not installed on the machine you're going to use?
Yep - this is exactly my point. really though if all you want is to pull some data and look at it plain SQL should work. if you want to get fancy and visualize said data and put it in an email report or webpage you'll need something other than sql I believe.
From experience, I would recommend making sure they get adequate experience with UPDATE, ALTER, DELETE, etc. Many data science tasks tend to start and end with only SELECT queries because the data has already been prepared, but in the real world data prep will be a HUGE part of the job and knowing the C, U, D in CRUD really well will be a major advantage.
Reading the entire discussion, I'm prone to simply nest functions. You made the chained examples pretty by using multiple lines and crammed the nested example on a single line with no spacing. 
It's a very feasible way to get yourself banned.
I've never used Wing but I've read what source assistant is and maybe you need the quick documentation window in PyCharm. It can be invoked by pressing CTRL+Q 
Hey, thanks! That seems like on the right track. Wing is able to show more information than what this seems to be showing, but it seems to be on the right path. Maybe I can do some messing around now that I know where to go. 
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Once somebody get fed up of it, he/she'll make a post to take it down and we'll decide again.
Thanks for the detailed reply, sorry just saw this. Fortunately I have free access to both through my school, so I will give PyCharm a go. No matter how hard I tried, I couldn't get IntelliJ to detect a module (PRAW) I was trying to import, so I will see if it works with PyCharm. 
Why would a student need the pro version??
This seems like the wrong place to post this.
https://youtu.be/p1iX0uxM1w8 Is this the video?
Vim scripting in Python would be cool.
The *best* way to do this is to not do it at all. You have ~~designed~~ inherited a system which is complicated and stupid and goes against the Zen of Python, so whatever solution you come up with is going to be complex and stupid and go against about half of the Zen of Python. You will have ugly, inelegant code that will be hard to use. I really, strongly suggest you rethink your design. (If you haven't already done so, run `import this` at a Python prompt.) If you cannot rethink the design, then you are stuck with a mess. It can be solved, but there is no good way to solve it. What I would do is something like this: Walk the directories [mainFolder, subFolder1, subFolder2, ...] in that order. For each directory: * add the directory to the *front* of sys.path, so you can import from it: `sys.path.insert(0, path)` * import ClassA to get the module in that directory * save a reference to the actual class: `list_of_classes.append(ClassA.ClassA)` * remove the cache `del sys.modules['ClassA']` * remove the temporary path entry: `del sys.path[0]` Now you have a list that looks like this: [ClassA, ClassA, ClassA, ...] where each class comes from the appropriate directory [mainFolder, mainFolder/subFolder1, mainFolder/subFolder1/subFolder2, ...]. Now to merge them. What I'd like to write is this: class MyClass(*list_of_classes): pass but that gives a syntax error. Instead, use the three-argument version of type: MyClass = type('MyClass', list_of_classes, {}) Now just use MyClass. Of course, if there's a bug in any of the subclasses, this will be practically impossible to debug, but that's a consequence of the design. Oh, you may want to reverse the list of classes first, so that the deepest SubClassA comes at the front. And if you're inheriting from anything else, expect to have all sorts of fun trying to get a consistent base class order. (I expect to see this written up on the DailyWTF in a few months or years.) Edit: I'll give you the benefit of the doubt that it's not *your* fault for designing this system.
&gt; Second, once you're used to it, developing in a traditional text editor or non-JetBrains IDE feels a lot clunkier. I'd argue the opposite. Developing inside of an IDE is extremely clunky when you're used to regular text editors. Going back to text editors from an IDE, I imagine, feels empty/lacking.
How about some free copies for open source projects?
There is only one problem, it tends to be relatively slow on big projects, slower than something like sublime or vim, but faster than other IDEs for Python 
I work on 14" 1080p laptop, and it seems fine both in ubuntu and win8.1, although I dont use scaling on windows so might not look great with scaling enabled.
Perhaps you want to develop something with django than integration come in handy
This is a hard problem and I'm not surprised you're struggling. You might want to look at branch of computer science theory called "Constraints". http://en.wikipedia.org/wiki/Constraint_satisfaction. 
Doing mostly scientific programming, is there anything the pro version gives me over community?
Please share your experience!
&gt; good syntax highlighting and code completion, **including for non-Python languages** This should be highlighted more. Integration for HTML, CSS, JavaScript, various Python templating languages, etc. is definitely a major bullet point for this editor.
Great idea, good luck!
If your open source project is older than 3 months and not a commercial project you can request a free pro license.. 
[It is a function](https://docs.python.org/2/library/functions.html#property). Decorators are just some syntactic sugar for passing a function to another function, and returning and assigning a new function to some name. E.g. this: @some_decorator def some_function(foo): pass is basically equivalent to this: some_function = some_decorator(original_function)
Someone needs to tell Disney!
Little of column A, little of column B. There are a large amount of startups in my area looking for talent.
A decorator is a function that takes a function as its first argument and (normally) returns a function. You can write your own function and use it as a decorator. It is a function. It should be important to a lot more python developers, if they understood just as another function, they could write their own. It is not some deep dark magic. I did another post a few months back about them: https://codefisher.org/catch/blog/2015/02/10/python-decorators-and-context-managers/
My point is that I've NEVER heard it called "The property function" except in your article. People say "Hey, use the @property *decorator*". I'd suggest changing the article title.
It is, but I just want to make the process easier - just two clicks to generate a graph, instead of opening python, then loading the file, then running the file, and generating the graph.
What is Kivy UI toolkit that you speak of, is it a widget drag n drop drop environment for Kivy? Quick google returned nothing,also I'm in mobile. I recently came across Kivent few days ago and was thinking of exploring it all summer after my finals,the timing for new version couldn't be more perfect.All the best.
As a warning to people thinking of enforcing privateness was using this strategy, bare in mind private variables are intentionally omitted from the Python syntax and thus are not idiomatic Python, and properties will slow down your code about five times. If you feel compelled to make all your classes have private variables, make well-documented descriptor to do it. Your intentions will be far more clear
[Part of the Kivy Organization.](https://github.com/kivy?page=1)
Fun fact. The original story of Aladdin was actually set in Ancient China.
a nice i use for that https://github.com/fschulze/sqlalchemy_schemadisplay
[8pin ESP8266!](http://www.ebay.de/itm/171486621891?_trksid=p2057872.m2749.l2649&amp;ssPageName=STRK%3AMEBIDX%3AIT)
Wow, I had no idea to look for an API for a lot of these services, lol. Nice work.
I've ordered like 3 of those, great if you just need WiFi through serial, but the lack of access to GPIO pins makes them a bit useless.
I've been ignoring the bootcamp thingies but now I see it everywhere and it looks like any intro course is now called a bootcamp. Is that the case? It's just 'into to SQL' and it's an intensive hands on 3 day course so it's called bootcamp? Or is there some other aspcet? The Syllabus and IPython notebooks are all on the Github repo, but the links in the Syllabus seem to head over to dropbox. Maybe make the links refer locally or explicitly to the Github repo. [This IPython notebook](https://github.com/DaveBackus/Data_Bootcamp/blob/master/SQL/SQL_Intro.ipynb) didn't load in the Github web page (for me). You commited a `desktop.ini` and `.dropbox.attr` file to the github repo. It looks like you didn't want those files there. I went through the first pdf of lecture notes. &gt;Trigger Warning: This will take some getting used to - but it's worth it Is that necessary in lecture notes? It's educational material. Do we have to apologize ahead of time for telling people something they didn't previously know? Or is it a tongue in cheek jab at people with anxiety disorders? If this is the candour of the course, and you present it with the appropriate tone/wink/nudge/sobriety/whatever I guess it's fine. A lot of the material in the first p[age is devoted to suggesting people really try to learn to program. But surely they know that and it's why they're in the class. Regarding why csv is so useful: if familiarity with Unix command line is assumed (obviously it can, right?) then maybe remind the class that csv is great since it's usually line oriented which means you can use head, tail, sort, awk, and all the friends to subsample or find out basic information about the dataset. Maybe linkfify FRED, Fama-French, World Bank so people can click through to the pages with the greate data resources promised by the descriptions. There is some `LaTeX` gurgle in the Python listings at the end of the lexture notes. `#%%`. IIRC `%%` is 'newline` in `LaTeX` so this somehow found itself rendered in the file. It will probably be fixed if you put a space between the `#` and the `%%`. I tried to find some actual SQL in the course (no mean feat) and found [this page which isn't displayed correctly by Github](https://github.com/DaveBackus/Data_Bootcamp/blob/master/Code/IPython/SQL_support_code_test.ipynb) &gt; `# don't read, just run!` Maybe wrap the offending code into a function like `def fresh_db_tables()` and make a comment saying it's deleting the tables so they aren't in the way. Then they can just call the function and it should be self explanatory. And they're not copying and pasting these lines over and over. &gt; table_name Should `print table_name` so the newlines are new lines. &gt; No postgres Booo!
Yes, i actually did :)
Yeah, it doesn't look that good with scaling enabled..... And the resolution I'm talking about is 3200x1800 
I dont see any repo named Kivy UI toolkit, i think OP and you are referring to [Kivy designer](https://github.com/kivy/kivy-designer)? I tried using kivy desinger a while back but couldn't get it to run.
I think JKovak was referring to Kivy itself when saying the Kivy UI toolkit. Kivy Designer is the only thing close to what you're talking about, but it's very experimental early release software because it hasn't attracted much developer interest. We have a GSoC student working on it this year, hopefully it will reach a more usable state.
It DOES work...! It is somewhat still in a developmental stage but I can easily scan networks, connect to local wifi, connect to local server, print website of remote server. not a lot of support but here is the tutorial I followed. https://learn.adafruit.com/building-and-running-micropython-on-the-esp8266?view=all They provide firmware precompiled! 
Where do you go that doesn't issue an email?
I have two very important issues with Pycharm 4 and 4.5. I've been using Pycharm since 2.7 and I've never had such issues until 4. 1- I can't "execute selection in console" if I've never opened console manually. Every time I click "Debug" button, I also need to open console so I can "execute selection in console" (shift-alt-e) [4, 4.5] 2- I can't set environment variables for django manage tool. Thus I can't use it. My database settings are stored in environment variables. [4.5]
I'd love to get all meta and create a search API for finding Python wrappers. Want to help? :)
Added a warning on top of the article...
It's about not using dunders on both sides, as that is considered to be the purview of the interpreter, not userland stuff. However, many packages disregard this (see: SQLAlchemy's `__tablename__` property). 
by default, pip install is version python3 on ubuntu machines now. You have to do pip2 install or you might even have to install pip2 for it. 
Awesomeness.
So putting this on my work computer would probably be a bad idea. 
Good stuff, thanks a million!
A decorator can also be a class though.
Cheers! I could sure use some help with adding more libraries/wrappers. Submit some PRs! :)
NEVER SUDO PIP INSTALL
just trying to trouble shoot...I was actually going through the steps to make a docker image.
Properties are awesome, however, if there are some complex calculations or some expensive operations involved, it's better to be explicit and just have functions like `calculateX()` or `fetchY()` or something like that.
1. This doesn't create private variables 2. The reason why python doesn't have private variables is that privacy doesn't make it easier to write or read code. You could also not have it in any language which has it, and use naming conventions and proper documentation just like Python.
uh that's Python AND web development: mucho stuff
I see what this article is trying to get at, but it does so quite clumsily. Properties are not exclusive to python, and they are not a "fix for private members". You could use C# or any other language where property and raw member syntax access is the same, and the same analysis will hold. Yet C# has the "private" keyword. Member access levels are a solution to two separate problems: restricting an API and providing compile-time checks. For the former, Python's approach comes from module and package structures, as well as the dunder. And the latter is simply not a concern for a language that has no compile-time checks like Python, as the author notes. But properties have very little to do with either. They're a mechanism to provide users with the impression they're just interacting with parameters, while they do something more complex under the hood. Properties may have also been a fix for the ugliness that were getters and setters in object-oriented, statically-typed languages, but that has little to do with Python.
You know I haven't typed up a feature list, something like: * Arena Memory Allocation for your GameSystems so that we can ensure entities with alike processing patterns are local to each other in memory. * A new rendering pipeline for Kivy focused on explicit multi-buffering so that it reuses instead of reallocating memory. * A basic subclassable GameSystem for creating your own Python game systems. * A more advanced subclassable StaticMemGameSystem for creating your own optimized Cython game systems that store all their data in arena allocated arrays of structs. * A growing library of built in GameSystems including: systems for abstracting 2d Position, Rotation, Scale, and Color data, 3 built in renderers that make use of different data formats, integration with Chipmunk2d for complex collision or 2d physics calculations. As far as what is coming up next: * Better Resource management, I have some ideas for making our internal model format both more efficient for rendering and more flexible for developing your own model formats. * Particles Module - There's the pieces of an old one but I need to finish converting it from the older code to the newer code. * Animation Module - It's not fundamentally difficult to do animations right now, but it should be readily available instead of roll your own. * Serialization support - There is no reason I shouldn't be able to support a variety of serialization schemes. I am considering [cap n proto](https://capnproto.org/). * Z-sorting renderers, both with and without pre-sorting. * Cymunk really ought to get updated to chipmunk2d 7.0, there are many things that used to be paid that were made free in the newest version. Other ideas that might happen: * Better SVG support (since 1.9 added basic SVG support we definitely ought to be able to look into this pretty easily) * Noise generation module * Dynamic 2d lighting (like sprite lamp, but open) * Perhaps even 3d support, not much is in the way here and there is already some interest in the kivy community. 
The API is available over at [http://api.pyimagesearch.com/](http://api.pyimagesearch.com/). If you have any suggestions for endpoints that you would like me to create, feel free to let me know!
Wow, that is totally kickass. As someone that enjoys using Cython in my projects this is fascinating stuff. 
Completely agree. This is where properties excel
I have really developed a huge love of working in Cython over the course of building KivEnt. If you are already well versed in cython you may want to consider looking at the source for the more internal (non-GameSystem) parts, as they have many cdefed functions that sphinx can't find but they're all documented in the source. I still need to look into a solution there. 
Yes. I was expecting some comprehensive review of seaborn, bokeh, matplotlib, pandas, etc., or some courses because of "learn data visualization" part, and instead all I saw was how to make a pie chart! 
I knew using a dunder method would be controversial :). I chose to do that for the sake of consistency with other ad-hoc Python protocols in the scipy community, e.g., [`__numpy_ufunc__`](http://numpy-tst.readthedocs.org/en/latest/neps/ufunc-overrides.html) and [`__geo_interface__`](https://gist.github.com/sgillies/2217756).
The post is not really about enforcing privateness, but why it is not needed in python. It is easy to patch the problem up after.
Sounds like you're trying to create a plugin framework. I [tried something 3 years ago](https://github.com/aspidites/ViCE/blob/master/vice/plugins/__init__.py). The requirements there were: * to be light weight * have no external dependencies * learn a bit about introspection * not require much from the user * not require the parsing of arbitrary files The idea was that plugins were simply a subclass which implemented a specific API*. If you check out the unit tests, you'll see how they were expected to operate. That said, I didn't come up with that on my own. Here are a few of the resources I (remember) using: * http://stackoverflow.com/questions/932069/building-a-minimal-plugin-architecture-in-python * http://wehart.blogspot.com/2009/01/python-plugin-frameworks.html * http://martyalchin.com/2008/jan/10/simple-plugin-framework/ If I were doing things today, I'd probably one again rely on introspection, or leverage setuptools' entrypoints mechanism, depending on my requirements. * Note that "action" plugins were over-grown functions, but I needed them to be subclasses of plugins, which is why I used `__call__`. I don't generally recommend doing something like this. A lot of the time [you don't need classes](https://www.youtube.com/watch?v=o9pEzgHorH0).
That's true, but it's a lot easier to get people interested in and motivated to learn that stuff is you first let them see "this is what a canny edge detector does" and then show them "and here's how it works" The theoretical stuff is important but you kind of have to let their interest grow organically or else their eyes will glaze over
I could not agree with this more. There has to be some sort of catalyst that makes people become interested in computer vision. Seeing a script that can detect faces in images, at least in my opinion, is an example of such a catalyst. And after seeing the API, perhaps the person wonders -- what libraries are used for face detection? Where they will inevitably find out about OpenCV. And if they read the documentation, they'll end up at the Viola-Jones algorithm. From there, they can continue to explore. Not everyone has to be academically inspired. But for those who are, we can help them find the details. I certainly respect that there is a difference between teaching computer vision and teaching how to drive a library, but I don't think there is anything wrong in teaching them in tandem. And furthermore, I definitely don't think there is anything wrong with trying to get people interested in a quickly growing field via visual examples.
A "[callable](https://docs.python.org/3/library/functions.html#callable)"
 local python install vs global pip call?! 
Yeah, that's why it's not working -- you're invoking your system install of python, but your command-line pip is installed/operating out of a virtualenv, for some reason.
I defaulted to webdriver because I use it a lot, but looks like this is also a solution: https://impythonist.wordpress.com/2015/01/06/ultimate-guide-for-scraping-javascript-rendered-web-pages/
&gt; than to create a new project in PyCharm and debug my code Yes, that would be an odd way to use PyCharm. pdb or pydev would probably be more appropriate if you're not going to use the IDE as an IDE.
There is no private because "We are all adults"
Do you have any sources for properties slowing down code ~5x?
There is a pycharm specific type hinting syntax.
I suggest SQL: solves a different type of problem than Python, and therfore complements Python really well. Even if you use ORM's, you'll still want to understand SQL to know what the ORM is doing.
Can you just use "requests"? maybe try asking this in r/learnpython ?
I don't think I can use requests; that's pretty much where I started. I rather doubt this is a good topic for /r/learnpython considering the advanced level of the problem. 
@kenfar - I appreciate. @SBSTP - I believe this is an appropriate title which syncs with the content of this article. There is nothing 'clickbaity' about it. Well! As nothing comes perfect in this world, there are always areas of improvements.
Python on a boat!!!! Wish I could go, maybe next year.
Most important detail missing WHICH CRUISE SHIP IS IT? If it's [this](http://imgur.com/k585Ab5) count me in. If it's [this](http://imgur.com/SzrqwRf) I'm not going anywhere near it.
OMG, you're right! Carnival Sunshine!
So good, I love that
the pandas library has built in functionality for the yahoo API. It lets you do something like # not the exact function call, do google search for # pandas finance yahoo to figger it out for real dataframe = pandas.io.finance.get_ticker('AAPL') print dataframe.head() # date, open, close, volume... etc # 2015-05-15, 120, 125, 120999985 # 2015-05-16, 124, 118, 142900000 # etc I highly recommend pandas, it was built by a financial dude to help with time series analysis.
_variableName is as good as a private method/variable if you're not an idiot. You shouldn't be messing with the classes/modules/packages internals unless you really know what you're doing.
Unfortunately I think it would be a little heavy if you know nothing, and it says it requires a little bit of programming experience. If you've made a couple small projects then that should be fine. The course I took was the beginner course. I'd had a decent amount of experience (some college, an internship) but my brother was completely fresh. He went from knowing nothing at all to being pretty competent as a programmer. It doesn't look like they're offering the beginner course right now though, I'll ask Santiago 
Take a look at [KivEnt](https://github.com/kivy/KivEnt). I haven't done much experimenting with it, but it seems fairly popular.
Creator of [KivEnt](http://kivent.org) here. I'll go over a little of why I chose Kivy a few years ago. 1. Cross-platform, iOS, Android, Desktop. Kivy is designed from the ground up not just to run on all these platforms, but to take advantage of their different types of input, has supporting libraries for interacting with the native apis, and has established build tools for the platforms that aren't covered by existing tools like pyinstaller. 2. I was looking to build games, but Kivy's generalized, not just a game framework means that games built with Kivy have access to a fairly nice UI library (yes the default theme looks outdated but this is easy to replace) and many other niceties that often you do not find in strictly-for-building-games tools. 3. Cython! When you are building games you are very likely to need to either call into C/C++ libs that handle complex tasks (such as physics calculations), or perhaps you just need to optimize your own code a bit. Cython is an invaluable tool in this area, it is incredibly helpful to be able to start by just changing your .py extention to a .pyx and begin only optimizing what really needs to be optimized. 4. Kivy has a beautiful architecture. There are so many great design decisions on display throughout the source. Yes it is way young (2010) compared to almost all of its competitors, and yes it is not as developed in some areas (particularly people looking for a drop in replacement for existing desktop ui kits find it frustrating), but if you are looking to have an app that runs everywhere EXACTLY the way you want it to, Kivy gives you the power and tools to build anything you want really, and has been built from the ground up with the idea that you will be modifying its basic UI widgets and building your own more complex UI constructs. This matters more in an area like games, interactive art displays, or other non-traditional desktop application use cases, and it is in these areas Kivy really shines. It's not really going to beat QT or .net for building a quick and dirty gui for your data migration tool or something, but for games, touch table kiosks, and other sort of less typical UI needs I think Kivy's approach and relative youth is a huge advantage. Kivy was born in the modern, fragmented ecosystem of different form factors and input methods. It is just at home building a touch app for a 50 inch table with kinect-style camera integration as it is building a mouse and keyboard application or a simple smartphone application. 
On one hand, this sounds like a lot of fun. On the other, I rely far too much on web-based documentation to be able to afford this cruise. (For those who don't know, cruise ship Internet is provided by satellite that is both excruciatingly slow and paid for in the realm of dollars per minute.)
I'm using Cocos2dx for C++, and if cocos has a Python version, I'd jump on that.
Am I missing where I can preview the book? It seems weird to pay for a book that's 20% done without seeing anything but the TOC with a 45 day money back guarantee, but no guarantee the book will be done in 45 days, meaning if the finished product isn't good, you can't get your $ back.
&gt;Wut! Is "wut" "woot" in some non-English language?
Kivy hands down. It was hilariously easy for me to make an app that ran on Windows, Linux and Android (I didn't try iOS or OSX).
Hey thanks for clarification. I figured since i cant access it with the old name it must be not available. Good to know \o/
Ah .. so easy!
It is a fine line. I teach a lot of engineering to many diverse fields, and I believe it is essential to understand the cost of failure of your abstraction, and that when designing complicated systems, the cost of failure should be linear. Everyone can think of their favourite comically highly abstracted framework that promises a 5 line of code hello world that does something phenomenally complicated. That is great until someone picks up that framework on ill-considered pre-tenses, throws together something that works half way towards what they want, and then to build the other half has to learn an exponential amount of everything as they unpack the abstractions to bend the framework to their needs. If you don't equip people for failure, they will resent your architecture ten-fold.
&gt; Install MS Windows &gt; Set up your Machine &gt; Download and install Anaconda FTFThem
My results (on 2.7.8, IPython 2.3.0) is different: In [27]: timeit('a.x', 'from __main__ import a') Out[27]: 0.06062483787536621 In [28]: timeit('a.y', 'from __main__ import a') Out[28]: 0.059065818786621094 Seems to run at pretty much exactly the same speed. Maybe that book is slightly outdated?
If you can make it the top entry, and in red, then yes.
Well, I made a cool thing with the data returned by the api, it loads an image and the data returned by the API and draws rectangles over the faces. My first test was [with the Obama image used in the API example](http://blha303.com.au/canvas.html), then I wondered how many faces it could find, and the answer? [One too many](http://blha303.com.au/canvas2.html), :P Another idea I had was to provide a form for a URL, and then load a canvas and the image and the API data and do it all live, but I can't get it working so far :(
Give us your python path : import sys, pprint pprint.pprint(sys.path) Then check where is installed PyRSS2Gen : find -iname "*PyRSS2Gen*" It's possible that docker has some strange path setup. 
http://bit.ly/1lznbcw Seems like I'm about to learn python data science from someone who can throw an infographic together, but can't copy/paste a shorted link.
but sometimes you have to wait 6 weeks until they fix a bug and release a new plugin version that was already fixed in pycharm.
came for an infographic that was supposed to teach me all of data science. got cancer instead. would not do business with again.
Who upvotes this crap ? do people actually read it ? 
Nobody mentioned it, but you could use Libgdx with Jython. Although cocos2d sounds nicer.
I know you are interested in python, but have you seen [Godot](http://www.godotengine.org/)? It isn't python scripted but its scripting is nearly identical to python. It looks and behaves a lot like python but you'll notice some differences. You should have no trouble leveraging your python experience to pick the engine up quick. The bonus is a really nice UI and is great for rapid prototypes.
Some brief info is in README file in repo. Hope someone would enjoy it.
Of course it's possible in theory, but why not use the API?
&gt; Python 3.4 is now a supported platform for all the Py3 ported &gt; modules.
The author of this article is very confused. The title is "Why Python does not have private METHODS" but it's about why Python classes do not have private ATTRIBUTES. Also then he mentions something about static methods which is completely out of context (I don't think he understands what a static method is)
I personally don't like that answer, it is too much of a cop out. And it does not fix what I am trying to address, fixing API changes. Which I think is a major part of the need to make something private. If you don't know if a attribute will change or not, you don't want to expose it. But it is not a problem in Python, since you can patch over it after the change.
This is an ongoing support https://twistedmatrix.com/trac/milestone/Python-3.x. 
Unfortunately, many books go one side or the other (mine included). Your theory based books jump right into the mathematics and can get overwhelming. I would recommend reading Computer Vision (A Modern Approach) by Forsyth and Computer Vision by Shapiro if you want the theory. For the practical side, Computer Vision with Python by Joseph Howse is good. I also have two books that I've written that teach the more practical sides using the OpenCV library. I won't post the link here since I don't want to self-promote, but if you're interested, you can easily find it from the PyImageSearch.com homepage. Also if you're interested in motion tracking, take a look at the [CamShift](computervisiononline.com/blog/tutorial-using-camshift-track-objects-video) algorithm. Again, this blog post is very practical and not theoretical, but you can jump right in and play with it. You can dive into the theoretical side by reading [this paper](http://www.jku.at/cg/content/e60566/e155475/e155539/FRCAMShift.pdf).
Nice! Great usage of the API. Also, take a look at the section entitled "Faces aren’t being detected in my images. What gives?" on [this post](http://www.pyimagesearch.com/2015/05/11/creating-a-face-detection-api-with-python-and-opencv-in-just-5-minutes/) for more information on why faces are not detected or false-positives are being fired. The gist is that OpenCV uses pre-trained Haar cascades to find objects (In this case, faces) in images. And while Haar cascades are fast, they are prone to false-positives or missing faces completely if the parameters are not correct for a given image. That's why we see more advanced methods like HOG + Linear SVM and deep learning used more.
I am from India. My school/college didn't issue me any email and they still don't. 
As I understood the chat API was redacted, but if there is another one I can use then perfect. You have a link for one I can use?
AFAICT yeah
CSS is magic.
This is brilliant! I didn't know that I can just learn it! Wow omg, now my life will change forever! 
Kivy hands down, KivEnt JUST released their version 2.0.... and I see the dev already posted. Kivy uses a widget system, and .kv files that might take a little getting used to, all in all they allow you to move boiler plate code out of the way so your game code becomes less cluttered. Give it a try.
Please note it must be seen in the view port without scrolling when the page load, and be easily dissociated from the other entries. It's the most important thing.
Yes, but only 66% of the twisted code base is currently ported, although it's now reaching a good conversion pace. Also, you can't run asyncio and twisted reactor at the same time, and twisted @inlineCallback uses yield, not yield from (nothing about async/await ATM). So it still requires a little work, but that's already a very bid deal.
You're asking the wrong guy.
Hey! I think this course is going to be too much if you don't know anything about coding. We also offer introductory courses (also with scholarships), but those will be open next month. Keep an eye on twitter.
CamShift wouldn't work all that great in grayscale, it's primarily used in 2-D color histograms, such as combining Hue and Saturation together to track color objects. If there is enough contrast between the object you want to track and the rest of the image, then simple thresholding is by far the easiest. You can also explore extracting the contours of the region you want track, like if you were [finding targets in a drone/quadcopter stream](http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/). And lastly, you can resort to training your own Haar cascade or [HOG + Linear SVM classifier](http://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/).
It should be possible with Selenium no problem. Start at facebook.com/messages/ and work from there. The only thing that is going to make it difficult is that you need to scroll up on the conversation for later pages to load. I don't use Selenium very much but I imagine that would be difficult. You might also look at the "download all facebook data" option. That might be in a nicer format. 
Thanks, I'll check out the Database and code profiling stuff.
Thanks. I guess my project is also going to have changing orientations. Is HOG orientation invariant? Are there any classifiers that work on grayscale, and are scale and orientation invariant?
Thanks :) ! I started with the pythonchallanges , lvl4 right now :P. will checkout the other resources as well!
I understand what you mean ! I was in working with Cisco earlier where I worked with C , currently with an ecommerce companies where the code is in Java ( python/PHP for scripting) . Initially I felt java was best of both world : C and python , but now I feel its not as good . What I hate about java is overengineering . We had to create an api to update/create/get some inventory data and expose it via rest , fair enough . What I hated is the design discussion : 10s of frameworks , wrappers , the code is almost impossible to figure out the flow! DAOs , interfaces , builders , google guice , hibernate , dropwizard , and plenty more things just for a basic api which is not going to be modified or extended later. In that regard I like C more , hard to figure out some syntax etc but the flow is much much clearer in C. C++ is something I feel is the hardest language to learn!
WTF you are right! That I did not expect.
No one is going to do your homework for you.
not to mention this garbage website scrolljacks, which is infuriating.
Check out https://github.com/RaghavSood/FBMessageScraper A word of warning: I have not tested the script. 
thanks for the help. The openSSL error is not appearing anymore... but now I have another issue: http://stackoverflow.com/questions/30031279/scrapy-error-error-downloading-could-not-open-connect-tunnel
I fiddled around and came up with an answer. I solicited input from others [in this thread](http://www.reddit.com/r/learnpython/comments/36hv7v/how_would_you_format_these_nested_function_calls/)
For C, I've been using Learn C the Hard Way.
Actually, it's the '\n' char at the end of u'Olaf\n'. Strip it using the .strip() . for x in team1bans: the_key = x.strip() champion_ban_count[the_key] +=1 print('Team 1 bans are: %s . Ban incremented for: %s' % (team1bans, the_key)) Also, one free hint I can give is that you can the [Counter](https://docs.python.org/2/library/collections.html#collections.Counter) structure to do that counting.
I'm not sure why you think this isn’t XML-RPC - it looks like it to me, so I think you might be over-thinking it or confusing it with one of its many offshoots. Based on a quick Google (and assuming I have found the correct product) there is an example using the standard Python XML-RPC library here: http://opensimulator.org/wiki/RemoteAdmin:RemoteAdmin_Examples#Example_1_-_admin_broadcast I realise it is not doing the same thing, but does that example work if you try it? Maybe try modifying the method call to login and add all the required parameters? If you want to stick with a hard-coded XML string, look at your headers. You are sending a content-type header after the payload - it needs to go before and be separated by two CRLFs. Also, the XML-RPC spec requires a content-length, user-agent and host to be specified in the headers.
&gt;Only thing is I know very little of how and why python works the way it works can you clarify and expand on this a little bit? what, specifically, would you like to know about Python? 
/r/learnpython please
Hahaha I've seen this one before :P but honestly webpages are so weird and arbitrarily coded, not all of them are properly formatted. After you know which tag holds the data you need, regex is one of the easier ways to extract data from a webpage in one go. 
This is freaking awesome. Thanks :-)
Yeah I've always found the Python VM to be more of a bottleneck than regex.
I was waiting for these news. I want Scrapy to support Python 3 already.
RIP Maple T_T
yeah you just set the cell type to text or markdown or latex or whatever you prefer :) oh and you can do slides like in ppt right off the bat
Finally got back to this and got everything working with deployment as well, thank for your help!!
This is in fact the correct product :D However, the API under discussion there is a remote administration module which does not use the end-user login methodology. Good eye though ;) EDIT: My bad, I replied before reading the entirety of your post. Your last paragraph cuts to the chase wrt to what sort of solution I need to find. I want to say I have had it that way (headers before the content) in some iteration of the work. That's one of the problems I've been having, is that I haven't been able to find much in the way of examples for doing things this way (and no real surprises there). 
Well there are a lot of tools that can bring python really close to the faster alternatives (cython for example) and cpu hours are cheaper than dev optimization hours but thats kinda offtopic. The performance increases havent been like 5x but enough to put effort into. It could also be wrong usage of regexes. One plus is that python tends to be more readable too.
Is there a milestone to switch the internals of twisted to asyncio ?
Hi , As compared to C , where I have to implement the maps/lists / dictionary whatever I use , I know indepth about what op will work the fastest , what it is more optimized for VS an easy to use list in python. What if I have to use say 1million objects : int or some big class , in C I can take into account and do the underlying implementation appropriately. In python I love the ease of use but not sure how optimized the things are , but I guess I would not be using python for such cases anyway. Apart from these , very basic things like for loops , in C its pretty simple , in python it is on steroids . It does so many things ,and I dont know how and why xrange is btr than range , and what is the complexity of an inline for etc. tl;dr : For C I started with going through K n R and some other books , same for Cpp , for python I just start making things without knowing my tools properly , its awesome but its a little unsettling at times.
Best way to learn see is to code firstly the basic data structures , like generic maps , lists , heaps etc then use them to build say a multithreaded ,safe hash table etc . As with any language the best way to learn is by coding :) , though it would be good to look at some open source implementation to get the best practices
Can you elaborate on this a bit ? Highly unaware of performance issues in python? xpath/pythonvm/regex performance/ ?
Apparently this ship is one of the cruise liners that has improved internet. Probably still expensive, but better than before.
I was sad when I copied and pasted because I thought it was too soon for me to make arrangements and also too expensive. Now I am happier. 
if you're gonna try to be an asshole, be a little more clever about it.
Appreciate it. Wasn't aware of the existence of the subreddit and posted a bit hastily.
Use [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) or another markup processing library. Sure, you could do most of the same things with RegExps, but BS will handle a number of exception handling cases and you'll probably wind up using something like it anyway once you get into nested structures.
Yep, as far as I am aware, that is the official spec by the guy that invented it.
I see the problem now that you've pointed it out for me but the .strip function doesn't seem to work out. When used as you've shown, it returns an error on Dr. Mundo now. This is team1bans before the for test and after the .split function: [u'Dr. Mundo', u'Shyvana', u'Olaf\n'] Traceback (most recent call last): File "C:\Program Files (x86)\JetBrains\PyCharm Community Edition 4.5\helpers\pydev\pydevd.py", line 2357, in &lt;module&gt; globals = debugger.run(setup['file'], None, None, is_module) File "C:\Program Files (x86)\JetBrains\PyCharm Community Edition 4.5\helpers\pydev\pydevd.py", line 1777, in run pydev_imports.execfile(file, globals, locals) # execute the script File "C:/Users/Tiko/Programming/parse_data.py", line 81, in &lt;module&gt; champion_ban_count[the_key] +=1 KeyError: u'Dr. Mundo' Is the \n put into the string (i actually think it's a list) when it is .split()? And would it be better to specify the .strip, i.e the_key= x.strip('\n') 
Python3 gets rid of xrange anyway, so you don't have to worry about that
Slightly off topic, but sounds like you also might need to get comfortable with using libraries in C. Glib and several other utility libraries provide lists and maps for C. Unless you've got constraints on your runtime environment in which case carry on...
No worries!
You van think of python as best practice c with some added bells and whistles. Sorry, writing on tablet.... In python you make a class: Class MyClass: Pass Def doStuff(self) Pass In c you would make a struct and pass a pointer to it to some functions. To make it object oriented in c you would need to name the functions MyClass_doStuff(self); With self being the pointer to an instance of a struct. Once you realize that, understanding what python does becomes pretty transparent.
Be careful feeding this non-american dates, as the way it detects dd-mm-yy is if it gets an exception parsing the date as mm-dd-yy, so it could seem like it's behaving correctly towards the end of a month only to give you something you didn't expect as the next one starts. There's a way to include a format string like the datetime module, so it's perfectly usable and pretty cool, but I thought I'd point it out anyway.
Change jobs to where you can do python full time. Nothing comes close to that level of exposure :P
Hi , Was working with Cisco and netapp both of which had their own custom OS ( linux based kernels though) , so most of these things were written by devs . (Not me , but I generally went through the source codes before using ) .What I meant is doing the same thing in python for a beginner will take a week , for C it might take more than a month before someone becomes comfortable with making useful things. I love C , nothing against it , (and yes I do need to look a bit more into glib) , its just that python struck me quite hard as being very easy to write new and useful things in!
Joining facebook in July , will move over to PHP now :P , even though some teams do use python but by and large PHP and hack along with Cpp
Will check it out , is it like a super fast interpreter ? I havent read too much but I think the default is Cpython? What are the cons of pypy that its not that widely used? apology in advance for silly questions but I am pretty new to this!
Coming from (mostly) perl/php, I am constantly shocked at how things work in exactly the way I expect them to. My first python program was 'hello world'. My *second* one provisions GPON equipment, providing web-based front end for customer service folks, and using telnet to talk to the equipment. Given really any prior programming experience, python is almost absurdly easy.
Good job man. Your life is bound to get easier. You're going to have a lot more power than other Python programmers too, because you'll have no trouble writing custom C libraries if you do need the performance. You have the best of both worlds. You can drop into native code and take full advantage of the CPU and you can script useful things super quickly. A good Python and C developer is extremely competent and useful. Having the ability to drop down into C and write extensions makes your python ability that much more powerful.
No worries. Pypy is an alternative interpreter almost fully compliant with cpython, but it is written in python (or rather a subset of it). The surprising thing is it usually runs 5 to 100 times faster than cpython with no extra work for most things. Basically, it uses just in time compiling so it can do stuff over and over again without reinterpreting it every time among other optimizations. There are a few things it doesn't play nicely with (apache/wsgi and some database stuff for example) but for the most part, it's quite usable. Point is, you should try it. Very worth.
Exactly! the best part is that it behaves how it expect it to, eg . for x in list , or x*2 for x in list , these are some of the things that you almost talk when writing such things and verbatim can be coded!
No idea what advantages this has over the threadpool stuff in the stdlib (or concurrent.futures etc)
Static methods are things object-oriented purists invented to get around the fact that they don't have, and need, first-class functions.
Awesome. Yeah, that's one route. If you want the logic potentially for stuff outside of Python, I'd use ctypes and wrap a shared library, but if this is purely going to be used in Python, that way is a great way to do it. I'm not sure if there's overhead to going one way or the other. I'm assuming there'd be slight overhead to going ctypes instead, but if that's a problem you'd probably not want to use Python at all.
Actually range in python3 is what xrange in python2 was. range in python2 returned a list with all numbers of your range in memory. range in python3 is an immutable sequence type, thereby being very memory efficient when iterating over it.
http://scrapy.org/ Python Scraper framework. Will likely handle a lot of the stuff you're manually building yourself.
[import antigravity](https://xkcd.com/353/)
[Image](http://imgs.xkcd.com/comics/python.png) **Title:** Python **Title-text:** I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/353#Explanation) **Stats:** This comic has been referenced 145 times, representing 0.2261% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_crebmbf)
Because old style classes don't support properties. The self.y assignment in the constructor actually creates a field called y. The getters and setters are never used. The decorators are valid so don't throw errors, but the class plumbing isn't there to take advantage of them. So, predictably, the speed of x and y are equal because they're both field accesses. Try running this in 3.x vs. 2.x. There won't be any getter/setter output in 2.7.9, and there will be in 3.x. class A: def __init__(self, x, y): self.x = x self.y = y @property def y(self): print('In the y getter!') return self._y @y.setter def y(self, value): print('In the y setter!') self._y = value a = A(1, 2) print(a.y) Edit: just to make things a little more surreal, *getters* work on old style classes, but not *setters*. It's probably because @property is a straightforward decorator, but @y.setter needs metaclass plumbing to recognize the decorator name. If you change the 2nd line of \_\_init__ above to self._y = y, you'll see that the getter is accessed down in the print(a.y) line. As soon as you assign to self.y, though, you blow away the getter and it's a field again.
Oh, I absolutely LOVE regexp! Rarely use it. Oh, it's amazing and I can solve so many problems with it! Rarely the best tool. But I still love it &lt;3 Actually, for scraping HTML I've found two simple *find* usually does most of the job, although I usually combine it with xpath. def between(self, a, b, start=0): pos1 = self.find(a, start) if a else 0 if pos1 == -1: pos1 = 0 if b: pos2 = self.find(b, pos1+len(a)) if pos2 == -1: pos2 = len(self) else: pos2 = len(self) return self[pos1+len(a):pos2]
Since you are watching for price drops, check out http://lotsof.coffee. There is intro system which allows you to send notifications to your android phone and/or desktop which I've developed. I'd provide more info here but I'm on my phone now. The backend is written in go but you can send the notifies with http POST requests.
Bloody hell. How come I've never heard of this? It looks pretty incredible... And it's nearly Python!
&gt; and I dont know how and why xrange is btr than range Even though this is gone in Python3, the distinction is pretty important. `range(0,1000)` returns a `list` of the integers 0 through 999. The bigger the range, the more memory is taken up by the list. `xrange(0,1000)` returns an `xrange object`. An xrange object does not take up more memory if the range is larger. It just supports indexing, len(), and iteration. This is one of my favorite parts of python. You can loop over anything at all that supports iteration. All you have to do to support iteration is the following. You need to have an `__iter__` method that when called returns an "iterator". All an iterator is is something that returns a value when you call `next` on it. If the iterator "runs out" of things to return, it raises a `StopIteration` exception. So when you do a for loop like: for spam in iterable_object: package spam what is happening is that `iter(iterable_object)` is called to return an iterator. Then `next()` is called on that iterator and whatever is returned is bound to the name `spam`, and the suite of commands in the loop runs. When `next()` raises `StopIteration`, the for loop ends. You can try this by hand: &gt;&gt;&gt; a = iter(xrange(0,3)) &gt;&gt;&gt; a.next() 0 &gt;&gt;&gt; a.next() 1 &gt;&gt;&gt; a.next() 2 &gt;&gt;&gt; a.next() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; StopIteration What I really like is that I can make any class I want that supports iteration just by defining `__iter__` and `next` to do the right thing. `xrange` and `list` types already support iteration, which is why you can use them seemingly interchangeably in a loop.
I know the difference. Just I did not put the time or effort into the post that I normally do, and it came out wrong and really sloppy. I am personally disappointed with how it came out. I should clean it up/rewrite parts when I get time.
 &gt;Any good resources for taking my knowledge to the next level and some good projects to take up next? I highly recommend going through the [Python tutorial](https://docs.python.org/3/tutorial/index.html).
https://github.com/ContinuumIO/blaze you can build abstract expressions and execute at your time of choosing on multiple backends. 
I don't fully understand the problem this module is trying to solve. The parse method is dubious at best without an explicit format string, the holiday functions make the mistake of confusing data with functionality, and the string representation of timedelta doesn't seem necessary.
I'd blame the engineering team, not the language. Granted: java has some warts due to backwards compatibility, but nowadays I see perfectly clear java as often as I see entangled python. 
If anybody wants to do something similar, I wrote a blog post about how I did it which might serve as some inspiration. No guarantees that my implementation is the best way to do this sort of thing, but it seems to be adequate for my needs. https://willrosecrans.wordpress.com/2015/05/19/python-script-editor-with-html-output/
Stuff like this makes me realise I should really start looking into switching to 3.x... 
But I have never heard anyone bitch COBOL "pain to use...."
Be warned, LPTHW is getting a bit dated nowadays most of it's fine but just be aware. You don't need `bin` ~~or `docs`~~. Executables should be done using [entry_points](https://chriswarrick.com/blog/2014/09/15/python-apps-the-right-way-entry_points-and-scripts/). Your documentation should be in the form of [docstrings](https://www.python.org/dev/peps/pep-0257/) but often external documentation (from sphinx or something similar) is also useful. I personally like to have a big introductory docstring in my `__init__.py` file which acts a bit like a stripped down README. You don't need `__init__.py` in `tests`. nose is pretty sound. I only found out about [nose2](https://nose2.readthedocs.org/en/latest/) the other day so I haven't had time check it out. As for `distribute`, it was merged back into `setuptools` about 2 years ago so don't use it anymore. If you're using `pip` you should be using `setuptools`. You should be using `pip` so you should be using `setuptools`. [More info here.](http://stackoverflow.com/questions/6344076/differences-between-distribute-distutils-setuptools-and-distutils2) For the `setup.py` it might be best to learn from example. [Here's](https://github.com/Sean1708/reFILE/blob/master/setup.py) one I wrote a while back. It isn't flashy and that actual project wasn't very good but that should get you up and running. Note that usually you don't need to mess around with `install_requires` like I did, I just had some weird dependencies, usually it just takes a standard list. Also note that I put all my metadata in `__init__.py` and then import it in `setup.py`, that isn't required but I like to do it so that I'm not repeating myself. Edit: Often a `docs` directory is pretty useful.
Read Head First Design Patterns. Saw: WeatherStation weatherStation = new WeatherStation Gave up on Java before even considering it.
Java is everywhere for purely tautological reasons.
http://stackoverflow.com/questions/2549399/what-makes-cobol-such-a-hated-language
I feel like the problem of Java is the stupid decision to force you into using OO. OO solves many things, but when you put it as a dogma, you lose expressiveness.
It does not seem to work? import inspect def hello_world(): print("Hello, World!") inspect.getsource(hello_world) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File ".../lib/python2.7/inspect.py", line 701, in getsource lines, lnum = getsourcelines(object) File ".../lib/python2.7/inspect.py", line 690, in getsourcelines lines, lnum = findsource(object) File ".../lib/python2.7/inspect.py", line 538, in findsource raise IOError('could not get source code') IOError: could not get source code Assume also that I don't have a file that contains the source code. Otherwise I could just cat it..
looks nice, I could definitely see myself using this
This only seems to be a problem if you are interactively defining the functions in an interpreter. It should be fine if you have it in a source file or if you have defined it in something like an IPython console/notebook. If you define it in the interpreter, Python compiles it down to bytecode and tosses the original source code. That's what you were seeing in your previous example I believe. 
It's a song! ♫*Weatherstation, weatherstation is new weatherstation*♫
&gt; So why has Java pretty much long taken over the programming world ? Same reason McDonald's is so popular.
I don't have enough experience with it to have an opinion, but it's what I started with.
Maybe if you looked, you would have seen that I answered him. 
I bounced between a bunch of editors, but frankly, I think Spyder is one of the best IDEs to learn on. The combination of the interactive interpreter and the editor side by side makes the idea of trying new things out REALLY easy. Now I use the ipython notebook more often, or for the larger project I worked on where I had a GUI designed with Qt Designer, I used PyCharm.
I'll add this: [Raymond Hettinger on Python Classes](https://www.youtube.com/watch?v=HTLu2DFOdTg) ..and every video of Raymond Hettinger :)
I set mine up as: project_name/ docs/ installer/ # the pyInstaller directory project_name/ __init__.py # includes a version parameter that is imported in the setup.py all_tests.py # imports all other tests subdir1/ __init__.py test/ __init__.py all_tests.py # imports tests in local dir test_a.py test_b.py setup.py setup_developer.py I don't use C code, so no bin directory. I like having a separate test directory for each component, so I can limit the number of files in my directory and know immediately where everything is (e.g. I dislike recreating the project structure in a test directory). All my test directory have an `all_tests.py` file and then I have more global level `all_tests.py` files.
Even more interesting is that `range` is a full sequence object: r = range(1000) r[123] #&gt;&gt;&gt; 123 r = r[3:-62:7] r[123] #&gt;&gt;&gt; 864 123 in r #&gt;&gt;&gt; False len(r) #&gt;&gt;&gt; 134 This is really useful for making slice proxies and doing maths on indices (eg. lengths of slices).
IDLE is probably good but I was previously using Notepad++ and so I continued with that.
[IdleX](http://idlex.sourceforge.net/features.html) has a tabbed UI and some other nice features.
I used notepad++ when I was first learning and quickly switched to emacs, now using emacs+elpy+ipython. I think an important pre-question is (Was python your first language?). If python was a second, third ... language a user may already have a preferred IDE/editor and not need to use something like IDLE to learn.
I've put my preferences into software: https://github.com/Springerle/py-generic-project Essential reading: * http://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/ * http://docs.python-guide.org/en/latest/writing/structure/ * http://blog.ionelmc.ro/2014/05/25/python-packaging/ (esp. on why "src" is a Good Thing)
Wrt the ide issue, I really like pycharm, but then as an instructor, I get all the jet brains stuff for free. 
I started with it and use it for trying out small snippets, but serious work is with PyDev.
ME TOO。
Why do you need an all tests file? Wouldn't nosetest by default run every one of them?
My advice for you: Go to pyvideo.org and watch all the stuff from David Beazly and Brandon Rhodes. [Brandon Rhodes - All your ducks in a row](http://pyvideo.org/video/2571/all-your-ducks-in-a-row-data-structures-in-the-s "All Your Ducks In A Row: Data Structures in the Standard Library and Beyond") about data structures in python. [David Beazly - Python 3 Metaprogramming](http://pyvideo.org/video/1716/python-3-metaprogramming "Metaprogramming") and [Generators - The final frontier](http://pyvideo.org/video/2575/generators-the-final-frontier "Generators - The final frontier") will give you a bunch of new ideas and new sights about pythons possibilities.
Marketing
I don't use nose. It has issues with running with multiprocessing on Windows. There are cases where things take longer with 8 processors than if you turned multiprocessing off because nose messed things up (again, only on Windows). On our CI system, we specify which files to run. Multiple all tests file also lets me run all the tests at once or all the tests in a subdirectory. They're super simple with `from ... import *` and a `unittest.main()`
I started with Python 2.3, so IDLE was the thing then. I switched to Textpad when I realized IDLE was double pasting blocks of code in random places when I moved a function in a large file. I stuck with Textpad until well after 2.7 was released. I tried Eclipse, but hated it, but eventually found WingIDE, which is amazing. IDLE was broken for a long time. It's still not good or the best free thing out there.
Yes, quickly latched onto IDLE when I learned.
Also, to expand upon this, Java was one of the first to do embedded right. No more cross compiling, and fun stuff like that. So it worked its way into tons of devices, and became a bit entrenched. It also did web stuff very well long before other languages, and still powers a lot of web sites today.
For me the perfect in between is Go, after you're ramped up you develop most things at the same speed and it has so much in the standard library already. Also concurrency with Go left me awestruck coming from Python. 
it feels like pre-made lego pieces. you know, you get a lego set as a kid, and there is a piece that looks exactly like a barrel. or a piece that looks exactly like a helmet. When you build it, you end up with something that looks llike a barrel or a helmet, but did you really make it? Its like learning how to assemble something, and learning more about making it look nice, having it smell good, than actually doing what its supposed to do efficiently Its like learning to talk to an interface or interpretor, instead of the machine itself. I strongly suggest unless you need it for specific reason it is already known to do very well, easily, that you learn c++ instead. You will be thinking about memory allocation, addresses, pointers, in a way that is very intimate to the "soul" of the pc. Rather than learning to talk to a program that wants to you think of etiquette and other irrelevant things. tl;dr: python, for me, felt very dumbed down and irrelevant. I would worry about things that never really mattered, unlike c++, that will present to you the problems as they are, as well as providing pre-made pieces if you prefer that approach.
it was like working with a third party system, as opposed to the machine itself. made me feel like a stranger in a made up world.
do you mean ... pointer-less?
Ahh yeah. Whoops. Yeah I'll cross post it there. Sorry about that. 
I can save you some time. Python became a ghetto after the language became obsessed with default Unicode representations. People who care about performance left for Nim. People who care about math went to Julia. People who like programming went to Haskell. Unless you're obsessed with default Unicode representations the exits are here, here and here.
They all do. They are implemented as methods which implies a date has some fundamental property of easter (or father's day, etc.) which is absurd. The definition of important holidays depends on the specific region, religion, language, nationality and should not be built into the functionality of a class. This information should exist in a data structure and be accessed by name, not as a method.
You only need to log in once but you do it every 60s. last_id = str(tweet.id) f = open("last_id.txt","w") f.close() f = open("last_id.txt","w") f.write(last_id) f.close() You don't need to open and close it to truncate it (I assume that's why you did it). Opening it truncates it already and it's ready to write. For : response3 = '@' + tweet.user.screen_name + ' ' + response2 use the .format() method, so this would look like: response3 = '@{} ()'.format(tweet.user.screen_name, response2) And then assuming that: with open("last_id.txt","r") as f: last_id = f.readline() public_tweets = api.mentions_timeline(since_id=last_id) works (that you can give since_id as a str with a newline at the end, and not strictly as an int), then the only other thing is that you never use your sys or requests imports.
What modules are you using to scrape?
Only in your warped imagination is Python a ghetto. I bet there are more people using Python and more Python job postings than all three of those combined.
Lowest common denominator. Few choices, no complex decisions (which wine to pair) or skills (using knife and fork) required. Java was written so masses of average and poor programmers could be marshal led to churn out code.
I've always used Notepad++ with it, and it's my first language. Any others you guys prefer over this? I'm on Windows, if that makes any difference.
... I feel like you can't run this argument unless you are programming in binary
maybe. you know what I mean tho
Check out [atom](https://atom.io/). It's not an IDE but it's like a much better version of notepad++. Multiple cursors and file tree browser are game changers. I still use notepad++ as, well, a quick notepad for small things, but I do all of my code writing in atom. I am looking into getting PyCharm though as I feel like I'm just about experienced enough that I'll be able use it without getting overwhelmed now.
I think https://atom.io/packages/term2 is good(but not best) package for you. It provides Terminal Panel for Atom, so you can run `python yourscript.py`.
Thanks for this! Great article! 
Yes, a plugin framework is exactly what I'm thinking about. I'm planning on doing it with the imp module. Thanks for all the great info and links. *Very* helpful. Thanks again. 
Why does that bother you other than having to repeat WeatherStation twice? Seriously a dumb reason to reject a programming language. 
In fact, I did not like static typing back then. Now in Haskell I love it, but I still don't like it in Java.
Sorry, let's look at a bit more of that code: public class WeatherStation { public static void main(String[] args) { WeatherData weatherData = new WeatherData(); CurrentConditionsDisplay currentDisplay = new CurrentConditionsDisplay(weatherData); StatisticsDisplay statisticsDisplay = new StatisticsDisplay(weatherData); ForecastDisplay forecastDisplay = new ForecastDisplay(weatherData); ...
You could, you know, name it something else. 
You are most likely correct in more support packages being built. 
Very good point, I'd forgotten about that. 
I did because I was told to, but really I wish Ipython notebook was integrated to the stdlib and idle removed.
pycharm community edition is still free , didnt use it much though ,using sublime text currently
Lots of Go suggestions :) will add it to my bucket list . Lot like C as in sits pretty close to assembly and a compiled language?
Go is very comparable in the look and syntax of C, there definitely aren't as many libraries in Go as there are Python (mostly due to age) but Go provides the basics to pretty much everything you will need. The two pain points I have in programming concurrent systems are normally memory management and concurrency which Go does well at. You may still prototype in Python just because it isn't statically typed and is less strict but anything worth maintaining I will write in Go. I invite you to come poke around in /r/golang to see where Go is being used and what people are doing with it. 
just saw this talk , the first 3/4th was really useful , the last 15~ mins or so didnt understand fully , something with annotations and stuff.
My advice for C is code as many basic ds as possible : generic hash tables , heaps , bst etc . Then use your .h files in bigger applications , eg try to build a filesystem on a file , or a multithreaded safe hashtable , the more you code the better you' ll get , for unix I really liked stallman's book , is a bit long but has a lot of info!
&gt; debugging those segfaults with gdb is even more awesome Yeah, sure. It's *awesome*.
extremely relevant xkcd :P
This thread has done nothing but make me want a big mac. 
I was already coding in other languages so stuck with other editors, also Tk widgets make it feel a bit weird and old compared to everything else.
I did because I started Python by reading your crypto book!
I upvoted you because I get what you're saying. C++ just feels more hardcore. And it is more hardcore. **But being hardcore in not what Python is about**. Python is like Lisp. Ever heard of Lisp? It was a crazy language that started as a mathematical paper in the 50's, but from which all other languages are still borrowing features (e.g. Java just implemented lambdas, which Lisp had 1958). Lisp offered a higher level of abstraction as well, and 'true programmers' shunned it. That's why in 1995, when the web was starting to take off, the dominant language was, you guessed it, C++. Everybody was coding in it...except for two guys, [Paul Graham](https://www.wikiwand.com/en/Paul_Graham_(computer_programmer)) and Robert Morris. They decided that because a server could run any language it wanted to, they could use Lisp, because its high level of abstraction meant that they could add features to their website much faster than their competitors, who used traditional languages like C++. If they saw their competitor had a new feature, they could add it in just a day or two. The result of their efforts? Yahoo bought their website in 1998 for $49 million of Yahoo stock (which is worth a quarter of a billion dollars now, though at some point it was over half a billion). All this is outlined in Paul Graham's infamous essay [Beating The Averages](http://www.paulgraham.com/avg.html). My point is, don't hate on Python. Google uses it in a lot of stuff. Instagram, Dropbox, Quora, Spotify and more are coded in Python. [Some of these sites and applications are valued at *billions* of dollars](http://www.npr.org/2012/04/10/150372288/instagram-sells-for-1-billion-despite-no-revenue). Time is money in the coding market, and when you use a higher-level language, the speed at which you can add features and scale is one of the major ways to keep your product on the market.
Hey , I did build a few for this usecase only , but still I struggled when in a machine coding round of a company where I dont have my libraries available and I have to use maps and heaps and plenty more things I have to reimplement them it gets a little irritating!
ok...i dont really know java that well. i had to learn java and the book i used had alot OOP design patterns. it was for building GUI's in java so i dont know if that was why. 
Every programming language has regex built into it, whereas only Python has BeautifulSoup. As I had mentioned in my above comment, I do advocate using the BeautifulSoup library. But I feel like regex is just something every programmer should know. It doesn't take time to learn, maybe a solid day or two to grasp it fully, and you can find the need for it in a thousand places. 
+1 for checkio. Going through the too answers shows you the 'pythonic' way of doing things 
I think I started out using vi, and shortly thereafter switched to Eclipse, because of the excellent git integration. By the way, are there any other open source IDE / editors which offer the same level of git support? Because I took a look around and the potentially interesting stuff was closed source.
No I went straight to geany.
The key technology is XPath. That's available in many languages. All links on a webpage: //a/@href , easy :)
sudo pip is kinda bad and also violates the philosophy of homebrew. You can (almost always) 'cd /tmp' first and use pip without sudo.
A much better Python install on OSX (or Linux, or that other one) is [Anaconda Python](https://continuum.io). You don't need to be root, and you can run multiple virtual environments that don't waste disk space (unlike virtualenv) and can be any version of Python you want, not just last decade's 2.x 
Wow! Mention of Erlang! As an Erlang programmer this made my day! 
The website for weasyprint doesn't look terribly active. It's sad because it really looked promising but there are a few gaps which stopped it fulfilling its potential.
I think [moment](https://github.com/zachwill/moment) is a cleaner implementation of the same idea
Thanks! Very cool. 
Very wrong; static typing is not the same thing as bureaucratic typing. Haskell is one of the languages that got static typing right: automatically inferred types, without having to annotate every single goddam variable. Say yes to static typing, no to type bureaucracy. 
&gt; After you know which tag holds the data you need, regex is one of the easier ways to extract data from a webpage in one go have you seen pyquery?
&gt; I dont know how and why xrange is btr than range read about iterators
The stdlib is where modules go to die. Why do you want IPython to die?
I personally go for [lxml](http://lxml.de/index.html). It's faster than Beautiful Soup and has a really clean API. I specifically use [CSSSelect](http://lxml.de/cssselect.html). 
I attempted to do the same just yesterday, but I failed. I think there is no way to do so...
[Cython](http://blog.perrygeo.net/2008/04/19/a-quick-cython-introduction/) lets you mix in near-C code in your python, and [PyPy](http://pypy.org/) is a JIT-enabled python runtime.
http://www.paulgraham.com/avg.html &gt; Ordinarily technology changes fast. But programming languages are different: **programming languages are not just technology, but what programmers think in. They're half technology and half religion.[6]** And so the median language, meaning whatever language the median programmer uses, moves as slow as an iceberg. Garbage collection, introduced by Lisp in about 1960, is now widely considered to be a good thing. Runtime typing, ditto, is growing in popularity. Lexical closures, introduced by Lisp in the early 1970s, are now, just barely, on the radar screen. Macros, introduced by Lisp in the mid 1960s, are still terra incognita. As for why this may be: &gt; I'll begin with a shockingly controversial statement: programming languages vary in power. &gt; &gt; Few would dispute, at least, that high level languages are more powerful than machine language. Most programmers today would agree that you do not, ordinarily, want to program in machine language. Instead, you should program in a high-level language, and have a compiler translate it into machine language for you. This idea is even built into the hardware now: since the 1980s, instruction sets have been designed for compilers rather than human programmers. &gt; &gt; ... &gt; &gt; You can see that machine language is very low level. But, at least as a kind of social convention, high-level languages are often all treated as equivalent. They're not. Technically the term "high-level language" doesn't mean anything very definite. There's no dividing line with machine languages on one side and all the high-level languages on the other. Languages fall along a continuum [4] of abstractness, from the most powerful all the way down to machine languages, which themselves vary in power. &gt; &gt; Consider Cobol. Cobol is a high-level language, in the sense that it gets compiled into machine language. Would anyone seriously argue that Cobol is equivalent in power to, say, Python? It's probably closer to machine language than Python. &gt; &gt; Or how about Perl 4? Between Perl 4 and Perl 5, lexical closures got added to the language. Most Perl hackers would agree that Perl 5 is more powerful than Perl 4. But once you've admitted that, you've admitted that one high level language can be more powerful than another. And it follows inexorably that, except in special cases, you ought to use the most powerful you can get. &gt; &gt; This idea is rarely followed to its conclusion, though. After a certain age, programmers rarely switch languages voluntarily. Whatever language people happen to be used to, they tend to consider just good enough. &gt; &gt; Programmers get very attached to their favorite languages, and I don't want to hurt anyone's feelings, so to explain this point I'm going to use a hypothetical language called Blub. Blub falls right in the middle of the abstractness continuum. It is not the most powerful language, but it is more powerful than Cobol or machine language. &gt; &gt; And in fact, our hypothetical Blub programmer wouldn't use either of them. Of course he wouldn't program in machine language. That's what compilers are for. And as for Cobol, he doesn't know how anyone can get anything done with it. It doesn't even have x (Blub feature of your choice). &gt; &gt; As long as our hypothetical Blub programmer is looking down the power continuum, he knows he's looking down. Languages less powerful than Blub are obviously less powerful, because they're missing some feature he's used to. But when our hypothetical Blub programmer looks in the other direction, up the power continuum, he doesn't realize he's looking up. What he sees are merely weird languages. He probably considers them about equivalent in power to Blub, but with all this other hairy stuff thrown in as well. Blub is good enough for him, because he thinks in Blub. &gt; When we switch to the point of view of a programmer using any of the languages higher up the power continuum, however, we find that he in turn looks down upon Blub. How can you get anything done in Blub? It doesn't even have y. &gt; By induction, the only programmers in a position to see all the differences in power between the various languages are those who understand the most powerful one. (This is probably what Eric Raymond meant about Lisp making you a better programmer.) You can't trust the opinions of the others, because of the Blub paradox: they're satisfied with whatever language they happen to use, because it dictates the way they think about programs. 
It's not a problem, it's a design choice.
thats a good answer I think. Also, I dont hate python, but I feel "tricked" by it, kinda. Mind you, my programming is only on a hobby-basis, so I dont know that much, but it felt so removed from reality. I want to "talk" to the computer, think how it does, define concepts for it, make it robust. It was like an imaginary environment, where indentations and formatting is more important than optimization and eloquence 
But it's a god damned weather station! 
In the Intro CS class I took in college, we used IDLE, so I used it for quite a while. I've since switched to Vim.
There's money in the ghetto.
To be fair, C++ has improved this over time. In C++11x you can use `auto` when the type of the is obvious from the assignment: `auto * weatherStation = new WeatherStation();` But using RAII something like this might be more likely: double getCurrentTemperature(Location loc) { WeatherStation ws(loc); ws.calibrate(); return ws.measureTemperature(); } Then you don't need to worry about deleting your WeatherStation when you are done with it, the destructor is automatically called when you leave scope. It's also a matter of opinion (IMO) if you really need to name a `WeatherStation` with very limited scope such a descriptive name as `weatherStation` as you already know the type. I think descriptive variable names are more important in more dynamically typed languages where you might need some hint as to what obect a name is bound to.
I think that's unfamiliarity with the language. I felt like that transitioning from C/Perl to Python as well. Push through it.
I was able to find the author's website. He has the usual social media memberships so you could ask him directly if you get no luck elsewhere.
IDLE will put people off Python for life. Python's supposed to make programming fun. I don't call fighting with crappy tools fun. Kids can work out how to install Minecraft mods. They can sure as heck work out how to install an editor. (You have to install the game, then you have to find the button that changes the version number to the one that matches forge, then you have to download forge, then you have to install forge, then you have to set the launcher to run forge, then you have to load the mod ... FFS, even I had trouble. Kids do all this now, so we shouldn't be afraid of telling them to forget all this 'out the box' and tell them to go get Atom or Sublime or Notepad++)
&gt; COBOL is still in use in a lot of financial institutions but would anyone today start a new project in COBOL? Your analogy doesn't make sense. A lot of organizations are still creating new Java projects, some surprisingly still targeting Java 7....
http://dronewx.com/briefing?latitude=51.683&amp;longitude=-0.314 &gt; No airports found within 10 miles. There's [at least one](http://www.londonelstreeaerodrome.com/). Charter helis come in and out of there very regularly. Maybe 'No data for this region' might be a more appropriate message. Also degrees F?
Do your own fucking assignment.
It's clearly an unusual paradigm, but it looks amazing. Can't wait to find a good reason for experimenting with it.
Wow, this is exactly what I've been trying to do for the past week! Thank you so much for posting this.
The challenging part for now is to use Flask with database. Tried the tutorial but can't quite understand how to integrate them.
Refactoring as part of the major version bump could make sense for a number of reasons. If they dropped particular 2.x features from 3.x, that makes refactoring easier because there are less special cases and subtle features to keep in mind when doing the refactoring: solving a simpler problem lends itself to a simpler and hopefully more maintainable solution. I bet that being able to simplify the language made refactoring more feasible. Also, as a major version bump implies that things using it might break, it is a great opportunity to, well, introduce the new bugs that are inevitable in a major refactoring. As you say, it probably looked like the right way to go at the time. I also think it still was the right way to go and that the python community needs to help out the team by more aggressive adoption.
Maybe, but flexibility is not what you want when you're starting up. "There should be one-- and preferably only one --obvious way to do it", as the Zen of Python says: you want structured things, the minimum amount of moving parts to manage, so that you can concentrate on understanding the language. Having to deal with the multi-window idiom (something that even Apple, its main proponent, has quietly ditched in recent years) is an unnecessary distraction imho.
Cool stuff :) I recently made a text/cli python game, I learned so much and I'm sure you did to. The best part is in a couple months when you look back at your old code and see how far you've come. Seems like no matter how much I learn, when I look at old code I wrote I get the 'wtf was I thinking' feeling. And check out pep8, good habits to get into early on 
No, considering everything that course offers is available from a free source, e.g.: * http://www.codecademy.com/en/tracks/python * http://learnpythonthehardway.org/ Also, a "python certification" will *literally* make any prospective interviewer laugh, possibly out loud.
No, I don't believe it is. A "certification" in Python is worthless, and I don't think there's anything in that course bundle that can't be found elsewhere for free.
s/coolest/most aweful/ :)
Server 500'd on me when I tried: Buffalo, New York as a city, FYI.
namedtuple in the stdlib: https://hg.python.org/cpython/file/da711bdcc1bf/Lib/collections/__init__.py#l404 Python 2/3 compatibility hacks: https://github.com/bottlepy/bottle/blob/master/bottle.py#L136 Template engines: https://github.com/bottlepy/bottle/blob/master/bottle.py#L3516 
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Fixed! Thanks for letting me know.
So.... unlike most things in my life which go by and get forgotten. This one keeps coming back to haunt me. :-) I have an automatic "look for the Pycon 2015 talk" cron job that fires off every month. Still no dice it appears. Are there any other talks which will provide similar enlightenment? I really liked the Boundaries talk!
I thought to be very creative use... very basic way of code obfuscation. http://stackoverflow.com/questions/13358451/compile-and-eval-of-base64-string 
Needs a longer title, and maybe a better text description.
www.web2py.com the best uses for eval https://github.com/web2py/web2py/search?utf8=%E2%9C%93&amp;q=eval
I used it to parse JSON by defining variables with the names of the relevant constants and just reading it in as a dictionary. Awful enough for you?
But... why?
Moment.js is deprecating creation of new instances without explicit format definition. http://momentjs.com/docs/#/parsing/string-format/')`
Because I was too stupid to use `json.loads()`.
I'll reply to you when I have more time, currently in the middle of exams
There is a good set of examples already. In a year or two some examples and tutorials will just get outdated. There will some new and new supported board but I doubt in any big changes.
Nothing, I need ideas. 
I believe that's quite right about lists vs deques. I've heard that CPython can do a specific optimisation with adding to strings, because it's reference counted. So `s = s + 'a'` may not reliably be fast on other Python implementations. In more detail: unlike `list.append()`, `s += 'a'` is not mutating the string (because strings are immutable), but creating a new string and assigning it to the same name. However, CPython can know that there is only one reference to that string, so it can take a shortcut, and reuse the memory where the old string was allocated for the new string, avoiding the need to copy all the data.
i'm using mechanize. Does requests have the same level of automation?
I actually started out with emacs, because that was the recommended text editor in the first programming class I took. It was painful (with no previous programming background), but I'm glad I did it that way. 
For me, it has a shitty API.
String concatenation is cheap *in CPython*, but not in PyPy or possibly other implementations. There it's quadratic because the JIT can't optimize it. .join() is more portably performant. Head down to "String concatenation is expensive." http://pypy.org/performance.html#micro-tuning-tips 
I could swear that I've never had to sudo pip after doing a brew install. It's operating out of the /usr/local tree at that point, as would be anything it touches.
Why are you version-pinning virtualenv in this? I generally just brew install virtualenvwrapper and let it grab its own dependency. It's worked fine for me. One other note, having bash-completion installed helps greatly for virtualenvwrapper.
Nothing against Anaconda, but brew does let you install python3 as well.
If someone executes `sudo pip install` just once, the whole directory gets owned by root, and all subsequent pip installs must come with `sudo` until it's fixed.
I get a lot of job offers for Python. They all so far have allowed me to be remote, but most prefer that you can come on site from time to time. It's usually a slight red flag if you're only willing to work remotely in a company. Company's are communities, and your unwillingness to be a part of it can be an issue, and should. I know I'd rather work with my co-workers and employees face to face. Getting people orchestrated remotely is also a massive pain. It can work for small businesses, but then they tend to fail, both because of being small and frail in nature, but also in poor ability to orchestrate and manage. There are lots of companies that are run right now with remote programmers and employees, but there is a lot to be said about physically being there. Being someone who is unwilling to find a local job, it means that you run the risk of eventually being let go as the tides turn. Sure, the setting right now might be in your favor as demand is high, but times change fast, and your habits wont. This is all being said by someone who works for himself and sometimes takes on jobs, so far all being done remotely, though I have been willing to go on-site sometimes. It's been more of a "team" effort when I work with someone rather than a "Career" or "job."
Here's another good deal: http://pythonprogramming.net/ Don't pay for beginner tutorials. If you ask me, I'd say don't pay for any tutorials, ever... but sometimes you might find you just really like someone's style, and they have some paid content or something. Or maybe books... but definitely don't buy online classes, yuck. The programmer community is literally like your new best friend. If you put in a little effort, almost anyone will help you, answer your questions, and lots of people put out free education.
&gt; Are you targeting everyone or just new programmers? For this poll, I'm targeting everyone, though I assume IDLE is mostly just used by beginners and non-software developers. &gt; I understand how "Not needing to install anything extra" can be an advantage. In my opinion, that's the *only* advantage that IDLE has, but it's a big one. (IDLE's also nice if you are just looking for a simple Notepad-style editor rather than a full-blown IDE.)
I'm about to start om book number 3, but I'm not sure how complete it is currently, and if I should start reading now, or wait. I haven't played around with django nearly as much as I did with flask, going through book number 2, so maybe I'm better off using a month or 2 building something in django, before reading book number 3? I hope this is not too OT. 
you do? I haven't followed any of this, but can't you serve on 0.0.0.0 (for computers in LAN) or 127.0.0.1 (locally, for machine self-consumption)?
Man, I can't get it to work at all
Visiting your profile page while logged out (or while incognito) will show up as user not found. Check rspivak's profile.
Once you guys understand the understanding on how to build a web server, you might want to check out [socket.io](http://socket.io/), a better alternative that uses the websocket API. [Here](https://pypi.python.org/pypi/gevent-socketio/0.3.6) is the python library to make a socket.io server. More info on socket.io [here](http://davidwalsh.name/websocket)
&gt; What do I need to do to get this to work? gcc I've never used Cygwin, but [google says it's easy to install](http://stackoverflow.com/questions/25705726/bash-gcc-command-not-found-using-cygwin-when-compiling-c).
This is so unnecessary and yet so awesome.
&gt; String concatenation is cheap *in CPython* *...sometimes.* Personally, this optimization was a terrible idea. It can break [really easily](http://stackoverflow.com/questions/24040198/cpython-string-addition-optimisation-failure-case). Any time you want to refactor the code, the optimization breaks. It even makes people think PyPy is slow. And most of the time this actually matters, using `''.join` is no worse.
Thanks! I remembered there was some CPython wrinkle I'd read as well and you found it. Agreed, re: .join(). Better just to stick with that in almost all cases. 
Gosh, all these benchmarks and not even a single attempt to explain important question of *why*? (Thanks [/r/minno](https://www.reddit.com/r/Python/comments/36of1q/myth_busted_repeated_string_runs_in_linear_time/crfoju1) for offering theirs.) How does the author know that the 4th figure is a quadratic just by looking at the curve? To make this clear, it should be plotted on a log-log plot and fitted to a straight-line to determine the exponent. Additionally, log-log plots have the advantage of showing some of the small-input behavior, which may or may not coincide with the large-input behavior because of caches and what not.
I recommend using [lxml](http://lxml.de/) with xpath. :)
My local work-ecosystem has very few Python jobs (almost none), it's mostly PHP, java, and Javascript. Remote work gives me the opportunity to get a Python job from another place in the world, while also getting payed in a better valued currency. I would prefer to not work 100% remotely, but when it's another country it gets hard to get face to face : ( 
Why the deprecated units? Who the fuck uses fahrenheit?
Post your code and what happens when you run it.
I've used [flask-sse](https://github.com/DazWorrall/flask-sse) in a project. For my application, the Asterisk PBX is generating events. For certain events, I call that library's `send_event()` function. Browser support is hit-or-miss for client-side support of SSE. I control my app's environment so I don't have to worry about it, but you may have to consider something else. One gotcha is that the SSE consumers (browsers) open a never-closing connection. This means you _MUST_ run your Flask an evented-type platform. I use gunicorn with gevent. Failure to do this will result in hangs after your server process opens a certain number of client sockets.
You need the zmq-devel packages, and in particular the zmq.h header. Not sure about how to get those on cygwin, though.
Is it an online API? You'll probably need to install requests (with pip or similar). Then you can do something like payload = requests.get('http://example.com/api/users/') and inspect payload accordingly. You might need an API key depending on the service, which you can get from the provider.
Oh well. Voat.co starts looking better with every passing day.
irrelevant
Adria's a dumb bitch just trying to start drama over nothing.
&gt; When you do s = s + 'a', it re-uses any spare space in s, but when you do s = 'a' + s it reallocates the backing memory on 'a' and copies everything in s over That can't be it, and trying out `s = s + 'a'` confirms roughly the same results as with `s += 'a'`. This stands to reason. When you execute `s += 'a'`, python can't modify the string referred to by 's', as it could be shared: s = 'a' t = s s += 'a' print t # this has to print 'a', not 'aa'
Decorators? They're just sugar for functions that take a function and return a function. Basically, @bar def foo(x): return x*x is exactly the same as def foo(x): return x*x foo = bar(foo)
Is this python being emulated by javascript in my browser, or an actual python being run by trinket.io?
I've always wondered if its feasible to do an ipython-notebook-as-a-service thing. 
Yes, kpurdon is right. You can install same python packages in different virtual env's . But you can't install differently configured same types of servers,Databases and other Software in a single system.Let you are a consultant and working on multiple projects. If you use Vagrant,then you can create multiple working project enviornments ( see here projects , not normal environments) . Other wise you will mess up the system. You can do same thing with docker. It is one more gun for shooting same problem. Thank you. 
The programme's wrong isn't it? It tells you how many heads there were, then leaves all the heads in instead of taking them out!
Yes, exactly. There's a [thread from a few years back](https://mail.python.org/pipermail/python-dev/2009-August/091125.html) on the Python-Dev list where one developer found that downloading data over HTTP from Python was ~~*thousands*~~ hundreds of times [slower than IE](https://mail.python.org/pipermail/python-dev/2009-September/091581.html) or ~~Firefox~~ wget. Most of the core devs couldn't reproduce it, but it eventually turned out to be due to an interaction between the repeated string concatenation optimization and the specific details of the OS's memory management and hardware. The optimized code failed for that *one specific user* and nobody else. After reading that thread, I would **never** rely on repeated string concatenation in production code. Not only can it fail, but it does so in a manner that is platform specific and almost impossible to replicate. Oh, and the kicker? The relevant code in the std library included a comment that it could be slow and should be replaced with a call to str.join. Guido described it as an [embarrassment](https://mail.python.org/pipermail/python-dev/2009-September/091592.html). Edit: Added links, fixed a couple of minor details I remembered wrong.
How does it tell whether or not the OS can cheaply resize blocks of memory? 
It doesn't, it just calls `realloc` which technically is a part of the OS anyway (though living in the userspace to varying extent) and which might or might not extend the same memory block instead of copying to a new one more or less often.
That's pretty much how dequeues are implemented anyway, so you don't want to bother with that extra little overhead in lists.
I actually had the honor of talking the CTO and co-founder of trinket in February this year. This site does more than just allow you to share code online. It is a tool to help interest younger children in computer science and teach them Python. It uses the same concept as Scratch, the drag and drop coding, but this will then be translated into Python and printed out beside of it, allowing a child to see the relationship between the two are. It is an incredible site and concept. They have put a lot of work into it and to create a useful tool to help children get involved in computer science. 
A python distribution
Because /r/learnpython will be able to do something useful with "I found some code online, and it didn't work. Without telling you what the code is or what exactly happened when I ran it, how can I fix it?"?
Any reason to have `send` take an Envelope rather than envelop's arguments? That is, rather than: r = p.send(html( content='&lt;p&gt;Hello 世界&lt;/p&gt;', subject='Hello world', sender='John &lt;john@jon.com&gt;', receivers=['doe@jon.com'], )) Why not: r = p.send( content='&lt;p&gt;Hello 世界&lt;/p&gt;', subject='Hello world', sender='John &lt;john@jon.com&gt;', receivers=['doe@jon.com'], ) Actually, I see that you have send_many, which allows for multiple envelopes to be sent, so perhaps scratch my last question. (Leaving it for posterity). That said, what if, rather than send, which proxies to send_many and send_many, this: def send(self, *envelopes): with self.connection() as conn: return [self.deliver(conn, e) for e in envelopes] Then you'd be able to call it as `postman.send(html())` or `postman.send(html(), html(), html())` Also, this doesn't seem Python 2 friendly (for instance, classes aren't inheriting from object, which of course isn't required in Python 3). 
Out of sight out of mind.
He didn't check for imaginary roots. 
I changed your code to be 1200 pennies. sorry.
Yep check out [Wakari](https://wakari.io). There was also PiCloud which ran on top of Amazon EC2 but not sure if they are still around. Have a look at this reddit [thread](http://www.reddit.com/r/Python/comments/1c86p8/where_to_use_ipython_notebooks_in_the_cloud/) 
So basically this is a "fiddle" for python? 
Thanks for your reply. And you are totally right. I haven't heard of pep8 before, thanks for that too. It would be cool if you shared your game as well.
I don't know about trinket, but pypy has been ported to run in browser. http://pypyjs.org/ It works surprisingly well, save the very long startup time. 
eh, I'm not sure I see the "awesomeness" of this. It may have been cool a few years ago, but now running language X in the browser is down right boring.
I learned how to use Python for networking. I also made a course on this topic. Check out my website for more details. Hope you enjoy it! http://www.pythonnetworking.com/
Before paying for this course, or any course, research other sources of python for networking, there are many free alternatives out there, with one of the best algorithms in the world doing the ranking of them.
That really depends on what type of computing you're talking about and the scale you need to hit, given that you haven't outlined any of those you shouldn't take any advice as fitting since none of us can know what problem you're solving... That said, a few I have enjoyed working with for various reasons: * [tornado](http://www.tornadoweb.org/en/stable/): Asyncronous event loop based. * [Django](https://www.djangoproject.com/) for data driven apps (CRUD, etc.) * [Flask](http://flask.pocoo.org/) for small-scale/one-offs (it can be used for bigger stuff, it's just less opinionated then django so more of the work falls on you putting in the middleware). What type of stuff are you doing? e.g. simple CRUD, number crunching, etc.
You are right. That's why I posted the link, so that people will study the course curriculum. Moreover, there are free lectures at the beginning of Sections 12-16, so anyone can see what they are going to get from the course, before spending any money. Please have a look at the course and if you feel that it might be useful to you, than use the coupon code and enjoy! :)
hey, I was actually thinking of contacting you to ask if you plan on doing tutorials on Twisted. Love your website. Thanks for all the resources you've put up.I'll actually be working with raspberry pi this summer and your tutorials have been so helpful :)
I have a server set up for me and my co-workers on a Digital Ocean VPS and it has been great for collaboration for coastal water quality data analysis since we work all over the country.
or try this http://www.codeskulptor.org/demos.html#tabs-Hall-of-Fame :) 
Nice work! 
repl.it Skuplt
From everything I have heard and read is that it is actually Python. It has an embedded Python interpreter allowing Python to actually be run, not a JS emulation. 
[brython](http://www.brython.info/) is another project. it doesn't quite implement python 100% to spec, but it's close enough to be useful. better yet: it's fast enough to be useful.
Well done!
Good question. `Path.rglob()` is more like `os.walk()` (plus fnmatch filtering), so it could probably use scandir to speed itself up, similar to how we've sped up `os.walk()` in the stdlib. The `scandir()` function itself is much more simliar to `os.listdir()`, a fairly low-level function that returns entries in a single directory, non-recursively. I really would have liked to make `scandir` functionlaity part of `pathlib`, or make `scandir()` return `pathlib.Path` objects. But the problem is that the `Path.is_dir()` and similar functions are guaranteed to call the OS and return up-to-date data, whereas the whole point of scandir is that the entries it returns already have that info cached. There was some discussion of adding use_cache functionality to `pathlib.Path` objects, but it wasn't easy without adding confusion, and was decided against. Read a bit more [here](https://www.python.org/dev/peps/pep-0471/#return-values-being-pathlib-path-objects). 
Yeah, the development process opened my eye to how much discussion and review is required to get even a comparatively small feature like this into Python. Which feels rough at the time, but I think makes a ton of sense given Python's massive user base. And the fact that once a feature is in, it's very hard to change it!
Absolutely. PM me and I'll happily help you. Although I prefer google hangouts if that works for you too. No fee for the first hour. :) Also if you haven't done so yet PyOhio is still looking for presenters and we're an excellent free conference if you'd like to attend.
Good job, and thank you!
Interesting, never even heard of SSE. I like the flexibility of WS, but I'll look into this.
This looks awesome. I would like to integrate this in to [pyfileystem](https://github.com/PyFilesystem/pyfilesystem).
Congrats! That is rad.
hopefully not any worse! /s feel free to check it out though, there's some examples on the README.md and if you clone the source and run the demo.sh it'll set you up a venv and some demo projects with tests and stuff to play around with. the goal was just to make something that reduced the turnaround time and requirement of writing a setup.py when making a new project.
I've occassionally abused it for golf. Notably awful usages are: 1. As a replacement for loops. Want to read 8 lines of input and concatenate them together? The obvious for loop sets you back 37 whole characters. Better would be: s=''.join(map(raw_input,['']*8)) but if you're prepared to duplicate the *code*, rather than actually looping / mapping, you can do it 2 characters shorter: s=eval(("+raw_input()"*8)[1:]) You can take this further. Got a complex calculation that needs to iterate a bunch of times? No need for a loop when you can just stick the code in quotes, use string multiplication to duplicate it a bunch of times and then exec or eval it. Eg. to print the first thousand digits of pi: z=s=e=1;exec"s+=z*4*10**1008/e*(2**e+3**e)/6**e;e+=2;z=-z;"*1800;print'3.'+`s`[1:-9] 2. To replace dict lookups. Why waste space with quoting, `{}` and `[]` characters when you can just stick your lookup strings into the local namespace and use eval to translate them. Eg. a roman numeral translator: p=t=0;I=1;V=5;X=10;L=50;C=100;D=500;M=2*D for v in map(eval,raw_input()):t+=v-2*p*(p&lt;v);p=v print t 
Funny, I remember coming across this exact optimization in the past and proposed it to speed up GNU grep: http://lists.gnu.org/archive/html/bug-grep/2010-08/msg00036.html
I find it really easy to use, you can achieve nice results with a few lines of Python, without much knowledge of D3.js
Thanks, you just gave me the title for my next post
&gt; I'd see projects not having a setup.py under source control Until you're there, this is more of a project templating solution. *If* you go there, make sure you support the "pip install git-url" use-case you're losing there. PS: Also, take a look at `argparse`.
you can check out the available free sample
Author here, if you have any questions or feedback let me know.
you could keep support for `pip install &lt;git-url&gt;` by adding a pre-commit hook to run `py-build -s &amp;&amp; git add setup.py`. In that way it becomes a template tool in some regards yeah. also, I've [used](https://github.com/ccpgames/pypicloud-tools/blob/master/pypicloud_tools/__init__.py) [argparse](https://github.com/demonware/bladerunner/blob/master/bladerunner/cmdline.py) [before](https://github.com/a-tal/nagaram/blob/master/nagaram/cmdline.py), I just threw the options bit together quickly this time because it's not really that involved.
I started with the python interpreter in a terminal - you know, learning as though it was a glorified desktop calculator. 15 years later, I usually have a terminal window open with python running in it... just to try syntax or whatever. But for coding, I use kate (KDE), even on windows. Basically just an advanced text editor with minimal IDE features. 
&gt; EDIT: What do you think of the Middlewares? Should they be removed? Mail isn't my thing, so I might be missing a use case where they would do more than what you have now, but I'm inclined to say that they should be downgraded to functions, rather than classes that implement the callable interface. I'd have to have a go at playing with it, but off the top of my head, I think decorators could be nice. That said, looking at the postman factory function, middleware doesn't seem to be optional, so it probably makes more sense to remove them and promote them to attributes of the Postman class. Just my hunch after a brief glance. 
Python packages are not modules. They are similar but they are not identical and an explanation of a Python package does not describe a module (which is what was being asked).
`__getitem__`'s slice part should probably use new = self._range(slice) return crange(chr(new.start), chr(new.stop), new.step)
That works too. Just make sure not to get thrown off by the off-by-one error; crange has an *inclusive* end: `len(crange('a', 'z')) == 26`
I'd be interested in seeing a write up at some point on a comparison of the various machine learning modules that are out there for Python. I've only used scikit-learn myself but often wondered if I should infact be trying out some other packages. Surprised they didn't mention that the Anaconda python distribution includes a great number of those Analytics packages built in right form the get go. One of the main reasons I recommend it to folks interested in getting into python for scientific computing/data science.
I know. I know. Going to update to Postgres. 
can you email us at info at real python dot com. thanks!
Maybe correlating to the proximity of other negative tweets would allow a percentage to be tagged as sarcasm, or with a :-( in it. Simplistic I know. Interesting stuff all the same. 
Looks interesting, but my problem is that I disagree with your `setup.py` design. Can I customize setup.py the way I can with Cookiecutter?
Head on over to /r/learnpython. If you wanna learn about the current bleeding edge, /r/python is the place to be. For learning python, we'll move heaven and earth to help you at /r/learnpython. To briefly answer your questions: 1. **Follow along** with a tutorial. 2. Yes, for pretty much everything in Python. LPtHW is prolly the most lauded. 3. Anything. It's turing-complete. It's better at some things than others, but you don't need to worry about that. 4. Write write write. You don't get better by reading, you have to write. Good job it's fun in Python.
I got zmq to build! See my update to the post!
Too bad about that 50 link karma.
Ok thanks 
Thanks for your advice! I've already made some changes (and added some functionality), but this will be very helpful going forward. 
Yup, that is the preferred way to send attachments. Note that you get the extra benefit of having the `Content-Disposition` header set for you if you use the `Raw.from_filename` method. Which basically allows email clients to know that its an attachment and its filename. About UTF-8 filenames- I have looked into the spec for multi language filenames but at the moment I think it will clutter up the API, but I might add it in the future. Also because most mail clients don't support it I thought of not supporting it as well.
&gt; leads to the problems OSX has It doesn't actually have any problems (as far as I can tell). The example code you posted causes problems in Python, not OS X. &gt; I agree that things like iteration and probably even indexing should use graphemes. [...] you should still be able to access the code points. Exactly. My thinking is that if Python 3 (or any language) wants to go full-Unicode so badly that it pretends that something is Unicode when it isn't really (surrogate escapes—and I mean "isn't really" in the practical sense of "you can't encode it", not "it's not valid Unicode"), then it should probably go the whole hog and define a `text` type made of graphemes, not code points. It's as dodgy as, if not more so than surrogate escapes, but would be more useful for texty things. In for a penny, in for a pound and all that. &gt; It is possible to make a forwards-compatible, normalized encoding, but it's useless without strong industry support. This is something that bothers me a bit. Obviously, this is coming from someone who (hopefully) knows much less about alphabets and languages than the folks that designed Unicode, but it seems to me to be fairly obvious that system designed to represent text should, where possible, either have one way only to depict a certain letter/ideogram/whatever or at least make it reasonably possible for different representations of the same thing t to (losslessly) compare as equal. 
I use them as documentation. It's no different than when people put `@type` annotations into their docstrings, except those always gave me an icky Java feeling. PyCharm even understands them once in a while. Here's [langcodes](https://github.com/LuminosoInsight/langcodes/blob/master/langcodes/__init__.py), a project where I use type annotations extensively, because in this code it's pretty important to distinguish when you have a `LanguageData` object and when you have a `str`. I like the resulting code, but it comes with some slight costs: * I have to remove them in a separate Py2 branch (`pasteurize` doesn't work well enough yet, and `3to2` never did) * GitHub's new syntax highlighter doesn't understand them * Type annotations might get standardized in a future version of Python, and I'll have to edit them if I want to play along 
Read the [Python Packaging User Guide](https://packaging.python.org/en/latest/). Always always always use a virtualenv. With virtualenvs, not only are your packages easier to keep straight, you can have as many versions of Python itself as you need with no confusion and no conflicts. If you have the ability to compile all the packages you use, you can get away with `pip` and `virtualenv` being the only things you ever install into your system Python. I can always tell quickly if I'm accidentally using system Python because nothing's installed there, not even `ipython`. Unfortunately, some things are difficult to compile. You may find that you have to install binaries of things like `scipy` globally, and then symbolic link them into your environment. (Can you use symbolic links? You haven't said what OS you're using. I imagine this is a big problem on Windows, and I've heard that Anaconda might be the answer there, but I haven't used it.)
https://py-generic-project.readthedocs.org/en/latest/installing.html is my write-up of the fundamentals, and an overview of the multitude of options to install Python software.
Have you had success using jythonconsole with Jython 2.7rc2? Something seems to have broken between rc1 and and rc2. It's in the jythonconsole bug tracker: https://code.google.com/p/jythonconsole/issues/detail?id=33
There was a note about booking by the Carnival agent so it was just a case of remembering the names of the ones I had seen in the area. Magic was the only one I could remember.
What company if you don't mind me asking?
&gt; I guess this means that the async equivalent to obtaining an iterator through `it = iter(xs)` followed by `for x over it` will have to look like `ait = await aiter(xs)` followed by `for x over ait`, where an iterator is required to have an `__aiter__` method that's an async function and returns self immediately. I see "for x **over** it" in the above snippet. Should that be "for x **in** it", or is there some new for ... over loop in the works?
Had me thinking Guido said that :/
Data science course in python, from harvard: http://cs109.github.io/2014/ 
&gt; ...Except PHP. err...[what?](https://lwn.net/Articles/633203/)
Depends on what you plan to do with Python. If your just learning to program, definitely use v3. If your using a specific module that requires v2.x, then your obviously going to have to use v2.x. Mostly, if your new to programming (at least in Python), the changes shouldn't disrupt your learning. Work through the tutorial for Python 3.4 on the official website. If you want more context, check the link in the sidebar on the right called "Should I use Python 2 or Python 3?" edit: spelling
This is about annotations, but it looks like you are talking about decorators.
I really like them. Mostly, I just use them so I can have auto-completion in PyCharm, but they are a great way to provide documentation as well. I was a little reluctant at first because they aren't very widely used and they seemed a little awkward, but they are actually pretty nice to use, just give it a try in your project and see what you think.
Interesting. Can you expand on that a bit? 1) For your point about `readdir_r`, are you referring to "On some systems, readdir_r cannot read directory entries with very long names"? Is this really a problem in practice? In any case, the C implementation actually uses plain `readdir`, which is all you need (because the `dirstream` is attached to the iterator and not being shared between threads). So I could probably fairly easily change the ctypes Python implementation (which is far slower and you probably shouldn't use it) to use just `readdir` too. 2) What do you mean about the traversal not being race-free due to not using the `*at` functions?
It's not academic. I want to be able to produce useful websites. 
Thanks for the input and langcodes looks like an interesting project. I'll have to think about supporting Py2 and Py3.....should be fun to automate.
I didn't think of them as shocking or crazy. I was really just wondering about people's thoughts as amongst some of my co-workers they are a hated feature.
I like them as well so far and helps when doing a quick search on documentation.
thank you so much for your work.
Can you make a script that will build a KML to put a point per $ at each location then run the heatmap by number of points? 
What's wrong with: 1. max(list) 2. sum(list) 3. "".join(list)
&gt; What if you want to calculate sum of squares? sum(x**2 for x in range(5)) &gt; to concatenate first letters of a bunch of strings? "".join(x[0] for x in ["aaa", "bbb", "ccc"]) &gt; or even more complicated computations? List comprehensions are cleaner and more understandable.
&gt;If you are about to ask a question, please consider /r/learnpython. It's a confusing name, but it's for questions. This sub is for news and releases. Also, I'd consider dropping the attitude. Python's community is generally pretty friendly.
I've just glanced over the snippets: looks nice but it really, really lacks documentation. :( The API and concepts looks like the ones of OSGi, maybe you could share on /r/osgi ;) 
Most popular names would yield half of the western countries?
Probably not, since many of them have different spelling for the same name, so even though 'John' is very popular in every western country, 'John' itself would give Commonwealth nations, 'Johan' would give Scandinavian countries, 'Johann' would give Germany, 'Jean' would give France etc.
[Relevant](http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
2nd that. Are we looking at downloading gigabytes or terabytes of data?
We often think foreign names are exciting and exotic like "Stannis", but Stannis -&gt; Ioannis -&gt; John... and now Stannis is boring old John.
Very relevant. My own names don't work in OP's module.
&lt;typo mention&gt;
thanks. changed it
There is a magic number at the beginning of the file. Check this answer explaining how to read this number http://stackoverflow.com/a/7807749 I should add that there is no guarantee that 2.7.x bytecode will work with another 2.7.y minor version of the interpreter. There has been slight changes/optimizations in minor updates. 
Yep. Thanks for your work!
My workflow involves creating and recreating virtualenvs a lot. For my current project this brought the time for `pip install -r requirements.txt` down from 83.4s to 5.4s. THIS CHANGES EVERYTHING!
I use them to get better auto-completion in PyCharm. I'm hoping that MyPy will mature quickly (and get some PyCharm integration) to get some more static code checking
This question has been asked a few times in the past couple of days (since that groupon offer went out) and the consensus opinion has been that it even at 90% off it is still over priced compared to the competition out there. If you want to learn python, start with either: http://www.codecademy.com/tracks/python or http://pythonprogramming.net/ Unless you need the monetary investment to motivate yourself. 
Was going to link to that, and suggest that to use OP's module, you should have to agree to an EULA-like thing that says "I have read and understand the article 'Falsehoods programmers believe about names' and am thus aware of the inherent limitations of this module and ones like it".
That's a pretty big insight, if you see the kinds of assumptions so many programmers make about names.
I used to run 'pip wheel foo; pip install foo' for every package, glad this is not needed anymore.
Do we have a pip update yet? 
No blog posts on the s3fs, but essentially once it has been constructed it works like any other filesystem. Some info in the comments... https://github.com/PyFilesystem/pyfilesystem/blob/master/fs/s3fs.py
you're welcome :D
This is what I'm talking about &gt;People’s names are all mapped in Unicode code points. WTF are you supposed to do with a name that can't even be represented by Unicode? You might as well have them write it down on a post-it note and stick it to your server for all the good it would do.
Not really. Python 2's been around longer, and Python 3 has only been being promoted as the "default" for a few years now, so many of the tutorials and guides are still for Python 2. Many small things changed between them to make python 2 code incompatible with python 3- in your case, many of the xml and http libraries were renamed or reorganized. There's definitely enough out there for python 3 for you to do what you need to do, though.
Haven't tested yet, but I'm in a similar situation to prophile... and my big rebuild timesinks are 'lxml', 'pandas', and 'numpy'. I've also got a large number of small packages that need compiling, but together they probable equal the time taken by those three. I've actually got a single build system that builds wheels for them, then I install those on the virtualenvs of the production systems (which have roughly the same OS &amp; hardware), just to not have to rebuild the darn things.
I know whenever I spin up a venv with numpy or SQLAlchemy in it, the build takes forever because of the C components. 
Touchy subject. And a painful one. The python community is still not ready to switch to py3, and the main reason for it might be that py2 is "good enough". If your intention is "to use the version that most people are using" then, with a little sorrow in my heart, I'd advice you to take on python 2. Once you have a clear, all round picture of python as a language (which doesn't take long, python is a very kind animal), you could start learning the differences and motivations for py3.
My biggest thing would just be finding someone to do it with me. Taking to twitter to find locals :D 
My pleasure, it was fun to make :-)
You can provide any of the setup kwargs as json key/values? I'm curious in what way you disagree with the outputted setup.py.
The tools are there, just chain them together: alias pip-update-all='pip install -U $(pip freeze | grep "==" | cut -d "=" -f1 | tr "\n" " ")'
I can't believe how quickly they're racing forward with something that mangles the simplicity of the language. The use of "List" and "Dict" instead of "list" and "dict" is infuriating. Or how about using "Any" instead of "object?" I expect that sort of half-assed design from Perl and PHP, not Python. It's like they sat down and tried to bolt on the most unpythonic type declaration system possible. Apparently this feature needs to be added so quickly that there's no time to address any of the underlying Python limitations that force such gobbledygook solutions. 
I recently discovered the 'pip-tools' package. It's got a few edges to polish, but `pip-review -i` does a nice interactive review of all the packages you have, and what the latest version is.
Try pip-accel
Doesn't this also update dependencies of installed packages that might be fixed to a specific, "outdated" version?
Right now, I do python setup.py sdist upload to push my open-source packages up. How do I make them into wheels?
make sure you have the wheel package (pip install wheel) then it's: python setup.py build sdist bdist_wheel twine upload dist/* (you should use twine over setup.py upload b/c setup.py upload sends your credentials in plain text)
Maybe this should be put on the side bar. I feel like I see it at least once a month.
I took a Coursera course a couple years ago and found a meetup of like-minded folks who were also taking. Perhaps, you can do the same.
Just tried it with a heavily customized venv. The only thing to be cautious about is if there's an upstream package with the same name as your custom package and it's also a newer version. Otherwise pip just replies that the packages are already up to date if it can't find something newer.
Our full dependencies include numpy, scipy, matplotlib and pandas, which all require significant time to build. Poor Travis usually runs 8 minutes just to fetch and build those dependencies for us. Really hope this will be able to speed that up for us.
It's okay. Its a great post. That's why I think maybe it should ho on the sidebar.
I love the idea of this and try to use it in many problems I address, but seem to always have issues applying it. The problems presented in this and the pymc3 examples are a bit more researchy or toy problemish than I'd like to see. Additionally, pymc/pymc3 are a bit tricky to use. On the other hand, Think Bayes takes a much more simple approach. However, it is much more limited in its applicability, and the coding approach makes things somewhat more difficult to follow (using google's style guide), and can be slow since it relies heavily on dictionaries. I don't think the code provided is meant to really be used as a bayesian library, it is just there for reference. I'd really like to see a bayesian library in-between focused on practicality. Maybe that would be building a library from some of the concepts Think Bayes provides. If anyone is aware of something at this level, I'd be interested in checking it out.
Actually, docutils is the worst offender—I think 2to3 is to blame. numpy already has wheels up on PyPI, but things like SQLAlchemy do hurt as well.
I haven't actually gone through it thoroughly. let me sit on this. Good points to contemplate though !
Is the issue still present in 2.7? You've linked to a bug in 2.6.3 for Windows, with no activity since October 2011. I was under the impression 2.6 was EOL, and in any case, it should be easier to drop in an upgrade to 2.7 on Windows since the OS doesn't ship Python by default? Although I don't actually know how Windows works.
"Accept characters liberally and don't try to transform them" is pretty much correct. The only thing I might object to is names not representable in Unicode. It's too much effort to handle those.
It'll be faster for people to install your package.
&gt; The only way I see to get around this would be to have a fs_normalize function. I know of exactly 0 languages that have such a function. (Plus, wouldn't it depend on how things were mounted?) Do any other filesystems do that? And do any offer mount options that dick with the encoding/normalisation? I'm only really familiar with HFS+ and EXT3/4, and EXT uses bytes.
Two things: 1) Should I be doing this with dictionaries? 2) In his use case, storing true/false flags, wouldn't a set be preferable? if the thing is a set member, it's true. If it isn't a member, it's false.
Isn' t **get** method enough for that in dictionaries? from your README # Ever have this happen to you? users = [ {"name": "John", "settings": {"new": False, "subscribed": True}}, {"name": "Mack", "settings": {"new": True}} ] for user in users: print user["settings"]["subscribed"] # KeyError # One solution is to check for the key's existance for user in users: if 'settings' in user and 'subscribed' in user['settings']: print user['subscribed'] But you have not to check for existence, as you can use **get** for user in users: print user.get('settings', {}).get('subscribed', False) Or even better, you can use **collections.defaultdict** to create a dictionaries which returns default values for some keys.
Will there a be a plugin or option to have the wheel cache be something other than the local filesystem? For instance right now I have to build a lot of VMs, and always point pip at a devpi index server. I have a bit of script that checks that there is a wheel for the latest (or pinned) version of a package, if not makes it a wheel, then puts in devpi. Basically it's the same as what pip is doing here, but sharable across lots of machines. One way I guess would be to have a shared filesystem for --cache-dir but, there are other reasons I need a private pypi anyway, so...
For a test case for (1), the easiest way would be a custom FUSE file system. For (2), if you use `openat` consistently, you can make sure that you are always descending further down the tree, and make sure that you do not follow symbolic links accidentally (`O_NOFOLLOW`, `lstat` etc. only apply to the final path name component). There is also a slight performance advantage (no need for repeated path name lookup on the directory), and you can descend into directories whose full path is longer than `PATH_MAX` (yes, `PATH_MAX` is the same kind of maximum than `NAME_MAX` is). Do you want me to open bugs in Python bug tracker for these issues?
I've got exactly the same feelings! I don't know why are you being downvoted...
pyrsistent has some even nicer APIs to deal with nested structure... although it's not dicts but immutable structures, but still.
Have you looked into conda? It has prebuilt packages for modules with C or numpy dependencies. It also has environments like virtualenv, and if a package is not made for conda you can still just do a `pip install`. I have been using conda 100% for all personal development and deployments on servers.
Ah, forgot logging could do that. Side note: I dislike the logging module more than any other - it's maybe the only module that needs books for documentation. Need to find a great python3 alternative (Twiggy is just python2).
I never had an issue with HFS+ partitions under Linux, and *a lot* of my files have non-ASCII names. Well, no more issues than with HFS+ partitions under OS X. It is a POS filesystem. 
Well, the issues only show up if you're looking at strings where the normalization matters. I don't actually encounter a ton of those situations.
`pip list -o` does that as well.
I think my next step is to Docker. 
It's not currently planned, but speaking as a pip developer I'm not immediately against the idea. Open up an issue to discuss?
Pyreverse (`pip install pylint` and you have it) and PyNsource are the two best I have found - http://metaperl.org/python/generating-class-diagrams-from-python-code
what id really like to know, is whether its typical for a pl to go default-unicode like python3 does. unicode *support* is important, but bytestrings like python2 and character arrays like c seem to be the rule. so if i want strings that work like strings in almost every mainstream pl, unicode is a secondary string format usually, right? i wish there was a list of pl's that are unicode-centric the way python3 is. (i realize python3 has bytestrings on the side.) maybe javascript...
Admittedly, the tip is a bit late given the existence of caching of the end-product, but there's the PIP download cache (which is enabled and configured by default as of the previous release give or take), and then there's stuff like ccache which would offer benefits outside of building pypi packages (if that's a thing). Worth mentioning.
[Dive Into Python 3](http://getpython3.com/diveintopython3/) is a great tutorial for Python beginners. And the eBook is free...
*was here 11 days ago :)
It's present in 3.4.
I'm just about half way through my gravity simulator for python. I finished all the math and now am taking a break before I tackle the graphical side of it. Check out the PyGravity.pdf under ./docs . During this project I realized that I'm getting pretty handy at using Tex, so if anyone has an open source project that needs documentation help let me know. I'd be glad to type up some tex for you.
Uh... what's a 'wheel' in this context?
Thanks. I realize latex and PDFs aren't great for docs, but I also use it for a lot of math papers already. I'll try out sphinx when my project is all done. Besides right now my docs are way too verbose as it is. They are more like a report that goes through my whole process of how I made my program. When I'm done I'll definitely try sphinx for the normal docs.
The Haskell version is not much more readable than the body of the C function would be. It's like you don't understand the point of Python at all.
coroutines != threads, do you know what coroutines are?
how can those of us who agree with you express our opinions on this?
Interesting, I have heard a bit about docker, but that fits my case for a few aspects of my application. 
Except for not being JS, these aren't insurmountable issues. It could reasonably expose its event loop using asyncio.
`urllib` is a package, i.e. a collection of modules. `urllib.request` is an actual module. Try the following: &gt;&gt;&gt; import urllib &gt;&gt;&gt; urllib.__path__ You will then see the system path to the urllib package. If you change to that directory, you will see that urllib is actually just a subdirectory of your python standard library. Inside the urllib directory you will see the request.py module. 
I'd suggest using numpy. For a large number of points, you code won't be very efficient.
It is technically a module, see https://docs.python.org/3/reference/import.html#packages If you import it, it runs the script `..../urllib/__init__.py` and binds any definitions to the urllib namspace. For urllib, `__init__.py` happens to be empty so nothing happens. You can do a `dir(urllib)` after you import it and will see that it has nothing beyond the minimum attributes of a regular package module. If you want to make a package, you typically just create a directory and put an empty `__init__.py` file in it. Then it is a package, and you can put modules inside the package. Note that python2 works the same way.
Didn't pip do this already? I've had it set to cache for ages.
TL;DR: No, if you use pure Python (arbitrary precision). Yes, if you use something like Numpy or Pandas (C ints). 
It already cached the sdists, but it would re-run the build process each install.
how to use virtualenv with miniconda ?
I'll have to check this out more. I've seen it a few times but never bit because it seemed so analytic/science based. 
http://conda.pydata.org/docs/examples/create.html
I haven't used vispy proper, but their vispy.gloo module is top notch! Much nicer than PyopenGL. 
probably stating the obvious, but it doesn't have to go all on one line. The following is equivalent, and sticks to 'one operation per line', which I think is a much better guideline than a # of characters limit ``` floats = read('foo.txt') floats |= sfilter(lambda s: s and s[0]!='#') floats |= smap(float) floats |= ssorted() ``` In real-world use, I tend to use the one line versions for trivial operations (e.g. Pull the first line from a file and count the commas to see if it's tab or comma separated). For more etl-like operations where I perform transforms and processing, it's one op per line. It's like everything else in Python - yes, it could be dangerous, but the culture is to write readable code rather than short or self-consciously clever code.
Which incidentally is then translatable. GP's logger call isn't, because the filename is not necessarily at the end of the sentence in other languages.
Any explanation for the version jump/mismatch? My local install was at version 1.5 before the upgrade, and installing reports: pip install --upgrade pip Collecting pip Downloading pip-7.0.1-py2.py3-none-any.whl (1.1MB) 100% |████████████████████████████████| 1.1MB 291kB/s Installing collected packages: pip Found existing installation: pip 1.5.5 Uninstalling pip-1.5.5: Successfully uninstalled pip-1.5.5 Successfully installed pip-1.6.dev1
its because urllib isn't a package in python 2, its a module containing code by "python2 works the same way.", that was referring to python 2 having the same package/module mechanics in this regard, not specifically urllib
I get a lot of great information from this blog. Thanks for sharing this valuable information to our vision. You have posted a trust worthy blog keep sharing. http://www.joinfita.com/django-python-training-institutes-in-chennai/
Do you have experience with pitch tracking? I found these papers helpful &gt;T. Tolonen and M. Karjalainen, “A computationally efficient &gt;multipitch analysis model,” IEEE Transactions on Speech &gt;and Audio Processing, vol. 8, no. 6, pp. 708–716, 2000. and &gt;Gareth Middleton, “Pitch detection algorithms,” 2003. Actually its not a trivial task even for monophonic signals. You can get good results with simples approaches like ACF but it all depends on the piece, instrument and whatever. So making it robust and work over a range of pieces is the hard part. As for modules their is also [librosa](http://pythonhosted.org/librosa/index.html). Have never tried it but the tutorial looks promising. Another option would be synchronizing your signal with a known score (e.g. [this](https://www.youtube.com/watch?v=PF05xP1NqUM) using chroma features). **edit:** module, typos
^\[citation ^needed]
Thanks. Your comment just became much more useful.
I'm a fan. I first heard about it maybe a year ago, and in that time it's gone from having potential (the higher level stuff seemed to just be beginning to stabilise) to being a fully viable replacement for mayavi for my needs. It's still not quite as easy so I had to write some wrapper code, but that's largely due to a specific optimisation that hasn't been done yet and I think is on their roadmap (specifically mesh data collection for multiple visuals). I'm also manipulating the scenegraph directly which is high level but still a bit more verbose than a plotting api like mayavi's, but vispy's own high level plotting api has begun to be developed recently. For these reasons I think vispy is already an excellent tool for some tasks (including some that weren't that easy with e.g. mayavi), and is rapidly improving on many more. That said, it's not the only visualisation toolkit around and there are others that are more mature and perhaps currently easier to use for specific tasks. I mentioned mayavi above, which I've used for a long time for its simple but powerful tube and mesh plotting, though one disadvantage now is that it's python2 only and has some annoying dependencies. Others include toolkits that some of the vispy devs developed themselves, including (off the top of my head) glumpy and pyqtgraph. I think these are more optimised and mature for some tasks, and may have some different features, but I'm not sure about the details. I expect that most of these features will turn up in vispy eventually.
Hate, HATE that bug. 
It's actually pretty fantastic. How about you take that attitude and fuck off.
They changed versioning from X.Y.Z to just X.Y, and removed the leading 1 to accomplish that. So 1.5.5 → 5.5 → 6.0. https://mail.python.org/pipermail/distutils-sig/2014-December/025470.html
The cache feature was introduced in pip 6.1.1, am I wrong?
take a look at http://www.sikuli.org/
&gt; using pip 7 which caches the builds in wheel format. Where are the wheels cached? On https://pypi.python.org/pypi or on your local machine? If the later, that means the author is assuming they are able to re-use the same machine deploy after deploy, right?