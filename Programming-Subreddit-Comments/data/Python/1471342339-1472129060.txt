More complete documentation is forthcoming. 
&gt; That should be how you always check for x being None and the type system should enforce that. No, that's just how you should do it. The type system is working fine. I guess you could make an argument for `if 5` and similar being too implicit, but I'm really not seeing what's wrong with empty strings. &gt; Where the user was asked something didn't enter text in the text box (blank string) that was treated identically to "user wasn't asked" (None). Again, just write `if x is not None`. I don't understand why you keep writing `if x` and getting frustrated that it exhibits the same behavior for `None` and empty strings if it does this *every single time*. It's well-defined and not that complicated. I don't even remember the last time I've encountered a bug caused by this. &gt; It means that when you push a string into a place which is expecting a list of strings you get bizarre non-failing behavior rather than a simple failure. Yeah, because they're iterables. What about when I accidentally pass a dict into that same method? What about some user-defined object implementing `__iter__`? That behavior might be bizarre as well. You're looking for Python to enforce `f(arg: List[str])` without having to type it out, which is stupid. I don't want to useful remove parts of Python to reduce errors made by beginners. &gt; Treating a string as a list of characters isn't something done commonly enough for it to make sense making it implicit behavior. I use it often.
Nice thanks!
Thanks.
&gt; It takes you to a huge page with the entire module, not a page with that thing. That means you have to search in-browser too. That's not the case for any other language afaik. Exactly my point
Try this: https://pythonprogramming.net/django-web-development-with-python-intro/
Poor github practice, I expect. Is there a reference for what should be added to the .gitignore for Python builds?
&gt; I guess you could make an argument for if 5 and similar being too implicit Exactly the argument I'm making. &gt;I'm really not seeing what's wrong with empty strings. There's almost always a subtle difference between empty string and None and conflating the two will create bugs. Many bugs. &gt;Again, just write if x is not None. I don't understand why you keep writing if x and getting frustrated that it exhibits the same behavior for None I'm obviously not, and this bug doesn't appear in my code because I know it's a pitfall. Other people are - often on legacy code bases. Those people consider it 'pythonic'. If anything it's tacitly encouraged by the python powers that be. &gt;You're looking for Python to enforce f(arg: List[str]) without having to type it out I'm looking to not treat string as a list implicitly. Especially since 95-97% of the time I don't use it as a list. I want more obvious runtime type failures and fewer non-obvious implicit type conversions in general. This is just one instance. I'm well aware that there's a trade off - in order to do this you need to increase the character overhead (i.e. string.char()[0:5] is more than string[0:5]). Sometimes that's worth it, other times it's not - it depends upon the frequency of the bug and the number of times you need to use this behavior. &gt;What about when I accidentally pass a dict into that same method? Consider a junior-ish developer looking at this code: for item in {1: 2, 3: 4}: print(item) Is it obvious what it's going to output? What about this? for item in {1: 2, 3: 4}.keys(): print(item) On the whole, explicit is probably better here too. The number of saved characters is going to be small but the increase in understanding/lack of bugs caused by surprise implicit behavior is going to be high. &gt;What about some user-defined object implementing __iter__? Should obviously work as an iterable. It's the developer's fault if they make it behave in a bizarre non-obvious way that causes bugs.
You're correct, it is more fragile to interface changes. However, image recognition also works with apps that don't use the accessibility layer. Correct me if I'm wrong, but I believe that goes for Citrix-published applications as well.
&gt; If I tell the mouse to click the OK button of an order form in the main window of an app, it's going to click that button regardless of where it appeared and even better if an update to the app or OS came out that changed the look of the button, it's still going to get clicked. that might be a downside if you're trying to do UI testing. Suppose your button is being drawn outside the screen or something like that, your GUI-hooked test will still pass while the pixel matching will correctly detect the problem. Plus, a lot of the time when you're trying to do this kind of automation you're messing with ancient custom coded apps that are pretty unlikely to be programmed properly for stuff like usability.
Correct on both points. We don't deal much with Citrix apps so I forgot about that. I don't know if you're in the US or not but all apps should be accessible, even internally developed ones. So that makes it easier for my team to do automation. 
Good to know, thanks!
I recommend adopting a dedicated documentation browser like [Zeal](https://zealdocs.org/). It's a really handy tool, and search takes about two seconds to end up at the searched functionality. 
&gt; No type aliases that I've seen, so complex types are hard to express. Is any new syntax required for that? Surely tools like mypy should be able to understand things like: listint = List[int] a: listint = [1,2,3] &gt; Python's a dynamically typed language. Types should be inferred, not declared. Embrace it and write better tools to infer types if you want docs and static checks. I haven't seen cython come up in this discussion. Adding type declarations to cython code is critically important for performance reasons, and it's often very useful to be able to write code that can be understood by both cython and python. Cython already [has several ways](http://cython.readthedocs.io/en/latest/src/tutorial/pure.html) of adding types to pure python code, but they're all pretty awkward to use. I believe cython now has some type inference, but there are limits to what you can do with type inference. For example, it can't possibly predict whether it can replace a python int variable with a C long, or whether that will lead to overflow.
Worked like a charm! Just in case you want to add it somewhere, to run it with Python 3 without modifying the code too much I just changed the `urllib2` import to `from urllib import request as urllib2` that way I din't have to touch anything else. Thanks for the fast reply and fix!
ok cool. 
I'm no fan of this method at all. Is there any reason why you couldn't just use [OrderedDict](https://docs.python.org/3.5/library/collections.html#collections.OrderedDict)? from collections import OrderedDict stuff = OrderedDict({"a": 1, "b": 2})
I never understood why do people need ordered dicts... Is it the (relative) predictability of the order? 
You need fast access by key, but there's also a "natural order" in which to present the items. 
I can't imagine the amount of retarded questions that would come with this if it were to become popular.
But you have an extremely limited control over that "natural order". Or do people use them as some sort of poor man's read only sorted dictionary, where they insert items sorted by key and don't touch anything afterwards?
But aren't insertions slower for ordered dicts?
Thank you! I didn't know there were such tools! Will be useful also for other languages.. 
[This page](http://python-packaging.readthedocs.io/en/latest/command-line-scripts.html) explains the two right ways to do it.
&gt; `class collections.OrderedDict([items])` &gt; Return an instance of a dict subclass, supporting the usual dict methods. **An OrderedDict is a dict that remembers the order that keys were first inserted. If a new entry overwrites an existing entry, the original insertion position is left unchanged.** Deleting an entry and reinserting it will move it to the end. Ah, that explains it. OrderedDicts don't support insertion in the middle anyway.
For example: I have a modular system with a dict (module key &amp;rarr; module information). While I usually access through module key, sales has strong opinions that in a list of available modules, 'Advanced Additional Module (for testing)' should definitely and under no circumstances appear before 'Flagship Product'. Another case (where OrderedDict with "insert order" doesn't necessarily help, but still is related): I have a list of nodes that have an order specified by the user, but I as often acess an individual node through its key.
Passing a dict as an argument first creates a normal, unordered dict, so key order may get messed up before the OrdereredDict constructor is even called. 
Dict order is not guaranteed so seeding an OrderedDict with a dict does not guarantee desired insertion order. One could overcome this by using a list of tuples.
Exception types are very poorly documented. I tried to a find a list of them and what throws them. No luck.
Why do you want it to run exactly like that? Encapsulate your logic into a module, then create a launcher script in the root directory.
I think it's that the dict might have `b` first, because it's a regular dict that gets passed in.
It's how I'm used to run scripts (e.g. `sh bash_script.sh` or `./bash_script.sh` if it has a shebang), but maybe I should follow your advice and drop that idea as it doesn't seem to have too much support around it. Thanks
I'm a fan of using OrderedDict passing a list of tuples, since it's an inline solution. Can't wait for the new implementation in 3.6 though.
But this works OrderedDict([("a", 1), ("b", 2)]) But I admit, it's pretty clever to use a tuple of slices as an argument.
Just create a launcher script in your root directory. Something like `import your_package.cli; your_package.cli.main()`. Then you can run it with `python launcher.py`, or add a shebang to it. 
You can create a `funniest/__main__.py` entry point file for your package, which will be launched if you execute `python -m funniest`. If you want an explicit file to launch, i.e. a launcher, do what /u/K900_ recommended. (You could even make the launcher a shell script that just launches `python -m funniest`.)
Also, regarding your tests question: yes, that's the accepted practice, though I'm personally starting to like Rust-style tests in the same file as the code, especially for stuff you expect other people to use. 
You're reading that wrong. They show this example: a: int print(a) # raises NameError The type declaration changes nothing. 
See [this section](https://www.python.org/dev/peps/pep-0526/#id6): &gt; Omitting a default value leaves the variable uninitialized: &gt; a: int print(a) # raises NameError 
They lost me later at the use of `class` in an assignment. `stats: class Dict[str, int] = {} ` What? Why does it matter whether an object's attribute is inferred from a class (as a class attribute) in the first place?
You should if you don't understand the fundamentals of the module. If you don't understand the nature of the module, then documentation about a single function won't help you at all. If it's your first time with the code, then YES, read the whole module documentation.
Or /r/learndjango .
I have code where the order of certain items in output doesn't technically matter, and the algorithms involve dicts, but it's nice to produce output in a *consistent* order for regression testing. 3.x's dicts broke that for good reasons; OrderedDict would probably solve all these issues for me (and I somehow only just thought of it now!), and `explicit is better than implicit`.
Using **kwargs provides a dict. There are cases where preserving order would be nice (for example, `assign` in `pandas` doesn't let you use new columns in assignments because they may not exist yet; if order was guaranteed, you could do all of your assignments in a single step)
Github has a pretty large collection of generic `.gitignore`s here: https://github.com/github/gitignore
&gt; makes them take less memory This is the surprising part for me. Any technical notes on what it's doing under the hood?
Are you looking for any help with the project, or are you looking to keep this as your own solo software adventure? Edit: I'm do my python development on a variety of Linux/*nix OSes, so I could help with implementing that cross platform compatibility you were planning on (or even documentation if that's another task that has been pushed to the back burner for a while). 
I would take those provided example .gitignore files into consideration, but generally the files that are ignored at a minimum are .pyc files and the \_\_pycache\_\_ directories that are spawned during testing, any configuration files containing sensitive information (obvious, but a good mention), and generally files that wouldn't be automatically reproduced whenever the software is being used by the user. 
It's quicker to ask the OP. It's better one doesn't need to.
Sorry about that, it is running on a free heroku dyno so it might take a moment to wake up if it was sleeping. Otherwise it looks like it's still working on my end. The gif in the [readme](https://github.com/jwkvam/bowtie/blob/master/README.md) shows the demo being used if it doesn't work as well. edit: I've only tested it on chrome so maybe it's a browser thing. Which browser are you using?
Yea sorry about the lack of documentation, I wanted to see if there was interest from others before I dove into making docs. Maybe that was a mistake and maybe I'll come back and post again when I have some docs. I wasn't a huge fan of pyxley because I thought the api was too complex. I tried to create a simpler api but maybe since I'm the author I missed the mark. 
Yea, that's also a biggie. We have some ugly hacks in tri.declarative to work around this. 
Typing helps to get this `TypeError` on static analysis instead of runtime. Python has this problem almost as bad.
I don't see that as a bonus; I would prefer if there was no way to depend on insertion order, or alternatively randomizing output order.
I'm sorry, I don't get it. Can you elaborate? 
As an alternative to running `python -m code` you can set the `__package__` attribute of the module. The effect is the same, but you run the script with the ordinary `python` call. Setting that attribute correctly can be a pain, though. I recently put a package up on PyPI which sets it automatically. See [set-package-attribute](https://abarker.github.io/set-package-attribute/) for details.
Helping CERN find the Higgs boson.
I think [this blog post](https://spacy.io/blog/dead-code-should-be-buried) justifying writing spaCy as a full-blown replacement for NLTK provides a good argument for when it's appropriate. In a nutshell, NLTK has a lot of old, poorly-documented code and gives no indication for which of its many options work best. spaCy seeks to remedy that by providing cutting-edge parsers that are known to work well.
Define "invention"? I'd say Dropbox was rather inventive, and their entire backend ran Python until they switched to Go/Rust for performance reasons.
How did you try to include the library? It looks like this library includes many compiled components, so you'll probably need to make a python-for-android recipe for it if you want to use these. You'd likewise need to compile it somehow to use with QPython, unless they provide a prebuilt version.
Helping LIGO find gravitational waves.
Google
[You're looking at one right now.](https://github.com/reddit/reddit)
Hmm, I missed that section. But the very first example in the abstract is still misleading. You kinda assume the top and bottom example are equivalent, but they're not? http://i.imgur.com/XHXrtuO.png
How will I know which TLA is the correct one?
&gt; That means you have to search in-browser too. That's not the case for any other language afaik. So call `help(math.sqrt)` or just try it out. Also what's wrong with a 2 second in browser search? I prefer it to numpy's one function per page approach.
Thanks! Sites based on robot overlords kind of build themselves.
bittorrent
Can't wait to try this out! Thanks!
&gt; https://github.com/TriOptima/tri.declarative Interesting, not sure how I can leverage that off the top of my head, but I'll look into it.
TV Overlord hands off the magnet link to the default handler which is set by a desktop environment. To make it work without a desktop, a command line only bittorent client needs to be installed and then the command for that client needs to be added to the 'client' section in config.ini client: transmission-cli --download-dir "/home/ricka/tv shows" {magnet} The {magnet} get replaced with the actual magnet link. The config.ini location can be found by typing: tvol config This will output a bunch of information. Here is the documentation for the config file: https://github.com/8cylinder/tv-overlord/wiki/Config-file
Unless it's optional in which case your whole statement is a needless source of concern. And small errors are still errors. Saved time is saved time.
FlexGet (from my brief look at it) is mostly to run as a background process, you set up a yaml file and it downloads stuff based on those settings. Also the setup looks fairly complex. TV Overlord you run it, it does its thing, and goes away. And; in my biased opinion; is simpler to use. But, if anyone wants a fully automated system then TV Overlord is not for them. Also, with FlexGet to add or remove shows, you have to edit a config file but with TV Overlord that is easily handled on the command line. tvol add "doctor who 2005" This is nice if you are constantly adding new show to watch.
I have recently made my own search thingie for these kinds of things, but it's 1) made in PHP (all I currently know properly) and 2) not at all as fancy and nice as this. I like it. Thanks for sharing! :)
Appreciate the feedback!
The "magnet folder" setting (if set) is used if there is no bittorent client. Text files get put there with the magnet link in them. This is non standard and as far as I know, no client will open them directly. But they can be downloaded to another machine with a client and used there, then copy and paste the link. This method is not that useful, really only for testing or until a proper bittorent client gets installed.
I'm having trouble thinking of a scenario. Do you have one off the top of your head?
Sad, but true. As a PHP programmer, I cannot stress how much `php.net/&lt;whatever&gt;`has helped me in the past 10 years. It's easy, accessible, and _most of the time_, the docs are great. Except when you get those "*Only the definition of this function is documented, the usage is experimental.*" or similar, where it actually isn't experimental.
Hard to do as someone learning the language.
I already have a bunch of scripts that add magnets to transmission at certain times of the day. I cat the magnet file and parse it to transmission which works fine
Thanks for the feedback, much appreciated.
If you need to use OrderedDict a lot, I can't see why not. The implementation is pretty straight forward, so if somebody sees a notation like that for the first time, he can check the code and will understand immediately (assuming he has some python knowledge)
That would be great, but still it would be an implementation detail.
I vaguely remember having encountered this in the real world, but I can't remember the details of that, so let me construct an example scenario instead: You're implementing a data structure that keep a number of large strings with some metadata. For convenience for callers in the cases where your class is being used for small sets, you're also defining an all_items() method. A natural implementation in terms of dict would be something like: class MyClass(object): def __init__(self): self._content = {} def compute_metadata(self, item): return blahblahblah def add(self, item): self._content[item] = compute_metadata(key) def all_items(self): self._contents.keys() Now, any client can easily depend on key insertion order, and my experience is that these kinds of dependencies do sneak in. If you discover that you want to change the underlying data structure to a prefix tree because the strings are huge and you can save a lot of memory - whoops - your API is now different, and you'll have clients failing. Again in my experience, the most common failure after these kinds of changes is test failure, but actual logic failure happens too.
A word file is actually a `.zip`-file that gets read by the Office suite. If you extract it it will contain an `.xml`-file. This file contains all text and properties of the word-file. One possibility is to use a xml-parser to find the relevant list in this file and look whether it is bold. Have never done it myself but imagine it is doable. http://etienned.github.io/posts/extract-text-from-word-docx-simply/
This looks super awesome! Thanks!
PHP is all sorts of awfulness to deal with but at least it's well documented awfulness.
I used [wxPython](https://wxpython.org/) for the GUI, [SpeechRecognition 3.4.6](https://pypi.python.org/pypi/SpeechRecognition/) for the Voice Recognition, [Pyvona](https://pypi.python.org/pypi/pyvona/) for the Text-To-Speech, [Wikipedia 1.4.6](https://pypi.python.org/pypi/wikipedia/), [WolframAlpha 2.4](https://pypi.python.org/pypi/wolframalpha) and [NLTK](http://www.nltk.org/) for Question Answering (also used the [OpenWeatherMap API](http://openweathermap.org/api) for weather information), and finally the threading module to get everything to work together concurrently.
This looks great! I'm creating a web based mediacenter application (like plex) in python. Is there any documentation on calling this from another python application?
This seems a lot like pyautogui but my cursory read of your docs could have missed some crucial differences.
I would say no - especialliy if your code is long - you are far more likely to loose track of what this special all lower case 'trick' does. Be Explicit, if you want an OrderedDict, use one and initialise it with a list of tuples.
Something that follows UNIX philosophy. 
Keep working until you can do something as fancy and as nice as this and I'm sure you will! 
I was thinking that lackey can recognize text on the screen, but looks like only image patterns. Doesn't sikuli support this?
Cool. How long have you been programming? 
When faced a similar situation my response was to tell everyone, or rather to make a function available to everyone that submitted stuff in sorted order. Like, this is my problem: it feels like what you guys really need is a sorted dictionary, std::map like, it's sorted by keys and it has an _explicit_ order of traversal, and it allows you to insert an item gracefully... but people welcome OrderedDict because it's not as bad as a usual dict, where SortedDict would be so much better but you don't know that it's an option :( 
This looks like a great complement to flexget.
On and off for about 15 years, but mostly off. TV Overlord has been a hobby program I've been working on sporadically for myself and using it to learn Python. The code is pretty crufty and parts are embarrassing.
just thinking of your average it "admins" asking something stupid like whether or not it will speed downloads from several private ips that are Nate natd out the same connection over and over and over
It's illegal either way.
drugs and coding mixes so well whatchu sayin
Very nice tool you have here. One question, Does it have a mark all as watched option? If not, this comment has turned into a suggestion ;)
I tend to use them when I have two lists of items, and sometimes want to see the corresponding item in the other list. This is pretty common when dealing with full and short names for table columns, for example. A, B = ['a', 'b'], [1, 2] # iteration over A and B preserves order a_val = None if 'a' not in A else b[A.index('a')] is equivalent to D = OrderedDict([('a', 1), ('b', 2)]) a_val = D.get('a') There are similar gains in ensuring that corresponding elements don't get out of sync, and so on. I've also used it as the (internal) deserialised data for a config file, where only non-standard entries should be retained and maintaining order is key for readable diffs.
This makes me miss TV Torrents :(
Pretty cool. installed it and tested it. it would be great on download to mark minus using a wildcard to avoid downloading. something like tvol download --doNotGet "SE01*" "Mr. Robot" so you can skip downloading seasons you've already seen via other methods. IF that already exists then apologies for not seeing it in the help.
Definitely illegal enough that the nice men at the FBI would have no trouble shutting it down, but likely it will never be popular enough to be worth their time. 
It looks like you used the --user flag on pip. This is a better way to install python packages since it installs to your ~/.local dir but, the local bin folder has to be added your path. Do a search for transmission_done and that dir tvol is in and it should be added to the $PATH. 
autobahn will work on 2.7 in falls back onto twisted, just need a few tweaks to support it
&gt;It's my understanding that there is virtually no legal recourse that companies have for people who stream torrent Regardless of what they can and will do legally, they can and will complain to your ISP if they catch you (and they do watch what IPs are seeding/downloading when they can). Your ISP, if comcast for example, can punish you how they see fit or give in to legal recourse if they follow it and give up your name. I think Comcast punishes you somehow by doing something like disconnecting you for a bit or throttling your internet if you keep getting caught. If you're at the point where you're getting caught, you're just lucky that the company that caught you doesn't want to sue. They can sue you for copyright infringement if they want. Doesn't matter how legal it is or isn't if they want to throw a big team of lawyers down your throat.
We already have type hinting for functions. I like it. It is a form of documentation, which although I don't use it very often because of the dynamic nature of Python is better than doing it all in docstrings (which adds clutter and repetition). This is type hinting for variables. It is different, and in my opinion pointless. At best it will make IDEs slightly better, but at the cost of filling your code with unrelated information. As for what you said about functions (again, unrelated to this PEP), no one wants to make an integer that overrides the `+` operator to make it actually divide, but it isn't all that uncommon to write types that act like numbers, but are more complex than numbers and there are even builtin things like fractional types in the standard library which you might very reasonably want to use with your function. When dealing with iterables (and other common interfaces), I make an effort to avoid writing functions that work on only a single type. It's true that a lot of functions I write are meant to be used with a single type, but again, that has to do with _function type hinting_ (which I fully approve of), not _variable type hinting_ (which I don't).
 &gt;&gt;&gt; from jellyfish import metaphone as mt &gt;&gt;&gt; mt('Cathryn') == mt('Catherine') == mt('Cathrin') == mt('Kathryn') == mt('Katherine') == mt('Cathrynne') == mt('Katheryn') True Wow, thank you so much for posting this. This is super useful. 
 PATH=$PATH:~/.local/bin/ Resolved. Thanks. 
&gt; I will post a future tutorial covering how to do this as a GUI app (using Python's Tkinter Library). Isn't Microsoft Excel a GUI app for working with Excel spreadsheets??
Seems like a worse version of remi / pyxley
[thefuck](https://github.com/nvbn/thefuck) - surprisingly code is readable and well tested for app with that name.
&gt;&gt; We do? Where? And if we do, that's worthless if we don't redirect the newbies to these resources. &gt; On the documentation page Eh, that's a fucking mess. Have you clicked those links? &gt; You don't need to have an encyclopedic knowledge of the libraries you use, but you do need to have a fundamental understanding of how they work. That's exactly the problem with the docs as they stand now: you DO need an encyclopaedic knowledge of it, and the docs are formatted as a book with the assumption that you consume the docs to get such knowledge. &gt; Simply knowing the signature of a function in said module isn't adequate That's MY point. That's why we need a list of what the parameters actually do in a nice table, not shoved in a big paragraph without even properly highlighting the parameters inside the block of text. &gt; Someone who skims documentation without understanding the module they're using is just as bad. Sure. Also bad: more strawman arguments. Look, I just need to read the overview stuff a few times, but I need to look up the specifics of certain parameters A LOT. That's where the current docs fail. &gt; Then you are a fool with no humility. Excessive confidence is a strong indicator for a lack of competence. I know of the Dunnig Kruger effect. I also know my school sucked :P Dunnig Kruger doesn't mean anyone who says they're an expert is actually an idiot. Again: you're being silly.
That's a pretty terrible title 
this is amazing. Will source code be available?
Probably the simplest way to do that would be to actually write to the text file instead of piping the output over.
Yeah, humor is rarely understood on the internet.
&gt; Compact and ordered dicts are probably going to land in 3.6, very much inspired by PyPy. That's a bit disingenuous considering [the original proposal and explanation was made by Raymond Hettinger on the python-dev ML](https://mail.python.org/pipermail/python-dev/2012-December/123028.html) (with Armin Rigo later participating in that discussion)
I'm on Ubuntu 16, kinda confused how you're running tvol as a command line after install it through pip3? edit: fixed from other post... thanks! PATH=$PATH:~/.local/bin/
link to localhost:8000, nothing to sea here
Have you tried [subprocess](https://docs.python.org/3/library/subprocess.html) instead of os.system?
Honestly, any code that succeeds in doing what it says it does is just about as well written/tested as any project can get. I don'e believe in subjectivity when it comes to software. Either your code works, or it doesn't. If your code works, then it's among the best code ever written. If your code doesn't work, then it's right alongside all the other projects that don't work.
yeah, sorry about that, here's the link : http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html 
I'm sorry, but that's not true at all. I've seen shitty code and well written code accomplish the same thing, one was manageable and executed efficiently and the other was a cluster fuck and fumbled it's way too it's goal.
Until a dependency changes
Things are going to change. Unless this is a personal project that no one will use. But if you're going to write something that matters it'll need updated, you might even need help to manage it. Then you're going to eventually have to rewrite it from scratch because of the hole that you dig yourself. It'll happen, unless you write clean code from the start.
As long as it runs numpy, pandas, matplotlib and everything off pypi... ABSOLUTELY!!! Seriously the answer to you're question is no. Nobody needs that, there are plenty of other languages that could fulfill that role. But don't let that stop you if you want to write such a thing. Just don't expect a line of people outside your door.
[yep](https://github.com/reddit/reddit) ;)
Nope.
Realistically, not worth your time especially since it already exits as rpython. You should look into cython if you're struggling with speed. However, I'd caution you: do you actually have evidence backing up that your Python code is running too slowly and that it's not algorithmically limited? Compared to most other interpreted languages, Python has one of the fastest run times. Any time I've debugged someone complaining about its speed I've seen a few common things: 1) they're doing large matrix and/or array operations and not utilizing numpy 2) they're writing for loops everywhere and never using list comprehensions (list comprehensions can be a huge help) 3) they have some based-in-theory-not-in-measurement assumption about how much Python is hurting them when in fact they've written a O(n^3) algorithm that could have been written in O(n)
TV Overlord won't do season by season searches, but you can do a simple non db search. tvol nondbshow 'one piece season 1 complete' Using nondbshow to download is the same as if you had used the browser. You have to manually manage the files after download. For older shows with no seeds, I usually download the seasons separately then once I've caught up to more recent ones I then use tvol download. 
&gt; it already exits as rpython. You should look into cython Thank you for the detailed reply. It looks like RPython is much more restricted than what I was planning to implement - nonetheless I will see whether it, or Cython, can help me with my performance issues. &gt; large matrix and/or array operations and not utilizing numpy I have definitely been guilty of this in the past. Switching over to NumPy has improved speed significantly, but as mentioned in the OP, using it makes distribution to end-users more complex. Also, of course, not every algorithm can be expressed in terms of NumPy's facilities.
Learn swift and apply your language development talents there. I say this in all seriousness being a long time Python user. Why Swift? It adopts a lot of features from the likes of Python and other modern languages however it is designed to be compiled right from the beginning. More so the language is new but is gaining rapid acceptance on platforms outside Apple sphere. Swift isn't perfect but it is very moderne and very high level. Why not Swift? It is in the development stage. As such ports to other platforms like Linux and Windows are works in progress as us the software on Apples platforms for that matter. However Swift 3 is what is being targeted as a stable platform wth minimal changes coming down the road after that. It hasn't been standardized in a formal manner which bothers some people. 
Is this comparable to BeautifulSoup? Can anyone that had used it tell us about their experience with it? 
Thats why you only use dependencies that are well written enough to rarely ever need to be changed. One dependency I like to use is Django. In the past 8 or so years I've used it, hardly any of it has changed. When something works, it doesn't need to be changed.
 &gt;1) they're doing large matrix and/or array operations and not utilizing numpy Some people would consider the need for jumpy to be a fatal flaw. Jumpy highlights a major performance issue with Python as it wasn't designed to do numeric swell on its own. That isn't a bad thing but it does cause some people to dismiss it as a good choice for numerics. 
In bulk? 
I'm not familiar with Blender so I'll assume it requires X. In that case you should give Xvfb a try. It's a X server that doesn't have a display, it's just emulating one. 
The Python language as a whole is large and very dynamic. Trying to write a JIT compiler for the entire language would require a very complex implementation - we would essentially be re-inventing PyPy. By restricting ourselves to a subset of the language we can have a simpler implementation. This would make it easier to obtain high performance and would allow for smaller binary sizes, easing distribution.
works for most stuff. I do like to just type "python queue" though.
Dude....
 def one_pizza_menu_please(i_guess_im_not_hungry): i_guess_im_not_hungry='vince vaughn' but that's not how you use arguments
In this case, you should save yourself a ton of hassle and use [Anaconda](https://docs.continuum.io/anaconda/), or at least [conda](http://conda.pydata.org/) as a package manager instead of pip. The advantage of conda is that it manages non-Python dependencies just as well Python ones. This includes netCDF4 and HDF5, each of which relies - as you found - on a large body of additional libraries such as zlib, proj.4, udunits, and others. You *can* try to configure all of these libraries and dependencies, but you'll soon find that the array of configurable options is bewildering - and you need to pedantically compile them all *exactly* in the manner that your CPython installation was built, which is not a trivial task, else you'll run into all sorts of problems. Anaconda/conda will automatically take care of all of this for you, and build self-contained versions of the packages which live exclusively in an isolated location, which helps to minimize conflicts. That way, in case you're building some other tool (like WRF or a climate model) that needs netCDF4/HDF5, it can use your system-installation and all the Python libraries can use the conda-installed one. As a bonus, there are packages on conda for CDO and NCO!
IME that often gives you Python 3.4 or lower docs before the generic 3 version. (/3.4/ vs /3/). 
Ah, I missed the bit about the JIT. Will you be writing your own or using something like llvmlite?
If you make the magnet uri(s) a link in an html file, then open that file from your default browser, clicking on the link your browser will open your default torrent program and pass the magnet link. I discovered this kludge when I had a magnet link but nothing would open it even if I copied and pasted into the "open torrent" dialogue.
Have you given pyqtgraph a try? It's my go to plotting library. I frequently use it to do 2D plots with hundreds or thousands of data points, and it's interactive to boot. Give their examples.py a shot. 
It doesn't handle JS by default, but you can easily integrate with Splash (a JS rendering engine), via a Scrapy Middleware: https://github.com/scrapy-plugins/scrapy-splash
Yup, it's a neat collection of related functions. Great if you need to do some kind of fuzzy matching on names.
This may be an issue from selinux. I just ran: /usr/sbin/setsebool httpd_can_network_connect=1 but now I get error: Traceback (most recent call last): File "/var/www/html/py/t5.py", line 9, in &lt;module&gt; driver = webdriver.PhantomJS(service_log_path='/tmp/ghostdriver.log',executable_path=r'/usr/phantomjs-2.1.1-linux-x86_64/bin/phantomjs') File "/usr/lib/python2.6/site-packages/selenium/webdriver/phantomjs/webdriver.py", line 52, in __init__ self.service.start() File "/usr/lib/python2.6/site-packages/selenium/webdriver/common/service.py", line 86, in start self.assert_process_still_running() File "/usr/lib/python2.6/site-packages/selenium/webdriver/common/service.py", line 99, in assert_process_still_running % (self.path, return_code) WebDriverException: Message: Service /usr/phantomjs-2.1.1-linux-x86_64/bin/phantomjs unexpectedly exited. Status code was: 1
Python guide has a good page on this topic: [reading great code](http://docs.python-guide.org/en/latest/writing/reading/)
You should try custom searches aliases. So you just write "py queue" and browser will start python doc search with "queue"
Probably best that you thoroughly test an application which can execute commands, though. 
Instead of response = os.system("ping -c 1 " + serverNames[i]) use subprocess module like this: from subprocess import Popen, PIPE proc = Popen(['ping', '-c1', serverNames[i]], stdout=PIPE, stderr=PIPE) proc.communicate() # wait for process to terminate response = proc.returncode 
On the contrary I work in a team where features need to interact with each other and my code is highly likely to be modified as others need to. If I write code that isn't manageable and can't be easily understood by my other team members then I'll be kicked out and replaced with someone that can code in a way that is much more future proof and team friendly. If it's just you working on a small personal project then I can understand but for anything even remotely big I need to be able to constantly refactor and clean well laid out and manageable code is the key to me keeping track on my own code.
there is an error on line 30 of the generated configfile. It reads: search type can be "torrent" or "newsgroup". This should read "torrent" or "nzb" because tvol wont start otherwise. 
Did anyone try actively using `df.query()`?
Ah, I see, that makes sense. I'll have to figure out a way to make that work. I wrote a couple if ideas at [github issues](https://github.com/8cylinder/tv-overlord/issues/21). If you have any ideas add them there. 
I really like [discord.py](https://github.com/Rapptz/discord.py) 
I would dare to say that flask promotes some pretty bad practices, like the global request object instead of DI. I know that talking shit on flask on this sub is karma suicide, but my point stands.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
So.. non-Apple environments still don't work?
You have to press enter to execute the suggested command
This is awesome, looks like a great excuse to get into python 3.
all that is true, but the fact remains, code that adds business value(does it's job) can be shitty or elegant but the users of what the code implements wont care as long as it works. elegance serves developers, code that does a job serves users. often users needs trump developers needs. i dont get rewarded for shipping clean code, I get rewarded for shipping features. the fact that I may have refactored a subsystem or wrote more tests is not what users pay for. Have you ever seen something like &gt; announcing cool system 3.0. no new features but we refactored the shit out of the rendering engine and now the developers are happy and bobby get's to keep his job. you can have it for the low price of 10K per license more than the previous version. 
Crap, so it looks like the nzb downloads are broken. I'll put a fix up today.
How about dubbed versions of the shows, like, German?
If you **really** want to, go for it. Don't let anyone discourage you, and I'm sure you'll learn a lot. Python is very dynamic, so creating a subset might be tricky, specially since people will expect the entire PyPI to run on your interpreter. Adding to the list others have mentioned, [Nim](http://nim-lang.org/) looks really nice, very Python-ish and it compiles to C then to machine code, so you should get the speed.
its just a typo. The programs output is clear enough. I changed it myself in the configfile. 
This is false thinking. Unless code is tested, there is no way to prove that it works 100% correctly. In order to test code reliably and efficiently, the code needs to be built in units/components that expose the least amount of complexity individually, but form a complex system together. If code is broken down in this way, it is likely that the code is easy to follow, and if it is tested well, then you have live examples of implementation of each component. This, to me, is good code. Just because you think your code works, doesn't mean it does. You have religious faith in yourself if you believe otherwise.
Or you could use DuckDuckGo with its '!bang' syntax. '!py queue' takes you straight to the Python docs' own search results for 'queue'. There's '!py2' for the Python 2 docs as well.
Jumpy?
If your reason for using a subset is "otherwise I'd have to rewrite pypy", why not just use pypy?
Excellent, thanks!
It seems "headless" was not an appropriate word here. "GUI-less" would be a better word. That is, I want to access all of blenders scripting features using python, without showing a GUI. Whether X is installed or not, or running or not, is of no concern. Blender is a "professional free and open-source 3D computer graphics software product used for creating animated films, visual effects, art, 3D printed models, interactive 3D applications and video games." Have a look at /r/blender and /r/simulated for an idea of what is possible. It is currently possible to script without a GUI using the python bundled with blender, but there seems to be no way to install it as a regular python package, even though it would obviously be a great boon to the python package ecosystem. [Have a look at all the things we'd could use by just adding a dependency](https://www.blender.org/api/249PythonDoc/). Blender is already easily installable with a single download for Windows, Linux and OS X. I had hoped it was practical to simply to make, say, a wheel variant of each. 
No. I'm sick of fragmentation in the SW world. I stick to the established stuff, and wish the niche variants would just die off.
The nzb downloads were broke, torrents were ok since that's what I use. Anyhow, version 1.3.8 is needed to download nzb's. I need better testing. 
And in fact you can use Splash + BeautifulSoup if you want to (tis what I am using)
Flask is a great framework for standing up applications quickly that have a fairly straightforward structure, but after having implemented more abstracted applications, I find the structure of Express to be better (path variables on the request object not function args, middleware passing), but I still prefer working in Python. Ultimately, the large user base and ecosystem of Flask helps to make up for some of the design decisions.
Isn't this kind of like publishing the solution to Project Euler problems? Takes the fun out of the whole thing, sort of.
The pdf version is also available. 
Maybe if you continue typing that and scroll down and click the python 3 version, Google will over time up the rank on the py3.
Thanks for pointing me to the challenge, but I'm not going to look at your solution. Perhaps you could consider some sort of landing page, so people can have a go at the challenge before looking at your answer?
Web2py
Check out pyramid. Flask is really good if your app is like 3 files and all of them have under 200 lines.
"headless" is synonymous with "GUI-less", what you are describing is an Application Programming Interface (API). Blender has a [Python API](https://www.blender.org/api/blender_python_api_current/). On the tips &amp; tricks page of the docs, [blender as a module](https://www.blender.org/api/blender_python_api_2_77_1/info_tips_and_tricks.html#blender-as-a-module) is what I think you're looking for.
If JetPython doesn't have what makes writing Python code so fast compared to other languages, I'll continue to write Classic Python with a small amount of C code when Python's performance isn't enough (it happens to me very rarely, actually). I think this is due to Python's dynamic nature; if you are planning to make it less dynamic, you will end up with a fast language but slow to code. Just like a lot of other languages. I'm quite happy with PyInstaller/Py2exe + InnoSetup: I can make installer executables contaning pure-C DLLs that make my Python stand-alone applications very fast, when needed. My clients are quite happy with them. I don't know what's your level of expertise, but be sure to not underestimate the difficulty of your project. In the end, I think you should begin writing a small but barely usable interpeter/compiler, build a clearer idea in your mind about the potentiality of your project, and only then think about the major features. 
As mentioned in another comment, BeautifulSoup is more about scraping, Scrapy is also about crawling. The part of Scrapy which is more comparable to BeautifulSoup is Parsel: https://github.com/scrapy/parsel Also, Scrapy is about easing life of crawler developers -- e.g.: it has a nice shell: scrapy shell SOME_URL This downloads the page and lets you to try out selectors and stuff on it. :)
&gt; If somebody (which is usually me) finds a bug in my software, I fix it. Wait, does your code have bugs in it or not?
I didn't know this existed, it's surprisingly fast. I'll give it a go.
Sounds like some r/iamverysmart content ðŸ˜€
Pyramid is nice yes, however Reddit still uses Pylons. Edit: source https://github.com/reddit/reddit/blob/master/r2/setup.py#L60
Pretty damn skippy! If I ordered out more, this'd be great. I'm sure others could make good use of this.
In my experience, typing "python 3" will only actually give me the 3.x documentation half of the time.
So how to look up these small 'tricks'. But that is very clear! Thanks a lot :)
http://i.imgur.com/BWJsK4s.gifv
I get in around 9:30 and usually zone out for an hour in front of my computer, but it looks like I'm working. I then zone out for another hour after lunch too. In fact, in a given day, I'd say I do fifteen minutes, of real, actual work.
This is very strange. Without looking at your code, I would suspect that the overhead of creating 50 subplots is what dominates your time. Any the libraries you mentioned can do 400 points no problem. Even 50x400=20k points is cakewalk; we have Bokeh plots that do that with ease, without even needing to go to webGL. The main problem, then is in the layout and drawing of all the axis elements, tick labels, etc. etc. So I would encourage you to think about minimizing that stuff, and creating the most minimal subplots you can, as a means of expediting it. On the other hand, reading your post again... 10-30 seconds per figure is a LOT. We do realtime plots in Bokeh, transferring into the browser and colormapping in Javascript, at 15 Hz, on tens of thousands of datapoints. So, you might want to post a code sample here to to StackOverflow, because maybe there's something you're doing that unnecessarily slow/expensive...
You can always just go right to the Kaggle website. They have all the necessary information and actual data for this Titanic competition. 
Thanks! I will try that out. Is there a way to integrate these libraries with pandas so I can analyze the data using dataframes?
I see.
*People* find bugs by using the software, unit tests do not find bugs. Unit tests are only for testing bugs that have already been found.
I chose a long time ago not to spend too much time in proprietary programming languages. Microsoft saw the light and hopefully Apple will too sooner than later.
Oh Man, I just bought Python Playground on Amazon. I should've waited :/ [edit] Anyone have personal experience they'd like to share with these?
site:https://docs.python.org/3/ &lt;search term&gt;
Realm of Racket was the best thing I ever did for my R programing 
Thank you!
Does anybody use it in production environment, where reliability is required? It seems reasonable, but we encountered some gotchas (like columns being casted to floats in many operations, even string -&gt; float). Is there any risk of bugs altering the data?
Humble bundles are awesome. I've been buying them since they started.
Amazon has an excellent return policy! :)
Go [here](/r/learnpython)
Always interested to see how people are using pyparsing - please post a link to your project when you are ready!
as i said, pypi is too "bland" :-( ActiveState was interesting but it's snippets and articles and everything... There is also [pypi-ranking](http://pypi-ranking.info/) but it's very general too (no categories) and also appears to be broken/not updating. (also no commenting/community feature). 
How good a deal is this bundle if I only really care about the Python and Javascript books and already have a copy of The Linux Command Line? Also, I've never bought a humble book bundle before. Can I get duplicate copies for on my Kindle and PDF for my tablet?
The books are downloadable in multiple formats including Kindle and PDF, so no worries. No DRM to screw around with either. I've grabbed a couple of these bundles with no regrets.
&gt; i dont get rewarded for shipping clean code, I get rewarded for shipping features. Your bugfixes and features will get delivered more quickly if you write maintainable code. You might gain a few minutes by using single-letter variables and not thinking about good naming, but you'll lose it again when you come back to that bit of code in 6 months time.
No, that's a regression test. You can absolutely write unit tests for something and discover it has bugs.
I really liked Pylons and when it went into permanent hibernation I went over to [cherrypy](http://www.cherrypy.org/) to which the documentation has been drastically improved compared to the mess it used to be.
There are a few on the list. Eloquent Javascript is one that I've worked from. And I'm pretty sure that Automate the Boring Stuff With Python is at least partially available online. Edit: [Eloquent Javascript](http://eloquentjavascript.net/), [Automate the Boring Stuff](https://automatetheboringstuff.com/) **Edit twofer: I also found a few more [here](http://www.onlineprogrammingbooks.com/haskell/)
&gt; what is bad about this awesome deal Well, several of the titles have Creative Commons licences and are freely available on the web. And I'm pretty sceptical that the normal combined price of these ebooks would really be $480. And realistically I don't think very many people are in a position where they plan to learn the basics of python, linux, haskell, erlang, F#, javascript, lisp, racket, R, *and* clojure.
Thanks for the list. Yes, of course it's great that some of these authors make their work freely available, and much of it is very high quality content. I don't feel like I'm taking that for granted. At the same time, when I purchase a book and find out that everyone else on the web is reading it for free and I could have too, it doesn't feel very good, and it makes me wary of any future bundles like this. I have no problem with supporting quality work or charities through Humble Bundle, but I think it should be more clearly disclosed when that's what you're paying for. It feels a little disingenuous to add up the download or print prices of otherwise completely free content to imply that you're getting some incredible discount. ("$480 worth of digital books!")
I am usually a linux/windows guy, but i have to use a Mac at work. This library looks great though...
I use it with Mac at work as well fwiw 
Seriously. 
Do you know Pyautogui? https://pyautogui.readthedocs.io/en/latest/roadmap.html
&gt; I did try conda in the interim but netcdf wasn't playing nice with that either Glad you got it working, but I'm confused by this statement. How was netcdf not playing nice, it is a conda package you just install. 
Oh! I didn't know R was functional! That changes everything, haha. I tried Haskell once or twice and couldn't figure it out for the life of me (I was pretty new to programming). A few years later I took a class in Racket from Matthew Flatt (one of the main implementers of the language), and that changed everything.
While these are available online for free you get the mobi versions with the purchase so if you have a kindle or book this is a major win
This technique could be really useful for applying all sorts of tricks, particularly optimizations. I'm thinking that Numpy or other similar projects could rewrite operations so that there's minimal allocations, or mypy could use it for import time type checking. I like the feature shown here quite a lot, but there's a lot of potential in it to expand Python's capabilities without having to write a PEP, have it accepted, implemented, and released in a future version of Python. 
Also new getting started course just started on Coursera! https://www.coursera.org/learn/python/home/welcome
Worked like a charm! Thank you. Just for my understanding (I'm mainly doing this project to stay fresh before the semester starts), what is the stdout = PIPE and stderr= PIPE doing? I'm guessing it's directing the output to PIPE, which we're not using for anything, thus it doesnt show up, and stderr..not quite sure. Thank you again! EDIT: Also, I noticed with this modification, all my responses say the host are down. Is there a different condition you need to check when using subprocess?
Great advice, thank you!
Thanks for the feedback!
 A column of strings were cast to floats? Tons of people use pandas so I'd say it's as reliable as it gets. If you can reproduce the bug, you should definitely let them know.
Clojure for the Brave and True is also free (as in beer) in HTML, although the kindle copy is $18.
Really appreciate the sentiment here. And I agree with most all of it. The world needs both pip and conda! While there's some convenient overlap in their capabilities, the core mission of the two projects tackles two different problems. Any python code conda installs as a conda package will typically be a downstream version of what's on PyPI. PyPI is the canonical source of truth for the python ecosystem. Just like rubygems.org for the ruby ecosystem and npmjs.com for the node ecosystem. The one point I strongly disagree with is the security argument as you've presented it. For at least the last six months, security patches for openssl were available in the default conda repository in less than 12 hours after release. We also take care to dynamically link openssl wherever possible, so with one package update everything is covered. When it comes things like openssl, Anaconda/Conda is just as secure as any distro-specific package manager. A completely valid security argument against conda--right now--is its insufficiency at guaranteeing package provenance. We use md5 hashes of packages to verify the success of a download. That mechanism was never designed or intended to be a security guarantee. TUF implementation is definitely on conda's roadmap. 
&gt; Some of the packaging recipes are not open Anything in the default repository built within the last four months should have the actual recipe embedded within the package itself (if not, it's a bug!). Like @pwang99 said though, these won't always be conda-build recipes so there's no guarantee you can use conda-build to create the package yourself. But you can definitely see exactly how it was compiled. However, the majority of recipes in the default channel **are** now valid conda-build recipes. And they're all on github: https://github.com/ContinuumIO/anaconda-recipes
http://repo.continuum.io/pkgs/msys2/ is now included in the default channels on windows also. Lots of useful stuff there.
Well the second tier (8+) is mostly Javascript (3 + 1 out of 6). And the first tier has a good intro to python book, and the third tier a decent follow up python book (to help you explore the language). This is definitely not a bundle for anyone who took a computer science course with a programming languages course (you've probably already studied these languages) or who wants to expand their library on languages they already know (these books are all intro, or jumping off from intro books). It's a bundle for people who want to either a] learn programming, or b] expand their understanding of programming (not just learn a new language). A number of these books are language agnostic. But you should seriously consider learning the other languages presented, **they will make you a better programmer**: * F# / Haskel : These are both ML languages (F# is more accessible for windows bound new people, but Haskell is probably better). They are functional first, and will require you to think in a completely different way. Recursion instead of loops, leading to ideas like Map/Reduce/Filter for example. Pattern matching (rather than if's), functional purity and immutability, etc. * Erlang: A massively parallel and safe language, designed that way from the beginning (to run phone switching systems). Google bought a company for nearly a billion dollars per Erlang engineer once. It's a way of thinking about how to build future-of-computing applications from 20 years ago that is now the future. * Scheme/Racket/Common Lisp/Clojure: These are lisps, lisps are powerful multi-paradigm languages. Powerful in a way that's an order of magnitude more powerful than just about any non-lisp language. They will allow you to think about what programming languages are, fundamentally, through the axiom that code is data. A lisp has every feature of any programming language you have ever used, and then some. Python's metaclass system (which is quite powerful) is a cheap imitation. * R: A pretty great statistics environment and a replacement for matlab, always worth knowing.
... could someone check on /u/Azulsky? I think they might be having a seizure.
... R isn't a functional language. It's imperative/OO. R is not Racket.
I mean, common lisp and scheme aren't LISP either. ML is the family of both F# and Haskell, it's their spiritual parent.
Not even close. Common Lisp and Scheme resemble the original Lisp in most ways, from syntax to philosophy. Haskell doesn't resemble ML in any significant way other than being functional. It has completely different syntax, completely different semantics, different execution mechanisms (lazy vs eager), etc. ML and Python have more in common than ML and Haskell. Saying Haskell is a successor of ML is like saying Python is a successor of COBOL.
http://docs.python-guide.org/en/latest/shipping/freezing/ You probably want py2exe. What method did you try? How? What's wrong with that method?
My lisp example was bad, but I still think you are taking it too far. Java is seen as based on Objective-C (it self based on C and Smalltalk), and those languages are quite different in key ways. SML had a variant known as Lazy ML, from which Haskell was based. Hence Haskell continues the ML line, among others, the way Java does C and Smalltalk.
Hell yes, especially when you push toward 100% coverage.
How do I disable a language?
On the bottom left there is a "Select documentation" button.
Thanks! I had to wipe my cookies/localstorage :)
Just bought them through the reddit browser on my phone but it just kept saying waiting for PayPal. I've had a message from PayPal saying I've paid but it's like it has gone through with humble bundle Edit: scratch that the order has gone through now I was worried something might have gone wrong as I used the Reddit is fun in-app browser.
Why are you even shelling out to `ping`. Just use ICMP over raw sockets, it's incredibly simple.
&gt; Numpy or other similar projects could rewrite operations so that there's minimal allocations http://numba.pydata.org/ &gt; mypy could use it for import time type checking I don't think mypy would ever consider going that direction, but others have https://github.com/prechelt/typecheck-decorator https://github.com/dobarkod/typedecorator et al &gt; expand Python's capabilities without having to write a PEP, have it accepted, implemented, and released in a future version of Python. There is a PEP to end all PEPs for this topic, [PEP 511 -- API for code transformers](https://www.python.org/dev/peps/pep-0511/)
Error code 2 would mean [*No such file or directory*](http://www-numi.fnal.gov/offline_software/srt_public_context/WebDocs/Errors/unix_system_errors.html) and would indicate that Python is not able to find *ping* binary. Try changing ping path to whatever is on your Operating System *proc = Popen(['/bin/ping', '-c1', serverNames[i]], stdout = PIPE, stderr = PIPE)*
/r/learnpython or /r/linux4noobs
/r/learnpython
/r/learnpython
/r/learnpython
https://github.com/pydata/pandas/issues/9958 Also,sometimes when you assign a dtype for column through constructor, effect is visibly the same, but later column is randomly casted. It's most likely buggy constructor. We're in the middle of investigating it, though.
It doesn't exactly make an exe, but if you want to let Windows users without Python run your application, [Pynsist](http://pynsist.readthedocs.io/en/latest/) is a tool I made to build installers.
I find SICP hard to read. The lectures are great, though.
lol I have downloaded most of these books.. this is a good way for me to ease my guilty conscience in a single transaction
I think it was an issue with a version mismatch with HDF5; version 1.10.0 got installed automatically when I grabbed python2 via a package manager but when I was trying to build netcdf/install via conda, I was using a 1.8.4 version. I think it was more so a python2 issue than conda, it installed fine via conda, just wouldn't import.
I just picked up the full tier (all the books). Don't know when I'll get into the other languages you discussed, but I'll check them out eventually. Right now though I need to focus. No point in jumping around a bunch of languages to a shallow level at this point, I'm trying to build on what I know and dig deeper, and Python is the language I'm most familiar with. For now I'll be sticking with the Python books and following up later with JS and the code agnostic ones.
I have now. =) It's amazing what you turn up after you start writing your own library.
Unrelated supervisord question. How are you setting startup order?
Yes I included the person id as one of the final features. As you can see, it has the highest feature importance. I'll probably try to discard the person id from the very beginning and see how the score goes. 
Also supervisord is not needed when you run a linux distribution with systemd. 
Whats wrong with django?
It is one less daemon I need to run, It has better logging. It integrates way better with other daemon management software. It has dependencies between python scripts (start/stop order) and other system daemons. Edit: Also tracks all processes launched by your python script. Memory/CPU/Network limit per script or group of scripts.
If you are looking to minimize web framework bloat -- CherryPy might be up your alley: [Give us a REST](http://docs.cherrypy.org/en/latest/tutorials.html#tutorial-7-give-us-a-rest)
This can be so freaking annoying too. 
I don't get warnings doing this. Which version are you referring to? Edit: actually I may still be using 0.17.x. I will have to make sure I have fully updated before I can stand by my comment above. 
Write Great Code Volume 1 is basically a repeat of Assembly/Machine Organization from college. It's a great intermediate book if you know a language and want to gain a deeper understanding of how the computer works at a more fundamental level. Haven't started on the others, can't comment there. 
I find this library really useful and thought it'd be good to give it some publicity. Plus, I just think the name is really cool; Ulmo is a deity from the Lord of the Rings, known as [the King of the Sea and the Lord of the Waters](https://www.wikiwand.com/en/Ulmo).
well now you are projecting. let me try again. customers care about features not the how. developers care about the how(and rightfully so) but how you get the feature out the door is not the business value, the what you get out the door is. this can easily be disproven by showing me a version announcement for a product that is used by users(not developers) where it was announced that everything was refactored and that's what the customer should pay for. 
yes, and now you are projecting again. align yourself with the goal of adding business value and things like you are advocating(which I agree with) go along for the ride and you dont have to argue about them. 
Oh thats awesome news, will have a play when im back in work
DRF + Django may be an overkill if you need simple API that Falcon could do.
Falcon is great. Used it many times, it's very straight forward and provides you with only what you need. You have a lot of control. edit: you might also want to look at [HUG](https://github.com/timothycrosley/hug), built on top.
Flask or Django + DRF depends on size of app &amp; if you already have a codebase with admin-ui
Port your userbase to Linux. 
Does python-eve still add keys to your JSON response that you cannot toggle off? edit: looks like it http://python-eve.org/features.html This is fine if you're developing apps from scratch and have that flexibility, but if you're working to spec, it gets in the way.
Took me a while to figure out you meant a web framework
It was nice. "Designing BSD Rootkits" was my favorite out of that bundle. Several of them started out simply enough, and then you're down the rabbit hole muttering, "What the fuck? I'll have to come back to this later." Unlike what /u/Not_a_dog_I_promise said, the only two in common were the two he mentions. The rest were unique compared to this bundle.
Another great post. I think I like this import approach the best since you'd see it right at the top of the file (like a `from __future__ ...` import) and you wouldn't have to apply it manually beyond that.
Thanks for the input. Haven't had such a course at uni, so might be worthwhile for me then!
They do, haha. But I don't want to return it because I'm very satisfied with the book. Owing it twice is not really that bad, just a "oh dang" type of thing.
Ok, so those 3 make the whole thing worth it (Python Playground is really good too). Thanks!
Your options are essentially: Py2exe, Cx_freeze, and Pyinstaller to make an executable. Pynsist will help you create an installer. I have used the first three and successfully created windows executables for semi-complex python applications. Without seeing the exact errors you received there is nothing else that can be done to debug you situation.
You can try Nuitka, I haven't tried it on 3.5 yet, but it says it should support it now. http://nuitka.net/ 
My man Dharhas on this project! Nice work all! 
[](/twibeam) On a side note, I appreciate the Tolkien reference.
All hail Djang0 + DRF combo, I have had no problems with it in the past. Gets the job done if you want something proper and professional, else you can use Flask if you need something adhoc.
Learning how to package a basic Python lib takes under a day. Is it ideal? No. Is it silly to have your packaging metadata mixed in w/ arbitrary code? Yes. Is it anywhere near as bad as people continue to pretend it is? No. I 100% agree that the big problem to solve is a clean way to deliver end-user applications, but I'm not aware of a language in the same space as Python that has a good story for that.
&gt; Also, if anyone had any recommendations on a way to write Python code without using CodeAcademy Labs, it'd also be appreciated. I'm currently looking for a method but can't find one What?
Not that any of us achieve it on a consistent basis, but it should be a professional goal not to interpret criticism of some code you wrote as a criticism of you. We all write crappy code, for a stunning array of reasons ranging from excellent to awful. Accepting that is a big step on the path to writing better code, because it makes it easier to learn from constructive criticism.
 if color == "Blue" or "blue" or "b" is the same as saying: if bool(color == "Blue") is True or bool("blue") is True or bool("b") is True): ... Since nonempty strings are always True, that simplifies to: if color == "Blue" or True or True: ... which is always True. You want something like: if color == "Blue" or color == "blue" or color == "b": ... or even if color in {"Blue", "blue", "b"}: ...
Sure, but in order to make your product viable in several years time, you need to deliver well-written and well-designed features now. Your *current* customers won't care, as you say, but your *future* customers will. That's why I think there's a false dichotomy presented in the original comment I replied to: &gt; elegance serves developers, code that does a job serves users Good quality enables you to quickly deliver new features in several years time, and therefore serves both developers and users. 
I completely disagree that you can learning how to do Python package in one day. I don't think anyone really knows the best way to package, and even getting to a point of basic competence requires you to know randomly stumble across the right blog posts to read (and avoid old and stale ones!). At best, you can arrive at a state of "this isn't too bad for me" by using something like cookiecutter, but no one really understands all the options, and I will frequently see popular projects that, for example, don't use console_scripts when they should. &gt; I 100% agree that the big problem to solve is a clean way to deliver end-user applications, but I'm not aware of a language in the same space as Python that has a good story for that. "Languages in the same space" just means Ruby and Node, which is two languages. If they're doing badly, it doesn't mean Python is doing well. People say good things about Cargo. I haven't used it though, so I don't know for sure.
There can be only one.
The [official tutorial](https://packaging.python.org/distributing/) is quite easy to follow these days. You won't have a comprehensive understanding of all the ins and outs, but you'll have a redistributable wheel suitable for publishing on PyPI (or your internal devpi server or whatever). To be clear, I don't think Python packaging has achieved some Platonic ideal. It's got tons of room for improvement. It's just that I don't believe it is some unprecedented train wreck. I did more than my fair share of Java, and I can tell you that `setup.py` is light-years ahead of Ant "scripts" and psychotic Maven configurations (you think `setup.py`is copy-pasta, you should check out the ridiculous XML hoops you had to jump through to actually build all those super-duper awesome fat WAR files; and yes, fat WARs would make some Python things *way* easier). Cargo was pretty fantastic the last time I used it, but I was following along with a Rust tutorial. I also don't think static linking is going to become a de facto Python solution.
make a package for the package manager obviously.
I wish I would have bought that one. I meant to but got side tracked and forgot to pick it up.
I hope that this project gains some more traction and contributors. It is fantastic, but it is pretty far behind matplotlib in terms of features. One of the features they've been working on is visual flow control widgets, much like LabView. This could potentially be a killer feature. The upside is that it gives you can make full pyqt applications with it. Embedding matplotlib in other applications has always been extremely frustrating. The downside is that you need to learn about pyqt, even if you don't want to.
That sounds dangerous.
There we go, Thanks
Yeah, I definitely was not suggesting that it's not worth buying just because a few of them are free. Just a "for what it's worth" kind of thing. I picked up the $15 tier myself--I love me some dev books on my iPad!
I like it, very compact code. If I get a chance I'll try it in one of my projects soon.
The metaprogamming to end all metaprogramming :) I think this is fantastic. I could think of a lot of uses for this, particularly on the math side of things.
[here](https://github.com/mrasband/elo/blob/master/elo/schemas.py) is a sample of what I was doing with it, though this project lost the steam for me at the moment. I should probably make these components so I can pull them into other projects. Copied here for help (specific to flask): def consumes(schema: Schema, *, err_status: HTTPStatus=HTTPStatus.BAD_REQUEST): """ Decorator to wrap a request handler method and automatically load the request data using a predefined schema. On error, the err_status is returned with the error content (as given by marshmallow). Args: schema: Marshmallow schema instance to use err_status: Status to return on error Returns: decorated function (flask response, or json response on error) """ def _consumes(f): @wraps(f) def wrapper(*args, **kwargs): to_load = {} if request.method in ('GET',): to_load = request.args elif request.method in ('POST', 'PUT', 'PATCH'): if request.is_json: to_load = request.get_json() else: to_load = request.form many = isinstance(to_load, list) g.payload, err = schema.load(to_load, many=many) if err: return jsonify(err), err_status return f(*args, **kwargs) return wrapper return _consumes def produces(schema: Schema, *, ok_status: HTTPStatus=HTTPStatus.OK): def _produces(f): @wraps(f) def wrapper(*args, **kwargs): response = f(*args, **kwargs) many = isinstance(response, list) return jsonify(schema.dump(response, many=many).data), ok_status return wrapper return _produces 
&gt; experience tells me i'm right and you are wrong no matter what the reddit consensus seems to be here. same for me mate &gt; no fucking shit. but if you dont have years to spend what are you going to do? that's the point. be willing to accept the debt in exchange for some value if it makes sense for the given situation because delivering value is what customers pay for, not the how you got the value. If you have poor customer retention sure
It isn't even a comprehensive list. As another poster said, you might as well have asked which companies are using a screwdriver.
Fix any bugs people find. It's pretty much only been me using it and now that it looks like a few others are using it bugs are turning up. The next step is to improve the docs. Add a faq covering the most common problems people have getting started. Add some platform specific info for how to get things configured. The biggest thing that needs to get fixed is to add tests to all the code. This is my biggest pain point, I don't feel confident when I make a change that I haven't broken something somewhere else. Tests would solve this, but it will mean rewriting a bunch of code. Lesson learned: always add tests from the beginning. I'm open to any contributions - suggestions, bug reports, documentation, and pull requests. I also don't mind taking time to explain how the code works if someone wants to try and figure it out.
That influences which command is run first. But the second command could still start before the first
Sorry to blow you up but I used pip3 install random and it could not fetch index base URL nor find any downloads that satisfy the requirement random. I'm connected to the internet and I'm doing this via the command prompt 
I learned the [native unittest module](https://docs.python.org/2.6/library/unittest.html) circa Python 2.5. I've heard of the other things you list but I don't really grok them (Test framework replacing my existing tests? Test runner calling them? Both?) and it's been several years now and I'm too afraid to ask. So lurking this thread.
I would start with the built in unittest, once you know that if you decide to move to nose it would be easy, they are very similar. Multi-mechanize I have only used for load testing, it is more of a performance testing system then a general test framework. Lettuce is a behavioral driven test framework, it lets you write your tests in something close to plain english so it may be useful if non-developers need to read your tests. Most of my work is API testing and I'm the only one reading my tests so I don't use lettuce. I've heard good things about [pytest](http://doc.pytest.org/en/latest/) but I haven't used it. Depending on what you are trying to do, you could probably get away with using unittest or nose or pytest. When you pick a framework you are pretty much just choosing a syntax to write your tests in, you can call whatever external libraries/dependencies/things you need from any test framework. 
They're called ebooks and they come in paper form too
Thanks for the summary. I didn't realize py comes with unittest
&gt; If you have poor customer retention sure yes, because that would be the only reason you wouldn't have years to spend. there's nothing like companies just starting out, limited funding and limited time. if there were they would be called startups or something.... see not so black and white now is it fella?
Sounds like it's not a pip issue. Fix your permissions.
Windows (running bash through cmd)
ls -l $(which ping) ?
It's kind of useful for utter beginners---which when it comes to machine learning, I am. I have always wanted to get into it, but beyond programming K-means in CUDA once in university, I haven't done anything.
I am a big fan of py.test. It has great features like fixtures, temporary directories and files, and uses simple assert statements. It is very easy to get started with. Unittest comes with a simple mocking package, but it feels too java to me. It works a lot like junit.
Thank you for the response. This still gives me 2's, but I appreciate the feedback.
You can set ```VERSIONER_PYTHON_PREFER_32_BIT=yes``` in the environment to run Python in 32-bit mode on OS X. I've not tried it in the latest OS X version. 
Does ping work from the console? 
 You could try Anaconda. They have prebuilt windows binaries for most python modules.
`ping` requires special permissions on Linux because it's technically a host related action not a user related one. Try something like `curl www.google.com` which does require sending an ICMP packet. This should rule out any network issues.
http://python.w3clan.com/tutorial/14/introduction-to-python http://www.tutorialspoint.com/python/python_overview.htm - - - http://python.w3clan.com/tutorial/15/variables-and-types http://www.learnpython.org/en/Variables_and_Types - - - please f off mate
OP I know you're reading this try r/learnpython... it has less users perhaps but maybe they can give you a book/e book recommendation instead of spicy comments like these. Much love, Another noob
If you choose to be on Linux, you don't need my package as part of a package manager. You can already get all the dependencies very easily. You made the choice to have more freedom over your OS, learn to handle it. There are also too many versions of Linux, so I'll pass. Regarding Mac, I'm not spending $2000 for a paperweight. I make software for Windows because I have it and it's easy to support.
There's an app called Learn Python that you can download the lessons for offline use. Can't speak for the quality because I haven't tried it yet. 
If you are new to python please use Python 3
You will need: - to write tests ([make them discoverable](http://doc.pytest.org/en/latest/goodpractices.html#python-test-discovery)) - a tool to discover and run your tests (eg `py.test`, `nose`) - a tool to mock up state such as DB connections if applicable And I cannot recommend [Hypothesis](https://hypothesis.readthedocs.io) strongly enough - it dynamically generates test cases, finds the subtle issues I never think of, and reports the simplest example to reproduce.
&gt; Some Linux distributions, e.g. Ubuntu, are known to have a broken Unicode font installed by default, which causes various visual artifacts (specifically, Ubuntu Mono font isn't really monospace - many Unicode pseudographic characters have double (or so) width, [...]) Well it is hard to solve, but at least this is *not* broken. The [UAX #11 *East Asian Width*](http://unicode.org/reports/tr11/) Unicode standard categorizes all letters to a handful number of width classes, and the "ambiguous" letters (including most pseudographic characters) are typically full-width in the East Asian culture---hey, pseudographics are to be used with letters and if your letters are full-width it makes sense for them to be full-width as well.
In trying to use this package, I ran into the following problems: picotui/ __ init __ .py doesn't exist, so if you try to run python widgets_demo.py you get the following error: Traceback (most recent call last): File "widgets_demo.py", line 1, in &lt;module&gt; from picotui.screen import * ImportError: No module named picotui.screen If you create picotui/ __ init __ .py then you get: SyntaxError: Non-ASCII character '\xe2' in file /home/username/ExtReps/picotui/picotui/screen.py on line 139, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details Anyone have any suggestions on how to get around this? I tried defining the encoding as utf-8, but that just caused more problems. Thanks.
It's actually OP on his phone in bed. This community is harsh, in retrospect maybe I should have tried r/learnpython. I cross posted to raspberry_pi and found a much better welcome; I'm glad you have the mindset you do.. also if you have the time check out the OP's idea for a non-profit in his very recent history which needs some $.02 from programming minded people 
Good point. For some reason only google is pingable (maybe because I'm using Google's DNS. I get responses to my own address in console and to localhost, but I don't in my Python prog, all give result of 2
It's a tool to easily access climate and hydrology data from certain sources. Here is a tutorial: http://earthpy.org/ulmo.html
I have a perfect project to try this on. Thanks for the link.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
thanks for your feedback. I'll ask the front end dev team to check it
The awesome thing about urwid is that it can be integrated with different event loops (asyncio. Tornado, etc.). Also, if it's new framework, why there is no nice declarative way to make gui? I mean something like VerticalLayout( Label(...), HorizontalLayout( Button(...), Button(...), ) ) Finally, I think there should be AbstractScreen with minimal set of methods and check-methods (e.g. can_use_mouse) to make ports to platforms, which have no curses-like and they need some special way to output symbols and attributes. Of course if picotui target is minimalism, then everything is ok. But I think most users will choose urwid.
See: https://github.com/jquast/wcwidth
Not really, since it will return 1 for ambiguous letters described above, which is unacceptable for CJK environment. (I think `wcwidth` interface itself is very misleading because of that.) Probably explicitly moving the cursor every time you are to print a box letter would work though...
Essentially, those are already well known, aren't they?
Mypy is a solid first choice on the list I would say that [hypothesis](https://hypothesis.readthedocs.io/) and [py.test](http://pytest-django.readthedocs.io/en/latest/) should be the testing libraries that python devs should checkout this year. Most python people will already be familiar with nose. [jupyter notebooks](https://jupyter.org/) should probably also be mentioned with matplotlib If you want to be super trendy then I'd add [tensorflow](https://www.tensorflow.org/) I realise that stuff you should learn for the year is highly personal, but if you've used python for a while you should already be aware of uuid (come on, standard library), pygame and requests and shouldn't be on the list "for 2016". If I was being really harsh, I would say this reads more like blog spam than solid advice for python devs.
Hypothesis is pretty amazing, cannot recommend strongly enough ^once ^you ^understand ^testing 
Pygame? Isn't the latest version of that like 7 years old? 
It can never be enough well known. Well, maybe except for PeeWee when we have Records and Progressbar when we have tqdm.
Ye and if I properly read the article I would have seen that Pygame is in development again so excuse my ignorance.
In the BDD field, I have been quite happy with [pytest-bdd](http://pytest-bdd.readthedocs.io/en/latest/) myself. In the ML space, tensorflow is great indeed (nice [tutorial here](https://github.com/tflearn/tflearn/blob/master/tutorials/intro/quickstart.md)) as well as [Keras](https://keras.io/) which sits on top.
use scrapy/async/grequests to do asynchronous requests. also go to /r/learnpython
doesn't work on Python 2.7
&gt; I couldn't figure out what is wrong with Google. Google spend big money to fight with bots/scripts because bots don't click the ads, and Google doesn't earn money.
First, worry about making it work before making it faster. Then profile it and look at where the time is spent. If most of the time is CPU time, tackle that function and/or use pypy, numba, etc. If most of the time is waiting time (as I suspect being internet stuff), work on making it multithreaded or using async
Okay, but maybe in the future?
Thanks, just started to use it and it is very usable. I wish there was a way to automate the downloading step with some criteria (e.g choose the 720p version with the most seeders).
&gt; This is why we were careful to enhance rather than replace the existing and idiomatic Python package management ecosystem with Gradle. Reading this line makes me think Python does something particularly good to programmers minds - if this was nodejs it would have been 'one feature was missing from this tool, so we re-wrote the whole thing from the ground up and invented a new plugin ecosystem for it too' :P
If the platform im using supports it, I'd transition. What's better about 3 over 2.7?
Have you even tried looking for some in play store? You know there are things called reviews in the play store?
What is wrong with the regular logging module?
I wouldn't say it's horrible, but there's a huge size disparity between the body text and the headings (probably because they are logos) which make it look unbalanced. It also looks like a Microsoft Windows layout, but I'm guessing that's a feature for your target audience.
Many good ORMs will let you get a generator as a result. For something super lightweight I'd recommend [Records](https://github.com/kennethreitz/records).
Holy crap! The author of the readme.md file is so cocky that I was going to contribute (or at least look at the project) and now I feel fear of even clicking in the screen.
I wonder if it's a rendering bug on my end. The body text looks [super wonky](https://my.mixtape.moe/pnfarl.png) to me. The thickness is very inconsistent, most visible on curved letters like 'o'.
[Comment describing what I'm talking about if you can't see it for some reason](https://www.reddit.com/r/Python/comments/4yhhew/10_interesting_python_modules_to_learn_in_2016/d6nzo8a)
&gt; It extends the ElementTree API significantly to offer support for XPath, RelaxNG, XML Schema, XSLT, C14N and much more. Very nice. I currently have code which spawns `xmllint` in a subprocess to validate XML files and it would be much neater to do schema validation in-process.
Not to discourage you, but [jq](https://stedolan.github.io/jq/) is an excellent tool that does this and much more.
Can you explain why not?
This has worked for me on Ubuntu since at least 12.04: $ apt-get install libxml2-dev libxslt1-dev $ pip install lxml
Wow, that does look bad. I don't get that.
there was pycontracts that existed before this disgusting mypy type annotation mess.
Linux is usually not a problem for me since I use the package from the repositories. macOS and Windows can be a pain though. (not so) fun fact: libxml2 2.9.4 has a nasty bug validating schemas: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=832602 and is the version available in Debian Testing / Unstable :-S
Thanks, this looks even better than what I hoped for! It still exist and according to the documentation even works with Python 3 style type annotations. https://andreacensi.github.io/contracts/
 allias ppjson='python -m json.tool'
Yeah. No self-respecting python developer would write an article titled "10 interesting python modules to learn in 2016" and include requests on there. Your "really harsh" to me sounds entirely accurate.
Do you have access to Pandas? http://pandas.pydata.org/
Personally (matter of opinion), I find it's overkill for many small and medium projects. It's also overwhelming to new users because it's a very comprehensive module. For the record, I'm not denying the usefulness of `logging`. It's amazing for bigger projects. Sometimes it's just more convenient to have something quick and easy, though.
openpyxl seems to work pip install openpyxl https://openpyxl.readthedocs.io/en/default/
Good perspective, thanks. At least we'll know that if new Unicode versions will come out, it's not marketing gimmicks, there're actually problems to resolve. Well, picotui tries to stay on the light side of things, essentially it tried to do what was possible to do on IBM PC terminal in 1981. If that means not supporting CJK and users' awareness of needing to fiddle with fonts, be it. (And of course, picotui is open-source project, so someone can fork it and add proper CJK support.) 
I went from nothing to writing my own py.test plugins within a few months. I ended up making a set of tests to run my Jupyter notebooks and automatically convert them; https://github.com/DadAtH-me/pytest-notebook-tests
Welcome to "opinionated software" series by yours truly. Other titles include https://github.com/pfalcon/ScratchABlock , https://github.com/pfalcon/ScratchABit . Enjoy.
until another one comes along and we have to learn how to do the same thing again
why not add all these features to unittest instead? 
Pretty surprised to see Pygame on there. The latest version is like 6 years old or something. lol at Drowzee. 
Except that jq is massive. There's still plenty of room for small tool that do one thing well.
Ask the maintainer of the python standard lib ðŸ˜‰ To be more serious: it always takes time until something new is integrated into the language base. There are plenty reasons for that, some more or less important are... * the code base will increase. * you will have to maintain more code * 3rd party modules will always be more bleeding edge and can adopt new trends. So you will never win the race, no matter how many modules you integrate into the standard lib
I would not put too much importance into the choice of the framework. Imho understanding the principles of ''unit'' tests (vs integration and system tests) and practising writing good tests and good (testable) code is much more important. It is true - as for almost every other framework - that if you know one specific tool, it is quite easy to switch to another one later on.
What do you mean by records?
Btw, @pohmelie, I missed it was you, long time no see! Please don't leave djgpp MicroPython port alone! And well, if you're concerned with even loop integration, as soon as asyncio/Tornado will work on djgpp port, I promise to add picotui support for those to my queue to look at ;-). (Apologies if that's different @pohmelie.) 
&gt; the old school `if __name__` pattern So what's the modern alternative?
The Getting Started example is impressive from the standpoint of creating a REST API quickly. I'll have to compare it to Morepath if I have done work to do. 
Why for mofo in database: url = mofo instead of just for url in database: Why do you calculate instantiate `file_size` and `meta`, when you aren't using it? Some web servers won't serve bots, that may be the reason why you get an error on the second link. What happens if you shuffle the links? How many files are you downloading? Maybe 16 hours isn't so bad. Are all files from the same host? If so, maybe you need to hit them less often.
No it isn't. There is no solution to the problem, only approximations. Project Euler problems tend to be binary, either your solution works or it doesn't. You can't say that a score of 0.8134 solved the problem.
Well, the variables are inside this javascript file https://cs.chromium.org/chromium/src/components/neterror/resources/offline.js?q=offline.js&amp;sq=package:chromium&amp;type=cs I'd say it would be way easier to do what you want in javascript directly than with python, If you really need to use python I think you will have to use Selenium to open a browser and access the Javascript variables.
With docker things are so ridiculous fast to set up anyways, I'm using this image for "quick" rest projects https://hub.docker.com/r/yuxiaorui/docker-django-rest-framework/ Sure it will have more than you need, but if this was a critical performance sensitive system a newbie to python (like me) would probably not be developing it.
As another poster said, python -m json.tool *filename* Is part of the standard lib and already does this...
Cool, I'll give that a try, thanks! 
It's not a great solution, but if you're going to have to test and release every time six is updated to make sure other packages that need newer versions of six wont install because you've frozen your six version low pain ensues. On the flip side, how large is the six.py file? As I've learned the lesson of brittle requirements the hard way I have become much more bullish on the freezing requirements in my project, especially when it's a small utility like six or a potentially soon-to-be unsupported open source library that does one thing I need. Freezing does pass the onus of auditing and bug fixing the code to you, and you have be careful that a license allows it. But where possible I've increase the stability and decreased the number of provision or deployment breaks significantly using this policy. Freeze early and often :)
Yeah, came here to say `tqdm`... it's 2016.
God I love developers on this site. Made me crack up at that last part.
Wait, there is an alternative to `if __name__`?
python has a community that really hammers on good coding practices. you'll hear the word "pythonic" thrown around a lot.
I would have expected a list about interesting libraries to learn in 2016 to be limited to libraries that were introduced in 2016. 
Thank you! I'll experiment with this to see if it really does not preload everything to memory at once when using the default MySQLdb driver with no additional configuration. I'd still be curious to hear any suggestions for the original question or a good example to look at.
&gt; it always takes time until something new is integrated into the language &gt;base. It always *used* to take time until something new was integrated into the language base. Now they're integrating MyPy before it's even finished! :-(
You're being downvoted but are correct. Often in open source the attitude is... "I don't like how this word processor does spellchecking... I think I'll create my own word processor." 
My project, sandman (and sandman2, it's maintained successor) is pretty comprehensive: https://github.com/jeffknupp/sandman2
For packages, I guess there's `__main__.py`.
Done, thanks.
You really don't know how open source works, right? There are not people in suits walking around deprecating stuff while sipping on a Starbucks coffee. The time you spend with friends for a beer on Friday evening is spent by other people to keep all these little frameworks going that you use every day. Yes, keeping them alive takes time, energy and money from other people. Deprecating an open source project will in some cases (like this one) being the result of the person who sacrificied so much for it not being able to continue doing it, and nobody picking up the slack. It's do what you want to be there or find a way to motivate others to do it. So if you want to pay me a full salary I'm willing to pick up nose and keep it going for you. You could even hand in VIP feature requests. Or you could say byebye to your girlfriend, your dog and your buddies in the bar and work on it yourself. However there is nothing to complain about, especially if you done literally zero work and put in zero money to keep the open source world spinning.
`nose` works fine as an extension for the built in `unittest` .. but it doesn't even come close to `py.test` for complex test suites with very granular control over how things work. Your nose tests won't stop working because there's a more modern/advanced framework; you can use both if you want.
[Check out attrs](https://glyph.twistedmatrix.com/2016/08/attrs.html)
&gt; So what's the modern alternative? This pattern is mostly used by people who come from languages like java where you need a specific entry point. It is besides one use case pretty useless. Normaly your script is your entry point. So it is highly recommend to pack all your logic into modules import these into your main script and just run it. Some people like to use this pattern for testing, in my opinion not very good, seperate your tests from the real code. The one use case in my mind is multiprocessing to stop child processes creating new child processes on their own. If you have another use case where `if __name__ == '__main__'` is important please enlight me, besides multiprocessing, which I barely touch I didn't encounter a problem where I had to use this pattern. Anyway in the example of OP it is really just boilerplate. /u/fofo314 also for you the question for an important usecase of that pattern.
Love me some progress bar! 
thank you for the information ;-) 
and i was wonderd , that its possible to run a terminal properly without root access
Wow the readme is trashy and edgy. Written by a 12 year old?
At that point it's probably best to write a small helper function: def contains_any(text, words): for string in words: if string in text: return string This will fall-thru and return `None` if none of the strings match, otherwise it will return the first string that matches. 
To my knowledge the app Termux does not require root access to install or use. However you won't be able to use the 'sudo' command if you are not rooted. However, you shouldn't need to do that to just install python.
Here is an alternative: it does not return the first match, but all matches: def matcher(thing, words): return filter(lambda s: thing in s, words) example: &gt;&gt;&gt; words = ["abcdef", "zzzzzz", "something", "1234", "some other thing"] &gt;&gt;&gt; matcher("thing", words) ['something', 'some other thing'] It returns an empty list when no matches are found. Edit: removed square brackets around `words` since it is already a list.
Cringe....
Well then, take up the maintenance of the project if it means so much to you. That is how free software is supposed to work!
Do you only want the first one, or all of them? If you want all of them, that's pretty easy: &gt;&gt;&gt; words = ["test","foo","bar"] &gt;&gt;&gt; text = "omg this is foo" &gt;&gt;&gt; matches = [word for word in words if word in text] &gt;&gt;&gt; matches ['foo'] If you want the first one, that's pretty easy, too: &gt;&gt;&gt; match = next(word for word in words if word in text) Also, not to be that guy, but check out /r/learnpython for stuff like this.
To expand on the second part of this answer, if you want to get the first matching word you find, but it might be possible that none of the words will match, use something like: next((word for word in words if word in text), None) The second argument to `next` is a default that's returned if the iterator is exhausted without yielding anything. If you don't provide a default value when you call `next` it will raise a `StopIteration` exception instead (which is often less convenient to deal with). You might want a different default value than `None` (e.g. an empty string) depending on what you want to do in the no-match case. If you were iterating on a more diverse set of data and applying a more general condition (rather than just matching strings), you might need to use a sentinel value other than `None`, since `None` could be an actual value in the list you're iterating on. An instance of `object` is often a good choice as a sentinel: sentinel = object() # this specific instance will certainly not be in the list result = next((x for x in some_iterable if some_condition(x)), sentinel) if result is not sentinel: do_stuff(result)
Well, 10 years seeing the wheel turning, and I know what you mean. But I don't think it applies here. It's not a hype that makes people move from A to B, but that nobody's continuing work on A. You can still use A, and if you are willing to put in the hours you can even keep it going in case some dependencies start to break.
yes because i have nothing else to do... Besides, if someone had the time to do py.test, they probably had the time to do more work on nose instead.
Using `if __name__ == '__main__'` is neither old-school nor outdated, you are talking out of your ass. How can you accuse others of bad practices and rudely assume that "python is not one of [their] primary languages", while being even worse yourself and actively spreading misinformation. The entry-point pattern is useful when you want to write modules or scripts that act like both: If I plan to import the module, I don't want to execute random top-level module code during that process, and when I run it directly, I want it to act like a script and use the functionality defined within. And to cut you off beforehand: yes, I use this regularly and there's no "modern" alternatives -- whatever old-school and modern may mean in this context according to you. &gt; The one use case in my mind is multiprocessing to stop child processes creating new child processes on their own. Do you want to know why this happened? Each new process you started, imported your module again and executed all top-level code in it (and recursively started new processes) because you weren't using the pattern -- this is a clear indication to me that _not_ writing proper "main functions" is bad practice.
```try``` https://docs.python.org/3/tutorial/errors.html
Twisted is the goto package for TCP in Python http://twistedmatrix.com/trac/. Asyncio is quickly gaining traction too https://docs.python.org/3/library/asyncio-protocol.html.
i did my time on that. enough.
Let me know if you have any Q's on basic excel functionality with Pandas. I learned basic Pandas functionality a month ago by messing around with imported xlsx stuff. It's actually really quite easy when you get the hang of it and (as far as I know) is capable of everything that openpxyl and librecalc-Python plugins are; the data analysis is just an additional point of interest. As an example, I compared and manipulated and edited and re-organized two xlsx datasheets with a whole bunch of missing and unnecessary data, one of which was 300,000+ lines long and the other at around 85,000. Used a lot of functions too. At the end of all the work, running the program fresh would only take about two minutes of waiting time. Not sure how much data you're working with, though.
&gt; You can still use A and become irrelevant.
&gt; Pytest is really well designed. i am absolutely sure someone said the same for nose.
And there is no disadvantage to it (except for 1-2 extra lines of code, whatever). You explicitly state that this part of code should be run automatically if it is run as the main program.
The standard of code in Celery was a welcome surprise. https://github.com/celery/celery
Oh, my mistake. Thanks for pointing it out.
Blender-as-module is ideal.. *however* it is possible to start blender in a headless mode and get it to run a script. In the past I've used this to implement a (very heavy) file converter.
Whenever I installed a requirements.txt that includes lxml this package takes the longest. Anyone have any idea why?
&gt; Do you want to know why this happened? Each new process you started, imported your module again and executed all top-level code in it (and recursively started new processes) because you weren't using the pattern That is pretty much what I described before but your explaination is more detailed.: &gt; The one use case in my mind is multiprocessing to stop child processes creating new child processes on their own. &gt; If I plan to import the module, I don't want to execute random top-level module code during that process, and when I run it directly, I want it to act like a script and use the functionality defined within. I tend to organize my code in module that have no additional code that will run after importing. If the module code needs preparations I will pack that also into a function and call this function in my actual script. If you use it often could you give me an example where it is urgent to write modules in that style? I am aware what you can do with this pattern, but for an every day use I don't see much use here. I don't write fancy modules that are patches something in other module during importing. &gt; whatever old-school and modern may mean in this context according to you. You got me here, I used the wrong phrase for what I really meant. I saw alot of mostly tutorial or example code that uses this pattern without any point. That is my problem, not the existent of that pattern. I my mind it is like an old hat, so often used and no real purpose. I didn't want to indicate that there is a modern way or something else. By the way an apposite username :D
It can be achieved with entry points. See Flask's `setup.py` for a good example of how to use it: https://github.com/pallets/flask/blob/master/setup.py#L96
One problem with using unmaintained libraries happen when you want to upgrade to a new Python version, and the library happen to use features that are no longer available. If you depend heavily on this library you may not be able to update at all without patching libraries by hand. Regarding py.test it has been around for quite a while. The first commit was in 2007.
Express is so dope. I bang out microservice APIs with it all day every day and it's as easy as it is powerful.
Celery is blowing up, not something you integrate into your project quickly but once you've got it you feel like a next level programmer.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I am using python (pandas to clean data and psycopg2 to load) and postgres. I am inserting about 2 million rows per day. Does this library have the COPY command? I typically write a csv file then open and load it with COPY. It isn't that efficient because I am writing a file temporarily. I also make aggregated tables and stuff using python because I am more familiar with pandas than postgres. So I read from postgres, modify the data, and then make a new table. I'm trying to figure out if this library you made would benefit my work flow 
It only needs python3.x (maybe 3.5, I think) in your machine. If you further need back up to s3, then awscli (aws command line interface) is also required.
Nobody can stop you from using unittest if that's what you want to do. Similarly, you can't make everyone else use unittest when a nicer option exists.
Of course, it's important to remember that it's the references that are immutable, not the objects. &gt;&gt;&gt; t = ({'a': 1}, {'b': 2}) &gt;&gt;&gt; t ({'a': 1}, {'b': 2}) &gt;&gt;&gt; t[0] = {'a': 3} Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: 'tuple' object does not support item assignment &gt;&gt;&gt; t[0]['a'] = 4 &gt;&gt;&gt; t ({'a': 4}, {'b': 2})
I don't really know how far it has progressed since then, but the last time I checked, there wasn't. 
If it is like Python and their goal is the speed of Pypy why not to use directly the battle tested Pypy?
Ping requires special privileges on Linux if you want to do strange things - like flood ping, etc.
Since increasing my use of Python database connectors, I've found tuples to be better in the long run for continuity and security's sake. Since position matters, it allows me to control how my code interacts with databases (as data comes in as a tuple object anyway).
Let me summarize something for you: Nobody cares if any single person X uses open source project Y or not. And people like you, people who think that the rest of world is just there to make them more happy, we actively don't want that. So please go somewhere else. Maybe Java is something for you. Because you are the kind of person who really makes things worse. Go. Away. thanks.
I believe the original was: "Be the change you wish to see in the world. Now guys, how are we doing on those nukes?" â€” Mahatma Gandhi
Good news @kankyo, just pushed input/output validation in this [commit](https://github.com/n9code/calm/commit/8821975487efae128d4c00f4a76869a6ff646f52). Will be rolling out to PyPI in version 0.2, which will also include Swagger.io definition autogeneration.
There is no difference in indexing between the two. Tuples are more efficient to create because there is a custom arena memory allocator for tuples of small common sizes, since their sizes are fixed and cannot very. 
ah the old fuck you got mine attitude. "I don't give a shit if others don't have the time to learn the latest gimmick. I do, fuck them".
So... what's the difference between a dictionary and a namedtuple?
&gt; Pygame? Really? It is old and sadly useless in the modern world, I think kivy is now the way to go. There's also PySDL2 for game dev. The only downside is it's a lot more "low-level" than PyGame (though there are PyGame-like functions available, they aren't completely the same). It is however quite a bit more performant afaik since it uses SDL 2.x instead of SDL 1.2 (which PyGame uses).
[lxml 3.6.4] (https://pypi.python.org/pypi/lxml/3.6.4) is out already
reading one highlighted paragraph out of a page of the docs doesn't mean i am productive proficient with it. 
The distinction clicked for me when I started thinking about tuples as *records*. A row of a table, or some other predefined shape of complex data. Suspect it was my brief adventure with Haskell or F# where i came across that. 
Hi! ;) &gt; don't leave djgpp MicroPython port alone! I didn't, don't worry. I build every new minor MicroPython version and publish it at https://github.com/pohmelie/micropython-freedos with ad-hoc module. And test proper building of MicroPython djgpp build from official repo (without ad-hoc). Probably later, when I will use djgpp build at work (since right now this project is in "awaiting hardware" mode) there will be place for updating FreeDOS build. &gt; as soon as asyncio/Tornado will work on djgpp port Maybe I will try to do it :)
No, there are (unusual) instructions to try it out on github: https://github.com/cheery/lever#how-to-try-it-out and the author also uses vim.
Yes, right now I'm using redis to set flags and have a program wait until a flag in redis is set before continuing. I find it surprising that supervisord doesn't have this feature
I'm upvoting this for the only reason that it was funny to the point of entertaining. Yet, don't expect to learn anything :)
Very slow. I had to write my own for a game server. 
Just to add to others comments, Jupyter in the browser is also easier to extend and theme than a platform-specific compiled Qt application. But mostly I agree that the cross platform nature of browser GUI, wide acceptance of javascript (way, way more js than Qt in the world) and the potential for client-server separation were the drivers. Modularity is an added bonus.
He didn't modify the tuple, he modified dictionaries inside a tuple. Which is allowed, dictionaries are not immutable. You can't put arbitrary mutable objects inside tuples and expect them to magically become immutable.
It's similar to how lists and tuples are different. Dictionaries would be for when you have an arbitrary number of key/value pairs to store, namedtuples are for a specific set of such pairs. Also, dictionary keys can be any hashable object.
Numpy's speed comes from being able to do operations in batches through broadcasting. You don't get any of that with the standard library `array` module. Any time you want to manipulate a value in an array, it has to first be converted to a standard type, the work performed, and then stored back in the array. And you have to do that for each value individually. This is significantly slower than using a plain list: &gt;&gt;&gt; import random &gt;&gt;&gt; random.seed(0xfeedbeef) &gt;&gt;&gt; nums = [random.randint(0, 2**30-1) for _ in range(10000)] &gt;&gt;&gt; import array &gt;&gt;&gt; arr = array.array('L', nums) &gt;&gt;&gt; %timeit [n // 3 + 7 for n in nums] 1000 loops, best of 3: 1.44 ms per loop &gt;&gt;&gt; %timeit [n // 3 + 7 for n in arr] 1000 loops, best of 3: 1.65 ms per loop &gt;&gt;&gt; %timeit array.array('L', (n // 3 + 7 for n in arr)) 100 loops, best of 3: 2.1 ms per loop &gt;&gt;&gt; %timeit -n 1 -r 1 for i in range(len(arr)): arr[i] = arr[i] // 3 + 7 1 loop, best of 1: 2.85 ms per loop 
of course it depends on the computations you are going to use it for, in many cases it can be convenient but I've never seen it used 
In which cases would the built-in array module be convenient? 
I added the last example where you modify the array in place, and it's much slower. But note that in the second example even just iterating over the values is slower, due to the required conversions. Everything is slower. You made the claim that it will "speed up list code so much", so it's up to you to prove that claim. I shouldn't have to be mythbusting anything. 
What does the php script do? Is it a script that you call from a command line? Or is it a Web page? Either way using a database is a good way to share data. Or you could just serialize the array as json, and write it to a file, then run the php script. Or send post it via http, if it's a page.
lol a single well done benchmark is much more meaningful than two misleading ones like yours. check that benckmark again and focus on why it is correct (you can just copy and paste the code). Plus it is not the only benchmark, look at the memory issue there, reducing memory usage so much is indeed a *speed up* (consider the case when you start to swapo memory out, just to name one...)
Under "except" put: try: ... except: print("Failed URL{}".format(url))
First, you'll get a lot more help at /r/learnpython. Next, you'll get a lot more help if you post your code and what you've tried. Right now, no one can help because they have no idea what your code looks like. And if they've gotta do a lot of work just to figure out the question, why would they help? 
I'm always interested in the different way people accomplish things with Python. For example here's a slightly different approach with a similar end result. import os import requests CHUNK_SIZE = 58192 for url in database: file_name = os.path.basename(url) try: r = requests.get(url) with open(file_name, 'wb') as f: for chunk in r.iter_content(CHUNK_SIZE): if chunk: f.write(chunk) except requests.exceptions.HTTPError as e: print('ERROR:', e) print('URL:', url) 
It should have been `Elist = [0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 2, 8, 5, 6, 7, 3, 4]`.
/r/learnpython
/r/learnpython
 Dlist = ['ask', 'not', 'what', 'your', 'country', 'can', 'do', 'for', 'you'] Elist = [0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 2, 8, 5, 6, 7, 3, 4] str="" for each in Elist: str+=Dlist[each] str+=" " print(str) 
Some men just want to watch the world burn.
 [Dlist[i] for i in Elist]
itertools rawk.
Nicely functional :-) `' '.join(map(Dlist.__getitem__, Elist))` or the more pythonic: `' '.join([Dlist[x] for x in Elist])`
That's why [`namedlist`](https://pypi.python.org/pypi/namedlist) should be in then standard library (albeit with a better name, maybe `record`?)
Or use a generator comprehension as the argument to `join`: ' '.join(Dlist[x] for x in Elist)
I am using pandas write and read pickle. 
Me brother, very good
Normally "opinionated" means "like Jony Ives", not "like Donald Trump". You sound like Trump. That's not a good thing. 
I'm just starting to learn Python.. I've been looking at different udemy courses and code acadmy. Thanks for sharing this post dude 
awesome, thanks for explaining.
There sure are a lot of iterators functions. I've used the permutations functionality before - very useful.
can you tell me the browser type and version it looks bad? thanks
I use attrs[[docs]](https://attrs.readthedocs.io/),[[pypi]](https://pypi.python.org/pypi/attrs/16.0.0) to make classes where I need records. (there are now n+1 competing standards, like string formatting)
thanks. you can look in the site , there are some more python tutorials for begginers http://www.discoversdk.com/knowledge-base 
Firefox 48 on Linux.
thanks. i'll check it
When I see an open-source project which duplicates efforts of some other project, the first thing I want to know why the duplication. That's really the first and most important information I need to know. Everything else is secondary. Of course, working on such project myself, that's the first thing I communicate. I'm sorry to hear that some people need to read about "python setup.py" first. 
Happy to help! 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Double underscores before/after are used for some special built-in names. \__name__ is name of the module where the script starts or __main__ if this is the module the script starts from. The if statement let's you make Python files runnable and importable(without running)
Idle is seriously the worst thing ever. It's a little more difficult to figure out but I'd recommend pycharm(free community edition) and ipython asap.
For me the approach of pyglet was very interesting. But is also low level and the documentation is pretty much non-existent. Also it seems that nobody on the net is using it. And this is very important for a game framework, a active community. Years ago I played around with some flash game frameworks and besides all the negative sides of as3 and the environment flixel and especially flashpunk were very good frameworks. Usally they handled the low level stuff pretty well and you were free to create you game without pressing you too much into a very specific engine like unity is doing. As I said kivy looks promising and offers you a handy environment with buildozer and pyler. But personally I don't like kml layer like qt is doing with its qml. It makes me thinking I build an GUI and not an actual game. But that is personal preference. Beside that it looks like python oversleept the whole mobile and game market. Yes you can create a webapp with the powerful web frameworks as replacement for native mobile apps but it feels like an overkill for a simple mobile app the most people just want to code... And the performance is another problem.
I have PyCharm, i just didn't feel like explaining how to set the interpreter and such up when I typed that part of the tutorial so I said to use IDLE. I feel like IDLE will work just fine for now. Although I liked the fact that PyCharm through errors as you typed.
Don't get "WOW" effect for this article. Standard library documentation is more than enough, have excellent examples and python equivalents for itertools functions.
When a module loads there is a global attribute set called `__name__` which gives the name of the module. The exception is when the module is being executed the `__name__` attribute is set to `__main__` - this allows you to detect the difference between an imported module and an executing module. I didn't know that Guido had tweeted about using the multi-line as a comment - I am not sure I have ever seen it in production code, but I am happy to stand corrected. 
Yup, see examples with [PyQt5](https://github.com/takluyver/pynsist/tree/master/examples/pyqt5) and [PyQt4](https://github.com/takluyver/pynsist/tree/master/examples/pyqt4).
That ends up being a single test though. Py.test allows you to parameterize fixtures. A test function using such a fixture will have a unique execution for each value. In the unittest framework, I will fail early by default. I would give a concrete example, but I'm on mobile. If I have time later I'll update the post. 
Maybe you're looking for [types.SimpleNamespace](https://docs.python.org/3/library/types.html#types.SimpleNamespace)?
You can either send off the data via HTTP in the endpoint, surround it in its own Try..Catch block so if it fails it doesn't kill the client response. Or, set up a BufferedLogging interface and save your ES data over time and fire it off after a threshold of time or size. The overhead is going to be minimal unless you're saving off tons of data .. and then you probably have other issues to worry about.
Ok, the try/except solves the HTTP failing, but what if the HTTP takes 1 second? The user is going to be waiting 1 second longer for the response... Also, what's buffered logging? I mean, I can imagine what it is, but is there a module to take care of it? The logging module doesn't seem to do it.
If you're using an asynchronous web framework you can leverage that so the logging won't block. Tornado, gevent, aiohttp, they're all built in. And this is what i had in mind, it's a special type of `MemoryHandler` called [`BufferingHandler`](https://docs.python.org/2/library/logging.handlers.html#memoryhandler) and should just drop into your code if you're using the built in `logging` module.
So, I don't know about tornado or aiohttp. However, gevent as far as I can tell, can only be used to shoot several request asynchronously, but the code will still block until all responses are in. What I would need in this case is a way to shoot 1 request and move on without waiting for a response. (I will look into your link, thanks)
But away, I could be mistaken but I think that a gevent spawn is not what I want. Gevent spawn is "asynchronous" in the following sense: ## http request g = gevent.spawn(...) ## this would be the http request to elasticsearch while g: ## asynchronously do stuff while g is running ## http response This is not what I want. What I want is something like ## http request ## make http request to elasticsearch, continue without waiting for response ## http response In other words, gevent relies on an event loop, which is not what I want (as far as I can tell)
1) When you say flaw, what is the code producing? 2) I don't feel.like this is testing the Monty Hall problem. The Monty Hall problem is applying the game theory that by chafing your original choice, you go from a 33% chance to select the correct door to 50%. You look like you are testing if you are winning or losing more often than not. So the question is what is it that you are trying to test with this program. As far as the 33% vs 50%: You have three doors (2 that you don't want and 1 that is the winning door) You choose one, example door 3 That's a 33% chance to have selected the correct door ( 1/3 == .33333333 aka 33%) The next part is reveling a door that is not the winner (Example: door 2 is the winning door, and because it is the winning for and you have chosen door 3, they would show door 1, if it was door 3, they could show either door.) From there, that leaves two doors left, and they give you the option to switch your door to the other remaining door. (1 out of 2 chance to pick the current door, that's 1/2 or .5 aka 50% chance) This works better by thinking of more doors. Do it with 100. Choose 1 out of 100, that's a 1% chance, then show all the doors except what is behind the door you choose and another. You have two options, keep your door or take the other. Its now 50:50 because you have two options, and that's it. All the other doors don't matter at this point, only the options left in front now. This world due to the fact that you are now working with more information than before. When starting, you know nothing behind any doors and now you know what is behind one of them, but by changing your original choice to the other option, you will raise your chance of success. Note: this is about increasing the probability of winning, but it is not a guarantee or winning. 
That's cool! Thanks for sharing that!
Similar to the points mentioned about nose vs. py.test, it's also worth looking at alternatives regarding progress bars if you are looking for additional functionality (stuff like estimated time left etc). E.g., [pyprind](https://github.com/rasbt/pyprind) or [tdqm](https://pypi.python.org/pypi/tqdm)
this is quite a valid point you put there, I am wondering that as well. ps: I am not promoting arrays, I am __just__ asking something
Maybe. So put a LINK to the rant at the top then. 
They also have a sliding window function in [PyToolz](https://toolz.readthedocs.io/en/latest/api.html#toolz.itertoolz.sliding_window) (which is a great supplement to itertools). But they use a strange trick with a collections.deque to remove the first items from the tees. Source: def sliding_window(n, seq): return zip(*(collections.deque(itertools.islice(it, i), 0) or it for i, it in enumerate(itertools.tee(seq, n)))) Edit: I wonder why they don't use their own toolz.drop function: from itertools import tee from toolz import drop def sliding_window(n, seq): return zip(*(drop(i, it) for i, it in enumerate(tee(seq, n)))) print(list(sliding_window(3, range(10)))) 
Just use ffmpeg, either from a shell script or from Python via something like PyAV. Just about every "audio conversion suite" uses ffmpeg internally anyway. 
THANK YOU. This is exactly what I needed.
I use pyephem to give me astronomical data for a journal script I wrote. It can give the distance to earth for any body in the solar system. From what I can find it's accurate and has been used in actual scientific situations by astronomers. Check out their [quick reference](http://rhodesmill.org/pyephem/quick.html) which gives you an overview of some of its capabilities. 
In addition to /u/snaftyroot, you can access namedtuple fields with indexing which you can't do with dict like: from typing import NamedTuple Person = NamedTuple("Person", [("name", str), ("age", int)]) p = Person(name="Keanu", age=51) p.name # same as p[0] p._asdict() # returns namedtuple as OrderedDict 
`sliding window` is nice and very descriptive name for the function. But I am wondering, won't using a deque make the thing not beeing 100% lazy? BTW PYToolz seems to offer very nice additions but somehow I don't like their general naming convention, it sounds so much like script kiddy language ;)
&gt; But I am wondering, won't using a deque make the thing not beeing 100% lazy? No, if you take a closer look at the code you'll see that it's just a weird trick to drop the `i` first elements. They should just use `toolz.drop` which is a synonym for `itertools.islice(seq, n, None)`. &gt; ... I don't like their general naming convention, it sounds so much like script kiddy language ;). You mean because of the z in toolz? I think they had to do that because itertoolz shouldn't be confused with itertools. Most of the function names are quite readable imo.
&gt; You mean because of the z in toolz? I think they had to do that because itertoolz shouldn't be confused with itertools. Most of the function names are quite readable imo. Partly the z bothers me, but I complete forgot to mention something else. This is from the streaming example: `&gt;&gt;&gt; from toolz.curried import pipe, map, filter, get` I don't like that they override the built-in functions `map` and `filter`.
 """ $ python monty_hall.py 1e6 3 Won stayed: 33.30 % Won swithced: 49.96 % """ from __future__ import division import random import sys samples = int(float(sys.argv[1])) doors = int(sys.argv[2]) won_stayed = 0 won_switched = 0 for _ in range(samples): r = random.random() if r &lt; 1/doors: won_stayed += 1 if r &lt; 1/(doors - 1): won_switched += 1 print('Won stayed: %.2f %%' % (100 * won_stayed / samples)) print('Won swithced: %.2f %%' % (100 * won_switched / samples))
Can confirm; am astronomer, have used pyephem. It's way faster than AstroPy for doing position calculations.
&gt; The fact that you chose Python already says that runtime performance isn't your #1 priority This is becoming an ever harder argument to make with the development of [numba](http://numba.pydata.org/). There are already some cases where numba-jitted Python beats compiled C.
From itertools doc page: chain('ABC', 'DEF') --&gt; A B C D E F I don't understand what examples you need more? This is exactly what chain do. There is no extra arguments or corner cases, it's simple.
Now that the code is over... Surely you could look up the answer on the interweb? So the question is surely "why it is 2/3 to switch?", and not "what is the answer?" Wikipedia _is_ generally reliable especially when they give the mathematical proof. It's good to check things, of course. The hard question is what do if due to a bug you did not see, your code returned 50%? :-)
Amazing that you found *exactly* what you were looking for. Is there anything python cant do? 
What's the point of such posts? Do people seriously believe that Python is an obscure language and celebrate whenever it "makes it to mainstream"?
Unless this is a training exercise, consider using os.walk: https://docs.python.org/3/library/os.html#os.walk
Thanks RubyPinch for reporting us, we have sent the message to author http://python.w3clan.com/?tab=author for copying the content and not providing source url . We are waiting for his response. Thanks
I can't be 2/3rds. They took away an option that you cannot choose, leaving only two options, hence is 1/2, at least the way I see it.
If you initial choise was the wrong one then they don't take away an option at random. The chance your inital choise was right doesn't change when they take away the door, so changing your choice leaves you with 2/3 odds of winning. Take a look at the second python program the OP posted, it will tell you the chance to get it right if you switch really is 2/3.
I was initially skeptical, but this seems to have a very solid use case. The tl;dr is that it's really only used for dependency management (and possibly building extensions), then providing dependencies to Setuptools.
Looks like that might actually become something useful. The standard docs are pretty bad, especially for beginners, so this might be something worthy to point them to. The only downside for me is that stackoverflow's setup doesn't really feel like it's good for documentation. The vote based sections make proper structuring of a comprehensive guide difficult and they apparently still don't have basic features like syntax highlightingâ€¦ Maybe that'll improve in the future.
[Here's a good list of ideas](https://github.com/karan/Projects).
Everybody's talking about the chance of winning. If you choose to switch, your chance of winning is 2/3. If you choose not to switch, your chance of winning is 1/3. Your solution - that the chance of winning is 1/2 whether you switch or not - is exactly the seemingly obvious (but incorrect) solution that makes the Monty Hall problem interesting and famous. If the answer was just 'there are two identical doors left and so each has a 50% chance of being correct' then we would never have heard of it.
https://betterexplained.com/articles/understanding-the-monty-hall-problem/ 
Glad to see you're reading up, since it's a really interesting problem. Hope it's starting to become clear now!
When I was 15 I was writing eggdrop scripts and BitchX scripts... I then graduated High School and became a line cook. It wasn't until I was 25 or so that I got back into technology... I'm now 35 and a DevOps engineer. You're never too old to learn new things. 5 years ago everything I worked with was in Ruby, now it's Python. 
Thanks :)
The good things from namedtuple with mutability would make a nice container. It seems that many people have been looking for/have implemented this. The answers on this thread suggest namedlist / types.SimpleNamespace and there are more in the answers of the SO question http://stackoverflow.com/questions/29290359/existence-of-mutable-named-tuple-in-python .
Are you aware of the module index [modules ](https://docs.python.org/3/py-modindex.html) and the general index [index](https://docs.python.org/3/genindex.html), top right hand corner of the screen? I find them extremely useful.
This might be helpful: https://ilya-sher.org/2016/05/19/tips-for-beginning-systems-and-software-engineers/
Hi @metaperl, if you have any doubt about how to start with Ray or even if somethings during the development goes wrong, please, feel free to send me a message on Twitter: @felipevolpone.
Try reading [Teach Yourself Programming in Ten Years](http://norvig.com/21-days.html). The author isn't much in the world of programming, he's only the Director of Research for some little startup called Google :D
You can use https://pypi.python.org/pypi/recordtype/, which gives you a mutable tuple. After experimenting with the list/tuple/namedtuple/recordtype approaches, I've come to the conclusion that the extra boilerplate of defining a class to represent a record is more than worth it for the autocomplete, static code analysis, runtime validity checks (bioinformatics is full of text-based data formats, and text based data formats tend to not to adhere to their own specs) and post/pre processing of the fields.
&gt; The standard docs are pretty bad compared to what though? many languages would wish to have as comprehensive a documentation as python has.
Yea.. Not great though. As others have pointed out in this post already they scroll away for example. 
Runtime performance is still not a compelling argument for Python; the language excels more clearly at other things.
`pycodestyle` (ex. `pep8`) is the most popular one, just for code style checks. There's also PyLint and PyFlakes which provide some limited static analysis, and PyCharm, an IDE that provides a really nice set of static analysis features (think IntelliSense hints in Visual Studio, but very well integrated with Python, even using type information collected during debug runs (!)). Honestly, if you want linting, just use PyCharm - it's great with that.
http://www.fluentd.org/guides/recipes/elasticsearch-and-s3
Yeah thanks, but I don't really understand what problem fluentd solves. My original question was about how to make a PUT into elasticsearch asynchronously inside the request/response HTTP cycle so that I could be pushing some data there. Here I would be pushing the data in a _real time scenario_. If I knew how to do these asynchronous PUTs (which btw I've learned how to do; let me know if you'd like details) I wouldn't need outside tools like fluentd, it'd just be a matter of coding a PUT myself. Then your comment got me thinking that I don't really need to be doing this in real time, actually. A _non real time scenario_ is much simpler. Like you said, I can just write the data into a file and once in a while send it to S3 (and offline, in a different machine, I would pull the data from S3 and send it to elasticsearch). So I started reading about logrotate (which is a really simple tool) and s3cmd (which is also a really simple tool), and problem solved. So once again, I don't know what problem fluentd would be solving in this scenario.
Wow, thank you for sharing your journey and the perspective you've gained. I find your story inspiring. I've been kicking myself for too long for not getting into programming earlier. Partially because I know many people who had less computer knowledge than me as a child who then went on to be very successful through their programming knowledge. As a 14 year old I had friends my age who getting companies online for the first time in the 90's for a lot of money. I've mostly worked in education and tourism for many years. I've had a good and interesting life and traveled a lot. Programming is something that comes back to me like a comet ever few years. The people I admire the most are those who can work remotely anywhere in the world there is internet, an element of programming seems to a common trait many of these digital nomads have. I've decided to stop regretting what I didn't do and make the choice to start learning and get a feel for programming and see if the reality of it is something I enjoy. I'd appreciate having a look at your program outline. You can PM it to me if you like.
I'm pretty sure you mean well, but "Hi guys, execute this totally unvetted code as root and you'll see naked ladies!" pretty much rings every possible computer security alarm bell.
Jesus christ that's terrible code.
well, in all honesty. i couldn't get it working without root. if you can suggest a way to make it work? i'm all ears!
I have often written something similar. Except that i also test for iso-8859-15 being european and all. It is a very sane pattern if you are certain your encoding is in a specific subset. But i must admit that i very much like having switched to python 3.
Why is this being ran as sudo? I suggest just fixing the permission issues that is causing you to think you have to run as sudo. Also why are you using urllib.request for the http requests and requests to handle the https? Why not just do both with requests?
https://docs.python.org/3/whatsnew/3.5.html#pep-461-percent-formatting-support-for-bytes-and-bytearray
fluentd lets you take a file and send it straight into elasticsearch. I.E you don't have to send it via S3. It's like logrotate but a bit more pluggable. Eg you only need fluentd not logrotate, s3cmd and whatever moves from s3 into elasticsearch.
Haha, no problem. But it should be pretty easy to tweak this to work in a safer way without root: * Instead of using subprocess for file creation/deletion, use the os module. * Instead of using subprocess for launching the browser, use the webbrowser module. * While this isn't strictly required, if you find yourself doing path manipulations via string operations, it's pretty much almost always better to use os.path instead for reasons of bug prevention and portability across operating systems.
Sure, I understand. Just letting you know. You can change your http url to use requests also ;) But does the https one download the image correctly? I didn't test, but I see you get the response but you don't do anything with it.
Thanks for the feedback. `toolz.curried` is a convenience namespace. The functions contained within it are curried. For example, `toolz.curried.map` is equivalent to `toolz.curry(map)`. It doesn't change the meaning of `map`, it simply let's you partially apply arguments to it. This let's you do convenient things like: pipe( seq, map(func), filter(predicate), map(another_func) ) which I think is much more readable than: map(another_func, filter(predicate, map(func, seq)))
what is this code trying to do? What's the expectation for "res"? Why should str() ever throw an exception? What purpose does res.decode('utf8').encode('utf8') serve?
It's ironic that the function is called unicode_safe. It's not unicode and not safe. It probably should be called utf_8_at_any_cost(). 
Really like the type hinting.
When you write this kind of code, it shows that you have no idea what type of variable it is. Python 3 finally makes things explicit. You have two distinct types: strings and bytes and it's harder to lose track of it, because python will throw errors.
Oh, fair point, I guess. I guess I was sort of prejudiced because I've seen quite a few of them and I think that more of them were in Python than in C (or anything else), so I was, just, like, what's the point? If the point was to show that you can actually use Python for low-level things like that, then all right, good stuff.
`cd` into the folder you have it, and do `ll`. It's possible the user running the script doesn't have write access to `img/`.
[Django's force_text()](https://docs.djangoproject.com/en/1.10/_modules/django/utils/encoding/) is better and also shows that the Python 3 path is not simpler.
15? Here is my chronology of languages I've learned over the years, and the age at which I learned them: BASIC - 13 FORTRAN - 17 Pascal - 24 PL/I - 27 COBOL - 29 C - 32 Smalltalk - 35 C++ - 35 Java - 37 Tcl - 38 C# - 41 Python - 43 Boo - 45 Processing (Java) - 47 Groovy - 48 It looks like I'm overdue to learn another language. But in the Python world, I'm more than busy enough keeping up with web frameworks, databases (relational/NoSQL/graph/document), asynchronous/threaded frameworks, cloud deployment, mobile app development. If you want to learn another language, learn enough C to create a little library, and then figure out how to call it from Python using ctypes. Knowing multiple languages can really help you in appreciating tradeoffs and implementation bits from one language to another (like Python and Java's garbage-collected memory management, vs. C/C++ manage-it-yourself, or the implementation ramifications of Python's native data structures). 
Django's `force_text` isn't the greatest example. It has to work on Python 2 and 3 simultaneously (Django is not a Python-3-only framework yet), and also has to handle things that aren't strings but are intended to become strings (like lazy translation objects which don't get resolved to a particular translated version until the last possible moment).
There are three mostly-distinct kinds of Python linter: - `pycodestyle` for... code style, as per PEP8 - `pylint` for static analysis - even with dynamic typing, it catches most of my stupid mistakes - `mypy` (`pip install mypy-lang`) provides optional gradual static typing, with decent type inference from annotated function signatures. Anything can still happen at runtime, though :)
Is it pretty common to use a linter?
Full disclosure: I'm the author of this project. I wanted an async web framework for Python 3 and asyncio that was simple to use, and whilst aiohttp was satisfactory I decided to implement my own. After a few months of dev I'm finally at a version that I feel is "presentable" to the public, and wanted to show it off. If anyone has any questions, ask me and I'll be happy to respond.
Here's a quick and dirty script I wrote you can look at https://github.com/libresec/Ping-Sweep
I think Flask + async is a great idea. Will you cover more aspects of Flask extensions or just vanilla features? i.e. the 'batteries'
Similar extension styles might be added - I'm not really sure how to structure these though.
this is like /r/programmingcirclejerk material right here
Project Euler if you're into math problems!
Have you done any benchmarks comparing the speed between Kyoukai, Flask and Django?
For web apps, when you need asynchronous or background processing to occur it is often a good option to use worker processes. http://www.celeryproject.org/ is a popular Python library for that. In addition to offloading the Elasticsearch operations you can benefit a lot from delegating nearly anything that doesn't require the user to have a connection open, for example processing uploaded image files, sending emails to newly registered users, or even pre-warming a cache at a certain time every day.
Or if rewriting all your IO code and/or restricting yourself to a subecosystem seems like a bad idea just use gevent, Flask has built-in support for it.
If you're logging to a file, you can also use [Logstash](https://www.elastic.co/products/logstash) to forward the data to ElasticSearch
That is true, and part of my job was working with old data with mixed encodings. So sometime real-world happens and you got to play dirty to get stuff working in a specific timeframe.
In fact the title is completely wrong, "why is no one doing anything to amend it?" indeed. There is a specific component on the Python bug tracker specifically for doc changes. I've known such changes be approved and committed within minutes of being posted. Whinging, bleating and complaining on reddit or any other third party site will not change anything. What really infuriates me is the people who do not have time to propose changes, but do have time to complain, how strange? Perhaps such beings should revert to proprietary software, which is always beautifully documented.
I would haved hired a hitman to put me down if I touched a computer if I was 15.
That was the very main reason. God, I despise Unicode "support" in python 2.
Fluent Python goes into a lot of detail and might be Worth checking out for you :)
So that people can go atomic 
hey thanks for the reply! I was planning on running this as an alternative (https://github.com/kfichter/OpenATC/blob/master/Scripts/supremenewyork.py). Yet I still have one question, where do I input my own info? Would I simply create another file and patch it into the script? like per say a document where billing_address = "xyz 123 street" ? As a complete novice this would do me a great service of understanding.
&gt; Run as root :) 
And according to LibHunt, it is among the top 6 most actively developed frameworks https://python.libhunt.com/categories/254-web-frameworks?order=activity
It would be more lines and very likely bit slower. Clarity is also debatable. Function is not that big to benefit from splitting up code. Sometimes people push "best practices" too far..
it appears to mean â€œboundaryâ€ or â€œborderâ€: http://www.wordsense.eu/å¢ƒç•Œ
Sure, or you could do it for free with fluentd
``list.__sizeof__`` only measures the size of the list itself, you must also account for the million extra longobjects being kept alive on the heap. On 64bit these are 28 bytes each + allocator overhead (which I believe is either 12 or 16 bytes in this case)
Don't do what Flask did with naming extension packages like `Flask-Package` which provides `flask_module` that also can be imported from `flask.ext.module` through a convoluted non-standard import mechanism. Please rely more on the standard (read well-established) distribution / module declaration methods, especially now that `distribute` is merged back into `setuptools`. Do rely on [namespace packages](http://setuptools.readthedocs.io/en/latest/setuptools.html#namespace-packages) so you can actually declare `kyoukai` as a namespace (or `kyoukai.ext` if you want to follow the "flask" convention) and then have extension developers follow that practice (i.e. full blown proper Python packages with correct namespace declarations).
itâ€™s a bit sad if after 16 years you donâ€™t know that the real solution is to not write this function, but instead to fix the whole mess that ended up creating a demand for it. this function makes objects of any type into utf-8 encoded bytes (except if the objectâ€™s `__str__` method returns non-utf-8 bytes), while special casing bytestrings and unicode strings. instead the codebase should work with unicode strings throughout and convert bytestrings *to* unicode when appropriate.
~~I've been meaning to do a *proper* benchmark, but I can say that from my own testing, the HTTP server runs about as fast as a multi threaded Gunicorn with Flask.~~ ~~After some benchmarking, I'm retracting this statement. The built-in HTTP server is about **5x slower** (3ms vs 0.6 for gunicorn) right now.~~ After identifying the bottleneck, I further retract this statement.
The slight weeaboo tendencies lead me to it
When is this a better choice than flask and why
Hi Octane, it looks great! I like a framework, where i still can see how it works.
One of my biggest motivators was to write something that was easily embeddable inside my other async applications. Whilst I could definitely do this with aiohttp, I also had a bit of curiosity about if I could write my own framework and thus this was born. So I believe it's definitely a better choice for embedding inside an async app compared to having a flask server. You can't say which is better, because they have differences and their own set of advantages and disadvantages.
if possible, you donâ€™t, and instead you login interactively, and request a login token that is valid for that machine for subsequent logins. read below the line if you want to do that. the trivial way would be to read them from environment variables or arguments. then you populate those by using your password managerâ€™s CLI. if you have OSX or linux, you can do sth. like this: export USER=foo export PASS=$(security find-generic-password -a $USER -s myapp -w) #export PASS=$(kwallet-query -r "$USER@myapp" kdewallet) python myapp.py --- for the token approach, iâ€™d use [`input`](https://docs.python.org/3/library/functions.html#input) and [`getpass`](https://docs.python.org/3/library/getpass.html) to get username and password, then use the siteâ€™s API to get the login token, and store it (to a location retrieved via [`appdirs.user_cache_dir(...)`](https://pypi.python.org/pypi/appdirs)). iâ€™m doing almost that [here](https://github.com/IRkernel/irkernel.github.io/blob/65a6754993a7d034847c7020683f3b66dac5ec45/docs/update-docs.py#L22-L88) the only differences are a bit of API-specific error handling and that i use `getuser` instead of `input` sorry: thatâ€™s pretty involved and requires the app to have a token-based authentification system
Oh ok. And how can I measure the real memory usage?
~~Before you get too hyped,~~ please consider the following: - I'm shit at programming - I suck at making things work - English isn't my native language so keep that in mind - First time using github so sorry if I make any mistakes
Gevent can be tacked into asyncio (probably horribly), without that much business logic changing. In fact, outside of changing the globals to locals, rewriting actual worker code probably wouldn't take that much. Of course, I do not recommend switching framework to this from an existing project, so I have no idea where you got that from. And sure, you may be locked into asyncio, but asyncio is pretty nice to usem
Brilliant. In fact this release contains a feature addition by me. It was my first contribution to the project and the code base was a pleasure to work with and the team were very helpful.
/r/learnpython
I think we're going to start seeing next generation of Python web frameworks with the introduction of asyncio and this is one of the examples. To the OP: The way you write type hints are inconsistent.
I guess it is very well tested.
Focus of this release: a drop-in replacement for the Sphinx LaTeX builder. No more need for a large LaTeX installation to produce professional-looking PDFs.
I'm not quite sure what you're comparing here, but I want to note that Flask is one of the slower frameworks out there on doing "hello world" benchmarks at least. Django is faster, Morepath (disclosure, I'm a developer) faster still, Pyramid's a lot faster still, and Bottle, Falcon and wheezy.web are fastest. So if you're going to do benchmarks, make sure you compare with something else than just Flask alone. Stupid hello world benchmark I use: https://github.com/faassen/welcome-bench 
This is very interesting, thank you! I've been considering what Morepath would look like in an async environment. Morepath's routing splits the database query and the rendering of the result into two separate steps, and it would be interesting to see what would happen if both steps were made asynchronous -- it could move on to rendering more responses while waiting for an answer from the database. I'm not sure whether that *would* make a difference in practice, though! So if we get serious about that I'll definitely be digging through your sources for inspiration if nothing else. :) 
Well, yes, however much like Python 2's deprecation status, things can end up sticking around for a hilarious amount of time if it wasn't done right the first time around, as people will to take their sweet time to migrate away from poorly thought out conventions. Basically, if Flask had declared `flask.ext` as a proper namespace module in the first place (also if they got everyone to stick with `setuptools`) and got extension devs to build their modules correctly, `flask.ext` would be _the_ useful namespace where all extensions live, and none of this deprecating business would need happening. Not that I am a fan of how flask does extensions at all, but honestly building extensible systems is hard work and a lot of planning to not miss the mark. Realistically there is one shot to do this right before it requires support forever (or one can just throw all the users off the cliff).
Unless users are explicitly silencing the warnings or just ignoring logs, then they know it's coming. Probably with 1.0 (if/when that happens) 
It's most probably a reference to the anime [KyÅkai no Kanata](http://myanimelist.net/anime/18153/Kyoukai_no_Kanata).
Exactly, this is the conclusion I came to myself when investigating this ;-) However, since I don't really need the Elasticsearch operations to be real time, I think I'm going to go with the suggestion of a different user in this thread of writing everything to a file and have a cron job taking the file and push to Elasticsearch. By comparison, using celery+rabbitmq seems like unnecessary complexity: number 1, I'm sure it has a lot of gotchas that I'll surely fall in to, and number 2 I'd need to find a way to have an Elastcsearch machine with high availability somewhere.
You could try configparser, it lets you set up a file with various info that can easily be read into your script. I use it for scripts where I'll be adding or changing input data often...
I'll almost certainly go with `kyoukai.ext` as I feel it's cleaner, and I don't want any of the implicit magic imports (I specifically designed this library with as minimal deep magic as possible).
I believe [this](https://www.youtube.com/watch?v=sgHbC6udIqc&amp;ab_channel=NextDayVideo) will be an interesting talk for you, if not very useful. Just use Python 3 and understand representation in transfer and representation at rest. If you're sending the text somewhere, encode it to a bytestring. If you're receiving it from somewhere, decode it from a bytestring using whatever encoding it is. If it's not coming or going anywhere, leave it as a Python3 native unicode string.
&gt; It has to work on Python 2 and 3 simultaneously And that's precisely why it's perfect to compare the two languages. Unlike OP's one sided example and ridiculous FUD...
What feature did you add?
You can see the PR [#1428](https://github.com/pytest-dev/pytest/pull/1428).
This looks really interesting. Something to watch while I work, thanks!
The problem being if you want to store a password, this would be plain text. You could encrypt the string, but one way or another the key will be visible. Using the system keychain, if one is available, would be good for those.
What's up with so many project names being Japanese nouns?
I understand saying inspired by flask but you use di, not singleton. much better.
Well, good on you, mate. I wonder if you've heard of [redditp](http://redditp.com/). Just add any subreddit (e.g. [/r/kittens](http://redditp.com/r/kittens/)) and you are good to go. Sadly doesnt work with multis.
I'm not too familiar with py.test, what is the pro/con of this vs. the native UnitTest testing package?
Not sure if that's desirable.
Ohh you're a gem. I so need this for my website backend.
Your README uses `kyokai`, while docs use `kyoukai`. By the module and import I see that the docs version is correct, but the README is misleading. Upon further inspection (a search :P) I see you used the same import in [sessionhandler.py](https://github.com/SunDwarf/Kyoukai/blob/master/kyoukai/ext/sessions/sessionhandler.py#L11), as well as some docstrings and .rst files and whatnot. Is this intentional?
I changed the package name to ``Kyoukai`` a while ago, and forgot to change the README, I guess. That sessionhandler file is outdated and I've forgotten to delete it.
Removal of "support code for Python 3 version &lt; 3.3" is probably not an issue unless some project uses a tool like Tox that still tries to run on 3.2. I don't usually have 3.2 on any platform I use to run tests so I can't confirm.
I use it for its reduced boilerplate, making the time to test a lot lower. I also really like its failure reporting, making it easy to show how an assertion was violated. I will say that set up and tear down is more intuitive (for me) in unittest, but the decorators provided for this purpose in pytest are also really powerful. 
As I mentioned in the article, I discovered these edge cases while working on Batavia, a Python 3 bytecode interpreter implementation in Javascript. I was keen to find out whether my own surprise at them was common, so I put together the quiz, and asked other attendees at the PyConAU sprints to do it. I thought it was remarkable that among a group of people who have above-average knowledge of Python, the average mark on the quiz was below 50%. A number of people encouraged me to write up the quiz in an article. My first draft only included the questions about bools, because I thought those were the more interesting ones. However, a friend who reviewed that draft encouraged me to cover all the questions in the quiz, so I expanded it to do so. 
unrelated to the thread but how does your project, morepath, compared against twisted.web (which does async under the hood if you use it properly)
BTW, there's another post that deals with the quiz here: https://www.reddit.com/r/learnpython/comments/4y5bh1/can_someone_explain_why_true_1_0_but_true_2_true/ This comment in particular explains what's going on very well: https://www.reddit.com/r/learnpython/comments/4y5bh1/can_someone_explain_why_true_1_0_but_true_2_true/d6l2679
What is this, PHP?
There is certainly feature overlap with the native unittest, however the two are not mutually exclusive. Having used the native unittest module quite a bit, pytest really shines when you start getting lots of tests (say &gt; 50) and you start to realize that it's silly to define the same setups and teardowns over and over in each class. For example, imagine a case where your setup and teardown create and destroy information in a database. Do you want to put this in all your setup and teardowns? There are workarounds, but they all seem clumsy and they seem to be only practical for pretty small projects.
I'm glad that at least the built-in functions are well documented... Would be great to have all the docs so well documented, unfortunately it's not like that..
Full disclosure, /u/RBazz and myself are the project devs, and we're happy to answer any questions you may have about the project, or even just python types in general.
I hoped for Kara no Kyoukai reference.
I'm kind of surprised that there's no mention of tornado anywhere in this thread. :(
The repository is empty. This is a brilliant comment on the bloated state of game production today. Or, you forgot to add the code.
This is true, but if it's a script you're just going to run locally is it still so important?
oh okay i will definitely check it out.. Thanks :)
While Kyoukai is an interesting name, Tokkuri might be a good name too. 
Well, few points out of my head: - It can greatly simplify the integration testing between modules developed by different members of your team. (e.g. it will start complaining if suddenly something unexpected is being passed or returned) You can easily turn it off for production for performance reasons. - You can wrap third party tools with it to know immediately if some of them are misbehaving. (Can be really useful if you are using a lot of other open sourced packages from pip) - You are exposing or consuming some sort of API and need to be certain, that the data received/sent is of required type. And as you can see, validating data from external sources can only be done in runtime. Also, I am not planning to support 2.7 at all. If anyone wants, they can fork it and add a support for 2.7 themselves. 3.3 and 3.4 are not currently supported but if there is enough interest, we might add it in the upcoming releases. There is really nothing conceptual preventing us from doing so. The reason for incompatibility, at the moment, is that some of new 3.5 syntax features were used in the development. Also, this module is rigorously tested against Linux and Windows with a decent test coverage of 91%. This is a complicated process and every added feature requires a lot of testing. We would really like you to try it out yourself and tell us what you think or if you have found any bugs. We want it to be as stable as possible. Finally, few points about the module: - It has a pretty much full support for TypeVar (including covariant and contravariant type variables.) - It supports most of Callables - It does support tuples (including unbound) and lists. However, container types are currently not very performant. We will address this in the next releases. What is expected of the library in the upcoming releases? - Full support of user defined and inbuilt Generics - Lazy evaluation: a) evaluating container types only when its members are accessed b) evaluating types which are passed as string Thanks!
Yep, it raises an error which you can then catch, log, do whatever with. In a production environment you would log and continue, but you could also just have the program exit. With this decorator, type hints are no longer just *hints*, but rather actual type checks that are *enforced* at runtime by raising exceptions if mis-typed.
Now I finally understand it all I think, thanks! :)
That's up to you, with the added caveat of at least suggesting to be sure of the file permissions to make it only your user that can read them. I'd still defer in favor of security that I don't have to think too much about explicitly
Isn't this different from aiohttp? It's like saying "I could have used requests, but instead I used Flask". Making requests != handling requests.
I am sorry, I kind of forgot about custom __subclasshook__ because type checking is currently done invariantly unless it is a TypeVar. Our support for TypeVar includes both invariance and contravariance, though. However, I have forgotten to include a check for custom subclass hook as it was a rare case for us. I think we should have a switch to change global invariant mode to covariant (which I believe is used by issubclass). Also, do you think it makes sense to check for custom subclass hook only in covariant cases? Because otherwise I do not know how it should work for all the cases. . . Thanks for the point. I should file an issue.
Pyprocessing, I think it's called? It's processing for python.
Cool, didn't know.
Upvote for effort... I like your desire to share with everyone, but something like a blog post, Web page, or even a github.com gist would lend to better presentation, more attention, and more karma of course! 
thanks, well this is what brought me to giving this small program a try. i wanted to be able to have more than one sub. thanks for not hating :)
That's not even pedantic. That's just saying "I don't think that word means what you think it means."
Ah, my apologies, I was mentally referring to the static aspect of function declarations, but I messed up the definitions... 
Hey, it's your example. I'm not convinced it's a worse approach as you increase the number of arguments. I like this approach when I see it in the wild - it's very clean: https://github.com/jonathanslenders/pymux/blob/master/pymux/process.py It's not something that's normally necessary on every argument, either.
Like I said before, I'm all *for* stricter typing. And yes, larger, older projects need it more. I just think that there needs to be a strong bias towards the kind of stricter typing that yields the most gains (in terms of dangerous type-related bugs quashed) with the least characters spent, in the most readable way. That's a three way trade off. It's *very* easy to spend thousands of extra characters on static typing and not catch a single relevant bug but cause extra eyestrain for everybody reading the code. It's called Java :) This isn't directly a criticism of you (I'm pretty skeptical of type hinting for this reason alone), but your project does, if used as intended, look to be exacerbating the issue.
not any more, fixed it!
To an extent it's definitely a matter of personal preference, and now that we have a dedicated method of type hinting, we figured we could use that instead of (or as well as) manual assert statements.
fixed it so no you can run it as a normal user and will work on any os!
I absolutely agree. I definitely would not want any codebase to necessarily have these type hints used everywhere, and I especially would not want to do type checking for all functions. Instead, I (personally) mainly use this type hinting (and checking) as a way to either help others grok my code, or as a way to help reduce error in important functions. Everything in moderation, and python typing doubly so.
An outstanding issue that we have in the works currently is to have these decorators applied globally to all functions so that way you don't have to add a decorator around *every* function. It's up for debate whether or not that sort of feature is a "good" feature, but we have been trying to minimize cruft in application.
No. Both type hinting &amp; their enforcement lend themselves to gradual use along side assertions and unit-testing. Using it sparingly where correctness is critical and test coverage isn't sufficient makes a ton of sense. And sure - you should also improve test coverage - but this will be much faster to implement and may catch problems that arise in scenarios that are difficult to test (run out of disk space for example).
Or Flasynk
The main thing for me which I don't see posted is that the barrier to entry is near zero. It's the same reason I love python. To get started takes almost *nothing* but you can make it as complex as you want. def test_somestuff(): assert(thing() == True) then $ py.test
&gt; you start to realize that it's silly to define the same setups and teardowns over and over in each class. Isn't this the power of inheritance, though? You can define some sort of base class (that itself derives from `unittest.TestCase`) to handle common stuff. I used pytest for a while, but ended up preferring the `unittest` way of doing things. Mainly I found it more natural to use classes for organizing tests (which of course you can still do with pytest if you want, it's just not the way that is most documented). The "fixture" concept also seemed a little too magical to me whereas I can immediately grok `setUp` and `tearDown` methods. I still use pytest as the test runner so I can continue to take advantage of test discovery and some plugins, but I am generally finding it easier to use `unittest` when it actually comes down to the unit tests.
late to the party on this one:- import random sims = 10000 s1, s2 = 0., 0. for i in range(sims): doors = [ 1, 2, 3 ] correct = random.choice(doors) selection = random.choice(doors) # reveal a door opened = correct while opened in { correct, selection }: opened = random.choice(doors) doors.remove(opened) # strategy 1 - don't change if correct == selection: s1 += 1.0 #strategy 2 - swap to a remaining one doors.remove(selection) selection = doors[0] if correct == selection: s2 += 1.0 print 'no change',s1 / sims print 'change',s2 / sims the way to understand probabilities, is simply jot down all the possible outcomes at each point in some event. In the initial one, you have a one in three chance of selecting the correct door. 1 - Car, 2 - Goat, 3 - Goat 1 - Goat, 2 - Car, 3 - Goat 1 - Goat, 2 - Goat, 3 - Car Strategy one comes down to pure chance. Second time around, one of the options is eliminated Using the above table to visualise. In game outcome 1:- * you choose 2. 3 is eliminated, swapping to 1 means you win (its the car) * you choose 3. 2 is eliminated, swapping to 1 means you win the car * you choose 1. 2 is eliminated, you swap to 3, you lose. But you can see that in the 3 outcomes, you win in 2/3 games.
Real men run as root. If you're not a real man you probably can't handle these girls anyway! j/k Don't run as root (we don't want you stealing our girls. No, wait. I mean it's not safe.)
I did not attend, I found those slides on twitter.
This is a part of a tutorial series: http://www.petercollingridge.co.uk/pygame-physics-simulation. The others in the series have worked well for me, too. Are there any other good physics engines for Python?
If your objective is to learn Python, carry on! And check out one of the books in the sidebar (Al Sweigert's Automate the Boring Stuff with Python). He has a tutorial for this. If you just want to get the job done use a macro program like [AutoHotkey](https://autohotkey.com/)
Yeah, I messed up. I was thinking of the wrong thing when I wrote the title, it's not static, it's a runtime type-checker, not static at all.
One indexing makes it dead in the water for me. In addition I really loathe domain specific languages since eventually they get patched in with general programming language features that end up being rather poor. See R. If it wasn't for its community, no one would be using R. It solved a problem for the time, but now is burdened with it's poor syntax and the difficulty of writing something more complex than a function is really difficult. Programming languages should be left to computer scientists (it's a really tough thing to do well) and I strongly believe statisticians should just add statistics to existing languages instead of creating new ones. I'd rather see Scala being patched to have a stronger stats package than Julia being developed. Then you get spark integration for free. 
nice work! :)
Unless you're using only one-indexing, the mental switch between zero- and one-indexing is a pain. That is, if you're using Julia and Python, it's an unnecessary hurdle. &gt; domain specific languages since eventually they get patched in with general programming language features One funny thing about Julia is that when it started, they used the "Matlab" excuse for a bunch of things (including one-indexing). A couple of years later, most people I know (of) that used Matlab moved to Python (or Python mixed with some Matlab). &gt; If it wasn't for its community, no one would be using R. And this is how I see Julia now. If it grows enough, I might be forced to use it but won't really support it. 
It actually isn't a DSL....just being marketed as one because technical computing is its initial focus market. Its type, dispatch, module system is fully general. Do you see anything specifically DSL about it, or are you referring to the general buzz? There is even a django like web framework being written (genie.jl)
They were asking about your use of static in your comment, where you spoke correctly. Mypy is static and yours is runtime.
pytest also supports classic style setup/teardown: http://doc.pytest.org/en/latest/xunit_setup.html http://pythontesting.net/framework/pytest/pytest-xunit-style-fixtures/
pydoc is an autogenerator for documentation from source code. I supposed it could work. But given there are repositories for documentation it seems the wrong way to go about it. I was expecting there to be a relatively standard pip package for this.
Yes. You can have speed if you want it; but speed is not why you choose Python in the first place. Which is fine for almost every project you'll ever tackle.
Thanks ;) 
How do you Plan on getting the necessary Info about the live music? I want to do something similar and havent yet found out How to react to specific frequency Ranges for example.
Unless you literally mean me in which case... not really.
&gt; I've been told the original incentive for adding single dispatch to the standard library was a more elegant reimplementation of `pprint` (that never happened). This makes plenty of sense, since `pprint` is basically just another Python-y way to serialize objects.
I think this is what i was looking for thanks so much!
Why not just use flask + tornado?
Raspberry pi, rented VM in the Czech Republic ($4/Mo.), Intel NUC.
Nicely written. I also like [http://simeonfranklin.com/blog/2012/jul/1/python-decorators-in-12-steps/](http://simeonfranklin.com/blog/2012/jul/1/python-decorators-in-12-steps/) It explains everything: scope, lifetime, namespace, closures in a very understandable way as one user says: &gt;Reading this article is like eating a mushroom by Mario.
fedora 24 for testing and centos7 for production
Consider docker/beanstalk
Yet the mypy type hint syntax is an official one
Your options are: 1. Run locally using cron and make sure you have your laptop on when it needs to run. 2. Rent a VM and run as a cron script on that. 3. Run as a scheduled AWS Lambda. 4. Host and run as a scheduled task on https://www.pythonanywhere.com
Thanks, what's your thoughts on needing login/passwords for scripts using selenium - running on the external systems? 
Yeah I'm having some issues with launchd - I need to get to the bottom of it but this prompted this thought. (It's some sort of permissions issue I think) 
Off topic, but how well has dask worked for you? For me, it works really well in a handful of cases and in the other majority of cases I feel like I have to hack my workflow around what dask is capable of. So either I don't understand how to use dask properly, or dask isn't suited to the kind of data I'm analysing. I'm just interested to hear from other people who have tried it to compare experiences. 
This was the next python thing I was going to learn. Great timing! Thanks for posting.
Neat! How does Nutika compare to something like Numba? What about something like Cython?
Go to /r/pygame or at least to /r/learnpython And next time add 4 spaces before **all lines of code** to correctly format code on reddit. Or use [pastebin.com](http://pastebin.com/) and don't forget to set "Syntax Highlighting: Python". --- You have mess in code - it could be in this order: imports, constants, classes, functions, rest (starting at `pygame,init()`) See [simple template](https://github.com/furas/my-python-codes/blob/master/pygame/__template__/0__empty__.py) and [other templates](https://github.com/furas/my-python-codes/tree/master/pygame/__template__) `draw.rect()` is used to draw on screen. If you need rectangle to keep position and check collisions then use [pygame.Rect()](http://www.pygame.org/docs/ref/rect.html) 
Can you share a link to the vm host in Czech Republic? 
Another possible option [barnum] (https://github.com/chris1610/barnum-proj)
Sure: http://www.finalhosting.cz/cz/27/server/detail/64 You can write them an email in English.
A lot of people are misunderstanding that I want it to react to the music. It's more like I launch a script that behaves independently and I play a song.
It looks really nice! http://pyvideo.org/
Wow, this is actually a useful code bite. I think I will add this to my project where I am dealing with unicode issues (god I wish I were kidding but I am not...) P.S. This project is only used internally by me. Not likely to worry about "safety"
This is wonderful news. I'm happy for Will that he's able to step away from a project that dogged him, I'm happy for Paul to improve and continue the site, and I'm happy for all of us who get to continue to use and enjoy pyvideo.
Actually you are the one conflating :) class C(object): pass c1 = C() c1.field1 = 1 c1.field2 = 'works'
YAY! 
We're fortunate to have Paul Logston as part of the Python community. Thanks for taking the reins, Paul!
it's truly a shame
The old, slighly less insane type hints, yes.
Of course there is! I have become an OpenCV master and got a job at Facebook, just by looking at that one image! /end sarcasm mode
Thanks, shall try it out
Assuming storing passwords in the script is unavoidable (i.e. you can't use a refresh-able API key etc), then if you're running on something like AWS/DO/Heroku or Lambda then its mostly safe if you take the basic precautions and don't do something really stupid. Never used pythonanywhere, so can't speak to that.
Usually the debugger "just works" when you launch your program using the "bug" launcher icon. Do this not work for you?
Not to be snarky, but can you ask your friends? Seems like that may be the best place to find it. 
automating the distribution of rows to existing and newly created spreadsheets.
I think you'd be better of making a post over at r/forhire. 
The return statement close the function so the print is not part of the function and must have no indentation 
It's possible in some cases, since a JIT compiler can perform optimizations based on actual runtime metrics. In general cases, though, no, C++ will outperform Java. However, in the majority of cases, Java is certainly fast enough.
A ODROID-C2, headless. aarch64 is still a new platform with some issues, but to my own surprise I installed pandas and other libs etc., moved my 24/7 data crunching over to the C2 and... It just runs! :-)
It would change the language's semantics if you started storing objects by value instead of by reference. A JIT can make optimizations like that to local variables sometimes, but it can't make sweeping changes like that.
No, it would not change the language's semantics. The JIT can recognize the access pattern and make whatever optimizations it wants.
then why did you mainly argue 2 and 3 in your original post?
because I'm looking for a method that can be used with python that is efficient and ideally without too much effort.
It can, PyPy already does this with lists of a single type.
Not a single word in your original post mentions security risks, you clearly targeted speed and size as your main arguments. And since others have mentioned that your original arguments may not be valid at all, you now seem to be grasping for the security issues mentioned by /u/PM_ME_YOUR_BOTNET to justify your post. It just makes you seem weird and argumentative. But whatever, you're on a crusade and unwilling to have a meaningful discussion after all, so why even bother.....
Is that send keys in the script? 
Cool thanks for the tip
Just a cursorary glance yeilds some empty fields in you `bigtestboard.txt`. The last 15 lines don't have anything in the third column.
I think if Python matches Java's performance we'll be happy, and future research after that will probably go towards reliability or something else.
In my experience memory allocation is the main one. The JVM/GC can re-use old memory often by literally just changing a couple of pointers. C/C++ would need to reallocate, which is expensive. Of course custom written memory managers in C/C++ could also do that but I think the "competition" is about realistic code, and not about perfectly optimised code.
Could someone tell me, why did we use JIT, instead of just compile the program?
I listed to a talk by Victor Stinner recently. I think it was the PSF panel at US Pycon? He was there with Larry Hastings and and 2 others. Anyway he was quite vocal in saying that he doesn't want to see any more changes in CPython.
CPython. As far as I remember. I didn't get a clear impression from him over exactly what he meant by 'cpython'
/r/learnpython
You did not mention this with one single word in your original post. It obviously wasn't an important point for you, you didn't even think about it when you started posting this.
&gt; can be faster under the right conditions. When the moon is full and ... ;)
Java has primitive types that are not heap allocated like reference types.
Unlikekly. Having dynamic typing makes it hard to generate high performance code because of type checking. That's why V8 and SpiderMonkey still can't beat HotSpot.
Because then you would have to distribute programs on all architectures instead of just distributing the source code.
Agree (at least about Python). Don't know anything about how V8 works but sounds credible. :-)
Second to Pythonanywhere. With a free account you can run a couple basic scripts pretty frequently. Their pricing structure is super fluid
Not if you compile to a bytecode and then use a virtual machine. See: Java.
I run scientific simulations, i.e. large numbers of small, interdependent function calls. But even though the individual tasks are tiny, the sum of their arguments and results are way bigger than my memory (I have 100 Gb of memory available). Dask schedulers are a great way of defining and scheduling such tasks, and take care of serializing pending tasks and completed tasks to disk. The distributed scheduler even doles out tasks to our small compute cluster. In comparison to other multiprocessing libraries, I find Dask very easy to use and setup, while at the same time being much more robust and scalable than, say, IPython clusters (which don't handle larger-than-memory task lists for example). 
You dug up a 11 day old post to make an argument. Turn about is fair play.
If the MyPy people developed a JIT, they'd suddenly be all for it. 
Nope, I came for a discussion, but I see now that with you there's no reasonable discussion to be had. Have fun on our crusade, I'll not bother to reply again.
I think numpy moves way too quickly to be rolled into the standard lib. Maybe one day, it will enter maintenance mode, but for now the library is too critical for a slower release cycle.
&gt; I think it was the PSF panel at US Pycon? [Maybe this video?](https://www.youtube.com/watch?v=UaNt4GD2ebs)
I get the platform independent point, but couldnt we have a problem that translate bytecode to target machine code?
" one-third of all NumPy downloads are for Python 3" -- After 8 years? Not very impressive. The other 2/3 must be for Python 2 then. Experienced developer picking up Python for the heck of it here ... IMO the Python community needs to get their act together on this 2/3 business. It's a real mess.
&gt; Python is fast enough for the kinds of things people do today with Python. Mostly because those of us who needed more performance gave up on it long ago.
I get great performance generating GPU expression graphs in pure Python. Hard to know, but probably comparable to C++.
If you can't find anything on reddit, you might want to check out a website such as freelancer.com. Disclosure: I work there.
Take hasattr as an example. How do you know if an object has an attribute with a name if you compiled it? Of course you could compile in a way that kept links to names as strings. But if you keep fixing every problem you eventually get to an interpreted language ;)
Agreed - "Python's fast enough for the kinds of things people do with Python" is a self-fulfilling prophecy. If you need more performance than Python can offer, you have to use a different language - and suddenly you are no longer doing "the kinds of things people do with Python". I am beginning to realize that I am in this situation. Python is too slow for the kind of programs I want to write - it is also far too difficult to build into self-contained binaries. If you have given up on Python due to poor performance, I am interested to know what language you tend to use now? Is there a language comparable to Python, but faster? Or have you moved to a very different (e.g. statically typed) language?
A few reasons. First, the historical ones: Originally, Python was used to write fairly simple scripts, where performance wasn't a concern, but portability was. It's only in the last 10 years or so that high-performance applications are being written in Python, so for most of its life, performance wasn't a big issue. There are some technical challenges to compiling Python code natively, due to its highly dynamic nature. Take, for example, this simple C code: int n = 2; n += 2; That's fairly easy to compile. The C compiler will know that `n` is an `int`, and can easily add two to it and store that value somewhere. It's only a few CPU instructions! Consider the same Python code: n = 2 n += 2 Thanks to its dynamic typing, a hypothetical Python compiler wouldn't really know before runtime what `n` is, so it can't easily compile `n += 2`. It first has to lookup `n`'s implementation of `__iadd__`, then `__add__` (if `__iadd__` isn't present). Maybe neither of those methods is present, in which case `__getattr__` has to be called, and so on. Point is, since `n` could be any type at runtime, the appropriate methods, even for this simple bit of code, have to be looked up at runtime. In essence, any Python program would ultimately be backed by a fairly complicated runtime library anyway. Long story short, it's hard to say how much faster such an implementation would be; there may not be huge performance boosts for a natively-compiled Python. (There are some languages that are as dynamic as Python *and* are compiled, such as Objective-C. Objective-C is still fairly fast, but it also has a somewhat complex runtime library.) And that's just a simple bit of code. The presence of constructs like `eval()` in Python essentially mean that any natively-compiled Python program (or the hypothetical Python runtime library) would essentially have to contain an entire Python interpreter anyway.
Using lists of tuples to load into pandas is something I use a lot. Fixed size, a few different data types that make numpy the wrong tool.
I mean the same issues apply to compiling in general. Which is what we are discussing currently. 
Thank you for the update!
Not to relitigate the 2/3 issue, but from personal experience the main problem is bureaucratic inertia in python-using organizations. At one of the biggest corporations on the planet (I'll leave them nameless), I'm stuck using 2.7.3. Not 2.7.12, 2.7.3. It's not because they have anything against 3.X, it's just that most organizations suck at doing big changes without an emergency to provoke it. 
Unfortunately, I don't have any. I was talking about what is theoretically possible. Here are some papers from some quick googling: http://ieeexplore.ieee.org/document/1213259/ http://dl.acm.org/citation.cfm?id=1075386 Apparently, one term for this is "dynamic optimizations".
Only in very specific cases. In general you cannot, because identity is rarely opaque as it is for these specific types. In particular, this requires the types to be provably immutable, which is extremely difficult to show in Python.
The higher a language you go the slower it is. [MenuetOS](http://www.menuetos.net/) is written in assembly and it *flies*. However it comes with all of the downsides of being assembly. What they buy you is easy of use and reduced development time.
dSpace just recently updated to 2.7 from 2.5. Their solution to 3.x is to say "Eh, screw you" and dropping straight Python libraries and making you use the C# bridge
Perhaps fork the parts of numpy that haven't been touched in ages, like arrays.
You can actually statically compile Python code; [see Nuitka](http://nuitka.net/). The problem is that it doesn't buy you any *performance*. A JIT is the only method we know of to reliably make dynamically typed code fast.
Just a small suggestion from my end. I really think that the UI can still be made prettier. This would give a good feel before starting to learn the actual material. And secondly, I think it would be nice if we can establish some sort of (star/score) based rating to each video, which would be very helpful for others who are yet to watch. For instance, [Ned Batchelder]'s talks are pretty awesome. This doesn't mean that others' aren't. I think that we should quantify each talk's quality in terms of "some score function"
I have to write Python 2.6 at work because that's what cent 6 ships with. But I only have to wait until 2020 until I can write python 2.7. :/
Luckily I get to write for 2.7 at work /s We package everything in venvs so I'm sure we'll be using 2.7 past 2020 or until we can't hire anyone who will write for 2.7
&gt; Nuitka doesn't buy you any performance. In my experience it's around a 2x speedup - still not anywhere near annotated Cython, but certainly worth doing in some cases.
Your comparison with Cython suggests to me that you might be thinking of the similarly-named [Numba](http://numba.pydata.org/). If you have actually got 2x performance with *Nuitka* on normal code, I'd be quite interested to hear about it.
I think /r/learnpython is best for this type of question as this subreddit is more about Python related news and releases. I also want to point out that formatting this question better is going to lead to people wanting to help you more.
What do you think of pyfora , it allows you to run normal python code (with some immutability restrictions ) in distributed clusters , with no additional changes to the language . http://pyfora.readthedocs.io/en/stable/tutorials/intro.html 
Nope, not Numba (I keep meaning to try it, but...) I spent a while exploring Nuitka (~0.4 I think) to create native binaries - focussing on the windows-end-user distribution problem, not performance per se. Testing it on a work script that does a lot of iteration over numbers, simple math, and dictionary lookups - no numerical libraries - it ran in around four instead of tenish minutes. So it's not at all a firm scientific result, but does leave me thinking the developer's claims are reasonable. More importantly, it's a no-code-changes speedup on 3.4, and doesn't focus on numerical applications :)
Ah, thanks. Sadly that benchmark sounds like a best case for Nuitka, since its main speed-up comes from removing interpretation overhead which is especially high in those examples. Real code tends to have a higher work:overhead ratio, so the speed improvements are a lot more modest. 
Yep. That's why I was focussing on the 'here's a windows binary' part, though the ratio might get better in future releases as Nuitka gets smarter.
SchÃ¶nfinkelisation EDIT: no, really, that's the potentially more accurate name for currying However, what's in that example is currying under the hood, with some magic to make the final result be an integer instead of a function (depending on the formalism we're talking about, they may be equivalent, but they also may not be).
I would use PySide inside of Maya vs. using its maya.cmds UI commands. you should check out my Maya Python workshop on [cgcircuit.com] (https://www.cgcircuit.com/workshops/learn-python-inside-maya/v/1) otherwise post your questions about python inside maya here: [Python_inside_Maya](https://groups.google.com/forum/#!forum/python_inside_maya) that's the BEST place for maya python questions.
why are you being downvoted.. There are people that can read c code and tell you how different compiler flags from different compilers will compile to different assembly.. It is not reasonable for me to beat a compiler but fine for someone of that level of experience/knowledge.
&gt; It may one day even be possible to have Python be faster than C++ since JITs can make optimizations based on runtime statistics rather than compile-time guesses. Profile-guided optimization is essentially an ahead-of-time runtime-statistics optimizer. Train it well and it will yield better than JIT performance.
It's fast enough for the kinds of things people do with python, because python's not fast enough for people to do other things with it.
Yet another recommendation for Arrow. A library that just throws away types and gives you valid output for invalid input. 
I could imagine you could do some clever stuff with memory allocation to allow that to work without changing semantics (have pointers that are accessed close together point to spaces in memory close together to keep the memory hot), but you probably couldn't do that in the tiny amount of time JIT compilers have to actually run. 
well someone can clearly say: it's easier to switch to IPv6 than switching to Py3. Both are clearly chicken and eggs problem: to switch to IPv6/Py3 we need more service/library to switch, but in order for them to switch we need more service/library already using IPv6/Py3. People won't just "shift" to Py3.
Currying (invented by Schonfinkel, not Curry) is just applying functions to not enough arguments. In lambda calculus it's a meaningless concept, any expression without free variables will still be a function, and so there are never "enough" arguments. When you get onto concepts like combinators where the objects can take more than one parameter, currying starts to happen. All it really means is that although some variables are bound, not all are, so there's not a lot of point in evaluating the function application yet. What the stackoverflow post is asking about is a thing where you can apply a function to one data value (integer) and get a result, but you can also apply it to more data values and still get results. The question is, how does the function know when it has been applied to enough arguments to give a result? The answer is it can't, so the result must be some sort of object which is both a data value and a function of one argument returning that same sort of thing. Languages like Python / Ruby / Groovy can do this, though it kind of breaks our notion of what numbers are hence is not really advisable. In combinator calculus there aren't data values anyway, just function / combinator objects, so the question is meaningless in the context in which Schonfinkel invented currying. In lambda calculus you can create functions which act like integers, but the traditional construction doesn't act like that. It might be possible to construct such a thing, but there's not a name for it. So, I wouldn't call this currying, I'd just call it a programming language trick, of dubious value.
Trite
&gt; Many interesting things in world of "big data" are happening on JVM, e.g. Spark And yet, Spark 2.0's biggest feature is the start of a shift to their C++ based runtime, Tungsten: http://www.kdnuggets.com/2016/05/spark-tungsten-burns-brighter.html &gt; Yet python lacks a good story for expanding beyond single machine data sets (yeah, I know about pyspark). Look at dask: http://dask.readthedocs.org
The module is usually sufficient namespace for the free-standing function. Being a class staticmethod implies some sort of specificness to the users of that class. But if it's a honest utility function that just happened to spring out of that class, there's no reason to maintain such implications.
Functions like these should never ever be needed, it is just sign that the developer has no idea what the variable contains, chances are that such code will produce weird results from time to time and most likely will also have security vulnerabilities. Of course you can do this in python 3, but it is harder to do. Django has that code, because was written in python 2, then converted to also work with 3. 
I'm talking more on the order of dead code elimination, loop invariant hoisting, that kinds of static analysis. An example: def f(val): x = ((val * val) + val) / 4 y = val * val return x Compiles down to: 2 0 LOAD_FAST 0 (val) 3 LOAD_FAST 0 (val) 6 BINARY_MULTIPLY 7 LOAD_FAST 0 (val) 10 BINARY_ADD 11 LOAD_CONST 1 (4) 14 BINARY_DIVIDE 15 STORE_FAST 1 (x) 3 18 LOAD_FAST 0 (val) 21 LOAD_FAST 0 (val) 24 BINARY_MULTIPLY 25 STORE_FAST 2 (y) 4 28 LOAD_FAST 1 (x) 31 RETURN_VALUE When anything from line 3 shouldn't be included at all (it does nothing).
I find it very cool when big companies open source things. I guess this fosters technological development and also builds trust. By the way apparently Linux turns 25 tomorrow. 
This is off topic but I recommend you take a look at Elixir, its syntax is similar to Ruby but its performance is similar to Haskell.
&gt; C compiler produces code that probably beats any human coding in a assembly This is such a common myth that has been debunked so many times, it's not even funny any more. Compiler produced asm is horrible compared to hand-crafted asm. Compiler produced asm merely is good enough that in general you shouldn't bother writing asm by hand if you can just write it in C instead. But even then there are plenty of situations where hand-crafted asm blows compiler produced asm out of the water.
This is where the problem is: "if player_2_cards_value or dealer_2_cards_value == 8:" Needs to be: if player_2_cards_value ==8 or dealer_2_cards_value == 8: Otherwise it is evaluated as: if player_2_cards_value is True or dealer_2_cards_value == 8: So you'll always enter the block below the if statement if player_2_cards_value has any non empty value (as it will then be "True") Sorry for poor description, on phone + lazy
I have to go where the libraries and support are so it's all C++ or C# for me. Not sure of any credible alternatives to Python that keep most of the benefits. 
Caveat: I like Elixir but after working with it for a half year, I can say its performance is limited to having very good concurrency by default, and providing reams of libraries to help you handle distributed state, and recovering gracefully in the face of errors. Elixir is not especially fast as a calculator. It's not especially fast at pulling data from disk. It's not especially fast at string manipulation (though it's a lot better than Erlang in that respect). It is however very good at parallelising non-trivial algorithms of the sort you'd find in anyones 'business logic'. 
3x has breaking changes, and it has taken a while to accumulate enough additions to the standard lib that it's worth it to switch. There is no killer app for 3x, it's the slow accretion of age. Performance though is still worse than 2.7, so its a simple trade off between dev time and run time.
Thanks for the idea ! I have done this now just got to host it :D 
Awesome ! I will Direct Message you lately 
Try PDFminer
Caveat: Python is not very good at any of these ðŸ˜‰
It might be the same as JIT performance assuming your profiled runs are representative of your current run. Why should there be any difference?
ftfy saved the day when importing shitty legacy data.
Oh yeah. My fault. I was confused by other thread. I mean compiling a statically typed language is simpler. BTW GCC has a java compiler to machine code many years now. gcj I recall it is named.
JITs don't do whole program optimization very well, and they inevitably take the runtime overhead hit of having to trace and translate this stuff. PGO doesn't.
&gt; but after you invest the time â€“ and it does take time â€“ to learn the key combinations, you will speed up your overall workflow! Citation needed. I've seen studies that show mousers are faster, but keyboard junkies THINK they're faster. On another note: why didn't you write a script to set up VIM and then spend the article showing what you end up with? And please compare it against something actually GOOD like PyCharm instead of Sublime.
This post is a train wreck. 
Sorry, I'm not particularly experienced with JavaScript. The decompression routine mentioned above was probably comparable to your one of micro-benchmarks (hence I could quickly re-implement it in multiple languages), and was written quite naively. There is nothing particularly fast about my JavaScript code (the Duktape JavaScript interpreter took ~1000 seconds to run it) - all of the speed comes from the V8 JavaScript implementation. The V8 JIT's performance is *just that good*.
Wait, really? Like clang or gcc for C++?
&gt; I've seen studies that show mousers are faster, but keyboard junkies THINK they're faster. Not to be that guy, I just genuinely would like to read the study you're referring to.
How much are we being held back by ancient tools?
No. Julia can store immutable complex objects on the stack
http://www.asktog.com/TOI/toi06KeyboardVMouse1.html
http://twistedmatrix.com/trac/ Current code using that lib kabooms on Python 3
There's really not any tool-set that makes VIM anything close to PyCharm, and if their is, you'll burn hours and hours trying to find it, set it up, get frustrated, rinse and repeat, until you get maybe 85% of the way there for your particular workflow. Spacemacs comes closer and costs a lot less in terms of hours, but it's not there, either.
this definitely isn't the first time, you posted this here two weeks ago.
Not really an answer to your question, but I think that TikZ is quite programmable. For instance, not sure what you mean by "arrays", but TikZ has both matrices (i.e. arrays of the canvas you're drawing on) and lists (one-dimensional structure on which the "foreach" statement iteratesâ€¦). Here's an example, straight out of the manual (I've got a pretty old version at hand, but that shouldn't matter): \begin{tikzpicture} \foreach \x in {1,...,4} \foreach \y in {1,...,4} { \fill[red!50] (\x,\y) ellipse (3pt and 6pt); \ifnum \x&lt;\y \breakforeach \fi } \end{tikzpicture}
Yes, gcc features this option. It's called profile-guided optimization.
I use visual studio code and its pretty good
??
&gt; Functions like these should never ever be needed, it is just sign that the developer has no idea what the variable contains, chances are that such code will produce weird results from time to time and most likely will also have security vulnerabilities. You must be new to dynamically typed languages. &gt; Django has that code, because was written in python 2, then converted to also work with 3. And water is wet. Next in our series of boring revelations - the precise difference between unicode handling in Python 2 and Python 3: if six.PY3: if isinstance(s, bytes): s = six.text_type(s, encoding, errors) else: s = six.text_type(s) elif hasattr(s, '__unicode__'): s = six.text_type(s) else: s = six.text_type(bytes(s), encoding, errors) 
Thanks. I didn't know that one.
Looked at Cython yet? http://shop.oreilly.com/product/0636920033431.do
Even in Excel the keyboard is much, much faster. &gt; It takes two seconds to decide upon which special-function key to press. Deciding among abstract symbols is a high-level cognitive function. And at that point I would say that the user didn't know the function key to do a particular task. So yes, a mouse *is* faster. But for often repeated control tasks you get those committed to muscle memory. You should be able to press Alt-D-S faster than it takes to even put your hand on the mouse to select "Data &gt;Sort". &gt; They have not had to set their task aside to **think about or remember abstract symbols.** I've seen this same argument when people try to tell me driving a manual transmission takes 'effort'. It's not, it's muscle memory. It's up there with trying to remember to breathe. Edit: Remember this study was commissioned at a time where even Ctrl-C/X/V weren't common place. Keyboarding still wasn't taught in schools and "WPM" was something people actually put on their resumes. Case in point for "Keyboards are faster" are FPS where timing does matter.
You know PyCharm can automatically upload files on save over SSH... no need to do anything over a remote terminal.
&gt; When anything from line 3 shouldn't be included at all (it does nothing). Only if you can guarantee that `val` is a type without overloaded multiplication.
it's cool that you publish this program :) But isn't, for example, absible(https://www.ansible.com) doing the same thing?
It's also still being developed
So how fat do we make the binaries? Here's a grid showing which of the common platforms these days I'd like. What about you? | FreeBSD | Linux | Mac | Windows ---|---|----|----|---- x86 | x | | | x x86-64 | x | x | x | x ARMv6 | | x | | ARMv7 | x | | | ARMv8 | | x | | And this doesn't even deal with the mess that is the actual difference between specific ARM chips. When you have a small number of platforms to target, fat binaries are fairly easy. For Apple, they basically had to target two platforms at a time (old and new). But for Python, you probably reasonably have to target ten or so, maybe more. And if you're making fat binaries, you have to figure out some way to run them. Which I could do on three of the platforms listed (just make a bash script that extracts the correct binary somewhere), but can't figure out how to bring Windows into that. So we might need a platform-specific bootstrap app, at which point we might as well just have a JIT compiler there.
Thanks for the comment. This is a great question! I'll try to explain as best as I can on why I built the program. Ansible is extremely powerful and I think that it has a steep learning curve. Once you get into Ansible, it can do the same thing as this program and go way beyond what my program is trying to do. My program is not trying to compete with the big Ansible type network automation programs. I wrote this program as a learning experience / ease of use type of program. I am hoping that any person using my program can pick it up with no problems. I feel that my program is simple to use and will not require it's users to go though a big learning curve. The goal of this program is to allow it's users automate commands as simply as possible. If you know the commands for a device you would log into and you run it those commands multiple times on many devices, just type those commands into a the script editor window once and have it run line by line. I hope this explained my thought process behind writing this program. I appreciate your comment on this post. :) **TL;DR:** I tried to make it this program simple and easy to use and I felt network automation could use a simpler tool. 
please, follow pep8 style and use markdown for docs next time
I seeâ€¦ Well, that could be done but I can only think of ugly hacks, soâ€¦
This is basically why I pay for PyCharm Professional. This and the Web Development features.
PEP-8 is on my list to do. I want to re-write this code because there is a lot of redundancies in it. I'll try and write using PEP-8 when i re-write. Thanks for the input! :)
I haven't used clang too much so you would have to check the documentation, but I do know many of the GNU and Intel compilers do have this option. 
A compromised study that is actually a marketing piece and measured the wrong thing is useless. Pure theory and even intuition are better than that. In the end, it depends on what you do. Even Apple wouldn't claim that entering characters with the mouse is better than "shortcuts".
What happened here?
Ten years ago when I was in grad school I used a package called [PyX](http://pyx.sourceforge.net/) to create some nice graphs with Python code. It lets you create some rather interesting figures that are similar enough to TikZ. I was pleasantly surprised to see that it had some new work done recently and that you can use `pip` to install it.
Looks like great stuff! 
And you can always install IdeaVIM which will give you a decent amount of vim emulation, which for me was more than enough. power users might not be satisfied with it though
Thanks! I know I have a lot of work cut out for me but I am proud that I found the courage to put this out there. I was really nervous about the input I would get.
Yep. VIM is great when you need to dump out a &lt; 500 line script and a lot of it is going to use code you have in code blocks. Even with all the addons the stuff IDEs do well feel clunky. I definitely notice I develop differently in VIM vs something like Eclipse or Pycharm. I'm not sure which is better but I feel more consistent with VIM but more confused when I'm working with a multi-day program where I have to scroll back and forth a lot.
Can you give a citation on performance? As far as I'm aware, Python 3.5 is significantly faster than Python 2.7.
Is there a way to quickly run a Python script in Visual Studio Code now, without having to edit the task file for each project?
Fabric?
Vim with jedi is slow as hell for me. Anyone else have the same issue?
Is this a question? Here is a link to the Fabric python library if that is what you wanted. http://www.fabfile.org/
Pycharm has a vim plugin. It's pretty popular and is actively being maintained.
VIM is made to minimise the movement of your fingers. For example, code navigation can be done solely with hjkl. One these techniques are mastered it enables the user to quickly and efficiently modify text. This is, of course, no substitute for intelligent auto completion, refactoring and other functionality IDE's provide.
Coming from a "scientific computing" perspective too, one of the things I think would be incredibly helpful would be for numpy (or a library on top of numpy) to start working on its own asynchronous/multithreaded routines. I quite frequently need to do several things in numpy arrays where I'm creating a new array and only reading from several others. And I need to create several of these new arrays. If numpy had a way to easily say "I want to call this, and by the way do it asynchronously and hand me a Future", the fact that all my Python code sits in a single thread would be practically irrelevant. A lot of my code would end up looking like this: x = [thing.do_async_task() for thing in stuff] for output in x: x.wait() But now I'd be able to use all 32 cores on my machine, which would be glorious.
Thanks , I'll check it out. 
Not as much as ignorance and prejudice.
Where is this feature? I can't seem to find it. 
Even if it is, val is never used again after setting the value to x. It is set to Y, but then val gets thrown out, as X has already been calculated.
https://www.gnu.org/fun/jokes/ed-msg.html
I might be wrong. The last time I checked it wasn't with 3.5
I really dont care which editor you will use since you code clean thats gud 2 me, but in my workstation i lov 2 use vim well, Im not a "chiita". It really depends of which kinda work you are doing.. 4 example, last week I was working with R programming and I decide to use an IDE because it was easier then read the math source on vim. .. so
Fine. How is your thing different to fabric?
&gt; Is it just modularization in this structure? Yes. The `__init__` file tells the Python Interpreter that a script can go into that folder and use the scripts there. For example, in **models.py**: from yourapp.views.home import home_view It's what basically denotes a folder as a collection of scripts into a module instead of individual scripts; it's why there's no init in the templates folder ... it's just a folder after all and not part of the bigger program. Obligatory /r/learnpython
Makes sense. Many thanks! 
&gt; I'm not the author of the tool, though :-) You don't work at Yelp?
How about Neovim?
&gt; Julia can store immutable complex objects Is that because they're immutable? I've heard of interning immutable strings on the stack before so I imagine its something like that; but are there any examples of storing an arbitrary mutable object on the stack (or even just a mutable one). 
+1 for PDFlib. Their API is kinda gnarly (very C-ish), but works amazingly. Been using since 2004 for both PHP and PY
Trick question. Why post in /r/python?
It's half a joke, but so far so good. Not really using any new features so I can't comment on that -- but 3.5 code seems to work just fine!
It's written in python so I posted it in /r/python. Phew, that was a hard trick question. I guess the logic behind this is the same reason why I hope /u/ilikebigsandwiches gets to have a big sandwich. I hope you enjoy your day. :)
An `__init__.py` file can be used to do certain kinds of logic, re-exporting, definitions, etc. It is just a python script, after all, but it's a special one that tells python "Hey, the folder I'm in is a package, treat it as such when doing imports and things". Without it, Python just sees it as a folder with files in it. This is not that uncommon, Rust actually uses a similar structure but named it `mod.rs` instead, which is inconvenient if you want a module named `mod`. You can also have a `__main__.py` in a folder, such as myproject/ __main__.py __init__.py a.py Then in `__main__.py`: from myproject.a import A A.run() Finally, this can be run as python -m myproject And Python will happily run the `__main__.py` in the package named `myproject`.
Hi, I have been using pyopenssl for quite some time and I think its pretty good, I was able to do everything I needed so far. Whenever I needed something I could find it in their documentation here: https://pyopenssl.readthedocs.io/en/stable/index.html . Or you can also find all kinds of examples here: http://www.programcreek.com/python/index/3765/OpenSSL.crypto . For what you needed, you can simply do something like: from OpenSSL.crypto import load_certificate, FILETYPE_PEM cert = load_certificate(FILETYPE_PEM, open('certificate.pem').read()) cert.get_issuer() cert.get_notAfter() # for expiration time cert.get_subject() ..... 
As soon as anybody heads down the old "ditch the mouse" bunny trail, I know their tinfoil hat is on too tight.
..&gt;OMG VIM kiddies get over it. It's 2016 coding in VIM is not faster than in IDE and it definitely does not make you professional... Edit: It's 2016, coding in VIM (for me) is not faster... ---- Personally.. ..2% of the time I sometimes need the remote debugger of pycharm 90% of the time I use my highly personal pet vim environment 8% of the other time I can't remember cause I was hung over but it was probably something involving a keyboard
evil-mode. But we really don't have to get into this. Vim, Emacs, or whatever IDE or gui editor people like are all perfectly capable as long as you're happy with it and know its limitations. Edit: In addition to personal preferences, all have strengths and weaknesses for different situations. I use Emacs, Vim, and Atom, (in order of most to least usage) all set up with very similar keyboard setups. Sometimes, one can do what the others can't, or I'm in a different mood. The editor wars are pretty pointless, someone will always find ways to point out strengths in their preferred editor and weaknesses in others.
A bit redundant since this is almost exactly how the [scipy documentation](http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) looks.
I will never understand how can someone give up the power of IDE.
change your last line to c = b * 0.07 
Its useful for someone who wants to learn it by example fast and its based on the documentation but more readable and in one page
Thanks! Let me look into this. :)
oh my god really? [e] oh Pro only.
While PyOpenSSL is good, it is being slowly retired now in favour of [cryptography](https://cryptography.io) and its [x509 library](https://cryptography.io/en/latest/x509/). The equivalent of your above code in cryptography is: from cryptography import x509 from cryptography.hazmat.backends import default_backend cert = x509.load_pem_x509_certificate(open('certificate.pem').read(), default_backend()) cert.issuer cert.not_valid_after cert.subject ... Cryptography has wider support for formats and implementations, which gives you the opportunity to do some altogether more interesting stuff than PyOpenSSL in most cases. 
You're my office mate, Chris, aren't you? While I respect your opinion, PyCharm is truly a better option for me. https://www.jetbrains.com/pycharm/
Why link to a PEP that's 10 years old? I think that was the original proposal for [memoryview](https://docs.python.org/3/library/stdtypes.html#memoryview) objects (and their [C API](https://docs.python.org/3/c-api/memoryview.html)).
I will never understand why someone would want to blog about it. 
wtf is this nerd shit?
I use both Emacs and Vim on a daily basis; I'm just sick of these posts.
You know this isn't a subreddit about snakes, right? 
Cool except vim is STILL single threaded so linting and other background tasks require weird hacks. Pycharm is just straight up better.
I still don't understand how people code and debug using lightweight text editors. I think I am probably still not understanding it, but how does one inspect the objects that are created when you run code? How can you get buy without being able to inspect function/class definitions. Why wouldnt you want the ability to click on an error message and go to the relevant code...? I just don't understand how people can code without 'easily' being able to do the following: - inspect classes, functions, function parameters - relevant autocomplete - be able to run bits of code and explore the resulting objects easily 
If you're using the *jedi-vim* plugin, `&lt;leader&gt;g` jumps to the initial declaration point (assignment), and `&lt;leader&gt;d` jumps to the original definition, e.g. the class if you're jumping from an instance name. Unfortunately, YCM still doesn't have these methods set up so you have to still use *jedi-vim*, but configured with the completion support disabled so that YCM can be used for that.
Vim actually introduced async in the last big update, but your point is still valid. Vim is pretty awful software (but great keybindings) and in general requires lots of weird hacks. Pycharm is polished and has a good vim mode. I love pycharm for the refactoring and the inline debugging (see your variables update as you step through), but I love vim for its startup time and being able to do stuff in terminal like `:!rm test.html` without leaving vim 
thanks, yes i see how could that work and the value of keyboard only once you've trained yourself, although i dont really understand what you mean by buffer. I'd hesitate to add to the voices of Pycharm as there are suspiciously many already, but I must admit when I opened it up it gave me a lot of what i had been searching for with other editors with a short learning curve. 
ah, i see
To be honest vim should work as well for you as nvim, I just chose it because it seems to run synchronous plugins (like Syntastic syntax checking) more quickly. Might just be my imagination. I guess the problem with Vim is that it is a text editor which people are forcing to become an IDE via ridiculously complex plugins. Youcompleteme and Syntastic are surely two plugins that are more complicated than Vim was ever expected to have. But regardless, I still enjoy using them, since the most important thing to me is Vim's keybindings. May editors (Pycharm) have Vim emulation modes, but they're not as thorough as real vim, and they always seem like imitations rather than implementations. [My nvim .init file](https://github.com/andysalerno/dotfiles) is currently very, very, very basic. The bare essentials. Uses Vundle to manage just the plugins I care about. (nvim's .init is equivalent to vim's .vimrc. Watch out for the path set in lines 5 and 6 if you're using vim instead of nvim... you'll want to change those back to Vim's defaults)
Just realize that there is no link back to the GitHub repo, I think it would be really nice and useful to add a link in the header or footer somewhere :) Other than that, nice package. In contrast to machine learning / statistics packages for i.i.d data, I feel like time series in Python was definitely a bit "lacking" the tools :)
Definitely interested in trying this out. Not an expert in this area but I read time series analysis was one place R had a leg up on Python? Not that I would voluntarily use R....
I gotta agree with /u/youcanteatbullets: the linked documentation is not useful for those who don't already have a clear understanding of what the various models are and what they are used for. That's what you need to add if you want this to be consumable by a general programming audience (e.g. subscribers of /r/Python): a general description of what a time model is, an introduction to what the particular time models implemented by this library do, what distinguishes them from each other and why you might pick one over another. The introductory paragraph misses the opportunity: &gt; PyFlux is an open source time series library for the Python programming language. PyFlux allows for easy application of a vast array of time series methods and inference capabilities. You don't say what kinds of methods these are. Are they statistical methods? Predictive methods? Analytical methods? Graphing tools? Database manipulation tools? Just saying "time series" you're assuming a very specific audience that already understands what's here. Splitting the documentation between two locations (the website and the API docs) further complicates the job of finding out what's here. If that's unavoidable, then you need links between the corresponding sections of the two documentation sets so people can navigate between the two information sources easily. 
Block and copy a large section of text, then paste it in a different area. Did you enjoy watching the cursor sloooooowly move in response to your arrow key inputs? No? Well see, there's this new thing called a mouse, and it speeds up those interactions. And, if you really wanna go faster, if you use a trackball you won't have to search for the mouse each time, either! _What will they think of next?_
To each their own. Want to copy from the beginning on the line you are on and the next 5 lines? '0v5jy' and now you are ready to paste where you want. Wanted to just move the stuff to line 50? '0v5jd50Gp'. I think I can do that faster than moving my hand to the mouse, finding which screen the mouse is on, highlighting text, ctrl+c, mouse to line 50, ctrl+v. Or maybe I'm just crazy and I've convinced myself of that. Either way, do what makes you happy. 
One of the reasons I use vim is for editing large text files (300mb to 1Gb in size). Vim is hands down the best editor for large files. I can select a huge precise block of text (hundreds of thousands of lines) using only keyboard commands. A mouse is actually a pain in the ass in that case, because it isn't precise and it takes forever scrolling down to find the right line.
Roger that, whatever works for you!
Sorry :) I did not know the version of Python was relevant, or unicode, since I was trying to generalize the problem for any string. I'll make it more explicit. Thanks for pointing it out.
If you're looking to go further, you can try switching it to websockets https://github.com/miguelgrinberg/Flask-SocketIO. Also if you use conda build for the package, when you install your package you can also specify entry point for starting your server. http://conda.pydata.org/docs/building/meta-yaml.html#python-entry-points
Thanks for the improvements. Your code doesn't work, though; there are some minor issues (`import res` â†’ `import re`; `print file_string` â†’ `print(file_string)`; unescaped newline) which I can fix myself, but more importantly `separators` isn't defined.
Just say that and add a link to the site at the top of the doc index there. Simple.
you know.. this is just one rsync cmd?
r/learnpython is oriented to this sort of discussion. r/python is used for discussing current topics related to python
I use Dvorak. And gold-plated usb connectors.
Could an app like this be used to send messages from your own account? If not, how would you go about doing this? Looking to create a scheduling system for myself. 
The `__init__.py` files tell Python that the enclosing folder is a *package*. Nesting such folders simply create nested packages which you can access in Python with `import outer.inner` and so on. That has been the case in Python for a long time. What might perhaps be surprising to a lot of people is that `__init__.py` files are no longer required since 3.3. Such packages that omit this file are called *namespace packages*, and the most accurate description of how they work is in the [PEP specification section](https://www.python.org/dev/peps/pep-0420/#specification). They might be much less known because they're not mentioned in the [Modules section](https://docs.python.org/3/tutorial/modules.html) of the tutorial.
I discovered that one of my primary causes of RSI was the mouse. After fixing all the other ergonomic factors I then moved to vim &amp; tmux for my environment, reducing my mouse use again - and that helped enormously. Now I'll fire up an IDE on occasion - but I won't use it for long just simply because of the health impacts.
Ok it's running now. To be honest I am quite proficient as a programmer, I just wanted to discuss the implication of this program in particular, and which other general approach would have better performance. Thanks for your repairs again and sorry for not making the code correct in the first place. It's running now.
I'm seeing the same issue on python2.7. It works fine on python 3.5 for me though. However, after installing numpy it was fine for me. I'm assuming the issue is similar to [this sklearn pr](https://github.com/scikit-learn/scikit-learn/pull/6990)
If you're final product is web-based, the [D3 JavaScript library](https://d3js.org/) might be a good alternative. It feels a bit like the programmatic equivalent of Adobe Illustrator/Inkscape and is more intuitive than TikZ. I only mention this in a Python context because it can be easily displayed in the browser-based Jupyter notebook. It is a good option for doing the types of scientific sketches that you mention when you're working in the notebook or any sort of web environment for that matter That being said, while D3 is very powerful, it is extremely verbose and I've found the learning curve to be quite steep. 
Yeah, a lot of the good tools are double edged swords like that. Take my project for example. Would it be awesome to have different runtimes communicate peer to peer? Yeah. Is it probably going to be used by botnets? Yeah. 
Per save. So no not even close. Plus in a big directory rsync can be pretty slow. 
&gt; It would be crazy for a JIT to not compile from some kind of IR Surprisingly not that crazy. I've heard some JS engines discard IR after each compile to save memory; their parsers are fast enough relative to optimization that the savings are worth the repeated computation.
&gt; It should have some 50 very small strings inside that I want remove. How small is very small? If you have a lot of 1-character strings, there's a `str.translate` method which **may** be faster. If they're merely short, but not that short, you should consider making a regex that matches them all. Python's [`regex`](https://pypi.python.org/pypi/regex) has a "named lists" feature, though you might find an explicit union (possibly using [re2](https://github.com/google/re2)) produces a faster regex. &gt; Also, do you know if there is any immediate drawback from using **read()** It hurts memory caching and prevents reading extremely large files, but not much else. I would suggest writing with open('some_file.c','r') as file: data = file.read() instead, though, as that makes sure you don't leak file descriptors. I suggest never using `readlines` and to normally avoid `readline` too. Iterating the file tends to be a lot nicer than those. But `read` is preferable here.
Hello
It's not needed in python 3
&gt; with how cheep memory is When you have users with hundreds of tabs on a couple Gb of memory on a platform as absurdly memory inefficient as a browser, you can't really afford to waste tons of memory on JIT intermediaries you aren't using.
Thanks a lot for these. I'll take a look!
TouchÃ©. I've never worked in the browser/JIT space before (only a couple of prototype AOT compilers), so I don't really know the constraints, but to me it would seem like being in a constrained situation like you mentioned, keeping the IR around for a bit of time (not forever, but until the JIT was warmed up "enough") would aid having to reparse megabytes of code. Please correct me if I'm misguided at all.
Can you elaborate? I'm not aware of any new feature which changes the init.py semantics but I'd be interested to read about it if there is one.
Well, it *would* help. It just wouldn't be worth the cost, given that JITing is comparatively rare and parsing is only a small fraction of the actual work that the compiler does.
D3 seems to be very powerful indeed. My final output, however, is PDF or (E)PS.
So you save offline and it syncs when your'e online again?
You always work locally and you sync when needed. And you can then enable to sync the files that are changed when you save.
Cool, this is useful - thanks. To be honest, I was aiming the library at those with a technical background and some grounding of statistics, but I can definitely look to make this consumable to a general programming audience with more introductory docs. Cheers!
Thanks, will look to rectify as they've done in that pr
will do!
The thing I like about TikZ is the concept of nodes. It is super easy to connect two filled circles with an arrow. And the arrowhead would just stop at the circle boundary. Such things are a little more cumbersome in Matplotlib (but not impossible).
Almost no-one is doing large websites in C++ but there are a lot in Java. By example, ebay has a lot of Java. C++ can't complete there, while Java can't compete in gamedev.
Wowow Too much logic in one line `regex_seperator = re.compile("|".join(["(?&lt;!\{)(?&lt;=(?&lt;!\\\\)\\\\{%s})(\|)" % x for x in range(0, number_of_escapes+1, 2)]))` `list_of_strings = [x for x in regex_seperator.split(one_bracket.group(0)[pre_slashes:][1:-1]) if x is not None][0::2]` Please make it seperate!
There is no need for creating account just to bash an open source program. I am taking what you are saying and trying to think of any way I can constructively take this to make my program better. I get that I am not a professional python programmer, the program still does what it is meant to do. On Fabric's website it states Fabric is a python library which users Paramiko. NetScript Assist is a GUI that uses Paramiko. As far as learning SSH, here is what my code does: ssh.connect(nodeip, username=username, password=password) ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) chan = ssh.invoke_shell() On my 'website': www.netscriptassist.com, I do not have users enter any password. There is simply a download link and other pages to help users. The only place where they would enter a password gets called in the SSH connection function. I even made it a point to have the logs use the variable name instead of the variable content. This was done so that if the users use the variables in the scripts they won't see the variable content in the logs. Additionally, I have made the program open source so users can see what I use the password field and any other variable for in my code. Ansible is extremely powerful and I think that it has a steep learning curve. Once you get into Ansible, it can do the same thing as this program and go way beyond what my program is trying to do. This program is not meant to do what ansible does. **TL;DR**: I am taking what you are saying with a grain of salt and trying to think of how I can value your input. 
So basically: &gt; it's ugly &gt; it's error prone
yeah, basically :) a colleague said to me, after reading this, "thanks for stating the obvious".
For what things do you prefer one editor over the other?
Couldn't disagree more here. Your update is one reason for this being faulty reason - an object that just encapsulates data isn't really an object. Another is pace of development. If an object has little to no functionality, or the functionality is shoe horned in, it takes longer to develop. Your point about how to reason about what is happening is also flawed. If you have a hard-on for objects, you are probably also the type (hehe) who likes to inherit quite a bit and inheritance chains and mixin soup attribute even more friction when trying to determine the program flow. And as others have said, objects are dicts and dicts are objects. There is nothing in your example that needs an object or meta programming. It's a succinct code snippet that's perfectly fine.