I personally think that's ugly though. It does look like erlang wins code golf.
Constant look up is asymptotically faster than hashing, whose worst case complexity is not constant. &gt; you'd be replacing a more intuitive solution with a slightly faster one and it's pretty much a matter of preference at that point (in python at least) I wouldn't say using a set to store already explored nodes is a more intuitive way. If you want to know whether a node w has been explored, what would be more intuitive than checking w.explored? Adding an attribute to each node, however, might not be as desirable as keeping a separate data structure, depending on the application.
You are absolutely right, it would be slightly faster. But a node in NetworkX can be any hashable object. This means you must check that the variable name doesn't clash with any attributes of all the nodes.
Oops, I might have left some debugging code there. Rest assured, the code will be cleaned up. (I created this plugin)
Erlang, to me, is a beautiful language. But it's like, "Come 'ere you ugly fuckin' thing, I love you."
You are right about the licence, but by using their code I mean for example one enum of cache attributes. But I know, I am the bad one... Thank you for your recommendation regarding unit tests. The main reason for this is my editor (Sublime Text) and it's "Build" command. Actually I'm too lazy to write my own build system which would support better directory structure. :)
The interesting part about this specific quicksort is that it is done in-place, which is how quicksort should be done. I love Haskell, but you can do pretty much the same in Python: def quicksort(l): if len(l) &lt; 1: return l x, xs = l[0], l[1:] lesser = filter(lambda el: el &lt; x, xs) greater = filter(lambda el: el &gt;= x, xs) return quicksort(lesser) + [x] + quicksort(greater) Of course, Haskell does it better in my opinion, but it's not that much of a difference.
I knew that already!
Technically, the free version is for evaluation only... it does everything the "full" version does, just you should really pay for it if you decide you really want to use it.
[test 2 string](http://i.imgur.com/O5aVJwx.png)
Hey !! Me too! My first lib : https://pypi.python.org/pypi/ssc I did versioning a little different that you. But I can ask, for what version of Python is your lib ? For my newbie view of Python, looks that you aimed for Python 2.x, not ?
This is the only useful Kivy tutorial I have found for anybody also interested in using Kivy for cross platform applications.
Yes, you are right, I aim to Py2.7. PERSONALLY I thing Py3.x is not supported enough by 3rd party libs to switch.
Maybe it's just my obsession, but every time I launch a new SW, I spend at least half an hour by playing with its settings. Try it too. ;)
Ah, good to know. I wasn't quite sure if it did, or if I had to enable it. The README didn't say anything about pyflakes but I did see some mentions of it in the code, so I assumed it was doing it by default.
this'll be the first hackathon i've ever done :o and i'm still learning python :P
The speaker runs our local Python user group!
Javascript integration is next on the [roadmap](https://github.com/ipython/ipython/wiki/Roadmap:-IPython#overview-of-2013-2014). Jake Vanderplas has been doing a bit of hackery to get it working today. He blogged about it: http://jakevdp.github.io/blog/2013/06/01/ipython-notebook-javascript-python-communication/.
Thanks, I'll look into that as well :)
Interesting, this approach seems to rely on javascript polling the kernel, which seems like it won't work if the kernel is busy and you're trying to plot partial results from a long-running computation. The approach I hacked together was to run a zmq-websocket bridge and use an HTML object that creates an iframe containing arbitrary javascript. It would be nice to be able to reuse the notebook's zmq and websocket functionality instead and get messages dispatched to javascript from the kernel. 
Mate you are a legend. Your blog is so easy to follow compared to the official pyenv page... I'm running into [this](https://github.com/yyuu/pyenv/issues/22) problem however, which I'm not sure how to get around? I imagine the installation of numpy will be simple once I've figured it out. If it is an OpenSSL version compatibility error, I wonder why you didn't also get it?
Is there a changelog somewhere from 0.13.2? Also, I'm personally excited for iPython 3.0 with multi-user notebooks! EDIT: Found some stuff here: http://ipython.org/ipython-doc/dev/whatsnew/version1.0.html
I like the product but &gt; an architecture for interactive computing, that can drive kernels in a number of ways using a well-defined protocol, and rich and powerful clients that let users control those kernels effectively. Sorry, what? 
Kernels = python interpreters Clients = console / wx-gui / "notebook" webpage 
If kernels is an abstraction, I can only assume one could write a kernel which is something else than a Python interpreter. Right?
So many features, and I only ever use the shell.
Again, I dont want to be blunt, but how does it compare to Smalltalk? From my point of view *Pyhon is still behind.
Possibly, yes. I don't know how tight is their integration with the Python language.
Yes. For example, Julia. https://github.com/JuliaLang/IJulia.jl
Depending on what you want from Smalltalk, Python will never catch up. It's not image based, there isn't full reflection, you can't control the stack or other such run-time aspects in Python, built-in types are closed for modification, etc. Those weren't and aren't its goals, so if that's what you want, you won't get it. Language-wise, Python doesn't have blocks at all and will never get them. Python also prefers a smattering of syntax instead of object (eg, 'if' and 'for' are statements, rather than objects which take messages). If you want those, then again, Python will never catch up. Another way to view this, though, is that Python's on a different road. If I'm driving to Quito, Ecuador and you're driving to Sydney, Australia, it makes no sense to ask if I'm catching up to you when we didn't even start on the same continent.
In the meantime there's [contextlib2](http://contextlib2.readthedocs.org/en/latest/).
Nice project. This certainly looks like it could be very helpful. I have one observation to your use of Tornado: this [code here](https://github.com/agschwender/pilbox/blob/master/pilbox/app.py#L82) looks like you will block the IOLoop when resizing the images. This can severely limit your throughput. You should spawn some [multiprocessing](http://docs.python.org/2/library/multiprocessing.html) workers before starting the IOLoop and send the resizing tasks (e.g. using multiprocessing.Queue) their way. You'll probably have to poll the results using tornado.ioloop.PeriodicCallback which isn't completely ideal but should do for the beginning. Threading will not help here because of the GIL.
awesome talk!
edit: installation problems solved by going through pip 
That's exactly the point, yes. 
Not blasphemous enough. 
I'm pretty sure it makes sense for a large application. But if you've never built one, I understand why you're ignorant. Besides, why wouldn't you want all the helpers and boilerplate taken care of in a way smarter than you are able to build yourself?
Sphinx is kind of a standard in the Python world so I'd keep it.
If you aim to Python 2.7, you can make it to work with 2.7 and 3.3 at same time.
p.90 has a very good comparison of using generators/iterators to process a log file versus the intuitive for loop.
There's a similar plugin for nose, [nose-progressive](https://pypi.python.org/pypi/nose-progressive/)
i've definitely never built a large application.
Why they says 12 years? Do they mean from the very start? Because then they say 12 months.
If you've never tried it, it's at least worth checking out. Try running "ipython notebook". 
print / print() ?
"...drop(3, xs) returns the last three elements in xs." I think that should be "...drop(3, xs) removes the first three elements and returns the remainder." 
IPython isn't really anything to compare to Smalltalk. It isn't a language, but a utility on top of the language.
`from __future__ import print_function` =)
You're looking at it in the wrong way ... now, imagine a wsgi/django development server written in PHP - that's blasphemy !
A was referring to all xxxPython tools. Not just iPython. 
You can render your IPython notebooks to reST and embed them in a Sphinx site. No problem.
It's in the second part.
Tabs vs space is as big of an issue as you make it to be. To me it's still a meh issue. Just follow the convention, problem solved. In fact, I wish Python adopted a more militant approach like Go, where the style is whatever `gofmt` says it is, so there is never an argument. I'm surprised that you say that it's hard to refactor. Python, by far has been the easiest language for me to refactor structure-wise, hardest being C++, and OK one being C# just to compare. But then again, I use Vim, where changing indentation is very natural, can't comment on other tools.
I see, I guess what I am looking for to begin with is keyboard/mouse manipulation for windows? 
[Here](https://www.google.fr/search?q=python+keyboard+mouse+manipulation+for+windows&amp;client=ubuntu&amp;channel=cs&amp;oq=python+keyboard+mouse+manipulation+for+windows&amp;aqs=chrome.0.69i57j69i62.6927j0&amp;sourceid=chrome&amp;ie=UTF-8) you go ;-)
&gt; for example windows keyboard/mouse input manipulation? Screen reading? retrieving webpage data? and so on. input manipulation/Screen reading : [sikuli](http://www.sikuli.org/) google: "python gui automation" retrieving webpage data: google "python web scraping" 
something like http://pyjs.org/ ?
If I were to make a list of reasons python is better than php, I wouldn't start with the fact that php uses curly brackets and python uses whitespace. I'm not even sure I'd mention it at all.
Excellent article - though I'm not crazy about JADE in a few ways, I very much like the idea of a whitespace-aware templating language. In fact, I liked it so much I went and threw together what I think a pythonic templating language would look like, and posted here on Reddit to see if anyone was interested (or could shoot it down): http://www.reddit.com/r/Python/comments/1k1b8g/a_pythonic_templating_language_concept_inspired/
I have to say I disagree with almost everything you've said. &gt; It promotes the old tabs-vs-spaces debate from a mere "meh" issue that only pedantic dickweeds would argue about to an actual problem How? In my experience you just use whatever the project already uses, which tends to be 4 spaces for a tab. But if it uses two spaces, or tab characters, you just configure your editor that way. It is a minor hassle to have to reconfigure your editor on a per-project basis but as a Vim user this is something I can mostly dodge by just sourcing different vimrc files. &gt; but the worst part is that it contributes to Python's utter resilience against refactoring. When moving code around, I have to be very careful to not break its structure, and I can't simply auto-indent the whole thing to fix the indentation, because there is not enough information for the auto-indenter to work properly. I've never had an issue refactoring in Python. Any properly formatted block of Python code you start with simply needs to be indented/dedented as a whole, which for most text editors and IDEs is a very trivial operation. Between copying and pasting I don't quite understand what could go wrong to contribute to Python's general "resilience against refactoring." Nevermind I do not feel a resilience against refactoring in general... &gt; discussing Python code on IRC or e-mail is not fun I will agree that discussing Python on IRC isn't fun, but that's simply because I dislike the atmosphere of most IRC channels. It is a small hassle that you can't paste a huge line of Python mess and have it auto-indented to something clean like you can with e.g. Java. But then, you can always just use gist or a pastebin clone and that problem is solved. As for e-mail, most e-mail editors have some sort of preformatted text option, or you could use an attachment, or you could use pastebin. I've never encountered an issue communicating Python code via e-mail (although to be fair I rarely have a need to). &gt; the ugly wart that is pass How is `pass` an "ugly wart"? It seems like a simple and straightforward keyword with a very clear purpose. It hasn't ever occured to me as a "wart," just a natural consequence of the significance in whitespace as Python. But perhaps I'm biased because I see the significant whitespace as a strength? &gt; crippled lambdas Crippled lambdas is the one point of yours that I do agree with. Python's `lambda` hasn't ever actually stopped me from writing concise and readable code, but there is something nice about Ruby blocks. &gt; counter-intuitive behavior with multi-line list and dict literals Counter-intuitive how...? I've never had a single problem with dict and list literals, which both seem to be quite flexible. What was your issue with them...?
How do you have vim set up? Currently I have vim set to use 4 spaces as indentation on everything and I get problems when that's not the convention of the code I am working on especially if the code uses actual tabs.
Actually, much of image processing is IO bound. It really depends on the scaling algorithm used. Nearest and bilinear, for instance, don't require much in terms of CPU. Most of the work for those, is just copying memory around. For reference, a 1024x768 24-bit RGB image is going to take up about 2.25 MB of memory. CPU *is* relevant here, is because Pilbox is using the "ANTIALIAS" scaling method, which uses the Lanczos3 algorithm and is much more CPU intensive.
&gt; Tabs vs space is as big of an issue as you make it to be. ~ $ cat hello_world.py if __name__ == "__main__": print("Hello") print("world") ~ $ python hello_world.py File "hello_world.py", line 3 print("world") ^ TabError: inconsistent use of tabs and spaces in indentation ~ $ The problem with indentation is that it completely breaks copy and paste. It breaks it everywhere. If I copy and paste a C snippet from one place to some other place, it might be indented to the wrong number of tabs, or not in accordance with the style guide, or it might be completely fucked up with zero newlines and/or zero indentation, but that doesn't matter; you just use whatever auto-beautifying tool you're familiar/happy with. Reddit's markup decides to unindent literally everything, and put consecutive lines without a blank line in between into a single solid wall of text, with one space between each word regardless of how many spaces, tabs, or newlines were there to begin with? With C, that doesn't matter; [`indent`](https://www.gnu.org/software/indent/) knows what a semicolon is, and what curly brackets are. So does the compiler, in fact; it doesn't need to be pretty to compile. On the other hand.... this kills the python. Don't get me wrong; python is the most beautiful language there is. But saying that everything is perfect in the garden of eden is incorrect. There do exist valid criticisms of python. Syntactically significant whitespace is one of them.
Selenium for Python heard is a good place to start.
We had to build a small reporting tool in Django redently. There was an API that accepted various data points for the report and then I added in JADE and SASS templates into Django. Normally I don't render much in Django these days but for the project it made sense. The final piece was rendering the templates out into temp files via a celery task and then converting the resulting html and css into a PDF.
in ten years of discussing python code on IRC and in email, I have never seen any significant problems. Allowing tab characters in Python code _was_ a mistake but it's relatively easy to avoid these days.
Besides the fact that your "solution" has nearly none of the functionality of Enums, it baffles me that you used a namedtuple instead of a set or dictionary. Or a tuple. Actually, I would have picked almost every other data structure in the standard library before I picked a namedtuple. Maybe even a pandas time series, too. I tried to write a workaround that makes as much sense as yours: def enum(*args): def __super_private_function(): def set_as_unique_global(thing): globals()[thing] = object() return 1 class TheEnum(object): def __init__(self, len): self.len = len def __len__(self): return self.len def __getitem__(self, index): reburn globals()[index] return TheEnum(sum(set_as_unique_global(arg) for arg in args)) return __super_private_function() &gt;&gt;&gt; Colors = enum('Red', 'Green', 'Blue') &gt;&gt;&gt; Red is Green False &gt;&gt;&gt; 'Green' in globals() True &gt;&gt;&gt; Colors["Red"] is Red True &gt;&gt;&gt; hash(Green) % hash(Red) % hash(Blue) 1 Read the article if you want to see workarounds that aren't bullshit. 
@ /u/gschwa A good indicator is to just saturate the server with as many resizing requests as you can get through and look at the CPU utilization of the machine. If you don't use 100% CPU on all cores all the time you are wasting resources.
Thank you!
Have you tried (tldextract)[https://pypi.python.org/pypi/tldextract/0.2]? It's fantastic. 
I thought this was a very understandable lecture. Slides from the lecture are here: http://www.slideshare.net/dabeaz/understanding-the-python-gil .
I just started picking up Python and while I am able to accomplish some tasks that I set out to do, it takes a heckuva long time and I'm slooooowww. I came across this Kickstarter site for "flow based" programming and one of their stretch goals is implementing their product in Python. Anyone have any thoughts?
Not sure i like it but Id like to see the code of how you are generating this - might be something here
The first 4 minutes hooked me. Looking like a good talk
There is no code, yet :) I'm hoping to see if there is interest in it before I devote significant effort to it. I think I can write a minimally-working version in a few hours. It would be whitespace-aware and would support parsing Emmet syntax (which I've discovered is what Zen Coding is called these days). I don't think I'd be able to extend Emmet to support iterative generation in that time, but I might surprise myself. There's also the small issue of variable printing and flow control...
I use it for both email and domain validation. 
pymouse is really nice for mouse stuff. http://code.google.com/p/pymouse/wiki/Documentation
Ok thanks!
Re: tabs vs spaces: There are [clear rules](http://www.python.org/dev/peps/pep-0008/#tabs-or-spaces)
Yeah, same here. After about 5 minutes I knew I was finishing it all.
I think it's kind of arbitrary to call HTML and CSS different languages but to call the border-image syntax in CSS and the gradient syntax in CSS the same language.
I need flup to talk to a fastcgi process but I don't want to add any dependency to this script and keep it as single file. At least that how I understand it based on what [Ian Bicking did][1] 8 years ago. If you have any idea how I can do that in much simple manner than wphp, that would be interesting to explore. [1]:https://bitbucket.org/ianb/wphp 
This is one of the most memorable PyCon videos I have ever watched... And I've seen a lot! 
With the pywin32 extension you have access to virtually all of the windows apis and can do all sorts of automation. That's what I do for a living in fact! We use ActivePython, which comes bundled with said extension : http://www.activestate.com/activepython
You can find out even more about the GIL on his website (for instance the impact of the GIL on signal handling): http://www.dabeaz.com/GIL/
I just finished watching it. And now I'm very sad.
&gt; When complex problems do present themselves, visual programming is the headphone wire that you left in your backpack. That's a great quote. But not all visual programming has to involve the spagetti of wires like most instances of visual programming.
GR!
BTW, what about unicode support.. do you need to handle it differently on 3x with all the changes?
Yes. Unicode strings are the default in 3.x.
&gt; it's hardly worth being so rude about it. In other news: it's hardly worth being so sensitive about it. Why do [you want to change](http://xkcd.com/386/) my style of expression? Am I invading your personal space, or some other [mediocre excuse for lack of a personality](http://audiour.com/playlist/fx1rur4y)? Fudge off, banker.
Who's being sensitive here? (6 days later, even!)
Wut?
And now (sort of) lazily, in python 3.3: def quicksort(l): if len(l) &gt; 0: x, xs = l[0], l[1:] yield from quicksort([e for e in xs if e &lt; x]) yield x yield from quicksort([e for e in xs if e &gt;= x]) It's possible to do it more lazily, using itertools.tee or something like that, but it loses the simple elegance we have here.
Madness!
Why would you ever use `set([])` anyway?
This is surreal. I may be LyndsySimon in a parallel universe. I have been thinking of a very (and I mean very) similar thing in the past few days and today I saw this.
You should probably investigate Autohotkey, its not python but its a language literally made for this and can pass vars to python scripts if necessary 
I'm really enjoying the proximity of this and the "My asshole crushed his hopes and dreams" post on the front page right now.
Great in a jam, but painfully slow.
You definitely could have worded this better.
A compromise in what way? It's both.
I don't see it as a compromise. It's going to be both lighter weight and more reliable than a python server.
[splinter](http://splinter.cobrateam.info/) Splinter ... lets you automate browser actions, such as visiting URLs and interacting with their items. 
Check out AutoKey. I wrote a blog post on it [here](https://ubuntuincident.wordpress.com/2013/05/19/automate-tasks-with-autokey/).
Yes. I am aware of that. My point is that such rules are much more important in Python than in, say, C. Making a whitespace mistake in C is a nuisance at worst, and any auto-indenter worth its bytes can fix it. In Python, whitespace differences can actually break your code.
If you have a fairly recent php installed you can also do `php -S 127.0.0.1:8000`. Yeah, I don't like php either.
I used it once to [install a greasemonkey script](https://ubuntuincident.wordpress.com/2013/05/20/install-a-greasemonkey-script-from-a-local-file/) (that I couldn't install from a local file).
PyPy is working on a fix. You can help by donating -&gt; http://pypy.org/tmdonate.html
Well yes, because a whitespace error in Python is equivalent to forgetting a semicolon or a closing brace in C. I would argue that an indentation error is way easier to find and fix than a missing brace or semicolon. 
 pip install fs fsserve .
I use the node.js module too. Seems more suited for the job.
Tabs vs. spaces is a meh issue until you give it the power to break your code. Not everyone follows conventions and style guides and whatever, and especially with something like whitespace, detecting errors often takes active effort. When whitespace is not relevant, you go "meh", run your favorite auto-indenter over the code, and proceed. But when it is, the auto-indenter doesn't work - it can convert from one indentation convention to another, but it cannot fix broken indentation. In such a situation, a militant approach becomes necessary to avoid exactly this problem, but when whitespace is arbitrary, you can be as militant as you deem appropriate. Refactoring Python has a few problems; some are because it's a dynamic language (e.g., there is no way to make 100% sure you have found all references to some identifier - after all, something like reading a method name from a network socket and using that to call a method is perfectly valid and legal), and those problems are impossible to solve without sacrificing the language's dynamic nature. Python shares these problems with all the other dynamic languages, and I'm not demanding anyone fix them; it's a logical price to pay for dynamic features. Others, however, are a consequence of syntax-relevant indentation. For example, something I do a lot while refactoring is move blocks of code around, usually into a different context with a different level of indentation. With most languages, I use vim's `]p` command for this: it pastes and then reindents as appropriate. But this doesn't work with Python, because in order to know the correct indentation level, you need to have properly indented code. If I paste after the following: if condition: log("Condition met!") ...then it is impossible for the editor to tell whether I meant the paste to go into the `if` branch (which would mean "indent by one level") or after the entire `if` block (which would mean "align with the `if` keyword). With explicit block delimiters, I can make the difference by pasting before or after the end delimiter, and the editor can reliably figure out the correct indentation from there. Another problem is `pass` - we need `pass` because even though we want conceptually empty blocks, we cannot have syntactically empty blocks, so we have to introduce an artificial "explicit nothing". The consequence is that pasting into an empty block is not the same as pasting into a non-empty block (see also my other comment).
Tabs are great. I love tabs. With tabs, I can view the same source files with 4-space indents, while my teammate uses 8-space indents and yet someone else uses 2-space. Tabs for indentation, spaces for alignment. It's not hard, you just have to do it. It works like a charm. Not in Python, though. In Python, I avoid tabs like the plague. Haskell, too. Tabs in Haskell are almost as evil as in Python. I don't blame the tabs though; I blame the languages.
Oh, I have something for you: http://www.reddit.com/r/Python/comments/1k2yvo/what_is_going_on_behind_the_scenes_when_working/ Not a significant problem of course...
whenever I do this from a computer that's on a wireless network, I can never find the right IP address.
I'm a big fan of python but there is a alternative tiny server called mongoose (https://code.google.com/p/mongoose/). The .exe is just 349kb on windows. Easy to carry on a usb drive.
Or even an Apache server for that matter
What data type would the operations be performed on? Lists, sets, or arrays?
Power of Python always 
But... Itertools?
:( I wish people would tell me what I was doing wrong instead of downvoting without explaination. OMG, that's so unpythonic.
For the forward-looking crowd, you can do the same one-liner in Python 3: python3 -m http.server 
Ideally numpy arrays, which is why I can't see this PEP going very far... Those who want to do statistics can already use statsmodels or scipy.stats. Admittedly, there's some work to be done in developing stats libraries for python, but I don't think it needs to be in the standard library.
yeah we can use itertools to get answer's instantly but that guy explains the algorithm better.
FYI, port 8000 is the incorrect port for this. [Port 8000 is officially reserved for iRDMI](https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=8000). Normally, you'd use [port 8008 or port 8080](https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=http-alt).
The reason people aren't telling you what you are doing wrong is that it's impossible to know from only "It doesn't work."
I gathered from the downvotes that it was a stupid obvious thing. Wasn't really asking for help before that.
now that I think about it its probably because slackware defaults to a buncha closed ports. 
The PEP states that the functions will act on iterables, buy they may be coerced into lists inside the function. This obviously includes numpy arrays, but this library doesn't intend to compete with numpy - it's mainly for people who cannot install numpy, or who are only writing small pieces of code for which numpy would be overkill. 
Geez you people are picky.
Just because a port is *reserved* doesn't mean that's the only "official" or "correct" usage of the port. I can use any port I want to do anything, I just may run into conflicts with established protocols. And we're just talking about a transient service to serve something once, can't really believe you went here.
I realize that. But Port 8000 *is* official. Yeah, you can use any port you want, but it's always best to use the right port and comply. People with the it-doesn't-matter attitude are the ones that cause problems in systems and projects. You can get away with not caring, but it *does* matter. The ability to do something does not make said activity acceptable.
It's official, but you can't seriously believe running on a non-standard port (especially temporarily) is *unacceptable* and will cause problems.
"ip addr" is preferred these days.
what do you mean "you people"?
Itertools is the correct real life answer, but I'm guessing OP was just refining his interview solution publicly.
You know what I mean.
ip addr will also tell you if a network interface has more than one IP address.
I think the node.js module http-server is a little better for running directories locally, but if you're working in Python then SimpleHTTPServer is the better option.
What I do on my localhost or even LAN is totally up to me, it's not the internet.
Very useful. Upvoted! . Is this why IronPython benchmarks better than CPython?
 twistd web --port 8080 --path .
This. I work for a company which has a large python codebase. We use this to process large quantities of data (many tb at a time). Works well, , nice how we can use it on our own machines, or on Amazon EMR.
Why not? Isn't the standard library where error-prone (and for the uninformed, numerical stability, accuracy, and precision are very much error-prone) and difficult code are supposed to go? That way, the core devs can write it once and the rest of us just have to import it. I personally would love to not have to remember anything (or at least not a lot) from my numerical analysis class. (That class was a nightmare)
Scipy is a huge piece of code to import for a simple mean function. I personally think it's ridiculous to recommend people to use scipy/numpy for this kind of elementary numerical work.
http://xkcd.com/353/
As a PHP developer, I'm disappointed you speak so harshly.
Seconded. AHK is amazing, and *extremely* easy to learn (the basics anyway, you can get quite elaborate, reading pixels and images off the screen etc.) You can write useful keyboard shortcuts for yourself in seconds, just by reading the included help file. If anyone wants an example of a bunch of useful Windows shortcuts, and how to launch them at startup, PM/comment. I've also investigated writing a simple casino bot (mainly for fun/education rather than profit), using AHK's ImageSearch function, which is almost "magic" seeing it working! 
Careful with Sikuli: it's easy to get started, but it's quite flaky and unstable. I had a rather long script simply "disappear", even though I'd technically saved it. I'd recommend AutoHotKey (for Windows). Somewhat trickier for screen reading, but extremely stable, mature, [helpful forum](http://www.autohotkey.com/board/), tons of examples out there, very light on system resources, etc.
Actually I have a couple of friends who do code in wordpress, make templates and everything, wordpress today can be use for many many things and don't use haha but I know is possible... I like better frameworks but I like to code... wordpress have also plugins to make e-store and that kind of stuff.. check this plugins for example: http://vandelaydesign.com/blog/wordpress/ecommerce-plugins/ You will have to play a little with word press and decide if it fit you or not. 
Excellent explanation of decorators from SO: http://stackoverflow.com/a/1594484/484820
I'm sorry I offended you. I hope this won't make you cry http://me.veekun.com/blog/2012/04/09/php-a-fractal-of-bad-design/
You can do the same with bash with and netcat. http://www.linuxscrew.com/2007/09/06/web-server-on-bash-in-one-line/
 python3 -m http.server 
I'm a little sorry this comment is downvoted so much that it won't be displayed by default. I think that while bacondev's concern is misguided, he really tried to help and even tried to link to relevant documentation.
PHP is useful (because your only other realistic options are asp or node.js which isn't really the same thing), but it's an ugly language.
An issue of numerical stability does not belong in the standard library. I have no issues with it being there if it ignores obviously pathological numerical issues. That's like saying 1.0/3.0 * 3 should be equal to 1.0. It's just not going to happen.
Yeah, but if you're already on a computer with python installed (and if it's your/your work computer it probably does), using python is much easier and quicker, and it's cross platform. Mongoose only has binaries for windows and mac, you have to compile it for linux.
It's also not incredibly easy to deploy, in my experience.
Not that compiling it is any big problem. wget https://mongoose.googlecode.com/files/mongoose-3.8.tgz tar zxf mongoose-3.8.tgz cd mongoose make linux
On YOUR front page. Everyone has a different front page depending on the subreddits they're subscribed to.
People still type in raw IP addresses? `avahi-browse -at`
I'm waiting for reverse implemetation :D Python interpreter in PHP :P
No it isn't. Having a numerically stable mean algorithm is nothing like saying the base float operations should have infinite precision. Right off the bat, one is possible, one is not. If all you're going to say is "it doesn't belong there", I'll just counter that with "Yes it does.". And besides, even if we ignored precision/accuracy/etc, having the basic statistic functions in the standard lib would be convenient. That way I don't have to create a dumb util module just so I can import a mean function into my various modules. Even if they aren't hard to implement, it's more convenient when they're already built in. (Python is a "batteries included" language, after all.)
I thought it said Python *shaved* your ass, and I though, man, Python is really powerful.
Don't do ln.sort()! Using the sort method sorts in place, modifying the original list &gt;&gt;&gt; a = [3,2,1] &gt;&gt;&gt; a [3, 2, 1] &gt;&gt;&gt; median(a) 2 &gt;&gt;&gt; a [1, 2, 3] you should do this instead def median(ln): ln_sorted = sorted(ln) pos = int(len(ln) / 2) if len(ln)%2 == 0: # Even number return ln_sorted[pos - 1:pos + 1] else: # Odd number return ln_sorted[pos] on a separate statistical note, in the case of an even sample size, I would use the mean of the two values (this is pretty standard in statistics). def median(ln): ln_sorted = sorted(ln) pos = int(len(ln) / 2) if len(ln)%2 == 0: # Even number return sum(ln_sorted[pos - 1:pos + 1]) / 2.0 else: # Odd number return ln_sorted[pos] 
Thanks! I noticed that it modified it, but I assumed it only did it in the function... Silly, I know. Updated my post.
Also, sorted() is also a better choice as it will work on any iterable - you're not limited to passing lists anymore (you can pass tuples!)
This is exactly why this needs to be in the standard library!
It looks like the new thing you are adding is simply making the writing of the html easier? IDEs already do that, and I use sublime text which would be about the same keystrokes. I can't imagine a production server would want a templating language that takes longer to parse for programmer convenience as well. My templates are written by HTML design guys and the only thing I care about is speed. 
Yes, but, you can get a beautifier addon for working with php.
This and a basic plotting library would just make my day.
From [here](https://github.com/brandon-rhodes/pyephem/issues/20#issuecomment-20021367): &gt; (TIL [Python floats](http://docs.python.org/2/tutorial/floatingpoint.html#representation-error) are like [IEEE-754](https://en.wikipedia.org/wiki/IEEE_754) [binary64 doubles, which have 53 bits of precision](https://en.wikipedia.org/wiki/Double-precision_floating-point_format) and that [BigFloat](http://pythonhosted.org/bigfloat/) wraps [GNU MPFR](http://www.mpfr.org/) in order to utilize arbitrary-precision arithmetic, while [gmpy2](https://gmpy2.readthedocs.org/en/latest/mpfr.html#multiple-precision-reals) implements "a new *mpfr* type based on the [[MPFR](https://en.wikipedia.org/wiki/MPFR)] library".)
[Here's](http://www.reddit.com/r/Python/comments/1iuxhr/newbie_coder_firstever_program_download_time/cb8y7et) a (start at a) [momentary mean / simple moving average](https://en.wikipedia.org/wiki/Moving_average) function that yields floats. 
* https://en.wikipedia.org/wiki/Floating_point#Machine_precision_and_backward_error_analysis * http://docs.sympy.org/dev/modules/mpmath/technical.html#precision-and-representation-issues
&gt; Selecting arbitrary columns from a 2D array: [`operator.itemgetter`](http://docs.python.org/3/library/operator.html#operator.itemgetter) and [`operator.attrgetter`](http://docs.python.org/3/library/operator.html#operator.itemgetter) for simple cases. a = [[10,11,12],[20, 21,22]] _itemgetter = operator.itemgetter(1,0) assert list( itertools.imap(_itemgetter, a) ) == [(11,10), (21,20)] _selector = lambda x: x[1][0] assert _selector(a) == 20 
FTR, `ln` is not defined in [`math`](http://docs.python.org/3/library/math.html), where the function for natural log is [`math.log(n)`](http://docs.python.org/3/library/math.html#math.log).
I'm using `ln` as an abbreviation for `listofnumbers`.
This comment is, IMO, the best in this thread since it contributes to levity and not telling me I did it wrong by not using php or node.js or whatever else.
For a fun challenge try to calculate a median without sorting the items and only doing one pass. This is relevant when you have really long lists, or are reading them sequentially such as from a file, network connection or database. I've been in this situation a few times. You obviously can't get the perfect correct answer, but there are various probabilistic algorithms that work. 
&gt; It looks like the new thing you are adding is simply making the writing of the html easier? IDEs already do that, and I use sublime text which would be about the same keystrokes. SublimeText isn't an IDE, first of all, it's an extensible text editor. :) But no, this isn't just about writing HTML easier. Emmet does that now, and there are plugins for just about every editor or IDE you might use. This is about representing HTML in a way that's terse and succinct, and that doesn't require that you change so much of the way you think when moving from writing back-end code to front-end code. Instead of saving keystrokes, I'm more interested in saving brainpower. &gt; I can't imagine a production server would want a templating language that takes longer to parse for programmer convenience as well. Hmm.. really? Python is all about readability, often at the explicit expense of speed. That said, there's no reason there couldn't be an intermediate format that would allow the webserver to only have to compute the dynamic portions of a template on reload. If this gets written and if it gets adopted, there is room for optimization. &gt; My templates are written by HTML design guys Ah - well, I'm a full-stack developer. I know where you're coming from though, and this wouldn't be for you. &gt; and the only thing I care about is speed. Wait a sec... why are you in a Python community, then? If your only concern is speed, then you should be writing everything in C, or maybe ASM, right?
&gt; This is surreal. I may be LyndsySimon in a parallel universe. How would you know? Maybe I'm the one in a parallel universe, and I'm you... &gt; I have been thinking of a very (and I mean very) similar thing in the past few days and today I saw this. Cool - if I do this, it'll be on Github. I'll shoot you a message. You're welcome to join me :) If you sit down to write it, let me know and I'll do the same.
I'm not denying that at all.
You *don't* have to. I'm just trying to share some knowledge.
what does the # mean?
Nah, we PHP folks are confident in our superiority complexes!
PHP is useful if you're writing code that other people need to run on their own servers, or that you're going to hand off to semi-skilled developers.
&gt; I thought it said Python shaved your ass, and I though, man, Python is really powerful. from toiletries import razor razor.shave(self)
349kB for a simple webserver!?
I was thinking that, I've only done a tiny bit of HTML, and I found it very dull, but I at least indented it. If this Part A is inside Part B then indent it. Even the inspect element thing on Chrome does that.
Yes. Not everybody uses multicast DNS, and it's only useful on office and home networks.
Never had to work with a rack of identical 1Us with a dozen cloned VMs each differing only by hostname?
I work for a hosting company, so yes.
Times stared mostlike.
I must admit that I thought the same thing. But I cannot imagine the kind of apps that I could build with this. 
I agree about reading more source code. I brought it up at a dev meeting last week that we should all be reading more source code from open source projects and sharing what we learn with each other. The fact is, though, that I don't have any spare time at the moment to hunt for hours through nose's rather large code base to answer a pretty straightforward question. I've read through the nosetests arguments list many times. In fact, I read each flag's description/usage in `man nosetests` last week individually - every one. My test running setup in Vim uses attribute, and I use cover often to check my test coverage, and I had a particularly tricky bit of business going on testing in an embedded python, for which I had to isolation (an answer I got directly from the guy behind the nose project). This doesn't have anything to do [I think] with how adding an `__init__.py` would break importing. This is at a level above the nose testing itself, and I want to understand how this works, not just throw in a hackish workaround. Let's face it... importing in python is [a nightmare](http://python-notes.boredomandlaziness.org/en/latest/python_concepts/import_traps.html). Hierarchy is one of the hardest things in all of computing, and almost everyone gets it wrong, and it's a mess both in importing in Python, and in package management. These are not at all easy problems, and this is far from my first attempt to push through and understand this mess. I just still don't, and was hoping for some clarity from people who might get it.
Github stars
Whether it's hard or not, you don't have to do it. The fact that different editors can display tabs differently is the main reason they're bad.
How does this compare and contrast with the Python [Natural Language Toolkit](http://nltk.org/)?
I disagree; the fact that different editors can display tabs differently is a good thing, if you know how to use them right. Some people prefer 8-space indents, I like 4-space, some others like 2-space. If you use tabs for indentation, each of us can view the source code in their own preferred style, without breaking anything. Saying "don't use tabs at all" is, IMO, just giving up - your teammates are too stupid to use tabs correctly, so you just outlaw them altogether, giving up on the actual benefit they have. This is so common that most editors even have clumsy workarounds for this, where they treat sequences of n spaces like single tab characters under certain circumstances - but really, this is exactly what tabs were designed for.
It demonstrates how textual communication channels (such as IRC, email, or reddit) and Python code are not a very convenient combination. Of course it is *possible* to paste Python code into reddit (I did it in this same thread), but apparently it's not straightforward; that's why this poster inserted "(tab)" to indicate indentation.
I think you are lacking ambition. What about going beyond JADE/HAML? Consider the following: * Inheritance. Django templates and Jinja's main selling point is template inheritance. I consider this a must. * How could I specify a tag attribute value from: * a context variable? * a context variable concatenated with some static text? * a macro? Jinja example: &lt;a name="section-{{my_value}}"&gt; * How could I specify a tag attribute **name** from: * a context variable? * a context variable concatenated with some static text? * a macro? Jinja example: &lt;img src="{{filename}}" data-{{my_html5_extra_attr}}="{{my_value}}"&gt; * How to specify multiple attributes/values from a dictionary? * How to suppress an attribute based on: * a context variable? * a macro? Consider those cases and we might be talking about a Jinja replacement.
This is tangentially related, but I figured I may as well ask here. Does anybody know of good resources for natural language *generation* , preferably using python? I ask because all I can find are highly-technical papers that I'm not at all competent enough to understand at this point. I realize NLG is a hard problem, but surely there must be some sort of tutorial *somewhere*.
Is there an NLP that plays nicely yet with the frequent abbreviations and txt speak found on twitter or other sources where formal English isn't the norm?
can you set placement numbers per project? 
here are the slides: https://speakerdeck.com/kitanata/superadvancedpython
One reason there tend to be less user-facing NLG packages is that there's no way to craft the tool that doesn't require you to know linguistics very well --- the input structures are going to be some sort of logical form, so I don't really see what you can do to get around it.
Any chance for 720p?
I like [webfs](http://linux.bytesex.org/misc/webfs.html). You find it in the repos of your favorite distro.
Things like this dialogue happening are why reddit is so fucking awesome. 
Right, right I see. Yeah I'd planned to have the interface from raw strings to a simple Python data structure. Usually I'm dismayed to have to deal with some library's classes to read the output. I've been planning to release a model that's intended to be a bit more robust to input variation. The research-optimised models are particularly weak that way, because usually in the literature we want to compare apples to apples, and one stable value for "apple" is "fully optimised" --- because there's a general understanding that the tweaks to make the system more robust are quite straight-forward. Unfortunately, those tweaks seldom actually make it into people's hands!
I also wrote about it once: [here](http://pythonadventures.wordpress.com/2012/03/21/lexicographically-next-permutation/).
Does he do anything else than explaining some more or less Python-unique features? What is the most advanced thing he talks about?
On SpkrBar. http://www.spkrbar.com/talk/11
Some interesting information, but not a great talk. 
Hi WallyMetropolis, I'm the guy speaking in the video. Could you tell me what exactly you didn't like about the talk, or why you thought it wasn't that great? Is there anything you would want to see in this talk that I didn't go over? I'm always trying to improve myself as a speaker and whatever feedback you could give me I would greatly appreciate. 
A [statistics tutorial module](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) in the top 10! I'm in good company...
I see. Maybe some list of contents with jump links in the description of the video would be nice.
Getting this: &gt;Not Found &gt;The requested URL /talk/11/ was not found on this server.
Works for me.
Interesting, it works now. I didn't purposely put the ending / there, it was added by Chrome when I clicked on the link (I think) but now when I try it, it loads properly.
I had a similar reaction, even after reading that it stands on the shoulders of those 2 packages. I downloaded the source and had a look: seems textblob *contains* NLTK and some other code. So I'm not sure how much it's "playing nicely" to also *ship with* NLTK... It would be useful to see some review of this, and specifically how it improves on these packages and what it has which wasn't there before. In general I do understand that it provides a simpler interface, e.g. from the samples in the documentation. But maybe reading the code is the best way to see what exactly it's doing :)
The link is broken.
Thanks for the feedback. Out of curiosity what would you consider 'super advanced' in the Python context?
The preparation was the thing that was the most distracting. There were many examples of 'do what I say, not what I do.' For example, saying: name your variable well instead of naming them badly like I have done. Or example code that wouldn't actually run. That kind of thing really takes away from a talk. I think a large part of the reason you had trouble describing some of the trickier things in the talk is because you didn't practice actually saying that thing, word for word. I got the sense you were just winging it. Depending on the audience, that can be ok. A more informal talk, you can get away with that. But if you want to film and and post it, maybe it could stand to be more polished. I hope my tone doesn't come off as insulting or something like that. These are just my thoughts on how you can improve. 
First time I hear of a dict comprehension. Mindblowing. Okay that's maybe an overstatement, but it fully justifies looking at those slides. Let's see what else they have in store...
Just a minor observation: you got the position of the "`&gt;&gt;&gt;`" wrong in the slides: in the python prompt they precede the input, not the output.
This is really awesome feedback Wally and I really appreciate it. Unfortunately even though I tested the slides as much as I could before the talk I missed some things. This was also the first time I've given this particular talk, and even though I practiced it quite a bit I lost my place several times throughout the talk. Next time I give it I will make less and less of these mistakes and it will seem a lot more polished. Thank you again for your feedback.
super advanced: * embedding CPython in other software * interact with non-Python software (libraries), especially writing callbacks in Python (i.e., hook Python scripts in OCI calls) * PyPying * monkey patching stdlib * automatic monkey patching of bytecode to optimize for speed / memory * autoreload all the elements in a big class hierarchy of a long running process on source changes * deploying Python programs as packages on hostile systems (IOS, Android, Windows..) 
Out of curiosity, why? I can see the argument for batteries included, but what's your personal reason for not using numpy and matplotlib?
agree, it takes experience to be good teacher
 python -c "import sys; print('\n'.join(sys.path))" pydoc site strace -e trace=file -- python -c "import difflib" 2&gt;&amp;1 | grep 'difflib' [EDIT] python -m site
1. Output for demonstrating the `compress` function is wrong. The output should be `[a, c, d, f]` instead of `[a, c, d, e, f]`. 2. Also, for some reason you are not using new style classes which causes `type(unladen_bird)` to return `instance` instead of `Swallow` which is a bit confusing for those who were expecting `Swallow`.
I see there is sentiment analysis included in the API. What are you using to train the sentiment analyzer? I would be worried about using the analyzer from domain to domain.
Why is this only recorded/available in 480p? &lt;insert "what year is this"-meme here&gt;
So the only thing I didn't know there was that you'd have to import from the package's namespace. That didn't occur to me, because it violates some very big rules in hierarchy, and I recoil from ever doing that. Affecting branches from their containing leaves is an *incredibly* bad idea when dealing with hierarchy, which invariably leads to constant frustration (when I change my package name I have to change imports in every test file?), and orders of magnitude more code to deal with the incorrectness. That explains the [frustrated, convoluted tech talk](http://pyvideo.org/video/1707/how-import-works) I watched by the guy who wrote 3.3's import ("conceptually the same as older versions"). I think it also explains the [horrors](http://lucumr.pocoo.org/2012/6/22/hate-hate-hate-everywhere/) of packaging. The packaging project maintainers spent [an entire talk](http://pyvideo.org/video/1731/panel-directions-for-packaging) essentially apologizing for the problems with packaging, and at the end literally answered the question "What *should* people use for now?" with "We don't know. They're all really bad." Sigh... Hopefully we'll figure this stuff out without such acrobatics one day. In the meantime, thanks for the pointer. It works, but I still things it's very wrong.
"Yeah!!"
Yup. As with anything: practice is key. 
I got about 15 minutes in and at least up to that point, everything you covered was either basic set theory or mentioned at some point in [the Python tutorial](http://docs.python.org/2/tutorial/). Perhaps you could've spent less time on warm-up?
Well, I was confused about your use of 'set'. You mentioned mathematical sets but you gave examples with Python sets. Python set elements must implement \_\_hash\_\_ and \_\_eq\_\_, so some things cannot be stored in Python sets. Also, there are oddities like set([0.0, 0, 0j]) =&gt; set([0.0]) while set([0j, 0.0, 0]) =&gt; set([0j]). Thus, you cannot have both 0.0 and 0 in a Python set, so your use of the Python concrete notation was either distracting or confusing. "For any set we can apply some number of functors to arrive at another set. .. Anything in Python can be transformed into anything else by simply applying functors to sets." Is that specific to Python? It sounds like it's true of any programming language. Why was this important to an understanding of Python? Can you write, in Python, the functors from the set of zero-like objects to the set of 10-like objects? What about to the set of integers? In any case, I didn't see how category theory was used to guide any of the latter understanding of Python, though I only listened to the first 20-odd minutes. You said: "How do you create unbound functions in Python? Lambda expressions" That isn't correct. Unbound functions are functions accessed via a class rather than via an instance. &gt;&gt;&gt; class Spam(object): ... def spam(self): ... pass ... &gt;&gt;&gt; Spam.spam &lt;unbound method Spam.spam&gt; &gt;&gt;&gt; Spam().spam &lt;bound method Spam.spam of &lt;__main__.Spam object at 0x100e40a50&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; class Eggs(object): ... x = lambda : 1 ... &gt;&gt;&gt; Eggs.x &lt;unbound method Eggs.&lt;lambda&gt;&gt; &gt;&gt;&gt; Eggs().x &lt;bound method Eggs.&lt;lambda&gt; of &lt;__main__.Eggs object at 0x100e40a50&gt;&gt; Also, it's not that a function is "part of an object." It specifically must be part of a class, as documented http://docs.python.org/release/2.3.4/lib/typesmethods.html . "Class instance methods are either bound or unbound, referring to whether the method was accessed through an instance or a class, respectively." For example, here I'll assign a function to an instance, instead of a class: &gt;&gt;&gt; class Spam(object): ... def __init__(self): ... def spam(self): ... print "Hi!", self ... self.eggs = spam ... &gt;&gt;&gt; Spam().eggs &lt;function spam at 0x100e39b18&gt; &gt;&gt;&gt; Spam().eggs() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: spam() takes exactly 1 argument (0 given) &gt;&gt;&gt; Spam().eggs(3) Hi! 3 and you can see that it's neither bound nor unbound. Also, functions defined in a module are not bound to a module: &gt;&gt;&gt; def foo(): ... pass ... &gt;&gt;&gt; foo &lt;function foo at 0x100e34230&gt; These function (which are neither bound nor unbound) have the module as global scope, but that's not the same as being bound to the module. I see that you are using Python3 syntax ("print(x)") but talking about Python2 methods ("iterkeys"). Was there a reason for that inconsistency? You didn't mention "from \_\_future\_\_ import print_function". In your filter example, you pointed out that the first example, with a list comprehension, was faster than the second, with a filter+lambda. It sounds like someone in the audience said that was because of the function call overhead of the lambda. You said that wasn't the case, because Python makes an unbound function under the covers in the list comprehension. That's incorrect, which you can see by doing a disassembly of the byte code: &gt;&gt;&gt; def filter_example(data): ... return [x for x in data if x % 2 == 0] ... &gt;&gt;&gt; import dis &gt;&gt;&gt; dis.dis(filter_example) 2 0 BUILD_LIST 0 3 LOAD_FAST 0 (data) 6 GET_ITER &gt;&gt; 7 FOR_ITER 28 (to 38) 10 STORE_FAST 1 (x) 13 LOAD_FAST 1 (x) 16 LOAD_CONST 1 (2) 19 BINARY_MODULO 20 LOAD_CONST 2 (0) 23 COMPARE_OP 2 (==) 26 POP_JUMP_IF_FALSE 7 29 LOAD_FAST 1 (x) 32 LIST_APPEND 2 35 JUMP_ABSOLUTE 7 &gt;&gt; 38 RETURN_VALUE There's no hidden function call here. (And anyway the use of "unbound function" isn't correct.) You mentioned how any() and all() work on lists. They actually work on iterators, not just lists. There was a question at 22:38 asking about using a counter variable in a for-loop, and the scope of a variable in a list comprehension. You replied: "Everything inside a list comprehension is scoped to that comprehension". This is also incorrect, and an unfortunate bug in Python 2 which has been fixed in Python3. Here I use Python2: &gt;&gt;&gt; x = [1,2,3] &gt;&gt;&gt; [x*2 for x in "abc"] ['aa', 'bb', 'cc'] &gt;&gt;&gt; x 'c' In Python3 this gives the more reasonable [1, 2, 3]. You could also infer the namespace leakage from the above disassembly, which uses a STORE_FAST and LOAD_FAST of the expression variable x. This is where I stopped. Overall then it felt like you didn't know the terminology or implementation of Python all that deeply, so you ended up leading people astray where you didn't know the limits of your own understanding. 
&gt; Heavily implies that repurposing a ghost-town port is unacceptable and incompetent behavior &gt; "I'm just trying to share some knowledge" Kid, we already know jaywalking is illegal. You don't have to try to evangelize this to us when we traipse across long-deserted streets in the name of minor convenience. We're aware of the letter of the law, we just have the common sense to comply with its spirit/intent instead of its letter. At some point you're just a drunk-with-power hall monitor, trying to enforce rules where they have no practical reason to be followed. Which, to be honest, no one would give a shit about any more than iRDMI, if you didn't go out of your way to antagonize the pragmatists. I don't know if you expected everyone else to conform to your own anal-retentive worldview, or you just wanted to achieve a personal moral high ground over everyone else (downvotes be damned), but that just makes you look silly. But even this, I would let slide without significant comment, if not for the weasely and self-righteous final comment, "I'm just trying to share some knowledge." That's just the icing on the entertainment cake. It's like you're trying to get the cease-fire of an apology, in the most snooty an non-apology way possible, and it's not like it's even a situation that deserves an apology in the first place, just some sort of live-and-let-live statement that doesn't have its head up its own ass. I honestly don't dislike you, I'm just a person with a bitter streak/penchant for calling people out on their bullshit. None of this matters a jot, and that's kind of the point. Learning what to care about and what not to, is a pretty important part of being a successful engineer in any field. If you're sweating small stuff like running a temporary HTTP process on port 8000, you will die of a heart attack before your 40th birthday. And that would be sad. So try not to die. tl;dr: Your silliness amuses me, but I do not wish you ill, I just like making fun of people
&gt;what do you mean by 'generation'? it's a broad topic with a large number of sub-domains. That probably explains why my google-fu is failing me. I'd like to generate *meaningful* speech. At a minimum, it should do the following: 1. Not be ostensibly computer-generated 2. Summarize a large body of data (though *not* necessarily text) 
I have a bit of a psycholinguistics background. Could you suggest some reading?
It's such a shame the link does not have a positional description for each entry.
I'd consider the bits on metaclasses fairly advanced, but the rest I'd rate as "intermediate." Not that I'm a particularly advanced Pythonista myself.
I don't know how I feel about seeing things like this. Yep, another library where somebody wrapped some very simple functionality into Python. Is this really controlling your projector with Python? Because it looks more like controlling my projector using the RS232 port. I'm happy to see things where Python uniquely does something well, or where somebody brings functionality into a Python library which makes daily tasks much easier. 
This is awesome and all your points are valid and very valuable feedback. I will incorporate this knowledge into the next time I give this talk. Thank you. Seriously. Thank you. &gt; For any set we can apply some number of functors to arrive at another set. .. Anything in Python can be &gt; transformed into anything else by simply applying functors to sets." &gt; Is that specific to Python? It sounds like it's true of any programming language. Why was this important to an understanding of Python? Thats true. I tried approaching the talk though from the perspective of someone who has never done functional programming. The point was that via functional programming concepts you could solve nearly any problem you were facing in Python. At the beginning of the talk the "Proof" I presented could apply to any object oriented language with first class functions. &gt; You said: "How do you create unbound functions in Python? Lambda expressions" &gt; That isn't correct. Unbound functions are functions accessed via a class rather than via an instance. I should have said anonymous functions. Edit: I think a lot of these errors is from my attempt to bounce between Python 2 and Python 3 and I think to keep thing simpler next time I give this talk I will only focus on Python 3.
Sure, I guess I should just go throw out my and the team's AutoCAD (that I began automating via IronPython) and Windows-only engineering analysis programs and enroll people aged 50+ who don't know what command line is into a Linux course. P.s. Stuff like this was a recent exercise of my interns using a Python script implementing a highly configurable geometry processor and AutoCAD export-import files, all Windows. They are not even halfway through the LPtHW and I'm not even a real programmer. Python rocks on any platform. https://trello-attachments.s3.amazonaws.com/503f3987c89e718e4f9793c0/5200eef3041905470a003312/c362e42defc816a34262a6cff600e6fc/ScreenClip_%5B4%5D.png 
&gt; those out to get the phrases into the talk, and then you weaken it ("when I say set, I mean list") and then let it drop without showing something cool that results from considering sets of python objects. I agree with this whole heartedly. Unfortunately I didn't catch this error until I gave the talk (and actually if you watch me, I get stuck for a minute while I realize my mistake). The problem is that category theory works with any collection of objects not just sets and I was trying to go from thinking in collections to thinking in running some number of functions to transform collections into other collections until arriving at a desired result. My attempt here was to help those that haven't done functional programming to modify how they think about working with datasets but I believe I did a huge disservice by the technical errors in the presentation. 
I also wanted to say that my understanding of bound/unbound methods in Python was completely skewed. For some reason I though binding referred to scope. I will definitely avoid this error in the future.
done!
Valid points, I will definitely use as much as data to an extend. But for starters, I tried to keep it simple. would you care to create an issue and write some of your ideas ? https://github.com/pythonhackers/pythonhackers Thank you so much! 
I dunno. Because it's easy to take [a github search of python repos sorted by stars](https://github.com/search?q=stars%3A%3E1&amp;type=Repositories&amp;ref=advsearch&amp;l=Python), display it pretty and get to the top of /r/python with minimal effort?
That's awesome, thanks for the quick traction :)
Sorry if this was mentioned in the beginning, but I couldn't find it. Will any of these features not work in Python 2.x?
Like others have said, I don't want to import a titanic library just for some basic functionality. 
You're right that this isn't much more than a wrapper around PySerial. Sure, you're communicating over the RS232 port. This isn't a large project at all. That said, I had a need for this. Now that interacting with the projector is simplified, I can move on to setting up my phone to act as a remote control (via speech commands using Tasker). In short, this was useful for me, and I'm sure there's others out there in a similar situation. I put the code online for them to use, if they so choose. What's wrong with that? That's part of the reason I love Python (and the large ecosystem of libraries) - if I want to do something, I can quickly make it happen. They usually aren't giant projects, and they usually aren't earth-shattering, but they are always useful. Plus, I get to play around with cool things (like attaching methods to the object at run-time). I'll keep uploading the small tools I make, and if even one person finds them useful, I'll be happy.
can't find it, will clean testing ever be mine!? * and even if I could it seems that its not maintained anymore. :(
Kivy is 66! On the rise!
Don't forget the value of the config library. There may not be a lot of configs at the beginning, but the abstraction is going to become very nice over time, because new users don't have to reverse-engineer their projector's serial interface to control their projector.
The 349kB executable includes webserver with lua dynamic pages and sqlite3 embedded.
I could be wrong, but aren't these almost always provided in the manual?
I guess the saying "if all you have is a hammer, everything looks like a nail" doesn't apply to everyone... Some tools fits best the job than others. Keep mind open for available technologies.
Most will work in Python 2.7+
Please keep on pressing the pagination links ( 20 times at least ) while I write my answer. 
I just noticed this. Thanks. By the way, I've made a new version (1.0.0) and linked to your site in the readme.
Do you have a reason for this comment (aside from hassle when renaming files): &gt;So the only thing I didn't know there was that you'd have to import from the package's namespace. That didn't occur to me, because it violates some very big rules in hierarchy, and I recoil from ever doing that. Affecting branches from their containing leaves is an incredibly bad idea when dealing with hierarchy I don't get why it's problematic to have to use fully-qualified imports in packages - you're going to hit problems with renaming either way. Say you have three subpackages in your library, and each has a `common.py` file that holds import elements for them. If you just have `import common` - you end up with different behavior based upon which directory you are in if you move the file. In contrast, if you do something like `import subpackgeA.common as common`, it makes it clear what's going on.
Did you really read all 400? be honest.
I would start with a class on probability and linear algebra. Most tools rely heavily on these. No escaping it.
&gt; `55. Play framework` wat?
I was also wondering the same thing :) look at the source code.. Interesting
Really interestin project mate. Congrats
i was going to be boss and send a pull request, but lost interest really quick. http://developer.github.com/v3/search/ &gt; sort &gt; Optional Sort field. One of stars, forks, or updated. If not provided, results are sorted by best match. the 5 minutes I spent looking at what is possible on this, I couldn't think of any qry that would be useful. So nevermind. you don't have much to work with here because of the limits of the github api. I was thinking watchers would at least be a better measure than stars. But you can't sort by # of watchers. 
http://github.com/thekarangoel/Projects is #16.. I'm actually doing all of them now!
I'll second the projects list! It's a great way to dive into a language. I'm currently going through them with Scala. It's a fantastic little way to get your hands dirty with a language. 
Somewhat surprised QIIME isn't up there considering how many microbial ecologists use it, but I'm assuming it isn't classified as purely python based project. 
Did you submit the wrong link or something? This article has nothing to do with Python or programming in general, nor does it have anything to do with where people click and where they pay rent. o_0
Yay living-in-at-least-the-year-2008!
[Ansible](https://github.com/ansible/ansible) should be on the list. It's written in Python and has 2546 watchers placing it at position 15.
The only projectors I've had much experience with were at my school, and at my job. In both cases, I would be surprised if anyone would be able to find the manual in a timely manner, or really have any idea whether it hadn't just been thrown away years ago. So yeah, if you still have the manual on hand and you don't mind putting in serial commands directly like a foreign tourist awkwardly wielding a phrasebook, then the only advantage you get from pyjector is a nicer API, at the cost of initial time investment. But even then, you can submit a pull request with your work, so the next guy with Brand X Projector will find that pyjector works out-of-the-box.
&gt;That's like saying 1.0/3.0 * 3 should be equal to 1.0. It should. It happens in Cobra by making Decimal the default real number representation. :-) 
&gt;You can do symbolic math instead of doing the math directly Then that's what we need... in hardware. Where do we file IEEE Enhancement Proposals? 
&gt; And now I'm very sad. Don't. Let's see how other languages are doing: 1. Java/JVM: Fine grained locking. Requires a huge ass VM and longer warm up times 2. Perl/Tcl/Lua: Not native threading. One interpreter per thread 3. Ruby(MRI): GIL 4. NodeJS: No threading support. [Sauce](http://nodejs.org/about/). It's either multi-process or Fiber, just like Greenlet in Python. 5. Go: LOL WEBSCALE LANGUAGE WHERE GOMAXPROCS == 1 all the time. 6. C/C++ Handling data structure lockings manually. malloc/free/segfault like a hundred times per run per debug build. Conclusion: GIL is an extremely overhyped problem. GIL as a matter of fact, can be avoided. GIL will be released in CPython during IO wait, or explicitly in ctypes/C modules. 
[PRAW](https://github.com/praw-dev/praw) made it at #310!
Can you provide an ELI5 `threading` vs. `multiprocessing`?
1. not much difference in Linux 2. if you want zap performance out of CPython using threading or multiprocessing, you are probably doing it wrong.
good to see [storm](http://github.com/emre/storm) is on top 200! :)
thanks.
Nice to see Flask about to rape Django's ass...
with 40 stars left behind a bit.. It's marked as a Python project in Github though..
Aw. Unittest isn't so bad. But if you want something cleaner, try pytest or nose. pythontesting.net has intro posts on all three. It's a good place to start. (Shameless plug for my own site.)
interesting that Github doesn't consider Ansible. Shame on you Github!
There's also set comprehension, which looks just like list comp with {'s, or like dict comp without :'s. That is set([1,2,3]) {1,2,3} {x for x in range(1,4)} all produce the same set.
Vouch for this, py.test is awesome (if only pytest-sugar would work for me)
Well, C and python are very different. Python is designed to be a higher level language and has a ton of shortcuts because of it. You can find a palindrome in two lines in alot of languages, including c++.
Saying that something "stands on the...shoulders" of something else, and "plays nicely" with it doesn't really say much. If you don't want to answer the question and explain how TextBlob improves upon or goes beyond NLTK that's fine, but there will be people (like me) who might be somewhat interested but simply don't have enough hours in the day to be digging into every package that someone claims is worth checking out. Good luck.
For scientific development Ruby is a no-go. Not enough math/bio/stats libraries, at least nothing as fleshed out as Scipy/Neo.io/NEURON/NEST.
If you ask me, both programming languages are pretty much equivalent in every significant way. It basically comes down to library support for the thing you want to do.
&gt; I would be surprised if anyone would be able to find the manual in a timely manner, or really have any idea whether it hadn't just been thrown away years ago. Uhm ... internet? If you have the need to control projectors then sooner or later you'll write some kind of wrapper because you're getting tired of writing things like `~sB85\r` to set the brightness. This becomes even more important when you need to control multiple projectors.
Some of us are in corporate environment that require use of Windows. And sometimes IE as low as 6. So, yeah, it's nice to use Linux, but it won't give me a job.
So what's all about this end after yield in python example? Also self is not required. I personally use _ instead
No kidding? I'm working on the exact same thing and I'm also using pyserial. The code for controlling the projector was finished months ago. But I will definitely look at your code (and maybe do a little review :P). There's one big problem that I saw immediately though. Here at work I have two device models, an InFocus and an Acer. The Acer one is really crappy. The serial interface is basically mirroring the hardware buttons which means that you can't set absolute values for brightness and contrast and so on. Even more pain was caused by the fact that you can't get the current values of these (no status query). The InFocus one is much better. You can set absolute values and you can get a status back. But here's the problem with this model and your project: how do I write my config? E.g. for brightness which can have values between 0 and 100. Do I write my config like this?: "brightness": { "command": "~sB", "actions": { "0": "0", "1": "1", "2": "2", "3": "3", ... "100": "100" } } I ended up discarding the idea of such a config file like you have and started implementing it as a plugin system (although not a very good one :P). Here is what the InFocus plugin looks like: https://gist.github.com/dAnjou/c93dca05c091d68429a4 ([the command reference](http://imgur.com/a/BXqht)). I'm using this very neat validation library [schema](https://github.com/halst/schema) to validate **and** convert incoming commands from JSON to a Python dict.
Like this? class Foo(object): def __init__(_, bar): _.bar = bar Why would you not use `self`?
I've been doing the Ruby vs Python dance for a while, and while I greatly prefer Ruby I have decided to focus on Python. For two basic reasons, focus and community. Python's community is larger and more active. Ruby has been almost completely hijacked by Rails. Don't get me wrong Rails is awesome, but its turning Ruby into a one trick horse. If the ruby community gets its act together, Ill probably switch back.
Yep. Coz self is 4 char and mess up my mind a bit, while _ is distinct
I'd still recommend using *self*, both because it's the convention (and doing otherwise might confuse readers of your code), and because _ has other conventional meanings (which might also confuse other readers, and clause clashes for you in the future): In the interactive shell, _ holds the result of the last executed statement. _ is often used to indicate a throwaway / unused variable, as in the following django snippet: # get_or_create returns a tuple of form (object, created) # if we don't need to know if the object is created, we can just do: user, _ = User.objects.get_or_create() _ is also often used as a shortcut for the gettext family of translation functions (e.g. from django.utils.translation import ugettext as _). 
&gt; Your approach seems well thought-out though Not really. I'd rather have a config file like you and I did some research. But I didn't find a config or schema format that was simple and easy enough to read and write (even for non-programmers) but also powerful enough to handle these different kinds of possible values. Anyway, for my project it won't be a big deal really. We can just buy the same projectors again and again. So I guess you can say that we have the input under control :P
It is very similar to a lambda in other languages. But a block can have control flow inside of it. For example, you can have a break inside a each block.
better than to perpetuate 2.7 ad infinitum, no?
Originally youtube itself was written in python, not sure how much of that code is still lying around.
something something escalated quickly.
You mean that it can have flow control that works in the containing scope? Perhaps a `break` that works in a `switch` statement mapping states to blocks? If you mean only that it can have flow control inside of it, then I still don't see a difference from other first class functions. I use flow control in my JavaScript functions all of the time and pass them about, as one can blocks.
I get a "Sorry, invalid Syntax" error when I submit https://github.com/kopf/ahye/blob/master/ahye/views.py . Croaking on the split lines or the decorators or something?
I have just about 0 interest in this, sans source.
Just wanted to say thank you for putting this all together. It's been a really big help for me in understanding python
Flow control is usually out of scope from a lambda, but it is a common approach. Objective C does the same. 
Nah i hate the convention, like that 80 char length when all monitors are at least 1920x 1080 in our office. I want it to be easy and readable and noticeable, moreover we don't use django. If i could i would use either tilde or a number sign, but those are the python language limits...
Are there any Bayesian libs for Ruby? Just curious.
I'd say it's a very biased article: *"The Ruby code uses less characters so probably has the advantage"*. Come on. Cause to me most of the examples are more readable/understandable in Python. I remember there was some graph showing that Ruby is more human-readable language than Python. Seriously? How is that: items.map{|i| i + 1 }.select{|i| i % 2 == 0 } More readable than this: [i for i in [i + 1 for i in items] if i % 2 == 0] I dunno...
Okay, so blocks aren't restricted (read: broken) lambda implementations, but I still think that they're just functions. SmallTalk does the same thing with its [block closures](http://syx.berlios.de/doc/manual/html/Block-closures.html) (probably where Ruby got the name), which is why I'm wondering.
Pure lambdas aren't "restricted" nor "broken", they do not have flow control because you can have it using other language features (in Scheme you use continuations). Of course, there are languages (such as Java) that don't provide either. And Python's lambdas are just too simplistic. But yes, that's the only difference between an anonymous function and a block. All else is similar.
It depends on your background. Personally, I think Ruby's version is more readable, because I'm used to languages that use lambdas and high order functions a lot.
&gt; Rails it's just a web dev framework like django right ?
Except Django isn't all-consuming of the language and its community like Rails is.
&gt; Nah i hate the convention, Then I hate you. The 80 char limit (now 100 if it makes code cleaner) is so you can have multiple editors side by side. is self so hard to type? Just set up your editor to complete `s\t` into `self.`. You'll type the same amount of characters. Not being able to use a number sign as a variable name is not a python language limitations, it's an almost universal in all languages. I'm really grateful that I don't have to work with you. 
I don't know any ruby (but know lots of python) and I think the first is more readable than the second. I would leave the first as is in ruby while I would totally turn the second into nested for loops. I think for me the main problem is the repeated use of `i` in the list comprehension. It troubles me for some reason.
Very cool! Really liked the homework on how this emerged and what the alternatives look like. I'd love to see a catalog of various id generation methods along with attributes like: ease of configuration/deployment, reliability/availability, id size, collision probability, etc. Next challenge - do it as a 32-bit number! :-)
EventGhost for windows is pretty awesome at this sort of thing. It uses Python for scripting too. 
I'm also not talking about Lambda Calculus, I'm talking about lambda in programming languages. "Lambda", in this sense, is an anonymous function. Blocks are basically lambdas with flow control (your example is also a lambda that can may have flow control - I don't understand that much about JS). And I'm also saying that a lambda without flow control is not necessarily broken. Scheme can have flow control with continuations, but this is not part of the lambda itself.
Yep. I was specifically referring to the ability to "inline" the function definition where you need it, as in his example, vs needing to write it out elsewhere to use it.
What is fundamentally broken about that example is that you can easily `map` and `filter` in Python as well and then it will look very similar to the other example. A number of these are structured like that.
Yea, I am a Python guy, and I don't care for the implementation of lambdas in Python, but as you say, who cares? I do wish that we had a function expression, but oh well. Thanks for answering my question, by the way. I thought that I had the right of it, but I wanted to confirm. I know exactly zero Ruby.
&gt; Same for @ vs self. when referencing class member variables. The Ruby code uses less characters so probably has the advantage. Yeah I hate readability too... &gt; puts i So put just does i + "\n" pretty much right? Why is it not called print? Furthermore why isn't this pointed out as not readable as the author is so quick to do with Python problems? I also love all the comparisons without mentioning Python's filter and map functions while at the same time comparing them to Ruby's filter and map functions. ------------- I love how biased the author is for this "comparison". They point out things wrong with Python but don't mention a single problem with Ruby? This just seems like a pissing contest between languages. Next time perhaps write about something useful. Like perhaps about the languages strengths and weaknesses and particular libraries that are really good in each language. Give us a use case. Don't just write an article about Pythons "weaknesses" compared to Ruby. 
I started working on ruby with a friend and was amazed by the multiplying way they have of making methods. For instance, ruby has `for...in` but it also has a `.each`. There are two different notations for ranges (inclusive and exclusive), and myriad unexpected methods for other things: `unless` (instead `if not`), `upto` (instead of the aforementioned range), etc. It all seemed philosophically messy to me, like they just let whomever patch in whatever tool seemed most useful at the time, and did not imply the same rigid philosophical framework that the python community has adopted. I'm not an advanced developer and, admittedly a huge fan of python, but that's what struck me. Lastly, a lot of the examples in the piece are poorly constructed: python has `map` and `filter` as well. 
Because a lambda is just a function without a name.
It might be for older python where print is not function yet. But I'm not sure. I got "Sorry, invalid syntax" on valid code too and quickly became uninterested
An extremely common noob error I see at /r/learnpython and /r/learnprogramming is running Py3 while learning from a Py2 tutorial or vice versa. These are the signs right off the bat: * `print` often produces a `SyntaxError` in Py3. * `raw_input` produces a `NameError` in Py3. * `input` likely produces a `NameError` in Py2 if the user enters a word. * `input` enventually results in the `3 == '3'` error in Py3 if the user enters a number. I really wish the very first lesson in every tutorial consisted of: * The appropriate Python version number in large, bold font. * Where to find the appropriate Python version, again in large, bold font. * Launching a command line and running `python --version`, again in large, bold font. 
Please do! If not anything, it brilliantly show cases the use of ipython notebook (along with python of course) in scientific computing. I'm already in the process of evangelizing as many of my colleagues as possible... very exciting times!
The author wants an immutable type, and tuples are immutable. Using `collections.namedtuple` is an option, but defining a `Node` class would be overkill. 
Excepting that a lambda cannot do flow control apparently (I'm not finding any literature on this), which makes a block the exact same as a function, which is why I was comparing to that.
A function also can't do flow control. I'll try to make myself clearer. Having a "break" inside a "each" block in Ruby is permitted with a block: foo.each { |i| break if i == bar } But if you create a lambda (Ruby also has them), a "break" would be meaningless foo = -&gt;(i) { break if i == bar } Just like this would be meaningless: def foo(i) break if i == bar end So the lambda behaves more like a function, where the block can control the flow of the outer scope. This is another good example: def foo(bar) bar.each { |i| return i if i.baz == 2 } end The return in the block would return from the *method*, because a block allows that. If this where, let's say, Java 8, that wouldn't work and would give a compiler error (supposing an "each" method existed in a Java list, of course): Foo foo(List&lt;Bar&gt; bar) { bar.each((Bar i) -&gt; if(i.baz==2) { return i; }); } Because the flow control "return" in the lambda would return from the *lambda*, not from the *method*. Since the *method* doesn't have a return statement, the compiler would give an error. Likewise, a return in a function returns from the *function*, not from the outside scope. That's what I mean when I say that a block can have flow control, and that's what it makes it different from a function or a lambda.
Looks like an HTML escaping issue.
It is nice aim at precise results for statistical function, it would be even better to aim for exact results (including the estimated error on the results) https://pypi.python.org/pypi/uncertainties/ 
&gt; Even so, the use case in my head is "hey, we lost the projector remote," In our case it's a media facade that uses rear projection onto screens.
Also Numba and Numba Pro.
Well when there's 5 calls to class method or var in line it does mess you up.
Ah. Yeah, I can see how that would be a lot more reasonable to just serial-control from Day 1.
Okay, that makes entirely more sense; it's what I [first thought](http://www.reddit.com/r/Python/comments/1k74jb/ruby_vs_python/cbm3aa6). Example code is the best way to handle these sorts of discussions. I still think that this isn't entirely useful behavior as the same thing can be handled by returning from a function instead of breaking in a block. I'd be willing to bet that if I had that feature, I'd find uses, though. Thanks for having the patience to explain it to me!
Rails was far from alone in popularising Ruby: the other major driver was the Pickaxe book.
Not really, there were *some* people using ruby, but it was largely popularized by Rails.
This article seems to catch the issue, but only by accident. The difference between Ruby and Python is that, in Ruby, there are a *million ways* to do the *same damn thing*. I never wanted this feature in Python. If Python had it, then there would be a hundred guides out there that recommended using it, and tutorials on how to use it, and a pile of other crap to learn standing in between me and my code. When I ask how to do something in Python, there's much closer to *one* answer. Obviously, there's more than one answer, sure. But... There are only a few good ones. And I'll get one of those, and be like, "yeah, I know what you're talking about!" rather than, "well, thanks, you just introduced me to another day's worth of documentation to sift through."
In the example you gave, I think the Ruby is easier to read. The Python would be more readable as [i + 1 for i in items if (i+1) % 2 == 0] 
It's not *quite* an anonymous function. Ruby has two different types of blocks: procs and lambdas. Your general block is equivalent to a proc, but you can get a lambda via the lambda keyword (or the newer -&gt; syntax). The most pertinent difference between the two is what `return` does. In a lambda, `return` just returns from the lambda itself. In a proc/block, `return` causes a return *from the enclosing scope outside the block*. I don't know how you'd do that in Python.
You and me both!
&gt; There are only a few good ones. Assuming there are *any* good ones. Take class method definition, for instance. There are at least three different (practical, non-metaprogramming) ways I can think of doing it in Ruby, and I've used all of them in different circumstances to make the code read better. In Python I've sometimes designed around needing them at all, because the "one true way" to use them makes it clear they were an afterthought.
&gt; "The Ruby code uses less characters so probably has the advantage" Machine language is clearly the most advantageous to code in.
True, we could say that Rails wouldn't have existed without the Pickaxe, that doesn't change the fact that most people started doing ruby because of rails, not (directly) the book.
Yes, this is totally the best way to write it. Flat is way better then nested in this case.
I don't think you've ever coded in machine code. Machine code uses way more characters than any high level (or any level above machine code) language. (It's a horrible experience, don't try it at home)
scikit-learn
So it's like UUID, but 64 bit instead of 128 bit, and continuous instead of random?
&gt; That didn't occur to me, because it violates some very big rules in hierarchy, and I recoil from ever doing that. Affecting branches from their containing leaves is an incredibly bad idea when dealing with hierarchy, fortunately you can just use [relative imports](http://www.python.org/dev/peps/pep-0328/#guido-s-decision): from . import bar I'm not sure what import issues have to do with packaging. 
Yeah.. I'm completely amazed that after going through the exercise of writing this entry, the author still prefers Ruby. I think some people truly do enjoy complexity (look at the abundance of complex board games/video games). I do not (if I play a board game, it's going to be Go). Ruby is great for those people. I enjoy solving problems using as few steps as possible, and I certainly subscribe to UNIX philosophy. I love python because it gets the hell out of my way and lets me solve problems.
You can use a framework like [Flask](http://flask.pocoo.org/docs/) or [Django](https://www.djangoproject.com/) Flask is very minimal and light weight, it's one of my favorite frameworks. A minimal Flask application is as small as this: from flask import Flask app = Flask(__name__) @app.route('/') def hello_world(): return 'Hello World!' if __name__ == '__main__': app.run() Django is bigger and more complex, but it's a popular choice.
 newitems = [ i + 1 for i in items if i % 2 == 1 ] Is that against the spirit of the exercise? Or since you're not really worried about performance anyway (using python or ruby): newitems = [ i + 1 for i in items if (i + 1) % 2 == 0 ] 
I agree entirely. When I read "There should be one-- and preferably only one --obvious way to do it," I felt like I was home. By contrast, Ruby appears to take a fundamentally different stance. (Seriously, though, why would you ever need an `unless` as long as `if` exists?)
&gt; Bayesian libs for Ruby [Sort of.](http://classifier.rubyforge.org/) It's not very good though.
So why not just give print optional arguments like python does?
You'd have to type "lambda" all over the place and "chain" parentheses instead of chaining dots, which is somewhat less elegant and has a big shortcoming of forcing reader to "read-execute" the line backward: filter(lambda i: i % 2, map(lambda i: i + 1, [1,2,3]))
Wow I hope you're the only one who codes and will ever read that code. Conventions are there for something, interoperability for one.
filter(lambda i: i % 2, map(lambda i: i + 1, [1,2,3])) Idioms * forelse * swapvalues * readfile * variables Uhh... I fail to see the meaning of it.
Thanks!
&gt; Besides what if my editor is not constant. &gt; having multiple monitors is a must have then. So your argument is really outdated How can you assume that I have multiple monitors all the time, when you don't even have access to the same editor? I use a laptop, and I carrying multiple displays with me is not feasible. I also do just fine with them, as the code I write and most of what I read is written by sane people. As for outdated, with the ubiquity and power of mobile devices, my argument is far from outdated. &gt; If it's notepad self kills you. It absolutely doesn't kill me to type `self`. &gt; I ll release all my oss with _ instead of self and without pep8 complience. Please do so. And send me a link to it will you? I'll gladly clean it up for you, and send a pull request. &gt; Just so we can see what would catch on better. Comfort or crazy oitdated norms of 20th century Lol. PEP8 already won. It's the standard. It's not the norms that are crazy, but you. &gt; That's fine for me, because I m the guy who orders work, not who works with. Would you mind stating where you work, so I can avoid any products you make?
It would be blasphemy if Python was religion. It would be blasphemy if the code would protect 'self' as the one and only reference to the class, like in Ruby for example. But hopefully that is not the case. When I asked Python devs about changing the self to something smaller and more comfortable, they suggested changing self to another var name. So I'll stick to this without zealoting and you can be inquisitive about whatever you want, as there are no rules written in stone on this example. Even Pep-8 is a guidance and not a rule.
Thanks! 
&gt; It absolutely doesn't kill me to type self. Well it kills me, I'm dying here, please help it's 'self.run(self.ast(self.code[self.compile(i) for i in self.data]))' zombie virus... &gt; Please do so. And send me a link to it will you? I'll gladly clean it up for you, and send a pull request. But will I accept? It's crazy how a simple _guidance_ brings so many minuses to karma here :). Hopefully the number of fucks I give about it will raise a ZeroDivisionError if divided. &gt; Lol. PEP8 already won. It's the standard. It's not the norms that are crazy, but you. Won what? A medal? It's not a standard, just a guidance, which everyone on this reddit obviously drools over. About crazy norms of 20th century is the vt100 width used by PEP-8. &gt; Would you mind stating where you work, so I can avoid any products you make? Why would I do that? :)
But are we arguing short-ness or readability? Because you could easily define the functions and then avoid the crutfy-looking aspects of anonymous functions: def is_even(num): return num % 2 == 0 def add1(num): return num + 1 filter(is_even, map(add1, [1, 2, 3]))
Why? I think the decorator is very simple and nice to use.
True. However every time this is thrown in a language comparison thread I can't help but feel this is a defensive "hey look, Python is top-class in something!" way to win an argument. I mean, what percentage of development falls into scientific development that merits bringing it up on every language discussion? Reminds me of people clamoring "but but {SML|Haskel|Clojure} is great for writing parser generators!". Awesome, but chances are you won't sell me on this one. Disclaimer: I am a Python programmer that has done a bit of "scientific computing" over the years.
This looks awesome. I'll be in need of distributed ID generator for one of my projects soon and I'm definitely going to give Simpleflake a shot. Thanks for sharing!
So it's exactly like /r/python?
Thinking about it as a percentage game is incorrect and misleading. Instead, it's best to think about it in terms of published literature. After all, that's what actual science is about. In my field, for instance, a quick search through [Frontiers of Neuroscience](http://www.frontiersin.org/SearchData.aspx?sq=Python) shows that Python is alive and well in terms of producing cutting-edge research material. [Good luck trying to find anything published using Ruby](http://www.frontiersin.org/SearchData.aspx?sq=Ruby). And since we're talking about how much Python is being used in "scientific computing", why not [look at this paper describing this very phenomenom in Neuroscience?](http://www.frontiersin.org/neuroinformatics/researchtopics/Python_in_neuroscience/8). I don't think I need to remind you that Neuroscience as a whole is neither a small nor insubstantial field, in terms of publications, labs, and above all funding.
Fair point, sorry, should have linked to: https://github.com/zhaowen901/pythonidioms
Good suggestion, thanks.
Do you know any good resources to learn javascript besides code academy?
Good question. I'll say I don't know, but I do know that it is python 2.7.5, and uses the standard library parsing routines. I have also commented before that it should say upfront that it is python 2.7 specific.
Think about what that statement tells you about how it was designed: Python puts *decorators* ahead of *class methods*. Class methods don't get any particular syntactic convenience, they're shoe-horned in with a bit of functionality that just happens to be able to implement them.[0] This despite the fact that there's a nicely intuitive hole in the syntax which could have been used instead... class MyThing: def foo(class): pass Wouldn't that be nicer? Or class MyThing: def MyThing.foo(self): pass I'm glad python 3 has tidied up class method `super()` calls though, because that used to be a right pain. [0] Actually, I suspect this isn't the story. I suspect that class methods were difficult to get right (or just plain difficult to argue convincingly for), so nobody tackled them properly for ages, then the `classmethod()` hack became widespread enough it became the de facto standard and was retconned into being the Right Way All Along.
nope
Nope. I'd be happy to help you if you wrote most of the code and just needed some guidance and/or simple help with the code.
.lower()
im completely lost I don't even know how to start it but thanks anyway
I would appreciate it if you would help I could email you my assignment and you can show me where to start
Not sure if trolling or what... PM me. I'll guide you through them if you're willing to think, but I will not do them for you.
can I email you my assignment so you can take a look at it and see where i need to start
PM me with the assignment and your "concept" and I'll tell you if it's the right approach to solving the assignment and if not I'll point you in the right direction. Or you could post it in this thread so that more people can look at it and maybe help you out.
thank you I appreciate it
In this assignment you will build a stock portfolio manager. The manager program will consist of 3 dictionaries. 1.The first dictionary, called Names, maps the stock symbol to the company name (example: "GM" maps to "General Motors"). 2.The second dictionary, called Prices, maps the stock symbol to a list of 2 floating point numbers corresponding to the buy price (the price the user paid for the stock) and the current market price (the price the user could sell the stock for today). 3.The third dictionary, called Exposure, maps the stock symbol to a list of 2 floating point numbers, corresponding to the number of shares purchased, and the risk associated with holding onto the stock (i.e. How likely the stock is to gain value in the future). Your program should consist of the following functions: AddName - Asks the user for a Stock Symbol and Name pairing then adds it to the Names dictionary. AddPrices - Takes a Stock Symbol as an input parameter, then asks the user for the Buy price and the Current price of the corresponding stock, adding them to the Prices dictionary. AddExposure - Takes a Stock Symbol as an input parameter, then asks the user for the Risk and Shares of the corresponding stock, adding them to the Exposure dictionary. AddStock - Calls AddName, AddPrices, and AddExposure to add a new stock to the portfolio. GetSale - Finds the maximum expected value of selling a stock. The expected sale value of a stock is the current profit minus the future value of the stock: Expected Sale value = ( ( Current Price - Buy Price ) - Risk * CurrentPrice ) * Shares The GetSale function should calculate this value for each stock in the portfolio, and return the stock symbol with the highest expected sale value. Main - Should take no arguments, but present a menu item consisting of "1. Add Stock", "2. Recommend Sale" and "3. Exit". If the user selects '1,' the Add Stock function is called, and when it is complete, the menu is presented again. If the user selects '2,' the Symbol of the stock corresponding to the highest expected value (returned by GetSale) should be displayed, and the menu presented after completion. If the user selects '3', the program should end. 
With lots of data being created, there is a high demand for data analysts/scientists. Python has several mature tools in this regard. I think people weigh programming languages too much with regards to how they fare in web development. There are several important uses cases outside of web development which happen to be also scientific computing and statistics related.
For the most part you just need to know how to manipulate dictionaries, lists and get user input which almost any basic tutorial should cover. As far as where to start, once you know how to work with (basic) dictionaries/lists make required dicts and fill them with data then start by writing functions one by one, start with ones that don't depend on other functions e.g. write `add_stock` last because that one calls `add_name`,`add_prices`,`add_exposure`. Once you have all functions written write the `main`/menu part then (if needed) fix bugs.
This is a stupid mistake I have made. I have fixed it and now it works. I replaced all "&lt;" and "&gt;" to "&amp;lt;" and "&amp;gt;" to support HTML tags in the code. I did that too early before checking syntax.
**def**: This is used for defining a function. A basic definition of a function is a repeatable progression of steps to get to a solution. def hello_world(): print "hello world" Every time you call the above function, it will always print hello world. **if**: if is what you will use for certain conditions. For example, if you pass the number 1 to a function, it returns True, otherwise it's false. Think of else as "what do I want to happen if it doesn't match my if statement". def is_true(num): if num is 1: return True else: return False **print**: This just means it will display whatever variable or datatype you pass to it. print "Hello World" displays the string "Hello World". print num will display the number you assigned to it. **list**: a list is an array if you've dealt with that before. Just think of it as a long list of sequential mailboxes you can put stuff in. There are some limitations to that analogy but that's the general premise. So if you take 3 words ("My, "name", "is") and put them in some list (my_list). Then my_list[2] will be "is". This is because lists start count at position 0 which means my_list[0] is "My". You can declare a list like so: my_list = [ ] or my_list = ["My", "name", "is"] **dict**: A dictionary is similar to a list but it allows the binding of data structures to words. So you can typically bind some string or number as the key to some value. my_dict = { 'question': 'What is your name?', 'answer': ['My', 'name', 'is', 'Todd']} Then if you want the question you defined in the dictionary, you can type my_dict['question'] which will return 'What is your name?' There is a lot of really solid documentation for python, so start googling. Learning to find the answers via documentation is fundamental. As a side note, programming isn't about learning formulas, it's about learning a thought process to solve problems. You need to look at the problem, break it down into small manageable pieces and then build each of those up into the overall solution. Hopefully this helps.
Instagram faced exactly the same challenge and implemented a smiliar solution inside postgres: http://instagram-engineering.tumblr.com/post/10853187575/sharding-ids-at-instagram
thank you I will do a little more thinking on it
I have just fixed this issue. You can try it again and I think it will work. Sorry for that.
Can you PM the assignment?
Ya that's what it seems like.....
In this assignment you will build a stock portfolio manager. The manager program will consist of 3 dictionaries. 1.The first dictionary, called Names, maps the stock symbol to the company name (example: "GM" maps to "General Motors"). 2.The second dictionary, called Prices, maps the stock symbol to a list of 2 floating point numbers corresponding to the buy price (the price the user paid for the stock) and the current market price (the price the user could sell the stock for today). 3.The third dictionary, called Exposure, maps the stock symbol to a list of 2 floating point numbers, corresponding to the number of shares purchased, and the risk associated with holding onto the stock (i.e. How likely the stock is to gain value in the future). Your program should consist of the following functions: AddName - Asks the user for a Stock Symbol and Name pairing then adds it to the Names dictionary. AddPrices - Takes a Stock Symbol as an input parameter, then asks the user for the Buy price and the Current price of the corresponding stock, adding them to the Prices dictionary. AddExposure - Takes a Stock Symbol as an input parameter, then asks the user for the Risk and Shares of the corresponding stock, adding them to the Exposure dictionary. AddStock - Calls AddName, AddPrices, and AddExposure to add a new stock to the portfolio. GetSale - Finds the maximum expected value of selling a stock. The expected sale value of a stock is the current profit minus the future value of the stock: Expected Sale value = ( ( Current Price - Buy Price ) - Risk * CurrentPrice ) * Shares The GetSale function should calculate this value for each stock in the portfolio, and return the stock symbol with the highest expected sale value. Main - Should take no arguments, but present a menu item consisting of "1. Add Stock", "2. Recommend Sale" and "3. Exit". If the user selects '1,' the Add Stock function is called, and when it is complete, the menu is presented again. If the user selects '2,' the Symbol of the stock corresponding to the highest expected value (returned by GetSale) should be displayed, and the menu presented after completion. If the user selects '3', the program should end. 
did you get it
MongoDB uses time + server id + randomness.
I would still give ruby the upper-hand here, due to the order of reading being clearer. With your current example, you have to parse from inside to outside, so to speak, while ruby is just left-to-right. Does python have something like the threading -&gt; macro? That would help a lot in this case. 
Seems about right. When they say "simple"....
**Do not use w3schools**. If you're interested in why, check out [w3fools.com](http://www.w3fools.com). If you need Javascript or CSS documentation, then nothing beats the [Mozilla Developer Network](https://developer.mozilla.org/en-US/docs). (But won't be suitable until you've read through a tutorial or book or two on the language.)
&gt; And since we're talking about how much Python is being used in "scientific computing" No, we're talking about how much "scientific computing" is used in "overall computing". No offence to Neuroscience or science in general but in the grand scheme of things there are probably more, say, Wordpress developers (with and without quotes) than neuroscientists.
&gt; In general I do understand that it provides a simpler interface... This...this is all TextBlob was meant to be. Nothing revolutionary in the way of NLP. FWIW, the project began as a small hack with a simple goal: take my favorite parts of NLTK and my favorite parts of pattern.en, and put them together in an API that I would be comfortable using. Oh, and make it Python 3-compatible. 
&gt;there are probably more, say, Wordpress developers (with and without quotes) than neuroscientists. Why should I be offended? If we're talking about raw numbers then there are literally millions more Java programmers than both Ruby and Python combined. That doesn't mean Java's a better programming language, or more important, just that there are more of them. I'm failing to see how quantity matters here except from a purely business perspective.
I fat fingered the command line and did 10 million. my server ran for 16 hrs. 0 999440 1 999333 2 1000306 3 999965 4 1001093 5 1000466 6 999337 7 1000206 8 999814 9 1000040
I'll use conference attendee numbers as proxies. These are almost worthless, but at least give some comparison: The PyCon 2013 conference was full, and capped at 2,500 attendees. The WordPress 2013 annual conference attendees list has 1,058 names. I can't tell if all of those people were at the venue since they also sell live streaming tickets. The SciPy 2013 conference was full, and capped at 300 attendees. (Says http://www.kitware.com/blog/home/post/527 ). FWIW, EuroSciPy seems to be around 200 (based on http://ianozsvald.com/2012/09/04/euroscipy-parallel-python-tutorial-now-online/ ). "One impact of combining JavaOne with Oracle Open World (OOW) is that instead of 15,000 attendees there were now closer to 60,000 (though only about 2,000 of them were for JavaOne)." says http://pragprog.com/magazines/2012-11/the-javaone-snooze . The 2013 International Supercomputing Conference had 2,423 attendees. The CSC 2013 International Conference on Scientific Computing says they "anticipate to have 2,100 or more attendees from over 85 countries." So as an rough approximation, "scientific computing" is about 10% of "overall computing", based on conference attendance. It really is hard to say though. I do computational chemistry. Python is popular in that field. I never go to a neuroscience conference. I haven't even gone to SciPy, because most of the topics don't interest me and I don't see what I'll get out of it, compared to going to a conference in my specialty. For that matter, there's only a few thousand people in my area of focus.
Always get an Internal Server Error ([sample code](https://github.com/posativ/weave-minimal/blob/master/weave/__init__.py) and all other python files in that repo).
I couldn't make heads or tails of that final link ("this paper describing this ..") As far as I could make it, those 3 or so paragraphs was more like a call-for-papers, and the collection of 24 articles on the topic (all "Original Research") only talk about specific pieces of software related to neuroscience. I saw nothing which actually solidified the claim made: to "demonstrate a critical mass and show that Python is an appropriate choice of interpreter interface for future neuroscience software development" Am I misreading things? Also, the UI on that page is full of fail. 
Okay, tell me how you think you should start this and I'll guide you. Instead of thinking about this in terms of Python, tell me how you'd do this in your own words if you were doing it by hand. Give me instructions, then what I need to do to do each task (addName, addPrices, ...)
&gt;and the collection of 24 articles on the topic (all "Original Research") only talk about specific pieces of software related to neuroscience. That's exactly what it's supposed to be. I linked to "Frontiers of Neuroscience" after all. All that software is written in Python, with interpreter interfaces in Python. That's the entire point. Those 24 papers are mean to be representative methods papers (of which there are dozens more not published in Frontiers), demonstrating the tools available that are written in Python. Comparing against Ruby, that's 24 vs 0 that I know of. There is no other programming language in the field with the same critical mass of tools devoted to it. Furthermore, why the air quotes around "Original Research"? These authors aren't Wikipedia editors, these are experts in the field. Are you trying to imply something disparaging about the authors? These tools are used in literally hundreds of neurocomputational models, only a fraction of which are cataloged [on ModelDB](http://senselab.med.yale.edu/modeldb/ListByModelName.asp?c=19&amp;lin=-1), sutdying everything from hippocampus, olfactory bulb, central pattern generators, etc. 
I mean what are dictionaries
MySQL provides an easy solution if you know the max number of nodes you will have and can assign each node an id - auto increment offset and stride. MySQL starts it's autoinc at the offset and jumps by stride each time, so if the systems share a stride and have unique offsets their autoinc values will not collide!
I don't develop in it full time - but use it where it fits the bill. I enjoy php as a rapid prototyping and general use language. It's easy to put junior developers in PHP roles and it's a powerful base for web apps when something like J2EE is too much overhead and rails is not responsive or scalable enough. I grant you that it has some terrible naming conventions, but it's far faster and has much more functionality in the standard libs than Rails or something like Django.
In certain cases, unless can make the code much more expressive and easier to follow for people coming in afterwards. Not that it always does, however. I love Ruby for its clean, expressive syntax, and that just about any way I think of doing something will work the first time, everytime. I love Python for its significant whitespace, incredibly mature library support (Pandas/NumPy/SciPy etc.), and that there's always one and only one way to do something. Different languages excel in different places - but everything has its niche, and ultimately it's your responsibility as a programmer to pick the best tool (language) for the task at hand. Don't be picky, don't be choosy - just use what is best suited to use the job. 
And nltk.
People mentioned that, but the author said something about duplicating the `i + 1` logic. Someone fired back with the super clever, but a touch implicit, `[i + 1 for i in items if i % 2 != 0]`.
Often "unless" makes code less readable to me. I think in "if" and "if not". I have to reformulate the condition as "if not" to understand it. But that's maybe just me (English is not my native language).
Reading this article made me setup a little template using bottle/JADE/SASS and instead of coffeescript I opted to use brython. https://github.com/Tylor167/BracketlessBottle Hope somebody can find some use out of it =]
Heh. Gotcha. Thanks.
Too mainstream.
"But obviously Ruby code is much more readable."
Quite interesting. Now you just need people to use it.
This literally sounds like you just want more ad views. You never even responded to this person. Can we just get this person banned please?
&gt; Yeah I hate readability too... I'm a Python programmer but I think the Ruby `@` syntax is a little nicer than `self`.
I originally posted this on /r/nagios but thought more people would see it here. :)
Decorators are more generally useful than class methods.
I think spending too much time on the framework you use won't really help you a ton in the long run. It's much more important to learn how to write your tests in a clear, concise way. Unittest follows the XUnit testing style, which seems pretty clean/clear to me. I'm curious as to why you think Unittest is messy. That said, I prefer Nose over Unittest. A lot more control over picking and choosing the tests you need to run in the long run. I'm not sure about this framework, but nose isn't too far off from that syntax-wise.
Neat project. I also use python + nagios, except I use a modified version of [push_check](http://www.jjoseph.org/linux_work/nagios_plugins) and just write my checks as python scripts (python 2.4 is available everywhere). It is slow though.. I need to try using ControlMaster to speed up the ssh connections.
really ? You first complained that Reddit was not my blog when I was submitting my Python **articles**. Now, you are whining that I should be posting something interesting or useful. Funny :)
Sense of humor not found :)
This might be the most un-readable code I've ever seen.
So your script pushes check_disk.py and friends to the remote host?
Yep, it scps the script to each host and runs it via SSH. It also does a little check to avoid transferring the file every time (check the md5 of the file on the remote host and compare it to the local file).
Confirmed. These guys are not kidding. t = (int(time.time()) - shared.maximumAgeOfObjectsThatIAdvertiseToOthers, int( time.time()) - shared.lengthOfTimeToHoldOnToAllPubkeys, self.streamNumber)
I was under the impression that nose was specifically made for django, but it sounds like what your saying is that I can use it for general purpose stuff?
At least it can be understood, as opposed to C-style i and j. However the unit is not included! maximumAge and lengthOfTime in what.. years? Milliseconds? Days?
Just a comment -- with open(...) as f: ... is more equivalent to: f = open(...) try: ... finally: f.close()
Seems to be working now. I don't, however, know what it's trying to tell me: http://ahye.ventolin.org/s/nH0rkVLm.png Is it saying that line 23 is an example of the idiom that's in the pop-up? Or is it saying that I should code something like what's in the pop-up? (Which happens to be terribly unpythonic and should instead be something like `generic_name = name in ['Tom', 'Dick', 'Harry']`
Saved the comment right there ;-) I don't know, it's readable enough for me.
And the worst part about it is that `{}` is not even a number! :-)
Closures are more generally useful than both, but we tend to like languages that give us more succinct toolkits for handling them than stacks of lambdas. The point isn't what's possible, it's what the language design guides you towards. It's pretty clear to me that class methods weren't designed in at all, they were hacked in and allowed to stay. Now decorators are The Way You Do Class Methods, and that's not likely to be fixed. This is where Ruby's object model wins, in my book. Class methods are just instance methods, they aren't special at all. And that's very obvious from the way you define and use them. That's not to say that Ruby's object model is perfect, by any means. I just find it less surprising in day-to-day use than Python's.
BitTorrent ?
The single-threaded version is very fast, this one is much slower. But when I read about the GIL, I thought I could only use one core and if I want to use all cores, multiprocessing is the only way. But it seems I was mistaken. Changing the print statement to "pass" doesn't change the performance in this example.
A process with multiple threads can only use one core at a time, because of the GIL. But, the OS might switch between different cores as it schedules your and other processes. 33% per core sounds right, ie., your process running 25% of its time on each core, plus some overhead. What you **won't** be able to do is to get 100% usage on each core.
Thanks for the clarification. If I want to get close to 100% usage on each core, is multiprocessing the way to go?
&gt; It's pretty clear to me that class methods weren't designed in at all Because they're not very useful. If we're using a feature checklist method to evaluate object systems, then CLOS or Scala or something else is going to win.
&gt; If I want to get close to 100% usage on each core, is multiprocessing the way to go? yes, but only if you can afford to run separate processes. If you want to stay multithreaded, you can, provided that only one thread executes interpreter code. That is, you can go multithreaded (real multithread) if you call some C code which uses threading and never calls the python API. The problem occurs when this C code must enter into python. In that case the thread will try to acquire the GIL, and it won't continue until the GIL is released. 
these are completely absurd though ... they ended up using entirely different sentences to describe exactly the same thing in a bunch of cases. Both of these in another thread could have been ... "timeout". lengthOfTimeToHoldOnToAllPubkeys ---&gt; publickeys.timeout maximumAgeOfObjectsThatIAdvertiseToOthers ---&gt; publicobjects.timeout *edit... and also ... numberOfObjectsThatWeHaveYetToCheckAndSeeWhetherWeAlreadyHavePerPeer ---&gt; objects.unchecked.count() With "objects" being the whole set of objects ... ".unchecked" returns a subset of all those not yet checked ... and "count()" being a method available on both. i.e.: objects.count() objects.checked.count() This sort of organization gets real useful in this sort of use-case ... since there are a bunch of common methods ... and various object-types/categories. objects.private.timeout objects.public.count objects[0].public_key.timeout
Phew, I thought his variable name was actually longer than 79 characters. It's only ~69. 
&gt; (Seriously, though, why would you ever need an unless as long as if exists?) I've worked in both Ruby and Python, although I've spent far more of my life in Python. I rather enjoy using the "unless" construct in Ruby. Sometimes it's just a tad easier to understand than an "if not" in my head. I certainly wouldn't fault Ruby for "unless." There are plenty of other language features in Ruby to bitch about. 
Too read-able
You can see how Twitter is using [Murder](https://github.com/lg/murder) in production to do exactly that.
I know bittorent..... What is ms bits?
Gee.. count yourself lucky. Really lucky.
I agree. Honestly that's way worse than just having absurdly long names.
http://msdn.microsoft.com/en-us/library/windows/desktop/aa362708%28v=vs.85%29.aspx
You are using all 4 cores (assuming each thread is scheduled on a different core), just not at exactly the same time, as only one thread can execute at any one time. It is slower because of the overhead of threads trying to acquire the GIL. That is probably where the 33% is coming from. 
I like Python better, even though I've been doing web development with Rails for over 5 years. One of the things wrong with ruby that has't been mentioned: lack of namespaces (or their usage). With Rails everything is jumbled up in a global namespace, and because of monkeypatching and letting anyone change core classes I can never be sure which of the 5 definitions of a function is the on that's being actually used. With ruby everything seems to be implicit. There are too many ways to do everything. Rails is what makes Ruby great. There needs to be something that "just works" for Python (that isn't just focused on doing sites with an admin backend)
There is a great Python visualizing tool at [pythontutor.com](http://www.pythontutor.com/visualize.html). It really helped get my head wrapped around *wrapping* a function with multiple decorators. They have a good [decorator example](http://www.pythontutor.com/visualize.html) too. After you look that over plug your code in and you can watch both the output as well as what's happening on the memory stack itself. Good stuff.
I prefer it because it seems less noisy. Also I'm guessing @ is read as an abbreviation of "attribute." It's certainly not clear at first glance but it is a fundamental aspect of programming with classes; once you learn what it is you'll never forget it or need to think about it again. I mean even in the less common case of creating sublists and the like, people accept syntax such as `mylist[::2]`. I don't specifically despise `self` but I think def add(self, other): return Vec2D(@x + other.x, @y + other.y) is less noisy than def add(self, other): return Vec2D(self.x + other.x, self.y + other.y)
I wonder if it could run under SL4A ?
It is quite broken. The protocol is extremely simple to detect because the negotiation is not encrypted. It is trivial for governments to detect and block it. Recommendation: do not use. Its a nice idea, but not well executed.
Two counterpoints: Firstly, when I compared functionality - you have to look at PHP as a self contained web environment. So while python has some great libraries, if you wanted to use databases or image magick or something, these are eggs to be installed and imported. In PHP these things are first class, C++ extensions, which is helpful. As for speed - PHP is faster in the sense that it is much more scalable, which is a big argument for its use. Django does well for small size websites, but start throwing a thousand concurrent requests per second at it and it will come to a halt. Rails dies at a few hundred. There are strategies to abate this that don't involve new hardware, but they do involve mucking around with nginx or apache configs, recompiling mod_python, etc. PHP is very strong in this regard. Install it, link It to Apache, and if you've written your code halfway reasonably, it will survive well past that threshold. That's my two cents, anyway.
Care to elaborate or link me somewhere?
If you want APL you know where to find it. @classmethod isn't any more inconvenient than knowing the three (it is just 3 right?) ways to define a Ruby class method.
I think he means that the packets transmitted between sender and receiver are easy to filter out by anyone controlling infrastructure, making this communication blockable if the government wanted to, which is a feature you dont want. (Youre susceptible to censorship) In an ideal app, the government shouldnt be able to see the difference between your data and other data being transmitted. 
The [rabbitmq](http://www.rabbitmq.com/getstarted.html) tutorial is a great place to start learning about amqp... Think of celery as a wrapper for your functions, using a queue to execute those functions whenever there is new work. With the example you provided, there would be a worker that is for sending emails, and probably a worker that on a 5 or 10 minute basis polls your db for new birthdays and submits to the queue itself.
&gt;is multiprocessing the way to go Note that instead of using the `multiprocessing` library you can use `concurrent.futures.ProcessPoolExecutor`. The interface is pretty much exactly the same as `concurrent.futures.ThreadPoolExecutor`, but it uses `multiprocessing` behind the hood.
As a general rule: * `multiprocessing` for CPU- and GPU-bound computations. * Event-driven stuff for non-blocking I/O (which should be preferred over blocking I/O where possible, since it scales much more effectively). * Threads for blocking I/O (you can also use `multiprocessing`, but the per-process overhead probably isn't worth it).
Let me get this straight. Ruby has two operations that print a line onto the console - `print` which prints it without a carriage return, and `puts` that does it with a carriage return after each entry? Is the rest of the language that badly designed? First, if you have to have two functions, why not have similar names, like `print` and `prints`? But why have two different functions? Why not have an optional argument to print? This is my first exposure to Ruby, actually, and I'm struck by how they seem to go out of their way to make unobvious choices. The first think I noticed about Python was the reverse - how every choice was obvious, even "boring". Let me tell you, boring and obvious are good when it comes to programming. I want my code to work!
Ok, so this is not an unfixable mistake in the protocoll but only a bad implementation detail?!
HOW DARE YOU! I WILL NEVER USE PORT 8080. I AM SO ANGRY AND/OR INDIFFERENT. ^Am ^I ^doing ^it ^right? ^you ^guys?
`self.` isn't "noisy". Noise means "lacking in information value". `self.foo = 2` says exactly what is happening - the attribute `foo` of the object `self` is set to be 2. I was able to understand what this meant the first time I saw a Python program. Now, yes, when I first saw this, I thought it was _redundant_ - because I came from a C++ background, I just wanted member variables to automatically appear in my local variables. Redundancy is not noise - almost the opposite. After using Python for a short time, I realized that the language was completely uniform - yes, I had to type four more characters to get to member variables, but I could just pick my code up and move it anywhere. Heck, in the middle of refactoring I've created functions (not methods) where I called the first argument `self` just so I could move methods out of classes. This @ notation is opaque and non-obvious. "self" (or whatever Ruby calls it) isn't "just another variable" - it's a special, magical thing with its own punctuation and everything.
Multiprocessing would work or you could try your hand at Pypy which doesn't have a GIL to my knowledge.
&gt; In a proc/block, return causes a return from the enclosing scope outside the block. I don't know how you'd do that in Python. If you can tell me _why_ you would want to do that, what effect you are wanting to get, I can tell you how to do it in Python. 
Dave Beazley gives a good talk about this from PyCon 2010: http://pyvideo.org/video/353/pycon-2010--understanding-the-python-gil---82
I think we should organize the logic before we worry about the Python syntax. Is that okay?
&gt;I would like this error to be catchable through either the `MyLibException` or `TypeError` types. Well then you have your answer. --- &gt;validate_string_input Why does this raise an exception? I'm just going to assume this was silly example code stuff... --- &gt;Are there negative implications of using this pattern of which I'm unaware? You might confuse people. People might assume that because they can catch `MyLibTypeError` under `TypeError` they can catch its subclasses. I don't think that matters. There might be actual reasons but I'm not aware of any. Don't go overboard. &gt;It gives me pause that none of the major libraries I've examined seem to use it. From the SQLAlchemy link: class NoSuchColumnError(KeyError, InvalidRequestError): """A nonexistent column is requested from a ``RowProxy``.""" &gt;That may be due to the need for backward compatibility, which is something we won't have to deal with yet. I don't see why that would make a difference.
&gt; Event-driven stuff for non-blocking I/O (which should be preferred over blocking I/O where possible, since it scales much more effectively). Gevent, eventlet for example?
`Yes().I.Have.see_this_same_sort.of.Shenanigans().Myself()`
One of the best presentations on the GIL was by David Beazley at Pycon a few years ago: http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2010-understanding-the-python-gil-82-3273690 More here: http://www.dabeaz.com/GIL/
The good news is it at least uses OpenSSL and -- more importantly -- its "envelope" API which eliminates procedural fuckups like not padding your plaintext properly. I can't speak as to whether it is *conceptually* secure, though. The bad news is that the code is horrible. The `sendMsg` method is 379 lines long and incorporates a mixture of byte-packing, network code, encryption, protocol logic, SQL, and UI events. I've seen longer methods, sure, but at least they had a coherent purpose. If you can't even read the code, how can you trust anything it does?
[**@xguse**](https://twitter.com/xguse): &gt;[2013-08-13 02:53:37 UTC](https://twitter.com/xguse/status/367116705186586624) &gt;Clever trick to create endlessly dimensional nested dicts on the fly &gt;dict_tree = lambda: defaultdict(dict_tree) &gt;[#python](https://twitter.com/search?q=%23python) [#programming](https://twitter.com/search?q=%23programming) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1kafof%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://www.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
[**@xguse**](https://twitter.com/xguse): &gt;[2013-08-13 02:53:37 UTC](https://twitter.com/xguse/status/367116705186586624) &gt;Clever trick to create endlessly dimensional nested dicts on the fly &gt;dict_tree = lambda: defaultdict(dict_tree) &gt;[#python](https://twitter.com/search?q=%23python) [#programming](https://twitter.com/search?q=%23programming) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1kafof%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://www.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
[Swarm](https://github.com/phoenixguild/swarm) maybe?
Don't understand yet how it being implemented but my initial test just work. Quite surprising for just one man work (I guess). Brief read on the docs suggest that it does not use any kind of virtualization such as lxc/docker like other paas such as dokku, openruko, deis, tsuru etc. Good fit I think for cheap vps like digital ocean or linode. Screenshot of the web panel - http://i.imgur.com/qd2oIOt.png
How would it compare to PyPy?
Interesting. Has anyone had a chance to try this out on one of their projects yet? What kind of results did you achieve? 
I'd give it a "not remotely similar". Did you read the article? PyPy is a tracing JIT compiler that breaks compatibility with the C extension API. Falcon is an interpreter that does fancier optimizations than CPython but remains compatible with the C extension API. You run your whole program on PyPy, and you mark up specific methods to be run through Falcon.
TL;DR: They claim it's about 25% faster than CPython on average, for their benchmarks.
Not having a strong background in formal computer science, this is the sorting algorithm I came up with around ~~10-15 years~~ 5-10 years ago or so: (sum(score)+3)/(count(score) + 2) (This is assuming a 5 point rating system). Basically, it adds one 1 star and one 5 star rating to every item. This offsets items with few reviews and high/low ratings. I'm sure it's not nearly as accurate but it is still better than the other two *and* is very fast and easy to calculate. EDIT: probably not as long ago as I thought.
I don't understand how you figure noise and redundancy are "almost the opposite." Having to prepend `self.` to every single instance attribute is quite verbose, and when you're reading `self.this(self.that, self.other)` instead of `@this(@that, @other)` it is indeed noisy. I agree that having explicit `self` has benefits. I'm only commenting on the claim that `@` impacts the readability of Ruby.
Exceptions are somewhat messy in that there's no consistent rule. Several different styles exist, and they all seem to work okay. Your solution looks fine to me. As another variation to add to the mix, do you have lots of different exception types derived from a common base, or do you have a single exception type with an errno? The built-in IOError does the latter, while Twisted has many specific exceptions. Python's 'decimal' module uses multiple inheritance in the way you want: class DivisionByZero(DecimalException, ZeroDivisionError): This is because 1/0 normally raises a ZeroDivisionError, and they wanted to implement that behavior, while also having a type-specific exception (DecimalException), which is derived from ArithmeticError. As a side note, ZeroDivisionError is also derived from ArithmeticError, this is a diamond inheritance. I did a search for ''class.*\(.*,.*Error\)'' in Python code I have hanging around: ./Cython-0.15.1/Cython/Plex/Errors.py 12:class PlexTypeError(PlexError, TypeError): 15:class PlexValueError(PlexError, ValueError): ./Python-2.7.1/Lib/email/errors.py 25:class MultipartConversionError(MessageError, TypeError): ./biopython-1.58/Bio/__init__.py 25:class MissingPythonDependencyError(MissingExternalDependencyError, ImportError): ./fwrap-0.1.1/fwrap/fparser/readfortran.py 267:class SyntaxErrorLine(Line, FortranReaderError): 322:class SyntaxErrorMultiLine(MultiLine, FortranReaderError): ./numpy-1.6.2/numpy/numarray/util.py 15:class NumOverflowError(OverflowError, ArithmeticError): Hope that helps assure you!
I like that definition in Urban Dictionary, dunno why it's put up as a shining example of ratings abuse. In a colloquial setting normal is not used as perpendicular or as median. Relatively rare things like a nuclear family or a white collar job are "normal". Good article otherwise.
25% speedup? That's non-trivial.
25% under specific cases.
They found that was their average speedup. If I were cherry-picking, I'd point to their "2.5x" findings.
The article said 25% on average and 2.5x under specific cases.
So I'd phrase it as "Python's reference interpreter runs at near theoretical-maximum speed." :-)
I don't really see how using normal attribute definitions is verbose. (If we're counting characters, it's only 4 characters more) *"It's certainly not clear at first glance but it is a fundamental aspect of programming with classes; once you learn what it is you'll never forget it or need to think about it again."* I don't think this is a good argument for it being readable. (I think it's quite the opposite.) Just because it's simple (and hence easily learned) doesn't make it readable.
&gt; Multiprocessing would work or you could try your hand at Pypy which doesn't have a GIL to my knowledge. http://doc.pypy.org/en/latest/faq.html#does-pypy-have-a-gil-why
Aside from the fact that Twisted is an invasive species that will dictate the entire architecture of your program. It's very much an all-or-nothing venture, so I generally avoid it like the plague, despite my love of non-blocking IO.
No, that's not trivial. But both this project and Unladen Swallow aimed for much bigger gains and found out it's more difficult than it seems.
"not by much" seems a bit dismissive, though. I'd be overjoyed if these sorts of improvements showed up in Python. I mean, it'd be great if I suddenly got a 500% improvement, but I'll gladly take 25% and say thanks.
I thought this was going to be about [easter eggs](http://www.paaseastereggs.com/).
You should probably start here then: http://greenlet.readthedocs.org
sounds good you know better than me what should I do next
You will.
How do you copy a list in Python? t = s[:] t = s.copy() t = list(s) from copy import copy t = copy(s) t = [x for x in s] Five ways. Serious question: Which is the one "obvious" way to do it? Sometimes the language doesn't stack up to the rhetoric. Disclosure: I love Python.
What on earth has why *I* would want to do it got to do with whether it's possible or not? Either it's possible or it isn't. 
TIL about Rosetta Code: http://rosettacode.org/wiki/Averages/Arithmetic_mean#Python
&gt; You run your whole program on PyPy, and you mark up specific methods to be run through Falcon. Though, to be honest, the only reason Falcon *isn't* a full Python implementation is because it would take a while to properly fork CPython and we're both busy grad students. If anyone wants to join the project to make a full Python interpreter out of Falcon, we would happily take on some volunteers. 
The first and last of those are methods for doing a general set of things with lists, that also happen to work for one specific, common function with lists -- copying. The middle one is reconstructing the list... which is technically what you want to do, but if you wanted to think about things in terms of constructors, you'd be using C, wouldn't you? Importing a library is stupid. So the second one is probably right... but the first one is probably more common, I guess. One way is an ideal. Obviously any programming language that lets you do a lot of things lets you do those things in a lot of ways. But Ruby has *more* ways. A point worth noting is that, with my limited python knowledge, I have used most of the mechanisms you listed, and recognized them all instantly. In Ruby, if you listed every way there was to copy a list, you'd surprise the most seasoned veterans. More importantly, if Bob writes code and Jim looks at it the next day, and they're both at some intermediate level in Ruby skill, Bob might copy a list using one method that Jim has never seen or heard of. That's just the kind of thing that's astronomically more likely in Ruby than it is in Python.
I'm not experienced enough to take a lead or anything, but I'd love to help out.
Have you also come across Numba? It uses LLVM to compile heavily numeric Python methods, which produces much more dramatic speedups, but only works on a subset of the language. It also maintains compatibility with C extensions. It's interesting to see another approach. Python speedups seem to have a kind of 'choose two out of these three: really fast, easy for developers, compatible with C extensions'. PyPy is fast and easy, Cython is fast and compatible, and now Falcon is easy and compatible.
&gt;Have you also come across Numba? Yeah, I'm working on a [similar runtime compiler](https://github.com/iskandr/parakeet) and have had some really interesting conversations with Travis, Siu, and some other folks from Continuum. &gt; which produces much more dramatic speedups, &gt;It also maintains compatibility with C extensions. With Numba you have to choose one of those. Either it preserves PyObjects representations (and then gives you only a moderate speedup) or it can't pass data to C extensions. 
ShenenigansFactory.create(Python.PROJECT, Functions.areNotFirstClassObjects())
you can spare the count methods and just implement `__len__`
Oh, most definitely! Nose is just a tool that you can use to: * dynamically find tests (nose automatically picks up any classes with 'test' in the front) * use it's testing tools (expect exceptions raised, check of equality beyond ==) * add functionality easily with nose plugins (e.g. it's incredible easy to add code coverage. Install the nose-xcover egg and then run nosetests --with-xcoverage) * tag tests so you can pick and choose the ones you run (e.g. add a 'slow' attribute so you can choose not to run slow tests if you need to run a quick pass. I don't use any other testing frameworks to run my tests, but I suppose you just choose one you like and stick with it. You can learn more about nose here: https://nose.readthedocs.org/en/latest/ 
Link for the lazy https://github.com/rjpower/falcon
Ah. Oh well. Either way, this was a fascinating project to read about. Good luck with your grad work, too.
&gt;The fact that there is no compelling reason for industry to move to Python 3 is &gt;what's hurting Python's growth. The most practical answer of course is that it's 3, the old one's 2, and 2 will be unsupported eventually and then you'll need to move even more active code when you finally have to move. Upgrading and refactoring old code to work with new versions of software is part of the software maintenance process unless the code is frozen and only seeing bug fixes. Continuing to develop new code in old versions is even worse. In that vein the issue becomes needing a compelling reason not to use the new version. &gt;I'd love to read your response to my points, by the way. Dr, Cannon already addressed this is depth at PyCon 2013. https://speakerdeck.com/pyconslides/python-3-dot-3-trust-me-its-better-than-python-2-dot-7-by-dr-brett-cannon I'd just be plagarizing his excellent summation by listing them all. But I still believe that sometimes things don't improve; they just change - often to lay groundwork for future improvements. Simply being different is reason enough. Things change; you refactor to ensure future compatibility. Period. If you don't, you're doomed in the long run. For instance - Python's way of dealing with Unicode changed. We can debate if it's better, but that's it - the ship's sailed. If somewhere down the line a new version of Python finally appealed to you, you're still going to have to convert your ancient code's Unicode. So why not just do it now and get it over with? Whether you finally embrace the present when it's Python 3.4 or 10.4, your Python 2.7 code's going to have to go. So it makes no sense not to port now because you're just going to have to pay the bill later with interest. Meanwhile, other people want to port but can't because of other people not porting. In Martin Michlmayr's summation of Van Lindberg's EuroPyCon 2013 talk on the next 20 years of Python, he wrote: &gt;Asking "why do I care?", he explained that it's important to keep growing  &gt;otherwise Python will end up where Smalltalk and Tcl are today. He rhetorically &gt;asked the audience when the last time was that anyone did anything interesting &gt;in Tcl. Noting that these are fantastic languages, Lindberg argued that "they have &gt;died because they have not grown". Python is growing, from advanced Unicode and nonlocal, enum types, more context managers, to yield from and SimpleNamespace, etc. Holding one's breath and waiting until some of these features reach tremendous heights of power and usefulness - i.e. until they're perfect and optimally realized with no room for improvement - prevents other people from using them at all. Just like PHP 6 which is coming forever and Firebird database 3.0 which is seven years late, it won't matter if Guido and company are growing the language to Brobdingnagian heights. Unless it's available to be used, it won't matter if it exists. If people sit on their hands, Python 3.3 effectively doesn't exist, and this makes it no new releases of Python since July 2010. If people continue to refuse to do their duty - support the current version of the language - it'll shrivel like Tcl, but for different reasons. &gt;The community isnt going to throw away something that works for something &gt;thats more elegant and a bit better. Does someone need to kiss the community's posteriors? &gt;They will only break backwards compatibility for something that works &gt;significantly better. You do realize how haughty this sounds, especially as it's available for free, right? &gt;So much better that its worth the time cost of installing a new Python distribution &gt;and refactoring, testing, and debugging the code base. The rest of us upgrade, refactor and test all the time because that's just part of the job.It's like getting a dog shots and taking it to the vet. If you can't afford to do that, you can't afford a dog. If you can't afford to move your codebase along to current versions, you don't have the time to develop the code in the first place. It's called "bitrot". You don't get a choice in the matter. http://en.wikipedia.org/wiki/Bitrot If "the community" has some amazing ideas for Python they're just not seeing, then let's see the PEPs. If not, then Python 3.3 is the current (stable) state of the art. It's one thing to still be on 3.2. But to remain on a non-compatible version (and for five years!) has real ramifications; it holds everyone else back too, and then lots of effort gets spent on backports that could be spent on improving the language. Then people complain the language isn't improved enough and that there's nothing compelling to warrant a move (thanks to the bending over backwards backporting of everything conceivably possible to the old version). It will be interesting to see what happens when Python 2.x's support runs out. It'll be just like Delphi... people had years of time to move to their new Unicode system, and instead they just kept using the backwards-compatibility mode. Now that Delphi is becoming cross-platform and moving to LLVM, suddenly they're filling the forum complaining that they "don't have time" to convert their code. They had four years, but they not only didn't bother, they kept writing ASCII-only code and now they're staging a mini-revolution against the nextgen compiler - which is both urgently needed from a features standpoint and the future of the language as it tries to find a new niche as a cross-platform (mobile) tool. Some are even freaking out about removing some Turbo Pascal for DOS backwards compatibilities. :-( If we don't get it together, that'll be Python in two years or so when the plug gets pulled on 2.7. I don't want to see Python become as irrelevant as Delphi. 
You know what he missed? namespaces. Ruby doesn't have them (and can reopen existing classes instead), but that also means that it can be hard to trace what the heck is going on (e.g., Rails' magic) or be explicit about where a method comes from. Import semantics make it *much* clearer where each element comes from (and much easier to traceback code). Less known (but I think important) difference: Python has docstrings, a builtin part of the language that's easily available in the interpreter...ruby has things like yarddoc or ridoc, but there's not as easy to get to in the console directly.
Other explanations of this are great - here's mine (I have an example from the pandas codebase at the end for creating an optional args decorator for decorators - it's a neat challenge to see if you understand decorators if you can wrap your head around it). To be clear, what's going on is that the `@` syntax just means "call this function with a single positional argument - the function below" So, a decorator called like this: @a def somefunc(): pass Means that you are doing the equivalent of: def somefunc(): pass somefunc = a(somefunc) If you think of that as a rewrite rule, it's pretty clear what's going on with a decorator with arguments: you call the external function first, which needs to return a function, which gets immediately called again def say_first(say): def decorator(f): def wrapper(*args, **kwargs): print(say) return f(*args, **kwargs) return wrapper return decorator @say_first("apple") def somefunc(x): print(x) which becomes: &gt;&gt;&gt; dec = say_first("apple") # @say_first('apple') rewrite &gt;&gt;&gt; print(dec.__name__) decorator &gt;&gt;&gt; somefunc = dec(somefunc) # now applying @say_first('apple') to func &gt;&gt;&gt; print(somefunc.__name__) wrapper &gt;&gt;&gt; somefunc(3) # et voila, the final function apple 3 That last line will print two 'apple' if you ran the first set of code and then the second set of code. --- Here's an example from the pandas codebase of a decorator of decorators to take optional arguments. Might be interesting for you to piece out how it works. # import wraps, decorator that transfers function metadata from functools import wraps def optional_args(decorator): """allows a decorator to take optional positional and keyword arguments. Assumes that taking a single, callable, positional argument means that it is decorating a function, i.e. something like this:: @my_decorator def function(): pass Calls decorator with decorator(f, *args, **kwargs)""" @wraps(decorator) def wrapper(*args, **kwargs): def dec(f): return decorator(f, *args, **kwargs) is_decorating = not kwargs and len(args) == 1 and callable(args[0]) if is_decorating: f = args[0] args = [] return dec(f) else: return dec return wrapper You can find it [in use in pandas/util/testing.py on github](https://github.com/pydata/pandas/blob/master/pandas/util/testing.py). It ultimately allows you to skip a layer of wrapping so a decorator can be used both with and without arguments.
Ah well I stand corrected!
&gt;I also love all the comparisons without mentioning Python's filter and map functions while at the same time comparing them to Ruby's filter and map functions. To be fair, though, map and filter are usually not considered the preferred way to do things in Python. Additionally, they are not methods, so you can't chain them while maintaining an easily-readable order. Disclosure: Python is one of my favorite languages, I have never written a line of Ruby, and I think list comprehensions are a godsend.
Not likely, falcon is c++, a dev is here and commented on s similar question, but on mobile; and about to die into sleep. 
&gt; So I'd phrase it as "Python's reference interpreter runs at near theoretical-maximum speed." :-) ...given the performance straightjacket that it has created for itself. :-) (That is, by allowing C extensions to directly access its internals, which prevents CPython from using more efficient versions of its internal data structures as this would break the C API.)
Those aren't really in the same domain as Falcon, though, because they are all about creating efficient operations for working with multi-dimensional arrays rather than speeding up general Python code.
&gt; How does a queue work? * https://en.wikipedia.org/wiki/Queue_(abstract_data_type) * https://en.wikipedia.org/wiki/Message_queue * https://en.wikipedia.org/wiki/Message_passing &gt; Is there a long polling worker, which will act? How does this work? I am confused. Or do I need to have a cron job, running, which will keep firing a script to check if there is anything in the queue, for the given time(with the precision of minutes) if yes, then fire a worker. https://en.wikipedia.org/wiki/Event_loop ([*](http://www.python.org/dev/peps/pep-3156/#event-loop-interface-specification)) * http://docs.celeryproject.org/en/latest/getting-started/introduction.html * **http://docs.celeryproject.org/en/latest/faq.html?highlight=polling#do-i-have-to-use-amqp-rabbitmq** [Celery can function like cron](http://docs.celeryproject.org/en/latest/userguide/periodic-tasks.html#crontab-schedules), but there is no need for celeryd to be called periodically by cron: *depending on which message broker is configured, tasks are pushed/routed to Celery workers OR Celery workers pull/poll tasks from named queues.* http://docs.celeryproject.org/en/latest/tutorials/daemonizing.html 
You can get close to 100% usage on all cores with something like celery configured to spawn as many worker processes as cores (maybe `n_cores - 1` for stability), though the [celery task/message queue model](http://www.reddit.com/r/Python/comments/1k9rhn/understanding_queues/cbncx6h) does not solve for inter-process communication/synchronization and avoids locking.
It says no such file or directory. I'm guessing I need to cd/ to the file location, but I don't know how to do that.
cd /path/to/your/script python yourScript.py You can also add "#!/usr/bin/env python" (dont include the quotes) to the top of your source file, and then after you cd to the directory where your script is, you can do: ./yourScript.py 
It keeps saying No such file or directory.
Where have you saved the script?
punch in ls and make sure your script file is there. If not, try cd ~/Download or Downloads (I don't remember if it's plural or not) and hit ls again
Oh. I fixed it. I put ~ at the beginning. Thanks! Although I don't know how the rest of this script works.
Sorry, I meant Python 2.7. The operating system is Ubuntu.
This is an interesting experiment. However the paper seems to skim over PyPy and does not even mention Jython or IronPython which both run on mature VMs that can do heavy optimization. The argument is that those don't provide compatibility with C-based extensions - however I don't see any details of how the benchmarks performed here involve such extension - in fact the paper itself just says "a variety of benchmarks" and a list, but it is not declared what is the source of these benchmarks or what was the reason for selecting these benchmark.. However, 100 points for providing the source code (and the [benchmarks](https://github.com/rjpower/falcon/tree/master/benchmarks)) - something which sadly still is uncommon in Computer Science. I inspected the benchmarks, and they don't seem to import any C-based extensions, perhaps unless you include by what is the implementation behind random and cPickle. Numpy, a likely candidate for such tests, is imported, but only for managing the benchmark tests. I am curious if Falcon was actually proved to work with C extensions? There is very little detail of the environment of the benchmark. Which operating system? Which CPython distribution? How was the benchmark measured? Was warm-up, spikes etc. accounted for? How many runs of each benchmark? What was min/avg/med/max? The benchmark is only represented as a graph - there is not even a table included in the paper. The data behind don't seem to be available anywhere. Could you upload them to [Figshare](http://figshare.com/)?
You say compatible with Python 2.6 through 3.3, but with Linux Mint 14 and Python 3.2 I get: joe@vm ~/falcon $ python3.2 setup.py develop Traceback (most recent call last): File "setup.py", line 8, in &lt;module&gt; import ez_setup File "/home/joe/falcon/ez_setup.py", line 106 except pkg_resources.VersionConflict, e: ^ SyntaxError: invalid syntax 
Hi, I'm the author of the PEP and the reference implementation. I'm not sure why you would want to import numpy just for the arrays, and then use my Python implementation instead of numpy, but the module is designed to work with any sequence type. Lists, tuples, array.arrays, whatever. If numpy arrays are iterable, then they should work. If they don't, please file a bug report (well, assuming the module gets accepted), and I'll fix it.
Again, though, what these libraries do is very specialized and they *only* help you in the particular case that you are making heavy use of multi-dimensional arrays; none of their tricks can be applied to optimize code that doesn't work with multi-dimensional arrays, in complete contrast to what pypy and this paper do. Besides which, creating an unboxed multidimensional array is relatively easy: you just allocate a raw array in C, and then provide a nice interface to that array. Sure there are tricks that can make working with this particular data structure efficient, but again, none of them are even in the same *league* as pypy which can do things like optimizing the representations of *all* Python types rather than just multi-dimensional arrays.
&gt; the only reason Falcon isn't a full Python implementation is because it would take a while to properly fork CPython That's what Google thought with unladen swallow.
https://github.com/fortharris/Pcode
Was just about to ask for some screenshots... then I refreshed the page and they were there. Good progress! Now I'm just curious but was there a specific reason you chose GitHub over BitBucket? 
Cool! Good to see you followed through.
Thanks!
I've only had a brief brush with Ruby, just long enough to decide I detested it! But I think the whole classmethod/staticmethod/method thing is a mess. It feels to be that if I write **t.f** where **t** is something with attributes and **f** is a function, then **t.f** should evaluate to a value that binds the function and the thing, so when its called, an *implicit* **self** (aka this or whatever) is the thing. That works consistently: if **t** is an instance then **self** is the instance; if its a class then **self** is the class, whatever. Then the need for anything special just vanishes.
Falcon explicitly aims *NOT* to break C extension compatibility, so I'm not sure what your point is.
Generally speaking, you should just assume that PyPy is **ALWAYS** faster unless you need a C extension, or it's a quick script that won't be running long enough for the JIT to identify a hotspot. Falcon is what you would use if you have one or more hotspots in Python that you need to speed up, without dropping down to C, but you *are* using C extensions that you don't want to break.
https://github.com/fortharris/Pcode
https://github.com/fortharris/Pcode
I'm not familiar with IronPython, but when I last tested, Jython was *much* slower than CPython for single-threaded performance. My understanding is that this is due to extensive locking required to achieve Python's guarantees about atomic operations on many of its core datatypes (`dict`s, `list`s, and the like).
Those are all libraries that sit on top of the CPython runtime and selectively make certain logic faster. This is a reimplementation of the VM (i.e. ceval.c) of Python itself to make it faster.
Most people wouldn't write their program or library as callback-driven insanity by choice. There are many ways to architect your program, total freedom of choice, until you start using Twisted, and you're manhandled into one of the most awkward and hard-to-debug models ever invented. Not many other libraries do this. The binary packing library doesn't. requests doesn't. Even unittest's influence on your software architecture is limited (but positive, IMHO). Twisted actually does stand out for the way it forces its own opinions and design patterns to permeate through your code, though part of the reason it stands out is that Twisted's opinions and design patterns are very far from "natural," idiomatic code. So it's totally possible there's an element of "other libraries push their patterns onto you, it's just less palatable in Twisted". Look at it this way. If I switch from unittest to nose, I'm mostly just working to change the APIs used by my code. It's work, but not a do-over. If I switch from Twisted to something else (or the other way round), the entire high-level design of my code is rendered invalid. I'll practically have to rewrite the whole thing to fit the new model.
A [surprising amount](http://wiki.python.org/moin/PythonImplementations) of people have tried to build faster implementations of Python over the past 20 years or so. Very few of them got much of any performance improvement or any traction. I'd say this is a certainly a non-trivial result.
Are you arguing that a language which provides more than one way to do things is less convenient that a language which has only one?
Yes, just like it would be inconvenient to read a product manual written in the style of Joyce.
TFA = the f**ing article?
Then we've reached an impasse: your definition of "convenient" is wildly divergent from mine. Having more than one way to do things allows a better expression of intent under different circumstances. That's just axiomatic. Possibly you're referring to it being convenient to learn. I can't help you there, every language takes effort. Fortunately Ruby's one of the easier ones.
I can't resist advertising my own Numba-like compiler: [Parakeet](https://github.com/iskandr/parakeet). However, none of these are really comparable to Falcon (or PyPy or IronPython). Theano is its own language with distinct semantics (including automatic differentiation) that you program by explicitly constructing syntax trees. Blaze doesn't really exist yet. Numba's fast path (when they abandon PyObjects) &amp; Parakeet only support a constrained array-oriented subset of the language. Falcon runs Python, full stop. Or, if it doesn't, it's a bug and you should tell us on github. 
No, there should be one -- and preferably only one -- obvious way to do it. That's axiomatic, at least in /r/python.
the example code here seems straight forward,http://twistedmatrix.com/documents/12.3.0/web/examples/. websockets are tcp though so maybe not ? alternatively you could write a setup script fairly easily for nginx and httpd.
Sorry, that setup.py really shouldn't claim compatibility with 3.x, we've never even tried it! (just fixed it)
&gt; However the paper seems to skim over PyPy and does not even mention Jython or IronPython which both run on mature VMs that can do heavy optimization. They're just not terribly relevant to our target domain. We're saying "Python is PyObjects--- how fast can that get?". PyPy, IronPython, and Jython all say "Python is the language spec, regardless of how data gets represented". If you need C extensions then they're not an option for you. &gt;I inspected the benchmarks, and they don't seem to import any C-based extensions, Those benchmarks wouldn't be very interesting, essentially you'd be comparing the runtime of compiled native code against...the exact same native code. Falcon isn't trying to speed up the extensions themselves, it just maintains a PyObject representation so you can call them in the exact same way CPython does. &gt; I am curious if Falcon was actually proved to work with C extensions? The data is kept as PyObjects and we use the same calling conventions as CPython. So, they *should* all work, but try it out and let us know if something breaks! &gt;There is very little detail of the environment of the benchmark. Which operating system? Which CPython distribution? How was the benchmark measured? Was warm-up, spikes etc. accounted for? How many runs of each benchmark? What was min/avg/med/max? Sorry, we should have been a little more meticulous in recording this stuff. If I recall correctly, all the benchmark were done on an E5345 Xeon running Ubuntu 12.04 under Python 2.7. I *think* we can each benchmark 3 times and took the median, but I might be mistaken. Of course, you don't have to take our word on the performance numbers. All the benchmarks are in the repo, why not run them yourself and put up a table of results somewhere? 
Unladen Swallow was a Google-supported (and started) fully-compatible fork of CPython aiming to improve interpreter performances significantly (the originally stated goals were a fivefold improvement) through the use of C++, LLVM and LLVM jitting. Although it did produce some merged code (cPickle, as well as a suite of macro-benchmarks used to this day (by Pypy mostly) and a bunch of LLVM contributions), the project ultimately never came close, petered out and died within a year or 2.
I'm *still* confused. I'm saying making a full Python implementation out of Falcon would take a lot of effort. And you're saying...an unrelated project took a lot of effort and then died? 
No, I'm saying a project with more or less the same goals *failed* yet you're completely ignoring this part of CPython's history (I see no mention o US in the paper, and apparently you were both unaware of it), and that a toy partial implementation is a terrible indicator of the performances a full implementation would have.
&gt; They're just not terribly relevant to our target domain. PyPy performs a number of interpreter-level bytecode optimizations ([e.g.](http://doc.pypy.org/en/latest/interpreter-optimizations.html)) which I'd think would be relevant to alternative implementations.
Cool, thanks! I didn't know about this. Their LOOKUP_METHOD/CALL_METHOD instructions look like something that we should copy :-) 
I think I know what you need to do, but I need to know that you know. I'm not doing your homework for you. I'll give you some hints. A dictionary is a list of key-value pairs. If I wanted to map a list of my friend's names to their IM names, I could make a dictionary that would look conceptually like this. "Jess" -&gt; "deathweasel" "Josh" -&gt; "dragonnine" "Kevin" -&gt; "rawrasaur" and it would look like this in python $ python Python 2.5.2 (r252:60911, Oct 12 2012, 20:21:56) [GCC 4.2.4 (Ubuntu 4.2.4-1ubuntu3)] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; mydict = {} &gt;&gt;&gt; mydict["Jess"] = "deathweasel" &gt;&gt;&gt; mydict["Josh"] = "dragonnine" &gt;&gt;&gt; mydict["Kevin"] = "rawrasaur" &gt;&gt;&gt; print mydict {'Jess': 'deathweasel', 'Josh': 'dragonnine', 'Kevin': 'rawrasaur'} You're given the ability to store these: 1- a dictionary that maps company names to stock symbols 2- a dictionary that maps the stock symbol to two numbers: buy price and current market price 3- a dictionary that maps the stock symbol to two numbers: number of shares purchased and risk associated with purchase. Given all of this information, how would you do: AddName - Asks the user for a Stock Symbol and Name pairing then adds it to the Names dictionary. Write it in English, then in Python if you can.
https://bitmessage.org/forum/index.php?topic=1666.0
This genuinely looks incredible. The true downside to facilities such as PGP is that often times users seriously are lazy. The benefit of security and privacy is outweighed by the fact that they have to *do something*. And fuck that, right? This is essentially looking to box up all that we know is good and well and providing it to users in one neat little package. Double click and F-U NSA.
model it on bitcoin 
The rule of thumb is easy: pure Python is stupid fast once the JIT has seen enough to find a hotspot to optimize into assembly. There are corner cases, sure, but it's usually best not to assume you have any deep insight into optimizations of high-level languages on modern computer architectures. You've got rules of thumb, and then you bust out the profiler, etc., when the rule of thumb isn't producing the results you want.
&gt; People who can code in the world of technology companies are a dime a dozen and get no respect. People who can code in biology, medicine, government, sociology, physics, history, and mathematics are respected and can do amazing things to advance those disciplines. If I had had this advice a few years ago...
Don't worry - it is a cool trick! ;-) 
That's lovely, but not going to solve the problem. The folks at No Such Agency have: - Essentially unlimited compute power - Access to the network fabric on which all mail flows - The best mathematicians around - The ability - at least in theory - to put silent man-in-the-middle attacks throughout the network Sooner or later, that's going to result in them being able to penetrate things like PGP (assuming they've not done so already). Moreover, the fact that you're *using* encryption is metadata that itself may trigger further monitoring on their part. "Oh, you have something to hide because you're hiding it from us." The solution to this problem lies with the public and who we elect. It's that simple. In this case pretty much all the left- and rightwingers have supported this stuff. It's been the libertarian right that's been almost the lone voice in opposition to unfettered monitoring of the citizenry.
&gt; The only reason to rewrite any code when you choose to use Twisted is if it was badly designed before. Twisted enforces callback-based design. It's one of the most debug-unfriendly, convoluted programming models I've ever had the misfortune of dealing with. To call all blocking-style code "badly designed" is either immensely opinionated, or immensely stupid, and I'm not sure which (or if there's a difference). &gt; It's all just Python code. Which, of course, is why we have to use Twisted-specific mechanisms for file reading, and I can't use that Kademlia lib as a dependency of my lib without forcing the end application to run the Twisted event loop as the main thread [!!]. Or I could just test with gevent, and write code that is portable across both blocking non-blocking end-use cases.
Pretty sure liberals and republicans are both to blame. Actually anyone who voted in favor of the Patriot Act without even reading it.
&gt; fact that you're using encryption If we can get everyone using encryption, that will change.
Out of the box, the Twisted http reverse proxy doesn't appear to deal with the websockets upgrade. If I run these two code snippets in separate processes, I get a simple web sockets echo server. If I insert the Twisted [demo reverse proxy](http://twistedmatrix.com/documents/12.3.0/web/examples/reverse-proxy.py) between them, it doesn't work. I haven't poked into the Twisted code to see why though (not enough time at the moment.) #!/usr/bin/env python # server from twisted.internet import reactor from autobahn.websocket import WebSocketServerFactory, \ WebSocketServerProtocol, \ listenWS class EchoServerProtocol(WebSocketServerProtocol): def onMessage(self, msg, binary): self.sendMessage(msg, binary) if __name__ == '__main__': factory = WebSocketServerFactory("ws://localhost:9000") factory.protocol = EchoServerProtocol listenWS(factory) reactor.run() #!/usr/bin/env python # client from twisted.internet import reactor from autobahn.websocket import WebSocketClientFactory, \ WebSocketClientProtocol, \ connectWS class EchoClientProtocol(WebSocketClientProtocol): def sendHello(self): self.sendMessage("Hello, world!") def onOpen(self): self.sendHello() def onMessage(self, msg, binary): print "Got echo: " + msg reactor.callLater(1, self.sendHello) if __name__ == '__main__': factory = WebSocketClientFactory("ws://localhost:9000", debug = True) factory.protocol = EchoClientProtocol connectWS(factory) reactor.run()
Finally checked back on this. Thanks so much everyone for the responses and resources!! Definitely going to dive in. I started taking a class on Udacity so we'll see where that goes. THANKS!
Well, I *do* think blocking IO is a bad design. But if you don't, you can still do it. Just do it in a different thread. Twisted works just fine in non-main threads. It's certainly not any worse than doing IO *without* Twisted in a thread.
I'm not a Cython expert so I'll let someone else answer that, but don't start scientific coding with optimizations. Start with python and numpy arrays. Once that **works**, then rewrite/refactor to make it faster and easier to understand. Once that is too slow, go to Cython and other optimization techniques.
Cython is smart enough to understand numpy ndarrays and operate with them efficiently, so you can use them both together. As to how much speedup you'll get ... that is highly dependent on your code. I have certainly seen 2x improvements for suitably marked up Cython/numpy code over straight Python/numpy, but it really depends on where most of your work is. If it's all tight loops over numpy functions then you'll probably see little to no improvement. It really depends. Profile your code and see what is taking up the time.
You've always been able to do it, but there's a new library making it more convenient: https://pypi.python.org/pypi/crochet
So, both recipient and sender have to have this for this to work?
That is *really* nifty. To the extent that I could see digging up that old project and taking another shot at DHT integration. I still don't expect to make my own projects with Twisted, but this opens up a lot of newly-viable possibilities. Thanks, man!
I don't want you to do it for me I need to learn I just need to know how to start it and the process I need to take 
I think that this is a good start: http://stackoverflow.com/questions/101268/hidden-features-of-python
This is wonderful. I love it.
There's plenty of browser extensions that are out to make PGP easy to use, but the problem is no one thinks they need it. Even with the NSA reports I doubt enough people will be willing to encrypt text, let alone switch off Google services all together. Hell, I won't either because a lot of my professional/school emails are based off a gmail account I have that would be very difficult to change. Ultimately I see this webmail having the same problem all other encrypted mail has: it will be incredibly rare for both parties to actually use encryption. Not to mention PGP is based off a web of trust, meaning you need people to also obtain your public key securely. People just want to be able to send messages to each other, not check the validity of keys. Encrypted communications is very hard to do in an end-to-end scenario, and I don't ever see it becoming a standard because it requires too much work and it's not easily automated.
&gt; Should I expect dramatic speed-ups with those, too? Depending on exactly what you're doing, it's quite plausible. Cython certainly has neat and powerful syntax for efficiently accessing and manipulating numpy arrays in memory. But all this kind of thing is *very* dependent on the particular problem and all the niggly details, and you may quickly run into diminishing returns. As others have said, the most important thing is to write the code first, then identify the bits that are slow - by profiling, not guessing; if you guess, you'll inevitably just waste time being wrong. You can then cut those into individual functions and easily cythonise them to see how it goes. One mistake to avoid is to throw yourself into cython and put it in everywhere, which just wastes time and loses flexibility. 
&gt; There's plenty of browser extensions that are out to make PGP easy to use Could you please cite some of these easy to use browser extensions that work with gmail, because I've looked and looked and have yet to find one that actually works...
No. There's nothing unique about the messages going back and forth or the way in which they're being sent. It's still just email. This is just a tool (potentially a really, really good one) to make it easier for you to encrypt/decrypt private messages and to index and search your messages.
The python syntax doesn't encourage one-liners the way perl or haskell does. The syntax isn't consistent, so you have multiple forms that make chaining ugly: reduce(func, data) array.max() sorted(list) and then the comprehensions: [x/2 for x in lst where x % 2 == 0] So in python you use named temporaries rather than LINQ style chained applications.
So I assume this should work out of the box with popular libraries such as Jquery?
is that a play on perl's Parrot?
Why does it also run "in the cloud"? If it's "in the cloud" the NSA can presumably read your emails at their leisure before they get encrypted.
If they had all of that, then they would be able to see everything. That means that Edward Snowden would never get to Hong Kong (NSA would intercept his messages with Glen Greenwald). That also means that the government would have no reason to try to take information from Lavabit which essentially forced Ladar Levison to shut down his service because they already had all the data. So, your arguments are not valid. **For now**.
Sure, and I've tried webpg and it means what it says on the label "gmail integration [EXPERIMENTAL]" ... it didn't work for me.
No :-)
What in javascript? The way I understood their description, it's supposed to run as a local server in which case, yes, the encryption would happen there. If it's a hosted service though, not so much... It could be made to encrypt exclusively client-side using javascript, though if we are worried about the NSA snooping in then it must mean they have access to the server or somehow broke https and in either case that means they can just as easily inject a bit of code to bypass pre-flight encryption or better yet, subtly weaken it. If they only do that for "select targets" it is extremely unlikely anyone would notice.
Yeah, I can look into grabbing those. Need to set up a bitbucket acct first which I probably won't get to till tomorrow. After looking around the tests, I'm not exactly sure how they run all of them and record the results. I'm pretty sure you just wanted me to send a pull request with only those files anyways but..if I add them, could you give me a quick run down of how one actually executes that code? surely not one at a time, and I'm assuming it has something to do with the __main__ name at the end, since that calls the test in each file..
Cloud foundry anyone?
Man, I have been going through some of this in my mind, and this is truly a great piece. Thanks.
Nope, I guess I'm just fond of bird names :-)
I started adding a few of the PyPy benchmarks and I'm working on a driver which will automatically run them repeatedly and report statistics of the runtimes. So, if you wait a day I can give you a more structured benchmarking setup. How does that sound? edit: I just checked a "run_all.py" driver into the benchmarks directory. Now all you have to do is find some benchmark which PyPy uses and Falcon doesn't yet have and drop it in. We're mucking with the internals so some things which should work are currently broken. Things you can expect to fail: any function which uses yield, "SETUP_EXCEPT", "DELETE_NAME", and a few other unsupported bytecodes. 
They say that ultimately paranoia is founded on narcissism because the sufferer believes that they are important enough that the universe has taken notice of them.
A sane comment about this issue... on *Reddit*! Wow!
Computers and big data means everyone is getting noticed.
"where" ?
The greatest thing about this is that I learned about [pagekite](https://pagekite.net/). I have some servers with public ips, so the [open source bit](https://pagekite.net/wiki/OpenSource/) is relevant to my interests. As for mailpile itself, the project looks interesting. I looked at their [github](https://github.com/pagekite/Mailpile) and their [website](http://www.mailpile.is/). I like the fact that it's a self-hosted web application, but I'd really like to know how fast/accurate the indexed search is/could be. Mozilla had something along these lines with a project called [Raindrop](https://mozillalabs.com/en-US/raindrop/) that I was truly excited for (and even had the pre-alpha running for a while) but it never came to fruition. 
After a PhD in computer science I'm not so motivated to start school again to go in another direction. But you are right, at 27, it is not too late ;) (Who know, I may end as a mountain guide and my computer skills will help me doing... I don't know ;)
Mailvelope is one I've used. It has some compatibility issues with importing keys created using gpg, as in I had to generate a key specifically for Mailvelope, but in terms of usability it works great! 
When he is saying "code in biology, medicine, etc" is he talking about programming applications made specifically for those industries or what? I guess I'm trying to figure out how those disciplines could be advanced... I'm still at a point in my college education where I could take advantage of this advice.
I need to start doing more list comprehensions. They can look confusing if you don't see then a lot.
Thanks!
I know a guy who studies viruses. He has special chips that detect something about them and has a cluster of computers crunching numbers. He's a biologist, but he's also a programmer. Yes, you can create software specifically for scientific applications, but there's also a lot of need for specialized software. Sometimes it needs to be written for a specific experiment. There's also a lot of use for major number crunching. Coursera has [an upcoming course on Scientific Computing](https://www.coursera.org/course/scientificcomp) if you're interested.
I see a new Cryptocat coming. It's in my opinion just a bad idea to run crypto in the browser, because what if the clientside javascript got manipulated? The user won't be able to see it and such attacks against a desktop are way more difficult. I wish them luck, but I think they will need it...
Erm... that's not a path you want to take as Ruby also has `STDOUT.write`. And `$stdout.write`.
&gt; If you can tell me why you would want to do that, what effect you are wanting to get You want to implement flow control, such as nested `while` blocks, using method calls and blocks. The goal is having a first-class block which behaves like a lang. That is why Ruby can implement `for` or `with` using blocks. That is why Smalltalk or Self could implement `if` and `while` and `try:except:finally:` and pretty much anything you can think of using blocks. (Ruby can but it's not done, because its blocks are not first-class: they're syntactic magic reified to a proc, and only one block can exist in a method call, the rest would have to be passed in as procs. Possible, but not idiomatic)
&gt; Python has the same thing (pretty much? don't know Ruby well), called lambdas. With two limitations: 1. a python lambda can only contain a single expression, a Ruby block can contain any number of statements 2. a Ruby block participates in the flow control of the enclosing method. `return` in a block will return from the method.
The big problem with using something like PGP is that I can't get anyone else I regularly correspond with to use it. These are people who can't remember their facebook password, so there's no chance they're going to be able to secure their key AND remember the passphrase for it.
You'd need a very good reason to use this given it requires the overhead of a python interpreter written in Javascript.
Thanks for the link. I watched it and it was really interesting. I learned from this that Python 3.2 got a new GIL implementation! Out of curiosity I compared the performance of 2.7 and 3.3 but 3.3 turned out to be a bit slower (even the single-threaded version). **Update** The test scripts are here: [link](https://dl.dropboxusercontent.com/u/144888/wordpress/20130813-concurrent.futures/gil-and-new_gil/index.html). I also added a README file. (Legends: Py2 = Python 2.7.4, Py3 = Python 3.3.1) *basic.py:* Py2: 5.32 sec, Py3: 9.66 sec *with_threads:* Py2: 13.41 sec, Py3: 17.32 sec *with_processes:* Py2: 1.28 sec, Py3: 2.27 sec My conclusion: Py2 seems to be a better choice for CPU bound tasks.
You could have a look at pygame, which has mouse and keyboard handling. I know I had to look at a win32 lib wrapper at some point.
Some miscellania; A lot of the information out there is outdated. More modern Cython techniques such as using memoryviews are often significantly faster and cleaner than older versions. Often, because it's not generalised, Cython loops are faster than the equivalent implied Numpy loops. Cython is faster than Numpy, but only slightly. As Derpscientist said, you won't easily improve on Numpy's most optimised stuff. The real advantages are where you're doing something that involves Python loops. Also, **profile**.
Still, an unencrypted and unverified PGP key would get you out of the NSA dragnet. They'd have to specifically target that user. I don't know exactly what they mailpile guys are doing (and I should ask when I next meet them), but I'd add your key hash as a header to every mail, so the other guy could look up the key. Then I'd make it an option in the program to always retrieve that key and automatically encrypt outgoing mail, even if the key can't be properly verified. Colour-code the security-level and if the security widget thingy is clicked, give instructions on how to verify the key. If you *do* verify a specific key, that would increase the security level retroactively, since then that key wasn't created for a MITM attack. And obviously always sign mail unless specifically instructed not to. 
Is 'big data' the new enemy like 'big pharma' or am I misunderstanding you? 
You know bitcoin is not anonymous right?
Click on the link. Read the "Motivation" section in the README.md.
The real advantage of Python, to me, has nothing to do with its one-liners. One liners are cool and all but they don't make a language *great*. I think, just post something you think just *isn't awesome enough* and {I,we}'ll try and show you what can be done. That might be a more direct way to show you what's cool. I do have to say, though, if you've never used a dictionary of functions you're not thinking high-level enough, though.
If it were easy it would bw cheap. You tried your own so you know just getting spam under control is hell. 
Like, some sort of desktop software that handles mail and PGP. Maybe call it a "mail client" ...
apart from its clean sytax, i always miss automatic unpacking in other languages. it is just so damn simple to write a function with multiple outputs.
Any examples of how the generated HTML look? Also, just like /u/mscook I cannot see the advantage of this over Sphinx. I can get Sphinx to work and the automatic API documentation seem to do everything I want. But I guess it boils down to one simple question. Can pdoc improve [PRAW's Sphinx generated API documentation](https://praw.readthedocs.org/en/latest/pages/code_overview.html)?
I have seen *amazing* speedups from using Cython. Literally 1000x faster for a numerical algorithm (mostly a big for-loop) operating on mostly numpy arrays. * Compiling anything with Cython is a possibility, but probably not worth the hassle if your code is slow because of text processing, file i/o or similar. * First, try to see if you can find suitable Numpy approach for your problem. It's often possible to write surprisingly complex calculations in 3-4 numpy calls. If your problem can be expressed entirely with numpy without iterating over the arrays in python code, adding Cython on top won't give much of an improvement (perhaps 20%, not 20 times). * However, if the perfect Numpy method does not exist, and are resorting to iterating over your data, then that's the module to compile with Cython. Very short HOWTO: * Make sure you have the latest version of Cython from pip. Various linux package managers are out of date. * Rename your numeric code module's .py file to .pyx, * Use pyximport from the main script ( http://docs.cython.org/src/userguide/source_files_and_compilation.html#pyximport ) to have it compiled at runtime without any extra build steps, and then * Start experimenting with adding a few "cdef"s (http://docs.cython.org/src/quickstart/cythonize.html and http://docs.cython.org/src/tutorial/numpy.html) The static typing part is the main speedup. Cython does speed up pure python code slightly - but if you add static C types, it can eliminate it entirely and run your algorithm without creating a Python object for each int or double.
Exactly the problem. That problem is going to be almost impossible to solve.
That's what I get for not testing it. Too much SQL lately.
I had a pretty good Exim setup back in the day (taken from http://www.penguinpowered.org/documentation/email_virtualhosting.html) and it did everything EXCEPT calendaring and spam really well. I used RBLs, spamassassin and some other bits to the point that my machine was generally running at around 70% CPU. The big benefit that Google has is the number of users. If 80% of people who've read a message mark it as spam, it's safe to mark it as spam for all of your users. I looked into 3rd party spam-only solutions - so I'd still do the mail hosting and that side of things, but I could set my MX to their server and they'd filter before it gets to me. Problem with that is that then you're giving all of your mail to someone else anyway, so I may as well just keep giving it to google ...
If you are working on an open-source project then: http://www.jetbrains.com/pycharm/buy/index.jsp No questions about it. Otherwise, umm I guess PyDev?
Your mind is going to explode when you discover PyPy.
You could consider eric: http://eric-ide.python-projects.org/. Current stable versions are eric4 based on Qt4 and Python 2 and eric5 based on Python 3 and Qt4.
These are all free and run on all platforms; I have used them for various sizes of projects * spyder: integrated debugger, very Python-aware (you can disable autoloading of numpy) * Komodo Edit: shortest learning curve (but no integrated debugger) * Eclipse with pydev plugin: brutal learning curve, but good once you get past that, debugger For more info see http://wiki.python.org/moin/IntegratedDevelopmentEnvironments 
Get rid of that stupid feedback tab, please. I'm not the guy who complained about it on the site.
From 2008...
Or just make make the margins a little wider. The site is great, but it's annoying that the feedback buttons covers some content :)
Does Py2Exe work for python 3? I don't think it does, but can't find it in writing anywhere. cx-freeze does, pyinstaller does not. 
Depending on what you are coding, I have found iPython Notebooks to be a good option for writing python code.
Big Data refers broadly to the technologies (like Hadoop) that enable analytics mining on very large datasets. (And big pharama isn't my enemy - they manage to produce products that help me live longer and better.)
&gt; Seems funny that you would write a package because you could not get Sphinx to work. If a tool is so complex that it's difficult for me to work with it, then I don't want to use it if I can avoid it. &gt; I disagree with the further points. If my documentation isn't with my source code, I have no hope of maintaining it.
&gt; Also Markdown and not reST... The rest of the Internet uses Markdown. I only have room in my brain for one plain text markup language. It would be absolutely trivial to fork and [modify pdoc to use something different](https://github.com/BurntSushi/pdoc/blob/master/templates/html.mako#L69).
In writing an OCR engine
OK I'll give it the one month trial tax for everybody's help
&gt; Any examples of how the generated HTML look? There is a link in the beginning of the README. Here's [pdoc's documentation](http://pdoc.burntsushi.net/pdoc), which was generated with pdoc. &gt; I cannot see the advantage of this over Sphinx. See the "Motivation" section of my README. Automatic documentation is not a primary goal of Sphinx, where prose separate from your source code is encouraged instead. In other words, pdoc and Sphinx are solving the same problem in two very different ways. It just depends on which path you like best; I don't think either is objectively better or anything. pdoc is hands off and essentially zero-configuration. Sphinx requires a bit more maintenance. &gt; Can pdoc improve PRAW's Sphinx generated API documentation[2] ? Dunno. Here's [how it would look, though](http://burntsushi.net/stuff/praw/index.html). To be clear, I don't typically have a problem reading documentation produced by others with Sphinx. I have a problem with *using* Sphinx myself.
You could also try https://github.com/fortharris/Pcode
Vim **editor war commences*
&gt;People who can code in the world of technology companies are a dime a dozen and get no respect. i am 21 and in 2nd year of my computer science degree(under-graduate) his advice has mad me sad.
Yeah on mobile at least, it covers content for no reason. 
Also, threading in python sucks because of the GIL. You get better results with async io and multiprocessing most of the time.
Big difference: the Mailpile server runs on your own computer, so it's as secure as any other locally installed application. 
[In English](https://github.com/BoboTiG/python-mss).
Or Emacs! :D
IPython + SublimeText FTW! Disclaimer: SublimeText is *free as in beer* but not *free as in freedom*. You'll still be hard-pressed to find a better graphical editor. If vim/emacs isn't your cup of tea, this almost certainly will be.
Please post it on /r/python when it's ready! I've been struggling with pytesseract with very disappointing results. Is there anywhere I could follow your project? Is it going to be released as free software?
Dat haircut. It's like he has the godly-programmer-beard, only upside-down. Jokes aside, this seems rather cool =)
GitHub seems to be down at the moment. You can just go straight to [pdoc's documentation](http://pdoc.burntsushi.net/pdoc).
Or Acme!
I long for the day when people say "remember the '10s? lol freakin' lightboxes everywhere" Lightboxes are the new frames
Which is probably a better fit for async anyway. Why dedicate memory to extra threads if they're just sitting there doing nothing much of the time?
that is something subtle, but absolutely incredible.
I have done lists of functions for menus and such. That instantly cut down on a lot of code. What situations do you use function dictionaries for?
If all your threads but one are just waiting, then by definition you could do the same work more efficiently in a single thread. Also you wouldn't lose context switching control and debugging sanity.
1. Good to know, thanks for pointing it out. Ruby's blocks sound potentially convenient. 2. Also good to know. And here, Python's lack of participation in the control flow makes sense for its philosophy of organization and structure. (It doesn't support gotos either, etc.)
In developing a pretty complex OCR engine I don't think IDLE will cut it
I forgot to mention that I working on OS X
&gt; (It doesn't support gotos either, etc.) That's not really the point though. The point of blocks is that they allow building structured flow control out of language elements, without having to bake them into the language. This allows language users (aka developers) to build novel flow control structures as easy to use and as seamless as the "core" flow control. I'll use Smalltalk as I find Ruby's blocks distateful: Smalltalk has no syntax for `if`. It has no syntax for `for`, `while`, `try:except:` or `with` either. All of these can instead be built from single-dispatch (method calls) and blocks. For instance, if condition: do_thing() else: do_other_thing() is written like this in smalltalk: condition ifTrue: [ thing do ] ifFalse: [ other_thing do ] `ifTrue:ifFalse:` is a Smalltalk message (a method call) on boolean types[0], `[ ]` is the syntax for a block. Now you could build something similar in Python by having a function taking a boolean and two functions, or creating your own boolean-ish and adding such a method on it, but you wouldn't be able to do this: if condition: return v1 else: return v2 with blocks, you can: condition ifTrue: [ ^v1 ] ifFalse: [ ^v2 ] (although in this case I could also have written `^condition ifTrue: [ v1 ] ifFalse: [ v2 ]` as the result of this message will be the result of the corresponding block) That's why they're called "blocks", although they are first-class structures and can be passed around things like `return` (which smalltalk spells `^`, as in `^ v1`) operate at the level of the enclosing method as in a C or Java block (which is not first-class) [0] it's easy to understand why `Boolean` is an abstract type in Smalltalk, with two concrete subtypes `True` and `False` each of which has a single instance across the system
I think he's talking about computational science. Just prefix your discipline of choice with "computational" and it turns out that's a major research area in itself. Computational biology, computational physics, computational economics, etc. (Although he might mean other things as well)
Take that sadness and forge it into inspiration.
It shouldn't. Typical programming work in technology companies doesn't even require a CS degree, just a high school education and ability to code in a couple languages like java, C#, basic understanding of data-structures, even more basic for algorithms, and an interest in computers. Computer science has a much larger scope than that and there are avenues to branch out. In fact, machine learning, artificial intelligence, numerical analysis guys are going to be the hottest commodity in this decade. You might as well go to grad school with these disciplines.
Yea sorry I've kinda wrote this post on the go so I forgot sorry
Well, I'm giving Vim a try on Python. It's pretty cool but it's got a somewhat steep learning curve if you've never touched it or *vi* before. I'd suggest a Python-specific IDE. If you're going open-source, give [Jetbrains' PyCharm][1] a go. They make good stuff. I love IntelliJ IDEA, their IDE for Java. Edit: It looks like you have to apply for an open-source license, and await approval. Maybe not your cup o' tea. [1]: http://www.jetbrains.com/pycharm/ 
I prefer PyCharm, but for free I like [pyscripter.](https://code.google.com/p/pyscripter/) 
No love for PyScripter? Well then...
"Unless you're working on a massive, complex project, I don't see how you would need anything other than assembly" See the flaw?
`from numpy import *` by default? No thanks =/
&gt;Anything other than assembly How does that equate? It's not like I'm telling him to just use Notepad.
PyCharm is the best Python IDE I've worked with so far. Even bought a commercial licence for my private and business use.
No, you're telling him not to use a REPL with features that make development faster and more enjoyable.
Ed, man! Man Ed!
This is how i learned Threading, there is a similar article about multiprocessing http://www.ibm.com/developerworks/aix/library/au-multiprocessing/
so? Nothing has changed in that field since 2008..
Curious, why machine learning?
On my font rendering wrapper, I have a tuple as my dict key # font class snippet def load_font(self, font=None, size=16): k = (font, size) if k in self.fonts: return self.fonts[k] = load_ttf( ... ) 
No, I believe things have changed. We have now got quite a few mature async libraries out there now as compared to 2008. People are now aware of the advantages of async, non-blocking IO due to the node.js boom. We now have `concurrent.futures` which handles both thread and process pools transparently. Do you still believe this article is practically relevant?
In python, you never use "getters" / "setter"s. You use normal attributes, and if needed, upgrade using @property External code doesn't need to even change. 
I used to use Sublime Text 2 with Sublime package control ( https://sublime.wbond.net/ ) SublimeRope ( https://github.com/JulianEberius/SublimeRope ) SublimeLinter ( https://github.com/SublimeLinter/SublimeLinter ) SublimeJedi ( https://github.com/srusskih/SublimeJEDI ) PdbSublimeTextSupport ( https://pypi.python.org/pypi/PdbSublimeTextSupport ) That will basically setup a Python IDE within Sublime Text, with errors/warnings in the gutter, auto completion etc. The only "manual" procedure is debugging via pdb. I've recently reverted back to Vim (old habits die hard), and here's the .vimrc I started from, which will more or less give you the same in Vim. https://gist.github.com/jinie/6243645 EDIT:I made a few screenshots of how it looks. Showing gutter marks, autocompletion, and some of the refactoring options. http://imgur.com/a/0iF81 Of course Vim does it just as well :) http://imgur.com/slTtgLv
Look for Geany. It's not specific to Python but it has syntax highlighting and auto complete that works quite well with Python. 
Kate, it looks great, runs fast and has a vi input mode.
Machine learning is the revolution. It's going to be key in artificial general intelligence which is going to turn the whole human condition upside down within one or two decades. Computer beating chess grandmaster in 1997, jeopardy champions in 2011, Google driverless cars, this is all heading towards a major disruption very soon. For details, follow up on the subreddits /r/singularity , /r/Futurology .
I use Vim (which is a bit of a pain to learn), although I hear Sublime Text 2 is a fantastic modern editor that works well with Python, just be careful with (raw_)input().
I haven't seen this before, it is GLORIOUS. Thanks for sharing.
I was thinking of making it open source but then I started calculating the costs and I decided to sell it
Visual Studio express w/ python tools installed.
Well regarding async, Tornado is defiantly my choice to go. Regularly i wouldnt use threads and go with multiprocessing right away. 
There's no IDE that stands along pycharm?
Big Data is a marketing buzzword that's been derided by the self-styled John Galts of the world as nefarious.
[it was already posted some time ago.](http://www.reddit.com/r/Python/comments/10y7od/pycon_uk_2012_create_beautiful_commandline/) The author of the library even made some comments their. Anyway nice link :)
&gt; To be clear, I don't typically have a problem reading documentation produced by others with Sphinx. I have a problem with using Sphinx myself. * http://sphinx-doc.org/ * http://read-the-docs.readthedocs.org/en/latest/ &gt; Automatic documentation is not a primary goal of Sphinx, where prose separate from your source code is encouraged instead. * http://sphinx-doc.org/ext/autodoc.html * http://sphinx-doc.org/ext/autosummary.html &gt; The rest of the Internet uses Markdown. I only have room in my brain for one plain text markup language. From [here](http://www.reddit.com/r/Python/comments/1j0gid/sphinx_extension_with_support_for_google_style/#cba8dnx) (emphasis added): &gt;&gt; If only just 1% of modern Python packages knew how to write good **docstrings**, &gt; &gt; From [here](http://www.reddit.com/r/Python/comments/1ew4l5/im_giving_a_demo_of_python_to_a_bunch_of_java/ca4htwo) and [**here**](http://www.reddit.com/r/Python/comments/18w8si/why_i_dont_feel_so_bad_brian_curtin_about_python/c8jby1t) : &gt; &gt;* http://sphinx-doc.org/markup/desc.html#info-field-lists (`param`, `type`, `raises`, `returns`, `rtype`) &gt;* http://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Comments#Comments (`Args`, `Returns`, `Raises`) &gt;* https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt#sections (`Parameters`, `Returns`, `Raises`) 
It's "fully functional cross-platform" and it hasn't been tested on Windows 8 or Mac OS X?
It's actually been discussed here before: http://www.reddit.com/r/Python/comments/u6ap4/docopt_02_argument_parser_that_kicks_more_ass/ where it received a lot of criticism
&gt; http://sphinx-doc.org I don't have a problem with Sphinx's documentation. I have a problem with its primary mode of use. I want my documentation coupled with my source code and I don't want to have to fuss to present it in a nice way. Sphinx **requires** fuss **by design**. That's **fine** if you like that kind of thing. I don't. Hence, pdoc. It's an **alternative** to Sphinx and a **replacement for epydoc**. Since it needs repeating, I'll say it again: pdoc and Sphinx solve the same problem in **two different** ways. &gt; http://sphinx-doc.org/ext/autodoc.html I am quite aware. I've never been able to get it to work. The tool is too complex for me to use productively. I have trouble finding enough time to write good documentation as it is. If I have to fight with a complex tool to do it, then I have no hope of writing documentation. Which means I have no hope of getting others to use my software. &gt; From here[5] (emphasis added): I don't want special syntax rules. I just want free form text with some ability to format things and show code samples. I value simplicity. pdoc is simple (&lt;800 SLOC). epydoc (&gt;10,000 SLOC) and sphinx (&gt;20,000 SLOC) are not. If you're happy with Sphinx, then pdoc just isn't for you.
Worth the price, like most JetBrains products it just "works"
"An attempt to create". It is under development, any help is welcome to test on non-tested systems :)
http://youtu.be/qzC5H5xrr-E 
Consider this an official plea to change your mind =)
Dime a dozen but still not enough for all the jobs out there.
Things like state machines and just generic forms of dispatching. Ranger, which is definitely *not* my work, is a file manager that uses a dictionary of "keys" for sorting directories. Often a dictionary can replace a list with these sort of things and end up looking nicer, although it's circumstantial.  At least it did last time I checked the source
&gt;I need to start doing more list comprehensions You need to start doing more *generator* comprehensions. The iterator-centric programming model is a lovely place.
Ok, I definitely see where you are coming from on that front. Honestly, I can't believe that I haven't realized that yet. 
This is a repost that I do not mind in the least.
Whilst I don't think they should model this client on Bitcoin, I don't believe that the client is intended to focus solely on security/crypto as opposed to anonymity.
What do you have against argparse? It seems to handle the simple cases very well.
What do you not like about `argparse`?
are these kinds of user-garnered ratings really normally distributed? 
&gt; I wish that Python had a **good** command-line argument parser in the standard library. Both optparse and argparse are excessively verbose, I find.
Excessively verbose. May just be me.
The criticisms were pretty poor. I saw three. &gt; 1) Not good to have runtime behavior depend on the docstring because -O0 can optimize docstrings out of the file and also because it gives people the willies &gt; &gt; 2) Might confuse people who've never seen it before &gt; &gt; 3) docopt is guessing what my usage/help string means and it's not good to have it guess 1 is silly, just move the usage/help string out of the docstring. Problem solved. As for #2 it's pretty hard to fix stupid. So... yep. 3 is just plain wrong. docopt is parsing the usage/help strings based on a well defined DSL. As long as the DSL is solid I think it's a great idea and I'm amazed that it's taken this long for someone to come up with it.
i would really like to make it free, and i don't believe donations/ads will cover the costs.
Enable development mode. Vim is installed. 
How about making a kickstarter? Tesseract is great, but the python bindings are absolute shit. I'm sure people would be willing to fund you. I could probably pitch in a few bucks myself. Or what about making it free for non-commercial use?
I disagree. I provide CLI counterparts to all commands/actions/distinct-chunks-of-business-logic that would normally be invoked by a web interface. Makes it much easier to test and develop, even if some of the commands have, like, 10 arguments.
&gt; even if some of the commands have, like, 10 arguments. But why would you invoke such a command from the command line and not from a throwaway Python script?
Nice to see a rebuttal. It's annoying that you often only see one side of the story on these very opinionated threads.
I don't see it going well on kickstarter lol. And as I said I'm working on a really low budget here and it still costs me a lot (for me) so that's why. Sorry.
Very fair. I tend to just copypasta my argparse stuff in from old projects and then replace the values, rather than re-writing by hand. This is probably not a good sign.
My goal is to make every operation possible from the GUI possible from the command line. This forces me to divorce functionality from UI, so it results in an application that is easier to reason about, test, port, etc.
That is a cool idea
Sorry to be late at the party; could you explain how can one get in high-level programming thinking? I've just learned python for a year, I can do most of the things I need but sometimes unnecessarily complicated. I don't really know OOP or really writing my own modules yet. 
I'm kinda sick of people describing code or interfaces as 'beautiful'. It's so clichd. Surely there's better adjectives to use.
Why not support both? Python docstrings historically are in reST, seems odd not to support that format by default.
I like to keep the dependencies slim, but you make a good point. I'd happily accept a pull request adding support for reST :-)
At least he didn't label it "For Humans". 
PyPy is an implementation of Python 2.7.2. All pure python modules should work well. C extensions can be compiled against PyPy, but YMMV.
Editra
*there
You would invoke it from a bash or perl script, so you need the command line interface. In fact in Bioinformatics or other complex work, you may have lots of such scripts that you use as standard invocations, just so you don't have to type so much.
This is wonderful. And by the way - this - simple rules, being allowed to be used multiple times, and in combinations, and re-used etc... This is the essence of the UNIX philosophy. Simplicity, elegance, and each part can be (re)used with the other parts. All our code should have these properties and should be this elegant. But its not easy. It requires a lot more thinking and work to make code simple and elegant. But its worth it 384 lines of code. Very, very nice. 
As has already been mentioned, a full IDE is not required: A text editor with highlighting support and a terminal is more than enough for most python projects. I personally use emacs, and jedi (https://github.com/tkf/emacs-jedi) provides decent autocompletion, however beware that the learning curve of emacs is quite steep to start with. 
how else are you going to describe the argument parsing functionality? magic? and 90% of that code is the help strings which you are going to have to write anyway. 
Man, Python users are spoiled! ;-) In Delphi, even if you knew about the essentially undocumented TCommandParser unit, you'd still end up writing at least this much code: http://bo.codeplex.com/SourceControl/changeset/view/71461#1510664 Otherwise, the only command line parser is a function that gets the whole command line and a Paramstr function that just splits the command line based on spaces. 
&gt; I call it "library-oriented development". I up-voted it, and I like it!
Pydev is good. I have recommended it to students who have worked on Eclipse (Java) in the past and they don't have any major complaints. Sure, Eclipse sometimes barfs and you need patience with the issues you face (searching on google, posting on pydev forums/SO etc.) but it works most of the time. I can't stress enough the point of trying out stuff. Take an already big project (open source or your own), import it in any of the free IDE's and give it a whirl. Stick with the one which suits you the best. Might take some time but in the end you'll be with something *you* are comfortable with, not with what other people are comfortable with. :)
I like how in python EVERYTHING is an object. The usual suspects like ints, strings, lists and dicts are objects, as well as functions, classes and everything else. This provides the language with a lot more flexibility and power, that its simply not available in other languages such as Java. One example of this are decorators. In python you can write this code: @my_decorator def my_function(*args, **kwargs): pass The @my_decorator syntax is just sugar for the following code def my_function(*args, **kwargs): pass my_function = my_decorator(my_function) Namely, my_decorator is a function that takes a function as an argument and returns a new function. This allows you to wrap your functions with added functionality, and abstract that extra functionality away and reuse it elsewhere. I personally use this decorator when debugging: def print_args(func): def wrapper(*args, **kwargs):- print "Calling", func.__name__ print "args:", args print "kwargs" ".join(["%s=%s" % (key, value) for (key, value) in a.iteritems()]) return func(*args, **kwargs) return wrapper Adding @print_args before the declaration of any function results in the name of the function and its arguments being printed before its invocation. Other things that I have implemented with decorators include: timeouts, acquiring/releasing resources (see also contextmanagers), and many many other things. This answer in stack overflow explains decorators much better: http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python#1594484 
Code COBOL for a bit, then come back and see if you feel the same way. Or Delphi. Or C++. Today I learned there's no way to assign more than one value to a non-dynamic array in Delphi. Got a three element array? There's no way to do someArray := (5, 6, 7); EXCEPT if you initialize it when you declare it you _can_ do that. And you can do it in code for dynamic arrays. But there's no way to just add an element to a dynamic array. Dynamic arrays have sizes(!?!) and if you're at the maximum number of elements you have to set the length to the length + 1 then add your element. Except you're told to never, ever do this because it thrashes the heap and performance is horrible. So you turn to TList, but that only handles pointers. So you look at the Generic version of TList, defined in another unit and also called TList. That's reasonably like a python list except you have to create it and manually free its memory... and possibly its contents, too, depending on the contents. But then for that there's TObjectList. Then you find you can't iterate through a group of TLists because Delphi sets are apparently defined by bytes dating back to Turbo Pascal for DOS so a set can only hold an integer up to 255! You try to make a TList of TLists but then realizes that works by value rather than reference so you'll still need to copy all the lists back out again to their original variables. In the end, you just call the same function over and over for each TList. Then you write the same code in Python. You're able to do things like adjust_early, adjust_mid, adjust_late = (process(item) for item in (early_scores, mid_scores, late_scores)) rather than adjust_early := process(early_scores); adjust_mid := process(middle_scores); adjust_late := process(late_scores); etc. and find it takes half the words and about 1/3 the characters and was intuitive and simple and ran correctly the first time. Try using languages other than Python and you'll quickly realize how beautiful Python can be, and that even the tiny features we don't talk/think about like multiple assignment and tuple unpacking can lead to clear, simple, beautiful code. Heck, I found myself with an equation where what a value was divided by depended on it were the high score or not. Originally I started by testing the score and if it was high doing the equation with value A and if not writing it out again with value B (in Delphi you tend to everything many times over). Then I thought that was unnecessary thanks to Python and decided it would be clearer to do the equation once but assign a value to another variable first according to the score. But then I started wondering what to call the new variable... temp? Denominator? Meanwhile, in Python the answer was, as always, simple and obvious despite being a complete Python neophyte: score_rank = (score / (high_score if score &lt; high_score else next_highest)) Simple, clear, English-like, beautiful.
If the beauty of Python encounters the Metro interface of Windows 8, though, don't they annihilate like matter and antimatter?
As a frequent pivotal user, I just want to say that this is truly awesome. It seems that a lot of hackers would rather stay in cli mode for large periods of time and as a result, their progress on pivotal is not true to their actual work. Incorporating such key pivotal functionality right into the CLI should really help - Thanks!
If you watched the video all the way through, or googled docopt, mutually exclusive options are defined with (--option|--other-option)
what happens if you want to specify the type of some of those options? I just find it easier to use the built in library...
I'll give you that. It offloads some of the complexity to you, but you know what you expect, and can code around it. For lame-ass scripts, something like assert type(arg) == int or something along those lines. There are, however, some rumblings in the github repo about adding a Schema object and such to have that all checked for you.
One of my favorite libraries.
Or emacs with evil [1]! [1]http://www.emacswiki.org/emacs/Evil
 """Usage: pep8 [options] input ... Options: --version show program's version number and exit -h, --help show this help message and exit -v, --verbose print status messages, or debug with -vv -q, --quiet report only file names, or nothing with -qq -r, --repeat (obsolete) show all occurrences of the same error --first show first occurrence of each error --exclude=patterns exclude files or directories which match these comma separated patterns (default: .svn,CVS,.bzr,.hg,.git,__pycache__) --filename=patterns when parsing directories, only check filenames matching these comma separated patterns (default: *.py) --select=errors select errors and warnings (e.g. E,W6) --ignore=errors skip errors and warnings (e.g. E4,W) --show-source show source code for each error --show-pep8 show text of PEP 8 for each error (implies --first) --statistics count errors and warnings --count print total number of errors and warnings to standard error and set exit code to 1 if total is not null --max-line-length=n set maximum allowed line length (default: 79) --format=format set the error format [default|pylint|&lt;custom&gt;] --diff report only lines changed according to the unified diff received on STDIN Testing Options: --benchmark measure processing speed Configuration: The project options are read from the [pep8] section of the tox.ini file or the setup.cfg file located in any parent folder of the path(s) being processed. Allowed options are: exclude, filename, select, ignore, max-line-length, count, format, quiet, show-pep8, show-source, statistics, verbose. --config=path user config file location (default: ~/.config/pep8) """ from docopt import docopt arguments = docopt(__doc__, version='1.4.5') I do have to admit, docopt does look like magic a lot of the time.
similar concept: [options.py](http://apenwarr.ca/log/?m=201111#02)
Happy to help hatesPonies -- let me know if there is anything else you would like to see in the util
Why not three?
It's all help text. And much more readable. 
I was worried about that too. Then I started to work through the article and I found it to be surprisingly informative. It may not cover the 'latest and greatest' techniques, but it does cover the fundamentals. I would still highly recommend it for any beginner in python looking to learn threading.
Can someone ELI5 what's happening here?
&gt; You would invoke it from a bash or perl script, so you need the command line interface. I'd rather invoke it from a Python script.
I wrote about five thousand lines of code working on a big Python Flask project using Sublime Text and was very happy with it. Then I discovered PyCharm ;) Plugins I used: * [SublimeLinter](https://github.com/SublimeLinter/SublimeLinter) * [SublimeCodeIntel](https://github.com/SublimeCodeIntel/SublimeCodeIntel)
You describe how you want the program to work in the comments, and the module parses the comments, and creates the argument parsing code to do the job. In the example, he took the --help output of one program and used it to create the necessary arg parsing code in a couple of lines. [example](http://www.reddit.com/r/Python/comments/1kfqb6/create_beautiful_commandline_interfaces_with/cbovada) 
Things which are annoying and verbose here: * having to type (or copypaste) parser.add_argument ten+ times (am C programmer; 6-character function names good, long function names bad) * having to provide fields names (action, help, type, default, &amp;c). Hm... it sounds like I could probably solve my own problems via a concisely-named wrapper function taking only positional args. Maybe I'll do that then.
Once I got in a situation that py2exe didn't work and I found PyInstaller. I never gone back.
&gt; PyInstaller I've read some about it but never actually tried, I do like the fact that you can create a stand alone for Linux too. Let's try it right now, hang on there..
It's so speciecist it should be illegal. ... so very not-fair for us non-humans.
&gt;&gt;You would invoke it from a bash or perl script, so you need the command line interface. &gt;I'd rather invoke it from a Python script. Forgive me, python is a wonderful language but it lacks the interactivity and terse flexibility of bash for doing things like aliases and quick mapping of long, complex commands into short simple invocations that can still handle the processing of command line arguments and options. Conversely of course, bash is nowhere as powerful a programming languages as python, nor as elegant :-) but for the work of making long, complex, command line invocations usable, bash is the better choice. Its far easier and shorter to code and it takes much less time. For everything else Python IS better. :-) 
&gt; but for the work of making long, complex, command line invocations usable The entire point is that if you try to make your scripts easily invokable from Python, at some point you no longer need to invoke command line utilities. And then syntactically you use dots instead of pipes, add some parentheses, and do not prefix option names with dashes. Like, not a huge difference, overall. On the other hand you no longer have to worry about escaping in your arguments and imposing reliable structure on the data you process. Can you recite from memory the "separate input/output items with nuls" flags used by grep, find, ls?
The [documentation on the homepage](http://docopt.org/) is excellent and covers a lot of this. It doesn't know anything about type though, and I'm not sure what you mean by 'counter' - are you referring to repeated flags, such as '-vvv' for 'high verbosity'? 
You can't deny that it's a great option to add a quick simple cli. 
&gt; The documentation on the homepage [...] covers a lot of this. Right, but I'm asking ivosaurus because he implies what he posted is a translation of the original, yet all the features I've mentioned are used in the original and not in his translation. What he posted is a half-assed partial reimplementation of the original which would require extensive custom code to reach feature parity. But oddly enough, he didn't mention these caveats. I wonder why. &gt; The documentation on the homepage is excellent Meh. &gt; I'm not sure what you mean by 'counter' - are you referring to repeated flags, such as '-vvv' for 'high verbosity'? Yes.
Shouldn't programmers be spoiled?
That's pretty easy to change. Here are two [fixes](http://stackoverflow.com/questions/14400993/spyder-default-module-import-list) in one post on stackoverflow
Oh god, I think I'd shit myself if I could use that in C.
[Here you go!](http://docopt.org/)
Eeeenteresting...
It was a few months ago, so I'd have to look at the code to be sure. And I'm about to hop in the car for a trip, so can't do that now. But there's nothing "theoretical" about its limitations: it lacks built-in validation. You have to write that with a separate tool - which isn't based on the same usage information. So, no matter what, you're stuck with some information in the usage string and some in code. I think the problem I was having might have been with multiple identical options. It was for a command-line game and the user can provide the 'side' as an option and a list of 1-N monsters for each side. Perhaps Docopt can "theoretically" handle multiple identical options or lists of values, but in practice it sucked.
I'm not a programmer by trade/training but I use python to make various tools that help me at work. I've tried a couple different IDE's then ran across Python(x,y) which is billed as "A scientific distribution." It uses Spyder as the front end and I've been pretty happy with it.
Ironically I'm a scientist, but I find that good coding practices go a long way (unlike the vast majority of my colleagues, unfortunately). I've been bitten by * imports enough times to stay far away from them. Spyder is definitely a cool idea and it should help move people away from Matlab, but: 1. It turns out I prefer ipython notebooks 2. I *really* don't trust developers who do `from blah import *` in production code. It makes me wonder what other bugs they're inadvertently introducing.
Wonder what /u/fijal thinks about this.
Thanks for sharing your experiences. 
The topic of argument validation has come up a few times. Personally, I've never used any argument validation with argparse nor am I aware of any special facility argparse provides for doing validation beyond type checking (string, int, etc). Any time I need validation I always code it up outside of the parser because that has always struck me as far easier than trying to shoehorn validation into the argument parser. Is validation beyond basic type checking (range checking, regex validation, etc.) something that people do with argparse? How does argparse make this easier than doing the validation after the arguments have been parsed?
Entirely serious suggestion: punt on cross platform GUI, serve HTML on localhost. Launching your app opens a web browser. Depending on what you're doing, this may be even better than hacking together a wx or qt gui. Guaranteed cross platform, you can use your existing web design expertise/materials, and underlying dependencies (of which there are a LOT for GUI stuff) reduce in scope. Accessibility is built in. For Windows, I use py2exe with the option to put everything into one .exe file. Don't have a suggestion on *nix/OSX.
Eclipse with PyDev is how I do everything. Excellent autocompletion and analysis features, integrates with source control, cross-module name lookup... it's excellent.
Thanks, but this is one of those apps that's seriously sub-optimal as a web app (it's for moving/renaming images). Here it is if you're interested: http://www.alanlight.com/dim/Dim.htm
I would suggest using PyQt or PySide (depending on your licensing requirements). They are almost identical and very awesome. Qt and Python actually work very well together.
Jump to definition = Control+Command+Alt+Up Go back = Control+Command+Alt+Left Manual Code Intelligence = Control+Shift+space Why not just use emacs ? :-D
In a previous job I created GUI application using wxpython that ran in Windows and OSX. We distributed executables created with [py2exe](http://www.py2exe.org/) and [py2app](https://pypi.python.org/pypi/py2app/). The configuration options were not obvious but, eventually managed to make it work. Others are recommending that you go with a Qt based solution instead. Although Qt is probably nicer to work with, wxpython is just as capable of producing a working GUI. In both cases, the bigger problem is how you are going to package and distribute the application. What you need to figure out first is the whole process of building a package that can be executed in your target hosts. Start by setting up a new virtualenv, installing wxpython and py2exe (or whatever applies for your platform) and create a toy app that you can get from development source to a built package ready to run in your target host. Test in all your target platforms. With that, you will have a solid foundation you can build upon. At least, that's what I wish I had done when I faced this problem. 
I have yet to delve into ipython, though from what I've read the notebooks would be a GREAT way to disseminate some of my work to teammates. This made me curious so I looked at the startup script for my installation. Here are all the import statements: from pylab import * import numpy as np import scipy as sp import matplotlib as mpl import matplotlib.pyplot as plt import guiqwt import guiqwt.pyplot as plt_ import guidata from site import _Printer Importing a package as an alias is considered a good practice right?
I and some of my coworkers have been using a free scientific distribution called [Python(x,y)] (https://code.google.com/p/pythonxy/) but recently management has taken notice of some of our work and I've heard some talk about buying the Enthought suite to replace Python (x,y). Not sure why.
Can you try numba on the python version? http://numba.pydata.org/
&gt; The command-running logic is encapsulated in separate classes like CLI or WebUI, that take care of instantiating Command instances and parameterizing them with the necessary inputs (command line args or HTML form values). I entirely support that, actually. After you wrote your code as a library, sure, feel free to write a separate UI (of any kind, of multiple kinds) for it. &gt; And because it would take about 50 lines of Python code to replicate the amount of work the CLI class does automatically for you behind the scenes when processing one command line invocation. My point is that maybe it's better to tell your customer sysadmins to do #!/usr/bin/env python2.7 import thing thing.run(reticulation=thing.FULL, splines=13, ...eight more parameters) than to do the same, only via a shell-script utilising your CLI. Because those admins, trust me, they will write that shell-script. Conscientious admins always write their command-line invocations as special-purpose shell-scripts. So... why not cut the middleman?
This is an insane, beautiful monstrosity. I will be thinking about this if I ever port Weblua to support LuaJIT, in addition to stock Lua.
Because my project is inherently more complicated than a trivial two liner bit of Python? Commands need to be parameterized and run in a very specific way. The CLI class removes the need to write all the boilerplate command invocation code. (Which you would have to do if you wanted to manually run one of the commands directly via Python.)
By the way, after going for a long walk and ruminating a bit on this, I want to clarify two things: First, I don't denote things as "insane" promiscuously. If you are building a monastery, and decide that having a 400ft drop could simplify plumbing, all right, that's probably a mistake, but not insane. Explaining how while, yeah, having to jump over a 400ft chasm on your way to the toilet sucks, but all your procedures and manuals and older monks, all are geared towards having that drop there, so fixing it is infeasible, still not quite insane. Describing that drop as an integral part of Freedom, that is insane. Second, in case you think that, I don't know, "Python is a programming language, a shell requires different things", consider this witchery: #!/bin/sh arg=$1 shift wrapped_program "$(which $arg)" "$@" How does it work? Isn't it impossible, you can have _anything_ (except nul, but that's tolerable) in your arguments: spaces, newlines, tabs, single or double quotes, it still works reliably! `which` can return anything at all too, it all goes to a single argument, OMG! Is it witchery, or maybe UNIX creators got an unusual spell of lucidity, or copied a sane approach, no matter, if at some point someone said, how about we pass the arguments as TEXT, THE ONE TRUE INTERFACE, and let programs strtok it on spaces, then somebody else must've replied, that would be retarded, let us not. So here you have it. What freedoms do you surrender in the name of safety as far as passing arguments goes? None. It turns out that the 400 ft drop is not necessary at all, and the freedom to plunge into it accidentally is not required, is not a freedom at all. It's a false dilemma. Why, then, the output of `ls -l` is not held to the same standard?
&gt; Commands need to be parameterized and run in a very specific way. Yes, and isn't it better to run them from Python three-liner than from a shell two-liner, since in the former case you don't have to deal with weird escaping? &gt; The CLI class removes the need to write all the boilerplate command invocation code. (Which you would have to do if you wanted to manually run one of the commands directly via Python.) What. By using a CLI you switch from using Python-style named arguments to dash-prefixed named arguments. Can you maybe explain what you have in mind on some particular example?
Don't forget reddit.
The current iteration of tk is actually quite nice. It also works with Python3. 
Ill watch it later... thanks!
The only way C# avoids this (in win-land) is all the automatic stuff. Doing raw c without VIM plugins is like pulling teeth.
Ah, I missed that distinction.
As another python-wielding geologist, this language allows me to do really complex analysis incredibly quickly. I haven't touched MATLAB in years, and I'm much better off for it. Now, to convince my colleagues...
Prefer generator expressions when possible.
WingIDE is incredible. I'd think it's much better than PyCharm (I have both). I don't think it has much of an emphasis on web development, but I couldn't care less about that. It's debugger is incredible and it's code introspection and search is far superior.
&gt; The shell script calls out to the Python CLI. It would have been hundreds of lines longer to write it directly in Python. Explain this. How is `import thing; thing.do_stuff(... args ...)` hundreds of lines longer than `./thing.py ...args...`? I work on inter-banking software, we have a shit-ton of Python scripts and it's one of the reasons I came up with this attitude, wtf, why do we have to jump through hoops to have our fragile system of shell scripts allow one Python script to call another Python script on weird "true UNIXEN" like HP-UX or AIX when we bundle Python already and can call shit directly (if not for the script being retarded and getting all the stuff together in the CLI part).
People have been saying that... but I do not understand a good context to use them in.
You got it backward, you should use them as the default. Modern python use iterators unless there's a good reason *not* to use them. For instance imagine I have an iterable of numbers represented as strings I got from some API somewhere and I want to sum them: total = sum(int(s) for s in some_list_of_strings) Had I used a list comprehension, I would have allocated a whole list for no reason. Another exemple close to something I had to do recently. Imagine you have two files containing each one half of a data set. They are tab delimited. You have to lowercase every line. You must ignore any line that contains the word "spam". You break them into individual items and send them to some function to process. Here's how it looks: from itertools import chain with open("file1.tsv") as f1: with open("file2.tsv) as f2: it = chain((line for line in f1), (line for line in f2)) # Now I can treat them both as one big file it = (line.lower() for line in it) # lowercased it = (line for line in it if not "spam" in line) # lines with spam ignored it = (line.split('\t') for line in it) # splitting on tabs for line in it: process(line) It looks like I'm transforming a full file in memory many times over but in reality, nothing runs until it has to and as little memory as possible is consumed. 
I've got to take some time to play with IPython Notebook. That notebook viewer link in the article looks amazing.
Cool, so if I'm understanding this right it does preemptive scheduling on green threads rather than relying on the green thread yielding? I can see it being very useful (if I'm understanding this right) in the use case where you're application consists of lots of IO bound threads and some CPU intensive threads, wheras with vanilla Gevent the IO boundthreads would get starved while the CPU intensive ones ran this should pre-emptively interrupt the CPU intensive threads and allow IO to keep happening.
Have you followed the link ? &gt; DIM handles the copying of images from your digital camera's memory &gt; card to your computer. Great idea to put that on a server! What zsouthboy is suggesting should work though...at least if you get py2exe to pack your micro-framework. 
As others have said, there's several good cross-platform GUI tools. What there isn't is a way to distribute your app cross-platform. Linux is, ironically, especially difficult to distribute something that will work across the various flavors of Linux. If you're targeting programmers or sysadmins you can give instructions and hope they figure it out. But reaching common users is nearly impossible.
You can use POSIX standards on on Windows programs...
The idea I think is that you run on localhost, with access to your local hard drive.
Cygwin? Ha ha, no that was eliminated from consideration before i even looked. I have hated cygwin for 15 years. Every 5 years or so, i think, "Maybe is should see if cygwin addresses more problems than it creates." And every 5 years, i go through the tedious process of purging that thing from my system.
Still haven't answered the question. Why can Windows programs use POSIX usage conventions?
Uh, what? I already explained this, POSIX utilities do not exist for Windows. Have you never tried to write platform independent code before?
In Python a class is an instance of the class "type". In fact you can derive this class and do some funny things (e.g. create methods from some definitions like active record does). Later you use this new metaclass like this: class MyClass(metaclass=MyMetaclass): ... Often you do something like this: class MyBase(metaclass=MyMetaclass): ... class A(MyBase): ... class B(MyBase): ... More on topic: Most of the time I rather write a function outside of a class instead of a class method. What are your uses for class methods?
Sure, not ALL of POSIX of is platform-independent, but the usage standard is just a format, like a specific way of organizing comments. I don't see where this library wouldn't work in Windows.
Or rather, that s walks like something that can be used to construct a new list, talks like something that can be used to construct a new list, and quacks like something that can be used to construct a new list. As I said, it is technically the *right* way to do it (not *best*, but *right*), but probably not the one people are going to end up using.
Argparse makes it extremely easy to check for type, whether or not the value is mandatory, what the default is, and what the valid values are. Beyond this I just write Python code. I've never run into a situation where schema seemed like it would be simpler to work with than my python code. You can do extra checking with subcommands. But I've always found that extremely confusing - it's where the complexity simply becomes too much. 
You understand it correctly. 
Never tried it =)
Are you starting it with pylab=inline?
One by one I've (almost) converted my entire team at work to use PyDev, the Eclipse plug-in. I've been using it for years for both big projects and one-off scripts. I highly recommend it. One of the most useful features is remote debugging, where you run python on computer A and debug it in eclipse on computer B. Very useful for our specific work. 
So it isn't a transpiler after all like the article claims? 
In fact, they recently released version 1.0, so I'd definitely go have a look. It's a very enhanced interpreter at least, and an excellent scientific tool.
&gt; This allows one true concurrency despite CPython's GIL using green threads instead of OS processes or OS threads such that spawning a new thread is still cheap. &gt; Cpython's GIL prevents OS threads from running concurrently and switching context for any reason but to perform IO. I don't follow this. If the library doesn't somehow enable parallel execution of Python bytecode, why bring up the GIL at all? It doesn't appear to be referring to the performance penalty of GIL contention or anything like that... it's just kind of thrown in there to the effect of "GIL bad, this library good."
This is absolutely wonderful! I've often been afraid to move my projects to open-source, out of fear that they weren't "respectably organized". This is the sort of guide I need to turn my projects into something I can share with others, I feel.
What's awesome is that just recently Audrey Roy created a project template for her cookiecutter tool that implements nearly everything Jeff talks about. Which means following his practices is really easy. You can find it here: * https://github.com/audreyr/cookiecutter-pypackage * https://github.com/audreyr/cookiecutter
Could you please expand on this one? Because I'm doing this very thing and having difficulties. As a python script, no problem, works well, a simple cgihttpserver, data and variables sent via post as form variables, easy. Problems arise when i want to distribute it. Needs to be an exe. Sounds easy as py2exe, but then the server expects to serve a py script, not an exe file. I've read I can hack cgihttpserver code to accept .exe, but I'm not sure it will work. Will it, or there is a different approach? 
&gt;Code exists to do something, not to hang up as art. Thanks for that, Great Arbiter of the Purpose of Code.
I write code like this these days, and it's glorious. I've never had so much fun writing so little code that does so much. `docopt` looks a lot like a few things I've made - DSLs that parse multiline strings and allow creating complex structures with no, or almost no code. It took a long time to get to this point, though. I have more than a decade of code that isn't like this.
OK, I've made my best effort! Take a look!
From the github page *conpig threads still can only run on one core of a processor*. So far as I can see from the code all it provides is a periodic signal which is picked up by the executing coroutine (gevent/greenlet thread) and which switches threads. But that means the threads switch at unpredictable points in the code execution, which is exactly what you don't want to happen in a coroutine, because you have to introduce locking again.
One thing to consider is [esky](https://pypi.python.org/pypi/esky). It still uses py2exe, py2app etc, but it provides a very nice update framework if you're intending to provide easy updates to your application.
Except absolutely no one uses `for..in` that's just there (im guessing) to help people transitioning from other languages. The `.each` approach is what is known as 'internal iterators' and they are wonderful for a great number of reasons, not least that they enable you to compose successive transformations to the collection from left to right rather than from right to left, improving readability and making it easy to refactor. 
You can easily get docs and source using the [pry](http://pryrepl.org) console
`x == !!x` will check whether it's a boolean, but i have never, ever wanted to do this and can't think of a single legitimate reason why i would want to.
What exactly is unreadable about it? `@var` always means `instance variable`. Always. End of story.
Agreed
It looks great I'll give a shot
Have you considered using Ansible? I switched from Fabric to Ansible at work because the Fabric files were becoming to difficult to maintain and use. I use Ansible to manage a somewhat complex provisioning process that installs all the dependencies (nginx, uwsgi, java, flask), downloads and builds the latest stable redis, deploys our code, and builds a bunch of very complex backend environments. It can turn any stock Ubuntu environment into a custom application and database server. The best part is that the provisioning files are just simple YAML (not even code) so that everyone can understand it and reuse it for other projects without effort, and it's very fast for deploying or updating many servers at once. 
What there wasn't was a library to automatically provide concurrency like the threading library, for *green* threads. I don't particularly like billing this as "True" concurrency though.
Thanks for the heads up on Twitter, btw. I'm in the process of updating the post to include a link/info about Audrey's project (which is, of course, fantastic).
This is exactly what I was hoping for when I wrote the article. I was sure that there were people exactly like you: they've written useful stuff but don't want to embarrass themselves by not having all the bells and whistles usually seen on popular projects. Hopefully this article gives people a bit more confidence and more Python code is open-sourced as a result.
This is great! I've been piecing this together from varied sources for a few recent projects, and honestly several of them provide less useful information than this summary of them all. Many people find the multiple version support of git-flow overkill, and use the methodology without release branches (and just tag the releases). There are a number of scripts that help with that (we wrote [our own](https://github.com/iFixit/git-scripts) at work), although the vastly simpler process means you can do it with massive git without much trouble. I'd like to see a section on writing documentation that doesn't come from your docstrings, e.g. a getting started guide. I've started using [invoke]( http://docs.pyinvoke.org/) as the "finally we have a make replacement!" tool that allows me to not have to remember all these separate commands for running tests, building docs, publishing to pypi, eyc.
The decorators make no difference that I can see on my machine (in any of the versions). In regards to the memoryviews, they don't really maintain the same logic as the numpy arrays do. The views are less powerful than the numpy arrays. For example, you can't multiply two memory views together (obviously). This means automatically unwrapping all vectorised loops, which is sort of against what I was going for in the tutorial. I wanted to show how easy it is to get a massive improvement with practically no change to the original code. Numba would have been good for this but actually ended up being a bit of a nightmare. I'm interested in implementing the memory viewed version but I get errors when trying to index in to arrays using other arrays ala: vertex[face[:, 1], :] I can't use face to index in to vertex, which means I'd have to unroll that code. That is really undesirable because if I'm going to go as far as that I might as well just pass in the two arrays and write all the code in a 'C' style. Any advice on that?
here we go yet again [here](http://wingware.com/downloads/wingide-101/4.1.13-1/binaries)
I think it's faster than PyCharm (a bit of a java hog, imo) too, right ?
No joke.
Factory methods are the usual ones, but I have been known to plonk stateless functions in a class just to get the namespace I want.
&gt; Very small grains, when submerged in water, have a mass small enough that they reach a terminal velocity before any turbulence develops Terminal velocity is independent of mass. Very small grains, when submerged in water, have a drag coefficient small enough that they reach a terminal velocity before any turbulence develops &gt; For large grains  pebbles, cobbles  this effect is so strong that viscous forces become insignificant and turbulent drag dominates Sorry, I'm an aerospace engineer, but by definition, if viscous forces dominate, turbulence is all that matters. He means flow separation, which is not heavily influenced by surface shear stress (in the case of a pebble).
I have a very long answer, but the short one is that this code should have tests (or at least run pypy's tests)
I have some nit picks. After reading the README, I still don't fully understand what problem you're solving or what your solution actually is. My first nit pick is: what do you mean by "true" concurrency? I saw another comment mention that this was using preemptive scheduling---is that what you meant by "true" concurrency? Just say preemptive scheduling! :-) If that is indeed true, then this part of the README needs more explanation: &gt; You still need cooperative yields if you want true fairness for programs that don't do as much IO. Could you elaborate on how your preemptive scheduling algorithm is still unfair in CPU bound tasks? How does it differ from the current state of affairs? I think your README should provide an example that has different behavior when using `conpig` and say, `gevent`. The example you gave is IO bound and I imagine would run as expected when cooperatively scheduled. Finally, if your goal is to get other people to use your library, then please get it on [PyPI](https://pypi.python.org/pypi).
As I said: When you write a DSL. You might want to pass something like ":foo =&gt; true" to enable something with the default value or with ":foo =&gt; 12" to pass the a specific value. And besides this, from an OOP standpoint it is clear that true and false should have a common super class (other than Object).
cx_freeze works fine with Py 3. I recently made a project that worked without changes on Windows and Linux. And the size of the package is much smaller than using tk library.
Actually, I'm using the default start up script. I don't see a pylab=inline statement in the script. But this comment is directly above the pylab import... # Pollute the namespace but also provide MATLAB-like experience: from pylab import * 
I am personally a fan of Geany.
&gt; Also, your script should begin with a "shebang" line Why? Big kids type python.
Ha! Despite the fact you're spamming the comments with this now, you're getting an upvote for follow-through and because you used Qt ;) The screenshots look really good, the layout is great and there's consistency in the icons - it looks *together*. Something that always bugs me with IDE's is there's always distracting crap everywhere, drawing attention away from the work; this looks like you've put more thought into the presentation. Nice job! 
Eh, it can be useful if you are using some non-standard packages, and don't want your users to need to reproduce the environment for it.
I wonder what the major differences are between the timedltas in datetime vs numpy and which is best when using pandas.
Thanks for this! So there are a number of project templating solutions (pypi search: "project template"): * [PasteScript](http://pythonpaste.org/script/): `paster` (pypi: "paster template", "PasteScript") * [Templer](http://templer-manual.readthedocs.org/en/latest/index.html): `templer` (pypi: "templer template") * [Mr.bob](http://mrbob.readthedocs.org/en/latest/): `mrbob` (pypi: "mr bob template") * [Pyramid](http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/scaffolding.html): `pcreate` (pypi: "pcreate") From http://www.reddit.com/r/Python/comments/1jqo4w/looking_for_a_text_template_solution/ : &gt; Both SaltStack and Ansible support Jinja2 templates. There are also a number of recipes for [zc.buildout](https://github.com/buildout/buildout) that support [Jinja2](https://github.com/mitsuhiko/jinja2) templates. Someday, I should prepare a template with the following: * `setup.py` * `tox.ini` * `README.rst` * `CHANGELOG.rst` * `COPYING` / `LICENSE` ([lice](https://pypi.python.org/pypi/lice) from /u/jacobian's requirements.txt) And: * `docs/conf.py` ([`sphinx-quickstart`](http://sphinx-doc.org/tutorial.html#setting-up-the-documentation-sources)) * `gh-pages` / [github-tools](https://github.com/dinoboff/github-tools) * [paver](http://paver.github.io/paver/) * [cookiecutter](https://github.com/audreyr/cookiecutter) * [zest.releaser](https://github.com/zestsoftware/zest.releaser), VCS -&gt; CHANGELOG.rst I also find it helpful to link **`#[\d]+`** in changelog messages to project issues / tickets / stories. [EDIT] Links https://en.wikipedia.org/wiki/Continuous_integration https://en.wikipedia.org/wiki/Make_(software)#Makefiles
&gt; long_description is the document used by PyPI as the description on your project's PyPI page. As there is another file, README.md with almost the exact same content, I use pandoc to automatically generate README.rst from README.md. Thus, we can simply read the file README.rst and use that as the value for long_description. Wouldn't it be simpler (and more DRY) to use README.rst as the project's README?
What installation format are you using? Cygwin? Python(x,y)? MinGW?
How did you upgrade Matplotlib? Did you use Python(x,y)'s pip?
Pry is definitely amazing, but not all ruby code is necessarily written with that in mind (and there are way more functions that are dynamically generated/can't be connected back to source in Ruby vs. Python).
Perhaps you could have a look at "Open sourcing a Python project the right way" which is #1 in /r/python at the moment. It would be nice to be able to install this with pip, etc...
I don't like my configuration always sitting in non-logic executing files. There will be some sort of edge case which will be difficult to back out of. 
As someone who has used sphinx I understand why you'd want to write your own! There is plenty of room for simple auto-magically generated documentation alternatives.
No, I used the compiled Windows installer from PyPi...
For Windows, I just go here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#matplotlib http://www.lfd.uci.edu/~gohlke/pythonlibs/
I've really never had a case that required advanced logic. You can also execute shell commands and logic directly in Ansible. The major difference for me is that Ansible playbooks are very quick to write and understand by everyone in my team no matter what language they use, and Ansible seems to deploy much, much faster than Fabric and Ansible allows you to rerun failing tasks with much more verbose output. 
Yes, I am planning on putting this up on pypi.
If you never explicitly yield in gevent (by performing some kind of sleep, or the thread ending), I don't think you will never switch contexts: http://sdiehl.github.io/gevent-tutorial/ You can try it for yourself. def test(arg): for i in xrange(1000): -1 in xrange(1000000) print arg gevent.spawn(test, "X") gevent.spawn(test, "Y") gevent.sleep(0) On my computer this runs test on X then test on Y then ends. If we were to use conpig, it would run them both, interleaving the IO in the way you would expect most other languages to do it. 
&gt; utational fluid dynamics (with a background in mathematics and physics) pay attention in your numerical mathematics courses. In fact, if you aren't all ready taking computational mathematics, do so. Take stuff like computational ODEs, computational PDEs, and computational linear algebra. That stuff is the bread and butter of computational mathematics and is used in pretty much every field that develops models. &gt; I agree with yudlejoza when he says people with this background will be hot commodities. Any idiot can program. But can any idiot solve a trillion by trillion sparse linear system quickly? In O(n) time (where n is the number of non-sparse entries)? The answer is no because the mathematics involved in such a problem actually pretty non-trivial and requires quite a bit of experience in mathematics to even know why it works (see multigrid for the required solution). Who cares, you might ask. Well, turns out Netflix and Google do and a lot of their internal operations can be reduced to solving Ax=b where A has a bunch of special properties. Any idiot can program the algorithm in front of them, a good programmer knows why the algorithm works and where it comes from. &gt; Machine learning is also mentioned. Well, turns out that a lot of machine learning problems are really just mathematical problems in Maths is not my strong suite but i will start paying attention to it. My university is offering only basic maths courses like Cal-1, Cal-2, Applied Differential Equation, Linear Algebra and statistics but i will keep an eye for computational mathematics / numerical analysis. Thanks for detailed reply. Do you have any links for online resources i might check them out p.s i am not in united states
Just go to the source file and change or remove the requirement check...worked for me.
&gt; If you never explicitly yield in gevent (by performing some kind of sleep, or the thread ending), I don't think you will never switch contexts Of course not, but you can trivially change that if you want. And you can improve upon that by never interrupting a greenlet that is not aware it might be interrupted.
I recently wrote something very similar: https://github.com/priestc/better-hn/blob/master/crawl.py the Hacker News front page is actually quite hard to crawl. The HTML is very bad. The problem I was having was filtering out the job listings that HN likes to sprinkle into their listings of stories. The CSS on those job listings are the same as the regular submissions, making them hard to deal with.
I have not used wxpython specifically, but pretty much all toolkits have widgets for progress bars, menus and panels. Whether those look the way you want them to, or are easily re-skinnable, is a different matter.
Okay, so I do want to also build a skin for my GUI. How will I go about that? Any tools available? I'm sorry, I'm pretty much a n00b when it comes to GUI builing. :(
Alright. There's no CSS-like scripting for Python? I won't do it if it makes things exceptionally complicated. I need to make a GUI that has great design. 
Got it. This helps, I totally understood. Thank you so much! :) 
I don't have experience with wxpython. but I suggest to take a look at [PySide](http://qt-project.org/wiki/PySide). It is based on Qt, has easy sintax and solid documentation. It's cross platform too.
I am looking at it right now. Thank you. 
Amadiro is right, it is not really CSS, but is [heavily based on it](http://qt-project.org/doc/qt-4.8/stylesheet.html).
Qt has a toolkit called Qt-Quick which is javascript and json based. I used it for making prototypes for a design group and it's really good at letting you easily create customized widgets pretty quickly. Anything you need to do that can't be done from it's javascript built-ins, you can write C++ for and tie it in. That was 2 years ago, it's probably a lot better now too.
I suggest to start with [this tutorial](http://zetcode.com/gui/pysidetutorial/)
wxPython is kind of on hold as a project for some reason. There hasn't been a new version in years and it still doesn't support python 3. PyQt4 is the standard but costs money for businesses. PyQt5 is the newer version of PyQt. PySide is an free implementation of Qt, but is not as popular. Use PyQt5.
Bookmarked. Thank you!
Ah, I'll need the Javascript and JSON advantage. Thanks for this!
I was beginning to think I was the only one! :-)
My memory is bad, but don't the job listings lack a link to the comments? That might be a good indicator. Just looked at your source. That's not so bad! :P
Either Qt or Gtk should let you use arbitrary images for your widget backgrounds, if you want pixel perfect control. (HTML would let you do this too.) Don't know about Wx. Most of what makes a UI modern-looking is this sort of styling. Do you have an image mockup of what you want your final ui to look like? This is the hardest part. Bear in mind that most real world desktop apps would rather match the styling of the rest of the system than have their own special (out of place) look. I know Qt in particular has done a lot of work to make this possible. You might want to look at some real world apps that run on Mac/Windows/Linux.
I think: If a factory method always returns an object of a certain class, then why not just use the constructor instead? If it doesn't it has no place in this class.
I use Python's lists extensively (I love them) within my Django project. Django translates database values (I use MySQL) into list iterables called querysets. Looping through the querysets within the application is identical to looping through lists. Such raw power with these guys. Not having to worry about all the data types being the same (like in other programming languages) is an immense plus for me.
The only "cool" thing I can think of that's inherently based on lists is the [`heapq`](http://docs.python.org/2/library/heapq.html) module. Lists are pretty basic data types, as these things go. It's like asking "what's a neat thing you've done with strings?"
PyQt
Cool. I like writing lists in Python than in Js, PHP, or anything else. Its quicker and more beautiful 
These may be helpful for developing a modern GUI in your Python project: * https://pypi.python.org/pypi/urwid * http://www.reddit.com/r/Python/comments/1gext9/what_programs_use_the_python_gui_tools/ * http://www.reddit.com/r/Python/comments/1fmgdt/is_python_3_that_obsolete_what_is_going_on_with/
&gt;The decorators make no difference that I can see on my machine (in any of the versions). Now I think about it, they won't make much difference until memoryviews are used (I think). &gt;In regards to the memoryviews, they don't really maintain the same logic as the numpy arrays do. The views are less powerful than the numpy arrays. For example, you can't multiply two memory views together (obviously). This means automatically unwrapping all vectorised loops, which is sort of against what I was going for in the tutorial. Gee, that's a good point. AFAIK (but I don't know much) the best option as of now is to use `numpy.multiply`, `numpy.power`, etc. It's less pretty but it might well work. There's a pull request that'll get native elementwise operations in Cython, but that's not going amazingly quickly AFAICT. &gt; vertex[face[:, 1], :] Umm... *hides* --- One thing you can do, and what I'd likely do, is carry around both pure-Python Numpy arrays and the typed memoryviews. Use the Numpy arrays for Numpy operations and the memoryviews for indexing. One thing you've managed to do is "trick" yourself into thinking that typing helps in many places where it doesn't  your normalise function never uses the fact it's typed so it'd be just as fast in pure Python. Having the separation might remove some of this confusion
I'm not sure if this fits your question, but I've solved several ProjectEuler problems with one-line list comprehensions.
QT's QStyle and QML support 'skins', which are very similar to CSS. * https://wiki.archlinux.org/index.php/QT#Bindings * http://stackoverflow.com/questions/4762768/qt-and-ui-skinning GTK (Gnome) supports themes: * http://art.gnome.org/themes/gtk2 * https://wiki.archlinux.org/index.php/GTK%2B#Themes
Yeah. I think the simplicity and beauty is an important aspect. Writing more complex list comprehensions is nearly always satisfying as well
Lists are awesome, but generators are awesomer. A generator is like a list, where you can iterate over it, but you can not access by index. Its a function that will return values until it raises StopIteration. A lot of database interfaces actually use generators, instead of lists. They return one row at a time, so that they don't have to load the entire result at once. If you don't need the entire result (break out of the loop early), it can make your application more efficient. 
names = ['frank', 'sam', 'henry'] names[::-1] was cool when I first learned it, seems boiler plate now though. I find alot of people that didnt know that.
&gt; Lists are pretty basic data types, as these things go. It's like asking "what's a neat thing you've done with strings?" * http://docs.python.org/2/library/stdtypes.html#typesseq * [`array`](http://docs.python.org/2/library/array.html) * [`Queue`](http://docs.python.org/2/library/queue.html) * [`heapq`](http://docs.python.org/2/library/heapq.html) * [`multiprocessing.Queue`](http://docs.python.org/2/library/multiprocessing.html#multiprocessing.Queue) * [`collections.dequeue`](http://docs.python.org/2/library/collections.html#collections.deque) * [`collections.abc`](http://docs.python.org/3/library/collections.abc.html) [(v2.x)](http://docs.python.org/2/library/collections.html#collections-abstract-base-classes) * [`collections.OrderedDict`](http://docs.python.org/2/library/collections.html#collections.OrderedDict) [(source)](http://hg.python.org/cpython/file/tip/Lib/collections/__init__.py#l26) * [`collections.UserList`](http://docs.python.org/dev/library/collections#collections.UserList) [(source)](http://hg.python.org/cpython/file/tip/Lib/collections/__init__.py#l920) 
Thanks. Would be quite a nice speed up if there wouldn't be any compilation errors and strange behavior (less, great and cross). Beside that, the effort doesn't look that big to get a nice improvement. 
&gt; I'm gonna have to make a very modern GUI for my college project. What constitutes a "very modern GUI"? Do you have a screenshot? Better yet... do you have 2 screenshots: one for what constitutes a "very modern GUI" and one for the "not so modern GUI"? GUI toolkits give you access to a range of native or native looking widgets that can be used to implement a modern GUI. Most GUI toolkits also give you access to a generic widget. This generic widget can be instructed to paint itself. You can also have access to mouse and keyboard information. These generic widgets can be used to draw whatever you want on them... from pixel perfect static size backgrounds done in Photoshop that you just bit blit to dynamic polygons drawn in response to size changes. 
I would avoid GTK/Glade. While I have used it before and do like it, it's a rather traditional toolkit and its cross-platform compatibility is not great. With PyGTK 2 you basically give up decent OSX support and (afaik) PyGTK3 is not entirely cross-platform yet. Qt is a little more complex to use, but fully cross-platform and you can make some incredible UIs (Skype and Photoshop were both using Qt at some points). TL;DR use PyQT5 or PySide
http://www.youtube.com/watch?v=_6_F6Kpjd-Q Gives you a pretty good idea of how easy things are to do.
There is a "better" license (LGPL) version of PyQt called Pyside that functions nearly identically. http://qt-project.org/wiki/PySide
Me too. It's so interesting. I really love reading about all of pypy's optimizations. Pypy is so cool.
If only I could just give them my internet points. I've got mountains more of karma than dollars.
Never heard of this, but it looks pretty nice. Just cloned it to try it out!
What is C4?
Yeah, this is the way to go. Your browser acts like a VM just like the JVM does for Java code, but will be easier to maintain and more lightweight usually. 
IIRC its their implementation of STM written in C
PyQt is heads and shoulders above the rest. In particular, it has a powerful and fully featured Canvas element (QGraphicsView/QGraphicsScene). Neither GTK or WX has anything comparable. Tk has a reasonable canvas element, and is more widely available, but is otherwise inferior to Qt.
If you want to dive right in without messing around, try this: * Download PySide, then download Qt Designer. * Make a little UI in Designer (It's pretty simple to work with) * Export the .ui file, and convert it to a .py using the pyside-uic script (This may come with the PySide package on whatever distro you're using... for Arch, it's a separate package called python-pyside-tools in the user repository). * Now, you have skeleton code for your project. It's all in a big clump and it's kind of ugly that way, but pick it apart, add documentation, take out the unnecessary bits (yes, there may be some unnecessary bits). Learn how to connect UI elements to code hooks, and you're golden.
i dont think this is an apples to apples comparison as some of the comments on the article have stated. One of GO's advertised features is concurrency. I admittedly haven't dug into go-restful but if it using any form of concurrency or threading, you are basically juking the stats. if you want a closer comparison , i would rewrite the example in ether tornado,gevent or use the standard twisted differed pattern.
You may wish to delete this duplicated posts to save yourself from some pointless downvotes.
/r/bitcointip might be a nice way to do so.
I typically put stuff in them. That's pretty cool.
It is notoriously difficult to get a good response for submitting benchmarks to a bunch of programmers. But when you post a poorly done benchmark (in more ways than one), it isn't going to be well received. For example, the author doesn't even state what value of `GOMAXPROCS` was used, which determines the level of parallelism used in a Go program. Plus, he's comparing a concurrent HTTP server with a synchronous HTTP server. WTF? If you scroll to the comments, you can get more comparable results. Unsurprisingly, in such a simple test, Python is competitive. A real benchmark to show Go's speed over Python would require more complex processing. But if you're just going to dump trivially generated text, you're not going to see much of a difference between concurrent HTTP servers regardless of the language. The only real value of this benchmark is to say, "Go's stdlib http server is better than Python's stdlib http server." But the OP doesn't even mention it!
Are you hinting to the fact that image manipulation is slow in PySide &amp; Pillow or are you hinting to a HUD type of interface?
Your limitation isn't going to be the language. At this stage, it doesn't really matter which language you pick, as long as you stick with it long enough to learn *how to systematically solve problems with a computer*. Python is a good choice because it's syntax is easy and there are a *lot* of libraries available, which means you'll be able to make lots of really cool stuff without much domain-specific knowledge. Want to do computer vision? SimpleCV allows you to do a lot of really cool stuff while knowing jack shit about computer vision. Want to program games? Pygame and Pyglet do the same. The list goes on. But frankly, you could learn C first if you wanted to dive into the deep end (I did. I have no regrets). You could learn scheme if functional programming sounds like fun. You could learn PHP and/or javascript if you feel like doing web programming that works on any old host. It really doesn't matter. You can do awesome things will all of those languages. Pick python (or don't), but realize that you're going to be much more limited than your language for the first few years.
It's probably easier to talk about what you can't or shouldn't do with it: * You can't do anything that's too low level because you need space for the Python interpreter. So you can't write embedded software for your new design of dishwasher, washing machine or microwave. * You ought not do hugely computationally expensive stuff because Python is quite slow. If you want to do 3D games programming you'd probably be better off in a faster language. * You can't or shouldn't develop for platforms that force you to use a prescribed language. This includes iPhone (who make you use Objective C), Android (Java) and Windows Phone (.Net). Pretty much everything else is up for grabs, but as a beginner you are going to be limited far more by your own lack of knowledge than by the language and its libraries. 