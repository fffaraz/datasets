See [PEP 448](https://www.python.org/dev/peps/pep-0448/).
You can work with it freely, as long as you want. Then, when you start to market your final product, royalties are based on your revenue if it goes above a certain threshold.
And then there's me, moving to console because tkinter is too difficult for me to customise.
Love the general presentation. The moving giff in the middle did make me pause however. You mention how to use Anaconda to rerun the notebook, but I don't remember a mention that all the available data is part of the submission? maybe you would get credit by showing that you submit completely reproducible results as this is a prominent topic at the moment. I wish you well :-) 
Well, I have include some datasets as examples, but totally forget to mention them in the documents. I'll add that later and `how-to guide` later, thanks for the feedback. I might not be clear at first. This is actually a program that people can use to run on their wind speed and direction datasets, not a presentation of my Master paper. So the whole point is about peole can use it, and this certainly includes reproducing my analysis results.
This site is barely usable on mobile, fyi.
I read the whole license, there is a lot of shit in there. I wouldn't touch it.
Could you please elaborate what potential problem did you found with the license?
`__getitem__` and `__len__` is used for sequences that don't implement `__iter__`. With `__iter__` you need to return an *Iterator*, which is the "parent" of generators. However, this works as well (assuming Py3): class BadRange: def __init__(self, n): self.n = abs(n) self.i = 0 def __iter__(self): return self def __next__(self): if self.i &gt;= self.n: raise StopIteration # announce iteration is over now, self.i = self.i, self.i+1 return now An iterator is defined as an object that implements both: `__iter__` (typically returning itself) and `__next__` (`next` in Py2) which returns values or raises a StopIteration (other exceptions can be raised as well, but StopIteration tells Python that iteration is done). Generators are just a type of iterator. Any type that just has `__iter__` defined is called an Iterable. And these usually return a separate object from that method (either it's a generator, or it returns a special purpose iterator).
Thank you sir.
Yeah, I agree. But the nice thing is it's just one file and it should be straightforward to edit the regex to be fully compliant.
There are two reasons: 1- They have a very strong matlab-like flavor. They even have a matlab compatibility layer that turns the syntax to matlab. 2- They are using the Slycot module which is the fortran bindings to the well known SLICOT that matlab also uses. Both are the reasons why I wanted to get away from matlab. Having said that I really like their work. More explanation about SLICOT can be found in the Wiki page of the Github repository. 
FreeBSD at home because it provides IMO the best unix experience and has a rock solid base system, while providing the latest software via ports. Ubuntu at work because I need a Linux and it is kind of a standard there.
I looked at the official Python grammar and I see why it happens, though I have no idea why it's done that way, and it looks like a trainwreck to be honest. https://github.com/python/cpython/blob/master/Grammar/Grammar Things of interest: First, `argument` definition explicitly consumes unpacking stars and delegates to `test` (the root of the expression hierarchy). So you can write `*1 if True else 2` and it will be parsed as `*(1 if True else 2)` in the argument context. There's a comment trying to explain it, something to do with avoiding ambiguity in the grammar. The list comprehension variant of the `atom` definition on the other hand redirects to `testlist_comp: (test|star_expr) ...`, and `star_expr` as you might have guessed redirects to `expr`, which actually sits in the middle of the expression hierarchy, below all logic operators and starting with `xor_expr`. So in expression context `*1 if True else 2` the parser parses `*1` as `star_expr` and dies (because it expects a comma or `]`). I'd say that this looks like a bug in the grammar, instead of `star_expr` they should have created and put the star handling in `star_test`, and then `testlist_comp: (test|star_expr) ...` would look like `testlist_comp: (test|star_test) ...`. Or something like that. Except that comment about ambiguity hints that then they'd have an even hotter mess with having to explicitly spell those stars everywhere like they did for arguments. Or maybe it's just a bug, I don't know. There's one way to be sure -- report it! :D *edit:* note that `[*[1] + [2]]` parses and executes correctly, as `[*([1] + [2])]`. I have no idea why they de-facto put the priority of unpacking stars there, I don't think that there's any valid interpretation of a starred argument to a logical operator.
You didn't count the number of LOC in markdown and slugify
Mostly websites are built differently so you will have to write different scripts.
Great point. I guess if I'm cheating like that I could write the whole thing in one line...
Exactly, I didn't do an MIMO stuff. Could you could reasonably describe harold as 'like python-control but easier for MIMO'?
Don't feel too bad - writing a GUI in code is tedious as all bird. Save for websites, if you count those, I haven't bothered with that in a decade.
That would be nice to interface with povray so you can design a 3D world and then raytrace it.
Great job, mate.
There is really not much left that resembles matlab or python-control with the latest additions. It is genuinely different (good or bad). Actually that was my initial drive to start coding. SISO is a small subset of the required computations. Things get ugly quickly when you step up to MIMO stuff. 
You'll get a lot more help on /r/learnpython,especially if you format you code for reddit (add four spaces in front of every line). 
&gt; Complete access to the C++ source code base on GitHub. Study, comment, fix and contribute easily. Maybe I'm doing something wrong, but I've joined your organization on github and all I see is a repo with python tutorials. No source in sight. 
Looks like some great resources, thank you!
*Master branch*. That is meta :P
My logic for this was to search on the homepage for email addresses. You can also search for ['contact', 'info', 'about'] occurring in urls found on the homepage, and scrape those pages. Word of caution though: spamming (writing to people without consent) is illegal.
so far very usefull *in N lines of Python* i have seen. 
How could this approximation be done?
/r/Python is for news and releases. /r/learnpython is for questions.
/r/Python is for news and releases. /r/learnpython is for questions.
I prefer palm os, symbian and blackberry os7. :) 
Pretty stupid cause, but reasonably solid code. Keep it up. I would suggest formatting your 3k compatibility a bit differently though: try: input = raw_input except NameError: pass
Does virtualenv work in Windows (e.g. PowerShell)? Does virtualenv automatically activate the version specified in .python-version on `cd`?
You can look at bigrams (word pair frequencies, normalized to the length of the text). So Shakespear would have "thou art" with a much higher rate than a more contemporary writer. Take the top 1000 most bigrams for each author sorted by the normalized value and then calculate the distance from the unknown text you are trying to measure. 
I'd probably stick with the nested loop
Maybe a better example would be when the nesting is deeper, as when generating all possible rolls of 5 6-sided dice (game of Yahtzee). Instead of doing a 5-level nested loop, just do `all_rolls = list(product(range(1,6+1), repeat=5))`.
I don't understand this. There's usually more learning resources for Python 2 out there so there is no harm in learning it. It's not like switching to 3 will take a lot of time unless you need to refactor your code base into Python 3 later.
&gt;https://github.com/FXelix/owlturd_downloader/blob/master/owlturd.py#L13 url = "http://owlturd.com/page/1" # start url The `1` there should be replaced with `%s % page` because you're just doing the same thing later anyway. &gt;https://github.com/FXelix/owlturd_downloader/blob/master/owlturd.py#L51 logging.critical(url) This should be `logging.info(url)` at best, given that it's not an error or anything. &gt;https://github.com/FXelix/owlturd_downloader/blob/master/owlturd.py#L20 res = requests.get(url) Crazy nitpicking here, but `resp` is a more traditional variable name for requests's Response. &gt;https://github.com/FXelix/owlturd_downloader/blob/master/owlturd.py#L33 Might as well break all this out into a method to clean up your main loop a bit.
Windows and Ubuntu. Windows because it's the OS I am most familiar with. Notably, getting Python initially setup and working on Windows can be annoying, but isn't as bad as people make it. Ubuntu since I chose it initially as my webserver OS, and have used it ever since. Linux is far more developer-friendly than Windows, but Windows is still, overall, a more user-friendly OS for other things. 
It depends on the how you are going to use the wind speed/direction. My model is a long-term model. It describe in a long time (1 year+) the wind and direction's possibility. One application to estimate the wind enegery resources for a specific location. Because different places have different wind speed and direction, and you obviously want to generate more powers with that. And this will also help some related problems such as how the wind turbine should be placed in a wind farm, so you can optimize the captured engery. Another application is estimate the wind load on buildings. This is also a long-term problem. As a structural engineer, we may want to know the load on the differen facades of a building. This will help us to determine how much wind load it neeeds to endure. However, for agriculture, I think maybe short term forecase maybe your concern? In this case, my model may not help you very much.
This is something I proposed and later developed by some friends. See github issue: https://github.com/ipython-contrib/jupyter_contrib_nbextensions/issues/532 You can use it here: https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tree/master/src/jupyter_contrib_nbextensions/nbextensions/toc2 However, I personally didn't use the version at `jupyter_contrib`. I find it hard to output to HTML format, so I use my own version. It's here: https://github.com/cqcn1991/Wind-Speed-Analysis/tree/master/lib/my_toc , and you need to define some function to run it (https://github.com/cqcn1991/Wind-Speed-Analysis/blob/master/lib/lib_loader.py)
Can't get either on the work box (enterprise rules). I've experimented with them for my home PC but it's jarring going back and forth. 
Yeah, if you can't get a consistent environment, it's more hassle than it's worth. Those are some stupid enterprise rules if they force developers to work in an environment totally different from the deployment, but unfortunately that's hardly unusual. 
You've reached the point that all developers reach early on. The books can't help you right now. Nobody can point you in the right direction. The greatest teacher for you, at this point, is failure. I don't mean that in a bad or negative way. Don't be afraid to fail. Just dive in. Write code. Write lots of code. Don't be afraid of "doing it wrong".
You almost certainly can. What they've done here is a little strange: the `with_metaclass` function is taken from `six`, so it works in Python 2 *and* Python 3. It's.. rather unclear why they suggest you need to use it for Python 3 (even if you don't care about 2.7 compatibility), or even why they include that (and only that) part of six as part of their own public API. 
[Oh](https://github.com/petezhut/ConfigReader) [look](https://docs.python.org/2/library/configparser.html), [a config](https://www.tundraware.com/Software/tconfpy/) [file](http://www.voidspace.org.uk/python/configobj.html) [parser](http://pythonpaste.org/initools/), [how](http://cfgparse.sourceforge.net/) [original](http://pages.cs.wisc.edu/~param/software/cfgparse/). 
ubuntu in a VM because I want to use python 3 and scrapy but scrapy use twisted and that is not available on windows so yeah
Good job, friend.
Thanks! I'll check it out!
Anaconda is definitely the fastest way to get going for new users, and most valuable on windows (where setting up your build environment and getting pre-requisite libraries compiled is a bit of a pain in the ass). Personally, I use anaconda only on Windows. On OSX I use brew. On linux I compile from scratch, or use the package-manager version. My dev machines are all Arch linux, so the version of python in the repos is always up to date. There are a few downsides to Anaconda : - Its dependency resolution is both non-deterministic (i.e. prove this to yourself via a simple loop like : conda upgrade anaconda; conda upgrade --all; conda upgrade anaconda; which rarely ends up at the excact same place twice) and is actually complete garbage the instant you stray from the 1-2 versions they actively support (iirc. 2.7 and 3.4). This means that the latest version of python 3.5 will work, but tomorrow some library will inevitably require a downgrade, while another will simultaneously require an upgrade, because some intermediate dependency is not yet met correctly in their repository. There are days or weeks at time where my conda install is in some weird state of flux because of this. It all eventually gets sorted when someone at continuum gets around to it, but if you want to consistently develop against the latest versions of packages anaconda is NOT for you! - They just can't seem to compile numpy / scipy binaries that consistently pass all tests on all platforms. This has been an issue for at least the past two years, and there's no indication they are capable, or interested in fixing it... e.g. try import numpy; numpy.test(); import scipy; scipy.test() ... I bet you that you will have failures on one or more platforms. This is partially due to their insistence on using old versions of compilers / libraries on their build machines for compatibility purposes. Ultimately, it's a shitty place to be if your primary packages are numpy/scipy, and you expect them to pass all unit tests cleanly on all platforms. - It drags along all of its own shared libraries in a self-contained install (for good reason, it's pretty much the entire purpose of Anaconda). I suppose this is fine on Windows (again it really is a pain in the ass to get all of the pre-reqs working for the more complicated packages). However on OSX, and Linux this is really kind of lame, and a big con in my book. I actually DO want to link against the latest system libraries managed by my OS, used by everything else, and not some old duplicate thing continuum packaged up and shoved deep in my home directory. Furthermore, when I compile new/custom packages from source against my anaconda install, I always have to be extra careful of where the libraries and headers are coming from. Ultimately, this makes debugging things much more confusing if you are also building your own software while using Anaconda.
Beautiful work. Congratulations. Will play around with this. I'm also utilizing jupyter notebooks for my undergraduate research on overlap between marine habitats and fishing grounds in a Crab fishery.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Nice job, OP! Especially like the fact that you stick to the stdlib and just one dependency. Breath of fresh air when every second project I download has 30+ lines of stuff in its requirements.txt file. Have you thought of using a third-party server? I see that you included things like multipart requests, but when I looked into writing my own HTTP server, I was dismayed by the amount of features and combinations that HTTP/1.1 offers - stuff like transfer encoding, gzip, HSTS, CSRF, etc. It seemed like too much for a one-man team.
I loved the in-depth reply you posted. As someone who is interested in networks and was thinking writing a simple http server would be a nice way to learn about network programming, where would you suggest I begin?
&gt;But more generally, even some relatively simply tools like quick and easy state space visualizations, trajectories, vector fields, linearization, bifurcation diagrams, etc. would all be great. Up to vector fields in that list, I do have some plans but first I need to get this thing running rather more smoothly. Then I do have some ideas about Strogatz like exposition. 
still cant get it 
Please.. no Django-esque regex routing. Have you considered using Werkzeugs's routing map instead?
read the RFCs (assuming you have a basic working understanding of the networking principles and http in particular)
I'm not in favor of having _no_ dependencies and rolling all of your own stuff - I event allude to this in my post above - "_Have you thought of using a third-party server?_". But I'm all for really thinking a dependency through. I've been bitten too many time by a dependency that's throwing a wrench in the works - things like a module working only with py2, a long abandoned fork, a seriously opinionated library/framework, etc. It's similar to the whole [Simple Made Easy](https://www.infoq.com/presentations/Simple-Made-Easy) thing - _yes, this library makes X simple, but will it be easy to work with? To change? To update? To meet new requirements? To pass this code off to the next developer?_
I'm afraid I'm not an expert on licences, but I think maybe GPLv2 would be adequate. Bear in mind that you can dual-license your work if needed. I would suggest that you dig in a bit before deciding: http://choosealicense.com/
Windows, because everybody here uses Linux and I'm not like everybody else.
What would be the preferred pattern? The Python docs and some googling didn't mention anything obvious. https://docs.python.org/3/library/__main__.html
&gt; nobody has thought of Django does this. So please change your readme. 
Having to audit thousands of lines of source + licensing issues. Terrible. 
I don't buy that personally. It's super frustrating when you actually DO need some logic. 
Why not use something like the glob module to just find all *.md files in the post folder? 
/r/django or SO
FWIW, in the app I'm actually building with this, I use something that generates the regexes. But switching to one or the other makes a lot of sense.
Seems to have been (at least partially) fixed, albeit six days ago: https://github.com/python/mypy/issues/1453
Pycharm does all of this stuff. It's not MIT-licensed though, I guess. 
How does this compare with freecad which is python based and has been in development for about 10 years ?
This is the most basic 3D modeller, so it's much more primitive than FreeCAD.
Cool, I'll definitely be checking back in. Should have mentioned Strogatz, that's exactly where I'm coming from. I made [this](https://github.com/hsharrison/sysViewer) back in my Matlab days. I've since done similar things with interactive IPython widgets but never in a general-purpose way.
You almost never need that power, it's not very readable (compare it to simple placeholders consisting of name and an optional type) and reversing it (building URLs from routing rule and arguments) only works for simple cases (and even then it's probably not that simple to code).
I have tried online courses, and they are great. But I still like reading books (call me old fashioned). This book is one of the best. It is targeted at beginners, but is quite thorough and deep. [Learning Python, 5th Edition - Powerful Object-Oriented Programming](http://shop.oreilly.com/product/0636920028154.do) By Mark Lutz 
I work with django professionally. I use the power constantly. It's actually extremely easy to understand if you know regex, which every programmer should. I like the way flask does it with the decorators, but it's not very modular and can get nasty if you're building an api with a lot of end points. 
I use this extension its pretty great! The intellisense is pretty speedy!
what do you want to learn about? then go learn about that.
I wasn't talking about decorators (which, by the way, are optional in Flask). For which APIs do you need something more powerful than `&lt;foo&gt;` or `&lt;int:for&gt;` or `&lt;any(a,b,c):foo&gt;`? /api/users/&lt;int:user_id&gt;/something/&lt;int:some_id&gt; /api/users/(?P&lt;user_id&gt;\d+)/something/(?P&lt;some_id&gt;\d+) I think the former is much more readable. And Werkzeug allows you to define custom types that are eventually converted to a regex just like the default types - with the difference that you can simply write Python code for the conversion from python to a string in the URL, without having to try to reverse a regex string.
You should remake the file every time imho. this is very straight forward, so i'm not sure where you are stuck. do you not know how to write to a file? I would do something like `write the header`, `write the body`, `close all the open brackets and write footer`. anyway, please elaborate.
Like you I had similar thoughts. I'm QA so I'm constantly writing automation scripts. Which means writing all day at work. When I get home, I'm just no longer in the mood to create anything. I keep thinking I just need to find the right personal project.
Whats the threshold of changes for something to be a different language ?
Pick some task that annoys the shit out of you, the passion will practically write to code for you. Don't forget to sprint and refactor so you don't get stuck twiddling all the fun Python knobs. Like 90% of my personal done-at-home programming has gone like "good hell X is annoying, if only there was a Y that could just do this". Recently I've become a fan of solving problems by shoving neural nets at them.
I don't see why you would want to heave an extra layer that converts your urls to regex instead of just writing them in regex. Your second example is just as concise as the first. In django, you simply pass the captured parameters as kwargs into a view function or method. And they are accessable anywhere the request object is. I just don't understand the need for an extra layer of abstraction for such a small amount of gain. Forgive me for not knowing a ton about flask as I don't use it as much as Django. Maybe it's just a matter of preference. 
Geographic Information Systems uses Python (arcpy) a lot now. If you like spatial analysis and maps, I recommend taking a look at GIS. Source: I've been a GIS Analyst/Developer for the last 15 years.
Regex is unreadable gibberish. I'd say one of the main reasons I didn't want to learn Django was because it used regex routing.
Sorry for the confusion. I wish this was straight forward for me. Is there a way to append text into a HTML file that has already been created instead of recreating the whole HTML page? OR What would you suggest as a better option? 
Python does not have a complete specification that you can use exclusively to implement new interpreters. "Python" is whatever CPython does. &gt; I definitely think they're the same language and so is Jython and Cython and so on Then how do you explain that a certain piece of code will run in Cython, but not in Jython? Wouldn't you expect them to accept the same inputs if they implemented the same programming language?
Python is one of most proliferated programming languages out there, second only to Java and C++, in that regard. Its used for pretty much everything. So its hard to just list things, BUT let me lay out some things that a Python developer, I'm not going to say should, but rather would probably like, to have under his or her belt. * A Web App. Making something on the level of a blog, using Django or Flask. My recommendation is both. Start with Django, then do another project in Flask. They are both good for different things. * A Bot. A Twitter bot, a Reddit Bot, a Discord bot, or maybe even a chatbot. This can be done VERY easily, or more complex. Either way its a great experience, that allows you to delve into Natural Language processing if you want to. NLTK and maybe PyAIML for a chatbot. * A small game. This is one of those projects that can easily snowball out of reach. But if you want a serious challenge in scoping, and maintaing scope through production, there is nothing like Game development. Pygame, Pyglet and Kivy are the frameworks here. * A Spider. This is a Webscraper that trawls the internet for information. Scraping Blogs, or Twitter or Tumbler posts, or anything you really want. Libraries to look at here, are Requests and Beautiful soup, for a simple scraper and something like Scrapy, for a more complex Spider. Also Feel free to join [the CSLESSONS Discord channel](https://discord.gg/pDhTg) for a collaborative environment of likeminded invididuals. 
*I hear and I forget, I see and I remember, I do and I understand.* You need to do. Make code. Here is what I suggest: Follow youtube tutorials, or online coding tutorials and code along. Then start making something really simple and see how you do. Then make something a little bit harder, and so on. Also Feel free to join [the CSLESSONS Discord channel](https://discord.gg/pDhTg) Here people can help you with whatever you are working on and involve you in collab sessions. 
&gt; It has two integer types I happen to like the two integer types. I never deal with `long` data types in Python 2. If I have a long, it's a bug and it's probably going to overbound an 8-character field that is a maximum node/element id in my FEA code. It also slows down Python 3 by ~10%, but whatever. &gt; it may or may not be built in a way that completely mangles 1/17 of the Unicode space Agreed &gt; it boasts strong typing, then casually insists that None &lt; 3 &lt; "2" I actually hate that. I've never actually had a Python 2 bug with things comparing incorrectly (I don't compare strings to ints, but I do sometimes compare Nones to ints) and actually creating a bad answer. It's just a random crash I don't care about that I have to code around. I haven't found a way to import that in Python 2, such that my Python 2 code with future imports isn't quite the same. Why in the hell can't I do this? key0 = dictionary.keys()[0] I have to do this instead... key0 = list(dictionary.keys())[0] What the hell? Just pick one. Obviously, I don't care which because the dictionary is unsorted. It's a stupid change for the sake of changing things. That's my annoyance with Python 3. &gt; lengths beyond your wildest imagination I'm sorry, I'd call fonts and graphics "batteries included". The SGI support is a bit funny, but Linux maintains backwards compatibility. I honestly don't see the problem. &gt; But if you’re just getting started in Python, or looking to start a new project, there aren’t many reasons not to use Python 3. Unless it's open source, in which case you should probably support both. It's not hard to support, it's honestly easier to develop for (sort doesn't cause a crash in some weird edge case), and it's still got the market share. Outside unicode, nothing really changed. If you don't care about sane unicode, Python 3 has very little going for it. I wish it did. Async is cool, but what am I going to do with that? Until then, Python 2 isn't going anywhere, so if you run an open source library (I do), you might as well support it. Thus, nobody really needs to switch to Python 3.
Well, sometimes you can't avoid breaking stuff.
One note: `list(dictionary.keys())[0]` is not recommended, and for the same reason that `dictionary.keys()` is no longer a list to begin with: It evaluates all the keys of the dictionary and creates a new list, which could be arbitrarily expensive. Just use the keys iterator as an iterator. The idiomatic way to get a random key would be: key0 = next(dictionary.keys()) which is essentially synonymous with for key in dictionary.keys(): # or dictionary.iterkeys() in python2 key0 = key break ~~Even more simply, you could write:~~ ~~key0 = next(dictionary)~~ 
Thanks /u/bobthecowboy ! Your mention of hobbies reminded me of another fun use of python to throw on to throw on the pile. Grab yourself a $35 Raspberry Pi, a cheap screen, and check out some of the kiosk libraries that are available on GitHub for python. You can literally turn anything into an integrated "smart" device. Make yourself a smart toaster! a smart refrigerator, a smart oven, a smart blender (careful with the voice activation on this one), someone has already made the smart spoon but in fact it may even be possible to make smart devices outside the kitchen as well, but I haven't looked into this.
Say that you have some backend code that needs to interact with a text box widget (Entry), then I'd subclass the predefined Entry class in tkinter and add my own methods to that subclass. That's one way to work with classes in this case, I'm not sure that's the pythonic way to do it tho!
This is exactly what I wanted to build but never got around to. Now I only need a solution for the reverse. That should probably handle a bit more like something ORM-y
:) https://github.com/kespindler/albatross/pull/5
All technical reasons aside... More and more people, companies, Linux distributions, etc. are starting to adopt 3, to the point the tide is turning. It won't be too long now - a couple of years at most - before having only Python 2 on your resume will make it look a bit dated.
thanks so much, will do!
woot! Words are awesome!
In this episode I talk with Michael about: * Episodes of his show having to do with testing. * His transition from employee to podcst host and online training entrepreneur. * His Python training courses. * Courses by Michael: * Explore Python Jumpstart by Building 10 Apps * Explore Write Pythonic Code Like a Seasoned Developer * Python for Entrepreneurs * Podcast of his related to testing: * episode 10: Harry Percival, TDD for the Web in Python, and PythonAnywhere * episode 45: Brian Okken, Pragmatic testing and the Testing Column * episode 63: Austin Bingham, Mutation Testing, Cosmic Ray * episode 67: David MacIver, Hypothesis Give away: * We're giving away courses from Talk Python To Me. Listen to episode to find out how to enter. 
I didn't know that you could use `next` on a dictionary. That's way nicer. Unfortunately, it doesn't work in Python 2, strangely even when I use `six.next`. I could write my own, but it's obnoxious.
Usually great but occasionally you run into a developer who was being very clever with strings and you have to rewrite everything. Also a lot of rewriting required of a library where content from objects that now output byte strings are put in objects that now expect Unicode.
I teach tkinter in an entirely OOP model, because I think it makes more sense and is closer to the way a lot of other GUI systems (particularly Java) work. This approach also eliminates some of the chicken-egg problems you can have if you use Tkinter with a procedural design. Here's my course notes with embedded audio. Note I recorded the audio when Python 2 was the standard, but I've also included Python 3 code snippets for everything. The first couple of examples show the procedural technique that you'll find in most of the documentation, but then I explain why this can be problematic and shift to an object-oriented approach for the remainder of the examples. http://cs.iupui.edu/~aharris/230/python/GUI-TK/gui.html Hope this helps edit - fixed the link.
It looks like you are missing a call to `iter`, `next()` will call `__next__` method on iterator object and will raise TypeError when being called with `dict` or `dict_keys` objects. This will works as expected next(iter(dictionary)) next(iter(dictionary.keys()))
Gah. My mistake. You have to use `next(iter(dictionary))`. It's not as nice as I was remembering, but at least there's a little less line noise than `list(dictionary.keys())[0]`, and the performance characteristics are a bit nicer.
It can, there is a BashOperator. The main [tutorial](https://pythonhosted.org/airflow/tutorial.html) for Airflow shows it in action.
Oh and maybe because python 2 will reach end-of-life pretty soon, and security updates are a good thing to get
Wow, fantastic... Thank you!
&gt; being very clever with strings We call that a comeuppance.
uvloop is just an implementation of the event_loop architecture, it doesn't touch HTTP at all. it's a great project though.
:D
It's not like every big project would see that Python 2 is EOL and decide to up and port right now. I hear tell of a number of shops still on 2.6, and that was EOL in 2013, _and_ 2.6 to 2.7 is trivial compared to 2.7 to 3.
&gt; but I do sometimes compare Nones to ints Well then your code is *wrong* - not because you're comparing None with integers, but because comparisons between the two (except `!=`) are always false: print None &lt; 3 print None &gt; 3 print None == 3 print None &gt;= 3 print None &lt;= 3 This means sorting doesn't always work: &gt;&gt;&gt; a = [None, 6, None, 5, 4, None] &gt;&gt;&gt; a.sort() &gt;&gt;&gt; print a [None, 6, None, 4, 5, None] 
What happened to the channels feature?
&gt;TypeError: 'classmethod' object is not callable This is because you're [applying decorators in the wrong order](http://ideone.com/pAzksY). &gt;And its funcutils module contains an implementation of wraps that preserves the signature of your callable. And it uses an eval to do that. Just great.
But you have make a clear deadline with a good amount of time. Imagine companies running &gt;50 script here and there. Some small, others might be larger. You can't just put aside everything you are doing because some external community have chosen to make something obsolete.
This
I would think that the whole point of doing decorators correctly would be that it shouldn't matter what order you apply them in. Whatever I passed to the wrapper should come out with the same signature and behavior. In general if we have two decorators `@logger` and `@memoizer` then from the standpoint of calling the function both orderings should work. The only difference would be that one memoizes and then (optionally) logs, while the other ordering logs and then memoizes. Why does it matter if the innermost function is a classmethod or not? These wrappers should respect whatever this thing is and pass it through unchanged. If the input is a class method bound to a type, then after wrapping it should still be a class method bound to a type. [Its somewhat weird that `@classmethod` is a decorator to begin with, but... whatever] 
Planned for Django 1.11
We aren't talking about normal methods though. We are talking about decorators. The whole point of decorators is that they should NOT be changing the semantics. Which is why logging and memoizing are common examples. A wrapper that changed the return value... would be very concerning.
Sounds awesome and useful, i will dig into stock markets, so im really interested in this stuff, but i dont know where to start as well. :P
The point of decorators is to work around the limitations of lambdas by giving you some ability to pass multi-statement functions to other functions. That's all a decorator is: a function that takes another function as an argument. There are no other restrictions. (Oh, and they can also be applied to classes.) &gt;Which is why logging and memoizing are common examples. `print('Hello, World')` being a common example doesn't mean the point of every language is printing stuff to the console. [Here, have some decorators that very obviously change semantics.](http://ideone.com/TVesjU)
Awesome, I'll be sure to let you know if I find something too :) The hardest part is definitely trying to get substance to grab at and start...
In fairness, the very useful [namedtuple](https://hg.python.org/cpython/file/7062eaee3adf/Lib/collections/__init__.py#l304) function is essentially just an eval'd template that contains a class definition. Eval isn't wrong, it's just dangerous in a lot of situations, and often unnecessary. If you're doing crazy things like this, evals could well be the cleanest and simplest (and fastest) way of working.
Small project i've worked on in my spare time. Provides utilities for retrieving some information and some basic statistical calculations from several different sources and a basic AngularJS/Django web view for some of the information. Still in infant stages but the data scraping and retrieving utility should help you at least get some of the data that you can then run your own calculations with https://github.com/rcoverick/Pynance 
Yeah, so far getting some python 3.5 modules to work on Windows has been a struggle (psycopg2, for example, doesn't install properly with pip, you have to easy_install the precompiled version). If I were you, I would stick with python 2.7 when you are restricted to a Windows environment. As long as you put pip on your path, any issues you have with installing packages should be manageable.
&gt; Unicode by default The more I use it, the more convinced I am that this is the wrong approach. Go got it right, by using UTF-8 by default. Python decodes everything into a Unicode object, whether it's necessary or not. For the applications I mostly write, that means reading UTF-8 over the wire, converting to Unicode, reencoding as UTF-8 and sending it back out again. That's a *lot* of unnecessary work.
lol I love how it ended with "we're hiring!" as if someone was fired by the end of that fiasco
Uhm, was it studied some other way in the past? Or ever? Corporate finance is also applied mathematics.
If you got UTF-8 over the wire and you don't need to manipulate it in any way, can't you just read and write it as binary data?
this wasn't really meant to be an incredibly serious project. admittedly i was mainly just messing around with magic methods and used the project as a playground to write cleaner, more concise code with tests and actual comments. 
A statement from the main author, back in May. https://groups.google.com/forum/#!topic/django-developers/QRd4v7OErT8
Awesome - I'll check it out! Thanks a lot. :) Gonna brush up a bit more on my Python skills. I've been stuck doing web development and VHDL for a while, so it's a bit of a change... Mind if I bother you with questions if I have any (periodically)?
True but they did some additional work. Take a look at http://magic.io/blog/uvloop-blazing-fast-python-networking/. 
Yeah feel free to send me any questions, feedback, or additions you may have. It's an ongoing project so I'll be adding new features off and on as I get time.
The leading cause of developer burnout in python-related jobs is caused by excessive 2 vs 3 debating
This works really well, and is what I generally recommend people who want to learn Python and are new to programming: https://automatetheboringstuff.com 
I'm just saying the phrase is weird since all finance is applied math, not that it doesn't exist.
Sounds good - let me know how it goes :)
Why is static method a decorator and not a keyword? Seems like you are arguing for one bug because of the existence of another. That's not to say that decorators should never change the signature, but it should be hard to write a decorator that does. The default should be sane and preserve the signature. 
Maybe try UpWork.com - I haven't hired anybody for Python but I have used some people for various programming tasks.
because, considering the dynamicness of python, it works great as a decorator. it seems a bit weird to consider the lack of a static keyword a bug! or the fact that signatures can change!
The argument for a static keyword is that the average person expects there to be a static keyword. I would simply say that `static def foo(x)` looks better to me than `@staticmethod def foo(x).` Among other things it greps better, I can just grep the "defs" out of a class and see what I have instead of thinking... "well what is that thing that doesn't take self?" Not all that different from async. Python was capable of doing async without async def and await, but it was accepted anyways because it was perceived to be better to declare these as core types than to pass around generators with decorators that loop on them and return the exception value. As I said, I not strict about the "signatures shouldn't change" rule, so I don't object to @staticmethod or @classmethod on those grounds. I just don't think it is a good argument for why the existing behavior of decorators is reasonable.
Might want to check out [Stack Overflow](http://careers.stackoverflow.com/house-rules)
Oh great I just migrated an ancient project to 1.9 yesterday, can't keep up, damn it :)
Dude. Somewhere, you have to draw the line. In biology, it's the ability to interbreed and have children that can also have children (which is why a horse and a donkey isn't the same species). In spoken languages, it's mutual intelligibility, which is why British and American English are the same language, even if they disagree on what you call the storage area in the back of a car. It's a matter of semantics whether you decide to call Python 2 and Python 3 different languages but.... considering the vast majority of people call them the same language, even if you think they're **really** different, it's probably better to hop on the boat, rather than trying to convince everyone else to use your *One True Definition* of what constitutes a different programming language. 
It is common for web frameworks to provide a decorator that converts a function that returns a dict to one that returns an HTTPResponse with the dict converted to JSON, or one that raises an exception to one that returns an HTTPResponse with an HTTP exception status. Of course in such a case, if combined with other decorators, this one would probably have to be the outermost. I would say that logging and memoizing are probably examples of a special subset of decorators, who by their nature can be declared in any order, but are not necessarily any more "valid" by their preservation of return values/exceptions than other decorators whose entire purpose is to facilitate mundane conversion of return values to JSON, SQL, AMQP, HTTPResponse, whatever.
Were you around for Emacs vs Vi editor war in the late 90's, early 2000's? Wanna talk about excessive. Slashdot was riddled with text editor flaming. It was madness.
Is airflow python 3 compatible ? I couldn't find that info in their docs yesterday. Excellent tutorial by the way ! I found it made the strengths of airflow immediately clear - much more than the official docs.
licence: 15 lines, 169 words, 1043 characters docstrings: 28 lines, 139 words, 959 characters code: 11 lines, 23 words, 241 characters to write roughly jsondefaults = {} jsondefaults[Decimal] = float def jsondefault(obj): return jsondefaults.get(type(obj),lambda x:x)(obj) json.dump(somestuff, default=jsondefault)
Was? You still can use it no problem. Just do this: http://channels.readthedocs.io/en/latest/installation.html
The problem I have with the kinds of decorators you describe is that it seems like they should just be functional filters. What if I don't want to convert dicts to json? Once you declare the function with the decorator there is no going back, you are committed to utilizing that decorator at every call site. So I like to think of decorators as a means of providing additional functionality without changing the output.
Static methods are a dumb Java idea and should never be used in Python. If you want a function use a function. Adding a class for no reason is pointless. 
Yes, WTF! I have been working on my first larger python project this month and I was so excited to work with something more broadly compatible than my normal C#... Surprised to find this. Does the Google Cloud equivalent support python 3.x?
I have 2 computers, my work horse which dualboots between Windows 10 and Ubuntu, and my on the go machine, a Macbook Air. Windows 10 is purely for games etc. Ubuntu is for programming at home, and my Mac is used at home and on the go. My personal preference goes out to Mac, because it's a nice looking, simple OS which just works. There's no hassle at all with anything. I love it. Mac &gt; Linux &gt; Windows for me.
Well RHEL 6 is still on python 2.6 and red hat has support through Nov. 2020. https://access.redhat.com/support/policy/updates/errata I feel you though, we have a huge code base to port over in the next few years, most of it numpy/scipy stuff.
Data Analysis https://github.com/mGalarnyk/DSE200_Python_for_Data_Analysis PySpark https://github.com/mGalarnyk/DSE230_Data_Analysis_Using_Hadoop_and_Spark_UCSD Machine Learning https://github.com/mGalarnyk/DSE220_Machine_Learning
Wait, what's the reason?? On their front page: &gt; **Go 1.6 is released** &gt; Today we release Go version 1.6, the seventh major stable release of Go. You can grab it right now from the download page. **Although the release of Go 1.5 six months ago contained dramatic implementation changes**, this release is more incremental.
The reason wad he could shamelessly plug his book
I know that creeping anxiety. 
How about PTVS in Visual Studio? Are they going to integrate with this plugin for VS Code eventually?
Can you not run whatever python version in a virtualenv with lambda?
It is not so bad. I have a small site with a django 1.2 inside and I can't even re-install virtualenv for it, few dependencies are missing now at PyPI.
Hi I was in the middle of a move yesterday so I couldn't get to your reply until now. As far as what I know, I've have already implemented a simple TCP echo server which was multi-threaded and even looked into using select. But I was following a tutorial ([this amazing talk by David Beazly](https://www.youtube.com/watch?v=MCs5OvhV9S4)) so I don't have a good understanding of things. I'll pick things from implementing some simple HTTP/1.1 header parsing and go from there to a point where my toy server acts like a simple static content server which can handle multiple simultaneous connections (a la nginx). Thanks for all the help again!
Thanks. I'm surprised they haven't shouted to the heavens that Python 3 is supported. The codebase is tested against Python 2.7 and 3.4: https://travis-ci.org/apache/incubator-airflow
Thanks! Didn't even think of it
&gt; Although the release of Go 1.5 six months ago uhhh.... &gt; After fourteen months elapsed between Go 1.0 and Go 1.1, the Go team adopted a release schedule to streamline the process of working on, finishing, and issuing releases. The overall goal is to make a major release **every six months**, which breaks down into three months of general development followed by three months of testing and polishing known as the release freeze. Yeah. Plug.
I always download PyCharm from webpage. I only have to unpack it and can run it. (Linux Mint) BTW: Edu is available as plugin in Community/Profesional version.
Static methods are for when you want to package a related function that is mostly used with instances of a class together with the class because people will naturally look for it alongside the class. An example straight from Raymond Hettinger's [video on classes](https://www.youtube.com/watch?v=HTLu2DFOdTg) would be an angle_to_grade method for a Circle class. 
Personally when learning languages I just dive right in and start a project and look things up as I need them. 
Most fun when this bytes/string shitfest is (unknowingly) relying on incorrect use or sideffects. Was a painful move but glad of it.
It's a 6x6 matrix, but there are elements with lots of trignometric functions. The python process is using 30% of the processor. I decided to leave two of this lines ( 'mass_matrix = trigsimp(kane.mass_matrix)' and 'force_vector = trigsimp(kane.forcing_vector)') running for the past 6h and now the python process is using 30% of the processor as well as 5Gb of memory and still didn't finish :/ (I hope the computer didn't enter in sleep mode or something...)
so... @jacobian talked about http req/resp cycle at eurodjango this year and how he thinks django middlewares were probably not a good idea and wsgi middlewares are nice... how come we have new django middlewares now? is there some discussion to read up on? personally I prefer any "global" req/resp manipulation in cbv mixins or base classes. are middlewares really still best practice? do those new middlewares maybe work also directly in cbvs (that would be cool)?
I stand embarrassingly corrected. Turns out MS have released "Visual Studio Code" for linux and mac. This isn't their full Visual Studio though, VS Code is a programmers editor with support for extensions. It doesn't include any build-tools or ui-development stuff. See https://code.visualstudio.com/download 
First you should ask qpython author "what happens". Yesterday QPython put message on Facebook: https://www.facebook.com/QPython/posts/854090358059084 Now you can get apk on github: https://github.com/qpython-android/qpython/releases
Yeah, it might be, but this site supposed to be closed at least five years ago, so it is only my nostalgic feelings support it (and little bit of laziness)
I never could follow Raymond’s reasoning (if we’re gonna call stating opinions “reasoning”) here TBH. Python has wonderful modules as namespaces (ObjC anyone?) and functions are *great*. [This talk](https://www.youtube.com/watch?v=aOEfIrC07XA) by Nathaniel Marista and Augie Fackler – whose engineering advice has been fantastic over the past years – makes a great point at keeping classes small.
The whole way, I had thoughts along the lines of "oh it's not so complicated, it'll only take two more weeks... A month at most" It's not Django holding me back though, it's the front end... I don't know JS nearly as well as I should, and my dumb ass decided to make a SPA with no angular or backbone or anything.
Seriously: it's *the* way to get signatures, it's fast, it's in the stdlib. So if your project is Python 3 only, there's no reason to use some 3rd party solution. And since there's no reason to not make a new project Python 3 exclusive, we're set.
You apparently can, but the code which lambda calls must be the python2 they give you. So you can resort to popening or whatever a separate python3 process, but afaik there's no way to just run python3 normally.
&gt; I am still on 1.7, been ~~avoiding~~ **lazy**. I know I am.
I mean, I phrased it as a question but what I really meant was that I do run Python 3 scripts on lambda using virtualenv and I think it works really nicely. The startup script has to be Python 2 but I manage not to feel *too* dirty about it ;-). Happy to share the config if you want it. 
Mind blowing shower thoughts.
Long time Debian user (since Sarge) and loving it, never tried OSX but what I've seen so far seems far too restrictive compared to my Debian/KDE-Plasma.
Windows should not be a hindrance, Python runs fine under it as well.
no PPA is required, it ships will all dependencies with the exception of the JVM. Just unzip, go to the `bin` folder and run the `.sh` script.
In the same notebook I have simpler examples that work just fine.
They just changed recently. I got fucked too upgrading from 2.7 to 3.4 because I deleted the app yesterday before seeing that it was off the store. Qpython is really good, it's worth getting. Give them time to get their shit together on distribution
Why do you need to find uncaught exceptions? Python uses exceptions in a way that typically makes it best to only catch the exceptions you intend to handle in narrow scores and then catch broadly at the top level and log.
Good point, however the situation I often see is where our application code will call down a few layers (and it's not clearly documented what exceptions those functions could raise), and then that code will call into Python library code, which is also often not clear on exactly what it could raise. So we sometimes hit the situation of an exception being un-handled, as it was just too difficult to figure out everything that could possibly be raised by all execution paths. We do have top level catch all handlers, but if an exception is raised in an intermediate layer, and it wasn't expecting it, that functionality will die, even if the exception is eventually caught and logged by the top level handler.
Yea... I mean, that's the way I learned programming, but that was before I had internet access and it was a mess. It's a wonder I stuck at it really :P
"... run it as an external package, compatible with 1.8 through 1.10 (which the package already is), and let it mature and develop outside of core, before coming round to [merge into core] ..." This is how most major, new capabilities should be done.
Hi, Apologies. First time posting on here. Wia is a real-time platform for developers who are building Internet of Things applications. We provide software that sits on hardware devices and all the cloud APIs to build an Internet of Things solution. More information at our website here http://www.wia.io and library docs are here http://docs.wia.io Hope this helps. If you have any other questions just ask :) CL
P.S. We have MQTT and Websockets APIs also :)
I hope that by time a programmer considers themselves "average", they would know and care. Maybe you're thinking that average means inexperienced? 
Well then the argument is: bug from a bug from a bug. If python shouldn't have `@staticmethod` then the argument for allowing decorators to change the signature because "`@staticmethod` needs it" is out... and we are back to wondering why the natural way to write a decorator changes the signature. The fact is that someone thought static methods were important enough to include the decorator for them in the standard library, but not important enough to make them a keyword.... which I just don't understand. And that is all to ignore `@classmethod` which has a much more compelling use case.
Humm.. 1 error so far when trying it out. .save() on a brand new model is blowing up from https://github.com/django/django/blob/master/django/db/models/base.py#L880 Not using force_update or force_save.. seems update_fields is set set to 33 of the 34 fields in my model. Can fix with force_insert=True, but I don't want to, want to figure out what is funky.
I read the whole thing. I actually write code to support Python 2/3 because why not? It's not that hard, but for what I care about, Python 3 doesn't have much going for it at the moment. When packages drop support for Python 2, then it will. The Python 2 standard library is a battery, but the wealth of packages out there is the drill press, band saw, etc. You can get by without fancy new batteries because it's been abstracted away and all you care about is power tools.
It won't specifically do what you're asking but you might try running pylint in errors only mode against the code.
Basically this. It could be possible nothing is wrong and this is just an extremely long computation as expected. Or maybe the algorithm never converges and the package you're using doesn't check for this or something similar. 
&gt; Python 2.7.12 is a bugfix release in the Python 2.7.x series. &gt; Python 2.7.11 is the latest bugfix release of The Python 2.7 series. &gt; Python 2.7.10 is a bugfix release in the Python 2.7.x series. &gt; Python 2.7.9 is a bugfix version for the Python 2.7 release series.
What part of "active development" confuses you? It's not just about adding new features.
I've never used it myself, but [BeeWare/PyBee](http://pybee.org/) is supposed to be a pretty sweet project.
RemindMe! 24hours
What you install with `apt install python` is python3. You can install ipython as really good cli code editor with `pip install ipython`. Sadly you can't install jupyter... it fails to install pyzmq, and there is no build for arm7...
I think it was my complaint that Python 3 doesn't currently offer anything new outside of sane unicode for most people. I simply do not feel limited in any way supporting Python 2.7 and 3.5 with the same code. In many cases Python 3 is different for the sake of being different, which is makes it harder to learn. Then you find out about libraries like six and supporting two versions is a lot easier. At some level, one project that uses Python 3.5 needs a Python 2.7 package that you also manage, but another project that uses 2.7 needs the 2.7 version. That creates a lot of frustration and resistance to upgrading. I expect Python 3 to become popular when 3rd party libraries drop Python 2.7 support. I drop support for various versions of Python (e.g. Python 3.2) based on what my dependencies do. I'm proud of my -17. People are silly.
Run [PyPy.js](http://pypyjs.org) in V8 in Python!
Hi douglas11825, Glad to hear you find it interesting! Would you be able to send some of the specific issues with the docs to team@wia.io and I can have the guys look at it? With regards to the keys, when you create a device, a secret key is generated (you can find it in the device settings in the dashboard). You can use this to send data, connect to the real-time stream and control the device remotely (see Functions in the docs for more info on that). For full API access and to subscribe to devices go to My Account then Security. You will find a user secret key in there. No environment variables are needed. Developers can create unlimited devices and send/receive 250,000 messages per month for free. We will be releasing information on pricing beyond that and a version for organisations later this week. Cheers, CL
&gt; decided to make a SPA with no angular or backbone or anything. Oh you, masochist you. 
I don't know about a PPA but I use `umake ide pycharm-professional` to install on Ubuntu 16.04. I just checked now and `pycharm-educational` is in there as well. EDIT: It's not listed on the wiki page but if you install `umake` and type `umake ide -h` you will see `pycharm-educational` listed there. https://wiki.ubuntu.com/ubuntu-make 
Really interesting. My largest project uses a JS sandbox environment to run semi-untrusted code on huge amounts of data. I've started with PyV8 and ran into performance issues, right now I'm using dukpy. I'm very curious to see how this implementation stacks up against my current solution. I'll definitely report back.
/r/learnpython
/r/learnpython
this is off topic for /r/python
Super helpful. Thanks.
&gt; Is there a way to combine all this into one? Would that be more efficient / quick? Yes. No. It would also be less readable. If you could be more specific about what, precisely, your code needs to do, we might be able to suggest alternative strategies for accessing less data, or for moving the inner loop into one of Python's C modules, but as of now all we know is that you need to access all of your data, which can't be done without accessing all of your data. for array_id, array2, row_id, row in (k1,v1,k2,v2 for k1,v1 in data.arrays.iteritems() for k2,v2 in v1.iteritems()): ...does it in one line. You might need to massage it, I think that's how it works. It's something like that. Don't do it though, it reads like shit, and it will be no more efficient. Probably less. And whoever looks at it next will look at it and say, "...wtf does this do?" while your nested for loop is perfectly clear.
No worries.
Or maybe the best place for a submission that should be read by beginners is /r/learnpython?
/r/learnpython is for questions. Questions. Not learning questions. All questions.
Thank you. I updated the Readme.md.
You might want to suggest a rename in that case. Further, /r/python does not proscribe questions entirely, e.g. one of the top-voted posts from last week: https://www.reddit.com/r/Python/comments/4vm6l4/what_are_specific_fields_i_may_explore_after/.
&gt; Even experienced programmers struggle with the same things. Nope. Maybe if you are clueless to begin with. I take it the author of this trash has never heard of **pip**?
 you need accessors but you can open any class and add accessors
Beginner's guide to using Python 3.3+ on linuxy systems. mkdir project cd project python -m venv venv ln -s venv/bin/activate . ./activate pip install whatever **Edit**: Note that on subsequent runs you still need to run `. ./activate` before your script.
I love that php has user supplied examples / notes in the documentation.
Can you honestly tell me you've never had dependency problems with pip? I've had 2.7 packages being installed in a 3.5 environment, packages requiring older/different versions of other packages that's not available, tons of packages failing to define all dependencies, etc. Then there's the issue with OS-specific libraries that you need to get through other sources not always playing nicely with virtualenvs. Sure, most of the problems is due to the developers/maintainers of the packages and we manage to work around it, but I see pip as a convenience tool that I try first, and when it (often) fails I just do it manually instead.
According to said post referenced by https://www.reddit.com/r/learnpython/comments/4sdw83/is_it_me_or_pythons_documentation_very_poorly/ http://ruby-doc.org/stdlib-2.0.0/libdoc/json/rdoc/JSON.html &gt; The Ruby docs are good and should be a model for Python. I disagree that the Python docs are bad. The Python standard library docs are not bad. &gt; I tried to install X. But when I ran it, it threw up a generic error, which meant (after Googling) that it needed Y. Okay. So I installed Y. But Y needed Z. And Z needs a C/C++ compiler. Okay, I’m on Linux, I have those. &gt; But no. The compiler fails with a random error. I’m guessing about a third of the beginners quit at this stage. They either don’t use that library, or, use another language. So my alternatives are what? Matlab where everything costs money? C++ which still requires a compiler? I'm on Windows, so already my life is 100x harder than the guy using Linux. My OS doesn't come with a C++ compiler. I can't just use `apt-get` to install it. Be grateful. It's not an exe, you deal with it or you download a prebuilt binary. Nobody is forcing you to use package x. Certainly you're not paying... &gt; One famous library gives nothing but API calls. One library creator starts off his documentation by teaching you how to write setup.py files That's not a Python problem. That's an everything problem. Also, I'd love if I could find a comprehensive `setup.py` example. I've been avoiding making a "good" `setup.py` for years and maybe that's a good thing.
None of the official python docs show the imports with the code examples, it wastes a lot of time.
have you tried installing matplotlib with pip? or pygame? or kivy? there are many dependencies that have to be manually installed
I think this is valuable reading for pros though as well. They have the power to affect projects and documentation to a greater extent and change the environment in ways newbies are unable to.
The author is quite correct regarding the docs compared to PHP. Having examples within the docs (as well as potential comments, though most are outdated now), really gave newcomers an easy way to get a quick understanding of the language and get started. It's something that would help Python quite a bit if it was improved imo. 
As someone new to Python this was comforting. I could have just installed linux before I figured out pip on windows.
So, what's your plan for improving these situations? Obviously, you can't fix every broken package out there. Nor do I think rewriting the docs from scratch is a wise idea or a good use of time, mostly because they're wonderful for the technically inclined. That said, examples are sorely lacking in some areas. In that case, I usually defer to [Python Module of the Week](https://pymotw.com/3/) -- change the three to a 2 for Py2 stuff -- for examples, Doug has done a bang up job providing *free* plaintext explanations of modules. If you have documentation issues with third party packages, find their issue tracker and file a request or better, submit a documentation patch (people love this because no one wants to write docs). Do this for actual code documentation *and* installation issues. If the library doesn't have an issue tracker you can find or it's going to be slow getting your PR accepted? Write a detailed blog post about your solution. If you did file a PR or issue, link it. Belly aching is good occasionally, but offering solutions is better. 
If you disagree that the python stdlib docs are poor, you should provide evidence for your claim.
The easiest way to improve the docs situation is to start adding examples to every single function in the stdlib.
I must've died and gone to hell already
I don't know when hating on the docs became the default state. You stil need to state your case...regardless... Per the previous reddit link comparing Python, Ruby, &amp; PHP &gt; The page isn't well formated. It's autogenerated. What do you expect? Also, so what? &gt; Text blends together due to lack of good markup and color choices. I disagree. &gt; Look how pretty those are. It's about the same. Look at numpy. http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html It's fine. It's slightly prettier than the Python documentation, but I think it's worse. Quality is what matters, and how to find what you're looking for, not the color scheme. http://www.vtk.org/doc/nightly/html/classvtkSphereSource.html It's got a class diagram. It's got methods and attributes and it sucks. How do you use it? I love VTK; it's ridiculously powerful, but the documentation is a mess. The difference is, one is generated from a docstring (numpy and vtk), the other is generated by someone writing a documentation page (Python, Ruby, PHP, etc.). Writing documentation like this is always a pain because it's way easier for it to get out of date.
That's right, it isn't meant to be a full blown IDE. Build tools are supported to a great degree, for many languages, as at the end of the day most build tools are simple scripts, check out TASKS in vs code. However ui development is not yet in there. 
Normally you want the row loop to be on the outside and the column loop to be on the inside. This is because of locality: data that is closer is usually quicker to fetch. Codewise, the two loops is probably fine - it communicates what is happening fine.
You're pretty hardcore if you're using Unix still! You both probably meant Unix-like and POSIX systems. To this end, "linuxy" works
A Unix based system? I know this!
Regardless of whether or not you find it clear, you surely accept that a great many people simply don't. If the page could be better formatted, what would be the harm?
What an inflammatory and vague article. Whoever wrote this needs to step back and take a breather. Python documentation has been great to me. Some of the non-standard libs could use some work (I'm looking at you APscheduler) but overall I have been able to tackle problems with new tools much quicker than I could have with other languages. That to me says they are doing something right. I also find it surprising that this author is shitting on the community that he praises in the end. Who do you think writes and maintains these docs? If he is so passionate about the (lack of) quality of the documentation. [I encourage him to volunteer his time to make them better](https://docs.python.org/3/about.html) 
Something like this should work. for item in my_array: if isinstance(value, dict): # Handle the dict else: # Handle the array for sub_item in item: # Do stuff You could clean it up by creating some functions to keep it from turning int spaghetti. 
For development (but not for production) I like to have a try: main() except Exception as err: log.exception(err) around the main function. Then i throw the weirdest inputs i can think of at the code, and see what fails when. I don't know of any tool that would do 'what could be thrown here' analysis. The only way to do it is to know what given function can throw, and then wrap it up accordingly. if you're addressing lists, then you want to catch IndexError, if you're pulling things out of dicts, you want KeyError, if you're doing IO, do IOError, etc...
ish, python 2
I'm going to use the [itertools](https://docs.python.org/dev/library/itertools.html) page of the docs as an example. What imports would you need? The page gives you a simple source with a few examples. The examples might call the functions without an import, but the top line for each function is the path for the function. For example, the [doc for groupby](https://docs.python.org/dev/library/itertools.html#itertools.groupby) has an example where `groupby` is just called, but the first line has `itertools.groupby` which shows you that you can just import `itertools` and call `itertools.groupby` or import it straight from itertools with `from itertools import groupby`.
Well, kinda. The thing is I don't know if that single argument `ln` command works on non-GNU versions.
I didn't find it so hard when starting python. Yes, examples are missing from the standard lib docs and that would be a good first area to improve them. But stackoverflow very quickly satisfies any itch you have for examples. Using the two resources side by side and you are fine.
Shorthand for Unix-like/POSIX systems has always been *nix, for as long as I can remember.
I use the "pip --user" method almost exclusively and it works rather well.
There's nothing really that tells you that you might need a c++ compiler to install stuff since the error messages are usually pretty cryptic. At least on windows, ms provides a convenient installer for the bare compiler. On Linux, you have to install a bunch of extra packages.
&gt;Try Perl. Sure, right after I willingly learn VBA. 
After 6 months writing a blog in Portuguese, I started getting 400 views a day from Google after 120 posts and I was like "holy shit why the fuck are there so many views." But I could never link it on reddit because it was in Portuguese. So I started translating the posts to English. Today, I linked a post in some huge thread which was already a couple hours old, in a reply to a comment which was a reply to another comment. And then I got 300 hits from that link alone. It's such an absurd and easy amount of traffic I don't even question why people post these kinds of posts anymore.
Recursion is the way to go. Write a function to calculate factorials for practice. That should give you the hang of it
No disagreements there, but the examples of what good docs look like vs. what bad docs look like look the same to me. The VTK docs are bad despite showing their class inheritance and class variables. The VTK examples are overly simplistic, half of them don't work, don't define the rendering pipeline works, etc. They're bad docs. I'm all for better docs, but the only way that's going to happen is if 1) people actually state what they want (e.g. formatting is bad because blah) and 2) someone does it. I actually think the first one is the harder task. I run an open source project. I look at the PHP vs. Ruby vs. Python docs and they're different colors, but honestly they look the same. To hold that up as an ideal, especially when people don't agree (e.g. /u/mtgordon), without an explanation is not helpful. OK something useful...change the color scheme from `classic` to `sphinx_rtd_theme` because the colors are nicer. Instead of using `sphinx` style docstrings, use `napolean` because it's easier read the docstring in code. It's not like it's hard the Python devs to fix a bug or alternatively provide a better error message with bad input. I mess around with binary files a lot, so I'm at the fringe of what Python does well. It's a lot better than it used to be. Shoot, I'm sure you could just write a better 3 line blurb, paste it as a bug and someone would patch it for you.
&gt;You're pretty hardcore if you're using Unix still! Yeah all these mac users are super hardcore
I think recursion is what you're looking for. Sounds like a fun project. 
This is what I came up with: import json import collections config = open('config.json', 'r+') configdata = json.loads(config.read().decode("utf-8")) def traverse(data): for tab in data: if isinstance(data[tab], list): for i, t in enumerate(data[tab]): # data[tab][i] is another tab field!! traverse(data[tab][i]) else: # we have a button field!!! print data["name"] if __name__ == '__main__': traverse(configdata) Now I'm wondering if there is any way to tell which recursion level I'm in. Because in the "button" field I need to be able to reference other things in that json object
Python 3 is being actively developed, Python 2 is being actively *maintained*. You could consider "development" to refer to the entire development cycle, but that is not the meaning people are using here. The reality of the situation is undisputed; you are merely disagreeing on semantics. Try not to be so abrasive.
[I think I figured it out](https://www.reddit.com/r/Python/comments/4vvbz0/parsing_a_json_file/d61svtc) 
Z Nation reference ?
As someone coming from years of experience with R, I found all these things to be why I delayed actively using Python for a long time. If I wanted to install a package in R, I just had to type "install.packages("packagename")". With Python, I needed to see if I had pip installed on my windows system, figure out where it was downloading to, and then like mentioned desperately try to find documentation on how to find it and all the functions provided. I've never had that sort of problem with R where most things have pretty extensive documentation on each function and variable used. 
pip install googlefinance Not sure if it works with Mac though. 
&gt; Z Nation reference ? No... Jurassic Park...
Now you're just pretending to be dumb and not able to understand basic principles because you know you're in the wrong. POSIX is a part of unix, a simple google search brings up the wikipedia page for OSX where, lo and beyond, the first few words read: &gt;OS X is a series of **Unix-based**
as opposed to what? Because python was probably one of the first ones, after perl, to have such a fucking awesome repository in pypy and that made it a joy to work with. The documentation thing is possible. I don't see it but, at this point, I think I can handle most things that are thrown at me so I might not notice. I love Qt's documentation though, If I have to choose. As for the third point, there's always bad tutorials around. Who cares? Some things might be useful. There's a lot of useful stuff out there compared to, say, c++ which struggles with a lot of legacy. Clickbait.
&gt; merely disagreeing on semantics Semantics is what we use to communicate. It's not some small detail that we can brush aside. Maintenance is part of development. Software development. No programmer worth his salt will claim otherwise, so why persist in this error? You want to say Python 3 receives new features? Just say so.
Okay, haven't watched Jurassic park since I was a kid / before I knew what unix was. There was a scene in Z Nation (which is a semi parody show) where one of the characters quotes the line when using an alien computer. It was pretty ridiculous at the time but adds another layer now knowing they were referencing Jurassic park. 
Don't worry, those people are wrong. The only reason to use 2.7 at this point is library support and legacy code.
&gt; Now you're just pretending to be dumb and not able to understand basic principles because you know you're in the wrong. Hah. &gt; POSIX is a part of unix [Nope, POSIX is a standard to which Unix conforms](https://en.wikipedia.org/wiki/POSIX). POSIX systems can, and do, exist completely independently from Unix. Most Unix-like systems are also POSIX compliant, but that's besides the point. &gt; OS X is a series of Unix-based Right. I don't contest that. I contest that what they mean when they say Unix-based is based-on-Unix, aka Unix-like , not literally Unix as you keep claiming. 
Not unix....mac is BSD based which is UNIX like and POSIX like ComZero mentioned.
You are not the only the one. I think it's just a different mentality. I can certainly see why people who just want to get to an answer ASAP will find the python docs frustrating. I guess that's not usually how I end up approaching things however, and I tend to find the python documentation to be very good. I suspect the people who wrote the documentation think like you or I and wrote it for their mindset. I would be interested to know what the distribution is across developers. Am I part of the small minority here? If so then yes, the docs need to be changed. I really have no feel for the numbers however.
ok i will try that
OS X is not only POSIX compliant but registered as an official product under the Single Unix Specification. https://blog.opengroup.org/2015/10/02/mac-os-x-el-capitan-achieves-unix-certification/ &lt;--- stright from the horses mouth.
In general, yes. However, I taught myself Python by buying a _book_ (yes, I know, _very_ anachronistic!). It was called ["Python in a Nutshell"](http://shop.oreilly.com/product/mobile/9780596100469.do), and it was well organized, easy to read, and thorough. It gave me a very solid beginning to Python. Yes, I've done a lot of Googling and stack exchanging since then, but that book started me off right. I agree, however that if a beginner wanted to learn Python _on the internet_, they are facing more of an uphill battle than they would for another programming language 
And if you really wanna go down that rabbit hole, you could run a pure Python JS implementation in PyPy.js and than run [JS.js](https://github.com/jterrace/js.js/) inside that!
The funny thing about that was it was actually a UNIX system. Very few people that knew UNIX used the SGI file browser (the Jurassic Park thing was a 3D file browser), so people thought it was fake. https://en.wikipedia.org/wiki/Fsn
I suspect that has more to do with a lack of documentation versioning in PHP. There is no page for `json_encode` in PHP 5.3 or 7.0, there's only the page for `json_encode`. This isn't a good thing, but it's nice for search engines. Python, and really anything that does versioned documentation, are pretty much guaranteed to make it hard for search engines to know what to show. Python (and other libraries) should [`rel="canonical"` link](https://support.google.com/webmasters/answer/139066?hl=en) all old versions of docs to the newest pages and provide urls like `/current/library/json.html` that don't change and always show the most current docs for the given page.
Both `sudo apt-get install python-lxml` (to install binaries for the system) and `pip install lxml` (to install from source in a virtualenv) work on my Ubuntu system.
Serious question: what specific packages have you failed to install as a complete Python beginner using `py -mpip install package-name` command?
It's the biggest pain in the ass for postgresql docs. Any search brings up 4 different versions of the same function, and you need to click on one then click on "current" to get to the latest version.
&gt; Berkeley Software Distribution (BSD) is a Unix operating system https://en.wikipedia.org/wiki/Berkeley_Software_Distribution
One thing for beginners - MITx EdX Introduction to computer science with python is an excellent class - It is my third time taking it (free/audit) and I am always learning something new - it is not easy - but I feel it gives you a golden solid foundation. 
This is bullshit. Sorry.
Nowadays pip comes with Python (at least it did when I last compiled Python). Pip will install to the sibling lib of the bin dir it is in (on UNIX/Linux it is easy to check using "which pip"). I don't see how "pip install &lt;pkgname&gt;" is significantly more complicated
Have you tried virtualenv? It makes that problem non-existent.
Would love to hear more about your neural nets. I find machine learning quite intriguing
The web documentation is indeed horribly organized and hard to read, but honestly I just use the help docs from the interpreter, or if I need an initial example, I use the stackoverflow "documentation" for quick reference.
Installing packages on Windows is definitely a headache. I eventually switched to Ubuntu and haven't looked back. Generally if I search for an error there's an answer on stack overflow or whatever. Biggest pain points: - Cuda/cuDNN/nvidia drivers/Theano ... Ugh! - Getting a good blas/lapack/atlas setup - Matplotlib virtual env missing backend problem I think the documentation is generally excellent, and it's not that hard to just read the code. The thing about python is the code is much more readable. In conclusion, far too much whining in comparison to the real situation we have. Also favorably comparing php docs is just ridiculous. It could have the best docs in the world and it wouldn't make up for the bad design choices. Its like saying a car that blew up had pretty paint. 
Google Finance is not real time, all quotes are delayed by about 15 minutes or so. To get real time quotes, you'll probably need to go through a broker's API, which usually requires either specific payment to access or a certain amount of activity on your account.
Not trying to be brusque, but what was confusing about "out of memory"?
I think maybe the people complaining about the lack of clarity in the docs aren't really cut out for programming. I'm not saying that's definitely the case, but if you have even a slight grasp of the language, the docs are totally fine. Maybe people haven't spent enough time with the basics before moving on to the more advanced topics? I don't think I ever once had a problem with Python as a language that I wasn't able to find a solution for in the docs in less than 5 minutes. Third party libraries are a completely different story. However, you can't say that a language is hard to learn because of the apathy of a third-party developer. I'm not saying it's the case, but it is a bit of a coincidence that the author advertises his beginner's course at the end of an article talking about Python being difficult to learn. Either way, I don't think the author is willing to put in the necessary effort to find the solution to a problem. Sometimes it really helps to just read the source code. As far as an example of what I consider to be excellent documentation, here is the [Django docs](https://docs.djangoproject.com/en/1.10/).
Haven't needed to use that yet. I'll take a look at it after I launch my current project.
That's pretty nice. I need to make beams finally work in my 3D code. I've got 3D rods/springs working though rotated sliders don't work. I'm bad at deriving the equations/understanding really what to implement from the books, but I'd like to get static/modal problems fully working (e.g. springs, rods, bars, shells, solids). Wanna team up? [My code](https://github.com/SteveDoyle2/pyNastran)... 
I'm right there with you. Though, so far I'm only getting deprecation warnings for third party urlconfs. There may be some hidden problems that pop up though.
Not op, but: MySql-python. For windows required an actual installation. Not too difficult, but was confusing and not obvious from error in pip.
I'd highly suggest the [Anaconda python](https://docs.continuum.io/anaconda/) distribution, it solves a lot of the python installation issues via their [conda](http://conda.pydata.org/docs/intro.html) package manager. It not only creates virtual environments for python packages but has support for the binary dependencies as well.
Paramiko
This [video](https://www.youtube.com/watch?v=FgfKA-HJFI0) may be helpful, I haven't watched it as of yet but it's linked on their front page...
I was pretty happy with ruby's documentation actually. Haven't worked with Python much to compare though.
`pip` works well most of time until you hit [diamond dependency](https://github.com/pypa/pip/issues/988). Python documentation is superb. Great examples, except for say, logging. 
This doesn't mitigate the fact that he has to 'touch' every entry; a single loop may set up more machinery than a single loop, but adding an extra function call and processing may not make much of a difference. If you want faster response and looping you may want to use a different language, or consider restructuring your code in some way so that the dimensionality is lower, or the number of entries you seek to process is lower.
$yes $it's $a $nice $@language ! Sorry, I went to through that before finding Phyton.
I love python, but I have to agree... the docs aren't nearly as good as they should be. My first adventure in programming was Java, and when I started python, the hardest thing to get used to was that the documentation just wasn't nearly as good. It's probably one of my biggest problems with python, as far as non language/runtime things go.
My start with python was easy because the number two google results were stack overflow examples
Every now and then I have to administer some ancient system. It usually has perl. I haven't learned a lick of new perl in over a decade, and that has sufficed. I think that it has objects now, don't know, don't care. 
I would be surprised if this whiny moron has ever had to solve a hard problem.
Oh I was actually of the impression that it was based on Free-BSD, and therefore not technically Unix but rather Unix-like. Cool! TIL EDIT: Still hold that if /u/novicenoobie was gonna be pedanticly correct "linuxy", POSIX and *nix/Unix-like would be the appropriate corrections to make. 
Most programming follows certain flows and expectations. The meta part of the programming becomes an obstacle just like OP suggests. A newbie trying to do some simple programming constructs runs into this far too much. Python is not the only example but is not exempt. OP's viewpoint is more correct that most who have overcome the obstacles might admit.
Thanks! Gotta keep working for right now, but it's on my playlist.
some people just want to watch the world burn...
If I ever have a task that involves some heavy string manipulation, I'm going to use Perl. That's what it was made for, after all. Otherwise in not touching that shit with a 10 foot pole
For Windows users it also allows you to install into your user directory so you don't need admin rights.
noob here, why would you use a language with a lot of overhead like python in the first place if you're on an embedded system? why not use a more lightweight language like straight up C? are my assumptions wrong?
Depends on how "embedded" we are talking. Stripped down single-board computer (something more barebones than even e.g. a RasPi zero) with an ancient custom Linux distro Linux distro, maybe you have to go with Python 2.X. For actual microcontrollers, there's [micropython](https://micropython.org/). It's a special custom Python interpreter that is stripped-down enough to run bare metal on microcontrollers. It's definitely not as efficient as C or assembler, but people use it for the same reason they use normal Python - convenience. It's good enough for a lot of things, especially hobby stuff. Note however that micropython is an implementation of Python **3**.
thanks for the response 
Another good point! Same on linux, which is doubly important so that you don't interfere with the system python.
Not OP, but my first reaction is to think about situations which are embedded (limited resources in a sense) but not necessarily microcontrollers. Image turning a Raspberry Pi into an IoT webserver: Webstack is sufficiently covered by Python Libraries that its use would likely save your developers tons of time and headache. Sure, in an assembly sense, it would be cheaper to do with C but the majority of engineering cost goes to development not Processor resources. (HUGE CAVEAT is consumer electronics where $$ is god and price is god above all else.)
... Looks at Perl6 and NEVER compares the beauty to VBA again!
Ah I'm not afraid of it, but I wouldn't exactly call it a fun language to use. Seems like you enjoy it though, so please take all the monies so I don't have to deal with it :)
my first Python program took three hours to get running. Here it is, one line: print "Hello, world!" Can you see the issue? (hint, I was running on Python 3...)
The PHP documentation comments are like StackOverflow, but fast and wrong.
Not sure what you mean by 'crack' bytecode, there are ways to [decompile it](https://docs.python.org/2/library/dis.html). 
works for me (win+linux platforms, professional pandas user). sounds like pebkac
.exe on Darwin?
Honestly, I love the language and the community, but it's disappointing to see that the community has begun to take everything so much for granted that they've become whiners. Python has it so much better than everyone else. I came to Python from Delphi. What problems do Delphi developers have to deal with? Trick question, there are no Delphi beginners anymore. You have to pay minimum $1400 to start, and that doesn't include the official multi-database library (like the DB-API, but in code rather than spec form so you have to pay another $500 plus mandatory support or you get no bug fixes). Python is available to anyone for free. People don't appreciate for how short a time that has been the mainstream situation. Problems installing libraries? Delphi developers' worlds stopped at Windows XP, so in their minds all source code should still be commercial.. Almost every library costs $150-$500 or more. Seriously. Even a PostgreSQL database driver [will run you hundreds of dollars](https://www.devart.com/pgdac/ordering.html). Until the last year, there wasn't even a package manager. I guess there still isn't; there's a "software store" you can access only through the IDE, no web page. Some open source is available, but only if it doesn't compete with any commercial component the language offers or you don't tick them off (they b*itch if you write a critical blog post then ask to have your software included, and yes you have to ask and initiate a manual process). Dependency hell isn't a problem because libraries tend to be distributed in statically linked binary blobs, source code extra. In one case I've seen a simple neural network library that [wanted an extra $1000 for the source code](http://www.shareit.com/product.html?cart=1&amp;productid=300384344&amp;languageid=1&amp;backlink=http%3A%2F%2Fwww.mitov.com%2Forders%2Fintelligencelab). Because K-nearest neighbor and backpropagation is so cutting edge and exotic. Documentation? Our documentation is PHENOMENAL. The community even invented a markup language and a documentation generator! I don't understand programmers, per the regex example in the article, that want something that looks to be procedurally culled from function headers and barely contains a line of English. Back in the 80s, software used to come in hardcover binders. There'd almost always be two books - one labeled "documentation" or "guide" and one labeled "reference". People who write articles like this are confusing documentation and reference material. A dictionary is a reference book, but it won't teach you English. Neither will the barebones function header collections they yearn for. Python has real **documentation**, with paragraphs of actual human English text and numerous code snippets sprinkled throughout. They're tutorials for human beings, written by human beings. That's in addition to the many free guides to Python, the MOOCs, the free interactive web tutorials, etc. It's incredible. Let's not forget Read The Docs and how easy it makes it to publish open source documentation automatically from a version control system. Delphi's documentation looked like it was scraped function headers, with the added bonus that it was produced by offshored Romanian developers in their spare time, such that often new features shipped **with no documentation at all** for several weeks. On top of that, there was no emphasis on documentation until they began shoving a crippleware commercial product into the box a few years ago. The tool - almost all Delphi doc tools, actually - is GUI based like a word processor. All of them cost hundreds of dollars, with one topping out [at $900 for the ultimate version ](http://www.doc-o-matic.com/purchase.html). Nothing produces PDF for under $200, but they all produce CHM for some 90s Windows reason. You're also locked into one framework and one poor IDE in Delphi, and you've got to use Windows. Many poor saps who moved to Mac now have to do all their development in a VM. :-( In the python world Python not only runs anywhere, you can develop it anywhere, from a supercomputer to a Raspberry Pi or even your phone. You have many IDE choices (or the choice to not use any thanks to many command line tools), including full-featured IDEs such as Eric 6 and PyCharm. PyCharm even comes in a special learning edition that can teach you Python right inside the IDE! There are over 80K free and open source libraries to utilize, and distributions such as Anaconda bundle over 100 useful, well-documented libraries. No one produces an API today without making a Python wrapper available, and libraries like Requests make it simple and beautiful to access a generic REST API. You can go into your local bookstore and find plenty of Python books on the shelves. Dozens of Python books are published every year, and many computer, open source and DIY/electronics/Raspberry Pi magazines regularly have columns dedicated to teaching Python and providing instructions for building fun projects with it. We also have this subreddit with OVER 130,000 SUBSCRIBERS. /r/delphi has 791, and many developers still communicate though USENET. We have multiple mailing lists that cull the best of the best and present it to subscribers. Over the last few years I've seen such amazing and compelling stories as controlling an autonomous 15 foot blimp with Python, hunting for flight MH370 with Python, and reproducing an Enigma machine with Python. Our community is awash in so much... well... **fun** things! Around every corner there's always a new library, a new article, a new fun project to read about or build yourself, a new piece of code to employ yourself to do something amazing in just a few lines of code. From hunting for oil or subatomic particles to fighting human trafficking and cancer, Python is used in so many diverse areas that there's a seemingly bottomless pool of fascinating applications to draw from to cover in the numerous Python articles, blogs, newsletters, podcasts, convention talks, etc. Python is free to start with, easy to learn, runnable anywhere and yet powerful enough to use in serious applications. It is the first true successor to the 1980's Turbo Pascal, which brought a $99 compiler and the first true IDE to the desktop PC market in an era when competitors cost hundreds to thousands of dollars. It was easy and fun to learn, yet useful enough to write professional applications with. Python, which is fast rising to prominence within education, from CS101 classes to being bundled with the Pi, fills this niche today. TL;DR: Python is the worst possible beginner experience, except for all the other ones. :-) For those of us 40+ and a bit of perspective, we can see how truly remarkable the Python beginner experience is and how it has lead to the second explosion in regular people learning to program computers (the first being the debut of Turbo Pascal in the mid-80s). 
Here's a plug for a lib I'm involved in that enables similar nice declarative APIs without having to do all that horrible meta class stuff yourself (because we've done it for you): https://github.com/TriOptima/tri.declarative
you know you can name your executables whatever on UNIX right? They don't /need/ to have an extension, but you can totally name them whatever.exe
Sure you can it's just &gt;
If you think they are poor you should provide evidence. 
In my day you paid thousands of dollars for a GUI library or you used Microsoft Foundation Classes, where every function call is Something(0,0,0,0,,0,0,0,0,0,0,0,0,Null,Null,Null,0,0,0,0,0,0,0,0) You kids today are just completely spoiled. You've come of age in The Golden Age Of Open Source. Appreciate it.
I just wanted to point out what a cliche it has become that you can't complain without having a solution ready. This is probably why the documentation isn't newbie friendly - newbies don't know how to fix the problem, and experienced users apparently don't know how to communicate with new users.
Why should a non-empty return be a SyntaxError? I'd expect it to work analogously to normal returns from normal generators: def gen(): yield return 1 def gen2(): v = yield from gen() print(v) =&gt; async def gen(): yield await sleep(0.1) return 1 async def gen2(): v = await yield from gen() print(v) 
Honestly, what could possibly be better about the Python documentation? It's written in English language paragraphs and not just an auto-generated list of function/class headers, which puts in ahead of 99% of the other languages out there already. You have many free books such as Dive Into Python. You have online MOOCs, interactive web courses, and a version of PyCharm that even teaches you Python right in the browser! There's nothing in the world easier to start learning than Python. This is the Java documentation: http://www.javafind.net/gate.jsp?q=%2Flibrary%2F36%2Fjava6_full_apidocs%2Fcom%2Fsun%2Fjava%2Fswing%2Fplaf%2Fnimbus%2FInternalFrameInternalFrameTitlePaneInternalFrameTitlePaneMaximizeButtonWindowNotFocusedState.html I'd rather read the Python documentation than read about "InternalFrameInternalFrameTitlePaneInternalFrameTitlePaneMaximizeButtonWindowNotFocusedState" any day!
You can but I doubt that's the default in the Python build
This isn't a python problem; it's a Windows problem. Windows doesn't have a package manager (although they seem to be trying to cobble one together). X is always going to need Y which needs Z no matter what language you're using. Also, you might want to try [NeuPy](http://neupy.com/pages/home.html). PyBrain seems to be... er... brain dead. :-) Its github page shows zero contributions in the last year and I'd heard something about the developers moving on to something else. 
Use conda! The numeric stack on python sucks to install On Windows. Alternatively, use Christoph Gohlke's windows packages. 
I'm an R package developer. I never encountered one of these
scipy, vtk, pandas, pyqt, anything that requires C++? Not everything comes as a whl.
It's funny. Some people complain that there are too many example, some too few. I've found in my professional career that people are on a continuum of "example person" and "theory person". I have two colleagues that are on the extreme ends and I did both their interviews. It was pretty eye opening. It would be nice if you could please both groups. Maybe a big toggle in the upper right of the screen with "prefer [exampels] [specs]" and that moves the chosen block above the other?
As for spot instances, you don't pay the current hour *only* if the instance is shutdown because of a price increase above your bid. That's not really clear in your post. Lots of useful infos otherwise :-)
In the commercial language I was using before Python, you used to get actual printed manuals (1990s)... a huge, heavy stack of getting started, tutorial and reference manuals. You could not only learn the language, but programming itself, UI design, testing and debugging, etc. from reading them. You treasured them and referenced them for years. Eventually that all stopped, documentation became only online. Worse, "documentation" came to mean an automatically generated list of function headers with sentence fragment descriptions (written, incidentally, by offshored Romanian developers) with scarcely a code example to explain how/why to use that function. "Documentation" just became a clickable list of 25 class definitions. I grew to detest it. Discovering Python - and its documentation that is written by actual human beings, for actual human beings - was a breath of fresh air. The documentation is one of my favorite things about the language! This is what I had to work with - in this instance, the standard library INI file processing unit documentation: http://docwiki.embarcadero.com/Libraries/Seattle/en/System.IniFiles.TIniFile Clicking on methods gets you this: http://docwiki.embarcadero.com/Libraries/Seattle/en/System.IniFiles.TIniFile_Methods Nowhere is there a simple English paragraph that explains, step by step, how to use this to process an INI file. Even the example (linked, not embedded) doesn't show you the INI file it's processing, so you get no sense of why the code is the way it is. You have to muddle though all of this to figure out how to use the unit. Now let's look at Python's INI processing unit: https://docs.python.org/3/library/configparser.html Look at that! An honest tutorial! A quick start that actually shows you first the file it'll be processing! Detailed explanations replete with interspersed code snippets and no function signature lists. Who can honestly claim the Python documentation is the worse here? Of course the Python documentation isn't perfect, but it's quite a bit better than any reference page full of class and function headers. In my day, all IBM PC software came with two manuals: one usually labeled something like "user guide", and one labeled "reference". User guide explained to you what you'd bought and how and why you'd use it. Reference was for looking up the nitty-gritty of individual commands. You always read the user guide cover to cover and did it first. Reference guide you flipped through as needed. People seem to be complaining that the Python documentation, which is along the lines of a "user guide", isn't a "reference guide". It's not, but don't complain that that makes learning Python harder. You don't learn to speak English from a dictionary, and you can't learn to program Python from a reference guide. 
Never had those problems. But I came to Python from C and Java, so maybe the article is about someone that learns from ground up, knowing nothing? ...and to this day can't wrap my head around UTF-8 in Python 2. Still have problems and weird characters instead of letters. So - still much to learn.
Just get rid of datetime.datetime and it's golden. 
Missing ().
The official python docs are nearly unusable unless you already know what you are looking for. It's a bit frustrating.
You basically proved his point. His entire position is that the docs are unusable and the community (stackoverflow, in this case) is the saving grace of the language.
Totally get what you're saying, but the virtualenv installs pip and solves most of the headache. My system-wide python install has only a few extra packages—it just doesn't make sense (for me) to install things system-wide when they pertain to a single project. The python package ecosystem has undergone a lot of changes in recent years and there have been many solutions to the same problem. It's one of those problems that isn't *terribly* hard for an experienced person, so most of the old-timers just grumble and deal with it, not realizing just how confusing this can be to a newcomer. So, just to see your side a bit, I tried your scenario: comejoinmynewcult@zika~ mkdir project comejoinmynewcult@zika~ cd project comejoinmynewcult@zika~/project python -m venv venv comejoinmynewcult@zika~/project ln -s venv/bin/activate comejoinmynewcult@zika~/project . ./activate (venv) comejoinmynewcult@zika~/project pip install pyautogui Collecting pyautogui Downloading PyAutoGUI-0.9.33.zip (55kB) 100% |████████████████████████████████| 61kB 338kB/s Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "/tmp/pip-build-ayld0dar/pyautogui/setup.py", line 6, in &lt;module&gt; version=__import__('pyautogui').__version__, File "/tmp/pip-build-ayld0dar/pyautogui/pyautogui/__init__.py", line 114, in &lt;module&gt; from . import _pyautogui_x11 as platformModule File "/tmp/pip-build-ayld0dar/pyautogui/pyautogui/_pyautogui_x11.py", line 6, in &lt;module&gt; from Xlib.display import Display ImportError: No module named 'Xlib' ---------------------------------------- Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-build-ayld0dar/pyautogui/ You are using pip version 8.1.1, however version 8.1.2 is available. You should consider upgrading via the 'pip install --upgrade pip' command. (venv) comejoinmynewcult@zika[1]~/project pip install Xlib Collecting Xlib Could not find a version that satisfies the requirement Xlib (from versions: ) No matching distribution found for Xlib You are using pip version 8.1.1, however version 8.1.2 is available. You should consider upgrading via the 'pip install --upgrade pip' command. (venv) comejoinmynewcult@zika[1]~/project ...and you're right it's totally broken and I wouldn't know what to do. I happen to know that pyautogui is failing to specify its dependency on python-xlib and later a package called pyscreeze fails to specify its dependency on PIL/pillow, so installing those packages makes it all work. Those packages are effectively broken and someone (nudge nudge) should open github issues mentioning that these packages are effectively broken. For a newbie who doesn't know that pillow is a fork of PIL, doesn't have a lot of faith that any of this is going to work, this *could* seem like hell. **FYI**: set up the virtualenv, then install pillow, python-xlib and pyautogui in that order.
I somewhat understand where the author is coming from, except that this isn't a Python problem. If you look at the Ruby ecosystem, the JS ecosystem, the Java ecosystem - all of those are burning trash fires as well. It's easy to find one bad item in X and one good item in Y and say "See, X is bad because ITEM". The last line of the author's post - _You just get used to licking your wounds and continuing._ applies equally to every language as far I know. We have 5000+ years of experience in building buildings, we have ~60 years of experience in creating software. Things are a little rough But this just means that everyone else has had to go through these rough spots. Take them as an opportunity to learn. Help fix the documentation. Write a blog post about solving some problem. Hopefully, we'll be able to pass on something that is a little less broken to the next generation of programmers. Also, I guess I'm going through something similar as what the author is going through. Sometimes I just feel deflated when I see that everything around me is broken, that clients are requesting the impossible, when project managers trust an article they read on Medium instead of your hard won technical expertise. In times like these I reach for one of the books about software projects (The Soul of a New Machine, Dreaming in Code, etc.) and I read how people went through _the exact same things_ 10 or 30 years ago. Human nature doesn't change. So while I feel pissed off at this article, I also feel sorry for the author.
i use the regular virtualenv, is there any reason I should use venv?
A lot of people aren't huge fans of this article, but I felt like this described my learning process pretty well (aside from the community). It would often take several hours of googling to find resolutions to my problems, and the only way to find good documentation was through tutorial point. If I had to go to the Python website I gave up within minutes because it was pretty much useless.
&gt;I don't know when hating on the docs became the default state. You stil need to state your case...regardless... The author of the article already did that. You were refuting the claims in the article so the burden of proof is on you.
How does python.exe help with that? Is Python a shell wrapper script or something? 
Anaconda includes many commonly used modules, including xlwings. I find it much more convenient than python.org distribution 
No, it's that the Python source tree includes, at its root, a directory called Python. On a case insensitive file system, you cannot place a file called 'python' at the root of the source tree because it's name conflicts with the directory name. So it gets called python.exe instead: a unique name. 
I feel your pain. Similar experience about 2 weeks ago. I was trying to read data from XML files, combine random selections, store them in a hash table, and print some debug info to the console. Took about 10 hours, most of which was trying decipher cryptic error messages like the fk I can't execute a script on a different drive without switching to the script's directory (this still doesn't work like the examples I found). I was ready to throw my computer out a window and swear off Python for the rest of my life. I finally got what I wanted, which was an automated way to generate data for the REAL work I need to complete but I'm already exhausted from Python and almost ready to try C++ over this insanity.
MSDN often tries to solve this problem with collapsible examples and by placing examples at the very bottom, which I think is a good solution. Of course you should be able to hide both code and text related to code, and you should have frequent "skip to example" links. This way you can start on the "theory end" but quickly skip to examples if you are at the "example end" of the spectrum.
 SyntaxError: Missing parentheses in call to 'print' Unless older Python 3 versions didn’t do that, you could just google for this…
`import itertools.groupby` is not valid, because groupby is a function, not a module. `import itertools` → use `itertools.groupby()`
I am still struggling with classes in Python.
With mini_racer we decided to do a one-way bridge with V8, meaning that you can only send and receive basic values (everything that is dumpable in JSON). The JS code have no access to the Python function, objects or memory so you don't have this kind of problem.
Wrong, wrong, wrong. &gt; cd project Don’t store virtualenvs in project directories, and if you do, make sure to put them in `.gitignore`. &gt; python -m venv venv The `venv` module? I’ve seen some breakage caused by that. Just install good old virtualenv with `pip install --user`. &gt; ln -s venv/bin/activate `bin/` is really simple to type and a standard. &gt; . ./activate Two dots are confusing. `source bin/activate` is more readable. Also, with virtualenvwrapper, things become even simpler, and if you can make your shell automate activation, zero typing.
To be fair, you're really starting with platform-specific desktop interaction, which is a *hard* subject from a programming perspective. For added complexity, you're on Mac (or you wouldn't need pyobjc), which is a proprietary unix requiring a few workarounds to do pretty much *anything* in python and without any significant support by the vendor. I don't blame you, I blame whoever told you this would be an easy introductory subject (in *any* language). &gt; (no virtualenv though) No, no, no, a thousand times no. Always use virtualenv, *especially* when dealing with crazy-ass C libraries like pyobjc. This way, if you make a mistake, you can just chuck the environment in a second and start again, no harm done; and you won't have interoperability issues with all sort of stuff required by your system. &gt; these seem like simple problems These are *hard* problems in any language on any platform, even more so with proprietary closed systems like Windows and macOS. There is a reason Java built its own desktop paradigm. As I said, I don't blame you for picking this as your first project, I'm just saying that it's not a Python problem as much as &lt;any non-vendor language&gt; problem. No amount of docs or help would make this sort of task easy for a novice.
Our needs was to write security logic in a language that could be embedded in our agents that are written in Ruby, Python, Node or any language. Think modern lua.
I have a friend, fairly expert programmer, who started with python only recently, while trying to use a certain package; he got stuck and asked me for help, and the first thing I noticed was that he wasn't using virtualenv, hence fighting his way through umpteen system installations. Once I introduced him to virtualenv, it was all smooth sailing. I think all tutorials should start with venv creation, now that it's shipped by default.
FreeBSD is compatible with POSIX and is a [descendant of UNIX](https://en.wikipedia.org/wiki/FreeBSD).
pyqt does come as a whl on the most popular platforms.
These look like syntax errors: &gt;&gt;&gt; b.update({a: 5, 0, c: 30, d: 30}) &gt;&gt;&gt; c.update({a: 90, 0, c: 20 }) &gt;&gt;&gt; d.update({a: 80, 0, b: 50, c: 20})
judging from the fact that larry wall is a very funny guy and built several jokes into the language, i’d be surprised if people wouldn’t find it fun to work with.
/r/learnpython
many packages come with binary wheels these days, and anaconda brings its own libs and so on which caused headaches for me when some stuff was compiled against its libraries and other stuff against my system libraries. by now i just have a self-compiled Python and R on my company’s server, and use those with `pip`/`install.packages`
wat
been using python for most of my study and work life so far. never felt the need to use venvs for anything. newest everything → smooth sailing i had two problems with it in the whole time, both of which got fixed within the week
So we just ignore the confuse part? Heresay!
I couldn't agree more. I had a huge problem trying to install opencv. Such a shame, considering python is such a beautiful language otherwise. I guess its libraries are just not meant for "regular" coders like us :(
I'm not a developer. My opinion is that interpreted/scripting languages should be intuitive, easy to pick up and execute, and have fairly straightforward error messages. My experience accomplishing the work described in my previous comment wasn't like that. One of the oddest things I found was the use of underscores when creating a class. I remember seeing similar things when I dabbled in C but it seemed to have a purpose because how low level you could get with C. I also found it odd that it was so difficult to run a script from the IDLE in Windows (I dont have my Linux VM for this project setup yet). Comments on the net pretty much said to call python from a shell followed by the absolute path of the script, which worked just fine (why doesn't this work in Python's IDLE?). There were all these silly things about configuring a Python Path in parallel to system Path, or, having Python scripts automatically executed with the extension dropped. This seems like stiff that should have come up in the installer but mayne I missed it. So after my frustration with Python, it's verbose but unhelpful official doc, the use of this low level like syntax in a scripting language, path management, etc...I just wondered why I don't try using C++ and a compiler. This is the type of work I expect out of using a full blown programming language so why not just use that? You might argue I've been impatient but isn't that part of the point of picking up something like Python? For whatever it's worth, I've been trying C# lately in my free time. When I look at documentation the object, member, and method names are generally intuitive. There are clear examples at the bottom of almost every page. My compiler is fairly spot on about locations of errors. Python by comparison was similar to C in that a reported error could easily be caused by something several lines above. Alright I'm done ranting.
I’ve seen bugs that couldn’t be reproduced with binary packages from other sources. It installs a lot of crap you won’t need — there are over 400 packages, does anyone actually use at least 50? They could do a better service to the community by providing wheels instead.
/r/learnpython
How about just: $ python3 Python 3.5.2 (default, Jul 5 2016, 12:43:10) [GCC 5.4.0 20160609] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; There is a time and place to start worrying about virtual environments, but as a total beginner I would just skip that for now. 
I was put off by the complexity of logging for many years, then I read [this post](https://lukasa.co.uk/2014/05/A_Brief_Digression_About_Logging/), which explains the minimum you need to start using it.
You can use `pip install pypiwin32`.
Perl 6 is officially declarred to be “not Perl”, though.
http://planetpython.org/ is a good aggregation of Python blogs. Also if you want to get a good overview of cool Python libraries https://github.com/vinta/awesome-python is a great starting point. This site also has a list of Twitter channels which periodically post Python articles.
[huh?](https://cloud.google.com/appengine/docs/flexible/python/configuring-your-app-with-app-yaml#general)
how so? tbh i just played with Perl 6 but can't find any such reference on the official site, so I'm curious.. EDIT: oh, I see .. it's a related language, more like iteration than new version of the same lang
Released 2014-10-06. Makes sense. 
Ya! Great point! I've talked about this with my friend. He is updating the code and needs some time to test that out during weekend. 
I responded this way because I've seen the topic of the quality of Python's documentation come up a few times in the last few weeks. And apparently it's been bothering people for at least three years. Like I said, belly aching and complaining is good - it brings attention to problems. But if everyone just sits around complaining about an issue that can be fixed, then nothing gets done. So let's fix it. 
That seems pretty good too. 
Yea, if they don't it's a problem. 
You may have meant `from itertools import groupby`? 
You need `build-essential python-dev` as well. Also, if you can't be bothered on windows there's a web page of .whl files of most common but annoying to build packages (looking at you numpy and matplotlib). http://www.lfd.uci.edu/~gohlke/pythonlibs/
Berkeley Software Distribution (BSD) is a Unix operating system derivative This is from your very own source BTW. Please do not only quote the parts that suit you but the whole statement or thought. BSD was started during the UNIX fall as a duplicate for those unwilling to change in those times and it evolved from there into the modern operating system it is.
Come on guys/gals. What's going on here. Is this the Python hate train? Python is the easiest programming language to learn to date. The documentation is 'good' and understandable, if you care about how it 'looks' go and improve it yourself, it's open source for jebus sake! You cry because you have to install some dependencies or compile some other ones? Do you use Windows or what? In Linux world that's a norm, any descent programmer knows how to swim those shallow waters, stop crying. Now go and try Ruby's RVM, Bundler and rake ... yeah. And Java's gradle, etc...? And don't make me start with PHP... don't. Did you try Python's pip? So please go back to your crying cave and leave the rest of us happy Pythonistas do our work. And if you have some things you don't like, again, stop crying and start collaborating, that's what the open source world is about. [Import Antigravity](https://xkcd.com/353/)
[Image](http://imgs.xkcd.com/comics/python.png) [Mobile](https://m.xkcd.com/353/) **Title:** Python **Title-text:** I wrote 20 short programs in Python yesterday\. It was wonderful\. Perl, I'm leaving you\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/353#Explanation) **Stats:** This comic has been referenced 272 times, representing 0.2256% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d62cpig)
I think this is a great article because when you get more skilled with a language or programming in general it is easy to be blind to these kind of problems because they don't slow you down anymore as they did in the past. Actually I wish there was a culture where this kind of feedback is encouraged. Most of the time people and especially beginners are ashamed to talk about such problems because they think they themselves are the problem. While in reality it is the software which could be greatly improved. But without such feedback we all think our software is fine as it is when it is NOT.
I really like this feature. Makes code less verbose compared to when we use `format`. Already making use of the similar feature in ES6.
All of my shit experiences on stack overflow have been asking python questions. 
Hence the using of the --user option. But in the case of macOS for instance, homebrew doesn't track python packages. You kind of have to use pip for the system packages?
ah ok, got it.
OS-X is case sensitive. I have no idea why the default make file named the executable python.exe EDIT: I was wrong about this
Python.exe is what came out of the default make file, I was pretty surprised too
&gt; Unless your OS has absolutely no ability to track packages OSX doesn't have a package manager (that allows third party sources), so it's exempt, you have to use a third party one.
Did you try binstar at all? Conda doesn't solve all problems, but it helps a lot with some of the binary dependency ones. I'm usually on Windows, so binstar hadn't been an option for me - any time I did find a package that conda didn't have, it seemed to be on binstar but only for Linux or Mac. I've also had to resort to specific Linux distributions on a VM, or preconfigured docker containers to get some things to work - but then this is not a Python specific issue either.
Ok, the website is much more informative than your README file - maybe just include a link to the website in the README, that would have been enough of a link for me to figure out what you are doing.
didn’t know of binstar
PostgreSQL. My fix was to use R.
I ave never seen a single person use it.
Strangely pyenv is deprecated and they now suggest directly using: python -m venv Edit: details here if you are interested https://bugs.python.org/issue25154
Account or post? If you delete your *account*, all posts you made remain, but your username is changed to [deleted]. If you delete your post, both post text and username is changed to [deleted], but your account remains. I corrected him. If he wants to delete his post over that, that's not my problem.
I still think that introducing this was a bad decision We now have 3(!) ways to format strings. Old-Style: '%s %s' % ('Foo', 'Bar') New-Style: '{} {}'.format('Foo', 'Bar') New-Style with KW-args: '{one} {two}'.format(one="Foo", two="Bar") and now: foo = "Foo" bar "Bar" f'{foo} {bar}' This goes against Pythons "There should be one-- and preferably only one --obvious way to do it." rule. 
Agreed.
I appreciate your input. It's something I would have never considered. 
Python3 introduced a new version of the GIL, as outlined in David Beazley's talk here http://www.dabeaz.com/python/NewGIL.pdf Basically the old GIL used an incrementing counter to decide when to switch threads (every 100 instructions or so IIRC), whereas the new one uses a global variable to tell the thread to drop the GIL. A thread can basically ask for the GIL to be dropped and waits until it has been unlocked.
The GIL was partially rewritten for [Python 3.2](https://docs.python.org/3/whatsnew/3.2.html#multi-threading). There are details [here](https://mail.python.org/pipermail/python-dev/2009-October/093321.html).
Thanks for the reply. What do you differently in the production build then?
Precisely because the PEP doesn't plan to add 'yield from' support to async generators. And non-empty return makes only sense when you have 'yield from'.
Hahaha whack-a-mole... that's absolutely what it is. Funny you mention that, I actually made [this page](http://www.vtk.org/Wiki/VTK/Configure_and_Build) way back when I was doing a lot of work with VTK. It was deprecated almost as soon as I finished it, but it hasn't been updated since.
For me, the main things that you get in a container that you _don't_ get in virtualenv: - Running multiple instances of the same service without setting up multiple virtualenvs - Clean start with every build - Exact duplication of python dependencies between test &amp; deployment - Easier to _move_ an installation from one machine to another Pre-containers we set up a new virtualenv for each deployment and had several deployments for each project (with different .ini files that differed only on the port number the web service bound to). Post-containers they all had the same config and container, and the orchestration sorted out port numbers and DB information. Pre-containers we had _many_ users for each service, to get user separation, post-containers each container instance has their own user namespace, and the same user-name inside each container. Not that much has changed, agreed, but now they are properly namespace separated from eachother. 
OS Xs *default* file system is case-insensitive, but you can choose to format the drive as case-sensitive if you wish and pretty much everything (from Apple) will continue to work fine. The two offenders with not working properly on case-sensitive volumes are Steam and (I think) Adobe.
why doesn’t it? it’s useful: def parser(token_iter): assert next(token_iter) == Token.start preamble = yield from parse_preamble(token_iter) body = yield from parse_body(token_iter) epilogue = yield from parse_epilogue(token_iter) return preamble, body, epilogue i can see the same pattern being useful in async iterators, too
Or you are using RHEL/CentOS. RHEL/CentOS 6 ship with Python 2.6, and 7 ships with 2.7. To be fair, since they started rolling out Software Collections, it's been a lot easier to stay up to date with development environments. Still, 2.x is the shipping environment. Unfortunately, I am currently writing this from a RHEL 6 box. And I know of at least a couple of RHEL 5 boxes still in service around here, which run Python 2.4...
I've switched to using [pew](https://pypi.python.org/pypi/pew/) now, which works very similar to virtualenvwrapper, but in a more cross-platform compatible way (such as support for alternative shells).
I added some more experiments increasing the thread count further, it looks like Python 3.5 uses very different locks. Of note, at 32 threads (didn't try the others) Python 3.2 and 3.5 have the same behaviour and performances.
Maybe? Do you have a specific question?
Not if it is implemented as described, as first adding the two numbers then calling `confuse`, because addition is commutative. So assuming `addAndConfuse` is implemented as `confuse . (+)`, that means that just swapping the operands doesn't change the value passed to `confuse`. For Haskell, you're not really allowed to have a function that can return different values when called with the same input(s) (dealing with that is wrapped up in monads, but the type signatures indicate these are pure functions). Since `addAndConfuse 5 7` and `addAndConfuse 7 5` both would call `confuse 12` but produce different results, this can't be implemented as described without cheating.
Maybe in python 4.0 we'll remove all the others and just have `f` strings. For the record there are actually 2 other ways. The noobish `"text" + str(value)` and `string.Template`.
DAMN FUCKING CLASSES!!!! I have been trying to understand classes since the past 3 months and have achieved nothing!! Y NO CLEAR CLASS EXPLANATION PYTHON?!!
All the old UNIX admins here at work all use Perl and they seem pretty happy... The windows admins, however, not so much. I feel bad for their VBA...
I completely disagree. The first point in the article isn't even Python-specific. News flash: programming is hard. I recently re-specialized from PHP to Python and had very little trouble. Rather than bitching, I read through pages of docs, digested PEPs, learned the syntax and libraries, and have been extremely pleased with Python, the **thoroughness** of its documentation, and the experience as a whole. I'll probably never go back to PHP. Yes, *it's work*. No, it's not "get started in .2 seconds with PHP!" or "write your own Twitter clone with Node in 12 milliseconds!" But guess what: *I've learned a ton*, not only about Python, but about software development and the inner workings of computing. The experience I have gained has been, and will continue to be, extremely valuable. I measure, in no small part, the worth and skill of a programmer by his or her willingness and ability to read, synthesize, and apply new knowledge, especially when that knowledge isn't delivered in bite-size, pithy excerpts with examples that don't teach one to think about the context of the problem, different solutions, and the trade-offs of each. There is so much knowledge and so many examples of good Python out there, I don't understand why this author had even the slightest bit of trouble. TLDR: This article is complete horseshit and it makes me more aggravated the more I read it.
Hm, I wasn't following PEP 498 development too closely. I agree that escaping seems weird. &gt; what can i do to prevent this mistake? I'd first quickly glance over python-ideas and python-dev archives to see if this was discussed before (and I'm sure it was). Try to find the reason/explanation for this. Sometimes you think something is totally nuts and there should be a better way, but in reality there's something that prevented that from happening. If you're unsatisfied with the explanation you found, feel free to raise a question/suggestion regarding the PEP on python-ideas, or directly on python-dev. Please don't use strong words like "insanity" there ;)
http://lmgtfy.com/?q=python+bytecode+reference
some things happen out of lazyness: they made pretty clear that they did it because strings wouldn’t tokenize properly. but they aren’t strings. they’re expressions consisting of strings and arbitrary other expressions. those embedded expressions are like function arguments, not parts of the “f-string”. disallowing `'` in an embedded expression in a f literal is as silly as disallowing `(` and `)` in a function argument because “function calls tokenize like that” i’ll follow your suggestions, thanks!
Pretty much every open source project loves people who contribute documentation, Python is no different. https://docs.python.org/devguide/ Subscribe to python-Dev and get a mentor (I'm not sure if they still do but contributors used to have a mailing list for people new to working on the language/interpreter to get started)
This is correct. `pyenv` is a 3rd-party library and doesn't directly deal with virtual environments (there's a plugin for it which does, `pyenv-virtualenv` if you want to switch between virtual environments within a certain python version). https://github.com/yyuu/pyenv https://github.com/yyuu/pyenv-virtualenv
Deploy Ruby, PHP, Go, Rust, Java, or C#/Dot-NET apps. Not all of us are in 100% Python shops. 
I think calling it `shutil2` while you're not the developer/maintainer of the original module is confusing to say the least.
i hate how long format() is, always puts me over my line length 
What is this? ELI5?
This should be its own post.
I've done lots of work, but the vast, vast majority of the work is on the IO side. There are lots of other useful things (e.g. calculating element Jacobians for shells) that are useful, regardless of whether you use a full solver. It's also nice in that it's a step towards that. The GUI already creates a max interior angle fringe plot, which is handy, but there are other useful checks. I guess at step 1, I'd like to see beam elements supported, but have never really seen the equations written out in 3D (e.g. Iy and Iz are considered, let alone with a shear center). I also am not sure how to add support in for distributed loads &amp; point loads not at a node (e.g. in the middle of a beam). I think you're supposed to integrate the load using quadrature points, but not 100% on that. Once the displacements have been found, you can calculate stress/strain, which at least is easy to check. Any ideas of what you'd be interested in doing? If you don't want to do any of that, but would like to help on the GUI, that'd be great too :)
&gt; Although it doesn't have a copy method You can create one method instead of one library. &gt; I prefer to deal with strings and functions instead of objects This will bite you on different systems, believe me.
I like the idea of keeping both f-strings and `.format`. On my team we don't support using the old style formatting anyway. Only string concatenation and `.format` will pass a code review. At least f-strings and `.format` keep roughly the same syntax. Unless there was a way to transform a string variable into an f-string. Then I'd be all-in for f-strings. var = "hello {x}" x = "world" translate(var) == "hello world"
Wouldn't say i am a complete beginner anymore, but I did not start too long ago and I seriously don't get this article. Of all the programing languages I got in touch with (C, Java, PHP, LotusScripy [i know, i know], JavaScript...) Python was by far the easiest to learn and i never encountered problems with the documentation. I could find everything i needed (other than in java, where more stuff seems to be deprecated than anything else). Sure i had some dependency issues with pip once or twice, but one has to a hypocrit to purely blame python for it. This is just something you encounter as programmer in almost any language. Don't ask how long it took me to install webpack via npm... Yes beginners might have problems with python, but they would probably have had problems with any language you present them, when it is their first language. We just have to accept that programming just is not as easy as eating or sleeping. Its a continous learning process and you can either start embracing that fact or write a click bait whiny article like the one presented in this post.
Tried it: Scalar found where operator expected at - line 1, near "$yes $it's" (Missing operator before $it's?) Scalar found where operator expected at - line 1, near "$it's $a" (Missing operator before $a?) Scalar found where operator expected at - line 1, near "$a $nice" (Missing operator before $nice?) Scalar found where operator expected at - line 1, near "$nice $@" (Missing operator before $@?) Bareword found where operator expected at - line 1, near "$@language" (Missing operator before language?) syntax error at - line 1, near "$yes $it's " Execution of - aborted due to compilation errors. 
Tried it. Gives an error for a print statement which is similar to when you try to run version 3 print on 2.7.
Thanks. Will try this. 
Why do you mention these specific packages? I see some if not all of them have binary wheels. If `pip install` doesn't find it; check http://www.lfd.uci.edu/~gohlke/pythonlibs/ If it doesn't help then ask on StackOverflow and if nothing else helps; read the installation docs. Luckily, you do not need it as a rule. Popular packages (that a newbie might encounter) do often come as binary wheels on Windows. 
That's not true. Perl 6 is "not simply the next version of Perl 5." They are both Perl, and live quite comfortably within the same family tree, but it's not as if, now that we have Perl 6, everyone should stop using Perl 5. 
The existence of multiple decades of Perl programmers reading and writing each other's code is not entirely in sync with that worldview. 
&gt; I haven't learned a lick of new perl in over a decade, and that has sufficed. I think that it has objects now Perl version 5 introduced objects circa 1993, so unless you're referring to a metaobject protocol (introduced in 2005 by Moose), Perl 5 has had objects for about 23 years. 
&gt; The only reason to use 2.7 at this point is library support True, but that's a pretty major reason to choose a language. It's the reason I use Python in the first place instead of a language that is more experimental but less widely used. 
[The installation instructions](http://initd.org/psycopg/docs/install.html#install-from-a-package) look simple enough e.g., it is the same old: `pip install psycopg2` on Windows. I don't see how any other language can do significantly better unless it is builtin.
Sorry, that's the one I use for 3.5. Maybe downloading the wheel for cpython 3.5 from https://pypi.python.org/pypi/pypiwin32 would help?
You need PostgreSQL installed on the computer. Or you have to find a precompiled version. Either way, the R installation process was much easier.
How to think like a computer scientist 
Shameful! Most of these are outdated, there's nothing to tell us beginners which ones we shouldn't buy. It's just link bait by agiliq.
Or http://www.brython.info/
It's good for libraries to have two types of documentation. There should be a Reference-style which is really just a listing of all the methods, call signatures, and descriptions of inputs/outputs. Then there should be a tutorial-style documentation that gives examples of common use cases. The Python docs have both, though I've always found the website's interface a little clunky. Sometimes it's difficult to figure out which 'side' you're in, and where to go to switch, if you just land on one page via a quick google search. Also it looks like the tutorial doesn't cover many of the standard library packages.
following the *"There should be one-- and preferably only one --obvious way to do it."* rule to the ends of the earth regardless of context, goes against the *"Although practicality beats purity."* rule
Gr a cias
This comment motivated me to revisit the inline docs for pyparsing - I am now adding more examples to the various class and method docstrings. This will probably double the size of the .py file, but hopefully will earn me some karma.
f strings are not meant to replace .format in general, just some usecases of it. The eventual intention (if I'm not mistaken) of this which will never happen, is to remove % interpolation, and leave Templates (since they work differently from .format for good reasons), and .format (since that can work on dynamic strings)
I don't understand why you're being a dick to me, but whatever.
The solution is the buy the book the author is selling, *obviously.*
This article is from another world. Python is universally considered to be a language easy to learn and the top comment on this thread seems to confirm this trend. Seems like the feeling described in this article is only experienced by a minority.
markovnet isn't based on any particular paper but on [2-D graphs of hidden markov models](https://en.wikipedia.org/wiki/Hidden_Markov_model#/media/File:HMMGraph.svg). You can certainly subclass markovnet.Func to select from high-dimensional arrays of neighbouring functions. The intention is for markovnet to be the most minimal layer necessary for probabilistic function selection from a hidden Markov model. You could then do experimental things like placing MarkovNet instances in iterables selected by more specialised classifiers. Hope this helps.
TIL! Never knew Python 3.3+ had venv with itself. Thanks! Any advantages of venv over virtualenv?
This seems like a bit of an exaggeration. Documentation isn't always helpful but the packages that most people use have plenty of tutorials and videos for. For every issue I've had with packages like Matplotlib, and Pandas, there's a tutorial/stack overflow thread with an answer. The real issue is for less used libraries like NiPy which have documentation that isn't particularly helpful and have no tutorials. Installing libraries is definitely a pain but as long as you know how to use wheels, it's not much of an issue. Installing libraries was probably the only issue I had when learning Python. 
yeah but you also have amazon affiliated links linked to shitty/outdated books
thank you! 
Thanks! Really useful post
I'm on Windows. I will check that out when I get the windows 10 anniversary update and the bash shell. I used the backup script as an example of a problem this module solved.
@avinassh affiliate code now removed. 
They're still gonna depreciate stuff. Just no absolutely enormous changes like `str, unicode -&gt; bytes, str` and `5/2 == 2 -&gt; 5/2 == 2.5`
Do you mean a make a browser plug in that will execute python in the browser? Your question is unclear
How would you write that particular graph with your library? 
... that's horrifying. I've been using OSX for quite a while and did not know.
Very cool. Question: In the writeup he referred to the distance between 'nodes'. If he referring to each object in his "basket of amenities" as nodes?
Wait, your objection to the Python documentation is that it has entire modules in single pages, and you'd prefer everything to be split into multiple pages?
Functions are snake_case in Python. Not CamelCase. 
For beginners, IDLE is pretty good. It's one line at a time unfortunately, but good for testing new concepts. For actual scripts and things, I really like Sublime Text 3
Sure will do :)
http://pypyjs.org/
Yeah Photoshop definitely didn't work on a case sensitive fs when I tried. In don't really understand how devs can be so inconsistent in referencing their own files. Then again as much as I love legacy Unix stuff, I can't really justify a use case for case sensitivity anymore.. Like if you're naming files the same thing but different cases you're doing something annoying that most people will tell you to avoid, so why even allow it?
I'm not saying that that's necessary, but I am saying that each function should have at least two examples next to its reference docs, and at least one sentence on each pararmeter that a function has. Once you've done that for every single function for a large module, individual pages for each function definitely starts to look more apparoachable. EDIT: fixed typo
DataCamp light works well too. You can make blocks that run python code on any webpage https://github.com/datacamp/datacamp-light Example: https://cdn.datacamp.com/dcl/standalone-example.html 
Additionally, it's important to note that the rule doesn't mandate that there only ever be one way to do anything - that would be stupid. It states that there *should* only be one *obvious* way to do something. In that sense, f-strings and `.format()` do entirely different things. One is a way to create an immediate string that can interpolate local variables, without fuss and bother, whilst the other is a way to transform an existing template by inserting known key=&gt;replacement pairs. It's also important to note that there are situations where format strings and %- interpolation are the non-obvious ways to do something, notably, when writing messages for exceptions. Clearly, you want to tell the user a bit about the environment in which the exception was thrown, but `.format()` alone is nine characters long, and adding in a number of key-value pairs adds a huge amount of wasted text. Previously there were no obvious ways to solve this problem, now there is one obvious way to solve this problem.
 My college library had not a single computer science book.. no joke
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/redditsync] [Code section is barely readable](https://np.reddit.com/r/redditsync/comments/4w0pb2/code_section_is_barely_readable/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Why should installing packages cause you to run out of memory? If you think about it from a high level perspective it is completely ridiculous that the act of _installing packages_ can consume all of your memory. Yes, they are compiling things... but why? Why should you have to compile packages? Shouldn't they be pre-built? What's the point of maintaining the package otherwise? /mini rant from someone who hasn't had this particular issue
It's a hell of a lot easier than making some weird exception for the primary alphabet in ASCII.
Most of the rebuttals seem to be from people who have some amount of Python experience. *What do the newbs think?* Did this article seem accurate to you? _Please only answer if you have less than 6 months experience with Python._
Given the behaviour of 3.3+ becomes very similar to 3.2 when the thread count increases, I'd think more that the overall scaling is the normal behaviour of the new GIL but they somehow improved things at the low end in 3.3. Though it could also be something similar to `io` (where the initial implementation had pretty bad performances).
&gt;&gt;What's your general opinion on Docker?" &gt;I didn't like it, and it seemed overhyped. &gt;I've used Docker for Mac now, as well as the Heroku Docker beta registry. This makes the experience of using Docker much pleasant. So much so, that I think I like it — for certain things. &gt;I do still think it's generally overhyped though. Not really sure why your average developer is excited about it." Amen.
i’m just repeating the official stance: there is a programming language called “Perl”, which is available in the major versions 1-5, and one called “Perl 6”, which had its first release (version 6.0.0) some short time ago. the latter is inspired by the former, but it *is* not it.
There's no harm in it, but you'd have to download and install the older version, then learn it, then learn all the ways the new version differs. And they weren't minor changes, by the way. There were a lot of very significant changes. It's almost a new language. For me, that's a big waste of time that could be better spent learning Python 3 and then learning even more Python 3. That's just my choice and my opinion. 
Technically, there's nothing you can do in Python/Git that a sufficiently disciplined developer can't do without them, either, given enough resources.
They each serve different purposes `f''` is for literal format strings. Since they are literal, there are less restrictions than... `str.format`, which only really allows you to change the formatting of variables (and access items and members), but allows non-literal strings to be used. `string.Template` is for making custom string templating, and is really good for user-facing formattable strings (since it can gracefully handle errors, compared to the other methods) `str%` is for c-like code, and as such, roughly follows printf formatting it /is/ a bit excessive, I agree. But they each do have different reasons to exist, which the others don't really properly fulfil
I just end up splitting my format call across several lines. Or throwing a `# noqa` on it if it's in a repr since that's just a developer helper 
Step 1: shut down your computer.
Type python3 instead of python. Could imagine that's your "question".
I started a year or so ago with Python2. I then discovered that any "new projects should be using Python3." The differences are huge. Everything that just works in 2 is a nightmare to use in 3 (Gtk I'm mostly talking about you). It probably doesn't help that Kubuntu is my primary OS with Python2 installed for system.
&gt; the official stance: there is a programming language called “Perl”, which is available in the major versions 1-5, and one called “Perl 6”, which had its first release (version 6.0.0) some short time ago. That's not the official stance. Not sure where you heard that. But according to Larry the situation is this: &gt;&gt; People tend to think of new versions of a language as parent and child (where the child is expected to kill its parent?!?), but nowadays we like to think of them more as older and younger sisters, with different strengths and weaknesses. There is occasionally a bit of sibling rivalry, but by and large they blend well when they sing together. And for sure, many of the Perl 6 developers still love Perl 5 for what it is, and don't want to break that. So, as a new member of the language family named "Perl", Perl 6 tends to be shinier than Perl 5, but they are definitely peers in that same language family. Side note: Perl didn't really have major versions 1-5. It's more complicated than that because of the way it was released, but for most purposes, the versions that had any real impact were Perl 4 and Perl 5. Perl 5 was arguably a bigger leap forward than Perl 6, even though it maintained more backward compatibility. I say that because it opened Perl 4 up to OO programming, functional programming, arbitrary C extensions, modules and reference types. It really did drag Perl up from the ooze of primordial scripting languages into the realm of generic high-level languages. Everything else that Perl 6 did was either refining those features (e.g. making subroutine parameters easier to declare and manage) or introducing an enhanced version of something (e.g. lists can be lazy). There are, as far as I can think, just three exceptions: * Explicit typing * Grammars * Metaoperators And huge as I think those are, and as desperately as I feel that some of the refinements and extensions were needed, I don't think Perl 6 really changes the playing field as much as Perl 5 did. Then again, having been there at the time, that's perhaps easier for me to see than for those who started after 1993. 
 Thank you! ^^:)
Perl 5 just caught up and became modern. Perl 6 is futuristic
The red are functioning temples, and the blue are temples that have been announced or are under construction. I used the data from [this site](https://www.lds.org/church/temples/find-a-temple?lang=eng).
Scripts generated by `entry_points` in setup.py startup slowly because they import `pkg_resources`; c.f. https://github.com/pypa/setuptools/issues/510. I wrote this monkey patch that generates a different script that starts more quickly.
That makes total sense. Thanks for explaining that to me.
I like this module. It is short and easy to grok.
:) I have more tutorial about tkinter on my blog, glad you enjoy this one
Is that the goto place for numpy/pandas questions? I sometimes have them, but I wasn't sure if it was too high level to post there.
How fast is it? How long in milliseconds or microseconds is a response?
PyCon 2017 is May 17-25. 17-18 are pre-conference summits and tutorials. 19-21 are the main conference days. 22-25 are sprints.
&gt; Edit: amusingly it occurs to me that the joke function I made up is impossible to implement and have it spit out the example values, at least not without cheating (unsafePerformIO). Can you explain that? I'm not that familiar with Haskell, but it seems that hashing the input values and returning the last bit of the hash would satisfy the definition (providing you picked an appropriate hash function), and appears to be pure (basically a reduce operation)
Interesting. I think I'll subscribe to contribute too then. I have had some really stupid problems that I wouldn't mind helping someone else out with if they ask there.
This is great! One I always liked was: If you do a job badly enough, sometimes you don't get asked to do it again.
I *think* there's some simplified logic in how python finds its site-packages directory and so on (the binary looks upward from its own folder instead of looking at some hardcoded path, so maybe the venv module can take advantage of that and simplify its logic? I don't know, I'm not real familiar with all the new machinery).
thanks, and to /u/comejoinmynewcult (that's exactly the error i get, btw, thanks so much for the thorough reply. will try what you suggest), /u/toyg, /u/kankyo, and /u/lmneozoo. i was inspired by the 'automate the boring stuff' course on Udemy, FYI. previously i only used native modules and went through the 'learn python the hard way' website. i clearly have some stuff to learn.. deeper i go!
[But think of all the power](http://i.imgur.com/SklOJsp.png)!
This is a classic updog problem
Thanks for the great share!
Logging module supports .format-style formatting with Formatter with style='}'.
If anyone's curious, [here's video of the rituals and costumes used inside](https://www.youtube.com/watch?v=-2MvdQKC0jc) (post 1990 after throat slitting gesture was eliminated)
In case this is OPs link, your SSL cert is out of date or not accepted by Chrome. http://i.imgur.com/oVjBRGM.png Check out letsencrypt.org ;-)
That would be a start. However, in order to move forward you will need contributions to something deployed and live. Pickup any open source project and start sending pull requests. Or join any company as an intern to learn the tools of the trade.
Can't comment on the hiring aspects, but on a personal level I'd say you need to go beyond tutorials and try to solve interesting problems for yourself. Not just complete exercises from blogs and videos. Try to automate tasks that you come across in your everyday life. Develop new solutions to small problems. It's far more important to develop problem solving skills than it is to learn to follow the instructions. You can also try to make a difference in some open source projects. See https://openhatch.org/
I bought two scoops, and even though it's good, its sadly outdated to the point that I am more frustrated than helped by it.
It's neither, OP's just not serving the intermediate certificates, and Chrome doesn't have them. OP, when you get your SSL certs your CA will have sent you both your leaf and a series of intermediates. Your web server needs to serve *all* of those, or lots of stuff will break.
Because "yield from" is an alias for "await".
I will be messaging you on [**2016-08-04 20:52:00 UTC**](http://www.wolframalpha.com/input/?i=2016-08-04 20:52:00 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/4w3jtv/restapi_in_python/d63osnd) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/4w3jtv/restapi_in_python/d63osnd]%0A%0ARemindMe! 12 hours ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d63ot58) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Conda is awesome. It took all the pain away from setting up Python on my locked-down Windows work PC, without admin rights, and blocked internet access to most websites (including the Conda repository). I just brought Anaconda on a USB stick and it works beautifully.
You probably want to: - add a black list to be able to specify some types to not flatten (you may want to ignore dict, strings, etc) - just remplace test_iter with a try/except with iter(). 
I use Anaconda on my work PC, and I'm glad it comes straight with any dependency I might need. My work PC doesn't have Internet access to the Conda repository (like most websites, my large company uses a whitelist), so otherwise I wouldn't be able to install any package. Here I just brought the whole thing on a USB stick.
Hi cricquebe, If you need to run tasks in background, you can look at [Celery](http://www.celeryproject.org/), which is a distributed task queue. A simple workflow would be : 1. Flask receives the job request by the client 2. It transmits the job request to Celery 3. Celery queues this job and generate a unique Job ID 4. Flask sends back to the client a HTTP 202 (aka. ACCEPTED, meaning "OK but can take some processing time") with the job ID 5. The client (or the frontend using your REST API) makes periodic requests to know whether the Job ID is completed 6. When OK (or error), you (Flask) send him a 200 with the result EDIT: Google App Engine [tasks queues](https://cloud.google.com/appengine/docs/python/taskqueue/) could help you do that.
You are closing csvFile twice
If you use pip to install stuff, you should now be getting sane entry_points scripts (thanks to *distlib*, I think), without any special treatment. This workaround is only necessary if you run `setup.py` directly - which you generally shouldn't do, because setuptools causes a range of problems.
Imho the best way to start is to start making a project (simple cms, forum, wiki etc.) on your own and only seek help when you don't know what to do. Do not blindly follow tutorials. You'll learn nothing that way. 
Yea, that's what I thought, and that's why I'm very curious to see what benchmark gives 100x speedup.
urllib3 is an independent project, too, and it's everywhere. (everywhere that requests is installed, anyway)
I know, I was just mentioning them as they're sort of related.
1. You will probably wish to go with Heroku since it is pretty easy to operate with the tutorials and only costs a few bucks for lightweight use. 2. GitHub isn't that hard to use and you should be able to get an education account from them. Are you mixing Git and GitHub as a tool and a SaaS service? 3. For Heroku you pay per app, in Digital Ocean you get a virtual machine (the droplets) that you can use to host multiple apps. 4. For a domain name you have to have a name server that points the name to a host. A domain name is a DNS record that basically translates a string that is your domain name to an integer that is your host IP address. Heroku should have documentation for this. You are mixing a few concepts here such as Digital Ocean VMs and Heroku Dynos, but that is OK. For your purpose I would use Heroku and their free tier or first commercial tier since they are easy and friendly. If you scale beyond those solutions which will probably end up costing under a $100 / year for your purposes you can switch to Digital Ocean or other stuff, but that is harder. tl;dr: Set up OpBeat (free) monitoring account and Bitbucket (free) or GitHub (edu) account and host your app on Heroku (free or cheapest tier) if you want to traverse the path of least incline.
Yeah, I guess I'd do something like this: def swat(items): for item in items: if hasattr(item, '__iter__') and type(item) not in (str, dict): yield from swat(item) else: yield item nested = [[range(3), (3, {'key': 'value'}, ['spam','ham',['eggs']])], [(i for i in range(5, 8)), [8, 9, 10]]] print(list(swat(nested)))
Instead of checking if interable you should just try iterate and catch the exception. That's considered more pythonic to ask forgiveness instead of seek permission. Also it's more duck typing. 
It does make it a tiny bit clunkier though, if you want to avoid iterating over certain types. From my own example above: def swat(items): for item in items: if type(item) in (str, dict): yield item continue try: yield from swat(item) except TypeError: yield item 
Python has long supported asynchronous operations via generator expressions/coroutines. So you have a function that occasionally `yield`s but unlike a normal generator you don't care what it yield, yielding is just a way to pass control up the call stack without losing state. The main loop then turns an asynchronous function call into a synchronous call looks roughly like: async_handle = func() while True: try: next(async_handle) except StopIteration as exc: return exc.value where `exc.value` is the value stated in the final `return val` of the async function `func`. Obviously all this boilerplate is a pain to write out, so 3.5 got new keywords `async` and `await` which simplify this process, however the side effect is that you can't write a generator that is asynchronous. For instance if you wanted: async def async_generator(): while True: val = await expensive_async_call() yield compute(val) The callers of that function would confuse the await expressions for the yield expression and would see a generator that interleaves awaitable, value, awaitable, value, etc... ------------------- That said its very hard to follow this PEP unless you know how the whole async mechanism works, and its not entirely clear what the use case for an asynchronous generator is, but I suppose somebody out there might find it useful. 
I recommend using a version control like git for any project programming or not which involves text files that change from time to time. 
Very fun, remind me of a problem I had and written about: http://lothiraldan.github.io/2011-07-07-flatten-dictionaries-values/ You could also use reduce
In this case would USER_ADMIN just be a number? Or would you use an enum?
Gooble gobble!
Oh yeah, good point.
An enum is better, but they've been introduced in 3.4, so prior to that your only option would be a number.
Please avoid using `type()` when `isinstance` will do: if hasattr(item, '__iter__') and isinstance(item, (str,dict)): Explicit use of `type` vs using `isinstance` will fail to recognize subclasses.
Heh, bottle.py has a built-in template engine for exactly this reason: Prevent external dependencies.
As long as you link dynamically to PySide and don't include it in your code or mix your code with the LGPL code of PySide you are fine to chose whatever license you like. Since there is no static linking in Python you need to mix your code with PySide to make it subject to the LGPL. From https://wiki.qt.io/About_PySide: "Licensing PySide has been published as a response to the lack of suitably licensed Qt bindings for Python. PySide is licensed under the LGPL version 2.1 license, allowing both Free/Open source software and proprietary software development." So the PySide devs want you to be free to develop even proprietary software. The only thing dangerous to me seems to be the generated code. But after reading this I don't think the PySide devs would object for you to license it under MIT and claim copyright. Maybe ask them to clarify about the licensing of generated code but shouldn't be a problem.
I have no idea what you just said, but is there a place I should go to learn more about this? I'm only getting out of codecademy. 
I've used Digital Ocean, AWS and Heroku for small projects and usually prefer DO for small projects where I want to keep costs low and capped. I like the static pricing and find that the smallest droplet at $5 is enough to handle small flask apps where I don't expect large bursts of traffic. AWS with elastic pricing is a bit more work to figure out what you'll be paying monthly. I believe there is a way to cap it as well but I'm not sure what direction to point you in. I'm not too familiar with Heroku's pricing model, it may be cheaper. It's certainly easier to deploy to and they handle the infrastructure end which is nice. With AWS/Digital Ocean you'll need to prep your server which involves sshing into it and installing the necessary software to get up and running. If you're okay with the command line it's not too difficult. If you're new to unix/linux then it may be a challenge. Digital ocean has some [great tutorials](https://www.digitalocean.com/community/tutorials) to guide you through setting up and deploying a flask app. You can use these for both AWS and DO. Purchasing a domain and pointing it to a droplet is also relatively simple with digital ocean. Just point your DNS on your domain name provider to digital ocean's servers, set it up on DO and point it to your droplet. I'm not sure how easy it is on Heroku. There are certainly a lot of options out there but it usually boils down to your budget and if you want to pay more for managed infrastructure and focus more on your app or if you'd like to save some money and do some of the backend stuff yourself. 
The "right tool for the job" in this case is probably virtualenv, not anaconda. I don't have a more specific answer though, sorry. 
https://checkio.org/mission/flatten-list/ Basically this problem. Lot's of solutions (viewable after you have solved it yourself).
I'm also on Linux. I have pip 8.1.2, and I just installed twine, as a convenient example, by running `pip install --user twine`. Here's the entry point I got: #!/usr/bin/python3 # -*- coding: utf-8 -*- import re import sys from twine.__main__ import main if __name__ == '__main__': sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0]) sys.exit(main()) 
Thanks, that pretty much is the answer I hoped for. And regarding the "generated code"-thing: generated is maybe not even the best fitting word, it is more like converted. You have that `*.ui` file from QtCreator and just convert it to a `*.py` file, so that really should not be a problem, but I'll clarify that. And thank you again for clarifying!
It probably isn't a good idea, you're almost guaranteed to run into subtle bugs, and that's assuming you can get it installed in the first place. You'd be better off using a virtual machine for windows development. Alternatively, you can write good test suites and use a CI service to check to make sure it works well as a cross platform application. One of the nice things about conda is that it provides many libraries for Linux and Windows, meaning that as long as you ensure those dependencies exist for Windows you're good.
Now it's getting interesting. I already have twine installed with my package manager, and it has setuptools-style entrypoints, just like everything I install with `pip install --user`, but I created a virtualenv, and installed twine, and I got same version you have (the one specified in pip.wheel). I wonder what this is about.
Where is your benchmark? Generators shouldn't really affect speed at all (or if it does, then it's negligible). They do affect memory - but only in the sense that they're not creating a new object. More or less, the same work still must be done regardless if you use a generator or a standard function unless that work is truncated in some manner. Tuples are generally faster reads than Lists, but it's minor. No doubt generators are cool. And coroutines can be exceedingly nice especially in python 3.5.2. 
Oh, don't get me wrong! I'm not saying that I liked Perl 5's object model. I've often referred to it as, "all of the tools you need to build a really great object model." And indeed, Moose is that really great object model, but it's slow as dog meat, and I can just use Perl 6 which is where that object model came from ;-) And since this is a Python group and not a Perl group, I really have to say that the 6model (the Perl 6 metaobject model) has some useful things to mine from other languages. If Python adapted the idea of roles from 6model and had a grammar system like Perl 6 rules, my day-job programming would be so much easier... 
Since you are a math professor at a university I highly recommend seeing if your department has anything. The three I've been at have all had systems that could be used for hosting. It shouldn't cost you anything and you won't have to deal with managing it. 
&gt; An enum is better, but they've been introduced in 3.4 Why not namedtuples though?
You're misusing excepts btw so if your lib is made with those assumptions you're probably doing something wrong. 
With a $5 DO droplet you can host a number of apps (512 RAM is enough for more than a few), buy a domain name and just asign subdomains to your apps. There's a great video by Mitchel Anicas about DNS management in DO, basically you buy a domain name (Namecheap or wathever) and point it to DO root servers, then manage subdomains with DO user interface.
The 3.4 enum package has a backport on pypi
... or the ``enum34`` package on PyPI... https://pypi.python.org/pypi/enum34
&gt; &gt; Any reason this is better than `isinstance` ? Due to the virtual subclass hook, this is what `Iterable` will do anyway (`any("__iter__" in B.__dict__ for B in C.__mro__)`), if I understood it correctly.
There was an excellent talk on this at PyCon: [Felix Crux What You Need to Know About Open Source Licenses PyCon 2016](http://youtu.be/9kGrKBOytYM)
I'm runnung my personal website on heroku. If you verify your account with credit card info, you have 1000dyno hours per month for free, meaning one website on one dyno won't cost you anything. Flask apps go to sleep after inactivity for a while, but there are services that can keep it alibe with pinging periodically - or you can just expect longer load times on average. As others said, you don't need github, but you will need to learn how to use git. The basics are easy and it will save you time. If you want more apps running, you can either use asyncio/threading to run more than just flask without running another dyno. I have my domain dsn pointing at cloudflare (mainly for ssl), that points to heroku and everything is running just fine. For free. And it'a super easy to maintain.
I hope you are just planning to give a warning or something instead of trying to ban all numeric literals used outside simple assignments. Otherwise you end up with stupid stuff like: ONE = 1 counter += ONE or TWO = 2 hypotenuse = math.sqrt(a**TWO + b**TWO) Magic numbers are only a bad thing if they could conceivably change or it isn't obvious why they take the values they do.
The only problem I can see with this is that `dict` instances are also instances of `Iterable` and you'd lose the values in the dict, and just end up with the keys.
Pylint lets you write custom plugins, so you could write one that looks for ints and raise a warning. Here's an example of how to write a pylint plugin: http://nedbatchelder.com/blog/201505/writing_pylint_plugins.html
No problem
according the GPL FAQ the output of GPL code is not covered by the GPL. Unless the output contains embedded GPL code obviously. I don't think that's the case here. The .UI file is strictly data right? Like your GUI layout and jazz? And then YOU create the .PY file from that. You own the copyright on both the UI file and the resultant PY file. Neither is GPLed.
Can you try now? You don't need to download it from Github, 'pip install wia' should do the trick. Version should be 0.1.4 :)
Thanks, folks! I added the intermediate certificates. 
The API is not only not simple, it changes frequently. It's also rife with obscure bugs. It's lovely having a script that sets up a fully fledged isolated development environment from scratch but if anything, docker/compose made that harder for me to implement, not easier. I never had any issues running services locally before except those caused by poor package managers (e.g. brew).
I don't understand, there are Linux and mac versions, why not use those? 
I'm running py installer in Wjne so that I can compile for Windows. 
Can you DM me your email address?
Jep, the ui file is just a file containing xml syntax info about what UI elements are where and grouped how and such. I guess I'll go with GPLv3 too then, even if I have the choice.
1. I would see if you can run it behind a password wall on your department's servers. Someone at the university should be able to help you set that up. Right now, can any student see another student's record? That seems at least like it would violate university policy for privacy. This site really needs to have a login. Since this is university related, it really should be something your department sets up. 2. Can you provide a reason for not wanting to use a social service such as github? If you post the code up on github, people can actively provide help to improve your code and potentially learn from it. As a professor, that seems like something you'd want: promoting learning. 3. See 1. It really depends on how complex the applications are. If you have something similar to what you've already built, you should be able to setup multiple applications. But you will need to provide a way to route to the different applications (http://website.com/url1 for app 1 vs http://website.com/url2 for app2). 4. Every registered domain name must have a host attached to it or when you type in the website address, it won't go to a page. You can register the domain name with something (e.g. https://www.namecheap.com) and then have that point (forward) to the host. There are many, many options for hosting. For someone learning, and if you're okay with its limitations, the free tier for heroku is probably best. 
Why not just code it all, then use something like py2exe?
PythonAnywhere dev here. I won't try to say anything about our competitors because you'd be crazy to trust me on that :-) But: 1. You can definitely carry on using PythonAnywhere for a longer-term site. We've got people running sites with millions of hits a day and it all works fine. 2. Like various other people in this thread I would recommend you have a play with git at some point. Just as a way of "checkpointing" your code so that you can revert it when/if development of a new feature goes wrong, it can be super-valuable. I wrote a tutorial on building a DB-backed website with Flask that introduces the basic bits of git for that purpose -- it takes about an hour or so, and you could create a new throwaway PythonAnywhere account to try it out without disrupting your existing app. Here's the link: &lt;http://blog.pythonanywhere.com/121/&gt; 3. On PythonAnywhere, you can have as many apps as you like, but yes, it does cost more. Basically, there's a fixed $5/month for your first app and associated stuff, then each extra app costs a bit extra. Exactly how much extra depends on how many "workers" each web app has. A worker is a process that is running your website; if you don't have many people using the site, then a couple of workers is fine. If you have lots, then you need more. Each worker costs $1/month, and there's a minimum of two per website. So, a basic account supporting two websites would cost $7/month ($5 basic cost plus $2 for two extra workers). Three websites brings us up to $9/month, and so on. I think Heroku's "dynos" are similar to our workers. 4. With PythonAnywhere you just need to buy the domain name, then set up a "CNAME" to point it at our servers. More info here: https://help.pythonanywhere.com/pages/OwnDomains
That was a really, *really* informative Talk. It made some concepts of licensing clear to me, that I even wasn't aware they existed. Much recommended!
Which edition? If it's 1.5 or 1.6, then yeah, it's outdated. On the other hand, the 1.8 edition should still be good about 95% of the time.
Well, even packages that I install today with pip 8.1.2 get the setuptools entry_points. I uninstalled my distribution's pip packages and bootstrapped it with easy_install instead, but I'm still getting setuptools entry_points. The fact that it does the "correct" version of entry_points scripts in a venvr leads me to believe that it has something to do with the site python configuration. I'll try building a fresh Arch system later in a chroot to see if that changes anything. I have confirmed that new packages installed with pip in Ubuntu 16.04 do have the new entry_points. Thanks for bringing this to my attention! [edit] after further investigation, I've found that some packages do install on Arch with the new entry_points. Many popular packages, in fact. However, many small-time packages still use the old script (including mine!) I have to see what the packagers are doing differently than me! [edit] The problem is using setuptools to generate the distribution, which is what I've been doing. Have to use `pip wheel` instead. So, yeah, this patch is deprecated already :D :( At least I learned something. Several somethings, in fact. Still don't understand why it would behave differently on different distros when using sdist.
And then someone comes in if Datetime.now() == 'April 1st': TWO = 1 ONE = 2
You can't. And how will you you deal with the fact that on the second visit you have key to the chest in the cottage? That's why all of these types of games are coded using classes. The methods of the classes include stuff like move(direction, steps) and get_item(game_obj) which interact with a map structure and inventory system (likely also classes) that keeps track of where all the game objects are. Without the data persistence provided by having multiple instances of a class object that keeps track of it's own data you will soon have big plate of spaghetti code that's impossible to de-bug. IMHO, a text adventure is the worst possible choice for a noob. You spend all your time writing cute story lines and developing characters and never learn how to program. Save the idea until you learn some OOP, then it's a fun choice.
They would serve OP's purpose equally well though, if not better (someone please confirm/deny though, I'm not sure whichever's the more memory-efficient)
This is on the money. If you do need some guidance through implementing this structure, Zed Shaw's book *Learn Python the Hard Way* has several chapters at the end of the book (Exercises 45-49) that deal directly with using classes to code a Zork-like game.
Yo what up. Thanks to you and the PA team for maintaining a sick platform.
I was hoping for this as well, glad I'm not the only one
Same
"--simple-prompt" only works with the new version tho, so if you try to fire up an earlier one (say from a virtualenv in which you can't update it), this won't work. 
Yeah, you'd need an adapter for SQLAlchemy to do that. There is one here https://github.com/CanopyTax/asyncpgsa.
That's true. I meant this is specifically a fix if you're using IPython 5. Don't do it if you're using a previous version.
Others are right when they say Objects and Classes would make this easier, but it's still definitely doable without them and I think it's still a pretty good exercise for a learner. The trick here is that you need to have some variables holding the current state of the adventure, and then in your loop you examine this state, figure out what to ask the player, wait for a response, and then change the state accordingly. A (very) simple example: map = { 'cottage': {'west': 'forest', 'north': 'cave'}, 'forest': {'east': 'cottage'}, 'cave': {'south': 'cottage'}, } def show_location_description(name): print "You are at the " + name print "You can go '" + "' or '".join(map[name]) + "'" def go_direction(location, direction): if direction not in map[location]: print "You can't go that way" return location else: return map[location][direction] def adventure(): location = "cottage" while True: show_location_description(location) direction = raw_input('Enter direction: ') location = go_direction(location, direction) adventure() every iteration of the loop, i'm just changing the value of 1 variable. the "code" for each iteration of the loop is the same each time, just with different inputs.
Really? Please go onto the [Python Bug Tracker](http://bugs.python.org/) reporting your complaints. Failing that, what do you not understand about the module/general index that is available at the top right hand corner of the [Python3 docs](https://docs.python.org/3/)?
Unless I'm blind, the psycopg2 results are not in the benchmark. Edit: Okay, I guess aiopg is considered psycopg2. 
Yes, aiopg is a very thin wrapper on top of psycopg2. In our benchmarks, the overhead of aiopg is only a few (1-3) percents.
For all us that don't read the fine print, I think you should mention that in the legend of the graph. 
What is this drivel about 'virtualenv', whatever the hell it may be? I've been using Python for over 16 years and have never once needed to use this 'thing', for lack of a better term. Why do people need to complicate things in a public forum, when more often than not, the simplest thing works? KISS?
Thanks for the reply. I'm not storing the student's grades on the site. The students have to know their individual scores (which they should once they get their homeworks, quizzes and tests back). What they usually do is show up to my office and ask what grade they have in the class at the moment. I then have to calculate it in front of them since they all have different weightages. I felt with this app they can just input their scores and it will spit out their percentages, so I don't think they need to have a login for that. Correct me if I'm wrong. It's like giving the input 15, 16, 20, 18 and getting the result 17.25 as an average. 2. I'm not against github. I just don't have the time at the moment to learning the ins and outs of it since I don't work with big lengthy code. I just want to get this app setup without doing this "extra" stuff. I'll probably look into github once I have more time. 3. Yes, that is what my plan is. When I create another app I will redirect it to a subdomain. I was just wondering if I needed to pay extra for that app or just a basic plan with Pythonanywhere, DO or Heroku would do?
Thanks for the reply. I just don't want to go through the university, since if I have any questions at any point, I don't want to always have to run to them. I would rather have everything under my control, since I also plan to write some more apps that have nothing to do with university work.
Are the various assessment weights not available to students? Seems very lazy to not work it out themselves.. should be beyond trivial for math majors
Nonsense. pip always installs to the site-packages directory, so 'import packagename' will always work. Then it is as difficult as help(packagename) or similar. How much does Python cost you? Is R the same price, cheaper, or more expensive? Get iPython and you're cruising. What do you want, blood on it?
Oh they know all the weights, but most of them are lazy and they probably don't even know their own GPA. Also, they are not all math majors to begin with. 
What is wrong with the module/index part on the top right hand corner of the page that can find you anything? As for stackoverflow, anybody who is dumb enough to expect decent answers there really does need their head examined, unless you *KNOW* who is replying. Consider Alex Martelli or Bryan Oakley as experts, there are others, but some of the crap on SO is so pathetic as to be, quite literally, unbelievable.
Great work guys with this and uvloop. And thank you for giving developers more compelling reasons to embrace Python 3.5! 
I don't understand your aggression in this post. 
Thanks for the reply. I really like how Pythonanywhere is so simple to setup. I'll look into the things that you mentioned. You mentioned about workers, what exactly is that? You say it's a process that is running your website. Is that the app that you are talking about? What would couple of "workers" do for a site. Would it mean I can run 2 apps at the same time at 2 different addresses? I'm kinda confused with that term. 
This is astounding work. The results are absolutely amazing, both with this and with uvloop.
I'd love to use this in Django.
Link is broken / 404ing
Wait, so database results from asyncpg can't be accessed by column name? That's a pretty big feature to gloss over!
Results in aiopg/psycopg2 cannot be accessed by column name by default. Results in asyncpg are always accessible by column name (that's the default).
Foreword, I have a pretty base understanding of asyncio and I've not done anything with it outside of tutorials and toy examples. You can't. This is designed for asyncio/uvloop, whereas Django isn't. You could call this from an executor, but you'd lose almost the benefits because you'd just block until the database stuff finished - something like `loop.run_until_complete` Plus, I doubt there'd be a pleasant way to interop it with the Django ORM. 
Not seeing the same results on Linux. They run at about the same speed here (oldish i7-870, Ubuntu 16.04), with 2.7 having a (very) slight edge. Also, interestingly, changing the class to a "new-styled" class for 2.7, by subclassing from object, sped it up by another 7% or so. Looking a the sys times, it looks like either the Mac version of 3.5 has some special optimisations, or the MacOS kernel has a faster lock than Linux. I raised the count by a factor of 10 to make it less noisy: $ time python2 atomic_counter.py real 0m23.661s user 0m21.420s sys 0m19.156s $ time python3 atomic_counter.py real 0m24.597s user 0m22.180s sys 0m19.256s $ time python2 atomic_counter_newstyle.py real 0m22.082s user 0m19.988s sys 0m18.060s 
&gt; Plus, I doubt there'd be a pleasant way to interop it with the Django ORM. You could write a new backend for it, seems straight forward. Dunno about *pleasant* but certainly *documented*.
I'm not deploying a missile defense system. Sometimes I just forget how to dump json to a file, so stackoverflow is great for that. Plus if you read the replies to the answers, usually if the answer is garbage, people quickly point that out. Edit: the problem with the index/module portion you mentioned, at least for me is that I didn't know it existed. I'll jump to different python official docs through a Google search on a different tab
Wouldn't the whole Django stack need to be async? Otherwise you'd have to wrap every db request in its own ioloop
Supporting unicode in my Python 2 library has been a never ending source of pain, as dropping everything to bytes doesn't work because you can mangle a rune (which usually provokes an error from MySQL) with a string length limit. Upgrading to Unicode everywhere on python 2 was satan incarnate.
Good question. I don't know. Can Django be used with async?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Django's ORM is tightly ingrained to the rest of the framework, I doubt it'll ever be fully separated even if the folks behind it wanted to do that. If you're wanting an ORM, check out SQLAlchemy which I think it's heads and shoulders above Django's ORM. As for why you wouldn't want to do this, is because once you start doing Asyncio, it's all in with no half measures if you want the benefits. And speaking of SQLA, I'm going to share [this article Mike Bayer wrote early last year](http://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/) which talks about asyncio and databases. 
Very good point here. Most Python developers still don't understand asyncio, event-loop yet. We need an asyncio-compatible web framework. No Django, Flask, Bottle ... Tornado uses a different event-loop. Not sure if there is any easy way to use asyncio as a drop-in replacement for its own event loop.
To the author, please add more documentation and examples.. 
We'd really appreciate it if you could create an issue on github.com/magicstack/asyncpg with a specific request on what you want to be better documented and what kind of examples would help
If he thinks django settings is too complicated to set up I don't think he'd like SQLAlchemy :P
It's actually correct but at least the official Reddit iOS client fucks it up and thinks the period is a part of the url :( it's a problem super often!
`pip` works very well for pure python packages or where the builds are relatively simple. Packages that have complex builds (for example, builds that are platform dependent and have several intertwined steps) can be a hassle on non-standard platforms (or Windows).
pip won't get any non-python dependencies for you. For instance, BEFORE you can install something like scipy you need a fortran compiler (which you have to go find yourself), and you need various other non-python libraries which pip knows nothing about (e.g. a BLAS library), etc. This all works perfectly in a package-manager ecosystem (e.g. Brew on OSX, or any linux package manager). However, it quickly devolves into a complete a shitshow on Windows where you have to do everything by hand to libraries which were not primarily designed with Windows / Visual Studio in mind (e.g. great you got a source copy of library x, but it uses GNU make, and your version of python is compiled with visual studio, not mingw, so now you have to muck around with the build scripts for the next half hour)
Guys, this is also very interesting: https://tkf.github.io/emacs-ipython-notebook/ . It actually allows you to have plots visualized in emacs.
Surprisingly one of the best talks I saw this year. 
Wouldn't returning (named) tuples be faster? Creating 1M dictionaries isn't free.
I'd like to know this as well. When looking in wireshark to the number of packets send by psycopg2 to postgres, I've always wondered why so many back and forth communication was needed for every single query. Would the binary protocol reduce this ? That would easily explain performance jump.
&gt; The language is backward compatible, with only additions and no deprecation. This means, no code updates required in the code. duh. Just download the latest binaries for the language and recompile your project, which, you know is faster than having to do all those API changes which Django makes to all the releases. &gt; &gt; Yeah Plug If you can understand this then fine, else downvote as usual.
because I often don't need to save all the output of all the commands I run. The notebook is great for a scripted, narrative code explanation, with saved output and sequentially-run code examples. A REPL is great for interactive exploration, with frequent switches between text editor and console. I typically start my work in a notebook, but move it to python modules once it solidifies. The notebook is then still a great tool for testing and documentation, but the main development happens in a REPL and python files.
Please have a look at this: https://github.com/millejoh/emacs-ipython-notebook
Check here. http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/ It is easy and usefull. 
Maybe this would be better at r/learnpython. Try NLTK; It would be helpful for stopwords removal and tokenizing.
&gt; backwards compatible wrt syntax highlighting that’s of no value at all, quite the opposite: the expression parts being highlighted as expressions is the right thing, them being highlighted as part of a string is just wrong and misleading. &gt; I can see how difficult it would be to create proper highlighting on the inner expressions yup. there can be infinite levels but they have to be escaped for no user benefit at all obviously it’s not good to have many levels, but if the obvious solution allows for it, why not? &gt; I think using \' in {} expressions is a bad idea anyway as said: it’s crucial for understanding that highlighting gets updated to correctly reflect the code nature of the embedded expressions. with that in place, it would be trivial to see which parts are strings and which aren’t --- here’s my post to [python-ideas](https://groups.google.com/forum/#!topic/python-ideas/V1U6DGL5J1s)
This is nice! got few problems while setting it up on OSX. * Got: Exception Value: unknown locale: UTF-8. Fixed it by disabling "set locale variables" environment setting of iTerm (preferences/Profile/Terminal) * Got: RuntimeError: Python is not installed as a framework. The GUI frameworks that matplotlib uses for interactive figures have some issues with virtual environments. Fixed it by adding `backend: TkAgg` in `~/.matplotlib/matplotlibrc` Just in case if anyone get these error/exception. This script is trying to download video info of 6553 videos! This would take a lot of time. And I don't think these are much right? Is there a way to optimize the requests ?
Yes, this is the version that is on MELPA and MELPA stable.
I know this is a Python sub, but since you're open to doing it in Go that's what I would do. Go is perfect for this kind of thing. EDIT: Forgot to mention anything useful. For the REST API portion, I'd probably go with either Gorilla/mux or httprouter. For the task queue I'd go with Machinery. I can give links later as I'm on mobile. 
I'll admit at least some of it is familiarity. whenever I've spent time with sqlalchemy's ORM, 1) it doesn't seem to give me anything I need (i.e. things for my use cases that would be valuable, I know it is more flexible and powerful in general), and 2) the api just seems clunkier, which is, obviously subjective. sqlalchemy's philosophy is different, it's more of an interface to the db whereas django orm is more totalistic. I prefer the latter.
None. If you dont know what you are doing or what you need then you use anaconda/enthought. Doing this will result in a ton of shit being installed that you will never use nor need. I will never understand why so many people are so clueless that they need something like anaconda/enthought. EDIT: I see the clueless have come out to defend the rubbish that is enthought/anaconda. Two companies making a shit ton of money packaging up *free software* for the clueless.
Ridiculous. Of course I know of sqlalchemy and have spent time working in it. This is the complicated part I was referring to: https://www.stavros.io/posts/standalone-django-scripts-definitive-guide/. It's more annoying than difficult, but always needing to set global settings this way is a pain. It's not a common design pattern.
If you stripped django down so all it could do was custom management commands that rely on the orm (essentially), you don't think that would eliminate overhead?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I looked at SQLAlchemy a while back and the boiler plate to get anything done was significant and the docs didn't give much in the way of best practices for why to do with that session thingie imo. 
It would eliminate some files on disk that you might not need. "Overhead" is a specific word that means things that go on top of something and add time or cost to it. A few files on disk is not really significant overhead. You might as well complain about all those libs that ship with a readme included. Is that overhead? I don't think so. 
Question for Emacs users: Why would you ever use the "inferior shell" instead of the built-in terminal emulator (M-x term)? IPython should run fine (or at least better) in the latter one.
What is your question 
/r/ShittyProgramming is that way --&gt;
It won't be 2x as fast anymore since you lose the advantage of being able to work async.
On the off chance you're serious: Do you know how *fucking huge* 2^12345678912345 is? The number of particles in the universe is less than 10^100, how the fuck do you expect your puny little solid state computing device to calculate 2^12345678912345?
Is this a bug? Waiting forever just to run a trivial program is not what a user expects..
In my benchmarking with psycopg2 NamedTupleCursor is about 98% of the default tuple cursor while DictCursor is about 70%
&gt; The user API is all that matters. Everything else is secondary. &gt; Once your software is released, improve it! Add new features, &gt; better security, optimal performance, and rigidity. But never &gt; compromise the API. From the author of requests: http://www.kennethreitz.org/essays/how-i-develop-things-and-why udatetime targets performance, and will satisfy a niche of users in the Python community. It's good. But don't try to pretend it's what matters most, because in Python it doesn't. In Python readability, ease of use, debug, etc., anything that is a consequence of the quality of your API, is what makes your programming session a good one. E.G: arrow has a method to let you had time in a natural way, such as you add a month to jan, 31th and you get fev, 28h. It has a method to turn time into "x minutes ago", and translated in many languages. It provides the infamous missing to_timestamp. Those are the stuff that will save developper time instead of machine time. One hour of my time is twice the price of a decent server for a month, so it matters.
Django was my first experience with an ORM (back on 1.1) and it was incredibly easy to pick up out of the box. SQLAlchemy in comparison is pretty unfriendly. It suffers from the documentation problem mentioned in a post a few days ago where you search for what you want, end up on a page which *might* tell you the answer, but it's buried in 15 pages of text. I know what I want to do in SQL, but can't figure out how to tell SQLAlchemy what that is.
Thanks for that link. I hadn't seen it and it was a really good read.
&gt; run a trivial program you start calculating 2 ** 12345678912345 by hand and then get back to us.
This is why I use my own module instead of the above: Clean API and forced awareness, without the speed penalty of the alternatives: https://github.com/David-OConnor/saturn udatetime looks cool!
I read it every so often, and then inevitably start reading Glyph's Unyielding post as well but stop half way through because it's a long ass article (very good though). 
Thanks!
psycopg2 and asyncpg use the same protocol. The difference is that psycopg elects to use *text* representation of data, and parsing text is much more expensive than working with fixed-length binary data. Working with binary also means that you don't need to copy data as much. In many cases in asyncpg Python objects are created directly from bytes in the receive buffer.
Create a simple AI with the persona of an old man and have it 'engage brands'. Some inspiration: http://gizmodo.com/todays-hero-made-an-ai-that-annoys-telemarketers-for-as-1756344562 Or, simpler: make a bot that generates an anagram from what you tweet at it. Or, in between: make a bot that tweets back at people in their own style using a Markov chain.
The client/frontend doesn't need to make periodic requests, you can use websockets (and should, imho, since that's what they've been designed for). You might also want to look at Autobahn (http://autobahn.ws/), i have not used it myself, but i heard it's pretty good at the kind of things you're trying to do.
Ah, thanks. I checked on the homepage, but couldn't find it... Deleting it now ... :)
Here are latest [docs](http://www.vtk.org/doc/nightly/html/) for VTK 7.1, released sometime in the earlier part of 2016. Building from source can certainly be painful, especially on windows.
udatetime looks good but it seriously needs some code cleanup. Reading through the source right now and it needs some definite cleanup before anyone can start to use it seriously.
A bot that finds feminist twitter feeds, and tries to convince them that men are the superior sex. 
It would depend at what level of access to the code that is constructing xyz thing i.e. video, image, zip, txt and/or what platform it is on. I would check StackOverFlow or the python forums and see if the developer(s) know.
I decided to use GoFundMe rather than Kickstarter. I will still be sending out prerelease versions to anyone who donates, before the public release of the code. I also intend on using .cy extension if you want to use the optional preprocessor (this is only needed if you want to embed inline C code or use features such as switch / case which will be converted into regular Python code). The .cy means I add syntax that would not be valid in regular Python.
Using python2 or python3 is for a linux machine (debian or Ubuntu)
Your question is confusing. An image is normally already stored in a binary format. What exactly is your end goal?
In Python you can open a file for reading in binary mode by adding the "b" to the mode string in the `open()` call. For example: with file_handle as open("my_file.jpg", "rb"): raw_bytes = file_handle.read() You didn't say which version of Python you're using - the data types will be a bit different between Python 2 and 3 because the latter explicitly separates byte strings from text strings. [Here's the docs for the open() call in Python 2.7.6.](https://docs.python.org/release/2.7.6/library/functions.html#open) If you want to twiddle the bits and then write out a new file, just open the new file in "wb" (write binary) mode and `write()` the new bytes to it. 
&gt; This content is locked! &gt; Please support us, use one of the buttons below to unlock the content. :(
Thanks i appreciate, how you can see i am not a native English ;) thats is my difficult explanation :( ,Seriously Tanks.
Looking at your example it's obvious what it does. But the lack of basic examples like this in the docs is what makes SQLAlchemy difficult to pick up (especially when I'm only dipping into it now and then). The Django docs in comparison have dumbed down examples for everything, which really lowers the barrier to getting something done. I just need to set aside a weekend and bang my head against the wall till it goes in.
Question on that. If all that is in my say "connect.py" file is the following and i execute I get an error on Line 8 which is effectively the con = cx... line Assuming the ' ' are not actually there around db and I type in the actual db im calling, and the user and pwd are the variables taken in from the raw_input, what is wrong with the ouput? //------------------------------- user = raw_input("Username:") pwd = raw_input("Password") import cx_Oracle con = cx_Oracle.connect(user/pwd@'db'/orcl') print con.version con.close() //-------------------------------
Another component of the benefit he doesn't mention though is that most of what he describes is consistent across osx, windows and linux. That is why I describe conda not as a replacement for pip, but as a cross platform package manager, similar to apt-get, combined with virtual environment management.
Yes binary ordination, i want to do a loop what edit files but using binary.
You really shouldn't be downvoted for this at all. Its perfectly reasonable thing to fuzz. For those who don't get it. Yes 2**123456789... is an absurdly large value and is not realistically "computable." The problem is that the interpreter is trying to compute it without throwing an error. We don't want that, we want the interpreter to quickly ascertain that this isn't going to work and point out the exact line with the problem. Since he has explicitly asked for compilation we would expect that this might happen on code that has not been tested. It is not unreasonable to expect some kind of basic syntax errors or typos to be present in the file. For instance maybe the author meant to type `2*123456789` or perhaps it was supposed to be `2**12.3456789` both of which are easily computed values. We expect py_compile to parse and compile the program and spit out either a syntax error, or a valid compiled script. We don't expect the compiler to go OOM or burn 100% CPU for centuries without ever telling us what the problematic line is. This is a perfectly reasonable thing to fuzz test the interpreter, and it does qualify as a bug.
Hi. I don't know how much time in total it took to get the info but it was roughly around 30 requests per minute. But in the end I got some cool insights :D http://imgur.com/a/k04A1 This is really nice. Plus, now I have logs of my views. Maybe, I'll try to keep it updated from now on. Its fascinating to think that the actual time spent would be more than the calculated results; considering that the person was an active user of YouTube even before 2009-2010 (the pre google-account-linked-youtube era) I'll also try to look into the code some time :)
Great article. 
I work in retail. It will be interesting to see how many days shoppers shop with the store before moving to competition.
While the explanation is easy to ascertain... it is a bug. A compilers job is to parse the code and compile, ultimately spitting out an executable or an error message saying that a particular line is ill formed. For the compiler to get stuck in a long computation is a problem because we often compile code we expect to have errors, we just don't know where and want the compiler to give us a hint. Maybe the source should have been `2*12345...` or 2**12.3456...` both of which are perfectly computable. Since this probably amounts to solving the halting problem in general, the best solution is probably too put some kind of async timer on any evaluation of code and abort it when it takes longer than X seconds to compute the value. When it does abort warn on the problematic line and spit out the instructions to execute instead of folding the constant. 
Arrow will also parse invalid input without complaint and return a valid datetime so you're fucked because you realize two months later that there's crap in your DB but have no idea how it got there. It also doesn't differentiate between date and datetime. That alone makes it just a big disaster. 
I had an idea for a SubredditSimulator bot. A bot for /r/totallynotrobots would be a bots trying to be human posting about humans trying to be bots. Could get interesting edit: It has already been done.. so yay
Miniconda has like 5-6 packages. Whatever is required for python to run. 
I am the author of Delorean. Comparing these libraries for performance is kind of moot; unless you are doing data analysis where parsing datetimes is going to be your main bottleneck (not going to happen), I echo the same sentiments as @desmoulinmichel this library was built for ease of use and dependability. Performance pull requests are welcome, oh and lastly 'lol' 
Give 'delorean' a shot. I am the author fyi.
So essentially this is just overlaying pre-rendered pictures?
You can continue to install additional libraries into Anaconda. It doesn't exclusively use conda packages. pip, etc. all work just fine.
Try installing Numba(http://numba.pydata.org/) and you will know how much of a pain it is to get the dependencies "right". In such a sense, the so-called "Anaconda" might be a good option. Having said that, if you need more control over the individual libraries, in the way how they are installed, installing libraries using package managers like Synaptic or even building it from source is really good learning experience and eventually you'll be a "good software engineer"
Just call it Fauxkemon - you know you want to!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I wonder how long Verizon will keep up that sponsorship now that Yahoo is no more..
Unlucky... 
Doesn't matter: http://www.recode.net/2016/7/7/12116296/marissa-mayer-deal-mozilla-yahoo-payment
See if [this](http://stackoverflow.com/questions/25885467/cx-oracle-pip-install-fails-oci-h-no-such-file-or-directory) helps edit: I just saw where you said you already tried with the SDK version so this probably won't help.
I'm wondering if i did something wrong in that. I don't know much about "PATH" but I'm looking at this https://help.ubuntu.com/community/Oracle%20Instant%20Client and http://stackoverflow.com/questions/25885467/cx-oracle-pip-install-fails-oci-h-no-such-file-or-directory and wondering if i need to adjust something somewhere.
It's not a sponsorship. The other commenters are correct that Yahoo currently pays them a lot, but Yahoo's search business is pretty much gone and they're being bought by Verizon, so that deal almost certainly won't be renewed (when it ends in a few years). Afterwards it's a big question mark, but for now Mozilla is actually raking it in.
I clicked on the first topic, and they [mangled](http://i.imgur.com/SVl5Y2B.png) the indentation. Not that that would be important in a Python tutorial . . .
Depends on what you want. Science computation probably not. Webserver is already faster.
Where? What kind of position? Dev? QA? Dev in test? Remember that Python might be an asset, doesn't have to be the core of job - like data analyst, CI person, etc.
That's a good answer. But my purposes are statistics and scientific simulation.
Yes! I use Anaconda because compiling the C packages was impossible on my corporate laptop.
Wow hadn't heard that before.. Thanks for sharing.
Well I would just "use" C++ if need be but the need hasn't arisen yet. 
Awesome! Hope we'll see a fully-working STM soon :)
Python on mac is a shithouse. The hoops you have to jump through to get wx working on Python 3 on a mac is ridiculous.
Next step: Reproduce worldofrandom's youtube page open source.
Pythonista 3. It's worth it.
I just use Pypi. I find conda to be annoying to use, especially since I don't use any of the data libraries that come with conda. I install python 3.5 manually on windows.
Hooray for funding!
Yes, it will increase the speed dramatically. 
I would really love this. 
While this is cool for Pypy, what does it have to do with Mozilla's mission?
Look at the "Intel Distribution for Python Support and Documentation". It's basically a Python interpreter that is accelerated by Intel MKL/TBB/etc for several Python libraries such as numpy, scipy, numba. 
Hard to believe but it is actually a project that I am doing for myself T_T
Pythonista 3 is your only option. And $10 is nothing. The only downside is limited access to core APIs on the phone itself: one cannot access phone call data, text messaging, and so on programatically in order to automate things or extend functionality. That would be boss af, but that's Apple's thing in locking that stuff down. 
Yeah but finding statistics libraries for use in C++ that work easily right out of the box is a whole issue unto itself. For Python/Julia/R it's a piece of cake. 
I'll be sure to give it a look. 
I knew that but are there any such libraries for C++? Now that's a tough question. 
Mozilla have a lot of projects thats rely on Python. Probably using Pypy can save money for them for this amount or more in future. I hope there is some business decision not only charity. 
I tried Julia for a while and its dictionaries were far slower than standard Python, not to mention the half-minute imports. I guess Julia works if your only data structures are arrays. 
You are part of the open source community, silly :)
&gt; the benefits of the conda package manager No. Pip is a package manager, anaconda/enthought are rubbish installers for the clueless. If you are in IT you get a pass because you need to install *everything* since your userbase is highly varied.
Anaconda/Enthought is far more complex than the pip -&gt; "install what you need" route. &gt; Whatever is required for python to run. No. Python is all that is need "for python to run." Why cant i find documentation for these "5-6 packages?" All i can find is this: sales@continuum.io. When i first started with python about 5 years ago (after 20 years of matlab/C/C++), i was at a major academic institution, i tried Enthought. It sucked and did not do what i wanted, it was clearly broken. Then i tried anaconda. It was worse than Enthought, then i saw that they charged for this "service." Both of them. So i deleted both and did a piece-meal install of what i knew i wanted. An hour later i was up and running after wasting days with that Enthought/Anaconda rubbish. I never looked back.
100% agreed. We've had the exact same problems in our codebase with all the different datetime libs.
ptpython is great on the terminal. For me, though, nothing tops [DreamPie](http://www.dreampie.org/) as my general Python shell.
Conda is open source and free as is the basic Anaconda distribution that gets you everything except for a few specialized packages. As far as the basic packages in Miniconda they are currently: conda 4.1.11 py27_0 conda-env 2.5.2 py27_0 openssl 1.0.2h 1 pip 8.1.2 py27_0 pycosat 0.6.1 py27_1 pycrypto 2.6.1 py27_4 python 2.7.12 1 pyyaml 3.11 py27_4 readline 6.2 2 requests 2.10.0 py27_0 ruamel_yaml 0.11.14 py27_0 setuptools 23.0.0 py27_0 sqlite 3.13.0 0 tk 8.5.18 0 wheel 0.29.0 py27_0 yaml 0.1.6 0 zlib 1.2.8 3 You can find documentation for all of them online. The list of packages is in the .sh installer. I would agree that the list of packages in Miniconda could be more prominently displayed.
I don't follow. &gt;&gt;&gt; python is too slow for numerics &gt;&gt; there's a library for python that will give you super fast performance &gt; well I could just use c++ There's no need to complain about python's speed for numerics, because numpy, numba and others solve that. If you want to use c++, go for it, but you sound like you're complaining though I can't tell what about.
&gt; conda is a package manager hat Nope. Its an installer. I recommend you educate yourself before being caught in the "package installer" trap. Its probably too late for you to take this advice, but anaconda/continuum.io is a *business.* Their purpose is to make money. Anaconda relies on some really shitty practices to support their really shitty product. When their shit comes back to bite you, you can look at this post and think, "Damn, homer was right." It will bite you, continuum is a company that is packaging the pro-bono work of many and charging for it. In my book that is "not cool" and their product sucks, so that is two strikes against them. Then you install their rubbish product and discover that your install takes hours and you have a ton of shit you will never use on your system. Yep, i see why you are defending a *for-profit company* like continuum.io. Way to go...good luck with their product.
Looks interesting. Can you compare it to mkdocs, showing pros and cons? I'm using mkdocs for personal wiki and project documentation and ark might be a lightweight, simpler alternative.
Nice! I wrote something like that too, but more so for json input. It recursively loads the json data into the same type of thing. I enjoy it haha :D https://github.com/uw-cmg/StructOpt_modular/blob/master/structopt/tools/dictionaryobject.py
Apologies, I think you misunderstand, what I meant was if I needed to prioritize performance C++ would be the way to go. Before what I was asking was how Python compares to Julia for mathematical computing. 
&gt;Python's scientific libraries are already written in C This is all I needed to know. If that's the case then they are probably already plenty fast. 
&gt; have a ipad &gt; &gt; won't drop 10 bucks on a app you're the reason why mobile apps are f2p garbage 
That is a good one! I may never type another bracket in my life!
 json.loads(string, object_hook=custom_dictionary_class) no need to recurse
That's an interesting read but it still shows python being ever so slightly slower than C, not that that amount would matter though. But you make a good point in terms of programmer productivity and execution speed combined Python wins hands down. 
 class blah(dict): __setattr__ = dict.__setitem__ __getattr__ = dict.__getitem__ __delattr__ = dict.__delitem__ def __dir__(self): return list(self.keys()) nice stuff, thanks
Really? Do you have benchmarks for that or anything? Didn't realize that.
No I meant if I were to just work in C++ instead of python for the speed boost, what statistical library is there that I could use that would require minimal effort to learn? Probably none. 
Ah right.. Probably none
You could split it into two pieces of ham and spam with pandas, then select the first 1000 rows.
Why do you need a dict? You can do this with any class derived from object without any code.
The funny part I always see about these posts is they talk about how the PyPy PROJECT is getting money, how about they donate some of that money to the contributors who actually work on the software? This whole idea of organizations being so high and mighty because they donate to projects while ignoring everyone who works on the project is pathetic. Edit: I have been informed that PyPy does give money to their developers typically in cases like this so I stand corrected.
http://doc.pypy.org/en/latest/cpython_differences.html &gt; The garbage collectors used or implemented by PyPy are not based on reference counting, so the objects are not freed instantly when they are no longer reachable. The most obvious effect of this is that files are not promptly closed when they go out of scope. For files that are opened for writing, data can be left sitting in their output buffers for a while, making the on-disk file appear empty or truncated. Moreover, you might reach your OS’s limit on the number of concurrently opened files. &gt;Fixing this is essentially impossible without forcing a reference-counting approach to garbage collection. The effect that you get in CPython has clearly been described as a side-effect of the implementation and not a language design decision: programs relying on this are basically bogus. It would anyway be insane to try to enforce CPython’s behavior in a language spec, given that it has no chance to be adopted by Jython or IronPython (or any other port of Python to Java or .NET). The problem is that none of the traditional heap inspection tools (muppy/heapy/etc.) compile on PyPy. So while it's fine if you write a new app, with awareness of these differences, trying to run any medium to large application on PyPy is a nightmare, because most of them were written assuming Cpython, and without heap inspection tools it'll be impossible to find all the leaks and close them. The fact that PyPy markets itself as ["almost" a drop-in replacement for Python ](http://doc.pypy.org/en/latest/faq.html#is-pypy-a-drop-in-replacement-for-cpython) doesn't help. (Most people don't find out about the GC differences until after they've moved everything over and start having issues) 
that's exactly my thought. Js only gets special treatment because Netscape decided it to be the language of browsers..
And look at Netscape now. They are a failed business. This is why companies that can't even keep themselves afloat shouldn't be allowed to maintain important technology standards and other intellectual property.
You know the same thing happens in every industry that's why the whole limited liability thing protects these guys from getting what's coming to them. Especially in the finanacial industry where I once interned. 
With the money from those donations, PyPy went from no Python 3 support whatsoever to a fully working Python 3.2 version, that was a huge amount of work, I wouldn't call it little progress...
3 things that python needs to win me over: proper jit, true async, web stack
I must have missed it in this post or in the associated links. Where does it say that the money will be used to pay developers? Or is this something stipulated by the PyPy project? Edit: I should note that I've seen where PyPy pays for specific features to be implemented, but I've never seen them just go 'Boy Jim you sure have helped us with a lot of work, here is 10k from the money we received!'. Edit: I have been informed that PyPy does give money to their developers typically in cases like this so I stand corrected.
because 3.2 isn't a supported version of Python anymore, and virtually no one uses it
It is actually the other way around. I personally use it to make traversing JSON objects more readable and sometimes create objects I intend to convert to JSON.
Nice
I'd prefer numpy on PyPy3 support :/
Either you're conflating `__getattr__` with `__getitem__` or I don't know what you mean -- and the latter seems the likelier.
Technically it's not a walk in the park, and most PyPy commercial users are still on 2.x, so there was no incentive to focus on 3.x. A crowdfunding campaign was enough to get a 3.2/3.3 beta but then interest and money dried up again. Hopefully some of this Mozilla fund will be used to move on to 3.4.2+, which was the last major bump in semantics, and after that it should be easier to keep it current.
Seems like you're using a simple XOR operation with the key. This is weak to [same attacks the Vigenere cipher is weak to](https://en.wikipedia.org/wiki/Vigen%C3%A8re_cipher#Cryptanalysis).
I mean that's true but look at the keys generated, I did some brute force testing when I knew the string output from the other side and it took me around 80,000+ attempts and I still wasn't able to brute force the key data.
It's possible to recover the key if you encrypt a sufficient amount of data with it. Read the Wikipedia page I linked, it explains the basic approach rather well.
Well.. "Known" is a bit vague. Maybe they should be dates but someone screws up the input. The only way you can truly know is if you yourself produced the strings and in that scenario you could probably just not format and parse and use the dates you already have anyway. 
&gt; erested in doing? If you don't want to do any of that, but would like to help on the GUI, that'd be great too :) Hi I looked at pyNastran. Is it correct that I need Nastran for the FEM calculations and that you use pyNastran to process the results? Or is it also meant to create models?
Thanks for trying :)
ptpython is brilliant if it works well. For some reason I can't get it to highlight syntax well in Ubuntu 14.04 (all good on 16.04). It does this weird thing where it assumes my indentation is 3 spaces rather than 4 so all colouring is off by 1 character for indent level 1, 2 characters for indent level 2 etc. It's pretty sweet otherwise!
sampled_df = df.groupby('class').apply(lambda x: x.sample(1000))
Of course. This is just a simple notation for a dictionary. You can add items to it and do anything else you'd do for a dictionary. Try adding a property to a named tuple after it's created!
Uh, what does this provide that the simple hacks posted in this thread don't, aside from insane project directory structure and C extensions to compile? `dict` is already implemented in C.
I hadn't used MkDocs before but it looks really nice. I love the auto-refreshing preview server - that's a feature I want to implement in Ark at some point. At a glance I'd say that Ark is more flexible and general purpose, while MkDocs has nicer off-the-shelf themes and a tighter focus on producing documentation.
I honestly prefer Exceptions myself, and my APIs use them. Other than that, this was a very interesting and good article. 
There are some claims that the Python numbers on Julia's benchmark claims were unoptimized. This guy was able to make Python faster in a lot of cases: https://www.ibm.com/developerworks/community/blogs/jfp/entry/Python_Meets_Julia_Micro_Performance?lang=en That being said, I've never come across a situation where the speed was that important, but I could see it for things like high frequency trading. 
Hi, I am wondering if your library could help me out with something: * read data from multiple long running HTTP connections (in parallel) * parse the data from each chunk * each chunk contains XML data. The chunked XML can contain more than one XML complete tag in one go. I state this because this requires finding the start and end of tags in a single chunk. * use the XML data and pass that onto celery tasks I initially had a python implementation with threads, however, it had problems that caused odd behaviour like randomly locking up. So I rewrote it in Go. However, that required me to use something to hold the state. I used RabbitMQ to push to a queue so that a another component could consume these messages and start the celery tasks. I would like to rethink the python implementation because I would like to remove the dependancy of RabbitMQ and reduce the latency and failure points. There is around 1.5M to 2M messages throughout the day. Do you think Riko would be a good fit for this? If not, please do let me know your thoughts on how you would tackle this problem.
Wrapping I/O in exception checking/error checking is elementary programming. I'm afraid this has more to do with your coworkers than which paradigm is better than another.
Yea and so does Python generally. 
Yes, I agree that's not accurate nor suitable. I plan on introducing a Date type in the next major version, especially for this use case.
[Shutupandtakemymoney.png](http://imgur.com/blqUQAO.png) --- ^(*Feedback welcome at /r/image_linker_bot* | )[^(Disable)](https://www.reddit.com/message/compose/?to=image_linker_bot&amp;subject=Ignore%20request&amp;message=ignore%20me)^( with "ignore me" via reply or PM) 
Ok this is interesting. I don't fully understand it though after reading the [docs](https://docs.python.org/3.5/library/json.html#json.load). Could you help? &gt;object_hook is an optional function that will be called with the result of any object literal decoded (a dict). The return value of object_hook will be used instead of the dict. This feature can be used to implement custom decoders (e.g. JSON-RPC class hinting). So if we have a class like OP's `LazyDict` or `blah` in the top comment, that class will be instantiated using the json that would normally get rendered via `json.loads`. Right? What if we have json that looks like this: { "an_element": "Bob", "a_list": [ { "Tina": 13 }, "Gene", "Louise" ] } which is a dict containing a list containing another dict. Would that list also be passed to the dictionary-like-class? If so, doesn't the class's `__init__` break because it receives a list as input rather than a dict? After testing, it works correctly, but I don't understand why. I am going to add an edit or two as I understand more so that I can narrow down what I don't understand. I found out that the value of `object_hook` is only given dictionary-like-json objects, meaning that in the above json only `{"Tina": 13}` and `{"an_element": "Bob", "a_list": [...]}` get passed in as arguments to the object hook. However, the list `[{"Tina": 13}, "Gene", "Louise"]` does not get passed in. Why is that? Is there something more special about dictionary-like-objects in json than list-like-objects?
For HFT I doubt anyone would use an interpreted language. C++ and some JVM languages are pretty much the de facto standard there. 
Thanks for the info. I've been avoiding Pycuda and have been using Numba instead because I really don't like that Pycuda has you write your kernel in C. Seemed kind of counter productive to chose to code in python but still need to use C code. If it is the better package though I'll give it a look.
Ah, okay, I was under the impression that numba hid all the implementation details. I have only played around with numba a bit, some time ago, so I might be totally wrong about this. If it contains a full wrapper of the CUDA API, then that's obviously better suited for you then PyCUDA!
&gt;I think it would have been much harder for them to ignore an error return value. Why? It seems like they just ignored the possibility of failure. Sounds like without an error from requests, they'd just happily keep collecting non data and then get some harder to discern error, like a key error or string object has no method X, at some unrelated time, like when a client views their dash board. If they didn't try/except, they certainly wouldn't have the forethought to if/else. 
Nastran is a commercial code, originally developed by NASA (the source from ~1993 is actually available). There are different commercial versions of Nastran out there managed by 3 different companies. It has static, modes, frequency, buckling, transient, frequency transient (convert frequency results into the time domain), static aerodynamics, flutter, nonlinear, heat transfer, optimization, contact, etc. There are no non-commercial versions, so you'd need Nastran to run a problem. I guess I just see Nastran as a file format. It's a super generalized input file format that has so many options that any unstructured format can be converted to and from Nastran with no loss of data. In my analysis process, I often change a model to Nastran's format, do some work (e.g. nodal equivalencing), and then flip back. I guess I'd like if at least the most basic Nastran solutions were not locked behind a license. I think using a common format is useful as a validation tool and increasing adoption. The pyNastran GUI isn't meant to make models, but I do programmatically build them from other formats. It does support Tecplot, STL, Cart3D, etc. so it's not just Nastran. It's nice having a common GUI for that I can add a new format very quickly. It's a GUI with legend, results sidebar, logging, picking support, displacement plots, animations, with some more code specific features tacked on. It can do some things (e.g. view aero panels) that not all commercial GUIs can do. It can also do custom CSV results, which is really nice.
Cool, yeah I feel ya. I've been using Pelican for a few months (really only experimented enough to get something running) but the demo site on Ark looks really slick. I think I'll check it out once I have some time to experiment with it.
Just because one server your service queries goes down doesn't mean your whole site should give a 500 error. Usually you catch the error and return a nice "such and such service is down, check back in a minute" type message.
Is this an undergrad project? Profoundly elementary and frankly an easy problem.
Ahhhhh awesome thank you, that makes so much more sense now.
A majority of NumPy (the original one) is supported on the latest PyPy through the improved C-Ext layer. 
If you readup on some of the (probably very slight for the purposes of a tutorial) differences, you should easily be able to work around it. That being said, readup on virtual environments, you can have whichever python you like then
I don't think so, as an open source project they should be as transparent as possible in this sense.
This course is outdated. I used it a few years ago, and it was fine, but nowadays you should choose python3
Right. You catch the error, log and notify anyone who needs with relevant info and then present a more appropriate response to the consumer. If you just let it stack you're probably getting most of it but maybe not everything. For instance you could provide a UUID for the page to report in case of support so you can find the exact stack that user saw. I've seen a good bit of things like that. Ultimately not catching the exception isn't the worst if you handle 500 errors in another way and your stack will properly log and alert on those situations. Otherwise if a consumer gets some ugly stack then that's irresponsible.
Can you have both ? What OS do you use ? If you use Linux then you can't uninstall because OS may need it to work. But you can have both.
For the first go at it, I just kept it as close to the original, mainly because I wanted to start using it in my other project. Though I definitely want to update to feel more Pythonic in the future. There are definitely awkward things, like default arguments, which behave differently in both languages that I need to tackle.
There are about a thousand better examples to use than "Requests." Im not even sure why time was wasted on that module, urllib/urllib2/urllib3 all satisfy all requirements you may need. They are easy to use, they are in the standard library, and all problems are easily diagnosed. None of that is true with "requests."
More speed would be nice for games and graphics.
This opinion might be unpopular, but this is a horrible hack pattern that I see all over the place and wish it would stop. Semantically, attributes and contained values are NOT the same thing! To use a real world example, if you look at a cardboard box that contains several books, you would not say that the box contains cardboard, it's composed of cardboard. Likewise, the books inside are not a property of the box itself, it just happens to contain them right now. tl;dr please stop conflating container membership with object attributes.
&gt; No need for that in Python, just use the @property decorator. I bet, urllib was implemented before the property decorator was part of the language.
i think it would also fair to mention [Nix package manager](https://nixos.org/nix). it is a general purpose package manager that works on any POSIX system (experimental windows support is supported via cygwin). i found myself that i not only work on python related software but it usually includes a mesh of all sorts of stuff. from nodejs, python, haskell, julia, ... and only package manager like Nix could give me a reliable development environment i can control. the downside of Nix is that is not as user friendly as other tools are, things are changing slowly but it is going to take months before we have something with better UX. also while everything is documented, beginner documentation is what i was missing when i started learning nix. if you get over that initial curve you will have an amazing tool that other will envy you every time :) 
That's good to know! I understand that it can take some time to announce where it's going, just want to make sure it's happening and developers are being paid. I've added an edit to my original post to note this.
Exactly 
Definitely 2, while 3 might not support enough of 3.3 language to handle the actual Python 3. I would like some 3.4 (3.5?) support so I could relax, but the project isn't at the scale where the addition of money will yield a concrete result in a few months. Probably 5 months until we see something productizable. I'd like to gently remind folks that it's easy to sign up for a donation of $10 a month. All it takes is a few hundred people giving a small amount to empower PyPy developers to continue to produce an excellent product - fast Python.
[Here](https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf)'s the Kademlia paper and [here](https://github.com/psybernetics/synchrony)'s a Python 2.x application that implements S/Kademlia. Enjoy.
I like the choice. All you need is a single raise for status call and you get it. I suppose you could wrap requests and auto call it.
Exceptions are only costly when they are thrown. If your code is going to succeed the majority of the time, you're actually making your code slower by checking return codes.
Yea, the author has that outright wrong. `requests` will absolutely raise exceptions for failure modes: &gt;&gt;&gt; import requests &gt;&gt;&gt; requests.get('https://foo.bar.baz') Traceback (most recent call last): ...snip... raise ConnectionError(e, request=request) requests.exceptions.ConnectionError: HTTPSConnectionPool(host='foo.bar.baz', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('&lt;requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x102795470&gt;: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)) The difference is what is considered a failure mode. If you get a valid http response back, then by default requests considers its job to be done, and it is up to your application to figure out what you want to do with it. Its a very debatable point how http error codes should be treated, especially considering how often they are abused! There are also codes which need to be considered special cases for the application where they are used, like 429 (slow down you maniac) and 402 (insert coin please). requests IMO has managed to squeeze through a rock and a hard place by defaulting to not blowing up on a 4XX or 5XX but allowing the user to very easily and explicitly change this behavior with a simple `response.raise_for_status()`
* A bot that will tweet something that rhymes with incoming tweets from a particular user or hashtag. * A bot that sums the height in feet of donald trump's wall will be every time someone says 10 feet taller * A bot that posts the corresponding Pantone code &amp; swatch for a given color hex code * A bot that will "x-ify" incoming tweets (ex. Samuel L. Jackson-ify, Yoda-ify) Those are all the dumb ideas I have.
#The Mexicans won't be able to nimbly navigate around this one. [Trump's wall just got 10 feet higher! *High Energy*](https://www.youtube.com/watch?v=qlIGom24qqc) #Total height: 228280ft. We are 38.655% of the distance of the thickness of the Asthenosphere! (590551ft)! 362271ft remaining. ***** Bot by /u\/TonySesek556 - [About Page](https://aws.wariomissed.com/TheWallGrows/) - **[TAKING SUGGESTIONS](https://docs.google.com/forms/d/1nbT77UN01wxB3OPVWC8LlesD1e8jqj5mnkhItd4qQqk/viewform)** - /r/Mr_Trump ***** If you don't want this bot on your subreddit or to reply to you, please send me a PM to my main account so I can add you to the blacklist!
Why it would be specific to Micropython ?
what state are you holding? Can you also post a link to a gist of the previous python implementation?
Exactly.
But the finanacial industry and its regulators are trying to shift to a market model where faster computers and software do not give one an advantage as that is counterintuitive to the purposes for which capital markets exist. And once that happens, enter Python. Afterall it's easier to teach an MBA Python than it is C++. And MBAs are cheaper to hire than quants with their PhDs.
Where's the poll option for "neither"?
Yea but he was a cool guy to be fair, but little annoying . thats what made his paperclip guy
So, you are admitting that you suck at programming? If i see someone using "requests" in know they suck and their code will be full of bugs.
Yep, Nick Coghlan made that exact point in his reply/ blog post he'd written before. 
What sort of web framework crashes on a exception instead of throwing a 500? Also raise_for_status.
Urllib and urllib2 are in the standard library, urlib3 will be in the standard library too. "Requests" will never be in the standard library, it does not add anything. Its just a urllib wrapper. I use urllib, and have no clue why so many have a hard on for requests. Wrapping urllib is not hard.
what is the way to interact with an editor for example emacs, for example can we edit from history panel ? how to cleanup history ?
[removed]
Wow that's a dense library, this could be useful in netsec with a bit of tweaking.
I've never seen a comment like this on /r/python, yikes man... you look fine. The mohawk thing is kinda weird but, really, this guy is ridiculous.
I'll take it out for a spin and shoot you my 2 cents. Thanks for the resource.
Showing a stack is a security problem too
This was not really the main thrust of my project, so subclassing dict kept my codebase simple, as well as my thinking. For debugging, this also gave me other dict methods (keys(), items(), `__str__()`) for free. But I do take your meaning, and often advise people to not confuse inheritance ("is a") with implementation ("is implemented using a"). In this particular case, I *did* feel this was a specialization of `dict`, so inheriting didn't give me serious heartburn.
I'm sure there are similar programs and this isn't the cleanest way to do it, but I was without Internet for a while so I made this.
The | operator is binary OR operator. That means it performs logical OR on each bit of both operands. For the first case it's `True = 1`, `False = 0`, so `(True|False) = 1 OR 0 = 1` and it's represented as True. For the second case it might be helpful to show how values are represented by bits: `5 = 00000101` `6 = 00000110` So `5|6` is 7, because doing logical OR operation on each bit results with 00000111. Since `c = 5`, the `c == (5|6)` comparison is false because it's basically `5 == 7`.
| is bitwise OR,not an intersection operator. It has nothing to do with sets. 5 | 6 bitwise ORs 00000101b and 00000110b to create 00000111b. the statement: c = 5 if c == (5 | 6) is the same as saying c = 5 if 5 == 7 which is false, so it will not run the print statement. https://wiki.python.org/moin/BitwiseOperators
&gt; It has nothing to do with sets. The set class overloads it to have the semantics of set union: &gt;&gt;&gt; {'foo', 'bar'} | {'bar', 'baz'} {'bar', 'baz', 'foo'} 
Also, if you actually have sets, ie. you have two lists of elements, use list1.intersection(list2) to obtain the actual intersection.
I'd really appreciate an extra parameter: requests.get(url, raise_errors=True) requests.get(url, raise_errors=[402, 404, 500]) Taking either a boolean, or a list of HTTP status codes on which to raise an exception. The parameter would be equivalent to (psudeocode for brevity): req = requests.get(url) if req.status_code &gt;= 400 and $raise_errors: if req.status_code in $as_collection($raise_errors): req.raise_for_status()
Disclaimer, your project
| is union, &amp; is intersection. What you wanted to write was: c = 5 # if c in {5, 6}: pythonic way if {c, } &amp; {5, 6}: # here we test for the intersection of 2 sets print "does work" # {c, } is intersecting binary operators can be used as way to do union intersection fast, but in this case it would have been c==5 if c &amp; (5|6): #5|6 is the union of both number and we check all bits of 5 are in it print "ok" 
And the difference to entry points defined in setup.py is?
You have the strangest style of coding I have ever seen :D! Why: for val in range(0, x): print(""" .... """) and not just simply: if x: print(...) Or even better, why not omitting checking whether you should print caution or not, and just only use it when necessary :D? It's very interesting how you're doing 3 open files with 1 with statement (which I have never seen and is quite interesting), but you do not check for a boolean to print something.
Let me know your name so I don't hire you.
Thanks for this. I have recently started learning and this week I was going to start on TF. This would come in handy.
Google?
Yup. Also note that he uses a very unusual (in the Python world) naming convention. It's not PEP-8, but it is at least internally consistent.
Good job! I've been looking for a simple py based example to help with my little project! I'd like to use TF to classify credit card txns based on historical training data that I've manually accumulated over a couple years i.e. a couple thousand txns that I've identified as 'restaurant', 'auto', 'misc', etc based on the transaction description e.g. "WALMART 1020 TOLEDO OH". The part I'm wondering about is how to make TF weight the txn description as words with descending importance i.e. the 1st word:"WALMART" is a much more important feature for categorizing the txn than is the last word:"OH".
I'm also interested in picking this up soon, mind sharing some of the resources you are learning from?
[this one](http://www.curiousefficiency.org/posts/2016/08/what-problem-does-it-solve.html)
Like I said, total noob. I started around 3-4 weeks backs and so far have mostly concentrated on Data Science and analysis. I have enrolled in Andrew Ng's ML class (highly rated) and installed TF couple of days back. Going to meetup this week where I'm aiming to get a jumpstart. Apart from this I'm learning from [DQ](www.dataquest.io), which I'd recommend, but it's a paid site. Datacamp has machine learning track too.
What do you mean?
"Friday" - as in the assistant from Robinson Crusoe "Johnny" - as in Johnny-on-the-spot "Hedwig" - as in the name of Harry Potter's familiar "Stewie" - as in steward You want something short and memorable.
It's python2.7 only
Do they mostly focus on tools or is there a decent amount of theory? I'm mostly thinking of the machine learning side 
Most (if not all) of the python stdlib is fugly because it just wasn't well designed, not because it was a product of a more innocent time. In particular it was designed by people who very obviously focused just upon implementing necessary functionality, not how to write a clean, elegant API. It stuck around in its fugly form because of backwards compatibility issues. I don't think this is a terribly bad thing. If urllib weren't so ugly we probably wouldn't have requests. I do think python needs a better way of introducing developers (via documentation) to libraries like requests, though. Too many newbies read the official documentation and use the crappy APIs in stdlib simply because they think that's what they're supposed to do. 
Thanks, I will try this.
&gt;oh no we've made a mistake .. And he didn't fix that bar=5 default value
The standard library should replace pip with something that doesn't suck. That's the solution. 
How does pip suck?
The standard library is where packages go to die. I want Requests to stay alive.
I think the most important thing is that you get good at "Data Science", not particularly "Python". In the end, Python is just a (wonderful) tool to get things done, but in a specific setting, it may be replaced by something else (say R). I am a Physicist (PhD) handling biological datasets and just made the move to industry. I think that online courses (with certificate) helped me tremendously. I can highly recommend "Machine Learning" on Coursera (it is Matlab, but once you understand the theory, you can easily use a respective Python library: scikit-learn, Keras, etc.). Another highly recommendable course is the PySpark one on edx.org. Once you have covered machine learning and distributed big data analysis (Spark), I think you have covered the biggest topics the industry is looking for right now. Good luck!
That should probably be the end of the story then.
Not sure if you found the answer yet but here's the reason: https://github.com/tflearn/tflearn/issues/249 Basically you need to install the bleeding edge version from the [instructions](http://tflearn.org/installation/).
AFAIK that's because he doesn't want to be tied down by the slower update process of the stdlib.
Standard library were libraries go to die.. 
0. This question is better suited for /r/learnpython, a subreddit dedicated to learning Python. 1. By "commands", do you mean Python code? You'll learn new ways to do things over time, and if you don't understand something in someone else's code, just ask the author - they'll likely be able to explain it to you, or at least point you in a direction to do your own research on. 3. If you're having problems implementing an idea, try breaking it down to the smallest bits possible. Let's say you're building a "guess the number" game. The computer chooses a number at random, then repeatedly asks the user to guess it and tells them if the number is too big or too small, until the user guesses the number. At first even simple things like this can be overwhelming, so what you should do is try to break it down into small meaningful parts. How do you choose a random number? How do you ask the user to input a number? How do you compare two numbers? How do you send the user a response? How do you keep repeating that until the user has guessed the correct number? Every one of those small parts is pretty manageable, and put together, they produce the thing you wanted to build.
You should post on learnPython... anyway: http://pastebin.com/pimXzEL7 
Whoops, I thought this was learnpython. I read both subs regularly, I clicked the wrong link. Thanks for the response though.
I mean what is the difference. Why define scripts in a random extra json file that depends on LinkY rather than defining them in setup.py as entry_points
it's not rude! thanks :)
I don't think you understand what console entry points mean in setup.py and this has nothing to do with pypi. &gt; It's basically the same thing as npm link. I'm sorry I don't speak polish.
The author of requests was interviewed on Talk Python To Me last year and he specifically said that they were keeping requests out of the standard library so that development can occur more quickly/easily. 
Gotcha. Thank you for the info!
Only if you use autoparse, which is only something should do in the shell for convenience. Serious code will use manual parsing. Plus for just date, you can just ignore the time and it works fine.
You haven't followed closely the state of money in the Python community. Big players rarely give money, the PSF has little of its own and the pypy team is a small bunch of volonteers. 
It prevented me from getting carpel tunnel syndrome. 
Wasn't there some price comparison done a while ago that determined lambda to be much more expensive than an ec2 instance?
I don't know that it wasn't well designed. The language of Python, I mean the way you write it at least, has changed since. Nowadays you expect to be able to make a web request in a single line, while back then they didn't think about abstracting it out that much. Beautiful code now means something very different than it did back then, I think. Sliding scale, and I'm sure ten years from now we'll wonder why requests was such a big deal when python-asks or whatever they come up with does it even better and shorter and cleaner.
Depends on what you're using it for. Need something to run 24/7/365? Use EC2. Need something to run on a schedule or run in response to an occasional API request? Lambda will do you fine. Lambda is great for doing "infrastructure level" cron jobs where you need to run a script say, once an hour or once a day and you don't want to set aside an entire server to run management scripts. For example: scheduling EBS snapshots.
Just out of curiosity, why and where do you use Haskell? We scratched the basics in one of our classes in college, and I enjoyed the language, but I can't imagine where I would use it over an imperative language (Java or Python in my case).
It's complicated and not all the factors are pips fault, although all of them are collectively pip's problem to solve (or some replacement project). In no particular order: - setup.py is a disaster. It's a metadata format that's mixed together with live Python code. That makes it unparseable without execution. It's executable because people have various installation special needs, but a good metadata format could just say "when you run install, go to location X and use this subclass of the standard installation class called Y instead of the default installer." - In spite of setup.py not being a metadata standard, there are a couple of inscrutable, poorly documented metadata files you need for Python app installation, like MANIFEST.in and requirements.txt (see below for more complaints on requirements.txt). - Python relies on C very heavily, and compiling C code is a nightmare. Every installation problem I've had with Python at work has traced back to some C library that you need to have installed before some other Python library will work. This is not Python's fault per se, but it is a job that needs to be solved before you can say that Python installation doesn't suck. - The command line UI for pip is crap. The commands for things like "just download stuff here" and "use my cached downloads instead of connecting to the web" are non-obvious. There is no command at all for things like "add a new dependency to my app's requirements" because there's no metadata standard, see above. - Conceptually, an installation system should have two metadata files: one for loose requirements (Django &gt; 1.4) and one for strict requirements (Django==1.9.3). The first lets others use your libraries, and the second lets app distributors have reproducible builds. Pip kinda sorta halfway has this between setup.py and requirements.txt but it is extremely half-assed and not at all thought through. - When you start using Python, all you need is the standard library, and it's great. Then you get a little further, and you install a couple of libraries, and things are still okay. Then you get a little further and realize that you need separate libraries for separate apps and then everything breaks down. If you think about it, there are three possible ways you might want to install something: globally, per user, or in a particular project location. Python was designed to install everything globally, and while it has been retrofitted to support the other two use cases, it's extremely kludgey. A "virtualenv" is just a case where because Python is so geared around global installation, the easiest way to do a project based installation is to make a "project global" by reinstalling Python in a second location. This is super-hacky, and extremely confusing to non-Python people who try to get into Python (e.g. at work when I need to explain to frontend devs how to install our web app). - Pip does not handle and does not try to handle the case of trying to distribute apps to non-Python users, the way that py2exe or pex or Conda or other projects do, but when you think about "packaging" as a whole, there's no reason why a Python packaging tool shouldn't do those things too. Basically, pip doesn't try to tackle that problem because it's too busy doing a bad job solving other problems, so it doesn't have any resources left over to try to solve this use case for people who want to provide GUI apps or command line tools to non-Python users. So pip sucks. I would say compared to bundler and npm, it's mostly worse except it never did the npm nested dependencies thing (which I've heard they've stopped doing). Compared to the platonic ideal of good package manager, it's not even close.
Except that that's not "fine". It's totally broken. Validating data is important. That's why we make fun of PHP. 
&gt; It will also locally globally install your desired package, so you &gt; don't have to add it to any environment variables. This doesn't make sense. &gt; many people test their command line interfaces by repeatedly: &gt; &gt; editing their programs &gt; versioning, building, and uploading them to pypi &gt; downloading them to their own computer and testing That is the most braindead thing I have ever heard, I question whether anyone ever did that. There is `python setup.py develop`or `pip install -e`. There are of course local virtualenvs too. I think your tool comes from you not knowing the above features of setuptools exist, and assuming others don't either. I think LinkY does nothing but confuse the situation even more.
I understand the sentiment, but it feels feature complete and reasonably ready for maintenance mode? I say this from the standpoint of only using requests to scrape a page or interact with an API. I'm sure there are funny edge cases I don't even know exist.
I don't think it's "braindead". I did know about those parts of setuptools, but configuring the bash command isn't part of them. Also, what is confusing you about the "globally installed package" part? It puts a symlink referencing your package in your Python interpreter's default site packages folder rather than you having to add your package's path to `PATH`, `PYTHONPATH`, or some other environment variable. Also, why say that it's braindead? Is it *really* the most braindead thing you have ever heard? All I did was make a tool. For this whole thread, you could have started out by trying to understand it instead of asking me questions; then, instead of quoting me and picking my comments apart, provided some sort of insight. In response to you not "speaking polish", why assume that something is wrong with what I said and google it? npm is an extremely commonly known ecosystem, so I assumed you knew what it was. Rather than lash out with some backhanded remark, maybe try to understand what I'm talking about. I took a look through your comment history, and it seems like you have absolutely zero clue that you come off as extremely condescending. Many people come here to learn, gather information, and show off their creations. You do nothing but bush-sit and send your snarky comments to beginners so you feel satisfied with your purported expertise and intelligence. How about actually *contributing* to the conversation for once?
&gt; carpel tunnel syndrome Upvoted you because I encountered something new.
You are a CS major and you write &gt; configuring the bash command Tell me what that means to you.
The standard library documentation does already point to requests. I would say that this already serves most of the same purpose as actually including it.
 &gt;I do think python needs a better way of introducing developers (via documentation) to libraries like requests, though. Too many newbies read the official documentation and use the crappy APIs in stdlib simply because they think that's what they're supposed to do. The official Python docs recommend Requests as the standard library for performing high level HTTP requests. It's in a very visible banner on the urllib page. 
Better yet, let me know the name of your company so i can watch it tank from afar.
Adding an executable file to a location in PATH, like usr/local/bin. If that file is named "link", when "link" is typed into a terminal prompt, the contents of the "link" file are interpreted and then run. 
For your understanding, this has nothing specifically to do with bash. It is off-putting that you kept bringing it up. `PATH` is `PATH` is `PATH`. It is clear LinkY does exactly what setuptools does when installing either a script or entry_point. But now you have to write an additional json file. 
&gt; I figured they just included useful libs at whatever stable That is what they do. Requests is a wrapper of a wrapper of a wrapper. Not stable and rubbish. There is no reason to include in the standard library...tldr "requests" sucks big ol donkey balls.
Fair enough. Just please don't be an ass to people. Or, at the very least, reevaluate how you help people. 
itertools, collections, math, sys, os, shutil are pretty good parts of standard library
Looks like a great learning experience, but I would strongly recommend against using it for anything important. Encryption is hard to get right, easy to get wrong, and just one mistake can render it all useless, in non-obvious ways. If you want reasonable encryption for your files, you have basically two options; one, use a one-time pad; two, use one of the handful of battle-proven asymmetric encryption algorithms (i.e., use GPG or LUKS or something like that). Your program seems to reinvent the one-time pad, but in a not-so-straightforward way, which makes it hard to tell whether it does it right. Then; as far as encryption is concerned, there is only one type of file, namely the stream-of-bytes. Adding any logic that treats certain bytes in the payload specially, or restricts it to, say, valid utf-8 (or even ASCII!), makes the encryption needlessly weaker. Then there's UI concerns. I strongly urge you to read Eric S. Raymond's The Art Of Unix Programming, which explains a bunch of basic rules like "Silence Is Golden" or "If your program can be a filter, you should implement it as a filter". Even on non-Unix platforms, it makes sense for a CLI program to follow Unix conventions where applicable.
Kind of a newb here, but what is the difference between "modern" beautiful code and "older" beautiful code?
Exactly. You should use a context manager around open files. The context manager's exit closes the file.
Remindme! 1 hour
Why doesn't requests have a method to download a file? Last time I tried to get an image, I had to get it in chunks. It would have been easier to make a single urllib call.
/r/Python is for new, releases, and discussion. /r/learnpython is for questions.
In PYcharm, go to project settings, interpreter, and create virtual env. That's give you a separate environment for just that project. You can also install your dependenacies using the GUI, from that same screen.
Can I get an upvote too? I gave my mate a lift to his club. We drove trough a tunnel and the speed humps were very bumpy. It jarred my wrists as I gripped the steering. Do I have carpool tunnel syndrome?
There is a middle ground here though. Why not have a "corelib" of independent packages that are automatically packaged with Python, but able to be updated (via PyPi) more frequently? The docs could even be hosted alongside the core documentation (separate, but linked) to ensure they are easily found. The packages would obviously need some level of core support, but I don't think it's unfeasible.
There should be a standard "library" outside the stdlib that's package with every install, which would include (a still upgradable) requests.
One simple example is that I can do the below with requests. It isn't easy to do this in urllib (to my knowledge?) because urllib was written before json became such a prominent way to store and retrieve web based data. data = requests.get(some_api_url).json() This alone doesn't mean that urllib is bad, just that it's outdated. Similar functionality could easily be added, but I imagine they prefer the modularity of "use urllib to make the call" and "use json to load the data if it's in json format". And that makes sense, it's just annoying and not anywhere near as elegant to me since the two things are so frequently used in conjunction nowadays that it just makes sense to have them be tightly coupled. So I guess my answer, in general, is that older good code can't easily see the future of various inter-dependencies and what its real role in real programs will end up being a decade later. Newer code already knows and can make better decisions because of it.
It's more of a 'tip' tacked on and they don't do anything similar for other libraries that I'm aware of (e.g. os/os.path, which isn't particularly nice either).
&gt;One simple example is that I can do the below with requests. It isn't easy to do this in urllib (to my knowledge?) because urllib was written before json became such a prominent way to store and retrieve web based data. &gt; data = requests.get(some_api_url).json() That is not elegant, it's a hack. Downloading data and parsing it are two orthogonal concerns. A library shouldn't do both. In X years, when JSON has gone out of fashion, people will wonder how this could ever have been considered a good idea. &gt; And that makes sense, it's just annoying and not anywhere near as elegant to me since the two things are so frequently used in conjunction nowadays that it just makes sense to have them be tightly coupled. You don't tightly couple things because they are frequently used together but because you have to. "Tightly coupled" and "elegant" are pretty much opposites.
&gt; Need something to run on a schedule or run in response to an occasional API request? Lambda will do you fine. Better than fine. At work we have a Lambda script which does some stuff when files are uploaded to our S3 buckets. We could have done this using an ec2 instance and a queue but the lambda script is simpler to maintain and has so far cost us nothing in AWS fees as it sits entirely within free usage.
Never seen someone with a hateboner for a library, did requests murder your family or something?
I don't know that you're right. If you're looking to download JSON from a server, you'd expect it to come out formatted. It's so ingrained in today's webdev that it might as well be able to get the formatted object right off the request. I see where you're coming from, when JSON gets replaced, but for the next X years it'll be nice to have. If it ever needs to go, we can deprecate it right?
Nope. Requests is a wrapper of a wrapper. Being included in the standard library would mean revealing their true nature...there is no reason to have wrappers of wrappers in the library. I write wrappers all the time, but i dont claim they are useful. The "authors" of requests are douchebags. It is not original, its a wrapper of a wrapper. That alone means it should be wiped...
 data = json.load(urllib2.urlopen(some_api_url)) Is this really worse? Edit: I'd argue it's much better, since you don't have completely different tasks wrapped into the same library.
I've heard this argument all the time but I still don't buy it. I don't doubt other packages in the stdlib have "died". But I suspect those have been cases where the primary developer pushed for inclusion, opted to become maintainer, and was stuck maintaining. But this is open source software. There's no (non-technical) reason why an interested maintainer couldn't take the current version to create a stable, maintained branch for inclusion in the standard library. The primary branch of requests could continue innovating unabated. The stdlib branch would pull only the most important bits. Several libraries in the stdlib do this already. sqlite3 to name just one.
&gt; I see where you're coming from, when JSON gets replaced, but for the next X years it'll be nice to have. If it ever needs to go, we can deprecate it right? I disagree. Imagine if that same line of thinking was applied to the [OSI model](https://en.wikipedia.org/wiki/OSI_model) If Ethernet and IPv4 had been designed as a single layer. (merge level 2 and 3), the introduction of IPv6 would have been very problematic. [Separation of concerns](https://en.wikipedia.org/wiki/Separation_of_concerns) is a good thing 
I heavily value usability over "correctness" in that regard, and I feel like python in general tends to as well. If in X years, the standard format is `requests.get(url).yaml()`, or `requests.get(url).woopdeedo()`, that'll be what the library uses and that'll be fine by me. And it will still have backwards compatibility with json() when necessary.
This is a single helper function, [9 lines](https://github.com/kennethreitz/requests/blob/master/requests/models.py#L803) long, though. 
&gt; So using Virtualenv, am I correct in assuming I can change up software like scrapy, django, ect with each new ENV I create? Yes. I would recommend using `toggleglobalsitepackages` to set globally installed packages as being available. It may seem counter-intuitive to using virtualenv at all, but I've found some packages (notably database drivers; matplotlib) are easier to install just once. Alternatively, it's no skin off my nose if you re-install DB drivers every time.
No so far it is great! I was in kind of a rush earlier when I wrote the post otherwise I would have been clearer. I just really wanted to ask a few questions before I had to go to work. Lately, any time I am not working, I am trying to get better at Python. I dunno what it is about this language, but I really love it. I have always been just a jack of all trades as far as languages go. I do freelance IT/Web Dev. I watched a Defcon youtube video about web scraping with Python by Al Sweigart. I bought his book the next day and I have been hooked ever since. I want to get as good as I possibly can with Python. 
I'm sure someone has linked to Kenneth Reitz's talk from the last Python Language Summit about this by now, but a major hurdle for requests being included is that it bundles chardet with it, and that code is annoyingly all LGPL because it was originally a literal port of code from a very old version of Firefox. LGPL code cannot be in the stdlib because it isn't compatible with the license Python uses. I say all of this as one of the co-maintainers of chardet. I was really hoping we could get chardet relicensed and included in the stdlib, but that turned out to be impossible, as is painfully detailed in this twitter thread: https://twitter.com/dsblanch/status/590942565995827200
Awesome! It felt like it was lagging for a couple of years. If this gets a boost in dev woot.
You read my mind! I was actually thinking about this earlier. I did not know the syntax though. So thank you for the heads up.
&gt; Downloading data and parsing it are two orthogonal concerns. To most users, that's an academic distinction they care little for. 90% of the time, they just want to get some data with as little effort as possible; the best libs recognise that and strive to give users what they want.
is that a get, a post, or what? Does it handle proxies, ssl and redirection out of the box? That's where `requests` shines: it makes trivial what should be trivial in this day and age.
Not everyone wants the latest and greatest. Part of the reason for the stdlib release model is that you can be sure python x.y.z will ship a certain module with a certain behaviour. If you make some of them upgradeable, you risk a situation where downloading another library will give you an unpredictable version of stdlib modules through cascaded dependencies. It's a can of worms.
What language has a better user experience than Python? When you go beyond the basics, pretty much all languages user experiences deotriate.
My first thought was when can I get this on django too.
Is there anyway to sped up django inserts? I inserted just 100,000 rows and it seemed like it was taking forever.
It's just so weird that new things come out as Python 2.7 only.
Is there a Google cloud lambda?
That code makes a lot of assumptions. - Assumes it gets 200 back (doesn't actually check), - Assumes it gets a response back. - Assumes it gets JSON back.
I guess implementing a new standard would be easier than making Micropython interactive with standard ssh tools?
If total time doesnt matter, can someone be amazing at python within 2 hours?
People learn programming at vastly different rates. It's impossible to answer questions like these. Yes, you *could* certainly become adequate in 4 months. Maybe you could become adequate in 3 weeks, or perhaps it will take you 6 months.
They do recommend pathlib for os.path stuff. But it's in the stdlib, so maybe that's not what you meant. They do point out [pytest and nose in the unittest docs.](https://docs.python.org/3/library/unittest.html) There's also a stronger recommendation (in red) to use [defusedxml or defusedexpat if you need secure xml parsing](https://docs.python.org/3/library/xml.html).
Tell me more about woopdeedo. Is it web scale?
I didn't say it didn't matter, I said it's not important. Time spent does matter, as it will take you time to learn anything, but what you learn is way more important than how long you do it.
&gt;I don't think there's anything PyPy can do about this kind of "bad code". No, there isn't. However, currently there is no way to even find this "bad code", other than inspecting every line of the program you're trying to run (and every library it imports). Hopefully the feature that /u/pmatti alluded to will be forthcoming. Until that happens, the best thing to do would be to caution people against trying to migrate large apps to PyPy from CPython and to stop marketing it as a drop-in replacement for CPython.
not sure i understand the question but: * pandas.expanding_max if you want the series of the maximum reached to that point * pandas.DataFrame.idxmax if you want the index of the max (with which you can find the associated date)
I only asked since you mentioned it. &gt; So I rewrote it in Go. However, that required me to use something to hold the state. But a concrete example would make it much easier to see if this can be done in riko. &gt; I initially had a python implementation with threads... Could you provide a link to the original python implementation?
Thanks for sharing. But that solution seems quite (too) complicated to me. So you have to reimplement the classmethod "check_extenstion" for every archive type. I think that's a code smell. You could solve this using a metaclass but that makes things even more complicated. Why not use some kind of strategy pattern? The real difference beteen tar and zip is that you have ZipFile(self.location_path, 'w') vs tarfile.open(self.location_path, 'w') in your context manager. Why don't abstract that away producing some kind of archive opener strategy. Could be as simple as def open_zip(path): return ZipFile(path, "w") and def open_tar(path): return tarfile.open(oath, "w") Now you refactor your BaseArchive's init into something like def __init__(self, location_path, files_to_pack, opener_strategy): where opener_strategy is either open_tar or open_zip. You're generate would be def generate(self): with self.opener_strategy(self.location_path, 'w') as zfile: for file_ in self.files_to_pack: file.write(file_) You're factory becomes then a dictionary like {"zip": open_zip, "tar": open_tar} 
I've never used Lambda but it seems like there is more to it than just uploading a script. You need to create a handler function, create a python package, zip it up, etc. Since your script requires a third-party library (twilio) that would also have to be bundled in the dependencies of your package. If you just need to run a script on an ec2 instance or something, you don't need Lambda. http://docs.aws.amazon.com/lambda/latest/dg/python-programming-model-handler-types.html
the analogy you describe of attributes:values::box:books works equally well for dictionary keys and values. In fact python objects are little more than glorified dictionaries. There's nothing you can do with an object that you can't do with `object.__dict__` besides operator overloading. It's almost as if the whole point creating classes is to implement operator hacks. Otherwise, everything else is possible with dictionaries and prototypical inheritance. I'm not trying to give carte blanch to all kinds of wacky hacks on attributes (e.g. like using `__getattr__` to execute functions or whatever), but the fact that python itself uses dictionaries to implement namespaces and as an alternative way to access object attributes (with `__dict__`) would suggest that mapping dictionary keys to attributes isn't quite the sin you make it out to be. &gt;&gt;&gt; class LazyDict: ... def __init__(self, dict): ... self.__dict__ = dict this ^ is functionally equivalent to the dictionary wrapper classes seen in this thread, but it's doing it in a way that intrinsic to the python data model. This is simply how python works.
The data structure you're looking for here is called a interval tree. A quick search turns up plenty of Python implementations, e.g., https://pypi.python.org/pypi/intervaltree
You don't, you install the Anaconda package which setup all linters, code-completers and other desireable Python related plugin for you out of the box. Then you just enjoy your life.