Every thing I come across seems to depend on a module, and that rabbithole goes deep. Even the most basic functions have to be conjured up from modules first before you can use them. Python has no functionality unless you import it, and if you dont know where its supposed to be coming from, it drives you up the wall. I supposed thats done to make it lighter, but it certainly doesn't make it easier.
Actually it works in two ways. When python loses the reference it will close the file. When the **with** block ends it will also close the file due to the \_\_exit\_\_ special method. So both, open('file.txt', 'a').write('Blah') and with open('file.txt', 'a') as fh: fh.write('Blah') end on the next except that, when using the **with** block you will be handling any errors correctly whereas, the chained "open" will not.
Yo dawg, I heard you like to build, so now you can build while you build so you can build when you build.
It's a *great* subreddit. There are a lot of professionals there too, but they're pretty dedicated to making sure that you: a) fix the problem that you've presented them with b) understand why this fixes the problem c) make your way to the solution with guidance instead of answers Great community there! Enjoy!
I wrote this over the weekend to help me clean up a requirements.txt file after I overhauled a large Django project. Hope you find it useful!
Why is it not on pip?
You can do this: from .bar import Bar from .world import World Bar.__module__ = World.__module__ = 'foo' I'm not sure if that's going to have any long term negative effects. 
The first thing that pops out at me (besides the small indentations) is the use of one letter variable names. This makes the code hard to read. Also there are a lot of "magic numbers" with no explanation, i.e. x = string.find("var TralbumData =")+17 In this case it would be much more readable and flexible like this: search = "var TralbumData =" match = string.find(search) + len(search)
No I posted it a while ago (like, at least six months) but I got around two upvotes, so after a couple of hours I deleted it. After that, I basically started commenting about it every time someone said "suggest me an editor", until I started getting downvoted probably by someone who considered it as I was spamming. 
I vote for list comprehensions. I think your example is a good argument for why. As written, this example crashes. TypeError: append() takes exactly one argument (2 given) I think you mean. resut.append((x,y)) We want a list of tuples. It seems like a simple bug. But it illustrates the fundamental argument. By the time your brain worked out the state changes to x &amp; y in the nested for loops and the if statement, it forgot that the point was a list of tuples. For loops and append/extend are state managing &amp; modifying tools. They are good in their place. But, to understand what they do you have to run the program in your head. Human brains are not as good at maintaining updating state. The list comprehentsion, when used properly is a data declaration. "This is a list of tupples. The first element of the tuple is an integer in the range [0,10). The second element is an integer in the range[0, 5), The product of the two elements is greater than 10." It's a long tedious specification, and this is just a toy problem. But the details and tedium shouldn't be mixed with possible state changes, especially as the problems become more complex. Human brains reason better about data structures, than state changing programs. List comprehensions are at their best when pulling state changing logic into data structure creation. Fred Brooks said the same thing 1975 "Show me your flowcharts and conceal your tables, and I shall continue to be mystified. Show me your tables, and I won’t usually need your flowcharts; they’ll be obvious." Flow charts are state change diagrams. Tables are data structures.
Zope stands for "Z Object Publishing Environment" and Plone was named after the electronic act of the same name that the developers were listenening too while writing it.
Pagegen is opinionated and makes a great deal of assumptions about what a site should contain and tries to provide everything you need right out of the box, just add CSS styling. The content management/organization in Pagegen has a very direct mapping between source directories/files and the generated site. Essentially it handles generating multilevelled site hierarchy and corresponding site menu based on the source directory structure. This lends itself to a transparent management of content, just move around files in directories. Pagegen also supports content files that are executable, on generation the executable output will included as the page content.
C can't even do printing without the stdlib, that's life. Such a petty argument.
&gt; I am shit at programming python, and I dont really intend to change that. don't you think this defeats the whole point of this thread?
Thanks! I didn't know about this search feature.
I'm perfectly content with being slightly less shit at it. I'll still be shitty at it, but as long as it gets this tiny job done its fine.
I'm a big fan of http://codecombat.com/.
Common aclark, posting flame baits in here? :-)
Oh no doubt dude, it could be better, was just trying to be helpful. In the meantime, if you need to do stuff at a low level, Cython might scratch that itch.
&gt; You can't do this without changes to vim's architecture. Good to know, that makes sense. So vim is at the point of being forked and the original will probably be left in the dust. oh well, as long as I can edit files it doesn't matter :-)
has anyone used their service? PS: why the suits?
If you want to compare Maven to anything well-known, then compare it to `setuptools` – dependency resolution (pip) covers only a small portion of it.
I'd use `__name__`.
Just curious how the general Python public perceives such issues. I trust the conversations here more than the "loaded" conversations that happen in proper circles. People either love it or hate it and don't mind telling you so. :-)
Raymond Hettinger recommended in [this video](https://www.youtube.com/watch?v=wf-BqAjZb8M) to use a line length of 90-ish instead of the pep8-sanctioned 79, but did not move the line length goalpost for docstrings and comments, they are still 72. I just tried this trick with the print margin set to 90, and then it wraps docstrings at 90 too. How can I keep the print margin at 90 while having ctrl+2 w (or something similar) wrap at 72? 
Only after im done marveling at your glorious elitism. sokonomi.exit()
Why not just buy the book?
I few months ago, I used a series of tutorials from sentdex to do something very similar, although I was somewhat disappointed with the coordinate results I got based on my keywords. Instead of mapping dots on a globe, I instead used timezones since Twitter forces users to select that from a list (read: it's standardized and required). Anyways, I highly recommend sentdex and his tutorials as great starting points. Good luck. http://pythonprogramming.net/twitter-api-streaming-tweets-python-tutorial/?completed=/mysql-live-database-example-streaming-data/ 
From a cryptological perspective, security through obscurity is no security at all. If someone figured out the algorithm, you essentially turned a strong 20 letter passwords in to a weak 5 letter password (4 key characters, and 1 length var). http://en.wikipedia.org/wiki/Security_through_obscurity 
Nonono. It's a python library that you give a dict and it builds a Tk data entry form for it.
I'm completely uneducated in the field but I can't see how it differs from normal password systems. The user can enter the password and select which characters are the key. If it's not the case, is there a way to make the password system secure?
Django uses flake8 and isort on a Jenkins box for an initial code review. Does this bring some significant advantages? 
[Here](https://github.com/ga7g08/GetTrainTimes/blob/master/GetTrainTimes) is a script I wrote to scrape data from the UK national rail times website. See the readme for its usage. Web scraping is a great way to collect data and taught me a lot about html etc.
If you're the attacker and you can figure out the specifications for the password, couldn't you do the same for a normal 20+ character password?
I was referring to the latter, in which the attacker would need to know the person's personal keys and length. If they found that out, wouldn't they be able to figure out a person's normal AlphaNum password?
This thread has been linked to from another place on reddit. - [/r/shittyprogramming] [How about those homemade cryto algorithms?](//np.reddit.com/r/shittyprogramming/comments/34309s/how_about_those_homemade_cryto_algorithms/) [](#footer)*^(If you follow any of the above links, respect the rules of reddit and don't vote.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
Hi, I'm the author of several Python for beginner books, all freely available under a Creative Commons license. My latest book, *Automate the Boring Stuff with Python*, is made *exactly* for the purpose you describe: learning enoug code to write practical scripts (such as web scraping, updating Excel spreadsheets, etc), without the complexities of OOP &amp; computer science. Basically, programming for office workers, not software engineers. You can read it online for free at http://automatetheboringstuff.com
Yes, given enough time – but guessing a 20 char password is *considerably* harder than guessing the length, and the 4 key chars and their positions. I'm imagining that the attacker tries all possibilities one after the other. A powerful computer that could make 100 billion attempts per second (not unreasonable for a dedicated attacker) could try all 1.4x10\*\*12 possibilities for key chars and length in under twenty seconds. (1.4 x 10\*\*12 / 10\*\*11 = 14 seconds). Do you understand how I got 1.4x10\*\*12 possibilities in my original post? By contrast, trying all possibilities for a 20-char password would take the same computer a thousand trillion centuries (62\*\*20 / 10\*\*11 ~= 7x10\*\*24 seconds). So yes, in principle it could be guessed, but it's going to take a *really* long time!
Thanx for sharing, looks very interesting 
I agree. I don't want someone to make fun of me for asking a question, so I wouldn't do it to others. Docs and tutorials help tremendously but sometimes you just want to talk to someone that's been there before. &gt;"Hey everybody, look at them! They're trying to *learn something*!"
Agreed, I thought he deliberately ignored the obvious systematic way that was suggested by you and others in the thread. Maybe he legitimately didn't think of it, who knows. 
Ok, so maybe it's not very pythonic, but you could use streamutils (http://streamutils.readthedocs.org/) for this. Equivalent code would be from streamutils import * floats = read('foo.txt') | sfilter(lambda s: s and s[0]!='#') | smap(float) | ssorted() # builtins are shadowed by s-prefixed equivalents print(floats[:10]) (Disclaimer: I'm the author of streamutils, and would love feedback on it!)
I can help with this. What version of Python is this for? A lot of this code is re-inventing the wheel, but there's a library I've used in the past that should work. https://github.com/bear/python-twitter Hit me up if you have any questions.
Compared to other tools and services, we've built QuantifiedCode not based on existing linters or code checkers. We built an engine that allows you to create your own code checks / lints by creating queries on the abstract syntax tree (http://docs.quantifiedcode.com/patterns/language/index.html). You are basically describing your code check as data structure rather than as linter (plugin). Like this, it is possible to create code checks for your own projects within a few minutes. There are several Django checks available, even some that help you with Django migrations: https://www.quantifiedcode.com/app/patterns?query=django
https://github.com/jul/check_arg/blob/master/check_arg/test_valid.py I made a decorator library for testing inputs and documentation (based on the idea people can name their function smartly which is a very high hope). The only advice I can give you is: don't confuse integration/functional testing with unit tests. Your decorator should be unit tested, not tested at this level. And the above mentioned link is a normal, basic unit test. Use the right test for the right case.
In addition to using the Run dialog to start a Windows Command Prompt, on Windows Vista, Windows 7, and Windows 8 you can simply type cmd.exe at the Start menu and cmd.exe should appear in the search results.
Help would be great! I PM'd you :)
Go to a local Python Meetup. 
Here's a blog site with some practical uses of Python in the "real" world dealing mostly with data analysis: [http://pbpython.com/](http://pbpython.com/)
/r/learnpython What doesn't work about your example?
I think my best tip is similar to what you mentioned earlier in the thread - treat each problem as a project within itself. The hard part is figuring out *what exactly are all the problems that need to be solved?* And once you got that, its easy to tackle them one-by-one until you're done! Also its extremely satisfying to get something completed (no matter how small).
Sorry, my sincere apology, I should've stated that right off the bat... The problem is either one of two things or both. Either Python doesn't recognize it as a character or it messes with the syntax because of the extra quotation. Thanks
At Pycon's there is always a jobs board too.
 while (self.experience &lt; good_job_experience): self.write_code(self.interests) self.experience += 1
the same i can do with jenkins
:O
I just understood what you meant: from .bar import Bar from .world import World Bar.__module__ = World.__module__ = __name__ You're right, quite better actually.
you learn regex and stop being a little bitch
if you have to ask you can't get a job
What if I don't want to get sued for sexual harassment?
Yes so, maybe this wasn't clear, but I want to replace “ with `` and ” with '' The reported error is: SyntaxError: Non-ASCII character '\xe2' in file /Users/~MYNAME~/Desktop/Evernote_LaTeX.py on line 19, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details 
I am missing the reference?
how about this, find out what they do, find out their problems, figure out a solution using python web development + amazing python libraries = awesome solution that you made. Spend loads of time learning, building, reviewing, testing, deploying, etc. Then they will hire you, GUARANTEED. TL;DR: Step 1: Learn Python; Step 2: ???; Step 3: Profit.
Thanks anyway! Any suggestions on work arounds?
I think your problem is actually with the python file you are writing. Like, *it* is encoded in unicode or something. Delete this thread. read the PEP the error references. Post in /r/learnpython . tell what OS and editor you are using, and post the code you've tried with the full error traceback.
Cool thanks for that! I will mess around with all of that and see what i can do.
Tried that. I get this everytime. Downloading/unpacking opencv Could not find any downloads that satisfy the requirement opencv Cleaning up... No distributions at all found for opencv 
You should look up PEP8. It's just a convention for code formatting and a couple other conventions designed to make your code look like everyone else's and thus make it more readable. Also, you do a lot of indexing and slicing. Replace all those magic numbers with constant variables whose names have meaning. Look up the Slice class. This will allow you to predefine slices that can range across any number of indices and then use them wherever you'd use the [i1:i2] syntax. It will make your code far more readable and maintainable. 
This is one thing I really like about Pyramid. Very few of the decorators (e.g. @view_config, etc) actually modify the function -- they just attach metadata which the scanner detects, and which then creates a decorated copy of the function for the framework's own consumption, without affecting the actually function; leaving it free for UTs. Short of that, I frequently write helpers that take in a function, and "unwrap" it to find the actual underlying callable. This does rely on the wrappers exposing what they wrap in some reliable fashion. E.g. functools.update_wrapper() sets the \_\_wrapped\_\_ attribute as of (some later?) release of python. I monkeypatched that behavior into to the version I'm stuck on, which helps anything that uses functools expose a traceable path back to the wrapped function.
 $ pip install git+https://github.com/oliverfields/pagegen_v2#egg=pg
You don't have to learn regex to use regex for this. You really gain nothing. `re.sub('match', 'replace', 'string')`
I think that's biting off more than you can chew. How about a google docs spreadsheet?
Well, yes, but I'd rather `pip install pagegen` it.
PyCon 2012.
Get an account on LinkedIn, StackExchange's Careers, make sure your Github's got some stuff on it. Learn a web tech, like Django ro something, and apply like crazy. 
Ah, this is actually a feature! Your editor is informing you that `range` is a built-in function. The reason this is a feature is that in python, every identifier (such as modules, packages, variables, classes, and functions) is "resolveable" by looking at definitions, decleartions, and imports *from within that file*... EXCEPT for built-in functions. So it's important to highlight built-ins so that you, the programmer, know that there might not necessarily be a way to "resolve" the definition of that identifier by reading the file. Rest assured, your editor is still working just fine. Every python syntax highlighter I've worked with works this way. Also: this has nothing to do with packages, just so you know.
well the csv module supports any delimiter, so you can do: (This assumes that the ; seperated file has a heading row, if it doesn't you can use a regular reader and read by column number) import csv with open('...') as in_f, open('...', 'w') as out_f: reader = csv.DictReader(in_f, delimiter=';') writer = csv.writer(out_f) for record in reader: if record['UserName'].lower() == '{}.{}'.format(record['FirstName'], record['LastName']).lower(): writer.writerow([record['UserName'], record['FirstName'], record['LastName']])
Also you should try posting in /r/learnpython
No prob, we all need to start somewhere.
Am I using a "link extractor"? Or would this be considered "implementing [my] own spider"? (I'm a novice with Python and Scrapy. I had some help creating this spider. Using this as a starting point, I can successfully scrape a range of different sites but still learning) class LaunchSpider(scrapy.Spider): name = 'launch' allowed_domains = ['sneakersnstuff.com'] start_urls = ['http://www.sneakersnstuff.com/en/2/sneakers?p=6133&amp;orderBy=Published'] def parse(self, response): for product in response.xpath('//*/a[@class="plink name"]/@href').extract(): yield scrapy.Request("http://www.sneakersnstuff.com" + product, callback=self.parse_product) def parse_product(self, response): item = NikeItem() item['url'] = response.url yield item I'm outputting the results to .json files. So I want to be able to crawl the start_url page whenever it's updated, and never scrape the same product twice. As for how to filter out the duplicates, I'm open to anything that works. Ultimately, I want to be able to automatically scrape whenever the start_url is updated.
I have been outputting the data to .json files, to be imported into a website. Could you please go into more detail about how to implement the 'proper' solution you've outlined?
There's nothing to be smart. It's the first line of the PEP Introduction This document gives coding conventions for the Python code comprising the standard library in the main Python distribution. .... Many projects have their own coding style guidelines. In the event of any conflicts, such project-specific guides take precedence for that project.
Pandas dataframe [from_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_csv.html) Import pandas as pd df = pd.DataFrame.from_csv('THECSV', sep=';') df['valid_name'] = df.apply(lambda x: '.'.join([x['first'], x ['last']])) df0 = df.ix[(df['valid_name'].lower() != df['user_name'].lower()), :] df0.to_csv('out.csv') 
http://learnpythonthehardway.org/
That actually sounds really cool! Although I'd prefer it to be an OSS tool like flake8, I guess that wouldn't quite fit in your business plan. 
If you wan't a feedback, then create a Pull Request from your project. Create new branch from this point. Reset all commits on master branch. Then create PR from this new branch. This way redditors can do you a Code Review.
find something on github you like.
/r/learnpython please
Thanks! :) 
Why don't you keep a list of crawled products, and check each product against it at the top of your product scraping loop?
I'm just getting started with python and scrapy. I tried searching for things as I mentioned above but I'm not sure how I would implement the solution you described, what method or strategy I might try. Maybe you could point me in the right direction?
Well, the safest and most straightforward way, as well as the most potentially useful to you in the future, would be to persist them to a database. Using something like SQLite requires no database server and is included in Python, IIRC. There is a fantastic library called SQLAlchemy that lets you build objects to represent tables, and interact with them in a very intuitive way. Check it out!
&gt;Full disclosure, I'm aware that all of these projects have "framework aware" testing facilities. But should testing the result of a function require a heavy duty test harness? Yeah, quite possibly. Or rather, the effect of using it. You test a scenario with selenium where somebody's credentials get verified or a scenario where they don't and your decorators get run implicitly. My rule is that if your method is doing something algorithmic, you unit test it. If your code is mainly integrating (which most, but not all, web stuff is), you slap on a heavy duty test harness. Most applications are a combination of both (so need a combination of unit/functional tests), but an awful lot of web apps are mainly just integrational, and in those unit tests may in fact be harmful. Hitting database &amp; verifying credentials definitely sounds like integration code to me, so unit testing doesn't sound like a good idea at all. You'd essentially be mocking half of what your method is doing anyhow, and if you refactor it, you may well end up changing the method signatures (and thus breaking your unit test while not breaking your code). That said, if your decorator is doing some complex calculations, it may make sense to unit test it. Or, to decouple the heavy duty calculations into a separate module and then unit test *that*.
&gt; self.func(self) LOL. That works in original very basic scenario, but actually wrong. You are passing descriptor instance self to the func that definitely not expects it. http://repl.it/3qC/7 BTW, i still think that is the really good python quiz.
Nope - http://repl.it/3qC/8 Base.func gots None as the self argument
Hello, i'm an author of pyspaces =) i'll look at your new project and at least i'll add link into my readme. Also many people can help you if you move your project to some open hub like github or bitbucket... Also can you tell more about your problem on ARM (i don't check it yet)? I use clone function from glibc with flags from linux source and it looks the same for x86 and arm, but maybe some logic still broken in arm linux version?..
Thanks for the anons on reddit ;) I got some traffic from it
Yeah I mean the project I work right now is in django with the `django-pytest` stuff. It takes 40+ seconds to run a single unit test. Most of this type is just bootstrapping the testing facilities(slurping in settings, loading fixtures, etc.) This is death for a tight TDD cycle
&gt; whatshouldibaketoday.takingrefuge.org if you are using Django for this you can just use {% block nameofblock %} {%endblock%} and load the content of the other website in that block and you can put the block in a div or iframe.
what about keeping a dictionary whose keys are the urls you've already seen? seen_urls[url] = result; then in your loop check for the url in seen_urls before making the request. if product not in seen_urls: result = yield etc etc seen_urls[product] = result 
My browser tests take about 15-25 seconds to complete (including setting up a database from scratch - bootstrapping is ~5 seconds). That's from the point when I hit save in the text editor. Running the browser under xvfb helped to bring that down, as does an SSD, as does the automatic test trigger I have set up. It's about enough time to take a sip of water (or beer). I think it's pretty tight. It is slower than unit tests, but unit tests will be more tightly coupled to your architecture, meaning that some kinds of refactoring will render them useless. It's also worth bearing in mind that while successful test runs take 15-25 seconds, a failure often gets reported *much* quicker.
It's telling you what type of package is available if you tried to upgrade right now. Source packages generally take longer to build, and in the case of modules with portions written in C, can require a specific toolchain and non-Python dependencies, whereas wheels are prebuilt binary packages. 
Where are you seeing all this documentation? I've been looking for a while. The official docs are really not very good, and most of everything else I've found seems really out of date.
I have a script which will optimise the parameters of a gas bearing formation but it might not be useful to you.. Truthfully there's no such thing as a generically useful script, it depends what you need doing!
Great! It might look [something like this](http://pastebin.com/Z3EsV6Y9). It's a trivial example, and obviously incomplete, but demonstrates the power and flexibility of a tool like SQLAlchemy. Things like having the product name be unique probably aren't a good idea, but I just wanted to show how you represent various database column flags/settings in code.
Yeah but pyramid has its own problems. Zope basically redefines decorators. In honesty I've only worked one pyramid project, but our biggest hangup was that it was difficult to write our own decorators or alter pyramid's default ones 
Doesn't seem to work for me. EDIT: Only works if you order either the ebook or print, not if you order the combo.
I'm not sure what the 'elements' are that you want to substitute from the database but assume from your question they are the `x` part of the `[x|y|z]`. Firstly the regex that you probably want to use is `\[.+?\|` . Secondly `re.match` will only return a match if it is in the start of the `text`. Take a look at [`re.findall`](https://docs.python.org/2/library/re.html#re.findall) instead! Also take a look at the flags you want to use (Probably something like `re.IGNORECASE + re.DOTALL + re.UNICODE`)
Just tried it. It seems very slow. Are you polling for updates? Why not use a persistent connection / websockets for example?
What is the list for? A generator would save you a lot of memory
Why? I doubt it
It is the next goal we are working on. Thank you for the suggestion. The polling approach is not the best way. Firstly I've to learn the use of websockets.
How much memory it takes isn't the only thing you should worry about.
you got it
/r/learnpython 
Here is my list todo using Python. 1. Twitter Bot to post tweets and etc. 2. Using Beautiful Soup , Scrap one site to get some useful data. 3. Download bot 
I rely heavily on the documentation provided by [New Mexico Tech](http://infohost.nmt.edu/tcc/help/pubs/tkinter/web/index.html) (oddly enough). I'll admit it's a little dry and you have to hunt for what you want, but the details are there if you're willing to hack around a bit. 
&gt; re.IGNORECASE + re.DOTALL + re.UNICODE the elements are just different columns in a database, x=actual text, y=type of text, z=text-id. I got it working now, guess I have to read up on the regex, long time ago I used them. Thanks man!
Web scraping can be a lot of fun! I would give making a flask application a go for too as that can be a pretty great learning experience.
Look at your `parse` method. That's where you're extracting links. Build the url and see if it's in a set of excluded urls and if it is, just `continue` the loop: ... def parse(self, response): for product in response.xpath('//*/a[@class="plink name"]/@href').extract(): url = "http://www.sneakersnstuff.com" + product if url in shit_you_wanna_avoid: continue yield scrapy.Request(url, callback=self.parse_product) ... Now you just need to serialize results after each run, and deserialize prior to running and store those urls in `shit_you_wanna_avoid`. There are cleaner ways to do it, established patterns, but that should work. Also keep in mind that sub-pages won't be spidered since that url won't be followed. Might not be what you're looking for.
I've not dug terribly far into this. We are using `django-pytest` and even if I `mark` a test in a brand new package and run the `py.test -m A my-app/tests` The scanning and bootstrapping seems to take forever. We are using sqlite as the test database and I think bootstrapping this is a large part of the problem. Is there a way to instruct `py.test`(in the django-pytest world this delegates to `python manage.py` to run under a different configuration for certain circumstances?
 ps -ea | grep python
On Linux I would suggest a CRON job. Dont know if windows is capable of doing such thing. But you could google this :)
Fine, thank you a lot for your suggestions. This is what is needed to improve the library. 
batch files (.bat) might be the answer! I know a friend that has used them for that sorta stuff. google'em!
Sorry guys, I got it. It was a Grsecurity issue. I had TPE set in grsecurity and my user was in the blocked group.
I would be happy to get some critique to do it better. 
I just discovered sys.getsizeof() just now, maybe you're wrong? &gt;&gt;&gt; for i in range (0,1000000): a.append([['a',i]]) &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.getsizeof(a) 4348736 &gt;&gt;&gt; for i in range (0,1000000): a.append(['a',i]) &gt;&gt;&gt; sys.getsizeof(a) 8816320
I have a Python script running with a Windows Task Scheduler. Is the machine with the Python script powered on at 1A? What is the error? What arguments are you giving the script?
It doesn't give me any errors it simply doesn't do anything. Right now my script creats a XML file with todaysdate+"output".xml name. If i run it, it works every time. However, when it runs on the scheduler it doesn't do anything. 
y no use [yeoman](http://yeoman.io/generators/)?
I might miss something, but why not using a dict?
It might seem like the obvious move but for my purposes it NEEDS to be a list, I just need to figure out how much memory it's expected to use. As i understand it a dictionary would not allow me to have 'a' as both 1, and 2 for example. It also needs fulfill the requirements above. 
You made 3 mistakes: 1. confused `append` for `extend` 2. reused `a` instead of using a second list 3. used just one `sys.getsizeof` which is incomplete: &gt; [Only the memory consumption directly attributed to the object is accounted for, not the memory consumption of objects it refers to.](https://docs.python.org/3/library/sys.html#sys.getsizeof) I think this makes more sense: &gt;&gt;&gt; import sys &gt;&gt;&gt; a = [] &gt;&gt;&gt; b = [] &gt;&gt;&gt; for i in range(1000000): a.append(['a', i]) ... &gt;&gt;&gt; for i in range(1000000): b.extend(['a', i]) ... &gt;&gt;&gt; sys.getsizeof(a) 8697472 &gt;&gt;&gt; sys.getsizeof(b) 17361840 &gt;&gt;&gt; def getmemsize(lst): ... cache = {} ... getmemsize_(lst, cache) ... return sum(cache.values()) ... &gt;&gt;&gt; def getmemsize_(lst, cache): ... if id(lst) in cache: ... return ... cache[id(lst)] = sys.getsizeof(lst) ... if isinstance(lst, list): ... for item in lst: ... getmemsize_(item, cache) ... ... &gt;&gt;&gt; getmemsize(a) 120697510 &gt;&gt;&gt; getmemsize(b) 41361878 Here you see a difference of factor 3 in favor of method #2
Except far too many python developers completely miss this. Thus you are smarter than the average bear. 
I understand. Thank you very much that was perfect. 
Makes sense. Thanks. 
Really interested in the machine learning part. Is the full source code available somewhere? 
Btw, could you tell us what your purposes are? Some of us might be able to come up with an even better solution that way.
Two consecutive or duplicate letters at all?
That's an option as is - [cookiecutter-flask](https://github.com/sloria/cookiecutter-flask). This blog post is more for learning so that you can either (a) build your own scaffolding tool or (b) customize an already build one. 
Maybe, but aligning is worse, especially if you need to maintain the code before the comments. If you have so many comments single spacing them starts looking cluttered, I would move those comments to their own line.
EDIT: Wait, not quite. Let me try some more.
Unununium - never forgotten! 
That's what enumerate is for: for i, n in enumerate(['a', 'c', 'b', 'v', 'f']): print(i, n) ------------- 0 a 1 c 2 b 3 v 4 f
Make sure that the task scheduler service is started. Windows+r =&gt; type in services.msc =&gt; OK Find "Task Scheduler", right click on it and press Start.
Can you explain what you're actually trying to do? I haven't seen a compelling reason that a generator wouldn't work here. Is this just raw data, like from a database?
Sadly, I cannot read an article on reddit mentioning C without writing any C code. printf("%s\n", "this is stupid");
Good idea. Maybe "What should I listen to?" as you can develop a project.
Site says: To get started with this tutorial, you firstly must have the scikit-learn and all of its required dependencies installed. Please refer to the installation instructions page for more information and for per-system instructions. Just download a release. Don't install it just extract it. Search the extracted release for the package. If it is not in there: contact them.
I am not a programmer, but I am a gamer. I hate the red planks. They are more annoying than challenging for the most part. It should be more obvious how they work (they are solids). The "game over" messages should be more friendly, at least in the beginning. You should first seduce the player, not insult him. The character does not have a natural jumping momentum. Look at Thomas Was Alone... it is mostly a very simple game, with great jumping mechanics. "The Impossible Game" is another good reference for you. In "Press Space" it is like the character hit an invible wall with the head and than fall to the ground. It is not natural, nor user friendly. Your game should be hard, not annoying. That is just annoying. I f* hate the red planks. I think you should keep working. This type of game is highly adictive. I like that you are starting small, and I can only imagine how hard it was to make this small sample. I also love the randomly generated levels. I like minimalist design, but I think you could improve yours. The sky background should be more blocky, like the rest of the elements. The buildings could be simpler, with less windows. The meter numbers could be smaller, and on the right bottom corner. You could also count the cm, in order to make it more dynamic. The game has a lot of problems, but I am sure you can solve them all. I actually enjoyed playing it for a while, and you should be proud. Keep up the good work!
If you're interested in concurrency, Dave Beazley's talk was amazing - he coded everything he was demonstrating live, on stage. Someone on here a few days ago posted a script that lists the Youtube videos from the conference by number of views - that's a very rough indicator of what other people have watched.
Some error handling might be nice.
(c) 2008 and incomplete (see the sections like dictionaries and inheritance are just TOC entries with no content)
Seriously WTF is this site?
Try this BAT file (with your own folders etc) start C:\Python27\Python.exe D:\py\_djm\daily_python_tasks.py I have had similar issues on Windows - some versions work nicely with task scheduler but in one case I could not get it to work, so I made a .NET exe to call the BAT file and that works. https://github.com/acutesoftware/Launch "...for when Windows Task Schedular just refuses to run a Python script"
Reminds me a bit of Open Firmware/OpenBoot. You could boot the computer directly into an interactive Forth shell.
i don't think anyone is actually working on Hurd. I remember reading about it back when my 533mhz Celeron was fast.
It looks like there's a mechanism to declare extra generic classes - see the Node example [here](https://github.com/ambv/typehinting/blob/master/GENERICS.rst). If everything that should match Heap will subclass it, you should be fine. However, your heap type looks like what some other languages would call an interface - it's not an actual type, but a description of the methods a matching type must have. In Python, the normal way to do this is with Abstract Base Classes ([abc module docs](https://docs.python.org/3/library/abc.html)). I haven't read any description of using interfaces/ABCs for type hints. I'd encourage you to ask python-dev about this: someone may well have thought about it, but now is the time to make sure, even if the result is only a decision that they're not supported. I don't think many of us redditors are following the discussion closely enough to be able to provide you with a great answer.
[Image](http://imgs.xkcd.com/comics/operating_systems.png) **Title:** Operating Systems **Title-text:** One of the survivors, poking around in the ruins with the point of a spear, uncovers a singed photo of Richard Stallman. They stare in silence. "This," one of them finally says, "This is a man who BELIEVED in something." [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1508#Explanation) **Stats:** This comic has been referenced 18 times, representing 0.0292% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cqs6nkg)
I am all for supporting small independent artists financially, but the word "stealing" implies that you take something away (i.e. the artists would lose access to their own music), which is a completely different thing than copying. You also seem to have the utterly wrong assumption that if people can't download stuff freely, they will be more likely to buy it. [The exact opposite is true](http://www.theguardian.com/music/2009/apr/21/study-finds-pirates-buy-more-music).
If you already have the separation, and Django is serving no CSS/JS, it makes no sense to involve django-compressor. I only use django-compressor for projects where Django is serving static assets. However, django-compressor doesn't play well with r.js natively. There are plugins; but, I don't care much for either. I simply call r.js externally and compress the resulting file as I would any other via django-compressor. Links to code * [Usage of django-compressor with custom tag for rjs](https://github.com/edx/edx-analytics-dashboard/blob/5c311a5fb1cd982ae63aeffb1bd494c95471cc4a/analytics_dashboard/templates/base_dashboard.html#L80) * [Template tag](https://github.com/edx/edx-analytics-dashboard/blob/master/analytics_dashboard/django_rjs/templatetags/rjs.py)
Shelve forces keys to be strings. DiskDict just stipulates that keys be serializable. Shelve also stores things in a totally different structure. Shelve seems to use various database stores, depending on parameters you pass the constructor. DiskDict mimics a hash table.
https://www.gnu.org/software/hurd/hurd.htmt &gt;The GNU Hurd is under active development. They seem to disagree. But then again, I can claim I'm sexually active.
is there a download button through the ui? no. the site is simply there to let you listen enough to know if you want to buy. you're stealing. 
django tutorial https://docs.djangoproject.com/en/1.8/intro/tutorial01/ AMAZING
Have you tried bypassing pytest and seeing if that improve performance. I've never used it before, but I can't think of any other good reasons why the unittest framework would be taking so long. 
IPython?
Any specific suggestions?
 It depends on how deep you want to go. If you want just a working set up, you could code it within a few weeks, say a month. Most of this time will be spent on understanding the scheme and less time will be taken for coding. I see you have posted in python. It may be good as a simulation platform, but generally you will want to do the final implementation in 'C' with some optimal code. The above is for just a working implementation. If you want the most optimal solution, you will have to spend some serious brainpower on it. I was planning to write a long blog post on it within a month. Haven't decided yet though. Have to consult with someone. If it goes through, you are in luck !! Stay tuned!!
Micropython actually has a Unix port which runs fine on traditional desktop computers. I've been meaning to run some benchmarks on it to see how it compares to CPython, Python, etc. Given that it's designed for microcontrollers I wouldn't be surprised to see significant performance gains in exchange for some feature drops. (It doesn't claim to be fully compatible.) *Edited to not consider microcontrollers non-computers. EDIT2: After some initial testing I have come to the following conclusion: Micropython is virtually always faster than CPython (assuming you can live without all the built-in libraries it leaves out) PyPy varies vs micropython, especially due to its slower startup times, but is faster for longer (&gt;5 second) scripts, especially those with tight loops.
And it is for python 2 and not 3!
Sorry, can't help you much with existing tinyOS projects etc.. Reason is, *blush* I am not a programmer or even much of an engineer. You may have better luck searching github etc.. I have not done much actual implementation for it. I am a mathematician and what I did was an algorithm design for a similar project. It turned out that for that particular situation it was not need to use wireless sensor network algorithms at all, and it was enough to use the algorithms for wired networks. This was why I said it depends on your network features. 
Where do I place that? Before def main and get main to run it?
/r/learnpython
So on the wiki page on Google Code site you never found: * http://code.google.com/p/modwsgi/wiki/WhereToGetHelp?tm=6#Read_The_Documentation which lists 'Documentation Index', which goes to: * http://code.google.com/p/modwsgi/w/list
You have anything like this? http://modpython.org/live/current/doc-html/tutorial.html 
Its okay, thank you :) 
Note that Graham is far too polite to point out that he personally is the author of mod_wsgi. But he's right, what you want is documentation about WSGI itself, which you can find on the site he links to. Another place to look is on the original PEP (Python Enhancement Proposal) that specified WSGI in the first place: https://www.python.org/dev/peps/pep-0333/
Can I use mod_wsgi directly easily (as easily as using mod_python directly), or am I forced to use a framework, that's really the question I want an answer to.
Go to: * http://www.wsgi.org It has a page 'Learn about WSGI': * http://wsgi.readthedocs.org/en/latest/learn.html You should also read the WSGI PEP: * https://www.python.org/dev/peps/pep-3333 as also linked off pages at www.wsgi.org. A search of Google for 'WSGI tutorial' yields: * http://webpython.codepoint.net/wsgi_tutorial
Reading it now, thanks for the links. 
&gt;status = '200 OK' Can you explain this? Why is it text?
Because that's what the [specification](https://www.python.org/dev/peps/pep-0333/#specification-details) says: &gt; The `status` parameter is a status string of the form `"999 Message here"`
&gt; It takes 40+ seconds to run a single unit test Our CMS is written in Django and our entire test suite (with 100% code coverage over ~4000 lines of code) takes less time than that. We're just using Django's test runner with standard unittests.
It copies and pastes all the data into the email for him....
We had a job where one temporary employee had to convert hundreds of images from microscopy slides with a gui tool into a zoomable format, back it up to an external drive, upload it to a web page and enter metainformation into an online form. Conversions took a boring long time (15min per slide) and sometimes error dialogs popped up and borders had to be tweaked. I ~~replaced~~ automated the whole process with python and [pywinauto](https://code.google.com/p/pywinauto/). The employees name was Toby so I named the script toboter.py. Toby was happy too as he could work on slightly less boring stuff ;) 
because micro benchmarks are counterintuative and frequently misleading?
I collect and analyze twitter messages for sentiment for roughly 8000 stock market symbols. I needed to run a daily analysis of all messages for all symbols and then run a bunch of other scripts to create different 'signals' for these symbols. Using multi-threading in python, I run a nightly script that does this analysis using a dual processor Xeon (giving me 24 cores) to update my daily signals and analysis. Additionally, I pull down stock market financial data nightly so this same script handles that piece for me as well. My next step is to rewrite this multi-threading piece to use Parallel Processing (or something similar) to offload the analysis to multiple machines.
There was a time where I found myself working a lot with json and xml, and yes I know there are a million proper stuff that do this out there, but I wanted my own, :P and used it as a learning experience for Google Cloud apps in Python https://github.com/johanvanl/json-alphabetizer https://github.com/johanvanl/xml-alphabetizer Another small project I did (https://github.com/johanvanl/feed-for-twitter), Twitter always provided RSS feeds, which they don't anymore, so I just wrote my own, using the structure I got from https://www.kimonolabs.com/ you should really check this out, if you haven't seen it before, you can actually make your RSS feed or api of choice, and use it from kimono labs, they have nice tools which make it very easy to build these.
I wanted to do something like this too, but with raw stock data instead. Are you pulling in any of that?
Can pywinauto read content from the program as well? Eg from a dialog box or similar.
See edit 1. Is that real code?
The Common Lisp MOP. Or at least the parts that allow new classes of classes and generic functions. No idea about how to do it Pythonically, but it would be nice.
That was some years ago but you could do a lot with it: https://pywinauto.googlecode.com/hg/pywinauto/docs/controls_overview.html Also have a look at [swapy](https://code.google.com/p/swapy/) 
So at my current job we were tasked with creating a bunch of accounts for some unnamed fruity service. Currently there are a few tools available to actually create them, however each id needs verified and when we have ~600 to do, it can take a while to login to email, follow the link to their site, and verify the account. In addition we had another issue where we created about half these ID's but the emails expired so we would need to login to the vendors site, resend the verification, and then verify the account with the new email. So I wrote a script to login to gmail, check the email and if expired send a new one. Then verify the account. This was really cool because I actually had to Reverse Engineer the post data being sent to their servers and mimic with my python script, along with passing cookies around. Anyways this saved dozens of hours split between employee's. As the process gets a little tiring when doing by hand.
 * What is the python version for each, where was it obtained (and thus what options was it compiled with) ? * What is the python bitness (32/64) for each ? * Do you want to know for curiosity or because there is some problem?
Cool, thanks :)
going to PM you to talk a bout cats and stuff.
First of all, I'm surprised you're doing n-body simulation in pure python. Consider looking at numpy, numba, or even pypy. Secondly, technically you are not comparing apples to apples. Osx uses lvm whereas most Linuxes use gcc. While it looks like a reasonable python to python comparison, you're actually comparing compiler optimization from different compilers, whereby the resulting binary is python. Historically, on average, lvm is slower than gcc. Though I admit it's probably been a year or more since I last looked in detail. It could be that this simulation creates a worst case corner for lvm/python. That said, this is strictly a guess if it explains the entire difference but it certainly seems like a reasonable assumption. 
by "raw stock data", do you mean price / volume data? I do pull that daily.
Reproduced the pystone result with a Windows host (110-115k) and a Linux guest (130k-135k) of x64 Python 3.4.3. EDIT: Linux directly on the same host gets 140-145k. That's impressively little overhead from virtualisation. I guess the Linux build is just more optimised.
After hosting a couple of [Euchre](http://en.wikipedia.org/wiki/Euchre) tournaments with friends I got sick of looking for items that could be used to draw straws. I built a program that would take an input of any number of player names, and a desired team size. Each player would be added to a list after a random number, these lists were collected in another list and sorted by the first value. The program would then loop over the larger list and print to my TKinter window a random team name, then the next player in the list with a blank space and new team name after the desired team size was reached. 
did you tell your physics teacher?
atexit https://docs.python.org/2/library/atexit.html Does like END: {} block in Perl. Very useful for freeing resources when a program is killed (except by kill -9).
Every day a TP-Link micro router running python on OpenWRT uses a circuit i designed to open and close the door of our chicken coop. It also provides the images from two webcams to a reflector i wrote in python on appengine. Naturally i named it chicken.py. http://chickenstreamer.appspot.com 
No, not only in the python ecosystem. You seem like a beginner and I don't trust beginners to evaluate the cost/benefit of anything. I liked how your 67% turned into 33% and will turn into another number when you math a bit better. Engineer a complex system and then talk about performance tradeoffs.
We do automated testing of our product in a remote location. Since sometimes things get mangled in the file transfer process, or we need to modify the data files before throwing them in our database, the files periodically get loaded into a buffer directory on our company server. We get files multiple times a day, once every hour at most. Since proper data evaluation can normally only take place once the data is in the DB, this can lead to my boss not knowing if our current batch of product is OK or not. Especially since testing continues during the night and on weekends, where nobody is here to manually transfer the data into the DB and then take the time to evaluate. However, most of the interesting information can be easily obtained from parsing single files. So I setup a crontab to have a python script run once an hour over the directory, look for new files, and generate a report email that gets sent immediately to me, my boss, and a couple of other coworkers (including or logistics guy, who can see if everything went as he planned it). That saves me from my boss popping in every hour to bother me for a quick and dirty data evaluation while I am working on something else. It also makes Monday mornings a lot less stressful because everyone already knows if a catastrophe happened, and can wait for the proper data evaluation to take place when I've had my coffee.
Just had to change this in some old code about an hour ago, ha!
/r/learnpython would be more suited for this question
Eloquent is a new ORM providing a simple yet beautiful ActiveRecord implementation. 
seriously, I would have just bought a new router without even thinking of that lol.
Out of curiosity, why a constant time and not something like "when the last n samples have an RMS of x%"? Or is the settling time short/consistent enough you can just choose a long enough time and leave it at that?
And Pyglet should not be on the list. You could probably get it to run using the Kivy python-for-android tools, but they certainly don't have any support for it and by default depend on Kivy anyway.
I was dating a girl who worked for her dad, an exterminator. It was her job to go to the health departments website, find all the violations of pests in restaurants and stuff, and give them sales calls. The process involved opening and checking a page for each separate business. I had just learned regular expressions and began playing with php so I made a web scraper that listed all the businesses. Plugged them into the Google maps api to sort them all by distance. Listed the phone number and which pest violation they had. It was great except that it was php! I was running it on a lamp VM, not exactly user friendly.
I automated creating App Icons and assets for iOS applications. It takes any image and automatically resizes it to all of the sizes necessary for every iOS device. It scrapes the apple website to get the resolution and device information, then uses Regular Expressions to to parse that info into OpenCV to resize the image to all necessary formats. Its also cool because it organizes and labels each asset image to make it easy to import into Xcode. Its open source and available [here](https://github.com/TheoBrown/iOSIconGenerator/blob/master/IconGenerator.py).
Thanks buddy! It's actually my accordionist gf playing. :) 
I dabble in this and need more sources. Leaving myself a note to investigate later.
Oh, thanks. Didn't know that was a thing.
I have a prototype of something similiar. Instead it scrapes music reddits, converts links to mp3 then rss feeds.
My job is to find recent relevant scientific articles in my field and collect them into a weekly newsletter. The worst part used to be cutting and pasting everything from online to a text file, into a messy HTML template. Now the HTML is generated with python from a plaintext template. This saves about 90 minutes per newsletter (x18 newsletters.)
I made [Titley](https://pypi.python.org/pypi/Titley/1.6) to download and select the closest subtitles for a movies. This program, after downloading available subtitles, will open and extract the subs from archive file, read them and print the time when a moderately long dialog appear in every one of them, so that I can match with the movie file I have downloaded. This was required because sometimes there were no available subtitle for the exact file, and I had to select the closest matching one from 20 or 30 available subtitles...
At work (callcenter) they use a work schedule only reachable in Internet Explorer 6 to 9 really annoying. Basically what I did was make a webserver in Flask that relays requests from ical based calendar apps (Outlook, iOS ...) and logs in, retrieves the schedule and transforms it to an iCal feed.
Put in incorrect info, check which exceptions occur, then wrap them in try/except blocks
Yeah, I initially read it like "tobooter.py" as in "Toby got the boot because of this". 
I use NLTK for sentiment analysis with my own training data set. Honestly, I have no idea about cores vs threads. I've heard different people say different things. All I know is that when my script kicks off, all 24 cores are running 100% for the entirety of the time the script runs. That may mean diddly squat (that's a technical term BTW) for the performance of the script but it is what it is :) 
My job is webdev / sysadmin, I made a webpage to create automatically signature for emails of my coworkers, they only have to enter their firstname, lastname, title and phone number and it generate a html signature. We're also dealing with a lot of wordpress, so I wrote a web app to create a new clean wordpress website automatically, it creates the vhost on the server, reload apache2 config, the website directory, the virtual FTP user, sets the rights and owner for the files and directories, creates the database and the user, generates random passwords, create the admin account for wordpress in the database, install the base plugins and append the Google Spreadsheet with all the info about the website. I also wrote a Python script to backup the websites and the databases automatically each night. Finally I made a web app to monitor the server in real time (the bandwidth, the disk space, the processor usage, etc...) There is still plenty of room for automation but I don't have as much time as I'd like.
You need to automate someone else's job so they can work on it. 
Here are a couple of factors that come to mind: 1) CPython on OS X (from Apple and python.org) are built with Clang/LLVM instead of GCC. Not to get into a compiler war, but GCC generates faster compiled code and has a large advantage at higher optimization levels. 2) The Ubuntu packagers might compile with more aggressive flags. 3) CPython's memory manager may perform better with the memory subsystem on Linux. 4) Your hypervisor may be helping Python performance possibly by keeping contiguous segments of memory assigned to the VM and then interpreter. There's practically no memory access overhead for VMs on Intel CPUs with EPT. It's almost certainly a whole combination of factors some of which haven't been listed. However, it's definitely memory performance that's causing the performance difference. I bet the single largest explanation are the compilers and compilation flags used. 
Custom scripts are always cool, but you might want to dig deeper into Jira before going in too deep with your GUI. There are quite a few plugins available for customization. The filtering tool is also pretty powerful. You can create a filter with an SQL like syntax, save it and share it with team members. 
[Literally the entire plot of a book I read as a young'un.](http://en.wikipedia.org/wiki/Danny_Dunn_and_the_Homework_Machine)
i have a couple: 1. at my job we need to run some SQL and export it into excel and do work in there with macros and ship those reports out to the customer. well i need to generate 8 different reports myself, which takes about an hour to generate total to just generate everything. the macros add another 40 or so minutes to this process. so i wrote a python script that does it all for me - writes the sql, generates the report in the appropriate folder, applies and runs the excel macro, saves the file, then when all of the reports are finished it creates appropriate outlook emails that lets me edit the message before sending to each customer 2. another process requires a report thats created in Tableau to be generated for over 350 customers, all with different data. so i have a python script that accesses the report on Tableau server, passes in the parameters it needs, and generates that report as pdf, and ships it all to an off-site ftp box
This is so mundane as to be embarrassing. A script checks stock closes for the day and updates a DB so I can get a monthly P/L statement. The interesting part was how to calculate ROI when there are buys and sells.
We nicknamed him toboter (from German Roboter) because of the monotonous task he was performing.
Bugs from what? JS compressors don't break your code..
Only semi-related, but back a few years ago, I downloaded a lot of movies and TV shows, and they were all scene files, so you had that sea of rar parts. I wrote a script that automatically checked all my downloads, automatically detected if they were a show (which were auto dled through RSS) or movie, extracted it, got rating/info from imdb, automatically archived tv shows in the right show/season folder, and did all sorts of clean up. It wasn't anything crazy, but it was actually my very first real Python script, and it's how I learned the language. It was definitely a fun project, although looking at the code, I've really come a long way since. 
Both are on my list to review. Thanks.
I made a script scrape a random picture (in the top 20 posts) of /r/wallpapers, download it, and set it as my background. I used Windows Task Scheduler to run it every time my computer was idle for &gt; 10 minutes
The ability to have real background tasks (celery) and use a database other than mysql (postgres) would be attractive for me. As would the ability to modify the code without having to learn php and being able to deploy it along with the rest of our application on uwsgi
Not for me, but my buddy. We're both in Portland and really into craft beer, but got annoyed with checking each bar's website for new stuff being tapped (and they would never update their Taplistr / Beer Menu lists). He wrote a python script to check every bar's website every 2 minutes and check for a changes to their taplist. If something new was tapped, the script sent us an email / text. Shameless plug: That script eventually turned into [Brew Notice](https://brewnotice.com), which lets anyone sign up to get beer notifications.
Don't use it anymore, but before they had automated investing, I wrote a script to automatically invest in lending club. This sounds scary, but it was actually quite simple. Lending club lets you buy small portions ( as low as $25) of loans they give to people. They grade the loans based on risk, which then determines interest rate they also have some small text describing the loan. I knew what distribution of risk I wanted, but it was hard to get the good high risk loans because hedge funds would snap them up, so if you can't beat them, join them. I learned when new loans were posted, and the script would run then, look at new loans, filter out some keywords (I only did personal loans, and nothing with the word wedding because I feel like it's a terrible sign to take out a multiple tens of thousands of dollars loan for a wedding). Then I would fit what was left into my distribution and buy remaining loans (assuming I had the cash for it in the account). In the early days, the number of loans was very limited, so I'd be lucky to be able to buy more than $200-$300 worth in a day, so this script saved me tons of time. Then I could toss extra money in every now and then and not think about it.
[Second post] I've also created a python script to browse OKCupid for me. I noticed that every time I'd browse around I'd get some kind of interaction, likely because I was being promoted over other uses because of recent activity. I made a python script to click random profiles and tell me if our match is over 90%. I don't send messages or anything, but I've noticed just hitting a ton of pages gets me a lot more messages and likes.
You should be using homebrew to setup your dev environment in OS X. Installing python this way is much cleaner as pip is setup for your user space automatically rather than system wide. http://brew.sh/
The only significant thing I've written in Python is a Blender script that assembles and renders every combination of options and colors for every one of our products from a few angles. Currently it produces about 41,000 images. The code is nothing pretty, just one big procedural source file. When we had just hundreds of options, we had a 3D artist creating them manually, and for a long time he kept up, but one year it grew out of control, and to deal with the backlog I inadvertently scripted him out of the job.
Uh. There is thing called source control. You may have heard of it. You know TFS, Git, SVN, been around for like a 40+ years...
That sounds interesting, why do you do it? I mean just getting and analyzing the data is just the first step right?
I am using the naive classifier using my own training data set. It has given me pretty good accuracy so far. That said, I'm branching out into other approaches (SVM, etc).
Yes, I currently have a python script (Scrapy-based) mining the profile data 24/7. I found the same result with just viewing lots of profiles, even as a male.
I am the 'sole' developer on a team (my boss codes but he does more writing about 'our' / his research) So my boss tends to tell me to do stuff by hand and being the lazy jerk I am, I spend time writing a script to do stuff for me rather than by hand like my boss suggests which is hilariously horrible for me because I am paid by the hour, but again: lazy jerk. One of the projects actually ended up getting distributed to a few other departments because it was a solution they had wanted for a while and had been doing by hand. Which terrifies me to no end. And because of this script, I get pulled into other weird desires they want but can't figure out how to do. Others are things I keep 'secret' from my boss (He knows they exist but he has never asked to have them for himself) The one that got distributed opens data files, finds a... uhm... certain parameter (not sure how much I am allowed to say), measures for a certain level of 'certain parameter', outputs if the level is over a certain set percentage. It sounds simple but there is more behind it, it is a special data format, etc etc. The data it goes through is essentially tables with 1,000+ rows and I was supposed to look in a long string for certain keywords... by hand. All of them are basically in the same vein. It runs on huge amounts of data which I get a kick out of watching. Right now I am actually 'adapting' it to run on a cluster. The others are just one-offs that turned into scripts I distribute if people ask or I can adapt the script to their work. Basically they manage the large amounts of data. My boss asked me to get a bunch of data, download it and rename it, again by hand. I wrote a script in an afternoon. It does in about 5 seconds what would take hours. One of my new co-workers (grad student, doesn't code, does analysis) was told the same thing, he did it by hand, I apologized when I saw he had done the work by hand.
Because, as I wrote, the errors are handled to my satisfaction by the upstream libraries.
If you want to adjust game settings, enter the konami code on the main menu.
Yes, I understand this. I was just a little confused by wording ' dual processor Xeon (giving me 24 cores)' like it gives him lots more of processing power. It just becomes faster because there was I/O speed bottleneck and now there isn't. My bad.
That's pretty nice.
Careful not to put yourself out of job ;) 
Hooray! This looks like it was a lot of fun to create and build. Keep up the good work! :)
Right. This is just the first step in many that I take to try to find 'signals' to enter/exit the stock market. Also, this is a continuation of my doctoral dissertation work which looked at twitter sentiment and its usefulness in making stock market decisions.
no one is going to put the guy automating his job out of work.... they will just use his skills to put others out of work.
Also leaving myself a note to check this out again
There used to be some GUI app for this, most of a decade ago now. I knew it wasn't going to last long, and I don't think it did. I can't remember the name now, though. You just checked shows you liked, and it did all the work for you, 'round the clock.
If you are really interested in speed for python you are better of with cython or pypy or whatever. I mean 30% speedup isn't bad.. but speed isn't one of the compelling arguments for python.
A twilio script to tell me hello have a great day in the morning becuz every1 moved away :'(
"Guys, check this out - infinite_monkeys.py"
Hmm. I have heard people have used GitHub to collaborate on writing projects but not sure on the specifics of it. Just a suggestion. I wasn't trying to be mean or anything, it just sounded like a incomplete solution for something that has been solved a lot before.
I do not save the match% because I am mining from a throwaway account because I didn't want to risk my main account just in case OKC staff find out. :)
Yea, that'd definitely be a bummer. I prevent that by basing the script in Selenium (which automates browser actions). After each action, the script waits a random amount of seconds between 1 and 5 the carries on. I run it on my home's media server while I'm at work, so no issues in terms of taking up browser space.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
I have a script in cron that parse how much bandwidth I have left from my ISP's website every 30 minutes. That script then POSTs the result to a web app(flask) that persists it to disk(sqllite). The web app has fancy graphs and exposes the latest result with a Web api(just a json with last date + bandwidth left). I then have a bunch of other scripts running on various boxes (home server, mac minis on my TVs, macbook, SO's macbook) polling that API once in a while to see if they can do whatever shenanigans I want (start/stop torrents, go pick new torrents at random if I have enough bandwidth and its the end of the month, pop a warning for my SO watching HD streams). 
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Ty very much the feed back is appreciated. I am likely to give this game a second try and I probably will implement most of the things you suggested at a later date. You do have a good point with the jumping mechanics, i was looking at using a maths "SUVAT" based equation to calculate velocity etc.. but I ran out of time.
Why don't you just use an RSS reader? That's what they are made for an they have Chrome extensions to show how many updates you haven't read. Edit: [Chrome Extension](https://chrome.google.com/webstore/detail/rss-feed-reader/pnjaodmkngahhkoihejjehlcdlnohgmp)
Sorry, that was a bit of a mess. With 8 BB effective you can still have shove calling ranges outside of Nash equilibrium in hyper turbos which is the game type I play. 
&gt; The code works perfectly fine in Python 3. This means "input doesn't execute whatever is passed in from input() in python 3," correct? From 2 seconds of testing it appears like that's the case, I just want to make sure....
I recommend you keep working oh this project... do not abandon it! And post updates. You can comment in my comment so I am notified :D. I'll be happy beta-test your game. 
Yes. In python 3, whatever line is entered is returned as a string without a trailing newline. If your system has readline, it is used to provide various editing and history features.
why can't you check it into your own branch?
Domo arigater, Mister Toboter
~~A post-receive git hook to deploy, and if relevant test, code depending on the branch being pushed.~~ Never mind I thought I was in /r/programming 
Do you use a production web server while developing? A production WSGI server? Are you running SSL? Are you sending your test emails through your actual email infrastructure? There's so many things which change from development to production, it's just the nature of the web. As long as you know your stack works correctly and everything produces expected results, I don't really see what the issue is.
Do you have a link to the source code? I would love to take a look at that
And that my friends, is why the market crashed a few years ago.
Not necessarily a daily task but... Old, homegrown tool X contained data that needed to get entered into a database. But before an entry could get entered into the database it had to be populated with additional information that tool X couldn't/wouldn't export. Someone would export information from tool X to a CSV, manually add certain values and then run a script I wrote that would set certain values based on information provided, format dates and numbers a specific way and then insert the data into the database. It was still a super ugly hack but it did what the customer wanted...
You might want to check out [Pandoc](http://pandoc.org/README.html) in case you don't already know it. It is like a swiss army knife for text conversion. For example, you can run the program to generate a html file that includes your toc and text. You can even specify a css-sheet that the html file should use and so on.
This is my favorite
Thanks for the confirmation!
I try to never do anything twice. 
Now he is Kunta Kunta.
Is there a way we could access your dissertation? It sounds like a fascinating topic I'd like to read more about.
PyVmMonitor is an amazing contribution, unobstructed profiling, seriously cool
are you using the vim plug in within pycharm? 
Except its really not. This was 4 times a day max, it only buys (doesn't sell) and wasn't trying to learn anything or make any decisions on its own. It was a very simple automation of a repetitive task. 
I've used Grunt a lot, I understand they're very similar. Is there an advantage to Gulp that you know about?
Ahhh, good ol' *import friends*.
Yes, [here](http://ideone.com/42nnxk) is the C++ source, and here is the header: --- stdafx.h #pragma once #include "targetver.h" #include &lt;string&gt; #include &lt;fstream&gt; #include &lt;windows.h&gt; #include &lt;curl/curl.h&gt; #include &lt;jpeglib.h&gt; #include &lt;csetjmp&gt;
That sounds like something I would really like to run, but then the first 4 hours of my day would be spent on XKCD...
Awesome, thanks!
 try: print(StrategyCalculator(hole, board).best_play()) except NoIdea: player.ship_it()
And flexget(pyhton) 
Twas a joke about your script causing it. :) But buying and selling debt was the main drive behind the crash.
If you don't want a full stack framework, bottle is a python lib that will make you task much easier, and is so small that it fits in a single file. You don't even need to pip install, you download, you keep the file next to your script and you just code your service.
Check out greenlets too. The GIL is going to prevent native python computational heavy code from benefitting from parallelism but I/O bound code (any Internet requests included) or calling native code in C/whatever can greatly benefit from something like greenlets.
Nope, it's an Intel.
I used to do helpdesk and got sick of walking around to all the printers and checking toner, paper, jams, etcetera. So I wrote a python script (originaly in PHP, but re-wrote in python) to scrape the printers pages and gather the date, insert into a MySQL database and then a PHP front end to organize it all and show pretty google cart graphs of all the historical data. I ended up calling it PrinterStats, and made a few modules to support different printers. HP LaserJet 4200, Ricoh 8200, and Ricoh 8300 are the only ones supported because well those were the only printers I needed to watch and had network support on campus. I left the job 8 months ago and have not really worked on it since, and don't even know if its still running at the school anymore either. All well it was fun to make. Github: https://github.com/RIEI/printerStats
I'm currently searching for a new job, and I got tired of looking though the same webs everyday, so I wrote a script to scrape my favorite job websites' search page for anything posted in the last 24 hours, and then refine the results further using by searching for keywords in the job description, before e-mailing me the results as a list of links.
Thanks. Will do.
i plan on teaching my sister how to code (she is 5 now) when she gets to elementary. Just so she can automate her homework by the time she hits high school. Also, if she is the next Zuckerberg, she can buy me a house. 
Look also at pyautogui 
Huh, I might have to read more into crontab. Looks like a great way to automate a ton of stuff
My boss kept getting on to me for not logging my time to Jira. So wrote a program that pops a Tkinter window with a list of tickets that I have set to in progress and tickets that I modified at some point during the day. I can then enter my time into input boxes on that window without ever even having to open Jira or remember my ticket numbers. I now have the best time recording in the company, have not missed even an hour of logged time for the past 8 months.
It's not finished yet, but I'm making an API for my home domotica. It should warm up my house when I'm coming home from work, turn on the coffee machine when I get up, turn off the lights when I'm going to work, etc :) Yeah, I like automation..
I love python, but one way of doing is page2rss, which makes a feed of anything. 
&gt;I want to mach the different elements in the arrays so that I can substitute them with instances from a database. You probably want re.sub for this, since you can do the substitution directly. Eg: # This function gets called for every match def subfunc(m): text, type, textid = m.groups() replace_string = get_string_from_db(text, type, textid) # ie. whatever your db lookup does. return replace_string r = re.compile("\[(\w+)\|(\w+)\|(\w+)\]") new_string = r.sub(subfunc, u' [Agitar|Action|shake] y [colar|Action|strain] en una [copa de c\xf3ctel|Glass|mixing-glass]") You may need to alter it, depending on the exact details of your string format (eg. is it always [a|b|c] - can one or more be omitted? Can the text contain a literal "|" character, and if so, how is it escaped? But if it's just a dead simple "change all things of the form [a|b|c] to something else, the above should world. Unicode shouldn't really make a difference, at least for the regex side of things, 
My system is based on a version of Markdown that I've customized specifically for novels. I don't know who Mark is though, so I call my format Jeffdown. :-)
Alternatively if you're using a linux distribution with systemd, you can use a systemd.timer. Cron is probably simpler, but systemd gives better integration into the systemd ecosystem. Some would call that a positive, some a negative.
I wrote a script that will take out all of the necessary punctuation in downloaded media files and sort them into folders, creating folders whenever necessary. (Drive/ShowsFolder/Show/SeasonX) Its more of a person script that I use like, once a month, but I like it!
If not, checkout autoit.
This isn't a daily thing, but after changing computers several times and moving files all around over the years, I knew I had a ton of duplicates in my photos and music directories. The problem was the files were renamed. I watched a Raymond Hettinger talk and he solved my exact problem in 1 slide by recursively walking a directory and building a dict of {md5 hashes : [filenames]}. I modified it to run faster by first looking at file sizes, and only building the md5 hashes of groups of files that had potential duplicates based on size (as well as adding a couple command line arguments to play with argparse). I still chose to go through and fix all the duplication manually (I'd rather do that than lose data), but it was still super helpful. Edit: Now with more git: https://github.com/RPFeyn/duplicates Warning: I only tested it on Linux. Additionally, reading my code too closely may give you cancer.
I made a script that does two things for my company. It checks our support email and creates tickets in Redmine. And if any developer on our team writes a ticket number in his todoist account, it automatically fills in all the details and converts the title to a link back into Redmine. 
I'll keep that in mind, thanks!
I enjoy browsing music and often have to look up info on obscure bands that can be found in Metal Archives. So I wrote a python script that scrapes band's info with a summary on discography and lists additionally similar bands (that's LastFM with [pylast](https://github.com/pylast/pylast)).
A lot of those sites have RSS feeds. Without doing any research, I feel like parsing the feed would be easier/simpler than scraping.
There was a kickstarter a while back developing a teaching package for kids to learn programming with Python. It was 'something'-box but not sure the exact name.
I wrote a script that automates a weekly newsletter that we send every Sunday. Saves me about an hour every week from doing it manually + writing the script was a lot more engaging than doing the task!
No. CoffeeScript relies more on Ruby's cleverness than Python's readability. RapydScript is pretty much like python: https://github.com/atsepkov/rapydscript or https://www.rapydscript.com/ it's newer but has the tooling to get you started: js2rapyd, gulp, grunt, vim, emacs, atom, django-pipeline packages. but: it has no source map nor repl yet (the author wants them). reddit: https://www.reddit.com/r/Python/comments/2xcjht/new_website_for_rapydscript_the_pythonic/
[Obligatory.](https://xkcd.com/1205/) 
Read the docs: http://docs.sqlalchemy.org/en/rel_1_0/
AutoIt syntax is fantastically annoying in many cases. I ended up rolling my own (limited) Python implementation of certain features I thought AutoIt was severely lacking in.
No.
[It looks completely fine in Python.](https://www.dropbox.com/s/xm4vbjbwi5o23n3/Screenshot%202015-04-29%2020.28.08.png?dl=0) Can you specify/explain the problem you're having? 
&gt; native python computational heavy code oxymoron
Try it in Python 2.7. Thanks to u/pau101 I figured it out, I needed to have # coding: utf-8 and a 'u' before any string that might have a long marked vowel in it
In the action dialog for your windows task: * under "Program/script" use quotes "C:\Python27\Lib\site-packages\package\run_script.bat" * under "Start in (optional)" do not use quotes [this is not actually optional] C:\Python27\Lib\site-packages\package contents of run_script.bat: cmd \K python C:\Python27\Lib\site-packages\script.py the "cmd \K" will leave the command prompt open after execution The final step is to then switch to Linux :)
No problem, I don't mind ;) Although (for reference) there was a [question/answer like this](http://stackoverflow.com/a/9365363) on StackOverflow; if you have a question you can try to search it up [there](http://stackoverflow.com/) first. A hint for searching: Add '[python]' to the beginning of the search to search only Python-tagged questions.
Using zip to iterate through multiple lists simultaneously A = [1, 2, 3] B = ['A', 'B', 'C'] for a, b in zip(A, B) print(a, b) (1, 'A') (2, 'B') (3, 'C') 
You can get quite clever when unpacking sequences. Suppose you have a sequence and want to group certain parts. You can do something like this: seq = [1, 2, 3, 4, 5] a, b, *c = seq Now a = 1, b = 2, and c = [3, 4, 5] You could alternatively done something like this seq = [1, 2, 3, 4, 5] a, *b, c = seq Now a = 1, b = [2, 3, 4], c = 5 If you had wanted to discard the last three values, you could do this: seq = [1, 2, 3, 4, 5] a, b, *_ = seq All of this unpacking will work with tuple, sets, and strings as well. If you unpack multiple items in a single element using the "*", then the resultant variable will always have a list type, regardless of the sequence type you original unpacked (it might have been a list, tuple, or string). For any given sequence, you can only use a single starred variable when unpacking. The interpreter will not know what to do otherwise. The only exception to this rule is when your sequence contains other sequences, like a list containing two integers and a tuple, but I'm not going to cover this case. EDIT: Fixed the syntax on the first example so the asterisk was a prefix 
I sat down in front of the TV and watched Mike Bayer (the author of SqlAlchemy) on YouTube do a 3 hour tutorial. Just search YouTube for SQLAlchemy. Time well spent. The key thing you need to understand is where to focus your learning effort. SQLAlchemy is broadly divided into the core and the ORM. The ORM does things in a more abstracted manner, designed to be easier to code in a Python-like style. The core is more about writing directly to the database and is closer to the SQL. Choose one or the other up front and focus your learning time on that. 
You might find the pyparsing library is better suited than regexp for this task. 
But thats no fun!
You can also use something like dataset to have an even higher level of abstraction over SQLAlchemy.
Found the F1 driver.. But really, does anyone have a good resource they have used to learn this type of python scripting? I'm looking for something targeted at an Infrastructure engineer. 
fromos :)
Checkout [pywin32](http://docs.activestate.com/activepython/2.6/pywin32/PyWin32.HTML) . really good for automating Windows GUI applications. There's also [sikuli](http://www.sikulix.com/). It uses jython instead of python and image recognition to hook into programs. What specific uses are you looking for?
Flask is a framework that requires python 2 or 3 to run. Start with python 3 unless one of your dependencies requires python 2. 
Primarily, I am looking at Cisco UCS Manager / Director related tasks. But I am also looking for things that are more relevant than finishing with a game like learn python the hard way. 
Looks great! Good job!
Could something like [Puppet](http://en.m.wikipedia.org/wiki/Puppet_%28software%29) or [Chef](http://en.m.wikipedia.org/wiki/Chef_%28software%29) be of use to you? After a cursory google search they both seem to work with Cisco ucs. 
Roald Dahl wrote a story about that. Automated Grammatizer I think.
I do SymPy development and while it does syntax highlighting, that's all it does. I tried to find a jump bar for functions/classes, but couldn't find one. For me, that along with syntax highlighting are the basics I need for a Python editor. If they could pop up an iPython notebook in the second pane like the Markdown preview, that would be great. I'd love to work in a notebook session and edit a module in the other. That facility would provide a good way to try out changes to a module.
What are you stuck on? I assume you're using sockets/threads to send data, and pyaudio to record/play. So you can record audio, send through a network socket, receive on the other end, and play back. Why can't you do that to two computers? Record audio, send through two different sockets to two receivers. Or on the other end, receiver receives audio from two incoming sockets, and plays both back at once. I'm assuming pyaudio can do multiple simultaneous streams; if not, you might need to merge audio (not sure how).
Really cool! Good job!
Yeah I was wondering why Pyglet is there since, as the article points out, it "runs on Microsoft Windows, Mac OS X, and Linux" (and therefore not on Android).
PowerShell is great but IPython/ipdb is greater. If there was a nice REPL with tab completion for PowerShell I'd use it more. Using ipdb to hook exceptions in python is just gravy. from IPython.core import ultratb sys.excepthook = ultratb.FormattedTB(mode='Verbose', color_scheme='Linux', call_pdb=1) It got to a point where I just raise exceptions when I am developing a script instead of printing.
Python has a global interpreter lock that does lock threads to a single process. You could create 24 processes to make it genuinely parallel (and in python people often do), it just isn't as efficient memory-wise as a true multithreading environment.
I mean that's the most obvious one. Was hoping for something else a little more guided. 
I edited the original to add detail and link my github repo for the project that I just threw up. See if you can make anything from that.
Buying debt had little to nothing to do with it. It was the excessive debt creation that was a problem.
Actually I am from the Netherlands but I really appreciate the offer. :)
Much appreciated! :) 
That's what zip is made for.
I think the problem Conan1234 is trying to address is: fruit_name = 'apple' ... lots of code if order.isOrange(): fruitname = 'orange' print(fruit_name) The bug is that fruitname is not the same as fruit_name, so the logic is busted even if the program is legal. Declaration solves this at compile time, not test time
I'm working on a follow up post about performance for the weekend...so far, I think Whoosh is great, but it's not designed for the scale and depth of engines built on Lucene (Solr, ElasticSearch). What it lacks in features and scalability I think it makes up in simplicity. Setting up a Solr instance correctly isn't trivial, ElasticSearch is a lot better but with both you have to remember you're looking into managing a whole separate search server from the main application. I guess I'm more of a developer than an IT guy, the idea of tons of database and search servers for my little do-dad projects seems really unnecessary 90% of the time :) Tomorrow I'm going to test it against MongoDB's search :)
Venmo removed the trusted feature which I used a lot with my girlfriend, so instead I wrote s script that checks for payment requests from either of us and automatically approves them: https://github.com/flxfxp/venmo-autopay
Where I work, we have a lot of software installed that users can use a program called modulecmd to keep track of. A lot of these programs like to put config files in the home directory which bothers me because I like mine to stay clean. So I wrote a program that would make a pseudo jail. It creates a new directory, simlinks some things from your home in to it like your ,xauthority so x forwarding works, then module loads the program for you and either starts it (guessing the name from the name of the module) or just gives you a shell in a semi protected environment. Kind of like virtualenv, but for home directories and not python paths. It saved me some time.
Here's one that blew my mind. Say you have a list of lists, e.g. rows in a csv file. How can you transpose them, so that you have a list of columns instead? And then get a column wise sum? cols = zip(*rows) sums = map(sum, cols) (There are better ways if your dataset is real big, obvs)
wow, thx for the snippet.
Looks cool, I'm commenting to find this easier later on.
Plus, it's ten minutes of activity but a much longer time when measured in loss of productivity. It could easily be a half hour to switch back to your normal work and get up to speed again.
You should look at the freeswitch project, for inspiration, or to hook into your python. 
I read a lot of manga (japanese comics). I mean a lot. A LOT! So when I started reaching 50 series, I started forgetting their titles, missed out on updates, etc. The site I was reading them on publishes all updates as separate RSS feeds, so I wrote a python script triggered by crontab to parse all my feeds for updates and store the latest update timestamp in a postgres database. Then I wrote a cherrypy website aggregating all my updates along with simple administration functionality. It works great, and I start my commute everyday by looking at the site and reading the latest chapters. I'm a 89 series now and counting :)
It's for python3.
If you do a lot of this kind of stuff, you might find numpy to be useful. Imho, numpy is incredible.
It's still good.
Instead of writing a function that returns a list or other sequence, write a generator, and wrap the call in `list()` or whatever.
This is seriously my motivation for so many scripts I've written. 
I wish you the best of luck obeying "the law" (which is the same in every country and universally right, as we all know) and just calling people assholes instead of replying to their arguments.
I have a shitty Ubee modem/router combo from Time Warner. Every so often, my shoes will drop from 110 Mbps down to like 3 down. I wrote something similar and stuck it in the crontab of my Linux vm. It does a cli version of speedtest.net's test every hour or so, and if it's anything lower than 50, uses beautiful soup to log into the router and reboot it.
Similarly, I often use: for k, v in dictionary: something tallying v something manipulating a lost of k something displaying v, k I use it often for keeping track of things. It's pretty basic, but I'm still a novice programmer. 
Yeah, that's what I do too. But not everyone is so technically advanced to know how to do that.
Daily.. well, maybe not daily. It used to be daily when bandwidth was less plentiful. Is still relevant when torrenting: * I wrote a little script using `mechanize` that logs into my ISP and checks **bandwidth usage stats**, calculates a few things based on those, pops them up in a notification box. I've written some not-exactly-daily stuff, eg: * I made a **4-character-"UUID"** system so that I could 'uniquely'\* identify files I used as refs for making art (rather than writing down some long path that couldn't fit in the spare space anyway, ugh -- I would never bother noting refs in that case). It basically takes the (SHA1 / SHA256/ other strongish hash of choice) hash of the file, takes the first 24 bits (6 hex characters) of that, and encodes that in base-64 to arrive at a code like 'uLlv'. \* collision chance about 1 in 2^23 (8 million), I guess. It accepts the tiny chance of getting 2 or 3 files instead of 1 when you look up a given hash, in exchange for convenience and brevity. * **Reviewing scans**: I wrote a little thing that recursively finds all the images in a directory, then flings that list at sxiv for reviewing. After sxiv quits, it waits 5s and then does the whole thing again. This is good to run before you start scanning a document set, it makes it easy to confirm that everything has been scanned and looks correct -- as well as to make simple adjustments like correcting orientation where needed. You just quit the current sxiv instance whenever you feel the need to review the latest scans. 
We had to add a bunch of additional information from the rows of an Excel sheet to the first page of a pdf document (reviewer marks and comments, presentation category, type of presentation and stuff like that). I automated it using a combination of PyPDF2 and FPDF (one can generate new pdf pages, the other can only read and write existing ones), pyoo (for reading data from libreoffice docs) and pandas (to allow for arbitrary grouping of the documents). The output was a single file ready for double sided printing (new docs on right page). It ended up being a one time job so I might actually have spent more time on programming than I would have on "just doing it", but this way I learned pyoo, FPDF and PyPDF2.
Note how zip truncates to the shortest sequence; you can map with the None parameter to replace missing values with None: In [163]: zip(range(2), range(4)) Out[163]: [(0, 0), (1, 1)] In [164]: map(None, range(2), range(4)) Out[164]: [(0, 0), (1, 1), (None, 2), (None, 3)] 
Most likely it's due to naming choice. I reckon the sort of a language-joke in "vai" for the Italian speakers but I'm not sure how appealing it is to the English ear; "pyvim" is instead what an user would expect for "vim clone written in python". This is the fourth time I'm writing this comment since I kept pressing \^-W near the end to correct some word. Hope this time I make it... ...and done.
I like to use the decorator syntax to quickly spawn threads: import threading def spawn(func): thread = threading.Thread(target=func) thread.start() return thread @spawn def task(): ... do stuff in a new thread ... task.join() Or, with Python 3: executor = ThreadPoolExecutor() @executor.submit def future(): ... do stuff ... 
Very much +1 this. You could have a significant community of experienced and budding writers using and enhancing these tools. On the other hand you might get a significant community ... to spend time on :). But I myself would love to see what you've written!
This sounds really useful! I tried to give it a whirl, but it appears to rely on PyCV, which itself relies on old versions of numpy, scipy, and a few other libraries. When visiting PyCV's homepage, the following message can be found: &gt;Thanks for interest in pycv. However, I'm sorry that at the moment pycv is not working. Basically, pycv relies on old versions numpy, scipy, and opencv. Time has passed and these packages have evolved. But pycv has not. This is because every team member of the project has left, I myself have moved to a new university. The funds for the project have run out. &gt;I guess it's safe to say that pycv is for now inactive until I can get funds to continue its development. Which certainly puts a damper on things.
No. Also, it's not Peel. You may want to look at a linter, like pyflakes. 
You can use `zip(*[iter(s)]*n)` to cluster a sequence (or any iterable) into n-length groups: &gt;&gt;&gt; s = [1, 2, 3, 4, 5, 6] &gt;&gt;&gt; zip(*[iter(s)]*2) [(1, 2), (3, 4), (5, 6)] See this [Stackoverflow page](http://stackoverflow.com/questions/2233204/how-does-zipitersn-work-in-python) to understand why it works.
But Tryton comes in addition with a sets of generic modules for common business requirements like sales, purchases, stock, accounting etc.
I agree with this. However I'd almost definitely say that Lucene is a little overkill for smaller sites. When you've got one or two servers (plus CloudFront/CloudFlare for CDN) and haven't yet got to the point of scaling out with an LB and database replication, adding another server for search is probably getting ahead of yourself. Start small, run Whoosh on your web app server, keep your code modular and if the time comes to scale out, consider rewriting your search module to use Lucene.
can I ask why? or is this just referring to exponential increase?
 collections.defaultdict So for example: import collections d = collections.defaultdict(int) d["x"] += 1 instead of: d = dict() x = d.get('x', 0) x += 1 d['x'] = x 
&gt; If more than one sequence is given, the function is called with an argument list consisting of the corresponding item of each sequence, substituting None for missing values when not all sequences have the same length. If the function is None, return a list of the items of the sequence (or a list of tuples if more than one sequence).
Just generally cleaner code - you conceptually separate the process of determining what goes in the list, from the process of actually producing it; and get to do that second part more simply than otherwise. It's especially noticeable when the algorithm for the first part is recursive.
Correct, Python 3's `map` does not support a `None` "callable" anymore (though `filter` still does). An other difference is it stops when the shortest iterable is exhausted, like `zip`. For the behaviour indicated by /u/qiwi, you really want `itertools.izip_longest` whether in Python 2 or Python 3.
I like to use `filter(None, iterable)` to quickly filter out false-y values from iterables. And I like using `textwrap.dedent` when including multi-line text literals in code. As an example using both, to remove empty lines from some text: filter(None, textwrap.dedent(""" this is a lot of text """).splitlines()) 
I've automated similar tasks. The packages in my case came with a bar code, so I made it possible to scan the bar code and automatically to print out the correct label. Saved some time but especially reduced the possibility for human errors.
I've said this before, but I see use cases for both onbreak and nobreak, so I can never remember which one else actually refers to. For me, it would be an onbreak, why would you need to do anything else if your loop completed? For this reason, I steer clear of this.
Nice idea! 
Same difference between `range` and `xrange`. One produces a list, the other produces an iterator.
It's worth getting familiar with the whole `collections` and `itertools` modules. Lots of useful little nuggets in there.
when I want to dump the values of a variable and am too lazy to write print(var); I write print ,var with a space between the 'print' and the comma.
Why not just filter with bool? More people would understand what that's doing IMO 
Cool, thanks!
&gt;or is this just referring to exponential increase? Yep.
As a student finishing his class projects, this is dangerous.
just learned 2 new things!
Using with to open files. with open(filename) as f: data = f.read() fiddle with data More info [here](http://effbot.org/zone/python-with-statement.htm) Disclaimer: I am in NO way a python pro, just happen to think this is an elegant way to do this. 
TIL. Also, what is this Python 3 people talk about?
I think Stackless did away with the GIL? Dunno if it has TCO, though.
Also, one exists in Python3 (`range`,`items`) and the other doesn't exist in Python3 (`xrange`,`iteritems`). And the Python3 symbols that exist (`range`,`items`) are iterables. EDIT: was iterators, thanks /u/robin-gvx .
If you want your module to have an `__all__`, but you hate keeping it up to date: __all__ = [] def export(thing): __all__.append(thing.__name__) return thing @export def func1(): pass @export def func2(): pass def not_in_all(): pass @export class Foo: pass 
Python 3 is the current series of Python. All new features will show up there, and most effort of the Python devteam is focused on it. Python 2.x is the historic series of Python: No features are planned to be added to it, only bugfixes. Though some backports of 3.x features have been done. However, partly because Python 3.x is not fully backwards compatible with Python 2.x, and partly because getting a package version upgraded in a corporate environment is rather difficult, and partly because some people disagree with choices Python3 has made, many people are still working primarily or entirely with 2.x. The Python wiki [has a page](https://wiki.python.org/moin/Python2orPython3) which explains in more detail.
What? How does this work? It'd just create a tuple of the function print and the variable var
Uses way less memory and it's usually faster. 
Whoosh helped me in a work project so much that it became the center of the system. For that I am thankfull that it exists.
For iterating over blocks of a file: for block in iter(functools.partial(file_handle.read, 1024), ''): print block This avoids having to check if .read() returns an empty block at each pass through a while loop, which is what you normally see: while True: block = fie_handle.read(1024) if not block: break print block
So what does that mean? 
 d={1: 2} print,d (&lt;built-in function print&gt;, {1: 2}) .. In what way is this better than just typing `var`? d={1: 2} d {1: 2}
Toggling boolean in a class class Example(): active = True def toggle(self): self.active = not self.active
Replacing keys with values in a dict: sampleDict = { 1:"a", 2:"b"} newDict = {v: k for k, v in sampleDict.iteritems()} &gt;&gt; newDict = { "a": 1, "b":2} 
If you like Numpy and pandas, look into [Blaze](http://blaze.pydata.org/en/latest/). I'm itching for a good reason to use it.
&gt; And the Python3 symbols that exist (`range`, `items`) are iterators. Not quite true. They are iterables, not iterators, which means they can be re-used. And they're pretty cool. Especially `dict.items`, which returns a view of the dictionary, which means among other things changes made to the dictionary are reflected in the view object. Also, you can slice `range` objects and stuff.
I read that book as a kid too! What a blast from the past to remember it now.
Thnx. Sarcasm doesn't carry over. I know python 3 I rarely use it. 
Else statements in for/with statements: for v in values: if v == 42: break else: print 'No values contained 42!' I'm on my phone or I'd post a more sensible example.
This was really useful. Wagtail seems to be progressing well. I evaluated CMS options for Django at the beginning of this year and, after narrowing it down to a choice between Django CMS and Wagtail, I ended up going with Django CMS. The thing that made me choose Django CMS -- and I would love to hear more about Wagtail's approach for this -- is the ability to integrate regular Django apps into the CMS. Django CMS has this concept of an app hook which allows you to attach a Django app to a CMS managed page. The reason why I would want this is because it allows you to keep your database tables clean and well structured by using regular Django best practices in your models. Instead of adding fields to a Page object (which you can also do in Django CMS), you can integrate a separate Django app/model which allows you to loosely couple your database tables and utilise the benefits you get from the Django ORM and an MVC-like design pattern. [This](https://youtu.be/aOlZaceMQuU?t=225) video gives an example of this pattern and outlines some of the benefits. For me, a good CMS built on top of Django should allow you to utilise all the things that Django does well already. tl;dr How can I integrate regular Django apps and manage their content with Wagtail?
None isn't callable in Python 2 either. It's just that map treated None as a special case. I don't get why they removed that special case from Python 3.
Using generators for long lists of data. It really has its benefits. 
I use one called TVShows for Mac - is that what you are thinking of? For shows not in its existing database, I just use Yahoo Pipes to create a custom RSS based on the show/seeder/series and add it in :)
&gt; None isn't callable in Python 2 either. I never said `None` was callable, I said `map` accepted `None` as a callable. &gt; I don't get why they removed that special case from Python 3. Because it's useless. For single-sequence `map` you can just return the list itself (or a copy thereof), for multi-sequence `map` it's completely redundant with `zip`.
Ah fair enough. Thanks
The primary advantage of namedtuple is that *it's still a tuple* with everything that entails, including the ability to convert a tuple-returning callable to namedtuples without breaking most of its uses.
You increase read size so you make less reads over time. In my opinion, for the example given, one would have other concerns if they felt the need to read only smaller chunks of a file (memory, network sending, etc), so the double-each-read-size doesn't really apply
Not that cool since I'm still learning but very helpful. I wrote a program to get data from files (with electrochemical data) in folders to analyze and process to create several sets of data. In my lab they usually do the same calculations on excel over and over. I tell the program which parts I want to copy to the clipboard to then manually paste (the finished data) on excel to graph because I'm still not fluent enough with matplotlib to do graphs as appealing as the ones on excel. Still not as automated as I'd want it to be but saves a lot of time. 
You'd have to explicitly call the *export* function on everything you want to end up in `__all__`, since there's nothing to decorate: from mod1 import func from mod2 import func2 __all__ = [] # export definition export(func) export(func2)
Thanks. If I decided to go with google docs, I was planning to use gspread. But the bigger question is whether or not to use google docs, or just use one of the packages that reads and writes excel directly.
I've been using gspread for a year and been satisfied with updates. Plus it's open source, so if he abandons it... you can maintain it. I don't know about excel, but gdocs is fantastic.
Perhaps a silly complaint, but I'm not a fan of having "class" in its name. Feels amateurish.
I'll look into it, it makes a few assumptions such as the server address and the workflow of my company that probably need removed.
I've been reading Ernie Chan's books and I'm contemplating dabbling in this stuff... I'll pm you for your dissertation if you don't mind
 &gt; with open(filename) as f: data = f.read() fiddle with data If you're just reading the contents of a file into memory, it's probably better (safer) to fiddle with the data outside the scope of the `with` call. This let's the context manager close the file for you. with open(filename) as f: data = f.read() fiddle_with(data) 
For my job I had to download a lot of revenue data from Google and Apple, user data from an Analytics provider, and exchange rates, and then put it all into an excel spreadsheet. I did this on a weekly basis, and it took me hours. I knew there was a better way, so I started learning Python and eventually wrote a script that downloads it all from various APIs and inserts it into a database. It saved me tons of time. Since then I've written a script to create email reports from that database, and I'm writing one at home that collects my banking data from my bank and from Mint, and puts that into a database (using Selenium). I'm loving Python and really enjoying learning more of it. Also these other stories are great! 
Im not sure, it just sits there.
I didn't know about the start=n thing! Thanks!
Yeah, zip(*arr) is a poor-man's transpose.
Hey, I just realized that your project had a great influence on mine! While I was wondering how to make my instrument, I saw your project and got the idea of doing it with python, so thank you! :D It really is an interesting way to make a playable instrument and more people should do something like it. 
Even more would recognize [x for x in iterable if x]
You should really check out David Beazley's generator presentation: http://www.dabeaz.com/generators-uk/GeneratorsUK.pdf It's a little advanced for new Python users, but if you understand this presentation, you will understand the true power of generators.
Nobody can help you unless you actually describe what you need help with. Saying "I need help with this program" is like walking into a mechanic's shop, telling the man at the front desk "I left my car at home, but it's acting funny. What do you think?" Some better responses would be "I'm calling function foo() but I'm getting this exception: MaxRecursionDepth and my program doesn't print any results" or "function bar() works as expected, except when I pass negative integers when it throws a FooException".
My all time favorite has to be the fact that the ``__getattr__`` special method also intercepts method calls on an object. With some trickery you can make a proxy object for any given other object that intercepts every method call and forwards it to the other object. This is basically the heart of my remote object calling library (Pyro4). Another favorite of me is the ``set`` datatype and the set operations it has. I use it often to efficiently and tersly calculate something that requires a lot of code and perhaps a very inefficient algorithm in other languages. For instance say we have a set of paint colors that you shortlisted for your house, and the set of paint colors that the shop has in stock: chosen = { "green", "blue", "purple" } in_stock = { "yellow", "blue", "red", "white", "green", "black" } # what colors from the stock are not chosen? &gt;&gt;&gt; in_stock - chosen {'yellow', 'red', 'black', 'white'} # what chosen colors are directly available in the shop? &gt;&gt;&gt; chosen &amp; in_stock {'green', 'blue'} etc.
Using `namedtuple` for structured data instead of tuples, classes, or `dict`s: &gt;&gt;&gt; from collections import namedtuple &gt;&gt;&gt; Person = namedtuple('Person', 'name age location') &gt;&gt;&gt; p = Person('Bob Johnson', 23, 'NY') &gt;&gt;&gt; p.name 'Bob Johnson' It's a very convenient data structure and under the hood it's also very efficient. You can still get the `dict` representation by calling `p._asdict()` or `vars(p)` (the latter is only available in the most recent versions of Python 2.x).
&gt; With some trickery you can make a proxy object for any given other object Oh, I had so much fun with this in IronPython. I had a little ~50 line library that let you call any .Net class, including a number that weren't supported by normal IronPython interop (such as COM interop, C# event members, etc.). I never measured the performance; I assumed it was worse than terrible, since I used reflection for all the "unsupported" features. I always wanted to try this with JSON serialization for client-server transparent RPC, for the practice. Ultimately, I ended up getting to do this with JavaScript (using a plugin that added attribute-overloading from ES6), which was nice.
Similarly, I use this little snippet for coroutines: from functools import wraps def coroutine(fn): @wraps(fn): def wrapper(*args, **kw): cr = fn(*args, **kw) cr.next() return cr return wrapper What comes out is an initialized coroutine that's ready to have it's `send` method called.
Python is so much the best for this sort of stuff, I've used it for a lot of things over the years - best one was automating software build and release for a software package called Siebel, which saved literally 1-2 hours per day. Downside, no more of this https://xkcd.com/303/ :(
:O I put that at the top, and I don't need the 'u' anymore?
Not exactly, None is the identity function for single-sequence maps, but it's a tuple-builder for multi-sequence maps.
Mostly for clarity. Also if you're working with numerical arrays it would probably be better to use numpy.
Guido has rejected multiple different proposals for range literals, including that one.
I'm no whiz at monetization, but it looks like a great service. If you made the service better, put the ads back, and spent some time marketing, you might make more. If you wanted to make it into a full-on business, you might approach some local real estate listing agencies. Sure, they probably want to drive traffic to their sites, but your site can help them sell listings faster. So, offer to sell it to them as a service; you scrape their pages for new listings (or have some way that they can submit new listings to you) and they show up on your page.
True. I mainly said "binary" because many text files are much more amenable to processing line-by-line than in arbitrary chunks like this, but I can see this technique being useful for a parser. Alternative joke comment: XML is just a binary encoding that doesn't mess up your terminal when you look at it.
You can install [pyenv](https://github.com/yyuu/pyenv) and use that to install 2.7.9 (or 3.4 or PyPy or whatever other version you want).
well you could write a script that converts to html and then back to markdown. But yeah, it gets a bit silly ... ;)
Don't use Python on OSX or Windows, there's no end to these problems. Python on Linux through VirtualBox on OSX or Windows will both work well.
Thanks, this looks promising, will have to see how to get it working with virtualenv. 
Python 3 doesn't have these issues. Also homebrew should have python 2.7.9.
With [a plugin](https://github.com/yyuu/pyenv-virtualenv) it works marvelously.
While I agree that Python on Windows is a massive pain, I've had no problems coding Python on OS X.
Design you protocol so you can forward identical packets to all the recipients. Failing that, make the changes between destinations minimal and concentrate on keeping the packet rewrite cheap. Actually sending data to multiple clients using socket calls (non-blocking mode) will not be a major performance problem compared to packet generation and network latency. Looking at your code, you need to change everything to non-blocking I/O (both the audio and the network sendto calls).
THIS!!! Love the book and want to give credit where it's due
We're going to start talking to them and see what it'll take to bring some of the PTVS support in. From our side of things we're pretty well abstracted away from VS. Our analysis engine and debugger can run completely independently. But there's UI interactions like advancing through signatures and displaying the correct thing that are pretty tied to VS. Hopefully the models are fairly similar though and we could just further abstract all of that logic into a common core. It's definitely something that we're interested in!
This guy recommends `sudo pip` on Linux what a terrible idea
&gt; but they can't help me fill out time sheets or check my email That's exactly why I wrote this book. I thought games and ciphers are fun and I'm still glad I wrote those books, but they have a rather limited audience. And I was looking at a lot of these "everyone should learn to code" sites and started asking, "Why? What do people need to do with programming knowledge?" So I put together the list that later became the chapters of the book's Part 2. And I wanted Part 1 to have a basic Python tutorial so it could be a complete, self-contained programming book for beginners. Thanks!
There are several implementations of Python that "compile" more than CPython's pyc. Compiling makes distribution harder in that you now have to match same arch and libs.
Awesome, sometimes I like to say networks is not an exact science, as pretty much all the rest of IT, some weird unexplainable things happen quite often!
&gt; David.j.balcom Just sent you a copy via SendOwl
Really cool thing. Currently using it in the code of my master thesis. It's really so much better then thinking about useful test cases yourself. Plus the dev is a really nice guy and usually responds in minutes to issues (just yesterday he fixed a minor issue within 3 minutes).
I'm fairly certain any gets my the same royalty rate, but you'll get the ebooks along with the physical book if you buy it off the No Starch Press site: http://www.nostarch.com/automatestuff
I do that all the time. I write lots of code that iterates over things counting various conditions and then reporting those counts at the end.
I've seen [that library](https://docs.python.org/3/library/asyncio.html) but honestly it just confuses me more and I want to learn how it is normally written in python
[What are the risks of running 'sudo pip'?](https://stackoverflow.com/questions/21055859/what-are-the-risks-of-running-sudo-pip) &gt; When you run pip with sudo, you run setup.py with sudo. In other words, you run arbitrary Python code from the Internet as root. If someone puts up a malicious project on PyPI and you install it, you give an attacker root access to your machine. Prior to some recent fixes to pip and PyPI, an attacker could also run a man in the middle attack to inject their code when you download a trustworthy project.
So, why do you recommend it?
Here's a function to flatten lists of lists of lists of... etc. from functools import reduce from operator import add def flatten (container, type=(list, tuple)): if not isinstance(container, type): return [container] return reduce(add, map(flatten, container)) if container else [] 
Nothing may be wrong with GOTO. But there is something very wrong with logic/program structure that requires their frequent use. Just like there is something wrong with a 5,000 line script with no functions. You personally might be familiar with that style and believe you're just as efficient with it. But the vast majority of the rest of the world, anecdotal evidence and academic studies have shown it is a pile of unmaintainable crap.
I really, really want this syntax: if obj = dict.get(key): obj.blah() Edit: added a couple of reallys
Maybe now someone can automate converting HTML "books" to a nice PDF ;-).
This right here. I code mostly on my macbook, and [HomeBrew](http://brew.sh/) is the best. `brew install python` will install and setup a copy of 2.7.9 that doesn't interfere with your OSX's system python.
That works too.
If it were me I would prefer to wrap it one level deeper so that the thread spawns on execution rather than on import. from threading import Thread from functools import wraps def spawns(func): @wraps(func) def spawned(*args, **kwargs): thread = Thread(target=func, args=args, kwargs=kwargs) thread.start() return thread return spawned @spawn def task(...): ... def main(): thread = task(...) thread.join() 
Following from this, a trick you can use if you need a nested structure built on `defaultdict`: &gt;&gt;&gt; d = defaultdict(lambda: defaultdict(int)) &gt;&gt;&gt; d['x']['y'] += 1 &gt;&gt;&gt; print(d['x']['y']) 1
Unless you are doing something in a library that is unsafe, it should be fine. A GIL and lazy GC are good for something.
The way it's normally done in Python is with Twisted (or with asyncio if you're using Python 3). Using the socket module directly is usually a Bad Idea. You're just going to need to reimplement what Twisted's been perfecting for decades.
You, too!
I've wondered this too, and I eventually came to the conclusion that I should think twice about why it is okay if *I* run a method externally but I don't want my users to. In PEP8, "internal" is referring to *within the same class*, not *within the same library*. So, my decision, if I wanted my users to ignore certain methods, is to create a wrapper class containing the public API. Methods on this class call (now made public) methods on your other classes. In this scheme nothing is private, but those other classes are documented as being lower-level and not for general use. I'm not sure if this is a good solution or not, but it's what I came up with. Curious what other people think.
Been paging through this book. Looks pretty good.
Don't forget your good friend zip(lst[:-1], lst[1:]) &gt;&gt;&gt; from datetime import datetime, timedelta &gt;&gt;&gt; from pprint import pprint &gt;&gt;&gt; today = datetime.now() &gt;&gt;&gt; lst = [unicode(now + timedelta(days=x)) for x in xrange(5)] &gt;&gt;&gt; pprint(zip(lst[:-1], lst[1:])) [(u'2015-04-30 14:20:47.940504', u'2015-05-01 14:20:47.940504'), (u'2015-05-01 14:20:47.940504', u'2015-05-02 14:20:47.940504'), (u'2015-05-02 14:20:47.940504', u'2015-05-03 14:20:47.940504'), (u'2015-05-03 14:20:47.940504', u'2015-05-04 14:20:47.940504')]
We really should have anonymous inner functions for something like this :-/
I was intrigued by your post and I am starting to do analytics on the loan data. From a quick peek, looks like the worst loans to invests in are: * House * Moving * Small Business Weddings on the other hand appear to okay. It is very small number of them but they are all current or fully paid off. Does that jive with your experience? How is lending club working for you in generally, looks like an interesting way to invest, though I am little scared by the long terms on these notes. You can't sell them once you invest, right?
What alternative(s) do you recommend?
That's a cool trick that I use when I'm trying to see if something will work, either in an ipythin session or while I'm debugging, but I would _hate_ it if someone left that in released code.
If you do the `list()` part, but if you just want `for thing in method(other_stuff):` then the generator is more space efficient.
I usually prefer `dict.setdefault` for this kind of use. It's more explicit and doesn't require additional imports. d = dict() d.setdefault("x", 0) += 1 I humbly suggest reserving `defaultdict` for use cases in which the default parameter construction is a bit more involved. *Explicit is better than implicit*, and all that :)
You just blew my mind
This is a really nice flow control trick, you'll save a lot of time not having to use flag variables
But really that doesn't work unless those are the only things locally, generally pretty bad practice
Is there really any advantage to using this over virtualenv?
Agreed, the use of int as the example is a bit too simple for this use case. 
Nice!
nublet here. What does the '@' do?
Hahaha. I've actually been bookmarking all the "I want to automatically do X" reddit posts over the last couple years, just to make sure I was writing a book people could use. It comes up a surprising amount.
You can't feed multiple threads from one generator using `send`/`yield` because it will block on the second iteration: each thread will grab the first datum from `yield`, but it won't come around for the second datum till the first has been sent. Your generator will then block till the thread it's currently trying to `send` to has sent that last datum to the client. If you're going to use threads, go the whole hog and use `Queue.Queue`. Give each client thread its own queue and `put` the data into them instead of using `send`. That won't block. Either that, or go full on coroutines and use `asyncio`.
I don't know about that, but I do love the fact that it makes code so much more maintainable, and that you can use `.elements()`, `.most_common()`, multi-set arithmetic, initialisation from an iterable...
Virtualenv is good for isolating your python dependencies, but with a vm you also get system level isolation (os, db, server, ...). Also, you can take it a step further and have vagrant run a provisioner (puppet, chef, ...) which will install everything you want each time. This allows you to pass around simple files that describe your complete production environment and allow anybody (on any os) to easily replicate your exact environment.
PATH is where the system looks for executable programs, like `ls` or `curl` or, indeed, `python`. PYTHONPATH is where Python looks for libraries when it executes `import XXX`. Each Python installation has a bunch of (platform-dependent) default directories that will already be in `sys.path` (which is where PYTHONPATH ends up). On OS X, many people like to install newer Python versions with Homebrew. 
&gt; calculate Fibonacci numbers Oh god, this is so true. I delayed attempting professional engineering for nearly a decade because of this perceived lack of mathematical rigor
Thank you! (Also, nice username.. hahahaha)
The spawn function is a decorator. In terms of python, this means a function that takes a function as input and returns a function as output. The @ syntax runs a decorator on the function and replaces it by they decorators output. In code: @spawn def some_func(): pass Is the same as: def some_func(): pass some_func = spawn(some_func)
TIL. That's very useful. Made me check if it had a step option too but apparently not.
Do you mean you want to wrap it in a minimal web browser so the existing interface can be used like a desktop app, or you want to recreate the UI as a native desktop app?
If you're simply importing multiple modules to flatten a namespace you can do: from mod1 import * from mod2 import * # more stuff __all__ = [any, explicit, entries] __all__.extend(mod1.__all__) __all__.extend(mod2.__all__)
What you're looking for here is a process called tokenisation. Basically, you want to take your line and split it up into a list of all the words that appear on that line. A very simple way of doing that would be to use `str.split` on your line to split it up at the spaces: &gt;&gt;&gt; line = '’Twas brillig, and the slithy toves\n' &gt;&gt;&gt; words = line.split() &gt;&gt;&gt; words ['’Twas', 'brillig,', 'and', 'the', 'slithy', 'toves'] &gt;&gt;&gt; 'the' in words True &gt;&gt;&gt; 'he' in words False The only problem with `str.split` is that it doesn't deal well with punctuation or word variations. You can try to handle that by doing something like trimming unneeded symbols from your string, but if you're really serious about doing this kind of analysis properly you might want to look into [nltk](http://www.nltk.org/).
I feel like having an IDE hide brackets in a language that depends on them would be a really bad feature. You might really easily miss an error caused by an omitted or extra bracket.
It's really not important worrying about how PyPy is implemented. PyPy is a tracing JIT for a restricted subset of Python called RPython. And it's not specific to Python, either; it's a general framework for implementing an interpreter for any language. Basically you write your interpreter for whatever language you care about in RPython, and then that interpreter is JIT-ed, resulting in an efficient implementation of that language. If that didn't make any sense, don't worry. Just remember that the PyPy project is really two things: a framework for creating efficient interpreters of dynamic languages, and an interpreter for Python implemented using that framework. The fact that RPython is used as an intermediate representation is neither here nor there. &gt; how can I find out which implementation of python I am using in terminal.app? You are using CPython. 999 times out of 1000, that is what you are using if you only know that you're using Python. You would have had to have gone out of your way to install anything else. And those alternative implementations are not called `python`, i.e. if you were using PyPy you would have been running your scripts as `pypy myscript.py` instead of `python myscript.py`. Moreover, none of those other implementations are anywhere close to a version 3.4, e.g. PyPy is currently at version 2.5.1. 
Either, trying to figure out what's best practices
I used the jira-python module. Basically just runs a few jql queries to retrieve my tickets and then edits them. Has everything you need to login and edit as well
Not true at all, you can have a huge dictionary and `**`-unpacking will only get the appropriate entries, which is precisely why it does work with `locals()`. I'm on mobile atm so can't easily time the difference between unpacking a two-element dict and a much larger one, but I'm pretty confident that it's a O(1) operation.
Ahhh didn't realize that! Very cool then! 
It's not that it discards values... I suppose I wasn't completely clear. _ in Python as a variable name is often used as a placeholder. After the iterable expansion, it will still contain a value, but the convention is that you will not use it. If you are unpacking a large iterable with maybe 10 values but only want 5 of them, you can actually assign the 5 values you don't want all to _. I often find myself doing this when reading CSVs
It's a wiki, so "just do it".
I realize this is incredibly selfish of me, so please forgive me. Why is the e-book version of this book a mere 1.67$ cheaper than the physical copy? One of the main reasons I got a ereader as a student was the benefit of cheaper book access due to removing all the silly need for all the overhead associated with physical books. *blush*
PyCharm is also very popular, has great vim mode, and can run selection or current line in the interpreter. https://www.jetbrains.com/pycharm/help/loading-code-from-editor-into-console.html Just a thought... 
It sounds like you basically implemented an interface in Python. I wish Python had a standard interface mechanism to use in situations like this. Guido [wrote about interfaces in Python](http://www.artima.com/weblogs/viewpost.jsp?thread=92662) a few years back.
Can client data be posted on the internet? Does Google Docs violate any of their security concerns? These are the questions I would ask before using a cloud based service... unless you're hosting the Google doc yourself... maybe I don't know what in taking about... I'd stick with delivering what they asked using a library made for working with Excel. Though I'm the rare Python dev who doesn't think Excel is a dirty word.
Ok. seriously can someone explain the value of vim to me? at this point I tend to think people only use it because they haven't heard of pycharm or they are stuck in the past. Any time I ask I'm just told I'm shortsighted for not already knowing it or retarded for using nano when all I want to do is just edit a single fucking line. 
I can *never* remember all the stuff about regexing filenames and doing bulk renames and moves in bash, so I *always* just write a script in Python to do it.
Do your own homework
Parse error: syntax error, unexpected end of file in /home/asweigartftp/automatetheboringstuff.com/wp-content/themes/eighties/functions.php on line 350 getting this error on opening any link
I learned Python from just lots of different sources. Most of what I use Python for is business related tasks. If I had seen this before I knew Python, it would be a great fit. Quite literally spreadsheets, text messages, and CSV files was one topic I looked at today and was something I was working with! 
Probably the biggest reason I use Vim a lot are for filetypes that PyCharm/Intellij/etc don't support or have poor support for. First things that come to mind are Dockerfiles, yaml (requires ultimate). My second use case is if I just want some scratch space or to take a quick look/quick edit a file from terminal. 
Sorry, I was temporarily changing some stuff in WordPress and I think the site went down for a couple minutes. It's back up now.
That's great to hear. I tried to narrow down the list (even though the book still ended up being over 400 pages) to the stuff that regular people would want to be able to code. I'm glad I got the right set of stuff to cover. :)
Or `pyvenv`?
I think most of the people here didn't actually ask / tell their boss about their automation. 
You may want to repost it to www.reddit.com/r/jobbit 
&gt; PyPy is python implemented in "python" ... what sort of recursive nonsense.. in which implementation of python is PyPy implemented? PyPy is a few things: 1. It's a compiler for a reduced set of python called RPython. This is written in Python 2. It's an interpreter for Python, written in RPython 3. It's a JIT compiler, also written in RPython To start with, the compiler is run under CPython, to compile the JIT compiler into an executable. This is very slow, but only has to be done once. There's shared code between the compiler and the JIT compiler, but my understanding is that they're best thought of as two different things. Then, when you run pypy, the interpreter is run by the JIT compiler, and this interprets your python. The combination of your python code and the interpreter form an RPython program which the JIT compiler can compile and optimise as it runs. One of the really interesting things is that the interpreter could be for any language, not just Python. It just has to be written in RPython. Hence we're seeing people use it for Javascript, and other languages.
It's just that something like the filter expression can get very big, if say you're iterating over tuples and the variable names are very long. Python usually needs longer variable names than typed languages. 
Yeah, it looks to be a very [limited subset](https://github.com/timothycrosley/jiphy#user-content-syntax--contstructs-jiphy-suppports) of python that's supported. You even have to leave a line after any blocks to allow for the closing bracket. Also, looks like it produces 100% globals by default.
One advantage to something like vim or emacs is that it's one editor for everything. "True" IDEs tend to be language-specific, which is fine if all you ever do is code in one language, but if you're using multiple languages regularly, it's nice to have just one tool. At any rate, if PyCharm works for you and you like it, keep using it. But for some of us, other tools are better.
&gt; pyenv Totally agree, but unfortunately am stuck on MacOS and the Home Automation system uses it :S 
Definitely. I could easily scrape a well structured site however when a person it doing the stuff on the other side, it becomes a nightmare. 
I spend enough time alttabing between windows already. Vim+tmux go a long way to helping. Plus, I can use the same editor for Python, Scala, Bash, markdown, etc. And with pathogen, I can have my cake and eat it too. 
Just did!
This might be your starting point: `:'&lt;,'&gt;:w !python -` The only issue with this is that if your block is indented all the way through (i.e. it starts with more than zero spaces/tabs), the interpreter will through an IntentationError. You might want to write a function that detects the level of indentation within the block, then strips the needed amount of whitespace from the beginning of each line and then feed it to the python interpreter. For one-liners, stripping whitespace at line start is easy (with sed): `:'&lt;,'&gt;:w ! sed "s/^\s\+//" | python -`
You could drive Excel directly from Python using pywin32: http://pythonexcels.com/python-excel-mini-cookbook/ If you don't want to depend on an Excel install being present on the host running your Python code then openpyxl will let you generate a .xlsx file: https://openpyxl.readthedocs.org Both approaches avoid using google docs.
&gt; Sets are available in the *sets* library (but are built-in in Python 2.5 and later). Makes me think this article is 10 years old.
Indeed, pip install now available.
Python advocate, uses wordpress. Full marks for pragmatism though - use the best tool for the job is sound engineering! I wish we had something similar in the Python ecosystem, with an equal plugin ecosystem. But I just can't wait until non-programmer website operators start hacking on the plugins and posting the code up on here! Python's ecosystem is very strong on things like sound engineering and code correctness, it'll be a fantastic sight to watch :-) edit: P.S. Your books are pretty good, please carry on writing!
The download links in the screenshot are of Python 3.4.3 and 2.7.9 so it is recent. But yeah, unless you have the misfortunate to be working in a legacy environment that only supports Python 2.4 (old RH versions, Civ IV mods) or something, you can basically ignore Python &lt;2.6. Some people are arguing for putting [Python 2.6 on that list too](https://alexgaynor.net/2015/mar/30/red-hat-open-source-community/).
pft, go back to your M$ overlord noob. do u even compiz?
HUH? I didn't know that worked!
like when using the shell command line. &gt;&gt;&gt; a = 5 &gt;&gt;&gt; print , a (&lt;built-in function print&gt;, 5) but u/tilkau showed me that &gt;&gt;&gt; a 5 I wonder why I missed that. 
Hi Al, interesting book you've written. Although I haven't checked out the entire book yet, I did manage to check out the CSV &amp; JSON chapter. In the csv examples, you've used the following code: handle_file = open('foo.csv', 'w') """ Do something here""" handle_file.close() Instead wouldn't it be better to just use *with* to handling files, thereby ensuring no file corruption. Something like this: with open(foo.csv, 'w') as file_handle: """ Do something here """ Just want to know your opinion on this. 
Last week, i coded a clone of supervisor (http://supervisord.org/)
Here are a couple of approaches: * [vim-ipython](https://github.com/ivanov/vim-ipython) - Lets Vim talk to an IPython kernel session. * [vimux](https://github.com/benmills/vimux/) - Requires tmux, a terminal multiplexer which allows you to run multiple terminal sessions inside single terminal window. So you can have one vim session, and one console session, and then this vimux plugin allows you to communicate between the two. I had really high hopes for the vim-ipython project. It basically allows your vim session to connect to an IPython kernel session which can then power your auto completion and give you all the other cool stuff you get with IPython. Its already pretty usable but development on it seems to have stagnated and I think it has potential to do a lot more, particularly now that IPython has a language agnostic fork in Jupyter. If I ever learn how to write vim plugins I'd love to make a fork and play around with it. *** Edit: I just re-read your post and noticed the data science part. In that case, I recommend that you will want to check out IPython anyway, particularly for their notebooks as they are really geared up for scientific use. Then the vim-ipython plugin will allow you to jump between any work you do in a REPL environment and any source files that you manage in vim.
You should get that checked out.
That is the way I used to do renames too. There is a tool called rename that is pretty nice and helps you remove the effort of writing a new rename script $ rename "s/.txt/.txt.bak/" *.bak It also has a dry-run flag "-n"
I'll give it a go, thanks!
The question of using excel in python comes up quite frequently on /r/Python I always put in a plug for my favorite module for dealing wit excel whenever the question comes up. Pandas - http://pandas.pydata.org/ With this module you can read from and write to Microsoft Excel documents. http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html It may be heavy for what you're seeking but the module can do all sorts of other things - its not just a library for dealing with excel - its a general data analysis library - so you may find that its quite useful for a large number of things but can also write out excel spreadsheets. The module is widely used - I don't think you need to worry about long-term viability. Quoting directly from the Pandas "Library Highlights": "Tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format", "Highly optimized for performance, with critical code paths written in Cython or C." 
My two cents: If you're doing this just for fun - as a side project or whatever - not something you're getting paid for - then go ahead and do it in python. Work on it as much as you can as a way to increase your skills with python and keep going until you totally hit a brick wall where python can take you no further (this may not happen at all). At that point step back and think about why python can't help you go forward any longer - is this something that could be easily done in C? Python interfaces with C quite nicely - perhaps you can write some C code that's callable from your python app to help you continue the project. If you want to get better at python - this seems like a great idea. But if you're ultimate goal is just getting this program to work as quickly and efficiently as possible then maybe spending some more time from the get go thinking about the optimal path is a better choice. 
Session for browsing API/Token for Single Page App I use [Django Rest Auth](https://django-rest-auth.readthedocs.org/en/latest/) with helps with the login/password etc. As for invalidating a token on password change, you could [extend the user model](https://docs.djangoproject.com/en/1.8/topics/auth/customizing/) and then override the pre_save signal and get it to reset the password. Then you change the change password endpoint to send back the new token so your SPA can update their token. I am not sure on a good way to destroy the token on mobile device lost unless you invalidate the token after X time. like /u/nharding mentioned. 
Python to Javascript is always interesting and kudos for your project, but why bother creating a new project from scratch when [RapydScript](https://github.com/atsepkov/RapydScript) can do the same (and much more)?
That is how it is normally written. You're confused because you're not used to that style of programming. From the module page: &gt; Asynchronous programming is more complex than classical “sequential” programming. Your confusion is a sign that you are beginning to understand. If you weren't confused, you would be totally lost. Give your brain some time to wrap itself around these concepts. They are not easy. It takes very smart people months to fully grok it.
I recommend not using Twisted, even though there are people who really like it. Greenlets should give you an even simpler coding paradigm. We've been using it to do async HTTP and it was pretty much plug-and-go.
Probably, but it's not exactly clear from your post. I think you mean you will add a marker for each piece of hardware to a PDF map of your hospital? Are you able to get GPS reception in your hospital? If you can scan each asset tag and then tag it with the current GPS location you should be able to build up a list of asset number/location pairs and then you could plot those on a map using Python. edit: depending on your level of Python skill this could take more or less time than just doing it the boring way, but it will be way more fun and you'll probably learn lots!
One big one for me at the moment is as I work across many different languages, I am used to the same experience in all of them. Don't get me wrong, I still have IntelliJ installed for when I need to debug Java (for example), but for 95% of my work, I like having a consistent programming experience. The IdeaVIM plugin is fairly good, typically, but still feels slightly awkward when you're used to various plugins that you cannot use in the IDE.
RapydScript is awesome. And If I had team buy-in on all my projects I would use it. However, that has NEVER happened. Jiphy is a very different concept. Jiphy is meant for single developers that don't have team buy-in to be able to convert a single chunck of code to Python syntax, edit it, and then convert back to JavaScript. - Jiphy converts in both directions (You can convert JavaScript to Python as well) - Jiphy is 1:1 - you know each line of Python will be and do the same thing in 1 line of JavaScript - Jiphy is syntax inter-mixable - you can open up a JavaScript file, add a Python function to it - run Jiphy and end up with a 100% JavaScript file. Thanks! ~Timothy
Hmmm...assuming you get GPS reception, you could probably automate almost everything. Use your cell phone to take a geo tagged photo of the asset number tag for each piece of equipment. Write a script that will process all the photos by using OCR to read the asset number from the photo and produce a list of asset number/locations and then plot them on a map.
With GPS would it be able to tell the difference between one room and another? Edit:(Difference in about 7 feet)
I was wondering how long it would be until someone did this.
Then I would call it ``@async`` and I do that sometimes, too. The above ``@spawn`` is mostly for small scripts or run-once code nested in other functions, not on module level. Should have mentioned that perhaps :)
Maybe not exactly (GPS accuracy is usually more like 10 feet I think), but you can probably add a tag to a photo using a room number rather than GPS, or use a combination of both.
I want to mine the web for everyday conversation text, then translate it to another language using an automatic translation online apps.The python software I am making will use machine learning algorithms in evaluating these translation apps' performance. I coded a Naive Bayes classifier from scratch using the numpy library. The training data for classifier was manually generated by myself and some friends. I will probably code other classifiers to see how the Naive Bayes compares to it. There are probably already available machine learning packages I can use, but again this is a project I am doing for learning purposes (and for fun). Although you raise a good point, what is my cost function. At the moment I am only familiar with the least-square-cost function, but this is for linear regression. Do you know of any cost function I can read about for the Naive Bayes classifier? 
This is mainly a self improvement project. I want to further advance my python skills but I also wanted to make sure I wouldn't hit a wall right away. Anyway, your advice is awesome! Thank you. 
Good call! I'll update the README tonight. Thanks!
Consume an iterator and throw away the result: def consume(iterator): collections.deque(iterator, maxlen=0) This consumes the iterator and just throws away the generated values. It is way faster than an empty for-loop (deque is implemented in C) and uses way less memory than ``list(iterator)``. Nice for a functional programming style and very useful if you use generators to cope with huge amounts of data a lot. 
Threading this wouldn't help, the PRAW still rate limits. You'd need to tweak your config. You'd risk getting banned though.
This thread has been linked to from another place on reddit. - [/r/subredditdrama] [/u/g2n in /r/Python ruins /r/circlejerk 's circlejerk](https://np.reddit.com/r/SubredditDrama/comments/34j4z9/ug2n_in_rpython_ruins_rcirclejerk_s_circlejerk/) [](#footer)*^(If you follow any of the above links, respect the rules of reddit and don't vote.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
This is certainly interesting and really don't want to rain on your parade. However I assume that this 1:1 conversion will only include a small subset of JavaScript, and leave out important JavaScript functionality e.g. Objects and Prototype based inheritance, anonymous functions etc. To use these features I assume you have to go back to JavaScript. In this case you would have mixed JavaScript/Python code and I can't see how this is better than just having JavaScript (even though it sucks compared to Python) So, while I really like the idea, I find this as something of very limited use (IMHO).
I recommend using oauth2 -- admins are *way* more lenient with your API usage if you register your app, etc.
it absolutely isn't about memorizing combinations of keys. It's about learning the language of vim. Movements, objects, operations. These are infinitely combinable when you understand what they're doing. You wouldn't approach python with the idea of "I have to memorize all these methods and classes in stdlib!" No, you should understand data structures and basic operations and design principles.
Can this be used to call JS libraries from python?
I think mitchellrj is sort of on the right track. So, for example, to get the list of four letter words from a stream of lines (say file for simple case), I would write this in Python: w4gen = ( w for line in open(fname) for w in line.strip().split() if len(w) == 4) and much later, can use for word in w4gen: blah Or, if I need memoization (caching, dynamic programming, or whatever you would call it), I'd do @lrucache or something like that and be done... All of these break down in this paradigm. So, some one using this approach (e.g. a JS user that needs to send code to Python user) will end up with bad misconceptions about Python -- specifically, they will think that Python is a really poor subset of JS. Unlearning such stuff is next to impossible. 
Your second paragrah is basically bollocks.
I actually like doing this with bash: find . -type f -exec sha512sum {} \; &gt; sha512sum-${PWD##*/} I definitely think there's optimisation available with what actually gets hashed and then a nice UI for when you're going through deleting the duplicates, though.
Yeah, sometimes it's *better* to keep checking in non-working stuff to your private branch, even. Obviously don't push it out to anyone else until you've got it to work but granular steps of what you're changing on the path to making it work can be very valuable.
&gt;&gt; In the meantime it's an 80% solution: it fixes the silly things that people that It is much much less than 80% -- without downplaying your work, I'd say it is a very small number (with a lot of potential towards going to a large negative [if someone uses it without thinking through]) 
Similarly, [Sublime](https://www.sublimetext.com/3), which is a text editor (like vim) with some light IDE-functions (opening a console, code completion, etc). It~~'s written in Python (not that it matters) but~~ supports at least syntax highlighting in every language I've ever come across. It's fairly stable. It also have a great plugin system. Might be worth investigating. Edit: corrected, see below.
Yes, you can use numba with python numerical code to compile to LLVM for c like speeds: https://github.com/numba/numba Also has multithreading.
Think you mean `Thread(target=item.report).start()`.
Thank you!
Looks like they finally caught on :-/ 
I think everyone is missing what this task actually involves. Bar code scanners operate like keyboards. The inventory is likely per room. So you'd walk from room to room, scan an object, and enter the room number. Afterwards, you'd actually put these entries on a PDF map. That breaks the project into two parts: data collection and publication. 1) Data collection You could write a simple Python script to deal with this, but it's probably way more trouble than it's worth. The main issue is the extensive amount of programming necessary to handle typos and going back to previously entered information. Writing those 30-50 lines is not worth it, and when (not if) you run into a problem in the middle of collection, you have to hope that it doesn't require starting over. There's just way to many problems and situations to consider for a project that requires ~8K data entries that it would never be worth it. In short, use a spreadsheet. Room numbers go in column A, press tab to go to B, scan item, repeat. 2) Publication Once you have the data, it's worth considering using Python to put it on the map. It all depends on whether the floor plan layout has some sort of metadata that can be used to locate rooms. If so, easy peasy. If not, the diagram may be so regular that you can estimate the coordinates for the inventory markers. 
It's used for some major software tools. Dropbox uses it. Abaqus (a finite element code that supports GPU processing) uses it and so does reddit. There are plenty of very serious, highly resource intensive software tools that use it. Granted, they do most of the heavy calculations in C with the interface in Python, but you don't need to do file parsing in a language like C. Just do all the work in C/C++/Fortran if you need the performance. Also, with many tools, you can just use libraries that are implemented in C under the hood, so you don't need to do that work yourself. If you really want to use Java, you can use Jython, but I'd strongly suggest CPython (or possibly PyPy).
Iterating over a sequence backward, using the splice syntax's obscure third parameter: &gt;&gt;&gt;foo = [1, 2, 3] &gt;&gt;&gt;for each in foo[::-1]: &gt;&gt;&gt; print(each) 3 2 1 This is especially handy since `list.reverse()` modifies the list in-place.
You might want to check out xlwings. I haven't been able to play with it too much as I am just starting to learn python, but as a pretty heavy user of VBA in excel it looks like it should work well. 
Relax it's the cj sub. No kittens died.
Fair enough. I skimmed through some other chapters as well. Great work and well thought of. Cheers! 
Yes, I have used that technique for distributing streaming audio to 10-20 clients from a central server. You have to think carefully about packet sequencing and missing packet concealment. Once you are operating from a central server over various ISP paths the probability of out of order UDP delivery and dropped packets increases significantly.
Thank you for your constructive criticism :)
Not about what sub is affected, it's the behavior. Do you really want this type of meaningless stuff and cross sub battling in /r/Python? I'd rather see relevant content.
&gt; I wish we had something similar in the Python ecosystem, with an equal plugin ecosystem. and a better code base.
Check out [rodeo]( https://github.com/yhat/rodeo/blob/master/README.md), not VIM but has VIM keyboard bindings I believe. But it is taylored for doing data science.
* slow clapping * Well done. EDIT: Oops. 
Don't you mean .start()?
Looks like you're trying to run it as Python code. pip is a shell command, you use it directly in your command line. 
Do you know how many posts you reported before they caught on?
That's good to know. Thanks! 
I used Python 2.7 since the Python 3 port wouldn't compile for me. Its pretty simple if you are doing basic historical/real time data requests, but more complex requests and error handling can get pretty involved. The documentation is good. You are only allowed a certain number of requests per day (50,000?) but you can get a large number of data points from each request. I basically try to get everything into a DataFrame as quickly as possible.
Don't worry, I reported it.
Wow that cool looks pretty simple. I didn't realize that it was so easy to write a reddit not like this. What library are you using?
[PRAW](https://praw.readthedocs.org/) the Python Reddit API Wrapper.
Deliciously evil. &gt;:)
Time to get drunk and make trolling python scripts.
I kept missing when my favorite chaturbate model came online so I had python check every 60 seconds if she was online using beautiful soup and requests. If she went online a push message was sent to my phone (using instapush). Also, the raspberry Pi I was running it on had an arduino with an RF transmitter on a breadboard connected to it. A signal was sent over serial to trigger the RF transmitter to send a signal to make my doorbell ring. That last part was cheating a bit of course. I should've hooked the transmitter to the GPIO of the RPi so it would've been pure python. Please note: I was not actually this desperate to miss her, but decoding the doorbells signal with a logic analyzer and emulating it with the arduino and RF transmitter was a weekend project. I had some time left and it was only a small step from there, and a good opportunity to dive in serial communication. I might regret posting this. 
Extensive beta testing
Pretty much 
They are not completely d8fferent. Both are used to make websites. And I never said they were the same thing. I said there are plenty of pythonic ways to make websites. 
Linking people to subreddits aren't. I think it's deliberate vote brigading.
A Reddit post being unrelevant? Nah, I live for this shit
EDIT: I dont know how to format my comment to make it look like a real code while I'm in mobile but i think you can get the idea I am still learning but its good to start small. Start with little things to learn how to utilize specific utilities, then begin putting them together. For example, learn the syntax for adding 1 to the below variable: Number = 1 Then make it happen under certaim circumstances. You can do this easily using a while loop. while 1 &lt; 2: print("hello") But this will print "hello" forever. Use the adding one thing from above to limit it. while number &lt; 100: print number number += 1 That will print what is stored under number, then it will add one to the number. Then since you changed what the while loop is paying attention to, it will run again and again, but only while that value is less than one hundred. Thats a simple piece of code to make, and while it doesn't have any useful real- world implementations, you still learned a necessary skill in the language. Code academy is great if you don't have a class or scholar or tutorer helping. Hit the books too if you want. It might be hard work but just look up how much python programmers make on average and you'll begin to see that he hard work will pay off.
Really enjoyed the regex part. Thanks :D
I'm 80% sure they expected this
my first python site, built with flask. inspired a bit by reddit. still in dev. but constructive criticism welcome. plus any tips.
That makes sense. So would it just be easier to use TCP right off the bat? Or will the performance penalties make it unusable?
1. You don't need to invalidate the tokens when the password changes. The point of tokens is that they are *not* linked to the account password. 2. There doesn't seem to be a great solution for JWT invalidation. The best solutions I have seen are to (a) set a short expiration time in the token and, in the worst case, (b) change the signing key on the server to invalidate all tokens. Another option is to keep track of all issued tokens, and reject requests that don't include tokens in your DB/cache. You might be better off using OAuth 2, which has support for access tokens, refresh tokens, and token invalidation. Update: Here is an article that discusses the use of JWT and SPAs: https://stormpath.com/blog/token-auth-spa/.
Post this to /r/firstworldanarchists 
so basically you're passing the method to the thread and then starting it while the for reply loop goes and the reports all get asynchronously submitted via api? How is this different than the OP? Are they passing the thread the return value of the method rather than the method itself, in essence making the multiprocessing useless?
You can install for your local user with: pip install --user &lt;package&gt;
/r/learnpython
Pfft, XGL is *clearly* superior. /s
They are at different ends of the framework spectrum. If you want a big framework with plugins and magic that does lots of stuff for you like Rails, look at Django.
Only 80%?
I would agree with this for many languages and systems. Cross platform, or platform independence, or whatever you call it is a desirable state of affairs.
Hi. Some quick notes that caught my eye (don't have time to do a proper code review ;)), should get you started at least. * Use 4 spaces indentation (if you feel differently, fine... I don't want to start a holy war here :)) * Refactor curses_main. Some things to fix: * Avoid using while True, you have a natural exit condition, why not be explicit * First three blocks are almost identical, generalize that code * The first part could be moved to an curses_init function instead * The run() method is blocking and wont return until the application exits therefore there is no point in assigning all those variable to self * The copy_members() function in ScreenBase doesn't do what you *seem* to think it does :) * Check out the logging module with the file handler, saves you open and closing that file. There are lots more but I don't have more time than this :) Peace out
I like to recommand ImportD, a minimalistic Django à la Flask: you get started very quickly, you have the full power of Django. http://importd.readthedocs.org/en/latest/ Recently came across Phoenix, a full featured framework for Elixir. It has channels (two-way communication) and the language looks awesome. http://www.phoenixframework.org/
"Can you file an issue so I don't lose track of it?" Sure thing!
Here's a few links you (and more for me) may find useful: * [UML2Python – Full code generator for Python Applications](http://modeling-languages.com/uml2python-full-code-generator-python-applications/) [*](http://modeling-languages.com/umltosql-umltosymfonyphp-and-umltodjangopython-are-now-open-source/) [Source](https://bitbucket.org/jordicabot/umltosql-umltophp-symfony-umltopython-django) * [Your Graphviz, UMLGraph or PlantUML](http://www.gravizo.com/) * [PyNSource - UML tool for Python](http://www.andypatterns.com/index.php/products/pynsource/)[*](http://www.andypatterns.com/index.php/blog/uml-layout/) * [Python: Visualise your class hierarchy in UML](http://twigstechtips.blogspot.com.au/2014/09/python-visualise-your-class-hierarchy.html) * [Pyreverse : UML Diagrams for Python](http://www.logilab.org/blogentry/6883)
Thanks!
There's a time and place for everything, but that is not now. 
Another way is via `zip` (dict comprehension works in python &gt;= 2.7) d = dict(red=210, green=105, blue=30) inv_d = dict(zip(d.values(), d.keys())) # {210: 'red', 105: 'green', 30: 'blue'} 
Did you try installing it with pip? 
I know, it's just disappointing that if you want details about five authors then you have to wait ten seconds. 
TCP is not the right protocol for streaming audio. You need on-time delivery and can live with dropped packets. Guaranteed delivery at the cost of latency is not ideal. You might want to look into STCP if you are feeling adventurous, otherwise UDP is the way to go even with the extra protocol and code complexity. Streaming audio right is not as simple as it looks on the surface. You should also look at the RFCs for RTP and related protocols to at least understand why they were implemented they way they are. If you don't have a compelling reason you might want to use RTP instead of reinventing the wheel. I didn't use RTP because the overhead is excessive and we transfer data over expensive (satellite) links.
wait...this is a thing that we can do? why was I never told?
Nice video. Thx for sharing
Sometimes a thread is archived but if you go deep enough there is an unarchived comment chain. 
One time I accidentally extracted a large archive to `/` when I meant to extract it to an isolated directory. It had hundreds of files scattered around `/bin`, `/lib`, etc. with no way to remove/uninstall them. Python saved me big time. I wrote a little program that would compare the package to the bad destination directory and removed matching files. It was under 100 lines, with command-line options to make it useable again (and documented code). If I had known what I know now it would've been even smarter. I manually made sure I wasn't going to remove existing system files using a bash command instead of checking the file creation time/date in python, and I extracted the package to inspect the tree instead of listing files directly from the archive file. I was being extremely cautious because I was afraid of ruining my system. I was a newb, but it still saved me a lot of time, and if I ever do that again I'll have something to work with (except better next time). I didn't know bash that well either, so I'm sure I would have created a monster if I went that route.
&gt; Type in "env" and see what it prints out for path. That's "SET" on Windows, not "env", and I already have. C:\Python34 and C:\Python34\Scripts are both in there. Pip is executable when I run the Pip.exe file in C:\Python34\Scripts.
Did you try doing it this way? https://pip.pypa.io/en/stable/installing.html#install-pip
For retweets, retrieve the tweets for your religious leader then use the tweet IDs to request RTs and count them. For favourites, it looks like this isn't supported by the [official API](https://dev.twitter.com/rest/public) (unless you're the logged in user). Take a look at the official API, which will give you an idea what is/isn't possible. https://dev.twitter.com/rest/public
Hmm docopt? I'm more of an argh guy when it comes to command-line processing. I use evernote for my notes instead of org-mode. Basically this is a quick and rapid organizer. Maybe if Evernote had an SDK you could simply leverage that instead of a local database so the notes are available anywhere at all times. Either that or use some form of cloud storage for the notes for that purpose. 
When something is so out of your league as this article, it is best to keep digesting a little more than you knew before. I saw this article in /r/programming and glanced through it. Now I have a few takeaways: * To avoid ambiguity, put a comma after a single element in a tuple. Otherwise the parentheses around it imply order of execution (I think). * The class of a class (aka metaclass) is the class named `type`. You can create a class directly using this by supply 3 arguments to the constructor of the class named `type`. That's enough for now. Any more will explode my brain. 
Good point. Still I think we can call it a valid proof of concept. Wonder if the site back end will change to disallow this kind of thing. Captcha verification of report etc.
It does this for me in windows 7 at work. The solution I have is to run it outside of the python interpreter. I use. &gt;Py -m pip install xxxxpackage 
This looks super useful, I'll install and try it soon. By the way would you mind it if I tried porting it over to python 3 ? Also you should try cross posting this to /r/learnprogramming . They love these kinds of projects.
Does anyone know of a similar tool for OAG-like flight schedules?
so what?
I suspect it wouldn't be too hard to add LaTeX support to my project (right now it _supposedly_ supports text, html, and textile, along with markdown, but I generally only use markdown itself), but I did try LaTeX on a few projects back in college. It didn't feel like a good fit for the things I was doing. It felt syntactically heavy, with a lot of stuff to remember and a lot of time spent debugging.
Not at all. But I have to warn you that like I mentioned it originally was for personal use so the code isn't really well structured or documented. But I'll try my best to make this better. 
your welcome :)
Now compare that to bottle :)
My welcome?
I am still shopping for a software to share passwords with fellow sysadmin on the terminal. Does this allow to share passwords?
If you're worrying about micro-optimizations you're probably using the wrong language :(
Have you tried pass? It just stores a bunch of gpg encrypted files in a folder structure and you decrypt with a master password. You could then just push this to a git repo and have your coworker clone it. Pass has this really simple git integration where it will add and commit when you add a password in so all you need to do is 'pass git push'.
Thank you! This really helps me out... I will have to think on this for a while then...
Thanks. Interesting, but the `singleton` decorator and the `Singleton` metaclass do not have the same functionality. Whereas @singleton class Foo(object): pass help(Foo) produces utterly useless help on the the decorator's embedded `get_instance` function, class Foo(object): __metaclass__ = Singleton help(Foo) produces useful help on the `Foo` class. 
wtf? you had all semester.
Funny, I was just working on a similar thing for my personal use. I have a few questions if you don't mind: - Are the files being saved to /tmp in plaintext, or already encrypted? - What's the fallback strategy? Supposing I cannot run your program anymore for some reason, can I easily extract the data using *nix command-line tools?
Sure, just share your ~/.passpie or whatever path you specified when initializing the database with your fellow.
As a newcomer with a cursory interest in Python compiled into Java machine code, why is there only a Python2 equivalent?
Because no one has written a py3k interpreter. Python 3 is next, now that 2.7 has been released.
Alright, consider a class to be a type of object something can be. So, for your first card, Card1, you would declare it as being equal to the class, with the parameters your class constructor("__init__") requires. Say we're creating a car: Your car has a certain amount of gas in the tank, so it'll be one of the variables in the constructor. class Car(object) def __init__(self, gas): self.gas = gas You follow the same procedure for each variable that kind of object would have, but you don't hardcode that variable with a specific value because, going back to our example, different cars will have different amounts of gas in them. On to declaring objects. As a comparison, look at how we declare an integer in Python: num = 5 Now, for objects, it's done in a similar way. Going back to our previous car example, since we're now creating a specific car, we need to fill in the specific values for all the generic variables our car will have. Since our car has some amount of gas in it, we thus need to declare the amount of gas in the car in order to fully *construct* (hint hint) the car. car1 = Car(40) Thus, as you can see, while all Cars have a gas variable, car1, a specific object, has 40 units of gas. If we were to create a second car, car2, we could then compare the two car's gas variables by calling their respective gas variables. This leads us to calling methods and variables from other classes. To call a variable or method from your own class, you can either just state the variable or method name, or preface it with "self." first. We use that in our constructor to make the gas variable for the class point to the variable which exists only in the class constructor. In order to call a variable or method from another class, however, you'll need to preface that variable or method name with the object's name first. Thus, to call the gas variable from car1, you would need to type "car1.gas", not just "gas". Thus, now that we know how to access the variables of specific objects after constructing them, we can directly compare these variables. Here is an if statement as an example: if car1.gas &gt; car2.gas: print("Car 1 has more gas!") Using these principles, you should be able to solve your homework on your own. If you have any more questions on how classes work, feel free to ask. Some of us might point you towards /r/learnpython since they're more equipped to teach you, but for future notice, it is alright to ask questions here as long as you show that you've tried to solve the problem yourself, and most importantly, that you're trying to learn, not just get someone to do your work for you.
keepasscli might work for you.
Wikipedia also gives you an option to search it in english on the start page. And it has a name that sounds like "encyclopedia" so it gives the user an idea of what wikipedia is. I have no idea what "r8lst" is. I'm guessing I will be rating lists. Lists of what? I don't know. And then, instead of caching the choice of english, any time I return to the website I have to tell it english again. Why do I have to pick it? Most people either speak english, or are able to navigate a web page well enough to find the part that says 日本語, or espanol, or whatever. And why does your production website have TODO lists in it? Why not remove those when you push to production from development? I'm still not sure what your website even does other than attempt to curate lists.
It's not confusing. It's very well-written. It's just I cant absorb new information so easily, so I just have to take a bit at a time.
If I double-click it just opens the console for a split-second and closes. If I type C:\Python27\Lib\idlelib\idle.bat it does nothing. 
meh
I get that, but the point is to show, remove unwanted django parts when not required.
Would luv it was on python 3 porting sucks
http://tvshowsapp.com/
I remember looking into Jython a long time ago when I was first using Python (I had more familiarity with Java back then than I do now). While it looked promising, it has seemingly always lagged far behind CPython, which makes it less compelling. It's really a shame, though, since there are some good things about the Java platform.
Vim is like a robot that does things for you, it can perform a lot of work for you - the catch is you have to give it precise instructions... You don't want to spend a lot of time explaining to it what to do, otherwise you might as well just do the task yourself in less time. But that would pretty much apply to computers in general. Or maybe that is the point - vim lets you apply the powerful capability of a computer to editing text. Vim is like the minimap and unit groups, etc. in a strategy game. Using some other editor is like side scrolling everywhere, and ignoring all the rest of the interface. That is a decent analogy for movement in vim, but vim's awesomeness is not limited to movement. Vim's selection and movement, based on objects of text (words, lines, paragraphs, etc.), is like using the magic-wand-select tool in an image editor instead of drawing a complicated selection freehand.
Hmmm, curious about your namedtuple comment - when I was using them to store vertex attributes for opengl stuff I found them significantly faster than using a regular class with instance attributes. I think namedtuples are implemented using a regular class with __slots__, is that right?
Which one? He did at least two at PyCon 2015 last week. Beyond PEP8 https://www.youtube.com/watch?v=wf-BqAjZb8M Super considered super! https://www.youtube.com/watch?v=EiOglTERPEo 
Thankfully this no longer happens in Python 3. It raises a TypeError. Much better.
Triple quotes as a drop-in replacement would add whitespace to the start of each line, unless you wanted to ditch the source code's indentation of lines after the initial one. To fix that you could do: return textwrap.dedent('''\ &lt;html&gt; &lt;body&gt; etc ''') 
I would say both are great.
it builds jvm bytecode which allows very deep integration with the jvm tools and java itself. Also, I think NO GIL but i would need to check.
where do you see 3.4?
Spyder ? iPython notebook. I love the last one but it's only good if you don't want to write libs in it.
This works great and I can see myself using it. Good job, man!
Does anyone know what advantages this affords over comprehensions? l = ['sam', 'bill', 'frank'] l2 = ['sam', 'fred', 'bill'] result = [ i for i in l for i2 in l2 if i == i2 ] print result 
This is an important point on the difference between generators and lists in Python – both are iterable, but usually iterating over a generator *consumes* the objects, i.e. you can't iterate on it more than once. In /u/nsfyn55's list comprehension (and /u/taleinat's comprehension using an iterator), l2 gets walked `len(l)` many times. By the time `'bill'` in `l` would have matched `'bill'` in `l2`, the iterable `l2` had no more `'bill'` to match having been consumed entirely during `l`'s `'sam'` item.
The result of `find_elements_by_xpath` is a list of elements, not a single element. If you're sure you only want the first one, use `[0]` to access the first element of the list, for example: from selenium import webdriver driver = webdriver.Firefox() driver.get("http://proxylist.hidemyass.com/") proxies = driver.find_elements_by_xpath("/html/body/section/section[4]/section[1]/div/table/tbody/tr/td[2]") proxy = proxies[0].text print(proxy) Also in your print statement you don't want quotes around proxy otherwise it will just print out literally 'proxy' instead of the value of the variable `proxy`.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Hash join**](https://en.wikipedia.org/wiki/Hash%20join): [](#sfw) --- &gt; &gt;The __hash join__ is an example of a [join algorithm](https://en.wikipedia.org/wiki/Join_(SQL\)) and is used in the implementation of a [relational](https://en.wikipedia.org/wiki/Relational_database) [database management system](https://en.wikipedia.org/wiki/Database_management_system). &gt;The task of a join algorithm is to find, for each distinct value of the join attribute, the set of [tuples](https://en.wikipedia.org/wiki/Tuple#Relational_model) in each relation which have that value. &gt;Hash joins require an [equijoin](https://en.wikipedia.org/wiki/Equijoin) predicate (a [predicate](https://en.wikipedia.org/wiki/Syntactic_predicate) comparing values from one table with values from the other table using the equals operator '='). &gt; --- ^Interesting: [^Symmetric ^Hash ^Join](https://en.wikipedia.org/wiki/Symmetric_Hash_Join) ^| [^LucidDB](https://en.wikipedia.org/wiki/LucidDB) ^| [^Block ^nested ^loop](https://en.wikipedia.org/wiki/Block_nested_loop) ^| [^Adaptive ^Server ^Enterprise](https://en.wikipedia.org/wiki/Adaptive_Server_Enterprise) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqwvyuf) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqwvyuf)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Seaborn makes lovely plots. It's included in the super-useful [Anaconda](http://docs.continuum.io/anaconda/pkg-docs.html) distribution of Python.
An awesome feature is that it sits atop matplotlib. You can just import seaborn and all of a sudden all your regular matplotlib plot look better ... and you have access to seaborn's great palette code and style context managers; so even if none of the seaborn plots are interesting to you, it's worth getting just to make better looking plots.
But sometimes you often need compatibility with 2.7. Sure for example 3+ is the way to go, but a lot of my tools require 2.7 still because I have supporting libraries that are not yet ported to 3 and are not in the position to be updated. While this is from 2011, its still valid today as it was yesterday http://lucumr.pocoo.org/2011/12/7/thoughts-on-python3/ 
Nah this is something she just sprung on us. I had many other projects to do in my design classes for engineering
Yes, if they are using WLST for WebLogic.
Import seaborn seems magic to my notebooks. All ugly matplotlib plot turn to beautiful d3-like plot.
Please forgive me for the ignorant question. I've been programming in python for a few years now. C# for about a year. I just don't understand the appeal or use for Jython. I'm sure it's there, because I know people who love it. Can someone give me some practical pragmatic uses for Jython that can't be accomplished with CPython or are easier in Jython? I'm genuinely curious and would love any resource or input.
Same reason everyone imports numpy as np, pandas as pd, and matplotlib.pyplot as plt. Simple convention. 
seaborn takes to long to type each time and its convention now, other people will be able to more easily read your code. Additionally its bad form to do from seaborn import * Same reason we do import matplotlib.pyplot as plt
Sure, but those others make a bit more sense. I could see `import seaborn as sn`, but the extra s just throws me off. It's not a big deal, I was just wondering if there was a meaning to it.
thanks, finally some help. I m struggling with this for 3 days. What about if i want to print all of the list? Do i do some kind of loop? Or is there some kind of better way to do it. And what if i want to just save all of them in file, do i do a loop? or i can just place all elements inside variable? And how do i do that?
To be fair, WLST and its IBM counterpart are stuck on jython 2.2... ... but if you look in the oracle_common folder of almost any recent Oracle product, you'll find a 2.4 Jython sitting there. Some of the most recent products even use Jython 2.5, like Financial Data Quality Management Enterprise Edition (FDMEE).
See [my previous comment](http://www.reddit.com/r/Python/comments/34oqe6/jython_27_released/cqx06lo). BTW I'm sure you know there's also IronPython, if you'd like to accomplish more or less the same thing in the .NET world.
literally the most empowering thing i've ever heard
(author here) Just to note - we're very interested in having a wide range of topics at the conference, please do think about submitting a talk even if you're not usually in this community.
Need to know if the following is possible using the API: Extract past 52 week data for price and net asset value for several equities. Also query the current price/net asset value and have it updated real-time.
It's in their contributor guide that code will be tested on 2.6...3.4 inclusive. 
I use PySide daily at work for a very large scientific simulation application (tons of custom widgets and visualizations). I am in the process of switching to PyQt5. To be honest, PySide almost feels abandoned. I haven't seen any development recently, and I am starting to encounter some very tricky garbage collection bugs that I don't think will get fixed any time soon. &gt; Pyside is slightly more pythonic/beginner friendly I don't think this is the case. Their API is almost identical. In fact, the only API differences I have seen are very particular cases where you are casting Python values to C++ values, where PyQt requires you to match the C++ API exactly, and PySide is a little looser. In practice, these cases are not a big deal. &gt; documentation is better Their documentation *looks* better, but again, I think PyQt and PySide are equal here. To be honest, the new Qt documentation is looks nice and is very helpful (it links to super/subclasses, inherited functions, etc), and I usually just use the Qt C++ docs anyway. Qt5 has been out for a while now, and there are a lot of features and improvements over Qt4. PySide simply does not support Qt5. &gt; It's a $500+ fee and the Python community by and large goes with free open source tools. There are a few reasons why the license fee doesn't matter much: * I believe PyQt is free to use for open source projects (can someone please correct me if I am wrong? I am fairly sure this is the case) * From a company's perspective, if you already pay a programmer close to six figures, then shelling out an extra $500 for a package they use every day is not a big deal. * A lot of companies still take comfort in paying for programming products. From their perspective, if someone is willing to charge money and put their name behind a piece of software, then they have a commitment to making it work well. I don't agree with this point, but many decision makers do. Overall, the biggest reason PyQt is still around is because it is simply more actively developed than PySide, and there is a PyQt5 and no PySide5.
looks like pyside isn't being maintained, while pyqt still is. http://sourceforge.net/projects/pyqt/ Last Update: 2015-04-20 https://github.com/PySide/PySide last commit: 3 years ago
Both are free software — PyQt is GPL, PySide is LGPL. Nothing about the GPL prevents you from making money selling software, you just have to distribute the source. The commercial licensing option allows the option to not be compelled to distribute the source. PyQt has been around much longer than PySide, so it brings a much larger userbase. PyQt is also a lot faster moving; it supported Python 3 long before PySide did. And PyQt supported Qt 5 about six months after it was released, whereas PySide to this day still does not support Qt 5 even though Qt 5 is now about two and a half years old. 
deleted by mistake, I dont think it works :)
Yeah, it didn't haha, still trying! 
Thanks. I may give Tkinter a shot for now then. I'm still a long way off from selling anything and just working on becoming a better developer at the moment, but with so many GUI options I'm just looking to be pointed in the right direction because it seems like I could spend months bogged down in comparing these (the paradox of choice). As for selling software, I thought there are packages like py2app that convert a python application into a binary. Would that not protect the source and allow it to be submitted or am I misunderstanding what they do?
Ah, if it's once per developer that's not too bad. I thought it would be a recurring hit for every app I make. I will look into it but that is a bit of a relief. 
FFS MAN it has to be str(submission.subreddit) Jesus subreddit = r.get_subreddit('all') for submission in subreddit.get_new(limit=25): a = (str(submission.subreddit)) if 'funny' in a: print('----------------------------') else: print(submission.subreddit) I mean it was right there, you cant iterate over an Object
Wouldn't named tuples be a better choice?
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Hahaha thanks!
Seaborn has some great default plots and nice integration with Pandas. I especially like lmplot and violiplot.
From what he writes, seems he picked complex numbers for performance reasons. Travelling Salesman is quite computationally intensive. Normally we would not care about performance in Python but this type of problem is an exception.
Seaborn is the best plotting package in python, and I love it, but it's interface feels so irregular; Creating groups, deciding whether I need lmplot() or regplot(), etc. Maybe it's the best that can be done on top of matlibplot, but when compared to ggplot2 (R package) or an ideal graphical grammar, it's . . . idiosyncratic. 
Normally, yes, from a clarity standpoint. But with the complex data type, he doesn't have to implement his own euclidian distance function. It would also likely be less efficient than whats already in the std library.
Would probably need a few more templates to keep it fresh, but it should be possible to do a "Next week on Game of Thrones: X, Y and Z" where it combines the other templates without reusing any characters.
Because PySide is basically dead and PyQt is much more stable. I have code that doesn't run in PySide, but is fine in PyQt4. There also is no PySide5.
[Or this](http://mitpress.mit.edu/sicp/full-text/book/book.html). Also free.
I find the opposite, guess it is what you are used to.
I suppose could build a feature to search each language from the homepage using a drop down. To be honest not had enough time to roll in all the features I would like. "Most people either speak english..." - really? wow. news to me. It's in alpha, but ye removing the TODO's is on my TODO list ;) and yup it's for curating lists.
I fully agree that he explains things so well. I didn't get a "wow" feeling from his first Machine Learning class, but I found his design of computer programs class at Udacity way beyond "wow"... These sort of material (notebooks like the TSP one and the other one on XKCD regexp golf) are showcasing the higher-performance side of Python and generate more awareness about "the right ways to do things" for lack of a better phrase.
Yeah, its mostly of use when you've enabled Unicode literals and/or are writing single codebase python 2/3 
I'll sum up the article: A Ruby coder says, "(Python is) inelegant to read". One more thing, the article linked to in this thread was posted earlier somewhere else.
There's a lot of DevOps stuff developed in Ruby (or at least there was, a lot of it seems to be migrating to Go those days, but, anyway), and it's hardly ever mentioned on those kind of lists.
I've installed seaborn with anaconda and am trying to import it (on a Mac), but I keep getting error messages like this: File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "~/anaconda/lib/python2.7/site-packages/seaborn/__init__.py", line 1, in &lt;module&gt; from .rcmod import * File "~/anaconda/lib/python2.7/site-packages/seaborn/rcmod.py", line 5, in &lt;module&gt; from . import palettes File "~/anaconda/lib/python2.7/site-packages/seaborn/palettes.py", line 13, in &lt;module&gt; Anyone know how to fix it? Is 2.7 the problem? Do I need to be using python 3?
Head on over to /r/learnpython please. :D /r/python is for news and releases. /r/learnpython is for questions.
You can use rtmpsrv from the same guys who write rtmpdump. Compile it from source, well if not available on your distro which the case for me. http://stream-recorder.com/ is a goldmine of information if you want more details. 
The "time" example has nothing to do with Django or RoR... it's a comparison of the languages and not the frameworks.
Hey could you help me, when I run this script all I get is F�$@Bi����d�} here is the script import socket,struct,binascii def recvRaw(sock): raw = '' while True: try: raw = sock.recvfrom(2048) except socket.timeout: data = '' except Exception as e: print 'err, ', e return raw[0] raw = socket.socket(socket.AF_INET,socket.SOCK_RAW,0) etherHeader = recvRaw(raw) ethrheader=struct.unpack("&lt;BBHHHBBH4s4s",etherHeader[:20]) Destination = ethrheader[:14] print version_IHL
Out of people using the internet I think its fair to assume most people read enough English to navigate a page or possess the ability to find A different language option. 
This is some of the best teaching material I have seen in a while. It should be required reading for any CS pedagogy curriculum if such a thing exists.
&gt; Add to this that the original developer/BFDL basically orphaned Jython when he was hired by Microsoft, his successors haven't always been paid to work full-time on Jython... and you have a very slow-moving project. Except for the times when Frank W. was employed by Sun the project was always slow moving. There were also some missed opportunities like providing UI controls ( for editor + console ) which let a developer add a Python editor+interpreter panel to a Swing based GUI with ease. CPython compatibility is generally good and Java/Jython integration is just great but I sometimes sense a lack of sensibilities when it comes to the needs of developers who are dropped into the Java ecosystem and want to approach Jython. They only find a raw interpreter without additional batteries. This area is still only for Python enthusiasts.
Man, I love Norvig. His programs focus so much on solving the actual problem, not over-engineering the problem description, and the end resutls are so nice. Everything on http://norvig.com/ is also a nice read, esp. the sudoku solver story.
Namedlist bases on list type. Python list is actually dynamically resizable array of objects. It implemented so that it can to grow and to shrink fast. But it always use more memory than necessary. So lists are not memory efficient. Namedtuple and recordclass are supposed to be both fast and memory efficient. 
This is the best online course I've taken. I really like the fact that I never feel as though he's dumbing down the solutions because he hasn't got to that bit yet. He shows you the best solution he can think of, and if it involves a new language structure that he hasn't mentioned before then he'll tell you about that after the solution.
if I were you i would have a look at things like regex and fuzzy matching - it seems more appropriate Best of luck https://pypi.python.org/pypi/Fuzzy http://www.tutorialspoint.com/python/python_reg_expressions.htm
An example from scientific computing: [QSharedMemory](http://doc.qt.io/qt-5/qsharedmemory.html) is a class providing access to a shared memory segment. With PyQt I can take a pointer to the memory segment ('data' method) and instantiate numpy array, without any copying taking place, like this: x = numpy.frombuffer(pyqtbuffer.data(), count=size_in_bytes) because PyQt's binding of this class supports Python's buffer protocol. With PySide you simply can't do this. I made use of this to replace Matlab script server for LabView, which refused to work with arrays larger than ~15 Mb, by python proccess, for computations that had to be done for every measurement, but were extremely clumsy to implement in LabView.
You can also depend on a websocket abstraction library to make things easier for you on the python side http://autobahn.ws/python/ Don't be afraid to depend on external libraries if it makes your code more reliable.
 import random props = ['prop1', 'prop2', 'prop3', 'prop4'] # list of props characters = ['char1', 'char2','char3'] # list of characters genres = ['genre1', 'genre2', 'genre3'] # list of genres elements = {'Prop' : props, 'Character' : characters, 'Genre' : genres} for i in elements: print '{}: {}'.format(i,random.choice(elements[i])) Edit: Sorry, didn't refresh and see dunkler_wanderer's post before posting.
Thank you ;-) I will evaluate this, although reinvent the wheel is never a good choice, the goal I dreamt to reach was to avoid the dependencies installation overhead.. I'm a bit undecided to do so... 
Thanks dude, I have only just discovered this subreddit today so i wasn't too sure where to post this. Say i wanted to add a whole lot more props to the props 'set' (haven't learnt about sets yet, thought that was a list sorry). Would there be a more elegant way of doing that than just adding 300 items to the set?
Your input data has to come from somewhere, you can't just generate it out of nowhere. Either you have to write your lists manually or you need some prepared files with the listed props, genres, etc.. Maybe you can find some word lists online. Also, use lists (square brackets) not sets (curly braces), because you can't use random.choice with sets. 
the current state actually fits the title...!! 
Next thread: *Comparing letter writing tools: Microsoft Word vs. Notepad*
i prefer [TQDM](https://github.com/noamraph/tqdm), its very nice edit: i just realized its your code OP, don't mean to minimize your accomplishments!
Sublime is a good editor, but it's propietary and costs 70 bucks, unlike PyCharm Community and Vim/Emacs (both editors with huge extensibility). As a developer I'd rather not invest time in a closed ecosystem if I can avoid it.
[It's actually Czech ;)](http://en.wikipedia.org/wiki/Robot#Etymology)
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 7. [**Etymology**](https://en.wikipedia.org/wiki/Robot#Etymology) of article [**Robot**](https://en.wikipedia.org/wiki/Robot): [](#sfw) --- &gt;The word *robot* was introduced to the public by the [Czech](https://en.wikipedia.org/wiki/Czechs) [interwar](https://en.wikipedia.org/wiki/Interwar_period) writer [Karel Čapek](https://en.wikipedia.org/wiki/Karel_%C4%8Capek) in his play *[R.U.R. (Rossum's Universal Robots)](https://en.wikipedia.org/wiki/R.U.R._(Rossum%27s_Universal_Robots\))*, published in 1920. The play begins in a factory that uses a chemical substitute for protoplasm to manufacture living, simplified people called *robots.* The play does not focus in detail on the technology behind the creation of these living creatures, but in their appearance they prefigure modern ideas of [androids](https://en.wikipedia.org/wiki/Android_(robot\)), creatures who can be mistaken for humans. These mass-produced workers are depicted as efficient but emotionless, incapable of original thinking and indifferent to self-preservation. At issue is whether the robots are being [exploited](https://en.wikipedia.org/wiki/Exploitation) and the consequences of human dependence upon commodified labor (especially after a number of specially-formulated robots achieves self-awareness and incites robots all around the world to rise up against the humans). &gt; --- ^Interesting: [^Enthiran](https://en.wikipedia.org/wiki/Enthiran) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqxx4kz) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqxx4kz)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
If I try installing anaconda now, after I installed python from python.org, will I need to remove any preinstalled python files or edit pointers (other than my .profile)?
nice, I've been trying to find progress bars, and I've only found [progressbar](https://pypi.python.org/pypi/progressbar) but I don't like it. [clint](https://github.com/kennethreitz/clint/blob/master/examples/progressbar.py) has a progress bar too, but I haven't gotten around to trying it yet.
leave me alone
If you are in a notebook you can use the widgets like this: from IPython.html.widgets import FloatProgress from IPython.display import display from time import sleep f = FloatProgress(min=0, max=100) display(f) for i in xrange(100): sleep(0.1) f.value = i Edit: Missed a line...
The trial never expires, so it's essentially free if you don't mind being nagged every 20 saves.
~~Your code throws an error for me: [SNIP]~~ EDIT: That's pretty nice, have an upvote! The only advantage I see to mine (and it's a small one) is it explicitly gives warnings if you haven't properly matched up the number of iterations in the instantiation and the loop. For those using Python 3, replace ``xrange`` with ``range``. 
 from __future__ import the_solution
Is this just another intro to python or does it have anything special?
And a difference in RAM usage of only 800MB. 
Turns out I do mind. And an endless trial doesn't make the editor OSS, so I'm still at the mercy of the author if he decides to stop supporting it or worse, he suffers a security breach and doesn't notice it. Anyway, I'm still not saying Sublime is a bad editor, it's very powerful. But very competitive (and way more mature) alternatives exist in the open source world which brings its own set of benefits.
Tis why we got choice. I am a long time vim user, just in some cases I have been finding it easier to bring the features I love about vim to a jetbrains ide or visual studio, than it is to try and bring a bunch of language specific features to vim or ST. Some people will find the opposite. Also has a lot to do with what features people use like do you feel you need the integrated debugger or not? Also the nice thing about the jetbrains ides is they all share a common java plugin api, so once you learn to customize one you can do it for all of them. Things also depend on the language I have never gotten vim or ST to auto complete very well for python compared to pycharm. But on the C# side of things omniSharp for vim or St is on par or very close to visual studio intellisense.
I mentioned this in another comment so I guess I'll just quote it here &gt;I use sublime text for reading and writing code and pycharm for debugging and refactoring it. It plays to the strengths of both tools, although it bears mention that I have sublime so customized/with so many plugins that it's basically a lightweight IDE on it's own. I don't end up using the debugger often, but when I do, I do normally pull out PyCharm. I'm way more productive writing code in Sublime though. The default colors, fonts, and underline styles are kinda crappy/ugly in PyCharm IMO.
Thanks. I should have suspected there was a beginner thread
hacker in the hackernews definition I suppose (ie not the computer security one)
Sublime can't hold a candle to PyCharm, especially if you do anything involving a database, web application programming, or ipython. It's not even a contest. This is comparing a text editor to an IDE.
"...but it's still better to have less errors in a book, right?" It's better to have *fewer* errors in a book.
Sorry I must have missed a line ... I edited my post to add this line: f = FloatProgress(min=0,max=100) 
I guess it depends on what plugins you have running. PyCharm normally uses about 500 for me with spikes to 800 if I've forgotten to exclude large database files/directories from the project. The only time it feels 'heavy' is when I forget to turn off project sync and it's attempting to digest a 2GB database file. Then everything slows to a crawl or gets queued, but the little spinning circle makes it pretty easy to figure out why. Different strokes for different folks, I guess. Minimal RAM footprint isn't a significant performance metric for me when it comes to productivity. 
Can you explain why? What advantages/disadvantages are there?
http://norvig.com/python-iaq.html?
Fixed, thanks! :)
Check out this web page: http://doc.qt.io/qt-5/qt5-intro.html In particular, scroll down to see the links for the updates for each 5.X version (5.1, 5.2, 5.3, 5.4). PyQt5 is based on Qt5, which is simply the next stage of development in Qt over Qt4. Giving you an exhaustive list of changes here would be no better than you simply reading the changes I linked to. All of the PyQt4 tutorials I have seen deal with QWIdgets, which went relatively unchanged in Qt5, except for the split of the QtGui module into QtWidgets. Therefore, you can use PyQt4 to learn, and then use PyQt5 without much trouble. Or, you can adapt the tutorials to PyQt5 by just changing the import statements. This is discussed in the document you linked to.
Yes, that's it.
Visual studio shouldn't be listed with the rest. 
Please, can you share ToC or some details about book contents? It is hard to understand what it is about.
The reality is if you find something passionate to work on and you want to make progress on that thing you're gonna have to make choices/tradeoffs. Those choices are not going to be easy. Everyone else is here preaching some kind of "work-life balance." In my short experience this simply does not exist. All the successful people I know sacrificed something. Figure out what your lamb is and sacrifice it.
Better train this operation on a bare repo! `git reset --hard &lt;sha&gt;` is removing code and there is no come back! if you got the repository and now want Code Review from redditors you can do: git branch # you should be on branch "master" git checkout -b name_of_cloned_branch # clone of branch master git branch # you are on cloned branch git push origin name_of_cloned_branch # this will push cloned branch to the remote git checkout master # come back to master branch git log # check history of commits # go to the end of list and copy sha of first commit git reset --hard &lt;sha&gt; # WARNING!!! this will reset all commits on branch master touch init git commit -am "init" git push origin master now go to bitbucket, github, gitlab etc and create a Pull Request from cloned branch to master 
Is there something like the ToC and a sample chapter anywhere?
I found these links on the author's website. Table of contents: https://julien.danjou.info/media/the-hacker-guide-to-python-toc.pdf Sample chapter: https://julien.danjou.info/media/the-hacker-guide-to-python-sample.pdf 
I was amused to see a site called "opensourcehacker" review two commercial tools. I've tried both, then stuck with emacs. (No evangelism here: different people seem to want different things out of their editors.)
Yes, tqdm works fine in IPython notebook. It is a shame there is no a new tqdm release though - there are small issues here and there. But unfortunately I haven't seen a progress bar package better than tqdm yet: some of them don't look nice, others are slow, others don't have a right API, etc.
[Click](http://click.pocoo.org/4/) does as well, though I'm not sure whether or not it works in ipynb. It's a great library otherwise too, I use it all the time.
Thanks. I also took another link at the book's web page and found these links myself now, I didn't notice them before because they're next to a field to enter your email address where I didn't expect to find them.
A mixture. I can use Sublime for coding in any language (C, Python, C++, markdown, etc.) so I've gotten much more comfortable in it than I am in multiple different IDEs. It also feels a lot more responsive, and support for multiple cursors and rectangular selection is still a bit better than PyCharm. It also looks a lot cleaner IMO. 
Yeah. Funnily enough, I've started to use VSC solely for the purpose of reviewing file changes before a git commit. Their git integration is pretty fantastic.
Web widgets have been improved a lot in Qt5: 1. QtWebKit uses a much more recent WebKit build in Qt5, whereas Qt4 uses a build that is about 4 years old. 2. Since Qt 5.4, there are new web widgets based on Chromium, which follow quite closely Chromium releases. 
Actually, they're used for both sets and dicts. 
In my experience, those 2 and (much more subjectively) much much better default keyboard shortcuts. Oh and it and all my settings persist when I'm using other languages which pycharm don't support
Looks cool, and it would be nice to play with while waiting for the WiPy, but I'm not seeing anything that says how to connect the ESP8266 to a MicroPython board - as in, which pins on the MP board should be used. I guess more digging is required.
Download link?
Single-executable files and a nicer pdb would be very nice carrots, but I still worry about the future of Python 3. 
Sounds neat - is there a demo or screenshot to have a look?
Sublime Text is a superior code editor, but PyCharm is a superior Python IDE. I wish I could smoosh them together to have the best of both :/ Off the top of my head, a couple of positive things: - PyCharm's code analysis makes working with a large code base so much nicer - Sublime's multi-cursor editing is far more solid, consistent and reliable And a couple of negatives, again off the top of my head: - PyCharm's auto-edit/complete behaviour *really* grates when it doesn't work correctly, especially since there's no way to turn it off (not even an *easy* way - I've simply found no switch at all to turn off eg. matching HTML tag generation). - Sublime's lack of IDE features mean I prefer to use PyCharm in large code bases ;) 
This is totally awesome. skynet here we come. :)
Yep. send me a message with your email address and I'll get one to you.
While true, I think the reason that pycharm is so popular is that the majority of people find many of the features they rely the most on, it does well enough, if not much better than other alternatives. Plus, 8-16GB of ram is becoming commonplace, so you might as well put it to good use by utilizing all the indexing, and code insight features. One thing to note on sublime text and add ons is that while some can be installed from package manager, a fair number rely on some external dependency. Like markdown preview, and the setup can differ from platform to platform.
https://julien.danjou.info/media/the-hacker-guide-to-python-toc.pdf Not an intro. Stuff like packaging, scalability and deployment are covered. I would describe it as "An introduction to large projects."
https://julien.danjou.info/media/the-hacker-guide-to-python-toc.pdf
You flash the firmware and it becomes a µPython board.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck! ----- You might also want to ask over at /r/math. However, you may want to consider this: Let's say there were a million doors, and you got to choose one of them. Then the host of the show opened 999998 doors that were empty. Would you switch to that last door? The thing is your chance to have chosen the right door doesn't change when the host reveals information. It's always the same. So in effect, you get to choose either what's behind one door, or what's behind all the other doors.
Passpie [v0.1 release](https://github.com/marcwebbie/passpie) is out there. For those who want to check it out. :)
There's no need to define your own `printf()`; you can already do this by taking advantage of the way method binding works: &gt;&gt;&gt; str.format('Hello, {}', 'world') 'Hello, world' If it makes you feel better, you can even do this: &gt;&gt;&gt; printf = str.format &gt;&gt;&gt; printf('Hello, {}', 'world') 'Hello, world' I wouldn't really call this a "missed opportunity", nor is it really even specific to string formatting-- you can call any `str` method on a string literal, and it's merely a matter of opinion that the author finds that syntax to be strange.
Ah... see? I'm still new to this :) hehe
&gt; PySide almost feels abandoned https://bugreports.qt.io/browse/PYSIDE?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel When M$ absorbed Nokia and laid almost everyone off, the QT and PySide developers left as well. Still there's a few people semi-buried under there trying to keep the pilot light on at least.
Thank you :)
If nothing else, this article has taught me to keep better track of the Django changelog. I had zero idea that they'd introduced django.http.JsonResponse. That's brilliant. I've been doing this, HttpResponse(json.dumps(output), content_type="application/json") and it's tiring. 
~~Paid using PayPal but nothing happens, what should I do then?~~ 
I can't figure out why there's a 4 byte discrepancy between the Flask (22 bytes) and Django (18 bytes) examples!
Wow (´・ω・`)
I'm not sure posting this is socially responsible...
This slides about GIL, concurrency, coroutines are very good http://www.dabeaz.com/talks.html I saw him for a keynote at EuroScipy 2012 and he is a great speaker.
Agreed. Unfortunately at some point most of us will end up working on projects built by someone (usually new to the language) who wants the familiarity of what they know from C or PHP. There's always a utils.py file with a couple dozen wrappers like this around standard methods. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Byte order mark**](https://en.wikipedia.org/wiki/Byte%20order%20mark): [](#sfw) --- &gt; &gt;The __byte order mark__ (__BOM__) is a [Unicode](https://en.wikipedia.org/wiki/Unicode) character used to signal the [endianness](https://en.wikipedia.org/wiki/Endianness) (byte order) of a text file or stream. It is encoded at U+FEFF byte order mark (BOM). BOM use is optional, and, if used, should appear at the start of the text stream. Beyond its specific use as a byte-order indicator, the BOM character may also indicate which of the several Unicode representations the text is encoded in. &gt;Because Unicode can be encoded as 16-bit or 32-bit integers, a computer receiving these encodings from arbitrary sources needs to know which byte order the integers are encoded in. The BOM gives the producer of the text a way to describe the text stream's endianness to the consumer of the text without requiring some contract or metadata outside of the text stream itself. Once the receiving computer has consumed the text stream, it presumably processes the characters in its own native byte order and no longer needs the BOM. Hence the need for a BOM arises in the context of text interchange, rather than in normal [text processing](https://en.wikipedia.org/wiki/Text_processing) within a closed environment. &gt; --- ^Interesting: [^Specials ^\(Unicode ^block)](https://en.wikipedia.org/wiki/Specials_\(Unicode_block\)) ^| [^Unicode ^and ^HTML](https://en.wikipedia.org/wiki/Unicode_and_HTML) ^| [^Charset ^detection](https://en.wikipedia.org/wiki/Charset_detection) ^| [^UTF-8](https://en.wikipedia.org/wiki/UTF-8) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqywz9v) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqywz9v)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
awesome i ordered one :)
Interesting. I had a go myself before looking at your answer and got the below: def split(x): return(((x-1) * 4)/5) start = 0 while True: remainder = start for i in range(0, 5): remainder = split(remainder) if remainder % 5 == 0: print("Starting amount = %d" % start) break start += 1 It's a bit more concise, but not particularly efficient. It only checks to see if the number is valid in the morning, as opposed to after each sailor. Edit: In a single function def get_coconuts(sailors): start = 0 while True: remainder = start for i in range(0, sailors): remainder = (((remainder -1) * (sailors-1))/sailors) if remainder % sailors == 0: print("Sailors = %d" % sailors) print("Starting amount = %d" % start) break start += 1 get_coconuts(5) get_coconuts(6)
I like [Logbook][logbook], which has a nice Pythonic API and is compatible with `logging`. Here is the same example from the post: import logbook from logbook.compat import redirect_logging import thirdpartylib redirect_logging() format_string = ( '{record.level_name}:{record.channel} {record.msg} ' '({record.time:%Y-%m-%d %H:%M:%S}; {record.filename}:{record.lineno})') handlers = logbook.NestedSetup([ logbook.StderrHandler(format_string=format_string), logbook.RotatingFileHandler('rotated.log', max_size=100000, backup_count=1, bubble=True, format_string=format_string), ]) root_logger = logbook.Logger('root') with handlers.applicationbound(): root_logger.info('started') thirdpartylib.do_something() root_logger.debug('finished') Note that thirdpartylib is still using `logging`, which is redirected to Logbook. [logbook]: http://pythonhosted.org/Logbook/index.html
Bit rude to ask the author himself for an illegal download link... then again, maybe it's just the march of progress. Straight to the top of the food chain.
The main difference is which C++ libraries (Qt4 or Qt5) need to be installed on your system. You should probably choose based on what is more likely already there on your target systems.
I personally think that `logging.config.dictConfig` is also quite nice. The examples in the official docs are using a YAML file from which the dictionary is serialized, but you can just as easily define it directly in your code.
I think something like this, still trying to figuring it out myself. The pfalcon/esp-open-sdk seems to be depend for compiling the ESP source in MP sudo apt-get install make unrar autoconf automake libtool gcc g++ gperf flex bison texinfo gawk ncurses-dev libexpat-dev python sed git clone git@github.com:pfalcon/esp-open-sdk.git cd esp-open-sdk git submodule update make export PATH=$(pwd)/xtensa-lx106-elf/bin:$PATH cd ../ git clone git@github.com:micropython/micropython.git cd micropython/unix make make test &amp;&amp; sudo make install cd ../esp8266 make 
Maybe he meant Visual Studio Code which is just an editor rather than a full IDE.
Open command prompt, and type: `C:\Python27\pythonw.exe C:\Python27\idlelib\idle.pyw` What happens?
Why not? It's a python project! Indeed it's relevant!
Flask is pretty printing the JSON. From jsonify.\_\_doc\_\_: &gt; This function's response will be pretty printed if it was not requested with ``X-Requested-With: XMLHttpRequest`` to simplify debugging unless the ``JSONIFY_PRETTYPRINT_REGULAR`` config parameter is set to false. edit: So maybe there's scope for re-running the test without the pretty printing to see whether that affects the performance...
Ah. Good point. I'll update it when I get the chance.
If you have an Amazon Web Services account, you could check out [boto](https://boto.readthedocs.org/en/latest/). It's an SDK that interfaces with the RESTful API for AWS. The documentation is good, and it's easy to get started.
Is every app relevant just because it is written in python? That way lies madness.
DAE think MicroPython should be renamed MontyPython.
Amazon drives me crazy with their APIs. Not that they don't do what they should, but I always find myself studying info on the wrong one. Maybe that's a product of them doing so much or maybe it's my own lack of knowledge in that area, but it's hard to find the right info.
I had a lot of fun playing around with https://developer.forecast.io/ (weather information) and https://geopy.readthedocs.org/en/1.10.0/ this past weekend. I used Geopy to get Lat and Long based on a zip code then used the lat and long to get weather information from Forecast. It was all command line to play around with it, because really, do we need another web weather app? EDIT: GITHUB REPO https://github.com/jhwhite/pyweather
Maybe I did!
Playing with python-requests can yield some interesting results, especially if you are going to probe an API. Another fun option would be to use selenium to data-mine websites. I've personally had a lot of fun mining some websites and putting the data I got into a data-structure that I could use for other projects.
Oh, that's even better news ;)
And more readable. Could it allow invalid numbers to sneak through and become valid again by morning?
I'd probably just install pyenv via Homebrew on the target Mac. [Installing Homebrew](http://brew.sh/) and installing pyenv via Homebrew are shell commands that can be scripted easily enough.
Do you send this comment to every post that is about a project implemented in Python? Stop this BS.
If you figure it out and wouldn't mind sharing a binary, that would be appreciated :) 
No one has mentioned beautifulsoup yet? Beautifulsoup4 is my favorite scraping (extracting data from html) library. Also I would highly recommend that you play around with the collections, itertools and functools core libraries. Many common problems can be solved easily by a combination of those libraries. 
Requests is pretty damn awesome if you want to automate http activity. Among other things, I've used it to create a simple script that sets the National Geographic photo of the day as my desktop wallpaper. 
Troll somewhere else.
def try_this(): return True
I really enjoyed using the open movie database API: http://www.omdbapi.com/. For something completely different, you could take a look at http://scikit-learn.org/stable/, a machine learning package for python.
I lol in the office! Really interesting and simple!
Will qgrid work within a Spyder ipython console?
I remember seeing this blog post, it was a really great read! I would also suggest using CamShift over MeanShift to get a little better tracking accuracy. And of course, if you can incorporate any other features than color histograms your tracking accuracy will only further increase.
Don't do that to a newbie, that's not nice
It was much easier just before they got into all the cloud stuff. AWS was simply an API to get information about products sold on the site.
what binary do you want? the firmware elf of the ESP source in MP?
http://www.patvdleer.nl/wp-content/uploads/2015/05/build-MP-esp8266.tar.gz ;) [EDIT] http://www.patvdleer.nl/wp-content/uploads/2015/05/build-MP-esp8266-2015-05-06.tar.gz 
&gt;Could it allow invalid numbers to sneak through and become valid again by morning? Hmm... In theory yes, though in practice I'm sure it's unlikely. It might even be mathematically impossible. Thankfully it's pretty easy to fix: while True: remainder = start for i in range(0, 5): remainder = split(remainder) if int(remainder) != remainder: break if remainder % 5 == 0: print("Starting amount = %d" % start) break start += 1 Now we actually break out as soon as there's an invalid number, though we still have the redundant morning check.
Yeah, I'd personally never use a dot in a branch name. Just a-z0-9_
Looked on google and didn't see a ~$2 model, could someone link it to me? 
http://pythonbooks.revolunet.com/ Search YouTube for talks, especially those tutorials from PyCon every year, like this one: https://www.youtube.com/watch?v=oYTs9HwFGbY&amp;list=PL3cxt4ZfxFMPGxw_N5MQErNTX_01WeKiz
Try eBay or AliExpress. The cheapest (ESP-01) is like $2.20, but might be better to get [one with more pins](http://www.esp8266.com/wiki/doku.php?id=esp8266-module-family). There're also dev boards that would save you some trouble.
Thank you very much
Here's a numpy tutorial: http://wiki.scipy.org/Tentative_NumPy_Tutorial This resource will help you immensely: http://wiki.scipy.org/NumPy_for_Matlab_Users Numpy is mostly about its array class and operations. Other things - optimization functions, linear algebra things, and so on - live inside the scipy project. For plotting, learn matplotlib. In addition to learning the scipy stack, you'll also benefit a *lot* from learning Python, the programming language. Engineers tend to sometimes think about programming as that thing that makes the matrices move, and cannot comprehend why someone would want to want more than a couple hundred lines of code. If you are working with code, becoming a decent software engineer is certainly something you should strive for.
\#madewithPRAW
No Praw, No Party
i like to use lxml instead of bs4. 
Seconded. BeautifulSoup works the way HTML manipulation ought to work. 
It is a little wonky to use, but the [WunderMap](http://www.wunderground.com/wundermap/) does that. I used it for a road trip recently. If you select the "Trips" tab on the right column, you can enter your locations and a departure date and time and it will give you directions and weather along your route as well as little notes such as "ChanceThunderstorm".
maybe [trolling](http://www.urbandictionary.com/define.php?term=trolling) is the correct form
I'm deep into BS4 right now and I love it. It's so nice that it will make an HTML complete document; you can feed it crap and it'll just chug out an html doc with at least, the bare minimum tags. 
My mistake, you're totally correct - like /u/roerd said though, I was referring to [Visual Studio Code](https://code.visualstudio.com/), it's a lightweight editor, and available for Win, Mac, and Linux. (They claim it can debug web applications, but I'll leave that as an exercise for others, I'm pretty set with PhpStorm. Looks like it's got potential though...)
For a beginner? I don't know, man. I feel like I'm a beginner and there is some deeper html knowledge that you need. I tried to use bs4 to scrape the flair numbers off of /r/thebutton and for the life of me could not figure out how. There also wasn't much documentation to help me. I had the span class name and I still could not do it. I'm sure this is going to prompt someone to post a one liner but remember I'm a beginner. I had all the syntax right (or so the docs said), but I just kept coming up with an empty list.
I'll post my must-have tool-kit for scientist/data analyst: **numpy** for quick numerics |--&gt; **matplotlib** for plotting | |--&gt; **seaborn** for even better plotting | |--&gt; **plotly** for interactive web plotting |--&gt; **scipy** for science | |--&gt; **sklearn** for machine learning |--&gt; **pandas** for data crunching 
I brought up writing web crawlers in an interview last night... hope it pays off for me too! 
It isnt a homework assignment :) But thanks! I learned quite a bit from this but i know now to post in /r/learnpython.
[Pillow](https://pypi.python.org/pypi/Pillow/) It's an image manipulation library. You can draw on a canvas and save images. You can filter an image, write a gaussian blur or bloom filter. It's a great way to get a visual side to your code. [SciPy and NumPy](http://www.scipy.org) If you're into math, you definitely need to check out this library. If you like image processing, all the math will be much easier with these. [Flask](http://flask.pocoo.org) Really my favorite toy these days. Write any HTTP service in a matter of minutes. Also, [Virtualenv](https://virtualenv.pypa.io/en/latest/) It's not a library or API, but it's an important Python tool. Familiarize yourself with it and you'll find that creating, maintaining and distributing Python projects will be much easier.
This seems like it would be complicated for someone with no networking experience. What can you do with network packets? Will I need another co outer to network to or am I just messing with my network and the Internet?
Extracting data from html? How much data does html hold? I thought it was the JavaScript that did everything like that. How much can you grab with tools like this? 
Hahaha! That sounds like a lot of fun. I'll definitely bookmark that second one. Finding lat and long off of zipcodes? That's awesome. 
What does it do?
`requests` seems to have pretty bad import/warmup time... I used to love it, now usually using `urllib3` for one-off scripts.
What does it do?
Thanks, I was wondering how to do this! Wonder if there's a way to add a "run" button in the sidebar? I'd love autocomplete support too.
The problem with that is that then you lose some of the functionality of print. Eg. you can't specify the file, ending character or whether to flush afterwards etc. And there's really no way to have both, because those are potential things that could be template parameters. You'd basically end up having to duplicate C and define a seperate fprintf etc as well, which seems a step backward. And the line terminator raises another question - to you copy C and omit it, or copy `print` and include it? If we're meant to be duplicating printf, then the right implementation is really: def printf(template, *args, **kwargs): print(template.format(*args, **kwargs), end='') 
Well, I did make several attempts (spent about an hour and a half trying to make it work before I gave up) trying to troubleshoot it. The first thing I did is make sure I was actually pulling the website correctly by simply printing the get. That worked. I'm fairly certain I had the right website. Then, I started trying to pull simple things like the title and body. That all worked, too. I could never pull the span, though. It was just beyond me. I deleted the project and everything or I'd show you how I tried to do it. I think there's something about tags in the docs that seemed right up my alley, but I never managed to get it to give me anything other than a blank list.
If you can see it in your browser, you can scrape it. 
Updates: The task definition needs a version property, where the version number is (at the moment) "0.1.0". Without it, the task works fine but it increments the warning counter in the bottom status bar. If you omit the "showOutput" value it defaults to "always", so it's not necessary. The resulting code: // A task runner that runs a python program { "version": "0.1.0", "command": "python", "windows": { "command": "python.exe" }, "args": ["${file}"] } And on OSX (using &lt;Shift&gt;&lt;Command&gt;B): // A task runner that runs a python program { "version": "0.1.0", "command": "python", "args": ["${file}"] } Of course you can use this idea to run all kinds of other things. I've been using this editor for a while now (instead of Sublime or Atom) on both Windows and OSX and no surprises. 
Don't know about the run button but I'm looking for options in the code. There is a run button in the debugger, and I managed to play with the debugger enough to get it to launch Python, but at the moment things didn't work very well (basically with Node controlling Python) -- I'll post if I find anything out. The Python Tools team at MS says they want to add lots of Python support (thanks, guys!) but it's going to be a little while. I told them I was going to try playing with build tasks, etc. and they were pretty supportive. Turned out to be easier than I had thought. 
Interactive computational environment. Make calculations, analyze results, draw pretty graphs. All from the web browser. http://ipython.org/notebook.html
You can mess with your own machine, locally, without anything involved in between. Make one program the "reciever" and one the "sender". Or just see what happens on the wire. Wireshark is a good tool ( the second link goes through a lot of them ) but over all, scapy is about as _simple_ as you can get networking on that level. You get an object-oriented interface that replaces what would otherwise be bit-shifting, bit-banging and specific padding, as well as CRC calculations, and all the other things. With scapy you can do small, simple things. Like build your own `ping` commmand. Or go more advanced, try out `traceroute`. Or why not see if you can get a hang of how `dhcp` and `arp` works. Here's something quick, an exploit against an IPv6 DoS vulnerability where clients would take an RA packet, look at only one field in the header, and apply that to the whole network interface, without further validation. [bongos.py](https://www.bongos.se/pages/exploit.html)
I am disappointed that it needs C compiler. Authors say that this module is modeled after luajit FFI, but there is significant difference: luajit FFI does not need C compiler to work. I hoped that Python's CFFI will work the same way and finally free us from the need of binary packages distribution.
HTTP is the way that web data is transmitted over the internet. It stands for "HyperText Transfer Protocol". When your browser visits a web page, it makes a series of GET requests, asking the web server to give you the webpage. When you submit data, for example, by logging on, or uploading a file, it does a series of POST or PUT requests to the web server, and the web server handles them. Also, whenever you go to a website, and get an error like "404 Not found", "500 Internal server error", "401 Unauthorised", and "403 Forbidden" etc., that's the webserver responding to your browser's HTTP request(s). These are HTTP status codes. https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Hypertext Transfer Protocol**](https://en.wikipedia.org/wiki/Hypertext%20Transfer%20Protocol): [](#sfw) --- &gt; &gt;The __Hypertext Transfer Protocol__ (__HTTP__) is an [application protocol](https://en.wikipedia.org/wiki/Application_protocol) for distributed, collaborative, [hypermedia](https://en.wikipedia.org/wiki/Hypermedia) information systems. HTTP is the foundation of data communication for the [World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web). &gt;[Hypertext](https://en.wikipedia.org/wiki/Hypertext) is structured text that uses logical links ([hyperlinks](https://en.wikipedia.org/wiki/Hyperlinks)) between [nodes](https://en.wikipedia.org/wiki/Node_(computer_science\)) containing text. HTTP is the protocol to exchange or transfer hypertext. &gt;The standards development of HTTP was coordinated by the [Internet Engineering Task Force](https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force) (IETF) and the [World Wide Web Consortium](https://en.wikipedia.org/wiki/World_Wide_Web_Consortium) (W3C), culminating in the publication of a series of [Requests for Comments](https://en.wikipedia.org/wiki/Requests_for_Comments) (RFCs), most notably RFC 2616 (June 1999), which defined HTTP/1.1, the version of HTTP most commonly used today. In June 2014, RFC 2616 was retired and HTTP/1.1 was redefined by RFCs 7230, 7231, 7232, 7233, 7234, and 7235. [HTTP/2](https://en.wikipedia.org/wiki/HTTP/2) is currently in draft form. &gt;==== &gt;[**Image**](https://i.imgur.com/CczH29N.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:Internet1.jpg) --- ^Interesting: [^Secure ^Hypertext ^Transfer ^Protocol](https://en.wikipedia.org/wiki/Secure_Hypertext_Transfer_Protocol) ^| [^HTTPS](https://en.wikipedia.org/wiki/HTTPS) ^| [^X-Forwarded-For](https://en.wikipedia.org/wiki/X-Forwarded-For) ^| [^Webhook](https://en.wikipedia.org/wiki/Webhook) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqzhxnk) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqzhxnk)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I dunno about urllib3, but urllib2 had problems with concurrent requests, which the requests library handled well.
It's a simple way to interact with rest apis. Try using python requests with the bacon ipsum API to print out something in a python script: http://baconipsum.com/json-api/ When you're done, PM it to me and I can code review it. Then you can move on to more advance APIs, like twitter, using the same library. 
You need a reversible (one-to-one) function that maps a sequence of characters into a number. This is trivial once you realize that a number already *is* sequence of characters. For example, the number 123 could be just as easily expressed as abc if you let a=1, b=2 and c=3. All that is left is converting between a base-10 and a base-N number system. The math is available on google. Look at hexadecimal or [Base36](http://en.wikipedia.org/wiki/Base36) for examples of number systems that use letters. The question actually contains an error because the provided upper limit of 26^10 is only the number of 10-character sequences. There are (26^10 + 26^9 + 26^8 + ... + 26) possible words of ten characters or less. Since there are more than 26^10 possible ten character words, it is impossible to map all of them into a number &lt;=26^10 without overlap (making reversal impossible).
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Base36**](https://en.wikipedia.org/wiki/Base36): [](#sfw) --- &gt; &gt;__Base36__ is a [binary-to-text encoding](https://en.wikipedia.org/wiki/Binary-to-text_encoding) scheme that represents [binary data](https://en.wikipedia.org/wiki/Binary_data) in an [ASCII](https://en.wikipedia.org/wiki/ASCII) string format by translating it into a [radix](https://en.wikipedia.org/wiki/Radix)-36 representation. The choice of 36 is convenient in that the digits can be represented using the [Arabic numerals](https://en.wikipedia.org/wiki/Hindu%E2%80%93Arabic_numerals) 0–9 and the [Latin letters](https://en.wikipedia.org/wiki/Latin_alphabet) A–Z (the [ISO basic Latin alphabet](https://en.wikipedia.org/wiki/ISO_basic_Latin_alphabet)). &gt; --- ^Interesting: [^Senary](https://en.wikipedia.org/wiki/Senary) ^| [^List ^of ^numeral ^systems](https://en.wikipedia.org/wiki/List_of_numeral_systems) ^| [^Base64](https://en.wikipedia.org/wiki/Base64) ^| [^224 ^\(number)](https://en.wikipedia.org/wiki/224_\(number\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqziet7) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqziet7)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Some neat things [here](http://pyvideo.org/video/1677/how-the-internet-works) (like making other machines think *you* are the router!)
Here's an example: Write a program that will access your reddit user comments page and scrape the first 1000 comments you made into a text file. That way you can archive your comments that you've posted on reddit, because maybe you've written some cool stuff over time and don't want to lose it and want it to be searchable on your desktop. **Edit**: Here's one possible version of the example program. It doesn't do any pretty printing, capturing dates, etc. but it does work. You could tinker with this version to create your own. import urllib from bs4 import BeautifulSoup url = "http://www.reddit.com/user/vplatt/" reader = urllib.urlopen(url) myCommentHistory = reader.read() # Use these three lines of code instead of the above 3 after reddit starts to think you're a bot. :) # myFile = open("example.html", "r") # myCommentHistory = myFile.read() # myFile.close() soup = BeautifulSoup(myCommentHistory) myPosts = soup.find_all("div", "md") saveFile = open("archive.out", "w") saveFile.truncate() for string in myPosts: saveFile.write(repr(string) + '\n') saveFile.close() 
Do you have pyopenssl installed? Requests will use it by default, and sadly right now it has a long import delay, though work is being done to fix it.
uh, that's undocumented and you should not use it. But there is dlopen which you should use
I completely agree, I was just responding to your point of: &gt;It's also notable that his replacement cripples formatting, making keyword arguments unavailable. I in no way condone or agree with what OP was saying, and couldn't have made the point clearer than you have above (vis-à-vis orthogonality of printing and formatting) 
Have you ever used ipdb? Being able to interactively dump variables is very helpful for figuring out these kind of things. It will also allow any commands to be run from the CLI so you can try out many different bs4 commands until you find the right one. For future reference, this concept is called REPL (Read Eval Print Loop)
/r/learnpython
why?
sqlite https://docs.python.org/3.4/library/sqlite3.html If you are new to python and want to start working with databases this is a good starting point. It comes with python so requires no extra setup and it's well documented.
I tried looking for "fun" examples to play around with and learn from, using the Requests library one time and the only thing I could find were basic tutorials on it. 
Asyncio will probably kill Twisted-as-we-know-it anyway.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Reddit has a pretty nice API. :)
I could not agree more. Go and concurrency are a match made in heaven.
It's not my project, but it does something like that. For instance, if you want to enter a non-existing directory, you get an error. If you issue the command "f*" the directory is created and you are entered into it. On the github page you can find more examples.
 #define BEGIN { #define END } History repeats itself, just the languages change. ;)
If you don't have even a passing familiarity with HTTP, using ANY API is going to be very difficult - and you can forget about debugging your program if there is an error.
I'm going to suggest Pygame. It's not terribly hard to get started with, and has a lot of capability for fun.
Regarding pillow, you can also use it to hide data within images :)
You mean the CTypesBackend and backend_ctypes are undocumented or that backends in general are not something to toy with? The backend keyword was documented, it's referenced in several other documents, the backend_ctypes module/CTypesBackend class were not prefixed with an underscore (which I'd usually consider to be 'don't use this') and there's tests for all that too. Usually that kind of setup tells me a few things about the API when trying it out: * Feel free to use this, it's just not well documented. * You can use this but it may have some unintended consequences that are not documented * We just built this and it's not documented yet but it's not hidden away either so it's probably ok to use (for now). Now I could go dive the history of the code as well as the rest of the code base and probably come to the conclusion that it's not something I should have done. Or I could probably figure that out through experimentation (which ended up failing in my case leading me to switch to dlopen). I guess what I'm trying to say is it was not immediately obvious to me that that setup was not something I should have used/recommended. Is there something I missed on the docs that would have made this more obvious that that was a bad choice? 
Let's see how a real letter looks like ! (couldn't find one on the website)
Cezar, you should do fun stuff with Pelican. Like totally beautify and make more awesome the ChicagoLUG website. 
&gt;If you don't have even a passing familiarity with HTTP ...you couldn't be posting here right now. :-)
I believe you can use LXML as the XML parsing engine for BS4. Haven't tries. it myself, though. 
Ya, its it can be a little rough to start but parsing HTML is a powerful. skill to develop. My suggestion: fire up your favorite debugger (the PyCharm debugger is fantastic) and take a look at what a BeautifulSoup object actually looks like, internally. Also, the book Getting Started with BeautifulSoup provides a more gentle introduction than the documentation. 
Is that at all like pandas' DataFrame? 
Yes you can, and it works well. But it's still slower than pure lxml parsing. The benefit of this approach is of course you can use BeautifulSoup's more idiomatic approach (IMO) for navigating/searching the document structure.
/r/learnpython
Twilio is super fun you can call people, sms them.
i can't even seem to get to the point where i can run 'Configure Tasks' as listed in the Tasks part of the docs link you provided. When I pull up the command line (OSX), there are no options that match as it is outlined on that page.... Which I'm assuming is the only way to get a tasks.json to work with in the first place?
I missed his visit to Bangalore. Hope he comes back!
[Link to PEP 492](https://www.python.org/dev/peps/pep-0492/) for the lazy -- "Coroutines with async and await syntax".
awesome! did not know about qgrid. Thanks for the post.
That's fantastic. PyCharm is the only reason I have Java installed &amp; great software. 
I came here to say openCV also. It strikes me as having the kind of fun, "wow you can do that?" element that a beginner would enjoy. Have an upvote and a link to a tutorial. https://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_tutorials.html
I've used lxml over bs4 because I found it to be much faster, but for ease of use and features I think bs4 is definitely superior 
I am not at my computer (at least not the one with Code on it) but as I recall... 1. Open a folder so you can see the folder contents in the side navigation panel. I don't think this is really needed, but it should help you see what is going on. 2. Create and save a file *hello.py* in that folder, with the usual contents, e.g. [ print "Hello\n" ] . 3. When that file is open, type the Build command (on OSX that's &lt;shift&gt;&lt;command&gt;B). 4. That will cause an error message of sorts, which will allow you to "Configure Tasks". 5. When you do that, you will have no *tasks.json* in a local *.settings* folder, so the editor will create one, copying a boilerplate tasks file there. 6. Edit that *tasks.json* file, getting rid of everything in it (don't worry, it's a copy, you can make more) and putting in the contents above. Save it. 7. Then go back to looking at *hello.py* and type the build command (again, in OSX, &lt;shift&gt;&lt;command&gt;B) (in Windows, &lt;shift&gt;&lt;control&gt;B) and it will cause the build task in the new *tasks.json* to execute and show the results of your program. Hope this helps! 
As with most things, you get what you pay for.
Would you mind sharing that script? I'm a super newbie looking for example scripts to learn from and that sounds pretty easy/interesting. (I hope I'm not breaching coder etiquette by asking this.)
Thanks 
Tear the program apart into smaller and smaller pieces until you find the problematic part
Trying that now, thanks. I think it's the fact that tried to def a function inside another function. Maybe I'm not doing it right idk 
Post the code??
Nah, he needs to do it himself. 
You probably have to install into the site-packages for both Python 2 &amp; 3. How did you install Pillow?
I'm not downloading some random file from the internet.
but BS defaults to lxml as its 'core' parser for a long time now. It's an API around lxml.
That's cool too 
the exact instruction for the program were "• Input is handled by one function. This function calls two functions: 1. A function that handles displaying the menu accepting various input from the menu and returning the meal cost, and the type of meal, a string. 2. A function that handles displaying the menu accepting various input from the menu and returning the room cost. The input function returns all entered data. • Calculations is handled by four different function: 1. The first function returns the product of any two arguments, this will find the charges for adults, children, desert, taxes, and gratuity.¬ 2. The second returns the sum of its three arguments, to calculate the total. 3. The third returns the sum of its four arguments, to calculate the grand total. 4. The fourth function returns the difference of any two arguments, this will find the balance due. • Output is handled by four functions: 1. A function that displays the header. 2. Another that generates an invoice number, and displays it and the data entered. 3. A third that display the list of itemized charges. 4. A fourth that displays the footing. " which is what i tried do in with the code, did i understand wrong or am i doing it wrong?
I can't help feeling a little vindicated. I suggested something like this here over a year ago and got nothing but downvotes. 
You play Dota2, so check out https://github.com/skadistats/smoke It's a replay parser that will allow you to do analysis on professional games, your own games, etc. Then from there you can just jump into trying to investigate anything that interests you about the game statistically!
This might not be so fun but I learned a lot playing around with [dnspython](http://www.dnspython.org/). I've taken the long self-taught path, it usually takes a lot more playing around with stuff than if you just read a book or take a class. So using dnspython was an amazing discovery about classes and subclasses for me. 
When this PEP was first posted a few weeks ago most people still didn't seem keen. I'm pleasantly surprised that Guido approved it so quickly. 
I have 2 pips as well. What OS are you on? and how did you install that 1st easy_install?
it has a super easy API too! and easy to test your app. good for a beginner.
I tried re writing the program. Without using functions inside another function. Rather than just have one function call another. But I'm still getting the same error I was getting before. Where adults is not define in adult_chrgs ://
Here's the new one https://www.dropbox.com/s/3yqd558hecerlo0/2015FINAL.py?dl=0
Dude, if it's being displayed it's in HTML.
That text box is in HTML also. It's hidden until you trigger an event. All javascript does is use CSS to display it (most of the time).