Ive always found the best way to learn is practice, rather than sitting and doing hello world over and over. Try to look at project euler, /r/dailyprogrammer, and other programming challenges (google). Figure out what you need to do a certain problem and look it up. Chances are there is code already up so if you get stuck you cam always see someone elses code.
Try making a daily life simulator for yourself. Make objects of things you encounter and give them some random behavior and then have it guess how your day will go. 
Well, at least I'll end up learning lisp, so there's that.
I'm somewhat surprised you didn't find it on your own, what with the interactive mode [telling you about it from the start](http://i.imgur.com/xZZmwVp.png) and all.
Like if you have a coworker named Lloyd who always either gets mad, says how are you, or says how's it going, you could make a Lloyd subclass of a coworker object that will do one of those three things. Use random.choice to have it decide. Then you can add like hundreds of other similar objects and just run it and have it say: There was not much traffic Then Lloyd got mad Then you got coffee and it was ok Then you worked in tps reports. Becky called Etc etc. Kinda silly but would be a good way to do lots of straightforward oo design. 
You just need to reverse it.
I knew very little about Python before watching that video. I remember my mouth being agape most of the time and bursting into applause at least twice. :-) I then told everyone at a forum for another computer language how awesome I'd just realized Python was and then they all hated me. :-( But it was worth it to discover how beautiful Python is. 
I have a whole bunch of scripts I need to write for work. Wanna work for free? ;) Seriously though, I just saw a cool project, it's called "ti", it's a time tracking for the commandline: http://ti.sharats.me/ You could develop something similar to that. It's actually written in Python! It would be a fun, and useful, project. Just don't look at his code, that would be cheating! Try writing something basic like that for yourself.
pyenv is not about shipping, just an analogue of rbenv - allows me to manage local python versions + virtualenvs using one application, deriving virtualenvs from python versions using pyenv-virtualenv ( like having anaconda handy for notebook session with statistics or developing Py3 alongside Py2 ). For shipping os packages (Linux and Windows), I use this: [infi.projector](https://github.com/Infinidat/infi.projector)
No, I'm shipping mostly Linux(Windows), so for building os packages I use this one: [infi.projector](https://github.com/Infinidat/infi.projector) For Mac I just have a copy of local pypi server, package with the infi.projector, it automatically uploads to local pypi server, and install in pyenv + venv using pip if needed.
Yes. Imagine that you're running hundreds of tests using Jenkins or any other CI tool. When you have your reports ready, you want to know what test failed on what platform, using `attr` plugin, and quickly navigate to the passed test using its ID (which is unique) instead of searching according to the docstring. Compare the following: Checking title appears ... ok Checking title appears ... ok Checking username exists shows successful dialog ... ok Checking password correct successfully logs in ... fail Checking password correct successfully logs in ... ok To (121, platform1) Checking title appears ... ok (121, platform2) Checking title appears ... ok (122, platform1) Checking username exists shows successful dialog ... ok (123, platform1) Checking password correct successfully logs in ... fail (123, platform2) Checking password correct successfully logs in ... ok (`121` and `platform*` are just examples of `id` and some other attribute, you might have many other) Which one is easier for tracking and more informative?
My first suggestion is, if things aren't working in CentOS, is to try turning SELinux off. Type 'sudo setenforce 0' into the terminal. Try everything again. If it works, then you know you need to fix your SELinux permissions to use Spyder. Type 'sudo setenforce 1' after trying this. If you need to set some permissions, search for 'setsebool' or 'audit2allow'. The former is easier, in my opinion.
I find the flask globals to be rather annoying (you touch on that [here](http://morepath.readthedocs.org/en/latest/compared.html#explicit-request)). I don't see what added value or simplicity they bring, and it just makes apps hard to test. In Flask, "Unit testing" is creating an instance of the `test_client` and sending requests to the application through the underlying WSGI framework to your application (which isn't really unit testing at all, thats more like integration testing). Actually unit testing flask view functions requires such a horrible amount of monkey patching the global objects that I don't even bother.
Thanks. Must have missed that.
:-)
Noooo, but I want actual refreshes... that way I get more pageviews ;-) Advice?
To clarify, I will accidentally do that when I want to have a list or dict as the default value for an unspecified argument. But really, the actual behavior I want is: def func(defaultarg=None): if defaultarg is None: defaultarg = [] # rest of the code 
So `nose-docstring-modifier` and `nose-ittr` must be used together to be useful? It looks like `nose-ittr` tries to achieve "parameterization" by monkeypatching attributes onto the test function. The docstring modifier then picks up these attributes and appends them to the docstring? Yikes. These examples are also confusing because the `@attr` decorator isn't in either of your libraries and theres no explanation of where it came from (assuming the builtin plugin `attrib`?).
If you reverse it you prepend instead of appending, which has just the same problem.
This seems great! I'm working through Learn Python the Hard Way at the moment. But it's a bit dry for my taste. I like a more "do it yourself" approach and I prefer to learn Python 3. I definitely give this one a go! Although I might skip a couple of chapters.
No. I find it useful because I don't hardcode things to docstring and I have the ability to show exactly what I want on different cycles. It's extremely useful when used with `nose-ittr`. Indeed. `@attr` assumes the builtin plugin `attrib`. Whether it's useful or not, it's up to you. I'm not forcing you to use it :) I just showed you examples of how much it's useful for me, and yes, combined with `nose-ittr`.
Seems installing this removed setuptools which is required by a few of my applications. simple `pip install setuptools` fixed that.
I'm coming to Python from Clojure, which has very cool unpacking (which is callled destructuring over there). I miss it very much in Python2.7, gonna take a look at Python3. Is there also dict unpacking?
Once I learned list comprehensions and used them more (mostly from working with Erlang for a while), I find them *much* quicker to read and understand, it clearly shows how the list being constructed will look, and the source of each piece.
Yes. For example, you can unpack a dict to keyword args like this: def foo(a=0, b=0, c=0): print(a,b,c) &gt;&gt;&gt;foo() 0 0 0 d = {'a':1, 'b':2, 'c':3} &gt;&gt;&gt;foo(**d) 1 2 3 
Yes, creating a pipeline with `|` requires the shell as it is the shell that establishes the pipeline. However, you can do that yourself to avoid the shell. To run the equivalent of `foo | bar`, you can do something like: from subprocess import Popen, PIPE foo = Popen(['foo'], stdout=PIPE) bar = Popen(['bar'], stdin=foo.stdout) bar.wait() That's not quite exactly the same but it should suffice for most purposes. 
[nose-ittr](https://github.com/taykey/nose-ittr) use the same method (monkeypatching) like @attr from atrib plugin to append those values to the test. The parameterization achieved by metaclass that replicas tests based on passed parameters in @ittr decorator, the monkeypatching is there to pass those parameter values inside the test for its use, and support running specific parametrized tests with -a argument [nose-docstring-modifier](https://github.com/taykey/nose-docstring-modifier) just use those values to make the docstring more informative 
I agree with you that global state makes testing harder. I've carefully designed Morepath to avoid global state. You can just call a view function like any function (with a model instance and a request) - and it actually really is the Python function you see that you call, not a wrapped thing, even though a decorator is in use. There is only one implicit system in Morepath, which is the dispatch context in which generic dispatch takes place. This is actually based on the Reg generic dispatch library that Morepath is built on. Reg has two modes of operation: * explicit passing of this context (through a 'lookup' argument to generic functions) * implicitly setting up the current dispatch context as a thread-local. Morepath itself only uses the former, and thus is completely explicit. But if developers write their own generic functions and call them without explicit 'lookup' argument, they rely on this implicit behavior. This is a compromise towards readability as passing lookup along over and over looks rather ugly. But you can also turn this behavior off for your own codebase, and I recommend framework code does this too. 
I've been keeping an eye on Docker, but can't quite tell if I should start using it. Can Docker be used to also include system libraries painlessly, like libgtk2.0-dev?
Morepath is primarily targeted towards building RESTful APIs and single page applications. While I believe a good REST framework can also be a good classic web framework as the concerns are very similar, REST is what we're using Morepath for. You may be interested in reading a previous blog entry I wrote that describes how the framework takes care of RESTful status codes: http://blog.startifact.com/posts/better-rest-with-morepath-08.html Concerning SQLAlchemy integration, more.transaction is an extension that can work with SQLALchemy. Here is some demo code: https://github.com/morepath/morepath_sqlalchemy Morepath has a built-in authentication and authorization framework: http://morepath.readthedocs.org/en/latest/security.html What's missing as of yet is integration with user signup systems and so on; it's something we've been looking into: https://github.com/morepath/morepath/issues/206 This would become a Morepath extension, as the core ramework is supposed to be general. As to an admin UI, I hope we can eventually build one on top of a REST API as a single-page app, but again it would be an extension to Morepath (or possibly even more general than that; no reason to tie a UI into Morepath specifically) By the way, you mention reading the docs and finding "but you're doing a bunch of other stuff as well" -- could you expand on that a little? What other stuff did you find that wasn't relevant to REST? We're very interested in what message we're putting out. 
Even though `shell=True` might be useful sometimes, and handy for throw-away scripts, I believe you should edit your post and tell people that it is extremely discouraged, because it is fragile and dangerous and unsafe. Really, the official Python documentation puts big red warning boxes regarding its use. Learn more: * https://www.reddit.com/r/Python/comments/2nh3jt/top_10_python_idioms_i_wish_id_learned_earlier/cme6hgy * https://docs.python.org/2/library/subprocess.html#frequently-used-arguments
&gt; In Flask, "Unit testing" is creating an instance of the test_client and sending requests to the application I don't agree with you at all. (On this point. I agree that global state is slightly annoying, at least conceptually, but not that much, thanks to smart decisions by Armin, cf. http://flask.pocoo.org/docs/0.10/appcontext/ .) In my case (cf. https://github.com/abilian/abilian-core for examples [*]) we have unit tests for our domain classes and our services that don't involve Flask at all. And we have integration tests that setup / teardown the Flask app and use the Flask test_client, to test the web layer. [*] Actually, this might not be fully the case yet, but this is the direction we are going towards. We're also moving towards more py.tests and less unitests and nose.
Pure RESTful server-side with a SPA client is, at this point, a radical architecture decision. I've recently started a project with this architecture (with AngularJS on the front-end) and went back after a while to a more traditional approach with server side rendering of Jinja2 pages. So at this point, I'm a little wary of a framework who only promises me REST services and no server-side HTML rendering. Also, I've noticed that "pure REST" architecture, despite their conceptual beauty, also have some performance drawbacks, which lead some (such as Netflix) to use a less conceptually pure, but more efficient, approach based on "use cases". Another currently unanswered question is: which serialisation standard to use, if at all? At this point we have interesting initiatives like Restful Objects, OData, collection.document+json, JSON:api, DocJSON, etc. So many competing standards, let's make one more ! (ob. OKCD quote).
&gt; I'd also add knowing that you shouldn't use a mutable value for a keyword argument, like in def func(arg=[]). That trips me up. Yes, that's a typical Python gotcha. However, once you know of it, it can be used as a neat way to persist data between function calls. Especially for nested functions in Python2, which lacks the nonlocal keyword. Something along the lines of: def cachedwrite(buffer, string, flush=False, cache=[""]): """Cache output as a single string and write to buffer.""" cache[0] += string if flush and cache[0] or len(cache[0]) &gt; 65536: buffer.write(cache[0]) cache[0] = "" 
Hmmm... I would much rather just whip up a simple class for this, it's a lot more obvious what's going on.
No, you can't destructure dicts. You can only unpack them into function keyword arguments, not into an assignment
Once you know the idiom, it's quite useful and natural though.
What would an example be?
I agree that testing on the web layer is a reasonable way to approach things. A lot of tests of Morepath itself are using webtest (from the Pylons project), and it is very useful to do that. (but of course you'd test a web framework on the web layer a lot) That said, I do think it makes sense to design a framework to avoid global state as much as possible. 
Don't say that when there's tools like exec around. :p But seriously don't do that.
The prerequisite is simply 1) mutable data and 2) sensible default. It's no different than having immutable data with a sensible default, except you need to mutate it during the function. I think maybe you're considering mutating from the caller's perspective (e.g. a function that exists purely to mutate the data you pass in), but this is mutating simply to construct an object internal to the function, and allowing the caller to pass in a default starting point. I can contrive some examples for you. How about building a select list dynamically def color_choices(choices=None): if choices is None: choices = ['red', 'blue'] # Sensible default if ...: choices.append('green') return choices &gt;&gt;&gt; color_choices() ['red', 'blue', 'green'] &gt;&gt;&gt; color_choices(['yellow']) ['yellow', 'green'] Or constructing a config object def build_config(default=None): if default is None: default= {'DEBUG': False} # Sensible default if ...: default['DEBUG'] = True return default &gt;&gt;&gt; config = build_config() And so on. Either of those would be nicer to be able to put the sensible default in the kwargs, but we can't.
links to http://invpy.com/diff are dead. (like on page 18)
just get a vm and install whatever you want. shared hosting wont get you anywhere if you want to do more advanced things. too many limitations, dont waste your time.
can't really go wrong with a vps from digital ocean or linode
Does that book use Python 2 or 3?
I've been building applications using this "radical architecture decision" since about 2010, so my perspective on what's radical is slightly different... There are a lot of popular web applications around that use a single-page approach. Why did you decide to go back from your Angular experiment? It would be interesting to find out. Obviously there are plenty of cases where server side templates are the way to go. It's also clear there's still a lot of learning to do in the client-side space. I think a JSON-based REST (without standards in sight) with a single page UI can create much looser coupling between UI and data than I've seen with the typical server-side approach. I found that really valuable. I think JSON-LD is one standard that can help add just a bit of structure to this JSON. REST can make an application more spammy - a request to get an URL, then making another request, etc. On the client side that can lead to nested callbacks, but good model/view style architecture can make this go away (as I found out with Obviel, along with everybody else around the same time with their own client-side web frameworks). It can also result in more (smaller) requests going to the server. That can be a problem in certain scenarios. I'll note though that we're not all Netflix, and we certainly don't all need to scale out to Netflix size all at once. In addition, a range of approaches are there to help you optimize HTTP traffic, such as caching. Using HTTP at least helps make analysis possible and makes optimization tractable. So people also argue *for* REST in the performance context. In any case, Morepath doesn't force you to do pure REST - you can come up with shortcuts if you like. But it Morepath helps you if you do go that route. Finally, if I may be so bold, while I do think there are legitimate arguments against REST and single page apps, your arguments without further fleshing them out have the faint whiff of FUD around them. I mean, let's try to turn it around: "I had a bad experience with PHP so I'm a little wary of frameworks with server side templates now. And some server-side approaches that used templates really didn't scale. There are a lot of server side templating languages and nobody seems to be even trying to standardize them." 
For VPS I love Ramnode, but shared hosting I've got a few small sites running on Dreamhost and it works reasonably well.
Yes you can. You create your docker images with a docker configuration file, then you can deploy those images. As part of creating an image, you can do things such as installing packages and libraries. Once this is done it is part of your image. You can ship and deploy your image (a big file containing your container), and it'll include everything you added to it.
Thanks for the suggestion!
With small VPS instances at $5 on DigitalOcean, there's little reason to go with shared hosting, especially when you have requirements for python versions etc.
Alright ill check it out gracias
What has you looking for shared hosting? I've used Linode since 2007 and am very happy.
How exactly are you trying to "use" the URL, and what happens as a result?
Will definitely trawl their code. Thanks!
Thanks!
Also recently setting shell to true would make you vulnerable to the infamous shell shock vulnerability even if you would escape arguments correctly. 
`Japan_Earthquakes` is a pretty strange name for a hidden porn folder...
with bluehost you can get shell and then use cgi to fcgi bridge. It not what I'd call ideal, but it is cheap and it does work.
I have the following method import http.client as httplib def exsists(site, path): con = httplib.HTTPConnection(site) con.request('head', path) response = con.getresponse() con.close() return response.status == 200 I tried in idle and it failed when i tried to do the request 
Standard library tools like `any`, `all`, `max`, `min` etc. seem almost custom-made for comprehensions/generators.
You might be interested in [this project](https://github.com/amoffat/sh).
I just switched to a vps after 10 years with godaddy . I got a vps server with 1 gig ram 1 proc core and 10GB SSH and ubuntu 14.04 for $3/month. I then got a $3 .info domain name and started setting up HTTP, HTTPS, SMTP, and Rainloop browser based email. I used the phrase "how to setup ___ ubuntu" a lot. Once I got everything working on the .info domain I set it up for my main domain and pointed it to the new server. I'm still using godaddy for domain management. I'm running LAMP stack, SMTP, and a Mumble server. It's all working good so far.
Sounds good! I maintain a cross-platform wxPython program, and getting all the wx requirements installed on Linux/Mac is a frequent pain point for users.
Wow, I didn't realize that Digital Ocean had instances for that cheap. At a quick glance the specs look similar to Linode (I've been on Linode for a couple of years and have had a great experience). Now I'm curious which experience is better overall.
&gt; I've been building applications using this "radical architecture decision" since about 2010 Good for you :) I don't write "radical" in a negative way (at least, per se). What I mean is that if your framework doesn't provide server-side templating and someday, for some reason (for instance, for SEO, or for performance, like LinkedIn did) you need to generate at least some pages server-side, you're out of luck. In other words, even if you don't need server-side templates now, it reassuring to know that they are available just in case. &gt; Why did you decide to go back from your Angular experiment? It would be interesting to find out. On the front-end, I had to work with (or against) a set of technologies, like npm and bower and gulp, that were unstable, at least on my development box. I also had to fight the Angular learning curve and eventually I thought the effort needed to get up to speed was not compatible with the timeline imposed by my client, and the productivity gains where not there at the point where I stopped the experiment. But I will definitively try again on another project in the future :) &gt; I think a JSON-based REST (without standards in sight) with a single page UI can create much looser coupling between UI and data than I've seen with the typical server-side approach. Indeed, which is nice for instance on a big project where you have a front-en team and a back-end team. This is not our case currently, we are full-stack developers (our breed is dying if you believe hacker news, I know). But this loose coupling comes at a price: having to write two similar object domain class hierarchies, one on the server and one on the client. &gt; your arguments without further fleshing them out have the faint whiff of FUD around them. I don't have arguments against REST :) I like REST, specially REST with JSON encoding (over SOAP/XML) :) Regarding the performance issue, see http://www.infoq.com/presentations/netflix-api-evolution and other posts tagged "netflix" on infoq. Regarding the domain class duplication issue (which is not a REST issue, but a REST+SPA issue) I don't have the reference around for some people with the same issue, but I'm sure you will agree that this is indeed an issue. (If you have a solution, I'm all ears ;). [Edit: change link to another, more relevant, Netflix presentation. Relevant part starts at slide #85]. 
This sounds like a front end apps... I'm not sure docker will be able to help you much in that case, it's more geared towards servers. To a user, a container looks like a separate host with its own ip, login etc...
It's still often better to return a new object instead of mutating the input in the general case.
I'm pretty sure I've done similar things before. But it's better IMO to use a function attribute, if the intent is that the 'default argument' is never supplied. I imagine there's a way to do it with decorators, too.
I plan to add more direct support for server-side templating languages to Morepath, eventually. But server-side templates are available in Morepath even today, you just use them as a library, just like CherryPy does: https://cherrypy.readthedocs.org/en/3.2.6/progguide/choosingtemplate.html So it's not exactly that you're locked in. I do admit that some template reuse patterns may need more from the framework -- it depends on the template language. You can also consider less usual (more radical?) approach. React is a front-end framework that doesn't use templating but renders HTML directly from JS code. You can also run this JS on the server using Node. Here's Python integration: https://github.com/lrowe/subprocess_middleware I agree that the whole tooling infrastructure on the client-side could use improvements. Here's a recent blog entry on that I found interesting: https://medium.com/@trek/last-week-i-had-a-small-meltdown-on-twitter-about-npms-future-plans-around-front-end-packaging-b424dd8d367a My own post on this last year is still one of the most popular things on my blog: http://blog.startifact.com/posts/overwhelmed-by-javascript-dependencies.html I haven't played with Angular yet, but I think React fits my brain better (though I do like templates). The single page app + REST projects I've done we've done with full-stack developers too. Not a front-end team in sight. I just noticed an interesting pattern: certain enhancements could be done entirely by tweaking front-end code, while other enhancements could be done entirely by tweaking backend code (even though they would affect the UI). That was a sign to me that the loose coupling was working. It's possible that's a property of how we used Obviel, though. With Obviel we didn't have a model hierarchy on the client - we'd just get JSON representations with a @type marker from the server, and we'd have client-side views for those. I've experimented with using React that way too. It's a fairly spammy approach though, so that's a drawback -- it depends on the app. Thanks for the Netflix reference; I'll try to take a look at this sometime! 
http://nedbatchelder.com/text/unipain.html This is by one of the big contributors to #python on freenode, nedbat. Tldr, decode everything to Unicode while working with it, and encode to utf-8 right before displaying.
dir(variable) and type(variable) will help you with this - I was daunted by json until I learned what dir did!
For me it works. Remember to escape the whitespaces properly (`urllib.quote`). I tested it with `requests`: &gt;&gt;&gt; requests.get("http://www.bano.no/pdf/DANISH%20PRODUCT%20SHEETS/BANO%20HØJSKAB%205302-5311-8341.pdf") &lt;Response [200]&gt; Works like a charm (but only if `http://` is prepended!). :)
TIL about function attributes. Thanks!
Oh, bugger.. Yes, the program is actually a desktop GUI application, not a server. So, not really good for those?
I usually try to take this sort of approach: def build_config(default={'DEBUG': False}): return { k: do_some_internal_logic(v, default.get(k, None)) for k, v in modifications() } (often involving that level of factoring.)
They're really nothing special. It's just a consequence of functions being objects. Well, I guess it's special in that *other* built-in types typically don't let you set arbitrary attributes, although user-defined types (without `__slots__`) do.
It seems that `http.client` is not designed to accept such URLs - it expects you to pass a Unicode string, and expects to be able to decode that string internally with the plain ASCII codec, and doesn't provide an explicit override. To get around this, you can use URL encoding: http://stackoverflow.com/questions/912811/what-is-the-proper-way-to-url-encode-unicode-characters https://docs.python.org/2/library/urllib.html#urllib.quote Although you should probably be looking at a more sophisticated, higher-level way to make the connection, such as the third-party `requests` library already mentioned.
I am not sure if you are being serious or just trolling. The behavior you see will of course happen in a couple of cases if you write Python 2.x like statements in Python 3.x. Also, Python 2.7.x is sort of a "bridge" between 2.x and 3.x, so it will be more tolerant. I got stuck in the comfortable hole of 2.7.x., but would strongly recommend making a clean cut for newer codes. My favorite joke is starting off with the xkcd cartoon on how python is easy (Hello world is just 'print "Hello, World!"'). And then talk about Python 3.x and how that statement fails on 3.x.
Lol when you say work, do you think I could take on it? Seriously though...
I know, it's so irritating. When I use bash syntax in python 2.7 I get syntax errors too.
Totally. I get the same thing when I type "foobar = function (){" !
OpenShift will give you three 'gears' for free. I don't they're too much after that. If you have "many" domains though, why not spin up your own EC2 server on AWS? You can have whatever version of Python you want then.
Care to explain what you mean by "shared hosting"? If I were you I would just setup an EC2 instance on AWS or get a VPS at Linode or Digital Ocean.
Thanks for pointing that out. Do you know why the assumption is that this is a generator, not a list? Python is supposed to the explicit, right?! #generator mycounter = Counter((randrange(10) for c in range(100))) #list comp mycounter = Counter([randrange(10) for c in range(100)]) #generator by default?! mycounter = Counter(randrange(10) for c in range(100)) 
?
I did something even more unnecessary. I wrote my own .ipnyb to .md converter. Hopefully this can be of some use to someone out there. I wanted to have IPython notebooks embedded within my posts with the blog style rather than the IPython. I wrote a script to convert simple notebooks to markdown for Jekyll. https://gist.github.com/satyamsatyarthi/26f3d560200f8537f648 You can define your own tags for math. For me its {% m %} latex code here {% em %} It also handles svg images by writing them to a pre-defined image directory. This entire post body, including the images, was generated from a ipynb. http://satyamsatyarthi.com/technical/kanes-dynamics-with-sympy-mechanics/ I think I went way over the top... 
I believe its because generators are more efficient (so you want to use them when possible), a single something in parens kinda looks like a generator, and having to do (()) is annoying, so they drop the extra paren. Personally, I'd argue that `randrange[10] for c in range(100)` is explicitly a generator expression, and by wrapping it in `[ ]` you even more explicitly tell it to evaluate itself and put it in a list (a list comprehension). 
seconded. this has saved me from unicode hell.
This was posted yesterday. http://www.reddit.com/r/Python/comments/2nh3jt/top_10_python_idioms_i_wish_id_learned_earlier/
I agree that a single something in parens looks like a generator. Still, I don't think it's explicit, although it's nice that more explicitness can be optionally added. 
Usually shared hosts don't support long-lived processes, because that means they have lots of unused stuff running, which in turn raises server costs. This works well for PHP, which was designed with this sort of architecture in mind, but not so much for modern python apps. If you see python support, that usually means they support cgi scripts, and you don't really want that. A vps will cost about the same in money, but more in administrative time; that's the trade-off for flexibility.
I can second that. I have used Webfaction for various Python Web apps and it works well and is quite cheap. Especially for the long term plans. Everyone is exclaiming the virtues of Vps providers, but sometimes it is really nice to have someone else take care of os upgrades, database server etc. On Webfaction you can either do a quickstart from one of their framework templates (django , pyramid, etc) or create a custom app that listens to a port. This can be anything in almost any language. Only problem is that there is no good upgrade path if you suddenly get a lot of traffic.
Whatever you do stay clear of libusb. The maintained and actually working libusbx is what you want!
We can use kwargs to emulate it, though: tank = {'power': 1, 'defense': 2} power, defense = (lambda power=0,defense=0: (power,defense))(**tank) What other options can we use other than the following? power, defense = tank['power'], tank['defense'] locals().update(tank) # Blame /u/indosauros Also, can we bend the language to unwrap a nested map? tank = {'power': 1, 'defense': 2, 'coords': {'x': 10, 'y': 20}}
You can use WebKit via GObject Introspection (`from gi.repository import WebKit`). I guess QtWebKit works with Python3, too.
Painlessly - depends on an underlying distribution. Docker is just a Linux container, running the same kernel as a host OS, but the operating system environment inside the container could be based on any distro, including those with libgtk2.0 properly installed. Think of it as a lighter VMware or Parallels. It's not a packaging and distribution system.
What is the difference between not having 2.8 and back porting all the useful 3.* features?
Do you plan to support https?
&gt; Actually, this might not be fully the case yet If you do figure this out, please post it somewhere (I'm genuinely very interested).
&gt; not a wrapped thing, even though a decorator is in use Thats really interesting. I'll have to dig into how this works, which shouldn't be that hard since Morepath appears to be exceptionally well documented (bravo!). Every decorator used on a view function in Flask makes it harder and harder to test as each decorator typically introduces more dependency on global state.
Not easily, but a quick google shows that people are strating doing it. Seems like a lot of work, you have to talk to the container over a virtual network etc.... I'm not sure how you'd automate that as part of your install. On the other hand, that'd be a nice trick to get rid of all the deep/permanent cookies.... run the browser in a new container each time!
That's great for me, I'm trying to use Python 3 only. I'm noting the book's name, that looks interesting.
The more I'm learning about IPython the more I'm falling in love with it. It's already my shell, now it can be my blog, too? 
For a while, Linode offered better specs than Digital Ocean, but nowadays Digital Ocean is pretty much the best choice out there if you want a VPS. Blazing fast network connections, full SSD drives, and insanely cheap. I think economies of scale come into play, because Digital Ocean went from small to massive in just a few years. Both Linode and Digital Ocean have had serious security issues in the past few years. For Digital Ocean, they had many recurring problems of improperly wiping VPS instances. This allowed customers to sometimes be able to recover sensitive information like passwords and private keys of the customer who previously used their instance. They've since (allegedly) totally solved that. Linode has not had those problems to my knowledge, but they suffered two extremely serious breaches. In one case, someone breached Linode's management infrastructure and stole 46.7k BTC from one instance. This is $52 million worth of Bitcoin at Bitcoin's old peak price ($1124/BTC): http://arstechnica.com/business/2012/03/bitcoins-worth-228000-stolen-from-customers-of-hacked-webhost/ In another, a hacking group gained access to their customer database, which included some plaintext passwords (though regular account passwords were hashed). The group claimed to have access to decrypted credit card numbers, but Linode denied that: https://blog.linode.com/2013/04/16/security-incident-update/ edit: It seems Linode has actually recently made their prices approximately equivalent to Digital Ocean's. So you could honestly go either way. * https://www.digitalocean.com/pricing/ * https://www.linode.com/pricing Either way, I'd agree with the assessments of everyone in this thread that a cheap VPS is always *far* better than any kind of shared hosting.
Spyder and Matlab are totally different animals.
I realize this is old at this point, but be careful when choosing an ode15s replacement. It's designed to (almost transparently) integrate both differential equations and differential-algebraic equations (DAE's). The scipy suite is good for ODE's, but not for DAE's. For DAE's, you need a different integrator, such as [SUNDIALS](https://computation.llnl.gov/casc/sundials/main.html). There are a number of Python wrappers for SUNDIALS such as [DAEtools](http://daetools.com/index.html) and [Assimulo](http://www.jmodelica.org/assimulo). Both of these packages are great at dealing with *both* DAE's and ODE's. I'd personally highly recommend DAEtools, as I've used it for some time now as a direct replacement for ode15s. I've found it to be quite flexible, and the developer is quite helpful.
Thanks for the very detailed response!
yea, webfaction is fantastic. it's especially nice for those who are just starting out or want to experiment with various technologies. They're admin interface is top notch, and their customer support is super quick...well it used to be...i haven't sent them a request in about a year
Ah, ok. Good to know. :)
So tell us, where did you get a VPS server with 1 gig ram 1 proc core and 10GB SSH and Ubuntu 14.04 for $3/month? Or did I miss something?
I used lisp for 6 months on an absurd "consulting" gig for an AI/robotics project which made no sense because I was utterly unqualified to do what I was doing, but after that, I've been searching for a realistic reason to use lisp again...it definitely left a hole in my heart :(
Pycharm. That's it.
HTTPS is supported in the same way as any Python web framework that I know it supports it: by putting a HTTPS capable web server such as Apache or Nginx in front of the Morepath server. 
1000 times this! 
Well I am not sure why you would opt for specialized frameworks that merely provide "webviews" to put into a Qt/Gtk/Tk app. What features do you expect from such a framework that are not available in a webbrowser + flask server setup ? 
THIS is why static typing is a good idea! You're supposed to run `generate(config)` but without any supporting documentation you have no idea what `config` is supposed to contain. So you're stuck with digging through the code looking to see where it's used and basically reverse-engineering the object. I don't understand the content of the project but there's an example of how to use it in sim_example.py.
[How are these results ambiguous?](http://lmgtfy.com/?q=python+game+library) Seriously google it and the top 3-4 results are what you're looking for. There's basically PyGame, Pyglet and Kivy. &gt; Also, how easy is it generally to implement small pieces of Csomething code for a few resource heavy computations (across platforms)? I wouldn't recommend you go as low as C but you can if you want obviously. Normally it's a whole game engine or framework written in C++ for accessing low level stuff and using Python to access C++ code/for scripting.
Might be worth taking a look at something like [Thrust](https://github.com/breach/thrust/) No idea how well it would work on a Pi though
&gt; I've experimented with using React that way too. It's a fairly spammy approach though, so that's a drawback -- it depends on the app. To avoid making multiple requests, I use JSON-LD embedding to inline required linked objects in the JSON response. This is 'framing' in JSON-LD terminology. A response document is a subgraph of the total resource graph (potentially the entire semantic web.) The 'frame' determines the view onto that total graph returned. In other words, I'm using push templating (the JSON response has all the information needed for rendering with React) rather than pull templating (the React view code pulls all of the required objects in separate requests.)
Same here... but then the whole webview/webkit thing has always been a bit confusing to me. Maybe someone could ELI5 why one would be preferable over the other? 
Ok, really bored and angry at myself atm, I have time for this, so bottom to top: * You're calling choseCave() but not assigning it to a variable, so it's return value gets lost, you probably want to do `cavern = choseCave()` then `print(cavern)` * that's the wrong syntax for return, you just do `return expression` not `return(expression)` * If you're trying to use that while loop to continue until cave is 1 or 2, then you should move the return statement outside the while loop, but keep it inside the function after the while loop. ie. unindent it, but not all the way. * Oh, and chose_cave is a more python-y name then choseCave. CamelCase is the way they do it in java, but python people prefer underscores. PS: nice b8 with the comic sans btw.
http://www.ovh.com/us/vps/vps-classic.xml 
OCR normally requires 300ppi images or higher, I have tested Tesseract out before and screen grabs and not had much luck. This is the output I got running your image through Tesseract: {'7 FPS: 47.3 Gamma LBD. mmgg STATION |K31:Fl§)\Q4‘m:$.4fz4‘T‘E&amp;‘I-AND F-IEFINER ‘E BOOBS LQAHBO newt}: D EXPLDSIVES _ 77.577 man Nvnnn8.EM_Fu:L now 19: Elena: men WNEFIAL DIL ass - -‘ amass Lnw‘ Pisnunass .173 131 - 13,997 LBW cmnnsrraon “ GILUYHING 351‘ ' ' 54.237 cnmsumsa rscnwuuoaw 6233: 3.34:: - 1‘$4,',733 HIGH DEM. m'&gt;puANr:Es sea’ - - axasa MED‘ FOODS INIMAIQMEAVT 123-13 - r- 5,535 L|3,W' CDFFE? 1.3-13 - - 2 537 LUW ‘ra§i:IES"-I:A’nTH|raGE's Faun ANCI VEGEYABLES sum smm-asmc MEAT TEA E)M'»T 1'99. 21‘ ‘I31 1.192 - 1‘a,'3an MED - 9,153 LBW - 952-ts LDW 55.200 ms}-1 .}a\iE’HAeE GA'L_'A_CT_IF 1791:: :52 oi: as an 355 CF! .7-10,35 . CE! I525 on 1,454 an man on 195 CH :39 ca ass as me dﬁ 1.549 5:: 667 CR - Flésh Jrorn_once~l|)r,ing a21ua§\c«mrgan:s'ms sale! as awfnhu sum Illegal :n§m’e,Jur.saic;ions. SUPPLV E 7 CARGO IMPORTED ‘PROM 701R ‘BEBE: D DUT CIFEH UNTW CMDR DECKS A 16.082 CH 
You can also check some of my examples - http://www.rkblog.rk.edu.pl/w/p/controlling-keyboard-emulating-devices-pyusb/
The time it takes for me to type out that one line is much shorter than the time it takes me to type out the evenly indented big for loop. It is still much easier. It's just how I think: [method [method for method in dir(object [method for method in dir(object) if callable(getattr(object, method, ''))] If I know /what I want/ and it is trivial to qualify from a collection with a small boolean statement, then the one liner is easier to fart out. 
Yeah the images themselves are 72 ppi bitmaps, so that's pretty far off the mark. Also a lot of the stuff above is pretty garbled. I can pick out some things, but not to any reasonable level. Thanks for the tips though. I wasn't familiar with Tesseract before!
**The first option**, that you've been researching, is using Python bindings for libraries that make native GUI applications that include a web browser (e.g. GTK, QT). Basically you're packaging a web browser into your python application that will run your GUI. The main advantage of this approach, I imagine, is that your users can download this application and it will run like any executable file, but there's a lot of downsides. As you noticed, many of these libraries aren't python 2 compatible because they require a lot of maintenance, and it's also completely missing that point that everyone has a web browser anyway, so why make them download another one? Which leads me to the second option... **Hosting a local webserver.** Now I suspect that the first option (packaging a browser) requires a webserver anyway, because you can only do so much with the file:// protocol. But the difference with this approach is that you don't need to use any GUI libraries at all. All you do is make a package containing a Flask application, and this will serve assets like HTML, CSS and JavaScript, which the user will then access via a local URL, like http://localhost:8765, which is a URL to your own computer. Since the web server is running on the user's computer, it has access to the local filesystem in a way that JavaScript running on the browser does not, so you can set up browser events, like clicking on a button, that trigger an HTTP (probably AJAX) request to the local webserver, which is where you write your python code. You could use any web framework for this, but Flask is ideal for things like this (and also it's amazing, and very easy to use). I highly recommend this approach, because it's easier, more common, more compatible, a smaller download, you'll get better support from using a well known framework.
Vim. 
Have you tried using a different library, i.e. Requests? Check it out: http://docs.python-requests.org/en/latest/
&gt;The command may look scary: &gt;&gt;cd /vagrant/RedditBot/Part2/; ./reply_post.py &gt;The problem is cron jobs are run in their own environment. Which means you can’t assume which directories will be in the path. So I have to cd to the directory, and then run the script from there. Why wouldn't it be possible to just run the file with its complete path? /vagrant/RedditBot/Part2/reply_post.py 
&gt;Hynek Schlawack wrote an article that discusses this: &gt;https://hynek.me/articles/virtualenv-lives/ Thanks!
Yup
Seconded. I just migrated over there last weekend. Couldn't possibly be easier to deploy a djanog app spread across EC2 and S3. 
Aw, I failed :( Nice challenge though, very effective result!
Is there any other way to pull this data? API would be nice but I doubt they have one. I'm sure with some clever hacking you could get that data somehow.
Yes
Hmm I wonder what kind of answers you'll get from this subreddit -_- I suggest you go to /r/learnprogramming and READ THE SIDEBAR in that sub.
I just read the sidebar in this sub and it suggested that I go to /r/learnpython. I will check both out, thanks!
Yes. http://learnpythonthehardway.org/ HTH, HAND.
If you really can't get the data in another way — maybe it's just stored in memory in a way you get can get your hands on it? — it might be worth looking into projections. Presumably, there are not an infinite number of categories and goods appear in the same place. If I was tackling this problem, here's how I'd do it. 1. Find all the goods. To actually pull this off, you need to know how tall each row is, how many rows appear in a screenshot, and where the first row appears. Then simply iterate through the image, grabbing an area as wide as the rows are (and as wide as you need), starting from the row number you're on times the height of the row. 2. Do a horizontal and vertical projection and compare to a database. It seems likely that there are a fixed number of tradable goods within the game, and by using both [projections](http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CB4QFjAA&amp;url=http%3A%2F%2Fcourses.cs.washington.edu%2Fcourses%2Fcsep576%2F11sp%2Fppt%2FImageFormation.ppt&amp;ei=hQ94VM-fH6_gsASS3YFI&amp;usg=AFQjCNGKJDDA_lXvpHDQ_SH2IVRkll1x4A&amp;sig2=HBgM4oZwwwV8AScljTX9ZQ) you should be able to get fairly unique information about what each type of good looks like. 3. Compare the projection for each row to a database and figure out what the good is based on that information. 4. Prices should be super easy, assuming each numerical character is roughly the same width. We're going to go back to projections again — each digit will have a clear projection, and you can probably get away with just using one dimension to figure out what each number is. So long as the projections you collect are within a certain percentage of similarity to the "ideal" projections, you can assume you have the right number. That is — if the projection you get from the buy price in row 7, digit 3 is within a *x*% of what your perfect "3" digit looks like, you can assume it's actually a 3. At this point, all you need to do is run through each section of the row and identify numbers. If you run into issues with fuzzy data or something, try thresholding based on the orange color. Because the background is so dark, you should get a fairly clear image of the numbers. It's going to take some trial and error to dial it in, but you're lucky in that the background isn't going to change from place to place — and even if it does, you can have a set threshold for each background. This is a cool project! Good luck.
Static typing or no — this is what documentation is for.
I've been writing *Effective Python* the last few months. It'll be published early next year. [More info is here](http://www.effectivepython.com/).
But if you had it calling additional Python files, or outputting to a relative directory (even just error logs) wouldn't you want to cd to the directory first?
I'll say it since no one else will. Learn Javascript. Way more popular than Python. Easy to get up and running since all you need is a browser and a text editor. You can also see the results in a web page.
Thank you amp180, you explained this the best out of all the replies. much obliged.
Thank you. A +1 for you.
The reason you want to cd first: Remember, we need config_bot.py to read the passwords, and it is in that directory. Try removing the cd. The code won't work, as it won't find the password file. You could get around that by having the passwords in the same file as the code, but then you won't be able to check your code in :) Cron jobs are a bit tricky, and sometimes you have twist yourself to get them to work. The problem is, they are not run as your username. Rather, Linux creates a special environment just for them, and so you can't make any assumptions as to what will be present on the path, what shell variables will be declared etc. So it helps to be as detailed as possible.
Thanks for a great in-depth answer. I really appreciate your explanation. it worked for me in python 2. Got a error in python 3 I used the .encode('utf-8') and it fixed it for me. con.request('head', path) File "c:\Python34\lib\http\client.py", line 1090, in request self._send_request(method, url, body, headers) File "c:\Python34\lib\http\client.py", line 1118, in _send_request self.putrequest(method, url, **skips) File "c:\Python34\lib\http\client.py", line 996, in putrequest if url.startswith('http'): TypeError: startswith first arg must be bytes or a tuple of bytes, not str It seams that got turned in to a byte object. I get my data from a xml document i parse with ''LXML''. Is there another way a standard string is handled between python 2 or 3? p.s. Seams that its finally possible to print unicode characters in the windows command prompt in windows 8.1 :D
You could make the bot get file paths relative to its executable or put them in a location like /etc/&lt;botname&gt;. I also think that you should use virtualenv.
Re: ORMs, performance, and expertise What is the likelihood that you and your team are going to optimize object (de)serialization and instantiation better than SQLAlchemy? What do you want to need to write tests for? If you don't need transactions, why even use a SQL database? If there is a full time DBA who can write faster raw queries with `engine.execute` (or DB-API) (and read them into testable objects), who knows better than to concatenate strings into queries without parameterization (in order to prevent SQLi by default), who contributes to or maintains a database driver and understands the idiosyncrasies of other database drivers well-enough to implement workarounds when that's the best option, then hire that DBA to normalize the tables into performance land and cross your fingers that they want to train additional team members, for the future. If performance profiling indicates that optimization is necessary (with a near-production architecture), then A/B and subtract. 
Hand around /r/RequestABot. Create a sub, and use it as a testing ground. When you get a good enough bot, [release it!](https://github.com/apythoncoder/Autotrope_Bot)
they added pip
+1 for Reg's and Morepath's documentation !
Apart from pycharm, there is aptana studio(based on eclipse/pydev), ninjaide looks pretty good too, spyder. And others: https://wiki.python.org/moin/IntegratedDevelopmentEnvironments
I have used a similar approach (using plain old JSON, not JSON-LD). The obvious trade off is that you can, this way, select very precisely which information your server sends to the client on each request (cutting off both pieces of the object graph, but also attributes that are not needed for a specific use case). But then, you introduce higher coupling between the client and the server because if for some reason the client needs some info that is not currently provided by the server in a given request, you need to modify the server to send the needed information. To reduce coupling, an option is to make the requirements a parameter of each request, and have the server only provide the information requested by the client. This way, in case of small requirements changes, only the client needs to be updated. But then, you introduce a higher level of complexity in the system, including the need for a language that precisely expresses how the 'framing' you mention should be done. Is this something that has already been standardised in the JSON-LD ecosystem ? If so, is it reasonably easy to use or do the drawbacks exceed the benefits for common use cases ? 
There are a lot more than those 3 in those lists, and the it still is not clear to me why I should pick one of them over another. If you have experience with Pyglet, I would love to hear about it.
Just watched the video. I think I understand it better now.
What would Requests replace out of the two libraries I am currently using?
Linode has instances for only $10 and their service is much better.
Check out Udacity.com too. They have some great, free resources.
Best choice? No way in hell. The linode service is of much higher quality in every single way. &gt;Blazing fast network connections Linode network has far better performance. I've experienced major segments of the DO network completely drop out. &gt;full SSD drives Linode also provides SSDs and they are of better quality and performance. This is documented in many blogs benchmarking the two. &gt;and insanely cheap DO is $5 and Linode is $10. Not exactly an "insane" difference. I suggest you post some citations for all the wild BS you are claiming. 
When you say library, do you just mean documentation etc? Sorry if that's a stupid question... complete beginner! :(
The libraries that come built in with Python are in the documentation. A library is a bunch of code that someone has already written to help make our lives easier. Try looking into 'import'-ing stuff in Python. In fact I suggest that you start out with [this course from Udacity](https://www.udacity.com/course/ud036). You learn a lot of stuff in a short amount of time and perfect for beginners. Pretty much what I wanted back when I was learning how to program.
Thanks, I'll have a look at the trial.
No problem. You can go through the trial or just access the courseware for free without any limit. Up to you either way. Good luck!
Hi there! It's awesome that you're getting started in learning to code, and it's great that you're asking for help. For the future, there's a whole subreddit dedicated to this, /r/learnpython! For now I'll answer your question here, but if you have more you should ask them over there. A warning: it's hard to convey tone in text. The below text might sometimes come across as rude or abrupt, and I'm really sorry if it does, that was never the intention. Your code has a few mistakes, but its biggest problem is that it doesn't save the URL. You should be getting exceptions here, and it would have been helpful if you'd printed them. Let me show you what the code would look like with requests, and then talk you through what I changed from yours. import requests from bs4 import BeautifulSoup class WebsiteScraper(object): def _init_(self, url): self.url = url print("hey") def textscraper(self): response = requests.get(self.url) return response.text def textfinder(self, data): soup = BeautifulSoup(data) for link in soup.find_all('ul.ingredient-table li'): ingredients = link.get('label') print(ingredients) if __name__ == '__main__': url = input("Enter website URL: ") scraper = WebsiteScraper(url) data = scraper.textscraper() scraper.textfinder(data) So, some problems. First, I have no idea if `input` works in a default argument but it's a terrible idea because it will only be evaluated once. That means if you ever try to instantiate the class a second time you'll use the same URL as the first time. Better to move it outside the class entirely. Secondly, no portion of this script ever executed the code, so I added a block at the bottom that will do it if you execute the script directly. Third, I replaced `httplib2` with requests. That's pure partisanship on my part, feel free to use httplib2 if you want, but I can't help you with it. Fourth, I removed the exception you weren't using. Fifth, I removed an unreachable print statement (it's on line 15 of your code, but it's after a return so couldn't possibly be hit). Sixth, I made sure you actually set `self.url`. In the code you posted you never assign to it, so it never gets assigned. This should have been throwing exceptions. Those were the functional problems with your code. I have one more bit of feedback: When you are struggling with code and ask for help, the phrase "it doesn't work" is extremely unhelpful. In Python, it's extremely rare for something to simply "not work". What will happen is it will fail and print out some message. That message is *hugely* important for working out exactly what didn't work. That's why I had to rewrite your code entirely: I didn't know what exact problem you hit. In future, when you report bugs or ask for help, you should post the code you used, *and* what happens when you try to run it. Don't make us guess. =) Scraping websites is a great first step for learning to code, and I hope you keep it up! You'll find it's a great superpower if you master it, and it comes in handy *all the time*. Keep it up!
dammit jim, I'm a programmer, not a musician!
":D", ":P".... Or more generally, "&lt;insert any emoticon here&gt;"
I recommend /r/learnpython for questions next time, but take a look at this SO post and documentation in numpy: + http://stackoverflow.com/questions/4315506/load-csv-into-2d-matrix-with-numpy-for-plotting + http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html#numpy.loadtxt
I had in mind saving too not just loading.
[numpy.savetxt](http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html) &gt; numpy.savetxt('outfile.csv', your_array, delimiter=',') For more advanced dataset management, take a look at [pandas](http://pandas.pydata.org/).
Pulling the data from memory was my first thought. Even if it moves around the logic for finding data is typically simpler than OCR.
Click on the filter "Free" next to "Buy" to see the free books written by various authors.
this is awesome!
glad you liked it :) 
i specially liked the upcoming books, some are fresh off the printing press!
First, my earlier comment was intended to be sarcastic. I apologize if it was in bad taste. And if you are using Python 3, my generalization is valid. [Screenshot](http://i.imgur.com/Xviw6AW.png?1)
Does savetxt escape quotes? "One, " two", three
I wrote a script that scans against Amazon Product API like once a week. That shows up new books that are released.
I wasn't aware cherrypy could do that. Reference: http://cherrypy.readthedocs.org/en/latest/deploy.html#ssl-support Could you explain why you prefer this to something that leverages nginx or Apache?
I'm not sure since I rarely use savetxt for saving anything but numeric data. I should also mention that savetxt takes a header keyword argument to name columns.
http://learnxinyminutes.com/docs/python/
Don't talk like pip is a brand new thing unseen ever before. It is used by vast majority of people who use python, therefore including it in python package is just as logical as including migrations in django 1.7 because most people use south.
Looks interesting. What type of APIs can it handle? I was looking to start a project to wrap an utterly disgusting XML-based API in python. 
&gt; Could you explain why you prefer this to something that leverages nginx or Apache? I'm working on something very specific, and I consider Apache/ngix like complete overkill for this project. In essence I'm working on RPC interface for Raspberry Pi, so only one connection no need for dedicated web-server. Requirements are security, low resource usage and ease to implement it.
Many free books https://github.com/vhf/free-programming-books/blob/master/free-programming-books.md#python
wow this is very helpful. 
Thank you for this. One suggestion: add the ability to show just 2.x or 3.x books.
Thanks man! You've been really helpful so figured I'd ask, but... he also mentioned they use Django with Python. Is 'Django' just essentially another GUI that helps you write Python a bit easier?
That makes sense. (though I wonder how high the resource usage is of a nginx compared to doing https in Python.) I wonder whether https capability is available as a WSGI server. That would make it useful with a range of web frameworks.
Don't worry about technicalities for now. Just take one step at a time or you'll overwhelm yourself. 
Anyone got a suggestion for both a free and a non-free book?
Thanks again for all of your help. Hopefully (with the help of some of these resources) I'll be able to write the command I mentioned in a week or so :)
We try to offre the best support for python as a PaaS in the Clever Cloud http://www.clever-cloud.com/ // being honest : i am the CEO of Clever Cloud
I'm sure you will especially with that Udacity course I sent you. You'll get a feel on how to use libraries.
That's a good option actually.
[Natural Language Processing with Python](http://importpython.com/books/239/natural-language-processing-with-python) is free, is about a very interesting technology and also makes for a great introduction to Python/programming.
Gotcha. Well, if you want to see one of the ugliest XML APIs I've ever run into, here is a link to the documentation page. It's got multiple name spaces, mixtures of tag properties (&lt;tag prop=value&gt;) and tag values (&lt;tag&gt; value &lt;/tag&gt;), tons of nested types. Even using python XML libraries to parse out the data usually gets it wrong. If you can design for that, you can design for anything. http://pubs.vmware.com/vcd-55/index.jsp?topic=%2Fcom.vmware.vcloud.api.doc_55%2FGUID-86CA32C2-3753-49B2-A471-1CE460109ADB.html
IIRC, there was a similar library with a pie related name that stopped being developed a while ago. Are you the same guy?
No. Python is best suited to those who read the sidebar. Or follow the advise of those who say to actually POST to /r/learnpython. Seriously. If you post there, you'll get some really good answers. If you post here, I'll be sarcastic and rude. :)
Missing: http://amzn.com/1500825964 Free version: http://ProgramArcadeGames.com
This actually looks really awesome. The one thing that confused me a bit was "external APIs" and I was like "will this wrap this shitty perl api for me??" But it looks like its just web? Might want to specify *HTTP* APIs. 
I don't think so, never heard of it.
It's part of the listing. Have read the first few chapters. Def a good book.
Thanks for letting me know. Will add.
Awesome idea. I will add it in the coming week. Thanks.
Tread carefully, people! It's not the quantity, but the quality of books that matter! You have to research their reviews and make sure they are worth investing your time in. 
The problem with the sleep is: What happens if your program hits an error and crashes? With a cron job, the OS will restart it. You can do the same with a Python script, but then you need some of these service monitors (can't remember any names now), that restart your script if it crashes. Cron job is just easier, and the pretty default way to do it.
Here's an idea: Make a Swear-a-bot: Everytime it sees swearing, it lectures the poster. Threatens to call their mother :)
Fair point. My goal is to wrap the API in Python to un-crappify it. It's rather daunting.
Awesome, great idea by the way. Building submodules that wrap tons of HTTP calls via requests has become all too messy/prevalent in my codebases. Thanks for this. 
Free as in speech, or free as in beer? Edit: Not sure why I was downvoted, considering there is a difference. Are they free as in gratis, or free as in libre?
Nice! Found a Python Scraping book in the pipeline for April 2015. Will make sure to use the referral link! 
I'm sorry, I was thinking of this: https://github.com/samgiles/slumber It has nothing to do with pies whatsoever, I was mixing it up with tastypie =P
To have similar functionality to Matlab and its gui. There are lots of python libraries that do the same things as Matlab toolboxes. And then one can inspect variables in both, debug in both. Not interested in having matlab code work in python, but just to freed of fighting over this and that toolbox license at work while still having a very nice prototyping tool.
It's not brand new, but it is a new feature to the Python distribution. They adopted a 3rd party package. That's a new feature. Python supports TkInter, but PyQt and Wx are far more standard. It would be like if they started including wx.
Digital ocean has a $5/mo vps that will probably meet your needs. 
Cool! So after I get an account there, how would I go about linking a URL [that I buy] to my custom server?
does github pages support django? I can't find any relative info
The Natural Language Processing in Python book is excellent (and available for free).
https://www.digitalocean.com/community/tutorials/how-to-set-up-a-host-name-with-digitalocean
What relevance to the program's build process have on whether it should be considered a new feature were it included with Python? It would be distributed with an installer, so it wouldn't matter. The biggest reason wx (and qt) are a pain to install (at least on Linux) is the required packages aren't clearly listed. Once you have all the dependencies, it's easy.
seconded, fast and cheap.
Exactly. You need the dependencies. How many of them do you need for pip?
Again, what relevance does that have to whether or not a package can be included in an installer?
&gt; if people love Python they get good at it - but they also write about it and read about it on here. judging by all the self.python questions that come up here regularly, I would disagree.
https://docs.python.org/2/library/csv.html#csv.Dialect.doublequote
Well, I never use WX, for I write django apps. Every part of our company however uses pip instead of easy_install. Pip is vital for python, wx and qt are not.
Once they get the answers to the questions though surely they do get better:) that's why people ask questions right? To get the answers
They're just static HTML pages. But I believe there's a Django "freeze" feature that'll build those HTML pages based on what you've got. 
Brilliant bub! Allowing both attribute and dictionary access is kinda like zope.
We use easy_install. It's ok. TkInter is also not necessary. Either way, adding pip to base Python is a new feature. It's one they should add, but it's a new feature. The point was Python 2 is still being supported and that's a good thing. I'm sure they'll be another new feature to base Python 2.7 at some point.
Awesome. What do you mean with dictionary method to the API? It's basically an abstraction of the URL, request and response part of APIs.
Wow I was fiddling around something like this for a creative coding project of mine.
You can't beat aws for price.
let me take your example and explain &gt;&gt;&gt; import tortilla &gt;&gt;&gt; github = tortilla.wrap('https://api.github.com') &gt;&gt;&gt; u = github.users.get('octocat') &gt;&gt;&gt; u.location https://api.github.com/ , present you with a dictionary of all the interfaces available using this API. Many APIs are not constructed this way, what happens if the dictionary is not present. do you handle it gracefully or fail on instantiation ? 
Many of our projects are still on Python 2.6.8 at work. We'll soon move to 2.7.x hopefully, but I don't see python3 on the horizon for the next 5-8 years. 
This is blatant self advertising and it's not allowed per reddit rules. Also I would suggest writing your recruitment "essays" in a less cringy manner. "Python champions", really now?
The higher coupling is a drawback. We recommend to our API consumers that they specify frame=object (no embedding) so that their code does not break when we change what is embedded for each page type. I specify the level of embedding in the Python app. This is necessary for the embedded document to be indexed in elasticsearch - we want users to be able to search through the entire content showing on a particular page. We also get to use it as a cache. Any single page request will get that full set of data. For search results and listings we do specify a subset of fields to return for each type, preventing long listings returning enormous result documents. As a result we can't reuse a search result for a full page display. There is ongoing work on a standard for specifying framing in JSON-LD (http://json-ld.org/spec/latest/json-ld-framing/) but I just went with specifying a list of dotted paths to be expanded. My code then just goes and replaces the url with the object at each of those paths. For us this approach has worked well. It makes server-side rendering a pure function of the json output. We do still use separate requests (client-side only) to fetch listings of related items.
this is a reddit about python the language not a job board at least you didn't try to recruit Guido van Rossum...
&gt; other than the usual tutorial docs on Python.org why isn't that a good resource for you as a starter?
a first programming language is never easy, but yes, python as first programming language has good chances to be less painful than most other languages
Without a web server, you also have the option to use Python implementations that run in the browser. [Brython](http://brython.info) supports Python 3 and has a built-in interface with the DOM and modules to generate and manipulate HTML tags and CSS in Python instead of Javascript
I just tried it out and it worked great. I like it a lot! It reminds me a lot of [Restangular](https://github.com/mgonto/restangular).
I second this. I've done lots of coding tutorials and intros and this is the best
I *am* using Python 3. But you're just quoting them in strings -- obviously anybody can do that with any utf-8 characters in any utf-8 supporting language. OP asked about "text emoticons that *are correct code syntax*". I wasn't particularly offended -- more that I felt it was necessary to make a smartass comment in response to your ridiculously broad generalization.
I'm a computer guy, already know shell, some perl, a bit o' ruby: enough to get by. I started learning Python last week. What would you suggest for me?
Get PyCharm (the community edition is free) if you haven't already. It's super helpful.
Floats are weird, basically. In order to be memory-efficient, they don't work in base 10 all the time, and so round off to numbers which look very weird to humans. Either use Decimal (from the numbers module, I think), or use something like this when checking floats: def float_equals(first, second, tol=0.00001): return abs(first-second) &lt; tol
Check out [Music For Geeks And Nerds](http://musicforgeeksandnerds.com/index.html). It's pretty awesome. Music concepts are explained with Python code, using the [Pyknon](http://kroger.github.com/pyknon) music library.
/r/learnpython
&gt; supports nose multiprocessing plugin Is there a reason that `nose-parameterized` wont? &gt; test methods don't need to accept new parameter Not sure thats a good thing. I don't think this will work on test cases that are not part of a class since the "parameters" are patched into the test case class instead of passed to the test function. Actually passing parameters to the test functions would eliminate any chance of having a namespace collision with existing members of the class. `nose-parameterized`is definitely more explicit in this way. &gt; Customized setup per test I'm not sure what that means since there's no docs to explain, but the custom setup appears to just patch and remove attributes from the test class. This is not necessary for `nose-parameterized` because it just passes values to the test function.
Think of it this way: `github` represents the base URL (api.github.com). the attribute chain represents the URL path (the dots become slashes in the path): `github.foo.bar.get('baz')` is the URL `api.github.com/foo/bar/baz` It doesn't need to know anything about the API structure, it just uses attribute chaining to build the URL of the endpoint you want to access.
Learning Python by Mark Lutz. 
post as code please, see the side bar
in short, it breaks and it meant to handle an API built a certain way. thanks!
Hopefully you're active cause I wanna get into this asap. Where is the link for udemy? I can't find it anywhere.
No, it won't break if there is no "dictionary" of api endpoints. If the GitHub api did not have that directory/dictionary info, the examples given would still work exactly the same.
I am active and... you just commented on the link.
Sorry, don't understand reddit very much, hardly use it xD Btw that actually helped me figure it out, thanks lol
Haha no problem, glad you figured it out!
Yes, technically it should work with any API. The target is to provide enough flexibility to tackle any situation. Although, I don't think this will make working with SOAP APIs much easier. :)
now that im in front of a computer and can actually view the code, i retract my statement.. the following is an example from an api im more familiar with: import tortilla bfx = tortilla.wrap('https://api.bitfinex.com/v1') print dir(bfx) print bfx.symbols.get() print bfx.pubticker.get('btcusd') print bfx.ticker.get('btcusd') print bfx.stats('btcusd') print bfx.stats.get('btcusd') yields ['__call__', '__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattr__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_url', 'cache_lifetime', 'debug', 'delete', 'extension', 'get', 'headers', 'parent', 'part', 'patch', 'post', 'put', 'request', 'silent', 'url'] [u'btcusd', u'ltcusd', u'ltcbtc', u'drkusd', u'drkbtc', u'th1btc'] Bunch(ask=u'377.61', bid=u'377.52', high=u'387.5', last_price=u'377.51', low=u'355.51', mid=u'377.565', timestamp=u'1417222178.200328144', volume=u'30981.45825099') Bunch(ask=u'377.61', bid=u'377.52', last_price=u'377.51', mid=u'377.565', timestamp=u'1417222176.924531434') &lt;Wrap for https://api.bitfinex.com/v1/stats/btcusd&gt; [Bunch(period=1, volume=u'30680.02688865'), Bunch(period=7, volume=u'157654.5319866'), Bunch(period=30, volume=u'996872.87184469')] one thing that would cool is for it to auto discover ('some') the interfaces. Bitfinex was an example of a well known api that does not list all interfaces available. 
No one ever explains the definitions of bias and variance clearly. The key idea is that you're considering a single test point and asking how sensitive your model's prediction is to the specific IID samples that make up your training set. High bias means you make consistent errors across training sets. High variance means your predictions are sensitive to the choice of training set.
Bishop's lectures on Bayesian methods are useful if you haven't had a course on this stuff. Don't try to learn the math from the tool. Figure out what you want to do, then ask how the tool can help. https://www.youtube.com/watch?v=ju1Grt2hdko
Yes, you are right. Running on your laptop would mean that it would stop running if you suspend it. Basically if you have a machine running 24/7 you can clone it there and let it run. Just make sure you install the required packages (requests and lxml are both non standard). 
Nice and simple code. But you should check out [www.camelcamelcamel.com](http://camelcamelcamel.com).
Very simple, not much to say. Don't use global variables unless you have an excellent excuse. This is because it's hard to keep track of what's happening with global variables in big programs. Imagine having 25 functions do 25 different things to a global variable and they all only work if the variable is in the right state at the start of each of the functions. Nightmare! Besides that, just add functions. The most obvious to me is pulling the username and password. That should be in a function, like "getUsernamePasswordFromFile" so instead of having to read that fairly cryptic list comprehension I can read the function name and know what should happen. You could apply that same logic to basically every part of the code. You could have a "setupConnection" function for example. Overall really solid beginner code though, nice start! 
Replacing?
Personally I'd suggest Regular Expressions.. /\w{6}/g Would work right guys? Still learning them.
A lot of the books listed in the beginning are not yet published or available.
Yea I kind of knew I was short changing myself by not learning the theory properly, but I couldn't find many easy enough to understand sources. I'm gonna watch this when I get the chance. Thanks.
I found the Think Bayes (available for free [here](http://www.greenteapress.com/thinkbayes/thinkbayes.pdf)) very intuitive and a good quick read when I was reviewing the concept. 
I'm running two django sites on Dreamhost and it works pretty well. I have a whole lot of other stuff there too though. 
Yeah. The way I see it, virtualenv is to isolate your python exe and libs from the one shipped/installed/updated by your OS. So is docker but on a more generalized level. I don't see the need to use a virtualenv inside a docker unless you are using docker for development. In that case you are actually using virtualenv locally and mounting the local volume in your docker container so the container has access to the code (in the common use case). This is because the virtualenv enviorments are technically not relocatable. The way I see it, no reason adding a needless layer to the docker container when I can us the system packages for pip and then use pip to install my python libs in the docker image. I'll be finishing a writeup this weekend hopefully, on how I dockerozed a web2py app recently to help others understand the workflow better. 
please format your post.Its supposed to be a value error as far as I can see... In the last two print statement you are trying to concatenate integer with string.Python does't allow it.You can: Convert the int to string: print "First piece equalled: "+str(firstpiece) Format it: print "First piece equalled :{0}".format(firstpiece) or print it like this: print "First piece equalled: ",firstpiece
Alternatively, you could use a cronjob to have the script run at certain intervals throughout the day. Or just control you script with a batch/bash script
Assuming your dicts are called dict_1 and dict_2: def find_value_with_length(dict_1, dict_2, length) value_list = dict_1.values() + dict_2.values() for value in value_list: if len(value) == length: return value If no word of the given length is found, None is returned.
Hi bdunbar, You should look at Learn Python The Hard Way if you like simple exercise at the end of each chapter. Don't let the name of the book scare you, it's the easiest Python Book out there. "Learning Python - By Mark is a pretty good book but too long for my taste.
You can use dictionary comprehension: {word: definition for word, definition in dict.iteritems() if len(word) == length}
Makes sense, this is exactly why I was asking. I'm starting to move towards virtualenv locally for unit tests, and docker for integration tests and prod. [kenfar](http://www.reddit.com/user/kenfar) made a good point above about extra packages, say for instrumenting, but I don't really have any right now, and if and when I do, I doubt they'll be much conflict. 
 &gt;&gt;&gt; import this The Zen of Python, by Tim Peters 
Alternatively, you can use the filter function &gt;&gt;&gt; words = {'abcd':1, 'ab':2, 'abd':3} &gt;&gt;&gt; filter(lambda x: len(x)==2, words) ['ab']
float values are most often not 100% precise, but only to a certain significant figure. Instead of checking for equality, you should check if the difference between 2 floats are below a certain predefined threshold.
maybe the filter should exclude books with a publish date that is in the future. Otherwise its the same as an amazon search for python-&gt; filter by new. Right now 14 books from your first results are unpublished. 
AFAIK, immutable globals are fine. They are a bit slower to get the value of, but I think declaring them as global in the functions that call them probably fixes that. It's not any different than making a settings.py and importing them. Just don't try passing values between functions by changing global variables. That's doing it wrong.
Not totally related, but people write unit tests for complex code to try all the edge cases so that later, if code gets changed, y'all know it still works.
Unfortunately the current state of python audio libraries is pretty terrible. If you want to play a few common tones, you should be just fine, but for generative music in general it gets rather ugly. Any recommendations for generative music libraries in python would be much appreciated.
If you are on Windows, simply type: exit() If you are on Linux hit `CTRL-D`
 def a_good_book(): return 10/10 FTFY
&gt; i made a keylogger using a tutorial and it ran stealthy. That sounds super dodgy! I'm not sure whether you want to just play around for educational purpose, or really run a key-logger to capture something. I am guessing the latter, so I will not help you with that one. Maybe someone else will.
Upswag for camelizer
*nose-parameterized* is a grate package that have been around for a while. Im not trying to say that one is better then the other, *nose-ittr* is just my solution to the problem. **multiprocessing** *nose-parameterized* does work with multiprocessing. But correct me if im wrong, *nose-parameterized* uses generator for running all the test variations based on original test method, thats means that all those tests will run in the same process. so i think (didn't try it yet) that if you'll run their example from GitHub with multiprocessing, only one process will open and not 7 *nose-ittr* use metaclass to add all the test variation back into the class before nose collection, so after nose is done collecting each test variation will have its own process **test methods don't need to accept new parameter** you are right, "parameters" are patched into the test case class. I agree that there could be a problem with namespace, but i think chances that it will happen are small, specially if you keep your code simple and clean. my idea was to make the code look more simple and readable by keeping all the test method look the same. **Customized setup per test** I do need to add documentation, and im working on it :) you are correct in what it dose. *nose-ittr* do pass the test values to the class instance, but also to tests itself, so you can use it like in *nose-parameterized*. The reason i added that feature is to make the test method have as little as possible code that is not test logic (again the clean and simple code approach). example: class TestFoo(object): def setup(self): # code that asks for selenium driver @ittr(browser=['firefox', 'chrome']) def test_foo(self): # test code logic for quick reference: [nose-parameterized](https://github.com/wolever/nose-parameterized) [nose-ittr](https://github.com/taykey/nose-ittr) 
Depends how you made it into an exe. With PyInstaller you can set the option to have the cmd not appear at all. 
[Tuples and sequences on the python documentation](https://docs.python.org/3.4/tutorial/datastructures.html#tuples-and-sequences) : "output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they may be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple is part of a larger expression)."
That's actually what I was reading(and still am) when I asked the question. Im combing through the docs to see find features i skipped over while learning python. but I meant in regards to speed and memory allocation
Both with or without parentheses the values are evaluated as a tuple. It makes no difference at all, except the extra character that have to be parsed which is negligible if it helps reading your code.
I've worked with Pyglet for a couple of projects over the last few years. While it is great in some aspects, it lacks in others. Sprite drawing is stupid simple and the OpenGL interface is fantastic (and speedy). Primitive drawing can be a bit awkward to get used to but it is definitely usable. It does lack documentation in some areas but there are plenty of projects out there with easy to read code. It does not have a built in collision detection engine, unfortunately, as it is geared toward being more of a "media library." You may want to look at pymunk, box2d bindings, or some other arcade physics library for that. Let me know if you have any more questions and I'll try to point you in the right direction. =]
Haha okay point taken! - I thought id try something new, you chaps didn't seem to like it so I won't try it again.
The ux issue for me was that a new guy on your site, in its default view, gets a result set that he cannot use. You could use a label like coming soon or a new option. The UX is up to you, really. I did not mean to sound rude if I did. Just providing UX feedback that I'd like on my own project.
I've never owned a book for Python, I usually find that the internet is a good enough resource. However I've heard that the book Learn Python The Hard Way is the best of its kind. [Here is the \(free\) online version](http://learnpythonthehardway.org/book/). If you decide to purchase it you get the whole book (in PDF format I think), as well as loads of video tutorials and other help.
&gt;perfect for adding internet capability to your cat [The dream]( http://b.vimeocdn.com/ts/446/258/446258140_640.jpg) But really though. This is awesome. Coding in C sucks.
This keeps getting better and better.
&gt;Coding in C sucks. It's actually pretty awesome and is the right choice for a lot of jobs.
The parens aren't necessary, so I think the question should be the other way around. Is there any advantage to using parens? The answer is yes in my opinion, because it's fairly common to need them anyway; for either multiline declarations, or a declaration inside a function call (e.g. `map(float, 1, 2, 3) !== map(float, (1, 2, 3))`). But, on the other hand, a special-case for parens containing a single element leads to surprising behaviour: type( () ) =&gt; tuple type( (1) ) =&gt; int type( (1, 2) ) =&gt; tuple # etc edit: got myself all turned about for a minute edit2: it's surprising behaviour if you mistakenly learned that the parens declare the tuple, not the comma
For the record, the correct way to create a tuple with one element is with a trailing comma; `(1,)`.
Try Nimrod
This is more "expensive" on some platforms than others. But in cases where threads trip over the GIL it is more than worth it.
Right, I meant more for beginners if you think "my code is slow so I should use multiple processes", then it might not be the first thing to jump to. Good point though, creating the process should not be that expensive.
&gt;I'm guessing it does mean an OS process because that would definitely work but it seems very expensive. I wouldn't say it's expensive at all. The time to create the new process is negligible at best, and if you're pooling, it's a one time hit. 
Pros/cons vs haskell? Looks like it would be like C without braces
it bypasses the GIL by using an entirely new python interpreter in a different process. with today's computers, its not really that expensive. 
From what I can tell, MicroPython is about the same speed as CPython (±20% either side). MicroPython's advantage is that it's *smaller*, so can actually fit on these devices. If you want close-to-C speeds, use PyPy. 
Actually looked into this a few days ago. Could not find much on what periperals the board supported. I'm very keen on buying one, but at the moment it's a little bit expensive compared to a raspberry pi. Depending on application, low power, iso, dac etc. it is great to have an option to use python in a more bare board than an entire computer.
&gt; it's a little bit expensive compared to a raspberry pi It's like $3-4 on eBay.
Definitely will make use of this early next year when I migrate our external bind layer to Infoblox. Thanks for sharing. 
Keep in mind that each Python interpreter process has a resident memory size in the several hundreds of megabytes. If you're spinning up dozens of "threads" (processes), that can get substantial.
Will most definitely look into that thanks a lot! 
Just wondering is there something like this, which can be as cheap and send GPS info
Unfortunately, you're probably biting off more than you can chew. With that being said, if you jump in, you're gonna learn some interesting tricks. There are a few ways to go about extracting the information you want, and they range from "sloppy, headache-inducing, and probably against the TOS" to "clean, somewhat complicated and definitely against the TOS." You're trying to do the first method, which involves really loose OCR and probably some basic automation for things like scrolling. This can work. That doesn't mean you should do it. You'll be learning some rather advanced image processing for the purpose of developing an extremely narrow bit of code that can break at a moment's notice. The learning is good; the pigeonhole is not. The "clean" method is to hook into the game process and read low-level calls to the display manager, iterate over a pagination method, dump that into a database, do some math. Learning how to do this lies well beyond the scope of this reply, but it *is* possible, with a little elbow grease and some patience. You're gonna have to roam outside of Python for a brief stint, but it'll be good for you. Do some Googling.
Hahahaha, no. Nimrod implements loads (and I mean loads) of language features. It includes pretty much everything Ada does. Really worth having a look at.
Here is an example using the pySNMP library. just change targetIp. You may also have to replace 'public' with your read community string and/or '161' with your SNMP port. See RFC-1759 for details on what 'prtInput' returns: # GETNEXT Command Generator prtInput = (1,3,6,1,2,1,43,8) #OID from public printer MIB (see RFC-1759) in tuple format targetIp = '192.168.1.100' from pysnmp.entity.rfc3413.oneliner import cmdgen errorIndication, errorStatus, errorIndex, \ varBindTable = cmdgen.CommandGenerator().nextCmd( cmdgen.CommunityData('test-agent', 'public'), cmdgen.UdpTransportTarget((targetIp, 161)), prtInput) if errorIndication: print errorIndication else: if errorStatus: print '%s at %s\n' % ( errorStatus.prettyPrint(), errorIndex and varBindTable[-1][int(errorIndex)-1] or '?' ) else: for varBindTableRow in varBindTable: for name, val in varBindTableRow: print '%s = %s' % (name.prettyPrint(), val.prettyPrint()) 
Technically true, but totally wrong for CPython, any object you so much as glance at will have it's reference count incremented and decremented, resulting in the pages being unshared. It's basically impossible to get CPython to share any significant amount of memory with `fork()`.
Your question is wrong. It doesn't "bypass" anything. You must first understand what processes and threads are, then understand what the GIL is and why it's there in the first place. The GIL is a global interpreter lock. Even though threads in Python are POSIX threads (that the kernel is aware of), the interpreter lock makes it so that only one thread within a process can be executing Python code at any time. Multiprocessing is simply spawning another process, so the spawned process operates completely independently of other processes and *has its own GIL*. Spawning processes is perfectly fine if you need to do it but you have to consider your use cases. Trying to spawn processes thousands of times per second for each new TCP connection, for example, is bad design. But spawning a few processes in a pool to saturate your multi-CPU system is very good use of processes, since you're not actually spawning them often, and there is no "expensive" overhead. Very efficient communication between processes is possible by designing your system intelligently. Use tools like ZeroMQ to help you. Don't blindly believe everything you read on some kid's cool new JavaScript NodeJS blog about how "threads and processes are expensive". Understand what they really are and understand when and how to use them and design with them. Edit: You can *actually* bypass the GIL in a Python thread by writing an extension module in C, or using Cython, or CFFI (I think). Such modules can be written to run in their own thread that does not need to acquire the GIL. You can highly optimize critical parts of your code this way while still taking advantage of the productivity you get with Python. Edit 2: The pypy project released pypy-stm, which uses software transactional memory and provides a way to execute multiple Python threads "at the same time" while still maintaining the thread-safety that the GIL provides. The pypy guys are very smart and it's one of the most amazing projects I've seen in a long time.
I'm not sure what gave you that idea? :) Using bundler as above is a reasonably standard way to generate the structure for a new Ruby gem. So I know I can literally just start banging out code in an "example.py" file but I would like to quickly set up a project as described in the link above without manually creating all of the files and directories.
[Here](https://github.com/jacebrowning/template-python) is a python project template that uses cookiecutter. (disclaimer: I am co author). The template generates an python package with `setup.py`, `README`, `MANIFEST.in`, and other standard files like `.travis.yml` for running your tests on Travis CI. It also includes a `Makefile` to automate common tasks like running tests (py.test or nose, your choice), doing style checks (pep8/pylint/pep257) and building/configuring a virtualenv.
http://tutorial.djangogirls.org
Didn't know this. Thank you!
If you want to learn a best-approach to Qt in Python, I'd suggest the [Rapid GUI Programming with Python and Qt](http://www.qtrac.eu/pyqtbook.html) book. It focuses on the old-style slots with PyQt, and has numerous errors, but it does a good job of explaining the process of building a UI with Qt.
Indeed, a source for the COW problem is here: https://mail.python.org/pipermail/python-ideas/2011-April/009892.html. But still. If your subprocess only works with a small percentage of the imported module space, it's not nearly as bad as "creating a whole new interpreter" and it's not accurate to claim the process is automatically equivalent to this from a memory usage standpoint.
Really? On my Linux box, python3 has a resident size of 8.5MB (with nothing running). Python is known to be very memory efficient, and it's using refcounting. pypy, on the other hand, can get a bit bigger and is using garbage collection.
It sounds like you are trying to reimplement features that are provided by every database. Generally, that's a really stupid idea ... you should use existing stuff like sql or maybe [pandas](http://pandas.pydata.org/) or whatever. If you really must, you could use something like this: data = {'x.title' : ["A","A","B","B"], 'y.title' : ["B","A","B","A"], 'z.title' : ["C","D","E","F"]} xdata = [] ydata = [] zdata = [] for (x,y,z) in zip(data['x.title'], data['y.title'], data['z.title']): if x == y: xdata.append(x) ydata.append(y) zdata.append(z) data['x.title'] = xdata data['y.title'] = ydata data['z.title'] = zdata Edit: Here's how you could do the same thing with pandas: df = pd.DataFrame(data) print(df['x.title'=='y.title':]) 
With today's mcu's(for ex. a $2 256K/108K flash/ram mcu by nxp) there's less need be limited to such low end microcontorollers. I even know of a company - synapse wireless that probably uses python on a wireless microcotroller as a way to rapidly build products to various niche industries , and they seem pretty successful , even got bought. 
I liked MIT OpenCourseware Into to Python
This is awesome!
Googling for sure, I'm just not sure the language of what I'm looking for :D I'll take your post and run with it though. It sounds interesting if anything, maybe nothing comes from it, but it does seem interesting to read about!
No, this is not the place, please post on /r/learnpython and you'll get the help you need! Good luck.
Especially since the matrix equation as well as some of the code goes *well* past the margin!
You're right. I'll delete this and post over on /r/learnpython, thanks.
Pirate it? With all the free resources out there that is just terrible advice. 
Thank you kind sir. I've been looking for a resource such as this.
I made some slight changes to your code to allow monitoring of multiple items. I submitted a pull request on github.
https://github.com/joke2k/faker
There's certainly many reasons to use IPython notebook, but its default page width compared to an arbitrary choice by a blog is near the bottom of that list, I think.
Why doesn't the outbreak start at the scrotum?
So is this just a wrapper for the Infoblox REST API?
I'd like this too, personally I greatly prefer Ruby, but ofc for scientific / numerical computing / neural nets the lib support just isn't there :(
This is very difficult to read.
I'm really not sure what you're asking for. some_var = some_var.foo().bar() that doesn't intrinsically mean anything. some_var would have to be an object with a method foo, that returns an object with a method bar. that assignment statement would place the value returned by bar in some_var, probably overwriting what it used to be (the object with a method named foo). is that what you mean? that sounds strange to me. i think i don't get what you're asking.
Godtdammit that's my motherland you're talking about! :D
&gt; Godtdammit that's my **fatherland** you're talking about! :D FTFY
[Real Python](https://realpython.com/) - specifically courses 2 &amp; 3
&gt; in regards to speed and memory allocation Nope, no difference. I answered it on SO just in case it's useful to others: http://stackoverflow.com/a/27210105/489590
You should probably do it yourself a few times and then consider a generator. Otherwise you don't get a sense of what the different parts are for. I know a friend in this same situation that jumped straight to generators and missed a lot of the context. He ended up with packages full of files he wasn't sure what were for. Even though it's python, there isn't one agreed upon easy to structure packages. Opinionated software is okay once you have enough context to know why decisions were made. 
&gt;And still Love C. Check out *21st Century C* Will do. I code in C regularly, I'm just not in love. Thanks for the recommendation!
Yes, the notebook is here, if it's of interest to anyone: https://github.com/maxberggren/blog-notebooks/blob/master/SweEbola.ipynb
If I'm understanding you correctly, you *can* already do this in several ways. Methods are objects, so if you have a *deep* (e.g. matplotlib.pyplot.scatterplot) method you can just assign that function to an object, or make a lambda or decorator to have only the amount of input you want. plot_scatter = matplotlib.pyplot.scatterplot I could then call `plot_scatter(x, y, ....)` as normal. Of course, noone writes code like this, because you can *automatically do this* in your `import` statement using the `as` instruction: `import matplotlib.pyplot.scatterplot as plot_scatter` Am i understanding you correctly? Also: to get **one** newline in reddit/Markdown use **two** newlines, not **one**
Oops, I'm not sure how to x-post. Meh, at least I can share it with you guys for now, if it picks up steam I'll look into the x-post part.
This is cool. Maybe you should limit it to 5 or 6 letter domain names though since those tend to be the most interesting. Also, instead of going through the Dreamhost api, it might be easier to connect to a whois server directly with pywhois. http://code.google.com/p/pywhois/
Yeah....incase someone wants the premium stuff and is a broke.college or high school student then only one should pirate 
If that's the case, then no it won't be useful.
Are you saying the original post is difficult to read, or that the feature makes code less readable? Either way, I agree with you.
If you send kill -USR1 to a dd process it will print the progress. You might be able to display that in the gui.
I was referring to the post but now that some other comments pointed out what he wants I think that's ugly as well.
If you're doing a lot of this kind of stuff, I highly suggest using pandas or matplotlib for this, the data-structures there are made for these kinds of operations and support logical indexing. Example of logical indexing: data = data[data[:,0] == data[:,1],:] 
I'm sure it's not a rock solid one to one equality but it's probably a good indicator of the interest in the language. 
You can do this already ap = list.append l=[] ap(l,1) print l #prints [1] If myobj.foo().bar is a function, you can assign it to a variable the same way.
I formatted the OP. --- So, I've been programming for about 2 years, particularly in python. One feature i've felt is missing is something that's similar to the increment operator for functions. Basically, it would allow you to call functions on a variable, and have them persist. # Currently, this is what you do: variable_here = variable_here.foo().bar() # And you can do: variable_here += "foobar" # But this leaves variable_here the same: variable_here.foo().bar() # So why not have: variable_here .= foo().bar() This seems like it's very simple to explain, and shortens a whole lot of code. In particular, when you have large variable names, or large function names, this makes it easier to comply with PEP 8. Am I crazy, or would this actually make programming in python better. --- I still don't get it. 
The safest practice would be to have the script be aware of its directory. quoting /u/mfitzp: &gt;You can get the path of the currently running script (from within the script) using `os.path.realpath(__file__)`, e.g. scriptdir = os.path.dirname(os.path.realpath(__file__)) with open( os.path.join( scriptdir, &lt;filename&gt; ), 'r') as f: f.read() &gt;Then it doesn't matter how you call the script, it will *always* be opening files from it's own folder.
You got a clear error, look at it! They accidentally stopped using commas to separate the tuples. Fix it yourself, run it, see if there's another ridiculous error, see if you can patch that, then report all these bugs on the github page.
https://en.wikipedia.org/wiki/Moder_Svea
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Moder Svea**](https://en.wikipedia.org/wiki/Moder%20Svea): [](#sfw) --- &gt; &gt;__Mother Svea__ or ___Mother Swea___ ([Swedish](https://en.wikipedia.org/wiki/Swedish_language): *Moder Svea*) is the female personification of [Sweden](https://en.wikipedia.org/wiki/Sweden) and a [patriotic emblem](https://en.wikipedia.org/wiki/National_emblem) of the Swedish nation. &gt; --- ^Interesting: [^Mother ^Svea](https://en.wikipedia.org/wiki/Mother_Svea) ^| [^Berga, ^Linköping](https://en.wikipedia.org/wiki/Berga,_Link%C3%B6ping) ^| [^Stora ^Nygatan](https://en.wikipedia.org/wiki/Stora_Nygatan) ^| [^35-åringen](https://en.wikipedia.org/wiki/35-%C3%A5ringen) ^| [^Carin ^Hjulström](https://en.wikipedia.org/wiki/Carin_Hjulstr%C3%B6m) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmgtxr5) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmgtxr5)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Just as a heads up to those googling (first result for bytereef...) there is [m3-cdecimal](https://pypi.python.org/pypi/m3-cdecimal/2.3) which is hosted PyPI. I'm not affiliated, and the sha sum doesn't match so no idea if it's been tampered with, but it uses the same (cdecimal) module name dispite the different repo name.
I am a little bit confused by your first example in the docs... import json from bottle import post, request, HTTPError @post("/somepath") def handler(): body = request.body.readlines() data = json.loads(body) if "somevar" not in data: raise HTTPError(400, "'somevar' parameter is required!") return json.dumps({ "something": 1, "result": database[data[somevar]] }) `request.json` exists and bottle turns dicts to json responses anyway. You could simplify your example a lot. from bottle import post, request, abort @post("/somepath") def handler(): if "somevar" not in request.json: abort(400, "'somevar' parameter is required!") return { "something": 1, "result": database[request.json[somevar]] } There is room for improvements. The `request.json` property for example could raise an HTTPError(400) on parser errors instead of 500. Pull requests are welcomed. 
"vi test.py" ;-)
Thanks for feedback. &gt; request.json exists and bottle turns dicts to json responses anyway. You could simplify your example a lot. &gt; The request.json property for example could raise an HTTPError(400) on parser errors instead of 500. It could, but it doesn't. &gt; request.json exists and bottle turns dicts to json responses anyway. You could simplify your example a lot. Yes, but only dicts. My wrapper turns everything into JSON, and you can optionally disable it using ``return_json=False`` parameter.
[Documentation](http://rbottle.readthedocs.org/en/latest/) updated.
That's neat. Is there a list of things `@micropython.viper` supports (or plans to support)? It seems to get to half the speed of PyPy... but only when it actually works.
I'm terribly sorry. My formatting was from a phone. This is what I meant to write.
It would be confusing, because in assignments in the form of `var += something`, there `something` is an expresson. However `var .= something` would be different, there `something` would be the thing that follows an attribute access dot. Nothing in Python works like that.
It was another penis joke.
Fair enough logic. This post has given me a lot to think about (not least to check formatting).
I've just built a twitter bot that do that https://github.com/defacto133/twitter-wordcloud-bot
Hey Max, I'd like to know more about this part of the code: from PIL import Image img = Image.open('popdens2.png') img = img.resize((img.size[0]/2,img.size[1]/2)) img = 255 - np.asarray(img) imgplot = plt.imshow(img) imgplot.set_interpolation('nearest') What do lines 4 and 6 do?
Honest question: What do I gain by using Emacs, Vim, Atom instead of a IDE like PyClipse, Pycharm, etc.? I don't want to induce any flame wars, I'm just really curious
Have any of you gotten this to run? I was wanting to play with it but am getting several errors, like "out of bounds" for the initial infection (309,170).
Line 4 converts a greyscale Image object into a numpy array of values 0 to 255. In each cell, it does 255 - the value, effectively inverting it. The last line is to do with how the discrete numpy array is resampled to a higher resolution by imshow: each pixel displays the value of its 'nearest' cell, rather than trying to do any sort of smooth interpolation. 
Quick, someone tell the *entire field of epidemiology* that we don't need maths any more. 
There is absolutely no difference to the code at all, although readability may be enhanced with the parens. The byte code generated is the same: py&gt; from dis import dis py&gt; dis("a, b = (1, 2)") 1 0 LOAD_CONST 3 ((1, 2)) 3 UNPACK_SEQUENCE 2 6 STORE_NAME 0 (a) 9 STORE_NAME 1 (b) 12 LOAD_CONST 2 (None) 15 RETURN_VALUE py&gt; dis("a, b = 1, 2") 1 0 LOAD_CONST 3 ((1, 2)) 3 UNPACK_SEQUENCE 2 6 STORE_NAME 0 (a) 9 STORE_NAME 1 (b) 12 LOAD_CONST 2 (None) 15 RETURN_VALUE The above is with Python 3.3. In Python 2.7, you need to compile the code first, not just give it as a string: py&gt; code = compile('a, b = 1, 2', '', 'exec') py&gt; dis(code) 1 0 LOAD_CONST 3 ((1, 2)) 3 UNPACK_SEQUENCE 2 6 STORE_NAME 0 (a) 9 STORE_NAME 1 (b) 12 LOAD_CONST 2 (None) 15 RETURN_VALUE The byte-code may not be the same when comparing two versions (Python 1.5 generates *very* different byte-code!), but the important thing is that whatever version you use, with or without parens does exactly the same thing. So don't worry about performance or efficiency, and write whichever reads the best.
So, *img* becomes the grid where we are going to apply our algorithm?
And those who have no idea what "flagged topics" means in context. 
Google has flagged certain search topics- if you search them, their foobar app will show up in the results, and you'll be logged in.
Why not just use elpy? http://elpy.readthedocs.org/en/latest/index.html
There's PythonAnywhere (full disclosure: I work there). You can host there, and you can code online from inside your browser too if that helps...
Working for large companies is the literal worst. This is why they need to hire so aggressively, to counter the turnover. I'll pass. 
I guess the challenge is how well you do at [Vim Golf](http://www.vimgolf.com/). I see [PyCharm got multiple cursors](http://blog.jetbrains.com/pycharm/2014/09/feature-spotlight-multiple-selections-in-pycharm/) in March, so that's pretty cool.
Note, the `--no-site-packages` flag for virtualenv has been the default for *ages*. It's even deprecated!
Thanks.
It's the default for everyone, `virtualenv` doesn't special-case linux users :S
Thanks for sharing. Looks useful. webargs is a library that has a similar functionality for "injecting" request arguments into view function arguments. It supports bottle as well as Flask, Django, and Tornado. https://github.com/sloria/webargs
I'm only posting this as an alternative to elpy or even for a potential way to enhance elpy capabilities with code introspection. This reminds me more of the functionality I had when I had a Wing IDE license, but I still missed Emacs. 
Did you clone the whole repo? https://github.com/maxberggren/blog-notebooks? It has some dependencies.
Yep. img starts as the image, then is the resized image, then is the numpy array representing the inverted image. 
Yes I use an image of the population density using the pixels as cells in my model after downsampling it to half the pixels. And as previously stated RGB values needs to be inverted.
Shouldn't the infection rate be beta*S*R, instead of beta*S*I ? You get contaminated when another zombie bites you, not by contact with infected people. Edit: Very cool idea by the way.
&gt; Why not just use elpy? or anaconda mode.
Cool! Are you allowed to use custom urls?
Actually the animation of the [SIR model on wikipedia](http://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model) was also written in python. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 1. [**The SIR model**](https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model) of article [**Compartmental models in epidemiology**](https://en.wikipedia.org/wiki/Compartmental%20models%20in%20epidemiology): [](#sfw) --- &gt; &gt;The __SIR model__ labels these three compartments __S__ = number susceptible, __I__ =number infectious, and __R__ =number recovered (immune). This is a good and simple model for many infectious diseases including [measles](https://en.wikipedia.org/wiki/Measles), [mumps](https://en.wikipedia.org/wiki/Mumps) and [rubella](https://en.wikipedia.org/wiki/Rubella). &gt;The letters also represent the number of people in each compartment at a particular time. To indicate that the numbers might vary over time (even if the total population size remains constant), we make the precise numbers a function of *t* (time): S(*t*), I(*t*) and R(*t*). For a specific disease in a specific population, these functions may be worked out in order to predict possible outbreaks and bring them under control. &gt;As implied by the variable function of *t*, the model is dynamic in that the numbers in each compartment may fluctuate over time. The importance of this dynamic aspect is most obvious in an [endemic](https://en.wikipedia.org/wiki/Endemic_(epidemiology\)) disease with a short infectious period, such as [measles](https://en.wikipedia.org/wiki/Measles) in the UK prior to the introduction of a [vaccine](https://en.wikipedia.org/wiki/Vaccination) in 1968. Such diseases tend to occur in cycles of outbreaks due to the variation in number of susceptibles (S(*t*)) over time. During an [epidemic](https://en.wikipedia.org/wiki/Epidemic), the number of susceptible individuals falls rapidly as more of them are infected and thus enter the infectious and removed compartments. The disease cannot break out again until the number of susceptibles has built back up as a result of offspring being born into the susceptible compartment. &gt; --- ^Interesting: [^Seir](https://en.wikipedia.org/wiki/Seir) ^| [^Epidemic ^models ^on ^lattices](https://en.wikipedia.org/wiki/Epidemic_models_on_lattices) ^| [^Mathematical ^modelling ^of ^infectious ^disease](https://en.wikipedia.org/wiki/Mathematical_modelling_of_infectious_disease) ^| [^Critical ^community ^size](https://en.wikipedia.org/wiki/Critical_community_size) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmh3q2g) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmh3q2g)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
This is just my opinion, but there's no real market for ruby/rails to survive in. Python will generally outlive Ruby as it's used in scientific computing. And Node.js is increasingly looking like the true successor to PHP that Ruby was meant to be. As unfortunate as it is for the ruby community, their numbers are dwindling. The writing's on the wall.
Paying somebody to do your homework? Low.
I'm not really following, are you having troubles with the big vector equation that spans more than the text width? Screenshot?
Fuck off. 
Yeah it is, but my professor didn't accept funeral arrangements as a legitimate reason to not do it, so I'm just trying to find a way to get it done.
Ah I read your article too fast, I thought it was Sane/Incubating/Rampaging or something like that. Said otherwise, I thought "I" was an intermediary step between 'Infected' and 'Is now a zombie'. My bad. No objection to your model then.
I am not allowed to use pandas unfortunately. How would I do what you stated above for any size dictionary? The one above works for three, but if there are a different number of column/row pairs it wont work?
Is there any way to convert the dictionaries im using to what you stored the data as in your example and then after filtering the data turning it back into a dictionary? Also, how would this work for more than three columns?
As I said, you could convert back and forth using the zip function. But that would kind of undermine my whole point. The example I gave only works with three columns because I used tuple unpacking to access the items inside the tuple. More readable, imo. I didn't think this would be a problem because presumably you know how many columns are in the data you're working with, right? If you index into the tuple instead, then it will work for arbitrary sizes (as long as you don't access a non-existent index): filtered_data = [row for row in data if row[0] == row[1]]
What makes it better than MQTT, except the name?
Would filtered_data = [row for row in data if row[0] == row[1]] replace filtered_data = [(x, y, z) for x, y, z in data if x == y] that you stated before? Also, lets sat the table I have is {'x.title' : ["A","A","B","B"], 'y.title' : ["B","A","B","A"], 'z.title' : ["C","D","E","F"]}. Can you use this example with that you did above, and then convert it back into a dictionary with the proper items filtered out? Sorry for the hassle, just not really getting how it all comes together. Thanks for the help. 
As someone going through their written courses, I highly recommend this resource and the RealPython books.
You (the programmer) will be partially responsible for any memory that crosses from python to C/C++. Python does this by reference counting: https://docs.python.org/3.5/c-api/refcounting.html . It is your responsibility to increase/decrease the reference count of an object as it moves between python and C. If learning C++ is your goal and you'd like to use Python while doing it, I'd recommend Boost.Python: http://www.boost.org/doc/libs/1_57_0/libs/python/doc/ . The tutorial is good, although it does assume that you have a basic understanding of C++: http://www.boost.org/doc/libs/1_57_0/libs/python/doc/tutorial/doc/html/index.html . I'd recommend reading a book if you want to dive into C++, such as http://www.amazon.com/gp/product/0321563840/ref=pd_lpo_sbs_dp_ss_1?pf_rd_p=1944687602&amp;pf_rd_s=lpo-top-stripe-1&amp;pf_rd_t=201&amp;pf_rd_i=0201889544&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_r=1C9XVC14E3BDBBF8VKP5 . 
You mean your own domain? Not on the free plan (that only support yourusername.pythonanywhere.com), but the cheapest "custom" plan (which should be fine for a low-traffic site) costs $4.10/month and supports custom domains. (Our $5/month "Hacker" plan doesn't support them, despite being slightly more expensive, though that's likely to change soon...)
Very cool! Thanks for the info! I'm going to talk to one of my friends irl (he has his own site) about what he does before I do anything. He's more tech savvy than I am anyways. 
I bet even though this is a lame trick because OP is too lazy doing homework, someone has already done or will do it, because unfortunately: &gt; Money makes the world go round Next time I would recommend starting earlier or at least trying to do the homework yourself if you need to rush it and then posting your efforts in /r/learnpython or something similiar. Because you might not have the bucks to maintain this lifestyle on the long run.
So what youre saying is that the example /u/Ilerea_Kleinokitz used can be modified to work with any number of column/row pairs? If that is correct, could you give me some idea as to how dict.values works with the code he/she posted? I dont get how to access each individual value in the row for each column and check if the values in different columns are equal.
Im not sure what this: for (x,y,z) in zip(data['x.title'], data['y.title'], data['z.title']): is doing but i understand how in the rest they are creating new lists with only the filtered data and then setting the keys of the dictionary equal to the new data. I just cant see how you could make that work for more or less than three column/row pairs.
&gt; MQTT First of all, MQTT is a protocol, sharknado is a server. It works over the HTTP protocol and that makes it human/developer friendly: messages can be pushed/pulled using a web browser. It's easily deployable, in fact it can be deployed on heroku with a single button click. It's super easy to use on the client side too, it's just a matter of GETting an url.
So the `data['?.title']` parts are just grabbing columns from your dictionary. This is done a total of three times, once for each column in your example. To get it to work with any number of columns you will need some way to get all of the values in the dictionary. I wonder how you could do that. These columns are then being passed to the `zip` function. `zip` _transposes_ its arguments, basically just flipping the columns and rows. So `zip([1, 2], [3, 4])` returns `[(1, 3), (2, 4)]`. All of those values you hypothetically got in the first step need to be passed as separate arguments. How could you do that? The `x, y, z` is taking those rows returned by zip and splitting them apart into the data in that row using tuple unpacking. This assumes there are three items in the row, so for the multi-column code you'll want to just get the row and worry about getting the data out of it later.
So for the first part you talked about, I could use dict.values()? If I do that on the example dictionary I get dict_values([['C', 'D', 'E', 'F'], ['A', 'A', 'B', 'B'], ['B', 'A', 'B', 'A']]) Would I do for (x,y,z) in zip(data.values()): now? 
Sounds wise -- always good to have someone experienced looking over your shoulder when trying new stuff like this :-)
Windows is supported now.
I have implemented GTK3 support in the new version. CEF support will come next.
Ahh yes, but technically no one mentioned a package. Only a project. And that can easily just be a single file. And I was not serious.
Reading through this brings up some questions for me about how PyMC works. When I look at the Monty Hall example and how they solved it, there doesn't seem to be enough information to solve the problem in PyMC, is there something I am missing or does PyMC only work in specific cases?
"Guess the words we're thinking of! If you guess right, we'll pass you on to the next stage of the interview!" Google actually thinks this is a good way to find candidates for a job? Sheesh, they've lost the plot.
There are no assignments worth cheating on (at least this publicly) when it can result in an automatic fail or even getting kicked out of a university/college.
When you say "calls a C/C++ script" do you mean via subprocess? Or do you mean you are calling functions in a compiled C library?
I have tried multiple ways for the last hour or two and have gotten nowhere. I feel like the answer is fairly easy but I cannot grasp it. Could you modify the code above to work for my conditions, at least partly, so I can go from there? Thanks for all your help.
Looks like you're missing MS C++ runtime files or something
Visual C++ is the official Python Windows compiler. Python itself is written for Visual C++ (in Windows). Why are you stuck on using MinGW?
Use binaries on Windows, don't try to build from source. 
I'm not going to disagree with you, since elpy has so many features. I had issues with completion with elpy on one project, but then again I've since switched from rope to jedi and been more pleased. I was never sure how these were implemented in elpy, I just know it takes a while to load an emacs session now that I use it. Granted, nothing compared to what it was like loading up an IDE for the first time.
It looks like you might be running into trouble by using Cygwin's gcc vs MinGW . Maybe try an easy to use MinGW distro e.g. https://github.com/develersrl/gccwinbinaries ?
(Read the 'formatting help' link for how to post code to Reddit without it being mangled.) Are those lists supposed to be the rows or the columns of the table? What is the desired output? And there are no floats in your sample data, only integers. If they are rows, the you don't want `zip()`, you want to just iterate over them, specifying a field width for each column, for example: row1 = [97565, 1, 'U', 23, 'ELECTROENCEPHALOGRAPHIC', 26] row2 = [81536, 2, 'YE', 24, 'ELECTROENCEPHALOGRAPHIES', 26] for row in (row1, row2): print('{:5} {:1} {:2} {:2} {:24} {:2}'.format(*row)) This prints: 97565 1 U 23 ELECTROENCEPHALOGRAPHIC 26 81536 2 YE 24 ELECTROENCEPHALOGRAPHIES 26 If they are columns, then maybe you want something like: col1 = [97565, 1, 'U', 23, 'ELECTROENCEPHALOGRAPHIC', 26] col2 = [81536, 2, 'YE', 24, 'ELECTROENCEPHALOGRAPHIES', 26] for row in zip(col1, col2): print('{:&lt;24} {:&lt;24}'.format(*row)) ...which results in: 97565 81536 1 2 U YE 23 24 ELECTROENCEPHALOGRAPHIC ELECTROENCEPHALOGRAPHIES 26 26 (By default numeric fields are right justified and strings are left justified; the `&lt;` changes that to make everything left justified. Use `&gt;` if you want right justification.) If you want to make a decision based on type, use `isinstance()`: for row in zip(col1, col2): if isinstance(row[0], str): print('{:&lt;24} {:&lt;24}'.format(*row)) else: print('{:&lt;24.1f} {:&lt;24.1f}'.format(*row)) Prints: 97565.0 81536.0 1.0 2.0 U YE 23.0 24.0 ELECTROENCEPHALOGRAPHIC ELECTROENCEPHALOGRAPHIES 26.0 26.0 I sidestepped the ambiguity in your question by checking for a string.
I'd love to find useful resources like this for python3, I just don't see the point of learning python2 if I'm not supporting legacy apps.
What better way to learn the Python 3 syntax by converting the code? Honestly, for the first 10 videos or so, you won't find much difference in the syntax. 
Yeah, I have a pretty decent handle on python3's syntax from a recent socket programming project I'm working on. I'm mostly just curious as to where this divide in the community comes from, I see tons of people advocating for python3, but then when super awesome tutorials like this one are posted they're in python2. Though I suppose if I really want to see change I should get off my ass and start making guides like this for python3.
I have done it before, but it was a colossal pain in the ass. I ended up saving off the binaries I generated just in case I had to ever do it again (cause I sure as hell don't remember all that I did). They are on my work computer otherwise I'd share them now (I'll try to upload them tomorrow).
Thanks for posting this! Great site. I am a business analyst looking to move from Excel to pandas. Partly to take advantage of scripts to automate some work using .csv files and partly to use files too large for Excel. I can't get enough of these pandas vs Excel posts. It actually appears as though pandas is fairly clunky in it's own right though. 
Yeah, but that's not what the OP is talking about, and you know it. 
I agree, I typically just use pandas to load data and then read it out as a numpy array for this reason. It feels like the DataFrame API is getting in the way of the data. 
You'll save yourself a ton of problems using compiled packages in python if you switch to conda: http://continuum.io/downloads Then: conda install pycrypto 
 for col in zip(*data.values()):
Saw it on Hackernews: https://news.ycombinator.com/item?id=8677556 It's not going to stop me "hacking" code in Python but does make me want to write more Java.
I can give you at least one idea that might help you find a project. That would be LinuxCNC.org. There is a lot of need in the open source CNC world for support programs that generate G-Code and the like. This is somewhat allied with the RepRap world too. If you like writing utilities, big or small it is a very active area of development. 
O_O tl;dr?
Hi, a few friends from my uni and myself are developing an open source distributed 3d printing service. Our previous dedicated python developer bailed about a week ago and we've been looking for a replacement. Seriously PM me if you're interested!
It simply is not practical. Not everyone has (or even wants to have) the Java runtime installed on their machines.
Here are a couple of links for help. [Tango with Django](http://www.tangowithdjango.com/) [Flask tutorial](http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world) Hope this helps.
Use one statically typed language because maintaining dynamic stuff is a pain and Java is the best statically typed ecosystem out there. Dude has a point. Still going to hack in Python though.
I just might, I've been looking for a reason to get my blog up and running and this could make a good series of posts. 
Using whois is a fantastic idea! I'm hesitant to use only 5 or 6 letter domains yet, but it's an easy change. I'm not sure how fast I'll run out of domains.
If there's some concept that's going to recur in your code, you might consider creating a class that represents that concept. Consider objects just far more sophisticated dicts that can have special functions and such. Suppose you have something like the weather report for a day. You might have the class Weather_Report that has many properties, including rainfall and snowfall as properties. Then you might want to get the total precipitation for the day. Well, there is a formula for that. Snow is approximately 10:1 when converted into liquid precipitate (i.e., rain), so you might have Weather_Report.rainfall, Weather_Report.snowfall, and Weather_Report.get_total_precipitation(self): return .1*self.snowfall+self.rainfall
I use pandas since 2 years ago and I can tell you it has come quite a long way into something pretty awesome.
&gt; .csv files and partly to use files too large for Excel. With large files you can use chunking to load them. Secondly be sure you have the correct libraries installed for excel files. I would recommend using HDF5 files for storing large datasets. 
Should be WeatherReport. Please follow PEP8.
I don't have to follow shit, least of all things called *proposals*. It's my code, I can do what I want. Notably, PEP8 calls for spaces instead of tabs, and *fuck that stupid shit*.
This is one of the reasons I like cython. You basically get all of C and all of Python right there. Can benefit from static typing if you want, or not, all dynamic python is valid too. Between python and C libs you pretty much have any amount of potential whatevers, and the native cython ecosystem is growing. Cython is what make libs like Kivy possible at all. It's pretty nice to have the option to either stay in python, interfacing with all your code as normal (but in the slow lane) or speed things up with a little extra work. You end up moving most of the more structural or performance critical code from python to cython over time in a flow that matches the sort of 'get it working then optimise' methodology most programs development tends to follow. The differences between the syntaxes are really minor, and it allows you very smoothly transition from your original hacky implementation to a more orderly one. Most of your code is probably not going to need too much attention, but cython gives you a very simple, not too many hoops involved solution for the code that does. A simple first pass static typing of the code can often double to quadruple performance (not amazing gains but often enough to solve certain issues), and a more thoughtful transition to a more 'C' implementation can see huge gains. (Basically C level performance) It might be a bit esotoric to get started with, and the whole compilation thing can be a bit of a downer if you're used to pure python, but cython is already a fairly robust ecosystem and gives you all the static typing you could ever desire, while being basically python with type declarations. 
Definitely a subjective piece. You could make that kind of argument for any language. Language choice is subjective after all ... Have in mind: the best language is the one you master.
it's an rm -rf / script, don't run this
what's that?
Yes, that works :) look at ´os.walk´ for files and directory and ´re´for the filtering. You can use this: http://regexpal.com/ to test your regular expression (re) 
It's possible in Python, but an answer that will probably get down-voted is to use the program [grep](https://en.wikipedia.org/wiki/Grep) (knowing what to use and when is half of programming). If you're doing this just for results, use grep. If you're wanting to learn how to do it yourself, then go ahead with python. Going with python, I'd break it down into steps: 1. How can I find all the files in a directory (do i need to go into sub-directories too)? 1. How do I open the files that are in the directory? 1. What's a quick way of getting each line in a file (hint: readlines()) 1. How do I search the line for the string of characters (just the exact string or a pattern)? 1. How do I write to a file? Putting all those steps together will achieve what you want to do.
Interesting! Can you elaborate here? pandas may have some quirks and more roundabout ways of doing certain things, but "absolute nightmare" is pretty far removed from my own experience. I'm curious to know your specific difficulties / use cases.
Awesome, thanks for the advice. I'm pretty new to python and it's half "I want to learn," half "it would be helpful for work." I'm not sure if I can get grep on the computer I need it on but I'll check. Thanks again.
Thanks, for the help. I'll check it out. 
Unnecessary, but not useless. At least to me, it makes the command more readable. It also makes it easier if I need to preprocess or apply some selection rule to what files I load. 
You **can** do what you want, but you **cannot** prohibit criticism, if you do so ;-) PEP8 is a convention, that you **should** follow if you share code in anyway with the community.
It works well on one OS and moderately (at best) on the others, anyone who claims it's fully supported and transplantable hasn't tried anything more than basic programs. I know the .net core is OS now and mono has been around for a bit, but it still has a long way to go until it's truly cross platform with all the stdlib support from windows. At the moment, I can't just pull c# over to my Linux box and have it work, it ends up looking like C with #if around. 
Elpy does much the same, I think - it uses either rope or jedi (configurable) as its backend for completion. (I've only ever used the jedi backend, so not sure how much they differ).
Depends on the task, but they have a bit of a point. I tried to use Python for a larger scale project and ended up regretting it. Don't get me wrong, I very much enjoy Python and use it often for scripts and smaller scale projects/tasks (and proof of concepts), but in the end of the day I'll probably choose something else for a deployable program that I need to scale. For the sake of collaboration efforts, I often think it's a better idea to write in something accessible rather than forcing others in my project to learn how to build the Python/C interop and make it cross platform. For most my uses Java, JavaScript or Go make the most sense.
If it's a real chart in Excel (and not an image pasted into Excel), then the data for said chart exists somewhere within the workbook. Reference the source data, not the chart.
We could work together on something, possibly expanding discoverflask.com. 1. Pick your poison - python2 or python3 2. Then the big one - diffs between the two :)
It is!, so if i read the formula of the cell?
&gt;Lots of what he says is so true, especially how the apparent verbosity of Java makes no difference in the long run Except that, largely independent of the language used, the number of defects correlates very closely to the number of lines of code in a codebase. So, in general, more verbose is more buggy. I'm also a bit cynical about the amazing benefits of TDD, but still do unit tests. I know enough about program complexity to know that, for any nontrivial application, you never can have anything near 100% test coverage, and I also know that tests can themselves contain errors. So I tend to do a cost/benefit tradeoff regarding how much unit testing is enough, and never allow "Well, it passed the unit test suite!" to lull me into complacency. But yeah... strange article.
Not the formula from the cell... Use the cell to find where the data originates from in the worksheet then you can read that
Glad to hear. Are there other topics that would be useful to cover in future articles?
Not really, every sensible solution involves at least temporarily converting data to row form. Is this for a homework assignment? Why do you need the data in dictionary form? You could do something like this: with open('yourcsv.csv') as csvfile: reader = csv.DictReader(csvfile) for row in reader: if row['title1'] == row['title2']: print(row) DictReader gives you a dictionary per row where the headers are the keys. After that, you'd have to merge the data somehow to accomodate your needs. 
I'm assuming you're the author. You forgot parentesis in line 12 of the second code listing. Line 2 and 3 of the fourth code listing should be swapped, or it's a syntax error.
Fantastic! I never even knew pandas existed so thanks for the great introduction.
I read the blog post and I found it a bit confusing, probably because of the example used. I do find myself creating classes very often, specially in early stages of development. This is mainly due to preparing the code for further implementations and I understand this is a time sink. I'm trying to improve on this, so I would like to ask you to share more examples of "when to create classes" if you know of any.
&gt;hint: readlines() That's maybe a bit outdated as a hint. Just iterating over the file will actually give you all the lines (and doesn't need to read them all into memory, so will be more efficient, and will work on huge files).
gstreamer?
These could be even more useful as an /r/IPython notebook. (e.g. though http://nbviewer.ipython.org/ or with https://github.com/jupyter/tmpnb etc.) * https://github.com/pydata/pandas * http://pandas.pydata.org/pandas-docs/version/0.15.1/api.html * http://pandas.pydata.org/pandas-docs/dev/api.html * /r/pystats #sidebar
Clearly the much more concise term of art should be Desecrator. 
/r/learnpython
i have used gspread to do similar work with google spreadsheets. might be worth checking out... i will try to see if i can find an excel specific library... this looks somewhat interesting https://openpyxl.readthedocs.org/en/latest/
This is abbreviated from https://github.com/westurner/pypfi/blob/da0e7267/pypfi/pypfi.py : import numpy as np import pandas as pd colname = 'date' n_rows = 100 start_date = '2014-01-01' df = pd.DataFrame({ 'date': pd.date_range(start=start_date, periods=n_rows ), 'amount': np.random.randint(0, 100, size=n_rows)}) df['year'] = df[colname].apply(lambda x: x.year) df['yearmonth'] = df[colname].apply(lambda x: "%d-%02d" % (x.year, x.month)) df['month'] = df[colname].apply(lambda x: x.month) df['weekday'] = df[colname].apply(lambda x: x.weekday()) df['hour'] = df[colname].apply(lambda x: x.hour) by_year = df.groupby(df['year'], as_index=True)['amount'].sum() by_yearmonth = df.groupby(df['yearmonth'], as_index=True)['amount'].sum() by_year_mon = df.groupby((df['year', 'month'])) by_month = df.groupby(df['month'], as_index=True)['amount'].sum() by_weekday = df.groupby(df['weekday_abbr'], as_index=True)['amount'].sum() by_hour = df.groupby(df['hour'], as_index=True)['amount'].sum() df_yearmonth = pd.pivot_table(df, index=['date', 'index'], columns=['year','month'], values='amount', aggfunc=np.sum, margins=True) output['pivot_by_yearmonth'] = df_yearmonth Something similar could be useful in the pandas docs, which are here: https://github.com/pydata/pandas/tree/master/doc 
Thank you so much, i've looked into openpyxl but it didn't seem to have what i needed
If it's a linux box, it will most definetely be there. And I agree, grep is by far the best way to do what you describe, it's literally a one liner. But, if you're doing it to learn, by all means, do it. It shouldn't be that much longer =)
just check all O(2^(n)) paths, duh :)
Dankon por la ligo. Mi amas pandas :) +/u/ppctip 1 coffee
^__[Verified]__: ^/u/cshoop ^^[[stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats_cshoop) ^-&gt; ^/u/chris1610 ^^[[stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats_chris1610) __^Ƥ1 ^Peercoins__&amp;nbsp;^__($0.7143)__ ^[[help]](http://www.reddit.com/r/PeercoinTippingBot/wiki/index) ^[[global_stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats) ***** ^[Peercoin](http://www.peercoin.net/) ^- ^The ^Secure ^&amp; ^Sustainable ^Cryptocoin
Heh heh, updated the post with your comment.
That could be nice.
Email me. Let's discuss. michael at realpython dot com. Cheers!
I can't speak to MongoDB, but one of the reasons we use a combination of Redis + RabbitMQ for our messaging pipeline is that Redis doesn't have durable persistence -- i.e. if Redis goes down you're up the creek and messages that have been enqueued but not yet dequeued are gone forever.
No experience with PyPy, but if you really want to contribute to a project start with a few bug fixes. I would also suggest contributing to any mailing lists and stackoverflow questions. You could also ask the mailing list (not sure if there is a dev specific one) about what they might want help on.
Sure it is, there is also an error on line 9 of the first example: &gt;&gt;&gt; greetThem.yo &lt;bound method Greet.yo of &lt;test.Greet instance at 0x10be9a908&gt;&gt; &gt;&gt;&gt; greetThem.meow Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: Greet instance has no attribute 'meow' Should be: &gt;&gt;&gt; greetThem.msg "meow" &gt;&gt;&gt; greetThem.yo() "Yo!" 
Actually, I'd say a python string is more like an array than a python list (though python lists are a lot like arrays too anyway). Strings can't change length (indeed, they're immutable altogether), or be inserted into etc. Importantly, the "contains" relationship works very differently between lists and strings. ('' in list("abc")) would be false, just as [] in [1,2,3] would be false. For strings, `in` checks for substring containment, while in lists, it checks for direct membership - ie there is an actual element with that value in the list, rather than there being a subsequence equivalent to that list.
No, thanks. If I have to change how I code before I give away something for free, then I just won't give it away for free. You sound like the noobs who show up in #Linux with an entitled attitude like "I'm using your OS; I deserve for you to fix my problem" Sheesh.
I read his comment as being *extremely* disrespectful to me. I took time to answer OP's question with something other than "google 'object oriented programming,'" and all I get is a guy telling me that I have to code a certain way in order to answer questions. Obviously there are plenty of other coders here to answer questions so you won't miss my minimal efforts, but this kind of response to my attempt at being helpful makes it less likely I'll offer help to anyone in the future.
I am. Our shop does not adhere to PEP8 because PEP8 contains stuff that literally is just Guido dictating what he likes. (case in point: the space/tab "debate")
I would be fairly skeptical of any study relating defects to lines of code. The biggest problem is that most of these studies use automated methods to identify coding errors which is ridiculous.
That's the discussion I use as a reference within the blog post. As I mentioned, he comes up with some very valid points but he doesn't really mention how to approach using OOP in languages that support it.
 sudo rm -rf ./ Will erase your directory recursively.
i have the same opinion to pep8 . At work we use a modified version of it for 'readability' reasons but our certainly doesnt pass teh pep8 filter. To be fair, if you take the pep8 filter and point it back at your pythons home directory, Python itself fails in many places.
This is a very good point. I didn't wan't to make the post too long. Ill add an edit in with multiple examples at some point this week. It is purely a design choice around how your software/game will work and where you will need to create multiple instantiations. You make thing's hard by creating small, featureless and hard to locate classes across multiple files. The best way to avoid this is to actually decide to containerize these functions/interfaces/properties inside a blueprint, that is your class.
IMO, what makes Java fast is an extreme commitment of engineering resources to making it fast. It's ironic to me that a lot of the techniques for making it fast were developed in highly dynamic languages (Lisp, scheme, Self, Strongtalk (a dialect of Smalltalk)). It's unfortunate that the leading dynamic scripting languages have such immature VMs. It turns a conversation about language features into a critique of speed. The two are only incidentally related. But... JS-family languages, Swift, etc. give me some hope. 
Make sure you're indenting your code when you post it on Reddit, you lose the formatting otherwise. Looking at your code, what I would do is set up a dictionary. binarydict = {A:01000010, B:...} And to display the value, use print(binarydict[A]) More reading here: https://docs.python.org/2/tutorial/datastructures.html
You mean related to Python and Pandas specifically or just other general topics?
Sidebar. Sidebar. Sidebar. Sidebar. Also: Sidebar. /r/learnpython
Look at xlwings, or makes interop quite simple. You can also look until Pandas, it has a lot more features that can more or less replace excel (for data processing) depending on what you need to do 
Typically, helping with Python 3.3 support is a task we give to newcomers, feel free to come on IRC and ask though.
Hi, I was able to contact the publisher (per Zelle's site) and get the answers to the exercises. Go here and fill out a request: https://fbeedle.com/drupal-6.19/contact I got a response within 24 hours. I would post the answers - but they specifically told me not to share. Hope this helps somebody out there.
Fantastic write up! I'm going to play around with this the next time I get a break. Thanks!
Seems that it was first mentioned in 2009: http://bugs.python.org/issue5639
Some of the material in the post is quite good but it is presented in a way that, for lack of a better word, reminds me of a scam. You know the type; "doctors hate her", "earn money from home" and so on. I wish more time was spent on talking about why the particular mask type was chosen, what other types of masks are commonly used and various considerations one should keep in mind when deciding on the mask to use.
I was hoping around $30 an hour but from what I see online it might be too low. I want to pay a fair price so feel free to PM me a message!
I tried doing it with an Image of Portugal and spain, but i failed miserably lol. :(
The site is trying to sell you a book about computer vision with Python. There's several articles on the site that are very similar. So it's basically a really informative advertisement. I don't know why you would consider that a scam (I'm not affiliated with the site or author, I just you know read the bottom part with the advertisement). I might agree with you if the code was not posted or it gave a vague description of the process and then said "well if you buy my book I'll show you how to actually do what I describe". There may well be more information about masks and their uses in the actual book. I don't get the complaint about explaining masks because the author *does* explain why a particular type of mask was chosen. They know their data set will have a lot of landscapes so there's going to be sky in the top quadrants of the images and ground in the bottom quadrants. There will also be some point of focus in the center of the images.
Sometime ago I read somewhere that to master python, write lots of python using only functions , dividing your code in modules, do that for a year or for a few big projects, then move to writing everything in classes only and do the same.. by the time you are done you will know when you need to use classes. 
change def reorganize (matrix[x][y]): to def reorganize (matrix): You don't have to tell python that you're giving it a 2d array. Just declare the function as accepting "something" called "matrix". See http://en.wikipedia.org/wiki/Duck_typing
Okay, thanks, I suppose I was putting that in wrong then. The [x][y] in the declaration were meant to indicate the size of 2d array. I'm probably going about this very wrongly, but I had p = -x immediately afterwards so that as I incremented p, I'd be able to reach the max length of array and stop, and the same with q = -y. If I feed in a 2d array into the function, is there a way to get it to also read the max lengths of the array?
Python strings are not null terminated. (At least, not from the programmer's point of view, though it would be possible for an interpreter to implement it that way.) To see this, try &gt;&gt;&gt; len('\x00\x00') 2 Python strings are simply sequences of characters (which themselves are strings of length 1). They have a length just like any other sequence.
If anything it was sarcastic but not even close to disrespectful.
Yes, I wonder about that. My guess would be that, for any sizeable application, it is debugged (and tested) to some perceived level of correctness, so the number of defects should related to the size of the application, and hence the number of lines. I also suspect than in reality the verbosity does not massively affect the size of the codebase measured in lines of code,. though that hypothesis might be pretty difficult to verify.
I may be missing a bit. But I just version control the source. So any developer can choose (be it not pycharm) and setup their environment like they want. 
Sadly this is true. But when I program I rather have a good introspection than nice macros for sorting or moving lines. Still it bugs me that when i do ctrl+k in pycharm it only keeps that last removed line where in emacs you can recall a whole block.
I am writing a [vim clone](https://github.com/stefanoborini/vai), fully in python. There's plenty to do. 
What's New in the latest version (0.2.5.post3): Performance timing/profiling enhancements &amp; additions. * `log_calls` reports and collects both wall time (elapsed time) and process time (CPU time), using Python 3.3+ improvements to the `time` module * Optimized the decorator itself, ~15% faster * Added a "true bypass" feature * enhancements/improvements to internals &amp; to documentation 
Try doing exploratory data analysis using Java and compare how you would do it with [Python](http://nbviewer.ipython.org/). There's just no comparison. I agree you can do most things with Java, but when it comes to data analysis or scientific computing...yeah have fun with Java.
Did you heard about standard asyncio module?
If you will be doing matrix math with python in the future, definately use numpy. If you can do what you want through vector/matrix operations, it'll be 20-200 times faster execution in numpy. 
If matrix is a numpy array, you could add x, y = matrix.shape To the top of the function. I'm not sure the best way to do it using regular arrays, as I never use them
Yes, but the asyncio module is designed to be used with "yield from" generators. I mean, I *could* create an asyncio implementation of this event loop, but there's no point at the moment. The purpose of guv/gevent/eventlet is that you can write code that looks like it's blocking for I/O, but it's actually switching to another greenlet in the meantime, and switches back when ready to read/write with very very little overhead. Furthermore, it requires zero modification to your existing WSGI app. And most 3rd party libraries which use blocking I/O like the requests module work out of the box.
Weirdest boner ever.
All are statements. An expression has the same definiton as [math expressions](http://en.wikipedia.org/wiki/Expression_%28mathematics%29).
&gt; I actually like the power to mix c and python without a strict divide between the two, but to each their own I guess. You can actually do this with cffi as well. I've found it to be easier to use than Cython, particularly while writing exploratory code. Here's an example (stripped for brevity) I tried while messing around with CFFI a while ago, doing some profiling (this is for computing a CRC24 checksum): from cffi import FFI from cffi.ffiplatform import VerificationError from distutils.errors import CompileError, DistutilsExecError defs = """ #define CRC24_INIT 0x0B704CEL #define CRC24_POLY 0x1864CFBL #define CRC24_MASK 0x0FFFFFFL long crc24(unsigned char *data, size_t len); """ funcs = """ long crc24(unsigned char *data, size_t len) { long crc = CRC24_INIT; int i = 0; while (len--) { crc ^= (*data++) &lt;&lt; 16; for (i = 0; i &lt; 8; ++i) { crc &lt;&lt;= 1; if (crc &amp; 0x1000000) { crc ^= CRC24_POLY; } } } return crc &amp; CRC24_MASK; } """ ffi = FFI() ffi.cdef('\n'.join([defs])) try: C = ffi.verify('\n'.join([defs, funcs])) except (CompileError, VerificationError): C = None def test_crc24_cffi(data): if C is not None: return C.crc24(bytes(data), len(data)) return 0 This could trivially be extended with a Python implementation (in place of `return 0`) to fall back to if loading the CFFI version fails for some reason, which is pretty cool.
when using nested lists you usually do something like x,y=len(matrix),len(matrix[0]) obviously there is no guarantee that your nested lists are all the same length, but such is life.
Thank you! I hope they respond.
Nice, made me go back and find this: http://bokeh.pydata.org/ D3 is rad.
Couldn't you build this on top of asyncio (instead of pyuv_cffi)? Or does this have way better performance? How did you make the choice?
libuv is written in C (used by nodejs and a few other projects), and it's much faster than pure-python asyncio, I ran the benchmarks. Another major advantage is that my pyuv_cffi module runs on any python, even versions like 3.2 which don't have yield from (pypy3 is stuck at 3.2 at the moment). It can very easily be made to run on 2.7, but I hate supporting python 2.x series - it makes a mess of the code. Python 3.3+ is vastly more clean and organized than any prior version, especially the 2.x series.
&gt; Just iterating over the file will actually give you all the lines That's handy to know. Thanks!
I'm really new at python too, but I don't think you're using int right. At the very least because you can't iterate over a variable that's an integer. 
Giving you the answer will deprive you of the opportunity to learn from your errors. Let's work it out. 1. Have you run the code? Does it run? If not, what are the errors? 2. Have you read documentation on the `sum()` method?
Okay. 1. This is the error I keep getting: Oops, try again. average([3, 0]) resulted in an error: 'list' object has no attribute 'sum' 2. I found this but I have no idea what it really means: "Sums start and the items of an iterable from left to right and returns the total. start defaults to 0. The iterable‘s items are normally numbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of strings is by calling ''.join(sequence). To add floating point values with extended precision, see math.fsum(). To concatenate a series of iterables, consider using itertools.chain()." What does iterable mean? And how do you set parameters?
What I really need is how to get to the end product using python. I don't want to do the data munging in Python and then throw it into Excel to formatted. I want to create and manipulate everything in Python, format it, and print to PDF, put it on a website, or just throw it into an Excel file. Visualization and display is what is hard for me! :(
&gt;... it is presented in a way that, for lack of a better word, reminds me of a scam. This is the thing that's a bit unfortunate about this guy. He's not very good at selling his product without it sounding like a terrible infomercial -- and his emails.. whoa boy are they annoying. But! His actual *content* is really solid. I bought his book when it first came out and it's actually a pretty darn good into to computer vision, especially at the price point.
Seriously, zionsrogue, you've been churning out some of the best, most useful tutorials imaginable. I've seen a lot of theory about CV, but you're the first one I've seen who actually applies it to real world, practical stuff. You could wrap everything you've done up into a O'Reilly Cookbook and I'd buy it in an instant.
&gt; libuv is written in C (used by nodejs and a few other projects), and it's much faster than pure-python asyncio Do you have any concrete numbers? Would be interesting to know.
If you're interested in labeled data-structures like pandas for n-dimensional data, you should give my library xray (https://github.com/xray/xray) a try. It is designed to make exactly those sort of use-cases easy and plays very nicely with pandas.
Thanks, I've had so much pain doing this with Pandas I wish I'd just written that type of library a year or two ago when I needed it. I'll look into using yours in the future. 
As a long-time eventlet/gevent user, I admit that I'm frustrated a Python 3 version of either library, providing even basic support has been so long coming. I remember how frustrating it was waiting for gevent 1.0 to release just so I could pip install and not have to jump through hoops. That said, I doubt it will be this simple. The impression I have gotten (and correct me if I'm wrong), is that a significant amount of the development effort for eventlet/gevent goes towards supporting corner-cases, which helps explain the long periods between releases. It may be that you will get 90% of the way towards supporting a basic web crawler with your first release. But the strength of eventlet/gevent, as you mention, is supporting existing code. And there is a lot of existing code. I will be watching this project, but I suspect there will be a long road ahead before I could consider using it.
The concept is simple; as long as the monkey-patched (socket, ssl, threading, subprocess) modules are correctly written and tested, then the vast majority of libraries will work. Those that use C extensions like psycopg2 provide hooks for exactly this sort of thing, so we can make them compatible very easily. On another note, have you seen the gevent/eventlet code? There are parts in there designed to support Python 2.4... It's horrific. Actively not supporting the 2.x series gets rid of a LOT of corner cases. I don't intend to be API-compatible with gevent or eventlet (although a lot of it already is); I only care about correctly monkey-patching the standard library to make this a useful event loop and WSGI server. The current guv code has borrowed much from eventlet/gevent so it's a great deal further than getting a basic web crawler working. 
Hiya
Yes, it is a good time(actually even 1-2 years ago it was good time). Python 3 was released 6 years ago. All major projects/Frameworks like Django and Flask support Python 3. Python 3 community is also quite mature now.
I do see what you are saying from a type checking perspective. However, your example would not follow the single responsibility principle. For me, it's the context that we are encapsulating and providing functionality for.
This seems like an awesome some idea. I would love to tinker with it and see if I can hook up my flask API. Any suggestions before I get started? 
Oh, well then I guess I will be making the switch. Thank you for the response
Noooooooooooooooo!
I'm aware of those nice key bindings. I used to work in emacs/vim professionally for years. Still it depends on what you need to achieve. For me I spend quite a lot of time making sense out of legacy code which involves a lot of looking up function and class definitions. Personally I wouldn't hesitate a second to trade key bindings for those feature plus the refactoring and inspecting ones. It seems that you know what you wanna do and what suits you right, so that seems totally fine for me. But I have seen to many people who won't try out any IDE for more than two days just because of the o-so-almighty editor. Its about choosing the right tools and not hanging on some old traditions. Most of those people are also the ones that will not use any VCS or write any tests. 
I think of it as relying on the fact that any string can have the null string embedded within it with the resultant being equal to the original string. If you take that in reverse then every string could be thought of as having a null string in it without change to the string. The null string '' is the *identity element* for the `in` operator.
If all you want to do is serve your flask app, there's nothing you have to do other than use the guv.wsgi server. Warning: I removed the psycopg2 support since I didn't have time to rewrite that module, and I didn't want to include known broken code. I didn't test out Cassandra support either. But since most network apps require database support, I'll add it back within a couple of days. However, pure-python libraries like pg8000 should work fine though. Also, don't use guv in production yet, not until I can get a stable release out soon.
There is only one Packt book out that covers Spark as its main topic (in the title) and isn't rated too well on Amazon. It has examples in Python, Java, and Scala, but with a strong focus on the later. I think it is OK-ish, surely better than nothing. But if you aren't in a hurry, don't want to read up the nitty gritty stuff after every chapter (e.g. no discussion of why you want Mesos, YARN, or a cloud), more books are coming from O'Reilly. Other than that: blogs and Spark's local documentation should get you started.
I'm also using this one: * https://github.com/patrys/httmock
Wow, when you put it like that..sign me up! :) Thanks, this sounds excellent!
Depends on your project. There are still a lot of things that don't support python 3. Porting your existing codebase is probably not worth it as python 3 doesn't really solve any major things that you didn't solve already, but again it depends on your project.
If I take the time to answer a question and the only thing you can say back to me is that my formatting is not your preferred way of formatting, that's disrespectful.
Thanks a lot for the suggestions. I watched some introductory videos by DataBricks on Youtube. These videos gave a very good introduction about the cluster system and basics (like running wordcount jobs). But being basic lectures, they did not cover how to write a proper app and details about the Spark API. I will try to see if I can get a hand on the book and try out the examples.
You should get yourself acquainted with python 3 asap as its got some really new cool features. If you're looking to decide whether to do some project in python3 then look into what libraries you'd need and if they have python 3 support. I've almost entirely shifted to python3 except in two projects where I depend on scrapy and/or goose.
Depends on your libraries? If you use opencv, pattern, or pybrain probably not yet. Most of the other ones should be fine.
https://github.com/thewhitetulip/SamplePythonScripts Some months back I created a github repo for small snippets in python because when I started out using python I didn't find any such repo. Enjoy!
I love python3, but biopython man. Its going to take ages to port that beast over. I really like to help but feel like I'm not quite good enough to do so.
Have a look here: https://python3wos.appspot.com/ if you see some package that you need, and its still not avaliabile for python 3, than its not the time yet for you.
Now with documentation for the api and a quickstart available at rtfd.org: &lt;http://kaviar.readthedocs.org/en/latest/&gt;. Any kind of feedback is highly appreciated!
And here a great article that claims the opposite: http://lucumr.pocoo.org/2013/2/13/moar-classes/ 
If you have no specific reason to choose python2, go with 3.
statements contain keywords and expressions. count &lt; 10 is a boolean expression So is True So are a 1 + 2 https://docs.python.org/2/reference/expressions.html
&gt; If you speak about python in public, you should better stay with PEP8 conventions Then I just won't help people any more or share my code publicly if me using tabs instead of spaces is going to garner this kind of condemnation. Thanks for the tip.
If you are using fabric as a part of your project. For me Fabric is deployment and config tool and I can use it with py3 project.
No go on the grep, it looks like I need to do it all in python. Thanks again for all the help.
As with many projects, documentation or bug triage are also valuable contributions and help getting an overview of the project. These are generally the entry points I consider when interested in a new code base. Kind regards Thierry
Second that, I don't really see the need plus running python 3 as the native python on my OS totally cripples the whole system.
I have managed to install OpenCV with Python 3.4. OpenCV 3.0 supports Python 3. It is still on Beta, but so far I had no difficulties.
I use python3 since 3.3. Not migrating old projects as it is a pain, but all new stuff goes under py3. And i do not look back, its great. Had very few instances when lib did not support py3. Usually worst case scenario with unmaintained libs is "experimental py3 support" committed to repo but nto made into release package. So for me its all good w/ py3.
You are welcome! 😉 To be honest... people who behave offensive like you seem to be not very interested in the python community itsself. That leads to the conclusion, that your knowledge is quite limited and probably not a good source of help. So your decision seems to be a win win situation.
If your doing anything science related, I'd advise against python 3 indeed.
When you complain about python 3 not working, those code samples you are citing are incompatible with python 3. Hence the major version jump, as there are api incompatibilities. The reason anything was changed is the same reason anything is every changed: progress. Python 3 is an improvement on python 2 in its language features and standard library. 
Why does the driver require a re write? API is not in production, currently just at POC stage so no danger there :-)
Thank you, /u/dangayle, I really appreciate that! :-)
This was very helpful, thanks a bunch!
Would you be open to messaging back and forth with me for a few minutes? (Or chatting over email?) I would love to hear some specifics about what makes the site seem "scammy" and like an "infomercial". I obviously don't want it to come across that way. I'm definitely not a sleeze-ball and don't want to give that impression.
Fabric is not going to get updated. It's bugfix only unless another maintainer wants to take the rains, afaik. Its spiritual successor, written by the same author, is [invoke](http://www.pyinvoke.org/).
My Multireddit placed this post right next to this one: http://www.reddit.com/r/javascript/comments/2o0lxu/there_is_so_much_innovation_going_on_in_javascript/ Irony.
I love pathlib as well.
All right, I got it. But is very hard to change something what you are used to. I am not acquainted with python3 yet. It also seems that python3 is slight slower than python2. Changes are important, but stability and predictability are also very important. What made Java dominate the enterprise and business world wast it stability and predictability. Better I delete my comments I never ever took so many down votes in my life. Down votes is a kind bulling against contrary ideas, out of the box. See also: http://blog.thezerobit.com/2014/05/25/python-3-is-killing-python.html 
&gt; Python 3 community is also quite mature now. So no fart jokes?
&gt; So no fart jokes? Remember, fart() is a function in Python 3. 
However STARTING a project in Flask with python3 would be no problem at all. Six years python3 has been out, and it is a true rarity that a library hasn't been written for python3 after that amount of time. Sure, there are several popular libraries that don't have python3 support, but it really is the minority. I agree with your advice, but am frustrated people are still using 2 when there is essentially no reason to the majority of the time. Python3 was and still is supposed to be cleaner, have less bugs, optimized, and include a variety of new and useful standard library functions.
I clicked on your name to see your other comments and I couldn't help but notice that 7 months ago, you wrote "I do data science - repeatability is key so I'm not leaving the Py2.7 numpy ecosystem for a while." I do data science, and I haven't yet made the transition off 2.7 for that reason. Also, I noticed in the [wall of superpowers](https://python3wos.appspot.com/) that Mysql-python is still red. Do you think it's time for data scientists to make the switch? 
 Python 3.4.0 (default, Apr 11 2014, 13:05:11) [GCC 4.8.2] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; fart Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; NameError: name 'fart' is not defined :( 
I cant into python 3. I think its just because 2.7 comes pre-installed on most linux distros so I when I am setting up a VPS/server for my script I can literally download the libraries, upload the script and run without having to change much. Also the print syntax is weird compared to 2.7, I know its not completely different, just added parenthesis. What benefits does python 3 offer apart from being newer? also I use python when doing reverse engineering related stuff because I like the fact it uses raw ascii and can add bytes to strings with escape characters.
I looked at that one too, but it looks like it only mocks requests and I needed to mock a SOAP wrapper. It looks pretty sweet too though!
There are two MOOCs using PySpark for teaching in 2015. 1) Introduction to Big Data with Apache Spark: https://www.edx.org/course/introduction-to-big-data-with-apache-spark-uc-berkeleyx-cs100-1x#.VH3KCOdVbd , starts on 23 Feb 2015; 2) Scalable Machine Learning: https://www.edx.org/course/scalable-machine-uc-berkeleyx-cs190-1x#.VH3KXOdVbdZ , starts on 14 Apr 2015. I'm looking forward to these courses.
It's not contrary ideas, you're saying Python 3 is bad because you don't know the syntax. It's like saying Ruby is bad because it doesn't run Javascript.
&gt; and moving to 3.x would break tools inherent to the OS. ...no! Python2 and python3 have coexisted peacefully for years, and most distros include both in their repositories with no problems - applications simply use the one they actually need.
&gt; actually even 1-2 years ago it was good time woa~ I'm sure some people would like you have you believe that, but the reality isn't quite so pretty. There's a reason that 6 years later it's only just becoming a reasonable target for new code. The performance, features and 3rd party support for python 3 have only really picked up in the last year or so. 2 years ago? Holy moly! If you migrated to python 3 two years ago, you'd have been in a world of pain, and probably had to back port your code to 2.7 to get your dependencies working. It's getting there now, but lets not sugar coat the history story here. 
I am going to cry when they take my print statements away. I may be the very last user of the 2.x line.
It's more a simple exercise to see if it can be done, without what I perceive to be the ugliness of a huge if/elif/elif/else. Unfortunately, python's bulky function definitions make this not much better.
Its nowhere as well maintained than the python2 version. Which especially sucks because my projects depend on the data parsing parts. Edit: I was wrong. The Biopython3 beast has already been tamed. Thank you /u/Gudeldar and /u/chickenphobia.
If you have some reason to start a Python 2.7 project, or if you are writing Python 2.x code, just make sure it is forwards-compatible to Python 3. That way, whenever you (or someone else) needs to migrate to Python 3, the migration will be smoother. I've been doing that: * [Django documentation](https://docs.djangoproject.com/en/dev/topics/python3/) has many tips on how to write code compatible to both 2.7 and 3.x * Whenever I write a piece of 2.7 code that is greatly simplified in 3.x, I leave the simplified version as comments. * `from __future__ import` is your friend. :) * `csv` module has a very different behavior: in Python 2 it only works on binary strings, on Python 3 it only works on unicode strings. (although the API is mostly the same)
If you want to be part of the problem, choose Python 2. If you want to be part of the solution, choose Python 3.
If you choose to stick to 2.7 at least upgrade to 2.7.8 for security reasons ;)
 print({ Suit.hearts: "Hearts!", Suit.diamonds: "Diamonds!", Suit.spades: "Spades!", Suit.clubs: "Clubs!" }.get(card.suit, "Invalid card suit!"))
Here is a page showing which projects are ported to Python 3 and which are not: https://python3wos.appspot.com wxPython is in a halfway state, where the in development Project Phoenix runs Python 3. 
I want to switch to python 3. What is the best way to learn 3 after knowing 2? Are there any resources that go over the 'main' differences in an easy to learn format? 
Sure, this solves the trivial example. I wanted to be able to support fully switched blocks, though.
Just a lambda is no good. I wanted to support full suites, and the only way to have a first-class suite right now is with a function `def`.
After a quick look through the documentation of Invoke I don't think that Invoke could replace Fabric for me. Fabric has been build for executing tasks on remote machine via SSH. Invoke looks to me as just another task executor for tasks on your local machine, like [pynt][1]: [1]:http://rags.github.io/pynt/
That was pretty useful! I had no idea you could unpack a tuple that way...
Do you know about this idea? http://code.activestate.com/recipes/410692/
You can do absolutely anything, this is such a general question no one will be able to help you. You need to give us more information. What is your prior programming experience? What are your interests?
If you are finding new bugs, please report them. SeqIO, AlignIO, these modules fully work in Py3. Any problems you have encountered must not be in our unit tests which would indicate you have found a fairly important bug.
I agree, if you like games learn PyGame and create a game. :)
Thanks for letting me now, this is very good news for me. 
Yes a game is a good option too. Though every time this comes up I have to recommend pyglet over pygame. More people should at least check it out. Its main advantage is that it uses an event model instead of a main loop. In pygame everyone ends up with one huge run function with a giant loop with all the code inside it. No organization. In pyglet you can register events (i.e. input received, collisions between objects) and create functions that handle those events. The code ends up much more organized and holds together well as the project expands.
Library developers generally sit on the bleeding edge. We all think that our project and the ecosystem is ready but I think you're correct. Only within the last year has the complete extended python ecosystem been fully ready for 3. Part of this is because it takes a few years for unmaintained projects to die and be superseded.
Are you actually importing Fabric into your project? If not, why is it a blocker? Py2 code will continue to run just fine along side Py3, as long as they are not running in the same project.
Don't run it as python, run it as python3. Just set it up in your path. Every OS supports this, and none will have the slightest hiccup.
Yeah... As long as we stay within the context of computer programming, the list of things you can't do with Python would be shorter. If you're willing to utilize libraries that do a lot of the heavy lifting for you, then 100 hours is enough time to do... lots of things.
Because double parens are redundant/optional and since there are no brackets it can't be a listcomp. And more generally, "being pragmatic" has equal weight as being explicit.
See [relevant discussion in the python-dev list](https://mail.python.org/pipermail/python-dev/2006-June/066008.html) as to why this kind of language construct is not included in python. Also keep in mind that the function call overhead in Python is going to be higher than using if/else, so your solution will come with a performance cost.
Yep thanks. I actually watched a video by the guy who coded this. I do agree although initially it took me a while to understand why it was the right approach. 
As a Django programmer, I'd love to go to Python3 but every project that comes up seems to have a requirement for Python 2.7 somewhere. However, I always make sure that my code is Python 3 compatible as much as possible.
Ubuntu locks its packages on version number for stability reasons. Only security subreleases get published. Each new version of Ubuntu gets updated version numbers for its packages. I'm not sure what the policy is on the part of the Python package maintainers; it's possible they backport the security updates to older versions of python so that they can be released into released Ubuntu versions.
Message.displaymessage() just screams redundancy in your face you could have just Message.display() and I don't see the point of display() method at all, mixing output and processing data in a class is a bad idea, why couldn't you just do print(message.saying) whenever you need it?
The dealbreaker for me is the `&lt;&lt;file` syntax. It's awful. I will admit, though, that I often forget the parenthesis when doing prints in quick ipython sessions. Luckily, we have the `%autocall` magic for that!
That article has an incredibly poor understanding of the huge changes python 3 brought. They didn't break backwards compatibility for no reason.
When distro maintainers do stupid things like lock onto a patch version instead of a minor version, it's usually on them to manually backport security updates. Security updates to minor versions is exactly *why* patch versions exist.
Certainly! The decorator returns the method unchanged.
LOL at it being *me* who's behaving offensively. Does "fuck" hurt your ears more than a fascist telling you you aren't allowed to produce code a certain way? And you're right. I'm so uninterested in the Python community that when I see someone ask about OOP in a post that hasn't even been voted up a single time yet (which should be an indicator that I was actually looking for new posts to help out on rather than just the already-popular posts), my first thought is "yeah this community is so bullshit and I hate it that I think I'll actually answer this loser's question!" and then I rub my hands together in a villainous way. What I don't like is taking the time to help someone and then the *only* response I get is "fuck your help because it doesn't conform to my arbitrary aesthetic standards." If that's what /r/python is all about, then you're right—I don't belong here. Good riddance.
Yeah it's an unfortunate policy. I'm sure it's served them well- Ubuntu is one of the most stable distros you can get- but it'd be nice if they could be more flexible with that policy.
No I meant that the support module for guv which allows psycopg2 to cooperate needs to be rewritten, psycopg2 itself doesn't need to be modified. Since psycopg2 is written in C, it needs a special support module to cooperate with guv - it's very small and very simple, so it's no big deal.
Install from source.
Two years ago, the only thing that ever stopped me from using Py3k was PIL. When that wasn't necessary, it was a no-brainer...and now pillow supports Python 3.
You can have /usr/bin/puthon{2,3} and just have a symlinked /usr/bin/python to python2. This is how all the distros have done it for ages now, including Fedora (who use Python for *all* of their sys tools, including anaconda).
Ok that makes sense. What about support for PyODBC, dose that need a special adapter or anything?
Yes they do. I use them on a daily basis in the tools I develop in Python3. 
With english subtitles
It can be pretty useful: zip(*[iter(range(30))] * 4) This will make tuples that are four-long slices of that input list.
Has gevent had an official stable port yet? It's never been the same for me.
Great video! Thanks for sharing
Why would you choose 2.7.2? 2.7.8 is out :) You should pick depending on what you want to do. I chose Python 2.7 because I need some libraries that don't exist in Python 3 and I couldn't care less about unicode. I care about math and science.
Gevent is dead, all hail Asyncio.
The [wall of superpowers]( https://python3wos.appspot.com) states that most of the most popular libraries in the python ecosystem support 3. I'm just saying the data. I'm able to go 3.4 with some complex web apps, and transitioning most apps to 3 isn't actually that hard. I suggest you look into porting those libraries to 3, it might be a good idea because there will never be a 2.8.
Hasn't PIL been dead since 2006?
This story is awesome. It's not exclusive of python's community, is beyond of that. Any community have credits of all that.
Check out the deadsnakes repository, by Felix Krull. I've been using it with great success for years. 
You are not going to pay us to do your homework.
Fabric (AS IS) will not be updated, but a new release (along with invoke) is in the future. Basically the author is splitting the task execution (invoke) from the remote execution stuff (new fabric). The current/old fabric is a mix of both task execution and remote task running. Don't bet on it anytime soon though.
AFAIU there are other MySQL bindings [that work on Python 3](http://stackoverflow.com/questions/4960048/python-3-and-mysql).
Pillow [gained support for Python 3 in 2013](https://github.com/python-pillow/Pillow/blob/master/CHANGES.rst#200-2013-03-15).
On Debian? Which Ubuntu release name do you use to match Debian stable?
Point me where you need some help and I'll start working on this with you.
Sorry man, no way is this not homework of some description. You could, of course, provide more details to prove otherwise.
I like the What's New documents from Python itself: - https://docs.python.org/3/whatsnew/3.0.html - https://docs.python.org/3/whatsnew/3.1.html - https://docs.python.org/3/whatsnew/3.2.html - https://docs.python.org/3/whatsnew/3.3.html - https://docs.python.org/3/whatsnew/3.4.html 
What's 100 pounds in fairy dust? Google wouldn't convert...
Did you mean Twisted? They're [working](https://twistedmatrix.com/trac/milestone/Python-3.x) [on](http://twistedmatrix.com/trac/wiki/Plan/Python3) [it](http://twistedmatrix.com/documents/14.0.0/core/howto/python3.html).
Interestingly, "abc".count("") returns 4, as if it is treated as ["", "a", "", "b", "", "c", ""]
Debian Jessie will be out within the month though, and it's shipping with Python 3.4
PIL, not pillow. Pillow is great.
The pypy sprints are an excellent way to learn. They are a very friendly crowd.
That could just as easily be: def switch(var, cases, default=None): func = cases.get(var, default) if func: func() def on_0(): print('NOTHING') def on_1(): print('ONE') def on_2(): print('TWO') def on_default(): print('MANY') for a in range(5): switch(a, { 0: on_0, 1: on_1, 2: on_2, }, default=on_default)
Unfortunately some of us are deploying Python applications on ancient versions of CentOS, and it's just easier to run Python 2 than to fight with sysadmins and compile everything from scratch. Otherwise we'd be using Python 3 I guess.
stop spamming this everywhere!!!!
because it is an infomercial...
I think that's what he meant by "if you have no specific reason to choose python2"
To be fair, asyncio is barely more than few months old.
very interesting
I don't know the exact reasons for not being backward comparible, but for example zip is now a generator, which will bring you a big increase in speed when working with big data sets. So it's one of the points where it's worth porting to 3.
Use [Miniconda3](http://conda.pydata.org/miniconda.html).
Very true. My goal was to implement something that resembles a switch to read- all enclosed in a suite, without scattering needless one-shot functions everywhere, or requiring much in the way of boilerplate.
If you list dependencies, if they are easy I will port them for you. Half the time there is no real reason why its not on python 3 other then no one has taken the time to switch the import statements/print/division stuff. Aka 2to3. Projects that do heavy string/byte manipulation are rare in comparison compared to tons of relatively simple libraries out there
I think its some SSL related fixes
I use opensuse. zypper in python3-numpy or etc. Arch and Gentoo have gone python3 by default. Other distros (Fedora, opensuse) have roadmaps that indicate python3 will be the default soonish. FreeBSD also has this as a prominent roadmap item. The only staunch holdouts I can tell are Slackware, RHEL, and RHEL clones. 
This is all interactive. Why would you need to expand everything into a whole list every time? `zip` and `map` work perfectly fine when passed into for loops, or (in most cases) when passed as arguments to functions that expect lists. I'll grant it's slightly more awkward when using them interactively, to print, but that's certainly not worth handicapping the whole language by forcing loop unrolling. `enumerate` didn't unroll when it was introduced to python 2, and no one complained about that. Besides, you should be using list or generator comprehensions instead of `map`- they're significantly easier to read in most cases, and you can be explicit about whether you want a list or iterator. As for the backwards compatibility- the number one thing is Unicode handling. Most languages, including python 2, treat strings as simple sequences of bytes. This works fine sometimes, but breaks down pretty quickly if you want to work outside of ASCII, as you have to do in an increasingly globalized world. Python 2's stopgap solution was to silently convert between byte-strings and unicode-strings, which led to bugs and other logic errors that are damn near impossible to track down. Because fixing this would have to be a backwards incompatible change, they decided to go all the way, fixing all the historical cruft that has built up all over the years. Some examples: - A much more streamlined library. Python 2 has 80 built-in functions, to Python 3's 68. This includes: - Much more consistency. All iterable wrappers (map, filter, enumerate) are iterators. - No need for different versions of things- No more xrange vs range, input vs raw_input - No more items()/iteritems()/viewitems() and friends - Unnecessary statements are now functions or expressions- print, exec, eval - No more old vs new style classes - Much more consistent import model There are numerous other benefits, though those are the primary compatibility breaking ones. 
I wrote a server in python3 asyncio, told our admin I need python 3.3 or 3.4 on the deployment server and that he doesn't need to hurry as there's time. he set up the VM and compiled Python 3.4 (even though he was sick that week)
The easiest way would be to perform a bounding box check between the ball and the boxes. A more physically correct solution starts to get math-heavy but there is a lot of information availaible on calculating ball to line collisions.
I'm about to make the switch... from 2.7.8 to whatever's current in Py3. It's good to know 'both' though. 
Never in a million years would I put this in my code. It's like deliberate obfuscation 
I worked in NLP (in python, no less)...here are some valuable resources. http://www.nltk.org/book_1ed/ - NLTK is a great collection of tools and the book they produce is good for getting a feel. http://scikit-learn.org/ - scikit-learn has a good amount of machine learning algorithms available with little setup or configuration. Requires scipy and numpy, but really, you should be using those already. http://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html - for when your word-word or document-word matrices won't fit in memory.
I'd be shocked if they dropped support for Python 2 any time soon (in the next 5 years). The last release of numpy that had support for Python 2.4 and 2.5 was 1.7.2 and was released on 2013-12-31. All numpy is going to do for the forseeable future is add a matmult to the array class that Python 2.6-3.4 can't use. If you're dropping support for Python 2.6 &amp; 2.7 based on that, you might as well drop support for Python 3.4. I run an open source library, and while I'd like to use matmult, I can't. It's sadly not meant for library developers.
Your code could just as easily be `[(i, f(i)) for i in x]`. Then you get the list you want, it's compatible with Python 2 *and* 3, it's much easier to read without all the nested `map` and `zip`, and it works no matter what kind of iterable x is.
Right twisted. That's what I said! :P
I didn't mean to suggest that it'd be a blocker, but rather, an example of python3 moving forward and innovating while python2 sits still. Eventually, the new features in python3 will accumulate to the point where writing the backwards compatible code will become cumbersome. As an example, even though numpy will be able to use the matmult operator, none of the code within numpy will be written to use it, since previous versions won't support it. It's going to gnaw at some people that they have to use the inelegant syntax for backwards compatibility when a more elegant syntax exists (zen of python and whatnot). So subtle pressure will be placed against backwards compatibility. It could be five years from now, but it'll happen eventually. And it's not like the old versions will go away. I mean, some people still use numeric.
Pydot is a strange example of something unported: the Python 3 compatible fork didn't even change much: https://github.com/nlhepler/pydot No reason not to have that on PyPI.
Maybe he/she realized that Numpy breaks compatibility in minor versions, so the only way to reliably repeat an analysis is pinning Numpy versions by installing Numpy in a virtualenv along your script and data. And since parallel Python versions are painless, nothing stops you from performing new analyses using a Python 3 stack.
Unfortunately, some people see those projects, don't notice the smell, maggots, and flies, and say &gt; this thing doesn't support Python 3, so Python 3 has literally no ported libraries
They are a few different ways to do it, as outlined here: http://tech.pro/tutorial/1007/collision-detection-with-pygame Checking if Rect objects overlap has been the simplest for me. Checking only the top and bottom boundaries of the Rect might need some more finesse. 
Pretty cool. I always enjoy seeing computer vision applied to real-world problems, like this one. 
&gt; It could be five years from now, but it'll happen eventually. I hope so. I don't like writing mixed code. Still, unicode is either hard. It feels like a game of whack a mole and people resist that. No one cares that modules moved, dict doesn't sort ints/strings, replacing range with xrange, integer division, or float division. Unicode is the only sticking point. &gt; I mean, some people still use numeric. I don't get why anyone would still write it that way. I update numeric code once every now and then. It's literally replace Numeric with numpy and change linear_algebra (I think) to numpy.linalg. 
What if I wanted to add support myself? :-) I'm not above getting my hands dirty if I have an idea of what im trying to accomplish.
He's got some todos in his README. Would be nice to have them converted to Github issues tho.
I hate to be that guy, but have you actually just maybe.. googled it? Because it's really simple, google is LOADED with good examples/explanations, and it would take you 15 seconds. If you don't understand it, then try and explain where you're stuck, but given that this isn't actually a python question...
Great! Can't wait to try it out :)
I'm no professional, but I feel like the author of this post just assumes that your Python code is gonna be badly structured and hack-y from the start. Just because you can write it like that doesn't mean you have to write it like that.
I feel like the Python community typically tries to be as gender-inclusive as possible, and this seems a bit inappropriate. Maybe this would be better in /r/funny?
Congrats. /r/learnpython or /r/learnprogramming are probably better for this kind of thing, though. Also don't forget to close files after you're done with them. If you do something like this: with open(filename, 'r') as f: # Do stuff with the file # This way the file will always be closed at the end of the with block, even if an exception occurs
It's not very funny, definitely belongs in /r/funny
Cool, sorry if this wasn't the ideal sub. I'll take your suggestion and put it into the code. Thanks for taking the time to respond. 
They're very friendly whenever I've contacted their dev team that supports the API, it's just still on 2.7.
Ok, so every concept that applies to gevent/eventlet also applies exactly to this library. All three (guv/gevent/eventlet) serve exactly the same purpose and have a good chunk of shared code (or at least interfaces). If the library is written in pure python and synchronous (like the vast majority of them are), then no modification is necessary, because calls to socket.send() or socket.recv() will automatically register interest in the file descriptor and yield until an I/O event occurs. For external libraries written in C, they use the operating system socket interface and therefore can't take advantage of the monkey-patching that guv does. In this case, your goal may be to find a way to register interest in the library's socket file descriptor manually, and call guv.hubs.trampoline.trampoline() with the appropriate arguments. trampoline() is meant to be called when you want to wait for an I/O event on a file descriptor, and yield control back to the "hub" (the event loop) which will let other greenlets run in the meantime. This is the fundamental way that guv works, and the core uses trampoline() extensively to work. For example, this is how eventlet adds support for psycopg2: https://github.com/eventlet/eventlet/blob/master/eventlet/support/psycopg2_patcher.py Note how simple it is (but also note that psycopg2 provides a facility for exactly this reason, so libraries like guv/gevent/eventlet can easily yield when waiting for I/O from the database). In fact, that psycopg2 module *should* be usable with guv with very little modification (maybe only fixing the imports). Additional info for psycopg2 regarding this: http://initd.org/psycopg/docs/advanced.html#asynchronous-notifications For things like pyodbc, I'm not sure of the facilities it provides to help in this situation. However, this might be a solution: https://github.com/gordonc/gevent-db Again, remember that anything designed for gevent/eventlet is very very very easily ported to guv since they all work *exactly* the same way (guv is just a bit more efficient than gevent, which is *much* more efficient than eventlet). Edit: This is how it's done with the Cassandra driver: https://github.com/datastax/python-driver/pull/46/files He created a new Connection class altogether. Trivial to port to guv.
Yup, I love Sphinx. I already set it up using a custom theme for my other library: http://amqpy.readthedocs.org/en/latest/ Sphinx is the best doc generator I've ever seen. Setting up the docs is definitely in the "high priority" list.
I'm on it.
Beautifully done! Thanks for the post.
Not helpful. The author is opening up asking for help, seeking examples. Try to provide some actual constructive criticism, based on the article, that is actionable. 
SnakeViz author here: Have you tried it recently? I released version 0.2 yesterday specifically with performance improvements for large profiles. No one has broken this release yet, and if your profile does break it could you please open an issue on GitHub?
SnakeViz author here: I just wanted to note that SnakeViz has just been rewritten with much better performance, so if you've tried it in the past you may want to give it another go. You can read about the new release at http://penandpants.com/2014/12/01/snakeviz-0-2/.
This is like the 10th different time he has posted **this exact link**. He spams it everywhere, it's not just an innocent "hey check this out"
There's also the subreddit /r/reviewmycode (or something similar, I'm on a phone so difficult to look up)
&gt; 8 to check your code against it. &gt; &gt; Write unit tests for your script (py.test, mock). &gt; &gt; Depending on your general programming level it migh Reddit is screwing with your formatting. Its: if __name__ == '__main__': main() Which prevents the code being run if this script is imported by another python script. 
Someone has made a "new" gevent like library for python 3 called guv. I cant get the link on my phone but it was on the r/python hot list yesterday and is probably on the first or second page still
Nitpicking if I may; you code should tell what you're doing, the doc string why you do it and how to use it. '#' style comments outside classes and functions as technical notes for the programmers i.e. #this function is I/O bound It's kind of a trick to help you think, why am I doing this? How should others use it? Are there kown issues others should know of? But in general it looks really good for a first script. 
He's Right most code has changed from 2.7 to 3. Look at a Print "statment" for instance ex. print "hello". 3 is a function for instance print("hello"). 
He's Right most code has changed from 2.7 to 3. Look at a Print "statment" for instance ex. print "hello". 3 is a function for instance print("hello"). 
True. But the way he wrote it made it sound like "in most cases, python 3 should be okay", and I'm not sure this is true. Sure, most big libs have been ported now, but I think projects could still run into issues if they rely on quite a few different libs. That's why I was stressing on the fact that one has to keep that in mind
http://codereview.stackexchange.com/
Python 2 CSV is plain broken. If you e.g. use a non-ASCII delimiter, it will tell you that it needs a one-character-string and dies (what it really means is a one byte long bytestring) In Python 3, it just works.
/u/kpurdon’s comment next to yours explains it pretty well.
Not a port, but serves the same purpose: http://www.reddit.com/r/Python/comments/2nzi2n/meet_guv_a_new_fast_networking_library_like/ 
Not yesterday, but a little more than a month ago. I'll give it another shot sometime recent. Most of my profiles involve IP from current employer though, so I don't think I could share them, but if it does break things maybe I can come up with something.
The main differences you have to wrap your brain around are: * Unicode by default. There is no more a weird “everything string” containing binary or text. Instead, APIs are more choosy in what they want. If that's text, they want the new default string type. If it's binary, you have to give them bytes. You'll have to maintain a clear boundary between both in your head, and as a result, you will never see any UnicodeDecodeError anymore * iterators everywhere. If you already use the 2.x iteritems, xrange and friends, you just have to return to same names. Else you'll have to understand that far fewer code generates lists, and more generates one pass iterators. Can bite you if you remove items while iterating something you think is a list. * better naming: no more thing.iter, xrange, iteritems, urllib2, .... * iterating a bytes object will yield ints representing single bytes * absolute imports and only explicitly relative ones. Inside your package foo, to import foo.bar, you need to do “import foo.bar” or “import .bar”, but not “import bar”
asyncio does not replace all the benefits of using gevent , other then being a stock library with similar functionality. not sure why people are pushing it in this subreddit.
Yeah. Also people should use bytearray if they want, well, mutable byte arrays.
Who cares what /use/bin/python points to? You should use the explicit version number for shebangs anyway, and if you want few key strokes, just alias py=ptipython3 (because prompt toolkit is the shizzle)
Thanks!
Thank you!
Thanks!
I like it, I'll spend some time this evening improving the documentation. Thanks so much. 
if you want to mask your password input you can use getpass instead of raw_input (or input under Python 3): import getpass raw_input('enter your user name: '), getpass.getpass(prompt='What is your password: '), and so on 
It's all good, welcome to Python! I like your first script. I think it's very well done. You are on your way to writing some excellent code! Keep at it!
Ntlk is pretty cool, but also has a pretty steep learning curve. 
For a prior attempt (never accepted) of bringing some consistency, see: * https://www.python.org/dev/peps/pep-0396/ You are also missing another common use case of version\_info. 
File IO is one of the worst things in Java. Trying to do that as well as get UTF encoding right is a royal pain.
what do you mean lambdas and full suites?
You listed the standard way... &gt;&gt;&gt; import requests &gt;&gt;&gt; requests.__version__ '2.4.1' __ version __ as a string Put it in the __ init__ .py file at the root level. Then in your setup script, you can import that, so you can list it in one place
So the problem with manually implementing a linguistic construct is that you don't get to take advantage of back end performance improvements. You are just working extra hard to make language A look like language B. I get the feeling that the canonical way of doing a switch in python is to just use an `if` `elif` chain. If you need to reuse the statement many times maybe use a dictionary of functions. Anyways. I didn't really come to post about python. I was wondering if you were familiar with the Go language? The `select` statement is like a wonderful drug; once you try it, you'll always miss it in other languages. Read up on channels is in go, once you understand them, the select is a real eye opener. 
I keep trying to like Go. Its lack of generics just feels like a HUGE handicap. I can't wrap anything properly or make any decent utilities. I'll try to make something that wraps a goroutine or a channel and it's just impossible without knowing all the types beforehand (hello code repetition) or using interface{}.
I agree partially. Although frequently when I'm trying to do something where a generic would work, an interface provides a similar capacity. Obviously working with built-in types, this isn't true. Currently the authors have committed to making no backwards incompatible changes to 1.x versions of the language and all proposed generic implementations would be backwards incompatible. I assume that golang 2.0 will handle generics, overloading, and operator overloading. Until then, it's still quite functional albeit with a tad more overhead.
So question for you, Why not use properties for the whole '_health' issue? This would safeguard the writer/someone else from coming in and doing a dot operator access 'hero.health ...' As the modifier logic lies in the property, effectively modifying any access to the health variable. Just curious :) 
Quite a daunting task having to move straight to coding with COM before I've really become familiar with Python (I have some faith I can work it out since I am familiar with MATLAB). Do you have any suggestions on resources to read relating Python and COM? Out of interest, what software are you working with while using COM? If you have any open source code, I'd like to have a look :)
This is not standard but +1 Then read the init file and do a regex in your setup.py. Never ever import the package in the setup.py of the package!
I think I would argue to learn Java first if you want to learn both. After you've learnt Python, you'll never want to deal with Java again.
&gt; opencv on python 3.4 Yes that is true but they reported some problems with several algorithms. Glad to hear it works because I switched then was disappointed that it did not work 
Stackoverfolow - [matplotlib diagrams with 2 y-axis](http://stackoverflow.com/questions/15082682/matplotlib-diagrams-with-2-y-axis)
Thanks. How about the sum of each interval/weeks that make up the second line? I can get the sums but not sure how to plot it.
I'm not sure what you are trying to do. Can you give me mockup data and tell me what you are trying to do? 
Py 2.5.4 is too old. You can watch the video and using Python 2.x/3.x. 2.x and 3.x is similar except third-party libraries.
Take the first advice of splitting the y-axis yourself manually. No need to get pandas to black box fix your problems.
Put the version number in your setup.py then in each of your included packages pull it out using pkg_resources
Nice case study! Better than many of your previous articles which seem like copying opencv examples and presenting them as revolutionary.
Everything they teach in that course will still work in python 2.7. Most of what they teach is still valid for python 3, though there are some gotchas. You shouldn't use 2.5 yourself, but you can still take the course with 2.7 and it should be fine. Also, /r/learnpython.
Because importing the package may require dependencies that are not installed at the time of the import (eg scipy requiring numpy at setup). By using a regex, or any other text parsing method, you avoid this problem. 
That's a very good example. Fits the target group.
I've been using Supybot for years, which has a pretty good ecosystem of third-party plugins (a few of them written by me). That said, it wouldn't take much to convince me there's a better Python IRC bot than Supybot. The project is stale (and forked a couple times) and documentation is incredibly poor. Anyone have experiences with both Supybot and Errbot and want to share?
Importing is a bad idea (dependency issues =&gt; package becomes uninstallable). You can store it in both files, and use some tools like https://pypi.python.org/pypi/bumpversion to manage the version.
Incredibly useful, explained with examples that interested me also and that always makes the learning process easier, thanks!
But that is not really running it as the default is it? That just means that modules/software/plug-ins capable of running python3 will do so, but the default will still be python2.
Save (on mobile)
&gt; pyglet Nice, I'll take a look.
There is also willie, which looks interesting. And I'd like an experience share/comparison too, in order to make a choice.
Err looks wonderful. I've used Willie before, and written some things for it, and this looks super interesting. Really digging the seeming simplicity of the extension system. 
I didn't know I needed Python 2 until half way through a project I found a good library that would do what I wanted. However it only worked on Python 2. It's not that hard to convert, but it's still a pain. So I'm going to stick with Python 2, since everything supports it.
ELI5: Why do people run chatbots?
The differences, even between 2.5 and 3.x, aren't big enough to worry about, you can trivially pick those up as you go later. If that course uses 2.5.4, go with it.
Your charsets are weak.
See: https://slack.com/ 
Substituting characters for similar-but-slightly-different characters is definitely cheating. (and generally doesn't work anyway)
FYI, if you get gevent from the repository, it compiles and runs on Python 3.4. Some little things are missing (can't monkey.patch_all() yet) but overall it's functional. In fact, it even seems there's a PyPy backend that was merged too.
Whoop! Didn't realize you were the author! I feel like an asshole now. To be clear! I'm definitely not saying your a sleeze-ball! On the contrary, I'd say I'm a 'fan' of sorts. Like I said in my original comment, your content is really solid, man. The book was well worth its price. As for the infomercial-esque-ness, well.. to be honest, I couldn't tell you what it is. Just something about the tone in some of the articles/emails, I guess. Any plans to release an extended version that digs into some of the theory behind the algorithms? (cause I would snatch that up instantly!) 
All right I recognize that I was wrong, but it is going to take some time to the Python community to change, specially business and doesn't like changes very often. Despite some trouble, Python 3 is thousand times better and less verbose than Java. I would really complain if had to program in java like I had during the college degree. One thing that I liked in Py3 is that 1/100 is no more 0, now is 0.001. One less bug.
No need to feel like an asshole! If I came off as scammy, then your comment is well deserved! I'll definitely go back through the site and emails and look for the infomercial-type tone -- like I said, it's not my intention to come off that way. And thank you for the compliment, I'm glad that you think the content is solid. In the future I'm definitely going to do more advanced techniques, including some theory. I have a lot of content planned for building custom object detectors, building large scale search systems, color calibration, etc.
I have no familiarity with Supybot (in fact, I hadn't even heard of it up until now) but I'm one of the maintainers of Err. I'll be the first to say, there's some ugly, taped together parts under the hood if you dive into the actual core code of it (then again, which software doesn't? :)), but as an end user you shouldn't notice this at all. I think the biggest strength of Err are the following: 1. Our focus on being very modular and pluggable. This makes it very easy to extend and adapt to your use without needing to touch any of Err's code itself. By utilizing git repositories as the primary means of installing plugins, we also make it simple to install, update and share plugins. 2. Our focus on being network-agnostic. We support XMPP, IRC and Campire, and include a dedicated back-end for HipChat (which is mostly XMPP) to support some of HipChat's custom features. The development on GitHub in the master branch also brings support for tox.im (a new release is coming soon). In addition to that, I personally also do my best to keep the plugin documentation up to date and of good quality. It needs a little more work still, and I should really overhaul the documentation on the setup of Err, but it's getting there. Compared to Willie, Err likely lags behind in terms of IRC support, though it's catching up. In the last month or so, support for managing rooms (channels in IRC) has landed in the master branch, and I am working on increasing the coverage of IRC commands further still. It should also be noted that, whatever Err doesn't provide abstractions of, you can still very easily get access to the underlying libraries (irclib in case of IRC) to interface with their API's directly. 
Is the course a computer science course or a programming course? There is a difference. 
This is really, really good.
I've tried, and being able to barely run on python 3 after years of development is hard for me to trust my production codebase on, since my company and clients depend on things not failing. If you try to run the wsgi server, it errors out in various situations. In addition, there are multiple blatant bugs in the code that seem very obvious to me but the development pace on that project turned me off from bothering to report bugs and submit pull requests. It's much easier making my own library since every single line of code has been written from scratch or ported and rewritten to run on python 3 only. I can also comfortably say that since my clients depend on this, it will aim to always be as stable as possible and as bug free as possible at all times. It's also licensed under the LGPL since I'm a huge GNU/Stallman fan and no one has anything to lose by contributing. I think having a company contribute to a codebase that is licensed under the GPL and truly open source is the best way to make sure that the code is actively maintained and of high quality.
Depends on how exact your requirement of "been there for longer than 15 minutes" is, and whether you are just comparing file names or want to monitor the actual files. Every 15 minutes I would generate a list of all files in the relevant directories, and then compare it to the previous list. This solution would require approximately 5 lines of code. http://stackoverflow.com/questions/3207219/how-to-list-all-files-of-a-directory-in-python The disadvantages of the aforementioned solution is that it could take up to 30 minutes to recognize a file if it is added right after the sweep, and that it only looks at the filename. Something more intelligent possible but you start having to do a lot more work. http://stackoverflow.com/questions/597903/monitoring-files-directories-with-python
I used os.path to check a file and compared the modified time to the system time. I just split the time output and used it to check for the correct day in the date of the date modified field using os.path.getmtime(). I have not used os.walk so I cannot comment on it but this might get you some what started on the right path. Hope it helps.
&gt; Importing is a bad idea (dependency issues =&gt; package becomes uninstallable). It depends on what you put in your init. I put package level variables at the highest level (e.g. is the package an exe or not, which is set dynamically). I don't put imports in the init that aren't part of the standard library. I think that is bad practice. Also, that version bumping tool seems like you're overcomplicating the problem.
Thanks!
Thank you!
That's what they all say, but briefly forget before making a broken release. Happens to the best :-) Not being able to import anything useful from the top level package usually makes very ugly api. Especially for something small in scope that doesn't do 10 disparate things.
Also, see https://packaging.python.org/en/latest/development.html#single-sourcing-the-version
One of the original creator of Err here, just to mention a recent addition to the err backends I am really excited about: Tox. As Tox is a serverless (P2P) chat, it makes it attractive for privacy conscious people and it is super resilient to outages (no central services). See r/projecttox/ One of the use case I am thinking about is the sysadmin/SREs hooking plugins to monitor their infrastructure, Tox is a good choice for a resilient "war room" and Err can be run from anywhere if the outage affects it.
I've used Err off an on for different projects over the years. For a good while, it was going through this Python 3 transitional stage and was very difficult to install. But it seems better now. In fact, you can install it in Docker now. I've even contributed some (very small) changes back. Mainly I've used it in work environments where we had centralized chat. These days this would be called ChatOps. It would poll systems like nagios and pop alerts into the channel. A command like `!status host.example.com` would grab the current status in nagios. `!lookup (servername|id|ip|other)` would reach into our hostdb to lookup a device by it's name, internal id, ip address, or freetext. A small list could be returned, a link to the hostdb search page, or if it had narrowed it down to a specific host, we'd get a brief summary of that device (hostname, ip address, internal ip, tags, os, location, etc). For home use, I had it running on my desktop before and it could check my email. I could put in filters to notify on email from certain people or with certain subject. I didn't use this very much because for everything I could use it for, I had another app on my phone that produced the same notifications.
To pretend to be a female and make $ from stupid men by pushing them to signup to a dating or webcam site.
first time doing something like this. I'm not a very experienced python programmer. Any constructive criticism is appreciated.
tried it, not here. lots of people hung up on nit picky style stuff rather then giving feedback on the code functionality and use itself.
You can just use that print_old_files function and iterate over the folder names. Maybe something like: if __name__ == '__main__': folders = [ 'path/to/folder', 'path/to/other/folder', 'and/yet/another', ] for folder in folders: print_old_files(folder)
Have a look at [Stevedore](http://stevedore.readthedocs.org/en/latest/index.html).
Thanks for the link. The chatbot I described above are the ones I'm most familiar with from making them myself. Only IRC chatbots I've interacted with are Trivia ones or warez ones back in the day.
I presume you're taking about the class that contains the entry point to the program. Calling that a "driver class" is far from common even in Java: most people will call it the main class or something similar. In Python, though, there is no automatic entry point, and there is very rarely any reason to put the main code in a class. Remember that functions can live outside classes, on their own at module level, and that is usually the best thing to do: classes are really only useful for when you want to encapsulate state.
Wow, the comments on the article (not these) are actually super-pedantic. About the only interesting point made in the comments is composition vs inheritance, but, seriously, it's a intro-to discussion. Maybe something to explore in a follow up blog post? Thanks for it anyway, /u/AlSweigart, it wasn't news to me but I definitely think you did a good job introducing the concepts. I'll pass it along to the Python-programming newbies I know.
Well yes, Google tracks your past searches and tries to show you the results that you are most likely looking for.
PyCharm puts the .idea directory in the "project" directory. In my case, it would be the main directory of an open source Python project that's already under version control. So, without editing the .gitignore file (which I'm reluctant to do as it's orthogonal to the overall Python project), the .idea directory shows up in git status.
I don't think so. I opened a Chrome incognito window so I wasn't logged into Google, searched "pandas" and still got the Python library result first. Unless they are tracking and suggesting by IP too.
Ooooh. This is actually really cool. It's not really much to do about Google Trends besides how hard it can be to circumvent Google's nonsense, but I never considered using Wiki trends. Wiki trends wont be as useful in some aspects, as Google Trends can be helpeful for a much wider range of things... but wiki trends is great for things like interests or general topics. Thanks for sharing this! Wikipedia has always had some API resources and has left their databases pretty open for program access. Been a while since I did a massive download from them, but I recall it being rather simple and not requiring any funny business. 
There is no battle. People have to maintain legacy code bases or use forgotten libraries no one else cares about. That are the only valid reasons for 2.x-only development and that reason will not go away any time soon. If you write new applications, use Python 3 only. If you write new libraries, try to support both but default to 3.2+ because that is available everywhere. It's that simple. People that choose Python 2 for their projects with no valid reason just because they don't like Python 3 are lazy (the bad kind). People that brag about it are hipsters. People that write 2.x only libraries just don't want their libraries to be used. Leave them behind. There is no war, or battle. Just progress. Nice and slow and steady progress. Progress needs time. And I am very happy that the Python development takes its time where it is important. Think about it. We currently have two very stable and usable branches of a great language, and an almost flawless history of backward compatibility on both branches (3.0 does not count). We support legacy code a LOT longer and better than other languages or frameworks. You can always just upgrade your Python (or operating system) and everything keeps running. You get new features for free. Try that with Ruby. You can almost throw away your big RoR application after a year because porting would be a nightmare (correct me if I'm wrong). It's progress. No one gets stabbed or shot. We are nice people and there is no deep and frightening split in the community (hey Perl guys) or anything like that. Stop overdramatizeing, start porting. Just go on and enjoy. **tl;dr** I don't like the word `battle` in this context. Sorry for the (kinda off topic) rant. Your link is fine. Here, have an upvote :)
I keep getting this error when I'm trying to download the Wikipedia Pagecount data. Any ideas? ConnectionFailure: [Errno 61] Connection refused 
I was just referring to the other link on the front page that had a bunch of people, myself included, "discussing" 2 vs 3. I figured for those using 2, that this would be a good link to have. edit: link to other thread for those wondering http://www.reddit.com/r/Python/comments/2o0str/python_272_or_python_3/
Assuming you've already downloaded mongodb, you have to actually start mongodb. Prior to using pymongo, type this into commandline: $mongod and if that still doesn't work, you probably have to go and delete your mongodb.lock file, then enter mongod again. 
Heheh, programming is a religion. I wrote a blog post that HTML is not a programming language and you shouldn't call it that, and got more than one, "Actually, it is a declarative programming language..." and "Actually, with CSS3 it is Turing complete..." They're as bad as people who use tabs instead of spaces. HERETICS. HERETICS, I SAY.
until twisted is fully ported i am unable to even think about python 3 http://twistedmatrix.com/trac/wiki/Plan/Python3
&gt; Not being able to import anything useful from the top level package usually makes very ugly api. It's a tradeoff. It certainly makes it more clear. At the top of my code, I always write something like... from numpy import array, searchsorted, argsort, ndarray from numpy.linalg import norm if it was instead... from numpy.array import array, searchsorted, argsort, ndarray from numpy.linalg import norm I don't think that makes the API any worse. It's 6 more characters (in this case). Also, I'd argue that's not even worse. There are people that import like this... import numpy as np They're adding 3+ extra characters to each call (they might use np.linalg.norm). It's just a preference. &gt; Especially for something small in scope that doesn't do 10 disparate things. I don't work on things small in scope :)
&gt; ust upgrade your Python (or operating system) and everything keeps running. You get new features for free. Try that with Ruby. You can almost throw away your big RoR application after a year because porting would be a nightmare (correct me if I'm wrong). &gt; &gt; It's progress. No one gets stabbed or shot. We are nice people and there is no deep and frightening split in the community (hey Perl guys) or anything like that. Stop overdramatizeing, start porti I suspect that the biggest problem right now is that a lot of online tutorials are python 2, the sidebar of this subreddit doesn't help as it makes it seem like Learn Python the Hard Way is the way to go. 
I'm surprised that it is that out of date, but it's basically fine. I still mostly use Python 2.5.4 and for development work. I am occasionally frustrated by stuff that was added only after that, but not too badly.
Are you on Windows?
Hot damn this is awesome
Nice candlejack avatar! Anyway, the module looks good, but you should probab
&gt; They're as bad as people who use **tabs instead of spaces**. HERETICS. HERETICS, I SAY. I... uhhh... *cowers*
https://github.com/vinta/awesome-python#authentication
Ugliness? pkg_resources is the standard way of getting pip package versions in python
&gt; People that choose Python 2 for their projects with no valid reason just because they don't like Python 3 are lazy (the bad kind). I create new Django apps in 2.7, but that's mostly because I've been too lazy to figure out Python 3 and virtual-env3 on CentOS yet.
Thanks for this!
Look at the Python source in [./Lib/test/test_socket.py](https://github.com/python-git/python/blob/master/Lib/test/test_socket.py). You'll find a full suite of unit tests for the socket module in there.
[Flask-SocketIO has unit tests](https://github.com/miguelgrinberg/Flask-SocketIO/blob/master/test_socketio.py). Seems like a good place to start ;). You may need to mock up parts of the service, so that you can isolate the piece of code you want to test.
Looks like you should be using [this](https://docs.python.org/2/library/httplib.html#httplib.HTTPSConnection) Oh, also, it looks like you should not include the scheme (http/https) in the url string. The problem is that httplib is looking for a colon and then if it sees one, tries to parse what comes after the colon as the port. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Spyder (software)**](https://en.wikipedia.org/wiki/Spyder%20%28software%29): [](#sfw) --- &gt; &gt;__Spyder__ (formerly __Pydee__) is an [open source](https://en.wikipedia.org/wiki/Open-source_software) cross-platform [IDE](https://en.wikipedia.org/wiki/Integrated_development_environment) for scientific programming in the [Python language](https://en.wikipedia.org/wiki/Python_(programming_language\)). Spyder integrates [NumPy](https://en.wikipedia.org/wiki/NumPy), [SciPy](https://en.wikipedia.org/wiki/SciPy), [Matplotlib](https://en.wikipedia.org/wiki/Matplotlib) and [IPython](https://en.wikipedia.org/wiki/IPython), as well as other open source software. &gt;In comparison with other IDEs for scientific development Spyder has a unique set of features - cross-platform, open-source, written in Python and available under non-copyleft license. [*[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed)*] [*[dubious](https://en.wikipedia.org/wiki/Wikipedia:Disputed_statement) – discuss*] Spyder is extensible with plugins, includes support for interactive tools for data inspection and embeds Python-specific code quality assurance and introspection instruments, such as Pyflakes, [Pylint](https://en.wikipedia.org/wiki/Pylint) and Rope. It is available cross-platform through [Anaconda](http://continuum.io/downloads), on Windows with WinPython and [Python(x,y)](http://code.google.com/p/pythonxy/), on Mac OS through MacPorts, and on major Linux distributions such as [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_(operating_system\)), [Debian](https://en.wikipedia.org/wiki/Debian), [Fedora](https://en.wikipedia.org/wiki/Fedora_(operating_system\)), [OpenSuse](https://en.wikipedia.org/wiki/OpenSuse), [Gentoo](https://en.wikipedia.org/wiki/Gentoo_Linux) or [ArchLinux](https://en.wikipedia.org/wiki/ArchLinux). &gt;It uses [Qt](https://en.wikipedia.org/wiki/Qt_(framework\)) either directly or through [PyQt](https://en.wikipedia.org/wiki/PyQt) or [PySide](https://en.wikipedia.org/wiki/PySide). &gt;==== &gt;[**Image**](https://i.imgur.com/tptky1I.png) [^(i)](https://commons.wikimedia.org/wiki/File:Spyder-windows-screenshot.png) --- ^Interesting: [^Django ^\(web ^framework)](https://en.wikipedia.org/wiki/Django_\(web_framework\)) ^| [^Arachne ^\(web ^browser)](https://en.wikipedia.org/wiki/Arachne_\(web_browser\)) ^| [^Subsurface ^\(software)](https://en.wikipedia.org/wiki/Subsurface_\(software\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmkewe3) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmkewe3)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Yeah I agree.
Yes, it supports them. Maybe you're using WinPython and have not registered? If that's the case, I think you need to use the WinPython package manager. You can also use pip to install Spyder with this command: `pip install spyder`
Well, it would give you a far better, educational, testing environment closer to reality! 
Awesome thanks! 
this argument come up all the time. looking at your post history your very pro 3.x and asyncio which is good but it really depends on the person is doing and how much they care about performance asyncio is not a drop in replacement for a proper reactor, threadpool or deferred chains. Also the other libraries i've tested for network level service just suffered in comparison to twisted. (read multicast 40 GB/sec services). twisted.web when implemented properly out performed flask 1000x1 in heavy load requests. (5 million rpc tx test) This tested was also duplicated with a single twisted.web instance and 5 flask instance behing nginx server using WSGI settings. Im not going to say there isnt a learning curve to twisted but it follows every other factory/protocol pattern that other languages, pythonic vs not pythonic is not really an argument here. 
I've been using Spyder exclusively for a couple of years now for all my Python needs. I think it's a fantastic IDE and wanted to say thank you for your development efforts. 
Neat! I can see myself using it if you make it smarter. I liked the results for `def`, but it went downhill from there. I've tried `list`, `import`, `import from` and the relevancy of most of the snippets wasn't immediately apparent. I assume the snippets are automatically sourced... Maybe a more manual approach would make more sense. Also, what are you trying to solve here? I guess making a searchable python cheatsheet? In this case it needs more one-liner examples and less #comments. Once again, I like the idea of searchable syntax-demonstrating snippets, just wishing for better relevance of search results.
I use Spyder a lot. Thanks for your hard work. Do you think it will ever be possible to open an IPython notebook in Spyder, where it opens a server in another console window, then a browser where the text editor widget is?
I'm sure if you went far enough back one of your predecessors complained that assembly was good enough for him.
I think the OP refers to the entry point, and not the kind of driver that this library handles.
Well in the end its all to personal taste, but why would adding .idea to .gitignore yield any discussion? Even github has .idea in their default .gitignore. Or better what's the difference to adding *~ to get rid of the emacs traces? Also I wouldn't drop an IDE just because git shows up some untracked files. And thats only in the shell. Pycharm wouldn't even nag you about it once you've dismissed them. Whatsoever. If this is all no good --global core.excludesfile could come to your help to set a user specific ignore without the need to change the projects .gitignore. And don't get me wrong. I'm totally fine with not using pycharm - there are problems with every tool. I just don't see this to be more than a little configuration.
In the making, at least the "open notebooks" part: https://bitbucket.org/spyder-ide/spyderlib/pull-request/77/ipython-notebook-plugin There is still a lot of work to do to make this work as well as our IPython consoles though ;-) But it'll be there in 2.4.
Thanks for your kind words!
Thanks for the link Wes. I also put a project mini-description at the end of the announcement :-)
I like this!
This is called confirmation bias.
I've been using spyder for all my Python work in the past years and I ABSOLUTELY LOVE it! Tried many IDEs and always came back! Thank you so much for your hard work guys! 
I would guess that new python programmers would be quick converts since they very little inertia. I think for them, the changes will be extremely superficial and they wont yet have large codebases to regression test or deep library knowledge to convert. Maybe there are enough new python developers that their mass adds up faster than the individually heavy experienced developer. Are you recommending that "Dive into Python" be listed above "Learn Python the Hard Way"? If they're comparable books, I see no reason why the mods wouldn't do that.
Best comment ever. Thanks man. 
just started using spyder in linux and windows with winpython....so awesome!
Yes
I'm not worried about discussion, it's just that I don't want to make any user specific changes in a public repository.
I'll use python 3 when its debian's default version. Until then, can't be assed.
I've heard it called something like "looping constructs" but that's not pulling up anything useful.
/r/learnpython in the future please. I'd do this def these(x): return [mydict['thing%s' % n] for n in range(x)] Are you sure you don't want to use a list and get a slice of it? mylist[:x] This would do what you want if you don't need a dictionary, ie, if thing1 is mylist[0]
I don't think you're going to find a "pattern" for this; but 50 lines sounds like a lot; perhaps a list comprehension might help. Assuming you have already set up a dictionary your_dict, you could extract the object via: MASK_BITS = [1,2,4,8,16,32,64,128] def num_to_objects(n): if 0 &lt;= n &lt; 256: return [your_dict[m] for m in MASK_BITS if n &amp; m] else: return [] # or whatever error condition suits you HTH! 
Yeah! Virtual tables are totally cool. I remember seeing that FB post but I had no idea it was built using SQLite / virtual tables. Thanks for sharing.
I was thinking "but then if you search enumerate in this..." but it turns up a lot of examples that include the string num, so not very useful. I expected to find some enumerate specific tricks.
Huh, thanks for pointing out pathlib! I'm not switching to Py3 yet, but surely I'm going to use the backport from now on!
&gt; People that choose Python 2 for their projects with no valid reason just because they don't like Python 3 are lazy (the bad kind). People that brag about it are hipsters. There are legitimate reasons for using python 2, even for new projects, and some people have no choice because of either 1) legacy code, or 2) company policy (like say, Dropbox, where Guido works). This is the same pitch the python3 crowd has been pulling for 6 years, and it was then, and remains now totally unnecessary to be this hostile. I otherwise agree with you completely; I'm just saying; the 'too cool bro' python2 crowd ('but I don't *wanna* use python3, because Reasons') may suck... but so does the 'holier than thou' python3 crowd ('You're lazy and dumb if you aren't already using python3'). 
&gt; If the trailing colon is present, the last parenthesised group is interpreted as an argument list Python parser would have to stop being LL(1) to support this.
This is called a [geometric series]( http://en.m.wikipedia.org/wiki/Geometric_series)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Geometric series**](https://en.wikipedia.org/wiki/Geometric%20series): [](#sfw) --- &gt; &gt;In [mathematics](https://en.wikipedia.org/wiki/Mathematics), a __geometric series__ is a [series](https://en.wikipedia.org/wiki/Series_(mathematics\)) with a constant ratio between successive [terms](https://en.wikipedia.org/wiki/Term_(mathematics\)). For example, [the series](https://en.wikipedia.org/wiki/1/2_%2B_1/4_%2B_1/8_%2B_1/16_%2B_%C2%B7_%C2%B7_%C2%B7) &gt;&gt; &gt;is geometric, because each successive term can be obtained by multiplying the previous term by 1/2. &gt;Geometric series are one of the simplest examples of [infinite series](https://en.wikipedia.org/wiki/Infinite_series) with finite sums, although not all of them have this property. Historically, geometric series played an important role in the early development of [calculus](https://en.wikipedia.org/wiki/Calculus), and they continue to be central in the study of [convergence](https://en.wikipedia.org/wiki/Convergent_series) of series. Geometric series are used throughout mathematics, and they have important applications in [physics](https://en.wikipedia.org/wiki/Physics), [engineering](https://en.wikipedia.org/wiki/Engineering), [biology](https://en.wikipedia.org/wiki/Biology), [economics](https://en.wikipedia.org/wiki/Economics), [computer science](https://en.wikipedia.org/wiki/Computer_science), [queueing theory](https://en.wikipedia.org/wiki/Queueing_theory), and [finance](https://en.wikipedia.org/wiki/Finance). &gt;==== &gt;[**Image**](https://i.imgur.com/i5SvmBb.png) [^(i)](https://commons.wikimedia.org/wiki/File:GeometricSquares.svg) - *Each of the purple squares has 1/4 of the area of the next larger square \(1/2×1/2 = 1/4, 1/4×1/4 = 1/16, etc.\). The sum of the areas of the purple squares is one third of the area of the large square.* --- ^Interesting: [^Divergent ^geometric ^series](https://en.wikipedia.org/wiki/Divergent_geometric_series) ^| [^Geometric ^progression](https://en.wikipedia.org/wiki/Geometric_progression) ^| [^1/2 ^+ ^1/4 ^+ ^1/8 ^+ ^1/16 ^+ ^⋯](https://en.wikipedia.org/wiki/1/2_%2B_1/4_%2B_1/8_%2B_1/16_%2B_%E2%8B%AF) ^| [^Grandi's ^series](https://en.wikipedia.org/wiki/Grandi%27s_series) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmkmam8) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmkmam8)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'm fairly certain that /u/defnull would count both of the reasons you listed as valid reasons to use Python 2. (In fact he explicitly mentions legacy code elsewhere in his post.) Those are both much betters reasons to use Python 2 than "I just don't want to use Python 3."
You're **really** optimistic in thinking Python 3 is "available everywhere". A major example: no Red Hat Enterprise Linux (not even 7) has it available even as an optional package without resorting to using the seldom-updated Software Collections.
What are you actually trying to do? Understand it?
The answer really has nothing to do with programming. Rather you must realize that adults move forward and don't dwell on the past. For those that are dense, yes I'm saying that those still using Python 2.x are childish. 
Your tutorials are always excellent. Thank you for continuing to share your knowledge with us. 
I just happened to be starting a small project of using mpi4py with hdf5, so this is great. Thank you!
This is awesome. Edit: what about a slow geared motor to rotate the platform while taking a video? That would save you some money on driving a stepper motor, and 30 frames a second would give more points for noise filtering. Also, would you be willing to share the code? 
As much as I like awesome-python, it recommends python-oauth2. I think I'll submit a pull request. In any case, I tend to go with https://github.com/idan/oauthlib.
Does this have tools for managing file concurrency? 
So you just print out 5 dots a second in a separate thread? I'm having a hard time thinking of a scenario in which this would be useful.
My point is that name calling has historically, and continues tangibly, to achieve nothing.
Wanting to avoid mindless name-calling is definitely valid, but while /u/defnull probably wandered into name-calling territory, he didn't just do so mindlessly. He clearly stated what he was calling out and his overall argument is pretty easily defensible.
You'll definitely have more successes early with python given that things like running it straight from the shell and having to write less code for certain things. If you decide on Java though going to python will be much smoother.
espescially for rasperrypis? so it's mpi4py4pi ? (jk)
Oh ho, so name calling is just fine if it's considered and backed up by an argument is it? You're ok with *categorically* accepting that people who write new python 2 code are doing it because they're lazy? Or are just the people that don't like python 3 lazy, but the ones who like it but can't because (insert valid reason here) aren't lazy? Or perhaps just all people who write python 2 are lazy? ...or perhaps, it's not a matter of 'being lazy' or not. How about: Some people have reasons to continue write new code in python 2, but there probably aren't many legitimate technical reasons to do so. There! done. That wasn't so hard. I'm not trying to call up the OP specifically, but there is definitely a subset of people who actively (here, on /r/python) sneer at and denigrate people using python 2. We don't need that, not from anyone, for any reason. 
thank you very much for the terminology. 
thanks on the learn python sub. didn't know it existed. i'm updating the OP with an edit explaining what i've learned after gathering what you guys have shown me.
Aren't you maybe.. taking it too seriously? It's just a joke. Also you're kinda preaching to the choir since this is /r/Python after all.
your input was ultimately how i found the solution. I was explaining to my dog how your code here worked, piece by piece. until i came across the part about n &amp; m which made no sense to me at all, because i mistook it for n &amp;&amp; m. once i googled it and understood the concept of "bitwise and" it reminded me of a way that i had used to store tile data in a tilemap previously, for that i had used hex numbers to store terrain (grass, sand, water, etc) but it "clicked" and it occurred to me to pack this data into a binary "list" of sorts. the piece missing then, was how do i get an ever increasing set of binary numbers, exponents made sense, except when i wanted 0000001. it took me some time to learn that n**0 is 1. must have been sleeping in math class that day. anyway.. Thank you very much for the breadcrumbs. 
But it is good calculator... 
I think you're taking a little joke too seriously. 
I was pretty excited when I saw the title, wondering to myself how you acquired Devine knowledge of what my function was doing with no introspection. I thought "how easy is this? I'm putting this on everything!". Then I looked at the code and came back down to earth. I can however see a use for this, as a utility to indicate progress on a task is being made (which fwiw could be completely wrong if the function is permanently stuck in a loop). 5Hz however, for something that is obviously intended to last a while seems like overkill. Perhaps a dot every second or every 5 seconds would be a better indication of such progress. 
Agree with pretty much everything you said, though there's one use case you didn't mention at all: Python is also a great desk calculator. 
i can imagine another great way to solve this with that function. thats pretty cool. 
The progress bar decorator could be notified of progress via the yield keyword.
I actually *often* use it as a desk calculator.
Just because python is a powerful, expressive language doesnt mean that people don't just fire up an interpreter now and then to quickly get the square root of something and the like. It is a legitimate use case. &gt; Java, there is nothing stopping it from getting performance enhancements in future (perhaps version 3.3 and later). The current release of python is 3.4. Also, I would argue that while python is slower than the other languages you mentioned, and likely always will be, it isn't _inherently_ slower. Just much more difficult to make it faster.
Typical use: I want some expression of x for many different values of x, so I just type python -c "print [x**2+3*x for x in [1000,200,55,457]]" It's a great desk calculator. And now I always have at least one IPython notebook open in my browser, so it's also a good in-browser calculator.
&gt; a utility to indicate progress on a task is being made Well... this just spins up a thread that prints period characters. Your actual thread could be stuck and this would still happily go forwards. The only thing this demonstrates is that the GIL isn't permanently locked in an infinite loop, which I guess is useful in some circumstances.
Two words: "surrogate escapes"
I use xlrd and xlwt. Simple API and easy to use. I've heard good things about xlwings, but I've not used it yet. 
&gt;use forgotten libraries no one else cares about. What?! lol, there is a bunch of libraries with hundreds of thousands and even few million downloads that don't support python 3. Your statement is incredibly wrong. I know this subreddit is very pro python 3 and wants it to progress, but don't lie. &gt;3.2+ because that is available everywhere. ... See my previous sentence.
Yeah but.. Progress bars make people feel less anxious! Think of the users. 
I use openpyxl for most of my work. Usually I just work in tab-delimited text files and just use a quick conversion script to save them as Excel files (or to open the file and convert to tabbed format). I think I settled on this one to use because of the xlsx (newer Excel format) support.
If you find a novelty useful, then it is. I wrote it specifically for a whois call one of my scripts makes, which takes anywhere between 1/2 - 10 seconds to finish. Instead of a static "contacting whois" print, I now have some progress dots, which I think for cli is a step up. I would also put this in user facing scripts like /u/nightlily said to make users less anxious. YMMV 
 fantastic IDE and wanted to say thank you for your development efforts
Thank you for posting with what you learned and how, that's a valuable contribution that not many bother to post.
This is a really big thing. I've been very vaguely looking at writing my own Python tutorial, and I thought I ought to check out the competition. Even after I googled for Py3 tutorials, excepting upgrading materials there was only really the one book that started out with Python 3. The biggest tutorials - and the tutorials everyone remembers and points to to from when they began learning - are largely still in Py2 mode.
Exactly. @pydanny here you go https://github.com/vinta/awesome-python/pull/274
Those results are pretty great! Was it a lot of work to transform the point clouds into a mesh with MeshLab? Some classmates and I just wrapped up a relevant class project in Python with OpenCV/Numpy for my computer vision class. Our initial plan was to create a reasonably decent point cloud of an object from stereo video taken with a Nintendo 3DS. Turns out the quality of the cameras on the 3DS is crap, so we just used some webcams lying around. We got as far as generating quality [point clouds](http://cl.ly/image/2k410X3C1f09/Image%202014-12-04%20at%205.03.34%20AM.png) from one viewpoint with a very [ghetto stereo camera rig](http://cl.ly/image/3A3n2K1h1Y3n/Image%202014-12-04%20at%204.53.16%20AM.png). We didn't have enough time to composite multiple point clouds into one (using [space carving (PDF)](http://www.cs.toronto.edu/~kyros/pubs/00.ijcv.carve.pdf)) however. Calibrating the stereo camera was tricky and time-consuming, but crucial.
How can you create a Python 3 project? That is, when I run the script inside the IDE, I want it to be interpreted by Python 3. Is it possible?
I don't see an OS X .dmg file for 2.3.2, just 2.3.1. I quite like Spyder and I use it regularly, even more now that I've been phasing out MATLAB.
Even though its target audience is scientific computing, does anyone perhaps use it to develop GUI apps, specifically PyQt/Pyside - PyCharm is borderline useless to me as it offers almost no completion suggestions and similar things? Edit: Nope. Looks nice though.
Cool project, asyncio. I haven't heard of space carving -- i'll have to take a look. As far as meshlab goes, the effort on my part was pretty minimal. I simply deleted the noisy points with the rectangle selector tool, then did some surface reconstruction.
I noticed that in the example of getting information by player ID, you essentially have to pass your API token twice -- once to create the app, and once to create the player. Maybe something like app.player() returns a new Player instance, doing the legwork for you. EDIT: this also applies in the Tankopedia instance. Doing this would also allow for stuff like: info = app.tankopedia().get_info(...) The app object could also just have these as instances set up as members of itself that themselves contain functions, i.e.: app.player.get_info(...) EDIT 2: also, requiring passing the player ID to player_details by utilizing another method of the same instance is not a clean way to use an API; nickname should be an acceptable kwarg that the method knows how to resolve.
Very cool - will definitely implement that, appreciate the feedback and tips.
That's worse solution, since you'll hardly get exact run time in the first place and even if you do it may be influenced by different hardware/platform. And if your code shows 100% but is not doing anything people will assume it's stuck. A better thing would be to send progress events from within the function which would increase percentage.
&gt;The chatbot I described above are the ones I'm most familiar with from making them myself. Are those even worth the time invested anymore?
That's amazing! I've been using Python / PyPy hybrid with multiprocessing for 22x speedups, but this seems to be much cooler :-) One thing that's not mentioned, how is support on Python 3?
This is not Python 3, but there is absolutely no reason why it can't be (you can also probably mix Python 2/PyPy 3 or the other way around if you insist)
Thanks! The challenge I found with multiprocessing was pickling things to go back and forth between the interpreters. How well does jitpy cope with classes/objects for example?
Good point. GitHub makes it pretty easy to rename repos, but I'm kindof stuck on it now... 
I personally have a professional situation where this is useful. I would not use OP's code though. I rolled my own (as you can see, it's quite trivial) 
Hah, yea! I like it.
I am not sure there is a specific tool, as this is purely for message passing, though you can build your own file locking. If you incorporate threading with a file lock for example, it will act as intended.
Upgrading to 2.3.2 stopped pandas from HTML printing in IPython and I couldn't get it to turn back on. Any tips?
Ahhhh Cooode fooooolding guys! I love spyder! Where is code folding a python IDE needs code folding!!
Replace the readable syntax of Python, but keep the poor-performing interpreter as it is? This is a terrible idea.
Thank you for being the only person on the internet who understands that car.honk() is an awful, useless example. I've understood the mechanics of OOP for years, and always struggled to understand why it's useful. This article finally made it a little more clear to me.
Probably stupid question, but when would you use this rather than just running the program in PyPy directly? (Maybe answer this under Motivation section)
I should - mostly when you have all other complicated dependencies that don't run on pypy (scipy comes to mind) EDIT: I added a short para
It is little messy right now, because I'm still working on it ;) 
There was a post last week of someone who used Hy to add `yield from` to Python 2.7. Apparently you can use Lisp macros with Hy to modify the language of Python itself....or something. I think it'll be useful for back porting functionality.
Can anyone explain what line 25/26 is doing? &gt; try: &gt; ran = function(*args) What exactly is 'function' calling? And how is it being used?
Yeah, I hate it when my programming language is useful for everyday tasks. I should probably switch to a different language that doesn't enable such trivial applications.
Yes. Always. It's all about volume.
Coming in 2.4 :-)
It's not possible anymore. In fact that was deactivated by the pandas guys a long time ago. We just didn't follow them correctly. But you can use our variable explorer to do this job, which is nicer.
I'll upload one this weekend or early next week. I finally took the time to create a build env for Python 3.4, so that's going to be the default from now on.
function is running whatever function the decorator was placed over. Think of decorator as a prepend or wrapper to the actual function. it happens before the function is actually reached wait_with_me() is the function called in the usage example. 
There are a couple of more fixes to make developing Qt apps nicer, like showing overloaded signatures and an event loop that goes well with the Qt one. I'll fix them in 2.3.3
Thanks! Really appreciate it!
Just install Spyder for your Python 3 installation. You can use pip for that: `pip3 install spyder`
Oh man I still have nightmares about implementing filelocking for threads in python.
Thank you! There are big things coming next year: IPython notebook support, better debugging, conda graphical manager, code folding, interactive tutorials. Keep it following it :-) 
Thanks!
I understand. Did you see gruvi, BTW? https://pypi.python.org/pypi/gruvi I'm not sure about the GPL argument, seems many successful projects these days have more permissive licences.
Have code posted anywhere? I would love to take a look at that.