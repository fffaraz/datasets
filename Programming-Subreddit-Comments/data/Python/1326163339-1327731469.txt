Doesn't quite handle the "every other" part.
If it were a person begging, you could be right, but it's circumstances suggesting or making obvious a question. An arrangement of facts do not beg. And now, I'm ashamed that such an arcane discussion compelled me to comment.
"Would of" Are you trolling us?
why do you say that tvnamer isn't mature enough? i've been using it for all my tv renaming and organizing needs for six months or so and haven't had any problems.
perhaps it would be easier to see how the code is working by multiplying all single-digit numbers. try: for a in range(0, 10): for b in range(0, 10): print(a*b) you will see 0 * [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] and then 1 * [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] and then 2 * ... and so on. they're all accounted for.
Maybe it could ignore tweets where more than 3 words are wrong?
you must have typed it incorrectly. the code, as it was written, first sets `a = 100`. it then sweeps `b` from 100 to 999, multiplying a and b as it goes. it then sets `a` to 101 and sweeps `b` from 100 to 999 again. next `a` becomes 102 and the sweep happens again... and so on until `a` gets to 999.
why would you import that, the name is totally unused.
Save as CSV and go from there? Not that I don't see value in being able to read a spreadsheet file and manipulate it, it is just that most such files are so irregular that I question the ability to do anything constructive from them. Writing spreadsheet files is another matter altogether. If you had reasonable control over where the data comes from you could put the data into a database of some sort or force the spread sheet user to enter data via scripts or something. Generally though third party spreadsheets are a free form mess. 
But both CAN be used properly. It'd have to be pretty complex to not have false positives.
Smells like teen homework.
Awesome work! :D Even better when correcting retweets, makes it even more random and possibly insulting! Yay!
You're correcting misspellings, which have nothing to do with grammar. Still, awesome hack. 
......no.
I wrote a bot a while ago (no longer running) which would record what people love or hate by looking phrases like "I love ", "I fucking love ", etc. It would also randomly RT some of the results. One Tweet it RTd was (paraphrasing) &gt; I love my boyfriend Joe Bloggs! Which caused the OP to fly into a rage, the bot received a flood of messages along the lines of &gt; Who the fuck are u!?!?!?! U stay the fuck away from my boyfriend biatch!! If he been fucking around I'll kill u. I actually ended up sending the OP a message to explain it was a bot, before her poor boyfriend got a grilling about this other girl.
I had a quick look through PEP-8 and PEP-257, but couldn't find anything - could someone elaborate on why? For the sake of convention?
For one line docstrings: &gt;Triple quotes are used even though the string fits on one line. This makes it easy to later expand it.
I'm very wary of your weary.
I'm puzzled - if you're comfortable with LAMP, why are you thinking about using IIS for this project? Just as a way to learn more about it?
obligatory vim recommendation.
makes sense. do you have retarded monolingual danish speakers over there to compensate?
Congrats to the work done by the team. I'm not a Web2Py user but I'm always impressed by their motivation and availability.
Who the hell is stupid enough to set up an international drug deal using a twitter account apparently linked to his real name?
I've tried Emacs, and Vim but kept dismissing Gedit. I may give it another look. Looks good enough for my needs.
Weeerll, my mother is trilingual, but not good at any of the languages, and she does act quite retarded at times.
So does Kivy utilize PyPy at all?
I think he means that for your code to make sense, it should be more like: from contraception import vasectomy procedure = vasectomy(self) procedure.perform() You imported contraception.vasectomy, then executed a method of self...
Congratulations to all those who have put lots of hard work into this. It is going to be a fantastic conference.
Ah. So it's between working with Windows, and working with an ancient version of Python. Tough choice.
Yeah, it's looking like ISAPI-WGSI is my first choice amongst those available to me. Assuming I can either get rights to admin the box or have a sysadmin install and set it up, that's the path of least resistance. I need to have base functionality for this thing in place Monday after next, even if that means I'm running it from Flask's dev server on my local machine for a presentation. Fast is good.
What is stopping you from using CPython on Windows rather than IronPython?
I think that before look into pywin32 or other libraries that will work with CPython for IIS before you decide. I'm guessing that you;d have more luck finding help going that way then the IronPython way, but again that's just a guess.
I'm trying to take the list of files and figure out which file is which episode for a given show. Thanks for the link
Sublime Text 2 anyone?
Yeah Apache mod_wsgi is the way to go for you.... If you have a choice of infrastructure and on linux I highly recommend that you look into using nginx(instead of apache) and green unicorn.
Aaah, I see. Yeah I can definitely see how my 'code' doesn't make sense!
Couldn't you install RHEL 6 ... that would give you Python 2.6?
Nope, the reference architecture is RHEL 5.3, so that is the only option.
"""(?P&lt;mygroup&gt;.)(?P=mygroup)+"""
python3 progress is going as well as the fundraiser, which is not so much. I'm very sorry to disappoint you, but I'll be doing whatever I feel like in my free time.
And even shorter: """(.)\\\\1+"""
This might take a while for long string, but you could get the list of characters in the string, loop through them and build a regex for that one character; check the match for the length greater than 1 and return it. Something like: chars = set(string) repeats = [] for char in chars: matches = re.findall(r'(%s+)' % char, string) repeats.extend([m for m in matches if len(m) &gt; 1]) print repeats 
Wow, it's really true, you can't please everyone. Don't bother trying, just keep being awesome. You're doing fantastic work and us mere mortals should really be happy for whatever we get. In my opinion, python3 might be nice, but there's no point until the rest of the python world has caught up and more people are even using the cpython version. Full numpy support will be far more valuable in lending some real credibility to the pypy project.
You ask for the impossible. *Nothing* could make constructive YouTube comments.
"Begging the question" is a case of people repeating an obscure phrase they heard and incorrectly assuming they could infer its meaning. You could have fun with this list too: http://en.wikipedia.org/wiki/List_of_English_words_with_disputed_usage
What about: str = 'fooooood' reg = re.search('(?P&lt;id&gt;[a-z])(?P=id){2,}',str) print reg.group(0) that will result in "oooooo"
Holy shit! This *exists*?!?!?! Where were you two weeks ago? I needed you!
Great joke, too bad some languages are not too cool to handle jokes like **that** 
If you're familiar with a lamp setup, for development, just download and use Activepython. It doesn't install anything to other parts of the system, only the directories you specify. Once you're ready to deploy, you can compile your own python and use that instead.
What you want is "*raises* the question." Imagine you're giving a presentation. You say something, and a slew of hands go up with a question. They've raised their hands because what you've said *raises* a question. 
So then this means that values in return statements are only returned locally within the stacked functions? ( like to the next level up? ) Does that mean that their function produces all of the values up to n iteratively and then sums them at the end for each iteration of the for loop at the end? Isn't that like way more inefficient then just iterating? Thanks by the way.
There's nothing blocking it, per se, we have a branch where it's being worked on, and tons of failing tests :)
Python 3?
Yes, recursive functions are almost always less efficient than iterating, but for some problems (and especially in some languages) they're significantly simpler to write. The usual examples are parsing, trees, and sorting.
I think that's how those binary installers work, so yes. However, you can download the egg which is just a zip archive, unzip it into some private location and point your PYTHONPATH to it.
More like `assert n &gt;= 1`, and the `assert` automatically raises its own `AssertionError`. But you're getting the picture. :-) 
I usually setup Vim as IDE on remote hosts but this looked like a good alternative to Eclipse like ides (lighter and easier to setup)
Well if you over complicate something like a simple loop that I had with what you have, later things may start to look like you just ported C code to Python. In case you didn't read the Python philosophy, "There should be one-- and preferably only one --obvious way to do it." When you start to have your way that's just about four times in length and is recursive for no good reason, it worries some Pythonistas (me). Not trying to put you down, just want to see you start off on the right foot.
numpypy isn't supposed to be a numpy re-implementation. Lots of parts will be taken from original numpy later. At least that's the plan as far as I know it.
Not yet, but some work has been done. See this message: http://groups.google.com/group/gevent/msg/759ba600b31e4c77
yes, what are they?
Yes.
Haha ya, Thanks for pointing out the error about numbers &gt;=1 and floats though I would never have thought of that.
Apparently, the author of the tutorial didn't think of it either. :-( I like using Python because it's not statically typed. However, if a function really, really needs the arg to be an integer, the function should right away either convert it to an int or raise an exception. 
I know. I was just typing out "there's no built in way to parse fractions", when it occurred to me that there was exactly that. Some of the lesser known corners of the standard library can be really handy. Other favourites of mine include shelve, struct and getpass.
I am not a user yet either, but I am always consider using it for a project. I think the built in complete authentication solution will be a motivator to make me take the step. Congratulations to the team.
Good work! One minor thing though: I don't think you meant to say "Laplace transform" (that's not a numerical concept).
I'd probably prefer if it continued to be in Florence for a while. Excellent work on the last conference though the wifi could have been better :) 
I'm a LAMP guy who dabbled a bit with trying to get a moderately sized Flask app running on IIS with a couple options including ISAPI-WSGI and it wasn't as seamless as I expected from reading various docs. IIRC, I got the WSGI stuff to work after some fiddling but there were weird issues with other parts of the app. I couldn't connect to my database from the WSGI app, for example. It was really hard to debug or find any useful information. It also wasn't very important to me so I just wrote it off as "windows is bad at this" and gave up after a painful day or two. So if you go the IIS route and need to do anything that involves external libraries or drivers, I'd suggest throwing up a few test views early on to make sure they work.
Upvote for irony!
I would agree only to a certain degree. I cannot think of a reason as to why f(n-2) cannot be eliminated.
Piss off. 
Just so I don't sound like an idiot at cocktail parties, please correct me if I'm wrong here: Pypy is an implementation of python, written in python. However, it gets translated to C and compiled, and that translation is also done with python. So they write the interpreter in python, it gets translated to C via python. The C is compiled into a binary executable, known as the pypy interpreter. So to initially build pypy, you need a CPython (or other python interpreter) on your system. Once that is built, you can replace the CPython binary with the pypy binary, and proceed as usual (using restricted python only). I think the confusing thing is that pypy is always referred to as python written in python. That's misleading to me, because people generally don't think of python code as getting translated to C and compiled. If that is faster than running on an interpreter, why don't people do that more regularly? Furthermore, if the answer to that is because of JIT options and stuff, why isn't pypy built once, then run an interpreted pypy on top of the compiled pypy, so that the run hierarchy looks like: script -&gt; pypy (interpreted) -&gt; pypy (C compiled) -&gt; machine.
Install web2py. make an app called init and put your module in init/modules/ #in file init/controller/default.py def index(): form = SQLFORM.factory(Field('input','text',requires=IS_NOT_EMPTY())) if form.process().accepted: from inputmodule import process output = process(input) else: output = '' return locals() # in file init/views/default/index.html {{extend 'layout.html'}} &lt;h2&gt;Write some text in here&lt;/h2&gt; {{=form}} &lt;h2&gt;Output&lt;/h2&gt; {{=output}} You can unzip web2py and give it to them as a windows/mac application or you can run it yourself and give the URL http://yourdomain.com/init so they can try it as a service. Add @auth.requires_login() before "def index" to require login to access the service.
*Project idea:* make a reddit bot based on this idea that replies to comments on /r/python. Use the [reddit_api](https://github.com/mellort/reddit_api) for posting messages.
Shed Skin or Cython are better for the faster-but-restricted Python niche. PyPy gives you a lesser speedup, but implements everything. [citation needed] on lesser speedup, especially for cython (*without* C types declaration, pypy should beat it, even with the answer is unclear)
&gt; Oh my God, PyPy nearly beat Haskell in its flagship application, the Fibs! And coded in its most idiomatic form!
TCO doesn't directly apply but appearently GCC is gotten really smart see [page 41](http://www.linux-kongress.org/2009/slides/compiler_survey_felix_von_leitner.pdf) (warning: PDF)
I am not arguing with your feeling. With web2py it is easierto download the zipped windows binary, add those few lines I posted, rezip the thing and you have a distributable app which includes everything you need (including portable python, database, web server, etc.) You can do that with Flask too but you need a little more instructions. Anyway. Flask is great. 
If you want something easy, try [easygui](http://easygui.sourceforge.net/). The enterbox and textbox should be really really close to drop-in replacements for input and print. Just depends on what you're going for. A bonus is that it just wraps tkinter with custom classes, so you can just add it to your projects directory and not worry about extra dependencies.
I should probably shut up because I haven't been watching as closely as others here, but I understand Python 3 is starting to ripen. If you are just learning now (e.g. you aren't planning on releasing production software in the next few months based on your efforts) you can probably just start with Python 3 and not worry about the 2.x releases. On the other hand, if you _do_ plan on writing production software for release in the next 6 months, want to take advantage of a larger third-party module selection, or expect to be maintaining or porting existing source code, you should probably start with 2.7. Edit: Truthfully the "Should I use Python 2 or Python 3?" FAQ answers this question much more comprehensively than I would want to try to. Reading what you said again, I would say just go with 2.7 and port to 3.x when you're ready to leap.
Correct me if I'm wrong, but I'm pretty sure what is being suggested for dependency management already exists (assuming the dependency is able to be found on pypi) in the form of including a install_requires list in your setup.py. For example, when you install the Flask Web Framework, using pip, it knows that it needs to obtain its dependencies (Werkzeug&gt;=0.6.1 and Jinja2&gt;=2.4) and will retrieve them from pypi if they are not there already. Looking at the [source code](https://github.com/mitsuhiko/flask/blob/master/setup.py) for their setup.py shows you how to do it. I'm certain other packages do that too, which is why maybe I'm not understanding the point of the blog article.
You're right, none of these queries returns what you'd expect. But they do all return a meaningful result. Specifically, each query matches US congressional bills that contain the query in their names. As we add lots more data in the upcoming weeks, problems like this should become much less frequent.
&gt; CPython isn't necessary anywhere in the build-process. It's commonly used though because when you just checked out pypy from its repository, it's usually all you have to start the translation.
I am pretty much in same situation as you. I decided to use Python 3 for stand alone tools and Python 2.7 for web(Django). Being sufficient in C, I don't think it is a major effort to learn both. I think it will come handy. 
There's still a divide. Python 3.x is a somewhat nicer language. The problem is that the C API changed, and there are still many legacy libraries that don't work with it. Two big ones for me personally are wxPython and django. Given your java background, you should definitely also look at jython. It's equivalent to python 2.5, except you give up non-standard c based extensions in exchange for the jdk. (Python 2.5 is not much different from 2.7 - see the various "what's new in python x.x" posts). 
So... how exactly does being 6x slower than Haskell mean that PyPy is giving Haskell a "run for its money"?
aah..gotcha. Yeah I'll save this one cause I'd like to see if you come up with a viable answer other than tkinter or curses :)
I wonder how hard it would be to incorporate something like this online bot ( http://www.sensationbot.com/jschat.php?db=smacktalk ) to talk smack back to all retweets? Just an idea, I'd consider giving it a try if I had the programming ability and time... I'm still just learning about python. Anyhow, I loved the bot.
I program in Python mostly but my work forces me to use Eclipse. Pydev for it it's so bad though, I use a plugin to let VI run within eclipse. 
I only skimmed it, but I'm going back to actually read it tomorrow over coffee. What I think he's suggesting is a standardized mechanism that integrates into the base language/standard library. He has identified several things that we have to worry about when making "applications" that goes beyond just dependency management. Hence the suggestion of __configure__ and services and such. (I think he missed logging) He's suggesting that environment integration become part of core python. Not a bad idea. Dealing with the environment is something that any non-trivial application has to do in some way - dependencies, configuration, logging, etc. Perhaps being a fundamental language feature makes sense. In fact, where I work, we do something similar - we have a package that all applications import that provides common framework for argument parsing, configuration, and logging. Further all applications present themselves as services (albeit not exactly the same as what the author was saying). And applications can provide a WSGI instance when asked that becomes the UI I'd rejoice at a standard method for doing all that instead of introducing our own dependency. 
Java to Python would certainly be easier. I learned Python first and spend all my time learning facepalming. Each time something is introduced, I think how much easier it could be done in Python. Further, everything is an object is a disease. Classes have some use to some, but forcing everything into a class leads to obfuscated code like a simple hello world app. If nothing else, learning Java makes you realize how beautiful Python is.
so, south will be fair enough to learn Django :)
It looks like you're just doing simple substring matches. If that's the case, then it's probably much faster to do e.g. `line.find('dwnld complete')` or `line.endswith('[MyApp]')` as those are more efficient than regexes. If for some reason you do need the full features of regex, then it's likely faster to combine all the patterns into one regex rather than looping over each one. Also, you're using `match()` but all your regexes start with `.*`. The only reason to use `match()` is if you want to anchor the search to the beginning of the string, but starting your regex with `.*` completely negates that, so you might as well leave off the `.*` and use `search()` instead. 
&gt;everything is an object is a disease. That's an extremely strange thing for a Pythonista to say, considering that **more things are objects in Python than are in Java**. The bit about classes is a totally different problem from what you describe. Sometimes I wonder if the reason so many students have trouble understanding the difference between classes and objects is that certain language designers seem to have trouble understanding the difference between class-oriented programming and object-oriented programming.
I've been using 2.7 out of habit but because I wanted Unicode strings without fiddling I changed my project over to 3.2 with 2to3 and the only changes it made were related to urllib usage because of the changes in its structure. The project then ran on the first attempt in 3.2. I don't know what kind of code people write but it seems to me that I've been writing 2.7 in a py3k compatible way and there isn't a big difference anyway. I tried 2to3 with other projects as well and there weren't really any changes other than unicode() and such stuff that are real changes. The main differences are just print -&gt; print(), unicode()/str() and u"", urllib stuff, filter? etc. The limiting factor is library support I guess, I think all of my stuff would be fine except the ones that use lxml.
Twas he.
To be frank it doesn't matter - the chances between versions aren't huge. We have yet to reach a tipping point in terms of packages being ported over to 3. I would start with 2.7.
I too wouldn't want to restrict myself to Python 2.4 so assuming that IIS is to used ... I think that using 'ISAPI Rewrite' (http://www.isapirewrite.com/) would allow you to run the Python/Flask app on the windows server in a very straightforward fashion and just allow IIS to just act as a proxy server. I've done this using CherryPy in the past and it all works fine. I've also used IIS to serve the static content but that's just icing on the cake. I *think* that this would simpler than the ISAPI-wsgi approach and (once the initial install of 'ISAPI Rewrite' is complete) would not require you to get admins involved.
You should compile the regexes (re.compile). Otherwise python has to parse the regex expression every time you call re.match
I just asked a pypy developer if there's any difference between CPython and PyPy in regards to these algorithms. This is the answer: &lt; arigato&gt; it's basically the same algorithms &lt; arigato&gt; plus tons of tweaks that don't change the amortised complexity
It must be joke! Please, tell me that the author has something wrong with his calendar and thought it is April 1st! PLEASE!
Yep you've understood what I want, the urxvt -e .. seems to work fine, I'm new to programming so sockets is too advanced for me still. I will stick with the non python way for now. Thanks!
Actually, there's one difference, which is soon to be changed. String concatenation with *+* is currently optimized in a quite hacky fashion in CPython, where if the reference count to the string is 1, it will not be treated as immutable, as strings ought to be, so that adding is much faster. Pypy has code to facilitate a very similar optimisation using the jit instead of reference counting, but it's not enabled by default (the translation option is called *--objspace-std-withstrbuf*). There is a branch in the mercurial repository for making that optimisation on by default, but there are still some test cases that fail. The performance of those string addition operations will be quadratic until that optimisation hits pypy nightly.
I carried on for the next sentence: &gt; Industrial strength languages are good for projects with several people working on the project where being formal and careful about what you do may impact lots of other people. Presumably NASA and Youtube just have one person each working on their Python code, and they don't have to worry about mistakes. To be fair, there are differences, and there are probably reasons for choosing Java in some situations. But this passage smacks of "now learn a real programming language", which is patronising and increasingly outdated.
This helps to put it into perspective a lot more. I have not yet seen a concise list of differences, thank you. EDIT: out of curiosity, if you were to learn them both would you go with learning 2 and then finding out the differences in 3, or vice versa? I am tempted to learn 3 first so that I only end up writing code for 2 where I absolutely must.
I'd probabaly not rely on that given that it's an implementation detail. I know, almost all questions always are wrt the default Python implementation, but explicit caching would be much preferred over implementation specific caching.
&gt; The Python 3 wall of shame shows which libraries support py3k and which don't You can also check the [Python 3 wall of praise](http://pythonpackages.com). Enter a package and if it supports Python 3 it will be highlighted.
You might also want to look at David Beazley's presentation on [generators and using them to parse large log files (PDF)](http://www.dabeaz.com/generators/Generators.pdf).
You should be fine if you use the latest 2.x version instead of 2.3.5 (that is 2.7.2 i guess, here you can check http://www.python.org/getit/releases/) However, if you try to use any 3.x version, as 3.0 breaks backwards compatibility, you'll possibly have troubles, see http://www.python.org/dev/peps/pep-3000/#compatibility-and-transition
Python 2.3? That was superseded over 7 years ago... If you use the latest 2.x release (2.7), the same examples should work, except in corner cases. Using Python 3 they would require a few changes (e.g. using print(x) instead of print x).
None. You should definitely have everyone on Python 2.6 or 2.7 by now.
The IT department seems to agree, all the computers have 2.7 installed.
I assure you this was not a concious decision of your IT department. It would have been bundled with the prepackaged OS they picked, or had picked for them. Unless of course you're using Windows, in which case they either installed the most obvious choice, or someone who knew what they were doing requested that 2.7 be the version rolled out. In general, system administrators are very poor programmers and years behind the curve. Edit: About 2 out of every 3 jobs I've had, the sys admins have been pretty poor. Good system administration requires programming. If a sysadmin can't program, they're just a glorified tech junkie with a control complex. That said, I have seen some good sysadmins, and they're always ex-programmers, and/or dedicated individuals who realise their job is to make other people's jobs run smoothly, without exception, 24/7, and NOT to spout rules, excuses, and workloads.
Good point. Having done a little testing, it seems that as soon as one uses a set of patterns more than once one can benefit from pre-compiling. This is true whether the set of patterns fits in the cache or not. Speed-ups in the range of roughly 2x to 10x, the bigger improvements coming after using the patterns about 5 times or more. 
"This page documents the time-complexity (aka "Big O" or "Big Oh") of various operations in current CPython" Is that python 2.5, 2.6, 2.7, 3.1 or 3.2 ? last edit is from december 2010 but measurement data could be older...
I don't really get what you mean, but imagine the sets are implemented using dicts (they probably are, I guess). Lookup, insertion and deletion are O(1), iteration is O(n). So for the union sUt, we create a new set, then iterate through the s (O(len(s))), copying each member (O(1)). Then we iterate through t (O(len(t))), lookup each item in the new set(O(1)) and if it's not there, add it (O(1)). So we end up with O(len(s)+len(t)) For the difference s-t, we create a new set, then iterate through s (O(s)) checking each element to see if it's in t and if not, adding it to the new set (O(1)). So we end up with O(len(s)). For the difference update s-=t, we could do it one of two ways: iterate through s, checking if each element is in t and if so deleting from s (O(len(s))); OR: iterate through t, checking if each element is in s and if so, removing from s (O(len(t))). I guess it's implemented the second way (which would make sense since you'd probably have t smaller than s more often than not). **edit:** oh, you're asking about the blank values, for amortized worst-case. Yeah, I think they're going to be the same as intersection, assuming the sets are using dicts or the equivalent. 
&gt; If you know Java learning C++ is easy. Hmmâ€¦
You're right, "measurement" was wrongly used, sorry. Anyway my point was more of a general complaint about the fictitious timelessness of many documents in the web. In 10 years, it is certainly possible that document being still there talking about "current CPython" and its small differences with "older or still-under development versions".
Yeah, I just checked it out there. I was running the 32 bit one, thinking I had the 32 bit python installed when it was really the 64 bit one. n00b mistake. Sorry. 
Is the binary string a valid UTF-8 encoded string? What happens if you do a "htmldata.decode('utf-8')" in grab_url_html()?
Are you downloading the installer or trying to install with distributed python files / `pip` / `easy_install` / etc.? In my experience with Python development on Windows, a lot headaches will be saved with larger libraries if you grab the binary installer from their web site (e.g. you probably want the **wxPython2.8-win32-unicode-py27** download from: [http://wxpython.org/download.php#stable](http://wxpython.org/download.php#stable)
-
fromstring(htmldata) assumes you have a string in some encoding. You're wrong about it. You should be sending Unicode or also sending the name of the encoding the web server says it's giving you in its response headers. fromstring doesn't make sense to take a string without specifying the encoding.
the quick workaround might be return unicode(htmldata, errors='ignore'), which will strip out invalid utf-8 stuff
Well, I'm aware of the current situation. My hope is that it change. 
This does look like it may be a bit too much for this program, but I'll definitely take a look if I want to try running this online. Thanks!
Forgive me for using Github to host this blog post, I'm still building a blog of my own so the posts would look terrible (no formatting) otherwise.
This is correct, but I may end up trying this out for my own personal use. Thanks!
Well, Dan Savage's twitter feed is called 'fakedansavage', so who knows...
I work at a 100% Java shop and this is exactly how I feel. I sneak it as much Python as I can, wherever I can. And I'm not even saying Python is the right tool all the time, I just don't agree with some of my co-workers who believe that Java is the right tool all the time.
Python 3 if you can. Python 2 if it's more convenient. Determine your dependencies and decide. Remember, porting to Python 3 will be trivial if you don't use much text handling (Python 3 changes string encoding from implicit latin1 to explicit utf8 by default). Otherwise you should try extra hard to go Python 3 out of the gate.
True, in that case it's only relevant for loops. Still, in loops that makes quite a difference - at least a couple of issues are submitted to the pypy tracker about it every now and then.
Big thanks for the advice and the challenge idea (I've got C++, VB, Java, and SQL classes this semester as well, so I might not find the time for it though).
The resource you are trying to decode is not in utf-8. You can try to fall back to cp1252 if you like: try: return htmldata.decode('utf-8') except UnicodeDecodeError: return htmldata.decode('cp1252') That could fail too, so you probably want a final fallback which does something unbreakable with the data, like the errors='ignore' trick. 
caks was right, but you should do this in a more robust way altogether. There is a module called [csv](http://docs.python.org/library/csv.html) included in the standard library that will do all the work for you and provide good error messages in exceptions if something unexpected happens. Just set the delimiter to `' '`.
Incomprehensible one line solution! a, b, c, d, e, f = list(zip(*(line.split() for line in open('try.txt') if line.strip()))) 
No, that's not what I mean, sorry - quite a lot of "good practice" examples, as in - always use with, use any and all for cases with multiple or/and statements, etc. "Good-practice" examples instead of good "practice examples", if you see what I mean. If he practices and learns through 2.7, he will probably be relying on things that won't work in 2.3
That was actually the first thing I thought of, minus the line.strip in the if clause, which is a bit of a clever hack :)
e.g. import csv with open('try.txt') as inf: infile = csv.reader(inf, delimiter=' ') a_thru_f = zip(*infile) a, b, c, d, e, f = a_thru_f 
Dealing with webpages is very hard since they often have different encodings. Look how you can detect them (In the http header, in the html head or just by guessing) And when converting again there is no promise that strange characters show up so ignore or replace encoding errors. Best is to convert all data you are dealing with first to unicode. And on a sidenote http://python-requests.org has a simpler api than urllib
Web interface is really simple for this sort of shit though. You just need to make one HTML template with a form and a bit for output.
equivalent to find . -name \\* -print
Does what it says on the box. Short and sweet.
What's wrong with just `find .`? If you just want files, `find . -type f`. Perhaps for some formatting into blocks, `ls -R`. You can add some color with `ls -RG`. While it's nice to play around with Python, why rewrite something that's so readily available?
Depends what you mean by 'works'. You might have lost some data.
You don't need the outer `list`. 
Pimping [PyFilesystem](http://code.google.com/p/pyfilesystem/) import sys from fs.osfs import OSFS for path in OSFS(sys.argv[1]).walkfiles(): print path
Making shell calls from python should only be done when you have a good reason. Otherwise, use what the language has to offer (os.walk in this case).
&gt; While it's nice to play around with Python, why rewrite something that's so readily available? Because OP can. I'm probably at about the same stage as he is, and reimplementing simple utilities has been very helpful in solidifying core concepts. When you're just starting out, working with a clear goal has its advantages over hacking away with nothing but a fuzzy idea in mind. As you can see above, OP [has even learnt about `os.walk`](http://www.reddit.com/r/Python/comments/oexe9/a_python_script_to_recursively_list_all_files_in/c3goy1m) along the way. Win-win, I'd say. :)
It isn't a problem for you to use a newer version to run the examples the teacher gives you. You'll have access to both their examples (using some outdated/suboptimal practices, but whatever), and the wider body of PyGame documentation. You can also use a newer PyGame, just change commands to functions and read the release notes (edit: there's only a what's new page) if something doesn't work as expected. If however the instructor expects you to give back work that they want to run on 2.3.5 instead of reading it, you won't have much choice but to dig up that version and use it.
Amen. I'm generally a Joel fan (I don't agree with everything he says) but that article is the best place to start for anyone who needs to deal with Unicode (which is almost everyone these days).
Ugh, I wish they would just give in and implement legit co-routines.
This makes me happy. 
Sounds like you want the [itertools](http://docs.python.org/library/itertools.html#) module. In particular, look at the combinatoric generators.
To understand how it works.
I didn't mean to call a shell call from Python, just that this script replicates functionality that already exists.
How would they look different (serious question)?
I was asking for something more like a mini-PEP (high-level only) for what *you* think coroutines in Python should like.
A bit off topic, but I'd stop watching after season 3.
Ah, thanks.
I'd order them in terms of quality: 1, 3, 2, 4. So if you're watching 2, definitely watch 3. You can watch 4 for some wrap-up and whatnot, but it's extremely obvious they made the show with the idea "This guy breaks his brother out of prison" and nothing else.
I'm not so sure about that -- I don't think it makes sense to "wait for coroutines to yield values nondeterministically", given that coroutines all execute in the same thread (and hence at the exclusivity of other coroutines). &gt;I've never felt that generators were lacking in expressiveness The precise reason I want coroutines is that every now and then I have some complex generator that can't be easily refactored because yield must be called from its top level. "yield from" will make this better but it seems like a hack in place of real coroutines.
You can do something like in your example using the `futures` package. from concurrent import futures pool = futures.ThreadPoolExecutor(max_workers=10) def process(i): return i * 2 for i in pool.map(process, xrange(100)): print i `xrange(100)` could be any iterator, including a generator. The results are mapped in parallel using threads (and so might come out of order). This is useful for batch processing when you want to take advantage of multiple cores. edit: I guess you sort of meant, working with multiple generators/iterators. In that case you could `itertools.izip` or `itertools.chain` the generators. But if you want parallelism then `futures` will do it nicely. 
listall[3][2] is what you are looking for
I wouldn't. I'm not really in this position by choice, but I'm sticking with it because I'm learning at an insane pace, and I don't want to look like a job-hopper. I was at my last job for only one year, so I feel like I need to put in my time here. Also, it's really impossible to be an expert in everything. I'd like to get into a job that's more focused on programming. I sometimes reflect on how much of a better programmer I could be if I spent my entire day programming instead of just 2-3 hours a day. I am a system administrator here because I have to be, but I'm not a very good one. I just really resented that comment about sysadmins not knowing what python version they have, because any sysadmin worth a damn would know exactly which versions are installed where. That's what sysadmins are for. If you have a sysadmin that doesn't know this, then you should fire them immediately.
Is your instructor just being lazy in not updating their course to the latest python?
os.path.join
&gt; however, when I invoked goroutines, I thought of a model of micro-threads that can also run on multiple processors, which is essentially what goroutines are. Yeah so preemted non-os threads/processes, instead of cooperative ones. Erlang also uses them as well (I prefer erlang's to go's as they don't share memory, and they have more interesting capabilities), and I believe so does GHC when calling `forkIO` (or when using sparks, but that's in the background)
As far as I'm concerned, that's as much and as desirable a feature as built-in curare darts in cell phones, or the ability for your glasses to randomly drill holes in your skull.
this is a mazing. excellent work!
Be careful though, `os.walk`silently swallows error messages by default (`onerror=None`), so your directory could look empty to you even if it's actually not.
I see, thanks. But you still know more than me.
Taking advantage of itertools.product and list comprehensions, I versioned your code: #!/usr/bin/env python # -*- coding: utf-8 -*- import itertools zero = one = [' '] two = ['A', 'B', 'C'] three = ['D', 'E', 'F'] four = ['G', 'H', 'I'] five = ['J', 'K', 'L'] six = ['M', 'N', 'O'] seven = ['P', 'Q', 'R', 'S'] eight = ['T', 'U', 'V'] nine = ['W', 'X', 'Y', 'Z'] listall = [zero, one, two, three, four, five, six, seven, eight, nine] print "what is your number sequence?" numbers = raw_input("&gt; ") listoflists = [listall[int(digit)] for digit in numbers] for element in itertools.product(*listoflists): print ''.join(element) 
yeah! I don't know about the downvote you received, I am embarrassed to see this link now, it is exactly what I am getting at. I suppose that a story, though, helps drive it home. I'd like to reminisce over breakthroughs.. I wanna feel it!
The challenge message at the end of your edit is: "THANKS A LOT FOR THE HELP" A different code and some guesswork is needed for that, though: #!/usr/bin/env python # -*- coding: utf-8 -*- from collections import defaultdict import itertools words_fname = '/usr/share/dict/words' with open(words_fname) as f: words = f.readlines() words = [word[:-1].upper() for word in words] # Remove newlines; make uppercase words = [word for word in words if word.isalpha()] # Words consisting of [A-Z] translation_table = ['?']*256 equivalences = {' ':'0', # Ignore '1'. 'A':'2', 'B':'2', 'C':'2', 'D':'3', 'E':'3', 'F':'3', 'G':'4', 'H':'4', 'I':'4', 'J':'5', 'K':'5', 'L':'5', 'M':'6', 'N':'6', 'O':'6', 'P':'7', 'Q':'7', 'R':'7', 'S':'7', 'T':'8', 'U':'8', 'V':'8', 'W':'9', 'X':'9', 'Y':'9', 'Z':'9'} for letter, number in equivalences.iteritems(): translation_table[ord(letter)] = number translation_table = ''.join(translation_table) rainbow_table = defaultdict(set) for word in words: rainbow_table[word.translate(translation_table)].add(word) message = '84265725683678434357' def decode(m): if len(m) == 0: return [] else: res = [] for i in range(1, len(m)): pre = rainbow_table[m[:i]] post = decode(m[i:]) if pre: res.append((pre, post)) if rainbow_table[m]: res.append((rainbow_table[m],'')) return res tree = decode(message) decoded_message = [] while tree: print 'Message so far:', decoded_message print "what sounds best to you?" for i,e in enumerate(tree): print i, ':', e[0] index = int(raw_input("&gt; ")) decoded_message.append(tree[index][0]) tree = tree[index][1] print 'Message', decoded_message In order to run this code you'll need a a wordlist. I've used Debian's */usr/share/dict/words* from package *wamerican*. Here's the final output: Message so far: [] what sounds best to you? 0 : set(['U', 'T', 'V']) 1 : set(['UH', 'TH', 'TI']) 2 : set(['VIC', 'VIA', 'TIA', 'TIC']) 3 : set(['THAN']) 4 : set(['THANK']) 5 : set(['THANKS']) &gt; 5 Message so far: [set(['THANKS'])] what sounds best to you? 0 : set(['A', 'C', 'B']) 1 : set(['CL', 'AL', 'BK']) 2 : set(['CLOT', 'BLOT']) 3 : set(['ALOUD', 'CLOVE', 'CLOUD']) 4 : set(['CLOVEN']) &gt; 0 Message so far: [set(['THANKS']), set(['A', 'C', 'B'])] what sounds best to you? 0 : set(['K', 'J', 'L']) 1 : set(['LN', 'LO', 'JO']) 2 : set(['JOT', 'LOT', 'LOU']) 3 : set(['LOUD', 'LOVE', 'JOVE']) &gt; 2 Message so far: [set(['THANKS']), set(['A', 'C', 'B']), set(['JOT', 'LOT', 'LOU'])] what sounds best to you? 0 : set(['E', 'D', 'F']) 1 : set(['EM', 'DO', 'FM']) 2 : set(['DOS', 'FOP', 'FOR', 'EMS']) 3 : set(['FORT']) 4 : set(['FORTH']) &gt; 2 Message so far: [set(['THANKS']), set(['A', 'C', 'B']), set(['JOT', 'LOT', 'LOU']), set(['DOS', 'FOP', 'FOR', 'EMS'])] what sounds best to you? 0 : set(['U', 'T', 'V']) 1 : set(['UH', 'TH', 'TI']) 2 : set(['TIE', 'THE', 'VIE']) &gt; 2 Message so far: [set(['THANKS']), set(['A', 'C', 'B']), set(['JOT', 'LOT', 'LOU']), set(['DOS', 'FOP', 'FOR', 'EMS']), set(['TIE', 'THE', 'VIE'])] what sounds best to you? 0 : set(['I', 'H', 'G']) 1 : set(['GE', 'GD', 'HE', 'HF', 'ID', 'IF']) 2 : set(['GEL']) 3 : set(['GELS', 'HELP']) &gt; 3 Message [set(['THANKS']), set(['A', 'C', 'B']), set(['JOT', 'LOT', 'LOU']), set(['DOS', 'FOP', 'FOR', 'EMS']), set(['TIE', 'THE', 'VIE']), set(['GELS', 'HELP'])] 
Whatever you want to do (and I mean whatever), there already exists a library that does it (or at least 90% of what you want to do). Spend 30 minutes searching for it if you need -- in the end you'll save yourself a lot more time. pip is your friend!
Regarding docstrings vs code, no, one cannot take up the task of the other. The rule is simple: The code is not the context. That is, the code will tell you what is being done, but not why. To some degree we communicate intent via good programming habits, such as naming our variables, functions etc appropriately, but it's not enough. In a sense, the naming of variables and functions is the very first level of documentation. The second is things like function docstrings and comments that give intent at a low level. The third is module-level docstrings (or your language equivalent) that tell you about the larger purpose of a big chunk of code - often with examples, notes etc. After that you have the big-picture stuff, narratives, references, use-cases, flowcharts etc etc. None of this is replaceable by code, but it's a bit of an art writing docs at each level that compliment but don't uselessly overlap the other levels. As a relevant aside, close attention to communicating intent by code also brings out some other oddities: def calculate_discount(price): return price * 0.15 def calculate_tax(price): return price * 0.15 This is a bit contrived (and I left out any documentation) but the above two functions, as far as the interpreter is concerned, are entirely equivalent. Yet it would be a mistake to create a single function to represent them both because as a human we know that 0.15 is an independent variable and could change at any moment. New coders might make this mistake, by **replacing** them with a function def derive_fifteen_percent(price): return price * 0.15 or whatever. We know that's a bad idea. More advanced coders may make a different mistake, by doing: def calculate_discount(price): return derive_fifteen_percent(price) def calculate_tax(price): return derive_fifteen_percent(price) but again this is an error - it is technically correct, but it communicates a relationship that doesn't exist. Only the first example trivially leads someone performing code changes to do the right thing. Thus the very structure of our code, and indeed apparently needless duplication, are vital to the communication of intent which is at the heart of being able to later read and correctly modify our code. But it's not enough. 
Haven't heard of it yet. Thank you!
Great, thanks
They're cases of (possible premature) optimization, by rewriting mathematical operations in their bitwise operation equivalents. In systems programming languages and assembly, bitwise operations usually execute much faster than mathematical operations. So, while doing a modulo-2 test to see if a number is even, it is much faster to just test for the least significant bit, because the cpu doesn't have to perform a division operation to do this. Also, dividing by 2 is faster if written as a 1-bit-shift operation (which is the same as dividing by 2 in binary). Whether these optimizations are actually beneficial in Python, is doubtful. There's too much other stuff going on to assume that they are, without proper benchmarking.
My very partial answer: if you suspect that you can use itertools to solve your problem, you probably can, and it's worth spending the time to figure out exactly how. You may discard it after you've figured it out if you like, but try it. Consider how that relates to learning to, as phira said, code idiomatically more quickly.
Look at idiomatic code from coders you respect, and you generally won't find cute solutions like this. It costs very little to add new constructor arguments and write the "self.". It also communicates the intent of the code very clearly to do so, and provides a natural limit on the possible number of constructor arguments. There are many good reasons to write out your "self."s.
Read http://nedbatchelder.com/text/python-parsers.html "Ned Batchelder: Python parsing tools" It has a good list of python parsers. I have not tried any of these but these sites look interesting: http://code.google.com/p/funcparserlib/ funcparserlib - Recursive descent parsing library for Python based on functional combinators http://spb-archlinux.ru/2009/funcparserlib/Brackets Nested Brackets Mini-HOWTO - nqw http://www.dalkescientific.com/writings/diary/archive/2007/11/03/antlr_java.html more ANTLR - Java, and comparisons to PLY and PyParsing Technical text http://gnosis.cx/TPiP/chap4.txt "python and parsers" 
Functions are first class objects. This is a concept a lot of programmers (especially those coming from languages like Java) don't take advantage of. For a simple example, you might have: def hello(): print "Hello world" x = hello x() That example isn't particularly useful, but enables other neat features like decorators: @decorator_function def hello(): print "Hello world" Is functionally equivalent to: def hello(): print "Hello world" hello = decorator_function(hello) One use case I've frequently taken advantage of that I don't see much elsewhere is using decorators to create a collection of functions. One class I use often looks like this: class FunctionCollectorDict(dict): def __call__(self, key): def wrapper(fn): self[key] = fn return fn return wrapper This enables me to do things like: fcd = FunctionCollectorDict() @fcd(".pdf") def process_pdf(flo): # Code for processing a PDF file @fcd(".htm") @fcd(".html") def process_html(flo): # Code for processing an HTML file Then when I have a document that needs to be processed I can call: fcd[extension](flo) To get the right function based on the file extension. Because the wrapper function returns the original function after adding it to the collection, you can decorate the same function multiple times, and call them with their original variable. If you simply need to iterate over a collection of functions, you can do something very similar by subclassing list instead of dict. There are a couple of micro frameworks (like Flask and Bottle) that use a similar technique for mapping the url space to functions.
In my opinion less experienced coders try to write clever code to show how smart they are. Experienced coders don't do this because it generally is a stupid approach. Code will need changing and simple code is easier to change. The best code doesn't actually do very much when you look at it because its been designed well. beginners write list comprehensions that are 3 deep an expert wouldn't. (there are always exceptions)
Bitshift will be faster than division in pretty much any language. I would be surprised if it isn't the case.
def geturlContentType(self, url, getdata={}): this is really fun. getdata will always be the same dict so if your function changes it then you are stuck with that copy forever. you probably want def geturlContentType(self, url, getdata=None): if getdata == None: getdata = {} 
Quality post. Thanks for posting it. Is there some semi-official guidelines on how to create easily readable code or maybe a website with examples of good and bad documentation?
I'd recommend doing a few years of picking up other peoples code and having to fix it. That way you learn a lot about what makes this painful. When you realise that you are writing the code for the next person who comes along that's when you start getting better. When I started out I thought I could write perfect code. I learnt that this doesn't exist. As far as resources are concerned I'm not aware of any :(
[you're good](http://www.youtube.com/watch?v=iZtbASCE7ZY) Edit: why not? name too ambiguous? def derive_percentage(price, percentage): return price * percentage
Thanks for the feed back, i have looked at scrapy in the past but it takes all the fun out of it, after all its a learning experience. as for validating html thanks for the tip. i really didn't like the way it was it was validating, but i had a hard time finding a solution in python, guess i should have looks a bit harder.
And how to you propose to communicate without shared memory? Pipes? Have fun serializing data.... &gt; And I'm biased because I always prefer correctness to programs running fast and wrong. So write correct programs.
Multiple cores in Python just from using an event library sounds pretty awesome. But it seems they're still a long way off.
It depends on the compiler or interpreter or JIT used as well. Some compilers or interpreters will automatically replace a "x/2" by "x&gt;&gt;1" if appropriate, thereby removing the possible benefit of hand optimizing. If you want to be sure, profile. (I just did on cpython 2.6 and &gt;&gt;=1 seems about 30% faster than /=2. However, with pypy, the difference was zero)
Over the past few years I've often had cases where I would have liked to extract the method names from my class in the lexical order they were defined. I always put it off as I figured it'd be a bitch to do. Until the other week... def get_methods_in_order(obj, predicate=None): return tuple( (i, m) for (i, m) in zip( itertools.count(), ( m[1] for m in sorted( (m[1].im_func.func_code.co_firstlineno, m[0]) for m in ( inspect.getmembers(obj, lambda v: inspect.ismethod(v) and v.im_func.func_name[0] != '_' ) ) ) if not predicate or predicate(m[1]) ) ) ) Side bar: I enjoy seeing if I can write functions using only generators and list comprehensions instead of loops. Example: def render_text_table(rows, **kwds): banner = kwds.get('banner') footer = kwds.get('footer') output = kwds.get('output', sys.stdout) balign = kwds.get('balign', str.center) formats = kwds.get('formats') special = kwds.get('special') rows = list(rows) if not formats: formats = lambda: chain((str.ljust,), repeat(str.rjust)) cols = len(rows[0]) paddings = [ max([len(str(r[i])) for r in rows]) + 2 for i in xrange(cols) ] length = sum(paddings) + cols strip = '+%s+' % ('-' * (length-1)) out = list() if banner: lines = iterable(banner) banner = [ strip ] + \ [ '|%s|' % balign(l, length-1) for l in lines ] + \ [ strip, ] out.append('\n'.join(banner)) rows.insert(1, [ '-', ] * cols) out += [ '\n'.join([ k + '|'.join([ fmt(str(column), padding, ( special if column == special else fill )) for (column, fmt, padding) in zip(row, fmts(), paddings) ]) + k for (row, fmts, fill, k) in zip( rows, chain( repeat(lambda: repeat(str.center,), 1), repeat(formats,) ), chain((' ',), repeat('-', 1), repeat(' ')), chain(('|', '+'), repeat('|')) ) ] + [strip,]) ] if footer: footers = iterable(footer) footer = [ strip ] + \ [ '|%s|' % balign(f, length-1) for f in footers ] + \ [ strip, '' ] out.append('\n'.join(footer)) output.write('\n'.join(out) + '\n') That one is fun. Now, these are both used on personal projects. Would I write code like that on stuff other people would have to maintain? Not so much. Edit: meh, reddit mangled my code. [Relevant pastebin.](http://pastebin.com/FEQurW1P)
I see. Thanks!
What he is saying with getdata is that setting a default kwarg doesn't "reset" it each time you run the function. Take this example: def funfun(a_list=[]): a_list.append(1) return a_list print funfun() print funfun() You'd think it prints: [1] [1] But really, it prints: [1] [1, 1] I've chased down insanely subtle bugs with this one. Hours and hours and hours wasted. Heed my warning... :-)
This, one thousand times this. An expert knows all the "expert" techniques in this thread, and that they don't need to use them.
Thank you good sir
&gt; Rarely do you see code from novices stray away from top down procedural patterns. Totally true, that's the main point I'm trying to overcome at the moment. I've read up on the topic quite a bit, but it is still very much unobvious to me when it's better to pull out the OOP toolbox. Would you say that tackling a *clearly* OOP task (e.g. programming a simple text adventure Ã  la *Learning Python the Hard Way*) would be a way to overcome this? It wouldn't help with realizing when to use OOP, obviously, but getting familiar with the tools is probably a good way to assess their usefulness. &gt; The first time they write a generator function that returns class objects they level up like 3 times. Why, thanks for the idea. :)
&gt; And how to you propose to communicate without shared memory? That's an implementation detail of the runtime, one without much relevance to the concurrency mechanism exposed to the developer. &gt; So write correct programs. Point is, threads-based shared-memory concurrency as you recommend it hinders writing correct programs by essentially making the whole program non-deterministic, and the developer then has to try and reclaim determinism by adding locks, semaphores and other such mechanisms. Shared-nothing concurrency inverts the problem by starting from full determinism and introducing clear and checkable points of non-determinism (message send and receives in message passing, for instance) when they're needed, making each actor of the program much easier to reason about and understand.
defaultdict. they are really useful for building nested dictionaries, as well as membership testing if you use defaultdict(bool) and ask if defdict[query]: do_something() instead of sets. sets bogged down my speed a lot for some reason.
The good programmer would get concerned about using floating point numbers for anything financial ;)
 Speaking of PEP 380, here's something using a yield statement. It wraps an arbitrary block of code with some simple code to save some "state", set it to some safe value, and restore it when the block is done. The particular place I've used this is on a project to test an ASIC. The new revision of the chip had a bug where you had to set some (unrelated) registers to a particular value before writing the registers you were interested in. This appeared in dozens of places in the code, and would have been very tedious and error prone to save and restore at each of those places by hand. from contextlib import contextmanager @contextmanager def safe_state(manager): saved = manager.get_state() if saved != SAFE_STATE: manager.set_state(SAFE_STATE) yield # body of with statement executes here if saved != SAFE_STATE: manager.set_state(saved) ... with safe_state(mgr): do_stuff_that_requires_safe_state() 
My office is currently going through a python craze (possibly started by myself). A few pointers I frequently give are: * Stop print debugging! Use the integrated debugger, it's stupid simple: import pdb; pdb.set_trace() * Access dictionaries with mydict.get("key", "default value") if you're not certain the key will be there. * Stop using urllib2, use [requests](http://docs.python-requests.org/en/latest/index.html) instead. And then I follow it up with tabs, not spaces. :-p
I'm getting worried about the future of PyPy. (_edit: OK, probably not in general, only about this particular direction_) Microsoft Research had an almost five years long project, trying to do more or less the same thing that PyPy guys intend to do: add pervasive STM to an imperative language. They went quite far with that, they had a working implementation that properly shadowed all accessed objects, etc. They overcame some hurdles that PyPy guys are only beginning to think about, and they had it much easier: a mature, heavily optimized VM, a statically typed language, a single target OS which has a transactional filesystem, a single transactional DB and a transactional MQ, so they could mostly sidestep the entire issue of "STM in a non-transactional world, how does it work?" -- they had the privilege of targeting a mostly transactional world. Then the project was discontinued, because they discovered more of even harder problems. Like, for example, dealing with nested transactions. What worries me is that, first, the PyPy guys seem to be betting the future of PyPy on the possibility that implementing STM in an imperative language is possible (at all!), and that they could do it with their resources, where other people with more resources have failed. Second, I haven't seen any mention of that Microsoft Research attempt in their posts, they should begin by learning on other people's mistakes before they set out to make their own. On the other hand, their approach is somewhat novel, I mean the whole idea that _everything_ runs in a transaction by default, and the program only commits once in a while. References: [the latest STM.NET specification](http://www.microsoft.com/download/en/details.aspx?displaylang=en&amp;id=8317), [one of the postmortems](http://www.bluebytesoftware.com/blog/2010/01/03/ABriefRetrospectiveOnTransactionalMemory.aspx). --------- On the third hand, I have my doubts even about that, because as it happens I reinvented the classic OOP as a sophomore, and learned a lot from the trainwreck that ensued. My intention was to make a game development framework which solved the reentrancy problem once and for all. The problem: an arrow discovers that it's about to hit an explosive barrel, calls `Barrel::receive_damage`, that method deals damage to nearby objects, so when the call returns, the arrow is actually destroyed, but doesn't know about it and can glitch in interesting ways. My solution: what if instead of calling other object's functions we _pass messages_ to them, and then continue whatever we were doing in a response event handler, fully aware that everything might have changed in between? I implemented that and discovered that instead of solving the problem I merely shifted the responsibility, and added a huge complexity cost on top of that. Trying to continue doing stuff in response handlers was much harder than doing it directly, and I still tended to ignore whatever changes that might have happened to the game world and to my object. Also, imagine my surprise when I read the Booch's seminal book, then connected the dots and realized that what I've done looks exactly like the Win32 message pump stuff, which sucks almost as hard as my attempt. Point is, even this novel approach might turn out to be something like that "solution" of mine -- good on paper, then you discover that it doesn't really solve anything, that you get much more of a headache trying to reason about safe places to yield than you do with locks. -------- **EDIT:** &gt; Like, for example, dealing with nested transactions. To elaborate on this: Are libraries allowed to use STM? If not, if it works like the standard `yield` statement, then you can't write a library that multiplies some matrices efficiently, all parallelism that you are allowed to have can only happen in your top-level function. That's, like, underwhelming. And if you are allowed to use STM from libraries/nested function calls, then you've just hit the motherlode of troubles. You can't `yield` from your `map_reduce` library function and have the parent transaction committed. That, again, would be useless, to say the least. So then you need properly nested transactions. What is the syntax? `yield` alone is inadequate, so there goes the entire idea of having something much simpler than lexically-scoped transactions. What is the implementation? How do you rollback a committed nested transaction when the parent transaction rollbacks?
That is exactly how I would do it (and have done it). I don't like to get meta if I don't have to. 
No defeatism here, as I said, I'm mostly concerned about them not learning on other people's mistakes, which means that they would have to learn on their own mistakes. Then, as they seem to be unaware of just how hard the road ahead of them really is, they might put too much effort in it, and in a wrong way. Like, they should try to get something working as soon as possible and then try to tackle the _hardest_ problems discovered by the people who tried that before them. Whereas they seem to be optimistic, and could waste a lot of time solving simple but effort-consuming problems (like rewriting the core parts of the evaluator to support the new model) only to hit a roadblock later. &gt; If the STM experiment doesn't work out, then Armin will have wasted some time, in exchange for learning something. I want PyPy to become the reference Python implementation. If Armin and Co waste a year on STM only to discover that it's not viable, that's a year wasted.
 dict.get() is nice and recommended, dict.pop() is fun too. I only ever use print for debugging pdb I can't stand - this is a personal thing I know people who prefer the other. I go with the "debuggers are for people who don't understand the code" argument. I say this but it's actually a lie as I generally use logging to do the output. For the sake of the children use spaces not tabs. people think they are interchangeable but they aren't, you see it when you start having multi-lined statements.
Look at the recent PyPy commits. stm is just one branch out of many active branches. Only one guy (Armin) out of the many PyPy devs has been committing to it, and it's far from the only thing he's been working on. Other people are working on things like Python 3 support, NumPy, PowerPC and ARM backends, sandboxing, concurrent GC, and general JIT improvements. Some of those features will be of interest to you; some won't. Some of those features will work out; others will not. But it's their time, not yours. Unless you're paying them, whine less about what they spend their free time on.
Haha, my only advice was "Don't be afraid to print debug"
I'm not whining. I'm pointing out a real problem with what they are attempting to do, and with how they are attempting to do it. By the way, I've added a couple of paragraphs to my original post, you might want to read them to realize how hard to achieve is their target and how misguided their optimism is. But OK, saying that I'm worried about the future of PyPy was too dramatic on my part, sorry.
The OP is a link to the PyPy blog.
yeah, I thought you could end up using it like that not to lose intent. some guy said that you shouldn't use floating point for these kind of things though. I've only worked in web development but why would this be a problem? not very accurate?
Whoa, this looks useful, and might be in the goldilocks zone between "too much trouble" and "not enough functionality"
&gt; Firstly, how can I start a program that is not in my path? say, ./blah.sh. Is that just "./blah.sh"()? i.e. do you monkey-patch the string class? I couldn't find this in the code, but your which() function seems to suggest it. A way to do it would be to modify the PATH from the script: PATH += ":/nonstandard/path" program() I also just pushed a commit that exposes a "Command" wrapper. So you should be able to do this: Command("/path/blah.sh")() &gt; Comments: The difference between -o and --option syntax is not so nice, but I guess option="blah" is mainly a convenience wrapper, which makes it OK again. I don't follow completely...do you mean that the keyword argument syntax could be better? &gt; ErrorReturnCodes. ErrorReturnCode_2? Really? Why not just ErrorReturnCode(2), or something along those lines? Yeah I was on the fence of doing it this way. 2 reasons I went with it: 1) A return code is almost it's own "class" of errors. A program has no standardized way to throw exceptions, so it uses return codes != 0...so it feels natural to map those to their own exceptions. 2) Less typing. try-catching with ErrorReturnCode_* is less than catching 1 exception and if/then-ing on the exception code. I'll consider this choice some more though... Thanks for the feedback!
I don't even know where to start. First we're fully aware about Microsoft Research approach and I would really suggest you read both - there are very crucial differences in both goals and means that there is not much point in saying "but it did not work for them". Should we also abandon making the JIT because Unladen Swallow folk failed to do so? Also, seriously, who are you to tell us what to do? I was planning to write a longer rant, but this is seriously enough - STM is by far not the main thing that happens in PyPy and I would suggest trying to read a bit pypy commit messages to see how much *is* actually happening. Anyway, I'm glad your approach is not that widely spread, otherwise we'll have no science whatsoever, if the approach has say 20% chance of success, would you ever recommend doing it? Cheers, fijal
Yes, you're whining. This is a research project (it means no promises it'll work) and goals are modest (2-5x slowdown for the serial case is fine for example).
No, you shouldn't use floating point for any operations that need to be correct, as opposed to really-close-to-correct. The technical details are outlined in various places on the 'net, you should read them, but what you really need to know is this: &gt;&gt;&gt; 0.1+0.2 0.30000000000000004 &gt;&gt;&gt; round(2.675, 2) 2.67 Neither of these are correct. The later, in particular, can result in you giving someone the wrong change (it should round up) - and if a multiplier is involved, it could be a LOT of the wrong change. The simple rule is: when money is involved, you use the decimal module. In practice this isn't always possible - sometimes there's javascript or HTML involved, or a stupid data store that doesn't have decimal support. In those instances, a string is recommended. Don't store it in a float, ever. Some people might talk about fixed-point, this can be ok but you need to understand it well before you use it. Where-ever possible, use native decimal types. Where not possible, use string and don't manipulate the value.
That was really good. Thanks!
Modifying the path of course has side-effects, so that's not really a good way of doing things, I think. The Command wrapper looks nice! The difference between -o blah and --option blah: you can run grep("-e mooh"), but not grep(e="mooh"), if I understand correctly - while grep(regexp='mooh') does work. The last one is cleaner anyway, though, so it doesn't really matter. On the ErrorReturnCodes: yes, they should be different exceptions and no, you should'nt be if/then-ing. I was more thinking of something like try: (...) except ErrorReturnCode(1), e: # maybe have stderr in e? (...) except ErrorReturnCode(2), e: (...) except ErrorReturnCode, e: (...) although the last might need to be different (e.g. using ErrorLevel(1) and UncaughtErrorLevel)
Embedding Python in Bash scripts is trivial: python program.py arg1 arg2 | do-something-else What this guy did seems like a slightly revamped version of popen. I don't really see the point of it. 
Parallelizing Twisted's (or any other's) event loop is *modest*?
I would guess if you don't see the point of it, it's not for you. It seems pretty interesting to me.. solves a lot of very common problems I have when trying to do things in Python. And popen? hah, that thing is a mess. I hear it's better than whatever came before it, but ugh. I already have to use envoy to avoid having to use it, so this is nifty in many ways.
Nested transactions is a problem of lexically scoped transaction model. In the event loop, you don't really have the problem or the need and you can *still* write parallel programs.
OP could also overload the pipe operator, so this could work too: ls() | grep("abc123") | wc("-l")
_Some_ parallel programs, as far as I understand. For example, you can't write a library that does some map-reducing on several cores, using the same abstraction. Or am I missing something?
The dead snake is the one that does not run the code that is already written - wouldn't releasing 3.3, 3.4, 3.5 be the act of polishing the dead one? There are enormous amounts of 2.X code that are not non PyPI that won't be ported to 3.0. - that on its own will keep the 2.X line alive for decades. I honestly think that the developers show a fundamental and tragic misunderstanding of the reality and just keep pushing ahead while they are alone and isolated from the reality Py 3.0 simply does not offer enough benefits to forgo the existing codebase. I see the Zope history repeating itself, where after a few years of boldly going ahead Zope 3 simply went nowhere and died while Zope 2 is still being used. 
You should open the textfile in an outer `with`-clause. By that you leave an open file-object behind...
Oh, and while I'm at it, here's another hard problem: request = get_request() long_and_painfully_process_request() statistics.processed_requests += 1 # BA-DUM-TSCHHHH That last line restarts the entire transaction if any transaction completed during the execution of this one (i.e. you are back to sequential execution, only slower and wasting all available cores). And you can't be clever and restart only that last part because it breaks the property of a transaction seeing a consistent snapshot of the world (i.e. then "`flag = get_flag(); value = get_value()`" could return an inconsistent combination). So what are you going to do? You can't do `statistics.interlocked_increment_processed_requests()` (which would suck anyway) because you don't have nested transactions, unless you somehow add another concurrency mechanism that your engine knows about. You can add `transaction_commit()` before touching statistics, but then the engine should become committed to completing that last part, it no longer can say: "OK, I tried 10 times and it didn't work, rolling back and aborting". ------------ I'm afraid I have to clarify it again: I'm not saying, "it's hard, stop wasting your time on it". I'm saying that it's hard, there are know hard problems with it, so you and Armin and everyone involved should begin by putting your pessimist hats on, writing down all known hard problems and inventing some more on your own, then clearly define the scope of your approach (making sure that it isn't too narrow to be useful enough), and then write not a single line of code before you have answers to all of the remaining hard problems. Make no mistake, making an STM engine that performs within 5x slowdown compared to vanilla PyPy _is not_ a hard problem. It's time consuming, it's, like, hard to implement, but it can be done, MSR guys did the similar thing, it is _known to be possible_; it's not in the same league as the semantics problems that I'm talking about.
nesting functions is pythonic?... looks like a mess to me. ~~function~~ method chaining on the other hand: ls().grep("abc123").wc("-l") that would be nice. *implementing it is a different story, of course.* EDIT: put emphasis on part of my comment, that indicates i read the above comment. also, i did not comment on overloading operators, just on the uglyness that is `ls(grep("abc123", wc("-l")))`.
 funds = withdraw_funds_from_client_account() best_opportunities = map_reduce(find_opportunities, funds) # BA-DUM-TSCHHHH deposit_funds(best_opportunities) If `map_reduce` is implemented using the same abstraction, then you're fucked, because it sneakily commits your transaction as well. 
OP, pbs must be imported. That bug, you're running it, not importing it. pbs needs to know from where it was imported so it can do the things that it is supposed to. The developer should check to make sure the module was imported. Also pbs only works under Python 2 currently.
http://saltstack.org/topics/ &gt;The networking layer is built with the excellent ZeroMQ networking library This makes it awesome. 
There is nothing pythonic about this. The whole point is to get the good parts of bash and the good parts of python together in one place.
are you suggesting the waterfall model?
Why are you so defensive? I'm suggesting thinking before coding, what's wrong with that? And of all things you might want to implement, STM in an imperative language is something that definitely requires some hard thinking before coding. Armins' blog posts make an impression that he hadn't thought the hard parts through, but is getting ready to tackle the easy but time-consuming parts, that's worrying. I'm not in a position to command him to stop and think, obviously. But it would be nice if someone like you recognized that the problems I'm talking about here are genuine and told him about them. I don't think he wants to waste his time solving easy problems before hitting a showstopper either, showstoppers must be dealt with first, that would shape the way the easy problems must be solved.
A while back someone did post something that let you use python constructs like dictionaries in bash. Forget the name though
just a regular-old import pbs will do :)
I updated an issue with some details, let me know how it works out for you: https://github.com/amoffat/pbs/issues/1
Still doesn't work: * test.py: https://gist.github.com/1616928 * output when running test.py: https://gist.github.com/1616930
don't "from pbs import *" just "import pbs"
Thanks, added a comment :)
You can't actually catch exceptions like that though. You'd have to do this: try: (...) except ErrorReturnCode, e: if e.code == 1: pass elif e.code == 2: pass elif e.code == 3: pass Or the way that it's done now: try: (...) except ErrorReturnCode_1, e: pass except ErrorReturnCode_2, e: pass except ErrorReturnCode_3, e: pass Saves a line and an indentation level.
Uhm, this is nothing special, right? There is: * `os.listdir()` * `os.getenv()` * `max_length = max(map(len, f)); f.seek(0); filter(lambda x: len(x) == max_length, f)` * `urllib` * `subprocess` + return codes * `sys.argv` * `time.sleep`
These are Methods, not Functions! You would need a common Datatype for all these Wrappers. I pointed that out in my posting. And yes, it is pythonic to call functions and pass parameters. Overloading operators ist shurely not the pythonic way.
&gt; Armins' blog posts make an impression that he hadn't thought the hard parts through, but is getting ready to tackle the easy but time-consuming parts, that's worrying. What made you think that? I'm genuinely interested in the answer, because I know armin and I might read a lot between the lines. EDIT: also, can you clarify what's easy, but time consuming and what's actually complex?
Indeed, the proposed model does not allow to do that. This is exactly the problem with all event-based frameworks -- you need to adhere to the global standard for event dispatch and you cannot "just" have a library function that has the internal incompatible event scheduler. This is a limitation and this is precisely what's in the proposal.
This release was out over 10 days ago, but I just want to make sure it's noticed here because PySide is a great library :-)
just an update, you can now run pbs.py as a standalone repl, or import from the python shell
It gives a much neater interface to those, to the point of making it worthwhile to use Python where previously it made more sense to use bash.
Erm, not in that trivial of a sense. More like ways to manage whitespace when running `python -c`, or inline, non-contiguous stateful python.
I think it's pretty cool. Not sure I'd ever really use it, but cool nonetheless. The only thing I don't really like is the piping. I'd rather do this: print glob('*') | du('-sb') | sort('-rn') than this: print sort(du(glob("*"), "-sb"), "-rn") As the latter is, literally, backwards (compared to shell syntax). But maybe getting the piping to work the same way was too difficult in this context (and, admittedly, not very Pythonesque, I guess).
I'd be interested depending on the kind of project you want to do.
&gt; you need to adhere to the global standard for event dispatch and you cannot "just" have a library function that has the internal incompatible event scheduler. No, my entire point here is that if your `map_reduce` library uses this exact event scheduler, then in fucks all your shit up, pardon my French. funds = withdraw_funds_from_client_account() best_opportunities = map_reduce(find_opportunities, funds) # BA-DUM-TSCHHHH deposit_funds(best_opportunities) "BA-DUM-TSCHHHH" is where a function you've called SUDDENLY committed your transaction. Because you don't have nested transactions, it's all flattened. So now the entire world sees the wrong balance on that account. No nested transactions == no library functions using STM, _your_ STM. I'm sorry, but maybe you should give yourself at least ten minutes to think about what I've written before replying, because otherwise you make incredibly clueless comments like that one. Sorry.
PySide was originally started because of licensing "issues". PyQT is under the GPL, which means that any software that you write using PyQT, will also have to be GPL *unless* you purchase a proprietary-friendly license from the PyQT people (that's how they sustained themselves). PySide was (I think) started by Nokia and licensed under a more "proprietary-friendly" license (i.e the LGPL).
&gt; also, can you clarify what's easy, but time consuming and what's actually complex? This: &gt; Make no mistake, making an STM engine that performs within 5x slowdown compared to vanilla PyPy is not a hard problem. It's time consuming, it's, like, hard to implement, but it can be done, MSR guys did the similar thing, it is known to be possible; it's not in the same league as the semantics problems that I'm talking about. ------------- &gt; What made you think that? I'm genuinely interested in the answer, because I know armin and I might read a lot between the lines. This, among other things: &gt; and goals are modest (2-5x slowdown for the serial case is fine for example). I repeat, for the third time, I think: implementing the entire shadowing machinery with 2-5x slowdown IS NOT anywhere in the same league as the really hard problems, the problems related to inventing proper semantics for STM in an imperative language. MSR guys solved the easy problem, they have made an alternative CLR implementation which supported transactions, logging all reads and postponing all writes, with acceptable performance. It can be done, no shit, Sherlock. And it would be time-consuming to do, and interesting, too, but ultimately a waste of time, because: Then you hit the REALLY HARD problems. Like, you have all this machinery, but you don't know what to do with it, because whatever you do, it makes extremely easy for an application programmer to fuck up, and extremely hard to solve some common problems correctly. That spells "failure". That's why the MSR project was discontinued. So you should solve the known hard problems first, at least on paper. The referenced Armin's blog post doesn't acknowledge the existence of any of the hard problems, you here _don't understand_ my explanations of some of the hard problems, WTF? 
OK, maybe casual was the wrong word. I only mean that this is not something which has to be a huge deal. I think what I'm describing is more recreational; I want to work on this a lot, and I plan on working to make this successful.
I know, you're right, and especially with programming everyone has their own idea of how to do the thing, even if they each agree on the thing to do. That being said, I never collaborate with others and I though it was be interesting to see how that would work, and I guess I would be open to working on anything, as the process is more important to me than the result.
Well, we know what to do with it. We'll use it for event-based loops to have transactions around events.
I have far more ideas and active projects than I have time to support. Why not create a website to match time-poor people with ideas with time-rich people looking for projects to contribute to?
Lets make a reddit bot that does some form of useful commenting for subreddits. What say you?
Sounds interesting, are you working on this or is it just an idea?
This code is godawful. If it were more readable I could maybe understand what you're trying to debug.
I'm interested as well! :D Keep me updated please~
I've been doing that off and on for a few years, I've solved 71 at this point, although I haven't been there in a while.
You have the "not finding a true practical application for programming, and thne abandoning it for a few months" down perfectly. I've tried to learn to program over the last 2 years, and I can never stick with it. I learn all of the loops, and methods, and how to use classes and everything, but what do I do with it? People always say "Think of something small and just make it." What am I supposed to make? Other than making something count from 1-10, what the hell do programs *do?* I obviously don't have the knowledge to make something huge like a browser or word processor... what's something small that's possible to make? Lately I've been messing around with text-based adventures... better than nothing, I suppose.
Right that's exactly how I feel, and I think there are a lot of people like us. I've tried changing languages and trying out new ones, which is interesting for a bit, but then each gets old. The problem, I think, is that there are really basic small programs like counting, or even simple games which are too basic for us, as well as really large, complicated projects which we can't jump into, or even work off of. There is really very little in between, which is what this is for!
In my experience as an Electrical Engineer, python is a tool to make you work better. It opens doors that would have been hard or impossible to do previously, and it allows you to quickly get where you're going. I'll use a couple examples to make my point: 1) We were working on an Android system and wanted to check the processor usage. Coworker spit out the PIDs and the memory usage, I graphed them in python, and it allowed us to figure out what was going on underneath. 2) Doing some audio stuff, python allowed me to easily plot the raw data and the fourier transform of the data. This allowed me to see the frequencies present due to the audio signal and the background (by moving around). 3) Working with some weird firmware, python allowed me to take the bitmap strings, rearrange them in the 'normal' way, visualize the images, modify if necessary, and spit the image back out in a bitmap string that the firmware liked. It's simple stuff. I don't plan out huge programming projects that take months (although I would like to, I don't have enough experience yet), but it's finding ways in which python can make my life easier or allow me to do things that I otherwise wouldn't do. I can't sit there and think of projects, I'll open up Spyder and just stare at the screen, but given other sources of information I can quickly find ways to leverage python to get tasks done.
Lets do it. somewhere on freenode? I am very new to IRC
Wow, I have a long way to go. I'm wondering if it's even worth it -_-
haha yah me too. But ok join the kcazyz channel on freenode
http://www.bravoserver.org/ Needs help ^ It's a custom minecraft server.
That's not helpful!
I'm not trying to debug anything. I'm asking a question about [ A Hithchhiker's guide to 'Fractal-Based' Function Approximation and Image Compression.](http://links.uwaterloo.ca/papers/waterloo/vr95.pdf) Read the article.
Why not pick an open source project that you like and fix some of their bugs? It's collaboration, and you'll know that what you're doing is actually useful to people. Also, it's a good way to start making a name for yourself.
I would counter by asking you what you think you would learn more from: being familiar with something you write yourself, or being familiar with something written by people who will undoubtedly have done things you wouldn't have thought of?
I am working on jazzchanges.net, and would love some contributors that are into music. Code here: https://github.com/jazzchanges/jazzchanges
Well that's the point of collaborating with someone. I've never done this before, so all my experience is my way of doing things, it would just be easier to do a collaboration when you are sure that other people are committed to it and can talk with them about it freely.
if your mapreduce needs global state within map or reduce its not mapreduce as known, else the proposed model already fits pretty much anything that resembles an actor model can be speed up with the proposed approach there is no point in iterating over use cases that are deliberately in contrast to that context just to make a already known point
Methods and functions are the same thing, and he already has a common datatype - if you looked at the source, you'd see a Command class that wraps everything. If it wasn't Pythonic to overload operators, why is it so [easy](http://docs.python.org/reference/datamodel.html#object.__add__)?
[wxFormBuilder](http://wxformbuilder.org/) generates python code as well. It is also extremely easy to use. If you have not tried it out I highly recommend it.
Not sure why you're getting down voted, this looks like a solution looking for a problem. It also pollutes the global namespace, which is...not recommended (import this). I'd be interested to see use cases where this is superior.
This is a great idea. Don't sign me up just yet, but I'd definitely be interested at some point in the future. Whatever you end up doing, it'd be cool if you posted updates in r/Python every so often. I'm sure that a lot of us would love to see the progress. And you know, there's a chance that it might not work out, as others have mentioned. Don't worry about that though, it'll be a learning experience no matter what.
what about a falling sand clone? http://fallingsandgame.com/sand/ Edit: I mention this because I threw together a slow clone using pygame this weekend. [Can be seen here](http://www.danomagnum.com/files/fallingsand/fallingsand/)
Anyone got a more detailed changelog? What exactly is the new "type converter scheme"?
The recursion error has been fixed by appending the fractal functions to a list, the math says that the functions should be added f1(x) + f2(x) but now that I have a list of functions does set theory give me a better way to add the functions?
Don't forget to add that the main issue here is Qt itself being LGPL.
Interesting question. I never tried, but since this is Python we're dealing with, then I'm 99% sure it's possible. In the worst case it should be possible to create a wrapper that does framework-specific calls based on which framework can be imported.
Also note that PySide is LGPL. PyQt isn't.
Zemo is correct. You should study the [Data Model: Special Method Names](http://docs.python.org/reference/datamodel.html#special-method-names) section of the docs. For an example of operator overloading, you could study the code for [fractions.Fraction](http://hg.python.org/cpython/file/5d1c177c585b/Lib/fractions.py) from the standard library, but it's pretty complicated. For a simpler example, here's an old lesson on creating a [Fraction class](http://www.greenteapress.com/thinkpython/thinkCSpy/html/app02.html). 
Absolutely. I did it for several benchmarks and demos. [Differences between PySide and PyQt](http://developer.qt.nokia.com/wiki/Differences_Between_PySide_and_PyQt)
Me too via Qt Assistant, which has a great full text search, but how do you get to know that certain modules of Qt are not supported by PySide?
I've seen another one of these. This one's nice in that it's got some fallback in case the user doesn't have SciPy set up. Any plans for using it?
If you don't mind messing with the registry, it shouldn't be a problem. It depends on which type of entity you want the python menu to appear on. You can make it appear on folders, on all files, or only on specific files. Here's a sample .reg file for this: Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\*\shell\Python Script\command] @="\"C:\\Program Files\\ActiveState\\Python27\\pythonw.exe\" C:\\Users\\GSchizas\\Desktop\\cm.py \"%1\"" and my sample cm.py: import win32api, sys win32api.MessageBox(0, 'You clicked on ' + sys.argv[1], 'Context Menu') This method works for all versions of Windows, even Windows 95 (the *.reg format was a bit different, but the concept is the same).
Hi equalx, I'm the author of this project. What do you mean by "using it"? "trueskill" is already using SciPy if it is installed.
Your regedit should look something like this: http://i.snag.gy/lgoSs.jpg
2nd try with fixes [http://idolines.com/2012/01/16/valid-html-crawler-take-2/](http://idolines.com/2012/01/16/valid-html-crawler-take-2/) thanks for the feedback btw
It seems cleaner to implement it like this, with no monkey-patch required: class BlackHole(object): def __init__(self, val): self.val = val def __add__(self, obj): return self.val def __radd__(self, obj): return self.__add__(obj)
Interesting idea, but I see some disadvantages that, for me, outweigh the benefits: * It's error prone if you mistype the "kind" argument, which could result in confused maintainers. When misspelling the name of a normal exception, there's an easy to fix NameError. * It breaks IDE support (no auto-completion of the exception name) * It breaks encapsulation of the exception class. If, for example, you have a list-like data structure that throws IndexError derivatives, but later on you decide that it should be a dictionary-like structure that throws KeyError derivatives, you have to change the "kind" string in each try-except block. * It does not allow for additional information in the exception class, which could be helpful for debugging and error handling.
I'm happy to make a game with a learner, I have some experience doing it, it's how I myself learned python! The game of pong is where we could work from if you still have the source. Git appears a bit scary at first, but it's very easy to learn and I can show you how it's done. I work on Windows and linux, so I can help for both platforms if you need it
On Windows 7 there's a folder for the 'send to' menu that you can customize, it will give your script the argument of the file you want. I don't think you'll be able to limit it to certain file types, though. `%APPDATA%\Microsoft\Windows\SendTo` put your script in there.
Some months ago, I've read that Nokia dropped this project. Was that true? If so, how are you and planning on surviving?
I think (s)he meant something along the lines of "What are you using this TrueSkill implementation for?".
Well, I was just studying the algorithm.
&gt; if your mapreduce needs global state within map or reduce its not mapreduce as known, else the proposed model already fits "My" mapreduce doesn't need global state. You are confused.
I believe Nokia was funding a smaller organisation, Indt/Openbossa to actually work on PySide. When Nokia cut the funding, they said they still intended to work on it (this was on the mailing list). What's in it for them, I'm not sure - perhaps they are using it in their own products.
PyQT still has a development team behind it (PySide lost funding). PyQT supports QT 4.8, whereas PySide is up to 4.7 with beta 4.8 support (I don't know if it compiles yet).
Your example of an unsuccessful game engine is funny. Games do have an event loop that is similar to what ui toolkits, reactor frameworks, all use. That doesn't make them suck. The callback spaghetti was because you didn't realise that games use discrete time, with changes all done in batches (movement, then damage) early in a render loop.
Ok, I didn't mean the binding mechanism itself by 'technically, but in a broader pratical sense. But why is the PySide binding better? I remember that they still need more ressources compared to SIP?
This would work: python &lt;&lt;'EOF' import this EOF If the Python needs stdin for something else: python /proc/self/fd/5 5&lt;&lt;'EOF' import this EOF 
Are you interested in web development? I'm making a simple search engine for files using flask and sqlite3. What about making your own filesystem? Using fuse, cache all accesses to a folder somewhere else. fusepy and such is helpful. Its just about overriding the posix open/fopen/stat calls and so on. Then we could add statistics to it since we intercept all accesses to a folder anyway 
Savings are not that huge (YUI Compressor is a pretty good minifier), but it may be more convenient to use Python solution and not introduce additional Java dependency in your Python project.
Honestly something like that (preferably for open source projects) sounds pretty cool and "easy" to get started with. I might do a bit of brainstorming to see if it's possible/viable to develop. Of course there's a good chance something like this already exists and thrives somewhere on the Internet.
Don't let the trauma colour your thinking on event loops. Event loops don't have callback spaghetti: the loop calls callbacks, callbacks are called from the loop. Calling other callbacks to do work in the event loop is breaking that high-level model, no doubt making it more difficult to reason about. When there's heavy work to be done, you ask the loop to schedule you an event in a few iterations. Instead of a reentrant model there are a few stacks and priority queues of the stuff you want to process next. Look at the [bare-bones example](https://bitbucket.org/arigo/arigo/src/default/hack/stm/transactionmodule/transaction.py) and at [test_add_more](https://bitbucket.org/arigo/arigo/src/default/hack/stm/transactionmodule/test_transaction.py).
I was bored so I re-worked your code a bit to nearer how I'd do it. I found a bug in that you didn't follow relative urls and also you didn't exclude fragments in urls, which might be intentional. http://pastebin.com/hwuQkees
Aha okay. What did you frame the implementation off of? The TS paper? Looks pretty solid!
YUI Compressor's selling point is compatibility, not best compression. Compare it with CC and Uglify.
&gt; So what, you really want people to bang their heads against the wall implementing nested STM? No, of course not. I'm worried about the apparent lack of the recognition of the fact that what they are trying to do is severely limited (and might have huge problems besides nested transactions (or lack thereof)), that's all. When Armin writes, *"Of course, transactional memory (TM) is not a perfect solution either. Right now, the biggest issue is the performance hit that comes from the software implementation (STM),"* I get really worried, and now you might understand, why.
This is for python news. For help try r/learnpython r/learnprogramming Or probably better: [stackoverflow.com](http://stackoverflow.com)
I have access to both windows and linux, and I'm not really sure which I prefer. I have a better keyboard on my Windows, so I'd enjoy that more, I think. I'm really not sure if I have the pong game anymore. I'll look. I've tried different languages at times, and made the start of pong in lots of them. Lua, C#, and Python I got the furthest, and I like python the most. I remember multiple instances of making pong in Python, so I'll find the best one.
I'm not a mod, but I don't have a problem with this sort of discussion. The occasional non-trivial "how would you..." or "I've got a great idea" makes for a bit of variety. I'd agree that this isn't exactly about 'learning' Python. SO is worth a shot for this sort of thing, but if you prefer r/Python, I'm not going to stop you.
Agreed, that is the most pythonic solution. 
Take advantage of python as a high level language. Look at OpenCV, LibSVM, Neurolab they all have python demos. Get PIL and if your on windows VidioCapture. Don't stay on the command line get a GUI like wxpython then take the simple example and just paste stuff into it. Use as much stuff that other people have written as possible 'Don't reinvent the wheel' its Open Source.
I think you're on the right track with process groups - generally the issue I've run into is getting the master process *not* to be in the same PGID as the children. Is that what you're running into? Rebuilding the tree by scraping ps seems like reinventing a wheel. 
The first line &gt; n &amp; 1 is a bitmask. It takes the least significant bit of the number. If you use this as a boolean, it's True if the bit is 1, and false if the bit is 0. If you not this, it's saying to do the If statement if the lowest bit is 0 (ie, it's divisible by 2). Numbers divisble by 2 are not prime, so it returns false immediately. The modulo has to divide the number and get the remainder of integer division. I would expect the bit mask to be faster, but the statements are identical. What it's doing is dividing by 2 and checking the remainder, if it's zero, it's divisible by 2 evenly. Bit shifting does something similar to bit masking. If you shift (not rotate) right, you move everything down by 1 and drop the lowest bit. This is identical to n/=2 because binary is base 2; similar to how if you dropped the 5 in 15, it would be like an integer division by 10 in base 10 (n/=10) or 1 truncated. 
I can't remember ever hearing about kivy. Looks pretty awesome.
You make some good points. I think the idea can be improved to address all of them: * That can be easily mitigated by requiring the creation of an error's superclass before any of its subclasses. For instance, Exc('calue/blah') could raise a NameError since Exc('calue') does not already exist, requiring you to either fix it as Exc('value/blah') or declaring Exc('calue') somewhere. This being said, the current behavior is not all that difficult to maintain: just compare the kind of error you catch to the kind of error that's being raised. * Good point. I don't use auto-completion anyway, but I can see the problem. Still, I very much like raising a different exception class at every site. Overriding an exception class's __ getitem __ to derive itself and return a fresh derived class would do the trick (i.e. raise MyException['xxx'](...)). * Following the previous point, it would be easy to make it so that Exc("a/b") == Exc("a")["b"] (maybe the latter syntax can replace the former). Then you can have MyExc = Exc("index"), and raise MyExc['...'], so now it's just as trivial as before to switch to KeyError derivatives. This being said, I must note one thing: switching the superclasses of your error classes is UI-breaking, and not acceptable in most cases. * Opening up an interface to the exception_classes dictionary would fix that issue. Just make a custom exception class and register it under an appropriate name. 
This is perfectly fine.
Some helpful pointers: if len(errors) == 0: return True else: return False can be shorted to the more succinct return len(errors) == 0 You do a bit of extra work in `extractLinks` when you set `linkList = []`, add items, then convert it to a set and back to a list. If you set `linkList = set()` to begin with, and use `linkList.add(link)` you'll have a unique set automatically. Also, why randomize the link order? If you're using it as a tool, and run it on your site and go through and fix a bunch of errors, you probably want them re-checked in the same order to compare log files. Since you're new to Python, you may want to read up on context managers, for example files: with open(logfile, 'a') as log: blah blah... log.write("my message") the context manager will handle closing the file automatically, regardless of how your code exits. You may also want to make the log file more useful by actually outputting the errors from Tidy -- so you know what to fix on your pages to make them validate.
when i get some time to day i will sit down and go thought every thing, thanks again for the feed back
I was just trying to figure out how to do this. This is genius - thanks! Do you know - if I try and develop an app and distribute it, are the registry changes at a .txt level the same across most installs of Windows 7? I.e. is "txtfile" the value that I want for adding this to all .txt files across multiple computers? Or would I need to search the registry for the value? And what about Windows XP?
I've also used [Inno Setup](http://www.jrsoftware.org/isinfo.php) which is a lot more powerful and user friendly. It makes somewhat larger install files (NSIS is really Spartan in both the UI and the size of the files), but I think it's worth it for being less of a pain to use.
This was originally posted in /r/software, but I realized this is probably the better spot for it. :P
I could have said a pluggable filesystem backend where a DB-FS would one of them. Why? Because it is the easiest way to make it "distributed" across multiple frontends; and you can store metadata such as permissions on files without messing with an actual filesystem. The downside is streaming files, which can simulated using tempfiles. Also stores using cassandra, mongodb or some dustributed FS could be interesting
I started playing around with Kivy over the weekend. So far, I've very impressed by the API. I am hoping to use it for a simulation project I'm working on.
OK, so let's pretend I'm switching from a more traditional 2D engine like to Cocos2D to the Kivy model. This is what I'm getting from the tutorial. Corrections/clarifications/debate welcome. The 'game loop' is just a scheduled callback in some top-level widget. Not sure how deterministic the scheduler is, need to integrate our physics dt properly. But this is usual handwavey stuff anyhow. Sprites are individual widgets, you probably want the game loop to update animation frames somehow. Looks like it will be called to redraw itself if loop updates pos/size. If you had some sort of tilemap you can use the scrollable widget in the framework to figure out how to manage the viewport. I'm not sure what the best strategy is here, though. I guess the sprites should be child widgets of the map, just hidden by the stencil? On a pos or size update you figure out which tiles are visible and issue a bunch of rectangle instructions? Or is better to just draw all the tiles and rely on the the stencil during pos updates?
Kinda neat. I tried it out, but honestly it's not a great framework/setup. I think I am going to go ahead and try to get something setup with Flask and Flask-FlatPages and Frozen-Flask.
Because by the time the list constructor is invoked, a generator has already been created to pass in as the argument. Whereas when you use a list comprehension, the parser recognizes that as a completely different kind of construct from a generator. Python does not generally do these kinds of optimizations because it is often impossible to determine in general that they are safe.
There is a MIT intro to CS class that's pretty good. Take a look: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/
Thanks for the link, I'm going to check this out :D
On Windows you can use a job object: http://msdn.microsoft.com/en-us/library/windows/desktop/ms684161%28v=vs.85%29.aspx . PyWin32 probably supports this. On Linux you can use a process group. Fork once, `os.setpgrp()` from the child (then exec as normal), then os.killpg(child_pid, ...) from the parent when the time comes, should do the trick.
That looks pretty cool, not sure it would work in my case, I pretty much need to support bash. But thanks, I've never heard of FTSH before.
I referred to http://www.moserware.com/2010/03/computing-your-skill.html and http://dl.dropbox.com/u/1083108/Moserware/Skill/The%20Math%20Behind%20TrueSkill.pdf
tl;dr Generators are not as fast because they are composed of objects and function calls. Primitive lists are faster. `list([a,b,...])` copies the inner list, there is an `O(n)` factor here. All of this makes sense. Also, use the ipython magic of `%timeit list(x*2 for x in xrange(1000))` saves having to use a lambda. If you are operating on sequences that are relatively small, using a fully materialized list is better. If your sequences are infinite or you are doing many transformation steps, generators save on CPU and memory. See, http://www.dabeaz.com/generators/ 
That's exactly what I'm getting, but I can't figure out why. That output is what happens when `time` isn't given a format (according to the manpages), but normal use of `time` seems to use a different style, even with the environment variable not set. And there's also the issue of no linebreaks... I'd like to see a breakdown of what exactly Popen is executing, but I have no idea how to do that.
Hello fellow Canuck!
Actually, `time` seems to be a [reserved word](http://www.gnu.org/software/bash/manual/bashref.html#index-time-36) in Bash, so the command `time` isn't quite the same as `/usr/bin/time`. Perhaps it actually works correctly? I'll test it out and get back to you. Edit: `time` prints to stderr, so that's why I'm getting an error message when I run it instead of the usual output. Any idea on how you want to handle that?
Just realized that for Linux, pstree would be great if only it returned a list of descendant child pid's instead of the visual tree graph. 
Awesome: running with sudo works! # test.py import pbs with sudo: print whoami() $ python test.py [sudo] password for user: root
I do this at work quite a bit, we use [killableprocess](http://benjamin.smedbergs.us/blog/2006-12-11/killableprocesspy/) 
This worked for me in one of my scripts. I was looking for the context entry to only come up for certain types of files (not sure if that applies to you, but in case it does): import os import sys def Install(menu_name='This is the name that shows up in the context menu'): '''Install registry entry for adding to context menu.''' import _winreg as wr for ext in ['.hex','.mcs']: # Check for extension handler override try: override = wr.QueryValue(wr.HKEY_CLASSES_ROOT, ext) if override: ext = override except WindowsError: pass keyVal = ext + '\\Shell\\' + menu_name + '\\command' try: key = wr.OpenKey(wr.HKEY_CLASSES_ROOT, keyVal, 0, wr.KEY_ALL_ACCESS) except WindowsError: key = wr.CreateKey(wr.HKEY_CLASSES_ROOT, keyVal) regEntry = (r'"C:\Python27\pythonw.exe" "' + os.getcwd() + r'\YourPythonScript.py" "%1"') wr.SetValueEx(key, '', 0, wr.REG_SZ, regEntry) wr.CloseKey(key) if __name__ == "__main__": if len(sys.argv) == 1: Install() elif len(sys.argv) == 2: inputFilename = sys.argv[1] DoStuff(inputFilename)
[Dive into Python](http://diveintopython3.ep.io)
Thanks for this! I'm gonna sift through the HTML version and buy the PDF if it turns out to be good!
Most of the speed difference here has to do with whether or not Python can determine the length of the iterator passed to the list constructor or list comprehension. xrange has a __len__, generator expressions do not. If you look at how list objects are implemented in Objects/listobject.c -- when the length of the iterator can be determined, it only has to resize the list once to the new size. If the length is unknown, it has to resize the list again and again as it pulls items out of the generator.
[Python Fundamentals Tutorial](http://marakana.com/bookshelf/python_fundamentals_tutorial/index.html) [PythonLearn ](http://www.pythonlearn.com/) [Python Documentation](http://www.python.org/doc/) [learnpython.org's interactive Python tutorial](http://www.learnpython.org/) [Google's Python Class](http://code.google.com/edu/languages/google-python-class/)
http://inventwithpython.com http://greenteapress.com/thinkpython/ Are more geared towards learning your first language. 
Was going to mention Think Python - it's pretty good.
I really like [effbot's](http://effbot.org/zone/) tutorials, for some reason they just click with me. That one has a lot of information, but something like his [lists](http://effbot.org/zone/python-list.htm#overview) is pretty concise and clear.
The littlest hobo is public domain. :) It's a very old show.
built in data structures summary: http://stsdas.stsci.edu/pyraf/doc.old/python_quick_tour/PyTuples.html woodyb is right the official docs are great
It is interesting and I am attracted to it... if I only could get what good kivy is for, is it just a collection of pygame+other libs or what? What does it do? Where are the kivy specific things vs other libraries? EDIT: So I wanted to try it out, and got this when doing pip install kivy inside a virtualenv Downloading/unpacking kivy Real name of requirement kivy is Kivy Downloading Kivy-1.0.9.tar.gz (7.4Mb): 7.4Mb downloaded Running setup.py egg_info for package kivy Traceback (most recent call last): File "&lt;string&gt;", line 14, in &lt;module&gt; File "/home/anto/.virtualenvs/kivy_exampl1/build/kivy/setup.py", line 12 print '\nCython is missing, its required for compiling kivy !\n\n' ^ SyntaxError: invalid syntax Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 14, in &lt;module&gt; File "/home/anto/.virtualenvs/kivy_exampl1/build/kivy/setup.py", line 12 print '\nCython is missing, its required for compiling kivy !\n\n' 
list comprehension does not call len
The hive mind does not appreciate you reviewing a book by induction.
Thanks for this :D will check out the documentation after I've learned the basics. 
As an aside: Look at the sidebar for book suggestions.
this; i just did this and its super helpful
Are you sure? Here in the US, anything newer than Mickey Mouse is locked down until the end of time. Has Canada been able to stay the mouse's clutching paws?
Paste the returned HTML. My guess is it's padding the cells with blank characters. (non breaking spaces)
[returned html](http://pastebin.com/YCcLsiQY) It seems it pastes the values, no spaces edit: i saw no width tag on some of the td's, so I added it on the script, but to no avail :( edit2: I also corrected a broken &lt;/select&gt; tag, no miracle happened, though
Why are all the "values" in HTML "text" input tags? I would be willing to bet those input tags are being rendered out at a default size, forcing your table cells to be bigger than they need to be. 
oh, my, bingo. Input size=5 (characters) did the trick. Ty, smencer, you saved me hours of desperation. I only wish I came here before.
As I said before, I wish I posted this here earlier, before wasting hours of clueless coding 
awesome :D
&gt; As you can see SlimIt performs better and itâ€™s pure Python.
Certainly a significant improvement. Congratulations. I don't see anything which restricts this to one domain so one advantage of taking a random url from the queue is to avoid repeatedly hitting the same domain very quickly. Probably not an issue with the current script but if adjusted to using threading/multi-processing/multiple workers could be necessary. Not sure if this is what knightZeRo had in mind though.
I think you missed 2 options: &gt;&gt;&gt; from timeit import timeit &gt;&gt;&gt; timeit(lambda:[x*2 for x in xrange(6)]) 1.4967827414384056 &gt;&gt;&gt; timeit(lambda:list(x*2 for x in xrange(6))) 3.040847566654186 &gt;&gt;&gt; timeit(lambda:list([x*2 for x in xrange(6)])) 2.0775102969555572 &gt;&gt;&gt; timeit(lambda:tuple(x*2 for x in xrange(6))) 2.706134777307337 &gt;&gt;&gt; timeit(lambda:tuple([x*2 for x in xrange(6)])) 1.8105202722812663 &gt;&gt;&gt; timeit(lambda:[i for i in (x*2 for x in xrange(6))]) 2.506493082558052 &gt;&gt;&gt; timeit(lambda:(x*2 for x in xrange(6))) 1.3047691465768025 I know that a list isn't actually generated on the last line. Still, if you needed to set up a ton of these at once and didn't mind to iterate slowly later - making generators wouldn't be a bad idea.
I would say the point of this contest is to acquire new users. Users == Testers. So, you found a bug. They have issue tracker on github where you can submit it (or even provide a patch) https://github.com/kivy/kivy/issues
[weakref.WeakKeyDictionary](http://docs.python.org/library/weakref.html#weakref.WeakKeyDictionary) if your Python version has it.
You have a one-to-one lock to instance correspondence, so why don't keep the lock inside the instance? Something like this (not tested): def synchronized_with(syncprimitive): # use RLock for reentrancy, Lock for simple synchronization def decorator(original): def decorated(self,*args,**kwargs): try: lock = self._lock except AttributeError: lock = self._lock = syncprimitive() with lock: return original(self,*args,**kwargs) return decorated return decorator
Noice!
You probably need to install cython. Depending on your distro, make sure the dependencies are installed: http://kivy.org/docs/installation/installation-linux.html
You need to install cython, or it won't be able to compile the graphics and other kivy modules written in cython. Depending on your distro, make sure the dependencies are installed in case easy_insatll isn't getting them: http://kivy.org/docs/installation/installation-linux.html
i've noticed that defaultdicts can make coding much easier but can easily balloon in size. each time you query a key, it gets added. if you do this many times, it can grow in size immensely. i sometimes clear out unneeded entries in defaultdict. could that be doing it for you?
Well, if you submit the bug report you're pretty much contributing. I think that's a pretty good point. 
OK, I've been thinking about your problem here a bit. Bear me out: I'm someone with a history of over-engineering solutions, and I think you might be doing that here. I want to sell you on the advantages of forgetting this decorator and instead using the following pattern: class Foo(object): def __init__(self): self._method1_lock = RLock() self._method2_lock = RLock() def method1(self): with self._method1_lock: ... def method2(self): with self._method2_lock: ... Advantages of doing this instead of making a synchronized decorator: * It's **more clear**. Anyone who knows python can look at that and know immediately what it is doing, whereas anyone unfamiliar with your application (including possibly yourself in 6 months) will have to first, find the decorator definition, and second, wade through it, to understand what is going on. * It's **more flexible**. If you decide that only a critical section of a function needs to be locked, changing that is trivial if you define your class as above. With the synchronized decorator, you will have to do some finagling. If you decide that two methods need to be synchronized with the same lock, this is also trivial to change. * It's **faster**. You avoid the extra function call and map lookup overhead. Maybe it's not that much faster, but if you're already considering using (ugh) Locks instead of RLocks, I guess you care about this. * It's **easier to debug**. It's less confusing to step through with a debugger, since you avoid the inner decorator, and locks all have explicit names. If you ever have a deadlock and want to print the state of locks in your system, all those locks are accessible and have names, whereas with the decorator method it is really tough to find the locks, and then figure out what they refer to.
sounds way cool. what are you simulating?
&gt; It's faster. You avoid the extra function call and map lookup overhead. Maybe it's not that much faster, but if you're already considering using (ugh) Locks instead of RLocks, I guess you care about this. I grant you that: it is absolutely *faster* to manually lock and unlock. You are absolutely correct on that.
&gt; It's easier to debug. It's less confusing to step through with a debugger, since you avoid the inner decorator, and locks all have explicit names. If you ever have a deadlock and want to print the state of locks in your system, all those locks are accessible and have names, whereas with the decorator method it is really tough to find the locks, and then figure out what they refer to. That may very well be true too.
Yep, heading out myself. Last year was my first PyCon. As for getting the most, it's not too hard. The conference is packed. There will be open spaces and interesting things after the conference so make sure you plan to stick around most evenings. As for the sprints, they'll let the teams sprinting get up on stage and give a brief summary on what they're working on. Just find something you're interested in and show up. Everyone is really cool and they'll find something where you can help and get started. 
Yes okay, fine I will. But what is kivy for, there is even a mention of a kivy language on the architecture page. Whats that about? I would like to use it, but I dont see what problem it solves for me right now. Perhaps its the easy wrapper for opengl calls? The "multitouch" thing? Having everything/all the APIs in one place/super-api? Have you seen the .pyx files before, any clues how I can solve them before I put an issue on github? This is probably an issue with the pip/easy_install setup files since depending on which one I use different errors are produced. EDIT: DISREGARD THIS; I SAW YOUR PREVIOUS POST SOMEWHERE 
&gt; How do I find a good team for that? On the last day after the last talks and closing stuff, we have each project who wants to sprint come up on stage and do a quick introduction of what their project is, who they are, and what they'll be working on. If you find something you like, go check them out. We did that last year and I think it worked well, so I imagine we'll have it this year again. Another thing people have done is just walk around in the sprint area and see what people are up to. Typically there's a board mapping out what sprints are in what room, then just ask people coming out of the room or in the hallway what's up.
Yep, that was the problem. Installed Cython in the virtualenv too, and I have the requirements installed from the packet manager. Now I get a gcc: error: /home/me/.virtualenvs/example1_kivy/build/kivy/kivy/event.c: No such file or directory And thats because the setup script creates another build directory inside the build directory, like this, /home/me/.virtualenvs/hey_kivy/build/kivy/ here is the setup.py and I guess its run from here by pip then I see running build_ext Generate config.h Generate config.pxi building 'kivy.event' extension creating build/temp.linux-x86_64-2.7 creating build/temp.linux-x86_64-2.7/home creating /home/me/.virtualenvs/hey_kivy/ alright you see the error. So now I have /home/me/.virtualenvs/hey_kivy/build/kivy/build/temp.linux-x86_64-2.7/home/me/.virtualenvs/hey_kivy/build/kivy 
I'll be attending this year for the second time. I attended (and spoke) last year, but this year I'll only be presenting a poster and representing myself (as I could not get my employer to pay again). I found PyCon to be overwhelming in a good way. All the talks I attended were great, and I really met an array of interesting people. I highly recommend attending any of the open-space talks, even if you're only interested in a topic, not actually heavily invested in whatever. You'll end up meeting plenty of people who might be able to expand your horizons. I didn't attend any sprints last year, so I can't really speak to those. 
Yes, of course, sure. But it's unacceptable when you try to visualise things like performance.
sorry. should have specified that. yes, it is the intended behavior. but if you query a lot of keys in a large loop, you can end up with a dictionary with hundreds of thousands of keys, at which point dictionaries are not very efficient.
&gt; but if you query a lot of keys in a large loop, you can end up with a dictionary with hundreds of thousands of keys, at which point dictionaries are not very efficient. Mmm, how is that (*valid*) observation relevant to the code pasted above?
yeah unfortunately the only way to not "poison" the namespace is to search your entire system for all executables in your PATH, wrap them in functions, and map them to the module's attributes
I am coming, last year was my first pycon. For getting the most, I say you talk to people, some of the most interesting and fun conversations I had was outside the sessions, after the day was over. If its your first time and you don't know anyone. Just try to volunteer. There is a lot of work that needs to be done behind the scenes and its a good way to meet people too. Raymond Hettinger and David Beazley's talks are really good. There are other great speakers too but those are the ones that I liked the most. Is anyone interesting in sharing a hotel room? I am trying to get my employer to pay but if that does not work out I would be up for sharing a hotel room, to save expenses
I actually quite like Aptana studio...
Good work. For sharing larger code samples like this, I'd recommend putting your code in a [gist](https://gist.github.com/) or some other sort of pastebin. This is especially true of Python code (whitespace sensitive) and will prevent any potential mangling of your code by Reddit's forum software. Gist has the added benefit to allow people to fork your code and let you track who has forked it.
Never been to one and can't make it this year. Maybe next year. I'd love to see a recap in r/python when you come back. Have fun!
Well that's entirely subjective of course, but I'm happy that you like it too! :)
Frameworks work like that, automagically, its not a library that you call and make it do things, frameworks do things to your code, and so they expect that you have this and that in place. 2. Is better with later releases. Concerning project/directory structure. 3. Thank god for no OO, just look at any Java framework and youll see why. 
PyCharm hands up
PyCharm and Vim
1. It is better now, many things is broken out in its own modules. 2. This is just the norm, i think you kan name your classes pretty much what you want. There is some exceptions, like **templatetags/** 3. With class based views you have more objects, but why should everything be objects? There is no forced file structure, all you need is a settings.py-file 4. That is wrong, I have written **myapp.models import mymodel** since I started using Django. So it is not as bad as you say.
Dive into Python is for people who already have programming experience. OP, if you're inclined to read, look at either How to think like a computer scientist or Learn Python the Hard Way. I used the first and it was great.
This is my one major gripe with using white space for code blocks, it's too easy for code to get mangled on the web.
What's the point of being pythonic or not? Does the api feel natural for you or not? If yes, it's fine for you, if not use something else.
It's a great start. You'll need to start throwing out bad results somehow. Maybe match a world list up until a certain number of letters and return good matches. It's easy to exhaust all of a user's memory in the current form, using around 20 characters.
I think the thing that makes it unpythonic how you have a settings.py file. You indirectly access the functionality. There isn't any central object that is easily apparent that you can extend. If you were new to Django, where do you begin? Python libraries in general have a central object that you can inspect and go from there. Django hides this for the most part. For number 4, I my have made that statement too general. I should have been more clear in that some things Django makes you do this: https://docs.djangoproject.com/en/dev/topics/auth/#auth-profiles
1. You can replace the templating system, the authentication system, etc. There's not that much else that you SHOULD replace. Until there's something you want to replace but can't, I'm not sure anything else needs to be replaced. 2. Isn't it supposed to be this way? Things are supposed to be put into folders. It's way better than the Java style, that's for sure (and I see someone else has mentioned this as well). 3. ORM. And why does it NEED to be object-oriented? Python supports a wide variety of programming paradigms and I fail to see why Django's not using this "application object" is an issue. Anyway, there is an application object, but it's not handled directly by your code. 4. &gt;one would assume that I would use the python import structure of from myapp.models import mymodel but instead I have to do this: from myapp import mymodel. What is this? What is this indeed? You have to do the former; you cannot do the latter. I don't know how you got the latter to work, but I'd like to know how. Anyway, Django is widely considered the most Pythonic of Python web frameworks. Or I think it was, anyway.
In that case, you should probably explain what the foolish parts were. You can't just quote that line and be done with it.
Also means that you end up writing the same shit every application you make, and have to develop your own way of, for instance, having sub-modules for your application. The great thing about Django is that you can hire a programmer that knows *Django* and they will be able to jump in and know where things are. Whereas if your application was built in Flask, they'd have to learn your weird ass way of doing things like routing (because one file with all your routes in for a large application really isn't that great). I've actually [started work](http://github.com/radiosilence/suave) (very very early stages) on a framework that uses Flask but has consistent ways of doing things like routing and "apps", the idea being that it elegantly strings together Flask, SQLAlchemy, and will also provide the ability to have plugins for high stack tools like CoffeeScript or SCSS. http://readthedocs.org/docs/suave/en/latest/quickstart.html That's the idea behind my routing (I'm determined to document, document, *document*) for it.
Excellent info, thanks! I'll see if I can figure out the stuffing thing now before I book my ticket. I've emailed someone about volunteering and they told me I would receive another email in the future with opportunities. I find work like that really helps with meeting people. Also, another question: In previous years has anyone made an effort to collect all of the social media discussions and put them in one place? For instance, you can simply look under the hashtag #PyCon but I'm sure you would be missing material under different hashtags or on Facebook or Google+, etc. I've been thinking that might make a great project for me, a live feed of all relevant PyCon discussions on the web. Has anything similar been done and do you think it would be useful? If someone is already doing it I would be quite happy to just participate in it!
[Geany](http://www.geany.org/) - I find it a good balance between simple text editors and crowded IDEs.
You don't have to use Django's auth system, or User model, FYI. There's some of that modularity for you.
Pythonic, one of those vague words like Manly, is in the eye of the beholder; however, straight from the Zen of Python: &gt; Simple is better than complex. It is simple to write the kinds of applications Django was made for the way Django is, and it would be more complicated to split Django in to even more modular parts than it already is, which is several. Most important website-level systems in Django are modular. &gt; Although practicality beats purity. It is easier for a paid professional to 'jump into' and do their job, and this is among the reasons Django is one of the most used Python web frameworks out there. If you say it's not Pythonic, then it's not Pythonic to you, but it's a damn good framework to do a job in. I say this as a full time Django developer for a project of 21,865 lines of Python code. Source: http://www.python.org/dev/peps/pep-0020/
Just discovered this when a recent [tips and tricks](http://www.reddit.com/r/programming/comments/o6aeb/sublime_text_2_demo_of_features_pdf/) post was featured on Reddit. My favorites are : * **Ctrl + D** to **"select more"** (be careful to escape out of this action every time, though, or you'll see some unexpected results) * and the **Ctrl + P** to preview a file in the current project * and **Ctrl + Shift + p** to access basically any setting or menu option or config you need.
Right, but in that case you should also almost always have error bars or some indication of the precision or uncertainty of the measurements.
Yep. Canada is great! "Crown copyright for published works generally lasts for 50 years since the first publication (this is true not only for the UK but also e.g. for Canada or Australia)." - Wikipedia [http://en.wikipedia.org/wiki/Wikipedia:Public_domain] For patents it is 20 years. :)
Why in this case? Suppose the runtimes of the programs in the OP were those numbers, would you expect him to indicate the error? They would be measured in micro-seconds. Whether you are using a zero-based graph or a non zero-based graph has everything to do with presentation and nothing to do with what you are measuring. And error bars are only included if they are significant, if the error is +-0.001%, they wouldn't even be resolved on your screen or a printout.
To be fair the issue gets somewhat complicated, which is why threading in Python isn't worse than useless (as tests of this nature would imply). That said, he could have simply explained that for the operations used in this example, which need the GIL to do their work (there are modules like zlib and hashlib that release the GIL while crunching data), only one thread runs at a time, meanwhile, for CPU-bound work, all the threads are constantly competing for that one GIL lock.
&gt; Note that, according to Raymond[1], your code is neither thread safe if syncprimitive is a python object It's a threading.Lock / RLock. I believe those are not pure python objects. This is why I chose defaultdict with those two syncprimitives.
So metaclasses can be useful here, but that would only be useful for, hum, classes where a single lock synchronize()s some or all of its methods. Which is different semantics from my example. Though, arguably, if you have instances that need two different locks for two different methods, perhaps the class needs to be rethought. Also, the metaclass solution does not let me choose the synchro primitive.
Geany. Also take a look at ipython notebooks (http://ipython.org/ipython-doc/stable/interactive/htmlnotebook.html), they are pretty awesome.
Pythonic? That kinda doesn't mean anything, in this context. It's sort of like saying something is "All American." That said, Django has a lot of warts at this point. Part of the problem is that when Django was made, there weren't good templating systems or really any other frameworks like it, they had to build everything themselves and forge the trail. I was at the ChiPy meeting when Adrian first unearthed it and gave a presentation, and the end of which I was seriously about to cry it was so awesome. But now of course, we have better developed ideas and are listening to Ian Bicking more-- always listen to Ian Bicking more. So anyway, there's a lot that Django gets right, but a lot of places Django could be better. I would like to see a total refactor, going back to square one. Remake it with wsgi as a central idea, maybe even build it on top of Werkzeug; spin off the templating system as its own thing, taking the optimization ideas from Jinja2; rewrite the ORM on top of SQLAlchemy, with the same awesome object interface; and rewrite the admin to be *that* much more impressive so that even people new to programming could make a site. All possible, all doable; I'll be the first to show up for the sprints.
Don't forget to give [SublimeLinter](https://github.com/Kronuz/SublimeLinter) and [SublimeRope](https://github.com/JulianEberius/SublimeRope) a try, for greater Python fun!
&gt; *Frameworks work like that*, automagically, its not a library that you call and make it do things, frameworks do things to your code, and so they expect that you have this and that in place. This is *not* true. A framework provides one differentiating fundamental feature from a library: *Inversion of control*. That the framework provides this functionality by being a set of interchangeable modules or a monolith is an *entirely separate concern* from the primary feature of all frameworks (IoC). As an example, you have Pyramid (a Python framework), which is entirely modular, and whose parts can be arbitrarily swapped, but which *still provides* inversion of control. TLDR: just because a framework calls your code, doesn't mean it has to be monolithic.
well since no one mentioned it..[SciTE](http://www.scintilla.org/SciTE.html) It's free and works well.
It wouldn't be per request, it would be on application startup (and could be only done if the source had changed).
Well the whole point of writing something that's isn't completely explicit is that you give it good documentation, and save writing unnecessary code (ala Django) That said, Blueprints do look interesting so I'll look into using those (perhaps abstracting them for my mount functionality as it looks pretty much the same).
I still think there is a fundamental pragmatic ease of use that Django solves that no other framework currently gets close to. But of course, the real secret sauce to Django is the documentation, which is fantastically well thought out. Pyramid is still mired in itself in many ways, and it all comes slopping out reading the documentation. It's almost as bad as the SQLAlchemy documentation. You get a sense that whatever you're trying to do is supported, if only you had some guide to the documentation. I much prefer Flask, which defines its limited scope, and sticks to it. Flask has some documentation problems as well, but generally it guides you through a very well thought out process. It leaves all the WSGI trivialities to Werkzeug and focuses on a strong api. If anything eclipses Django, it'll be Flask.
Dictionary to XML in 2 lines: import xmlrpclib as_xml = xmlrpclib.dumps(({'foo':'bar'},)) And loading: as_dict = xmlrpclib.loads(as_xml)[0][0] XML isn't as pretty, but that doesn't matter depending on what you're doing
First of all: in this case it probably doesn't make that big of a difference for interpreting the significance of the differences between performance levels here since the differences are countable in integer seconds. That said, don't assume that the differences are necessarily in microseconds, especially for the threaded cases where at least historically there were some race condition-ish behaviors. Even if all of this was run on a machine that was basically idle, all of this stuff is still being meted out time by a scheduler which has to share the system's resources between the operating system and other userland processes. When I've run tests similar to these ones on a relatively idle machine I've sometimes found standard deviations of hundreds of milliseconds on &lt;10 second runtimes. It's often the case that non-zero-based graphs are used so that hair-shaving differences in numerical values can be shown, and when this is the case it's completely unclear whether the differences are significant without a measure of uncertainty.
I didn't create convenience functions for standard utilities. The functions map to your system's binaries dynamically. It is a subprocess wrapper.
Sweet.
You can't. Project Euler are mostly math problems which are great for learning how to write alogrithms. However, there's much, much more to programming than writing alogrithms. I've coded some commercial applications in Python which implements maybe one algorithm in its 5000+ lines of code. Euler gives you a good grasp on the basic syntax, but you should learn more about python - function decorators, Classes, all kinds of string manipulations, class overrides, etc. Then you move onto GUI/web framework (if you want). 
Vim here also but I spent a lot of time setting up vim to my liking. 
A web framework must account for: * The web server. Is it CGI, async (plain HTTP like nginx), WSGI, or what? * The templating system. Do you want a PHP style "python in HTML" system or a simpler DSL? How will you make it modular, extendible, and extensible? What about form validation? What about JS and AJAX? * The ORM. How will this interact with the form validation? Will the web server know to 404 if there's no records found? How do you modify the schema? * The middleware. There's cachine (Reddis, memcached, HTTP caches, keep-alive?), headers, cookies, cookie security, SSL, throttling bad users, other security, rewrites, redirects, debugging, logging, and so on. EDIT: I totally forgot backups here. So does everyone else. Then they cry when it bites them. Oh, and APIs, code versions, deployment, and rollbacks. The whole thing does not scream "Pythonic", especially when it comes to handling errors (user, server, missing data), where everything has to interact. It's hard, and you won't find a simple, obvious solution. If you do, please tell us ;) I think Tornado does a better job, but it completely ignores the DB layer (which is a significant part of the complexity), forcing to roll your own form validation. IMO, you can do pretty stuff like form validation later, and just get the server secure for version 1.0 Also, Pythonic is not OO. It's more "pragmatic functional, with objects if you need them". But that's a whole new flame war.
If you're looking to learn python by way of problems, I would suggest the python challenge problems. It helped me a lot when I was new to python. http://www.pythonchallenge.com/
while this does technically work, it doesn't do a lot of things such as what happens if the value for the dictionary is an object other than a string/dict/list? what happens if you have a value thats just the string ' or &lt; ? thats what all of these seralizers such as xmlrpclib and lxml do for you, so if its just for simple stuff yes this works but it can also bite you in the ass
As zzzeek points out though, it's much better lately.
right it's not like there isn't a [master guide just like djangos](http://www.sqlalchemy.org/docs/), a [documentation overview](http://www.sqlalchemy.org/docs/intro.html#documentation-overview), a [search page](http://www.sqlalchemy.org/docs/search.html), [two](http://www.sqlalchemy.org/docs/orm/tutorial.html) [tutorials](http://www.sqlalchemy.org/docs/core/tutorial.html) that link out to everything, a crapton of [recipes](http://www.sqlalchemy.org/trac/wiki/UsageRecipes), a [FAQ](http://www.sqlalchemy.org/trac/wiki/FAQ) as well as the [most responsive mailing list anywhere](http://groups.google.com/group/sqlalchemy). But no. You needed to use SQLAlchemy one day, spent ten minutes with the docs not really reading it and couldn't find what you wanted. So now you get to shit on six years of work ! Have you written any docs ? Can I see some so I can shit on your work too ? 
A lot of online discussion happened on https://convore.com/pycon-2011/ which worked nicely to organize topics, although the site was was slow at times. Obviously that doesn't include posts from other social networks, but it did seem to me to be a central hub of online realtime discussion.
I'm really looking forward to going this year. Looking through the schedule, some of the talks I *really* want to see are on alternating tracks. How much time do you have between talks and how difficult is it to change rooms from one track to another? 
It sounds like you're treating Django like a library, when it's actually a framework. With libraries, as you said, you embed them in your application. But with frameworks, you embed your application inside them. Which one's better depends on the library/framework and what you're trying to accomplish. For example, Twisted and Django are both frameworks, but while I love Django, I absolutely hate Twisted, because with most of the applications where I need networking functionality, I don't want to rewrite into Twisted's paradigm.
Well said, could not agree more. 
I will be there and will be giving a talk. First time presenting but I've been to the conference several times. I second the comments recommending skipping talks if nothing peaks your interest. There's often something good going on in the open spaces. 
It could be we work with Python in very different ways. I spend far more time looking at the actual code than I do in the interactive session, so I would much rather have the code tell me what it is doing than a run-time modified docstring. Modifying the docstring in that way will not show up in the Sphinx documentation, anyway. I know the synchronized method thing is a Java thing, but I've never really understood the purpose of it. This could be just because I haven't (knowingly) worked in a domain where it makes sense. Typically I think of lock-protecting *data*, not methods, because if two individually synchronized methods access the same data, there's probably going to be problems. So usually I have what I think of as public methods that use a shared lock to access the data, which may handoff to private methods that don't need to bother locking. So maybe that's my programming question of the day: in what kind of situation do you care about only one thread running a particular method rather than only one thread accessing the data?
... but then its DONE. amirite?
&gt; How much time do you have between talks and how difficult is it to change rooms from one track to another? I want to say it's around 5 minutes. It's definitely enough time to head to the bathroom and grab a seat in the next room.
My apologies, giving a 2-line example using a library that kinda does the work for you made me think you were simply saying "you should do it this way"
&gt; Modifying the docstring in that way will not show up in the Sphinx documentation, anyway. Good to know. TIL. I thought Sphinx would actually load the computed docstrings of the modules in memory, rather than retardedly parse the modules and give you that. It seems so much more useful to just grow the docs out of the computed docstrings, especially for Python work consisting of dynamic programming.
Twisted should not be held up as an example of anything that's good or nice to use. It's effective at solving the problem it was designed to solve, but I feel like I'm jamming my dick into a blender the whole time.
&gt; I know DRY is a Ruby concept It's an everything concept and existed long before Ruby.
Nah, everybody re-implements something that's already been done. It's a good way to learn about it
&gt; So maybe that's my programming question of the day: in what kind of situation do you care about only one thread running a particular method rather than only one thread accessing the data? Probably in the case where an object is acting as a queued receiver of actions or data.
I'd say that Project Euler actually harms ones Python skills, there seems to be a bit of a thing for one-liners over there, and they are very un-Pythonic. Not only that, but pure algorithm solving tends to encourage single character variable names. Actually I'd go as far as to say that PE is the antithesis of good programming in general. Great brain exercises though.
&gt; Why is r/Python so against custom submissions? The submission doesn't even come close to guaranteeing valid XML
 dictToXml({'&gt; key':'value &amp; stuff'})
I did a major project with Twisted a year back, and I still have the dick scars to prove it.
I agree completely. I do the Project Euler problems for the fun/challenge, but doing them definitely won't cover even most of what you should know about Python. Still they teach valuables lessons. I wrote a Chrome extension for Reddit recently to give it a feature I like.. ended writing a recursive data structure that represents Reddit comment trees, and another fancy mapping algorithm to map a function over an array of data trees.. both concepts I learned while doing Project Euler problems. Those problems just make you think differently about programming.
I think you're overplaying this quite a bit. You imply that Django doesn't solve hard problems. And you also imply that Pyramid's critics don't either. And with all respect, that's a rather arrogant position, and is just plain wrong. All web frameworks attempt to do exactly what you're saying.
I know one thing, and it is to never ever say you 'know' a language. Every time that happens, someone from the internet shows up and tells me how little I really know about said language. When does everybody else say they 'know' a language.
That's also, um, yeah, that's how the `import` statement works. That's how Django models work. There's no magic here, you import it from where it is.
wow. this is neat. a vim comment without a corresponding ***** war. [takes screenshot]
There's an awful lot more to Python than Project Euler solutions. Just a few that you won't use there are developing GUIs, networking apps, web apps with libmodpython and apache, image manipulation and a host of other things. PE is a great place for programming practice and looking through the solutions after solving the problems is a great way to learn tricks on writing efficient and concise code, but it's only the beginning. Have fun!
TIL I learned I'm the only person who uses Notepad++ to edit his Python code.
I remember Turbogears and Django being very close in features, stability and popularity, maybe Turbogears being a little more popular. Then Guido did a review of a few web frameworks and said he liked Django best. I'm not sure if he tried Turbogears. Django took the lead from that day on though, I do remember that. https://www.djangoproject.com/weblog/2006/aug/07/guidointerview/
For those curious, this results in &lt;&gt; key&gt;value &amp; stuff&lt;/&gt; key&gt;
"to efficiently solve" ... or inefficiently solve. Some of my solutions worked, but depended on a chuck of CPU time, only to find that some people determined the solution by hand in a couple of lines. 
There is a lifecycle that these sort of frameworks go through, where they start out very lean and easy to learn but with few features, everybody starts using them and they grow and grow, until eventually they are quite a big thing to learn and also not as shiny and new anymore. People good at them will continue to develop with them, but suddenly something new will arise! It's interesting and developments around it are quick, it doesn't do quite everything yet but there is so much momentum, and all the new kids flock to it. I view Zope as being too much to learn (based on zero facts, actually, just reputation) and I think Django is now about half way on the path, and since we know how to use it and it has a lot of features by now, we'll be using it for quite a while longer.
Technically a package&lt;/pedant&gt; :)
Code like this is great for people, who are less experienced in Python. Makido's comment is also great to show that in can be done more easily and securely. The only important thing is to clarify which one good for what.
Flask has blueprints, have you checked them out? Nice suave. Do you need help with that? 
`setdefault()` is not atomic?
I'll probably need help eventually, but the project is currently in it's infancy. If anything the most help would be critique of what I've done and how I'm doing it, so that it goes in the right direction :)
All it takes is someone smarter than a monkey to understand the docs. They are very in depth and descriptive. 
zzzeek relax, he just lacks mental capacity to do simpliest of things.
Ah I always run my shit behind nginx, usually with gunicorn+meinheld but I'm toying with uWSGI. What I do is expose the WSGI app so that anything you want can use it. I'll most likely be working on some template supervisord and nginx skeletons for people to use, but the key will be in documenting the process to make a good, stable, fast setup. This is what I use when managing servers to generate nginx configuration: https://github.com/radiosilence/servers.py However I need to split the skeletons into smaller pieces and have my script add the right pieces based on configuration. So I'd have a default server template, but you could configure to have +ssl, +php5 or +wsgi, etc. It's always been a personal script anyway, but if I were to make it a formalised project I'd have to do the above.
Well, as far as I'm concerned it's certainly more Pythonic than Zope and it's pretty good in "convention over configuration" and all that. Getting from zero to something is ridiculously easy. There are some warts, yes, and Django still contains a little too much magic in some areas, but it's certainly improved a lot and is still undergoing continuous improvements (e.g. the rewrite of the forms module to make it easier to define your own widgets). Lock-in is a problem with Django as it is with other frameworks (look at the Zope stack for an example of why modularity isn't a silver bullet), especially those that aren't "micro". This is natural and although it may not sit right with some people, this tight coupling can actually allow a lot of synergy which wouldn't otherwise be possible. Ironically too loose coupling can result in bloat. If you try to keep your code as generic as possible and make as few assumptions as you can by reducing dependencies that also means you will re-implement a lot of functionality already provided by other libraries and possibly require additional adapters to handle each combination your code could be used in. I think what makes code Pythonic is not just a matter of style. It's also a matter of pragmatism. There is a fine line between flexibility and over-engineering.
But Pyramid doesn't have a soul. Yes, it's a subjective opinion rather than a logical argument, but I think this is the thing that most of its detractors really try to say. It doesn't feel right. The tone of the documentation is a little too mechanical. The jokes (not made by aliens, etc) seem a little too forced. It comes off a bit like Microsoft's attempts to copy Apple's advertising style. Pyramid is probably a good framework. A lot of thought went into its development, I am sure. The documentation looks like a lot of time was spent on it as well. That's good. The developers, writers and other supporters have been doing a great job. But I just don't like it. There's no point in trying to find objective excuses for it. It's not an objective argument. It's purely emotional. And we should be honest about it because the project doesn't deserve all this ersatz-criticism people have been throwing at it. PS: I like Django a lot (though it seemed a bit bloated a couple of years ago and I favoured Pylons over it back then). I also like Flask and Bottle -- though I think Bottle serves those cases better where a full-featured framework seems overkill as Flask's strong extension support always seduces me to re-invent a macro-framework with it. I don't like Zope because it feels like Java to me. I am fully aware that Pyramid has very few ties to Zope although people have often been saying otherwise.
Sublime Text 2
The main idea behind a "server-less" approach is to allow people to run your webapp just like any other program, pacman -S datsuave &amp;&amp; datsuave then visit it in the browser. The webapps I make are not made to be "deployed" on a server "somewhere else", they are made to be run by users like me and you, like any other service/program. Imagine running a webapp/website as simple as running a mixer applet, it could even sit in the notification bar and tell you when users are visiting. Imagine git clone datsuaveas &amp;&amp; python run.py # at your command through localhost:8xxx, both configuration for the web application and everthing else 
&gt; A web framework must account for: &gt; ... Is this a joke?
Not quite XML-to-dict, but XML to Python object: https://github.com/stchris/untangle
&gt; Also, Pythonic is not OO. I'm glad you said it, because I tend not to be so diplomatic. . OO is the most over used and misunderstood concept in programming today. Python is very heavy on "duck typing", which is somewhat blasphemous by traditional OO standards. Also `private` and `protected`, core principles of OO, do not exist in Python. 
I am not sure if this is a good thing anymore. Edit: Had to add pagination. Modify GET parameters to fit your needs.
Couldn't agree more. Also, the first time I tried this challenge I did it in Ada, which helped me to understand the power of Python. 
&gt; I accuse myself of creating a recursive tuple with ctypes Hmm, that sounds naughty but interesting.
I believe it's more complex than that. Suppose everybody puts project A and B as their first choices, and they're full. Now, I put A and B as first and second choices. Since everybody else filled those two projects, I'm left with an nondesirable project. If, instead, you assigned one of those A's or B's their second choice, I could have one spot there. I'd be happy, and the person that got their second choice would be too. I can't think of an algorithm that guarantees maximum happiness... Maximum happiness is hard :P
that's good i guess.
Correct me if I'm wrong, but it seems [this](https://github.com/j2labs/dictshield) is the equivalent for document dbs
:(
Looks similar.
I saw a niggers entry. Welcome to the internet. Mine was 84th. This'll go down in history.
I don't know. I'm *into* RDBMSs, having spent the last two years datamining pretty much 40 hours per week. I feel like I have a 95% complete understanding of the capabilities of Oracle in particular, at least as far as DML goes. I don't "get" SQLalchemy either. I tried to use it today, and it seems like just as much work to build the table definitions as a declarative as it is to map to a table as it is to just write the SQL.
I've spent about 40 hours a couple of years ago trying to learn Django from scratch - as in, little to no Python experience. At the end of that time, I put together a simple CRUD form for external users that was used to fill out a survey. Two weeks ago, I was tasked with writing a reporting system frontend, and I decided to do Python again. This time, I chose Flask as a framework. At the end of 40 hours of development time, I have the bones of a working system. For a new programmer to Python, I would recommend Flask. It doesn't have all the "batteries included", but you'll spend more time learning to write Python and less time memorizing all the magical things that happen in Django.
It was only a matter of time. Everything converges to "nazi", "nigger", and "penis" eventually.
So every project you want to litter your code with SQL literals, you want to write new functions to generatively build queries, you want to write functions to loop over your DBAPI result set and create instances of some data structure, you want to write code that only works with one database or in the subset of sql they all support?
What would *your* response have been?
&gt; Copyright 2009, AK. Created using Sphinx 0.6.1. 
I actually feel a lot better now.
Wow, thatâ€™s quite an interesting example. Iâ€™m not 100% sure on this, someone who knows Pythonâ€™s grammar well can probably confirm, but hereâ€™s what I think is going on: The first point is that the assertion is irrelevant, weâ€™re just evaluating expressions: &gt;&gt;&gt; (2 &gt; 1) is True True &gt;&gt;&gt; 2 &gt; 1 is True False OK, so what does "2 &gt; 1 is True" mean? Maybe itâ€™s just grouped the other way: &gt;&gt;&gt; 2 &gt; (1 is True) True Oh. Maybe not then. But wait, thereâ€™s a bit of syntax which lets you write things like: &gt;&gt;&gt; 1 &lt; 4 &lt; 7 True and I guess it works with other operators: &gt;&gt;&gt; 1 &lt; 4 &gt; 3 True These parse (semantically) like "(1 &lt; 4) and (4 &gt; 3)". So, Iâ€™d say that itâ€™s semantically treating "2 &gt; 1 is True" as "(2 &gt; 1) and (1 is True)".
According to http://docs.python.org/reference/expressions.html#notin: &gt; Comparisons can be chained arbitrarily, e.g., x &lt; y &lt;= z is equivalent to x &lt; y and y &lt;= z, except that y is evaluated only once (but in both cases z is not evaluated at all when x &lt; y is found to be false). So the expression: 2 &gt; 1 is True is equivalent to: 2 &gt; 1 and 1 is True `2 &gt; 1` evaluates to `True`, `1 is True` evaluates to `False`, so the result of the `and` operator is `False`.
2.6 was released in 2008.
TIL `assert` is a keyword rather than a builtin function.
(Hint: Try the "save" link under the OP text.) 
Yeah, just someone does not need to update as soon as it released, isn't it.
I have no idea why a Py2.5 programmer uses [`Set` from the `sets` module](http://www.lightbird.net/py-by-example/sets-module.html). 
Hej, thanks for the interest.. why ANTLR? Well, first off I wanted to use a parser generator because I didn't want to spend _any_ time debugging a handwritten parser/lexer. This was not the focus at all. I was made to write parsers by hand at university and it sucks. And as to why ANTLR specifically; it produces parsers that I can read .. this, to me, trumps a lot of disadvantages the framework might have. Secondly, it was taught to me at university and so is familiar. As to the complaints about speed, I guess I can see why that happens; ANTLR is pretty smart (as of v3 even more so) and when it sees a grammar that is not quite how it should be it will happily hoist rules and add predicates willy nilly to make your grammar parsable. In that case, it will probably also start to use backtracking and as far as I know this is where parser performance starts to choke. (std disclaimers apply, i am not an expert at parsers, just a nerd enamoured with PL design). Jeah but the best part about antlr generated parsers is that you can just go into the sourcecode and actually have a chance to understand what's going on.
Who is Andrew Ch, and what is he doing between Yan and Yourdon? 
I wish there was a shardable graph database with built-in replication written in Python... neo4j, like others, can't be sharded so far, plus it's done in Java. From that perspective it makes sense to use bulbs so that when said database springs into existence, one can take his app code and swap out the underlying database. Has somebody ever thought about starting a graph database written in Python (Python 3 preferably) that's shardable like infinitgraph? Maybe also with built-in replication, much like MongoDB but more granular i.e. replication on the object-level where you would only replicate certain objects that are important. I've been thinking and it seems for all the networking layer amongst nodes ZeroMQ seems like a perfect choice for such database. With ZeroMQ it also shouldn't be to complicated to give such database events e.g. make it notify the application when a stored object gets changed, stored, moved/replicated to another node, etc. The usage of ZeroMQ would also enable this database to be used quickly and easily from most programming languages out there (http://www.zeromq.org/bindings:_start), including Perl, Java, PHP, Ruby, C++... Another nice-to-have property of such database would be that there's no mapping needed i.e. no actual ORM since you would persist objects as they are used in the application. Thus each object/node in the database should have a uuid 1:1 to a URI i.e. each object/node in the database has the same ID the user sees in e.g. a URL. And yet another nice-to-have property would be (client-side) encryption because then you could use this database to drive some cloudservice such as dropbox and not be worried about giving away private information unencrypted.
Well I mean proving a simple deployment option wouldn't be hard, but picking which one to go with...I'd probably go with uWSGI or Gunicorn in a server context at least.
Thanks and its nice to see PyPy contributor replying. PyPy json as fast as ujson. This could be an eye opener for Python developers. But nodejs loading is faster than dumping. I haven't compared memory consumption . 
It took me a little bit to put your explanation into words that fit in my head, so in case it saves anyone else any time: `2 &gt; 1 is True` is not the same type of expression as `2 + 1 / 3`. The more familiar second type of expression is reduced using the traditional "order of operations." You force this behavior in the expression `(2 &gt; 1) is True` which becomes `True is True`, eventually evaluating as `True`. That is not what is happening in the first expression. There, (comparison) operations are not simply reduced, but are chained together with an implicit `and` and are evaluated from left-to-right. This makes sense in a more common example, `1 &lt; 2 &lt; 3`. Intuitively this should evaluate as `True`, but in a traditional "order of operations" approach, it would become `(1 &lt; 2) &lt; 3)`, then `True &lt; 3`, which doesn't really make sense. (By the way: it happens that `True &lt; 3` and `False &lt; 3` both evaluate to `True` for reasons I don't understand but which make me wish Python was type-safe.) tl;dr: what he said
&gt; (By the way: it happens that True &lt; 3 and False &lt; 3 both evaluate to True for reasons I don't understand but which make me wish Python was type-safe.) I suppose that's because &gt;&gt;&gt; int(True) 1 &gt;&gt;&gt; int(False) 0 
Nice.
What about pickle.HIGHEST_PROTOCOL ?
hearing for first time.
 &gt;&gt;&gt; bool.__mro__ (&lt;type 'bool'&gt;, &lt;type 'int'&gt;, &lt;type 'object'&gt;) As `bool` is a subtype of `int`, it will leak some implementation details of `int` to its behavior.
There's a difference between "coolness" and what feels right. Python feels right to me. It doesn't get in my way. It does what I want it to do. It's painless, flexible and welcoming. It's a complete joy to work with. I don't use Python because it is somehow objectively better than the alternatives, I use Python because I like it better. This is true for most people, we (nerds in particular, humans in general) are just very good at rationalizing it because we feel obliged to. Python certainly isn't cool anymore. The cool new thing is Ruby or server-side JavaScript. Or Haskell, if you come from academia. Python is still cooler than Java or C#, but that's because Java and C# are enterprisey and enterprisey things are uncool by definition. If you think this is only about coolness you are doing yourself a disservice. Design, usability, aesthetics, user experience and so on are important in everything we do. A lot of our motivations are subconscious even when we think we are acting out of rational considerations. Most Linux distros are objectively worse than MacOS X. That's not just about what's hot or not. They were just built out of completely different motivations. Apple products are engineered from the ground up to deliver a certain user experience. That doesn't mean they're better for everything: I don't use Apple products because of the very strong lock-in and the limitations of what Apple lets me do with them. These limitations are a logical consequence of their philosophy. What I want of an OS, smartphone or music player and what Apple delivers, however, are very different and incompatible things. We can pretend Apple products just suck all we want, but that doesn't make it true. Apple is financially successful because their products _don't_ suck. They only suck when you want them to do something they were not built to do -- like work without having to buy into the entire Apple microcosm. Intuition is underrated. You can create a perfectly balanced sword, yet two expert swordsmen may disagree about its quality simply because their needs may be different -- quite possibly different in ways they can't easily describe. "Liking it" may sound trivial, but in this context it really means: "Based on my experience and the workflow I have developed and the concepts I have learned to embrace, I prefer this over something else." There is no rational argument for using vim over emacs that would convince a die-hard emacs-user to switch to vim or vice versa. The same goes for most languages, frameworks or application stacks. __This is okay__. Taunting just proves your ignorance and unwillingness to accept this simple fact about human nature. We like things for reasons we cannot quantify. But if you know what you're doing and you have tried several alternatives, you may have very good reasons to do so even if you can't put them into words. Rationalizing will get you nowhere.
I'm going. First time. Signed up for two tutorials (though I wish I could do more!) I only live 2 miles from the convention center, which makes it more feasible to go. I'd be down for a Reddit lunch/dinner. n00b coming through!! 
Well, it's the second sentence of the pickle.dumps documentation. protocol 0 is before python 2.3, so you don't really want to use it. protocol 1 maybe if you subclass dict and _setitem_, since 2 uses _setitem_ to fill it before _init_. pickled with 2: 1.69552707672 loading of 2 pickle: 1.18669605255 pickled with 0: 4.27784991264 loading of 0 pickle: 1.5507080555 
Cool stuff; consider x-posting to [/r/compilers](http://www.reddit.com/r/Compilers/)
I can see I've touched a nerve, and I apologize for that as there appear to be far too many nerves frayed on Reddit these days. Your comments refer to two different aspects that are of course fairly invariant - lists of rows or objects are pretty much going to be lists of rows or objects within any system. Similarly, of course any system can emit *any* query. The Python DBAPI can emit any SQL query. So asking for "a SQL query which can be executed by SQLAlchemy but not by Django" is not really what we talk about, when we refer to how relationally-oriented an ORM is. When we use an ORM, we're not actually gaining any capability that we wouldn't have by working with a raw cursor and some decent glue code that could push result rows into objects. What we are getting is *automation* of the work that we do. This automation allows us to take what we know about the database and its schema, formulate relational queries against that schema, then tell the ORM what we'd like to do - the ORM then does the work of turning our commands into a statement to send to the database, relating the statement to the objects we want to get back, and returning the results. (Keep in mind this whole discussion is only about the query side; there's also the whole transactional/persistence side which is another area in which ORMs can be discussed). The argument that I frequently make here is that SQLAlchemy's object relational automation layer is most directly oriented towards the relational structures present in the database. It's obvious that any ORM tool can let you emit whatever SQL you'd like, and linking that to objects is only a matter of pointing columns back at object attributes. But SQLAlchemy's approach is explicitly relational, whereas Django's is not, or at least only partially. A key aspect is how joins are usually implicit in Django, how decisions about tables are typically made by default (column names, etc) and how the Python-level query capabilities don't always map consistently or fully to what is provided. How would I know this ? Mostly by what I hear from people who have used both the Django and SQLAlchemy ORMs almost every day. Here's a talk by Alex Gaynor, who you might know is a core Django developer. The talk is given from the POV of someone who *helped write the Django ORM*: http://speakerdeck.com/u/alex/p/why-i-hate-the-django-orm The whole point of this talk is to highlight some of these inconsistencies and specially how SQLAlchemy does a better job. I saw Jacob Kaplan-Moss talk in SF about "Stupid ORM Tricks" - paraphrasing, he included in his introduction "the Django ORM is probably the least capable ORM in the Python space" (Jacob if I'm getting it wrong please let me know). The talk was then about three very unusual, exotic edge cases you can kind of get Django to do with some patience - all three were things that SQLAlchemy has done out of the box since 2006. So there has to be *some* advantage to SQLAlchemy. There are obvious disadvantages. It doesn't work with the Django admin and doesn't work with all the many add-on applications for Django that use the Django ORM. SQLAlchemy's main disadvantage is pretty much that it lives on the outside of Django's ecosystem. As well as that it really is tailored towards people that like relational databases as opposed to those who see it as an implemtation detail - it requires a good couple of hours of documentation reading before you get it. But once people get it they're off to the races. In recent talks I also have a comprehensive example of how SQLAlchemy's "explicitly relational" nature allows you to build ORM-level queries, *without* dropping into raw SQL, while being able to express pretty much any SQL concept. The idea is not "wow nobody else can do this SQL !" That's not the point. The point is, when given an elaborate task, you can stay within the ORM and think just like you would if you were writing raw SQL. You don't have to re-mold your thinking to fit around some awkward concept like implicit joins embedded into WHERE criterion. Starting with a model as follows: class User(Base): __tablename__ = 'user' id = Column(Integer, primary_key=True) username = Column(String(50), nullable=False) addresses = relationship("Address", backref="user", cascade="all, delete-orphan") class Address(Base): __tablename__ = 'address' id = Column(Integer, primary_key=True) user_id = Column(Integer, ForeignKey('user.id'), nullable=False) street = Column(String(50)) city = Column(String(50)) state = Column(CHAR(2)) zip = Column(String(15)) Give me all households in New York with exactly two occupants where neither occupant has any residences outside of the city. Note that our schema isn't well suited for this particular query so at the SQL window we'd need to do some awkward correlation of equivalent `Address` rows. Also eagerly load all the Address objects for each of the User objects located. # New York addresses that have two # occupants two_occupant_ny = \ Session.query(Address.street, Address.city, Address.zip).\ filter(Address.city == 'New York').\ group_by(Address.street, Address.city, Address.zip).\ having(func.count(Address.user_id) == 2).\ subquery() # users who are different from each other u_1, u_2 = aliased(User), aliased(User) user_q = Session.query(u_1, u_2).\ select_from(u_1).\ join(u_2, u_1.id &gt; u_2.id) # join them to their addresses, join addresses # to the two occupant NY addresses a_1, a_2 = aliased(Address), aliased(Address) user_q = user_q.\ join(a_1, u_1.addresses).\ join(a_2, u_2.addresses).\ join( two_occupant_ny, and_( a_1.street==two_occupant_ny.c.street, a_1.city==two_occupant_ny.c.city, a_1.zip==two_occupant_ny.c.zip, a_2.street==two_occupant_ny.c.street, a_2.city==two_occupant_ny.c.city, a_2.zip==two_occupant_ny.c.zip, ) ) # who don't have a house outside of New York user_q = user_q.filter( ~exists([Address.id]). where(Address.city != 'New York').\ where(or_( Address.user_id==u_1.id, Address.user_id==u_2.id )) ) # pre-load all the Address objects for each # User too ! user_q = user_q.options( joinedload(u_1.addresses), joinedload(u_2.addresses)) users = user_q.all() output: SELECT user_1.id AS user_1_id, user_1.username AS user_1_username, user_2.id AS user_2_id, user_2.username AS user_2_username, address_1.id AS address_1_id, address_1.street AS address_1_street, address_1.city AS address_1_city, address_1.zip AS address_1_zip, address_1.user_id AS address_1_user_id, address_2.id AS address_2_id, address_2.street AS address_2_street, address_2.city AS address_2_city, address_2.zip AS address_2_zip, address_2.user_id AS address_2_user_id FROM user AS user_1 JOIN user AS user_2 ON user_1.id &gt; user_2.id JOIN address AS address_3 ON user_1.id = address_3.user_id JOIN address AS address_4 ON user_2.id = address_4.user_id JOIN (SELECT address.street AS street, address.city AS city, address.zip AS zip FROM address WHERE address.city = ? GROUP BY address.street, address.city, address.zip HAVING count(address.user_id) = ?) AS anon_1 ON address_3.street = anon_1.street AND address_3.city = anon_1.city AND address_3.zip = anon_1.zip AND address_4.street = anon_1.street AND address_4.city = anon_1.city AND address_4.zip = anon_1.zip LEFT OUTER JOIN address AS address_1 ON user_1.id = address_1.user_id LEFT OUTER JOIN address AS address_2 ON user_2.id = address_2.user_id WHERE NOT (EXISTS (SELECT address.id FROM address WHERE address.city != ? AND (address.user_id = user_1.id OR address.user_id = user_2.id))) --params: ('New York', 2, 'New York') # result ! User(name=u5, addresses=s1/New York/12345, s2/New York/12345, s3/New York/12345) / User(name=u2, addresses=s2/New York/12345, s4/ Can you do that SQL in Django, Web2Py, anything else? Of course! You might need to emit some extra SQL to get at those address collections. SQLAlchemy has the advantage that you can stay within the ORM space, not have to drop into literal SQL, and can think just like you do when writing SQL at the query window, with minimal shifting of paradigms. Eager loading is also highly capable at adding related loads and collections in an automated fashion, either via joins or via a second query that loads all collections at once. I hope this helps explain some of the many reasons why people seem to love SQLAlchemy. 
I am not saying that he repeated what Beazley has done, but he has completely omitted anything from it, which would have been important. There is no information as to why threading is wrong in this instance. (I do not need to know why it is wrong.)
MATH RAGE Sorry, had to. Post your code, please. How can we help otherwise?
What I find encouraging is that the times are half as long when using pypy than they are with cpython.
"principle of least astonishment" ?? ruby? not in my experience. 
&gt; I wish there was a shardable graph database with built-in replication written in Python Python is nowhere near Java or C++ when it comes to performance, yet. It's no wonder that almost all serious databases are written in C++ or C (recently in Java due to the VM enchancements). Of course, if the focus would be on "pure Python" without thinking a lot about performance, sure...
I won't comment on the usability, since that seems more subjective to me, but I would definitely agree that Python is much easier to learn for a complete beginner. Many of Ruby's concepts are very difficult to grasp, and I couldn't imagine many non-programmers being able to get into it well. (Note that I am primarily a Ruby developer who is currently employed as a Python dev, so I do tend to heavily favor Ruby).
Thanks so much. I guess that's the danger when using everyday language to program, sometimes you can forget how specialized the use of it is inside the programming language. You're explanation clears it all up though.
I've not researched Pyramid, but I did look at Pylons the first time around. Flask just seemed a lot more straightforward to me. There was no "magic", just a small API to learn. Further, while I intended to implement an MVC architecture, Pylons seemed to enforce that as a design decision from the start. Django's community is very strong, particularly on IRC. There is no forum that I've found that is popular for them, though, which I found a little odd. Flask... well, there isn't much to Flask. There is a Werkzeug community and a Jinja2 community, and I've found lots of information I needed via search for both of those. I've not tried to find them on IRC, as I'm at work and it is blocked. /r/django is *far* more active that /r/flask, though. The thing is, with Flask, I've not *needed* the support. The documentation is very good, and it's so small there really isn't a lot to go wrong. I'm learning different pieces of the framework as I develop more advanced needs, and they stay out of the way until then. With Django, I often found myself having to learn why things were structured the way there were, before I could learn the system. An example of this would be forms processing - on Django, I remember having to learn about the Forms models, and all of their configuration. Then I had to learn about Forms validation, and how they were handled in the view (by branching the logic based on request type). Finally, I had to learn about how to tie a form to a Model, or to use a ModelForm. With Flask... there is no forms processing included to my knowledge. I built the form in HTML (and wrote some helper functions in the process), validated the data on an ad-hoc basis, then wrote the SQL to drop it in the DB. There are extensions that add form processing to Flask, but I didn't use them. In this use case, a competent Django developer could get a CRUD form up and running in a shorter time than a competent Flask developer - but by the time I would consider myself "competent", I will have developed my own library of helpers functions and architectural conventions, and will have learned a lot about Python in the process. It isn't really a fair comparison - no one sits down with only one module and writes everything else from scratch. I think I'll ultimately end up using Django for prototyping and rapid application development, and Flask (or its components, Werkzeug and Jinja2) for writing things that are less well-defined or don't quite fit into the mold poured by Django. I don't think it's fair to say that one is better than the other overall, but I stand behind my contention that Flask is better suited to a new Python programmer.
True, there is the performance argument but then I think that the benefits of having a heavily distributed system that scales makes up for it above a certain number of nodes; you certainly wouldn't start such project in Python if single-node performance is your top priority. Also, I'd like to think that in the not so distant future PyPy will become the main Python interpreter most people use. This will narrow the performance gap even for a single-node installation of said database (when compared to existing databases written in languages such as C, C++ and Java).
Thanks so much, I think you're right. True and False seem to be a little tricky here as well, like 2&gt;(1 is True) returning True. Although I'm assuming that must be because it compares 2&gt;False or 2&gt;0. Still, tricky stuff.
Why can't you use numpy? You can also try other "speed-up" alternatives as pypy or cython. If you really want python, than you could (maybe, on big matrices) gain some speed by dividing the matrix into subparts and calculating those first. That way you utilize caches better. And the most obvious solution is parallelization, using subprocess (because of the GIL). It's fairly common topic, so it shouldn't be a problem to find some algorithm
You're using an interpreted language to compete with highly optimized native code. I'm afraid you won't get there. So, unless this is an academic exercise, I'd let it go. My only real suggestion is to use pypy.
Thank you for writing a technical post instead of you initial short list of assumptions about what I do and don't want. Now let me go digest all of this...
Sorry, but I still don't agree. Spawning nodes really isn't a solution here. Maintaining distributed sanity is still difficult. Also, Oracle database handles GiB's and TiB's of data. Would you still stick with "large" scale node based deployments? Even in a single threaded scenario, C or C++ still beat Python so your single "node" will still be slower compared to the same node written in C or C++. In really strict performance conditions, not being in control of the memory is again a liability. IMHO, interpreted/dynamic/simple garbage collected languages still have a *long* way to go to when it comes to these sorts of things.
Because that is not the point. I have other numerical algorithms I need to implement which cannot be reduced to numpy function calls. I need to decide whether I can use Python or I need to use C (and perhaps wrap them in python). If I have to use C, I may as well use C all the way. I am happy to pay a 10x penalty for using Python but not a 1000x penalty. I am trying to figure whether there is some trick I have not considered (I have tried using array.array to store the elements and that only made it worse). 
Look at the sponsored submission ( ad ) at top of [/r/Python](/r/Python) 
That's not really the reason it works though, you can compare any two objects: &gt;&gt;&gt; "whee" &lt; 3 False I believe the comparison is guaranteed to be consistent (if "whee" &lt; 3 is False, then "whee" &gt; 3 is True). Python allows, for instance, lists of arbitrary objects, and you can sort lists. That means you have to be able to compare arbitrary objects.
&gt; Also, Oracle database handles GiB's and TiB's of data. Would you still stick with "large" scale node based deployments? I don't get your argument here. Oracle scales horizontally by adding nodes. That's where it makes sales vs. e.g. SQL Server. SQL databases don't scale up very well with multiple users because inside a particular query you're still running up against what an I/O path can push through, what a cpu can run, etc.
How am I incorrect, and what is that a counterexample of?
Yep, the correct answer is duck typing. I knew the concept of course but I slipped to my answer because it is usual for people to frown to the fact that bool is an int subclass. Mea culpa ;)
Emacs, the run-python mode is pretty handy to have sitting around in your buffers when you're hacking around.
Pyinstaller works exceptionally well with me for windows XP,Vista and 7. It works with PyQt right out of the box with no fiddling around either. The only thing you need to confirm is the look of widgets between XP and Vista/7. Follow the Pyinstaller 'Getting Started' docs to the letter, and you should get results. The most you'll have to do is install a few packages locally. Then tweak your .spec file to fine tune your deployment.
How did you get a virtual Mac to work?
Awesome response. Much appreciated. I suspect Pyramid is more similar to Flask than it is to Django. I might check out both Pyramid and Flask.
Some part of PyQt may need QtXml and PyInstaller might not be picking that up.
Follow [these instructions](http://lifehacker.com/5583650/run-mac-os-x-in-virtualbox-on-windows). The torrent file is [here](http://thepiratebay.org/torrent/5203531/Snow_Leopard_10.6.1-10.6.2_Intel_AMD_made_by_Hazard). The instructions are pretty much the same for Linux.
I make exactly the same sorts of "je ne sais quoi" judgments about things. For example, I visit the Wawa convenience store nearby.. (maybe because it has prettier cashiers? i don't even know) even though 7-11 is closer and cheaper. On the other hand, I don't then feel compelled to go on a public internet forum in a thread about Wawa to say how much I don't like 7-11 for reasons I can't explain. I just go to Wawa instead. Apparently lots of folks have that compulsion, however. And that's fine. Since 1993 or so, as a consumer, it has been your god-granted right to emote about stuff you have a passing knowledge of publicly on widely-read internet forums. It's not your obligation to tell producers what you don't like and why you don't like it. It's their obligation to attempt to engage you and read those tea leaves if they choose. In the context of open source software, you can imagine that gets pretty dispiriting though. It's not like we do this for the money or the glory. We do it because we like making software and we enjoy it when other people use that software. We like to improve our software and documentation in response to constructive criticism. But responding to consumerist rants is a distraction from this, and the economics of the situation don't really allow for it very well. Open source isn't a traditional consumer-producer relationship. The way it's supposed to work is that people either complain constructively or help. This particular conversation has neither characteristic, which makes it pretty much a waste of time for both of us, I think. But given that I've been through a few shifts in the industry driven by cynical people taking advantage of consumerist tendencies, I feel like I'm obligated to respond in defense. If that makes me arrogant and ignorant, I can live with those labels. I'd prefer to have an actual conversation about technical things, but we can do this too.
Just found out today that my company is sending me! Very excited. First PyCon for me, only other big conference I've attended is OSCON this past summer.
How can Python be influenced by Java when Python existed 3 1/2 years before the first Java release?
the sqlalchemy whine brigade is trying too hard. if it were anywhere near as awesome as claimed people wouldn't be constantly trying to drop it at every opportunity or writing wrappers for the whole damn mess
This disassembly view gives you a very concrete way of looking at the operations being performed by the interpreter. But if you are just interested in how a statement is being parsed, you'd probably do better to try the built-in "ast" module. import ast tree = ast.parse('assert(2&gt;1) is True') print(ast.dump(tree))
The times are millions of times faster (without exaggeration) when not using timeit. I don't understand what timeit is doing.
You can compare any two objects in Python 2. The comparison is arbitrary and comes down to memory locations. That's dumb and an attractive nuisance, so they fixed it in Python 3. &gt;&gt;&gt; "fixed" &gt; 1 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: str() &gt; int() 
I concede that the answer wasn't precedence. But it would have been helpful if you'd answered the question, instead of simply pointing out that I was wrong. Happily I've figured out what *is* going on. Consider this, examples all using Python 3.2.2: &gt;&gt;&gt; 2 &gt; 1 is True False &gt;&gt;&gt; (2 &gt; 1) is True True &gt;&gt;&gt; 2 &gt; (1 is True) True The crucial observation is that "&gt;" and "is" have the same precedence, and that Python has special support for "chained operators". Remember this old favorite: &gt;&gt;&gt; 2 &lt; 5 &lt; 8 True 2 &lt; 5 evaluates to True, *except* when you chain the operators together like this. When you do that, if the expression is true, it conceptually returns the right operand. (I don't know *exactly* what it does; for all I know it might go right-to left. Certainly there is some sneaky intelligence lurking under the covers here.) So with "2 &gt; 1 is True", it thinks you want chained operators, because "&lt;" and "is" have the same level of precedence. So "2 &gt; 1" conceptually evaluates to 1 (not True) and "1 is True" returns False.
In case you are the OP: excellent essay. &gt; I removed the "ifilter()" call &gt; I removed the "**islice**()" call
Hey, I'm finally getting around to working on my remote command runner. I'd love to see your twisted code - do you have it on github or a similar site? I've been looking into Twisted - it looks like it's got all the bells and whistles but the doc's not the greatest.
Twisted called, wants its deferreds back.
Forgive possible ignorance, but what's wrong with multiprocessing.Pool? I've used it for these purposes dozens of times with no issues, and I don't need to do any "future" imports.
&gt; this thread is about graph databases and Python though My bad, I was just looking forward to a heat.. err, good discussion. ;-)
Correct. 2 &gt; (1 is True) is the same as 2 &gt; False, which is the same as 2 &gt; 0. A very different expression from "2 &gt; 1 is True".
I've personally used python-ldap. Aside from the minor difficulties with getting used to what queries return (as far as I can tell, everything is returned as a list, even non-multivalued attributes) and unicode support (or lack thereof), it's pretty easy to use. Another possible LDAP module is [pumpkin](http://pumpkin.prymitive.com/0.1/), which acts as an ORM for LDAP. I haven't gotten a chance to use it as I was &gt;80% complete with my project using python-ldap, but I'd definitely try this in the future as I'm a fan of ORMs. 
Out of curiosity, was PyPy json built from scratch?
"Readability counts" written on a spiral of words with a yellow background.
There is no "future" import here; "futures" is a submodule to "concurrent." The word "future" unfortunately already carries another meaning in Python, but it's the term already used in Java, which provides the model for this API. multiprocessing.Pool is more advanced, so "wrong" isn't quite the issue. The quoted text from PEP 3148 gives some of the reasoning for the new module. Beyond that, some of the differences are: the context manager gives a more definite boundary to the lifetime of the pool, each 'Future' instance supports a 'done' callback, which allows Twisted deferred-style event chaining, and it's a common API which can be shared with a thread-pool or with some alternate (eg, ZeroMQ) task distribution implementation. 
That turned into a bit of a clusterfuck, also a lot of tutorial presenters are full-time trainers and asking them to make their material free forever is a pretty bad business move for them. Most tutorials will post slides and example code publicly at least.
Repost, but a good one. Since I've never used Ruby. What is it's advanttages over python?
I didn't bother explaining where you were wrong, because there were already perfectly correct explanations being upvoted when you posted. You could have read them, or you could have tried to falsify your hypothesis with a few tries in the interpreter. It turns out it doesn't even work out for the expression in the original post.
I would like this one, but with the text normally formatted above the circle with "The Zen of Python" in it
Does anyone else hate the rather arbitrary, newbish comment about how namespaces are honking? That's not zen. The rest is fine.
Thanks I'll look into pumpkin as well. I'm currently just designing the project. I know what it has to do, but haven't put together a final design for it yet. Thanks for the info on your experiences with python-ldap. I can understand the annoyance with wrapping single valued returns in lists, but at the same time, consistency can be nice.
Good to know. Thanks.
Read up on "executemany" [(http://code.google.com/p/pyodbc/wiki/Cursor) ](http://code.google.com/p/pyodbc/wiki/Cursor) Very basic description, make a list of lists, or list of tuples and pass that to executemany, it will insert them all at once. That way you aren't waiting on doing an insert to finish before iterating the next piece of data. You may want to do a insert or ignore in case the row already exists. From the wiki: &gt;cursor.executemany(sql, seq_of_parameters) --&gt; None &gt; &gt;Executes the same SQL statement for each set of parameters. &gt;seq_of_parameters is a sequence of sequences. &gt; params = [ ('A', 1), ('B', 2) ] executemany("insert into t(name, id) values (?, ?)", params) &gt;This will execute the SQL statement twice, once with ('A', 1) and once with ('B', 2).
I don't know much about odbc, but I don't think this can be answered without knowing what the actual database server is. In most cases, you would want to wrap all the inserts in one transaction, and/or use a prepared statement instead of execute()'ing each insert by its own.
Thanks, that looks like something that might work better. I'll have to play around with it.
Does anyone know of a place where I can get decent sized python posters? I haven't looked enough yet, but what ones I did find were somewhat lacking.
Inversion or Multiplication? In any case numpy lets a BLAS-library do the heavy lifting, so the Matrix-Multiply is going to call the GEMM-implementation ( http://en.wikipedia.org/wiki/General_Matrix_Multiply , if you're interested have a look at the paragraph for "Optimization" about speed-issues ) of the BLAS library that it was compiled with. Two commonly used implementation of BLAS on Linux-Systems would be http://www.netlib.org/ and http://math-atlas.sourceforge.net/ In your calculation of factors you forgot to account for optimizations of CPU-caches. As far as I know (and I'm no expert) for smaller-matrizes (the ones that fit into RAM) cache-optimization plays a huge role, while the best algorithm (the one achieving O(n^2376 ) ) is only of theoretical interest, because the hidden constants are insanely high.
Here's an example (kind of), the author is testing the performance of pyodbc executemany vs ceodbc executemany, but it shows how to use both. [(http://pastebin.com/hACUK5ty)](http://pastebin.com/hACUK5ty) 
No, no, no. NO. It seems you've no formal training with Qt, may I suggest Mark Summerfield's book. A gem, a real fuckin' gem. Anyway, you're looking for: QRC Resources. You can use the QRC resource creator in QtDesigner or manually create the file (I find this easier) and then run it through the converter for the Qt-target language you want. Then you end up with a resource file which you just then import into your program. When you want to use the actual images, there's some magic with strings and the prefixes you give them. For example: from scanning_qthread.ui.ui.resources import qrc_resources As an import, for example. `qrc_resources` is a file which I created via the xml like language and ran through the converter. Below: &lt;RCC&gt; &lt;qresource&gt; &lt;file alias="ico.png"&gt;ico.png&lt;/file&gt; &lt;file alias="about.png"&gt;pdftotif_small.png&lt;/file&gt; &lt;/qresource&gt; &lt;/RCC&gt; This is what it's like before the converter. After: http://pastebin.com/5T1vnJpW Then in where I want to use it. For example in my main window class: class MainWindow(QtGui.QMainWindow): """ Main window for the application Takes Ui_MainWindow from mainUI.py, which is automatically generated with pyuic4 from the UI file. """ def __init__(self, parent=None): """Init Window""" QtGui.QMainWindow.__init__(self, parent) self.gui = Ui_MainWindow() self.gui.setupUi(self) self.gscriptpath = '"' + os.getcwd() + r'\gs\gs9.02\bin' self.gui.progressBar.hide() self.single_output_dir = '' self.deletions = [] self.work = QThreadPool() self.work.setMaxThreadCount(1) self.thread_number = 5 self.setWindowIcon(QtGui.QIcon(":/ico.png")) self.resolution = 450 self.mode = 'tiffg4' Of particular interest, `self.setWindowIcon(QtGui.QIcon(":/ico.png"))` this is the alias we defined in the above qrc file, so we call this again as pure string and Qt magically knows we want the file from the qrc file. It's not a particularly straight forward thing considering you're magically using a string prefix to denote you want the thing from the qrc file but it works and is flawless. Also, you don't have to supply the actual images or any resource files you want to use in your program. JUST the 'compiled' qrc file. HTH.
That is definitely true. I spent a lot of time writing python code to interact with a MySQL db (using MySQLdb) and in my experience, writing to file and then running a LOAD DATA INFILE statement is much faster than any kind of insert.
Try the executemany thing that was suggested. You can also try this little trick to combine the inserts into a single statement: INSERT INTO mytable SELECT 'row1val1', 'row1val2', 'row1val3' UNION SELECT 'row2val1', 'row2val2', 'row2val3' UNION ... (and so on) 
Your title should be more like, "Inexperienced individuals needed" or "Looking for inexperienced individuals". It would be helpful if you mentioned that you are looking for someone to learn with who is also interested in learning Python. Also, for a game, you probably need an artist. Good luck!
There's a tool that was supplied with the Qt library that you're using, Python's is called: `pyrcc4.exe` on Windows. Usage: `pyrcc4.exe -o output-fname.py qrc_file.qrc` If you put it on your path it's way easier, how it should be. Running pyrcc4.exe (or it's bin if on Linux) will give you usage options. Generally the `-o` switch is all you need, but there are more.
the big idea o' mine is to force the player to react to many many things. That's why i talked about The Oil Blue. I think it's power lays in the many machines (menus) you have to interact with. Like pump this oil cell, pressure goes up, if pressure goes to high you can say bye bye. Mean while you have to select where you are gonna pump and where next. But if you want to get more oil you will need to build more towers. More towers means more things to do. I want to create a situation like that. Maybe an oil platform, maybe a ruler of village/province/kingdom, if you have other ideas your welcome. Drvanon p.s. you can read the first lines of code on github.com. www.github.com/Drvanon/strategy-game/ 
Depending on the database, some will run better if you perform all the inserts as part of one transaction, presumably because they don't have to ensure the index is valid after every insert, just at the end.
If you're using QtDesigner, you can make a resource file. This will take all of your resources and make a single file. You can also add lines to your .spec file to force pyinstaller to include files. Note that this works well with single folder deployment. #Add arbitrary files to the install a.datas += [('version.txt', 'c:\\DPLworking\\version.txt', 'DATA')] a.datas += [('update.bat', 'c:\\DPLworking\\update.bat', 'DATA')] 
I had to go through the fun of installing cx_Oracle on Windows... it wasn't much easier.
Thanks for mentioning this. I've got a large (large large) pile of data to be putting into a DB and sometimes inserts of specific things can take a day or more. I'm looking into this now. 
Have a look at pyopencl, one of the demo programs is probably trivially modifiable to run your benchmark and give you another data point.
I've been successfully using python-ldap for years in production on Debian and Ubuntu Server. If you are working with Linux in an ActiveDirectory environment, I recommend the less-known-but-excellent python-ad (http://code.google.com/p/python-ad/). With that library, no need to worry about Kerberos, GSSAPI, multiple domain controllers &amp; Co.
Assuming that you have a somewhat normal distribution [here's why](http://en.wikipedia.org/wiki/Probability_density_function) almost all get their top two projects.
Thanks for the comment. I'm not a fan myself, but I wanted to have everything from **import this**, word by word. I'll make another version without it.
Yea, I remember that thread. I definitely will look into that book, since I've been mostly reading forum threads and Qt documentation to build the program. This is also my first Qt application, so in the beginning I didn't know how to structure it, hence the mess it is today. I finished removing the loadUi code, and the program build (almost) flawlessly with PyInstaller. The only problem I have is that the equation pngs are not showing. Technically I should treat them the way you showed me, with a resource file, but the problem is that they are created at runtime. Any suggestions? EDIT: If you end up cloning my repo, clone the experimental branch!
Thank you very much! :)
Really? On Fedora and Redhat you set ORACLE_HOME and "easyinstall cx_Oracle". You have to have oracle installed properly, however, and that person that wrote that howto didn't.
Maybe we should submit a patch the Python source code, and fix this in upstream :)
Can you point me to where they are getting created at run time?
Oracle Express...yeah I can see that.
When a user add a note, ImageLabel.slot_add_note() gets called, and creates a Note() class. The Note class contains all the functions to generate the png.
that is on my todo list. thanks for mentioning it anyway.
I dinna get the point. The [R project](http://www.r-project.org/) says of itself, it is "an integrated suite of software facilities for data manipulation, calculation and graphical display" which according to its screenshots (I'd link, but it's in a stupid frame) already does editing and graphics display in OSX and Unix. Possibly by wrapping it in PyQt you could end up with something that would run also in Windows, but I'm pretty sure it would entail almost as much porting effort (for the various embedded C modules) as just porting R to windows, period. Certainly you wouldn't want to duplicate their code in Python? Or try to reproduce their graphics using Qt's drawing primitives?
Might I offer some constructive feedback? I think you need to make your specifications much clearer. I've read your post a couple times and I still don't really know what you want. And I'm familiar with Python, R and PyQT.
I actually don't know much about R, but just from what I know, you may be able to base some of this off a few existing tools. As you mention, SciPy and NumPy are essential for building such a tool. In addition, I know that [Pandas](http://pandas.sourceforge.net/) was developed to provide the data structures used in statistical programming (and at least some instances are directly inspired by R). Also, I don't know how advanced R's interface is, but [IPython](http://ipython.org/) might a good starting point for such an interface (specifically, look at their [browser-based notebook](http://blog.fperez.org/2012/01/ipython-notebook-historical.html) and [PyQt console](http://ipython.org/ipython-doc/dev/interactive/qtconsole.html). Also, [Statsmodel](http://statsmodels.sourceforge.net/) may provide many of the necessary components.
What is wrong with namespaces being honking?
&gt; A Python R console also allows for a hybrid R/Python (SciPy/NumPy) interface to be developed (a more advanced project that would extend these two that we can put on the TODO list for now). Orthogonal to what you're saying, but I've done this at my institution in form of a series of packages that work as wrappers for some R libraries (those for microarray data analysis, which I use). In short, a Python interface (API-wise) to some bits of R data analysis. I used rpy2, scipy, scikits.statsmodels and pandas. And yeah, I wanted to write a publication but it got rejected as it's not really that new.
Something you should knowâ€”programmers are often jealous of mathematicians.
If you're interested, I already wrote a very simple GUI for R using Tkinter, when I got frustrated by the lack of a GUI on Linux (I tried R commander, but didn't much like it). I called it ARE (An R Environment): https://github.com/takluyver/ARE It is very basic - there's an editing pane on the left, and a console pane on the right. Select some text in the editing pane and hit F5 to run it. I still use it, although I know there are more advanced cross platform tools like [RStudio](http://rstudio.org/) now. But I'm hoping that tools like scikits.statsmodels develop to the point where I don't need to use R at all. ;-) It'd be great to manipulate my data and do the analysis all in Python, especially with an interface like the IPython notebook.
Your name is fucking awesome. I wish mine had brackets 'n' shit in it.
Rather nice, I love these kinds of solutions!
I'm finishing my thesis too and I also build software tools. This is exactly the kind of post/proposal I would write after my morning triple-coffee powered brainstorm.
Could anyone explain what is he talking about?
The rest of the text doesn't mention any specific language feature, and the tone is different from the rest of the text (this is obvious to a native speaker, at least). So it feels very out of place.
I hope someone can chime in as I want to learn decorators, but they are too difficult for me to understand at the moment.
Python allows one to define the value of any attribute on an object "dynamically" using the [`@property`][1] decorator. class Thing(object): @property def value(self): return 6 * 7 obj = Thing() obj.value # Returns 42 The magic that makes this happen is [descriptors][2]. You can define a custom descriptor and use it as an attribute on your class, and it will intercept every call to get/set the attribute value, giving your code the chance to calculate the value on-the-fly. This is cool. But you then have the overhead of going through that descriptor every time you get/set the attribute value. Also if you want to store the computed value for the next time it is accessed you still have to choose a unique attribute name and store it on the object. *(Well, you don't have to do it that way, but that's the way it is typically done.)* What he wants is a property whose value is calculated on-the-fly the first time it is accessed, but which doesn't have the overhead of going through the descriptor every time it is accessed, and which takes care of choosing a unique name to store the value on the object. His article describes one solution. [1]: http://docs.python.org/library/functions.html#property [2]: http://docs.python.org/reference/datamodel.html#descriptors 
He also deleted my comment explaining why True**False evaluates to 1. Maybe he's a saboteur from Ruby or something? :)
This isn't the best example of decorator usage, as property can be a bit obtuse compared to standard decorator usage. A decorator is a function that takes in a function and returns another function. You can replace function with "callable object" in the above statement if you so desire. A good explanation can be found here: http://stackoverflow.com/questions/739654/understanding-python-decorators. Both the top answers are valid, but the second goes into much more depth.
Your example doesn't satisfy the requirements and more importantly doesn't work, even on Python 3 (in Python 2 you need to inherit from `object` to use descriptors). &gt;&gt;&gt; obj = Test() &gt;&gt;&gt; obj.bar Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 4, in bar AttributeError: can't set attribute 
Which version of Python is your example compatible with?
Great link, thanks.
2.7.2
I see now, thanks, although I don't understand exactly why it works. However it only works on Python 2 and only for old-style classes, which makes it of limited use.
As someone who uses old style classes almost exclusivly (not for any ideological reason), it's what I would do when presented with the problem. However, yes, for someone who uses python 3 or new style classes, it won't work.
For those wondering why `property()` isn't suitable for this, note the distinction between data descriptors and non-data descriptors: &gt; [Data descriptors with `__set__()` and `__get__()` defined always override a redefinition in an instance dictionary. In contrast, non-data descriptors can be overridden by instances.](http://docs.python.org/reference/datamodel.html#invoking-descriptors) In other words, a data descriptor (like `property()`) is always used first for gets and sets, while a non-data descriptor is checked *after* looking in `__dict__` during a get and of course does not define a set operation so the usual store into `__dict__` happens instead. Subsequent gets see the value in `__dict__` first and bypass the descriptor entirely, making it invisible unless the value is later deleted. `property()` chooses to always act as a data descriptor. If you do not pass a set or delete method, it supplies one that raises an exception `AttributeError: can't set attribute`. This is most consistent with its usual role as a calculated attribute. If it did not act as a data descriptor then users could accidentally replace it with a normal value.
Interesting that you go for old-style classes. Why? Proper descriptor support is a great advantage for the new-style. Reading [this][1], I understand why your example works now, but it's awfully hacky. [1]: http://www.python.org/download/releases/2.2.2/descrintro/#property
Ha, you're right--and I hope we get there, but we're not quite there yet though.
This would be an attractive solution if the desktop version (local) didn't have to spawn a web server. 
Haha, mine would normally be starting a brand new project--at least these I have thought a great deal about and have worked on. :)
If we could get the R pieces properly connect, you've hit the nail on the head of where I'd like to this someday.
Your English is fun to read :)
It's kind of interesting that you're getting downvoted. I've been using python almost exclusively for 12 years and my initial reaction was that you were wrong too. I bet the problem stems from the fact that the people who know enough about python to weigh in also know enough to be able to skim python code and get the gist of it. I saw "@property" and "some code that basically says return 42" and I thought "this guy has no clue what he's talking about". But of course the two lines I glossed over really say "return 42 but also replace this entire method with a constant so there's no overhead next time". I upvoted you for being correct, but I'd warn against doing this without an explicit marker. (A simple alias like "lazy = property" so you can say "@lazy" and indicate something different is going on would make it much more readable.) 
I'm not sure why I'm even contemplating defending my code. It's correct, it's perferable in some situations, but in the majority of situations it's not what what you want. Personally, I have got into the (bad?) habit of declaring classes as old stlye when I'm not inheriting anything, but havn't noticed that usually I'm using new style classes because the classes I'm inheriting from are new style somewhere up the mro. I've never noticed before, so I guess I don't use newstyle features.
I thought maybe it was a habit you had from using pre-2.2 Python. I started with Python 2.3 and the tutorials all seemed to point me to new-style classes, so that's *my* habit. Since then I've cursed [ElementTree many times for using old-style classes][1] (I know that's [changed in recent versions][2]) thus making it harder to override behaviour. The down-votes are certainly not deserved. [1]: http://hg.python.org/cpython/file/9f8771e09052/Lib/xml/etree/ElementTree.py#l159 [2]: http://hg.python.org/cpython/file/8527427914a2/Lib/xml/etree/ElementTree.py#l171
The notes are not saved between uses. Basically, every time one edits the note, it is recompiled and a new png is generated. These pngs have random names and are discarded when the program exits.
Definitely! But I chose to save the notes in XML. You can export just the notes to an XML file, or you can save the PDF+XML in a fileformat that Okular uses. That way, Okular users can import the notes in text format.
Absolutely, but this is MySQL-specific. Many other database systems have their own ways of doing something like this though.
Also, the OP never said he was working with MySQL.
Please do not immediately duplicate StackOverflow posts here. If you asked it there, let it be answered there. If time goes by where you don't get the right answer, then ask it here.
If you work with gihub there's a little chance I can help. Just add Drvanon and notify me the link. 
If I understand this correctly, this makes a list called primes, and a phantom list called count, and then... where does the value of p come from?
I want to learn but I have no idea what you just said.
it is. i find it easy to go overboard with traits though. though you *can* use it in pretty much every project, i find that most projects do not require their complexity (and the magic that goes along with it).
Decorators and some of the standard library are influenced by Java.
The key is toasting the bun and not over cooking the meat.
Traits' coolness is epitomized by [mayavi](http://code.enthought.com/projects/mayavi/). I love TraitsUI module while writing my small scripts where having a UI is just a bonus.
It looks like it might be architecture astronautics, or it *might* be OO done right. Given the people behind it, it could be the second, but I'm skeptical. Are there any good simple examples? 
Why exactly wouldn't it work with new-style classes?
It's very cool if it does what you need. It's also a complicated extension module that could be too heavy for your purposes. In a project that required adding metadata to the attributes of objects in a hierarchical way so they can be exposed in a GUI, much like Enthoughts' Traits, I rolled my own "minitraits" because we needed other features that Enthoughts' package doesn't have, e.g. specifying the appropriate sqlalchemy declaration. What is particularly nice is that the basic mechanisms can be performed with just a few classes in a single file, something like class trait(object): value = 'default' def __init__(self, val=None): self.value = val or self.value class has_traits(object): def __new__( cls, *args, **kwds ): obj = object.__new__(cls) traits = [k for k in dir(cls) if isinstance(getattr(cls,k),trait)] for k in traits: setattr(obj, k, getattr(obj,k).value) return obj and most everything else can be built by extending and complicating this basic mechanism. It's also possible to do this with metaclasses, and I think that might be cleaner, but.. I'm still working on the code. 
It actually doesn't start as expected. They delayed it without stating the time that it will actually start.
Read the readme; still not sure why I'd want to use this project? In my experience, more abstract a templating language becomes, the more it slows down development. I already know HTML, as do my designers and front-end developers.
You might like to check IPython's [traitlets](http://ipython.org/ipython-doc/rel-0.12/api/generated/IPython.utils.traitlets.html) module. According to the docs, it's "designed to provide a lightweight, simple, pure Python version of many of the capabilities of enthought.traits". I haven't used it myself, though. *edit*: Just took a look at the code, seems pretty much self-contained. I'd give it a shot.
Alright, I think I've got some of the information I needed, but not quite enough to answer the question. I think I should define a few words related to programming so that we're speaking the same language. I apologize if any of this is too simple for you. I just want to make sure I've covered all the basics for someone who has never tried programming before. * Code: A set of instructions which can be carried out by a computer and any data needed to carry out those instructions. * Source code: The original code used to make a program; generally designed to be read and changed by humans. In Python, source code is stored in .py files. I'd like to see the relevant parts of your source code so that I can figure out how to answer your question. * Bytecode: Code which is designed to be read by an interpreter, rather than by humans. Bytecode is only used by interpreted languages. In Python, bytecode is stored in .pyc and .pyo files. I'm just mentioning this so that you know about at least two different kinds of code. * (Software) library: A packaged collection of code which can be referenced by other code. Useful for saving programmers from having to reinvent commonly needed features. In Python, you can use a library after you use the *import* statement. * Software framework: A collection of libraries involving a huge amount of code which allows programmers to handle a specific task in an organized and convenient manner. * User: A person who uses a program. * Interface: The part of a program that gives information to a user (usually in a window) and takes commands from a user (usually by clicking on things). Some programs have no interface and run invisibly on your computer. * GUI: Graphical User Interface. This is the most common kind of interface. It's the familiar interface with windows, buttons, pictures, sliders and so on. * GUI framework: A framework used by a program to provide a GUI to users. It sounds like vpython is your GUI framework. * Interactive Development Environment (IDE): This is what you use to make programs. It gives you a place to write your code, tells you when you've made mistakes, colors your code to help you read it, converts your source code to bytecode, gives you an environment to test your program and so on. In Python, your IDE is called IDLE because it's your Interactive DeveLopment Environment. Now that you've told me you're using vpython I can check their [documentation](http://vpython.org/webdoc/visual/index.html) (basically a reference manual) to figure out how it's supposed to be used. Since you've at least given me the name of the GUI framework you're using, I've been able to learn about it by reading the documentation. I can tell you that you can get the slider's current value by checking slider_name_here.value. You could also set slider_name_here.action to have a function which does things for you when the slider is moved. However, I still can't answer your question for you without seeing some source code. My answer will be different depending on how you've stored your variables, what names you've given them and so on.
Program starts like so: from __future__ import division from visual import * from visual.graph import* from visual.controls import* This is the code for the slider: def change(): # Called by controls when slider moves if b.value == '1e-14': b.value = '1e-16' else: b.value = '1e-15' c = controls() # Create controls window # Create a slider in the controls window: s= slider(pos=(0,1), min=1e-16, max=1e-14, value=.25e-16, axis=(10,0,0), size=(10,1), text='slide me', action=lambda: change(b) ) while 1: c.interact() # Check for mouse events and drive specified actions I am attempting to change b: ##Constants massAu = (79+118)*1.7e-27 massAlpha = (2+2)*1.7e-27 qAu = 2*1.6e-19 qAlpha = 79*1.6e-19 oofpez = 9e9 deltat = 1e-23 b=input(value=slider) I am sure there are mistakes within the code, and I really appreciate the time you are putting in to helping me, I can't thank you enough for your help.
Congratulations to Four Digits. Arnhem is a wonderful location in The Netherlands. For those coming from abroad the Netherlands, you might want to travel cheap to Weeze airport with Ryanair. Airport Weeze is located between German city Duesseldorf and the Dutch city of Nijmegen. Or you fly cheap to Eindhoven Airport (also Ryanair and other low cost carriers/operators). Both airports are about 60 minutes travelling by car to Arnhem. Note: It is easier to get with the train from Eindhoven to Arnhem than from Weeze. From Schiphol airport it will be 1 hour and 30 minutes by train or car. Advise is to take the train from Schiphol. Easy and no risk of traffic jams as these might cost you quite some extra travelling time during rush hours. See you there! Coffeeshops can also be found in Arnhem, but it would be better to visit the conference instead ;-)
agree. the downsides far outweigh the anticipated upside for this for some projects. I imagine for quick one offs with 1 developer it might be useful. But for "big boy" projects, there are better tools. 
Tip: You can format code posted on Reddit by putting four spaces in front of each line. #This is an example. Before you edited your post, I saw some code that wasn't in the vpython documentation. In particular, this line: b=input(value=slider) I don't see any documentation about what input is. My guess is that we're probably going to need to know how that works if we're going to fix the slider. There are two useful tricks in Python for learning about an unknown function or method. Try the following: print input.__doc__ print dir (input) The first line, with input.\_\_doc\_\_, will give you any documentation which has been associated with input. It's possible that there will be no documentation, or that the documentation won't be very useful, but I'm hoping that's not the case. The second line, with dir (input) will tell you every attribute held by input (think 'dir'ectory). There's also a special test we can do here: print type (input (value=slider)) This will tell us what type of object input creates, and we might be able to learn more about the problem by investigating that object. It would also help if you could tell me exactly what your program is doing. Are you getting an exception, or can you move the slider but nothing happens?
I agree with the abstraction bit when it comes to template languages, but I'd call this sparse before I'd call it abstract. Coming from XSLT with custom extensions myself, I could go on and on but I'll just pick a single example. Creating an array and iterating over its members for output is stupid simple and much more readable.
You're right, the project does lack some additions that are planned down the road such as proper eclipse integration with outlining and python syntax checking. But, if you're referring to dreamweaver or the likes so a designer can go in and drag and drop blocks of elements, then no, this along with a number of other wildly successful and useful tools are not ready for those "big boy" projects.
I've never worked with a designer that is dragging and dropping elements. must be a west coast thing. 
Why not tell us about your exciting new benefits now instead of later?
You need pygame. Things I'm looking for: 1. A better name 2. bugs 3. suggestions 4. your opinion
Two quick thoughts: - Lots of almost meaningless variable names (when you're first time reading the code). Now, for x, y and r, g, b I'll understand the choice, but sr, sw, a, b, d, s, l1, l2 needs some code reading to see what's going on. - Not a single empty line! kind of unusual :Ã¾ Anyway, nice example of pygame with this snake game.
As far as I can tell, the blog posts describes usability problem encountered by a newcomer when using IDLE. Do you have suggestions for improving it? Saving the shell as a runnable script has its own set of subtle problems. See http://bugs.python.org/issue11838 
By paragraph: 1. pythonpackages.com does not host any packages. 2. Yes, much harder than it should be. 3 and 4. That's a different issue, but yeah the goal is to raise, not lower standards. 5. That's a different issue, too :-) 6. Thanks!
Surely a value proposition would encourage people to take your effort more seriously. The cool response you have on the mailing list is to be expected: you're introducing complexity and another surface of failure points to a system people are currently reliant on, without any indication that you are taking the responsibility and potential issues seriously, nor any explication of the benefits. For all I know, your project could disappear or go commercial before its killer feature is unveiled, or simply be rejected by the community for any number of reasons. You don't seem to have a history in the community which would give people confidence that you understand what you're stepping into or have compatible goals. Do you really think this is a good way to promote a project in the open source world?
if you already have Oracle installed I suppose it's ok but they only provide RPMs and those are 2GBs plus I couldn't care less about Oracle, just want to connect to an external db
Oh, interesting. The timeout feature is news to me; I obviously haven't looked at the API documentation since Python 2.6 was released (as this is when the timeout property was introduced). Thank you!
Interesting it says: &gt;The optional timeout parameter specifies a timeout in seconds for blocking operations like the connection attempt But will it work for read()? Because that's where the freeze happens. I'm going to find a way to test this...
It should, as read() is a blocking operation.
The point is not so much to make it significantly easier (though it will) but rather the amount of features you can build on top of a service that automates the package release process, e.g. https://twitter.com/#!/aclark4life/status/161270097422458881/photo/1
Right, no one is disputing this is trivial for you :-) See above. I'm more interested in the automation than the "typing it is saving me". With this service it will soon be possible to do a release to PyPI entirely TTW (i.e. via github merges and then pushing the release button. Look, ma! No terminal! There, I said it :-p. Now go sign up for the beta already ;-))
&gt; Surely a value proposition would encourage people to take your effort more seriously. The beta is scheduled for launch by the end of Q1 2012, but probably will launch much sooner. ~80 people already take it serious enough to sign up for the beta. I'm simply noting another milestone in the project, nothing more to see hereâ€¦ &gt; The cool response you have on the mailing list is to be expected: you're introducing complexity and another surface of failure points to a system people are currently reliant on, without any indication that you are taking the responsibility and potential issues seriously, nor any explication of the benefits. Are we reading the same thread? Looks like I'm taking it very serious to me. &gt; For all I know, your project could disappear or go commercial before its killer feature is unveiled, or simply be rejected by the community for any number of reasons. Then don't sign up for the beta. &gt; You don't seem to have a history in the community which would give people confidence that you understand what you're stepping into or have compatible goals. http://aclark.net/team#aclark &gt; Do you really think this is a good way to promote a project in the open source world? I think it's a good way to promote a commercial project that markets itself to Python developers, yes. 
Here's a bit more: https://twitter.com/#!/aclark4life/status/161270097422458881/photo/1
Like I said, I'm not disputing the workflow is trivial for you. What I am saying is that I've configured a new PyPI user to upload packages sans credentials via pypissh, and that I'm using that approach successfully in my web application. If PyPI gets OAuth support, this will all be moot (which could happen in March, if you read the catalog-sig thread).
There have been a couple of pycon talks (single 1 hour lectures) on NLTK, you should find them hosted on blip.tv, like this one: http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2010-the-python-and-the-elephant-large-scale-natural-language-processing-with-nltk-and-dumbo-120-3279057
If you want to make your own, it uses [pyHook](http://sourceforge.net/apps/mediawiki/pyhook/index.php?title=Main_Page) to hook into the Keyboard. Or you could try reading the [raw input](http://msdn.microsoft.com/en-us/library/windows/desktop/ms645543\(v=vs.85\).aspx) of the keyboard manually.
TIL! Its like a lighter twisted I guess?
I think others may have stronger feelings about twisted vs eventlet pros/cons, but I found eventlet simple to learn quickly and use for some hackish projects ;)
And you noticed that crawling Wikipedia completely [doesnâ€™t make any sense](http://en.wikipedia.org/wiki/Wikipedia:Database_download), did you?
They are actually pretty decent on the topic of anything Keylogger. Check out the Python forum over there and you will find what you seek. [Good thread](http://www.hackforums.net/showthread.php?tid=2071191)
The power of reading the docs!
In that case, I still disagree with the "bad premise" part. Perhaps I like measuring penises. Maybe I can type "penis" and "Tlahuixcalpantecuhtli" really quickly, but not "The quick brown turd rolls over cho fat momma".
I love that line. It's so zen. But, you might have to have a deeper understanding to get it. To give you an idea, that line surprises you. Think about the fact that this surprise, this break of convention, might be intentional. It might be related to the principle of [Datsuzoku](http://en.wikipedia.org/wiki/Japanese_aesthetics): unbounded by convention, free. 
Congrats on creating the poster. Some people will like it for sure. If you truly want to create something so valuable that python programmers will throw money at you, I suggest to spend a little time studying [Japanese aesthetics](http://en.wikipedia.org/wiki/Japanese_aesthetics) especially the [Wabi-sabi](http://www.presentationzen.com/presentationzen/2005/11/more_on_wabisab.html) 
if you do the chimp tutorial, i'll add you as a collaborator in git.
In my opinion, I don't see what's wrong with a WPM test that gives you a passage of words you'd normally type, with a little bit of simple grammar thrown in (periods, capitalizing first letters of each sentence, some punctuation, etc.).
Why dont you solve the problem for pypi rather than make your own?
What are you hiding in that bag aclark? 
IPython also implements something they call "Traitlets". And yes, I think Traits and IPython's implementation make heavy use of metaclasses.
I'd say yes. If I had to build end-user GUIs, or if I was doing some sort of analysis task and was not content with IPython and the command line, I'd definitely use Traits.
Well, that's not suitable for some cases. But [this is](http://www.mediawiki.org/wiki/API:Main_page).
Cheers, not exactly what I was looking for because I don't actually know the range the y-axis is (the plots change around a lot depending on the code) but I think I can use this to get what I want by taking 0, 25%, 50%, 75% and 100% of the maximum of each plot and converting those values into strings for the labels. Thanks :D
Thanks for the heads up - I am going to start using the Special:Export setting as to not get my IP banned from Wikipedia for misuse.
Mexica tiahui
I'll give this a chance. As an analogy, preparing a patch and emailing it to the maintainer is easy, but Github's edit-online-and-submit-a-pull-request-instantly model makes trivial changes *ridiculously* easy. If we want to grow the programming community, I think we also need to stop assuming that everybody has a terminal open all the time and wants to remember a list of commands. That said, aclark, I think this sort of thing would make more sense as part of PyPI, than as a separate site. The management interface there could easily have links to the project's version control repo, and a way to pick a tag and release it. Or even to set up automatic releases triggered by certain tags.
+1 for Requests.
For fun, I pinged localhost over night and sent 34k packets, and managed to lose 6. I didn't think that was possible.
&gt;Threads are easy to kill Haha, no!
If you are just after finding out your WPM, check out [whatpulse](http://whatpulse.org), which is essentially a statistics program for tracking key presses.
The article is from 2007 but still applies to current Pythons. However the author notes one could override the list's `__len__` method to get the behaviour he wants, then notes this causes problems for other contexts. What he actually wants is to define [the behaviour of `__nonzero__`][1] so that it returns `True` even when the list is empty. &gt;&gt;&gt; class MyList(list): ... def __nonzero__(self): ... return True ... &gt;&gt;&gt; obj = MyList() &gt;&gt;&gt; len(obj) 0 &gt;&gt;&gt; bool(obj) True Either way, it would make more sense for his function to raise an exception if the file format is bad (as one of the comments argues). [1]: http://docs.python.org/reference/datamodel.html#object.__nonzero__
http://learnpythonthehardway.org/ Also, check out /r/learnpython
Why is a packet's TTL sexy?
This depends on what you are trying to do. If either of you ever wants to get deep into computer science, then it is better to start out with math/theory/logic, then a basic understanding of data types like int and char, then start coding. Far more productive. I recommend learnpythonthehardway.org If you don't have the math/logic background, you will have so many tools and no idea what to do. The focus when you learn programming should be on the programming, with the patterns and algorithms to solve the issue already formed in your mind.
using [pyhook](http://sourceforge.net/apps/mediawiki/pyhook/index.php?title=Main_Page) this would be very easy to code
sharing some of your code would help a lot here since "invalid syntax" usually means that there is a problem with the code's structure or formatting
This is exactly what I thought of as well. Making games just keeps it interesting for everyone.
But I'd advise people to avoid modifying basic types like that: it breaks other coders expectations about how things work (empty collections normally booleate* to False), and it relies on the test always getting an instance of your special class. Also, if anyone's trying this on Python 3, replace `__nonzero__` with `__bool__` *booleate: boolean evaluate ;)
[Think Python](http://greenteapress.com/thinkpython/) [download pdf](http://greenteapress.com/thinkpython/thinkpython.pdf) 
My GF is a librarian migrating more to the metadata/IS side, so she wants to learn a bit of programming, I assume to understand more of the tools and perhaps to write some scripts. My son probably wants to hack into banks and write video games. I would ask him but he's not talking to me at the moment.
Yeah, I've been looking at http://sourceforge.net/apps/mediawiki/pyhook/index.php?title=PyHook_Tutorial. Thought it'd be a bit harder than it seems, but oh well.
probably but as I've said, I don't have nor want (and probably can't) install Oracle so this is the way.
Ok, so I went through this a bit more, fixing up the indention (which appears was mangled when you posted it). I understand now how the program runs without the mandatory object passing ("self") for methods. The indention shown here hides it, but almost the entire program seems to exist under indention of App.__init__(). So getnumber(), clrwindow(), decode(), etc aren't methods of App, they are internal functions of App.__init__(). It obviously works... but is not exactly what most programmers would probably call "pythonic". For one, the evaluation of the possible word choices is mixed deep into the core of your gui layout. To me, this screams to be refactored into two main concerns: the gui and the "business logic" of your program. The most straightforward way would be to have two separate classes. One class would know how to generate the stream of possible character patterns (ideally, this would be a generator class that implements the iterator protocol). The other class would handle the UI. The UI class could create instances of the "solver" class as needed in response to callbacks, and the results of the solver would be sent to the UI to update the results panel. Also... it's worth noting that the stdlib has the itertools package, which has a great little function 'product', which pretty much impliments your permu() and apprun() functions directly. It just needs to be passed in an iterable of the various possible letters and it will spit back out all the ways the values within that iterable can be combined (in the order specified). e.g.: &gt;&gt;&gt; [''.join(x) for x in itertools.product('abc','mno', 'tuv')] ['amt', 'amu', 'amv', 'ant', 'anu', 'anv', 'aot', 'aou', 'aov', 'bmt', 'bmu', 'bmv', 'bnt', 'bnu', 'bnv', 'bot', 'bou', 'bov', 'cmt', 'cmu', 'cmv', 'cnt', 'cnu', 'cnv', 'cot', 'cou', 'cov'] You can easily get build that list of iterables required by itertools.product by using your input string to map into your 'listall' (although, you do mix up the contents of listall, which might make it harder (listall[0] and listall[1] are both strings; listall[2] through listall[9] are lists of strings).
If, the problem is with PIL itself, try installing Pillow (this is a fork of PIL). pip install pillow But if the problem is with your code: * Any stacktrace you can share? * What about sharing your code?
I'm planning on moving away from command line so that it caters to more users (especially people who don't know anything about unix or cmd). I've fixed the variable names and tabs. I'll get to the white space soon. Right now I'm working on a menu system for 0.4.
Thanks for the feedback. I've fixed the variable names.
A good one could be: [Beginning Python Visualization](http://www.apress.com/open-source/python/9781430218432), by Shai Vaingast. Full of good common sense, teaches basic Python and uses that on interesting sample projects. Quite an easy read also.
You are welcome. I really suggest chimp pygame.org/docs/tut/chimp/ChimpLineByLine.html, it is till now the second best tutorial I have found.
thanks, i'm going to check it out,
They're not? I'm coming from a C# background where this is the case. 
I know but rst is the standard for Python/Sphinx documentation so it would make sense to make a guide to it that wasn't just a reference.
Also, the author is a Redditor who will answer questions you email him.
&gt; I wish that empty lists didn't evaluate to False, but that's the way it is, so you just have to keep it in mind. Maybe I'm weird, but I prefer Python's behaviour in this case. In fact, this is one of my most frequent mistakes in other languages like JavaScript. In most cases you know whether you're expecting a collection (let's throw `str` and its brethren in this category in this case) or a scalar value. I find that this avoids the common null-checking boilerplate of other languages (`if string is not None and string.length &gt; 0` etc) while simultaneously discouraging the dreaded "using return values as failure indicators" anti-pattern (use Exceptions FFS!). If you want the distinction, you can explicitly check against `None`. Heck, anything is better than JavaScript's `null`/`undefined` madness.
I'm not sure why this happened- but I uninstalled everything and then reinstalled it all and the command worked! :D Sorry for wasting your time, guys, but thanks for trying to help! I'm sure I'll be back with more questions sometime soon haha
Good to know.
When I can afford a new HDD, I shall. ;-;
If you're on Windows, you can use WMI for this. [Tim Golden's WMI package](http://timgolden.me.uk/python/wmi/index.html) makes this very easy.
Thanks, I'll check it out!
Without understanding what you really want, I'd check out [Fabric](http://docs.fabfile.org/en/1.3.3/index.html) if you need to get this information from the machines themselves rather than a central server that has it.
I haven't seen that one before. This looks like your PYTHONPATH somehow includes /var/mail. Does /var/mail/idlelib exist as a directory on your filesystem? Report what you see with: import sys print(sys.path) 
/var/mail is empty... very strange. Here is the path from the print statement: ['', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/distribute-0.6.24-py2.7.egg', '/Library/Python/2.7/site-packages/pip-1.0.2-py2.7.egg', '/System/Library/Frameworks/Python.framework/Versions/src/scipy', '/System/Library/Frameworks/Python.framework/Versions/src/matplotlib/lib', '/usr/local/lib/python', '/usr/local/Cellar', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages', '/usr/local/Cellar/python/2.7.2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/setuptools-0.6c11-py2.7.egg-info', '/Library/Python/2.7/site-packages'] 
The files are xls? Yeah, get back to the vba dude.
I say pay somebody on odesk :) Put together 2 sample spreadsheets and put up the req on odesk
Ahh - sorry. Here you go: terminate called throwing an exceptionAbort trap: 6 There are over 84 lines that pop off of that.
Ok - so the error i traced from the previous error pointed to sizewell (a window resizing tool), which i thought was strange. I turned off the program and now IDLE runs fine. Damn strange for something like that to impact IDLE. Thanks for your help!
I like RTDs but have one minor issue with their tag. I dislike it when things are nailed to the footer. [See this](http://docs.pylonsproject.org/projects/pyramid/en/1.3-branch/) for an example, bottom right. To workaround it I end up deleting the element through Firebug to so it won't 'follow' me as I scroll. Maybe I'm the only one slightly irked by this but it'd be nice if it had a hide and unhide option like many footer bars. It's a great concept though!
How about putting the links into a csv file and importing them into excel?
I can. There are 1006 of them, from "aah" to "zzz."
Your question was probably downvoted because /r/learnpython and /r/learnprogramming are more suitable for newbie questions. 
Thanks for the awesome links guys!
and here are the templates. /templates/applayout.html &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt; &lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; {% with messages = get_flashed_messages() %} {% if messages %} &lt;ul&gt; {% for message in messages %} &lt;li&gt;{{ message }}&lt;/li&gt; {% endfor %} &lt;/ul&gt; {% endif %} {% endwith %} {% block content %} {% endblock content %} &lt;/body&gt; &lt;/html&gt; /templates/appwelcome.html {% extends "applayout.html" %} {% block content %} &lt;h2&gt; WELCOME &lt;/h2&gt; {% endblock content %} /apprsvp.html {% extends "applayout.html" %} {% block content %} &lt;h2&gt; RSVP &lt;/h2&gt; &lt;br&gt; &lt;form method="POST" action="."&gt; {{ form.csrf }} &lt;table&gt;&lt;tr&gt;&lt;td&gt; {{ form.name.label }}: &lt;/td&gt;&lt;td&gt; {{ form.name(size=50) }}&lt;br&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;{{ form.dates.label }}: &lt;/td&gt;&lt;td&gt; {{ form.dates(size=50) }}&lt;br&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;{{ form.guests.label }}: &lt;/td&gt;&lt;td&gt; {{ form.guests(size=50) }}&lt;br&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;{{ form.music.label }}: &lt;/td&gt;&lt;td&gt; {{ form.music(size=50) }}&lt;br&gt;&lt;br&gt; &lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;br&gt;&lt;br&gt; &lt;input type="submit" value="Submit"&gt; &lt;/form&gt; {% endblock content %}
I created these templates, and it worked fine for me (Debian GNU/Linux, Python 2.6, Flask 0.8). flowblok@heraan:~/tmp/redditbug/templates Z cat appwelcome.html {% for message in get_flashed_messages() %} {{ message }} {% endfor %} flowblok@heraan:~/tmp/redditbug/templates Z cat apprsvp.html &lt;form action="/rsvp" method="POST"&gt; &lt;p&gt; {{ form.name.label() }} {{ form.name() }} &lt;p&gt; {{ form.dates.label() }} {{ form.dates() }} &lt;p&gt; {{ form.guests.label() }} {{ form.guests() }} &lt;p&gt; {{ form.music.label() }} {{ form.music() }} &lt;p&gt; &lt;input type="submit"&gt; &lt;/form&gt; 
You could do it with openoffice and [pyUNO](http://www.openoffice.org/udk/python/python-bridge.html) 
[xlrd](http://pypi.python.org/pypi/xlrd) to read the info, [xlwt](http://pypi.python.org/pypi/xlwt) to write out a new combined one; [example](http://www.youlikeprogramming.com/2011/04/generating-excel-documents-with-the-xlwt-python-library-with-examples/) shows "Adding a Hyperlink to a Cell" about halfway down the page... (it's been a couple of years since I've used them myself, but at the time they were very useful...)
I have sworn off IDLE for ever and ever after a few similar problems in my first couple years of python programming. If it keeps giving you trouble, I recommend IPython as a (much better) replacement. 
Agreed.
In the directory of the Clint folder, where setup.py is, (Also make sure Python is properly set in your PATH variable) python setup.py install EDIT: I'm a derp. Thanks, bixmix.
Agreed. But don't suggest r/learnpython when people ask here, or you'll get ye olde downvoatte brigayde all up on yer ass. Even for nontrivial questions, I feel like r/learnpython has plenty of experts who can help with most things. 
If he's in to video games (what 12 year old isn't), then [Beginning Game Development with Python and Pygame](http://www.amazon.com/Beginning-Game-Development-Python-Pygame/dp/1590598725/ref=sr_1_1?ie=UTF8&amp;qid=1327398606&amp;sr=8-1) may be a good choice. Disclaimer: author here.
I'm probably in the minority but I disagree. I'm an experienced Python programmer but I like seeing questions like that in this forum. I like seeing the responses because I learn stuff from them. I like seeing technical information in this subreddit. If posts are limited to just stuff like project announcement then the place looks like a bunch of press releases and becomes much less interesting in my opinion. 
I'm not aware of /r/learnpython. Thanks for the info.
I have no problem with Python questions, they sometimes lead to interesting discussion and the subreddit isn't so full that they drown out other stuff. Python has always had a culture that welcomed beginner questions from the earliest python mailing list onwards and I believe that's always been one of its strengths.
&gt; python setup.py install
In addition, the quality of the answers in this subreddit is much poorer than the quality on stackoverflow. People who read this should consider going to stackoverflow to ask questions. Most of them would find their answer by searching for their question on SO or often it's a matter of RTFM. I consider learnpython just that: learning how to use python at a beginner level and not a source for questions and answers beyond that. 
The problem of Stackoverflow is that it is a victim of its own success. It has become TOO popular and as a consequence, there are way too many questions that remain unanswered. Go and check for yourself.
and with ~2300 readers, /r/learnpython is about half the size of /r/banana so it can take a while to get your question answered
Just add some css to the /submit page with something like: &gt; For Python programming help please try [/r/learnpython](/r/learnpython) first. That should do. Example of implementation: http://www.reddit.com/r/videos/submit
Well lets shut this subreddit down and be done with it then :|
I agree, stack overflow might be the standard, but I could easily see someone getting frustrated with their amateur use of "game theory" (or whatever you would call it) to engage users. 
The 21st century IRC, "internet relay chat", is also an excellent resource for finding near instant information of the type you find on stack overflow.
&gt; Even after you've signed up for SO, you still have to earn enough points to be allowed to post questions or respond to answers, don't you? [Nope](http://stackoverflow.com/faq#reputation). You have to get 50 before you can leave comments (a stupid decision imo), but asking or answering questions can always be done.
You're missing the fact that everyone here can answer python questions. So it's a larger audience that is equally knowledgeable in the subject matter. Probably more so.
When it says: &gt;Youâ€™ll now have a new command available to you: easy_install. Where is that new command? The Command prompt? Inside Python? I ran the script and it went through a whole bunch of stuff...but I'm not finding the easy_install script to allow me to install pip. Thanks
Just contact us for an API key: http://minus.com/pages/contact Thanks! [John](http://john.minus.com)
if [/r/learnpython](/r/learnpython) isn't up to speed, [/r/learnprogramming](/r/learnprogramming) should get you a quicker response.
+1 to this. I used xlrd and xlwt to maintain hundreds of spreadsheets in a data warehousing department for a summer job. (This was their answer when they were asked to document their databases.)
Although it is a great resource, people on stackoverflow, etc. can be real assholes to people asking questions that aren't "allowed", aren't in the appropriate location, etc. 
multiprocessing was the first thing i tried in python. - my supposedly real-time voice processing wasn't fast enough in a single thread - so i strung little processes together in python - &amp; magically it all worked fine. 
Dude. Awesome. Thank you.
http://www.microsoft.com/download/en/details.aspx?id=12028 Scriptomatic produces python code
Give [IdleX](http://idlex.sourceforge.net) a try. It fixes a lot of problems with IDLE.
If someone puts out enough low quality but still upvoteable answers, I am inclined to let them have their karma. If it answers the question, even without being particularly deep or insightful, I don't mind. 
No, there's only one way to do it.
Not to mention that they'll generally get better support by going to SO anyway.
Good idea! This relies on inotify to pick up changes, which is Linux-only, but for Mac one could make use of [watchdog][1] or see if the guts of the notification stuff can be extracted from [fileconveyor][2]. Both support Linux/Mac/Win, watchdog uses the Apache License, fileconveyor uses the GPL license. [1]: https://github.com/gorakhargosh/watchdog [2]: https://github.com/wimleers/fileconveyor 
I'm not sure I agree. Have you been to #python on freenode? Seems to be operated by a lot of people with very big opinions of themselves. Every time I ask a question there (Literally *every* time) I am insulted for asking "silly questions". Although to be fair, I stopped going there about a year ago, so maybe it's gone through some changes.
&gt; This relies on inotify to pick up changes, which is Linux-only That's another reason why I used the command-line interface, rather than `pyinotify`: I thought it would be easier to come up with commands for OS X and Windows which return when a watched-for event occurs - using whatever library is available. Then, you just replace the Linux command with the alternative for the other platforms (e.g. using `watchmedo`), and nothing else might need to be changed. EDIT: I updated the linked blog post to show alternatives to `inotifywait` for Windows and Mac OS X.
Hmmm, I'd say that most questions are maximally-googleable. The things that I can't find on google I usually can't find on stackoverflow either.
I haven't ever used #python. A lot of open source projects seem to have very friendly communities though.
I said what I meant and meant what I said: personally, I'm OK with /r/python being one place amongst many where people can ask even very basic questions about Python. Whether making it *not* be such a place is an insurmountable hurdle doesn't even come into the picture, so far as I'm concerned.
I'm not a Twisted expert and don't have time really to be reading through code anyway, but if you try r/learnpython, they exist to help (people in this subreddit mostly are here to swap Python-related news, factoids, and edutainment). 
I spent a couple years idling in that channel. Personally, I answered hundreds of questions and directed dozens of people to the right resources to find answers. It was fun to help, but people would pop in, spit out their problem and start pasting code and tracebacks all over the place. Some would get testy when nobody helped within a few seconds. Everyone handled it in different ways and, of the hundred or so "experts" idling around to help, many would get cranky if you didn't try Google first or read the docs on the methods or datatypes you were trying to use. Sorry you had bad experiences. In general it's still a good place to find out if you are headed in the right direction, you just have to go in there the right way: use pastie to put up your source and any tracebacks/warnings, enter the room and idle for a second to make sure there aren't too many people talking already, and finally ask the question once -- being concise and linking to the paste. If you want help often, idle there all the time and see if you can answer a beginner's question (i.e. "pay it forward"). I'm sure you'll notice a trend of everyone asking the same questions all the time and/or refusing to check the docs themselves, preferring that someone just fix their code for them. It's a strange ecosystem indeed, but it's still easy to get what you need if you try to understand the people that idle in there a bit.
Ditto. I've asked a few Python related questions in r/python and received lots of helpful and thoughtful responses. Honestly, I think it's partly due to the success and popularity of SO. In comparison, r/python is a bit off the beaten track. 
The languages are sufficiently similar.. The bulk of your *knowledge* will be transferable.. However, the *code* may still require non-trivial amount of porting effort.. 
Make sure that you are asking [good questions](http://www.gerv.net/hacking/how-to-ask-good-questions/) by learning how to [ask questions the smart way](http://www.catb.org/~esr/faqs/smart-questions.html).
From my understanding distutils is for building and installing application written in C and Python. I'm looking for something more general purpose: I want to define specific commands and the actions that should be taken for each one. For example, I might want a command to compress the css files of my web app.
Great idea! 
http://pypi.python.org/pypi/zc.buildout/1.5.2
I hate stack overflow though.
How does this compare to blogofile for example? That is my current static site generator.
I use [fabric](http://docs.fabfile.org/en/1.3.3/index.html) for this very frequently, even for non-python projects. Just having it installed is very handy. Create a file called 'fabfile.py' and define commands in it thusly: from fabric import task, local @task def cleanshit(): local('rm -rf ~/') Then run it in your command line like so: $ fab cleanshit It's awesome.
So since you're new to Python, I guess you're basically asking, how does Python and Django hosting work? This is actually not a simple question. Generally speaking, the emerged standard is WSGI, a standard interface between a web server and Python. For example with Apache, you'd use mod_wsgi. There are other ways of doing it. You can run a full web server in Python, then use mod_rewrite or ProxyPass in Apache to forward requests to your own webserver on another port. This complexity, as you can imagine, results in a lot of confusion. It's actually better now than it used to be. It's also why there are some hosting companies that specialize in deploying and running Python apps. WebFaction is one of them, MediaTemple is one I hear good things about too. Does that answer your question?
I vote for Paver. ((very) late edit): Paver looks very surpassed by Fabric now)
Personally, I've used [Fabricate](http://code.google.com/p/fabricate/) for simple build systems before. In order to deal with deploying to a remote server, you might also want to look into [Fabric](http://docs.fabfile.org), which is a way to automate running SSH commands on remote servers.
What is your hosting provider ? If it is a shared hosting, you can a local python virtualenv in your home directory and have pip to install any module. Check [this](http://www.web2pyslices.com/slices/take_slice/76) out on how to set it up.
I took a look, but I dont quite understand yet. What does virtualenv do? Does it somehow trick the server to execute a local python and it works? Can you please explain to a very desperate guy with limited python knowledge? edit: yes, I got a shared hosting, cheap spanish solution. But I heard they worked fine, wich they do, and they claimed they had python available, sigh....
Possibly a silly question, but what advantage does this have over just writing individual Python scripts for the tasks?
It's not a trick, it should work fine assuming you have shell access. It doesn't require any sudo privileges, and basically just links a local Python binary with any custom local modules you want to use. 1. Download [virtualenv](http://pypi.python.org/pypi/virtualenv) 2. Upload to your server and extract it 3. Run the virtualenv.py script in the folder, with one required argument, which is the name of the environment you want it to be called. You can also choose which version of Python to use at this point with the '-p' flag. Usually I name the environment after the version number of my application, or the current date in deployment, but it can be anything. 4. Run 'source bin/activate' inside the newly created environment and the local version of Python will override the existing one as long as you're in the environment. 5. Install any necessary modules you need with pip. This is the best way to deploy any Python-based web application (I use virtualenv when deploying Django, which works great). Alternatively, if you only need one module, why not just download the source of the module and use it as is? Just put the module library in the same directory as your existing code and it should work fine as well.
a) virtualenv: so I upload on 'any' folder of my host and create a working, independent python? But virtual env must call an installed python, and I fear I cannot install python in my hosting, I think I have not enough permissions/skill to do that. b) just mysqldb. this sounds great and simple, is it so? I just put mysqldb on the folder and hey presto magic? Bear in mind that I'm just on a shared server, a commercial hosting and I'm not allowed to tweak the settings. c) Please take a look at the notice i edited in my main post. 
&gt; CMS featured jekyll Can you elaborate on this (and you may assume I know Jekyll)? What are the extras?
Now THIS is interesting.
This. I really don't understand why zc.buildout doesn't get more love from the community. I use it now for all my python projects, big and small. It's super flexible and I've never had any problems with it, unlike alternatives such as virtualenv.
not to sound cruel, but since you say you are a "fake programmer" your options seem to be a.) become a real programmer or b.) get an account at a hoster that support mysql. Also: python module is one thing, are you sure the hoster has mysql installed?
Do they not provide any other db access module?
I don't look at VirtualEnv as a substitute for buildout (or vice versa), but rather a complimentary development tool. I use VirtualEnv to sandbox my development environment from my Python site packagesâ€”so I *know* I am not depending on anything that is not in the Standard Library in my application. I then add whatever third-party dependencies I need into the buildout script, including pinning particular versions (which I have had to do several times, e.g. to protect against awful, breaking beta releasesâ€”e.g. BeautifulSoup 4.0), which may differ from whatever versions my package manager may have installed or upgraded since I started development. If I intend to create an egg for application distribution, I then know exactly what packages and versions to use in my setup.py scriptâ€”although admittedly this doesn't happen often, because most of my buildout scripts end up pulling tarballs straight out of github (Great feature, that) for which there are no eggs on Pypi/elsewhere.
I use [Blogofile](http://blogofile). Needs some tweaking, but pretty cool, once you get it working.
nope. Its a shared server, so they say installing a module for one user is out of the question.
I don't think that's it. since buildout relies on recipes, the documentation burden is mostly on the authors of those. Some are documented better than others. looking at the actual docs of buildout, I can't imagine how it can really be improved. http://www.buildout.org/docs/index.html A list of recipes. http://www.buildout.org/docs/recipelist.html Yo dawg I heard you like virtualenv in your buildout.... http://pypi.python.org/pypi/tl.buildout_virtual_python/0.1.3 buildout suffers from being related to zope in my opinion. which is unfair honestly.
LOL, at first I was like, "What's the point in that?" because you can do the same with just using `subprocess.Popen` and the like, but then I realised that this is just pure abstraction on that, *and it's beautiful*.
 * a build-tool can check the inter-dependencies of your tasks and decide which ones need to be executed. * a **real** build-tool can also check if the task really needs to be executed again or it is up-to-date (and skips its execution). * other features will depend on the tool... 
What do you mean? What's the purpose of coming to poorly populated channel and ask "can I ask a question?"? If the guy doesn't leave in 2 minutes (which is usual) he'll wait an hour for an answer "Yes". But he doesn't see it immediately either and after another hour asks a question. But again, there is no one to answer. It's the most pointless question to ask in a support channel. Ever.
Thanks, just starting python using Learning Python the Hard Way, signed up for this one as it looks really interesting.
I didn't understand what you were saying at all. I read that as "don't ask a question if you're able to ask it" rather than "don't ask for permission to ask".
Ah, sorry for the confusion.
ah didn't see that - I've been using [s3vcp](http://pypi.python.org/pypi/s3vcp) which is about as effortless as you can get.
Me too :)
blogofile is absolutely nothing like Flask, frozen or not. I think you're mischaracterizing the "controller" concept, which is not something you ever need to deal with explicitly unless you want to tinker with how data-driven content is produced. If Blogofile has confused you by referring to "controllers" too often in it's documentation, then that's a simple issue of needing better docs. This is what building a static site with blogofile looks like: classics-MacBook-Pro:foo classic$ blogofile init bare Initializing the bare site template... classics-MacBook-Pro:foo classic$ vi index.html.mako classics-MacBook-Pro:foo classic$ blogofile build classics-MacBook-Pro:foo classic$ blogofile serve Blogofile server started on 127.0.0.1:8080 ... 
This looks promising. Can you elaborate more on the package placement thing? I mean, I got an egg file, should i first install it locally and then just pick up the directory to my host server?
This is very similar to a tool I wrote with the exception that I used the built-in `email` package to separate metadata from content rather than the triple-dash YAML header. That said, I'm a see if I can fork your project and stub that bit in. At least then I won't be solo hacking. =)
just in case, are you sure the service you are targeting is running in the same session id with the user(you)?
Fabric is equivalent to [Capistrano](https://github.com/capistrano/capistrano) from the Ruby world.
In fact, Python already decided to move to Py 3. And after py 3.2 was released last year it is not looking back.
This looked pretty awesome to me. My last startup did a lot of work with indexing and searching and I learned a lot. Two great resources for this kind of stuff are the Lucene code base: http://lucene.apache.org/java/docs/index.html (and Solr for a server built on top of Lucene), and Programming Erlang, which has a nice implementation of an indexer. There are also lucene bindings for python.
http://software-carpentry.org/4_0/make/intro/
Myopic view from some one who doesn't create re-distributed packages, but I might counter and say that virtualenv + fabric is a substitute for buildout. The biggest problems I've had with buildout have been generally around the recipes. Some packages (python-ldap I'm looking at you) have some strange build scripts and in general I haven't been able to make them work with buildout despite the recipes. With fabric and virtualenv the flexibility exists to do what actually needs doing.
And what role does a build tool play for a language that compiles and links itself just by being run? I use build tools all the time with C++; I've never found a need for one in Python.
A build tool is useful for Python apps with C extensions, and Python apps that are frozen for distribution to Windows machines (via py2exe and similar).
It is more like a role for your project than a role to the python language. Author of the question: "For example, I might want a command to compress the css files of my web app." build docs, run pyflakes, automate release process... I also use it as a functional test runner that needs to setup DB, start servers.
Aye, that's why I made sure to add that disclaimer :s The only thing restricting mynt to jinja atm is that the only renderer that exists right now is one for jinja. The parsers and renderers are completely modular.
This was due to a bug that is now fixed in v0.1.6. It should install just fine from pip now, and should pull in any necessary dependencies.
I completed Sebastian's AI course last year. The class was excellent and he is clearly a genius in the field. I disliked some aspects of his teaching style but the class was worth it. For computer science 101, I worry about his ability to communicate complex topics to beginners. He is also teaching CSC 373: Building a robotic car. Now that may be worth it because he is *the* expert in computer robotics.
Sounds useful to me ...
Aye, right now it's still a bit more of a developer's tool for those willing to dig a bit. At some point mynt will have a built in [octopress](http://octopress.org/) so-to-speak with an init command and a default theme. In the nearer future though, I'll be adding a *powered by* section to the docs site listing existing sites and their sources to give people some working examples to look at. For now, you can check out the [source](https://github.com/Anomareh/MirroredWhite) to my blog that uses mynt if you think that might help in the meantime.
I would love itâ€¦ if you plan to do it, knock me: I'll probably be able to help! 
Aye, that's the goal. Then for that type you could specify a whole set of options separate from posts *(e.g. url, parser, renderer, etc.)*. This is assuming that each publication is to have it's own page. For just making a list of data like that available in mynt, I'd just toss it in the config *(I believe you can even do that in jekyll)*. Everything in the config *(built-in setting or not)* is available via the *site* global variable. So instead of that frontmatter you'd just iterate over *site.publications*. Similar to how I'm using my blog's [config](https://github.com/Anomareh/MirroredWhite/blob/master/config.yml).
What operating system do you use? You need to add scrapy to your system's PATH variable. It's simple enough in any environment. Look it up or ask me if you can't figure it out and I'll tell you what you need to do.
According to the man pages, pip already works with git (and hg, bzr, svn): http://stackoverflow.com/questions/3689685/how-is-pip-install-using-git-different-than-just-cloning-a-repository Maybe instead you could edit pip itself and add the "intuit a setup.py file if none exists" code to a pull request. https://github.com/pypa/pip
How did you install? Hopefully via: pip install scrapy
 if (!qarrays) { Py_DECREF(tables); PyErr_NoMemory(); PyErr_SetString(PyExc_ValueError, "Not enough memory"); return NULL; } should be something like if (!qarrays) { Py_DECREF(tables); return PyErr_NoMemory(); } The ``PyErr_NoMemory`` function sets a ``MemoryError`` and returns NULL, so it's a shorthand function. Your implementation sets a ``MemoryError`` then immediately clobbers it with a ``ValueError``. You also do the same thing a few lines down.
[A book, but also a class \(available online\).](http://learnpythonthehardway.org/)
I imagine you could eliminate a lot of the boilerplate writing, but I doubt its possible to write a general script to analyze all Python git repos and spit out a setup.py. But maybe I'm wrong, definitely worth a shot.
lol, havn't heard that since 10th grade.
Waf is starting to get popular these days.
As I understood it, Sebastian won't actually be teaching the 101 class, rather it will be taught by David Evans. Sebastian will do the 373 one, though...
Free, as far as I can tell.
A territorial ircop worried about his domain falling into the anarchistic hands of those who would speak freely pretty much ruins a channel. I think it comes from a false sense of social responsibility.
Most of what you described is absolutely normal for IRC. I think #python just happens to be a bit strict, and when that strictness is called into question, the zen of python is abused in authoritarian ways.
is there more then one maintainer of PIL? like a mailing list of some kind? you could ask there to get your changes merged
They are teaching enough CS **TO** build a search engine...not BY
consider sending the change to pillow (PIL fork), IIRC, they are more open about patches/extentions. 
Til about pillow! ---- EDIT: http://pypi.python.org/pypi/Pillow/ 
Actually, you should not use PyErr_SetString in out-of-memory situations. It tries to generate new objects. Python stores a preallocated NoMemory-Exception object for this situation.
From the post: "I'm planning on using Python in the classes I teach." If you're teaching it, you have to decide on one version to use in class. Otherwise students will be copying lines of code and finding they don't work.
Patch pip
I used the Windows installer because I'm running windows 7.
PIL is dead/dying and already forked as a new package -- Pillow. 
Pillow does not (yet) contain any new code/features, but only changes to work better with pip and easy_install. Look at the changelog: http://pypi.python.org/pypi/Pillow I did some improvements for PNG encoding 1.5 years ago and my patch was accepted 6 month later, but a fix for my patch is still waiting. So maybe it is time for Pillow to become an "unfriendly" fork?! 
Unfriendly fork?
Oh thank god, does that mean there may be a Python 3 Pillow soon? PIL is what was preventing me from moving to Python 3.
We are considering Python 3, yes. If someone were to do the work and send a pull request, we would very strongly consider it.
The current fork is mainly a packaging fork, with other code changes very closely tracked. An unfriendly fork would be one that does not care at all about the upstream PIL. We still do.
Maybe, but it's a hard problem, and generally "pip installs packages"; it doesn't create them.
Left some comments at your branch.
ah. will you guys accept patches that upstream PIL won't accept? I'm mainly looking for python3 support, as PIL is one of the big libraries that hasn't been ported to python3 yet
I think there's only one maintainer. I post it to the PIL mailing list a few months ago. I didn't get any replies.
Thanks! I'll check that.
Nah; read the sylabus. &gt;**Week 1: How to get started: your first program ** Extracting a link **Week 2: How to repeat** Finding all the links on a page **Week 3: How to manage data** Crawling the web **Week 4: How to solve problems** Responding to search queries **Week 5: How programs run** Making things fast **Week 6: How to have infinite power** Ranking search results **Week 7: Where to go from here** Exam testing your knowledge Sure, they are going through the standard materials, but they are relating it back to their search engine at every single step.
If you're doing this:'scrapy startproject tutorial ' in the command line, then wherever the scrapy binary is, that needs to be on the path. It should just work if it's on the path. I'll install and figure out what it is you need to do. Just have to boot into Windows.
Not really. If you wrote a story or something in American English, you wouldn't have to rewrite the story so that a British person could understand it.
To reverse the string, something like this would work: string = "hello" string = string[::-1] To alternate the case, you could look in to the python .upper() and .lower() functions. Hope this helps.
You made sure to put a semicolon between that PATH entry and the previous entry? Also, you're sure you're using Python 2.7? In that case, all you have to do is open a new command line to be able to use it. If it still doesn't work, navigate to C:\Python27\Scripts in the file browser and see that scrapy and scrapy.bat are in that directory. If they aren't, you haven't installed scrapy correctly.
This is one way print ''.join([a(b) for a, b in zip(__import__('itertools').cycle([lambda x:x.lower(), lambda x:x.upper()]), reversed(raw_input('Insert string&gt;')))]) 
Strongly considering it, especially if there is no upstream progress on Python 3
Or rather, if you know how to ask the question in a way that that would please an experienced IRC subject-matter guru, then you likely already are one of the experienced IRC subject-matter gurus. That's actually one of the biggest problems with technology communities in general; they are accepting only of people who've already studied and bought into their particular technology, and they ridicule anyone who isn't between the ages of about 17 and 35. I remember when I was a newby programmer, I decided I wanted to build a simple roguelike video game, since it would allow me to write a real game w/out first knowing sound/graphics libraries, etc. I presented a very clear idea of what I wanted to do, and asked a dedicated rougelike programming channel if they liked the idea and if they had any idea where to start. They, of course, said that my project was unimportant to them, that rouglikes were too difficult to write for anyone but them, and that they all had their own rouglike projects to worry about, so why would I be stupid enough to talk about my own ideas for one, when they clearly didn't have the time to think about it? In the same way that the people who wrote those guides can "tell" whether or a person is worth talking to by looking at the question, I can tell whether or not they are worth talking to by reading the wording in their guides :). From the guide: Q: I can't get the code from project foo to compile. Why is it broken? A: The querent assumes that somebody else screwed up. Arrogant git... Perhaps that's true, but the answerer assumed that the asker isn't a kid just getting started, who doesn't even know what question to ask. They likely aren't assuming it's someone else's fault, they are just at a stage where they know a bit about programming, but don't know anything about compilation. The response is actually much more assumptious than the question, and much more arrogant. A more appropriate response would be direct them on where to get help for general program compilation, or to simply not answer at all if you are "above" helping people at this level (but if that's the case, then why would you be on that channel?). The point is, everyone used to be completely ignorant. I'm 100% certain of it. Hating on newbies just because they have the opportunity to be completely stupid online just prevents them from getting interested in the subject matter and becoming the next arrogant big-shot tech forum guru. 
I prefer Vim with a few plugins(SnipMate/NERDTree/PyFlakes/tab complete).
Try this: #!/usr/bin/env python # -*- coding: utf-8 -*- a = 'this is a test' print [(x.upper(),x.lower())[n % 2] for n,x in enumerate(a[::-1])] 
emacs python-mode/rope/autocomplete/flymake running pyflakes, version control mode, org-mode etc.... 
Any chance you could put it on pypi? Or put the setup.py file in the base directory so it can be installed with pip :) Finding out about this library is probabaly the best thing that has happened to me this week. Gone are the days of dirty regexes!
Please look around, search, etc. This question is asked very frequently.
It's there: http://pypi.python.org/pypi/phonenumbers.
This is great, thanks a lot!
Is this only for dependency resolution? PIP can install from github already with ease, iirc pip install git+url does the trick. In several years of python development I haven't ever come upon a dependency that I couldn't resolve manually in less then a minute (and these are rare), and I think this happened once or twice. I don't think such a tool is necessary. 
If you use IPython, you can type `foo?` as a shorthand for `help(foo)`, and if you type `foo??` then you get a source listing for foo.
PyCharm's syntax analysis is greedy and always uses all of your CPU cores. I "fixed" this problem by setting its processor affinity via Task Manager. The type inference that you get from the syntax analysis is golden, I'd suggest giving PyCharm another try.
Would you know how to set processor affinity in Linux?
Sounds great, but the last commit to blogofile was in April 2011, before the "Preview of Blogofile 0.8" post.
I use sublime text 2 on Windows 7, Mac and Ubuntu and it is great on all 3 :)
I was more or less curious as to what others used, not looking for something new. I apologize ._.
What's the name of the first Harry Potter book?
setup.py is really no more than writing a few lines of config.
Obviously, people are smarter than scripting language interpreters. The point of the analogy is that you need to make a few minor but persnickety adjustments in order to localize (localise?) for the audience. To port a British book, drop the u's and switch the single quotes to double quotes, etc. To port from Python 2 to 3, change print to a function, overhaul Unicode support (admittedly, this can be a pretty big task in some cases), and tidy up a few other loose ends. An intelligent human being should be able to understand either version though.
IDLE, but due to a dead HDD, Gedit. I like IDLE 'cause it features auto-tabifying, and syntax highlighting. I dislike it because there's all sorts of shit that I never use, and likely never will. Oh, and you require a .quit() in PyGame to make it behave properly in IDLE.
I still can't get numpy working in Ironpython 2.7.1 à² â•­â•®à² 
cool script, fyi - another option... http://ifttt.com/recipes/search?q=amazon+free+app
Hmm, is anyone tying in a GUI editor? I'd use Python a lot more if the GUI tools were better. 
fantastic!
Newer versions of gdb have python scripting [link](http://sourceware.org/gdb/current/onlinedocs/gdb/Python.html#Python)
Remember that in CPython it is *very* easy to integrate C/C++ code. I'd start with wrapping some of the existing C code you use in a nice Pythonic Extension API and show how easy it is to exercise (and in how fewer lines of code) libraries that are already there. Heck, if it's pure C you can just use CTypes to call out to it. Using Python as a high-level glue to code that's already there has been a superbly compelling example time and time again in my experience.
Oh! Excellent suggestion. It looks like the GDB Python extension was added in gdb 7.0 - but we're using gdb 6.8 with no chance of upgrading in the immediate future. Darn. Again, I'll keep this in mind - it might still be a worthwhile example.
I love python, it's my favorite language BUT, for the embedded world... have you taken a look at Lua? It's a beautiful language and, even if it doesn't come officially with batteries included, batteries can be found very easily. Also, LuaJIT is an amazing piece of technology. 
&gt; I greatly prefer Python over C for anything involving strings - parsing, manipulation, regex searching, etc. Yeah. "greatly prefer" is about the nicest way you could say it. Trying to do text manipulation in Python vs. C is the difference between a friendly touch and a punch to the face, in my experience. So, I've used Python to write a build system. I've also used pygccxml to parse C++ files, allowing me to provide default implementations for missing virtual-functions. The problem is that both of these examples are too big, and require too much context - I can pretty much guarantee that I'd lose my audience (I know, because I've tried explaining these tools face-to-face and invariably experience the politely glazed-over look of someone just waiting for me to stop talking). I suppose I need a problem that is simple enough that they could see their way to a solution in C. But complex enough that it would probably take a week. And then to show them that the Python version might take only a few hours. Setting up a test framework is a neat idea - I'll look into that. To be honest, I've never used ctypes or had to write the interface to a C library. Perhaps I should sit down and do this - maybe an example will present itself. Thanks for all the suggestions.
You may be interested in [Python-on-a-chip](http://code.google.com/p/python-on-a-chip/), that is Python running on embedded systems without an operating system.
Have you thought about prototyping? Writting proof-of-concept in Python and then porting it to C, not being distracted by algorithm itself...
my modus operandi is code a little, test a little. SciTE + Total Commander are my weapons of choice. SciTE is Zen. Simple, insanely fast, simple, simple... yet... it does a good job at auto-complete and provides assistance with errors while developing (links to files involved). Type a little; F5; see what happens, code some more.... F5... see what happens. 
We use python for most of our infrastructure, testing, benchmarking, building.. django also makes it easy to work on the important bit, presenting information.
What, seriously? The PVM opcodes seem too complex for a reasonably viable processor design...
It has been over a decade since I had my aha moment learning Python as a C programmer but this is what I remember being most impressed by: * REPL, being able to interactively test out little snippets of code, use it as a calculator, translate between hex/binary/decimal, prototype algorithms, even len("some constant string to hard code the length of"). * How easy it is to learn - When I realized I'd gone from never seeing python to writing fully functional code in hours, I got really excited. * The standard library - I spent days just browsing it and learning from it. * help() doc strings * dir() introspection My introduction was just reading http://docs.python.org/tutorial/. I didn't have a specific need or reason to learn python other than expanding my toolset. I think this was important because I wasn't given some task that I already knew how to do in C where I could possibly end up frustrated with Python because something didn't work exactly the way I was used to. I also wasn't shown some already completed Python project and told how great it was. I organically discovered its greatness and learning something on my own makes me feel accomplished. That said, here's my advice: * Don't try to win everyone over at once, start with one or two of the most open minded. * Let them read the tutorial and do the learning on their own. Just be there to answer questions. * Keep some Python books around on your desk at work, loan them out. * Don't be a fanboy. Python isn't perfect, be pragmatic about it, acknowledge its flaws. When and if you do help out with the learning process: * Keep it simple, stick to the default install and standard library at first, don't even mention pypi or pypy or python2 vs python3. * Stick to C language constructs at first, let them feel at home. Forget generators, list comprehensions, lambdas, meta programming, etc. * You might even want to dive in by showing how you can extend CPython with C. The C API is a good way for a C programmer to understand how CPython works and from there to "Wow, I can write Python bindings for my code and test things out on the REPL without having to re-compile constantly!". Good luck!
Around 2002 my team developed a c++ meta framework for debugging and testing. It allowed developers to develop using c-like functional programming in a c++ environment. Essentially it felt like C. We relied heavily on gnu template compilers so that we took a performance hit at compile time but not run time. We then developed a python interface to remotely access the debugging and testing framework within the embedded system via tcp. Essentially we could enable and disable runtime components. We could change the order of execution and we could stub components as well as inject data into the system at any execution point. For our industry, the normal development time was about 4 years from start to first product. Using the method above we shortened it to about 2 years and most of the first year and a half were brainstorming and prototyping the functionality of the framework. The real key though was our ability to dynamically manipulate anything we wanted to with python and to rapidly develop interfaces that we had never had before. Fantastic success.
I think a small demo program - or even a code sample - could be a good idea. Show the code to do something in C, then show the code to do the same thing in Python. If you know what you're doing, the Python code should be much shorter, and easy to read even for people with no experience in the language. You can also point out that there's no compile step, and if it blows up, you've got a useful traceback straight away. I've done something like this. When someone was demonstrating how to write a password generator in C++, I wrote it in Python. By the time I finished, the C++ version was twice the length, and was still having fencepost problems selecting random ASCII characters.
s/unfriendly/divergent
paster create is your friend. 
It's an interesting idea, but Pip isn't the only tool that can install packages with a setup.py, so I think 'pippify' wouldn't be a good name. These tools: * plain python (if setup.py doesn't depend on 'import setuptools'), * python with setuptools installed * python with distribute installed Support the: python setup.py install command. In addition, buildout, like pip, can use setuptools or distribute to automatically install packages (from pypi or some other site, or a local directory) as well. 
I use Komodo Edit now as well. Tried PyCharm few times but had problems with it* and also used vim but I'm too lazy to set it up every time (+now I also use Windows). Besides that I used Kate (which I was used to from Kdevelop) but it's not so good without the Kdevelop. Which I wasn't able to configure for python btw (for C it's a great IDE). * About PyCharm, do not want to do bad advertising si I should clarify - I tried it under OpenJDK and I suspect that was the cause of my problems.
I thought they were trying to focus on python 3 since they dropped development of unladen swallow.
Good point. I should have added rapid-prototyping to my list of reasons above. Can you think of any specific example where an algorithm that is tricky to get right in C, can be easily prototyped in Python?
Can you think of a specific example of a tool that was particularly easy to write in Python?
I'll have to check out ctrlp. I've used command-t and fuzzyfinder in the past.
&gt; The real key though was our ability to dynamically manipulate anything we wanted to with python and to rapidly develop interfaces that we had never had before. Fantastic success. Awesome - I'd like to learn more. If I understand you correctly, the objects in your framework were C++ objects manipulable via. a tcp interface (something like a socket, perhaps?). The framework and the interface were rich enough that you could dynamically affect running C++ objects, including replacing them with stubs, etc., all without tearing down or restarting your framework. You then use a Python environment for communicating via. the TCP interface - and you found that Python's dynamic runtime was a good fit for your framework, allowing you to easily map Python constructs to framework behaviors, thus dramatically simplifying your interface to the framework... ? Do I have that about right?
Interesting, thanks. Well, it's been a year so we are about due for another PIL update.
Textmate on Mac till now, but Sublime Text 2 is coming along nicely. Textmate 2 alpha is also out but since Sublime Text is cross-platform, I can see myself switching.
Add the SublimeRope (autocompletion, goto_definition, some refactoring tools, docs, etc), SublimeLinter (check your code for errors and PEP8 violations) and SublimeREPL (integrated python interpreter session) plugins, and you get a pretty decent Python light IDE.
So we define several tools as a toolchain, of which there may be n. Tools act differently, so we abstract common features out. This subset is then sent to a cluster host, along with a test. What the host executes, as well as the dispatcher, results analyser AND presentation layer, are _all_ written in python.
I think you have it. We used it as our main method of testing. We could run automated regression testing as needed (which was every release as well as every candidate release). And we used python's built in testing suite to develop our tests. One of our standard requirements were that we were testing with a language other than the one we used to implement the embedded software. On other projects we actually manipulated the chip's debugging capabilities, but on this particular one, everything had to be contained within the software. Consequently, we needed an interface. Python was an excellent fit. Another requirement we had was that we had to ship exactly what we tested. In other words, if we needed a debug interface, it needed to be included within the final binary. So every product has that debug/testing interface in it. And we shipped what we tested -- there were no surprises. One of the drawbacks, though, is that we had to design the entire thing inside of our software first. In some cases, this is a hard thing for developers to accept: your testing interface ships with your product. Many people like to add the debugging interface and then remove it before they ship the final product. We compromised by only providing the interface if specific locks (software and hardware) were available. So we had a runtime hit only if we were running the debugger, and even then it was really just a matter of actually having the tcp/ip interface running on the hardware. Our software was a control system and the design primarily focused on creating objects we called components and then looking at data flow (signals) between components. Signals could always be manipulated by components or generated by components, but they were not local to components. Components were primarily something like a c function call (that's how they were generally used). They were singleton (for the most part). They could store state and be executed multiple times. The singleton caused some issues when we needed multiple instances of a class which really represented different things, but it was tough to distinguish their names. Everything needed a unique name. Our design process was all captured within DOORS and we were able to manipulate that software to autogenerate our templates for both coding and testing. We registered and created every class at compile time using templates. This allowed us to take a hit during compile time, but the objects were already available at run-time to use. We had hard (do or die) startup requirements and we were particularily concerned with how long it took things to execute. On the Python side, we simply created proxy classes and then used our object lists on the hardware side as part of our introspection. Consequently, we would end up with something like: &gt;&gt;&gt; x = signal('somename') &gt;&gt;&gt; print x 'signal value' &gt;&gt;&gt; set(x, 'another value') # set x to a different value &gt;&gt;&gt; lock(x) # locked the signal to a specific value &gt;&gt;&gt; c = component('somename') # get a component that manipulates the signal &gt;&gt;&gt; c.execute() # ran the component &gt;&gt;&gt; verify(x, 'another value') # verify that signal was not updated &gt;&gt;&gt; unlock(x) &gt;&gt;&gt; c.execute() &gt;&gt;&gt; verify(x, 'new value') # verify that the signal changed etc. That's sort of the basic layout. It allowed us to do unit level testing at the component level. We also were able to do schedule optimization and do signal analysis to see what signal was affected by other signals (i.e. going backward through the design without really needing to know the details of the design). We could do all of that with our python software. 
Your comments really lean towards someone who doesn't or has barely used Visual Studio. 
Hmm, I'd like to focus on the behavior of actual code snippets rather than high-level descriptions of neat things you can do. With that in mind, I think this might be a bit too complicated for my purposes. I wonder if you could distill one aspect of your tool set in such a way that Python solves that problem better than C. Perhaps some dynamic or introspective aspect of your dispatcher or cluster host ...?
That is all well and good. Anyone with knowledge of Visual Studio can easily see that you DON'T have knowledge of it, based on your comments. That automatically make your opinion of it both irrelevant and easily seen as biased. There is a large gap between someone feeling qualified to discuss a subject and someone actually being so. I try not to be biased and still do a considerable amount of my work in Linux. You know what? Visual Studio still wins.
&gt; Anyone with knowledge of Visual Studio can easily see that you DON'T have knowledge of it, based on your comments. That automatically make your opinion of it both irrelevant and easily seen as biased. So, according to you, my not having used Visual Studio for years biases my outlook? That view indicts the opinions of those who *do* use it. Or hadn't you thought of that? My comment was limited to a well-documented Microsoft behavior, not Visual Studio per se. Microsoft's history of engulfing everything they touch is a [matter of public record and legal prosecution](http://en.wikipedia.org/wiki/Embrace,_extend_and_extinguish).
Wow, that sounds like a really productive environment to work in. Your tools team must be really something. Professionally, I'm as intrigued by your C/C++ design (object creation, registration, and mechanisms for dynamically querying / updating) as I am by your Python. My company's software is a message-based client/server architecture - and I've often dreamed of being able to visualize the messages passing between client / server. As well as, from within a dynamic environment such as Python's REPL, sending messages to a Server and observe its behavior / response. I completely agree that this would dramatically increase our productivity, and prototyping speed. Taking advantage of Python's unit testing libraries would just be icing on the cake. Of course, the biggest hurdle to writing something like this is the amount of up-front time required to implement it... Still, this is an excellent example of using Python's dynamic capabilities - particularly by using Python's dynamic dispatch to create proxy objects that behave very naturally, but that implement the TCP protocol under the surface. I'll have to give some thought over how to simplify this idea into a few presentable code-fragments.
Did some changes from your comments. Repo updated.
I'm looking more for something at a language level. Something that will fit on a few lines of code, that I can describe in 5 minutes or less. For example, perhaps some unexpected advantage of iterating over ranges instead of introducing spurious counter variables. What you're providing is indeed a very nice benefit of using a powerful language - and such high level solutions are really what makes or breaks any tool (i.e. it has to actually be useful at the macro level that we work at). Unfortunately, it's impossible for me to go into the level of depth necessary to explain something like that. I plan to focus, instead, on a few simple easily-digestible nuggets of information that will hopefully spur my teammates on to actually try Python and find the big solutions for themselves. I hope that makes sense. I appreciate your help, and hope I don't sound ungrateful.
You are biasing the usefulness of a development tool by the actions you perceive of the company who makes it. If you haven't used Visual Studio in years, then you have no measure for have good of a product it is. Just as using references to how a company behaved over a decade ago isn't necessarily relevant to how the behave today. Although, I'll be the first to admit that their practices most times are in the best interest of the company, not the user. And they have a history of buying or bullying companies to do things their way. It is hard not to replace the king of this role now to Apple, however. My use of Visual Studio is about 20% of my programming work. I use VI. I use PyScripter. I use Eclipse. I use any tool that is required to do the task I need to do. I stand by my belief that to form any opinion about an IDE, you need to have actually used it. To come back to my specific comment, what IDE is better than Visual Studio? And BTW - I have not down voted any of your comments, so I'm not the only one that feels like you are being disingenuous.
Yes, but it should be mentioned that it's IronPython specific. It is a pretty good experience though. Your UI markup is stored in a XAML file which is wired up dynamically to your class declared in Python. You can declare event handlers in the XAML and it gets hooked up to methods in your class. You can double click on buttons and we'll declare the event handlers in your Python code for you. And the IDE understands all of this so you get intellisense between the XAML and Python code.
The Python community is pretty big and our team is pretty small. Just like we didn't engulf Python when we were working on IronPython I don't think this will engulf Python either. Instead I'd say we're doing the classic OSS thing: we're scratching an itch. Python's awesome and we want to make sure developers have a great experience when working with Python on Windows. Part of that is having a great development experience, and part of that is taking cool things on Windows and making sure they're available to Python programmers as well.
For what it's worth: Currently I'm running python on an ARM9 processor. It does take about 2ish seconds to pop up the interpreter. But in my current product, this is an acceptable amount of time. We are currently using python, as opposed to c, to develop gui, hardware controls software as well as an ftp interface, web interface and database interface. Some things run faster than others.... For basic maintainability and understanding, though, python is a huge win for us.
It looks like it allocates a ton of dicts and strings in memory. Take a look: &gt;&gt;&gt; from guppy import hpy &gt;&gt;&gt; hp = hpy() &gt;&gt;&gt; print hp.heap() Partition of a set of 23554 objects. Total size = 3058536 bytes. Index Count % Size % Cumulative % Kind (class / dict of class) 0 9809 42 831720 27 831720 27 str 1 5538 24 449632 15 1281352 42 tuple 2 346 1 234352 8 1515704 50 dict (no owner) 3 73 0 212440 7 1728144 57 dict of module 4 174 1 187728 6 1915872 63 dict of type 5 1551 7 186120 6 2101992 69 types.CodeType 6 1475 6 177000 6 2278992 75 function 7 194 1 172584 6 2451576 80 type 8 126 1 136656 4 2588232 85 dict of class 9 1027 4 82160 3 2670392 87 __builtin__.wrapper_descriptor &lt;87 more rows. Type e.g. '_.more' to view.&gt; &gt;&gt;&gt; import phonenumbers &gt;&gt;&gt; print hp.heap() Partition of a set of 153624 objects. Total size = 31258536 bytes. Index Count % Size % Cumulative % Kind (class / dict of class) 0 42579 28 19827528 63 19827528 63 dict (no owner) 1 59509 39 3436360 11 23263888 74 str 2 25945 17 2596224 8 25860112 83 unicode 3 3185 2 891800 3 26751912 86 dict of phonenumbers.phonemetadata.PhoneNumberDesc 4 246 0 824592 3 27576504 88 dict of phonenumbers.phonemetadata.PhoneMetadata 5 632 0 662336 2 28238840 90 dict of phonenumbers.phonemetadata.NumberFormat 6 336 0 554880 2 28793720 92 dict of module 7 6339 4 519152 2 29312872 94 tuple 8 195 0 219720 1 29532592 94 dict of type 9 1719 1 206280 1 29738872 95 types.CodeType &lt;96 more rows. Type e.g. '_.more' to view.&gt; Haven't really looked in to *why* it needs such a big allocation of dicts and strings just when importing, but presumably it's loading the dataset in to memory.
Heh, Armin's actually making great progress on STM. He's currently got a prototype that exhibits linear scalar, though it is 8x slower on a single core (with tons of room for improvement).
wow... Anyways, thanks for the great product, Dino.
Do both!!! Go embedded on the higher level you are allowed to, embedded systems have a wide spectrum: 8,16,32 bits MCUs, for the big boys you can even have MMU (hence your virtual memory makes you feel you are dealing with resource restrictions). If you are allowed to use Python in your system, just leave the critial parts in a C extension, but really benefit from Python's productivity as much as possible (i.e. prototype faster). If you work for really constrained systems, there is still some place for python, for instance, develop your PC host interface software in Python, there are plenty of hardware related libraries (serial, parallel, usb ports). I often trigger the Python CLI and test some of my logic or array related handling (Python and C use arrays starting from 0). IMHO, knowing multiple languages makes you a better programmer for your. 
You do understand that Open Source means exactly that Open Source. It doesn't require to run on any platform other than the target. And you are only being a dick to belittle a project that is being given away for the benefit of other, because it doesn't follow in your thin little ideology of what is the correct behavior to be Open Source. Portability IS a problem with Visual Studio. However, it is not a legitimate reason to take a shit on this project. And, sorry to break it to you, but it is also OK to call a project Open Source that is written in VS proprietary code. Oh, the horrors!!!
I apologize that I'm doing such a poor job of communicating my request. Basically, I will be giving a presentation to a bunch of old-school C engineers, trying to convince them to use Python. The only effective way to do this, in my experience, is to give them problems that they face regularly - and then explain how Python can solve this problem much more easily than C. The challenge is one of balance - I need to give them enough information to make the examples meaty. But it has to be simple enough for them to digest, even if they've never heard of Python before. So your example of a "reliable cross platform execution environment" is an awesome example, but fails the "easily digestible" criterion. Your example code-snippet is good - what context do you use this code in (i.e. How can I get my coworkers to say, "Ah, yes. That would be useful.")? I'm intrigued by your networked manager - if you have an example readily available, I'd really like to see it.
&gt; You do understand that Open Source means exactly that Open Source. It doesn't require to run on any platform other than the target. I just found out what you think "open source" means, not its formal definition (see below). &gt; Portability IS a problem with Visual Studio. That results from the fact that it's not open source. &gt; And, sorry to break it to you, but it is also OK to call a project Open Source that is written in VS proprietary code. Only because lying isn't illegal. [Open Source](http://en.wikipedia.org/wiki/Open_source) : "In production and development, open source is a philosophy, or pragmatic methodology that promotes *free redistribution and access* to an end product's design and implementation details." 
&gt; As a developer, I've always known that my environment and tools are the most important things about my job because they are most often the things that slow me down Agreed, but there are other considerations. For example, it's a problem if nobody else on the team can read or modify or use your tools because they are not familiar with, and are not willing to learn, the language in which the tools are written / scripted. &gt; If you have enough development lead time to develop your environment, you can reap a significant amount of rewards from doing that environment and tools development and designing your software to build on top of it. I'm curious how you manage your scope. I find that even with a clean slate and lots of time, I typically wind up with hackneyed abstractions that only cover about half of my actual cases. This is one reason that I'd be very nervous to propose such a big tooling project to my management - I wouldn't be confident that the results were worth the expense. In your case, obviously they were. That's really awesome.
For the networked manager, you can write one yourself; Would you believe me if I said that this was in the [python standard library](http://docs.python.org/library/multiprocessing.html)? My example is worthless, all it does is achieve something that would take a lot more work in C; As for _actual_ examples, something cool is the [context manager](http://docs.python.org/library/stdtypes.html#context-manager-types) you get with the `with` statement: with open('foo') as bar: baz(bar) ... Another cool thing is inline place swapping: a, b, c = c, a, b People will hate me for this but if the scoping by whitespace really bugs you, you can use braces: `from __future__ import braces` You can debug your regex using `re.compile(expr, re.DEBUG)` 
&gt; I know EXACTLY what open source means. Based on your prior remarks, that's false. Open Source means "free redistribution and access to an end product's design and implementation details", therefore your earlier claim -- "It doesn't require to run on any platform other than the target" -- is false. Which part of "free redistribution and access to an end product's design and implementation details" didn't you understand? Or are these multi-syllable words simply beyond your comprehension? &gt; Open Source does not require the entire stack to be open. Your remark is contradicted by the definition of "open source". And you are now reduced to downvoting me for being right. &gt; You can't seem to see the facts through your ideology. I just stated the facts, by copying and pasting the definition of open source. Read, learn. 
&gt;&gt;&gt; So I can't evaluate Visual Studio against any other Open-Source IDE that will run on Windows, if I plan on running it on Windows, without evaluating Microsoft's policies? Why the hell not? &gt;&gt; Locate where I said this. If you can't, you're not arguing with me, but a straw man of your own design. &gt; Um, the post I responded to: &gt;&gt; You're pretending that Visual Studio can be evaluated without also evaluating Microsoft and its policies and past actions. Translation: "Okay, I can't read." Sadly noted. 
&gt;"free redistribution and access to an **end product's** design and implementation details" This statement says 1 thing. You must have access to the design and implementation details of ONLY THE END PRODUCT. This means Source Code. Period. There is nowhere that it states that it must run on another platform. Please reference that for me in the page you linked. IT ISN'T THERE. You are pulling that from your mind, but it isn't in the words. This is so simple to be stupid. Let's remove Microsoft from the equation, because it makes you blind to basic logic. I have a good software company, that pats bunnies on the head and makes a compiler for Windows that they sell. It is proprietary. I write a software program using this and publish the source under a MIT or GPL license. Please indicate how this isn't an open source project. I am giving you the design and implementation details. This is so basic that I don't understand how you can't see it. Hell, if the Linux kernel was written and no GNU C compiler existed, so it had to be compiled with a commercial POSIX C compiler, it WOULD STILL BE OPEN SOURCE. I really don't know how to make it simpler to get into your mind and past the ideology. &gt;&gt; Open Source does not require the entire stack to be open. &gt;Your remark is contradicted by the definition of "open source". And you are now reduced to downvoting me for being right. What you are having a hard time differentiating is that there are more than one topic on open source. open source project - a software project that has all of its design and implementation detail open. i.e. You have the source to rebuild it with the same methods that the creator built it. open source movement - the idea that all software should be open and NOTHING is open unless everything up to it is open. open source project and open source movement don't always intersect. And they don't have to. You are trying to force the open source movement onto every open source project, and frankly it can't be. One is an ideology and the other is a very simple definition that you can't seem to comprehend.
Direct link to Google's Python Class: http://code.google.com/edu/languages/google-python-class/introduction.html
&gt; You're pretending that Visual Studio can be evaluated without also evaluating Microsoft and its policies and past actions. In what world is this not you saying that I can't evaluate the Visual Studio software product while ignoring what Microsoft does otherwise? Your logic doesn't work and you come back with the problem being my reading comprehension. I don't know how else to help you understanding basic logic. I really don't.
&gt; My strategy was to pick a small subset of the new features that translate well to something my audience was already familiar with. I tried to show side by side comparisons of the "old" and "new" ways of doing things. Thanks for the slides. This is exactly what I'm trying to do! I assume that this approach worked fairly well. &gt; Show them Python in terms they are familiar with. I'm trying. It's really tough to come up with topics that are simultaneously meaty enough to be interesting and relevant, but simple enough to be easily understood and to not lose people's attention. This is the fine line that I'm walking, and the help that I am hoping to receive. So far I've received several good suggestions for topics that I want to cover. I can maybe dig around a bit for a useful examples. Sockets is another good idea - perhaps showing how I can easily establish communication between my PC and my module running on my desk, or something.
&gt; In what world is this not you saying that I can't evaluate the Visual Studio software product while ignoring what Microsoft does otherwise? That's not what you said -- here is what you said: &gt; So I can't evaluate Visual Studio against any other Open-Source IDE that will run on Windows, if I plan on running it on Windows, without evaluating Microsoft's policies? Why the hell not? Look carefully at your computer screen. See how the words are different? &gt; ... you come back with the problem being my reading comprehension. That's because the problem is your reading comprehension. You've built more straw men in a shorter time than anyone I have recently met. It should be an Olympic event. 
free redistribution and access. - That means you don't have to pay for and can see all of the... end product's design and implementation details. -- Source code. It really is simple and you are adding conditions that don't exist. Can you answer one question for me? There are literally thousands of open source GPL or MIT license projects written in .NET for Windows only. How is this possible, with your definition of the world? You can't be reasoned with and logic doesn't work with you. Enjoy, I'm done wasting my time.
It's a very cut down version of Python to fit on microprocessors. It doesn't "include batteries", but it's Python which would at least be attractive to students looking to start in microprocessor development.
It's a nice module. It's a nice piece. It's a nice blog (no distracting crap, decent typography). I think I am starting to *hate* this guy.
Why the hell does it matter who I'm talking to? It doesn't make you any more right. Questions I have asked that you have ignored: How can we have open source .NET projects hosted at all open source code hosts, when you say it isn't possible to exist? Why can't you evaluate Visual Studio as a software product, separate from the politics and actions of Microsoft? (Sorry, I know YOU can't, but explain it to be why it can't be done.) Where in the definition of an open source project does it include that the entire build stack is required to be open source? You remind me of Sheldon Cooper on The Big Bang Theory. By your Wikipedia bio your are obviously a technically bright individual, but you completely lack the ability to understand when you are incorrect. Is that hubris? Open Source Project is a very simple definition. You continue to add ideas into it that are not defined in the words you provided. I just don't understand why. You have never answered one of my questions, only attempted to pick apart my posts, which are just trying to get more information from you. Edit: I see that you created a Careware license. This is explaining more and more why you are having trouble separating the ideology of what you believe software should be from the actual definition of an open source project. 
Use what works for you. If you need to support Windows developers, then I guess fabric is not for you. I couldn't speak to it, I do not use Windows, but the dependencies install without a glitch on everything *nix.
&gt; you completely lack the ability to understand when you are incorrect. I proved you wrong, you ignorant jackass. I did it by simply quoting the official definition of open source, by copying and pasting a technical definition on which there is universal agreement. &gt; How can we have open source .NET projects hosted at all open source code hosts, when you say it isn't possible to exist? Stop lying. I never said that, jackass. &gt; You have never answered one of my questions Learn how to use social media. A given thread has one topic, not as many as you think you can get away with. I would suggest that you get treatment for clinical narcissism, but as it happens, there is no treatment. One more thing -- when you simultaneously downvote and reply to a post, you are only betraying your complete ignorance of rediquette. 
You keep missing that fact that is it only in end products implementation details. That is simply the source code. You are taking an ideological view to it and I take a legal view to it. &gt;It is false. Prove me wrong -- port a .NET application, and its implementation, to Linux, so that it runs. Conform to the meaning of "redistribution". There are literally hundreds of such .NET projects that run fine in Mono, which you admit. But that isn't what is needed there. Redistribution simply means that you are allowed to compile or rewrite to work on another platform, NOT THAT IT MUST COMPILE OR RUN. You are free to rewrite the source to port to another platform. You can take an algorithm from it and use in another if you give credit. In other words, it is open source. Edit: The more I read about your actions, including boycott of Microsoft, I am coming to realize that your ideology view and my legal view will never meet. That is fine, we will agree to disagree. Have a good evening.
Haha /u/kennethreitz (edit: well he wass here a minute ago) (edit2: d'oh reddit autolinking change)
&gt; Redistribution simply means that you are allowed to compile or rewrite to work on another platform, NOT THAT IT MUST COMPILE OR RUN. That's false, that is not what the open source definition means. And we've already covered this ground. &gt; You are taking an ideological view to it and I take a legal view to it. Wrong -- you just don't understand the legal definition of open source. As it happens, you're not the only one -- many people have been forced to stop claiming that their projects were open source when the implementation and interoperability requirements weren't met. &gt; You can take an algorithm from it and use in another if you give credit. In other words, it is open source. Bullshit. By that cracked definition, mathematics is open source because you can take an equation and implement it anywhere. That happens to be true, but that doesn't make it open source. Open source is more strictly defined: [Open Source Software](http://en.wikipedia.org/wiki/Open-source_software) : "Scholars Casson and Ryan have pointed out several policy-based reasons for adoption of open source, in particular, the heightened value proposition from open source (when compared to most proprietary formats) in the following categories: * Security * Affordability * Transparency * Perpetuity * Interoperability * Localization." Obviously not being able to run a given program anywhere fails this definition. This is why proprietary languages and platforms aren't regarded as open source. And this is explicitly spelled out in the source documents that define open source: "Casson and Ryan argue that 'governments have an inherent responsibility and fiduciary duty to taxpayers' which includes the careful analysis of these factors when deciding to purchase proprietary software or implement an open-source option." 
&gt;That's false, that is not what the open source definition means. And we've already covered this ground. You have covered the ground in your belief, but still haven't provided any source that says this. I read through the entire page and I'm honestly not trying to be a dick about it. The definition in the page still applies to .NET software, as ALL that is described as part of the Open Source definition is access to source code. The bullet points you reference are described in the context of advantages of open source, not the definition. Again this is an ideology and "spirit of the law" thing. &gt;Open-source software (OSS) is computer software that is available in source code form: the source code and certain other rights normally reserved for copyright holders are provided under a free software license that permits users to study, change, improve and at times also to distribute the software. This all still applies to a .NET program, proprietary to Windows, in Visual Studio. There is nothing in that **definition** that fails if it won't run on other platforms. Advantages of software that follows the ideals of open source do what you say, but that is not required in the definition. &gt;Wrong -- you just don't understand the legal definition of open source. As it happens, you're not the only one -- many people have been forced to stop claiming that their projects were open source when the implementation and interoperability requirements weren't met. I would love examples of this. Those I have seen are companies that either based code off of what could not legally be licensed in open source style licenses or did not meet the requirements of providing source code. I just haven't seen interoperability as a requirement. You could have open source 68k assembly program. It would not be required to operate on an Intel chip. Edit: I really wish whoever was down voting you would join the conversation. Perhaps that can provide something that would bridge the gap. I just am not seeing anything that forces the limited definition your are asserting.
I don't have experience with either, and am trying to make a choice, hence why I said it seems like that!