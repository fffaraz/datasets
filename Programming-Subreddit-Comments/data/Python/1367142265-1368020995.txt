It was a really good talk - thanks! In the Q &amp; A you mentioned that you had no plans for Python 3 support. Is this just a priority thing, or are there technical reasons under the hood why Python 3 support might be problematic?
They didn't mention Carbon, a graphics engine dev gave an interesting look into how they handle writing c++ extensions and why they have their own system instead of using boost::python. Unfotunately the talk wasn't really for programmers, thankfully one of the guys added a section that was far too technical for the general audience and therefore very interesting :)
CCP's reasoning for using Python and C++, an insight into their dev processes and a quick rundown of their in-house python - C++ utility code, and why they didn't use boost would be highlights. I thought it was interesting to see how a company used python in the high performance realm of game design, and how they developed their own ecosystem in the process as an established one didn't exist.
Hmmm, you'll have to give me an example of "simple api tie-ins". I don't know what you mean by that. If you use or seen examples of Pandas being used in IPython environment, I can see why someone might think Pandas has graphing capabilities since IPython can be setup to have matplotlib's pylab class in the default namespace so that you don't have to do explicit imports of matplotlib plotting libraries. So to the end user, it may "appear" that Pandas has graphing capabilites, but it doesn't. That would be like importing numpy and scipy, and then saying Pandas has array and scientific calculations capabilities.
So they threw away Django's ORM and templates. Why use Django at all then? Seems another framework like Flask would've been much better. With that you could've used SQLAlchemy which looks to me quite a bit smarter ORM(ish) framework ...
I actually think I needed to do depth first or something, 'cause I ended up using the filelist, and some interesting conditions, to get the treeview.
interesting. As one of the commenters said, tuple unpacking blew my mind coming from PHP and C#. That and named parameters were two simple features that I couldn't believe I lived without for so long.
Is it also the case that tuples are "more efficient" than other data structures, since they don't have to worry about growing/mutating?
I don't have much to contribute on the code side, but I will say that the style of the presentation is kind of offputtting. The art design looks like it's trying too hard, and the jokes are *definitely* trying too hard. It seems like a posterboy of the "brogramming" school of computer science and I don't like it.
I agree with mturk. It might be relevant to this subreddit, if only I knew what it does. Some sample output in the README.md would be helpful.
I logged in just to upvote this. This is really, really useful. 
Exactly, in this case named tuple would work even better. He for some reasons stresses that the position matters, which I don't quite get. Arrays are ordered too anyway, and the definition of NFA he gives is just convention (and honestly, I've read a lot of books on automatons and older ones each give a different definiton / order). As for tuple unpacking, can't the same be done with arrays? Really, none of the arguments he makes are any reason to use tuples. Sure in mathematics we call it a tuple, but the link he is trying to make doesn't hold. Hashing and performance are the reason tuples exist.
best beloved? 
They require one fewer word of storage, since they don't have to store both a length and capacity like a list. Tuple literals can be evaluated at compile time and added to the const pool of the code object (`co_const`) whereas list literals must be built-up at runtime: &gt;&gt;&gt; from dis import dis &gt;&gt;&gt; dis('for f in (1,2,3): pass') 1 0 SETUP_LOOP 14 (to 17) 3 LOAD_CONST 4 ((1, 2, 3)) 6 GET_ITER &gt;&gt; 7 FOR_ITER 6 (to 16) 10 STORE_NAME 0 (f) 13 JUMP_ABSOLUTE 7 &gt;&gt; 16 POP_BLOCK &gt;&gt; 17 LOAD_CONST 3 (None) 20 RETURN_VALUE &gt;&gt;&gt; dis('for f in [1,2,3]: pass') 1 0 SETUP_LOOP 23 (to 26) 3 LOAD_CONST 0 (1) 6 LOAD_CONST 1 (2) 9 LOAD_CONST 2 (3) 12 BUILD_LIST 3 15 GET_ITER &gt;&gt; 16 FOR_ITER 6 (to 25) 19 STORE_NAME 0 (f) 22 JUMP_ABSOLUTE 16 &gt;&gt; 25 POP_BLOCK &gt;&gt; 26 LOAD_CONST 3 (None) 29 RETURN_VALUE 
Yeah, it doesn't make much sense to use Django but toss the templating and ORM... especially since the "baked-in" parts like auth, users, admin, etc require them. They're basically using Django for page routing.
am I the only one who uses tuples to store matrices?
i use cygwin. most bases are covered.
Interesting point. I suppose frozendict would essentially be the same as namedtuple, though?
i lack a CS education, or much of the math. python's tuples were a gateway for me to learn a wee bit about tuples in mathematics and the theory of computation. it can work both ways :)
I use numpy.ndarray for that =)
I'd just like to point out that there are good datastructures for immutable dictionaries that allow cheap (structurally-sharing) copy-on-write updates. The datastructure I miss most in Python, and in any other language, is the Clojure {}, or a hash-mapped array trie. Basically, in Clojure it's used for everything that dictionaries are used in Python, and it's immutable.
Right, but realistically could a frozendict be optimally implemented by a namedtuple? You could drop the indexing semantics if you wanted.
The PyExcelerate module is currently faster than XlsxWriter. However, I have some performance optimisations due in the next 1-2 releases that will narrow or eliminate the difference.
Yeah. One of my favorite tricks is to implement a FILO stack with tuples. It looks something like this: class stack(object): def __init__(self): self._value = tuple() def push(self, value): self._data = (self._data, value) def pop(self): self._value, ret = self._value return ret Are there faster approaches? Sure, probably. This one happens to be fast enough for anything that's ever required a strictly-enforced FILO stack. It's also very space-efficient.
Yeah, probably =)
Glad I'm not alone!
Why on earth would you write a class for that? `list` already works just fine as a stack, with `list.append()` for push and `list.pop()` for pop, and I guarantee you that it's faster than this. 
Because I wanted to be 100% sure that there was only going to be appends and pops from one end. Like I said, this is about strict-enforcement. EDIT: derp'd my original response.
 &gt;&gt;&gt; li = set(dir([1,2,3])) &gt;&gt;&gt; tup = set(dir((1,2,3))) &gt;&gt;&gt; li-tup # methods unique to lists set(['sort', 'insert', '__reversed__', '__delslice__', 'reverse', 'extend', '__delitem__', '__setslice__', 'remove', '__setitem__', '__iadd__', 'pop', 'append', '__imul__']) &gt;&gt;&gt; tup-li # methods unique to tuples set(['__getnewargs__']) &gt;&gt;&gt; tup&amp;li # methods common to both set(['__getslice__', '__str__', '__reduce__', '__rmul__', '__sizeof__', '__lt__', '__init__', 'index', '__setattr__', '__reduce_ex__', '__new__', '__contains__', '__format__', '__class__', '__doc__', '__len__', '__mul__', '__ne__', '__getitem__', '__getattribute__', '__iter__', '__subclasshook__', '__add__', '__gt__', '__eq__', 'count', '__delattr__', '__le__', '__repr__', '__hash__', '__ge__']) &gt;&gt;&gt; sys.getsizeof(tup) 1136 &gt;&gt;&gt; sys.getsizeof(li) 1136 Edit: Correcting myself as I made a mistake above (I took the size of the sets, not the tuple or the list). &gt;&gt;&gt; li = range(1000) &gt;&gt;&gt; tup = tuple(li) &gt;&gt;&gt; sys.getsizeof(li) 8072 &gt;&gt;&gt; sys.getsizeof(tup) 8056 The sizes start to change slightly on huge ranges, but nothing notable. I think the idea behind tuples is really important for having generators - instead of a list where you can change things whenever you want, once you start a generator, it's determined what its will output. 
Not exactly sure what your question is, or why you're creating a list of lists, but * Piles = [[],[],[],[]] * Piles[0].append('AAA') * print(Piles) produces the result: [['AAA'], [], [], []] I'd take a look at whether you are appending properly.
Thanks for showing me dis. (heh)
It takes a lot more effort to intentionally do that. A list practically beckons you to have fun inserting and popping willy-nilly. This sends a big message not to screw around with the contents of `_values` because that interface isn't exposed. Of course if someone wants to try to work around an interface there's not much you can do. **Edit:** I should point out that I agree with the premise that using a list is the correct thing to do 99% of the time.
In that case, how about a list that only allows `push(val)` and the zero-arg `pop()`: class stack(list): __getitem__ = __setitem__ = __delitem__ = clear = extend = reverse = remove = insert = append = None def push(self, val): super().append(val) def pop(self): return super().pop() (This uses the Python 3 syntax; under 2.x you'd need to write `super(stack, self)` in place of `super()`.) I admit that `TypeError: 'NoneType' object is not callable` is not a very friendly error message if you try to use one of the forbidden methods, but you could clean that up by writing an explicit function that calls `raise TypeError("you can't do that on a stack")` or something. 
You can use python any where and any time on Linux or Mac os in Terminal. I always use it on Terminal when I was in college. 
&gt; how about a list that only allows push(val) and the zero-arg pop() Nothing wrong with that. The approach I suggested is (I believe) more space-efficient, that's all.
I've gone back and fleshed out the README. My bad--you bring up totally valid points
do you know what ptys (unix) and terminals (windows) are and how they are used? also input handling (missing) also the ringbuffer is broken (bonus points if you manage to figure the misstake on your own)
The explanation (summarized) was "ordered collections of possibly dissimilar types where position of elements has meaning"
Have a look into gammu, (http://wammu.eu), a widely used library for SMS and other interaction with phones. It has a python library too.
Here's a working implementation using the Growl protocol (GNTP). You can install this app which handles the Android side of things: https://play.google.com/store/apps/details?id=org.damazio.notifier ~~Then you could write a Python program to recieve Growl events and act on them. Or you could you a program like Growl For Linux which will recieve the notifications and display them in different ways.~~ It looks like that app uses a different protocol for sending notifications to Linux called DBus, but in any case, this will do what you want.
If you're working with a database that contains various extensions (in my case, to handle certain types of chemical analysis as SQL functions) that the ORM doesn't understand, then you need to do a raw query.
yeah seems your right, I was never familiar with the list construct. cool.
That seems like a pretty extreme case. I mean, are there common cases where a orm type of query is too expensive?
So you can enjoy the overhead of converting from one into the other.
Was that the list or the tuple?
So you just create new ones when you want to alter some values? It may work fine, but why the overhead when changing a single matrix? My guess is you realised that zip(*matrix) was only going to give you tuples, and you'd best get used to that.
Whoa, God this is some ugly code. Tuples are immutable, if you are going to make frequent changes you are using them wrong. They are used for storage of **heterogeneous** data which usually are the abstraction of some structure like the properties of NFAs in the article. Lists are used for homogenous data storage, they are a bucket you add or remove (usually similar) elements to. So if you want frequent changes just use the list builtin,or create your own linked list if you want optimal pops/pushes
Philosophical issues aside, why should tuples be strictly reserved for heterogeneous types? This sounds like dogma more than practical coding. I mean no disrespect -- I'm trying to understand.
The difference is *much* greater than a single word. Tuples have various optimizations that make them significantly more space efficient than lists due to not changing size. That includes these optimizations: * Storage is on the PyTupleObject struct (CPython), instead of a separately allocated array for a list. This avoids one allocation. * A free list of tuples is maintained for tuples up to length 20 and a certain number of tuples (2000 per length by default). When a tuple is freed, it goes onto the free list instead of immediately being deallocated. In programs that frequently create and destroy tuples, that's the difference between a malloc/free and a few relatively cheap instructions. * PyPy includes an additional optimization that attaches the tuple size to the type object instead of the tuple itself for certain sized tuples. * Unlike a list, only just enough space is allocated for the contents of the tuple, instead of overallocation.
Tulle. With a list or array typically the position has no meaning besides the ordering. 
I am not an expert on ptys and terminals. I think you are. Never intended to do input handling. It can be added when it is needed. Is the mistake are you reffering in ringbuffer is appending first and popping later? Or overriding append method?
I generally put all of them online, for two reasons. 1) At most of the conferences I speak at, I don't control the AV, so I put my slights up right away and the AV often follows a few days/weeks/months later. 2) I attach my speaker's notes, which aren't a transcript, but at least give you some of what I was thinking and what the takeaways I wanted to be. People have told me they've found this useful so I keep doing it.
&gt; tuple unpacking blew my mind which generalizes to destructuring-bind and pattern matching in some other languages. they are awesome.
Tuples are just lightweight classes without methods. You could make a class with attributes for name, date of birth, and balance, or you could just return `("John Smith", "1950-01-01", 15.00)` and then break out the records with `name, dob, bal = my_tuple`. List on the other hand are homogenous. It's a bunch of the same kinds of things. If I were in charge of naming things, Pythons tuples would be called "structs" and lists would be "arrays" (or maybe "vectors"), but nobody asked me.
&gt; why is there not a frozendict? because it's about efficiency in sorting/accessing, not about being immutable and you can just use OrdredDict
Of course there is no strict dogma, but that's their defining characteristic which will help you in your coding. You won't use a list for the coordinates of a point(x,y). You dont expect to add or remove coordinates, it's a structure of different properties defining a point. Now for a collection of point objects you will use a list. We do not expect it to be of a standard size as it doesnt define anything. It can change in size and we will usually store simillar elements in it.
&gt; A list practically beckons you to have fun inserting and popping willy-nilly. Who cares? Especially, when the stack method is slower. I agree tuples are faster, but modifying tuples is slower than modifying lists. You should be using tuples if you can, but if you can't, don't implement a stack to force someone to append-pop.
I gave several reasons why it might be possible for a frozendict to use less memory and be more efficient than a mutable dict. And OrderedDict has nothing to do with anything, because it's a dict subclass. 
I use: struct.pack('f'*16,*[0.0]*16)
Again, there are optimizations available for hypothetical immutable dicts that are not feasible for mutable dicts. 
I don't use ORMs much. The example I gave was the only time I needed to use a raw query in Django, in about two months of use. YMMV.
Can someone please explain to me what a tuple is? I never heard of one until two weeks ago.
That's like the first comment on that article.
Implement them/find an implementation of them in C and then use the FFI?
Other than immutable hashmaps what is there that you can't use in python? 
cool thanks
Perhaps I've [drunk too much of the kool-aid](http://en.wikipedia.org/wiki/Drinking_the_Kool-Aid), but a lot of languages seem to me at this point to be big soups of lambdas. Why have set and dictionary? Why have dictionaries if you have objects? Why files if you have lists? Etc. Yeah, must be the kool aid. Everything seems to be going lambda.
Dumb question, but in terms of speed how does it compare to set() ?
Tuple unpacking works with lists too, and you can use `[a, b, c] = xs` as an alternate equivalent syntax. The main difference is mutability, which is mostly about whether objects can be hashed in Python.
If you want to learn python 3, I highly recommend Dive into Python 3. There is a link in the sidebar. http://getpython3.com/diveintopython3/
The first program that book uses would be different in python3, since you have to call print as a function (and really you should be doing that in 2.7 anyway).
You (or someone) should make a google+ group for online hangouts. This sounds like an excellent idea.
What I meant was, if you are looking to learn Python 3 directly, don't avoid this book since the 2-&gt;3 differences are cosmetic. You'll learn Python either way
Just to be clear, you shouldn't be using print as a function in python 2. Unless you are importing from \_\_future__ in every program, writing print(my_string) in python 2 will actually create a one-entry tuple first which is messy to say the least. Try it out - compare print('hello', 'world') to print ('hello', 'world') to print 'hello', 'world' in python 2.
Count me in!
the method override, from that point on it can never grow in size again, even after the consumer did free some slots you should investigate maxsize and pop/retry when the full exception happens
I guess learning python by using an old version incompatible with the current one is what they mean by learning it "the hard way". ;-)
I'd be willing to help out on such a hangout
Is this at all representative of interviews that discuss Python specifically? I've never worked with Python professionally but hope to someday. Obviously lots of interviewers let you do things in whatever language you're comfortable with, but it'd be nice to be prepared if I knew I was going in for a Python-related position.
**Internal Server Error** The server encountered an internal error or misconfiguration and was unable to complete your request. Please contact the server administrator, [no address given] and inform them of the time the error occurred, and anything you might have done that may have caused the error. More information about this error may be available in the server error log.
Thanks, I appreciate it.
[PEP 416](http://www.python.org/dev/peps/pep-0416/) -- Add a frozendict builtin type Status: Rejected See BDFL's rejection notice in the PEP for details. Recipe for a frozendict: http://code.activestate.com/recipes/414283-frozen-dictionaries/
These are silly questions. They sound like someone watched a 30 minute video from PyCon and wrote down a few things they heard. I've never heard of an interviewer asking such questions as a major part of the interview.
count me in
It's often a dependency for other libs, though. I recently had a similar problem when trying to install SimpleCV. (OP, I fixed it by brute-force. I deleted PIL from site-packages and then re-downloaded through pip. For some reason it started showing up *after* I removed it manually, though that could easily be a coincidence.)
I found them vital to the understanding of how Python works. I also ask several general programming and logical questions to see how the interviewee thinks. Maybe not the best questions but I found these working for a short interviews where you can not set complex tasks to be solved.
Agreed. A system I worked on reached the point where it was unmaintainable, and full of the cruft of long-disused features. We rewrote it in Python, just that parts that were still used. Total success (except, I'm a contractor and paid by the hour, so now that maintenance is quicker .... less income!)
I am not sure what you mean here, "all" and "any" are already part of the standard library.
I interview Python developers, and I ask most of these questions as the very basic stuff, just to tell if the person really knows python like they claim. Other questions I usually ask: * What is a generator? What does the yield keyword do? * Write a FizzBuzz-style program. Now write it as a generator. * How would you count the number of unique elements in a given list? what's the complexity of that? * What's the problem with Python threads? How does the multiprocessing module help with that? * what's the problem in the expression logging.debug("Elements in the list: %s" % lst). How would you fix that? And other similar questions. That's just the easy fluff part. People rarely fail these, and if they fail one or two questions simply because they lack knowledge of the multiprocessing module for example, or some other implementation detail (like the filtering comprehension syntax which a lot of people don't know), that doesn't disqualify them. For the second phase we have a much more thorough test though. EDIT: too much use of the word "stuff" :\
Pillow is a drop-in replacement. You will still `import PIL`, no so need for hacks.
I have been asked a few of these question on interviews the other are things that I found important. Of course you can use simple loop instead of list comprehension but the latter is more Pythonic.
Because an easy grammar can be reliably read, modified, and written by programs. As soon as a config file can contain logic, you can't guarantee that a tool understands it.
Because an easy grammer can be reliably read, modified, and written by programs. As soon as a config file can contain logic, you can't guarantee that a tool understands it. FTFY
any() and all() are part of the standard 2.7 builtins.
If lst is a tuple, it will puke because % formatting treats tuples differently from other types. 
you're right, but that was not my main concern - I wrote "lst" so you can assume it's a list. the problem is a performance problem: If you use the % operator, the string formatting will take place *no matter what the logging level is*. using a "," instead causes python to just pass a reference to whatever objects you have after the comma, and then the logger decides whether to format the string or not - resulting in much much less being done. It sounds negligible but it really isn't if you log complex objects (hence a list was hinted), long strings, dictionaries, or logging messages inside loops. It can easily take up more processing time than the rest of your code if you're not careful. 
you just went full retard: i’m not talking about english grammar. also you didn’t actually fix anything.
Having started out on Python 2.7, I must admit I'm not familiar at all with the "Name: %s" % name syntax. I would almost always write "Name: {}".format(name) instead.
Why do you think they are silly?
x-post from /r/gcc: http://www.reddit.com/r/gcc/comments/1dc0rl/python_frontend_to_gcc/
Right, but understanding the mechanics of a particular programming language and being able to use that language efficiently or with elegance are two very different things. These questions would not identify a "good programmer" just "someone who knows python." 
[Google+ Community Link](https://plus.google.com/communities/116969234888661099943). 
Not that it helps much but: http://gcc.gnu.org/wiki/PythonFrontEnd
The python runtime understands it. Of course you can't prevent users from putting things in configs that don't belong there, but if you're releasing a tool in python, your users are probably programmers who will want to be trusted with more control. Plenty of config systems in compiled languages expand to include embedded scripting in something like Lua. We're all familiar with Bash scripts as configs. And ipython configs are in python.
I cant see how you can write good Python code without knowing most, if not all, of the answers to those questions. PEP8, virtual environments and generators may arguably not be vital knowledge, but the rest are about as fundamental as they get. Question #1 (Are arguments passed by value or reference) is one that would give a lot of trouble if the programmer is unclear about it.
yes, but those are end-user tools. even more: they are shells. almost everything you want to configure there modifies input behaviour, and in cases where it’s not, there are machine-modifiable sub-languages and -systems (environment variables, command line parameters, …) and this is about IOC. if anything, *this* should be configurable by a machine.
&gt; this should be configurable by a machine. And now you have to write two parsers. You can autogenerate python configs from templates if you have to. I'm not a big fan of dependency injection though, so I probably shouldn't tell those who are how to do it.
&gt; Also, xrange instead of range, damn it. In this case though, range is fine, isn't it? range returns a list and xrange returns a generator. This is important when the list may be very large. But in this case, the size of the list is static at 10. So there is no real advantage to xrange over range. I agree in general xrange is the better one to use though. 
They seem like good screening questions. Anyone who is claiming to have intermediate to advanced experience in Python should be able to answer these questions pretty easily.
Immutable, fast, cheap-to-update sets and vectors. Basically, 90% of what makes Clojure awesome is that the language designers decided that *all* data structures are better if they are immutable, assuming that you have fast enough update operations. Identity should be a completely separate concept from value, provided by different primitives. Clojure data structures are generally speaking ~4 times slower than the Java ones, which frankly is close enough, especially since you can claw some of it back because you never need to deep copy anything. Programming with pure values is insanely liberating. Those old enough might remember a time when all strings were mutable, and just how much easier string processing got when new languages added immutable strings. Programming with the Clojure data structures is the same, only for everything else.
Just a priority thing. I don't use Python 3 so haven't put any effort into porting to it.
This reeks of someone who got bit by a weird problem once, and now thinks it is a good interview question. 
It looks interesting, but is there any documentation? Looking at the test code, I can't figure out what's overloaded and when some of the variables are defined. For example, has *is* somehow been overloaded to assignment? Where are *wtf* and the rest declared? Is something mucking with the parse tree or *locals* or is this accomplished just with overloading? What's the purpose of the spaces in the tuple? with peg: short = ("omg" is wtf) &gt;&gt; wtf * 2 medium = ("omg" is o, " ", "wtf" is w, " ", r("bb+q") is b) &gt;&gt; o + w + b
If somebody make a dongle joke under water, do women on the surface get shamed?
Does it actually implement Python, or just something with Python's syntax?
I found the IPython approach to fulfill most of my command-line REPL needs, the "!" notation for issuing a command to my shell (and even assigning the output into a variable is wonderful sugar. What does 'sh' bring me beyond what I get in IPython (aside from the obvious non-interactive interface?)
PSA - xrange, though lazy, is NOT a generator.
There's quite a lot more that Sh can do - for example, many commands have context managers inbuilt, so you could do: from sh import cd, touch with cd("/tmp"): touch("file") or even nicer with sudo: service.ssh.start() (running a command with parameters or with method calls works out to the same thing) See the sh docs for more :) http://amoffat.github.io/sh/
I understand it, but still these are not the only questions I ask. Yes this is the Python part of the interview but I also ask Django, general programming and logic questions.
It doesn't work on mac or any of the other *BSD systems?
even better
Sorry, we're the free online book version (I'll fix the link in OP): http://learnpythonthehardway.org/book/
&gt; And now you have to write two parsers. [no i don’t :)](http://docs.python.org/3.3/library/configparser.html)
Certainly worked on OSX when I was playing with it a while back. There might be caveats I didn't discover, of course...
Sorry, I put it up in a hurry. Here's a link to the documentation https://github.com/lihaoyi/macropy#parser-combinators It talks more about "how to use" rather than "how it works", but should go a long way into understanding what you are seeing. The "how it works" is deep macro magic, and documentation for that will come later! 
Okay, those are pretty cool :) Thanks, I'll keep it in mind next time I'm playing in the shell!
Make it. If it's a bad idea then it'll die naturally. If it's a good idea, it'll work. As the adage goes: for many ideas, the best way to determine if it's a good one is to try it.
This can't possibly implement full python. Maybe it can do RPython-esque support, but why bother when RPython already exists?
Just do it. Whether the idea is good or bad, a bunch of people will complain that it's bad. Just make the subreddit and announce it where you need to announce it. 
You'd be amazed at how much I see the *pattern* of problem, never mind this specific one. It's okay that most people won't know what's bad about this. But explaining what's the difference between the two shows real understanding of how Python works. BTW A much more common manifestation of this I see all over, is people formatting SQL queries with %, not escaping properly. This goes way beyond performance of course. 
It's just the way Python works. The logging module uses this for performance, the SQL drivers use it for proper escaping, etc.
It may work on cygwin - I think the problem is more about how it searches $PATH to find programs
Not sure this compares favorably with [Parsley's](https://github.com/washort/parsley/blob/master/examples/parsley_json.py) or even [PyParsing's](http://pyparsing.wikispaces.com/file/view/jsonParser.py/30308858/jsonParser.py) syntax.
That question confused me. I started out with my 2.7 and then shortly after switched to 3 and all I could remember was "um, xrange is the one I used to use before they got rid of it...?" Admittedly, I'm still a python beginner, and would not claim to have intermediate to advanced knowledge, so my experience is probably a bad example.
Addendum to what user/xeltius said - Also have to remember the history of Reddit when making a new sub. When Reddit went live, for the first year and change it was just Reddit's founders posting content until it got momentum... same thing applies to a sub. Just keep posting often and with enough interesting info to draw a followers.
You ought to take a peek at your blog sometime with NoScript for Firefox. (No worries, I know how to use w3m)
yes, it can, it just would not be very good. You essentially do the equivalent of unrolling the interpreter loop. You can't all that many optimizations though
I'm being mad lazy at the moment, gimme a tl;dr for "why use this over os/subprocess with .system/.popen?"
Sounds like a good idea, I'd subscribe. I'd like it as well if this could be an unofficial place for Sage posts as well.
I would be very grateful if you could give me feedback on the page content, or any other help / advise, once I get /r/IPython online.
Thank you for the advice. I will follow the founders' example. *Spelling
Just FYI if you're an English learner: the noun is 'advice' and the verb is 'advise'. Like 'device'/'devise', 'practice'/'practise', 'licence'/'license', etc. (The latter are chiefly English English.)
What's wrong with subprocess or os.system? import subprocess subprocess.call["cat", file] #where file is a filename or os.system import os os.system("cat " + file) #equivalent to above. Best part: The first launches a new process, so it's now a multithreaded program! os.system, IIRC, is a tad outdated, and both are dependent on your os properly handling the command.
I sort of agree. I want to get shlex as an option into sh so the envoy-style command works better.
You can use it as a generator. So if you want to watch e.g. vmstat, you can get the output line-by-line instead of having to kill it, get stdout, then start it again.
I don't think you can reasonably expect people to design their websites with noscript users in mind in 2013
Sure, but the traffic at /r/python is so low that it certainly has enough room for all the IPython links you could hope for.
&gt;"Read my content! Please! It's good, I promise!" . &gt;"Oh, well we ***won't let you see any of it*** unless you allow us to run code that might be riddled with exploits on your own personal computer." Yea, there's plenty of other content on the web, much of it where I can get the gist of what is going on with AdBlock and NoScript active. Like, for example, Reddit. Don't surf without protection, kids. And it shows up great in the terminal using a text only browser like w3m anyway. 
Note that you can also use python variables in the commands given to ipython's magic shell function: `In [38]: x = 34` `In [39]: ! echo $x is $x` `34 is 34` 
I have used the local notebook, but not the cloud...but it looks pretty similar. The basic commonality with sage is that we're using notebook interfaces to do live/interactive computations, typically using math or science libraries. I believe you can use sage in ipython, see here: http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/categorie/ipython/
git submodules is a good suggestion, I'll look into it. As to #2, I have some of that stuff in some other environments i've used, maybe I'll port it over. This is just my barebones django env, with not much else. Thanks for the ideas!
Basically this. While this is a fairly barebones setup, I prefer vagrant for OS parity, etc.
Howdy. This: "config.vm.customize calls are VirtualBox-specific. If you're using any other provider, you'll have to find provider-specific configuration to translate to manually in your Vagrantfile" is fine, provided you are using virtualbox. Ignore it. Basically, looks like you have a single box in your local vagrant environment called 'precise32'. In my Vagrant file, you'll see a line that says: config.vm.box = "precise64" This indicates that I've configured the Vagrantfile to copy a base box called 'precise64', which is the x64 version of the same ubuntu build. You can do one of two things: 1. Change the line above to: config.vm.box = "precise32". Then it will work fine, using your existing precise32 box. 2. You can download and add a new box for precise64 to your local vagrant environment, and leave the Vagrantfile as is. The command for this is: vagrant box add precise64 http://files.vagrantup.com/precise64.box This will download and install the precise64 base box from the file repo hosted by the folks at vagrantup.com. Hope this helps!
It's shocking how bad even "experienced" web developers can be at basic SQL. Guys making $140k/year with 12+ years of experience and a list of very prestigious names on their resumes and they do SQL like a 1st year PHP community college student. Anyway, I'm curious what you don't like about Django ORM? My only real complaint is how they treat a PK - it must be int and can't be a composite key. Everything else I've needed to do has been supported. 
You're certainly right, but if you're hiring for a position that requires experienced Python devs, I think these sorts of questions are pretty good for a preliminary interview.
You're right, but let's say a candidate lists "x years of experience with Python development." It'd be wise to at least do a basic test of their knowledge, if they say they're knowledgable. If they say "I am not that experienced with Python," then you move onto other questions.
I think always using a comma vs. the format operator is the Right Thing To Do for logging statements, but I really can't imagine there'd be any serious performance impact between the two. Why would you log a very big, complex object anyway? Would make more sense just to log certain parts of it. If I were you, I'd replace such a question with a SQL injection test, as you say. As in "what's wrong with `mysql_query("INSERT INTO table VALUES ('%s', '%s')" % (var1, var2))`"?
It doesn't have to be a complex object, it can just be a long string, a list of multiple objects, etc. For debugging printing this stuff is fine, even desired, but in production you do not want that shit in your logs or taking up CPU time. 
Whats the difference? To be clear I'm not being pedantic but would appreciate a pedantic answer.
PyQt is very nicely cross platform. GTK can be cross platform, but it has more of a Linux focus, whereas Qt feels quite well supported on all the main platforms. Tkinter also works on the various platforms, although it looks a bit clunky.
The dependency isn't detected properly so you can't pip install packages that depend on PIL without them trying to install PIL, even if you already have Pillow installed. Not a big deal, but annoying nonetheless
I'm facing the same issue here as well.
I'm having issues with the install, still showing the module is not installed. Anyone try this? What did you think?
I went ahead and made /r/IPython please look at it when you have time, and thank you for all your hard work.
All true, but for a short script to require the whole Qt/Gtk to be installed on Windows is a bit overkill imo. Tk is included so it wouldn't bloat the size much. 
I am able to download and install the precise64 base box and run it. Edit: For running the git://github.com/cacois/vagrant-python-django.git which is mentioned in the original post: Ok. It's working now. So basically, vagrant-python-django is a kind of an add-on to an existing base box? 
Oh, that's much more to my liking. I still think `envoy.run('this | that -option &gt; file.txt')` is still far superior to `sh.that(sh.this()), 'option'=True, _out='file.txt')`, but at that point you should really be figuring out why you are doing so much Bash inside of Python! One of the big problems with envoy, however, is the fact that it is still a work in progress. If Ken Reitz learned anything from his [requests](https://github.com/kennethreitz/requests) library, it's that users don't like lots of subtle API changes when a library hits v1.0, but I wouldn't expect it to remain stable either.
Thanks!!! Already pitched in with some comments... I certainly hopes it becomes self-sustaining, we'll announce it on the lists.
Ah cool; didn't realise envoy could figure out pipes and stuff! Very nice!
I'll do my best to keep it moving. Thanks again.
Just posted to the lists, twitter and G+. Very happy to see this. Edit: forgot to mention g+
you could try logging in with your google/myOpenId/launchpad account. all three are free to sign up for on their respective sites.
Do it! subreddits are subject to natural selection - i.e. if it wasn't meant to be it will die naturally.
How is it different from [splinter](http://splinter.cobrateam.info/)?
Could you explain what the non-fact is? The homogeneity of list elements or the heterogeneity of tuple elements? Because just because tuples can have heterogeneous types for their elements isn't to say they *do*: it's more a statement that the element need not be of the same type. Now, Python being dynamically typed and all, allows you to push just about anything you want onto a list. However, that's not exactly a good idea because lists then to be lists of a particular *type* of thing. So, what exactly is this "non-fact" you think I'm repeating?
It's a non-fact because it's something that is made up fiction. A fairy tale. To decide whether to use a list or tuple, the only considerations should be: - Am I going to need to modify the elements of this sequence later? - Am I going to need to add or remove elements from the sequence later? If the answer to either is yes, then use a list, otherwise use a tuple. That's it. Whether the items are of the same type or different types is **completely irrelevant and should not factor into the decision in the slightest.** If I have a series of five floats, and it's always going to be five (say because it's the five day forecast) then I'm using a tuple. I don't care one bit that they're all floats, and the notion that a list should be used because they're all floats is simply ridiculous, given all the various positive performance benefits of using a tuple. (Now, I might use a list because of other reasons, like laziness since it's five fewer characters to type `[x * 4 for x in y]` than `tuple(x * 4 for x in y)` and I don't really always care about performance.) The language defines them both as sequence containers of arbitrary objects. Any further meaning you attempt to give them is your own naval gazing.
I know that this is going to sound borderline incredible, but I've seen systems taken down by string formatting log debug. It just comes down to the volume of what you're doing. If each web page call has another 3-4 log debug statements which are all concatenating strings (which of course then need to then be GC'd too), and you're serving multiple requests per second, it can seriously eat apart performance. Two jobs in a row now I've seen customer impacting production issues where a webservice is faltering because of a string building issue in a log debug statement, and not complex object, just maybe 4 or 5 key-value pairs from the stack.
I just registered a new account successfully... Also, support requests would be better lodged the support tracker linked from pypi.
oy, I hate virtualenvwrapper... it is too magical. Here, this is all you need. Lets say I need to write a hello world wsgi app that uses my nanoweb package but I need to work on nanoweb as well as the wsgi app. virtualenv ~/Projects/hellowsgi mkdir ~Projects/hellowsgi/src cd ~/Projects/hellowsgi . bin/activate pip install -e git+git@github.com:ericmoritz/nanoweb.git@develop#egg=nanoweb mkdir src/hellowsgi emacs src/hellowsgi/setup.py # create a setup.py for hellowsgi pip install -e src/hellowsgi done. Now both nanoweb and the hellowsgi packages are installed in "develop" mode. This means there is a .egg-link file for each project in the virtualenv's lib/python2.7/site-packages directory: $ cat lib/python2.7/site-packages/nanoweb.egg-link /home/eric/Projects/experiments/pysomething/src/nanoweb This allows you to change the code in those two projects without having to reinstall them or play tricks with the Python path. Easy peesy.
DataFrame.plot() is what I'm talking about. I don't need to import matplotlib to make it work, pandas handles that step for me, as well as saving me some boilerplate pyplot code. I don't deny that 100% of the functionality is provided by matplotlib, but how things "appear" to the end user actually matters and in this case pandas provides a nice, holistic api that includes graphing.
Huh, that's really interesting actually. So calling an object's `__str__()` method and interpolating it into a constant string (as with the `%s` formatter) actually has a lot of overhead? I didn't have any idea. I believe you though, and in that case I'll retract my previous comment and acknowledge he's right.
Ok, you seem to be under some kind of misconception about what I wrote. I replied to somebody who asked what a tuple was. I pointed them at the definition in the Python docs and I *also* gave the computer science definition of what a tuple is. I was explaining what a tuple is *in general* and *not* just the Python sequence type. *Nothing* I've written so far contradicts *anything* you've written. Heck, I use tuples as fixed length immutable lists all the time. However, and let me repeat this so as we're clear, I was not talking about the specific Python sequence type called `tuple`, but about the *general concept* of tuples, which the Python datatype exists to model in the language.
Vagrantfiles specify how to configure a copy of a base box, so in that sense, yes. The Vagrantfile provided basically creates a VM and configures it to install python, django, apache http, and some other standard django stuff, configures port forwarding, and configures a shared folder for your code.
Now make an announcement both here and in the subreddits in the OP?
But isn't the whole point of virtualenvwrapper that you're able to install your venv directory far, far away from your project directory so you can keep your projdir as clean/uncluttered as possible?
They are quite similar. Personally, I would prefer splinter, but our business team would rather use the Selenium IDE than write code. So I wrote this.
 # (Paraphrasing slightly here.) r = requests.get(url) embedStringBlock = r.text.split("var EmbedData = ")[1] embedData = eval(embedStringBlock) Yyyeahh....do **not** do this. Ever. This is one of the cases where `eval` is not only unnecessary, it is downright one of the worst security holes possible (*remote* arbitrary code execution). If I put `var EmbedData = ` in any part of the page you're visiting, and then follow it up with some evil Python code, then I'd have control of your computer. FREE = "FREE" PAID = "PAID" artist = "artist" item_type = "item_type" id = "id" true = True false = False I am simply at a loss here. if "name" in embedData.keys(): You don't need the `.keys()`; by default, anything involving iteration will iterate over a dict's keys.
For the first part: Yeah, that was the only way I could decode the JavasScript from the webpage, so I didn't know about the loophole, I'll think of a solution to that. For the second part: This part is to make eval work, because the JSON in the JavaScript function isn't valid, the keys are being evaluated as variable, so resolving these to variables will solve this issue. For the third part: Yeah . . . once again, my bad. It's a bad syntactical error on my part, thanks for the feedback! EDIT: And the security flaws have been fixed. :D 
I'm not the main author but a contributor to Rome, A practical Roman numerals implementation. https://github.com/halst/rome
Take a look at this: http://stackoverflow.com/questions/4033633/handling-lazy-json-in-python-expecting-property-name I'd say you should clean up the JS object and then `json.loads()` it. This will fix both your first and second problems.
What do you mean a typo? I intended to make it sound the way it sounds - people should avoid trying to learn a programming in 21 days because that is not how things are done. If you want to master a craft, you have to invest reasonable amount of time doing it.
\&amp;amp;#8211;
I was getting issues with handling lazy JSON with that regex . . . Especially since there are some links encoded in there, but I'll keep on toying with it. Thanks for the help! EDIT: I've pushed a fix to remove the use of "eval", and it doesn't even use regex . . . but it works perfectly now. Enjoy! 
Maybe and Maybe. You'll have to be more specific. What is your use case?
That would have been clever.
Well, imagine if you wrote `a + b`, but it simply crashed if both `a` and `b` weren't numbers. In Python there's the `__add__` and `__radd__` procol methods to allow these to work with arbitrary types, but I'm fairly used to seeing so called "Python compilers" that don't implement these. This is to say nothing of things like `sys.exc_info()`, tracebacks, and all the other introspective features Python offers.
This is a really cool project, and I'm playing with it a bunch right now. Have you taken a look at the [Bandcamp API docs](https://bandcamp.com/developer)? By chaining a few API calls, you can obtain mp3 urls for a particular song/album. It might save you the trouble of manually parsing through their mess of javascript.
Thanks. Got it. First, this has been really helpful since your example does a lot more with Chef. And it really shows off how you can use Chef. Plus it readily demonstrates how Chef fits into the picture (under the Vagrantfile). I think I would want to incorporate virtualenv into a Chef recipe and load this first to bring it up a lot of the Django and other library components under the virtualenv. Is it possible to setup a Chef recipe that does this? Or is there one already. Thanks. 
Here's the source code of roman.py, from the Docutils project: http://sourceforge.net/p/docutils/code/HEAD/tree/trunk/docutils/docutils/utils/roman.py
What the hell is Bandcamp? This is my first question.
the best site for independent music
Yeah i was going to say that this is in the tutorials somewhere. 
This does pretty much the same, a lot easier: https://gist.github.com/Simon1988/5487851 Of course without the ID3 stuff, but I just threw it together in 10 minutes. Also, disregard the sloppy code, like using .split as a poor man's regex. Also, all information, band name, album name, duration etc, is also in "album_data". Edit: Before anyone asks, this uses the API key present on their API documentation page. According to wayback machine, the key has stayed the same since at least September 2012. This is probably breaking their API guidelines, but OP's original program breaks the general site rules anyway (I assume, most albums on bandcamp cost money to download), so I wouldn't imagine that he cares. Edit: Noticed a small error, track in line 30 should be title. I have updated the gist. Also, this is without requests, if no dependencies are your thing: https://gist.github.com/Simon1988/5488506
I firmly believe you can learn the basic structures in 21 days. Keep in mind the title does _not_ say Become an Expert Programmer in 21 Days. And it would absolutely be correct to modify the title to something like "Learn To Program (Badly and at an Amateur Level) in 21 Days", but the publishing house probably rejected that.
Not a Python question (and if it was it should be on SO or /r/learnpython), the answer is mostly in database land. FWIW your interaction model is backwards, you won't get db events on a client-initiated connection.
I also found these: * &lt;https://www.google-melange.com/gsoc/project/google/gsoc2011/redbrain1123/11001&gt; * &lt;http://www.phoronix.com/scan.php?page=news_item&amp;px=OTYxNQ&gt; * &lt;http://redbrain.co.uk/&gt; 
What if I only want to learn what I can in 21 days and have zero interest in mastering the language? By the way, how many days do you recommend one should take to learn programming?
Looking at the commit log, it implements a lot less than shed skin.
Advertisement for shitty hosting?
SQL * http://docs.sqlalchemy.org/en/rel_0_8/orm/events.html * http://www.postgresql.org/docs/9.1/static/plpython-trigger.html NoSQL * http://stackoverflow.com/questions/7549565/couchdb-trigger-code-when-creating-or-updating-document * http://api.mongodb.org/python/2.0/examples/map_reduce.html * https://github.com/hmsonline/cassandra-triggers
Like with every other thing - your whole life.
The point of virtualenv is a private set of libraries and python executables for your app/lib/whatever you are developing. Where to place the virtualenv in relation to your actual dev project is just personal taste. All virtualenvwrapper adds, as far as I can tell, is that now you type "mkvirtualenv virtualenv_name" instead of "virtualenv /path/to/virtualenv_name". Then after it's created you type "workon virtualenv_name" instead of ". /path/to/virtualenv/bin/activate" which I always shortcut by adding an alias to my .bashrc and .bash_profile so that I just have to type "virtualenv_name". I agree with the parent poster here - I've never seen what effort using virtualenvwrapper saves that makes it worth adding more magic to the environment and yet another thing to install on my system. I've even been running it on my current setup for the last month or so just to give it a fair shot since so many other people seem to feel like it saves them so much trouble. I do vaguely remember reading something that said the way virtualenv unloads/overwrites environments is a bit unclean and virtualenvwrapper does something which cleans that up, which is probably a good thing. I'm not finding it after a very brief search, though.
Awesome. I could add the encoding to that script
File bugs on packages that require PIL. They should require Pillow instead. There's no reason to continue using PIL.
[According to the developer](http://www.reddit.com/r/Python/comments/1cjy3n/please_show_pydev_some_love_only_26_days_left/c9ho6ob), the PyDev stuff will be open source but the LiClipse stuff won't be.
I used [virtualenv-burrito](https://github.com/brainsik/virtualenv-burrito) to easily install it. It installs both virtualenv and virtualenvwrapper with one command. I'm using Pyramid with Heroku, so my project directory is already filled with INI files, run.py, run-app.py etc. Using virtualenvwrapper makes my workspace a tad cleaner which makes a difference to me. 
Nope- all you should need is Python, JSON data, and a web browser. 
Yes, I posted two days ago in different subreddits. Not this one. And two months ago I posted before there was a book, so I reposted when I finished the book. The website has seen a lot of updates in the last two months. If you do not like people providing free and ad-free resources for python, then downvote and move on. 
Sure, go ahead and use what you want from the script :)
Awesome. I don't use it but still awesome.
Sorry? 
*"Whipped up a Bandcamp ripping script for you all."* I'm pretty sure that this title says nothing to most people and the first question is "what is Bandcamp?". Some explanation should have been included in the title. This is the first time I hear about this site, it's not (yet) as well-known as Facebook for instance.
You will :)
Well ... yes, that is obviously what should be done. Doesn't really affect the validity of "so no need for hacks" statement unless you can just stop working and wait for the bug to be fixed.
This is great. Thank you for posting.
As someone that used to manage a printing shop for a living I can vouch for this guy. When you place an order to have a book printed you have to commit to so many copies. Our minimum was 250-500 depending on the type book we were making. We did everything in house, from burning the plates to putting the cover on it for you. We could even shrink wrap them if you wanted (we had a massive machine for this). When I'm working on a job that requires say, 1,000 soft cover books I have to plan out everything. I have to order a certain amount of ink if I don't have enough in house. We mostly keep black and red in stock, anything else we tend to order out for. If you want color (anything but black) I had to set the presses up to run color. Basically on a press the paper goes through rollers, one of those having the plate for the page wrapped around it. This roller transfers the ink on to the paper. When I run color I have to set up the press to run the paper through another set of rollers, with a second plate which transfers the color ink. This is a delicate process because if you don't have the timing of the press right the black ink will smug or fade. When you're running a press you're constantly adjusting it and having to check to make sure things are running correctly. That's why any printing shop charges extra for color. Basically it's a pain in the ass for whoever is running the press. We have to cut the pages to the proper size after printing them. Then put the entire thing together (collating). We have a machine for large jobs, but small jobs are done by hand. This is a long process either way because the machine often gets jammed. After all that the book have to be attached to the cover. This is a three man job at minimum and requires the help of a glue machine that puts off a lot of fumes. You can get high off glue just standing in the room when that thing is running. We try to circulate fresh air into the room by using lots of fans but it doesn't help much. Anyway, this is why books cost so much. The author (or his publisher) has to put up a lot of money just to get stock printed. No printing shop is going to print you 10 copies, we would lose money on labor and supplies. Also, don't forget about the fact that I have to plan for bad copies. If the customer orders 1,000 books that means I plan on printing enough material to make 1,200 books. I have to plan for something getting screwed up in the chain. I always give myself room for error and on the bright side if the customer ever orders more copies I might have 100 or so laying around and ready to go. My point of this rant is the price he's set for his book honestly isn't that high. He's also offering a ebook if you don't want to pony up the cash for the dead tree edition. I hope that you do because printing shops need the business...it's a dying art. :(
Seems to be kinda pre-pre-pre-alpha quality right now. Only a select few of the examples work.
You really can't say it's less than ten lines of python if your just importing and running it. I can hack the matrix in 2 lines of code. import matrixhacker matrixhacker.hack()
Hmm. I get the feeling these guys don't do much development with Python.
I want to send a push notification to connected clients when a table update happens, I'm using the tornado library with websockets if that makes a difference. 
Right, because he should also be flipping switches by hand, rather than even using software.
It is advisable, depending on how fast you learn things, to take at least 10,000 hours before you can actually say you are good at anything. 21 days will not help you much. As I said, the first time you have a child, you make a lot of mistakes. The second time, you will know so much better. The third time, you can teach others what you know. I don't recommend an exact amount of time because I know we are all different in capabilities - for this case, learning. Good luck.
It really isn't an achievement of the language but this specific library. I would say that it is valid to say this when you are trying to sell a library. EDIT: Although, you could also argue that this is part of the python ecosystem, thus it might be fair to say that python lets you do that easily. 
I think if you're packaging up code for other people to use, and the interface only requires 10 lines of code for it to run effectively, then you can advertise that it'll create what you promise in 10 lines of code. Complaining about how many lines of code are in the library is a waste of time because Python itself (cpython) would contribute to how many lines of code were written to support the entire ecosystem. You wouldn't say "Creating Map Visualizations in Millions of lines of code," even though that's what it is.
Here's what I (and others) are seeing: http://i.imgur.com/UOYoAc1.png
Hi- author here. Can you let me know which examples aren't working for you? I just ran all of them to make sure they work on my machine. Also, if it's an issue with getting the paths correct, starting a server and pointing the browser at the right files, etc, I want to know that as well. I want this tool to be as straightforward to use as possible. Your comment has motivated me to start building out the docs immediately, which I should have been doing in the first place. Docstrings and examples are good, docs are better. 
Looks nice. Especially the pandas integration will end up making it very easy to use. Can anyone explain this odd syntax (I'm too lazy to dig in): vis + ('2B4ECF', 'marks', 0, 'properties', 'enter', 'stroke', 'value') Since this is an expression (not a statement) and the result is not being used, I assume the '+' is overloaded to change the *vis* state somehow. Would '+=' have been more appropriate?
I did, sorry for the confusion. It turns out was my own local issue.
pub/sub is a pretty standard interaction model, what do you find backwards about it?
With a good title you could have saved a Google search for several of us. Just by a good and informative title I could've decided if it's interesting for me or not. Now I needed an extra googling to make a decision. You stole 30 seconds of my life.
You are spot on- using the + operator changes the state of the vis object, by amending that particular component of vis.vega Given that I haven't actually shipped V1, I'm open to changing the syntax to make it more intuitive. It's tricky, because I wanted to be able to drill down into multiple layers of very nested dicts and lists. Its funny you mention using __iadd__. Using '+=' actually does the same thing as '+' right now, but I think we're about to make a syntax change where the + operator allows you to stack visualizations, and += lets you modify components in any given visualization. Must build docs. Must build docs. 
Great, some docs would be helpful. But first, the "paths" you reference in the examples aren't consistent with the paths that will be created when the zip is unzipped, so they can't reference the source files. (I'm not sure how this could have worked on your machine. Did you try the zip files?) Next, it's often unclear what the purpose of the example files is... For instance, I might expect "vincent-maps.py" to create/show a map, but it doesn't. Nor does "vincent-line.py" create a line diagram. Is this kind of thing intentional? Finally, the examples on your webpage (http://wrobstory.github.io/tag/vincent.html) with the title "Creating Map Visualizations in &lt;10 lines of Python" never actually gets around to showing how to create a map visualization with any number of lines of Python. Did I miss something here? I'm sorry if this sounds too harsh. While I applaud your effort, I was disappointed with what I found.
Right. A general comment, that I think most Python people will agree with, is that '+' shouldn't change state. Explicit is better than implicit and all that. 
No worries. If it's hard to get working, I'm doing my job wrong. I just fixed the paths, at least for those doing a git pull. Will look at making it entirely zip-safe tonight. The visualization requires pointing your browser at a the files with a simple Python HTTP server feeding localhost- the vis is done completely in javascript (D3). I'll try to make that clearer in the README and examples. The feedback is much appreciated!
Excellent point- I think I might go through and change everything to += and +- tonight. 
using IPython as the REPL, for example.
As Tobu points out, getting the DB to initiate communication with the app is a somewhat backwards model. There are at least two ways you can approach this: * Generate a message in the app when updating the DB, and subscribe to that channel. Be careful of race conditions if the message is generated inside a transaction, or if using unsafe/async writes. * Use a trigger to push an item into a queue on record update, and poll the queue for changes. This happens automagically with Oracle Change Data Capture, the Mongo OpLog, and other built-in replication APIs. These will be database specific, so it depends on if you are locked into a database platform. 
Care to elaborate?
Doesn't appear to have any support for virtualenv yet, and I don't think the current iteration will be great for web dev.
Is there any plan to support shapefiles? That would make this project instantly much more useful, since so much geometrical data already exists in that format.
Database connections are client-request/server-response, with no provision for blocking on an event. If you want pub/sub, and thanks for coming back to clarify your requirements by the way, this is not the right way to do it. The other ways involve picking a database or a message queue. So you need to ask about that, not about Python db wrappers.
I am sorry about that. I reached the limit. Will be back soon.
I agree with you. But those kinds of books tend to make beginners think that they will be good after reading them. It is not true at all. They fool people. You can be good with the syntax. I have no doubt about it. But you cannot be a programmer within 21 days.
Well that isn't exactly what I want, the app would already be running and register a listener for the database, likely any database changes would come through the app as well.
IPython is excellent for data investigation/experimentation but lousy for testing code to be used in actual Python programs, since it behaves so differently.
How exactly does it behave differently?
Does it really behave that differently? Other than the magic functions, I was under the impression that code running under ipython would also run under plain-old python. I've been developing small apps under ipython for about 2 years now and I've never come across any differences (which admittedly doesn't mean there are none).
Just freakin' amazing. This last week, a professional (?) plumber has failed to show up twice. The bank handling our refi forgot to send the notary. The school where I'm taking classes has given me an assignment with no requirements, but where failure IS an option... And now, a person who is giving away software to do something valuable is doing so with far more professionalism and courtesy than I've experienced from all of those other so-called professionals. Well, my hat is off to you sir/ma'am! Keep up the good work, and may karma reward your efforts!
For me it's slow on the browser, and in the script, so I don't really know. &gt;Also, I just want to say . . . your code in 10 minutes is 100 times neater than mine in 20 minutes. I guess I should keep things as object-oriented as possible, eh? It helps me keep the overview when writing stuff at least, even if it's simple. Keeping methods short help me a lot too.
Yes. It's a pretty full-featured toolkit. There's even a WebKit widget if you want real HTML tables.
What *can't* we do in &lt;10 lines of Python?
Why use d3 on the backend? Isn't the advantage that you can have the client do all the work? Can `vincent` send its output to a browser and have the d3 instance there do the rendering, or does that defeat its purpose?
cocaine is a helluva drug
Great Tutorial. 
exactly. and it isn’t like the % and the ? would do anything in python either. they are always a a syntax error when occurring like they do in ipython, which makes ipython a superset of normal python. i use ipython all the time. sure, many suggest bpython, but that doesn’t have the `myvar?` (as shortcut for `help(myvar)`), and i don’t need the syntax highlighting.
I have a feeling if you read the authors own words on it you'll find they suggest having reasonable expectations. It seems to be more of a semantic issue than anything. How much about a language do you have to know before you can say you have 'learned' it? After Zed Shaw's, Learn Python the Hard Way, I felt comfortable reading other people's python code and looking up docs for any module I didn't know, and he covers about the same range of topics, and I completed his course in about a month.
He's probably just in the design phase right now. (I kid, I kid!)
Is the `vis + tuple_of_things` a Pandas thing? It seems bizarre to me.. Why use the addition or inline-addition syntax at all? You are using it to set attributes, so.. why not use the attribute setting syntax: vis = vincent.Map(width=1000, height=800) vis.fill = '2B4ECF' vis.marks = 0 ..or more directly, this seems a bit more self explanatory, and doesn't look like failed tuple-appending: vis.set(["#f5f5f5","#000045"], 'scales', 0, 'range')
Hey, thanks for the shout out. I personally subscribe to most of the blogs of the core dev team plus a number of other well known people in the community. I second Python Weekly (disclaimer: they have linked to many of my posts). 
Just be aware guys that PhoneGap does not use hardware acceleration like other services. Also you have to sell you soul to Adobe to register (you log in with an Adobe ID or a ~~sigh, Facebook, sigh~~ GitHub login) and there is that annoying 'creative cloud' phrase at the bottom of the page as you are messing around in it. Source: I have used PhoneGap to produce an App. Edit: Github NOT facebook
Thanks for clearing that up!
And also [pycoders](http://pycoders.com/) [planet-python](http://planet.python.org/)
See my comment above- Vincent is just a Python wrapper for the Vega visualization grammar: https://github.com/trifacta/vega It's really Vega/D3 and Pandas that are doing all of the heavy lifting. You should be sending the output to the browser, as right now it's the only way to render- I will try to make that much more explicit in the README. I plan on building in output to PNG, but right now the easy way to do that requires Node.js, and I would really like to avoid that dependency. 
Yes, actually. I want to build in some simple syntax that will let you input a shapefile, and then Vincent will call the Ogre API (http://ogre.adc4gis.com/) in the backend, save the geoTIFF, and build the map. It's on the list- I'm doing all of this on nights and weekends, so I get to things as I can. 
How so? Now *I* or *you* can create map visualizations in less than 10 lines of python.
Whenever people react like this to something, I *always* get the impression that they're trying to prove something.
 #python
My friend Doug Hellmann writes the Python Module of the Week, which is a great reference and way to find out about various modules I didn't know existed: http://pymotw.com
In one line... def permutations(n): return (bin(j)[2:].replace('1','(').replace('0', ')') for j in range(2 ** (2 * n - 1), 2 ** (2 * n)) if all((bin(j)[2:2+k].count('1') &gt;= bin(j)[2:2+k].count('0')) for k in range(2, 2 * n+1)) and bin(j)[2:].count('0') == bin(j)[2:].count('1')) Good night. (edit: formating)
Anything in python is turned into thousands of "lines" of assembly, so nothing can be done in 10 lines of code or less.
Excellent resource.
This is bomb.
This would be really cool for a nuclear war strategy game, like a Defcon clone.
I don't check up on him much these days, but [Eli Bendersky](http://eli.thegreenplace.net/) is fantastic in both StackOverflow and his webpage. Jeff Knupp is also a great dude.
All instances of '+' and '-' have now been depreciated in favor of '+=' and '-='. Thanks again for the input!
Thank you! I just put a README in the examples folder that I really hope makes it a little more clear how to run the visualization. If it's still a little painful to get it running, shoot me a message and we can talk about how I can make it more straightforward. 
It is filled with "Python Questions" bot tweets, sadly.
Just when I was about to ask this question on this subreddit. THANKS!! 
I still don't get the whole "app as html/css/js". doesn't html5 let you access most of the mobile features? just make a website! you'll be cross-platform too!
where does one obtain the data though? what do I do if I want a map of Middle Earth and there's not one defined in this particular JSON format? how hard is it to create arbitrary maps? I'm still going to play with this library :)
[I found a solution:](https://news.ycombinator.com/item?id=5636236) &gt; If you run LT from the command line after you've activated your venv it will use it. &gt; $ workon foo &gt; $ /PATH_TO_LT/LightTable.app/Contents/MacOS/node-webkit Not completely ideal, but not terrible. 
It's 2013, and here we have something brand new that doesn't support Python 3.x. :-(
That's how they're done with Python. It's designed that way. &gt;If you want to master a craft, Moving the goalposts. There's a difference between learning a programming language and becoming a software development expert. 
&gt;It is advisable, depending on how fast you learn things, to take at least 10,000 &gt;hours before you can actually say you are good at anything. Based on your blog, you're essentially pulling that number out of thin air because it's a saying. It's completely arbitrary. There are 260 weekdays in a year. Let's work full time, eight hours per day. That's 2080 hours. What you're then arguing is that to become good at Python you need to make it a full-time job, no vacation, for almost five years. That's ridiculous. &gt;21 days will not help you much. Raymond Hettinger says he can get existing programmers able to develop commercial-quality code in Python in one week. 
Don't the PyCon tutorials take people from non-programmer to manipulating live web data, traffic feeds, etc. in one day?
I believe one of the early features this was supposed to have was the ability to display multiple modules/functions at once. Does that work in this version?
I spend a lot of time on the Python tag on SO, and there are a load of great people on there I'm always seeing great answers from. [Martijn Pieters](http://stackoverflow.com/users/100297/martijn-pieters), [mgilson](http://stackoverflow.com/users/748858/mgilson), [Jon Clements](http://stackoverflow.com/users/1252759/jon-clements), [DSM](http://stackoverflow.com/users/487339/dsm) just off the top of my head, if you get an answer from one of these guys, I'd put money on it being a good one. Edit: Forgot [jamylak](http://stackoverflow.com/users/1219006/jamylak) - can't count the number of times I've been answering a question only to have him post it first. I'm probably forgetting others too - there are a lot of people who post a ton.
If anything it shows a lack of ambition. Why aren't we writing one liners with all the code in another file?
Isn't that an argument in favor of using ipython?
I think he means irc://irc.freenode.net/#python
Did anyone play around with the code? Show off the languages you implemented!
sametmax.com is a good (french) blog about programming python. Gave me some daily useful tips.
Definitely, in a pure Python environment. The promise of Light Table is that I could build a really nice, platform independent workflow for Python and Javascript, side by side. 
That's a trickier question. One starting point is Natural Earth for shapefiles: http://www.naturalearthdata.com/, then converting them to geoJSON with Ogre: http://ogre.adc4gis.com/ For middle earth, I'm afraid you will have to painstakingly create your own polygons. It would, however, be awesome. 
'world_countries' is a path pointed to the geoJSON. See the examples folder: https://github.com/wrobstory/vincent/tree/master/examples That has a data folder with the geoJSONs, and the vincent_maps.py example. 
That's how you know you're old. It took me a while to figure out saint\_glo was talking about Twitter. At first I thought they were talking about IRC bots echoing tweets or something.
Honestly? `dir(object)`, about 3/4 of the time.
Ran into the same issue, but I did find it on the Kindle store and bought it. In twenty minutes of browsing it on my phone I can tell it's going to be very useful.
huh ? for example....?
I did something exactly like this with scheme for my programming languages class. Very neat.
Yes python can handle this project, and with p2exe you can put a exe on your network. Have you considered a webapp for the gui? I think it would be much much simpler to update and distribution becomes a non issue. Might be worth looking into bottle or flask for this project. Good Luck.
... I can't connect to the Python intepreter. 
Your friend is awesome. PMOTW is one of the best Python resources on the web.
I feel like this will be the year of "critical mass" for 3.x. People will start to code in 3 when it's more convenient for them to do so and as more libraries come online that support it, it *is* increasingly more convenient. PS. I'm a 2.x guy right now, but I'd love to move to 3 as soon as I feel like it wouldn't be a struggle. 
Of course you meant In [1]: object? or even In [2]: object?? EDIT: IPython of course. :) 
Just a hint, I don't think this code is handling nested loops properly. You will need a stack to manage nested loops, not just a single integer to track where the beginning of the loop is, since you could be several levels deep in loops. Just as an example, this program should print itself out to_parse = '&gt;+++++&gt;+++&gt;+++&gt;+++++&gt;+++&gt;+++&gt;+++++&gt;++++++&gt;+&gt;++&gt;+++&gt;++++&gt;++++&gt;+++&gt;+++&gt;+++++&gt;+&gt;+&gt;++++&gt;+++++++&gt;+&gt;+++++&gt;+&gt;+&gt;+++++&gt;++++++&gt;+++&gt;+++&gt;++&gt;+&gt;+&gt;++++&gt;++++++&gt;++++&gt;++++&gt;+++&gt;+++++&gt;+++&gt;+++&gt;++++&gt;++&gt;+&gt;+&gt;+&gt;+&gt;++&gt;++&gt;++&gt;+&gt;+&gt;++&gt;+&gt;+&gt;++++++&gt;++++++&gt;+&gt;+&gt;++++++&gt;++++++&gt;+&gt;+&gt;+&gt;+++++&gt;++++++&gt;+&gt;+++++&gt;+++&gt;+++&gt;++++&gt;++&gt;+&gt;+&gt;++&gt;+&gt;+&gt;++&gt;++&gt;+&gt;+&gt;++&gt;++&gt;+&gt;+&gt;+&gt;+&gt;++&gt;+&gt;+&gt;+&gt;++++&gt;++&gt;++&gt;+&gt;+++++&gt;++++++&gt;+++&gt;+++&gt;+++&gt;+++&gt;+++&gt;+++&gt;++&gt;+&gt;+&gt;+&gt;+&gt;++&gt;+&gt;+&gt;++++&gt;+++&gt;+++&gt;+++&gt;+++++&gt;+&gt;+++++&gt;++++++&gt;+&gt;+&gt;+&gt;++&gt;+++&gt;+++&gt;+++++++&gt;+++&gt;++++&gt;+&gt;++&gt;+&gt;+++++++&gt;++++++&gt;+&gt;+++++&gt;++++++&gt;+++&gt;+++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;+&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;+&gt;++++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;++&gt;+++++&gt;++++++&gt;++++&gt;+++&gt;+++++&gt;++++++&gt;++++&gt;+++&gt;+++&gt;++++&gt;+&gt;+&gt;+&gt;+&gt;+++++&gt;+++&gt;+++++&gt;++++++&gt;+++&gt;+++&gt;+++&gt;++&gt;+&gt;+&gt;+&gt;++++&gt;++++[[&gt;&gt;&gt;+&lt;&lt;&lt;-]&lt;]&gt;&gt;&gt;&gt;[&lt;&lt;[-]&lt;[-]+++++++[&gt;+++++++++&gt;++++++&lt;&lt;-]&gt;-.&gt;+&gt;[&lt;.&lt;&lt;+&gt;&gt;&gt;-]&gt;]&lt;&lt;&lt;[&gt;&gt;+&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;&lt;-]&gt;++[&gt;&gt;&gt;+&gt;&gt;&gt;&gt;++&gt;&gt;++&gt;&gt;+&gt;&gt;+[&lt;&lt;]&gt;-]&gt;&gt;&gt;--&gt;&gt;--&gt;&gt;+&gt;&gt;+++&gt;&gt;&gt;&gt;+[&lt;&lt;]&lt;[[-[&gt;&gt;+&lt;&lt;-]&gt;&gt;]&gt;.[&gt;&gt;]&lt;&lt;[[&lt;+&gt;-]&lt;&lt;]&lt;&lt;]' but it ends up in an infinite loop.
&gt;This is an informative post which runs through five projects written specifically to compare five different web frameworks, including Lua, Emacs, Go, Flask, and Erlang. TIL: my favorite text editor is a web framework O_o 
Thanks for that! I wasn't aware BrainFuck allowed nested loops. I'll have to think of a better way of looping then. Any hints? My first thought would be to have a variable that contains the last open loop position and then another to store every currently open loop.
Actually, I don't think you would need a major modification to make this work. Instead of using an integer to track where to jump to at the end of a loop, you keep a stack of all the jumps you need. If you come to the end of a loop and you don't exit, just jump to the position at the top of the stack. If you are exiting the current loop, pop the top value of the top of the stack and discard it. If you come to the beginning of a loop, you push the current address to the top of the stack, as that is where you will wish to jump if the loop condition is true. Instead of using self.loop = 0 consider self.loop = [] 
I think his hint was to use a stack. In otherwords you can push each loops data on a stack and that way you can have arbitrary nesting and still be able to get out of the loop. When you see a loop push it onto the top of the stack. As soon as you have ended a loop you pop it off thee stack and you keep looping and popping until all loops are finished.
Well, I was, but it kinda looked like that was too? He was evaluating graphs inline on there? Or no I think I just had plain --pylab
Of course. Single line solution is possible. Glad to see it. :)
by stack, I'm pretty sure he means a python list
Hmm interesting. So like so: self.loop = [] def end_loop(self, i): if(self.memory[self.counter] != 0): return self.loop_stack.pop() Then?
Just realised that won't work
Haha, good catch. Looks like I added the word "web" to frameworks.
Close. Remember, you only want to remove the loop address from the stack if you are exiting the loop.
Looks good, I wrote one of these too. I think brainfuck is pretty interesting. If you're curious [brainfuck_py](https://github.com/toddsifleet/brainfuck_py)
You have to hit "connect" and link it to your python install folder. (ex: C:\Python26)
Fantastic! An easier way to open it from the command line is `open -a` open -a "LightTable"
It's not only in list comps, you can use it anywhere: max = a if a &gt; b else b
One quibble: Brainfuck allows programs to have arbitrary characters (for comments and such), so if you encounter a character that's not a Brainfuck "statement" (or command or what-have-you) you should just ignore it. (Self-plug: A keep a [collection of my Brainfuck interpreters](https://github.com/mdippery/brainfuck), including one written in Python, on GitHub.)
I wrote a little language that compiles to C using rply https://github.com/lucian1900/patina. The parser is almost done, but codegen is very incomplete and type check is not done yet.
Holy fuck. A few months ago some guys from Raytheon came by the hacking club at my university and gave out challenge boards, little arduino based puzzles run through terminal. The part I've been stuck on for a month is a puzzle in brainfuck code.
One day I've needed to use a wkhtmltopdf from python and there was no actually good wrappers, so I have made my own: https://github.com/JazzCore/python-pdfkit Hope this will help somebody.
Oh, sorry about that! I didn't notice it and the link didn't show up as posted. Either way it's a good post so it deserves a second look. ;)
I've recently used xhtml2pdf (because of licensing). It is no where near as powerful/feature-rich as wkhtmltopdf though. http://www.xhtml2pdf.com
does anyone have any opinion about parsimonious vs parsley? i recently saw [a parsley talk](http://redd.it/1d7zct) in which the creator claimed (around 8:40 in the talk) that he tried to make the notation more compact compared to other parser generators including parsimonious.
I also wrote a simple BF-interpreter in Python a little while back. It's interesting to see how similar our solutions are, down to the name PyFuck and the usage of a function map (although mine is uncommented): #!/usr/bin/env python import sys class PyFuck: def __init__(self, file=sys.stdin, buf_size=1024, _in=sys.stdin, out=sys.stdout): token_map = { '&gt;': self._inc_pointer, '&lt;': self._dec_pointer, '+': self._inc_byte, '-': self._dec_byte, '.': self._out_byte, ',': self._in_byte, '[': self._cond_jump_forward, ']': self._cond_jump_back} self._buf = [0]*buf_size self._out = out self._in = _in self._ip = self._dp = 0 self._actions = \ map(lambda token: token_map[token], filter(lambda token: token in token_map.keys(), self._iter_file(file))) def get_actions(self): return self._actions def run(self): self._ip = 0 self._dp = 0 while 0 &lt;= self._ip &lt; len(self._actions): self._actions[self._ip]() if not (0 &lt;= self._dp &lt; len(self._buf)): print('\nFatal error: Data pointer out of bounds ' '({0}@{1}).'.format(self._dp, self._ip)) return (-1,) self._ip += 1 return (self._dp, self._buf[self._dp]) def _inc_pointer(self): self._dp += 1 def _dec_pointer(self): self._dp -= 1 def _inc_byte(self): self._buf[self._dp] += 1 def _dec_byte(self): self._buf[self._dp] -= 1 def _out_byte(self): self._out.write(chr(self._buf[self._dp])) def _in_byte(self): self._buf[self._dp] += ord(self._in.read(1)) def _cond_jump_forward(self): if self._buf[self._dp] == 0: counter = 1 while counter != 0: self._ip += 1 if self._ip &gt;= len(self._actions): print('\nFatal error: Instruction pointer out of bounds, ' 'found [ with unmatched ] (@{0})'.format(self._ip)) self._ip -= 1 return if self._actions[self._ip] == self._cond_jump_forward: counter += 1 elif self._actions[self._ip] == self._cond_jump_back: counter -= 1 def _cond_jump_back(self): if self._buf[self._dp] != 0: counter = 1 while counter != 0: self._ip -= 1 if self._ip &lt; 0: print('\nFatal error: Instruction pointer out of bounds, ' 'found ] with unmatched [ (@{0})'.format(self._ip)) self._ip -= 1 return if self._actions[self._ip] == self._cond_jump_forward: counter -= 1 elif self._actions[self._ip] == self._cond_jump_back: counter += 1 def _iter_file(self, file): c = file.read(1) while c: yield(c) c = file.read(1) if __name__ == '__main__': import StringIO import os if os.path.exists(sys.argv[1]): input = open(sys.argv[1], 'r') else: input = StringIO.StringIO(sys.argv[1]) bf = PyFuck(file=input) input.close() result = bf.run() print '\nDONE. ' + str(result) Sample run: $ ./pyfuck '++++++++++[&gt;+++++++&gt;++++++++++&gt;+++&gt;+&lt;&lt;&lt;&lt;-]&gt;++.&gt;+.+++++++..+++.&gt;++.&lt;&lt;+++++++++++++++.&gt;.+++.------.--------.&gt;+.&gt;.' Hello World! DONE. (4, 10)
 #!/usr/bin/perl use JSON; use LWP::Simple; mkdir "album"; get(shift) =~ m/^\s+trackinfo : (.+),$/m; $dat = from_json($1); for (@$dat) { $_-&gt;{title} =~ s/'/'"'"'/g; $_-&gt;{track_num} =~ s/^(\d)$/0\1/; fork or exec "wget '$_-&gt;{file}-&gt;{'mp3-128'}' -O 'album/$_-&gt;{track_num} $_-&gt;{title}.mp3'"; } $pid = wait until $pid &lt; 0; system "clear"; print "Done!\n"; Invoke with $ perl bandcamp.pl http://chipzelmusic.bandcamp.com/album/phonetic-symphony-remastered
Well, if performance matters, then you most likely want to use a linked list for a stack. I'm not quite sure how Python lists are implemented, but I do know that deque's are the way to go for stacks and queues.
We already have an interactive IDE, it called iPython. LightTable is great, but for Python it's mostly meh, for real IDE works, use PyDev/PyCharm/PTVS/Sublime or whatever you want, for interactive use iPython, that's all
I have no doubt that I am re-inventing the wheel in how I handle XML, but in my experience the XML packages for Python, while being very good for generic or unknown XML files, become overly complicated when I'm trying to deal with a file that I already know the structure for. For example, an xml log file from a particular piece of software... That log file always has the same structure to it. If I want to access something in particular, it seems just as easy to me to open the file, read the contents, and feed it through one of these very simple functions. def parse(data, tag, initial_pos=0): tag_information_start = data.find(tag, initial_pos) + len(tag) tag_information_end = data.find('&lt;', tag_information_start) return data[tag_information_start:tag_information_end] def multi_parse(data, tag, initial_pos=0): list_of_found_items = [] for each in range(data.count(tag)): list_of_found_items.append(parse(data, tag)) data = data[data.find(tag) + len(tag):] return list_of_found_items For something that might have children, the snippet could be collected before processing through the above. def between_the_tags(data, tag, start_pos=0): tag_start = data.find('&lt;' + tag + '&gt;', start_pos) + len(tag + '&lt;&gt;') tag_end = data.find('&lt;/' + tag + '&gt;', tag_start) return data[tag_start:tag_end] Can someone sell me on what is so great about ElementTree or LXML or minidom? Or is this just a case where what I am doing with my xml files doesn't warrant the use of these packages?
cause it takes care of stuff like un-decoding strings that are xml encoded and just does all of the hard work for you, and is going to be less buggy. If your log format ever changes then its harder to change your code rather then just using lxml with xpath and getting a list of elements
bad link for me :(
Interesting. Just a heads up though. This does not help to parse through large xml files. That requires [iterparse](http://www.ibm.com/developerworks/xml/library/x-hiperfparse/) methods. 
You're only handling a small subset of XML there - no hierarchy, no attributes, etc. May as well use an INI file.
What's wrong with having more choice?
I said it's great but meh, I didn't say it's useless or so.
Because those 10 lines tell a 683 line library what sort of map it should generate.
I am an amateur programmer and have been playing with LightTable for a few weeks now. (Mostly using JavaScript/Jquery and HTML/CSS). I think that one of the things that when Python integration gets more sophisticated it will be a very valuable tool for someone working on a web app. Imagine being able to run a web app on Django / Bottle while tailoring frontend stylistic / ui tweaks in JQuery / CSS, all while having small changes made in the code reflected in a browser pane in the same IDE instantly.
I like your pragmatic response. It is way too early... In regard to ST2... I am half-way sure that Sublime Text 2 (and probably 3) is written in C++ with Python as a plugin layer See here: https://mobile.twitter.com/sublimehq/status/98962887904739329
[Google search](https://www.google.com/search?q=%22A+simple+printer+of+nested+lists%22&amp;tbs=li:1) leads me to http://blog.aclark.net/2012/05/23/a-simple-printer-of-nested-lists/ also complaining about it. A comment links to [this book section](http://books.google.com/books?id=ENIVBdZIJ6cC&amp;lpg=PP1&amp;ots=kPDX3bUWBH&amp;dq=%22Head%20First%20Python%22&amp;pg=PA60#v=onepage&amp;q&amp;f=false) which has the sample code that apparently many python learners are following.
Well by that logic every python program is a million lines long because we have to count Cython and the standard library and none of us accomplish anything in less than that many lines of code.
So I messed around with it on the release day and noticed a few issues: Output doesn't always properly display, so with a simple for i in range(1, 101): print(i) it doesn't always show all the output, sometimes it would count to 89, sometimes 70, no idea why that didn't work. When you encounter an error it was just hanging on the screen. Works with Python 2.7, no dice with Python 3.3 (granted this isn't a big deal, but it was worth checking). I won't be switching from using VIM/ST2 for the time being, but it's showing some progress.
Have you tried IPython notebook, it actually does much of that?
I said this in a comment elsewhere, but if you're looking for the ability to interactively engage with code, you should really check out ipython notebook (just run `ipython notebook` and see the magic). It lets you write code in cells and execute individual cells, exactly as you would do in an interpreter, but it also lets you save the output and post/share them with others. It's pretty amazing and I think it has the potential to do quite a bit of what LightTable appears to do.
Wow. That's equal parts hilarious and astounding and frustrating. 
Sublime Text already has a REPL plugin. You can also use a terminal + iPython. 
I don't like that it's proprietary. Why would you make a free (as in cost) IDE but not release the source? It seems really douchie to me. Especially since he made more money from the Kickstarter than most open source projects ever get. I tried using it, but it wouldn't work with virtualenv, so I couldn't use it with any of my current projects. I don't really see it replacing vim for me because I have a really nice workflow in vim, but I might try it side-by-side with vim if it ever starts working. 
Oh god i didn't even think about twitter.. 
I do "live programming" as close as it is possible for web development, as I have a local server that watches for changes and reloads its content appropriately.. so I make a change and as soon as I switch to interact with the system it has reloaded. That's perhaps not "instant" but since it sometimes picks up mid-coding syntax errors and crashes my server, I'm not as keen on it getting faster.
They promised to release it open source, just not yet.
[WeasyPrint](http://weasyprint.org/)
That's pretty awesome! PyFuck was the most obvious name that popped into my head haha
Nice! Brainfuck is quite fun to play with. 
I did run across that problem. This commit should've fixed it: https://github.com/andyhmltn/PyF-ck/commit/dd3f323e38a15f5becf67193d09a8dd35998f492
Just a warning. it is written in Clojure. It got parenthesis, enough parenthesis to make every python programmer cry tears of blood by the sheer look of the project file.
PyCon Slides (and Videos) are a great resource as primers and for depth: https://speakerdeck.com/pyconslides
Oh, yeah, I was talking about twitter hashtag :) I am halfway across the globe from the main Python population, so IRC channel is somewhat quiet when I go there. EDIT: s/Clojure/Python/g
thank gawd for thrift and protocol buffers. I don't miss XML. 
I too find that the way they do it is overly verbose and complicated. The way I end up doing it though is almost exclusively using xpath on lxml. You can achieve quite a bit with it, especially once you start using [functions](http://www.w3schools.com/xpath/xpath_functions.asp). I use it mostly for parsing HTML pages, but if you know the value your going for and the format of the xml document, you can write fairly solid xpaths and then grab the content in one line.
They're generated by people following along an example in the book Head First Python. The book's author has amended the lesson (through errata and next edition I guess) to point learners at testpypi.python.org (which didn't exist at the time the book was written). I run a cleanup script that deletes them every now and then. I haven't run it for a while... I'll put it on my looong TODO list...
Run it through a syntax checker before reloading.
I wouldn't say it's mature enough to actually use. Not by a long shot. Needs better integration with, for instance, Django runserver and virtualenvs (though you can run it from *within* a virtualenv and it seems to adapt). 
Is it so hard to use a few for statements?
When working with relatively simple xml files, I've found it easier to convert the xml to a dictionary so you can avoid tags altogether. I forget the library to do this but it's a pretty popular one, if I remember later I'll post the details. 
Also, did I mention?—*parsley is a piece of shit*. Just tried implementing the `mini` language in parsley, and I fail to do so due to parsley giving me errors. I implemented about 1/4 of functionality and parsley already takes about 1 second to run the tests! It takes 0.1 seconds to run *all* tests in case of parsimonious. If you can figure out why parsley is failing with my grammar—pull requests are welcome. **Edit:** parsley branch of mini-language: https://github.com/halst/mini/tree/parsley
I really like Sublime, and I don't want to start an editor war, but I've found Vim with the right setup to be quite a good Python editor. Everyone should use what they prefer, and if you do quite like Vim but haven't tried it with a good Python setup then you might want to give it a shot. You can use [Syntastic](https://github.com/scrooloose/syntastic) for validation and [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) for very clever autocompletion. Suggests package names and things when typing `import django.` for example. I think it uses Jedi under the hood. I think it has [Rope](http://rope.sourceforge.net/) integration too for refactoring.
i find it hard to get rid of margins with wkhtmltopdf and to get anything slightly complex to look identical to a browser.
There's a cmd line option for the margins, you can set at 0 to remove them completly. You can also change the PPI which will help render the document accordingly to your objective. Also, for a better looking result I use svg inline for all vector based graphics (logo and else).
Just a nice little tool I found. From the bottle.py author.
the cmd options for the margin dont actually work, i had to combine them with zoom to get them to work (almost, a thin margin at the bottem remains). Also, it appears some css doesn't work in the latest wkhtml like it does in the latest chrome. Specifically, I wanted to try and create a resume with sampleresumetemplate.net if you are interested.
I have just started writing this project in Python now. I have my API in a module, my website in a module, the model(s) in a module and then I will put the scraper in a module. My next question is, what about if I want to deploy the site to one server, run the scraper on another and the API on a third server? Is there an easy way to do that? I'm not sure if this is a high level architectural question or a Python specific one. I guess I want each module split out into applications but they share the model(s) and maybe some settings. Appreciate your time.
Some of you might be also interested in [PyFunge][]. [PyFunge]: http://pythonhosted.org/PyFunge/
Yes. If this happens we'll have a whole new world in front of our eyes. That's the true disruption.
It does exist for serious programs if you're writing in C# using Visual Studio 2010/2012. It works currently by setting a breakpoint in your code and compiling and running the code up to that point. Once there, you can make changes to the code and reset the current instruction pointer to run the new code. Lather, rinse, repeat. It's not perfect as you can't make changes outside the function (these require a full recompile/restart) or in LINQ expressions, but it's still very nice and a huge time saver, especially for long running programs and fixing small bugs.
it is
I think it was a sarcasm :)
I'm not sure and even if Foxboron didn't mean it serious, there are enough people out there who really think like this. But I'm cool - just trying to explain, since a lot of people seem to stay away from Lisp because of "its syntax".
Agreed, I see it all the time, people disliking "those parentheses". I guess it takes some experience to stop judging programming language by its cover.
Wow, best thing I've seen on /r/Python in months. Thanks!
I'm really not seeing any useful features, and I was really excited about the initial Kickstarter project. One thing I was looking forward to was the ability to display multiple functions at once (in their own small windows), but that seems to be missing in the current version. As is it just seems like a simple editor with a dark theme. I can't even figure out how to run a Python script in it.
I would love to, but its a physical arduino-based usb board that looks like a usb flash drive, the puzzles play like a text based game that you have to hack through
How has AppNexus been treating you? I actually just secured a position on the Data Platform team for after graduation and I'm really excited! 
You are right. Most people don't know what SFML (Simple and Fast Multimedia Library) is good for, even if they know what it means.
I meant that if I write the start if a loop, then go look up the method I need to use inside the loop, my IDE saves the file which triggers the reload. Sometimes I don't notice that this happened. I guess my point is that my turnaround time to see changes is already pretty fast.
Hey, thanks for your work on PyPI. Obviously it's a vital resource, but I appreciate the time you spend keeping it sane.
I know what you mean; I'm suggesting that you modify whatever's triggering the reload to run your code through something that checks the syntax first. If it fails, don't reload the code. That way, your server won't crash.
I use smartcd https://github.com/cxreg/smartcd. That tool is enabled/disabled virtualenv when I in/out at project directory.
In my experiences with it, the internal webkit css processor seems to shit the bed on any sort of floating text :(.
SWEET.
This is already happening with the right frameworks (Tornado/Twisted). These frameworks allow you to watch css/js directories, if a file changed, the framework can recompile the assets. You can also build your own auto recompile using [pyinotify](https://github.com/seb-m/pyinotify). 
I'll give ST2 a shot, I started programming with Java so me being the ~~cheap bastard~~ frugal person I am I went with Eclipse. Then when I started doing Python development full time I used PyDev because I already new the ins and outs of Eclipse. So I basically sit with Eclipse open and iPython when I develop. I will definitely check out ST2 though. Thanks. 
wow. actually, I wouldn't exactly know what to do with it right now, but I'm sure this comes in handy!
AppNexus has been/is/will be awesome, especially since you'll be joining the same team as me!
What really bugged me so far when it cones to Sublime Text praise is its poor integration elwith version control like subversion and git. Call me spoiled but with good old textmate I have an instant overview of my files' statuses. The only addon I found for ST for subversion costs another 15 euros. 
https://github.com/marianoguerra/rst2html5
The introductory tutorial given earlier on the same day is [here](http://www.youtube.com/watch?feature=player_embedded&amp;v=4ONBVNm3isI)
tldr: you can do some machine learning stuff in python with the scikits-learn package. 
Okay, I have a question. Is there any pandas integration with scikit-learn beyond the fact that dataframes can be cast as numpy arrays? I ask because I tried feeding the iris dataset into a pandas dataframe and then renaming each sample's category to a string (i.e., `versicolor`, `setosa`, ...) but apparently scikit learn expects a string. Am I missing something? String-form indexes and category labels would be really nice for these kinds of applications.
I worked for years as a software developer without a degree. I had done some open source stuff and light freelance, applied to a low paying position as a Linux sysadmin, then got promoted to the dev team. I kept building experience and soon enough, my lack of formal education was not really brought up by anyone because my skill and experience spoke for itself. 
Can't agree more. College Degree is not so important if you want to be a developer, just get your head into code and design, than work hard. 
That is very true. Passion, practice and you will be flying in no time!
in my opinion college really is about building a network so that when you get out of college you can then use it to help you find employement
Awwww...who got a Reddit-hug? They did! They got a Reddit-hug! Yes they did! Yes they did!
I am so sick of this hosting company! I need to upgrade to a better hosting for sure.
In all fairness I love 000webhost for their free service, and for practicing web_Design or looking at what others' sites will look like before they go out in the real world!
I can't read the article at the moment, but I find it highly implausible that it's possible. Programmers are hired by HR resume jockeys and HR resume jockeys both don't understand programming and are using automated resume processing software. As such, they just tick off a series of boxes, 99.9% of the time will include a degree because the HR resume jockey doesn't understand what skills and qualities make for a good programmer. Also, they don't like to read or spend any time doing this part of their job. The resume software will simply match keywords and the odds are your resume will never even be seen by human being. I'm not making this up. Studies have been done that have written the *perfect* resume for a job, popped them into resume software, and only about 1 in 5 pop back out again. In a related study, after hearing about Silicon Valley being desperate for established large project managers, resumes were hand-crafted by someone to match/exceed what these people were looking for. Degree? MIT or Harvard. Large corporate experience? IBM or Intel, etc. Again, only about 1 in 5 got responses requesting an interview. The moral: even if the perfect candidate falls from heaven into an HR resume jockey's lap, they'll probably can't tell. Of course, I reserve the right to change my opinion once the article article actually comes back online again. :-) 
But you have to show you know what you're doing, and to HR people that means a degree. Heck, I've seen places that advertise "Bachelor's Degree - any", and when I inquire, they say something like "having a degree shows that you have follow-through and can apply yourself", or similar back-of-an-herbal-tea-box nonsense. At a community college I saw someone get promoted in IT over someone else because of a degree. The degree of the fellow who got the promotion? Biology. I declared that if we ever had any *real* bugs in our computers, that degree might come in handy. :-) 
You left out the "hiring" part. You can'r be a developer without being hired, unless you start your own business. And to be hired, you generally need a degree. 
I wish they didn't ration too much. I will consider paying for it soon. They are good but am getting too many hits!
I hope the hosting company actually lets my site back as soon as possible. I wouldnt want to start migrating again!
I think the field is moving away from what it once was. If you lack a degree, many times they'll want experience. When you offer to show projects you've worked on (open source, volunteer, etc.) the hiring guy goes "no, I mean how much real experience... like in the industry" and I'd like to throttle them.
It's when Too Many Redditors navigate to a site and crush the server; usually caused by a link somehow making it to the front page of Reddit. It's basically like a big, retarded bear hugging you. And then it masturbates.
I second that. Pypi is one of my favorite things/sites. I put a package up so I could easily install it on my different machines (and any other machine that I might need it for) , but seeing other people have downloaded it makes me feel even better. 
what about programmers without a CS degree but some other science/engineering type degree? Are those common or no
&gt;And to be hired, you generally need a degree. Most of the sysadmins I've known didn't have degrees. If you are willing to study and get a cert, you can become a sysadmin, and from there it's pretty easy to get a dev job. In my personal experience, work history almost always trumps education. But if you have access to it, education is a less arduous route.
So you're talking about using a backdoor into another job, meeting the paper requirements of that job, and then trying for an internal promotion? Ok, I can see how that could work. 
America used to have a system like this. Then corporations figured out they could require people get the experience on their own dime before paying them apprentice wages.
&gt;And then it ~~masturbates~~ rapes you. FTFY
Sadly when the market is tight, a degree matters. After the dot com crash I watched three really talented and experienced friends go bring for jobs because they didn't have that piece of paper.
I think that that host is rationdd on the sub domain level. Create a new one.
I will learn how to mirror a site then try it. I have not done it before so..
I have never received this much traffic!
I am the owner of the site. I can't access the admin, unless I try to get the markup from the server directly. Let me see what I can do!
You went to a really shitty college then.
I don't have a degree. I work full time as a software developer. My response rate on my most recent job search was about 35%.
Actually I never graduated. Saved myself a pile of debt.
This is pretty common. I work with several people with either mathematics or physics degrees.
Wouldn't it be better for companies to choose the "better man" instead of basing their decision to promote someone on a degree that has not much to do with programming? I for one wouldn't want to work for a company like that. And maybe that same company should hire HR people who can do a proper job? If a HR person filters programmers he/she should be qualified to do that.
&gt; only about 1 in 5 pop back out again. So, apply 5 times and you'll probably get a positive response. Also there are plenty of places that don't hire the way that you mention. Our company is one of them. The last place I worked for is another. HR don't throw out anything unless we've instructed them to.
If you have a static or PHP site look into one.com, I use them, they are cheap and do not limits on CPU/bandwidth.
There is one here: https://github.com/paulgb/sklearn-pandas
VPS: it's like 2 euros at edis.at or if you want to *gasp* get a dedicated box, 100mbit/s at OVH/Kimsufi is 10 euros/month. 
yep, that's me
1. Get good hosting service. :)
ah, i have a similar experience. it makes the program usable only for simple documents, which is exactly not the use case I had in mind for it.
You can just use pastebin to put the post se we can read and later on find a new proper webhost.
I'm quite glad for my CS education, but I haven't experienced a ton of overlap with my software development passion/career. I think much of SD cannot be learned in the absence of sustained work on a shared codebase, which doesn't jive with the current academic model. 
If you're now looking for a new webhost because CPU / traffic, I suggest [RamNode](http://ramnode.com/) if you're up for setting up a VPS.
What's wrong with just one? a = [1, 2, [3, 4], 5, [6, [7, [8, 9], 10], 11, 12], 13] def printNestedList (lst, level=0, indent=' '): for elem in lst: if type(elem) is list: printNestedList(elem, level+1, indent) else: print indent*level + str(elem) printNestedList(a) 
[Nearlyfreespeech.net](https://www.nearlyfreespeech.net/about/faq) - that is, if you are comfortable at the command line, don't need your hand held, and want to host a low traffic website for about $0.03/day. (It's not that the site can't handle high volume, just that when you start getting really popular on a regular basis, the plans of other hosting companies start to make sense. NFS.N can handle an occasional "slashdotting" fine, and you'll never get a bill for going over bandwidth, and you'll never be forced to upgrade to a higher tier either.(There aren't any))
next time, 1. Create content. 2. Access it once via [CoralCND](http://simpledeveloper.com.nyud.net/how-to-be-a-software-developer-without-a-college-degree/) 3. Post the nyud.net link in comments when your site gets DDOS 4. (optional) configure with `mod_rewrite` such when you start getting a lot of hits from a specific referral string, you automatically forward to CoralCND
I got a job overseas as a developer without completing my bachelors. I'm still going to, and my job seems supportive of me continuing school while working for them.
Thanks, Olivier! Now that I watched the first 15 minutes of your presentation, sklearn's use of ints instead of strings makes a lot more sense! The good news for me is that my data should fit in memory =)
Side note: You are neither spelling nor using the word "albeit" correctly. If you replace it with the phrase "although it be," it should still form a sensible, albeit old-fashioned-sounding, phrase.
&gt; America used to have a system like this. When? Maybe in the 1600s ... the fact of the matter is the history of education in the US is involved and cannot merely be pinpointed simply to modern corporations.
Agreed. The closest thing we have like that in the US are co-ops, but it's kind of really backwards. Basically you can only get a co-op when you're in college, you have to pay the school tuition even though they aren't the ones providing any service besides possibly linking the business with the student, and then most times the employer doesn't have to pay the student! What's even worse is that a lot of degrees require this sort of corrupted behavior. Very strange.
*"although be it" Not that 'although it be old-fashioned-sounding' doesn't have a kind of rural charm :)
I didn't forget about you: http://wrobstory.github.io/2013/05/vincent-spatial-ogre.html
Site is down. I work as a software/web developer. I don't have a degree. Computer science was always my thing growing up, but I had no confidence in myself. A year after highschool, I was unemployed and not doing too well. A friend I had worked on an OSS project with when I was 13-15 called me out of the blue and offered me a contracting job. Three years later, I'm now a salaried employee, and I do a lot better than the CS graduates we sometimes higher. Unfortunately, I think my options for working in a conventional company are probably still very limited. And I have less negotiating power when it comes to wages. It can be a boon at times though, as I need to think more out of the box when it comes to business/job opportunities.
Started off as a desktop support apprentice, my company asked what I would like to do and bam! Here I am.
Ah. I was going to complain about it being JetBrain's issue, but since I'm running the server as a normal program I should be able to figure something out.
My friend is sysadmin for the 4th largest datacenter in the world .. never finished high school.
*although it be. [[citation provided](http://www.merriam-webster.com/dictionary/albeit)]
I graduated from college back in the late 90s. After a few years working in IT, no one has ever bothered to ask me about my degree or educational background. I could probably even get away with leaving it out of my resume. 
This. I've used RamNode for months now and absolutely love them. Have had no issues to this day with them. (And if you're looking for a coupon code, use LEB35 for 35% off.)
I worked at an infosec startup several years ago where most of the technical staff had nontechnical degrees. History, religion, English. Sure, there was a physics PhD there and a handful of compsci geeks, but they were the minority. And mostly the ones with nontechnical degrees were the better techies IMNSHO. FWIW, my experience after working at startups and larger organizations has been that tech startups by and large are much better at recognizing and picking good developers in the interviews, irrespective of any degree. Other organizations are more likely to rely on a combination of degree and experience and less likely to run the sort of interview that can recognize the software genius with a GED or random nontech degree. YMMV.
&gt;You are seeing this page because website has reached CPU usage limit of the server, and it was temporarily disabled. it seems they're past their five minutes of glory[...](http://www.youtube.com/watch?v=7uW47jWLMiY)
I like rdflib! I also like doing the array thing. I've used Jena in Jython, Clojure, and on the command line. I like using Fuseki and using JSON query results. Let me know what you wind up doing. 
I prefer red hat's [openshift](https://www.openshift.com/) :)
You probably want to check out [Bulbs](http://bulbflow.com/overview/).
How to Tap Out a Web Hosting Contract By the Third Day of the Month with One Reddit Post
I don't boast about germany a lot, but in addition to having the apprenticeship model, our university education is cheap in comparision, and in some states even free and at least equal in terms of quality compared to the US. I really don't understand why the US don't have "free" education, because good and affordable / free education for everyone is the cornerstone for growth. It's one of the things which are good about germany, and i think about most of europe in general.
"How it feels to be a software developer without a degree" -&gt; "CPU Limit reached" -&gt; That sounds about right, interesting premise to start with -&gt; Oh, this is a hosting page that's not part of the article. -&gt; I am not a smart man.
That's totally okay. When reviewing CVs i look more at references and examples than on education. A lot of very good programmers don't have any education.
Great resource, I was waiting for some more pycon videos. I posted this in /r/MachineLearning If anyone else finds this subject interesting, you might also find that subreddit worth subscribing too. 
Bandwidth limits breached, atta boy Reddit! *chuckles over irovy*
I bet you have a leg up on others. You know what the difference between a linker and compilier, bit endians, calculus, logic proofs, algorithm complexity and efficiencies, finite state machines and tons of other stuff non degree people don't even know exists. Don't sell yourself short as you can draw and expand that knowledge at any point in your life.
Friend-based startups are the new co-ops, where everyone helps each other become a trained professional.
Yeah... I was trying to create a picture report with fancy CSS and it couldn't handle it. Looking into other options like xhtml2pdf.
Is this free or paid hosting? If paid you should switch to like bluehost or something - I've heard good things about them. If it's free and low traffic there may be someone out there that has decent infrastructure willing to host you.
I would love to find someone willing to host me at the moment because am currently using free hosting.
I like zodb.org. It is a hierarchical database, but it is pretty easy to map a graph onto a hierarchy.
Maybe if you had a college degree ... you'd know what to do. Sorry ... couldn't resist.
I wouldn't say I'm selling myself short, I just have found that other than algorithmic complexity and occasionally state machines, the things you list don't come up very often when evolving a software product. 
I realize that it happens all the time. The question is though, is this good for the company in the long run if they favour an idiot with a degree over a genius without?
It's also pretty easy to map a graph into a relational database, a paradigm I'm already familiar with (as opposed to zodb, which I know very little about). I'm looking to see if there's a standard solution, probably using RDF.
&gt; I suspect that I want some kind of SPARQL query library &gt; that I can point at a backing RDF server. SPARQLWrapper meets the criteria you specify: http://packages.debian.org/squeeze/python-sparqlwrapper Could you provide a little more detail? Specifically, what leads you to conclude that you need an RDF server - are you intending to provide a SPARQL endpoint perhaps? Are you amenable to using virtualenv to construct a discretely separate work area and installing Python packages into that? If so, it would increase the number of options available to you. 
I'm guessing it isn't, but the problem comes with getting them to recognize that.
&gt; what leads you to conclude that you need an RDF server It's entirely possible that misunderstanding leads me to the conclusion. What I want is a place to store "x has y relationship with z", such that I can later make n-depth queries against it. Further, I want to do it in the most "standard" or "correct" way possible. I'm coming from the RDBMS world, so I'm looking for an analog to "I have relational data to store, so I have an relational database server that I store data in and make SQL queries against." I don't use virtualenv, but that doesn't preclude me from installing packages directly from pypi; I just set paths in `pydistutils.cfg` and `PYTHONPATH`; but if it's a server daemon separate from what I'm building myself, I'd prefer it to be something I can more easily manage with Puppet.
&gt; In Python 2.6, no one can hear you scream. Well said.
Good for you. 
&gt;I have very savvy friends writing new applications on Python 2.6. Our &gt;children will have flying cars before we're done debugging these &gt;steam-powered versions of Python. Here's the biggest problem Python has. I certainly hope Guido's learned something from this and we don't go through the same thing with 4.0. 
Disclaimer: It's the Friday afternoon before a bank holiday weekend and I've had a beer after work. If any of this comes across as hostile or provocative then I apologise. That is not the intention. I realise that there is more to Closure Compiler than minification, but I do not agree that it's the only way to create something great. Using JSHint on the highest possible settings will find some problems, albeit not all of them. You do not have to learn a new tool to write correctly. The code I work with is robust and well tested, which is no mean feat for a sprawling repository which has been worked on by 50+ people over the past couple of years. It's still maintainable, efficient and accessible by new developers. You can enforce things closure adds without tying yourself into it. I'm sure it is an excellent tool that has an incredible amount of benefits, but stating that it's *the* way to write good JavaScript is just misleading. I would imaging that was not your intention though. Are you just suggesting that it is a nice method to aid structure and maintainability? I may have interpreted it wrong. 
That's good to know. The best hiring process I've had so far involved chatting about code for a bit in an office then going for lunch at a Turkish restaurant. My background seems to draw me towards the kind of laid back environments that will hire people based on experience and personality rather than paper. It also means I've never had to wear a suit! I prefer working for smaller companies that give people like me a chance. I don't like the idea of being filtered out of a role by a complex CS question.
Everything.
I don't have any degree at all (working on a physics degree actually) and I have a developer position in a mid-sized company in the banking industry, writing Python code all day no less. However, HR does not control every aspect of hiring here, and my current boss handled almost everything involved in hiring me aside from getting permission from his boss to hire me, and then passing off all the formal HR stuff to the actual HR people once that'd been done. I never want to get a CS-related degree because I really don't care about the inner details of programming and just like to fuck around with code. It's worked well for me in the past ~20 years since I started playing around with the code in GORILLAS.BAS. :) So if you're trying to get a spot at a gigantic company, yeah you're going to have to wrangle with the resume jockeys who don't know a thing about what makes a good programmer. Otherwise, it's completely possible.
Okay, that makes sense. I think there are a lot of ways you can achieve a similar result though. Maybe TypeScript or Dart. I'd actually prefer to learn something like that than CoffeeScript. Only because CS seems to be a different syntax for the same language, whereas these other, more structured, languages seem to make large scale application development a lot less painful. I think I just prefer to write JavaScript outright because I prefer the shallowness of my stack and my lack of dependencies. I know exactly what is inheriting from what and I know how this will loop. I control as much as I can and actually enjoy reinventing the wheel when I have the time. I can see how closure would help though. It would just be difficult to bring a whole team on board I think. 
Oh wow, I did very similar project couple years ago: https://github.com/didip/bayes_on_redis
Do you have the content locally? Would love to read it. 
I was only talking about a C.S. degree and the class curriculum it includes; without taking those classes, I would suspect most people wouldn't learn it (maybe some people learn a fraction of it outside of college) and would be easy to test. Anyways, I find it is the people with the CS/MBA degrees that do the interviewing typically
&gt;What makes you think people without degrees don't know about those things? I would expect most of them do not however there will always be some subset of those people that do.
This looks like the best bet so far. It's not SPARQL (this Gremlin thing is new to me) but the [Neo4j server](http://www.neo4j.org) mentioned there has [a Debian repo](http://debian.neo4j.org).
I built something like this years ago just for fun using a subset of WikiPedia articles. You can find it [here](http://www.whatsthegist.com/). I took a slightly different approach than using intersection. I simply treated the sentences in a given document as a corpus in the tf-idf space. The title of the document was then assumed to be the query. To construct the summary, I computed the cosine distance between the tf-idf corpus and the query vector and selected the top k sentences. Extremely simple in terms of information retrieval, but it worked surprisingly well.
You should've launched your own product to compete with Adobe, instead of doing it as part of your daily job as an employee.
This is actually really timely for me. Thanks!
I am so glad I could help!
He's describing a project he did that relies heavily on Python... how is that not about Python?
YAY PYTHON YAY PORN 
I don't know, but I posted a sub-domain for my site and only that went down due to rationing.
I understand they treat two domains like "blog.mywebsite.com" and "mywebsite.com" differently. I will look for a better solution anyway!
Honestly, he probably made more in promotions than he would've competing against adobe.
* http://pythonhosted.org/SuRF/integration.html * http://packages.debian.org/stable/database/virtuoso-opensource * https://github.com/RDFLib/rdflib-sqlalchemy
How do you use threads asynchronously, overcoming the GIL?
/r/semanticweb
Thanks a lot! 
True, but the link you point to suggests lxml. stdlib's ElementTree also has iterparse, though - see the "stream parsing" section in http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/ Also ET's become quite a bit faster in Python 3.3 
&gt;"To make things even harder" I bet this is a recurring problem.
Thank you for this awesome comment. I hope you noticed the that the point behind "Learn to code in 21 days" was to discourage it and that is why I added "NOT" to the title. Thanks again and I will be checking out your github. 
Honestly if you want to be able to reach everyone use HTTP fragmented video files, bypass the restrictions of firewalls that RTSP faces. Then have your stream files in a "RAW" format which is read by your HTTP server and wrapped in the appropriate container for the end user such as F4F for flash or MOV fragments for apple devices. * * * Source, someone working for one of the large CDN providers.
This is filled with puns, I giggled at "share the load". Yeah, I'm that immature. 
Sounds like interesting work. I wonder what type of benefits package they offer.
&gt;He wrote code pssst, that's the part that's about python
Porn sites streaming &gt; Netflix, YouTube, other Flash and Silverlight streaming. Almost never crashes. Sometimes only when they embed tons of flash ads and moving GIFs.
I am deeply fascinated by the internet porn industry. they always seem to be solving interesting problems at crazy scale.
Programming? How on earth is it not about programming? Anyway, I agree it's not really "about" Python, but there *is* substantial Python-specific discussion in there. Seems to qualify this post for /r/python better than many. I think it would fit a more general subreddit better, but I don't object to it being here.
I am going through the data structures you listed to learn the ones I do not know. (sort of want to know who would possibly downvote this)
What this guy/gal said. ___ Systems engineer for a company that sells video streaming solutions to cable/media companies. I was at NAB recently, walking around, and it's amazing how many of these "Next gen streaming" companies are still storing a separate copy to stream HLS vs HDS vs Smooth vs whatever. 
&gt;YAY PORN Doing God's work son.
The implication being here that there's a video of a software developer working on code while doing it? And then the video of that happening is uploaded to the website IN the video, making it the most meta pornography available?
* https://pypi.python.org/pypi/urwid * http://excess.org/urwid/docs/manual/
If you're scanning the text with a naive bayesian classifier, you can rank sentences as you go by which ones have the highest-rating words in the given categor(y|ies). You don't need to compare one sentence to another. 
I do think that posts about things that were "mostly written in python" should be fair game for this subreddit, even if they are also programming related. Just as if this were done in brainf*ck it would relevant to that subreddit because it "shows the potential of the language".
Because ISPs use packet shaping to limit bandwidth for major sites. This is why Netflix established it's [ISP Speed Index](http://ispspeedindex.netflix.com/). I know TWC does it because if I use a VPN tunnel most things become faster. They also do it based on service tier.
GIL is irrelevant when your threads are just doing IO. It'll only bite when you parse the HTML, but if you use LXML (which is insanely fast), that releases the GIL while parsing. If the GIL/CPU is going to be a problem, multiprocessing is your friend. Not sure if that works with wxPython, though.
But to process the e-mails, Guido has to e-mail his program along with all of the incoming e-mails to another program, which has to e-mail the program along with all of the incoming e-mails to another program, which has to e-mail the program along with all of the incoming e-mails to another program, ^which ^^has ^^^to ^^^^e-mail ^^^^^the ^^^^^^program... RuntimeError: maximum recursion depth exceeded
Very nice, thank you.
That's actually quite a nice explanation :)
Original author here. I'm Hungarian and at the time I started working for the company it was a pretty laid-back place and good to work at. Sort of startupy. Money was good too. Things have changed since then, but here you don't have a lot of opportunity to work for the World's top 25th or so site when you're 23 :)
You guys are hilarious. Actually we did not mean to do that, just a happy accident. Oops :)
I'm not sure about that, but wowza and red5 were already there with their businesses and customers so it would've been hard. Although selling it to a large CDN might've worked. Also I'm sure ustream would've been interested, which is also a Hungarian company
The article's author here. It is actually a story of glory and win with Python. I couldn't have done it with C alone and I think it's beneficial, because it shows how easy Python is to learn. Also how quick can you develop a prototype in it and how great it is when it comes down to profiling. And last but not least how extremely powerful it can become if you sprinkle a bit of C on top of it. At the time I tended to think that Python is too slow for protocol parsing, and any work that needs to scale. Experience proved me wrong.
from funny_comment import crack_me_up crack_me_up()
Also consider going to his [website](http://ianozsvald.com/2012/03/18/high-performance-python-1-from-pycon-2012-slides-video-src/) 
Yup, this is definitely the largest streaming video provider.
Very cool read!
* http://sphinx-doc.org/builders.html?highlight=latex#sphinx.builders.latex.LaTeXBuilder * https://bitbucket.org/birkenfeld/sphinx-contrib
http://django.2scoops.org/
Excellent ! Both of these projects have made my life better at times, many thanks for the work :)
Looks good, nice set of resources :)
why is this any better than doing this: except Exception as ex this way you catch all exceptions and can either process them or throw them or whatever. 
As some with no background in computer science, and is just learning python now (more a linux geek/shell scripter really) could someone explain this to me? My understanding was that if speed *really* mattered, you wouldn't be using python. Or maybe there's more to performance than speed? To be clear, I've not watched the video (yet), but the title instantly jumps out as someone contrary to what I had come to understand.
The author is trying to demonstrate the risk in doing that unintentionally, and what happens if you write weak exception handling code. What you suggest is correct as long as every case is covered via else or default or something so that exceptions don't get eaten.
&gt;Newer technologies such as HLS, Microsoft's Smooth Streaming, and Adobe's HDS have emerged to enable adaptive bitrate streaming over HTTP as an alternative to using proprietary transport protocols. Please consult [this article](http://en.wikipedia.org/wiki/Streaming_media#Codec.2C_bitstream.2C_transport.2C_control)
Watch the first two minutes for the answer to your question. :)
&gt; My understanding was that if speed really mattered, you wouldn't be using python. Or maybe there's more to performance than speed? Performance is more subtle than just choice of language, though it is possible to write numeric code in Python that is on par with C if you use the right numeric libraries and data structures.
What on EARTH is the point of using SCGI today?
The git server that's built into git is a CGI server, but that's like all I got.
Ah, that's what I figured. I was on my phone earlier and couldn't watch the video, but realized after I posted that I was falling into much the same (mental) trap I'm trying to escape from now, which is to say, conflating getting things done faster with making more progress, (Yeesh, I, read a few books on management and suddenly I sound like every project manager I've ever hated.)
But that's insecure! Lets write our server as a domU running under Xen. Silly benchmarks are pointless. You can also usually tell when the benchmark machine is an average desktop. 
Fortran!
Partial credit
please use nginx+uwsgi for python (which is bundled with nginx btw) anything else except maybe gunicorn is just not state ot the art
http://www.reddit.com/r/programming/comments/1dotwe/bigo_cheat_sheet/
Just so you know, we didn't use Sphinx. We've considered using Sphinx, but the modifications or extensions necessary to Sphinx to create the book we wanted would have taken too much effort. That said, I love Sphinx. :-)
White space matters in python...also on reddit.
 import urllib2 url = 'http://aima.cs.berkeley.edu/data/iris.csv' u = urllib2.urlopen(url) localFile = open('iris.csv'', 'w') localFile.write(u.read()) localFile.close() Yuck. That is *really* terrible code to be displaying on a reference card. The proper way to save a URL to a local file in Python 2.x is this: from urllib import urlretrieve urlretrieve('http://aima.cs.berkeley.edu/data/iris.csv', 'iris.csv') For Python 3.x replace `urllib` with `urllib.request`. 
You should post this to /r/learnpython instead. print "Tax:", order*tax `order` is a string, as that is what `raw_input()` returns. `tax` is a float. You can't multiply those -- that is what the exception is telling you. You probably want to convert `order` to a numeric type, either int or float. (It doesn't matter which: int \* float and float \* float both yield float.) 
Click on the **formatting help** link and format your code correctly please. What you've posted is not Python (cuz whitespace counts :P)
Just for in the future, you might want to look into something like Pastebin or Gists to save some formatting problems.
See also: http://regebro.wordpress.com/2011/12/24/self-publishing-a-book-part-2-my-tool-chain/ * ReStructuredText * Python tests using unittest and doctest * Sphinx to generate LaTeX output * xelatex to generate PDF 
 A=5.45 B=4.49 C=7.79 D=0.95 tax=.07 order=int(raw_input("Please enter your order") quantity=int(raw_input("How many?")) if quantity&lt;=0: print "Please choose another number" else: order=(order)*quantity print "Your price before tax is:", order print "Tax:", order*tax print "Your total is:", order+(order*tax)
you are assigning a string to your variable `order` with `raw_input`. When you multiply a string by `x` you get the string repeated `x` times. ex: &gt;&gt;&gt; greeting = 'hello' &gt;&gt;&gt; greeting * 3 &gt;&gt;&gt; 'hellohellohello' in your case you're multiplying whatever string you get from `raw_input` with 0.07, and python doesn't know how to repeat a string 0.07 times, and I don't know either. You have the variables `A`, `B`, `C`, `D` in your script, but from `raw_input` you're getting the strings 'A', 'B', 'C', 'D' and they're not related. what you could do is either use eval or a dict: choices = {'A': 5.45, 'B': 4.49, 'C': 7.79, 'D':0.95} identifier = raw_input('Please enter your order') order = choices[identifier] # or a bit safer # order = choices.get(identifier) ... rest of your script
Finally. Great work!
When you say the original code is "*really* terrible" do you just mean there is an easier way to do it (which you show)?
 choices={"A":5.45, "B":4.49, "C":7.79, "D":0.95} order=raw_input("Please enter your order") order=choices[order] total=int(raw_input("How many?")) if total&lt;=0: print "Please choose another number" else: order=(order)*total print "Your price before tax is:", order print "Tax:", order*0.07 print "Your total is:", order+(order*0.07)
 so im thinking this if order!=choices[order] print "Please choose A, B, C or D" but i'm missing something here..
Ok i moved the post to the /r/learnpython page.. thanks for your help! http://www.reddit.com/r/learnpython/comments/1dq8rk/simple_python_help_for_a_new_guy/ 
Thanks! Sounds like a great resource.
And even better with iPythonQT.
I think this is terrific. I'm going to try using this in my next project. 
Yup. The inline plotting is wonderful.
My advisor said this about college: "The college you went to will help you land your first job, after that, no one cares where you went to school, they only care about what you've worked on". 
I'm so happy I could cry.
Both methods are valid and work. But his are more future proof.
It actually is pretty terrible - the entire contents of the file will be read() into memory. Plus no checking of content-length headers, etc. 
Usually, in Data Mining tasks you want to preprocess the data before to save it. The snippet published in the card makes clear how to read the file then save it. The function urlretrieve just saves the content to a file.
it is just an example, usually snippets need to be adapted for your purpose.
ooh. now if they could add ipython's "?" and "??" helpers - i find those a LOT easier to use than typing `&gt;&gt;&gt; help(foo)` or `&gt;&gt;&gt; foo.__doc__`
I like these cards a lot but I *really* wish they used "print(foo)" instead of "print foo". Such a simple change to the cards would go a long way to future-proofing them.
Where is that? Just curious.
Completely agree with this... Python is very easy to learn, and it has a wealth of libraries already available for data analysis. Ruby and Javascript may be worth it if you plan to do data analysis with heavy web work, but Python holds up pretty well in that realm as well.
You can learn technical skills in many ways, and a well-taught CS program is one way to do that. I agree, it's not the only way. But when I'm evaluating experience, one of the things that a degree tells me is that this person can set a distant goal, work under someone else's rules on things that may or may not be personally interesting and under conditions of stress and frustration and unreasonable people and somehow still deliver results. I completely agree that there are also other ways to demonstrate these qualities, and I have urged people who ask me how to succeed without a degree to think of ways to demonstrate these qualities. I think a core coder on a large open source project may well evidence some of these things but I'd definitely want whoever was interviewing to tell me why that was so. TLDR: A university degree talks about more than just passing subject matter tests -- it is evidence of thriving and enduring in unreasonable conditions. That matters a lot.
http://ipython.org/ipython-doc/dev/interactive/qtconsole.html this?
juchhu!
You also have urrlib2 and pycurl for http calls. You can get a lot done with very little code. 
Python. Definitely. There is a ton of support for scientific work available in the language, and there are many tools available to learn python online. Javascript is nice to work in for web (and node.js, etc) work but it doesn't have the support for file work and for scientific work that Python does. Edit: add some links: CSV support in language: http://docs.python.org/2/library/csv.html A nice beginner's page about CSV: http://www.pythonforbeginners.com/systems-programming/using-the-csv-module-in-python/ 
Don't forget bpython! It has really nice tab completion built in
For these I would recommend requests package. 
Requests is actually the most readable. I would definitely agree on this recommendation. 
Glad to see Python becoming better and better
I definitely agree with this, for data mining I think [this](http://refcardz.dzone.com/refcardz/data-mining-discovering-and) will be helpful.
On this note, Check out http://www.codecademy.com/#!/exercises/0 This is what im currently using to learn python. Working well so far!
I'm a big fan of [ipython's web notebook mode](http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html), which lets you easily organize, save and rerun snippets from your web browser.
REPL is "read eval print loop", yes, the interactive interpreter. "tab completion" has nothing to do with the tab character. It's about hitting the tab *key* on your keyboard to autocomplete the word you're typing.
Yup, that. `sudo apt-get install ipython-qtconsole`, then `ipython qtconsole pylab=inline`.
Me to, for publishing. I don't like how it's hard to debug in the web interface though.
I tried following it because plotting big data might be useful in my job but not essential, so I hoped this would be a quick start guide for the sciencey libraries of python, but all I do is print data and I have no idea what I'm doing. Also, using scientific data that I have no idea what it actually is (something about flowers) is really detracting from learning because I have no idea what I'm seeing.
http://codegolf.stackexchange.com/questions/464/shortest-url-regex-match-in-javascript
* [URI](http://en.wikipedia.org/wiki/URI) &gt; [RFC 3986 Uniform Resource Identifier (URI): Generic Syntax](http://www.ietf.org/html/rfc3986) * [IRI](http://en.wikipedia.org/wiki/Internationalized_Resource_Identifier) &gt; [RFC 3987 Internationalized Resource Identifiers (IRIs)](http://www.ietf.org/html/rfc3987) * [IDN](http://en.wikipedia.org/wiki/Internationalized_domain_name) &gt; [RFC 3490 Internationalizing Domain Names in Applications (IDNA)](http://tools.ietf.org/html/rfc3490)
It is not a start guide to Python scientific libraries but it shows how to perform some data mining tasks using Python. The nature of the dataset is explained in the first paragraph.
Ibm watson, of jeopardy! Fame, was implemented in prolog. If you like logic programming, have a look at [pyDatalog](https://sites.google.com/site/pydatalog/).
I'm curious, why did you put the WSGI application in an object?
If we're testing how fast we can asynchronously flush "Content-Type: text/plain\n\r\n\r" Hello World" to a socket then might as well code it in straight C with libev, which will outperform both. I question the value of this exercise though.
I've done these benchmarks and I did that to bash the "Fanboy" buzz long time ago. My post [Node on Nails](http://blog.creapptives.com/post/9677133069/node-on-nails) became so controversial despite my disclaimer that I had to revisit it. I've used both Node.js and Gevent in my projects and my take is pretty simple **DO WHAT FITS YOUR TECHNOLOGY STACK AND WHAT YOU ARE GOOD AT**. 
If that was your intent then it's still ugly, because it should be using a context manager to close the file and not doing it manually. from urllib2 import urlopen u = urlopen('http://aima.cs.berkeley.edu/data/iris.csv') with open('iris.csv', 'w') as outfile: outfile.write(u.read()) It's very common for newbies to neglect to close the file, and if you let the script just end without doing that, any data still in the buffer will not be flushed and the file's contents will be blank or incomplete. You shouldn't have to remember to close things -- context managers exist for that reason. Also, in Python 3 the return value of `urlopen()` works as a context manager, so you can write: with urlopen(...) as infile, open(...) as outfile: outfile.write(infile.read()) 
[University of Reddit &gt; Computer Science](http://ureddit.com/category/23442/computer-science)
* http://wiki.python.org/moin/PythonBooks * http://wiki.python.org/moin/LocalUserGroups * http://wiki.python.org/moin/StartingYourUsersGroup 
* http://www.codecademy.com/en/tracks/python * http://www.class-central.com/search?q=python
But I still can't easily copy and paste code into it.
https://github.com/dgerber/rfc3987/blob/master/rfc3987.py
link?
&gt; I have no idea what it actually is (something about flowers) http://en.wikipedia.org/wiki/Iris_flower_data_set
We use Gevents as we need to, but thanks for this, I'm actually quite impressed with Node.js speed, I thought it would be much slower.
R
* `python2 -m SimpleHTTPServer [port#]` * `python3 -m http.server [--cgi] [port#]` * http://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler.log_message * https://github.com/bboe/extended_http_server/blob/master/ext_http_server.py * https://github.com/Pylons/waitress * http://docs.pylonsproject.org/projects/waitress/en/latest/
While i personally like writing ruby more (I'm esp fond of using blocks to do functional meta programming) it's just too slow for any serious number crunching. We often use ruby to drive calling python/c/r but I'd def recommend python (and r for prototyping etc)
Just use ipython!
http://personalmba.com/best-business-books/
This is an awesome reference. Bookmarked :) 
[This](https://twitter.com/ellisonbg/status/327636198673747968) should solve your problems. I'm not sure if it's been pushed into master yet.
Now if we could get history from one session to the next!
Also IPython... but yes I agree! The built-in Python repl needs to take a lot of features from IPython.
Alas, not on master yet. I'll be looking forward to that, and will probably be on of the first on it. That would make me actually use the notebook!
Yes. I use this all the time- curl URL | python -m json.tool 
I reformat json in vim by `:%! python -m json.tool` .
Wut
Sorry for the late reply. I'm glad you like it :) Yes, searches using .filter() and .order_by() involve Redis ZSET intersections (except for the initial search/sort, which is a union).
Create virtual environment in Python 3.3: py -m venv my_env
Have a look at the [pypl index](https://sites.google.com/site/pydatalog/pypl/PyPL-PopularitY-of-Programming-Language) = popularity of programming language 
Seriously, anyone tried allocate the socket tx buffer to a shared memory, so whenver a requests comes we just syscall aio_write() ?
There’s Perl. For CSV, it has [`Text::CSV::Auto`](http://search.cpan.org/~bluefeet/Text-CSV-Auto/lib/Text/CSV/Auto.pm), for example. To make API calls, there is [`libwww-perl`](http://search.cpan.org/~gaas/libwww-perl/lib/LWP.pm). However, if you already know any scripting language, it probably has equivalent libraries. You might then reasonably decide to stick with it.
And last I checked, it chokes terribly on unicode :S
I too would say use Python. It has csv support and can handle data in lists out of the standard install. If you want a wealth of other data handling for Science type stuff you can install releases like [this](http://docs.enthought.com/canopy/) which has a lot more.
I always use this one: python2 -m smtpd -n -c DebuggingServer localhost:1025 This creates an smtp server which prints mails to stdout (and doesn't send them), useful for web development
It is much more simple to write a cli with such a tool than with argparse. However I don't know if it brings something comparing to a more widespread lib like argh (https://pypi.python.org/pypi/argh). argh is great, it allows to build a cli quickly and easily, and it is build on top of argparse so if have specific needs you can still use the argparse options.
uWSGI could run standalone, try its --http parameter. multithreading seems not the right choice, everyone is talking about Kernel AIO, libev/libuv/libeio 
Not sure what you're trying to do, but maybe you could use libpcap directly? There are tons of different libraries for that.
In heavy traffic pypcap and python-libpcap are not as robust as Tshark. But like I said: I'm looking for a solution and help is welcomed.
If you have _that_ much traffic, you'll probably be better off with C + libpcap.
Sure. But I don't know C. I can do this manually, but I'd like to automate this. I don't understand why there is a difference between "ctrl-c" issued manuallny and "terminate()" issued from the script. And how to solve it. "Learn C" is not quite the answer I was expecting on /r/Python. :)
Basically, `Ctrl-C` lets the program know the user wants to stop it, and `terminate()` just kills it. I found this horrible hack, try it: import ctypes ctypes.windll.kernel32.GenerateConsoleCtrlEvent(0, proc.pid)
Found this on StackOverflow and it does not work. If you like you can experiment on simple program: import subprocess import time import ctypes proc = subprocess.Popen("ping -t google.com", stdin=subprocess.PIPE) time.sleep(5) # just so it runs for a while # now: let us try some things # none of those work print "Writing ctrl c" proc.stdin.write(chr(3)) proc.stdin.write("\n") proc.stdin.flush() print "trying ctypes" ctypes.windll.kernel32.GenerateConsoleCtrlEvent(0, proc.pid) # this works proc.terminate() I know I'm missing something. But I'm too big of a newbie to see what exactly I'm missing here...
[google](http://www.google.com) 
http://pastebin.com/L306YEAk ;)
On the subject, I've been using for a couple of years a rather nice tool for acceptance testing: [Robot Framework](https://code.google.com/p/robotframework/). One aspect I think is brilliant is that it abstracts away the actual programming language that runs the tests. It comes up with a rather simple DSL that doesn't scare away non-developers. It worked really well at my company. I recommend it for functional and integration testing.
Technically, its been in the python interpreter even longer, it just wasn't active by default (though IIRC on windows you needed to install pyreadline seperately). 
When would this land in the standard python distribution?
I'm not sure how it is on the Python side of things, but on the rails end a couple years back(again, maybe that's changed), not really. The problem was that Rails was single threaded so if you were using something like mongrel, you had to spin 10 of them up(each on their own port) to handle 10 requests at once. But since your proxy software(apache/nginx) can't inspect those processes and see which ones were busy it was really hard to send requests to free mongrels. So if you had 5 requests coming in and 10 mongrel back ends, Apache would kick them downstream and any busy mongrels would just accept and que. Basically spinning from Apache via proxy downstream can be a PITA to work with on high usage apps, if your back end hosting app doesn't thread well. Apache can't detect remote app blocks very well. With Phusion you still have threads that spin up for the app, but Apache understands which is busy and spins out requests to free threads. Also you can have Apache spin up(or spin down) app threads as needed. It's also pretty easy to monitor how many threads are working at any given time via the command line. So monitoring the app and graphing usage trends is a lot easier. Now I can't speak for high volume Python apps and Rails hosting may have changed a lot in the last couple years, but moving from mongrel to Phusion was a motherfucking God send back in the day. I'd still proxy from Apache on the front end, but I'd proxy back to app servers running Apache/Phusion/app and let Apache manage the app threads. Because Apache is really good at that. 
You can use a reverse proxy module, but it's not as simple as using Phusion Passenger. With Phusion Passenger, you: 1. Create a virtual host. 2. Point your document root to the app's "public" directory and set "passenger_enabled on". 3. There is no step 3. If you want to deploy multiple apps, you simply add more virtual hosts like that. Processes are automatically managed for you. With reverse proxy solutions you have to run at least 1 app server process per app, keep them running with things like daemontools/runit/monit, remember what port runs on what app, and configure virtual host and reverse proxies. With Phusion Passenger, all of that becomes unnecessary. Phusion Passenger also dynamically adjusts the number of worker processes based on traffic. If your site is busy, it'll spin up more workers to handle the load. If it's not as busy it shuts down processes to conserve memory. As Tobias from Shopify once stated, Phusion Passenger is all about reducing the number of moving parts.
Historically Perl would've been great for this, but the language is sort of on its last legs. I know this is a Python subreddit, so everyone is going to say "of course, Python", but Python really is a nice general purpose language. The reason I'd recommend Python for your use is it has good financial/scientific support, the database support is solid, and as your needs expand Python will grow into where you want to go with that. If you decide you want to present the data via web, there are a few frameworks that'll handle that for you. On the flip side if you decide you want to create a desktop interface for your data mining, Python also supports some really solid desktop toolkits(Qt is fantastic). So basically Python has a wide range of APIs and will be easy for you to use today, and as your needs grow into directions you're not aware of yet Python should still handle what you want to do. It's an easy to learn language and very flexible. 
On Unix, the terminate() functions sends SIGINT, which allows the process to clean up after itself before exiting, while the kill() method sends SIGKILL which ends it immediately. However on Windows both methods call the Windows API function `TerminateProcess` which straight up kills the process and does not allow cleanup, so tshark never gets a chance to write its files. See [here](http://docs.python.org/2/library/subprocess.html#subprocess.Popen.terminate) and [here](http://blogs.msdn.com/b/oldnewthing/archive/2004/07/22/191123.aspx). I'm not much of a Windows expert, but have you tried `os.kill(process.pid, signal.CTRL_C_EVENT)`? EDIT: Looking at the [documentation](http://docs.python.org/2/library/subprocess.html#subprocess.Popen.send_signal) for subprocess, it also looks like you need to create the process with the `CREATE_NEW_PROCESS_GROUP` flag to allow you to send signals to it. As an alternative to os.kill, there is also the slightly cleaner `tshark.send_signal(signal.CTRL_C_EVENT)`.
A built in support for generating interactive CLIs would be appreciated.
My IPython version is at 0.13.2 (`conda update ipython` gives me that version). When I open a notebook, and enter `raw_input("This: ")` or `%debug`, it gives me an error. When I enter either of those lines, it gives me `StdinNotImplementedError: raw_input was called, but this frontend does not support stdin.`
http://msdn.microsoft.com/en-us/library/windows/desktop/ms684863(v=vs.85).aspx Call me stupid, but: "If this flag is specified, CTRL+C signals will be disabled for all processes within the new process group." ...doesn't this mean that this is the wrong flag to set? 
I see. Since I've mostly used multithreaded webapps behind nginx, I've never come across the issue you mention here. I can see why it was helpful indeed :)
Like, I said, I'm by no means an expert. At the beginning of the description though: &gt; The new process is the root process of a new process group. The process group includes all processes that are descendants of this root process. I believe that means the root process itself is *not* part of the group, only its descendants are, so the signal is not disabled for it. Additionally, In the subprocess documentation I linked earlier, it states: &gt; Note: On Windows, SIGTERM is an alias for terminate(). CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to processes started with a creationflags parameter which includes CREATE_NEW_PROCESS_GROUP. I don't know why, exactly, this would be the case, but my guess is it has something to do with this bit mentioned in the documentation for [os.kill](http://docs.python.org/2/library/os.html#os.kill) &gt; Windows: The signal.CTRL_C_EVENT and signal.CTRL_BREAK_EVENT signals are special signals which can only be sent to console processes which share a common console window, e.g., some subprocesses. EDIT: as an aside, this ctrl+c windows issue has some of the most widely dispersed documentation I've ever come across, jeez. Very difficult to get the full picture.
I agree the docs are quite confusing on this issue. &gt; MSDN states that CREATE_NEW_PROCESS_GROUP disables "ctrlc+c". Yes, but only for subproccesses of the tshark process, as I explained above. Not for tshark itself. &gt; Python dosc state clearly that CTRL_C_EVENT can only be used with os.kill(). I believe the intended meaning is that it does not work with the related function os.killpg(), which is Unix-only. But the docs are very unclear on this point. &gt; Maybe it's about sending ctrl_c_event to stdin?? I don't believe this will work since essentially it's just a number, it only becomes meaningful in a signal context. have you tried the CREATE_NEW_PROCESS_GROUP flag in combination with the tshark.send_signal method? If that doesn't work then we've pretty much tried everything.
As of now - I'm doing it like this: import subprocess import time import signal import os proc = subprocess.Popen("ping -t google.com", stdin=subprocess.PIPE, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP) time.sleep(3) # just so it runs for a while print "send sig" proc.send_signal(signal.CTRL_C_EVENT) time.sleep(3) print "os kill" os.kill(proc.pid, signal.CTRL_C_EVENT) time.sleep(3) print "desperate times -&gt; desperate measures" proc.stdin.write("\x03") proc.stdin.write(chr(3)) proc.stdin.write("^c\n") proc.stdin.flush() time.sleep(3) print "die hard" proc.terminate() ...as you probably know, the only part that does anything is *proc.terminate()*. Maybe I'm doing it wrong and I should not use Subprocess? Maybe there is a lib that allows for this sort of automation? I was just trying to automate a simple task and I'm losing 2d20 Sanity Points a minute. ;) Thanks for your help. I learned few things.
This bot needs some enhancement to stop trying to fix links inside code sections.
**[Software Testing](https://en.wikipedia.org/wiki/Software_testing) and [Python](https://en.wikipedia.org/wiki/Python_\(programming_language\))** * http://stackoverflow.com/questions/4904096/whats-the-difference-between-unit-functional-acceptance-and-integration-test * http://stackoverflow.com/questions/520064/what-is-unit-test-integration-test-smoke-test-regression-test * http://docs.python-guide.org/en/latest/writing/tests.html * http://ipython.org/ipython-doc/dev/interactive/tips.html * http://wiki.python.org/moin/PythonTestingToolsTaxonomy Testing Process Development: 1. edit, edit, commit 2. edit, commit 3. todo, edit, commit 4. todo, edit, test, commit 5. todo, test, edit, test, commit 6. todo, test, edit, test, commit, tag 7. todo, branch, test, edit, test, commit, { tag, push, send patch } 8. todo, qnew, test, edit, test, commit, finish, { tag, push, send patch } Testing Techniques: /r/IPython REPL ? %edit? %edit -p %ed -p %logstart? %logstart log_input_to_here.py %logstart -o log_input_and_output_to_here.py %run nosetests !nosetests --help !nosetests --ipdb %doctest_mode? %nose # ipython_nose Testing Science: Learning * http://software-carpentry.org/ * https://github.com/jiffyclub/ipythonblocks * http://nbviewer.ipython.org/urls/raw.github.com/jiffyclub/ipythonblocks/master/demos/ipythonblocks_animation.ipynb * https://en.wikipedia.org/wiki/Statistical_hypothesis_testing * https://en.wikipedia.org/wiki/Null_hypothesis * https://en.wikipedia.org/wiki/Bayesian_inference * https://en.wikipedia.org/wiki/Sensitivity_analysis Testing Software * https://en.wikipedia.org/wiki/Software_testing * https://en.wikipedia.org/wiki/Test-driven_development * https://en.wikipedia.org/wiki/Assertion_(computing) * http://docs.python-guide.org/en/latest/writing/tests/ * https://pypi.python.org/pypi?%3Aaction=search&amp;term=fixture&amp;submit=search * http://martinfowler.com/bliki/TestCoverage.html * http://martinfowler.com/eaaCatalog/ * https://en.wikipedia.org/wiki/Code_coverage#Basic_coverage_criteria * https://en.wikipedia.org/wiki/Template:Software_development_process * https://en.wikipedia.org/wiki/Category:Formal_methods Python Testing * http://docs.python.org/2/library/unittest.html * http://docs.python.org/2/library/doctest.html * http://docs.python-guide.org/en/latest/writing/tests/ * http://wiki.python.org/moin/PythonTestingToolsTaxonomy * https://pypi.python.org/pypi/unittest2 Testing Techniques: Logging * https://en.wikipedia.org/wiki/Computer_data_logging * https://en.wikipedia.org/wiki/Syslog * http://docs.python.org/2/howto/logging.html * http://docs.python.org/3/library/logging.config.html * http://pythonhosted.org/Logbook/features.html Testing Tools: Nose * https://github.com/nose-devs/nose * http://nose.readthedocs.org/en/latest/testing.html * http://nose.readthedocs.org/en/latest/writing_tests.html * https://github.com/taavi/ipython_nose * https://github.com/flavioamieiro/nose-ipdb * https://github.com/wolever/nose-parameterized Testing Tools: py.test * https://bitbucket.org/hpk42/pytest * http://pytest.org/latest/ Testing Tools: GUI * https://github.com/pybee/cricket Testing Tools: Tox * https://bitbucket.org/hpk42/tox * http://tox.readthedocs.org/en/latest/ Testing Techniques: Mocks * https://en.wikipedia.org/wiki/Mock_object * http://mock.readthedocs.org/en/latest/index.html * http://mock.readthedocs.org/en/latest/patch.html * http://docs.python.org/3/library/unittest.mock.html Testing Tools: BDD * https://en.wikipedia.org/wiki/Behavior-driven_development * http://pythonhosted.org/lettuce/ * http://pythonhosted.org/lettuce/tutorial/simple.html * http://heynemann.github.io/pyvows/ Testing Techniques: Continuous Integration and Delivery * https://en.wikipedia.org/wiki/Continuous_integration * https://en.wikipedia.org/wiki/Continuous_delivery * http://docs.python-guide.org/en/latest/scenarios/ci/ Testing Tools: Continuous Integration (CI) * https://en.wikipedia.org/wiki/Comparison_of_continuous_integration_software * https://en.wikipedia.org/wiki/Buildbot * https://en.wikipedia.org/wiki/Jenkins_(software) * https://en.wikipedia.org/wiki/Travis_CI * http://about.travis-ci.org/docs/user/getting-started/ Testing Techniques: Patches, Tags, Branches, Merging * https://en.wikipedia.org/wiki/ACID * https://en.wikipedia.org/wiki/Patch_(computing) * https://en.wikipedia.org/wiki/Branching_(revision_control) * https://en.wikipedia.org/wiki/Merge_(revision_control) * https://en.wikipedia.org/wiki/Revision_control * https://en.wikipedia.org/wiki/Distributed_revision_control * http://savannah.nongnu.org/projects/quilt * http://www.infoq.com/articles/agile-version-control * http://git-scm.com/book/en/Git-Branching-Basic-Branching-and-Merging * http://linux.die.net/man/7/guilt * http://hgbook.red-bean.com/read/advanced-uses-of-mercurial-queues.html * http://mercurial.selenic.com/wiki/Bookmarks Testing Techniques: DVCS: Bisect, Blame * https://en.wikipedia.org/wiki/Code_Bisection * https://www.kernel.org/pub/software/scm/git/docs/git-bisect.html * https://www.kernel.org/pub/software/scm/git/docs/git-blame.html * http://git-scm.com/book/en/Git-Tools-Debugging-with-Git * http://www.selenic.com/mercurial/hg.1.html#bisect * http://www.selenic.com/mercurial/hg.1.html#annotate * http://hgbook.red-bean.com/read/finding-and-fixing-mistakes.html#sec:undo:bisect Debugging * https://en.wikipedia.org/wiki/Debugging * https://en.wikipedia.org/wiki/Breakpoint * https://en.wikipedia.org/wiki/Program_animation * https://en.wikipedia.org/wiki/Tracing_(software) * https://en.wikipedia.org/wiki/Fault_injection * https://en.wikipedia.org/wiki/Probe_effect Debugging: Console, CLI, Terminal, REPL, /r/IPython import pdb; pdb.set_trace() * http://docs.python.org/2/library/pdb.html * https://pypi.python.org/pypi/pudb * https://github.com/gotcha/ipdb * https://github.com/gotcha/vimpdb * https://dev.launchpad.net/UltimateVimPythonSetup (F7 for `set_trace`) * https://github.com/mattboehm/vim-unstack Debugging: Web * http://werkzeug.pocoo.org/ * https://github.com/django-debug-toolbar/django-debug-toolbar * https://flask-debugtoolbar.readthedocs.org/en/latest/ * http://docs.pylonsproject.org/projects/pyramid_debugtoolbar/en/latest/ * http://firelogger.binaryage.com#python Debugging: GUI * http://winpdb.org/docs/ * https://github.com/lmacken/pyrasite-gui * http://wiki.python.org/moin/IntegratedDevelopmentEnvironments#IDEs_with_introspection-based_code_completion_and_integrated_debugger * http://pythonhosted.org/spyder/debugging.html * http://pydev.org/manual_adv_debugger.html * http://www.activestate.com/komodo-ide/features#debugging * http://www.jetbrains.com/pycharm/features/index.html#debugger * https://wingware.com/doc/debug * https://pytools.codeplex.com/ * https://github.com/pybee/bugjar Advanced Debugging * http://docs.python.org/2/library/inspect.html * http://docs.python.org/2/library/dis.html * https://github.com/tmetsch/python-dtrace * https://github.com/lmacken/pyrasite * https://github.com/alonho/pytrace * https://github.com/wyplay/pytracemalloc Instrumentation * https://en.wikipedia.org/wiki/Instrumentation_(computer_programming) * https://en.wikipedia.org/wiki/Profiling_(computer_programming) * https://en.wikipedia.org/wiki/Call_graph * https://github.com/tobami/codespeed/ * https://github.com/pydata/vbench * https://github.com/amcfague/linesman * https://github.com/bdarnell/plop * http://firelogger.binaryage.com#python * http://scikit-learn.org/dev/developers/performance.html Testing Databases: Fixtures * https://en.wikipedia.org/wiki/Test_fixture * http://farmdev.com/projects/fixture/ * https://docs.djangoproject.com/en/dev/topics/testing/overview/#topics-testing-fixtures * https://pypi.python.org/pypi/tablib * https://pypi.python.org/pypi/anyconfig Testing Databases: Schema Migrations * https://en.wikipedia.org/wiki/Schema_migration * https://en.wikipedia.org/wiki/Database_refactoring * https://en.wikipedia.org/wiki/Database_normalization * http://south.readthedocs.org/en/latest/ * https://sqlalchemy-migrate.readthedocs.org/en/latest/ * http://alembic.readthedocs.org/en/latest/ Testing Web Frameworks * https://en.wikipedia.org/wiki/Web_application_framework * https://en.wikipedia.org/wiki/Software_configuration_management * http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/testing.html * https://docs.djangoproject.com/en/dev/topics/settings/ * https://docs.djangoproject.com/en/dev/topics/testing/ * http://flask.readthedocs.org/en/latest/config/ * http://flask.pocoo.org/docs/testing/ * http://developer.plone.org/testing_and_debugging/ * http://bottlepy.org/docs/dev/recipes.html#functional-testing-bottle-applications Testing Web Apps * http://webtest.pythonpaste.org/en/latest/ * http://selenium.googlecode.com/svn/trunk/docs/api/py/index.html * https://wiki.jenkins-ci.org/display/JENKINS/Selenium+Plugin * http://www.seleniumhq.org/projects/ide/ * http://www.reddit.com/r/Python/comments/1qnbq3/webscraping_selenium_vs_conventional_tools/cdeq2t7 
My post is a bit off topic from your main post, but responding to you and what K900_ said: I know "Learn C" is not the answer you wanted, but I just travelled this road last year. Python + libpcap was great to hash out an application, and it ran fine for a few months, but traffic got bumped from 20Mbps to 100Mbps and it simply couldn't keep up. 100% CPU usage all the time, so packets were just dropped from the capture. Python's just not suited to that level of realtime dataflow. There's a lot of wasted cycles going from libpcap to python and back, translating the data structures, copying memory etc. It's not easy either. I had absolutely NO C experience. I grabbed the K&amp;R C book and went through that to start with, branched out from there. To put it into perspective, it took me 1 day to write the Python version of the application, and 3 weeks to write the C version, mostly because I was muddling through it very slowly, new to the toolchain etc. You really get an appreciation for the Python stdlib and extensions. Just doing something as simple as logging output and handling command line arguments is just.......slow. The Python application topped out at 41Mbps of traffic handling capacity, the C version handles just under 600Mbps on the same hardware. Edit: Python application was 91 LOC, plus libraries (pcap, struct, logging, time, collections, etc) C application was 549 LOC, plus a few libraries (pcap, socket, string). Most of the time was spent learning and building data structures that were all trivialized in python by using a dict. One line in python to format a MAC address turns into 18 lines of C.
Sorry I could not help you fix this issue :( it would seem like sending a simple keystroke/signal to a process isn't a difficult thing to achieve, but I guess we did learn that windows isn't very friendly to CLI automation with Python (actually, I believe it isn't very friendly to CLI automation at all, but that is a different matter). The last desperate act I can think of is to try CTRL_BREAK_EVENT instead, but I have little hope that would work. I'll be playing around with this script a little more tonight when I get home, I'm a very stubborn man ;) Perhaps some workarounds could be tried? I believe you can tell tshark to stop capturing after a certain time, for example.. if you make the time sufficiently large to capture the stuff you want, then use tshark.wait() or communicate() to wait for tshark to exit by itself, perhaps something like that could be made to work?
http://pyvideo.org/video/699/testing-and-django
http://carljm.github.io/django-testing-slides/
I was thinking about something like that - tell it to work for fixed amount of time. Even if it will work longer than necessary it won't break anything - If the traffic generated will stop, there will be nothing to capture. I'll poke around the subject. If I find any working solution that will not wake Great Cthulhu from eternal slumber I'll post it in this thread.
I use Robot Framework too. It's great. edit: I use it along with paramiko, pyserial, robotframework-sshlibrary, web power switches (with the dlipower python module), requests, and some other cool stuff to test networked consumer electronics.
If you have any questions regarding Phusion Passenger please feel free to ask. We're here to help. :)
You forgot to include search terms
Yes, the [gatling](http://www.fefe.de/gatling/) server is neat. 
I'm pretty sure it's a robot of some kind. Not mean spirited or troll - just a bot that found "ping -t google.com" in my post and tried to "fix the url". At least I hope it's not a wiseass troll...
[google](http://www.google.com) 
I might try that in the future. As of now - a simple task of Tshark automation is probably going to be done by AutoIt. Python and Windows does not like each other apparently.
Or he is mocking us. "Use google".
As a punishment, you nasty bot, you are going to write a nice success story "How I wrote a RedditBot in Python"!
I have some for dealing with QTypes (QString, QVariant, etc.) and some for some crazy metaprogramming with automatic `repr` and `__init__` and `update` methods. [QVariantAlchemy](https://gist.github.com/harvimt/4699169) [metaalchemy](https://gist.github.com/harvimt/5526304) - should maybe be updated to use `.format` instead of `%`
The server back end is written in stackless python but I don't think the game client is.
It depends on how fast you need results. For fun I used python to do some processing on an english wikipedia dump. Processing around a 40 gig file took under 10 minutes. That being said the machine in question had an SSD, an i7 and about 16 gigs of ram. Your performance will vary. 
If you're doing a lot of regular expressions you might find you like perl having built-in regex support. If speed wins over all else, then I think Fortran is still the reigning champion in that department. Not sure it's worth the trade-offs in terms of learning curve though.
It can suffer in environments with inexperienced or undisciplined coders. Between its "It's easier to ask for forgiveness than permission" attitude and its relatively permissive rules (in terms of scope and typing) it's easy to find a component that you think you understand, get it wrong, and then discover it a week later when everything explodes. Anywhere it isn't supported natively (mobile platforms, browsers, embedded systems) you might have some problems. Folks do lots of good work getting python to run in those places, but it is extra hassle. Though it *can* do shell scripting, I prefer ruby or zsh for writing command line tools. That's probably a taste issue.
I would say that Python is a good choice for everything except GUI applications and games. GUI applications and games can be done in Python, but in this case there are better choices.
yeah, I would think that the 3D rendering is done with C++, any links on the game client?
Device drivers. Other than that, if the results are fast enough for you, be happy and move on.
Already have ipython. This does nothing for me. Bfd 
I agree, I'd definitely still use Delphi or Visual Studio or a Java based solution for GUI applications. Not that you can't develop a GUI application in Python+some window manager but the reality is that there are currently better solutions out there in other languages. 
I also use Robot Framework. I use it integrated with Selenium for web testing. Very impressed how easy it is to instrument.
Seriously. Does 4 lines of actual code merit a post here?
Do you have a source for that? I've always heard that Eve uses Stackless Python but was never able to find good, specific information on how/where they use it. I assumed it was 100% server-side, but I know that Disney makes some kids MMO games using Python and Panda3D for the client so I wasn't sure.
I think he meant Graphics related tasks.
I know quite a few applications that use Qt &amp; Python. Qt in python is pretty mature and fast.
Safety or mission critical systems.
If you want to build guis with Qt, and don't want to use C++, Python is your only option. I'd say that's a pretty good choice.
I see, as I said before: I wasn't sure. I'll still leave it there since some people seem to like it and it could be a valuable explanation to some lisp-fearing programmers.
By chance do you happen to have a link to multithreading guide for a newbie in Python?
use ttk, and on systems where the default theme is terrible (e.g. linux) force a different theme. it's very pretty.
Thanks for the critique.
Science. It's a competitor to MATLAB® (the default standard) these days, especially with IPython.
I was really lazy and used no concurrency at all. Generally though with Python you don't use threads due to the global interpreter lock (GIL). You're supposed to use multiprocessing if you want any level of parallelism. 
I know it's kinda taboo to post something like this but *shrug* people are always looking for interesting open source projects. Figured I'd throw something out there that is not only useful but relatively easy.
From the [wikipedia article](http://en.wikipedia.org/wiki/Eve_Online): &gt; Both the server and the client software for Eve Online are developed in Stackless Python, a variant of the Python programming language. Stackless Python allows a relatively large number of players to perform tasks without the overhead of using the call stack used in the standard Python distribution. This frees the game developers from performing some routine work and allows them to apply changes to the game universe without resetting the server.[70] However, the Eve cluster is taken offline daily for database and server maintenance.[71] I remember reading a detailed article on its development, but don't remember where and can't find it on google. Sorry. 
This works: import subprocess import time import win32api import win32con proc = subprocess.Popen("ping -t localhost", stdin=subprocess.PIPE) time.sleep(3) # just so it runs for a while print "sending ctrl c" try: win32api.GenerateConsoleCtrlEvent(win32con.CTRL_C_EVENT, 0) proc.wait() except KeyboardInterrupt: print "ignoring ctrl c" print "still running" It sends ctrl-c to all processes that share the console of the calling process but then ignores it in the python process with an exception handler. You can't target the subprocess directly because [that signal cannot be generated for process groups](http://msdn.microsoft.com/en-us/library/ms683155%28VS.85%29.aspx). **ctypes version** import subprocess import time import ctypes proc = subprocess.Popen("ping -t localhost", stdin=subprocess.PIPE) time.sleep(3) # just so it runs for a while try: ctypes.windll.kernel32.GenerateConsoleCtrlEvent(0, 0) proc.wait() except KeyboardInterrupt: print "ignoring ctrlc" print "still running" **ctrl-break version** This can target the process specifically but with ping ctrl-break doesn't actually cause it to terminate. You may be able to use it with tshark though. import subprocess import time import ctypes proc = subprocess.Popen("ping -t localhost", stdin=subprocess.PIPE, creationflags=512) # CREATE_NEW_PROCESS_GROUP = 512 time.sleep(3) # just so it runs for a while ctypes.windll.kernel32.GenerateConsoleCtrlEvent(1, proc.pid) # CTRL_BREAK_EVENT = 1 proc.wait()
Python is a good language to implement prototypes, however when it is necessary to descend to the level of abstraction to get a little closer to HW is where it shows its limitations.
"not": such a small word, but yet so important ;)
Speed. It's not very fast. It's especially bad at iterating. You can however wrap Fortran or C into it nicely.
The hugely popular "calibre" ebook manager/converter/server comes to mind.
No, please don't use Delphi nowadays. Even most of the people using Delphi don't want to be using Delphi and the price is ridiculously high and the quality ridiculously low. The new cross-platform framework is two versions old and still has huge bugs and was rushed into production to the point where version 1.0 had nothing but stub code for OS X printing! Python and Qt give you inherent cross-platform ability (no Linux support in Delphi) and a much more stable product. 
I heard there's a microcontroller that has python (but not the standard library?) embedded in it now.
shameless plug?
Full on three dimensional MHD simulations. IMO just 3d interpretation of data. 
https://github.com/lucuma/orm
I personally like Python for command line tools, it's very easy and familiar to me. I wrote a class which makes command line arguments a lot easier to handle for myself, which certainly helps.
no, why? (s)he just stated that it’s popular, and uses PyQt. it works well, but i think it’s ugly. Frescobaldi, though admittedly much more niche, looks and feels much nicer.
I completely agree. I love listening to his lectures on youtube. Plus PLY is a lot of fun to mess around with.
Pandas is a great way to go, as is NumPy (Pandas is built on top of NumPy).
For the record, whoever decided that should be called PyQt instead of QtPy should be slapped with a Minuteman II.
http://software-carpentry.org/
When using python GUI toolkits, I rarely concern myself with "pretty"
The standard documentation for the threading module is pretty good. Read all of it, though. It's easy to think you understand it when you don't.
It also depends a lot on what sort of processing you're doing. If it's largely numerical work, numpy and the ecosystem built on top of it make Python a strong contender.
This is sort of correct. Because of the GIL only one thread can execute python code at a time. Use python's threading to speed up io bound processes. If your application is CPU bound, then use multiprocessing. There are more caveats and intricacies but I'm on my phone.
It's already been filed by someone else.
Because type theory.
Thanks for putting all this together! 
Happy Nurses Week!
Agree. There I'd *force* my team to use Haskell (w/ Quickcheck and stuff). They shall rather fight against sadistic compiler than forgetting about *one little detail* that would destroy something (or even killing somebody). But this is a very limited use case, not to be met by ordinary man.
IMHO best way is to write in python, fix all issues, profile, try to optimize algorithmically, test again, fix even more issues and then rewrite to C/C++/Java. Using C/C++/Java to experiment with algorithms is time consuming. Rewriting Python -&gt; C/C++/Java is easier.
Calling it 'easy' is never really a smart thing to do.
I in fact did not, but it looks like a handy module. Maybe I'll use argparse in my next project, but I don't think the exercise was a bad thing. 
I agree with /u/kgadek that Haskell's type system is amazing, and it's why I have begun to prefer Haskell over Python even, but I don't see how it'd be any more likely to have a bug in your code with Haskell than with Python. If the algorithm is wrong, it doesn't matter if the types are correct. I've written plenty of incorrect algorithms in both languages. While Haskell definitely handles a lot of bugs that would normally be discovered at run time, a divide by zero error will still cause a crash. If it's a safety or mission critical system it should have very rigorous and comprehensive testing, regardless of the language. And if it's that big of an issue then there should be fail-safe mechanisms built into the code all over the place, because you can't realistically write code to handle every single exception that could be thrown. Architecture has a much larger impact on the reliability of software than the language used.
http://pymotw.com/2/mmap/
I think you're missing the pont *entirely* you should repeat the benchmark with requests involving I/O which is when the async model really shines.
nothing. Python is perfect. Joking aside, handling large number of socket connections on a single daemon is pretty hard to do.
or you can profile and write the sensitive parts in some sort of cython
I would add Cython to your workflow. If using Cython STILL doesn't address your performance issues then you should think of a rewrite.
typed programming
There's a few cython-ish wrappers around openCL that would work well there.
 Prelude&gt; 1 / 0 Infinity ;)
If you want to do asynchronous IO, look up stuff like stackless, gevent and pypy.
&gt;unsafePerformIO Pretend it doesn't exist, it's a GHC-ism anyway. &gt;partial functions Aren't a problem with type-checking, are they? &gt;For something critical I'd want strong guarantees and would use Agda or Coq, instead. I agree, if we're going this far we may as well go all the way to dependently typed programs-are-proofs land.
*Only option*? Hahaha what? Plenty of languages have nice bindings to Qt. 
I do a lot of analysis of data in text files (bio data in tsvs or dna sequence data) and python is a usually a great choice. It has low overhead on startup and is fast at IO which is most often what will slow you down so it can even beat a language like java in lots of cases. The string manipulations functions are easy to remember and comprehensible to people who need to maintain your code. If the math starts to be the limiting factor you can vectorize with numpy. It stops being a great choice when your analysis involves something like a recursive function or nested for loops that can't be offloaded to numpy. Even then there are projects to speed up python in these cases (numba, cython, pypy) or you can write a module that calls C code for the hot spot. (I usually end up using go instead if I need the speed of a compiled language). I suggest that you do read the google python style guide as it has some good hints at writing maintainable production code instead of one off scripts: http://google-styleguide.googlecode.com/svn/trunk/pyguide.html 
I highly recommend you also check out [docopt](http://docopt.org).
And if they're decent programmers, they should be able to pick up another programming language.
Why not [SparkAda](http://en.wikipedia.org/wiki/SPARK_(programming_language\))
I did an interesting experiment with numpy recently. I took a 10,000 element array and calculated the cross correlation. It took several minutes to compute. However, I did the same calculation with MATLAB and it took about 2 seconds. Numpy really isn't all that fast. Faster than many other libraries, certainly, but there are many other choices if speed is your concern. Edit: The array was actually a million and took 34 minutes for numpy and .4 seconds for MATLAB R2012a. import numpy from datetime import datetime x = numpy.array([1]*1000000) y = numpy.array([4]*1000000) start = datetime.now() numpy.correlate(x,y,mode='full') end = datetime.now() print end - start 0:34:50.589205 x = ones(1000000,1); y = 4*ones(1000000,1); tic;xcorr(x,y);toc; Elapsed time is 0.462668 seconds. Doing FFT instead of cross correlation gives .149899 seconds on python and 0.070043 on MATLAB. Also, I think it is funny that I get downvotes for pointing out that Python is not the fastest language in the world and shfo23 gets 23 upvotes for comparing one python library to another. Something that I had already stated. This is why I don't go on specialty subreddits.
I don't think programmers are programmers. What you want for safety critical systems are safety critical systems programmers. And they might know Ada.
For mission critical systems you want a high quality, small team and for them to choose an appropriate language for the problem, which could well be Python.
* http://en.wikipedia.org/wiki/Rust_(programming_language) * http://static.rust-lang.org/doc/rust.html * https://github.com/crabtw/rust-bindgen
Client side web programming.
I think Sublime Text was built in Python. What would have been a better choice?
* http://en.wikipedia.org/wiki/Category:Real-time_computing * http://en.wikipedia.org/wiki/C_(programming_language) * http://en.wikipedia.org/wiki/Ada_(programming_language) * http://wiki.python.org/moin/EmbeddedPython * http://en.wikipedia.org/wiki/Stackless_Python * http://en.wikipedia.org/wiki/Cython
Sublime Texts plugin interface is the only part that is Python AFAIK. The GUI is written in C++.
* http://en.wikipedia.org/wiki/MATLAB * http://en.wikipedia.org/wiki/GNU_Octave * http://en.wikipedia.org/wiki/Julia_(programming_language) * http://docs.julialang.org/en/release-0.1/ * http://sagemath.org/help.html#SageStandardDoc * http://scipy-lectures.github.io * /r/IPython notebook
This library is like crack. 
That's not really as good a benchmark of `numpy`'s speed as it is of the specific algorithm you were testing. With the same array, I can get results 7700x faster if I use the `numpy` implementation of `correlate` instead of the `scipy` one: [1]: import scipy.signal, numpy [2]: a = numpy.random.randint(100, size=1000) [3]: %timeit numpy.correlate(a, a) 100000 loops, best of 3: 4.96 us per loop [4]: %timeit scipy.signal.correlate(a, a) 10 loops, best of 3: 38.5 ms per loop I wonder which one Matlab uses?
Please elaborate if you get the chance, also links are bitchin &lt;3
I use this for all my controls homework. The documentation could use a little work, and some functions are missing, but overall it's very useful. Combine it with Sympy and you have a nice controls workflow.
[PyPy](http://pypy.org/performance.html) is also a contender http://speed.pypy.org/
It does have some bugs in the state space method though...
By "partial functions" you're probably thinking of functions like '+' which take a value and return another function. I think what the previous commenter meant was functions like `head` which take a value and *might* return a value, or *might* throw an error. Better to use `safeHead :: [a] -&gt; Maybe a` and such.
FWIW that's now a compiler error in Go 1.1 
[here's something useful](http://www.slideshare.net/pvergain/multiprocessing-with-python-presentation). i used the multiprocessing module in combination with some cython for one of my model fitting procedures. turned a multiday job into a multihour job. 
Writing a Perl program.. No wait... Import Perl. Shit ;) ( bad humor?)
Ahh, so non-total functions, got it. 
Thanks. That started a bit awkward but got good.
I give you embedded. I'm not sure how any of these would avoid memory allocation/deallocation in a tight realtime section though; my gut feeling says that it's almost impossible to implement the garbage-collecting semantics of Python (whether implemented as sweeping GC or refcounting doesn't really change a lot here) in a way that also allows the programmer full control over allocations. Unless you extend the language to include syntax to indicate "in this block here, I do not want any memory allocation/deallocation to happen".
* http://en.wikipedia.org/wiki/Rust_(programming_language) * http://static.rust-lang.org/doc/tutorial.html#destructors * http://en.wikipedia.org/wiki/Software_transactional_memory * http://doc.pypy.org/en/latest/project-ideas.html#stm-software-transactional-memory * http://en.wikipedia.org/wiki/NX_bit
Also, if you are using numpy/scipy ecosystem of tools to do the processing, many of them support actual parallelism because they don't interact with the GIL during computation. NumExpr, Numba, and Theano, and others.
I found GUI development lacking.
Your collection of links does nothing to further whatever point you think you're trying to make.
http://en.wikipedia.org/wiki/Chunking
You make the common mistake of thinking that coders are all interchangeable and that you should adapt your problems or expectations to make it so. So you choose a common language, you get coders who are cheap and you go on your merry way. You remind them that they're replaceable cogs and that you can find any other C++ programmer to fill their place. Eventually, they go on to the next job which pays better, and you are left with a pile of code that is overly complicated to make up for language pitfalls and has no guarantees that an appropriate language would have. Or you can hire great programmers and train them (gasp!) to better perform their task. IBM/Rational has tracked this type of team development and shown that time and time again, investing in your employees yields a better product and long term cost savings.
COBOLing…
Why would I choose to use this over something like pyodbc?
Such as?
You're reading too much into what I'm saying. All I'm saying is "It's hard to hire Coq or Haskell programmers". Not impossible.
Here's what you wrote: &gt; In the real world, you actually need to hire programmers. Those programmers know C, and C++. That's pretty cut and dry against your current claim.
To the first point: use Safe Haskell, it's what it's there for. To the initial point that you'd use Haskell: Maybe, but for real-time and critical systems it'd be for proving and/or generating the real application's C code for compilation with e.g. a mechanically verified version of GCC. And if you are proving, then Agda might be better suited to the task, since, among other things, it has dependent types. 
First of all, NumPy can be built with several choices for the numerical libraries it uses, i.e. GotoBLAS, ATLAS, MKL etc., so simply stating "Hurr,Durr, MATLAB is faster" doesn't make any sense. Second, given my own experience [and the results of others](http://dpinte.wordpress.com/2010/03/16/numpymkl-vs-matlab-performance/) the exact opposite is true - I get much better performance in my daily work using NumPy, and I get to compare both all the time since I'm in research and we do cooperate with engineers a lot. Now I know the "benchmark" on that site also sucks...at least do a couple of runs, give percentiles etc., and my experience is nothing but anecdotal, but meh. What I'm saying is, provide an example of that autocorrelation code you used and let us do our own measurements.
It's a generalization. In the next sentence I say rarely. Relax
CCP developers do a lot with the community to keep everyone informed of changes, and a few of their devblog posts reference pythons usage. The big ones that I can remember go over * [The network code](http://community.eveonline.com/news/dev-blogs/2332) * [Using stackless 2.7](http://community.eveonline.com/news/dev-blogs/stackless-python-2.7/) * [and 2.5](http://community.eveonline.com/news/dev-blogs/stackless-python-2.5/) 
Do not take it wrong but it looks like Frontpage funny artwork from early nineties. Take a look at web friendly colours because here they just dont match. Of course it is my opinion only. 
I totally agree ^^
I find cross platform work to be a bit simpler with java, especially when I am working on servers I do not have access to install programs on. This was readily apparent when I was working with some image processing. Python + PyQt + numpy was a lot to ask somebody else to install, where java it was a bit easier. java + imagej + jama I could easily deploy this to other places.
Aye. The anycoder is for the anyjob.
That's interesting how scipy's correlation is so much slower. To be fair you need to make numpy.correlate perform the full autocorrelation by passing 'full'. I guess scipy's version can handle n dimensional arrays but it doesn't efficiently handle 1 dimensional ones. Wonder why that is?
No you don't. You should be using `pyuic` to generate Python UI classes from those ui files. This is the way it's done in C++ and makes way more sense than reading+parsing the ui files in at runtime.
The layout doesn't strike me as extra ordinary but you can work with it. The color choices OTOH not so much; you got to change it. Look for inspiration in places like kuler or colorlovers etc.. Don't take me wrong, but color choices are not your strong suit and until you can find a good mix, do get recommendations from those websites. Good luck with you project man :)
But but but... the native REPL.
Data mining =&gt; Python. That's all you need to know. People are working on data processing stuff for ruby and js, but nothing nearly as mature as the Python scientific stack. I unconditionally recommend using numpy+scipy+pandas, use requests.py if you need to pull stuff from an API. Reading a CSV file with pandas: pandas.read_csv(filename). That will get you a table with named columns and indexes and fast array manipulations, and you can read hundreds of thousands of rows in seconds. And the best part is once you learned python you can do much more than data mining, you can build desktop GUIs, website, system scripts, and more, which cannot be said for dedicated data analysis environments like matlab.
you should try the Pandas library for your numerical results
Tests? Python 3 support? SSL (presumably via nginx reverse proxy)?
Alas, I don't think Haskell is useful for the majority of safety critical systems, which are usually hard real-time and embedded. While Haskell is great in terms of getting your output correct, I don't think it helps you prove that you'll get it in a certain amount of time and without running out of memory (something which is easier in C but not really built into the language). Maybe it could be used for code generation and stuff like that though.
[multiprocessing](http://docs.python.org/3.3/library/multiprocessing.html)
Though they've been moving more and more of it into C++ due to performance issues.
Concurrency.
Considering the dynamic nature of python there's not really all that much difference between the two.
Okay, sorry. Best option then. Qt for Java has been discontinued by Qt Software, Qt for Ruby doesnt appear to have been updated since 2011. PyQt and PySide are complete, very stable and actively updated PySide ships with several highend 3d and compositing applications, such as Maya and Nuke
You can use ui files from QtDesigner (not the same as QtCreator), and you can use IDEs like WingIDE, PyCharm or Eclipse/PyDev
In addition to what other people already wrote, ordered by what I consider important: * Embedding -- it can be embedded (and I have done so, mainly using ss-python), but its a bit of a pain in the ass compared to languages that are made primarily with embeddability in mind, such as lua * The type of CPU intensive work where threading is used. We all know about the GIL and how to circumvent it, but there are certain classes of problems where processes are no viable alternatives to lightning-fast inter-thread-communication. * Python (and other VM-based dynamically typed languages) cannot run meaningfully on GPGPUs. * Python (and other VM-based dynamically typed languages) will not run well on certain CPUs, even though they are powerful enough to run it. Older ARM CPUs are an example here. The small cache sizes penalize dynamic languages that come with a bigger runtime environment heavily. This is just an implementation characteristic, though, and it would probably be possible to create a python implementation that is more friendly in this regard, similar to what google has tried to achieve with dalvik. * The type of problems where size is a problem. Python cannot be compiled to a small binary that can run on a microcontroller with 1024 bytes or similar of flash storage. In these cases, a compiled language such as C or C++ is really the only option, next to a super-small BASIC interpreter or somesuch. * Other weird CPU architectures: if your CPU is 27-bit based with 9 bits to a byte and has no IEEE compliant FPU, python will probably not be happy (although I admittedly have never tried this -- while these kind of chipsets exist, they are extremely rare)
An SSD may help, but it also may not be the bottleneck if you're using inefficient data structures or algorithms for your problem.
The GIL stops the same python process from executing two *Python* statements at the same time (because in theory, they might do crazy things like redefine len(), and the results have to stay consistent). The GIL is not a problem if: * Your program is slow because it is waiting for IO (network, disk reads). The GIL is released when a thread stops and waits for IO, and other Python threads can run. * Your program does heavy computation with a C library that releases GIL, for example numpy. While the library code is executing "outside of Python", other Python threads can run. GIL is only an issue if you do heavy data computation in pure Python code. In this case, the easiest solution is to fire up N Python interpreters in different processes, where N is usually the number of CPUs on your machine.
Looks a nice library but please don't use lazy imports ( "from something import *" ), even in examples. Your aircraft example imports from three libraries so how am I to know which library which function comes from? Better to use brief aliases e.g. import control.matlab as ctl Or list the functions you're using explicitly (remember explicit is better than implicit) i.e. from control.matlab import ss, step, tf As it is, I'm not sure which library things like 'diag' come from. 
&gt; Python (and other VM-based dynamically typed languages) cannot run meaningfully on GPGPUs. http://docs.continuum.io/numbapro/#getting-started
Pretty sure it's an example of a snippet.
http://pypy.org/features.html
What part of GUI development did you find lacking?
A few of the Python game libraries listed at http://wiki.python.org/moin/PythonGameLibraries support http://en.m.wikipedia.org/wiki/OpenGL , but really, http://en.wikipedia.org/wiki/Javascript http://en.wikipedia.org/wiki/HTML5 engines like https://github.com/turbulenz/turbulenz_engine have more support for http://en.wikipedia.org/wiki/WebGL
Gimme a break, this is basically the first public release of something that's taken *hours* of development time :-) It's a "Works For Me" release. You know, Open Source? Release Early, Release Often? :-) Tests could be added, yeah. I felt a little bad about that ;-) Py3k isn't an option inside my company, so no impetus for that yet :-( For the SSL side - you want it to be able to *serve* SSL? Why? The point of this thing is it sits inside your trusted network... But hey, if SSL serving floats your boat, put it behind something that can serve SSL like nginx, as you say :-)
No, but it's a good sign that if speed is your concern, you should consider alternatives. Numpy is not the fastest in the world.
 import numpy from datetime import datetime x = numpy.array([1]*1000000) y = numpy.array([4]*1000000) start = datetime.now() numpy.correlate(x,y,mode='full') end = datetime.now() print end - start 0:34:50.589205 x = ones(1000000,1); y = 4*ones(1000000,1); tic;xcorr(x,y);toc; Elapsed time is 0.462668 seconds. Hurr,Durr, MATLAB is faster
Why these were so heavily downvoted is beyond me. Would this prevent http://cwe.mitre.org/data/definitions/416.html -like errors?
I knew Go was a stickler of a language, what with its errors for unused variables and what not. But having Go compiler errors for asking Haskell to divide by zero is a whole other level.
Get some automated tests and I can have a crack on porting it to python 3
http://en.wikipedia.org/wiki/Python_(programming_language) has features of a http://en.wikipedia.org/wiki/Multi-paradigm_programming_language : &gt; Python supports multiple programming paradigms, including object-oriented, imperative and functional programming styles. It features a dynamic type system and automatic memory management and has a large and comprehensive standard library. From http://en.wikipedia.org/wiki/Python_(programming_language)#Features_and_philosophy : &gt; Python is a multi-paradigm programming language: object-oriented programming and structured programming are fully supported, and there are a number of language features which support functional programming and aspect-oriented programming (including by metaprogramming and by magic methods). Many other paradigms are supported using extensions, including design by contract and logic programming. &gt; Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. An important feature of Python is dynamic name resolution (late binding), which binds method and variable names during program execution. &gt; &gt; The design of Python offers only limited support for functional programming in the Lisp tradition. The language has map(), reduce() and filter() functions, comprehensions for lists, dictionaries, and sets, as well as generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML. http://en.wikipedia.org/wiki/Reference_counting#Advantages_and_disadvantages http://en.wikipedia.org/wiki/Late_binding#Late_binding_in_dynamically-typed_languages http://en.wikipedia.org/wiki/Global_Interpreter_Lock#Benefits_and_drawbacks
* https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt * http://scikit-learn.org/dev/developers/performance.html
That may well be, besides of course JavaScript which is natively supported with QtQuick or whatever. &gt;PySide ships with several highend 3d and compositing applications, such as Maya and Nuke Oh, sweet, didn't know that.
http://scipy-lectures.github.io
I'm assuming some people would prefer that you give an explanation or reasoning behind some of the links instead of posting a slew of links and assuming they'll be able to draw the same conclusions as you. Are you posting those links to say that Python is not good for those because it's a real time application or that it doesn't do what that other particular language does so well?
Any chance you looked at Qt(ex/ pyqt4)? I'd be curious to see where you felt it was lacking.
Python has real, real trouble with security because everything can be viewed and redefined. The excellent feature of being able to wander through the definitions of the current run time is wonderful for dynamic programming but terrible for security. It would be impossible to completely hide auditing code or security code. I would not write an accounting system in python. The reporting of data would likely be ok. 
[Here](http://radiofreepython.com/episodes/8/Radio%20Free%20Python%20-%20Episode%208%20-%20Memory%20Pressure.mp3) is a podcast with an interview from one of the EVE guys talking about how they used Python.
You have an integer numpy array and a double matlab array...
The former approach has worked fine for me in the past, at least for smaller projects. However, I can see the advantages of generating Python classes from the UI files.
 import numpy from datetime import datetime x = numpy.array([1.0]*1000000) y = numpy.array([4.0]*1000000) start = datetime.now() numpy.correlate(x,y,mode='full') end = datetime.now() print end - start It's been 10 seconds and it's still running. I'll be sure to update in half an hour when it finishes. Edit: It finished - 0:35:11.061600
YES! This is just great. Only... now I want all of d3 available from python. ALL OF IT
If you're iterating over numbers, and concerned about speed, and not using Numpy, that's a paddling.
Well, maybe I should confess I was kidding when I said that stuff about Agda and Coq, but if we're taking it seriously: What do you mean that partial functions aren't a problem with type-checking? I don't run the absolute latest GHC HEAD, but I seriously doubt they solved the halting problem and I didn't hear about it. :) Haskell is a powerful language and let's you write all sorts of partial functions. Smart compilers like GHC help with some easy causes of undefinedness: they can be asked to attempt to verify that your pattern matching is exhaustive at compile time (the default in GHC is to throw exceptions at runtime, though, I think?, and, of course, if you use guards it's hopeless to check exhaustiveness at compile time) and they can catch a few simple infinite loops. A function like secondPrimeInArithmeticProgression a d = (filter isPrime [a,a+d..]) !! 2 is only defined when a and d are relatively prime and I'd be hugely impressed if GHC warned me about this at compile time.
Actually never used head -- pattern matching is all I needed. Non-exhaustive patterns just [look wrong](http://www.joelonsoftware.com/articles/Wrong.html). Maybe monad is my friend anyway.
[PyJS.org](http://PyJS.org/)
Why it's more likely not to have runtime bugs? That's why: someFunction arg | guard_fun arg = Just (do_something_on arg) | otherwise = Nothing And now the *sadistic compiler* forces you to check for special case. It's as simple as that. Look at my [(slightly generalised) chinese remainder theory](https://gist.github.com/kgadek/5503271). There are no solutions to x=2 (mod 6) and x=1 (mod 10), so my code returns Nothing. No try-catch clauses you forget. No forgetting about checking if result equals -1 (and what if it's a correct solution?!). You just match.
Yeah, if you didn't see my other comment, I misinterpreted "partial function" as meaning "partially applied" and not "non-total", my bad.
That looks awesome. Thanks for posting!
Thank you. 
Thanks for your opinion on this one. I will improve and that is the reason why I came here for help.
And that's how it begins. 
Thanks for the tip. I don't have enough RAM or CPU to run those modules. Sigh.
http://redd.it/1dvakc
you're right, it's not up to the "quality" that is normally expected of this subreddit. /sarcasm 
If you'd read what he said, you'd realize that he was saying that there are other choices that may be faster than numpy for some things. He didn't say "Matlab is faster" and just that. Sorry you only read the first part of his comment before your little tirade.
I don't see any advantage over the existing time api
I can't fathom why you linked me to that post.
Yes, that's what I do. But it's not nearly as nice as having an IDE that understands the code, the UI, and the connections between them.
I like the look of [plac](http://plac.googlecode.com/hg/doc/plac.html#a-realistic-example), which bases arguments on the signature of a main() function.
The linked resource helps with adding metadata to a list of links as http://en.wikipedia.org/wiki/Microdata_(HTML)
Two advantages: 1. While you can accomplish some of Arrow's functionality using datetime, time, dateutil, and / or calendar, you usually wind up with a verbose mess of code using multiple modules to accomplish simple tasks. I don't think it should be that way. 2. There are a number of additional features such as parsing / formatting with non-strftime/strptime syntax, humanization and timespans. What kind of features do you think would add value to the project, or would you consider an advantage over existing apis?
Wait, am I reading this right? az4z3l says that Matlab's correlate is roughly 4500 times faster than numpy's correlate and you're saying that numpy's correlate is 7700 times faster than scipy's correlate. So altogther I should expect Matlab's correlate to be about 34 million times faster than scipy's correlate? Wow.
Your links make it absolutely unclear what it is you're trying to say. I can't even tell from the links alone whether you are agreeing or disagreeing with my comment, and I assume others' perception is similar. It doesn't have to be academic; just make an argument instead of just throwing a bunch of links around.
I don't even understand what you are talking about right now. Sorry.
If you're suggesting that OP has already added any metadata of this kind to his links and I just need to parse it, you're wrong. Otherwise, mabe you should be pointing this to the OP? Anyway, this kind of backend classification should be secondary to front-end classification.
I agree. [EDIT] * http://www.reddit.com/r/Python/comments/1dvc7s/how_to_do_functional_programming_in_python/c9v8792
http://schema.org/docs/gs.html
Hey there. I'm a heavy user of various date &amp; time related modules and packages. What I would like to see for this need is what [Requests](http://docs.python-requests.org/en/latest/) did for HTTP library: making it for human beings. There is less of a gap between what is readily accessible for date &amp; time manipulation and utilities and what human beings would like compared to the gap with HTTP library before but it would still be great to have it. Here is what I currently need for my app in terms of date &amp; time modules/packages: - datetime (from the standard library) - pytz (for timezones, timezones data, timezone support and various other stuff I guess) - babel (for localization based on the Common Locale Data Repository) - python-dateutil (for relativedelta and various other stuff I guess) You wouldn't really need all that stuff in a single package to be useful but be sure to check them out and see what they do. It could inspire you to make a better package. If you could get there (like Requests did), it would be awesome. Keep up the good work! EDIT: I had to created various utilities method which were not part of any those packages (or I did not find them) such as these: [Pastebin](http://pastebin.com/qUGkEKCz) If they would be included in a nice library, that would be even better for me.
Thanks! Requests was the primary inspiration for this module, in fact (Kenneth Reitz did a presentation on "Python for Humans" which references the need for a similarly-built library for date / time handling, see [https://speakerdeck.com/kennethreitz/python-for-humans](https://speakerdeck.com/kennethreitz/python-for-humans)). I am using datetime / python-dateutil currently. Have yet to need pytz (dateutil has a lot of timezone functionality), and this is my first time hearing of babel. This is just version 0.2.0, I imagine that by the time I'm nearing a 1.0 release I'll have iterated pretty heavily on the functionality. Again, thanks for checking it out, and feel free to pass on any suggestions you have. 
(... Thanks OP!) http://www.reddit.com/r/Python/comments/1drv59/getting_started_with_automated_testing/c9tfxgd
I'm added some custom/utilities function I had to create on my own in my original post. It might be interesting to add some of them in your stuff. http://pastebin.com/qUGkEKCz Also, check out on stackoverflow for the datetime related questions. Some of them are like *What, that is not part of the standard packages you can find around?!?*.
Didn't they end up installing spyware a long time ago? Or they were forcing ads on people or something? I remember a lot of controversy that led to Pidgin being the go-to client.
The Python for Humans talk has inspired me as well- I think Kenneth makes some great points about designing around an API to keep things simple for users. I really like that a key feature of Arrow is humanization- that's great. Also, this is by far the most attractive Sphinx doc format I've seen yet. Will definitely be using it for my next set of docs. Keep up the great work!
Thank you! This is the Sphinx theme for you or anyone else interested: http://vimalkumar.in/sphinx-themes/f6/html/index.html. ...this is the first project I've documented w/ Sphinx and after a brief learning curve it has been excellent. Looking forward to adding &amp; surfacing docstrings and having real API docs.
Fantastic, I will most certainly take a look :)
nice! d3 + pandas, what's not to like? Will be keeping an eye on this one.
The theme is licensed under the GPL, your project is not (not that this a bad thing) but isn't this violating the GPL?
What you need to do is learn how to program, for which Python is very well suited. seriously, no one jumps on a bike and win the Tour de France, without first learning to keep their balance, train a lot, take drugs and so on and so forth. There are lot's of tutorials out there and they are not hard to find, though guy that I just recently stumbled upon is great: http://www.youtube.com/watch?v=iGQv7bR6zCQ&amp;list=PLDFB7FFF90EE6F0C1&amp;index=1 Best of luck and best regards.
Thanks a lot for the feedback but I'm not just 'jumping on the bike'. I did take an hour class every week for 10 weeks, but they were terrible. The teacher basically brought in sheets of text for us to type into the computer. But I will check out your link. Cheers!
How does this compare to Delorean? Is there much overlap between the two libraries?
There's definitely some overlap. Both are trying to simplify working with and manipulating datetimes, tzinfos, timestamps, etc. Some key differences, as I see it currently: * Arrow has a more straightforward and simple module-level API for getting Arrow objects in a variety of common input scenarios. * Arrow objects implement datetime methods and can be used in place of them in many cases. * Arrow has nicer timestamp handling (big deal for me in my use @ work) * Arrow allows mutation of datetime values (hours, minutes, etc.) * Arrow has humanization. * Arrow always parses with a format string, so there is no room for ambiguity. Delorean seems to take much more of the dateutil approach of looking for a standard input format. * Delorean currently allows iteration by timeframe, which Arrow does not have yet, but will soon :) * Delorean has a definite focus on more natural language for manipulation, such as delorean.next_tuesday(), this is not something I'm very interested in right now for Arrow. ...apologies for any inaccuracies, and of course some things are matters of opinion. Overall, both seem to have about equal traction on github. This release of Arrow (0.2.0) is obviously quite new, but the original 0.1.x series surfaced a few months before I was aware of Delorean. I think its a great library with a different approach, and I'm glad to see users trying out and supporting both. 
What is the comparison with uWSGI?
better performance and commercial support.
I think this would only be a GPL violation if he had made changes to the theme itself and redistributed it without also licensing the changed version under the GPL. Because this is only documentation, and not actually part of his library, I don't think there's a GPL violation going on here.
Thanks for clarifying. I'll have to research it a bit myself as well, but hopefully there's room for me to use the theme without violating the license.
What's the code and what's the error? It looks like you're using `=` instead of `==`
I haven't tried this, but I believe this solves your problem http://stackoverflow.com/questions/130763/request-uac-elevation-from-within-a-python-script
&gt; take drugs ಠ_ಠ
[Run through this book](http://learnpythonthehardway.org/) (it's freely available on that site). It will teach you very well (it did for me), and many of the exercises are exactly what you're trying to accomplish.
I'll second the recommendation to read through LPTHW - it deals with your specific scenario (text based adventure game) and does it quite well. He even walks you through moving your text based game to a web app. Make sure you check the extra credit assignments too,lots to learn there. 
This is not a like for like comparison, numpy.correlate is not using fft where as xcorr is. Here is an implementation using numpy.fft, I'm not an expert so I haven't tried to make sure it gives the most accurate or fast results, but as you can see it is considerably faster than 34 minutes: from numpy.fft import rfft,irfft def fftcorr(x,y): res_size = x.size+y.size-1 res = rfft(x,res_size) res *= rfft(y,res_size) return irfft(res) ## -- End pasted text -- In [17]: timeit fftcorr(x,y) 1 loops, best of 3: 10.7 s per loop If you want to know more you should look at the feature request to add fft to the numpy.correlate http://projects.scipy.org/numpy/ticket/1260 It would seem that the matlab function "corr" uses the naive approach and performs as poorly as numpy.correlate. I had to do some research to find out why matlab was so much faster in your example "benchmark" and I learnt a great deal.
Without having really delved into the details of this particular implementation you have linked (I've seen several like it, for several different languages, and they all work on the same principle), it's always either a choice between using an extremely restricted subset (OpenCL/C with a "python-skin") , using a numpy-like interface (the actual code running is not written in python, but just a pre-determined set of operations you can queue and execute efficiently) or a mix of the two. To make python run on the GPGPU, you first need to strip away the things that make python python (and not C), like duck-typing, infinite-precision-ints, all of its standard library, modules, most of its basic datatypes (lists, tuples, ... which you replace with unsafer approximations), exceptions, recursion, lambdas, et cetera. At that point you are really just programming OpenCL/CUDA/C with a very thin python syntax-skin. Some people may have a use for this, but I personally consider it relatively pointless for practical purposes; CPython allows you to just program python without knowing the internals of the interpreter or the instruction it executes, but with these OpenCL/CUDA skins you need to already know the GPGPU backend language you are generating, and at that point you might just as well directly use OpenCL, which will cut out the middle-man and probably give you a good performance boost as well. Hence my statement that you cannot run python meaningfully on GPGPUs. 
The main difference is that uWSGI runs as an external process that you have to configure externally, and then hook up to the web server using reverse proxy configuration. Phusion Passenger integrates directly in the web server and you're supposed to configure it through the web server. This reduces the number of moving parts from the administrator's point of view. Phusion Passenger *also* has a mode that runs externally so if you prefer reverse proxy configurations then that can be done as well.
You are merely adding noise, no content. We all know that C is a language that can be used instead of python for writing kernels and device drivers, and that Ada is a language commonly used in applications that have a heightened need for correctness -- spamming the wikipedia link doesn't help anyone. In addition, most of your links are misplaced or misleading -- if you think stacklesspython somehow makes python more suited for {OS kernels, Device drivers, Embedded devices, Realtime-critical code}, you'll have to justify that, because that is not really true.
"some window manager"??
If you think you can pick up Agda (in a reasonable amount of time) because you know C or C++ (or even haskell, which its syntax is based on), you might wanna... actually try it. You need a bit more of a solid background in formal logic and intuitonistic type theory to wrap your head around it. It's really not much like a programming language in the traditional sense, more like a formal theorem encoding &amp; verification tool.
It is a like for like comparison. numpy uses a less efficient algorithm. If you write your own algorithm, sure. But using that logic, assembly is the best language because you can write all your own algorithms.
It's not like for like, read the docs for xcorr, it does an approximation using some method such as fft or gpu acceleration, the matlab function corr gives more accurate result for a wide range of inputs like numpy.correlate and is also slow for that reason. So your assumption that numpy.correlate is the same function as xcorr is incorrect, numpy.correlate is more comparible to corr. An fft based convolution can be found in scipy.signal.fftconvolve, the one I posted above is slightly faster as it assumes real input (no complex part). I don't understand your point about assembler.
No, I'm implying "don't spam irrelevant links" and "don't provide false or misleading information".
I will, as soon as I do stuff that needs handling time again. My last few projects were pretty timeless. Thanks!
&gt; what would be your recommendation and why? To just use OpenCL directly. &gt; but have you read http://www.cert.org/books/secure-coding/[2] ? Compilers can generally optimize and prevent double frees better than I can, on a good day. If OpenCL doesn't give you these features, neither can NumbaPro. As I explained, these types of libraries do not actually give you python on the GPGPU, they merely give you a python-skin for OpenCL. In addition, you do realize that those features are completely irrelevant for GPGPU programming? malloc()/free() does not even exist in OpenCL/CUDA.
Do you have an HLA library for that? https://github.com/rose-compiler/rose
&gt; What about the linkage between your comment and the subsequent sub comments indicates that anything I have shared with you is anything but true? Somebody posted a set of problems, and you replied with a link to (for instance) stackless python. At best, that would be irrelevant (hence spam), at worst, it may be understood as implication that stacklesspython somehow remedies the problems posed (which it does not, and hence it is misleading.) &gt; How did you make the inference that I was suggesting someone should write an OS in Python, or Rust, or Go? I did make no such inference.
http://en.wikipedia.org/wiki/Spam_(electronic) "is the [reprehensible] use of electronic messaging systems to send unsolicited bulk messages, especially advertising, indiscriminately."
What's the catch? Why wouldn't I want to spam all of my functions with @autojit?
As much as I love Python this sounds like something I'd do with NSIS instead. 
No one really read what I posted. They saw "Python isn't the greatest thing ever," saw it had some downvotes, joined the crowd, saw someone making fun of my post, upvoted. It's how specialty subreddits work. If you point out there are times that an alternative is better, you will get an onslaught of downvotes. Notice that when I delivered on his demand, all he did was downvote and move on.
I'd like to see a comparison between Numba and C. Are there any around?
This is exactly the same as functools.partial: https://gist.github.com/boukeversteegh/5533958#comment-827440
It is possible to do a text based game as a series of if-else statements, but it quickly becomes a rat's nest of unmaintainable code. Generally speaking, what people do is to write an engine in one language (for example, Python) and then have that engine process scripts or other assets written in a language specifically designed for it. Try starting here: http://en.wikipedia.org/wiki/Interactive_fiction
It will only work for some functions. The jit is very limited in scope of what it will compile, but for most of my work (numerical work), numba is amazing and has me very excited about its future development.
Right but couldn't it just bail out (and fall back to regular python) if it detects code it can't optimize? What I'm really trying to ask is - why can't this be applied on the interpreter level to speed up the whole language?
I like it that they are working on this. Makes raspberry pi less awfully slow ;)
Yes. Performance enhancing drugs exist for many human endeavors. 
Don't know why you were downvoted. It truly is a stupid title.
thanks a lot for this!
There is always a [performance](http://xkcd.com/323/) enhancer!
&gt; I really like that a key feature of Arrow is humanization- that's great You know that refers to the `.humanize()` method, which converts datetimes to "such and such ago" descriptions? (I find Kenneth Reitz's “for humans” marketing insulting)
In the recent [numba presentation](https://www.youtube.com/watch?v=COglHpt7KSs) there is a speed comparison with Fortran (which I believe is faster than C for numerical work) for [Laplace 2d equation](http://en.wikipedia.org/wiki/Laplace%27s_equation) at about ~29m.
You can ship [a copyright file like this](http://www.debian.org/doc/packaging-manuals/copyright-format/1.0/ "scroll for examples"), inline short licenses and put the GPL license in a separate file. Copyright-wise you're in the clear, since the library isn't a derivative of the sphinx theme.
I put it on a server in our network as a daemon and it works just as advertised. Well done! You might want to mention in your README that you can also set the proxy to be used at all times by putting the option in ~/.pip/pip.conf as follows: [global] index-url = http://&lt;ip&gt;:&lt;port&gt;/simple/ 
Numba was created with two goals in mind: 1) speeding up *numerical* code in python 2) integration with cpython scientific computing stuff So, if you're dealing with, say, strings, numba will simply add an overhead slowing down your code.
The simple composition is nice, though. And just a two-liner :)
Well, the reason it won't be incorporated into (say) the official CPython anytime soon is that JITs introduce a whole lot of extra complexity and the CPython people are more worried about keeping the core language bug-free. They've always been happy to leave numerical optimisation to the Numpy people. That also lets Numpy and the Numpy stack (of which Numba is a part) progress faster, because they're not tied to core releases and backwards compatibility. The reason no-one does, in practice, just put @autojit on every function is that for most numerical applications there is just one function which needs speeding up, and you already know which one it is. If you're not already using Numpy arrays then probably it's because you're not doing the kind of numerical code Numba will help with.
Try [Renpy](http://renpy.org) if you want to get straight into game making, it's GUI based, but built for exactly the type of game you want to make!
Awesome! * Does it have a "strptime" alternative that doesn't randomly break in threads (ie, pure Python)? * Does it integrate with Django's non-naive datetime stuff well? * Is there a way to get an arrow directly from a datetime.date more elegant than `beg_dt = arrow.get(mydate.year, mydate.month, mydate.day)`
Is the name derived from the expression "time flies like an arrow / fruit flies like a banana"?
Have you also looked at https://pypi.python.org/pypi/times ??
Not exactly.. partial application is not the same as currying. In currying you are flexible to provide as few arguments as you like, and you will always get a new function until in the end all parameters were filled in and the value will be returned. You can't do this with partial, because it modifies the function to accept a different number of params, but it isn't flexible. This doesn't work: add = partial(lambda a,b: a+b) assert add()(1,2) == 3 assert add(1)(2) == 3
Interesting library, thanks for the link :)
It's true... Haven't thought about it.
There will be on my next blog post on the topic :)
Perfect. I've thought (and tried) doing a comparison, but I'm no expert at Cython.
Uh, there's a tiny bit more to Haskell-style functional programming than function composition and currying. Let's see a strict compile-time type checker with a Haskell-like type system, transparent lazy evaluation, enforced purity, monads, do notation sugar, user-defined operators (with fixity and precedence definitions)...
http://www.michelepasin.org/blog/2011/02/24/survey-of-pythonic-tools-for-rdf-and-linked-data-programming/