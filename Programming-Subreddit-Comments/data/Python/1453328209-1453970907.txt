Okay, I am a bit biased here, but let me throw in another one (https://github.com/rasbt/pyprind) I typically use it with the `monitor` param to print out cpu and memory usage reports. But I am pretty sure that `tqdm` supports that to -- I am going to check that out, `tqdm` looks like a really cool tool! bar = pyprind.ProgBar(n, monitor=True) for i in range(n): time.sleep(0.05) # your computation here bar.update() 0% 100% [##############################] | ETA: 00:00:00 Total time elapsed: 00:00:05 &gt;&gt;&gt; print(bar) Title: Some test Started: 01/11/2016 17:01:40 Finished: 01/11/2016 17:01:45 Total time elapsed: 00:00:05 CPU %: 1.100000 Memory %: 0.365353
[removed]
Let's get this on GitHub
I've been playing with it for ~10 minutes. How would you define a workable grammar to parse bold and italics text, in markdown format? style_text = b_text / i_text / text b_text = "**" style_text "**" i_text = "*" style_text "*" text = ~"[A-Z 0-9]+"i `**One, *two,* too** to!` =&gt; **One, *two,* too.** to!
Absolutely not. Classes aren't file folders - they have state. class Login() def login1(self, ...) # Why am I being passed self for no reason? login1 = Login() login2 = Login() # Why should I be able to create multiple copies of Login? Login.login1(???) # This call isn't even valid without making the class methods static Frankly when you have that kind of code duplication something is seriously wrong. If you want to refactor the code you should be looking for similarities between the related functions and pulling them out.
Some features should be working in all workspaces, while others need the new workspace type. Unfortunately the developer who added this new Python support is in Europe so is currently asleep and I'm not sure if the new code completion features should be working in all workspaces. The easiest way to ensure you have all the new features is to push your code to a git repo or download them locally, create a new python workspace, then upload your files to it. If autocomplete still doesn't work for your project after doing the above please post or link me to a code sample that doesn't work and we'll fix it. 
glitches? Really? That's a python 'feature'? 
You may want to consider going serverless. Both Google and Amazon offer hosting python code without managing VM instances. It's a python function in the cloud and you only pay for actual usage. It automatically scales both up and down. The Amazon version is called Lambda and the Google service is called App Engine. It means getting married to the cloud provider. But it may be worth it. Ridiculously easy to use and scales infinitely. What's your backend? You can't keep any important data in memory (nothing more than cached data). It will need to be stored in the object storage or database service provided by the cloud provider you choose.
Thanks for the response! Will give that a shot tomorrow as I am in Europe now as well and it's getting a tad bit late. :)
I use pycuda from http://www.lfd.uci.edu/~gohlke/pythonlibs/ (without mini-/anaconda on Windows) and the cuda toolkit from https://developer.nvidia.com/cuda-downloads My python environment: * Python 3.5.1 64bit, Windows 7 * numba (0.23.0) * pycuda (2015.1.3) all binary packages (of dependencies) from http://www.lfd.uci.edu/~gohlke/pythonlibs/ So I am not using numbopro, nevertheless these variables (both) were necessary. Still, the explicit import for jit in the first numba example is missing. (In the guvectorize example, you do this import: from numba import jit, vectorize, guvectorize, float64, complex64, int32 so perhaps you went back to the first example of numba which is working then.)
Why is this guy getting downvoted? I rolled my own as well - its like 30-40 lines at most unless you start adding a bunch of random features. There are already 60+ packages in my virtualenv. There is no fucking way I'm adding a dependency every time there is an opportunity to save three dozen lines of code.
That looks clean, thank you for sharing!
this is pretty dope man kudos.. however, why don't you add it to a Github account it makes it easier to read plus then someone can fork it from your account. Github also preserves indentation for instance: def random_pic(): attachments = ['C:\\Users\\BOB\\Desktop\\TheFile\\1.jpg'] # Use the path to the image/images you would like to send is not indented making it harder for someone to copy paste then edit
Just for shared libraries at work. We're actively trying to eliminate or upgrade services on python 2 and one of the ways we encourage other teams to do that is by only supporting 3.
I'd guess this is so you can paste code beginning with a comment and not have the REPL treat it as multiple statements.
The whole bottom 50% of this can be erased with 'return random.choice(x)' 
This. I need to know this.
Make it in C so it's minimal overhead, so it doesn't slow my program down in tight loops
Ever have resistance to using 3 because of unwillingness to learn "new@ syntax? 
The "article" is bad and doesn't contain any useful information. 
Saw the matplotlib guys videos from pycon 2015... they definitely seemed very earnestly interested in pleasing the community and very open to people's feedback and help on how to help matplotlib improve.
Sorry you feel that way! I put time into all my posts. I sent you a PM if you'd reply! :)
[wordfreq](http://github.com/LuminosoInsight/wordfreq), for looking up frequencies of common words in many languages. (The English list now includes Reddit as a source!) It wouldn't work as well on Python 2, and we don't use Python 2 in our stack, so why backport it? The much more popular Unicode-fixing library [ftfy](http://github.com/LuminosoInsight/python-ftfy) is also on notice for similar reasons, but we're giving people at least a year of warning.
Sure, there are a lot of new patterns that don't work in 2.7. My personal favorite is [PEP 3132](https://www.python.org/dev/peps/pep-3132/). Example: &gt;&gt;&gt; some_list = [1,2,3] &gt;&gt;&gt; first, *rest = some_list &gt;&gt;&gt; first 1 &gt;&gt;&gt; rest [2, 3]
I've [been writing Python 3 only](https://github.com/cathalgarvey) since I started coding Python at all. Not interested in making the legacy problem any worse by being part of it. :)
Hmm.. maybe, I run the professional edition. 
According to pypi both `Pypdf2` and `pathlib` support Python 2.
Use modules for grouping, not classes. Python is not Java, you don't have to make every function a class member.
Use a text editor for yourmodule.py, Jupyter notebook for REPL / execution and use the auto reload magic %load_ext autoreload %autoreload 2 This way, you can keep your code in a python module, execute it, and display results charts etc, in the Notebook but every time you change the code in your text editor, the module is automatically reloaded, meaning you have the latest version. Your python code can sit in version control and the notebook ignored (or saved with specific examples for posterity). 
Ok, then you can use a wrapper for C. If Sqlite is good enough for Mozilla Firefox and Google Chrome...
Everything I do these days are Py3.5, I love the async-await-syntax when working with asyncio!
Nice! But note the following from the python library reference for the locals() function: &gt; The contents of this dictionary should not be modified; changes may not affect the values of local and free variables used by the interpreter. 
I think your formatting is broken?
[Write a tiny virtual machine, it's surprisingly easy.](http://www.multigesture.net/articles/how-to-write-an-emulator-chip-8-interpreter/) Chess is pretty neat too.
my implementation of SVG on top of OpenGL: https://pypi.python.org/pypi/seagull/0.1 it's even python 3.3+
For ML-like languages, there's a difference in typing between a beta-redex and a let expression due to let-polymorphism inducing a generalisation from a type to a type scheme in the latter and not in the former. That is, we want to be able to locally declare a polymorphic function via let and use it at two different concrete types in the body of the let, like so: let foo () = let id = fun x -&gt; x in (id true, id 6) Note, here the locally defined polymorphic function `id` is being used at both type `bool` and type `int` in the body of the inner let. Without the generalisation step in the typing rule for let this usage would be ill-typed, reducing the expressivity of the programming language in question. Otherwise, for typed higher-order languages without let-polymorphism, it's common to conflate the two. For example, in Isabelle/HOL, let is literally defined as a function application, as in the following definitional theorem: `HOL.Let_def: Let ?s ?f ≡ ?f ?s'
Yeah, should be: n = 23 print(n) with let(n=42): print(n) print(n) (precede each line of code with 4 spaces)
[Here](https://pypi.python.org/pypi?:action=browse&amp;show=all&amp;c=595) is a list of packages on PYPI that specifically identify themselves as only supporting Python 3. This isn't all of the python 3-only packages, however. Packages that only support python 3 but don't explicitly identify themselves as not supporting Python 2 aren't included.
Looks like it just reads and writes to file handles of the shared memory https://github.com/mrocklin/shmarray/blob/master/shmarray/core.py 
its seriously just javascript's (and other's) `let` statement, why is functional programming even being mentioned python can't arbitrarily create scopes for variables like other languages, this is the solution to that
I've interacted several times with the author and maintainer of AsyncSSH, Ron, and he's always been responsive and thorough above and beyond the call of duty.
can I ask what you are trying to accomplish? just trying to not run compute twice I guess? wouldn't `def pairmap(func,x): yield from map(lambda y:(y, func(y)), x)` be good enough? edit: I'm tired [x, b for a, b in pairmap(compute, list) for x in f(b)]
I think that's because python the language spec and python the interpreter aren't the same thing, so you have no guarantees as to what shit like locals() will do on different interpreters. But this will work in cpython and jython I think, at a minimum, and maybe also pypy. 
&gt;&gt; Can you guess what happens? &gt; Yes, if you're used to Lisp. So, what happens? I'm not saying that as a Python programmer I'm somehow unfamiliar with the notion of shadowing and it scares me. I'm saying that I'd hate to have to scan all the code upwards when I see `y = 22` to see whether or not `y` was made magical by specifying it as an argument to some `let`. What'd happen with `z` in my example is worth considering as well. Have you considered it? This abstraction leaks like some sort of a container with many holes in it. I don't understand your example, sorry. Why would you want to `del` a local variable?
&gt; just trying to not run compute twice I guess? Not running it twice, not writing it out twice, etc. As I said, when you become aware that this is a possibility (after seeing it in LINQ for example), you start wanting it rather regularly. You forgot to actually iterate over the iterable in your `pairmap` and anyway I strongly dislike it: it does unrelated things suited only to this particular instance of a problem. I much prefer just directly emulating a functor when I only have a monad by saying `for x in [compute(y)]`. But `let x = compute(y)` would be better of course.
Real Python is amazing. Paid course. www.realpython.com Made a career switch from finance/accounting to web development
Syntax errors. Context managers. Classes. Libraries from PyPi. Logging. Don't use sleeps. Also ~~possibly~~ definitely a violation of the Computer Fraud and Abuse Act if executed. Get this shit off of /r/python.
Python C api is great. Why do you think this is not possible? This might be the case that I don't know or you don't know and I'd like you to educate me on the issue, please.
I'd also like an `as` in non generator comprehensions so you can refer to what you are constructing: triangles = [triangles[-1] + x for x in range(1, 11) as triangles]
As someone who's subscribed to both /r/python and /r/clojure, the two feeds are giving me the giggles; here's an example of a Lispy let in Python; on /r/clojure, there's a story about avoiding let like the plague because reasons.
1. That's an unholy abomination. 2. Won't work with generators and set/dictionary comprehensions.
I definitely did not just assume that the example worked in a particular way then make a statement based on that... I promise... I assumed it would throw a `NameError` but it just printed `1 22 None` and now I feel stupid. Sorry. 
I'd personally opt for a more C-like way a = 0 b = '~' with Let() as let: #edit: corrected let. a = 1 b = '|' print(a, b) # 1 | print(a, b) # 0 |
For what purpose? 
what does the `**` before `**bindings` do, and where can I read about that in the python documentation?
[Django is planning to drop support for python 2](https://www.djangoproject.com/weblog/2015/jun/25/roadmap/). Though, to be fair, it won't be completely dropped for another 4 years.
[Read it here](http://stackoverflow.com/questions/36901/what-does-double-star-and-star-do-for-python-parameters)
Do you want to write your application in Cython or Nim?
https://docs.python.org/3.5/tutorial/controlflow.html#unpacking-argument-lists
That's not really a problem unless your variables are global, which you typically want to avoid.
I use Spyder which is part of Anaconda. It has a full python editor + ipython console + interactive debugger. You edit a standard py file but can create ipython cells by starting a line #%%. Then you can run each cell individually and see the results in the ipython console.....but you still have a complete py file rather than ipynb format. Occasionally I still want to have an ipython notebook. There is no built in way of converting py to ipynb and back. However I wrote a small script to do this which is at the link below.....note works for me but may need tweaking for different environments. https://github.com/simonm3/analysis/blob/master/scripts/spycon.py 
Oh. I didn't get that. I though it was for dev only. Although running sqlite on many projects myself, I've yet to discover something it's not good at for local projects.
Mmh, I tried it, and I don't understand how unnamed nodes are supposed to be treated by visitors. For now, all that I can figure out is writing: def visit_(self, node, children): return children and then let the parent node visitor decide what to do with results. It feels cumbersome though.
Also great is the Numpy-style docstrings, linked on top of the link. It's especially useful if you're doing any scientific applications.
"Dev time speed" depends on many factors: requirements, deployment, ecosystem, tooling... Python IMHO is vastly superior to Java in terms of density (less typing) and clarity (much more readable code), but it's not necessarily better when it comes to specialized tooling. If you're cranking out LOB stuff using wizard-driven IDEs (NetBeans etc) and uber-powerful frameworks (Weblogic and so on), shifting to Python won't necessarily give you faster development speeds (especially at first), because the ecosystem of business-oriented apps is much smaller. For relatively simple web work, Django is the most resourceful framework, it already has all the items you mention in default install. Flask is much more barebone, you'll have to pick and choose the add-on libraries you need, but this means it's more flexible overall. You'll then have to figure out deployment, which is a huge topic. In short, don't move to Python "because it's faster" -- do it if you like the syntax and paradigms it features, both in coding and deployment... IMHO it's worth it just because you'll get rid of the godawful "build" step.
great link. Thanks. I had only known ** for exponentiation.
You don't have too. Just put a "vendor" dir, dl the package code and put it here. Treat it as internal code and modify it if you need. No external dependacy, you save coding time and the implementation is likely to be more robust than yours.
Thank you!
My reactions to this: "Huh? ... Ooooo clever ...wait.... Oh. Ewww. "
I thought I'd give a little more information here about why I wrote this library. A good expect library can save a lot of hassle when dealing with a command line interface to a system when that's all you have. I've gotten a lot of mileage out of [Pexpect](https://pexpect.readthedocs.org), but a constant thorn in my side was the lack of support for using Pexpect on serial devices under Windows, because Pexpect requires a file number to work with. I set out to patch Pexpect with functionality to allow it to work with generic streams (anything that defined a `read` function), but the code in Pexpect didn't really lend itself well to the updates. About this time I was also dealing with the headaches of string/binary differences between Python 2 and Python 3. I decided that anything I wrote needed to take the same hard-line approach to text vs. binary that Python 3 did. streamexpect is the end result of that. For 95% of cases, it requires only a single line to initialize: with streamexpect.wrap(some_stream) as stream: # do stuff with wrapper Under the hood, there are clear delineations of responsibility that should make it very easy to extend where necessary. Please let me know your questions, comments, and suggestions!
That's not polymorphic though? I was thinking of how c++'s templates allow for generic data.
There's something else that does this (not overwrite containing scope), that's built into Python (all versions) and every Python programmer understands. It's called a "function call".
Re-formatted int func() { int a = 5; { int a = 10; } // a is 5 here }
languages with functional features, better at functional workloads news at 11 edit: I was bored, toolz package in use In : pipe(zip(x,y), concat, ''.join) Out: '1a2b3c4d' In : pipe([iter(list1)]*(n-1) + [list2], interleave, list) Out: ['a', 'b', 'x', 'c', 'd', 'y', 'e', 'f', 'g', 'h'] second one looks a bit nasty, but I know that there are other packages that might be considered "better" for functional usage
That's awful. Learn to use `zip`. data = range(1, 11) triangles = [x + y for x, y in zip(data, data[1:])] I challenge you to come up with a use for this that doesn't have a better alternative.
Do you have an example of how this might work to interact with a console process (e.g. spawned with subprocess)?
While you're right, aren't there libraries that support asyncio and are faster than Python's asyncio module? Yeah, it's easier with Python 3, but I don't think it's necessary. I could have sworn David Beazley mentioned that in his talk https://www.youtube.com/watch?v=lYe8W04ERnY
&gt; Functional programming discourages, where possible, variable bindings and prefers deeply nested ASTs to stacks of variable bindings and scopes. I'm not sure what language community you're referring to, but I've never seen anyone *discourage* people from doing that. It's true that people tend get lazy from time to time because functional code tends to be more terse, but in all coding recommendations I've seen it's actually encouraged to save things in variables as much as possible for legibility and as well as more sharing.
To use a class as a namespace only you should make all the functions static methods, e.g.: class Login(): @staticmethod def login1(arg1, arg2): # etc. It's probably not a good idea in this case, though. You would then need to access `login1` as `Login.login1`, which seems a bit clumsy. If the functions really are similar you could consider combining them into a single function, passing in a keyword argument (perhaps with a reasonable default value) to switch between the previous function behaviors.
Because it hasn't been mentioned yet, checkout [cherrypy](http://www.cherrypy.org/)! ****Edit:**** What's with the down votes? Does this sub just hate cherrypy?
I've never done this (it seems interesting) but I'd imagine take the highest population areas (if you have that) and then if you have a dataset of the roadways construct a sort of index based on the number of vector points within a junctions radius. (you'll need to get those although its not hard with a vector data set its the start and end of each roadway segment) and number of unique roadway segments within that radius. You could also weight the number of points based on the level of roadway that it is (i.e. interstate, US route, State route) from there assuming your in a city you should see a definitive radius starting to form naturally based on junctions around the city. In an ideal world roads are suppose to do that. Assuming your familiar with the area it should be a pretty intuitive thing to start drawing the framework around the city. For example the simplest thing would be to say give me all the starting and ending points for segments I have, from here you can iterate through each of those against the entire start/end data set (I suggest something like pandas for the table comparison for each iteration) if two points are on different segments and say within .05 miles of one another thats a pretty good indication their joined or at least influenced by one another. The easiest thing to do from their would be give each roadway tier a weight and multiply by the number of each unique tier at a junction and sum those, it may not be bullet proof but it will probably get you started. There however may be way more knowledgeable people then me on here (I'm sure there are) but thats how I would go about it assuming you only have roadway data. Hope this helps! 
&gt; It's called a "function call". Yes, and you have to define a function to do it, and then you either have to pass all the parameters you need through and return what you need afterwards which is a huge mess or put the function definition inline with your code and call it immediately which is gross in a different way.
Maybe it's a pending issue on GitHub? (It'd be great if pip would emit these hashes at least when installing the packages.) I guess for freeze it'd have to re-download the package just to hash it. Also, it's a bit worrying that PyPI still displays MD5 hashes at all. ([See](https://pypi.python.org/pypi?:action=show_md5&amp;digest=366b30f98e7141248b58207247fe17c2), linked from the Files part of any package page, like [this](https://pypi.python.org/pypi/justplot/0.1.2a4).)
I strong hardly disagree. Getting Flask up and running with a DB is extremely easy and quick.
I can't really give a general overview because every functional language is different, but `let` is one of the two main ways of binding variables in Haskell: let &lt;name&gt; = &lt;value&gt; in &lt;expression&gt; What makes is different from a typical binding in Python is that: - The variable is only accessible from inside the `&lt;expression&gt;`. This means if you mistakenly try to use it outside, you will get a compile-time error. - The `let`-binding itself is an expression, so you can do things like this: putStrLn (let h = heightOf person in "Height: " ++ valueOf h ++ unitsOf h) Personally, for readability reasons I don't find myself nesting `let` inside expressions very often. - The variable is immutable. I don't see the point of trying to do this Python though. The "let" hack is not an expression, and it's not immutable either. There is a small benefit in having a smaller scope, but it's (1) not really that big of a deal (I seldomly run into bugs caused by this); (2) ideally your functions should be small enough that this isn't much of a problem; (3) the benefits are not as great given that the error won't be detected until run time. 
Python does need fewer LOC across the board, and there are some old studies suggesting that development time usually correlates pretty well with LOC across languages. Even if it takes less time, does that matter if you are less happy with the result or the process? The only thing you can do is try it and see what you prefer. Nobody else could know whether you will like it better. You might be one of those people who just loves Java. You might be a person who loves Python, and then it might be a real problem if you have to write Java for years to make a living.
Once you find all the right Flask plugins and the right configuration to drive it. In Django it's all rolled together. SQLAlchemy is a great library, with features far beyond Django's ORM; but one thing it is not is easier to learn or use than Django's ORM.
Do you have an example of a real application you made with CherryPy?
I'm curious about that, too. The standard library pseudo-terminal module `pty` doesn't work under Windows.
You don't need SQLAlchemy, you can stick with SQLite. if you need sql features or performance you can't get in lite. Your site is probably pretty advanced all ready, and learning SQLAlchemy should not be a problem. [This is a great tutorial for getting started](http://flask.pocoo.org/docs/0.10/tutorial/)
I think the hate comes from cherrypy having a similar reputation as PHP - shit programmers writing shit code can make anything terrible, it's not the framework/languages fault. Just hearing the words "cherrypy" makes my blood boil. Not because it itself is bad, but the people who chose it for a few projects were Very Bad™ and made a horrid mess with it.
I haven't built anything using Django, but everytime I have seen Django code it's all just. django.code.site.number.two.in.this.class.use.function.three() Reminds me of javascript. I much prefere writing proper python, like you can in Flask.
Maybe you should respect rate limits, and stop breaking the law.
Awe that's disappointing, I've never really heard anything about it or even seen projects others have used it for. Any chance you have an example or two of such projects? Or examples of such pitfalls (I'd like to avoid them myself!). It seems weird to me because overall cherrypy is such a small portion of the code base and it's so clean and organized.
I recomend you djangoproject.com I love it, its very easy and have a great documentation. In django you can make a blog in 30 minutes or less (time it took me to do my blog :-P) and have great tutorials. I can't speak abou java because i never did a full webapp in java
Seems like it lets (pun intended, wait, is that a pun?) you do a "what-if" test. So if you want to run a bit of code under hypothetical conditions, just use let.
Aside from shilling for coralogix, as /u/ArielAssaraf is doing in many subreddits, what makes this any better than using an ELK stack? Does it scale as large as ELK?
Stick to what you know unless you have a pressing need or curiosity. If you know Java, then that's the best tool for the job unless you have some time to invest learning another language. I like [Django](https://docs.djangoproject.com/en/1.9/intro/tutorial01/) to build quick webapps, but that's because I'm still a n00b so I'm still leaning on lots of built-in functionality while I learn.
Why not using itertools.izip (and that's a serious question)? Ok the syntax is similar, so I don't challenge your point, but still: wouldn't izip be better if you have large data?
care to explain?
Backtraces in Python will save you hours of your life. No JVM to tune, no terrible app-killing garbage collection. Since there is no JVM, startup is much cheaper (if that matters for you) No heavy-weight IDE required. pip is great. Virtual Environments for testing are nice. Lots of good documentation for 3rd party Python libraries. Lots of 3rd party libraries if you use Python 2. (There are a lot of Python 3 fanboys here, I'm not one of them) I recommend, based on benchmarking raw throughput of 10k simultaneous connections to deploy a python web app using uWSGI behind an nginx proxy. nginx proxy should forward all requests to a unix socket, uWSGI should have the same number of processes as cores, and threads per core should be 1-2x the number of cores (benchmark your results). I like flask, have written small non production apps in flask. I find it to be a little heavy handed for my style, and it's significantly slower than alternatives for static content and dynamic content retrieving 3 keys from redis. flask does have a lot of user-created extensions for things like login.
This is the best tl;dr I could make, [original](http://devpost.com/software/trumpscript) reduced by 79%. (I'm a bot) ***** &gt; As the undeniably best presidential candidate in the 2016 language, we found that the current field of programming languages does not include any that Trump&amp;#039;s glorious golden combover would approve of. &gt; All programs must end with &amp;quot;America is great.&amp;quot; Our language will automatically correct Forbes&amp;#039; $4.5B to $10B In it&amp;#039;s raw form, TrumpScript is not compatible with Windows, because Trump isn&amp;#039;t the type of guy to believe in PC The language is completely case insensitive Grammar. &gt; E.g. &amp;#039;Make America great&amp;#039; assigns the value of the variable &amp;#039;great&amp;#039; to &amp;#039;America&amp;#039; Printing to stdout can be done via &amp;#039;tell&amp;#039; or &amp;#039;say&amp;#039; While loops are denoted via &amp;#039;as long as&amp;#039;. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/422dov/trumpscript_make_python_great_again/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ "Version 1.6, ~29070 tl;drs so far.") | [Theory](http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/) | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr "PMs and comment replies are read by the bot admin, constructive feedback is welcome.") | *Top* *keywords*: **Trump**^#1 **great**^#2 **language**^#3 **programs**^#4 **used**^#5 
Its nothing to be defensive about, frankly a lot of "self documenting" python code is painfully verbose because the author doubled the line count with useless crap. Its perfectly fine if it takes 10x longer to decipher a line of functional code if it also accomplishes ten times as much work.
Because in Python3 zip, map, filter, range and maybe some other functions became their itertools equivalents. And I don't know about other people, but for me somewhere around last summer Python3 has become the default Python, in no small part because it turned out that most of the stuff I need was ported and conveniently packaged by Anaconda. Plus the py.exe launcher for Windows provided for a convenient way to still run Python2 stuff via shebangs (unfortunately the launcher still isn't packaged on Anaconda for some reason).
&gt; the word "anomaly" is so frequently used in our market that with all the noise its impossible to differentiate You'll have to take the same care with your product. Logging is a difficult thing to get right in the design of a full stack, and there could end up a lot of noise in the logs when nothing is wrong. Or the converse, no noise in the logs when an error is occurring. Hence your product may end up learning on false positives and false negatives... even more noise on top of already noisy logs. Have you any advice on how to design logging to work well with your product? Our product is a collection of job servers and microservices, distributed across multiple providers and data centers. Our system is built with [eventual consistency](https://en.wikipedia.org/wiki/Eventual_consistency), and the system is constantly going in and out of convergence, as customers apply changes from various endpoints. How fine grained are your learning algorithms? How "fuzzy" are they? Would they work with an eventually consistent system?
Python can boost your productivity in many ways. See for example this video about Dependency Injection: [Raymond Hettinger - Super considered super! - PyCon 2015](https://www.youtube.com/watch?v=EiOglTERPEo). You don't need to use interfaces, xml config files, frameworks or warhever to do inversion of control and dependency injection.
Why aren't all those vars in a dictionary or class? Do you have like 300 globals?
Why aren't all those vars in a dictionary or class? Do you have like 300 globals? 
&gt; low effort on your end From a business perspective, I totally agree. From an engineering perspective, low effort is exactly what leads to poor quality logging. You're in a unique position to see many different types of logs and logging implementations. You might use that to produce a best practices guide. Demonstrating a high level of competency through technical blogging is a great way to differentiate yourself and attract customers, or even employees. See for example Netflix's technical blogs.
bandit is a great tool for looking for known problems that can lead to vulnerabilities
Python 3.
A fundamental difference between C++ and Python (and also between C++ and Java, when it comes to non-primitive types): In C++, a variable is a container that has space to store an object of the variable's type. When you assign to an existing variable, you are either replacing one object in memory with another \*at the same address (in the case of plain old data), or asking the left-hand object to turn itself into a copy of the right-hand object (in the case of a class with operator=). That is, assignment is a kind of mutation in C++. In Python, a variable is a name that can refer to an object: essentially like a pointer variable in C++, \*but without a type. Assignment in Python means making a name refer to a different object, and works like assigning pointers in C++: the object that the name used to refer to is unchanged (but unlike C++, you don't have to worry about manually deallocating it). So, in Python, plain assignment is not mutation (not of one of your objects, anyway—there is a symbol table behind the scenes that is being mutated). In Python, it is a little more complicated when assigning to a subscript. In that case, you are not binding a name in the symbol table, but rather a slot in a data structure. That means the data structure that holds the slot (the dictionary or array itself) is mutated. But, as with plain assignment, the slot is just a "pointer": the object that it used to refer to is unchanged. So in your example, "a[0]" and "b" are two names for the same dictionary object. `b['two'] = 2` (note that you're not assigning to b itself) says "b['two'] is now a name for \*the obect **2**", which involves mutating b. Since a[0] is still the same object as b (no one assigned to b or to a[0]), a will "see" the change. Later, "c[0]" and "d" are two names for the same integer \*object **3**. When you do `d = 4`, that says "d is now a name for **4**", which doesn't mutate the **3** at all (not that you could mutate it, but immutability isn't relevant here). So now c[0] and d are no longer names for the same thing: you broke the alias. In short: a[i] = v # mutates a, only rebinds a[i] n = v # only rebinds n **Edit**: added clarifications marked with \*
There isn't much to choose from out there. Right now HP Fortify does an *adequate* job with python. There is a jenkins plugin for continuous integration projects.
I don't know what you mean by better support. I've been a customer for quite a while and I have found that their support is exceptionally good, if you're referring to being generally helpful and willing to assist customers. If by support you're referring to support for various packages and capabilities, you might be interested to check their new docker container consoles. In other cases, they have added packages for me, or have helped me to find ways of doing things within their system. Overall, as an alternative to getting a bare box and hardening and maintaining it, I have found Python Anywhere to be very effective. What kinds of "better support" would you like to see? 
Python code is not the easiest thing to scan. It can be obfuscated to all hell if the developer wanted, through weird reflection techniques and including compiled malicious binary code. Honestly, I'd just skim through the code, and just argue for automatic acceptance of large popular products (like django, flask, requests, etc). If you're including a python library in your production code, you really should know how it works, what it does exactly, etc. I do this already anyway. I don't import some random python module I find without browsing the source tree quickly. It's third party code, and I want to know it's written well and I can trust it. If the code looks terrible, if it's not terribly hard I'll probably just implement it myself. I rather have something I can trust, that I know exactly how it works. But I won't waste any time maintaining something that was already built, and built well. You might try automated dynamic analysis with something like cuckoo sandbox. You would launch it to download the python package, and run it real quick to see if anything sketchy happens, files get written to, network traffic is sent, etc. You could use that to determine quickly if it's outright malicious and not trying to hide it very much. That will get around obfuscated and hidden malicious behavior for the most part. As for vulnerabilities, this is time consuming to find and always will be. You can scan real quick for calls to the shell. Look for "shell=True" and os.system calls. If there's user input in there and no good reason to have it run in a shell, just skip the code, unless you absolutely need it, then fork it, patch it, and submit a pull request maybe. Outside of that, vulnerabilities will be real hard and time consuming to find, and no good automation will find everything. If there was something magic like that, pypi would probably already be running it on new version uploads. But I seriously recommend reading whatever packages you plan on including regardless of what you do for security.
I read the title and came here to suggest Ruby on Rails as well. I love Python, I use it for all my scripting, scraping, munging, cleaning needs. However, the RoR framework is the best I've encountered for getting simple web apps up and running. 
The java ecosystem brainwash continues to fade and for good reason. Due to its strictness (hard to get anything done but if it's done.. its somewhat deliverable if lucky), it is prone to outsourcing. But you really are asking the wrong question. A notable developer should have necessary theory/background to work in whatever stack/framework that suits solving the task. If you theory/experience needs reinforcement (or maybe.. broadening) diversifying your skills in a new (python) framework sounds like a decent investment in time.
I've recently studied asyncssh's codebase over the past few months. There are few other asyncio protocol API's like this, and I know Ron has probably had to do a lot of work to be a first. My impressions: - **Great** documentation -- both guidebook-like and detailed API docstrings. A+. I hope to achieve half of Ron's quality of work here. - Great issue curation and release management. - Asyncio! This stuff is awesome. After spending a few hundred hours on asyncio, I'd much rather work with asyncio coroutines and futures than return to old imperative threading patterns used in comparable libraries such as paramiko. I hope Ron gets paid for this stuff, it is high caliber effort! I have been a heavy user of paramiko in the past and in future projects I will certainly try to use AsyncSSH instead. I've been watching this project because I wrote a alpha status protocol library (telnetlib3) for asyncio a few years ago when asyncio was codename "tulip", now I am preparing a 1.0 release with an API I plan to support for the foreseeable future. I've been using AsyncSSH's API as a guide for good practices!
I have absolutely no reason to ever use this, but very cool all the same.
Thanks, I couldn't get that part right so I just did it the long way. 
It is on my github as well. Thank you for the kudos. Im still learning.
I look forward to criticism, and I am well aware that there is things in my code that can be made better. However, I can guarantee that this code works 100% of the time, with 0 errors. As far as the violation of the Computer Fraud and Abuse Act, this is no more than an easy way for someone who needs to send out 100 of emails. If an individual uses this for nefarious acts, that's not on me. Same could be said for 90% of all other code by your logic. Just saying, but thank you for your input, and I would very much like some solutions from you to better this code if you have any suggestions. 
"Corresponding to the previous question, which of the following is the important for you to be a blogger or run a personal website? *" - If you only select 1, it turns red and says "Up to 2", but forces you to pick at least 2. Can I ask what's this for? 
I honestly just couldn't get it to work in a shorter form. I am still pretty new to programming. If you have a way to shorten it I would honestly appreciate the input.
Not all proxies support Google scraping, and I would need an 100% up-time and free/public proxies can't guarantee that. But hey man, thanks for the info!
I wish I had read this thing about getting py2exe set up **first** rather then now. I've got a full GUI and I'm trying to freeze it, and MOTHER OF GOD IT'S A NIGHTMARE. Ah well, you learn something new every day.
while others are fighting a religious war, let me advise you against this. if you are not thoroughly familiar with python, you will trip up at every step. python 2 or 3? very important because what are you developing on and what are you deploying on. if you are on windows you can basically forget trying to get any of the native database drivers installed. which version of django? because you will find documentation and tutorials on django that dont mention the version of django OR python they are using. what i am trying to say is that it is fast after you get the hang of it. and getting the hang of it is not easy. and if you learn django from the official tutorial on the djangoproject website good luck because if you are experienced webdev from some other platform you be frustrated at not being able to understand the mechanics behind the simple things like url routing. you will be mostly "i see it, but i don't understand it". and most of the tutorial is wasted in showcasing the admin module. and remember you are not a newbie. you are an experienced dev. so stay away from the official django tutorial. it will anger and irritate you. the worst thing about django probably is that the development and the production environments are VERY different. and you cannot develop in production environment, and obviously should not put development environment into production. And no one talks about this. I am sure flask has the same story. so start learning django or flask if you want. but dont leave your advantage of experience in java. it will take about an year for you to reach a level where _you_ are able to get work done faster in django as compared java. just saying.
I promise to go back here and update once we publish something like this :)
Well, I'm a java developer by day and python web app dev by night and currently I wouldn't use python for anything more than small projects. It might all be due to my missing deeper understanding of python or how to do things but... As much as I like dynamic typing and that I can do a lot of stuff I cannot do in Java I also like the realiability of Java. Even with PyCharm I can do so much wrong which I only find out at runtime. Wrong parameter type? Crashes at some point. Cannot find what type that object is? No idea what the parameters even are. I don't know enough about programming theory to explain it properly but with Java and Eclipse/IntelliJ when I type something I (mostly) know that it's probably gonna work roughly this way.
They are pretty much the same. I used to use PyQt and switch to PySide if I have some license trouble (using a library, or company policy). I don't code in Qt much any more, but I can give you a rundown to different between them (at least in my memory 1,2 years ago): - PySide only use native python type (like string instead of QString), PyQt default to Qt type (not sure if it changed). - Different import path, just a search and replace - Different signal/slot type, I don't really remember anymore but the PySide's way is supported by both, PyQt has an old way that you should not use. 
I'm pretty much read some intro and try to learn myself. The book "Rapid GUI programming" is pretty good I think. You only need to cover the basic since Qt is very large, trying to read it all at once is pointless.
PyQt is a mature product which has seen consistent maintenance and updates over the years and is backed by a (small) company whose primary business model is PyQt. (i.e. they have an interest is looking after it). It also has good documentation, a couple books over the years, is updated to follow new Qt releases in a timely manner, and a decent community of people who depend on it for real world applications. PySide simply doesn't have the kind of maturity that PyQt has in any way, shape or form. Does it even support Qt 5 yet? 
I don't think anyone hates cherrypy, I think they just hate on every web framework except flask and django. If you check out the stats for packages in pypi, 25% or more are all django modules. Django is absolutely huge, and one of the biggest reasons people use python. IMO, I think that's the biggest reason python is so popular these days. It's a great scalable web framework, and without it, lots of people would never have run into python. Flask is about next in stats. Incredibly easy to jump into. I think they're just downvoting you because, by the numbers, more devs are diehard django devs.
PyQt supports both types too, just have to use PyQt5.
TrumpScript made it onto the www.thebrowser.com, a great honour!
Pexpect has actually moved in this direction as well - as of version 4, the pty wrapper is one subclass of a generic `spawnbase` interface, so you can use it for other streams as you need, and you can use it on Windows. It's hard to evolve Pexpect, though, because I want to keep backwards compatibility as much as possible. A new package like this has much more room to change the interface. So +1! I'd be happy to collaborate if there's any benefit you can get from our work.
This surely depends on what you want to get out of it? Personally I didn't get statistics until I had read some Bayesian text books, I don't know if that helps.
Sweet, thanks again man, I'll get to fixing it this weekend.
What "godawful" build step you talking about? Eclipse recompiles a class in a couple of seconds, in the background, as soon as you save it. Funny you having a huge problem with a Java feature that i see no Java programmer complain about. You get a lot from that build.
You might want to ask in /r/machinelearning.
Seems extremely odd that you'd demand a "generic" linux system have library packages for X11, OpenGL, and Glib. If I'm running a headless server (you know, like those fancy ones all the kids doing virtualization love), I would want to have *none* of those installed by default.
Python is *not* pass-by-value. Please don't add confusion by misusing "pass by value" to mean what Python does. The canonical test of pass-by-value is whether or not the value is copied when passed to a function. Python absolutely does not copy values when passing them. The canonical test of pass-by-reference is whether or not you can write a "swap" procedure. You cannot do that in Python. (You don't need to, but even if you want to, you can't.) More [here](http://import-that.dreamwidth.org/1130.html) and on [wikipedia](https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_sharing).
The usual term for this in Python circles is [pass by sharing](http://import-that.dreamwidth.org/1130.html). Unfortunately, due to the influence of people who should know better, the terms "pass by value" and "pass by reference" sometimes get misused to describe this [calling convention](https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_sharing). The Java community is the worst offender in that regard, insisting that Java is "pass by value, where the value is not the value that you care about, but some invisible reference to that value that you cannot access from Java". I'm not kidding, that's the sort of [so-smart-it's-dumb](http://javadude.com/articles/passbyvalue.htm) mental gymnastics they go through to force the square peg of Java's behaviour into the round hole of supposed "compiler semantics". (I can only imagine that their head would explode if they learned about Algol's pass by name.) Ask yourself this: if I say `x = 42`, would you say that the value of x is 42, or some invisible pointer at an unknown address? If you say "the invisible pointer", you might be a Java guy, and all I can do is repeat [the Effbot's comment](http://effbot.org/zone/call-by-object.htm): &gt; "Joe, I think our son might be lost in the woods" &gt; "Don't worry, I have his social security number"
I've never heard it referred to as pass by sharing before. But that article is literally what I explained. Except I brought memory addresses into the equation -- which is what pops out when you do `id(myobj)`
Both. Think Stats covers the basics and frequentist statistics, whereas Think Bayes specifically covers bayesian statistics. It's not really an either-or situation.
This argument gets nowhere because the list is supposed to be a standard. The entire point of having a standard is that now I know I can have X,Y,Z libraries installed and I can then run any wheel designating itself as "manylinux1". So I *don't* have to go and manually look at what's compatible with what and sort through things and *hope*. But by your argument, these libraries are just permitted, they're not necessary - so why not add a few more permitted libraries? Lets add a BLAS that's permitted, and some basic Qt libraries that are permitted, and Boost, and... but it's all fine, right? Because they're permitted, but optional! So lets say I've made a server image, and following your advice, haven't included X11, because it wasn't really necessary and I don't think I'd ever need it. Then I go and pip install some `manylinux1` wheels and get off to the races and everything's great. Then 6 months down the track, one of those wheels has an update. It's now relying on another `manylinux1` wheel, but that wheel's latest version suddenly is linked to `libX11.so`! And my build process breaks because of broken dependencies, but everything *said* it was compatible. Ahh - it's turned out, if I actually don't want this situation to be possible (who in their right mind would), I *do* have want to install every single library mentioned. Meanwhile, someone makes a wheel that pip will install with no issues, and is apparently is compatible, but then tries to make an X window on a tty server. Everything said it would work, but then it didn't. I don't regard a standard that just allows things to fail as par for course as a great one.
Of course it's just RPC, but the idea is that this library would make it relatively easy to take an existing legacy codebase that uses ctypes (or maybe cffi) and RPC-ify it.
I agree. Unless you have a problem with the licensing model of PyQt, there is no reason to use PySide.
&gt; which is what pops out when you do id(myobj) No! id() doesn't return a memory address. It returns an **arbitrary** ID number. For example, here's Jython and IronPython: steve@orac:~$ jython -c "print id(None); x = 123456; print id(x)" 1 2 steve@orac:~$ ipy -c "print id(None); x = 123456; print id(x)" 0 43 The fact that CPython ID numbers happen to look like memory addresses is an accident of implementation. But they aren't memory address: you can't dereference them, or allocate memory at a specific address, or do a memory dump. And there is no guarantee that CPython IDs will continue to look like memory addresses into the future. Maybe they will, maybe they won't.
&gt; I mean, this is already the status quo We introduce new standards to improve the status quo, right?
You got it. There's no mystery here. The CPython REPL has a slightly different way of handling lines than the non-interactive interpreter. BFD. And for the record: &gt;&gt;&gt; # This is Jython2.5 &gt;&gt;&gt; &gt;&gt;&gt; # This is IronPython2.6 &gt;&gt;&gt; &gt;&gt;&gt; # This is BPython &gt;&gt;&gt; So that's three different REPLs that keep the `&gt;&gt;&gt;` prompt after a comment. But CPython has behaved the way it does since **at least** version 1.5. However, the very oldest version I have, 0.9.1, behaves like Jython and the others. 
Yes, and this improves the status quo by making it possible for projects to publish Linux wheels on PyPI. Perfect is the enemy of good.
Doesn't work if your import command has spaces in it: doubleunplussed:~ $ import() { python3 -i -c "import $@" } doubleunplussed:~ $ import matplotlib.pyplot as plt &gt;&gt;&gt; &gt;&gt;&gt; plt Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; NameError: name 'plt' is not defined &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.argv ['-c', 'as', 'plt'] &gt;&gt;&gt; 
Wrong sub, perhaps? (Can't find the reference to "subliminal," though.)
use self.ARRAY instead in that list comprehension?
This is due to list comprehensions implemented as generators in Python 3. See accepted answer here: http://stackoverflow.com/questions/20136955/python3-nested-list-comprehension-scope
Yeah same here on nexus 4 fyi. Interesting read, I'll consider this for our to-be-developed app!
A minor point: don't use `return functools.update_wrapper(wrapper, generator_func)` at the end of decorator, use `@functools.wraps(generator_func)` to decorator the wrapper. Let me see if I understand... you want to compare this: def exponent_df(n): data = [] for i in range(n): data.append({'a': i, 'b': i ** 2, 'c': i ** 3}) return pd.DataFrame(data) with this: @make(pd.DataFrame) def exponent_df(n): for i in range(n): yield {'a': i, 'b': i ** 2, 'c': i ** 3} Is that right? Assuming it is, you save one line. How about this for a solution instead? pd.DataFrame([{'a': i, 'b': i ** 2, 'c': i ** 3} for i in range(n)]) I don't use pandas, so I'm not sure what arguments it takes. It might even take a generator expression instead of a list comprehension: pd.DataFrame({'a': i, 'b': i ** 2, 'c': i ** 3} for i in range(n)) I suspect that your make generator is an over-generalisation. You can't use the same function with two different types unless you duplicate the code: @make(pd.DataFrame) def func(n): ... @make(list) def func2(n): ... # cut and paste the same code I think you might be better off making the type an argument of the function: def exponent(n, type_=pd.DataFrame): data = [{'a': i, 'b': i ** 2, 'c': i ** 3} for i in range(n)] return type_(data) frame = exponent(27) # uses DataFrame by default frame = exponent(19, list) # returns a list I spell the second argument "type_" so it doesn't clash with the built-in function `type`, but in a function this small, that really doesn't matter. Just call it "type" if you prefer. 
/r/learnpython
Dictionaries, Lists and Objects are passed by reference. Other types are passed by value.
Maybe using the opensuse build server (it has an api for that) is the best way to handle this: it provides a reliable build server for linux(es). 
This seems interesting but I'm not sure I entirely follow what you mean. I went to the github page but there was essentially no other information. Are here any code examples you can link me to to show the benefits of using qtpy?
Answer already given, here is a simple alternative class MyClass: ARRAY = {1, 4, 7} VAR = set(range(10)) - ARRAY 
shell is hell
hmm, interesting. I'll take a look. Thanks for sharing
&gt; Say goodbye to real threading Do you need threads in a web app?
Exactly. I'd start with Think Stats, and if you like the author's style, you can move to Think Bayes.
I really wish Python's naming and scoping rules were clearer and more consistent.
This "shit" has potential to grow into something awesome! It's also a great learning experience
[removed]
If you are planning on releasing it open source, or don't mind buying a license PyQt is probably better. PySide is LGPL so it doesn't need to be open sourced. It supports reading XML ui files directly which AFAIK isn't possible in PyQt 4? I found these YouTube tutorials somewhat useful, if a little outdated. https://youtu.be/53oeJPKRttY
Hey, thanks for taking the time to address those two points! I hope you don't mind me adding your comment to my blog post because I think the information you put forth is very valuable. Also, thanks for all the hard work on Kivy, it's a great framework!
I tried my hardest to get into thinkstats and highly recommend against it. It's too terse for anything but reference text. I appreciate the author making it free, and really regret that I couldn't get into it. I recommend an opencourseware or udacity course, or just take a regular class
It's 50mb because it has to include all of python. If you write the same program in c or c++ or something the exe will be less than 1 almost certainly But do you really, really need that space? 
The purpuse of cython isn't to create a standalone c code. It creates code that is linked to the python library. 
Cython is for writing high performance python libraries and such. What you want is nuitka. 
That seems like a fair assessment. Though I'm still picking up Python, using the book as a supplemental learning tool in that regard is one of my main motivations.
Keep in mind that Odoo is not open source any more. With Odoo v9 they have switched to an open core model, where certain features (non trivial ones) are only available under a license.
In python3 does a regular for loop leak it's variable into the class in this situation? I think so, correct me if I'm wrong. How would you get around it, (if the set solution above wouldn't work)? My first guess would be making a class method that helps instantiate the variable, but that seems messy.
I did not know that. Thanks for heads up. 
&gt; A list comprehension in Python 3 uses a separate scope To be even more clear, a list comprehension uses a separate scope *except* for evaluating the iteration component. For example, in Python 3: class MyClass(object): x = 4 y = [z for z in range(x)] works just fine, but class MyClass(object): x = 4 y = [z for z in range(x) if x] throws a `NameError`. But this was all explained in anossov's [link](http://stackoverflow.com/questions/20136955/python3-nested-list-comprehension-scope) ; ).
I will just say this on last time for you, I am new to programming. I would love to see your code from the very first year you started.
So, as kind of pointed out, but just for the sake of clarification. Part of the reason this is happening is you included it in a class. If they were in a method, or set as global variables (not usually a good idea), they would work. So the following 2 examples will work in Python 3... Using methods: def testmeth(): array = [1,4,7] var = [x for x in range(10) if x not in array] print(str(var)) testmeth() As globals: array = [1,4,7] var = [x for x in range(10) if x not in array] I hope this helps
correct
Have you got stats on that? ;)
Doesn't this result in VAR being a set rather than a list as in the original code? If so then it can't really be seen as a solution...
This made me laugh a lot! All programs must end with America is great.
Yes, exactly. That's why we use gunicorn or uWSGI. So for web development we don't really care about threads or need them.
There was no specification of whether the intent was to have a set or a list. You can always coerce a set to a list using sort() or list(), this is really basic stuff.
 class Foo(): array = [1,4,7] var = (lambda a: [x for x in range(10) if x not in a])(array) foo = Foo() print(foo.var)
You can also write it out as a loop (yep, it's valid): class MyClass: ARRAY = [1, 4, 7] VAR = [] for i in range(10): if i not in ARRAY: VAR.append(i) or put it in a function, of course.
Are you combat arms? Be a lawyer
Chrome on a Nexus.
By default pyInstaller includes everything that your program imports. Packages like wxPython and matplotlib import all sorts of junk they aren't using. It's best to build an exe from a virtual environment or a fresh install of Python.
There is a nice python script that already does all this https://github.com/rg3/youtube-dl/
Just wanted to wish you luck--I did the same thing after 10 years in the Navy. I managed to get lucky and work at a small company as a field tech for their Navy customers, and was eventually able to move over into software development. As Dracunos suggested, /r/learnpython is a good place to start. 
wow! That's definitely not a "small command line program" as the author calls it. I don't mean to object with that, it's just kind of an insult to the code, I think. It's a super impressive project, and this is what I initially started looking for before I tried to write my own. Since one already exists, I'll just advise others to use that like you suggested! Edit: I mean 'insult to the code' to imply that the author is downplaying his own impressive work in that sentence, not to insult the code writer or the tool itself in any way.
I have saved the file to my home diretory with the .py extension. I then go into my terminal (I am on OSX), and run python keepassx2pass.py I receive the following error. Traceback (most recent call last): File "keepassx2pass.py", line 83, in &lt;module&gt; main(sys.argv[1]) IndexError: list index out of range I am trying to simply use this importing tool to transfer a keepassx database into this nifty tool called pass which I have already installed. I know I am probably way off, because I don't even understand where I would tell the script the xml file is that I want to import from. Perhaps it's in the script, I see a spot where I think that might be, but I tried putting my file name in there and it didn't work, any tips. Thanks.
Someone asked me how to do this in the comments of another thread so I figured I'd share this. This example shows two ways to convert a Dataframe to HTML and display it on a webpage: 1. Send the HTML thru Jinja 2. Return the raw text which can be called from somewhere else on a site (I was setting this as a variable in AngularJS) This example uses Flask, but the same general approach should work elsewhere.
Yes I do, @nsiblebot. However I'm about to get off work and get it up and running again- I shut it off temporarily. Give me an hour or so and it'll be ready :)
cool do you mind if I try throwing some exploit code at it? (I will be coming from the same username as I am here, and I wont do anything malicious)
Totally man, throw whatever you got at it. It's an experiment and it could only help me learn, right?
ok awesome, thank you, yes in researching and with your answer I can confirm that this is how it should be done, that said, I still receive errors. i will keep looking into it, thanks for your response.
Yeah just follow the flow in the program you get the line numbers om errors and search for it :)
hmmm, okay, I'm not sure I totally understand. I'm going to try and parse the above better as I am sure it's just me not getting it. But I certainly see what you mean about me not supplying the .xml for testing, this is what I am using to test in an xml file. "Group","Title","Username","Password","URL","Notes" "Root/Software","sample software","sampleusername","samplepassword","","" BTW, Thank you so much for all of this help. Lastly, this is the full error I recieve at present: Traceback (most recent call last): File "keepassx2pass.py", line 82, in &lt;module&gt; main(sys.argv[1]) File "keepassx2pass.py", line 78, in main for group in ElementTree.parse(xml_file).findall('group'): File "/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py", line 1182, in parse tree.parse(source, parser) File "/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py", line 656, in parse parser.feed(data) File "/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py", line 1642, in feed self._raiseerror(v) File "/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py", line 1506, in _raiseerror raise err xml.etree.ElementTree.ParseError: not well-formed (invalid token): line 1, column 7
+1 Will do
If I end up really wanting to switch I'd consider it. Currently the switch would only be for new projects
How about: import() { python3 -i -c "import $*" }
Np, there was a link in my first answer to a stackoverflow post. The first answer is quite extensive about sys.argv. Can't help you with the rest, but good luck. [Here](https://docs.python.org/2/library/xml.etree.elementtree.html) are the docs for the xml stuff. I am not familiar with the tree structure of the xml-file. Check case sensivity maybe (Group is not equal group), but invalid token in line 1 column 7 sounds like a different problem, since you only have 6 columns.
There exist libraries for that kinda stuff, but yeah, I'm afraid you'd have trouble figuring it out without at least some knowledge on neural networks. I'm not sure if I could do it right myself tbh.
I really think it was a curiosity to try something new that pushed me to asking. I have a few small projects in the pipe at work that are to be fit in between now and q3 where I will likely be a lone dev. That was why I was so interested in the speed. They are not going to get a ton of my time and was hoping to spare as much of it as I could if the "open box, import bootstrap, receive webapp" theme that I had been hearing was an actual reality. 
&gt; Backtraces in Python How would that differ from a stacktrace in java? Or is it just a recommendation because the language/ide is more prone to not alerting you to errors upfront? thanks for the input.
Thanks for the objective insight.
Most of what I end up doing these days is simple data visualization. Query a few million records and dump out some stats based on filters. Nothing super earth shattering. API programming sometimes for a bit of batch processing for other devs. Very little outside of the realm of CRUD and process.
Would an end user need anything installed? Could they export a csv file potentially? It's hard at my company to share information. People have excel if anything at all. It'd be nice to build something they could manipulate and export. 
I hadn't really considered RoR. I have heard so many horror stories about stability that it never really entered my mind. Have I been run off by lies and heresy?
from what I know, you can freeze with cython, but I'd be somewhat surprised if it'd be possible to completely avoid the python interpreter via that, as it still works with python objects and the such &gt; https://github.com/cython/cython/wiki/EmbeddingCython so yeah you still take the entire CPython interpreter into the exe, so the best bet would be to try and trim all the python packages that are getting pulled into the install (for some freezers, they just grab everything stupidly, which obviously causes massive bloat)
Given that `pip` supports installation from any Git repo, why is this necessary?
Let's say you do your main data analysis in IPython notebooks, build some predictive models, and you want to turn them into some sort of web application. [Here](http://raschkas.pythonanywhere.com) is a trivial example where I created a simple form field to enter a movie review, and the app predicts whether it's positive or negative. Anyways, there may be tons of similar (more useful) things you could do ... :) 
you got it! i was a little nervous when i saw your injections, until i combed through it and felt pretty secure about it :) thanks for checking it out! I'm pretty proud of it.
I used this to download like 130 defcon talks before the official torrent was available last year. It worked well! 
In that sense, I totally agree.
I know you don't understand. That's my point. You don't understand, and yet you're being a judgmental asshole. Kick bricks, son. This shit isn't okay to do.
But...but...you didn't understand what OP was saying. He didn't say "insult to code" he said "insult to THE code" meaning he thinks the original programmer did a hell of a job and is downplaying it by referring to his code as simple.
There is no technical advantage to that syntax, and it makes it harder to reload a module. I use "from" only when I know a function will be used a lot in an actual script, for clarity; but in the REPL, I just straight import.
The end user would just need access to wherever you're hosting the site and a web browser. Check this out: http://code.runnable.com/UiIdhKohv5JQAAB6/how-to-download-a-file-generated-on-the-fly-in-flask-for-python Pandas has a to_excel method that would make this easy, just replace the csv file in the example above with the result of the to_excel method.
&gt; virtualenv oh my bad and thank you for the reply 
Why should I switch to this from keepassx ?
This tool seems to allow me to send a notification but does it also let me retrieve existing notifications?
Sweet! I've been using ffprobe for this. It's not great, honestly. I'll try this out. 
No reason to switch of you like KeePassX. What I like better about pass and passpy is that all your data is saved in (encrypted) plain text files that simply are organised in folders. So the data is organised in an easy to understand structure as opposed to the complex database layout of KeePass. Another big plus for pass and passpy in my book is, that they come with a command line interface right out of the box. Last but not least, if you have some cool idea on how to interact with your passwords or want to have some application of yours access them, with passpy you could do that now and even in Python ;)
Funny you mention ffprobe, someone else mentioned it in regards to PySceneDetect. What command line options were you using, out of curiousity? Eventually I'd like to setup a comparison page of PySceneDetect versus the other alternatives. Also, a quick heads up, the default detection mode is threshold-based (similar to the ffmpeg blackframe filter), so use something like the following if you want to detect jump cuts between scenes, like the example link above (a threshold `-t` of 30 works well with `content` mode): scenedetect -i VIDEO.mp4 -d content -t 30 You can also add `-df 2` to downscale the video by a factor of 2 to improve processing speed (e.g. `scenedetect -i VIDEO.mp4 -d content -t 30 -df 2`). I've taken the liberty of updating the original post with this information, just as a kind of quickstart/use. And lastly, the `-l` argument might be helpful if you want a list of all scenes printed prettily to the terminal. Let me know how PySceneDetect works out for you, and feel free to share any other questions, comments, and feedback/suggestions you might have! :)
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
name_python_variables_like_this
"you wouldn't download the mall"
Jesus, fucks like you make me never want to post any OC. Seriously leave.
Direct link - https://www.udemy.com/learn-python/?couponCode=LIMITED
Interesting. I'll check out the Flask extension. I didn't even know that was an option. Thanks!
[You wouldn't steal a handbag...](https://youtu.be/ALZZx1xmAzg)
Have you read about MVC? It is one way of doing it. Separate your code in 3 parts. M, Model: your data, your logic, saving and reading files. Here everything can be done mostly with Python. You can add QT with decorators, but avoid QT attributes in your classes. V, View: you just show your data. It should have as much QT and as little python as possible. The view should not be allowed to change your model. It can only read. C, Control: Here it is also mostly QT, the Python code here will be from using your Model. Here you change the model state according to the inputs from the View. 
I know the concept. Though using a classic MVC pattern would conflict with Qt's own model(-delegate)-view architecture in a lot of ways. Besides that, in general I consider the MVC pattern to be more applicable to a language such as Java, where it provides a much needed structure. In Python, on the other hand, I think it often just means a lot of unnecessary overhead and boilerplate.
It makes it a lot shorter and nicer to write commands though.
I get that; but, why would anyone ever do that? You're assuming everyone uses the master branch of a Github repo for dependencies. That's simply not good practice. All of my dependencies are set to a specific version for Django projects or a range of versions for libraries.
It most definitely uses your code as a base. Apologies for not giving credit, but as I didn't attach a license to this script, nor post it for any other reason than sharing a small, horribly written, mildly useful utility, I have not given credit where credit may be due. I am not making money, I am not asking for praise, and just trying to share a tiny script I wrote that I found useful. If you'd like, I can mention your script in the Readme, but I didn't think it was necessary. If this project were to be larger, to have significant use by others, and if I were putting a license on it, you would surely be credited. Thanks for doing a lot of the work!
not a big deal to me .. i just remembered my script, thats it.. :)
happy coding, welcome.. :)
I've recently started writing a lot more C# using Visual Studio to make Kerbal Space Program mods. Auto completion isn't something I normally see in my professional life, writing mostly Python in Vim or some other text editor. But the convenience of having the IDE going into the API and pulling out the calling conventions, checking my syntax as I code, listing out the members of a class, etc. It all makes working with closed APIs so much easier.
PySide currently doesn't support Qt5 (and PySide2 isn't ready yet), and Qt4 is end-of-life. So IMHO, PyQt5 is the way to go currently. Making things work with PySide2 in the future should be quite easy too.
Better watch out for Paul Blart.
This would be better for /r/learnpython or /r/learnprogramming. Try calling type(n) and see what happens. Look at the [raw_input() documentation](https://docs.python.org/2/library/functions.html#raw_input)
i've read from former infantry guys that it's a good path. plus the patience you have will probably work wonders in reading long and boring contracts
From the [docs](https://github.com/docopt/docopt): &gt; You know what's awesome? It's when the option parser is generated based on the beautiful help message that you write yourself! &gt; ... &gt; The option parser is generated based on the docstring above that is passed to docopt function. docopt parses the usage pattern ("Usage: ...") and option descriptions (lines starting with dash "-") and ensures that the program invocation matches the usage pattern; it parses options, arguments and commands based on that. The basic idea is that a good help message has all necessary information in it to make a parser. mind=blown
Whooosh...
Any chance you could test it with this first page of the Django tutorial (linked in OP) and verify that it works for you? It works for everything I've tried except what I described in the original post.
Docopt is really cool but I personally find it a bit backwards. It's easy to work with you're guaranteed to have pretty proper documentation but it just makes for a pretty strange development cycle.
AWESOME!
Qt's MDV is another name for MVC. You can do it in many different ways. And it fits into python magnificently. Python's decorators are beautiful. You don't have to write boilerplate at all. It actually reduces boilerplate. I don't know how big is your app. In small apps, I tend not to split V and C very much, but splitting the M is always very, very good. It makes testing your code so much easier. Here's one example: https://github.com/wuerges/connection_monitor/blob/master/pycomon/gui.py https://github.com/wuerges/connection_monitor/blob/master/pycomon/tester.py The gui.py file has the View and the Control and the tester.py has the model. 
Emacs with Jedi has great autocomplete for Python. 
https://docs.djangoproject.com/en/1.8/intro/tutorial01/#creating-models Create the models defined in the tutorial, then instantiate a question model with `q = Question(question_text='whatever', pub_date=timezone.now())`, then try to autocomplete `q.cho[tab]`, which should auto-complete to (or at least suggest) `q.choice_set`. If that works, try to auto-complete `q.choice_set.[tab]`. I think that iPython is able to get it because it's a run-time environment, so it's not just analyzing the code, but running it. Maybe Jedi does something similar, but I think it's dropping the ball on this.
I'm using emacs (spacemacs) with anaconda-mode, which uses Jedi. It's good, but it's missing what I described in the original post.
It depends on the frequency with which you use the function. If you are only going to use it once or twice, prefixing it with the module will the the reader exactly where the function is from, without them needing to go to the top to read it. Not necessary if it's a common function / module. And yeah, if you are using it a bunch of times, then it's better to import it directly. 
The reason iPython shell will always be better is that it is actually running the code. Or rather, when you type in "my_var (dot)" your variable already exists. So it's easy for iPython to just run dir(my_var) in the background and get all the options. With other autocompletes, you haven't actually run the code yet, so they have to make do with scanning the file and trying to guess. They could try and run code up until that point, but having some back-end unintelligently grabbing code and running it would probably lead to some bad side effects. Not to mention what happens when you edit the file out of order. Yeah, I do data analysis in Python, but Web dev using C# and I'm always missing the nice static type guarantees and code completion. Maybe as type hints become more mainstream, autocompleters will be able to get better. 
&gt; Make Python code from either, Pygame, Pyglet or Kivy, compatible with JS and HTML5 Canvas. That would be incredible! A canvas module sounds more realistic, though.. But what do I know.
I believe C# either already has, or is in progress, of developing a REPL. Now that it's cross-platform, I'm kind of hoping that the data analysis field starts switching over to it. I'd start using it myself, but Python just has a much better ecosystem right now. Though, the other positive is that Python's simplicity makes it more attractive to people who didn't learn any computer science and are now trying to add some data analysis to their work flows. Seeing types, and dealing with things like Interfaces (instead of duck-typing) doesn't really bother me, but I learned all this stuff in classes years ago. I wonder if that will keep data analysis grounded in less verbose languages as it's typically a field where programming is not the main focus for many of the practitioners. 
Once I thought about it I figured that might work better. We would still need some way to transfer 2D physics over, like Pymunk. Or at the very least collision and game logic code.
Do you have any recommendations for ways to trim the packages that aren't really needed? I tried it in a very raw way by building to a folder so it had exes and dependant files in the one folder. Then I ran the exe and tried deleting files from the folder and if Windows didn't come back with "This file is being used by another program" then I'd deem the file trimmable.
I think a hello world script compiled to a single file exe with size 7mb. My one is so big because the script imports a lot of heavy modules (numpy, pandas)
Start with guestfish, libguestfs and guestmount. https://www.google.ca/url?q=http://libguestfs.org/&amp;sa=U&amp;ved=0ahUKEwiikIfqzcDKAhUhk4MKHaVFApUQFggNMAE&amp;sig2=CMgrO5ZSX6HIID03SslOmQ&amp;usg=AFQjCNEUD4o3JvRFRSutpBuiB7zPsbYDFQ This link shares how to read a guest disk residing in VMware Vcenter https://rwmj.wordpress.com/tag/guestfish/
The "else:" line should be indented more to be in line with the "if:" statement. Also as already stated, the missing ":" at the end of the "if" line
This is the error I am getting: Traceback (most recent call last): File "python", line 4 else: ^ SyntaxError: invalid syntax
The print line should not be indented, it is not part of the number function. def number(x): if x &gt; 5: return 'I am read!' else: return 'I am not read!' print number(6) 
The graphics probably can best be handled using an existing JS library manipulating the HTML5 canvas directly and efficiently. This library could be wrapped in some simple Transcrypt classes to give it a Pythonic interface. The game logic could be very well written in Transcrypt. Note that an important design goal of Transcrypt is to benefit from existing high quality JS libraries: Anything good that's there we shouldn't reinvent. fabric.js added as Python module to the distribution 
Thanks, that seemed to work :)
In PyCharm I use type hinting in docstrings to improve autocompletion, and I am not below adding superfluous accessor functions to get completion to behave.
This should be in /r/learnpython.
Basically everything uses Jedi (except for PyCharm where I believe JetBrains developed their own).
Link gives me error 403
You could just write def number(x): if x &gt; 5: return 'I am read!' return 'I am not read!' 
Strip the quotes from the parameters.
Just for completeness, here's the code that should work def number(x): if x &gt; 5: return 'I am read!' else: return 'I am not read!' print number(6) Btw. you may have noticed that Python is extremely crazy about indentation and spaces. Make sure you always indent by 4 spaces; or make sure that your text editor expands tabs to 4 spaces when you write Python code.
Start with this: http://anh.cs.luc.edu/python/hands-on/3.1/handsonHtml/io.html
Yeah, it's a really lovely interface.
Thanks man
 help(sum) #&gt;&gt;&gt; Help on built-in function sum in module builtins: #&gt;&gt;&gt; #&gt;&gt;&gt; sum(iterable, start=0, /) #&gt;&gt;&gt; Return the sum of a 'start' value (default: 0) plus an iterable of numbers #&gt;&gt;&gt; #&gt;&gt;&gt; When the iterable is empty, return the start value. #&gt;&gt;&gt; This function is intended specifically for use with numeric values and may #&gt;&gt;&gt; reject non-numeric types. #&gt;&gt;&gt; The second argument is the `start` parameter. `sum` shouldn't be used for non-numeric types (it's particularly slow for them), so this is bad code on that front. Much simpler, though, is from collections import Counter from itertools import chain token_counts = Counter(chain.from_iterable(documents)) unique_tokens = {word for word, count in token_counts if count == 1} If speed is needed over clarity, this **might** be faster unique_tokens = token_counts.keys() - (token_counts - Counter(token_counts.keys())) Likely even faster is token_counts.subtract(token_counts.keys()) token_counts.subtract(token_counts.keys()) unique_tokens = (-token_counts).keys() 
woah thank you okay will implement now
I think the idea of wrapping a JS lib for python use is the best idea so far. 
I can't even see how this would run. What is the documents variable? What type and value? Doesn't the set() method guarantee unique members? If I had to write what I think this is supposed to do, here is what I would use: tokens = documents.split() #assuming documents is a string unique_tokens = set(tokens) Or if documents is a list of file names: tokens = [] for file_name in documents: read_file = open(file_name, 'r') for line in read_file: tokens.extend(line.split()) unique_tokens = set(tokens) I haven't run this but that's how I'd go about it. 
When giving tracebacks, copy the whole thing (and indent it four spaces to get `code formatting`).
could probably pass a modified python_path. some freezers pack the standard lib into a zip, and things can just be pulled out of that zip easily enough. it really depends on method, and honestly I don't got enough info about any of them personally 
Thanks, I forgot that `with` should be used to open files. What exactly is being accomplished by this code? I'm not sure what this is trying to do. 
Python 3!
It's finding those elements (of the hashable type) that occur exactly once within exactly one list in `documents`. It does this by first flattening `documents` into `all_tokens` (with `sum`, sadly) and then finding those elements in it for which `all_tokens.count(element) == 1`.
Are for-in and for-of loops gonna be / are they supported? same for labels too. also https://www.python.org/dev/peps/pep-0511/ might interest you, probably worth keeping an eye on perhaps
I've looked into the following transpilers: PyJs, Py2Js, RapydScript, Brython, Flexx, PyPyJs. My estimation is that it won't be easy to merge Transcrypt with any of them, since the core of it is quite different, due to the combination of multiple inheritance, bound function assignment and the wish for lean downloads and readable JS. However sharing certain libraries will probably be possible. I haven't looked into that yet.
I absolutely enjoy the idea of wrapping a good 2D Game oriented JS library into Python, that would instantly be very popular if it was made to deploy simply.
&gt; light side That's racist.
I had largely thought of the Python lambda as a rather weak, limited-use system which could only really handle certain single-statement functions, as opposed to JavaScript anonymous functions which are as powerful as named functions. This contrasted to my few dabblings in Scheme, in which I had seen its lambda structure to be actually pretty powerful, on account of an entire program being an expression, something which is not the case in Python. It occurred to me after a while that if I included multiple expressions in a list, and used a [-1] index after it, I could imitate Scheme behaviour and include multiple expressions in the body of a singular lambda. What I could do was still limited to the syntax subset of expressions, but allowed me to do multiple things in succession. The exercise basically snowballed from there. Not something I would do for serious coding, needless to say.
Call it a "compiler" instead of a "transpiler" there's no need for the new jargon when the old works already.
It's not new jargon
That's black.
3.5
This just sounds like a genius idea.
You should look at packaging with conda. It takes packaging with setuptools and wraps it with simple commands for building, testing, and installing your packages. http://conda.pydata.org/docs/build_tutorials/pkgs2.html
You see this all the time in games that use python for scripting, don't want people to reverse your scripts do this.
You mentioned that this wouldn't be alone in the field. What other options do we have if we want to compile our pygame code to JS/run it in a browser? I've been reading about Pyjsdl, among other things, but this is all fairly new to me.
I imagine you could make a fair approximation, but I doubt you could pull off a 1:1 -- there are just SO many NumPy methods.
You're right, I should've posted the question of there. I realized that only shortly after I'd asked. I'll remember that next time.
Sorry, I'm running 2.7.10. Would it make a difference if I used 3.5.x? I think my code should be cross-compatible, or maybe with a few very minor changes.
I don't think it will make much difference between 2.7.10 and 3.5.x I edited my original post, btw. maybe thats helpful advice for you. 
I have a question when it comes to using cpp libraries (such as pillow), what happens there?
you didn't call `read_file.close()` so your code will produce a bunch of dangling file handles. that will, at minimum, cause a short term memory leak (until the function body closes and GC can clean it up when their ref count goes to 0). 
&gt; I need my web app to be able to use a VPN. Does this mean your backend server needs to communicate over VPN, or your end users need to access your app over VPN? In either case, it shouldn't matter. If your end users need to connect to a VPN, they do so, and the app should work with no changes. Similarly, if your backend service needs to communicate over VPN, make the connection at the OS level, and your app should work with no changes. Your system may be different; but, it has been my experience that the VPN is simply treated as another network adapter. Once connected, network requests work without needing to change my applications.
ok, this is cool, now how can I have it tweet directly to list and/or hashtags as part of a discussion? I'm in like the very early stages of python so I'm playing with your code as one of my tutorials to learn. :)
I can't make the connection at the application level? Or alternatively, is there a pythonic way to do such. I have my torrent program, for instance, going through my vpn, but not at the OS level. I was hoping to achieve similar functionality. 
You most likely can. You'll need to dig into Python networking code/documentation to determine how to send requests to a specific adapter/connection.
Thank you man. I'm excited to get started learning, I've been reading Python for Dummies, but there is nothing out there like breaking down a script and being able to have someone explain things into lamen terms for you and assist you. I think I'm going to give your script a full blown try with modifications of my own over time. I'll definitely post on the twitter profile where credit is due. I'm hoping to build a twitter bot (I wanted instagram but they are a pain to get out of sandbox mode with) that will one way or another help generate a following. If I could figure out the best and fastest way to use a bot to generate followers that would be great. I plan on then using it for marketing (not spam) purposes. I'd really like to work with someone on this project so if it's something you'd be interested we should exchange some more information. I think it could be a fun project and you've already laid some ground work.
I'm always down to help! I don't have enough people with which to work on Python projects. If you want some more quality reading, check out *Automate the Boring Stuff with Python* by /u/AlSweigart. Also take his class on Udemy, which I believe is currently on sale for $15. The CodeCademy course isn't bad either. In my opinion it's never a bad idea to do several intro courses, rather than just one and moving on... that way you can really get an idea of the foundation of the language from multiple sources. If you have any cool ideas, send them my way along with what exactly you'd need help with. I'm always looking for new projects to tackle, so if you'd like to get some stuff done let me know. At what level of learning would you say you are sitting at the moment? Do you have anything I could take a look at?
You definitely should not worry about optimizing this. In general, never try to optimize (beyond picking the right algorithms etc) until you are done writing it and have discovered it's too slow. Once you're there, you should rely on profiling to figure out what to target to speed up. Also, it is most likely the case your program is not being compiled at all, but rather interpreted. This means that it's being stepped through line-by-line by the interpreter, so there's no opportunity for doing this kind of optimization. It would just evaluate the conditional each time it saw it. (This is a simplification but correctly captures the spirit of the situation) Also, as a side note: your proposed optimization would not necessarily be correct for a hypothetical compiler to do. For example: &gt;&gt;&gt; True, False = False, True &gt;&gt;&gt; if False: ... print "see?" ... see? &gt;&gt;&gt; 
You should add a list of notable missing features (even it it'd be empty).
Well, the [new pypi website](warehouse.python.org) is written in Pyramid. I think that speaks to its effectiveness. 
When I began writing C# for fun in Unity, I fell in love with a static typed language for that reason. So much autocomplete and very clearly structured interfaces. ...then I started using JSON via REST and immediately missed Python.
&gt; PyJs, Py2Js, RapydScript, Brython, Flexx, PyPyJs Is there anywhere a comparison of all these projects (plus your own)?
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](http://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 2454 times, representing 2.5311% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cz9onwv)
Good point on using wraps decorator. My example is simplistic, but you can of course imagine a situation where a generator expression wouldn't make sense. For example, there might be some set up before the loop. And you're correct also that this would be undesirable in the case where you might ever want the data in more than one form. More generally, I think you're right that its an overgeneralization because it doesn't really abstract much away, and it could definitely confuse some readers. However, it also prevents the creation of an unnecessary temporary data structure (the list called `data`), which has performance benefits. Of course, readability is more important than performance or else I wouldn't be using python. pandas is used for representing data in a way similar to R. It provides useful reshaping functions.
This is brilliant! 
I know how you feel. I started a similar project until I found youtube-dl. I've since abandoned that my project because youtube-dl is superior in every way to anything I could have ever coded myself :(
It was posted on r/The_Donald which is the real Trump supporter subreddit. Thank you for keeping us in mind!
Mypy is a work in progress compile-time type checker. However it doesn't cover many frequently used libraries such as numpy and flask. There are also several run-time type checking packages that use decorators and one (couldn't find it) that uses the py3 annotations.
This is like looking at a train wreck... It's powerful, unexpected, unique, and I can't look away. Bonus terrible points for it being a wall of text with no formatting of any sort for readability.
no_problem
Can you explain what was going on here?
Come on, you can't say it wasn't python art XDDDDDDDDDDD 
`int()` doesn't round, it truncates (discards anything after the decimal point; effectively the same as always rounding down), so for example `int(1.99999999)` is still `1`. This is similar to the behavior of casting a floating point number to an integer in other languages (Java, C++, etc.). The [math](https://docs.python.org/3/library/math.html) module provides functions for rounding up or down, and the builtin `round()` rounds in the traditional sense.
I saw a comparison somewhere, forgot where. Transcrypt wasn't yet in. 
If they're distinct forms, they probably ought to 'POST' to different end-points, and thus have different 'views'. If they have to be posted to the same view, then the `name` attributes of the various form elements would have to follow some sort of naming convention. eg. Form 1's name input: `name="form1__full_name"` Form 2's age input: `name="form2__age"` Just some sort of chosen convention. This would then be used to access and organize the POST variables in the view.
Every language I've ever coded in has the same behaviour. What language did you use that rounds instead of truncating?
Neat!
try pandas
 "in the command line" always makes me think of the environment, so go ahead and try combinations of `sort` + `column` `column -t` is a good one. 
May be pretty table. .?!
This subreddit is for Python programming language related posts only. Maybe try it on programmerhumor. 
[removed]
Note that this behavior is inconsistent with integer division behavior: &gt;&gt;&gt; -3 // 2 == int(-3 / 2) False &gt;&gt;&gt; 3 // 2 == int(3 / 2) True Because integer division truncates toward -inf (like most "mathy" programming languages), while `int()` truncates toward zero (like the C family). And to add insult to injury `math.fmod` follows C rules, while `divmod()` and using // and % with floats uses Python rules. Programming is hard, let's go shopping!
Because when I do Integer division, I'm expecting an integer usable item out of it, I'm not expecting a float to come out of it after being treated with the rules of integer divisions. Just as I don't expect two ints in an integer division to result in a float. `type(3//2)` &gt; &lt;class 'int'&gt; `type(3.0//2)` &gt; &lt;class 'float'&gt; This trips me up at times, because I _expect_ an integer division to return an integer, not a float treated to the rules of float. Because: `type(4//2)` returns `int` while `type(4.0//2)` returns `float` . It's about expectations, When I do integer division, I _really_ expect integers back out of it. 
I think the advice should be don't process multiple forms in the same view. You chould have a search form and a new content form on the same page, but are handled by separate are handed by separate views.
Why would one need an ECS?
I'm the author of AsyncSSH. Thanks for the kind words! I'd be happy to answer any questions you have about it.
When I run my script, the output is some data value that should be displayed in a tabular form in the shell itself.
Certainly. Though it protects you from corrupting your system, possibly rendering some (python) applications unusable, after changing/overwriting some libraries that are essential to those other applications.
`pip install --user`
That's racist. 
tabulate (plus pandas, depending on what you actually want to do with the data)
I'm guessing this isn't in any way official. It seems a little disingenuous to call it "python community". 
Pandas
Not sure why you keep saying this. Form.prefix has been around since before 1.0. The only thing that was added in 1.9 was the ability to specify it on the class definition, rather than just on instantiation.
It was founded from the group on the official python-community mailing list for a more direct communication link - so not technically official - that is correct. I'll add a top level comment on this.
NOTE: This isn't an "official" PSF sponsored community, it's a fork of many members on the python-community mailing list (and has grown to now include various meetup location groups aas well). Sorry for not considering that it may be misleading on accident!
If you need precision and consistency in your use-case and keep getting confused by all the conversion rules, just use the [decimal](https://docs.python.org/3.5/library/decimal.html) module and be done with it.
I'm still learning python.. what's wrong with the code?
Pros and cons to installing Python 3.x from brew instead of downloading it from their site directly? Also does pip track updates to packages I've downloaded? 
I'm still learning python as well, but this might be helpful for what you are trying to do: https://automatetheboringstuff.com/ There's a free and paid version (text-only vs. video).
Homebrew, npm, ect. Makes installing software a breeze. Being that pip now comes packaged with python3, updates seem to be applied quite rapidly now.
I would like to have one good supported library instead of bunch of libraries maintained by one person. It is open source so you can have your commits to one project. You dont need to start at green meadow again and again :(
Homebrew is great for installing/updating/removing packages and managing dependencies I usually install Python(3) with brew and install python3 packages with pip
There already is a python community - #python on Freenode IRC server. Why the need to meet on another platform? We have #pyramid, #django, #flask and all others with their creators and core teams present all the time.
`pip install --user`
&gt; In this, all months are taken to be 30, and the year with 365 days. I think that's the part he's saying is arguable
https://docs.python.org/3/library/index.html
XDDDDDDDDDDDDDDD 
Thats fine, I'm just pointing out there is a very active and probably "best" channel already. And by "best" I mean that people involved in many prominent projects are already there so why look further? It is also an open platform.
The program I already made does that already. What I was asking for was how to go about displaying the results to the user on a single line. Meaning if the user enters: 600 days then instead of displaying 600 days is equivalent to 85.71428571428571 weeks 600 days is equivalent to 20.0 months 600 days is equivalent to 1.643835616438356 years It would display: 600 days is 1 year, 7 months, 3 weeks, and 4 days.
This subreddit is for things related to the programming language Python, not for things related to snakes. Your comment has been removed, but if it's cute enough, you might try posting to /r/aww
bloody painfully dry read though, its nice to have a clean example
There are different strategies, I'd say the most common one is by using the `os` module. E.g., Create a simple directory &gt;&gt;&gt; import os &gt;&gt;&gt; os.mkdir('some_path/new_dir') Create multiple levels of directories &gt;&gt;&gt; os.makedirs('some_path/another_new_dir/new_dir')
"[Disclaimer: Only do this if you hate yourself and the rest of the world.](https://github.com/kragniz/json-sempai/tree/master#id2)" Thank god, was worried.
Yes? That I'm perfectly aware of, and using as an example in this case. What I, as a developer, DO NOT EXPECT is that a term called _Integer division_ Would return a _float_. When working with data where type matters, I _expect_ the result of an _integer_ division to return an _integer_. I do not expect it to be a _floating point division treated as integer_ . However, the _python3_ manual doesn't call it _integer division_ but _floor division_ which is, subtly different. So when /u/xXxDeAThANgEL99xXx and others call it "Integer division" this causes even more frustration and annoyance. TL;DR; Integer division should return an int. Flooring division should return a staircase. 
Gradual typing is a welcome advance towards static typing. It's hard to say it's the best of both worlds. You still have to interact with lots of dynamically typed code, with the disadvantages that entails. Also, not all type systems are alike. The devil may be in the details. Is the type system expressive? Can I have type inference? What kinds of invariants can I check? Will I reap the performance benefits of the static types?
My company is sold on this. It is now mandating notebook formats for analysis. Transparency is the main aim.
If you could restructure your modules your package MIGHT come in handy... no? I mean that following example would work: file1.py: def my_func(): return "foo" file2.json: {"tools": "file1.my_func"} file3.py: from jsonsempai import magic from file2 import * print(tools.myfunc) ...just in case you get bored... ;) 
/r/emacs
No, there are glitches on some zoom level on inkscape (which I used to export the png). There was no glitch w/ firefox but I couldn't zoom enough. (Btw, if someone knows why inkscape does that, I'm interested...)
/r/doyourownhomework?
Pycharm is the best one I encountered.
Why is it such a terrible thing?
extracting a function?
Care to explain how? Docstrings come in a variety of styles and many people don't see a particular editor as the solution to language problems. I think pycharm is a fine editor, I recommend it to novices frequently, but personally I prefer pure editors that can be extended easily, like vim, emacs, and sublime. My editor can provide great autocompletion, static analysis, and inline docstring displays just like pycharm can, but it isn't the solution for large distributed teams using different editors. These features should be a standardized part of the language, especially since it allows you to inspect functions at runtime easily to do metaprogramming, one of my favorite sledgehammers when I see a thumb tack. 
Many text editors meet all those criteria. Are you sure you know what an "IDE" is? For a completely cross-platform text editor I like Geany. Sublime Text is also very popular. 
Sublime Text 3, I'm working on a plugin to allow for better/cleaner documentation. But as is, sublime is amazing.
Related to David Beazleys talk, where he did a live coding demo of how to import XML files?
By returning the result truncated into an integer.
Py2Exe can do this but its not supported using python 3. The way it does this is by essentially zipping all the DLLs into a single executable and unpacking them into a temporary folder when you run the program. As that is pretty hacky other python to exe systems don't support it. What you can do is use IExpress to create a self extracting zip which will then function like an exe. In the future /r/learnpython might be a better place for questions like this. 
Tying a language to an IDE and using docstrings which have no standard is in no way superior to this. In fact, it's completely useless to anyone who doesn't use that docstring standard to pycharm.
That would only be a problem if it is meant to be used as a module. Just like what he was saying
Your site has dodgy CSS on mobile causing images to be stretched.
'ugh..' MRW
Your system object takes 3 arguments but only uses 2? The init method also calls self.set_up which doesn't exist. class System(object): def __init__(self, eventmanager, entities, ecs): self.ecs = ecs self.set_up(eventmanager)
Hey there! Please check out /r/learnpython for posts like this; one of the few rules we have is to disallow posts asking for help and suggest that people try over there.
It seems like there might be a lot of gotcha's and a lot of little things to unit test. Do you really want to test every function on whether it does the right thing when you feed it a string, a tuple, a list, etc., when It should only ever work for integers? You can test to make sure that an integer is being passed and then throw an exception, but again, it's much less complex to just define something as an integer and let the compiler throw an error before any values ever get passed.
&gt; a for freezing python code into an executable for distribution. But I'd like to know if it is possible to merge the dependancies with the .exe so it is truly a single-file-distribution? &gt; &gt; I have tried with a program ca No, it would have to replace Nuitka - it would be slower. 
Why would you ever use file extensions? Check the mime type of the file, only windows actually reads the extensions to figure out what a file is. You also don't need to maintain your own list. Just look for image type, or video type, etc. Better yet (psuedo code since I'm on a phone): find . -type f | while read file; do case $(check mime type $file) in Image) foo ;; esac done
Any reason you aren't using a hashmap for the pool so these lookups are O(1) instead of O(n)? Maybe memory could be a concern, but I don't think so. def get_id(self, Search_ID): for entity in self.pool["default"]: if entity.id == Search_ID: return entity return None If you do that, this def exists(self, Search_ID): if self.get_id(Search_ID) is None: return False else: return True becomes def exists(self, Search_ID): return Search_ID in self.pool["default"] and the original function becomes def get_id(self, Search_ID): if Search_ID not in self.pool["default"]: return None return self.pool["default"][Search_ID] Also, if "default" is hardcoded for the pool, why have multiple pools? It's somewhat confusing.
* don't store bins in git repo (i.e. dist/*) * project structure needs work -- checkout cookiecutter * keep coding!
No. This is not how the python community welcomes newcomers, but /r/python is not the sub for newcomers to post half-baked projects. OP should probably checkout /r/learnpython. This is the sub for more 'kind' feedback. Initial peer review goes a long way as well. I usually have 2-3 peers review code prior to /r/python submission. Whenever I submit to this sub I am looking for scathing curt feedback. I don't know if this is correct, but it's kinda the nature of the industry ATM. 
I instigated a nice discussion about sudo pip installation
Can you give me an example of "extract to a function" because I think we aren't on the same page as far as what you mean
Python is not moving towards static typing nor is that the intent of type-hinting. It's a feature intended to be used with linters. Python remains and will remain dynamically typed.
&gt; /r/python is not the sub for newcomers to post half-baked projects. Fair enough. I would not have been able to tell from looking at its front page.
Awesome, I wish I had a job that had anything to do with my skill set... If you ever have any Python-related projects you'd like to work on, let me know.
&gt;when It should only ever work for integers [You should not write a function/method that only ever works for a specific implementation of a type in the first place, that would be a poor abstraction.](https://en.wikipedia.org/wiki/Liskov_substitution_principle) &gt;You can test to make sure that an integer is being passed and then throw an exception This defeats the purpose of using Python, doesn't it? Python will throw an error if something doesn't implement the behavior you expected it to. If something does implement the behavior but is only usable with code written for its specific implementation of the behavior/interface then you have poorly designed abstractions. The same thing could happen in a statically typed language by misusing interfaces. Static typing doesn't really help here anyways.
Try [argparse](https://docs.python.org/3/library/argparse.html) for handling command line arguments. It will handle weird edge cases that you won't have thought about, and as a bonus it does validation and automatically generates usage (i.e. `--help` works). File extensions are a fallible way to figure out file format. If you have an audio file named `picture.jpg` you'd hope it would still be categorised as audio—but with your current code, it won't. Take a look at https://github.com/ahupp/python-magic. While I'm here complaining about file extensions, I would also like to complain that Windows' default of paying attention to file extensions _but also hiding them_ is one of the worst design decisions in the history of bad software design decisions. `boobs.jpg[.exe]`? Enjoy your virus!
This sounds like something you could do with my more general renaming library (shameless plug): https://pypi.python.org/pypi/aka/
Well for one thing, if you're going to add the complexity of needing to read up on a module and understand what it's doing and why, there better be some functionality to make it worthwhile. That is not worthwhile. It's a whole module that basically does this: import json with open('tester.json') as f: tester = json.load(f)
 with jsonsempai.imports(): Disappointed that this isn't `.notice()`.
I've used it for a couple of "real" projects at work. I like it because it's easy to run unit tests, work with virtual environments, and get reasonable code completion. I'm also using emacs, and I like what I see, but I have to say that PyCharm is definitely a very good quality tool and I will be sticking with that for now. 
Creator of the [KivEnt](http://kivent.org) game engine that also runs on an ECS. Here is how I'd make the pitch for why an ECS becomes useful: When it comes to large, real-time systems like visualizations (includes games but could also include other categories such as real-time data applications and so on) architectures that favor composition over inheritance (such as an ECS) have become popular because that address a few problems: 1. They allow you to easily remix and reuse the logic you have already created to create new things. Since you have focused on building parts that perform discrete functionality, any potential 'feature' of your application is just some combination of the discrete parts. You sort of get all the permutations for free. All the possible permutations that you have not yet implemented as actual realized objects in your game are just waiting for you to do so. This is largely designed to solve the 'diamond' inheritance problem that comes up a lot when you beginning trying to mix the behavior of your game objects to get the most bang for your buck out of your existing work. 2. It is an efficient way to think about single processor real-time systems such as games. An ECS forces you to keep the data associated with your game objects separately from the code that processes such data. This turns out to be a hardware friendly approach to building things. Essentially, when it comes to performance in a complex real-time simulation, we are mostly limited by the cache friendlyness of the process of getting the disparate data that makes up all our game objects, finding the data about the specific objects we want, and then having the specific logic we want performed on those objects. The more everything is previously lined up in memory, the faster the CPU can eat through it, the more objects we can process in the .016 seconds that make up a single frame of our game. 3. It matches the loosely coupled nature of games and other real-time simulations really well. For instance, rendering an object on screen, we really only care about its position on screen and the vertices that make up that object. However, to determine its position on screen we may be running some physics calculations: These calculations depend on some other properties of our game object but do not care about the rendering at all. Rendering and physics do not need to know about each other at all, but both do need to touch the position of an object, one to read from it and the other to write to it. When you begin to add in all the different types of data that make up a real-time visualization: models, sounds, textures, more ephermal things such as size and shape in a physics situtation, not to mention all your made up simulation governing code (such as stats, player input, etc) the separate of concerns forced by the ECS gives you a much clearer, easier to optimize picture of what is actually happening in your simulation. If anyone is interested in reading more, my favorite introduction to ECS is [here](http://t-machine.org/index.php/2007/09/03/entity-systems-are-the-future-of-mmog-development-part-1/), 5 part blog, 1st part linked to. If you are used to building distributed web services with relational databases, some of the concepts used in designing ECS code and such systems dovetail a little. The biggest different imo is that the ECS is designed for short term storage and calculation over the life time of a single run of the application with a much 'stricter' definition of real time (.016 second response), where as the distributed web version is designed for long term storage and a looser definition of real-time (.5ish seconds is an ok 'real-time' response). 
I don't know if you could consider a snake cute
True, but I'm pretty sure Bunch has a better implementation of that. It even has it's own methods to convert straight from JSON. I'm not sure it's still maintained though. Edit: I guess the new fork is called Munch.
Good catch, thats old code
Moving from a straight hardcoded list to a dictionary actually sped up the application by a significant amount since the operation is an intersection of sets rather than an iteration
Ah, sorry, my mistake, I was browsing on my phone earlier and it was hard to tell what was going on. However, how would you suggest temporarily removing a component? `delattr` does exist, but I find it ugly to use, and I would have to reconstruct the component in order to reimplement the behavior (I can't just store a pointer to it like `tmp_ptr = entity_x.pop_component("Render")`). Basically what I'm trying to say is that an Entity in a traditional ECS is just supposed to be a bag of data, right? However, you're turning the Entity into the actual data itself.
&gt;Really? Is it poor abstraction to have an on/off switch that only accepts a boolean? [Generally you can use a list, string, tuple or an int in functions that are expecting a bool in Python. So yes it would be.](https://docs.python.org/3.5/library/stdtypes.html#truth-value-testing) &gt;And you want to code every function that deals with a string to know how to handle tuples, lists, integers, booleans, etc.? No. You simply don't make functions that deal with strings, you make functions that deal with objects that act like strings. &gt;[Pythonic programming style that determines an object's type by inspection of its method or attribute signature rather than by explicit relationship to some type object ("If it looks like a duck and quacks like a duck, it must be a duck.") By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). Instead, it typically employs the EAFP (Easier to Ask Forgiveness than Permission) style of programming.](https://stackoverflow.com/a/1952481)
&gt; Argument seems to be "static typing is good because it lets me get away with not doing basic testing." That's a really interesting argument. I personally much prefer static typing to lots of unit tests, but I don't think it's one or the other at all (the article doesn't mention this, but writing unit tests in rust is reallllllly easy and requires no extra modules). &gt; trade offs with static typing (additional syntax Consider this - what takes longer to type, good unit tests, or the type of an object (which, in rust, is usually inferred for you)? Regardless, for me, that's the *least* of why static typing is so critical to robust software. I do not view it as a replacement for unit tests but an aid. Static Typing allows you to reason about your program - you can easily deduce what data is where and how it will behave, how you can interact with it, etc. It's a lot harder to reason about code without types because... you just have variable names and no information about the content within. &gt; Optional static typing (only use it when I want the speed benefit) seems like a good approach. Well, if it's optional, you don't get a performance benefit. As soon as your types touch an untyped interface, you lose guarantees that they're going to be anything you can expect. That's why Python's optional type hints are useful for linting and that's about it - they can not be used for optimizing the code or to make guarantees.
Looks neat. A few things.. Creating entities should probably assign unique ids all the time. I don't see a case where you would need to specify an id explicitly for an entity, and is asking for trouble. Also it returns none if I give it a wrong Id, where this operation should raise or otherwise fail. It would be nicer to perform operations directly through the entity class without touching core. Eg. A static method in entity for creating a new entity? Also, I find it awkward I should have to add a component to an entity through core, rather than through the entity itself. Looks good!
&gt; Really? Is it poor abstraction to have an on/off switch that only accepts a boolean if by boolean you mean only the literals 1 and 0 (or the constants True and False, which are aliases for them, try `True + True` in your repl), then yes it would a poor abstraction. if you mean accepts any object that implements `__nonzero__` so you can call `bool(obj)` on it, then no, its not a poor abstraction. what I just described is the Pythonic approach to duck-typing, and its how the language is designed and intended to be used.
This whole talk opened up Python to me in a way I'd never through about programming languages (never took a CS course, just stumbled in to a career of development): https://youtu.be/sPiWg5jSoZI?t=2h2m50s 
Imo its too magical. I'd be annoyed if I was supporting someone else's code and I came across shit like this. It just isn't immediately clear what's going on and there is no benefit, only confusion
Yeah
Oh, my mistake on that one. I didn't see tempID on line 33 for whatever reason. There's no real reason to use tempID instead of just changing line 28 to ```Entity_ID = len(self.pool["default"])+1```. It leads to extra code (you could lose line 31 if you made that change) and gains you nothing but more difficult to follow code IMO.
There's "you shouldn't do this because it's bad programming practice" and "you shouldn't do this because it's wrong and will cause unexpected side effects". While I agree with your statement, it's the former. The issue with mutable defaults is the latter. Also, there are valid reasons to modify the state of something - like if the copy is expensive (large list) and the function is explicit that it alters what is passed in.
Weird.... what's happens when you run in IDLE? Do you get an error message at all?
There's a few reasons. It creates "needless" magic. I've got some sympathy for the author on this. If the syntax is better, I think it's worth doing. And so long as the magic is neatly bundled up and robust - nice. My dubious reaction was for a different reason. Serialisation formats grow and die like empires. First they start off as a practical solution to a real problem. Then astronauts come along and over-genericise them. Then the suits get involved with bitchy standardisation committees. Finally, you have FIX Protocol industry parties where not a single person in the room knows what a wire protocol is, much less what a flawed wire protocol FIX is. XML went through this. In the 80s/90s, there was a thing called SGML. It was 'complicated'. So someone started XML, a to-the-point subset of it. And then it got schemas and meta this and meta that and standards attached. XML is now far vaster than SGML. (XML is actually quite good. XSLT is awesome, you can just ignore the XML schema, and there are even occasions when the DTD stuff is nice. But it's big and heavy and doesn't feel at all pythonic. XML and Java were built for one another.) In reaction to the overgrownness of XML, Crockford popularised JSON as a wire protocol. But he saw the way that XML went and wanted to prevent this with JSON. So he said this: it's only a wire protocol. To hammer this home, he said that it's invalid to have comments in JSON because that goes directly against its purpose. So to my point - when I see this my first reaction is - what [bad thing] are they doing with json that makes them want to be able to dot-index into it? At at guess - they're using it as a configuration file format or similar. If you want a tank-like serialisation format - you know where to find XML. And you probably don't need that. With python you can just write code, and it's so easy to read tha it doubles as a configuration file format. We already have a really powerful configuration file format which happens to also be a programming language - that's what python /is/! So the backstory for this is probably someone with a java background writing python and not really getting it. Not that it's any of my business. People should do what they like. I won't use it, and I hope I've EIATYW5. 
What does "sempai" mean?
Again, there's still a big difference between "this isn't good practice" and "this is wrong". Mutable defaults is wrong. Mutating pass-by-ref is bad design. And say I have a list of 1 million elements and I need to trim all the ones that do not match a certain criteria. Also assume that this isn't a good use-case for a generator (need to iterate through the list multiple times after the trimming, say). If I have no need for the original 1million element list after the trimming, mutating that list is a valid choice.
This is related to debug symbols, it actually has nothing to do with the IDE.
&gt; Do you really want to test every function on whether it does the right thing when you feed it a string, a tuple, a list, etc., when It should only ever work for integers? I think that's a sort of strawman argument because there is an infinite number of possible incorrect types that you could pass a given function, so there is no practical way to construct such an array of unit tests. It would be more interesting to see an actual example of a function `foo(TypeA)` with reasonable unit testing and a docstring indicating its input parameter expectations, and then a well meaning function `bar(TypeX, TypeY, ...)` *also* with reasonable unit testing that somehow inadvertently calls `foo` with `TypeB` under certain conditions that are missed by the unit tests. That's the sort of thing that this article misses, and would be needed to make a persuasive case. The example given in the article is useful pedagogically to help a beginner understand how type errors are handled in dynamic and static languages, but it doesn't make a strong argument for type hinting since any reasonable unit testing would have caught that particular error immediately.
http://knowyourmeme.com/memes/i-hope-senpai-will-notice-me
I managed to fix it thanks to /u/rasbt. I believe my whitespace was incorrect. Thanks anyways though!
Explained it as though you were 5 In response to ELI5: Explain like I'm 5
Explained it as though you were 5
You can see the list of Cython's limitations [here](http://docs.cython.org/src/userguide/limitations.html) and [here](http://trac.cython.org/query?status=assigned&amp;status=new&amp;status=reopened&amp;component=Python+Semantics&amp;component=Python3+Semantics&amp;order=priority&amp;col=id&amp;col=summary&amp;col=component&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone). It's a pretty short list. You're unlikely to run into any differences that actually matter to you.
Why the page limit?
I want to start something I know I can finish.
Any book you start can be finished.
Thank you. I just kept seeing "most of" between parenthesis when python was mentioned and wanted to know what they meant by it.
When I'm staring down a 500 page tome I tend to feel intimidated. Two weeks later when I'm only on page 140 I tend to get discouraged and quit. Simply put I don't like massive books.
&gt; Engineer, not professional programmer here, but wouldn't basic unit tests (to make sure the code actually does what it's supposed to before putting it into production) address many of these concerns? Not really. Even if you only do high-level integration testing, you'll be able to massage out most of your type errors lurking in a program in short order. The problem is more in code that's not executed often, like: def send_to_server(msg): try: _server.send_msg(str(msg)) except IOError: log("Couldn't send to server:" + msg) See the bug? `msg` can be an `int`, `str`, `list`, ... without issue if sending it succeeds. If sending fails, you get a `TypeError` if `msg` is just about anything but a `str`. If the function was initially designed assuming `msg` would be a `str`, but someone else later decided that `msg` could be anything, I could *totally* see this slipping through without a test case. Because of this little slip-up, you now get `TypeErrors` instead of log messages, but only when the network gets flaky *and* someone is using the function in this new way. If the original author tried to add a guard like `if not isinstance(msg, str): raise TypeError('...')` to protect this invariant, and added tests for *that*, it would be frowned upon. And it would slow the code down. And it would be just as restrictive as static typing at run time, with no "compile"-time benefits. (FWIW, [Twitter apparently had lots of checks like these in their Ruby code; grep for `kind_of?`](https://www.artima.com/scalazine/articles/twitter_on_scala.html).) Having static types, even if they're not enforced, to catch dumb things like this is *really* nice. It's not a replacement for unit tests, but it can eliminate an entire class of bugs, which I don't think anyone would say is a bad thing. **EDIT:** For clarification, programmer 1 wrote the code assuming `msg` would be a `str`. Programmer 2 wanted to pass in anything, so they added `str(msg)` and forgot to change `log("Couldn't send to server:" + msg)`. Programmer 2 introduced a bug. The idea is that static types would have caught this, rather than letting it slip by until there's a network outage or similar.
This year pycon India shall also be held in Delhi.
Why would you use string concatenation instead of interpolation? Different languages have different best practices. A more Pythonic way would be ``log("Could not send: %s" % msg)``. This doesn't suffer from the bug you described.
I would use a trusted web server such as nginx or Apache.
Are people just dropping whole python projects into cython now and hoping for performance improvements? Use pypy if that's what you want. I have always heard of cython for when you want to take an expensive loop and statically type it and use it with numpy arrays. I'm sure you get an improvement with dropping it all into cython, but you lose the ability to easily make sure the performance heavy part is accurately optimized (did you accidentally leave a python object in there) and I assume profiling gets harder if not near impossible. I think this path will ultimately lead to non-optimal performance.
python-magic still isn't enough, any container formats can contain both audio and video, or either of the two (and with just audio, its an audio file pretty much) magic number detection won't work for these cases
Ah, I read in the docs that they weren't supported but that's awesome if that's changed I'll do some more investigations! For testinc cdef functions I've been doing that, writing helper and wrapper functions but it's just added cruft and maintenance... 
Gulp is a task runner, mainly used for assets management. You should be talking about nodejs. 
I usually organize by file extension.
Hey thanks! I found this and it looks pretty cool. https://learnxinyminutes.com/docs/python3/
&gt; If the function was initially designed assuming msg would be a str, but someone else later decided that msg could be anything If your function is designed assuming msg would be a str, then why would you call `str()` on it? The whole point of calling `str()` is to take anything at all and return a nicely printable representation of it. Its kind of insane to call `str()` when you send the message and then not call `str()` to log the message. Or better yet use `.format(msg)` which produces a string representation anyway.
How do you test whether an object implements `__nonzero__`? I've tried `isinstance(x, bool)`, and it only gives true for `x = True` and `x = False`. I also tried `x = 4`, then `hasattr(x, '__nonzero__')`, which gave an answer of `False`. Or are these correct results?
&gt; If your function is designed assuming msg would be a str, then why would you call str() on it? The whole point of calling str() is to take anything at all and return a nicely printable representation of it "But someone else later decided that `msg` could be anything," was meant to indicate "someone else added `str(msg)`, because they wanted to pass in anything, introducing a subtle bug." Apologies about the lack of clarity.
&gt; what [bad thing] are they doing with json that makes them want to be able to dot-index into it? You know that the Javascript Object Notation is dot accessible in Javascript, the language that inspired JSON as a format? &gt; python as a config man when python allows safe importing, sure, but that config file can then do anything from giving you variables, to deleting all the user's files (if it was mucked around with maliciously). a "safe" format has a lot of value in not being a partial vector for RCE
What's wrong with ELY5? Way easier for someone to leap from ELI5 to ELY5 than from ELI5 to EIATYW5.
&gt; Why would you use string concatenation instead of interpolation? Because string concatenation worked just as well for the theoretical programmer who initially wrote the code. The core of the example was meant to be "code was fine, programmer refactored it to make it less strict, and ultimately introduced bugs in rarely run parts of the code that can trivially be caught with simple static types." &gt; This doesn't suffer from the bug you described It doesn't really matter, but the example is only slightly less broken with `%` formatting. Try setting `msg` to a multi-element `list`, `tuple`, or `dict`.
If that's what you want, why not just make file2 more Python? file2.py: import file1 tools = file1.my_func
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
I thought that was for parsing the JSON into a defined class though. I mean technically you could use it for whatever, but that's what I figured the main use case was. Am I missing something? We're talking about taking a dict and just being able to access its key/value pairs with dot notation, so defining a custom class and a function to create an instance of it from a dict seems like more work than either module for no gain since we're not trying to add any methods or anything to it.
nah its for providing an alternate thing for every javascript object encountered so any time there is a {...} encountered in the javascript, it'll pass that to whatever object_hook is, if that doesn't exist, it'll use `dict` instead json.loads(json_file, object_hook=DottedDict)
This was what I was trying to use. I ended up just making Flask serve everything. Not sure if this is frowned upon or not, but it seems to be working so far. edit: I should mention that I am currently looking into nginx. We want to be able to deploy it on DigitalOcean down the road.
It's a "recommendation", and I use 120 in my open-source projects. I try not to exceed 79, and often, I am successful with that (Let's say 99.5% of my lines are 79 chars max.); on the other hand, I don't mind it if the line's a bit longer. 
&gt; So the backstory for this is probably someone with a java background writing python and not really getting it. Well, I think the back story is that it's someone writing a Python joke that also utilizes some of the module import magic as an example. :-) If not, then it's probably a JavaScript web programmer not really getting Python. It wasn't Java programmers that turned JSON from a wire protocol to a "use for everything including config files and the kitchen sink" file format.
file2.py: import file1 class tools: class foo: bar = file1
&gt; Why would you use string concatenation instead of interpolation? Because mistakes happen. Also, &gt;&gt;&gt; msg = (1, 2, 3) &gt;&gt;&gt; print("Could not send: %s" % msg) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: not all arguments converted during string formatting &gt;&gt;&gt; Edit: Though in this particular instance new-style string formatting helps a lot, &gt;&gt;&gt; msg = (1, 2, 3) &gt;&gt;&gt; print("Could not send: {}".format(msg)) Could not send: (1, 2, 3) &gt;&gt;&gt;
There's nothing wrong with serving static files from the flask development server during development. I don't know what your plan is for deploying to Digital Ocean but you shouldn't be using the Flask development server for live deployment, if that's what you're thinking. Install a proper webserver (eg Apache or Nginx), let that serve your assets and pass the requests to flask via mod_wsgi.
The reason it's in PEP8 is because it's a general and widely accepted convention in Unix. Not only is 80 characters the limit for maximum reading comfort; it is also a (sonetimes soft) limit in many protocols, most notoriously e-mail. And because of this, more textually-inclined Unix folks optimize their setups for 80-char terminals (e.g. my tiling window manager and terminal emulator are set up such that I can have exactly two 80-char terminals next to each other). And yet another reason is that the longer your line length limit, the more variation in line length you will see. With a 200-char limit, even if it fits on your screen, only a small handful of lines will actually use all that space, most lines will be under 20. Which means that you're seeing a lot of empty space, about 90% to be precise. That's terribly wasteful.
You were right! Thanks alot! :)
It appears to be breaking JSON license https://github.com/kragniz/json-sempai/issues/2
Asking because the project is spelt with an m, not an n
Apparently both spellings are used. 
It's difficult to compare them, they are all very different. * RapydScript, Flexx and PyJs are basically preprocessors, similar to CoffeeScript, although Flexx and PyJs go way beyond that and give you full application environments. * PyPyJs is an asm.js project, which basically means no real DOM interface. * Brython is a straight runtime compiler, which means you get DOM access and the most intuitive "using python instead of JS client-side" feeling (IMHO). * Py2Js is dead. ~~Most~~ A few of them don't support Python 3 (Edit: I was surprised to find most of them actually do now. Score one for Py3!). Some of them are more efficient than others. All of them usually result in pretty large downloads (if anything because you have to redistribute tons of stdlib code). I can see why /u/jacdeh might have become frustrated enough to start his own project. However, IMHO, none of these solutions are realistic for widespread usage without some help from browser vendors, which is not going to happen unless it's a general-purpose multilanguage solution. Asm.js is getting there, but it still needs work (mostly, proper DOM access interfaces); once that's solid, I think pypyjs will take over the segment pretty easily.
emacs is always the right answer, to pretty much any tools question
it depends, I really really dislike breaking conditionals to the next line. Most of the time 79 chars is the best.
I am not a fan of PEP-8. In all the projects where I get to decide code style, it is tabs for indentation, spaces for alignment. But 79 characters per line is a rule I will follow almost all the time, only making exceptions for multi-line strings that require longer lines, or things like the very occasional one or two characters past the line.
Fantastic, thanks a lot!
[Think Python, 2nd edition](http://greenteapress.com/thinkpython2/index.html) is a free and excellent book at around 200 pages.
&gt; Cython.Compiler.Options.cimport_from_pyx = True in your &gt; setup.py, and then you don't need .pxd files to do cimport. TIL, thanks 
Then you need to do a 3 ways merge.
I generally go that way of thought for indentation too, but I haven't been doing so outside of C because my programmer friends get mad at me.
 def send_to_server(msg): try: _server.send_msg(str(msg)) except IOError: log("Couldn't send to server:" + msg) You could eliminate this class of bug by having a lint rule that fails when it sees string concatenation. &gt;Having static types, even if they're not enforced, to catch dumb things like this is really nice. It's not a replacement for unit tests, but it can eliminate an entire class of bugs, which I don't think anyone would say is a bad thing. I don't think catching type bugs is a *bad* thing per se, but they don't appear (at least in my case) to be all that common a class of bug, and your code has to become more verbose to accommodate the static typing. It's definitely a trade off. (As opposed to a lint rule which isn't a trade off that means you have to sacrifice terseness for additional type checking)
This would actually be a great idea. Obviously nice to have, pretty doable even for a beginner and deliciously ironic.
It's the same word
Come on you're artificially inflating the code in other languages by adding messages and stuff like that.
How long before node kids think "hey, that's a pretty great idea!"
It is a prime number, so it's got that going for it.
I go with Orwell on the line length: "Break any of these rules sooner than say anything outright barbarous." I try to keep a reasonable length of around 80 chars, but I will readily break that rule rather than either mangle variable names, split equations such that they become unclear, or anything else of that nature. And most of all, I avoid wasting too much time thinking about it - formatting is good by definition if it is clear and readable. Keeping a 'reasonable' line length is part of that, but only a part, and definitely not something to obsess over - especially not to the detriment of paying more attention to sensible variable names and arranging the logic in a readable way.
You seem to think it can't be both? If I don't have enough realestate to display all the related characters (eg the whole line) than readability takes a hit. 
Way to go JaSON! 
not all exploits are instantly RCE, like, for example some anti-virus' browser extensions have exposed the ability to write to arbitrary user-owned files, but doesn't give any ability to execute those files (thanks AV software). at that point, you need to find a file you can write to (user owned, not system owned), and it also needs to be likely to be executed. add those conditions together with a ~/.config.py and you've got a fully working RCE, because safe evaluation of a python file is currently impossible unless you want to build a custom version of PyPy which is unreasonable
Levels of indentation in my programs: 1. The class 2. The function. 3. An for loop. Guess I better not have any if's inside for loops. These kinds of rules may make sense for some kinds of software, but not so much for python, and certainly not the kind of end use python I write.
Yeah I know that now, was just trying random solutions. Do you know how I'd combine python-related .dll and .exe? :)
Can't really contribute a lot of practical knowledge here, but I can give you a good resource for deploying web-apps: [Full Stack Python](https://www.fullstackpython.com/). If you haven't checked it out yet, I'd wager you can find some useful info there. 
Python 3.3? Rock on!
The solution to your problem is Type Hinting, new in Python 3.5. Take a look at this [Pycharm blog post](http://blog.jetbrains.com/pycharm/2015/11/python-3-5-type-hinting-in-pycharm-5/)
Is it possible to use SQLAlchemy in weppy?
I don't see any hitch on that. You should write down an handler (middleware) to manage connections and commits and register it to your application. You can use the DAL one as an example: https://github.com/gi0baro/weppy/blob/master/weppy/dal/base.py#L25 Notice that using an external ORM will prevent you to take advantage of the forms generation from your models and the auth module. So my question would be: what do you need from SQLAlchemy that is not shipped with the weppy ORM?
Function signature annotation are almost unusable with 80 character limit :(
&gt; Which means that you're seeing a lot of empty space, about 90% to be precise. This is a pretty compelling reason to stick near to the line limit. There's something incredibly jarring about a lot of empty space. 
"Practicality beats purity."
Honest question, how is python popularity in Japan?
My stance on this is that everything beyond 80 characters is subject to being ignored. If it's just a string literal or boring data that isn't functionally important to the working of the code, then exceeding 80 characters can be excused, but if you'd miss out by skipping that part, breaking it up is the better choice.
I heard that they eat printed copies of Python sourcecode to boost their manliness 
They wouldn't need to go to the lengths of writing python. If they have shell access, they could just add entries to your ~/.ssh/authorized_keys. Not set up that way? Then they could RCE you via your .bashrc. They could use wget to pull down a utility and install it in a cunning place. Or use netcat, or background a one-liner in python or perl to open a shell. They could put execut ehandles into your .gitconfig. They could use the database credentials in your config file to connect to your database and inject RCE exploits into the stored procedure layer. Pickle and marshall files are not safe either. Console access is full access. 
I'm using 99 at work. This is okay according to the PEP8 spec. From the PEP8 text: &gt; Some teams strongly prefer a longer line length. For code maintained exclusively or primarily by a team that can reach agreement on this issue, it is okay to increase the nominal line length from 80 to 100 characters (effectively increasing the maximum length to 99 characters), provided that comments and docstrings are still wrapped at 72 characters.
It's not just both, it's either. Even if you have enough real estate, there's a point beyond 60-95 characters at which people's reading speed slows -- typographers were sticking to this rule long before computers were invented. This is why, when text is printed on landscape pages (A4/letter size), it's done in two columns instead of one wide one. As for why shorter lines are easier on the eye: some quick duck-duck-going suggests it has to do either with the distance your focus must jump back, or the shallowness of the angle at which you must 'send off' your eye when it jumps to the start of the next line.
Wikipedia also says that its inverse, 97, is also a prime. It's also the atomic number of gold. And way more other [79 facts](https://en.wikipedia.org/wiki/79_\(number\)) than you probably wanted to know.
Ok, fair enough - I can see now how something like that could actually happen. Maybe the logging statement is from 2008 when no one in the organization knew much python. A new dev alters `send_to_server` to handle a numeric type msg. There are already two unit tests, one testing for success with a string, one testing that the IOError is handled, both with `_server.send_msg` mocked out. The dev adds a unit test for a numeric input with success, but not a test for a numeric type and IOError. The code reviewer sees a new test and thinks ok, and doesn't even look at the string concatenation in the logger statement because it doesn't show up in the changelog. Integration tests pass, Q/A throws a bunch of crazy numbers at the system and it works, it gets deployed, and then one Saturday night at 2 am a network switch starts to flake out and operators are left scratching their heads over why worker threads are dying.
I'm currently tied to the bed after a foot surgery and had to change the screen resolution so that I can still read something. Now there hardly fit 79 characters on the screen (and it's a pretty big one). Don't forget the disabled people! :) BTW, here's a nice talk by Brandon Rhodes in which he mentions some ways to keep line length short: [A Python Æsthetic: Beauty and Why I Python ](https://www.youtube.com/watch?v=x-kB2o8sd5c)
This is true for blocks of text in columns, where every line is more or less the same length. That problem doesn't exist when it's a single long line amongst other shorter lines, as is overwhelmingly the case for long code lines.
Yikes, the future. 
Err no it is based on screen size, you do remember the days of 80 column CRT terminals. The standard really has no applicability in the modern world. Besides with Python and the forced indenting you loose character fairly quickly. Also indenting effectively created columns of text that are just as readable as something completely left justified. Imagine if you have a block of code that is three indents in, that would be 12 characters 79 - 12 = 67, so your block of code is limited to 67 characters following this standard. In some cases you might have less than 60 characters depending on the number of indents. Normally one would think of that as a lot (the remaining characters) but it hampers one important aspect of Python, that is readable code. Readable code requires rational, meaningful variable names that easily extends a line length. With modern IDEs you simply keep the text to the left of the window and still have room for the required number of characters to deliver your code. 
Why does it remind me of "tentacles porn" ?
The reason I'm saying that isn't because Python &gt;= 3.0 isn't good, but because it's not fully backwards compatible.
Because you were watching tentacle porn before you started redditting.
This looks pretty cool. I plan to check it out later this week. I would only need the resource for occasional computing - is there any limit on the 'trial' length? Ie. you mention getting $10 by registering - does that expire or canI use it indefinitely until the money runs out before refilling Jut a heads up - on your blog posting page in the section labeled "**Second - a repository with the code of your program is required.**" it seems the 'f' key on your keyboard was taking a 15 min break Also, it seems there are a number of buttons and UI elements on the dashboard in various places which are not in english ... This is a bit troubling. 
This is a good point which demonstrates what I was saying - just as SSH and Telnet are different tools (to do the same task), so does Python 2.x and Python 3.x are different programming languages. Again, I'm not saying Python 3.x is bad, I'm saying that backwards compatible is important.
You can have printed text on a billboard or in a pocket book—each of the billboard's letters is alone bigger than the entire pocket book! But both follow the same rules of readability. The physical size of each letter doesn't matter, the 80 column terminal is the billboard to the pocket book of today's high resolution displays. It's also not that you're supposed to fill the entirety of the column with text: shorter lines are better for reading. This also means variable names inside code should be concise. You can always have elaborate names and data structures for global access, aliasing them to a short local name as needed.
That is all well and good but if you have a block of code at an arbitrary indent level the characters lost to the indenting have no impact on readability, your lines of text are still narrow even if the interpreter is seeing 90 characters instead of 79. Beyond that the mind is often working differently when reading code. It actually has to parse the code a bit to grasp what is going on. You can't directly compare coding to reading a news paper. By the way I'm not saying that lines of text in Python should be hundreds of characters long what I saying is the limitation at 79 characters is a hold over from,the dark ages and is pretty useless considering how modern programming is done. That and I'm a big of variable names and coding prose that reflects the real world that the code is being written for. For example if your code is looking a real world value say a temperature zone in a machine, I'd rather see a variable like TempZone_1 than say T1 or a function TempZone() than say T(). Well written, readable code simply requires more characters than some of the compact approaches we see. This example isn't too bad with 10 characters used but it isn't unreasonable to have to further increase the variable size. In any case you can see where the line length becomes an issue when you try to write code that leverages pythons strength of producing readable code. The reality is you almost immediately loose 8-12 characters before you even get to the meat of a routine. Those lost character shouldn't even be considered in your line length. 
good!
SSH is basically a direct upgrade from telnet. Telnet has absolutely no security, and will cough up your password if you just look at the stream of data. Just like python 2 allows you execute shell commands if you give someone an input() prompt.
We're talking about two different things -- you could have improved python's security without changing its syntax. I'm talking about syntax, not context.
Therefore, they're different languages. Think about a C compiler that would evaluate 1 / 2 to be 0.5 instead of 0.
I like it! I had a similar idea of scraping data from bitcoin markets and doing computations on it, then experimenting with making some kind of rule based system that simulates trading on these markets. But I havent made it very far (yet?). I will definitely give your library a closer look. (and nice choice of language for that!)
Yeah, there are many variations on romanization of Japanese.
This is cool. You should also check out Quandl for historical data. They have a super simple python package for grabs huge amounts of historical financial data. But to get the real time stuff you have to pay, so yours is nicer there. 
He didn't talk about console access though.
Good point. It could be a source control system, with no local access. Deployment is done via checkout. And interpreted python would provide a vector for getting code and console on the machine. I'm not yet convinced there's a problem though. What I'm interpreting is a basic distrust for the people who are driving the development of the software system. I can't connect this to a problem. If you don't trust people, you don't want them anywhere write access on your configuration. They can kill you even without opening up a console - they can just put wildly wrong FX rates into config or something like that. If you do need to have kinds of config that need to be rigorous, JSON is wrong for that as well - you need XML and schema enforcement. An example of where I'd do this - if I was receiving XML documents from a partner over an API or message stream and wanted confidence that any message was structurally sound before I started processing any of it. 
I'm using Sublime Text 3. I believe it's the default shortcut of Alt+Q, it wraps any block of text to your currently set wrap width. It doesn't always play nicely with Python, in particular it won't wrap well inside multi line strings unless there's a blank line before and after the paragraph, but for line comments in pretty much any language it just works even without the blank lines bracketing the comment. I find it really handy because I can edit the comment all I want, then hit Alt+Q to get it nicely formatted. I'm sure you could write a similar plugin for just about any editor with relatively little effort, it just seems to be an overlooked feature in most editors that really shouldn't be. Of course there's a point where a name is simply too long, but I think most variables can be explained well in 1 to 4 words, using whatever naming convention you see fit (camelCase, snake_case, whatever is syntactically valid, I don't really care because it's a silly argument to have). Any longer than that and you're just making hard on yourself (except in extreme circumstances).
Those are supposed to be 72 characters per PEP-8 :p
You merely adopted the tentacle porn, I was born in it.
This is another good point, who ever thought strings should be split up to keep arbitrAry line lengths really needs to rethink their opinion because it does nothing for code readability. 
yes! 
I try to make my variable names descriptive, which sometimes leads to them being kind of long (20 chars). That's where I run into trouble 
That is just evil! &gt;I am not a fan of PEP-8. In all the projects where I get to decide code style, it is tabs for indentation, spaces for alignment. Some of my wrist debugging adventure came from people putting tabs where spaces should go. 
The point you are missing is that real world attacks usually consist of multiple combined attack vectors. Someone might find an exploit to overwrite configuration files. Such an exploit can be dangerous enough on its own, but combined with the fact that the config files are interpreted by the Python shell gives the attacker shell access.
Open source software in general is pretty popular there.
I blatantly ignore it but then really regret later when I'm trying to go through my monstrous code. Is there a good utility to automatically split long lines up?
So all in all it does what it is supposed to do because I set a default value for that variable But if it wasnt set it would kinda never run any line of code I just want to enter something With the Python script started everything works perfectly fine 
Start by breaking this problem down to its core requirements. To be entered by the user: * number of different characters that could have been used in the password * number that is the length of the password To be determined by the program: * number of unique passwords of specified length that can be generated using characters from a pool of characters of specified size * how long it will take to try every password given it takes an amount of time specified in the problem
You should probably take this to /r/learnpython, it's a subreddit created precisely for those kind of questions :)
pypyjs using asm.js is a dream if it could have reasonable download size. It's just that currently it hasn't. Browser vendors sure could open this up. But I'm a bit tired of waiting. Have coded quite some JavaScript &amp; gathered enough frustration to start this. And, by the way, it's fun!
Yes, that's how it works. Think it's called market mechanism... In some respects it's a waste! But it's also how nature works, survival of the fittest. So maybe there's something to it...
I do not have a experience with the weppy ORM. I work with Flask and SQLAlchemy. I do not like Flask, but I like SQLAlchemy. So I'm interested in python web frameworks that are alive and do not have embedded ORM or allow to use SQLAlchemy.
This is so vaporwave
If books end up giving you trouble, plenty of people have learned the basics without books at all. There are tons of tutorials and more interactive teaching methods out there these days, take a look at the /r/learnpython wiki
I make my variables descriptive too, but I'll use creative abbreviation to keep the characters down to 5-8. 20 seems excessive... 
If you get a few characters over, just go over. If you're continually nested 16-20 characters levels deep, that's a code smell. Use more functions.
&gt; there is a difference between 7 * 4 and 7 * 4.0 Not a numerically important one, just one of data types. &gt; In python 3 an arithmetical formula over integer numbers may produce a result of either int or float - that is my biggest issue with that change ) Better than having the actual *result* change. I don't care too much if the data type changes, it's just an int(x) conversion (or float(x)). But with integer division when both types are float, the actual number changes.
This looks like something from the 90s
I agree with you: long and descriptive variable names are definitely the way to go. If my overfull line is a simple clause with one to three long variable, function, or method names, then I'll happily keep it together. Often, however, the overfull line has some hierarchy inside it: it is a nested function call; or a function called with multiple arguments; or a chain of method calls; or some boolean logic like `(X or Y) and (Z or A)`, which adds up when the names are long. The longer the variable names, the harder it becomes to pick out any hierarchy *within* the line, because the parentheses etc. are pushed apart. That creates a natural push towards making my lines short again, and this is why I find 79 chars easy to attain. &gt; Beyond that the mind is often working differently when reading code. It actually has to parse the code a bit to grasp what is going on. You can't directly compare coding to reading a news paper. Very true. Onnn the other hand, if the line is long I do find myself having to 'recognize' the next line rather than my eye just landing on it, so there is some overlap in mechanism. As a final note, I find having 79 characters as a rule keeps me honest. It makes me keep my lines simple; and whenever I go over length, I end up with a line of 80-99 characters, instead of 100-119.
Eh, I can type very quickly and my editor has auto-complete, so I'd rather not waste time coming up with abbreviations that me or whoever is reading my code in the future may or may not understand.
I've found that most of my problems with 80 char lines isn't the indentation depth, but long and descriptive variable names. And those are *good* things to have in your code. The 80 char limit definitely makes some code look uglier than it should be, or pushes me towards using less descriptive variable names. I wish 90 chars was the standard, but it's not and thus setting it at 90 makes no sense as it's likely going to break too many people's workflow. In my vim config, I put a marker on char 80 or 110 depending on the filetype. 80 for stuff like Python and Bash, 110 for TeX/C#/Markdown/Java. I keep under 80 chars in 97% of my Python files.
If you're reading your post on a widescreen monitor (at least 1680x1050), then it goes above 80 characters. Do you have any issues reading that? Edit: might be a bit snarky here. I do agree there is a limit to line length for readability. To say that it is 80 characters is rather presumptuous. Anyway, pick a length and stick to it. The only thing worse than a line 10 characters longer than your desired length is having the source control cluttered with line changes &amp; splits every other commit. (personally, I use 100 line lengths. I find that's about where I can split text files on the same monitor w/o horizontal scrolling). Edit2: I also find enforcing a decent line length makes it easier to deny really long one-liners. If it's going over 100+ characters... split it up for comprehension's sake. I find that especially is the case for more complicated boolean expressions, or generators. 
[Image](http://imgs.xkcd.com/comics/password_strength.png) [Mobile](http://m.xkcd.com/936/) **Title:** Password Strength **Title-text:** To anyone who understands information theory and security and is in an infuriating argument with someone who does not (possibly involving mixed case), I sincerely apologize. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/936#Explanation) **Stats:** This comic has been referenced 1979 times, representing 2.0368% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_czbj9ju)
Which is complete bullshit. 80 chars, sure, it's reasonable for code, but annoying for docstrings. But 72? No way.
Creative abbreviations are problematic though: it's really easy to accidentally abbreviate something different the next time you write it.
I have no problem with that one. It's very easy to meet. Maybe I overstated it &gt; For flowing long blocks of text with fewer structural restrictions (docstrings or comments), the line length should be limited to 72 characters. https://www.python.org/dev/peps/pep-0008/ Regardless, it's a suggestion. Don't let other people PEP-8 your code or complain about your lack of PEP-8'd code. It's not like core Python actually follows the PEP-8 "rules" everywhere.
&gt; I love being able to look at 2 files side-by-side in Vim without anything hidden by the edges When your monitor is wider than it's high, chances are that you're not going to have any problems running 2 110-char files side by side, though.
Learn Python the Hard Way is 300 pages, and it's very quick to read. PDF: http://www.souravsengupta.com/int2pro2014/python/LPTHW.pdf Webpage (probably easier to use): http://learnpythonthehardway.org/book/
Your post as a whole is unproductive with this context, in my opinion, since it's founded on what I think /u/tty2 is trying to highlight as a bad premise. You seem to highlight the issues with available education as a preface to this post, which one has to believe has some kind of relevance. Based on your past post history and the fact that you mention "infosec" and "web technologies" as strengths, sure, it makes sense that you're basically unemployable as a programmer, and that translate both to 'traditional' software engineering jobs as well as most contracting opportunities. If you highlight education as a gap, and others agree that your claim about education opportunities is bullshit, then it makes sense to call out the bullshit. Because the education is a gap. Something to correct. Get an education. We don't believe that there isn't education available to you (at least not as you describe with final exams on "how to write a proper while loop".) So if we as members of this community were to try and help you, we would tell you to pull your head out of your butt and figure out education, not try and convince you to go apply to some B.S. "find a programmer" sites, or something like that, because that solution isn't helpful. Solid education is. But no it's okay, go on believing that final exams are about while loops outside of your first intro computer science class and the degree programs are focused on HTML/CSS. Ignore the opportunities available to you in traditional institutions and instead look at the wrong programs at the wrong schools. Go on posting in subreddits about hacking without actually understanding any semblance of computer organization or computer science. But if you want to eat, a degree is your best path given your non-existent background.
&gt; Column width is a readability issue, not a screen real estate issue. It's also, to my understanding, more of a physical width issue than a number of characters issue. As higher resolution displays have allowed most of us to use smaller fonts than we had when the 80x24 terminal was king, we get more usable data in the same readable width (to a point, of course).
Isn't google finance data delayed 15 minutes?
It depends a lot on what kind of work you do. You should never feel forced to do anything because of character count. I've got a project where accessing the database always needs 120+ characters. Squeezing it into 80 would be horrific. Its not like the longer lines are unreadable or confusing. The length is mostly a result of descriptive naming which makes the code very understandable. 
 api.nova.tenant_quota_get( IsA(httpRequest), '1')).AndReturn( self.quotas.first())) 
Why should I use this instead of pandas? The docs mention pandas has installation issues, but that's simply not the case for people using Anaconda.
Presumably you are using SQL queries? You can always use continuation lines (or whatever they are officially termed). Something like: read_sql_query( 'SELECT * FROM data ' 'WHERE id &gt; 1000 ' 'ORDER BY timestamp DESC') I find this style more readable for longer queries, personally.
&gt; 79 line limit is for Terminal width -And that's so you can accomnodate diffs! +And that's so you can see diffs on one line!
&gt;Almost no code is reflowable. Oh it is, but do we want that? [thing_var + constant for thing_var in things_container if any(thing_var in valid_set for valid_set in valid_sets if x is not thing_var)]
&gt; 3.3 &gt; 2016
No that's Yahoo Finance. Google Finance is [real-time](https://www.google.com/googlefinance/disclaimer/)
&gt; what [bad thing] are they doing with json that makes them want to be able to dot-index into it? Personally, I use IPython, which lists/autocompletes object attributes while coding. Being able to dot-index into a JSON object would make it easier to sort through it while coding in that context.
* So the modules are installed, it runs but pyCharm says they are not ? =&gt; pyCharm read your package folder and cache the result. The pyCharm cache must not be up-to-date. * Or python does not run and throw an error 'package not there' ? =&gt; Do you have multiple interpreters (2.7/3.5)? Your project might be using the wrong interpreter 
Give [pyramid](http://www.pylonsproject.org/) a go.
Thanks. Unfortunately there does not appear to even be a directory for it to find it in, according to Windows. (see first linked screenshot on the left, compared to the pip uninstall command, on the right.)
My question exactly...
Try again, thats python with the *awesome* (sarcarsm) mox library. I know, it looks totally out of place. Ugh.
I found that these days you need to restart PyCharm after you pip install something new into your virtualenv that PyCharm is supposed to watch for changes, I found that PyCharm *used to* sense new dependencies being installed and automatically rescan, but this has been broken in the last few releases... so a restart is required each time.
This is what I do as well.
"Real-time price data represents trades which execute on the NASDAQ and NYSE exchanges. Volume information, as well as price data for trades that don’t execute on those exchanges, are consolidated and delayed by 15 minutes."
I've never liked multiple fors or ifs in comprehensions. 
I use a 90 character limit.
Is anybody else bothered by the apparent disregard for short-circuiting `and` and `or`in chapter 2? I suppose it gets tackled later.
It's so great when Japanese is actually English and you don't have to know anything new... 😀
I´d like to suggest Homura for downloads. It´s simple, works pretty well and resumes downloads.
tuple or dict would cause a problem. list would not. The newer ``.format`` solves that issue.
Are you running the code in the GUI OS or through an SSH session?
This isn't a homework-help subreddit. Your question is more appropriate for https://www.reddit.com/r/learnpython. But there's nothing peculiar about the Python remainder function. `7 % 2 == 1`, and so on. Your question seems more about "how do I use `%` to solve my problem", which is very simple as problems go, so you might pose it on https://www.reddit.com/r/learnprogramming.
Just writing some code and encountered a case that may serve as an example why I am a bit more relaxed about the 79 chars for importer, pkg_name, is_pkg in pkgutil.iter_modules(package.__path__, prefix): ... vs. for importer, pkg_name, is_pkg in pkgutil.iter_modules( package.__path__, prefix): .... 
Geohashing is dope! it blew my mind when I discovered it because it only rounds up a number I was trying to interpolate and and compare. I used [this](https://github.com/hkwi/python-geohash) script when building a script that operates on tables and reduces it, to a constituent geohash count table. (Which is I think what you meant by statistics and clustering maybe) You can do some cool stuff with a geohashing script I wrote a heap map algorithm some time ago. I'm done with KMLs (to many limitations) for now but GIS on a data science Python stack is 1000x times easier then a lot of the javascript stuff I've seen. I'm working on a pipeline between raw table data and MapBoxes mapping service now directly. Unfortunately even if its a local link its still pipelined through there service. (I think) I'm just hashing out one issue at a time before I get to a Python GIS service that makes sense. MapBox doesn't want Python on their APIs. What you need is a javascript stack that just does the tile serving and mapping functionality on locally. (and of course the tiles) I want [I/O GIS](https://video.twimg.com/ext_tw_video/690882081082232832/pu/vid/1104x720/HuII4TJ0CRhgH2fb.mp4 ) pretty badly, folium offers it but not quite in the way I want, but I'm getting there. [pipegeohash](https://github.com/murphy214/pipegeohash) [pipeheatmap](https://github.com/murphy214/pipeheatmap)
In the GUI OS
I'm not running my sqlite db in memory. The parsing doesn't really run into problems. Also inserts don't take very long either. The problem I run into is during the comparison of the cidrs and ip ranges. I have to do a nested for loop referencing the cidrs and I compare each value to every single cidr entry. I haven't really gotten to push it up to github simply because this is a project I've been working on at work; however, the stackoverflow link is very similar to the case I'm working with. I use a similar tactic except I use sqlite to search in. I'll see if I can strip parts of the code and push it up to github to show you, but I really do feel the problem occurs during the process of finding overlaps excluding the overlap and assigning new ip ranges for that zone. To put in perspective it will take each cidr value and compare it with the rest of them one by one. That's roughly about 26000 rows for this one file. I appreciate your response and your insight on the matter =). 
That looks very good for a first Python project - getting that first 'build passing' badge can be tricky :) Are you developing in Python 2 or 3? Notice you have the line &gt; from __future__ import unicode_literals One tip that helps is to have these lines in the header of each program &gt; #!/usr/bin/python3 &gt; # -*- coding: utf-8 -*- and use Python 3 as this will help with the Unicode issues. If you want to get it nice and polished, you can follow the PEP8 standards and get put a docstring in each function. One other thing, you should put some classifiers in the setup.py or no one will find it (people generally look by category, unless they know your packages name) 
Please see my response [above](https://www.reddit.com/r/Python/comments/42m8xc/meza_a_python_toolkit_for_processing_tabular_data/czc7si6).
I wouldnt say so, Pandas can do a lot. Its just that i designed meza to fufill that particular use case plus a few others. Meza will appeal to those who prefer functional programming, which, imho, is a better way to approach the workflow you described. For example, i often come across poorly formatted files where there are blank rows/columns before the actual data. Im not sure how pandas handles this, but most meza readers have a `first_row` and `first_col` option for it. Meza also provides things like atomatic file encoding detection, type detection, and type casting, just to name a few.
how does this compare to aria2?
PEP8 actually allows for an arbitrary line length, it only mandates that your project is internally consistent. So if all your code fits inside 90 or even 120 characters it is PEP8 compliant.
It might be a good idea to bind the module iterator before the loop. Just because that also reduces the complexity packed on the loop line.
Just to add, you can get the full list of classifiers [here](https://pypi.python.org/pypi?%3Aaction=list_classifiers) (find it anytime by Googling "Python trove").
Im currently well over half way through LPTHW, and was thinking of starting with [Automate the Boring Stuff](https://automatetheboringstuff.com/chapter0/) when I am done with LPTHW. Would you advice me to just stop with LPTHW and start with ATBS right away?
As with most live demos half the video is me debugging, but you get the idea. I wasn't expecting to be able to do it that quickly. The idea is raw table data to a map like it should be. 
Hey OP, interesting problem! Have you profiled your script? I've had the pleasure of being pleasantly surprised a few times by things I thought _should_ run fast, but weren't. Python has the nice [cProfile](https://docs.python.org/2/library/profile.html#module-cProfile) module, but I've found that graphing things makes finding slow parts a bit easier, so I've been using this script: python -m cProfile -o profile.d script.py gprof2dot -f pstats profile.d -o profile.dot dot -Tpng profile.dot -o profile.png You only need graphviz and gprof2dot installed to make this work. As far as advice, the only thing that comes to my mind is either using [set](https://docs.python.org/2/library/stdtypes.html#set) to get unique values, or laying down some [cython](http://cython.org/). 
Does this actually work for you? I find PyCharm doesn't always respect this setting for me (v5.0.x)
&gt; Miniconda is only small by conda standards, it's not small by any &gt; other. If you are writing a 1Gb CSV file then caring about a hundred megabytes of miniconda dependencies is nothing but crocodile tears 
&gt; Or maybe because they need to write a 1 GB csv file, and pandas is impossibly slow at this? Just want to underscore the importance of this. meza reads and writes files iteratively, i.e., it doesn't read the entire file at once. So as long as you aren't sorting or grouping, you can do your analysis (including file conversion) with minimal memory usage.
The point isn't to reinvent the wheel, but to propose a tool with an expressive and simple syntax. I'm not stating SQLAlchemy isn't a great tool, but if you consider *reinventing the wheel* any alternative tool that propose a different syntax, you can say the same for flask and django. See my point?
&gt; web2py has an ORM and data description language that automates a lot of the UI creation doesnt it? does weppy have that? web2py doesn't have an ORM, but just a good database interface. No, weppy doesn't have an admin panel. &gt; such as? Eg. * the pydal library under the ORM to work with the database * the auth system * the templating syntax &gt; To create URLs for what? To make writing the routers easier? To dispatch requests to the routers? Example needed. You quoted a phrase from the docs that is explained in the next lines and in the routing section :-/ &gt; In other words not easy to create reactive single page applications. Still stuck in the old days of whole page requests and whole page rewrites. It depends on how you write them actually, since you can use blocks and ajax components. Btw, if you expected a templating system that reinvent angular or emberjs, I think you won't never see it on any python web framework, since it won't be such good as client side frameworks, born for that. This would be *reinventing the wheel*. &gt; Is this the same as the DAL from web2py? Do changes in the code update the database? [Have you read the migrations chapter?](http://weppy.org/docs/0.6/dal/migrations) &gt; How about an automated data entry interface, like Django? Is not on the roadmap and neither on the intentions. But I wouldn't exclude an extension for that.
Oh, it looks like it's not where pip thinks it is. From inside Python, try: import xlsxwriter print(xlsxwriter) That should tell you where it's actually imported from.
It might be useful to another beginner to read the code, or maybe this little c project can be adapted to fit into someone's application by providing a starting point. If you have criticism of the code posted then it can be helpful for the author to receive feedback, and helpful for you to practice reviewing code. Lighten up a bit, this is just reddit. 
FYI, pandas can do this too. You can set chunksize to turn it into an iterator.
&gt;Or maybe because they need to write a 1 GB csv file, and pandas is impossibly slow at this? pandas supports iterative reading and writing the way this does.
Bayes is dump. It's easy to implement though.
Perfect 5/7
I could give that a try. I currently use pypy in attempts to speed up the script. It's similar to cython, while using pypy did speed my script up it still runs pretty slow for what I'd like it to do. 
 &gt;What difference does that make though? No matter what your editor or IDE looks like, with 200-character lines, Let's not be dense here nobody is talking about 200 character lines. &gt;you will still have to choose between seeing all your code but wasting a lot of screen real estate on empty space, Python already creates a great deal of white space for you. As such that white space simply removes characters from the line length. Even though a line might technically be longer that 100 characters, properly scaled, the text isn't a problem &gt;or clipping your code to a smaller limit and not seeing the parts that exceed it. An IDE doesn't really change anything; On a machine that has the hardware to support the display of long lines it changes everything. The IDE can be smart about what the programmer sees. &gt;it will most likely make screen real estate more precious though, because unlike a more minimalistic approach, you will have more things on screen simultaneously. The idea is idiomatic code that doesn't require deciphering. Even a non parameter should be able to determine what is happening in the code. 
Ditto.
&gt; Let's not be dense here nobody is talking about 200 character lines. It's an extreme example, but the general premise holds: the longer the line length, the more likely it is for an individual line to be much shorter than that limit. If your limit is 20, most lines will be near the limit, so an editor window of 20x80 characters will be filled almost completely, i.e., it will make maximum use of screen space. If your limit is 200, most lines will still be under 20 characters, let's say your average line length is 40 characters; this means that on average, you are using 5% of each line, and a 200x80 character window will display 5% code and 95% whitespace. No matter how you render your text, or what IDE features you throw at it, as long as you're looking at the code itself, that is the screen space usage you will get. The only alternative is to make your window smaller than the maximum line length, in which case some lines will never be visible in their entirety, or to use line wrapping, which will make indentation / alignment less obvious. &gt; On a machine that has the hardware to support the display of long lines it changes everything. The IDE can be smart about what the programmer sees. But the above still holds: either you see everything plus a lot of empty space, or you see not-everything but more of it. &gt; The idea is idiomatic code that doesn't require deciphering. Even a non parameter should be able to determine what is happening in the code. I don't even know what that is supposed to mean.
Good to know! I wasn't aware of that. However, their method involves [two steps](http://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas/12193309#12193309): import pandas as pd tp = pd.read_csv('file.csv', iterator=True, chunksize=1000) df = pd.concat(tp, ignore_index=True) vs from meza import io records = io.read_csv('file.csv') 
Maybe you will find this Pandas [cheat sheet](http://nbviewer.jupyter.org/github/pybokeh/jupyter_notebooks/blob/master/pandas/PandasCheatSheet.ipynb) useful? Also check [this](http://chrisalbon.com/) out too.
An if then statement that tries and check if the first line is a comment
Thanks for the suggestion, but of course python tells me it's at: &gt; module 'xlsxwriter' from 'C:\\Program Files (x86)\\Python 3.5\\lib\\site-packages\\xlsxwriter\\__init__.py' That directory just doesn't exist on my computer, as far as I can tell, and it's very weird. Similar to what I posted in my original post from the command prompt, but this is the window for that folder-- noticed that show hidden items is checked, just to eliminate any doubt: http://imgur.com/Qf7iKsP 
Thanks. I found it, and according to THIS it even says XlsxWriter is installed... so why does it underline? Ugh. http://imgur.com/lqM9nAC 
Easy :P &lt;!-- not a doctype --&gt; &lt;html&gt; &lt;/html&gt;
Thanks for this! I wanted to do one for a long time now but could not for the life of me understand black and scholes and calculating the volatility. Do you have any resources for the mathematics behind it? something geared towards a python programmer perhaps?
l got that link from the pandas documentation so i assume that is the preferred way of doing it. And you would use it when the file wont fit into memory, so opening it the normal way doesnt work.
I had started looking into modifying lxml to make that optional but priorities at work changed.
except every page thats dynamically generated will include a doctype unless its a custom made one which more likely than not will be a doctype. that was a dumb post since the false positive rate would be extremely low anyway.
The issue described in that SO thread has long been fixed. The only scenario where pandas would fail the read would be when you actually run out of system memory.
Seconding /u/Twangist. Also, for the record, the [divmod](https://docs.python.org/3/library/functions.html#divmod) function might also be useful here.
Aren't functions first class objects in python? Maybe I'm misunderstanding your point about functions instead of objects.
I felt like I was asking the same question all the way through the end of college. The answer is that "real" programs (which I take to mean GUI apps) are basically just thin layers on top of command line-like programs. The distance between writing a calculator command line program and GUI seems insurmountable, but it basically just boils down to using some software organization patterns like MVC (Model, View, Controller) and calling out to libraries that can draw to screen. A good way to make the gap seem less daunting is to use HTML. Write some HTML pages by hand, then write Python script to automate the construction of webpages. Keep iterating on that and you've got the basic principle of how much of the internet work. (Reddit itself is Python, as it happens!)
LXML has such a crappy user interface that it's almost worth any speed penalty to get away from it. It's not actually worth it, but it's _almost_ worth it.
+1 for that, yep — that's what we would use for this problem. It'll spare you from having to subtract each remainder from the remaining quantity. (Seconding [/u/EvM](https://www.reddit.com/user/EvM) :). 
Hey there! You have been shadow-banned from reddit. Check out this sub: /r/Shadowban for more info on this. You'll need to [contact the reddit admins](/contact) to get this sorted out. 
Great tutorial, I get really excited when I see new posts about Kivent / things made with Kivent. Keep up the good work!
If the html isn't your own, always use defusedxml.
lxml is based on libxml2, which does this by default unless you pass the option `HTML_PARSE_NODEFDTD`, I believe. Code [here](https://github.com/GNOME/libxml2/blob/master/HTMLparser.c#L4777). I don't know if you can tell lxml to pass that option though.. libxml has python bindings that you could perhaps use directly but they seem really hairy. EDIT: did some more digging and that option does appear in the lxml soure [here](https://github.com/lxml/lxml/blob/master/src/lxml/includes/htmlparser.pxd#L20). That option does exactly what you want but I'm not sure how to activate it yet, if it's even possible.
I guess I could have been a bit more descriptive. The distinction I'm making is functional programming vs object oriented programming [1]. Pandas revolves around the DataFrame **object**, which you create and then call **methods** on: import pandas as pd df = pd.read_csv('file.csv') df.sum() meza revolves around **iterators** with which you apply **functions**: from meza import io, process as pr records = io.read_csv('file.csv') pr.merge(records, pred=bool, op=sum) The advantage is since there are no special objects, any compatible iterator works will all of meza's functions. [2] &gt;&gt;&gt; import itertools as it &gt;&gt;&gt; records = it.repeat({'int': '1', 'time': '2:30', 'text': 'hi'}) &gt;&gt;&gt; next(pr.cut(records, ['text'])) {'text': 'hi'} - [1] https://www.google.com/search?q=functional+vs+oop&amp;ie=utf-8&amp;oe=utf-8 - [2] https://github.com/reubano/meza/blob/master/docs/FAQ.rst#memory
Ok. If that is the case, can you please show the the canonical way of "Reading a file that won't fit into system memory"? I'm by no means a pandas expert, so I rely on what its documentation says. 
&gt;I could be wrong, but it appears that pandas reads the whole file before detecting the types. It does not read the whole file. It sniffs a chunk and chooses appropriately from that. It complains that you didn't specify types if it gets halfway through a file and then has to change a column type. NaNs are the worst offenders because they cause upcasting of ints for performance reasons... A fact which annoys me to no end due to my use case. The join is clever. I do like that. I think the biggest things your code has over pandas is pypy compatibility and smaller footprint. Play those up, but play with pandas a little more before you say it can't do "x". 
That shouldn't be necessary, given all the attacks it defends against, except for zip bombs which are really something that affects everything and better handled in a lower layer, are specific to XML and don't apply to HTML.
Points taken. Pandas is a great project so I definitely have no intention to claim otherwise. It is huge and takes a while to figure out all its capabilities. Even the research I did on type detection suggests that it is inefficient [1] (again, linked to from the pandas cookbook). I'm not trying to discredit your statement, just merely showing how difficult it is to actually figure out what pandas does and doesn't do. Will follow your advice though. [1] http://stackoverflow.com/a/15556579/408556
:-) pandas is one of those 500- item Swiss army knives. It does everything but it's heavy as hell and other tools do certain jobs better.
I think you need to contact somebody who knows more about the lxml source code, perhaps file a bug somewhere. From what I can see lxml doesn't support this option currently meaning you're pretty much out of luck unless you want to use libxml2 directly (whether through their python bindings or ctypes or cython or whatever). You might be able to get the lxml guys to add an option for this, or maybe there already is a way but we've just missed it. I'd Google around and see if the devs have like a mailing list or something. 
Look at the apache tika libraries. They have python hooks.
Right, right. It's just that if you have very little memory and resort to chunking *then it's pointless to read all the chunks into memory and concatenate them*. It consumes just as much memory as if you read the whole file to begin with because you still have the whole file in memory. The file reader itself doesn't care how large the file is and will keep happily reading until the system refuses to allocate more memory. I've used chunking to move huge CSV files into hdf5 datastores and sqlite databases. That way I never have the entire dataframe in memory at any time.
bro, do you even xpath? 
[2 days ago](https://www.reddit.com/r/Python/comments/42ghjj/use_json_files_as_if_they_are_a_python_module/).
These are good. I've been teaching a class of 11-12 year old boys (6th grade US) using *[Hello World!](https://www.manning.com/books/hello-world-second-edition/)*, and it has many of your exercises in it, plus a lot more. However, it does not have turtle graphics, so I taught that without the book.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Hi, now I'm not at home. But tomorrow I will do. ;-) However it requires about zero configuration.
&gt;how does this compare to aria2? It doesn't, aria2 allows for all kinds of flexibility. (Many threads to 1 download, multiple download sources, etc.) "DSDownload" allows a configurable number of files to be downloaded at the same time. It does not multithread the download of a single file. I'd love to know how they came up with "452% faster."
Old/current PyPI doesn't use zope. They didn't want to pick a web framework because that would be showing "preference". That " brilliant" decision made maintenance and security craxy fuck harder. Learning and contributing to the current choice base is annoying and frustrating, hence the small pool of individuals who have tried. The current maintainers have dealt with this design mistake for years of painful debugging,, and we owe them a lot of thanks.
I'm not sure I would use a decorator in this context, but I don't see anything wrong with raising an exception in the wrapper function returned by a decorator. Raising the error in the decorator itself probably would be a bad move, but in an empty decorator like `def mydeco(f): return f`, `f` can clearly raise an exception whenever it likes. Does this mean that `mydeco` is raising that error? Of course not, the error is being raised in `f`. Similarly in your example, `check_credentials` does not raise the exception, `wrapper` does. Since `wrapper` is supposed to be modifying the behavior of `f` this seems like a normal use case to me. It may make things a little harder to track down at debug time, but python stack traces are generally pretty good and would point straight to this decorator implementation. I would ask your coworker for an explanation as to why they think it's not a good idea to do this along with some examples where it can go wrong, rather than just taking it on faith. There may be a reason I haven't considered that would make it a bad idea, so don't just take my opinion and run with it.
looks like we have a disagreement here folks, who has some evidence? 
 &gt;It's an extreme example, but the general premise holds: the longer the line length, the more likely it is for an individual line to be much shorter than that limit. If your limit is 20, most lines will be near the limit, so an editor window of 20x80 characters will be filled almost completely, i.e., it will make maximum use of screen space. The problem is you don't want maximum use of screen space. "Matrix" like screens simply aren't readable by humans no matter how much it makes for a good movie. Your goal isn't 100% fill rates on the screen it is rather legibility and keeping statement concise. &gt;If your limit is 200, most lines will still be under 20 characters, let's say your average line length is 40 characters; this means that on average, you are using 5% of each line, and a 200x80 character window will display 5% code and 95% whitespace. You really need to ask yourself what this has to do with anything. &gt;No matter how you render your text, or what IDE features you throw at it, as long as you're looking at the code itself, that is the screen space usage you will get. The only alternative is to make your window smaller than the maximum line length, in which case some lines will never be visible in their entirety, or to use line wrapping, which will make indentation / alignment less obvious. Wrapping of text sucks, this is one of the reasons I hate limits on line length. It really doesn't matter if the editor does it for you or you do it yourself by breaking up a statement into multiple statements. Think about this for a minute, let's say you need to look at or edit a large CSV file. If you open this text file up in an editor would you want it to wrap the text at the 80 the column? I would imagine not as it would make for significant readability issues. If one of the data filed has a lot of text in it, say paragraphs of text, you run into a problem, that problem won't be solved by wrapping text in an editor you may very well need a more specialized tool to view the data. Now granted this is slightly different than programming but it is all about how you organize things for human factors. &gt;But the above still holds: either you see everything plus a lot of empty space, or you see not-everything but more of it. I really don't understand what you are getting at here. White space in most circles is considered a good thing for code. Readability actually goes down hill if you break up a line of text into multiple lines simply to meet an arbitrary line width goal. Your white space then gets replaced with a thick block of text with the line breaks as such that the flow of the operation gets broken up. &gt;I don't even know what that is supposed to mean. Neither do I. I think my iPads auto correct screwed me bad. The idea is that you write software in a way that even a NON PROGRAMMER could have some ability to understand. The opposite approach is something like APL where programmers can write a program in five minutes and not understand what "they" wrote ten minutes later. My whole point in logging into this thread is that I really believe that arbitrary line length limits lead to bad code. Code that is hard to read and maintain. This isn't an argument supporting 200 word lines at all, it is about making sure your code represents what is going on cleanly. If that takes 81 characters for a line of code it shouldn't be a problem to anybody. As somebody else mentioned the days of punch cards are well and truly gone. So too are terminals with 80 columns of text hooked via RS 232. This is where these text length limitations come from, it really has nothing to do with legibility. 
&gt; at what point does coding leave the shell and become an actual program that does things? The shell is an actual program that does things. Things like retrieving, transforming and relocating data. The shell runs in an OS. That's an actual program that does things. Things like connecting and synchronizing hardware devices, optimizing the access and transfer of data. The OS runs on your microprocessor, which may contain microcodes: actual progams that do things. Things like optimizing calculations. For the sake of developmental efficiency, technology is often developed in layers. If a programmer had to write his program, and an OS, and microcode, he'd never get anything done. Instead, we have nifty tools like Python that allow us to get a lot done with a little code, because we don't need to worry about the lower-level details. But Python is itself just a layer in the overall sandwich of "doing things". You may need several more layers to get your "thing" done, such as a user interface, possibly on a remote hand-held device (your mobile phone), possibly through a sensor / actuator (your home automation), or any other number of devices. You may also need several more data layers, such as an online database, or an interface to a messaging system, etc. An engineer needs a tool kit, as well as materials, to build a machine. Python is just one tool (data / user interfaces could be considered your materials)... but it is a versatile one!
[Facebook](https://code.facebook.com/posts/872547912839369/improving-facebook-s-performance-on-android-with-flatbuffers/)'s article has caused my biggest interest in using it.
Great, thanks!
What a great website. I invite you to link to your videos from blogory.org/python
Cool! I'm not an engineer so some of the math goes over my head. One piece of advice though, make sure you reference iPython Notebook or Jupyter in these posts so that people know right away this awesome tool is being used. I suspect it would draw more people. 
My apologies. Didn't know there was another subreddit. THank you
https://docs.python.org/3.5/library/collections.html#collections.UserDict
https://github.com/euske/pdfminer this is pretty good, particularly for text data. you'll occasionally run into really pathological pdfs that have crazy shit like content blocks of 1 character each, or something awful like that, but for the most part this works. 
Nice. Bud sadly only for 3.x.
two too: https://docs.python.org/2/library/userdict.html For reference, few things are Python 3 exclusive in the standard lib. A quick Google search would have found the above.
Python 2 is for Luddites!
I've scraped a database of 400.000 PDF documents. Started out with PyPDF2, but it was no good, because it got some encoding tasks wrong and page numbers were situated awkwardly in the flow of the text. Then I tried to find another pdf parser just to understand more about how extracting text from a PDF document works. Stumbled upon PDFBox and it worked so well that I decided to use Java for extracting text from PDF documents. The result is so clean that I now present the text extracted from PDF on my website rather than the PDF itself. I have been told that PDFBox is actually integrated into Elasticsearch and so you could use it with the Python bindings of Elasticsearch. 
Your overiding methods work, it's just they are not used for building the second dict: class B(dict): def __init__(self): self['a'] = 'b' def keys(self): return [1, 2] def __getitem__(self, key): return 1 &gt;&gt;&gt; dict(B()) {'a': 'b'} &gt;&gt;&gt; B().keys() [1, 2] &gt;&gt;&gt; B()[0] 1 It's not a bug, it's because you expect dict(mapping) to always use keys() and \_\_getitems\_\_ to build the new dict, which it doesn't. dict() only use them if it can't find a more efficient way. When passed with a real dict or dict child, it probably uses directly the C API to copy the key/values which is more efficient.
/r/learnpython
Thanks for submitting. No, this is not maximum recursion depth problem. In fact, **iif** function will never run as I believe. Your solution works for this particular function. I had just use factorial because it is so simple and well known. The target is rewrite *iif* function to mimic if-else statement and works with recursion. Well, it is probably impossible because you have to achieve not to evaluate last **z** expression. I surely know how to write factorial and recursive function myself. :) 
As others have said, it wouldn't be considered a bug. If you need the functionality of creating a new dict from your subclass, you'll need to implement an initializer method \_\_init__ that checks for the presence of your subclass in the argument list, and otherwise calls up to dict.\_\_init__. Or better yet, override dict.copy
I wouldn't call this a bug. Inheriting from any type is risky because it can break encapsulation -- you've discovered that you now need to know how a `dict` represents itself internally in order to subclass it in the way you want, and that's a "bad thing"™. It's especially risky if the author does not *explicitly* document how and when the type can be subclassed. For example, the Python docs say that we can [subclass `dict` to override `__missing__`](https://docs.python.org/3.5/reference/datamodel.html#object.__missing__), so inheriting in that case may be warranted. But the docs say nothing about overriding `keys`, `__iter__`, etc, and so it isn't clear what the resulting behavior should be. For example, what does `list(B())` do when `B` inherits from `dict` in your code above? I'd argue that the correct thing to do here is to use composition rather than inheritance -- and it looks like someone gave you this advice in the other thread, which is good. Subclass from the `collections.MutableMapping` abstract base class and write a class that simply wraps a `dict` and provides your special behavior. It may take a little more typing, but the purpose of inheritance is not to cut down on keystrokes ; ).
Right, that's what I said, or at least intended to. As you wrote it, `iif` will never be called, because `fact` recursively calls itself without a base case. If you want `iif` to work in this recursive setting and be called, you'll have to define `fact` in such a way that it doesn't evaluate itself (but rather `iif` evaluates it) or `fact` establishes a base case (and in this case, you don't need `iif` at all).
Thanks! I don't always hear much since KivEnt is still very new, and it's mostly me. It's good to hear there are some people out there following the progress.
I stand corrected.
 def iif(x, y, z): return x() if y else z() fact = lambda x: iif(lambda: 1, x&lt;2, lambda:(x * fact(x-1))) # Or ... def fact(x): return {0: lambda: 1}.get(x, lambda: x * fact(x-1))() The `lambda`s are necessary to delay evaluation of the recursive call.
I'm fine with it in my projects depending on the context, and Django [does](https://github.com/django/django/blob/master/django/contrib/auth/decorators.py#L72) [it](https://github.com/django/django/blob/master/django/contrib/admin/decorators.py#L23) in a few places. He's probably saying something like "don't raise for user-visible stuff", ie. login validation, instead only raise to ensure the programmer isn't using the decorator in the wrong place.
I didn't quite understand... There's some variable that should be assigned by stdin (e.g. raw_input) and isn't?
Nice one, thank you. I would say this is closest to what I would call solution but I would object tweaking your factorial function instead of pure tweaking iif :) But I like it. EDIT: You can use partial as well to do same thing: partial(fact, x-1) &gt;&gt;&gt; partial(fact, x-1)() == fact(x-1)
See my edit of original post. I consider this to be mental exercise not reinventing wheel :) I could not use and/or simply because of fact I planned to use only functions :)
&gt; I would ask your coworker for an explanation Did that, check my other comment.
I would say your function is most definitely using an if-else construction. You used to word `if` in it. Do it with a single while loop.
SQLAlchemy is great but try the DAL before making a final choice. DAL for example, can abstract Mongo and Google Datastore as well as 10 supported database. Can do inner and outer joins, expressions, aggregates, etc. For example (assuming a SQL db): rows=db(db.product.purchased_by==db.auth_user.id).select(db.auth_user.first_name, db.product.cost.sum(),orderby=db.auth_user.id) 
Like Google, Lucas, NASA, Eve, and virtually all other serious users of Python. There's a difference between advocacy and zealotry, friend.
I did the same thing, screwed around in Python for a bit before giving up and using Java.
How flexible does it need to be? If it's for one model of gauge, with a fixed camera, it should be enough to detect the needle, measure its angle, and have a predetermined angle -&gt; reading map. If it's for similar gauges where the scale and camera position might differ, how much set up can you expect the user to do? It can still be fairly simple if you rely on the user to calibrate it for their scale. If you need to automatically recognise the scale, that's more challenging. I don't think PIL has the necessary stuff to make this easy - look into [SimpleCV](http://simplecv.org/) and [OpenCV](http://opencv.org/) for ideas.
It's definitely a true statement
was hoping it could just be a handheld shot, but if the scale is an issue, maybe i could have an overlay on the screen to help them get scale correct, and therefore make my job easier
Actually deployment is done via Heroku (currently at least, subject to change at any time) but local development environment is managed via Docker.
Luddite here. It really is. One day we will ascend to glorious Python 3. But really, the unicode/str crap of Python 2 continually bites me in the ass and I'd love to dispense with that altogether by moving fully to 3.
&gt; Python 2 is for Luddites! Yeah, throw away all the billions lines of code in all the companies and start again \o/
&gt; Your overiding methods work, it's just they are not used for building the second dict: I know they work, I even know when they didn't now. But I don't think that it is good idea to have random unexpected behavior, which is really, really badly debugable. After all, this is not the PHP.
&gt; I'd argue that the correct thing to do here is to use composition rather than inheritance -- and it looks like someone gave you this advice in the other thread, which is good. Subclass from the collections.MutableMapping abstract base class and write a class that simply wraps a dict and provides your special behavior. It may take a little more typing, but the purpose of inheritance is not to cut down on keystrokes ; ). I've solved the problem differently. But I still think that having this undocumented behavior is not a good idea.
You also need this when you use `**my_dict`. `.copy()` should imho create a copy of object, not object of different type.
Hm, interesting. I've never heard of this bug. Do you have an example at hand to demonstrate (and reproduce) the described behavior? I am curious. Btw. I think your assumption is not correct &gt; I assume that an ndarray is not a "sequence"... For example: &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; np.arange(10) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) &gt;&gt;&gt; type(np.arange(10)) &lt;class 'numpy.ndarray'&gt; 
It happened to me. It was indeed awful.
Trac does this with the trac-admin tool. [Line 116 of this file creates the entry spot.](http://trac.edgewall.org/browser/trunk/setup.py) and [connects to line 596 \(def run\) of this file](http://trac.edgewall.org/browser/trunk/trac/admin/console.py). I lifted that setup to make [a command line interface ontop of the iBoot DxP protocol package](https://github.com/Wildcarde/python-iboot).
Sorry, a bit after the fact, but is there support for async functions? Any asyncio support?
Exploring it a little more, it seems like the bug occurs only with multidimensional ndarrays. I don't have a jupyter notebook to share, but try this in your python: &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; import random &gt;&gt;&gt; a = np.array( [[1, 2], [3, 4]] ) &gt;&gt;&gt; random.shuffle(a) &gt;&gt;&gt; a Sometimes, but not always, this sequence of commands will result in a becoming [ [1, 2], [1, 2] ] or [ [3, 4], [3, 4] ].
Be sure not to tell *anyone* your method for solving it. 
&gt; If your're writing a library (i.e. more than a single file) and you want it to be installable, you will need to add a `__main__.py` file to your project. I've been coding in Python for 10 years and never once made a `__main__.py` file. My largest package to date is probably 300k lines, mainly written by me. You don't need them. If you want to be installable, you need a `setup.py` file and probably `__init__.py` files for organization.
I just ran the following code: In [1]: import numpy as np In [2]: import random In [3]: a = np.array([[1,2],[3,4]]) In [4]: a Out[4]: array([[1, 2], [3, 4]]) In [5]: random.shuffle(a) In [6]: a Out[6]: array([[1, 2], [3, 4]]) In [7]: random.shuffle(a) In [8]: a Out[8]: array([[1, 2], [1, 2]]) So, I think I just replicated the behavior you're talking about, unless I'm missing something.
This is really interesting, I didn't know argument-less lambdas could be used in this way.
Awesome feedback, thanks a lot! In regard to structure, good point. It didn't occur to me that tests could be outside of the main tree. I'll move it there :) And good point on dynamically generating test data... I realized it's the only way I'll easily be able to attain full(er) test coverage. I'll work on that later. I skipped 3.5 by accident. I was using a .travis.yml file from another project as a guide, and I guess that project hadn't added Python 3.5 support yet. The "requirements.pip" thing is the input to a program called [pip-tools](https://github.com/nvie/pip-tools) and "requirements.txt" is the output. It automatically creates a requirements file where the versions are all locked to the newest available, so you don't need to worry about users getting incompatible dependencies that break your program when installed. Totally agree about ChatMessage after looking into it again. I changed it into a named tuple. The threading thing was a vestige of something else I was going to do, but forgot about. I'll take it out and remove the callback thing. No idea why I did that with the generator after taking a second look. Fixed :) Good point on everything regarding terminal colours. I found it kinda odd that that library I used doesn't come with wrapper functions. Maybe I'll create some for the library and submit a PR. I see what you mean about logging. Is it possible to do the "progression" effect I have though with standard logging? Not sure what you're referring to with [0:30]. Isn't that the middle of an import statement? :/ Good catch on the [::-1] thing. .reverse() makes a lot more sense on the surface. Thanks again for the big write up!
That's exactly what I mean! Thanks for taking the time to replicate it.
This is nice, I like it. Agreed that this is cleaner and more general than my example. Thanks for expanding and making it better. And I learned something! `functools.partial` is pretty handy to have in the toolbox, I'd imagine.
HTML is just a XML with a well known schema and relaxed usage rules.
I just did a pull request to improve the functionality of this library a thousand fold if you are a lazy backend developer: https://github.com/kragniz/json-sempai/pull/25 https://github.com/kragniz/json-sempai/issues/23
I'm pretty sure this wasn't targeted at my post.
How did you remove the page numbers with PDFBox?
The docs state that the positional parameter needs to either be a mapping object or an iterable of iterables with exactly 2 objects each. So, MutableMapping is definitely a good way, or you could just write a class that implements `__next__` and `__iter__`. Seems like a useless exercise though to implement a class that's sole point is to construct a dict a certain way, and through the dict constructor specifically.
Here is the code for the shuffle function: https://hg.python.org/cpython/file/2.7/Lib/random.py#l277 Basically it iterates the list in reverse index order, picks a random index lower than the current loop one and does an in-place substitution on both indexes. The problem is this operation: x[i], x[j] = x[j], x[i] If you test this directly in numpy, it will fail: import numpy as np a = np.array([[1,2],[3,4]]) a[0], a[1] = a[1], a[0] print a Out: [[3 4] [3 4]] 
Here is the code for the shuffle function: https://hg.python.org/cpython/file/2.7/Lib/random.py#l277 Basically it iterates the list in reverse index order, picks a random index lower than the current loop one and does an in-place substitution on both indexes. The problem is this operation: x[i], x[j] = x[j], x[i] If you test this directly in numpy, it will fail: import numpy as np a = np.array([[1,2],[3,4]]) a[0], a[1] = a[1], a[0] print a Out: [[3 4] [3 4]] Not sure if it is a bug in numpy or a documented gotcha (their indexing doc is overwhelming: https://docs.scipy.org/doc/numpy/user/basics.indexing.html)
Uh, 2010 called...
Subclassing dict is not a normal thing to do in Python anyway.
I'm sorry, which of the large, important Python shops I named is using Python 3 in a major way in 2016? Which did I miss that I should have included that I should have? MailChimp, maybe? (Is there no one more serious--I can't think of whom.) We can add Dropbox, Yahoo, and Reddit to my list.
My love for `dotteddict` and I disagree.
[removed]
I don't know if I'm just slow, but I don't get what is means to put openpkl into a password input to view logs, from what I understood it didn't work
No worries, HTH. &gt; I see what you mean about logging. Is it possible to do the "progression" effect I have though with standard logging? If your intention is to provide incremental feedback to the user indicating current status, then there's no reason why not. Using logging, you simply expose standard configurability to users through logging such as using other logging managers (i.e. syslog) without having to deal with piping at shell level and such. It's also super easy for a user to stifle your logging output based on log levels, which can be a huge benefit at times. &gt; Not sure what you're referring to with [0:30]. Isn't that the middle of an import statement? :/ Heh sorry, I was starting to get lazy. This wasn't row:col, but a list slice :) There must be a reason that you're ending at 30. A constant lends itself much better to readability is all.
Yah. I also don't know what "traditional download" is.
It is only necessary if you want to be executable using 'python -m' An example reason would be if you are not allowed to put a script on $PATH.
Say that you will do it as he recommends. He needs to be able to enforce some basic stylistic constraints, and maybe you will learn something. Then ask your coworker what his reason is. It is impossible for reddit to guess.
Thank you, see my Edit 2 in original post.
To learn something new was my intention. PS: You can use partial in very useful way, not only for function but even for partial object creation. 
You could roll your own simple motion detection in like 30 lines with [Pillow](https://python-pillow.github.io/).
;-)
Eager evaluation is not causing any trouble. But if you don't like eager languages, just stop writing Python and only write Haskell.
I think the underlying cause of this symptom is that numpy arrays return [views](http://docs.scipy.org/doc/numpy-1.10.0/glossary.html#term-view) for a lot of the array operations (in this case the index a[0] refers to the same underlying memory as a). The behavior is the same if you do a temp-variable swap, but easier to see in action: t = a[0] # t refers to the same underlying memory as a[0] a[0] = a[1] # copies bytes from a[1] into a[0], now t is also [3, 4] a[1] = t # copies [3, 4] back into a[1], which is already [3, 4] 
&gt; Would I be crazy for wanting to use this in actual code? Yes. Ignoring the security implications, what happens if you have a typo and accidentally download a massive package? It is also a problem if you depend on this functionality for code you distribute to other people. Not everyone has an internet connection, and among those that do not everyone has one all the time.
Jesus Christ
How do you control which version of the dependency you download?
I'm currently working on something with a similar premise. [Pyimagesearch](http://www.pyimagesearch.com) is a fairly good place to start. It's definitely not small or light since it relies on Opencv, but it will get you started. I'm not at my computer right now, but I'll try to remember tomorrow to send some other links when I find them.
Please no.
[you animal](http://i.imgur.com/RJMimfk.jpg)
/r/learnpython
wishful thinking and tears
A library to download a library so that you don't have to download a library. Librariception. 
&gt; Subclassing dict is not a normal thing to do in Python anyway. Do you realize, that this behavior is also present when you subclass OrderedDict and almost any other dict-like structure, you can found in python API? So .. dont subclass anything dict-like, because of random interpret-specific optimizations.
&gt; I don't think you should expect a library's internal code to always access itself using its own public methods, especially when that makes it slower. Eh. Okay. Indeed magic methods, sometimes magically ignored. &gt; For what you're trying to do, you should either call your own constructor, or call dict() with a generator instead of the object itself. This is part of the module API and I can't control what the users will do with it. Only thing I can is to make sure it works as expected and that dicts-like objects will be convertible to dicts.
Thank for the info. &gt; Honestly, if there's a bug here, it's that the language allows you to subclass dict, set and list in the first place. Why?
If you were raising it in the decorator itself then I might agree, but putting it in the wrapped function *shouldn't* be an issue and there's no good reason not to. That being said, you should probably have the checking and exception raising performed by another function so that the decorator is kept concise and so you can use it from another context where a decorator might not make sense.
In that case, you should use composition instead of inheritance - wrap the dict type and pass through the methods you don't want to override, but don't subclass it. The result will be an object that looks like a dictionary but isn't copied like one. &gt; Eh. Okay. Indeed magic methods, sometimes magically ignored. No. This isn't some weirdly inconsistent API, it's just an incorrect assumption about how the constructor works. The one thing that is "magic" about this is that due to Python's dynamic typing, there's only one constructor. If this were Java or something statically typed, you'd have multiple different constructors, and they might look like this: HashMap(Map&lt;? extends K,? extends V&gt; m) { // Constructs a new HashMap from an existing Map. } HashMap(HashMap&lt;? extends K,? extends V&gt; m) { // Constructs a shallow copy of an existing HashMap. // (in reality, this would be the clone() method) } In that case, there'd be no doubt that passing a subclass of `HashMap` isn't the same as passing a subclass implementing `Map`, and invokes a different constructor - one that copies the HashMap directly, without caring about overridden methods.
Can someome explain why everyone is saying stuff like why did you do this? 
Impressive work, and it's under 3000 lines!
I can almost picture the asshole that is too lazy to install the package they need, but cheeky enough to get this working instead.
Thank you for your generous comment. I will upload a link. 
Do you mean [in this comment](https://www.reddit.com/r/learnpython/comments/42rqee/help_dict_subclassing_and_dictmy_subclass/czcv885?context=5)?
If the gauge is always the same, you could try to identify features (like the mounting screws in the example photo) to work out where it is. Or write a special smartphone camera app that indicates where to line up the scale to take the photo. But it's hard to imagine any of this being easier or more reliable than just having the user read the gauge and type the number in. If it really needs to be automated, I'd look into digital pressure sensors that you can connect to an Arduino or a Raspberry Pi or something.
I also brew beer, though not professionally (yet). I've been interested in doing something similar to this, i.e. using sensors, data, and software to improve the consistency of my beer. if you want, I'd be interested in collaborating with you, or at least swapping ideas. I am a mechanical engineer and I have experience with digital sensors and programming microcontrollers, so I feel like at the very least I can get you away from this pseudo-ocr path you're on and get you hooked up with digital pressure readings for under $100.
Nice, thanks :-) It looks quite similar to Qt designer, which I've used before. What kind of file does it save? Is it producing a declarative file like the `.ui` files Qt designer uses, or is it producing Python code directly? How do you connect the UI it makes to your code? Do you plan to integrate an editor into it to make a kind of specialist IDE? Or do you prefer to point people to an existing editor to write the code parts of an application? How is it handling layout? Is it easy to e.g. snap something to a corner or a centreline so it looks right when the container changes size?
&gt; If you need the functionality of creating a new dict from your subclass, you'll need to implement an initializer method `__init__` that checks for the presence of your subclass in the argument list You can't override the `__init__` of the `dict` class, like, in the dict class itself, which is what would be necessary for your suggestion to work. Overriding it in your subclass wouldn't help when `dict(my_dict)` is called.
Very nice, I recently released a project with a similar goal called [meza](https://github.com/reubano/meza) and would be interested in your thoughts.
Reading the doc (https://docs.python.org/2/library/stdtypes.html#dict), nothing let you think which method it particularly use to populate the dict. It just says 'mapping'. You assumed a definition of what a mapping is, and reduced it to 2 methods. 
Hi, It saves directly into python code. The py saved file is ready to be executed and does not need further operations to work with. The best is to use existing editors, I haven't planned to write a new code editor. But maybe in the future I can mind to write some kind of plugins in order to integrate the library in an editor. Right now you can use a auto-layouting container or an absolute positioning container. The HBox and VBox widgets layouts the widgets automatically (the size of children can be modified by the right side property panel). The generic Widget container allows to drag and resize children manually. But, you are not limited to this. As this is an "html gui library", you can manage the layouting as in a standard webpage.
If you want to extract content from a PDF file, then pdfminer (for python 2.x) or pdfminer3k (for python 3.x) are the most reliable libraries I have come across. The below links provides detailed overview on how to use the library. https://euske.github.io/pdfminer/programming.html http://denis.papathanasiou.org/posts/2010.08.04.post.html If you are looking at transforming PDF file, such as combining pages or removing pages or rotating pages, then PyPDF2 library is the simplest library I have come across. However PyPDF2 does not work well, if you actually want to extract content from PDF.
This might: http://www.tryton.org/
To speed the operation of finding overlaped record, I suppose you need a rtree index on ipstart and ipstop. http://www.sqlite.org/rtree.html 
Isn't that basically automated with pip requirements files? That's how we do it where I work.
nlib is a better name. That's all I got.
I downloaded cx_freeze and did the same as you do using py2exe
Because the definitions for those types don't exist in any py file. They aren't written in python, they are what python is written in.
They have those, it's called malware.
This looks much better, doesn't recommend bad practices and is maintained by someone without a sad track of responding to criticism. Edit: Some time ago I stumbled upon [agate](https://github.com/onyxfish/agate) it looks quite good. Here's an introductory article https://source.opennews.org/en-US/articles/introducing-agate/
&gt; You assumed a definition of what a mapping is, and reduced it to 2 methods. Actually, if you look at the linked post, I've reduced it to `.__init__()`, `.__setitem__()`, `.__getitem__()`, `.__delitem__()`, `.clear()`, `.keys()`, `.iterkeys()`, `.items()`, `.iteritems()`, `.get()`, `.popitem()`, `.__iter__()`, `.__contains__()`, `.has_key()`, `.__eq__()`, `.__ne__()` and few others, which I've tried during debugging. None of which worked. If you look at the C code, you will see why.
Then write the code and submit the patch. If it's a useful feature it'll get picked up. It might even get enough traction to be a whole class by itself. Some kind of user defined dict. A UserDict, even.
You're not supposed to inherit from dict in this manner. In programming there is a rule "design for inheritance or prevent it". Since in Python we can't prevent it, and since designing everything for inheritance would be a drag, the general rule is don't inherit like this *in Python*. Make a new thing called mydict (or something), that *contains* a dictionary. i.e. use composition.
You've been watching the same anime I have ;)
This should be in the sidebar: http://nedbatchelder.com/text/names1.html Then we wouldn't need people messing about with id().
This code is from a book. The library is automatically generated from the book LaTeX, so are the examples you see.
My view is that as everything in Python is an object and that all objects have a unique identifier then the use of the id() function can be a useful 'debugging tool' when you find yourself saying WTF is happening here. Using the id() function allows for reflection on the Python data model as shown at this link: https://docs.python.org/3.3/reference/datamodel.html
So this is not a library, it's an autogenerated code dump...
Just looking at the [code](https://github.com/carlosescri/DottedDict/tree/master/dotted), there is nothing there that subclasses dict.
thanks I'm looking to extract data only. I have no use for the pdf once the data is extracted. I'll take a look at pdfminer. How did you find the speed?
I did not mean using it literally for debugging but merely to experiment with small snippets of code to help build an understanding of Python code. Also the video is for beginners and maybe intermediate users of Python and if they are following the sequence of videos in the series they will not have covered identity comparisons - but I take your point here. Best wishes Phil
Now I remember! I was supposed to come back and thank you for the pointer that led on to [grako](https://pypi.python.org/pypi/grako), and a sufficient numbers of grammars to get me [back on track](https://pym.readthedocs.org/en/latest/parsing.html#parsing-non-python)
nice! I was aware of onyxfish's `csvkit` lib, but not `agate`. I'll see what I can learn from his implementation. And the graphing is really neat, btw!
Man, it's deceiving to call this a library. You even recommend using a * import without defining a `__all__` list... SO by your recommendation I'm polluting my namespace with all your test "functions". Come on, you KNOW this... The fact that you are teaching people using this gives me shivers.
ok, gotcha... I'm a flask guy myself, so I'm not yet hip to the web2py community :) 
This code has NOTHING TO DO with web2py.
Strawman fallacy. Most people think you should program Python like you do in Python.
Very nice work with meza although it seems to be very different in scope. Thanks for sharing.
Suppose I create a library called reqests that sends me all of your personal information when it gets imported. Now suppose you misspell requests.
You are welcome hang around the web2py community any time. We like Flask and we have learned a lot from it. We implemented some ideas coming from Flask including the thread local context and the optional ability to store session in cookies. We have made some of our modeuls like web server, DAL, and templates available to all frameworks. We are always discussion what the future should be and we would be happy to hear opinions from non-users.
Here's what's going on inside Python when this happens. Every Python object has a pointer to its "type" object. When you create your class and instantiate it, your B() instance points to a special B "type" object, representing everything we need to know about B. Inside the type object is a flags integer with some bitfields. One of them is called Py_TPFLAGS_DICT_SUBCLASS. If that flag is set, then Python knows this object is a subclass of dict, and it can make some assumptions about the object, and take shortcuts like ignoring methods on the class and instead calling directly into the C API. Whenever you inherit from dict, this flag will be set in your class. There are also flags for subclassing long, list, tuple, bytes, unicode, BaseException, and type itself. Inside the dict constructor, it checks to see if the object you pass in has Py_TPFLAGS_DICT_SUBCLASS set. If it does, it has a fast-path where it uses the C API directly (and otherwise ignores the type). If that flag *isn't* set, then it has a second "slow path" where it does what you thought it would do: it calls keys and __getitem__ and so for. Note that if you change B so it doesn't inherit from dict, the sample does what you were expecting: *dict(B())* returns *{1:1, 2:1}*. I guess this is one of those places where "practicality beats purity", and speed was judged more important than catering to obscure use cases like subclassing builtin types. If you want to override dict methods, you have to not subclass dict at all and instead implement your own mutable mapping object, as other people in this thread have described.
woah I need to give this a try. Thank You so much for this. I'll have to run this out on my simulated data. I guess the part that I need to figure out next would be accounting for the IP overlaps. For the module I use I'm able to just determine if there are IP overlaps and then call the exclude function to exclude that network and create a new network to create a new IP range. Do you have any insight on an efficient way to perform that task? 
Several, actually... :)
love this quote of the link. :-)
Interesting, never heard of Pillow before. Is there an obvious reason to choose Pillow over PIL? And are there existing implementations of such an motion detecting algorithm with them?
Thanks for the link. OpenCV might be too heavy duty for my use case, but it certainly looks like a very educational read!
yeah but someone could make requestss and have that automatically execute rm -rf / on install, so isn't pip an atrocity then? 
Anaconda should install most of the necessary packages, but for most things I need I use pip, which works fine. =)
&gt; rather than going through the command line process every time I need a package installed This sort of suggests that installing packages via the command line is difficult. How, exactly, are you installing packages? In the vast majority of cases it is as simple as `pip install packagename`.
Thing is even when I take the derivative without any filtering I can see the general trend that I expect, it's just really noisy. But when I increase *k* in the *UnivariateSpline.derivatives* from 0 to 1, the filtering is so large it masks most of the features and everything gets rounded. What I wanted is a mid-ground, where I just have enough filtering to get rid of some noise in the resulting derivative but still show the features of the data. I don't seem to be able to do that with *UnivariateSpline.derivatives*, but maybe there's another function where I can control the filtering a little better? Also, I could upload the data here. Just don't know how.
You are absolutely correct. The problem is that you do not know what packages do and they can do nasty things. This is true for all packages you install from the internet (pip, apt-get, appstore). You need to trust the source.
You might want to check with the folks of /r/pystats they are pretty well versed in this sort of thing. Its not particularly active so hopefully you don't need an immediate response. 
&gt; So .. dont subclass anything dict-like Don't subclass anything whose documentation doesn't explicitly say you can subclass it, and even then only subclass it in ways that the documentation explicitly suggests.
Don't be a dick; everything you've said is true and could be said much gentler. 
This looks fine to me, so long as you are handling that exception in your exception handler and not just returning a 500 to your user.
Yeah, ultimately you are right and he's wrong but if he's the lead you will probably have to back down. I would show him the Django code as an example of a decorator raising an exception in a pretty popular open-source codebase and perhaps that might change his opinion a little. I suspect he fears decorators out of ignorance :P
And the patch would add CPU cycles for every dict creation that anyone ever does in all of Python, to support an obscure edge case that is better handled in code that already exists.
I did not do it yet (users of my website prefer crappy html to pdf), but I think that I will use some kind of regex.
Conda is great but some times you cannot. Consider the case of shared hosts that do not have numpy and do not allow you to install binary packages. Also having pure Python algorithms means that they work on types other than numerical types. nlib and numpy+scipy do not completely overlap either. both contains algorithms that are not in the other.
What about using a pressure gauge that provides an electronic interface (serial/USB or even just a DC voltage)?
&gt; Still a shame about /r/python users being upset about you calling out this bullshit This isn't bullshit. This isn't even really about Python. It's about why inheritance is often a bad idea. How does `dict.values` work, internally? Does it call `dict.keys` and then use `dict.__getitem__` on each key it obtains? Or are all of the values inside the `dict` stored in a set, separately from the keys, so that `dict.values` can simply iterate over the set? As users of the class, we *shouldn't* need to know these implementation details. For one, it makes the abstraction of a dictionary easier to understand. And secondly, if the implementation of a dictionary should ever need to change (say, to make it more efficient), then it won't break our client code. When you subclass and override public methods of a class whose inheritance interface is not documented, you're making an assumption as to how the class works internally. In this case, it's a bad assumption. If you override `keys()` and `__getitem__()` as the OP does in the example, `values()` does not magically work. And that's OK. It isn't a symptom of bad design. It's a symptom of a programmer misusing inheritance.
As a sysadmin, if you try this you're getting locked out of production
You should use a better library to test your module. Did this work with python 3?
Yeah, all those CPU cycles (how much? 10? 20? and used only in `.update()`), what would we do without them? It is much better to create random, interpreter-specific optimization, which you don't tell anyone about, because, you know, optimizations, then say that subclassing of `dict` is doomed (why the fuck it is possible then?) and create UserDict written in python, because that is super effective and doesn't eat CPU cycles at all.
I feel like we are two or three missed abortions away from becoming Perl.
So, programmers. 
Best off with Java instead of python (unfortunately) - PDFbox has nothing even close equivalent in python. You could integrate into your python program relatively simply using subprocess and stdin/stdout, or do something more complex running a java deamon and communicating via sockets. 
Man, you people are downers. No, it's not a good idea to use, but it's kinda fun. 
Short answer: no. Long answer: this was written in a way that worked with both 2 and 3 but since it is extracted from a book in an automated way, and since readers of the book got confused by the compatibility statements so support for python 3 was removed. I can easily reintroduce it in the code but I do not want the code to be out of sync with the book. I will try address this in the next version of the book, within one month. 
That doesn't sound easier or faster
These are all terrible advice. The first rule of image processing is. Don't give me a random representative image, give me 20 images from tge real setup. Then I can give you good advice. Until then, everything here is wrong
When you post things publicly, you lose control of what is said or done about or around them. I've seen you fight this fight for years and you still don't seem to get parts of it. 
The good part is that the pythonistas realize the crazy sick shit is for educational use and not for production use. The perl users of times past never made this realization. Instead the insane sick shit was treated as hot, new, and cutting edge. 
You are free to say anything you want. http://i3.kym-cdn.com/photos/images/newsfeed/001/042/619/4ea.jpg
i'm totally game for the digital pressure reader and would be interested in collaborating
I use the example of `values()` to give an additional case where inheritance requires knowledge of implementation details, and to take away any special consideration given to the constructor. The OP's example, as you say, shows that he can override everything and the constructor does not work as he expected. In my example, I can override everything and show that `values()` doesn't work as one might expect. But is it really surprising that `values()` doesn't work? &gt; Or at least say that it shouldn't be inherited from The *default* is that a class shouldn't be inherited. Inheriting a class in Python should be treated the same way as messing around with names with a leading underscore -- it might break things, and it's probably not a good idea unless it is clearly documented. &gt; Then, dict is supposed to be inherited from. It provides the missing() hook for example. I gave this example in one of my comments above. Yes, subclassing `dict` to override `__missing__` is a valid, documented usage of inheritance. But that doesn't mean subclassing `dict` and overriding, say, `keys()` is going to have any well-defined effect. The documentation doesn't say that you can override `keys()` and what such overriding might do, so I simply wouldn't subclass `dict` in this way. I would say, though, that the documentation for the `dict` constructor could be improved to acknowledge this behavior, because as of now it isn't strictly correct. It says that if a *mapping* is given, then a new `dict` is created with the key/value pairs of the mapping, but this is ambiguous in the case of a subclassed `dict`. Are the key/value pairs those which are returned by `items()`? Or are they the data stored inside the superclass dict?
thumbsup up. just starts getting expensive.
Programming has always been a fluid process. I think from my own experience it's all trial and error. There is no definition of a 'good' programmer in python (or in any programming language really) - as there'll always be something else to learn (web development in Python, use of SQL databases in Python, using sockets and learning about packet structures, etc). There's an almost limitless amount of different topics to master in the world of programming so I think it's just best the learn the basics and then try to make 'something good'. Step by step. Figure out how you want to do it, then what you'll have to learn, then execute. Good Luck and Happy Pythoning ;)
When I said &gt; I think from my own experience it's all trial and error I meant you have to make the mistakes in order not to do them again.
Adding cycles to the dict constuctor is not going to be a popular suggestion. Dict is one of the highest performance objects in all of python, and it is used as such. Adding 10 cycles to an operation that is done trillions of times a second all over the planet is not a trivial decision.
Ok, i like it! :D
Reminds me of the post a few weeks ago about [direct imports from github](https://www.reddit.com/r/Python/comments/3zfe6x/import_python_modules_straight_from_github/). This type of stuff is wonderful for unorganized sysadmins (aka most of them) spending most their time with ipython across multiple systems. However, if I ever unknowingly installed a package that had this as it's sole requirement, and then tried to 'automagically' installed other packages from whichever pypi I am proxying at the time, heads would roll. 
Sqlite3 comes with Python and covers most needs.
I did not know he did that. I added your link to his talk to my readme file. 
When do you use this? Why would you choose to use this over `pip install -r requirements.txt` with versioned requirements?
You have to keep in mind that since the derivative uses two or more values the error effects are enhanced because you now have the uncertainty from multiple calculations to deal with. As a result you typically need to ensure your base data is low noise to start with. 
No longer really true, you can't even argue for PEP 8 without half of the Python community screaming at you.
The solution to all your problems is anaconda You won't feel like you need a gui because it works always (unlike pip)
It is background some people won't know about. It puts this code in context. It isn't like you wrote this without any prior history, saying "ha ha this is just a joke" when you have seriously advocated for similar things in the past. People will use the code if they want to and they can judge it however they wish, I'm not saying anything about it.
You have been pushing this particular boundary for years without any real reason. Now you are saying it is to explore and learn. If any horrible idea has equal priority, then we can just have some monkeys type on typewriters and then run their output in production.
That is not really true. The only PEP 8 issue I see others argue about is line length, which PEP 8 provides a soft recommendation. Anything else is usually the squabbling of a new user that has not written a script with more than 1000s lines split among a few files.
I guess some people are running numpy in environments where they can't reasonably get a numpy binary package installed, or locally compile numpy. I don't think this makes sense as a solution to that, but whatever.
try the gui tool for sqlite3/spatialite: http://www.gaia-gis.it/gaia-sins/windows-bin-amd64-test/ then you can import some test data to make your life easier. Then check out what to do in python. There's a bunch of short demos around the web. But the gui up there should make life a little more easy to learn the SQL part. 
I would automate the crap out of it, it looks like a perfekt use case for ... http://www.sikuli.org/ I automated a dozen of old BI tools with it. Think of me when you chill during the free time you'll gain. 
Oh cool! I like this. I guess that'd give me about two days to figure it out efficiently. But I think this chart is assuming you already know HOW to do it, and just need to compare the time. If you don't know how to do it yet, then I think the educational aspect makes any overage on time spent much more worth your while. I guess if I knew HOW.. then I guess I could shave about 2 days off of a 5 year span. I probably won't be with this company in 5 years haha. Thanks for the chart.
Yea.. good points. I will leave this alone, pretty much a guarantee I would fuck it up and get fired. I was just wondering if it was efficient if I were able, because I have a hard time finding things I need automated, and this would be at the top of my list. Also I can't test it without actually running invoices to my corporate office and saving them to the main network drive. Thanks.
I'm not really sure that this can be automated in python. If it could, I would automate it. I love automating things, so it's easy for me to see the benefits outweigh the time it takes to automate. I know you didn't want to hear how to automate this, but I don't think you need or could use python for this. This could be done using a macro. The issues come with you saving the new file your file name would need to be the same everytime in the macro. If the file name needs to be different, this might be too hard to automate and you'll just have to do the 20 mundane tasks a day. 
Nothing comes to mind, but I'm sure Google can help. This is the basics... import sqlite var = 'spam' conn = sqlite.connect(db_filepath) conn.execute("select xyz from table where parameter in (1, 2, 3) and user = ?", (var,)) conn.execute("update dinner set course1 = 'spam' where name = 'tomarse'") conn.execute("insert into dinner (course1, course2, name) values ('spam', 'eggs', 'Bryan')") conn.commit() conn.close() Edit: Thanks regendo
A subset of Numpy has been implemented for Skulpt. 
And what if WebAssembly really happens! 
Exactly. Only you want to make sure you document your docker image (aka install instructions) since it likely needs at least one outside port open to talk to the world. Just handing me the image with out telling me _any_ additional info is not that useful. 
you should get used to using a command line interface. its exceptionally powerful and once you get passed the initial hump of the learning curve you'll have added a very useful tool to your collection. 
Thank you. The point is exactly to make readable algorithms, not as a replacement of numpy/scipy. In fact the overlap is minimal anyway.
Here's a tutorial on sqlite3: https://pythonprogramming.net/sql-database-python-part-1-inserting-database/
If you are distributing it (as a frozen exe or otherwise) its nice to not have that requirement. Tacking on 60mb for the scipy stack is overkill if you only need it to compute a Fourier transform once (not a great example because its not in nlib either, but the point is a lightweight pure matrix implementation can have its uses)
Thought about that first, too. However, there's anaconda/miniconda now so that you don't have to worry about compilation and binaries etc. And if your system doesn't even support that ... well, I doubt that you'd do your data analysis on such a system for various other reasons ...
How does it perform speed wise?
&gt; https://github.com/mdipierro/nsa This is pure genius.
Even for the experienced SQLAlchemy can be a bit of an uphill struggle to get on board with, however especially for any kind of commercial development, this is an investment of effort that will guaranteeably pay off for you. The basics of SQLa aren't that difficult to get used to, and it comes with add-on tooling (like Alembic) that you will almost certainly eventually require in a project of any level of maturity, so it's worth starting to climb that hill now. You can always work directly in SQL, but at some point you are likely to outgrow its abilities (perhaps when you realize you've written the same boilerplate SELECT * for the 1000th time, or the first time you need to plan for upgrading the schema of an existing database, or..). Mongo and Couch are fine choices for 'simple' applications, but they heavily lack especially in writing aggregate queries (e.g. running reports), and in my experience no worthwhile application ever stays simple for long.
weird. not intentional. will remove it.
Thanks! I decided to not solder the buttons to the board, so I can't really interact with the thing to request other information. I have been considering to show new stats every five seconds or so. On an unrelated note, I ran into a problem with the install script. It wouldn't create /etc/pihole because of insufficient permissions. I made the directory manually and ran the script again to fix that problem.
At least it's not paste. Yeah, thanks, I'd love to store my configuration in .egg files or whatever.
When did you install? There was a bugfix pushed today that should have sorted that.... (I'm just reflashing my SD card now to try an install from scratch!)
https://youtu.be/XjNm9bazxn8
https://www.youtube.com/watch?v=b2F-DItXtZs At least MongoDB is web scale
With my own experience in the last 2 years in a windows environment, I never had any issues in installing python libraries. One thing I noticed is that python needs to be installed in a folder with a name with no spaces in it. Also the folder needs to be placed in the root drive like the C drive. Don't place it in the program folder directory because python doesn't like it. Why? Not sure. I can help with Windows installation. Created also a few programs for work which uses Windows computers and they worked fine. As for installing modules I use pip and wheel distribution files. 
&gt; On the other hand, do you think I should be using new databases like MangoDB or CouchDB ? If so, why ? I can recommend you [RethinkDB](https://www.rethinkdb.com/). It is very easy to setup, has a powerful functional query language (ReQL), provides a changefeed and clustering is very easy and it supports asynchIO, maybe because it is build on erlang. Besides its young age it has a very good [documentation](https://www.rethinkdb.com/docs/) and offers modules for python, ruby, javascript and java. Also the ReQL looks powerful, you can chain commands and use lambdas like normal functions and not a weird string, look at you sql. Also it seems to run pretty fast and when it's running you can go to `localhost:8080` you can see the dashbord and overwatch or administrate the whole database as a normal website. Pretty handy for example queries or creating new tables or indexes. Also joining different tables is pretty straightforward and so you can emulate relational data. Overall it feels like a hybrid of a SQL an Non-SQL database.
Any experience using this along side a Django app?
I've found it helpful to enable echo at first too so you can learn what it's actually doing under the covers.
oh gr8...ill have a look...thank you :)
Sqlalchemy is a pretty good orm.
What if you do legitimately need a remote server (ie. multiple Python clients checking results into a centralized server)?
Thanks! I got the web scraping part down (at least in AutoIt.. which forces me to use IE objects if I want to parse with AutoIts native HTML parser). It's ugly to say the least lol
Learn SQL first. http://sqlzoo.net is my favorite resource for that. Hopefully it never goes offline. :)
I share small scripts with coworkers who have no clue how to do things. Auto installing the library means I don't have to touch their computer to get it to work and can add libraries at will.
I think sometimes this is why my sysadmins fear me. I am capable of doing their jobs more so then they are of doing mine.
I'm not sure if you need to implement absolutely all of these, but it looks like the docs are saying all mapping objects need to have these. Also, if you do get away with less, no telling if an interpreter other than CPython will work the same, or even a later version. By far, it's much easier to just use an iterable of 2-item iterables instead of a mapping object. Or, you could use composition and just expose the dicts implementations of these. But given how easy it is to generate a sequence of 2-tuples and get the same result, I wouldn't do anything but that if you are just going to call dict(obj) on it after instanciating it. len(d) Return the number of items in the dictionary d. d[key] Return the item of d with key key. d[key] = value del d[key] key in d New in version 2.2. key not in d iter(d) clear() copy() fromkeys(seq[, value]) get(key[, default]) has_key(key) items() iteritems() itervalues() keys() pop(key[, default]) popitem() setdefault(key[, default]) update([other]) values() dict.items() viewitems() viewkeys() viewvalues() 
Generalizing on /u/SinEngine's recommendation: 1) you may need to apply one or more transformations on your experimental data before performing any statistical analysis. 2) you need to measure / estimate error bounds and carry those numbers through your analysis 3) your analysis should include some sort of "goodness of fit" score that will tell you how reliable your analysis is To 1): in addition to noise (which may or may not be Gaussian), your sensor data may also contain other sources of bias and/or distortion. Have you calibrated and/or characterized your sensor? Did you repeat the exercise before and after collecting your experimental data? &gt; I tried reducing the number of knots Tuning your filter to "fit" the data will introduce even more bias into your results. Instead, tune your filters to match your sensor's characteristics, then apply the same tunings to your experimental data. Edit: feel free to message me if you need more help. I studied experimental particle physics for a number of years, focusing on sensor design and characterization.
&gt; Anaconda isn't even recognized as a command and I've tripled checked,its set in PATH env var. The command is `conda`, rather than `Anaconda` (conda is a package manager, Anaconda is a big bundle that installs it along with lots of useful Python packages). That might make life easier!
I saw that, but I don't think I follow the process for taking a miniconda that I have added numpy to on my build server and then making *that* an artifact. Just zip the miniconda path? I guess that's fine. Or should I be messing around with conda build?
1. Installing Python, make sure to check the 'add to path' checkbox 2. Download and install pre-compiled modules from [this amazing place](http://www.lfd.uci.edu/~gohlke/pythonlibs/) For me, Windows is easier to install packages on than my linux systems (sounds crazy, hear me out). On windows, every tutorial or package that is available for it usually has a nice 'dummy guide' to get their stuff working. Trying to get proper linux development libraries installed on a non-mainstream version is just hell.
conda was unrecognized too!
I cannot stop laughing. I have never seen this. Thank you. 
I'll give this a shot later. Thanks! :)
Time to make a package that once imported contacts a server and listens for arbitrary shell commands, then put it on pypi under a bunch of common misspellings for popular packages (tronado, djagno, you get the picture. Could even use misspelled standard library stuff). Sit back and watch your botnet form around you. 
Just making sure, you downloaded lxml-3.5.0-cp35-none-win32.whl correct? 
Thanks - I'm going to check this out tonight. My current async solution is hacky at best. Are you able to call blocking calls like accessing the database from within the handlers?
This chart is a decent starting point, but leaves a lot out. For instance, is the task highly detail oriented, in a way that automating the task could reduce the number of errors? Is the task menial or frustrating? Does the task time depend on how large your data is (I.e. Do you need to manually check rows in an Excel file one-by-one, or are you going to throw all of the rows into an aggregation function of some kind anyway?), etc. Given that OP seems highly frustrated with having to repeat this task over and over, and given that it has to happen manually for each file with high possibility for mis-keying the file name or placing it in the wrong folder, I'd say automate if you can. 
I use pip as a fallback when a package isn't in the default conda directory. Both are pretty painless, but I've pretty much exclusively used virtual environments, which is a breeze with conda. This is on a mac.
Try posting on the anaconda google group list, they are pretty responsive. 
If you want to follow up debugging this: * Did you definitely install Anaconda, not vanilla Python? * What exact folder did it add to PATH? * Is there a `conda.exe` in that folder? * Have you opened a new terminal since PATH changed? * What's the exact error message you're getting?
And none of that would help because when the dict constructor detects that the other object is a dict as well, it bypasses all of them and stuffs its tentacles in the other dict object's privates. As determined by examining the source directly. So you are trying to send everyone else on a wild goose chase that everyone knows will end in "oh, so it doesn't work either". That's a silly and assholeish thing to do, you know.
[Tornado](http://www.tornadoweb.org/en/stable/) has had [WebSocket client support](http://www.tornadoweb.org/en/stable/websocket.html#client-side-support) since 2013. `aiohttp`, as already mentioned, is also nice.
&gt; you will probably have to back down &gt; I suspect he fears decorators out of ignorance Yeah, already did that the moment conversation happened, didn't want to make a scene like google proofs that I am right etc, I just said "ok, Ill check it in every method" and no hard feelings of course, just wanted to ask here if maybe I didn't know some "good practice" related to that. Thank you for your input.
5-10% speed increase with only [1%](https://mail.python.org/pipermail/python-dev/2016-January/142956.html) memory usage increase? Sign me up!
When website overrides a scroll, part of me dies.
Are you sure the randint function is being called each time the damage variable should be updated, rather than it being run only the first time?
If its genuinely a project with a finish to it then yeah sqllite is a pretty good module. Worth noting but where I work (terabytes of data) we'll use python for the extract and transform then postgresql for the load and construction of cubes for users. Perhaps ive been taugh in and old fashioned manner but as an ex-user myself they always want new data cubes or new stuff joined. And python ive found to be a pain when it misses joins and other "sql things". If its an ongoing thing that's my two cents.
Seconded: sqlite is probably the way to do with this, especially from Python. I would definitely stay away from NoSQL at first until you've had a chance to learn relational databases. That way, when you do learn NoSQL, you'll understand the trade-offs better. I see too many people have went down the NoSQL route without relational exposure, and then they don't understand why they're always having data consistency issues and why their queries are so slow. That said, single user databases are the way to go when just learning databases. If you want more visual / accessibile tools, Microsoft Access is also a good way to pick up the basics because you'll be learning normalization, indexing, SQL, etc. Heck, it might be a terrible option for this project, but it's just an example and there a lot of tutorials available to learn the basics. Personally, I think a beginner should be flexible and explore a bit and committing yourself to any database technology should only be ventured upon once you've mastered some of the basics.
Ha np. No credit needed. *lurks back into the darkness*
First, set up sqlite or mysql or postgresql, get familiar with SQL and inserting and querying data. Spend some time of this until you start to know how to do multi table queries and how to structure your data without looking it up. When you get to that point discard everything you've done so far and use an ORM, like sqlalchemy or peewee. Writing sql directly should only be done in very special cases, but you need to know how it works to make sense of those tools.
RethinkDB is perhaps the only DB I know that doesn't run on Windows.
OpenCV is a pretty big library, the hardest part is getting it compiled and installed correctly. But from there, you can get up to speed quickly with some practice. If you plan on doing any type of real-time processing, it's worth getting it configured and installed properly.
&gt;... but if you implement those, you don't really need to subclass dict. 
Have you seen this "Numerical differentiation of noisy, nonsmooth data" http://math.lanl.gov/Research/Publications/Docs/chartrand-2007-numerical.pdf ?
Are you sure this isn't confirmation bias on your part? It has been a long time since the release of Python 2, and there have been many performance tweaks in there.
Comparing python performance improvements to ruby performance improvements is a really terrible metric of anything. They're different languages with different runtimes and different amounts of baggage. I mean Perl6 has been steadily improving in performance and some tests are several orders of magnitude faster than they were in november. But I agree that CPython could do with a few of these. Expecially Python3 which has the unicode baggage, which, while being a correct choice, introduces bottlenecks to performance.
How often do we see "use Google style" posts in here?
you wrote sqlalchemy? wow! thank you sir, take a bow
I don't think it is a terrible metric. They're both object orientated languages with a familiar syntax. Both at this point are totally batteries included and both enable you to quickly get a MVP up. Sure it's not perfect, but it's not the worst either.
Maybe. Python 3.5 definitely doesn't give much of a performance boost from Python 2.7 (I can dig up benchmarks if you want but there's plenty out there).
Because people began treating PEP8 as a dogma, rather than a guide. I've worked places when people will take time out of their day to email me if they find a line that was over 80 characters. Of all the problems in a code base that people could, nay, _should_ argue about, people spend time arguing about line lengths. Deal with that for a few years and you'll curl up into a ball whenever the subject comes up : ) My current policy is to just do whatever whoever complains the most wants. That way we can all move on to _actual_ problems. 
sqlbolt.com is super cool! So is codecademy.com. They both have interactive online tutorials that cover the basics. If you want to go indepth, I recommend the Stanford Databases course online. Just google that and you should be able to find it. It is free, doesn't take too long (make 2 hours to go through all the videos if I remember correctly) and goes into quite a lot of depth.
There's an excellent scipy cookbook for a simple algorithm to smooth 1D data sets using a number of different re-defined window functions with adjustable window size such as flat (moving average), Hanning, Hamming, Blackman to name a few. I have found adapting this method quite useful for smoothing data before looking at the derivative I think its [here](https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi54dzapcvKAhUG1x4KHdA5AFwQFggcMAA&amp;url=https%3A%2F%2Fgithub.com%2Fdwf%2Frescued-scipy-wiki%2Fblob%2Fmaster%2FCookbook%2FSignalSmooth.rst&amp;usg=AFQjCNEK6zRiZy86OKBGuIcd3oORt9BUZw&amp;sig2=8VAfVckJff9UmZotVzAzYQ) but github seems to be down for me at the present moment - can update the link later if this is incorrect 
In Python code (all code outside functions) is executed when the module is first imported. That code can do anything it wants and the author of the module wrote it. It can delete all your files. It can rewrite itself. it can connect to the internet and download and execute stuff. Even if you do not call any function in the module. The authors of the import mechanism clearly allowed this. You do not need autoinstaller to do any of those things. You want and expect it not do so because you want and hope it works like in compiled language. But it doesn't. I am not making any statement about right vs wrong here (a knife is nor good or bad). I am simply stating what it can or cannot be done. autoinstaller simply shows one more thing that can be done. You can be assured I will continue to push this until I make something so complex that becomes self-aware. ;-)
Why does anyone else have access to production?
Hm, I am not sure if I am understanding this correctly: You mean, you want to install miniconda on system 1 and then copy it over to system 2, and you are planning to run it on system 2? For similar architectures, I think this wouldn't be a problem. I have one central installation here and run it from 2 RedHat and 2 CentOS machines. Why I mentioned miniconda in the first place is that it takes the pain away from installing all the compiled libraries (and/or compiling Python myself). It even runs successfully and sort of reliably on a hosted server rack.
So it's airoscapy without channel hopping? Edit: nvm 
NoSQL are BASE, SQL are ACID.
Start a simple project! Using praw and sqlite3 you can build something like a reddit bot that logs posts into a database. Have fun, and good luck!
That's true, although it's not quite as expensive as the Qt commercial license.
Also. Feel free to give constructive feedback on my other videos too. I am learning from my viewers all the time.
Thanks for writing sqlalchemy for people like me who prefer an ORM instead of writing those long long queries! How does it feel to know that people make their living and work with something you made every day? I hope youre proud! That being said I would've loved if the sqlalchemy tutorials took the same step as the django tutorial (i.e. step by step teaching you basics and building on top of that with examples). But Im nowhere near your expertise to make any suggestions so thanks again!
Thanks! I was trying some quick and dirty things. If it doesn't work out I'll give this a go.
See qatamah's answer. ACID is critical, but also, even if a NoSQL product can claim ACID, they aren't going to be able to claim the same level of consistency provided by referential integrity; not without a LOT of extra work. Bugs that could be prevented with a simple RI enforcement or a trigger usually require manual coding in the application logic.
&gt; Smarter than the documentation. Oh, for fuck sake. Maybe you didn't noticed, but it doesn't say anything about how the key-value pairs will be copied and that it will ignore all magic methods and getters and properties and whatever, which are otherwise consistently used in all other parts of the python. I wouldn't say anything, if the entry in docs said something like: &gt; If a positional argument is given and it is a mapping object, a dictionary is created with the same key-value pairs as the mapping object, and all you magic access methods will be ignored, because of optimizations at the C level, so don't fucking subclass this shit ever, or BadThings©® will happen. Use fucking UserDict, or fucking collections.MutableMapping, which we created, because dict is broken by optimizations and thus subclassing it will result in unexpected behavior. But thats actually not what is written there, is it? There is no indication, that this behavior will ever happen. To expect something like this in perfectly normal situation (which subclassing is), is something like expect, that subclassing the dict will create cat-eating unicorn monster. That makes me conclude, that this behavior is indeed undocumented, not even in common literature.
Note that `socket.io` is an additional layer on top of raw WebSockets, with a custom protocol scarcely [defined](https://github.com/socketio/socket.io-protocol) by the authors. There's a [python implementation](https://github.com/miguelgrinberg/python-socketio) of that protocol.
 import subprocess up = subprocess.check_output('uptime') of course then you'll need to likely do some parsing on the string 'up' which contains the output from the system command 'uptime'
Pyodbc and freeTDS works well for MS SQL
Funny, I'm planning to add sqlalchemy to a project I'm working on tomorrow!!! 
When a typo will open your system to vulnerabilities, that is not the same argument as "trust". That's like saying a gun shouldn't have a safety because you have to pull the trigger to fire it. Accidents are a real part of this world.
Increase in performance isn't a good metric though just because the more performant you are to start with, the harder it is to increase performance. Why not just compare performance directly? 
I guess to clarifiy I don't care what i do, I just don't want to do something that involve me standing in front of a conveyor belt for the rest of my life. Only thing I want is a job that pays well that is tech-centric. If that makes any damn sense.
It doesn't hurt to try. Start going through the book Automate the Boring Stuff with Python as a start. I believe it's free at nostarch.com, it will get you up and learning quickly. It may take you weeks/months/years to become proficient but keep working hard and get away from that conveyor belt! 
Honestly can't remember, but when I run the timeit module: python35 -m timeit "sum([i + i+1 for i in range(1000)])" 10000 loops, best of 3: 165 usec per loop python27 -m timeit "sum([i + i+1 for i in xrange(1000)])" 10000 loops, best of 3: 94.4 usec per loop
From what I read, the goal was to keep the interpreter simple so more people could contribute. This would limit the crazy optimizations so that everything is understandable. I read a static analysis report on the core and it is really clean.
the squeaky wheel gets the grease!
But you also know the old saying "try before you buy", yes? ;) Nothing against those sites (although I have no first- or even second-hand experience of them), but before you fork over $ I'd recommend using free resources first to see how well you take to the subject. You'll also get general culture, and it will make you a "more informed consumer" of the pay-to-play offerings. Consider Coursera as well.
Hahaha exactly!
I'm learning Python specifically for data science. I appreciate this :)
Great suggestion, I've played with dataset with a Postgres database and it went swimmingly.
It's worth pointing out they're not actually _generators_ (at least range isn't in python3, and I'm pretty sure the same goes for python2.). They're their own iterable types (and even then with some caveats). https://docs.python.org/3/library/stdtypes.html#typesseq
I couldn't believe it when I read it, but here is a company that, when faced with the same problem, just rewrote their software in Lua. [Using Lua for Our Most Critical Production Code](https://www.distelli.com/blog/using-lua-for-our-most-critical-production-code) via [HN](https://news.ycombinator.com/item?id=10974870)
For speedy math, I expect most people choose NumPy.
Yes, sure, or even Theano (I do a lot of machine learning stuff); however, this was just a simple example that didn't involve strings :P
What are some interesting exercises to do for learning SQL? I've written a few SELECT statements and such but I work at a real estate startup that uses Django and god it's so easy for me to just go use the Django ORM to write a script and get it to do exactly what I want it to do... We have an app written in Flask/SQLAlchemy that I want to get into but your comment just confirmed to me that I should probably get under the hood before trying to abstract it away.
Newbie question: If you're keeping track of how popular a global lookup is and optimizing based on that, isn't that basically JIT behaviour? What distinguishes a JIT from Cpython interpreter? Just that it's not compiling anything?
You can probably feel free to kill the .DS_Store files in your repo ;)
Multiple users can read from the database at the same time, but if you need many users frequently writing to the db concurrently you should probably look elsewhere, as SQLite locks the entire database for each write connection.
Nah.
- Why split this into two different repos without PyPI uploads/dependencies/etc? - Why not use multiprocessing instead of threading? You're only using a single core with threading.. - Where did the 452% increase come from? It's generally a good idea to have /some/ form of benchmark data proving numbers. 
i think most of the coders focused on hot-rodding are contributing to the [pypy](http://pypy.org/) project
Nice code. No dependencies. Nice job !!!
Very interesting. Maybe it's just my background, but I find benchmarks like this more informative than things like the sieve of Eratosthenes. I wrote a small simulation in undergrad using only numpy. I never benchmarked out against the old Fortran version, maybe I will now.
Plenty of write-ups but it is still hard to have an opinion about the current state of Mongo. Lots and lots of people seem incredibly frustrated with Mongo, that understandable if it corrupts your data but it never go past just ranting. I'm in a new project that use it. What should i worry about exactly ? I heard the default are a lot better since 3.0, is that true ?
This udacity course is great for interacting with sqlalchemy: https://www.udacity.com/course/full-stack-foundations--ud088 That being said, there are a number of good SQLite guides out there (which can be applied to other sql db setups. SQLite is popular on the small scale where saving to a file makes the most sense.) http://sql.learncodethehardway.org is a good site to learn the bare basics from. I would write Create Read Update Delete wrappers in whatever language I am working wth to establish a grasp of fundamentals and how to apply them to coding projects.
Hi, r/Python/, I’m preparing to write a coding tutorial of “How to Make Web Crawler in Python, Beginner's Guide”. You can check more detail here &gt;&gt;&gt; http://goo.gl/PN4cs4 If you are interested, feel free to give me any feedback and support.
Only for positional argument calls? That's pretty crap. I for one write a huge chunk of my code with keyword arguments.
Access has some issues with enforcing some stuff that's a combo of not standard SQL, and optional in standard SQL. It can be a pain if you're looking up a SQL query on Stack and then trying to put it into Access. For the most part though, AFAIK, it's standard SQL. It can potentially be a useful learning aid because you can use the GUI view to put together your query, and then flip over to the SQL view to see what SQL is behind the query you're doing. 
Really cool! Out of interest, do you usually speed up these kinds of algorithms by storing particles in some kind of space partitioning tree in order to do fast nearest-neighbor calculations? 