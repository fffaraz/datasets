My point is that it is actually really simple once you understand Haskell's evaluation mode. Like as in if someone else wrote a similar definition for something other than Fibonacci it would take seconds to figure out what it means if you understand Haskell. Like it is simpler to understand than most functions. 
Thank you a lot for the help, gonna fix the linux thing and try the X11 stuff!
Another reason: Arrow is really slow. Although [this article](https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html) implies Pendulum's even slower.
This article dates back to August and a lot of effort has been made in improving performances since then. You can see some benchmarks on the FAQ: https://pendulum.eustace.io/faq/
8 Pendulum posts on Python reddit in the last 3 months is a bit much though. Though I might be alone on this one. Either way, whenever I would need pendulum I will certainly know to find it -- and I would use it, too.
This isn't a formal benchmark, but I just did a clean install of arrow and pendulum from pip, and here are the results for a simple datetime addition: %timeit datetime.datetime(2016, 1, 2, 9) + datetime.timedelta(days=200, minutes=5) # 1000000 loops, best of 3: 1.24 Âµs per loop %timeit arrow.Arrow(2016, 1, 2, 9).replace(days=200, minutes=5) # 100000 loops, best of 3: 14.3 Âµs per loop %timeit pendulum.create(2016, 1, 2, 9).add(days=200, minutes=5) # 10000 loops, best of 3: 24.5 Âµs per loop Seems inline with the article I posted. YMMV for different tasks; I picked one arbitrarily. Btw, I like your add/subtract syntax. Simple.
Pendulum is slower in this case because when you add time, pendulum properly applies DST transitions when needed, so it requires an extra check that you can't have with the native library and Arrow does not check it properly (I mention it in the article).
Here's another: %timeit datetime.datetime(2016, 1, 2, 9) # 1000000 loops, best of 3: 205 ns per loop %timeit arrow.Arrow(2016, 1, 2, 9) # 1000000 loops, best of 3: 1.14 Âµs per loop %timeit pendulum.create(2016, 1, 2, 9) # 100000 loops, best of 3: 7.13 Âµs per loop Still in line with the article I posted.
I didn't have a chance to read through all of the link you posted, but I was able to find a few things that might help in debugging this. The same issue pops up with Qt on windows in several places. They all link to this [bug report](https://bugreports.qt.io/browse/QTBUG-50191) and fix. I might not start with building a patch, but at least it should get you headed int eh right direction. I also saw that a few people complained about the same thing in the [microsoft forums](https://social.msdn.microsoft.com/Forums/vstudio/en-US/86bc577b-528c-469c-a506-15383a44c111/missing-corecrth-from-the-default-include-folder-for-vs215?forum=vcgeneral_). Another thing you might look into is third party conda packages. That article is a year old, there is a chance that by now someone else has compiled a different version that doesn't have this issue. Hopefully that was helpful. If not, like I said in my other comment, you'll probably get a lot more help at /r/learnpython.
Thank-you! I see now that the key message of the page (*We're getting ready to drop Python 2 support*) is not at all obvious at a quick glance. I've been too caught up in details to see it with fresh eyes. I've [opened an issue](https://github.com/python3statement/python3statement.github.io/issues/51) to make this clearer. Edit: We've made some changes that should make this clearer.
The official tutorial and 2 Scoops are great. 2 Scoops is really good at showing best practices. However, I wouldn't consider either of these "full stack" resources. They don't go into selecting and setting up a database (MySQL, PostgreSQL), or setting up a web server (Nginx, Apache), etc. at all.
Now I added manage.py support with tab completion. You can run manage.py commands anywhere in the project.
You could also try out [Pants](http://www.pantsbuild.org/python_readme.html).
^^^ that
This is exactly correct. You might not be the author of what you're scraping, but if you are, note that you're going to break assumptions of some tools if you have multiple id's that match each other on the same page. You you are representing style, consider a class="container". If data, consider looking at the data attribute API. For instance, you could name the attribute data-object-type="container"
Try building a website for your club together! Treat it like a business project. * Discuss a design * Choose your framework (flask, django, bottle, etc) * Split into work units * Create a github account for your collaboration * Write it together! If jumping into this is a bit too challenging to do at first, pick one of the numerous resources in the sidebar and go through it together. I learned from Learn Python the Hard Way, but it really helped to have a project to dive into, which is why I suggest something that your club will find useful. Hacker Rank is also a good start for a long list of small projects.
it's unpacking an array-like object (list, tuple, set) into individual variables. `a, b, c = [1,2,3]` also works
Well based on the week vs weeks parameter alone, that is a crusade I'll gladly join. It's like trying to achieve the **most surprise**. one name "replace" for two actions replace and shift, with the parameters being confusingly similar. Should of just had a shift() and a replace() and if they accept both week and weeks they should do the same thing. But, wants the point of shift() it's just an alias for additions and should be handled by the + operator.
I could see a use for it with regards to a simple script that I have released. The script scans a text file for info, and then uses that info to scrape a website and download some stuff. At the moment if someone wants to use my script, they need to install python and the required modules (only requests), and then launch the script on a CLI. A small stand-alone exe would be ideal. I'm sure the alternatives you mention can do the same, but I only had the briefest look into them and it seemed too hard. If you go ahead with this, please make it is extremely simple to use. I imagine it should be possible to point such a tool at my virtualenv and custom packages/scripts, then give it a start/entry point, and then click create.
As GUI Automation enthusiasts we're preparing [pywinauto](https://github.com/pywinauto/pywinauto) 0.6.0 release with initial MS UI Automation support. It's a result of more than one year's work of 4+ contributors. Now working on documentation and last minute clean-ups for usability and consistency. pywinauto 0.6.0 will support both legacy "win32" backend and "uia" accessibility under the hood. The high level interface will remain almost the same (just aligned with PEP8).
&gt; So this isn't a list of projects supporting Python 3, but rather a list of projects which will drop support for Python 2. On the other side, I've been exclusively using Python3 for scientific work for several years now. In 2016, the only thing I've needed Python2 for is unusual use of `mpl_toolkits.Basemap` - but even then the library nominally supports Py3, it throws an error when dealing with an unusual projection.
I see what you mean. The way I've done it might not have been the most subtle, I agree. It's just that seeing a lot of people getting stuck because of bugs and issues in Arrow that exists almost from the beginning of the project was just baffling. In the end, I just wanted to raise awareness about the problem.
Who is Nilesh and what are you talking about my dude
All of which have had Python 3 support for quite some time.
I love reading these threads. I'm a complete noob with a big project swimming in head and a ton of reservations. I love seeing all the ideas and ambitions of people! Keep up all the good work!!!! RemindMe! 23 hours
I will be messaging you on [**2016-10-25 23:04:00 UTC**](http://www.wolframalpha.com/input/?i=2016-10-25 23:04:00 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/59612i/whats_everyone_working_on_this_week/d96cjzc) [**3 OTHERS CLICKED THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/59612i/whats_everyone_working_on_this_week/d96cjzc]%0A%0ARemindMe! 23 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d96ckfk) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
The ability to distribute small(&lt;1MB) fast standalone executables for basic python scripts would be amazing even with some limitations. My main use case would be distributing cli programs. Seems like there could be [plenty of functionality](https://github.com/micropython/micropython-lib) coming with MicroPython. PyInstaller works for a single file but the executables are large(5-6MB) and very slow to start. I can live with the size but the startup speed can be problematic. So far the best I've found is Nuitka + UPX packing the executable. That gets the file size around 3MB while still being very fast. 
An Al Gore Rhythm for recognizing ebony porn with black girls fucking white guys. It's the only thing that turns me on
Noob question : Why not use datetime? What is th epoint of these tools? 
A MIME message parser. Python's standard email package gets some multipart edge cases wrong, doesn't handle bytes very well, is unable to serialize parsed messages back to their original form (it mangles them), and pulls entire messages (including all attachments) into memory at once. All of the third-party parsers I've found have significant flaws as well. I need a better email parser, so I'm writing my own.
Ok. So it is solved... by changing the user-agent to Googlebot/2.1. Previously I was using Fiddler(when I was using fiddler to simulate post requests, which was also giving me the 302 code and redirecting), or Mozilla/5.0(like a normal browser). So I guess the 30X code and redirecting means that the website detects scraping? And I tried several other user-agents I found online and some work and some still don't. User-agent is something I always get confused. What exactly is user-agent? Is it like a nickname you use when you visit a page? How come they will block me even when I use Mozilla/5.0 like a normal user/browser, and will let me pass when I use a user-agent name that contains 'bot' string?
Assuming the expressions can be statically evaluated (ie: doesn't depend on run-time state), you could probably use the [ast](https://docs.python.org/3.5/library/ast.html) module to parse the code into an Abstract Syntax Tree, do transformations on the tree to condense the obfuscations into their results, and then spit the code back out as text with the [codegen](https://pypi.python.org/pypi/codegen) module.
Thanks for the info! I'll check it out
That depends on who is reading it. To me, I'd much rather see this than the equivalent function version as much of that is just line noise. Honestly, I prefer this over: `filter(lambda s: not s.startswith('#'), lines)`. If we had scala style lambdas, it might be a tossup between the generator expression and filter, but I'm not sure if there's a succinct way of negating scala lambdas. For the record, scala lambdas take the form: `_.methodToCall(x, y, z)`. There's other restrictions, but they're kinda out of scope for this trivial example 
not sure what you mean, is a post about Python applied to green tech, based on an interview with DjangoCon speaker on python for sustainable energy.
no, it's a link to an image that says "[learnpython.org](https://i.redd.it/ihzzd45f0csx.png)"
I couldn't help wonder why it named Arrow, Pendulum makes senses for a time library at least.
I see. that makes a little more sense.
This is about Python 2...
Here is the [git repo..](https://github.com/RyanZotti/Self-Driving-Car) 
I see, I am n00b on reddit, seems when you add an image on top of the link it takes the image and leaves the image. I publish the link under a comment.
Neat! I don't end up reading a lot of python functions in vim. I'm curious if the settings.py finder is slow on your projects. I haven't installed this yet. Some other ideas are searching for `manage.py` first, trying `DJANGO_SETTINGS_MODULE`, maybe using `scandir` instead of `listdir` since you'll grab the `is_dir` information in the same call, or storing it in a local variable (can `b:` be used like that?) last_searched = None for node in os.scandir(directory): if node.is_dir() and node.name not in ignored and node.name != last_searched: settings = os.path.join(node.path, 'settings.py') if os.path.isfile(settings): vim.command('edit {}'.format(settings)) found = True break last_searched = node.name might work for the scandir idea. I'll give it a run tomorrow.
God I wish I could make nice charts and graphs from my spreadsheet data...ugh always turns out crappy for me.
Holy hell h2non, from the looks of your github, you are one of the most productive and multi-talented human beings on the planet. Also, this looks like a fantastic library!
Thanks. If I try it I will use your link.
[`puresnmp` on Github](https://github.com/exhuma/puresnmp)
My sympathies! (I assume [Cython](http://cython.org/) isn't an option? Basically you write Python, compile it to machine code via C, and annotate the hotspots for better code-gen.)
Brain skipped the word "toy".. I was about to start raging about how irresponsible a DIY autonomous car would be.
Recently released [Pyvisgraph](https://github.com/TaipanRex/pyvisgraph), now I am going to use it to implement a website with Flask/Google maps API where you can find the shortest path from any point to any point on the ocean. Will use this for work.
Normally one would need to import datetime, timedelta, and maybe calendar to do complex operations. IMO, this is fine. You only import what you need, instead of using a heavy abstraction built on those same libraries. I mean, really, you could do just about everything you need with only datetime and timedelta, you can find month bounds easily by using timedelta, etc. However, that's a lot of duplicate code if you need it on multiple projects... It gets worse if you add features or find a bug and fix it, etc... It would be a pain in the ass to move that code to all the other projects... This is why python modules exist. Whether these particular ones are worth anything, I don't know, nor care... I'm fine with the standard library and my own simple utility modules.
It's constantly about the same thing though. If everyone would post all their version updates, /r/python would look totally different. It's not the worst kind certainly, I just thought to at least point it out.
I knew what this would be before clicking.
At least syntax differences are minor 
Figuring out Pandas :) 
&gt; Username: GovSchwarzenegger &gt;Green 40.25% &gt;Conservative 25.48% &gt;Liberal 18.22% &gt;Libertarian 16.05% 
Specifically, datetime uses naive objects by default, and making them tz aware requires additional modules and awkward, difficult-to-remember syntax.
Yes. pythonanywhere comes to mind. If you really, really want the simplest web tool, try bottle. It's single py file you put next to your code and start creating web page.
Look at this https://github.com/dddomodossola/remi It is a gui library in pure python, suitable for local network webapp.
I'd recommend not doing this unless you want to spend a lot of your time puzzling over a non-standard web framework. JavaScript is an easy language to learn and the popular frameworks are well documented and widely used. 
Sorry...
Well, most of the reasons why Python is a good choice for data science are about the same as why Python is a good choice in general: simple, easy to learn, highly readable, good libraries. But for data science in particular, you have good Hadoop interfaces (most data scientists rely on Hadoop), you can easily do map/reduce type operations in Python (though not as easily as in, say, Go), and you get Numpy, Scipy, and other mathtastic libraries.
The relevant error message is: zlib is required unless explicitly disabled using So you need to have zlib in you environment. I always found installing stuff with pip on Windows to be very frustrating and I would suggest to use something like anaconda since these package managers take care of such dependencies.
There are some things that arrow and other libraries do, that can't be done with datetime. So for me it's not really a question of 'if we use a library' but which one we use.
https://backchannel.com/how-the-web-became-unreadable-a781ddc711b6?gi=e90ab0fdc44d#.27php9jqi
1. `pytz` 2. Force a format. Garbage in garbage out.
You need /r/learnpython r/python is the subreddit for news (and arguing about interpreter internals).
I see a lot of votes for pythonanywhere, and cloud hosted VPSs. You may also want to look at PaaS (platform as a service) offerings, of which pythonanywhere is a member of. But there are many others, like [OpenShift](https://www.openshift.com/). The essential premise is you just provide code, and the as-a-service kicks in for handling your webserver and machine administration. pythonanywhere is great for python, but more generalized PaaS's like OpenShift can open the doors to running a lot more than just python if and when you get into it (caching layers, etc)
Thanks alot, ill check out how threading works. 
Network effect. The main reason it is used for data science is because everyone uses it for data science. As such it has a massive ecosystem for data science, with the most complete libraries, training and documentation for this use case. The language itself is pretty no nonsense and easy to pick up, which is probably why took a hold to start with.
&gt; though not as easily as in, say, Go Well, but then again, you don't need to deal with the horror of go.
I've considered it, but C++ was easy enough to learn that I've never felt bothered to add another layer of tooling. I want speed, so why not go straight to the source?
Do you plan to write something to manage incoming email with it when you're done? I.e. improvement over imaplib?
At home - I've just started mapping out a text adventure game. Also will download [Anaconda](https://www.continuum.io/) this week to start exploring that. At work - Tweaking my text analysis script for a new project.
I love good horror stories about programming languages. What's so bad about Go?
Be aware that pytz has limitations and bugs of its own. And it does not perform very well. I made an article about that: https://pendulum.eustace.io/blog/a-faster-alternative-to-pyz.html 
Great, thanks :-)
I'm wondering too now, which solution is faster. I will check when I go to home (Now I'm at office). Maybe the file path of settings.py (also manage.py) can be placed to a variable to use next times. I guess this can be help a little bit, thanks!
[MDBtools](http://mdbtools.sourceforge.net/) can parse at least some MDB files - I've used it to extract data in the past. I don't know of a Python wrapper, though, and I don't know if it compiles on Windows.
I suppose you are coming from a language like Ruby or C# which allows you to "open" the built-in classes and extend them. As a person who writes most of his code in Python, I can see the novelty of the idea but ultimately think it would be more trouble than it's worth. I would much rather see an `IPAddress` class inheriting `str` than all of the sudden have all strings act like IP addresses. &gt; some assumptions about writing strings that are pretty basic and an inherited class won't "do the right thing" in such a circumstance the way string would I suspect that in these cases there might be simple, Pythonic solutions. Could you provide a specific example? 
I've never seen this before so I got confused for a moment when trying to see how this was related to Autodesk Maya and vim.... Anyway, looks like a cool project.
Question: Does your class provide a `__str__` method for reproducing as a string?
I am developing a vim plugin for django now. Here it is: https://github.com/umutcoskun/vim-mule
Look for something called ADODB for python http://adodbapi.sourceforge.net/ http://mayukhbose.com/python/ado/
Thanks! I was looking into that but I think it can only run in a UNIX environment :(
thanks! I have been reading about threading, and i do not need to thread in my application. i simply need to start a new process. How would i go about launching an entire (self contained) script using the multi process module? isn't this module intended for running just individual processes? thanks in advance
Thank you, this solved a really annoying problem for me. I was trying to pour a text file with 9 million lines to a django mysql database, but I kept running out of memory in my online hosting environment. This solved it nicely.
I really don't think you are going to find a *reliable* library or alternative python implementation that lets you do this. It would be an awful lot of work to provide some functionality that is potentially dangerous and barely useful. You can already monkey-patch all manner of classes in the standard library that are implemented in python, but people rarely do it, because it causes confusion and might create incompatibilities with other people's code or future python versions. Having said that, I found [this](https://gist.github.com/mahmoudimus/295200), but it's a mess and clearly relies on CPython implementation details. I don't know my way around the C API, so I don't know if it has any warts or is likely to work in future versions (it seems to work in python 3.5 if you fix the print statement and replace `DictProxyType` with `MappingProxyType`). &gt; `"127.0.0.1".doThingToDottedQuad()` I really don't understand why this is better than `doThingToDottedQuad("127.0.0.1"). I know ruby lets you do this kind of thing, but I don't understand the value of it. Most articles I can find about monkey patching in ruby advise you to try and avoid it if at all possible. &gt; `doOtherThingThatExpectsString(str(thing))` Most functions that expect a `str` are going to be able to cope with a subclass of `str` that merely adds a new method, so coercing back to `str` is probably unnecessary in most cases.
You can't handle timezones properly with the standard library. And it's just not for newbies. There are a lot of reasons why you would want to use a library such as this: ease of use, reusability and proper handling of timezones that is not that intuitive with the standard library.
&gt; I suppose you are coming from a language like Ruby or C# which allows you to "open" the built-in classes and extend them. No, I'm coming from C (and c++, when I must), which lets me do anything I want, as long as I'm smart enough, and careful enough, to do it. :) Other than c, Python is what I write, and has been almost since the first day it because available to me. I *love* Python. About a decade ago, I finished spending some years writing perl (because I was required to.) I hope the trauma will wear off some day. Previous to that, I mostly wrote assembly. Which I loved, but is rarely called for these days. &gt; I suspect that in these cases there might be simple, Pythonic solutions. Could you provide a specific example? Again: "127.0.0.1".doNonBaseStringClassThingToThis() I want a way to make that _work_; and the lack of a solution to that is what motivated this post. 
Sure.
Or, that it's up to date with version 3
https://backchannel.com/how-the-web-became-unreadable-a781ddc711b6?gi=e90ab0fdc44d#.27php9jqi
In the end, you're just going to get a library that writes out to html/javascript. You might as well as just use bootstrap and something like flask/django/jinja to generate the html. It'll scale much better than any python library that currently exists
Well what do your scripts do? Generally if you want them on the web you want an endpoint, so you may as well use Flask. Once you're using Flask you can use pythonanywhere without even thinking about anything.
&gt; Having said that, I found this That's interesting, thank you. &gt; I really don't understand why this is better than `doThingToDottedQuad("127.0.0.1"). I know ruby lets you do this kind of thing, but I don't understand the value of it. Well, there are several. The general justification is the same for having: newstring = myString.replace('foo','bar') instead of: newstring = stringReplace(myString,'foo','bar') You get things like being able to "dir" the class for what it comprises, help/docstrings, and mechanisms specifically designed to deal with, and which are automatically selected, for the object at hand. Whereas a function of some name tends to be more vague. It could be anything. It might be designed to do anything. There's nothing particularly intuitive about remembering it as opposed to every other function in the system, whereas if you're working with a string, the following can immediately show you the lay of the landscape: dir(str) # oh hey, there's replace. That's what I want... help(str.replace) # or more specifically Make sense? I just think it would be lovely to put this at the head of a python script... import myclassmods ...and then be able to write in "extended" python. 
Haha. That IS a great example of garbage in garbage out. If you have web site parse in js and format it in long form as they type. But that's not what we're talking about. 
Something being up to date with py3 does not imply that it was working in py2. Specifying the language version implies that it is a newly released feature.
I understand that you want to be able to do "127.0.0.1".doNonBaseStringClassToThis() and I'm not sold that this is a good idea. But to each his/her own. What I'm really after is an example of a case where having a `DottedStr` class doesn't suffice. That's partly for my own edification, because I'm struggling to see the utility of extending the built-in. Maybe I've been missing out!
Please do u/sentdex! Speaking on behalf of python learners, we all appreciate your videos!
No? Nothing javascript at all, just let them know the format you're expecting, parse it as such on the server, and throw an error if they fucked up. See: Django forms. If your data's not coming in interactively, then you'll be able to know the format ahead of time by inspecting it.
Well, let me turn it around, and perhaps we can reach a mutual understanding. Why is it worthwhile to have... newstr = "foo bar".replace('foo','champagne') ...rather than: newstr = stringReplace('foo bar','foo','champagne') ? What I'm saying here is that if there is any justification for having useful class methods in the first place (justifications including dir, help, clarity etc.) then there is justification for _other_ class methods as well. I would further contend that, barring poor underlying infrastructure that digs into a class deeper than I think there's any justification for going, there's no reason not to allow such things. So far, IIRC (which I may not, I'm old, lol) that's the only real justification I've run into: that some things would be confused by a class that had a method added to it (again... that tells me that planning was lacking for an extensible function mechanism, not that extensible function mechanisms are either difficult or somehow improper.)
&gt; as long as I'm smart enough Those are some dangerous words you wrote there.
Libraries (scipy and numpy paved the way, scikit-learn and pandas and whatever else built from that). Nice repl (esp with interactive notebooks). Easy syntax (compared to say java that requires a fair amount of comp sci knowledge, or r that tends to be difficult for non maths people). Fast enough generally. All that led to a strong network effect.
Oh, I know. There are days... \[reaches up to upvote your comment\] But OTOH, I have a pretty deep background in writing generally reliable, powerful, secure c code. It has (so far) always felt like the closest thing to assembly language I could find. And a lot of what I write is real time, very demanding in terms of CPU cycles... so my choices are limited, realistically speaking. Plus... and I hesitate to even mention this where modern programmer types can react to it... but I _like_ c. :) 
I'm in the same boat as OP. I can't seem to find a module that writes to SAS. Writing to csv for the SAS users to import works. But I would still like to have the option to write directly to SAS so the SAS users can just open the file as opposed to writing yet-another import step (have you ever seen how crazy verbose they are?).
You may want to use `subprocessing` in order to spawn a child process. If the scripts are executable, they ought to spawn their own python process as a child of your GUI.
Typically you want multiprocessing.subprocess() which takes a list of the command line args you would use on the command prompt, like if you were just executing the binary from bash.
Hi Python Community, I'm proud of [PlatformIO](http://platformio.org), an open source ecosystem for IoT development ðŸ‘½ Cross-platform build system and library manager. Continuous and IDE integration. Arduino, ESP8266 and ARM mbed compatible. [1300 stars](https://github.com/platformio) and 100% Python stack: * Multiplatform Build System based on SCons * CLI based on Click * PIO Remote based on Twisted. Regards, Ivan Kravets - CTO, Founder of PlatformIO
I've used repl.it a few times to quickly test Python code and I found that it's a very good tool. It's more practical than using the Python console, especially if you work with several source files. Nice to see that they added all packages!
&gt;i would say R is better for data science. I've only seen this said in biology fields for historical reasons and the obscure stats functions R has coverage for. But for 99% of data scientists the bottlenecks in their work are not a lack of some stats calculation or another. What Data Scientists need is the wide ecosystem for things they don't want to have to think about, like web frameworks and system administration tools. 
A few reasons: * As others mentioned, the suite of available scientific libraries is fantastic. * Performance is generally quite good (especially since it's pretty easy to write fast C libraries with Python interfaces). * It's easy to scale. A lot of data science problems are embarrassingly parallel. It's really easy to do multiprocessing in Python or use GNU parallel or whatever. * The most important bit: dealing with data is *really easy*. Reading/writing text data is incredibly easy with Python. SQL is easy. 80% of the time spent doing data science is just spent munging data, and if you can dramatically lower the barrier there, like Python has, then you've got a winner.
If all you need to do is basic interactions with the shell, I'd recommend pexpect's pxssh. It is much simpler to use than paramiko. http://pexpect.readthedocs.io/en/stable/_modules/pexpect/pxssh.html
You have double quotes inside double quotes. Try `'download_url'` instead. Also, [jq](https://stedolan.github.io/jq/) is a great tool for this purpose (and JSON processing in general). With it, you can just do `curl https://whatever/... | jq .download_url -r` to get the same result (and the query syntax is very flexible - you can do stuff like `.result.data.download_url` and a lot more). Also, /r/learnpython is a better place for questions.
Just wanna talk the few people who purchased this course! If you have any issues please contact me on Udemy or right here on reddit. C
Don't tell Arnold
Sorry for title gore. This is my first python module, so if anyone has feedback (+ or -) I would love to hear it. 
&gt; JavaScript is an easy language to learn and the popular frameworks are well documented and widely used. My co-worker don't want to learn Javascript. Anyway, according to them, the current web framework are too difficult to work with. jQuery is ok, but anything beyond that is a no-go. I can't convince them that an SPA is the best choice for the future of our application.
I honestly do not know much about Hadoop, but it sheds some light on why a hiring manager wanted me so badly. My PhD is in uncertainty quantification and he wanted me for data science. I didn't really understand why since I never touched it or Hadoop (which he kept talking about). I guess he saw through the "hyped" part and was looking for someone who could *really* learn it. I didn't take the job for other reasons, but at least I now have a better idea of why he wasn't crazy
https://docs.python.org/3/library/datetime.html#datetime.tzinfo
datetime will give you the offset. 
Well, I'm not a data scientist, I just know it's a popular tool. Can't speak much beyond that.
Make an idea generator
&gt; it's non-standard dd/mm/yyyy is the most-used format by humans in the world. &gt;mm/dd/yyyy Most stupid thing possible. &gt;parser can't differentiate User error.
As a second year student in computer engineering, how might I go about recreating something similar? I've wanted to play around with a Raspberry Pi for a while, and I want to learn OpenCV, so this sounds so cool. 
why? 
Is there a live demo anywhere?
+1, you are a really talented YouTuber!
&gt; most used Citation needed. And who cares? It's not the standard and it's stupid. &gt; most stupid thing possible Sure. But you're the one arguing "common" and that format is common because Americans are silly. &gt; user error It's the users fault but it's YOUR problem. Your blame-someone-else-attitude doesn't actually help solving the problem. You're just continuing the same bs and then blaming someone else instead of being a part of the solution. 
tl;dr. I went for a KISS approach. A simple CSV file logger in Flask and then the ESP only has to deal with pinging a URL: https://www.reddit.com/r/homeassistant/comments/54nzaj/esp8266_data_collection/
I've been using arrow for a long time, and reacted with skeptisism when pendulum was announced. Then the author started to almost attack arrow and I quite disliked the tone of it. But in the end, and after doing some side by site comparison, I must admin, I will now use pendulum. The API is better (the omnipotent get() and non standard format language are my pet peaves) and the results are more accurate. I don't mind the performance. And why am I not using: - datetime ? Because it lacks feature I want such as easier time shifting, human formating, better text parsing and timezone handling. - pytz ? it's installed with pendulum anyway, and the later bring more things to the table.
`replace` though is a method that obviously works on all strings, whereas `do_thing_with_dotted_quad` is not. If we could modify the `str` class to add this method, it would also become possible to do something like: x = "a regular string".do_thing_with_dotted_quad() I suppose you could make this raise a `ValueError`. But to me it seems fundamentally bad OOP to attach functionality for dotted quads to the string class. There is a case to be made that dotted quads are a subclass of strings, but they are not the same thing. Note that if your `DottedQuad` class inherits from `str` its instances should work in places that a `str` does. `isinstance(DottedQuad(), str)` will return `True`, for example. I'd be interested in seeing examples where you have to explicitly mist convert back to a string.
You may be able to use the `code` module. It will let you drop into an interactive prompt after running or importing a module. https://docs.python.org/3/library/code.html
Data Analyst here. I use Jupyter Notebooks most days, because a lot of the work I do is in preparing reports or analyses, for which they're a natural choice. It's absolutely fine to do any reporting work, or even more exploratory stuff in Notebooks. What I tend to do when studying something new (software or data-wise), is make a few Notebooks as I fuck about and get closer to what I'm trying to do, then eventually move the bigger moving parts of that out into modules which I call from the Notebooks. When you need to write a program consisting of more than just one linear flow, there's no real need for Notebooks. Working in a plain old IDE/text editor is fine, and maybe it'll even help you organise stuff better.
you're welcome. Jupyter Notebooks are really awesome, but you are somewhat constrained to jsut doing big long linear scripts. I recently hired someone to work with me, and they've learnt Python *via* Jupyter Notebooks pretty much. I was quite a big switch for them to start doing more modular coding, because it was so different from what they were used too.
&gt; What are the advantages of using Mayavi over the VTK library itself? VTK seems to be lower level, and Mayavi has more of a MATLAB/matplolib syntax in my opinion. I'd say it's for convenience, e.g., mayavi seems to be the "seaborn" for vtk in some sense.
mayavi is pretty cool. One time I was prototyping different motor control loops in Python and I used mayavi to interactively visualize the maps; it was a great tool and it really helped me choose the best control algorithm for the job (PI) and tune the coefficients just right. When I ported the algorithm to the microcontroller it "just worked". 
Seems interesting, but matplotlib and ratcave didn't import. Is there something that needs to be activated or set for these packages?
Oh, why do I always miss stuff like this (
Just going to expand a bit on why Hadoop isn't a core data science thing. The problems Hadoop solve all involve scaling up to amounts of data that don't fit in a single machine's RAM, and it solves those problems by building an architecture that lets you schedule computations to run in parallel on a cluster of computers. The programming model is pretty awkward and it takes a decent-sized cluster to get enough raw performance to make paying the overhead "worth it". It's trendy nowadays to want to use the "big boy" tools like Hadoop, but the vast majority of data science is still done on data sets that fit in RAM using tools like R and Python. They offer a much friendlier developer experience and can still use threads/processes or GPUs for parallelism. Seconding the calc/linalg/prob/stats recommendation too, because no amount of R or Python (or Hadoop lolol) is going to make up for not understanding where the numbers you're looking at are coming from.
Are you violating any licenses here? Eg linking against AGPL code? Are you including and displaying MIT copyright and warranty intonation?
I just tried a scipy sample snippet because it's something I've never successfully installed on my PC. Got an error though: ImportError: libtk8.6.so: cannot open shared object file: No such file or directory Code: """example.py Compute the maximum of a Bessel function and plot it. """ import argparse import numpy as np from scipy import special, optimize import matplotlib.pyplot as plt def main(): # Parse command-line arguments parser = argparse.ArgumentParser(usage=__doc__) parser.add_argument("--order", type=int, default=3, help="order of Bessel function") parser.add_argument("--output", default="plot.png", help="output image file") args = parser.parse_args() # Compute maximum f = lambda x: -special.jv(args.order, x) sol = optimize.minimize(f, 1.0) # Plot x = np.linspace(0, 10, 5000) plt.plot(x, special.jv(args.order, x), '-', sol.x, -sol.fun, 'o') # Produce output plt.savefig(args.output, dpi=96) if __name__ == "__main__": main() I could easily be doing something wrong though. Cool concept still.
I look into that, thanks!
is it going to be on safari books online?
This isn't a homework help forum, but you may be able to find some help on /r/learnpython if you're willing to provide a code example you can't get to work. More generally, you should check if your professor or TAs offer office hours. They would be better able to help you think through a problem in a way that touches on the topics they want you to learn about.
That's fantastic, wow. Definitely going to use it to check out libraries before installing them. But at the moment`import requests` doesn't work at all, no response in the repl.
Looks like cv2 has tons of native dependencies. Probably going to be hard to get all those types of packages running. However, I'll look into it -- thanks for the report!
Probably because we disable network on the containers. This is something we're looking into but will probably be for paid accounts or something because opening the network will make it an easy target for abuse.
Can someone explain what the challenges are with overriding `__getattr__()` on a class where this is a common use case? Obviously you have to create the class representation of the object, but that doesn't seem like much overhead.
Does it handle graphics
So... not "every python package"
This is an example of nasa apod using python-telegram-bot.
Sorry, I'm just another jerk who thinks you should inherit from `str` and doesn't understand what the problem with that is. For a good example of a project that does this, check out [plumbum](https://github.com/tomerfiliba/plumbum)'s `Path` (or `LocalPath`) class. from awesome import DottedQuad as DQ thing = DQ('127.0.0.1') thing = thing.doThingToOrWithDottedQuad() doOtherThingThatExpectsString(thing) What's wrong with this? Rereading, I see &gt; an inherited class won't "do the right thing" in such a circumstance the way string would and I think this is a problem. If you want it to be a `str`, don't write it in a way that breaks `str`s.
In general, Python threads only stop when they choose to stop. If you mark them as "daemon" threads before starting them they'll stop when the main thread stops, but otherwise you need to design it into them. Including some sort of "time to stop now" event is probably a good idea if they're long-running threads.
Tried `import keras` and the prompt hanged.
Sandboxed.
Jupyter Notebooks are great to tell a story or explore data ad visualize it, but when it comes to production, you'll need to eventually have a .py file and most likely your own modules, in which case you'll want to go to a text editor like Sublime/Atom or a full IDE like PyCharm
More than attack Arrow, I merely wanted to point its flaws (some I consider critical) to help people be aware of them. And I certainly did not want the tone to sound to harsh. Anyway, I'm glad you like pendulum. Regarding pytz. The next major version of pendulum will no longer depend on it since it implements its own timezone library and know rely on [pytzdata](https://github.com/sdispater/pytzdata) for the timezone database.
ewww I was not aware of that real world issue. Damn real world.
Is an IP Address really a string though? Would you call `ipaddr.capitalize()`?
You don't need VS Code, try IDLE first (it is included with the official Python distribution). IDLE is an interactive interpreter but there's a file editor too (File/new file). Try that and if have more questions please read the sidebar and check this sub: [r/learnpython](https://www.reddit.com/r/learnpython/)
One problem I've had with Matplotlib is that in text-only modes you need to change the backend. I run Matplotlib on a no-Xorg RPI and I have to do `matplotlib.use('Agg')` to make it work without a display server. Also Matplotlib requires `libtk`. Hope this helps.
Parse reddit for programming idea 
That was my only point, from the beginning. :P
Testing happypanda (manga archive library) and Melissa (virtual assistant) 
It's really neat to see my package in here (pysparklines, `import sparkline`). How are you resolving module namespace issues? I'm sure there must be overlap in pypi.
Anaconda is a package manager (or package installer?), REPL is the thing you type into to execute code as you type.
It isn't, and I don't think he should inherit because it violates Liskov. But I'd *rather* see it than an extension of `str`!
I find R to sometimes be nicer when doing my actual data analysis (read : analyzing tabular data and making plots). I much enjoy using Python for many more general purpose programming, but R can be pretty nice at what it was built for. Not to say that you can't use Python for data analysis, it's just that there's already so much in the R ecosystem for data analysis that works well already.
The following fails on python 2: import scipy
Great answers! I actually dislike Go, the lack of generics and operator overloading is too awful for me. And to make things worse, error handling in Go is too much verbose. But Go has one advantage in something that is terrible in python: easy to package into a single binary, and easy to deploy. Rust in the other hand is a fantastic language, but really complex and low level relative to Python &amp; R. For me, Python is leaps and bounds the best language for Data Science. The only competition is Julia, but only on scientific computation - for everything else Python easily trumps Julia. The cherry on the top is the current efforts to improve the areas where Python is a bit poor (type annotations, JIT extensions, better packaging...)
A asynchronous web frameworks with a different taste. Not "async flask" or "async django". Something providing a bit of a different paradigm. Getting the HTTP req/res cycle right is actually the easy part, the hard part is actually ironing API so that async is easy to code and debug. 
The popular lodash library for js has `_.get(obj, "some.complex[3].path.ofAttributes")`
Just use a shebang line in your script or you can call the specific version when you call the script. It's trivally easy to locate the files for Python in Linux, even if you don't know the default installation point. I have 2.7 and 3.4 installed and use both regularly.
I would have prefered the inline except to be accepted: foo = bar.attr except AttributeError: "default" It easier to read, feels more like Python and has a bigger list of use cases. Espacially, we rejected the classical foo ? bar : else ternary syntaxe in favor of keyword. I really dislake the whole '?' invasion.
At work, I find the only people using Spyder/IPython/Jupyter/etc. are people coming from a MATLAB background. They use it because it feels more familiar. People without a MATLAB background tend to use a text editor or IDE, running the programs from the command prompt. I also tend to keep an interpreter up and running just to test lines of code. 
Holy cow this is amazing.
Ah! How would I do that? lol
A tangent but if you need scipy have you tried anaconda or (my preference) miniconda? 10,000% less headaches with python environments involving libraries like numpy scipy etc.
That's awesome! I'd recommend everyone to watch the video at the bottom.
http://www.9cloud.us/pricing/
I'm sorry, this is abuse!
Reasonable idea, but I don't like the syntax. If we get something like this, it should be _better_ than `if hasattr(x, y): y`, not worse.
Before we start rewriting what other people have already written up nicely elsewhere, maybe just start reading through some intro tutorial, e.g., https://www.python.org/about/gettingstarted/
Autobahn is another option built on top of Twisted. I have started using it, but haven't fully explored the features or performance so I have no comparison information for you, but it was dead simple to use with Twisted.
Confirming. One of the reasons I love Jupyter is because of my experience with Mathematica.
You could check out https://docs.continuum.io/anaconda/ That said I don't think virtualenv/rbenv is that fiddly. Normally you just point your IDE/testrunner to the interpreter in your environment directory and you are done. 
I use pyenv for installing and managing my python versions
Very cool! Well done!
&gt; The question you need to ask yourself is "Does this change make sense to every string in my program?" That includes ones coming from other libraries and going into other libraries. No, I don't buy your approach here at all. "string".replace() isn't useful to every string in my program either, but that doesn't mean I don't want to find it there when I want it. Same goes for just about everything. &gt; That includes ones coming from other libraries and going into other libraries. Strings don't carry a class with them. If they did, they'd be crazy huge (and a large part of the point of a class in the first place is that you get to reuse code.) They are instances that call shared procedures. So: I create a string with my extended stuff. I call `newstring=JoeBobsLib.hooHa(myString)` JoeBob was blissfully unaware of my extensions, and so obviously neither used them or expects them. My extension code is live in the shared class, but irrelevant to his code. Now, when I get `newstring` back, I _am_ aware of my extensions, and I can use them to do whatever it is that I am so hepped up about doing. Doesn't hurt JoeBob at all. Helps me. So it really comes down to "can you, or can you not?" And the thing is, doing it is fragile because it isn't designed to be done. What I was hoping for, obviously, was some effort to get it happening in a nice, standard way. I don't mind discussing it at all, but I was actually kind of hoping for someone to go "oh yeah, Sue Codemonster did that last year... here's the link." &gt; Rather what you should be asking yourself is "What do I want to accomplish here?" I did. The answer is, "extend the string class." :) Seriously, dotted quads is just one example. I could give you many, each with it's own use case(s) I would enjoy having around. I've written a couple of text processing languages, and I can tell you with authority that Python barely scratches the surface of cool things you can do to strings. Which likely, you know already. Where we part ways is in that I would like it to, and you don't see why it should. That's okay too. &gt; But you can monkeypatch these types by going through the C api and touching them directly. Yeah... It could have been done (it really makes no difference whatsoever if something is written in X or Y language... it's about functional design, not implementation detail. But to _use_ it, one would want it in the native language, in this case, Python.) To paraphrase, "if you implement it, they will come." 
On the gif it shows it importing pygame but if you try to run a pygame script it says no availabe video device. I understand why it might not be practical to run pygame scripts but I just want to know if I'm missing something.
I can't speak for the OP but maybe the focus of this project wasn't just training autonomous driving but to do the entire project in physical space? 
Yeah, no. replace only works on strings that have something to replace. Dotted quad functions only work when there is something to do with dotted quads. And certainly one would hope a dotted quad function would deal properly with a non-dotted quad thing, just as one would hope that replace would deal properly with being handed a string it didn't understand -- something that can definitely happen in Python 2.6-ish, btw. The argument that "I can't use it all the time, so it's not useful or appropriate" is definitely not resonating with me.
its competing with def func(a_variable=None): a_variable = a_variable if a_variable else [] which then becomes def func(a_variable=None): a_variable ?= [] 
YES
Surprised at the negative reactions, this looks incredible to me! It's the maybe monad in a single character!
For all non Hindi speaking fellas out there, Mayavi means magical in Hindi.
Assuming use of Delorean, as per your example, the proper way to do what you expect is the following: &gt;&gt;&gt; from delorean import Delorean &gt;&gt;&gt; from datetime import datetime, timedelta &gt;&gt;&gt; paris_time = Delorean(datetime(2013, 3, 31, 1, 30), 'Europe/Paris') &gt;&gt;&gt; paris_time_utc = paris_time.shift('utc') &gt;&gt;&gt; paris_time_utc_delta = paris_time_utc.datetime + timedelta(hours=1) &gt;&gt;&gt; tz_aware_delta = Delorean(paris_time_utc_delta).shift('Europe/Paris') &gt;&gt;&gt; paris_time Delorean(datetime=2013-03-31 01:30:00+01:00, timezone=Europe/Paris) &gt;&gt;&gt; tz_aware_delta Delorean(datetime=2013-03-31 03:30:00+02:00, timezone=Europe/Paris) All timedelta operations should be done in UTC, and then you localize at the end. *edit* Simplified version: &gt;&gt;&gt; paris_utc = Delorean(datetime(2013, 3, 31, 1, 30), 'Europe/Paris').shift('utc') &gt;&gt;&gt; paris_delta_local = Delorean(paris_utc.datetime + timedelta(hours=1)).shift('Europe/Paris')
For those working on data pipelines, which often include sparse data or even missing data, this PEP would be a great improvement. I'm 100% convinced about the syntax, because it consists of a single character, there's a risk of missing it when reading 
[Bokeh?](http://bokeh.pydata.org/en/latest/)
Do want.
Something very like it, anyway. Bokeh doesn't install on this 2.6 installation, so that's not it. 
I like Socket.IO personally, and we use [flask-socketio](https://github.com/miguelgrinberg/flask-socketio). That being said... If you just want to do something simple, you can just do [server-sent-events](https://flask-sse.readthedocs.io/en/latest/quickstart.html) to send from server-&gt;client and then use normal ajax calls from client-&gt;server. *edit* Socket.IO is nice because it works also as a fallback if websockets aren't possible, via polling, and also it re-connects on disconnection if there's a network hiccup.
I do like this syntax better. Explicit is better than implicit in this case imo.
Awesome thank you Tundra, will jump on tonight and take a look
That's an elegant little implementation. Bookmarking that to show to my cognitive science class next semester!
and when you use hadoop, python is not a tool of first choice 
great Ill definitely check this out as well, thanks for the info re: placement of question too!
Cool feature, ugly syntax.
`or` checks for false-y values, so if a_variable is meaningfully `0` it will still be set to `[]`. I'd prefer `a_variable = a_variable maybe []`.
How is `dt + timedelta(hours=1)` not explicit? (dt being a Pendulum instance) Or you can just do `dt.add(hours=1)`.
Yeah, they just pip installed everything but didn't install any non-python system dependencies. Its a cute but not very functional thing to do. I reckon nothing that has any compiled code works. Also, they probably installed a bunch of malware. If they used conda, it would work better for them.
problem though with stuff like that is the copy-paste-update issue a_variable1 = a_variable1 maybe [] a_variable2 = a_variable1 maybe [] a_variable3 = a_variable3 maybe [] a_variable4 = a_variable4 maybe [] which, considering how boilerplatey and noisy such sections are, these errors can often hide pretty well for a long while. And copy-paste-update issues are definately common enough (almost every project tested with PVS studio seems to have 1 or 2 issues relating to it, e.g. http://www.viva64.com/en/b/0376/ )
I really like this. It seems very similar to the null propagation and null coalescing features of C#, which are some of my favorite parts of that language. Just the (?.) operator in particular would be great to have. 
Condas isn't an option?
&gt; How is dt + timedelta(hours=1) not explicit? (dt being a Pendulum instance) Is the Pendulum dt object generating a datetime object there to work with timedelta? Is that stdlib datetime timedelta? If it's stdlib timedelta, how are you ensuring transitions on DST? Are you perhaps converting to UTC and back? Or are you doing it in a bassackwards way and subtracting UTC offset differences? I have a bad feeling it's the latter... &gt; I just don't agree, even though it simplifies a lot datetime operations. Yep, using UTC simplifies datetime operations because that's the way it should be done. Why fight it? [From your own FAQ...](https://pendulum.eustace.io/faq/) at the very bottom: &gt; Delorean's epoch() assumes UTC and does support specifying a timezone I assume you mean *doesn't*, and yep... The epoch **is** UTC. Why would epoch be some other naive local time? You're missing the point of unix epoch then... lol def epoch(s): dt = datetime.utcfromtimestamp(s) return Delorean(datetime=dt, timezone='UTC') &gt; The epoch is the point where the time starts. On January 1st of that year, at 0 hours, the â€œtime since the epochâ€ is zero. For Unix, the epoch is 1970. To find out what the epoch is, look at gmtime(0). [Source: python docs for time module](https://docs.python.org/3/library/time.html) Why doesn't it say UTC there? Because it's obvious, and everyone knows [unix epoch](https://en.wikipedia.org/wiki/POSIX_time) is in [UTC](https://en.wikipedia.org/wiki/Coordinated_Universal_Time). I looked at your code... and your convert method uses [datetime's astimezone()](https://docs.python.org/3/library/datetime.html#datetime.datetime.astimezone) which is doing exactly what I said, using UTC offsets... And you have [offsets all over your code](https://github.com/sdispater/pendulum/search?utf8=%E2%9C%93&amp;q=offset&amp;type=Code)... and [adjusted_offset](https://github.com/sdispater/pendulum/search?utf8=%E2%9C%93&amp;q=adjusted_offset&amp;type=Code) which is based on UTC. So why are you arguing against this? It's dishonest to use flawed examples to prove why your library is better. At least do it right in your examples, with UTC, and then explain why your library is better because it implicitly does all that logic, conditionally, and assumes local time for all naive datetime objects. It's quite simple... Just be honest and don't bend the truth. *edit* a letter
Will work on it, email me at amjad@repl.it so that I can update you when it works. btw, we have a classroom product that's very popular for these types of scenarios: https://repl.it/classrooms
I am not arguing against it. I'm just saying that pendulum does it internally so that the end user doesn't need to worry about it. As for epoch: I'm just saying that there is no way in delorean to get a datetime corresponding to a timestamp in a specific timezone like the stdlib fromtimestamp, arrow or pendulum provide. Nothing more. Anyway, to sum it up: Pendulum aims at making datetimes easier to work with by abstracting some concepts that end users should not need to worry about, that's all.
It is, but that's so much more work. Programming isn't a big enough part of the class to justify me and the TA micromanaging installations. Students really struggled with something similar last year.
That's true that we didn't install all the native packages, however, scipy for example works on Python3. Some compiled packages like numpy also works. But I can live with 'cute'. Cute enough that thousands of teachers already used some third-party packages in their teaching. Thank you :)
Yea, we built that for tri.declarative: getattrpath Also we built a setter: setdefaults_path
I think you need to know some data scraping to scrape data off the database, suggested modules: **Scrapy, Beautiful Soup** Then you need another module to write the data to Excel files, suggested modules: **Xlwings**
`import skbio` fails with [scikit-bio](https://pypi.python.org/pypi/scikit-bio) being a pypi hosted package.
How do you dynamically show/hide a form input?
&gt; there is no way in delorean to get a datetime corresponding to a timestamp in a specific timezone like the stdlib fromtimestamp What are you talking about?! You don't need Delorean to do that. You're missing the point, still.... Use the standard library, haha. But if you insist on using Delorean, for some reason... &gt;&gt;&gt; delorean.epoch(1477459754).shift('US/Pacific') Delorean(datetime=2016-10-25 22:29:14-07:00, timezone=US/Pacific) &gt;&gt;&gt; delorean.epoch(1477459754).shift('US/Pacific').datetime datetime.datetime(2016, 10, 25, 22, 29, 14, tzinfo=&lt;DstTzInfo 'US/Pacific' PDT-1 day, 17:00:00 DST&gt;) And put whatever timezone you want, or your local one... I think you're missing the point of Delorean, it's not supposed to replace datetime, it works alongside it.
How about a wrapper class that overrides getattr/setattr/getitem/setitem: Maybe(bar, default=None).baz.spam.ham
I doubt it; they're not modifying any code thus the AGPL shouldn't apply, and they're not distributing any code (even compiled code) so they wouldn't have to show MIT/BSD notices. This is the same situation that all SAAS providers find themselves in.
cv2 has given me so many headaches installing it in different environments. Good luck.
So is mine o/
Actually, by relying on python 3 the author was able to use the nonlocal keyword and thus show an interesting counter example that would not have worked as is in python 2. Thus the use of "python 3" in the title is warranted.
while it is the more interesting solution, it does have some issues (since its wrapped, it would need to be either unwrapped, or similar, to deal with instance tests, to pickle correctly, etc) It helps with the boilerplate reducing though (noting that since attrgetter will work for multiple attr paths, default is forced to be a keyword) A('X', default=Y)(Z) B(Z, Y).X probably the most practical, without adding compatibility to any pre-existing python function, would be attrget(obj, path, default) with boilerplate of C(Z, 'X', Y) it still won't highlight correctly though, but it would be "the least surprise", since it won't impact instance checks, pickle, etc
&gt; diff the container and make sure nothing fishy is happening and then extract it to a large shared NFS drive. So my package needs to save the time it installed, wait a week *then* start running privilege escalation exploits on the system when it's imported, got it! Thanks 
pywinauto uses accessibility technologies to get texts. There are 2 technologies available on Windows (Win32 API &amp; MS UI Automation). I've just described how to decide which is applicable for you. See [dev branch of the Getting Started Guide](http://pywinauto-fork.readthedocs.io/en/uia/getting_started.html) for now (not yet in official docs). Actually I don't know tools that can do OCR for GUI Automation. Sikuli and similar libraries use just gold image matching that is already CPU intensive enough. Accessibility technologies are much faster in any case but they might be not applicable for particular cases. That's why Sikuli is quite popular (it's better than clicking by hard-coded coordinates).
Clearly, I missed something. It doesn't work, even on numpy. It works exactly like their gif does. It returns None...
Thanks! Cool approach, I did not know that you could get GUI controls through accessibility features. I do not know if one of these (Win32|UIauto) can see the controls of the game (Magic The Gathering Online). I'll discover with the suggested tools (Spy|Inspect), thanks for the guide - it was very enlightening.
r/python is intentionally catch-all to a degree, sans learning questions moderation only works when people are awake and not busy usually r/learnpython is obvious r/pythoncoding (which I now run) is for content but without the beginner stuff, but lacks content
well, the sample size changed mainly (from your 1, to several classes of students) And the people who are taking classes relating to computing is far more varied now (since programming et al is now a serious, well paying, industry), compared to it mainly being people interested in such topics. (and these new people arn't always kids, university caters to people of all ages, including those who are older than some of the first practical PCs) No, children arn't progressively becoming dumber as time goes on
negative reactions because python strives for readability. Those symbols are awkward. `?else` is offensive. 
TL;DR straight from the Pytho docs: "The marshal module is not intended to be secure against erroneous or maliciously constructed data. Never unmarshal data received from an untrusted or unauthenticated source." 
codecademy.com really helped me learn Python, it teaches you parts of Python and then makes you do challenges using that knowledge. 
I love the idea, but ?else is sooo ugly. Having said that, I don't think any language has a good operator string for this feature.
Fantastic :)
I use Jupyter notebooks are mainly for exploration, and PyCharm or vim for writing files. I also usually have a Jupyter qtconsole open as well, attached to the same kernel. When I want to finally clean something up, I either export it into a python file or copy paste it into my IDE, and save it for future use. At least Jupyter has tab completion and docstrings etc, I guess? And you can reload (automatically is possible too, I think) python files whenever they are saved. So explore, write final version of function, use it in the notebook for further exploration.
jesus I really wish you were joking. that's what you consider readable? 
You and /u/execrator misunderstand how it works, `bar?.baz` is equivalent to "`bar.baz if bar is not None else None`", not to "`getattr(bar, 'baz', None)`".
I did not know that
I made up the number. It's actually $5.30/month, yeah.
Saving a few keystrokes isn't a great justification for adding weird syntax to the language.
I agree, the existing "a = b if c" syntax is perfectly clear if a verbose. A new standard library function like SQL's `nvl` or `coalesce` would just as useful and less disruptive.
[Automate the boring stuff with Python](https://automatetheboringstuff.com/) is a great beginner's resource. Depending on how much you know about Python, you might want to read through the first chapters or skip straight to Chapter 11 for web scraping, downloading files and so on.
On the client side, you use something like React or Vue.js to manage the form state. Or just get away with https://github.com/miohtama/jquery-interdependencies On the server side you create forms imperatively http://websauna.org/docs/narrative/form/form.html#creating-forms-imperatively-data-driven-forms
I don't see how that could work. There is no way for the `Maybe` function to understand the difference between: `val = Maybe(foo).bar.baz` and `_ = Maybe(foo).bar; val = _.baz` So instead of getting `val is None` you would get a `Maybe` object in the `val`.
If you use Atom, you might want to check out the [Hydrogen](https://atom.io/packages/hydrogen) package, which lets you do stuff that's similar to Jupyter inside an editor. The Sublime Text plugin API has also been improved in the last year, so someone might make something equivalent here too.
I have no idea what your setup is for the website - But Anaconda python is pretty great at resolving dependencies. I doubt it's feasible, but you could look into what they do to get a better handle on the dependencies.
I think he's talking about teaching a class rather than attending a class.
You can work with Jupyter notebooks in ways other than via the browser interface. The Jupyter notebook server exposes a client API, so you can have the best of both worlds if youâ€™d like. Iâ€™m afraid I canâ€™t provide an exhaustive list of clients implementations, though; I have used notebooks from within Emacs at the time however.
So I tried it, using 1 core and: affinity.set_process_affinity_mask(0,1) 891.822 seconds with affinity set, 903.73 without. So no change in performance. This was using bash/WSL.
You might want to look into APL or even Perl in that case. They can be far more concise than Python.
What you are missing is virtualenv. This tool (previously separate, recently part of python distribution) can create a directory with a copy of your system python, so you can have it there combined with packages of your choice without messing with system version. In your python scripts you just set #!/usr/bin/env python and than you set up your shell to use particualr env by doing . venv/bin/activate
Spyder also has cells that allow you to do that.
You are sending api_key in POST data, but you need to pass it as GET argument. post_data = {'amount':'0.00001000', 'target':'50', 'condition':'&lt;'} post_response = requests.post(url='https://api.primedice.com/api/bet?api_key=&lt;API KEY&gt;', data=post_data)
This tutorial is overkill. Working with the Python interpreter directly is one of the features of the language. This seems like learning a tool to learn Python when really you can learn without it!
Your example isn't as useful as you think if bar has no baz. 
Is there any way to get [Hy](http://docs.hylang.org/en/stable/index.html) ?
Thanks for elaborating the questions. * Colander has something called deferred processing to dynamically set field and widget attributes http://docs.pylonsproject.org/projects/colander/en/latest/binding.html -However this does not dynamically add or remove fields. You can hide them, however. * You can achieve the same effect during schema and form construction. I just created this example for you: http://deformdemo.repoze.org/dynamic_field/ * This feedback is valuable and we'll consider this feature in upcoming Colander/Deform releases 
Maybe I don't notice it as much since I also read /r/matlab and that is truly painful with the questions that 5 minutes of thought or 2 of Googling would help fix. Or, maybe it is a sign of Python becoming a taught-to-beginners language and more and more people are using it 
Yeah, assuming it's not a programming class but like psycholinguistics or something, 95%+ of the students will not know what a library is let alone how to install it. Probably 40% of them will not know how to reliably download and open a file. For the last several years I've been teaching undergrad juniors and seniors in psychology labs that involve some limited programming and holy shit every little thing is a headache.
If you have access to a server you could look into JupyterHub. I've used this with success for classes with ~20 students. Saves them all the hassle of installing things.
I think it would be useful to provide some examples - in particular of using this with deeply-nested data structures where entire levels of lists or dictionaries could be missing.
Take a look at selenium, which will help you open a browser you desire and login to website you want to download from. There is already build script that will help you achieve that. 
While I agree that it is an issue I think the copy/past/update problem is kinda built into the language. def __init__(self, var1=None, var2=None, var3=None): self.var1 = var1 maybe [] self.var2 = var2 maybe [] self.var3 = var3 maybe [] 
Why would one want to use a closure rather than a class?
It's one of the few courses I took before going to college and I will say it's also one of the best out there.
I would rather use javascript for these type of things.
There are tons of courses on the Internet. There's no excuse for developers these days to shy away from other Javascript frameworks. They should learn more frameworks or they will be left behind.
I would rather use a text editor like Sublime, but that's just me.
You can run block of code in ipython console using %paste ipython magic command. I use jupyter notebook to explore data or documentation , otherwise, I use sublime text + ipython %paste
Wow, this is actually tempting me to switch over. I think Atom is able to do this largely because it is based on web languages. Not sure if Sublime will be able to follow suit.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
&gt; Yeah, assuming it's not a programming class but like psycholinguistics Very close -- it's COGS 2201: Foundations in Cognitive Science. =) EDIT: You and I should talk IRL (I think you know who I am) about your experiences teaching undergrads programming.
I don't think so either.
Yes, Windows 7
That is what jupyterlab and nteract are addressing! But have you tried ptipython which comes with autocompletion and error checking? It is slowly integrating into ipython project. So simply jump between pycharm, jupyter, Spyder, rodeo, and ptipython :)
Nice.
You probably need to read the article again. Closure helps you to create a "dynamic function" and class has a completely different role 
Yes, I know I could have been more subtle with the title. I see that now. 
Thanks for the kind words!
Wowza, I've been using PyCharm for about 2 years now and didn't know that was a feature. This might make me start using more Jupyter notebooks. Thanks for sharing; have an upvote!
Thanks @aphoenix for your reply. A few questions/remarks: * Would there be a way to make the instructions in the sidebar stand out even more? Like putting the bold characters in red? * I also see that there's a top post saying "Post learning questions to /r/LearnPython". It's great, but I guess that not everybody reads it. Suggestion: when we post a new link, would there be a way to modify the form and remind people (once again) that any learning question should be asked in the proper sub? Maybe this would offload you a bit.
Okay, makes sense. Thanks!
Thanks for the link. I'm aware of notmuch, but I don't think it offers sending, receiving, scalable storage, or a web interface, so it doesn't solve my problem. I'm glad there are a few of us left who realize that email isn't going away any time soon, and are making tools to improve working with it. Good luck with yagmail.
It's a great idea, but I'm not convinced by the execution. I think the biggest problem I have behind it is that it uses a bunch of different *kinds* of syntax to accomplish the same concept, which is really confusing. Hypothetically speaking, let's say Python adopts the concept of "existence" as proposed. If you're learning the language for the first time and trying to understand "existence", now you have to understand all of: + ```?=``` + ```?else``` + ```?and``` + ```foo?.bar.baz``` + ```foo?[bar][baz]``` That's a lot of different approaches to something, and easily confused with existing syntax. Put succintly, it doesn't strike me as pythonic. **What I *really* like about this PEP:** target ?= expr It's great. It's concise. It's understandable. With two seconds, you can explain it: "If target exists, use target. Otherwise, use the value of the expression." And it's a direct replacement for an overly verbose, extremely-commonly-used Python idiom: ```expr if target is None else expr```. **What I'm on the fence about:** expr1 ?else expr2 That's not terrible, but it takes some getting used to. It especially confuses me when contrasted with the ```?=``` operator above; why not just use a short-circuit ```expr1 ? expr2```? It makes both concepts easier to explain: "If the thing on the left exists, use it; otherwise, use the thing on the right." And it means that the augmented assignment is truly equivalent to ```target = target ? expr```. **What I don't intuitively understand:** expr1 ?and expr2 This really, really confuses me to look at; it just doesn't make sense. Only when described as ```if exists(expr1): expr2``` do I start to get a feel for it. But that begs the question -- why not just use that instead? **What I dislike:** expr?.field.of.interest value = expr?["field"]["of"]["interest"] This just doesn't "pop" for me. It just isn't clear (to me) in the least what's going on here, without *significant* cognitive overhead. If I were learning Python as my first language, this is just going to confuse me. But the behavior of this syntax is tough to replace with anything except an operator, because it: 1. short-circuits lookup of the attribute / item: + ```value = exists(obj, then=obj.attr)``` will always raise an ```AttributeError``` if not ```obj(exists)``` + expr? bypasses lookup against attr, so no error is raised 2. explicitly specify which object is enclosed by the existence check + it disambiguates between ```if exists(obj) then obj.attr.subattr``` and ```if exists(obj.attr) then obj.attr.subattr)``` + ```obj.attr.subattr except AttributeError: None``` (or similar) cannot tell which missing attribute is actually supposed to be caught ------------------- I would much rather see these combined into a single additional ```?``` operator: + Conventional: ```expr1 ? expr2``` + Augmented: ```foo ?= expr1``` + Unary: ```?(foo).bar.baz``` The unary operator would need a bit of extra thought to implement. I think the best option would be to introduce a new built-in type, ```class Missing```, perhaps as a sub-type of None, as in ```class Missing(None)```. The only difference between ```Missing``` and ```None``` is that ```Missing.__getattr__``` returns ```Missing``` itself; in this way, AttributeErrors are (recursively) avoided in anything following the unary operator. Conventional examples: &gt;&gt;&gt; foo_exists ? bar_never_evaluated foo_exists &gt;&gt;&gt; foo_missing ? foo_exists foo_exists &gt;&gt;&gt; foo_missing ? bar_missing foo_missing Augmented examples: &gt;&gt;&gt; foo_exists = 'foo' &gt;&gt;&gt; foo_exists ?= bar_never_evaluated &gt;&gt;&gt; foo_exists == 'foo' True &gt;&gt;&gt; foo = Missing &gt;&gt;&gt; bar_exists = 'bar' &gt;&gt;&gt; foo ?= bar_exists &gt;&gt;&gt; foo == 'bar' True &gt;&gt;&gt; foo = None &gt;&gt;&gt; bar_missing = Missing &gt;&gt;&gt; foo ?= bar_missing &gt;&gt;&gt; foo == None True Unary examples: &gt;&gt;&gt; ?(foo_exists).bar.baz foo_exists.bar.baz &gt;&gt;&gt; ?(foo_exists)[bar][baz] foo_exists[bar][baz] &gt;&gt;&gt; ?(foo_missing).bar.baz Missing &gt;&gt;&gt; ?(foo_missing)[bar][baz] Missing &gt;&gt;&gt; ?(foo_exists).bar.baz_missing Traceback... AttributeError: &lt;foo_exists.bar&gt; object has no attribute 'baz_missing' &gt;&gt;&gt; ?(foo_exists)[bar][baz_missing] Traceback... KeyError: 'baz_missing' &gt;&gt;&gt; ?(foo_missing).bar.baz_missing Missing &gt;&gt;&gt; ?(foo_missing)[bar][baz_missing] Missing An alternative name to ```Missing``` might be ```DNE```, short for "DoesNotExist".
I didn't even know about that subreddit! Thanks for the direction! Best regards! BBhatt12
You can set HTML5 &lt;input&gt; validation parameters for now (email, tel, regex, etc.) Currently there is no AJAX validation in the core. However this sort of thing has been done with Plone and KSS in the past. Colander can perform validation for a single field, so one could do AJAX call after blurring the field for the server side to render the validation status in fly.
I came here to say Bokeh as well, it's fantastic. May I ask why you're set on 2.6? Legacy reasons? You're vastly limited.
I don't use it anywhere near its full capabilities, but atom rules.
IME data scientists love them but they are more doing exploration than traditional "development." When they have finalized code they will usually transition to an editor/IDE.
So, does this mean that you're not opening your computer up to Java exploits. I'm intentionally not running java for security.
Does SQL alchemy have a migrate function like djangos orm. That's such a good feature for developing at least. Change the class, generate the migrate scripts, and migrate them in.
SQLAlchemy doesn't have migrations built into the library itself, so you'd use [Alembic](http://alembic.zzzcomputing.com/en/latest/) for migrations. Django's ORM prior to Django release 1.7 was similar in that you'd use the separate South migrations library.
Nice, but... I use Pyramid quite a lot and the same thing goes for at work, but we never really went with Deform because it seemed it was very tightly integrated with Colander. I ended up going with Pyramid + wtforms + jinja2, which gives a very Django-like feel and I've come to quite like this stack. One of the reasons our team at work ended up really disliking Colander, is because (at least if you use it for API schemas) it serializes fields very badly to JSON and everything just becomes a string which is not really what you want for ints and bools for example. I also found Colander schema classes to be a bit more verbose than Marshmallow because every field is wrapped in a SchemaNode() type, while Marshmallow doesn't really need this. Once again, I do not know much about Deform and if you can even use it with Marshmallow instead of Colander, or if that even makes sense. Colander can be "fixed" by subclassing every field, but this is a bit annoying and I really hope they "fix" serialization to JSON. https://github.com/Pylons/colander/issues/80
/r/Python always surprises me. A dedicated matrix multiplication operator? Great! Type hints? Awesome! `b = a?.attr`? GTFO, that's too hard to read!
If you're still not sure how to develop the actual gui application why complicate it even further by wanting to create a client-server system right from the start already? I suggest creating something that at first stores stuff inside a local sqlite database (for instance). If you make sure your data access is done in code that is clearly separated from the rest of the application, it shouldn't be that hard to modify it later on to store it somewhere on a server. 
 for i in range(100): print('ha')
never heard of ptipython 
The road to enlightenment is paved with many epiphanies of one's own ignorance. From now on, when you see something like while X &lt; Y: X += 1 an alert should go off in your head that maybe you should be using a for loop.
If you prefer Django-like feel check out Websauna http://websauna.org/ - It's SQLAlchemy + Jinja + Deform. Colander is underlying serialization and validation engine for Deform. One cannot go without other. However, in the end everything going into HTML must be a string. HTML doesn't have types. Thus, I am not sure if your concern is valid here. For API serialization, people seem to be hyped about Asphalt from Alex GrÃ¶nholm nowadays. https://pypi.python.org/pypi/asphalt-serialization/3.0.0 - I have not used it myself, but I know Alex and he is a solid architect, so I am looking to use this in my following projects. In Deform 3.0 we are looking to replace HTML client side with something more modern and unified widget kit, though not sure what it will be. This could also change serialization. React and Vue.js based options are contenders.
&gt; That's the nature of an inherited class; there's no inherent understanding of it. Whereas an extended class can be completely transparent. What do you mean? I think you'll find that the vast majority of Python developers hold a completely opposite view here, if I understand your sentiment. Extending means pollution, ambiguity, unreliability, surprises, bad-neighbor libraries, and high risk of breakage -- and when things do break, there's a good chance figuring it out requires spelunking gear. While separate (which includes inherited) classes means, well, the opposite of all that: much more straightforward debugging, decoupled code and intents, non-interfering good neighbor libraries, lack of surprises or ambiguity, etc. If you really want to do a lot of programming in that style, but also kind of Python style, maybe those projects should be in Ruby. Not only will the language itself not get in your way, but if you're working with other developers or projects, you'll find the community less consistently hostile to those practices. Again, though, I highly recommend checking out the library I mentioned for something similar to what you want, without extension.
We can do better print('ha\n'*100, end='')
The first thing that came to my mind was the Forrest Gump quote, "Run, Forrest, run!", but that's just a guess.
Hey folks, I keep working on my pet project - it's a dependency injection microframework for Python - Dependency Injector. https://github.com/ets-labs/python-dependency-injector Now I'm working on making optimizations using Cython and plan to finish this week.
" shit scam because what you really need is a few semesters of college learning linear algebra, calculus, probability &amp; stats at a minimum." ^^^THIS^^^^ I've done a few MOOC's, started and abandoned a few more when I realised they were skipping over fundamentals and treating the algorythms as a mystery black box. Also: maintaining a hadoop cluster is a serious task on it's own. I'm leaning towards using an AWS service and being content paying someone else to manage the infrastructure when I get to that stage. That said: learning to tune, optimise and select datasets carefully can negate much of the 'need' for serious hardward. Add - powerful GPUs are cheap and if the problem set + system is configured properly, the GPU solution can be much faster than CPU based. [caveats apply, hopefully someone more knowledgeable than myself can step in to clarify/correct as appropriate.] 
This is the one that I have been looking at the most. Autobahn can also be used with asyncio which is built into python as of 3.4.
&gt; Does "do stuff with four dots" get to the heart of what it means to be a string? Yes. It's a string. There's no "four dots" fundamental datatype, so string it is. &gt; Does it bring added value to str Certainly, for anyone who wants it. &gt; for everyone, because modifying what str does in your own code actually modifies it for everything that calls your code and everything your code calls. No. All a good design would do is extend a malleable function table. There's only one copy of the class running in any program; everything else is just an instance. So extra functionality not passed around, and has zero impact on performance. There's no more of a reasonable objection to this than there is if you import X, and I don't. There's one copy of X in-system, you know about it, I don't, no one is passing functions around, just instances. In a good design, mind you. If Python actually passes copies of every function in a class around... well, then it's doing it wrong anyway. A very important advantage of a class is that its code can be reused without adding costs. I I instantiate class X, I get a copy of whatever is dynamic, and everything else is shared without duplication. If it doesn't work that way, it's barely worth calling a class, frankly. Also it's stupid. :) &gt; Doing this is messing with implementation details because Python has said, "These types are special because reasons." Which yes, is unfortunate because it creates an exception where maybe there didn't need to be one, but I doubt Python would be as performant as it is if they weren't exceptions. Yes, well, yes. (cough)bad design(cough) &gt; This is an XY Problem: You're presenting this as "I want to monkeypatch str" but we're all asking "Why do you want to do this?" What is motivating you to add behavior to str? No, I'm presenting it as a "has anyone made this really work in Python" not "is there some incompatible and/or unstable way I can do this that is likely to break everything." Definitely my fault if I didn't make that clear. &gt; I'd much rather incorporate a new type into my code than shoehorn behavior where it doesn't belong. Okay, but that's fine, and I'm not presenting an argument against it. You want to do something your way, I'm all for the language supporting your ability to do that if it's even remotely sane. Which what you're describing, IMHO, is. Conversely, if I want to add a method to string, why should you care? Why can't I do it (leaving aside the "Python was built in such a way as to make it difficult or impossible" argument, which I concede up front [while pointing finger at what I consider a critical design flaw and frowning, but...]) &gt; Because after you implement your ip address parsing stuff, someone will come in and say [other things] Again so what? Some strings are first names. Some are last names. Some are product names. Some are nouns. Some are verbs. Some are sentences, sentence fragments, poems, listings, messages, random junk, etc., etc., etc. So strings are _already_ basically as big as the world. I'm just saying there's nothing wrong with acknowledging that and making them easy to deal with. If: * it can be done without a performance hit (easy) * It can be done without breaking anything standard: (easy) * It doesn't get in anyone's face but those who use it (why would it?) * someone didn't screw up the language design (cough) Then why not do it? What you'd rather do in your code is a matter between you and your code. For me, same thing. I'm not saying you'd have to use the mechanism, or even pay any attention to it. Just like you can write Python without ever instantiating a class, you could write Python without ever appending a method to a class. No skin off your teeth. Zero. Do it the way you want. And sure, me too. 
AND.. This led to my first coding commit to an in-use open source project... https://github.com/waylan/Python-Markdown/pull/507
Good read, thanks. Some words on performance? If I got this https://www.techempower.com/benchmarks/#section=data-r12&amp;hw=peak&amp;test=fortune&amp;b=2&amp;s=1&amp;l=27wphb correctly, in each tested framework, what seems to be the most penalizing factor is SQL alchemy. Filtering only for Flask for instance (https://www.techempower.com/benchmarks/#section=data-r12&amp;hw=peak&amp;test=fortune&amp;b=2&amp;s=1&amp;l=27wphb&amp;f=zhb2tb-zik0zj-zik0zj-zik0zj-zik0zj-1ekf) you can see that it's twice faster at least without the ORM. Sorry for the big links, on ðŸ“± ;) 
What's *wrong* with using inheritance instead?
Machine Learning and BigData :metal:
i don't have a single one but i like this list/feed: * https://pymotw.com/3/ there's also a python2 version linked there
I feel like you'll enjoy mixins in Ruby or scoped traits in Scala/Rust. Monkey-patching builtin classes really isn't something you should be doing in Python.
No. Less lines is always more beautiful and more readable. That's why Python has a `;`, so you can cram multiple lines onto one. ^(I'm kidding but golf is fun)
It's effectively monkey patching for whoever is reading the code. Even more so if you hardcode the list of "magic" functions. It also adds a build step, which is not a cost I want to pay for that. 
Yes this is of great help! MVC in particular for visualizing Is the API something i would create for the interaction? Can i ensure it's only used by my application? Great plug, I'll check it out. What problems did you have in mind to tackle when you were developing it? Ideal use cases? I can see it being very useful for keeping both sides of the equation flexible for me personally
neomake, vim-jedi, set foldmethod=indent not much else that's specific to python.
The question you asked has been hotly debated [here](https://redd.it/40s6dm). So it is better to move to Python3. 
On linux the easiest thing to do is install both versions (they're usually in your package manager). And just change the top line of your script from `#!/usr/bin/python` to `#!/usr/bin/python3.5` or whatever specific version you're targeting. On windows, I target WinPython, since it installs to a self-contained folder and doesn't mess with system versions at all. It contains 99% of the third party packages I'm using anyway, so it saves me the hassle.
This isn't really what you asked but in case you haven't found it. I really like the autocomplete-python plugin for Atom. Also to setup projects you could always use a tool like cookie cutter, but that wouldn't be integrated with your editor. https://github.com/audreyr/cookiecutter
Redundant wording, the api is the interaction but i was curious if its construction is something i have full control over With the added detail about security though it clicked and i see why that's a whole thing. I really like the direction of your library. I need to restructure my model a bit but i think it reopens some doors i closed regarding P2P updating. If I'm reading correctly, if i have a python class that is a custom graph, i should be able to send an instance of that graph from a computer running the application and a pyro server instance to another computer running the application making a request for it. In other words, it can allow for two computers with access to each other to trade arbitrary python data type instances? Ideally to be able to use those instances in other functions within the application Assuming i wrap the request properly 
[`db.py`](https://github.com/yhat/db.py) is *great*. Never again `pyodbc` or `sqlite3` (directly).
Golf is fun, but I prefer C for golfing. There's a lot more *interesting* things you can do in C.
please let me know if you have any questions, concerns or features that you would like me to implement in the project.
You can still run queries like normal. Sometimes really complex queries don't benefit much from the main purpose of the ORM part of SQLAlchemy - turning relationships into objects (example: car.wheels). There's are lots of other helpful things that SQLAlchemy does though. The main examples that come to mind are connection pooling, transaction management (sessions), and thread safety (with scoped_session).
I coded html sites in '90's. I want to code full feature site in python. Can anyone advise on this initially free setup.
It's a custom build of XP for in-house hardware. I was able to convince them that downloading the driver was a necessity. There really isn't ANY good options out there. 
In this area I'd recommend the detailed performance documentation at: http://docs.sqlalchemy.org/en/latest/faq/performance.html as well as the example suite that lets you play around a bit with the dials between "richly featured" and "raw speed", introductory docs at http://docs.sqlalchemy.org/en/latest/orm/examples.html#examples-performance.
&gt; Security experts are mostly found in IT. Aaaaand this article has lost all credibility 
At work: making a meteorological cms with django At home: improving a translation server and client to work with django. They can be on separated django projects, or together. The aim is to manage all the project translations with one database, and using the django admin.
How could I had missed this? ðŸ˜”
I absolutely love spyder. Perfect bridge for data exploration and "developing".
the only thing I dont like about sqlalchemy is the use of expressions AND orm. It makes flask admin maintenance very hard/complex filters/queries than django orm.
Atom isn't really ever going to be as complete as Eclipse/PyDev in terms of being a complete IDE. It's really a text editor with syntax highlighting and a basic plugin system. The packages I use with it for Python dev: * magicpython -- better python syntax highlighting, supports async &amp; parameter annotations in particular * linter-pylint -- run pylint continuously on your code and add a red squiggly underline to parts which don't conform
Isn't it more fun to write it all yourself?
Yeah, 3 is better. As times change, 3 will become more popular due to more programs transitioning.
As expected, tkinter doesn't import. Not like it would do anything anyways in a browser.
I'll continue working on my Telegram bot app based off the Telepot framework. It's basically a bot that can help you identify songs, retrieve lyrics and videos of the song. I definitely recommend creating a bot as a fun beginner project to work on :) You can check it out on Telegram at: https://telegram.me/MusicLyricsVideoBot. A simplified version of my source code is at: https://github.com/davidkohcw/MusicLyricsVideoBot-Public 
configobj and voluptuous.
Well, maybe after the library of Alexandria.
&gt; No SQL is required to create, maintain and query the database. I don't think this is entirely true. Technically, yes. But once you start moving beyond basic queries into even just joining across three or more tables, a healthy understanding of SQL makes using SQLAlchemy much more intuitive. If I'm having trouble with retrieving data, I'll often think out how I'd approach the query in raw SQL and derived my SQLAlchemy expression from that.
I think it's a Metal Gear Solid reference
That sounds pretty wrong
Like a damn dream, is how. At a previous job I inherit a _terrible_ database, like where TableA joins TableB on `TableA.foo = SUBSTR(TableB.bar, 4, 3) AND TableA.baz = UPPER(TableB.qux)`. That's _not_ an exaggeration. SQLAlchemy saved my ass time and again as I spent a lot of time in the first year turning all those awful rules into SQLAlchemy properties, writing computed foreign keys, etc. After all that I could write dead simple `.join()` queries and actually get back the data I wanted. Couple that with building queries generatively, where you can write a query expression and then use it as a subquery later, and you get a really nice idiom for expressing complicated relationships very nicely and readably.
Still trivial using the join operators. That query looks complex because of the number of fields involved, but it's really very straightforward.
We can already extend built-in types like string: class MyString(str): def mymethod(self): ... There. MyString extends str, as requested. What you're doing is writing a pre-processor that lets you pretend to have monkey-patched built-in types but without actually monkey-patching them. Why bother? Just write a function and be done with it, rather than pretending to be writing Python-with-monkey-patching.
&gt; For example in java if I wanted to run a build on JDK 8, I could add an &gt; environment variable to the command, use the chosen binary directly, &gt; then change those two and use JDK 7 in the next command. You still have to install both JDK 7 and 8. And chances are *neither* is installed on your computer by default. Python's no different. If you want to run software against version X, you have to have version X installed. Then the *simplest* way is: python3.5 myapplication.py python3.4 myapplication.py There are less simple ways that are better in some ways, but require more effort to set up. Consult your Linux sys admin and ask about the pros and cons of hashbang lines, aliases, setting the PATH, etc.
Except it isn't a function, it takes about three times as much code, and it has the downside of not using nested functions. This isn't Java where everything needs to be a class. If you want a function, write a function.
Say you want to make a finance app with social media aspects, this app deals with the social media portion by providing you an already made platform where users can register, log in, message each other, post and even take pictures (all these features will be configurable so the developer has a choice on what he wants on his app). So now the developer can concentrate on what sets his app apart i.e what is his niche, and how can he achieve that. So if he wants to create a finance market app, all he can put his time and energy on will be the actual finance market app.
Why would you want to write a six line class rather than a two line closure?
Okay. I'll take your word for it. I'm just glad I don't have to fuck around with that database ever again. 
I don't know - I count six lines of code for my implementation, and seven for the one in the article... &gt;&gt;&gt; def counter_factory(): ... count = 0 # here I create the variable to increment ... def counter(): ... nonlocal count ... count += 1 ... return count ... return counter ... &gt;&gt;&gt; counter1 = counter_factory() &gt;&gt;&gt; counter1() 1 &gt;&gt;&gt; counter1() 2 So it certainly isn't &gt; three times as much code And the thing about python is: every function is a class anyway.
Another common one: y = ['a', 'b', 'c'] pos = 0 for x in y: pos += 1 print("pos {} = {}".format(pos, x)) can easily be replaced with: for pos, x in enumerate(y): print("pos {} = {}".format(pos, x)) 
Python stuff * MagicPython for syntax (especially if using python3 with mypy/type hinting) * linter (general linter with plugins available for many languages) * linter-flake8 (flake8 plugin for linter, combines pep8 and flake) * python-indent * python-tools General dev stuff * project-manager (for saving projects) * git-plus Other visual stuff I like: * minimap (for that sublime like file minimap) * fonts (more monospace fonts, including Meslo) * file-icons (show icons in treeview based on file type)
code: import os.path import ConfigParser from ftplib import FTP_TLS class IMPLICIT_FTP_TLS(FTP_TLS): def __init__(self, host='', user='', passwd='', acct='', keyfile=None, certfile=None, timeout=60): FTP_TLS.__init__(self, host, user, passwd, acct, keyfile, certfile, timeout) def connect(self, host='', port=0, timeout=-1): if host != '': self.host = host if port &gt; 0: self.port = port if timeout != -1: self.timeout = timeout try: self.sock = socket.create_connection((self.host, self.port), self.timeout) self.sock = ssl.wrap_socket(self.sock, self.keyfile, self.certfile) self.file = self.sock.makefile('rb') self.welcome = self.file.readline() except ftplib.all_errors as e: print str(e) return self.welcome def check_login(ftp_server, ftp_port, fname): try: ftps = IMPLICIT_FTP_TLS() ftps.set_debuglevel(2) ftps.connect(host=ftp_server, port=ftp_port) ftps.login(user=user, passwd=password) ftps.prot_p() ftps.cwd('/') #ftps.storbinary("STOR " + fname, open(fname, "rb"), 1024) ftps.storlines("STOR " + fname, open(fname)) ftps.quit() return 1 except ftplib.error_perm, e: return 0 error: Traceback (most recent call last): File "new_ftp_check.py", line 89, in &lt;module&gt; write_status(ip,port) File "new_ftp_check.py", line 70, in write_status result = check_login(ftp_server, ftp_port, fname) File "new_ftp_check.py", line 63, in check_login ftps.storlines("STOR " + fname, open(fname)) File "/usr/local/lib/python2.7/ftplib.py", line 759, in storlines conn = self.transfercmd(cmd) File "/usr/local/lib/python2.7/ftplib.py", line 376, in transfercmd return self.ntransfercmd(cmd, rest)[0] File "/usr/local/lib/python2.7/ftplib.py", line 693, in ntransfercmd conn, size = FTP.ntransfercmd(self, cmd, rest) File "/usr/local/lib/python2.7/ftplib.py", line 334, in ntransfercmd host, port = self.makepasv() File "/usr/local/lib/python2.7/ftplib.py", line 311, in makepasv if self.af == socket.AF_INET: AttributeError: IMPLICIT_FTP_TLS instance has no attribute 'af' 
 print(*['ha']*100, sep='\n')
this response of someone who know nothing about it .
 print 'ha' * 100
It's pretty good, but flask and requests give it a run for its money in terms of useful libraries.
Yes, the problem is in mysql - you will have less problems with other database like postgresql.
I've never used the SQLAlchemy orm, just the SQLAlchemy core. It's fast! ,safe, and writing wrapper code is simple enough.
Spin up a Linux EC2 instance with more RAM? 
This is more reasonable than adding ram to your physical machine, imo. Even the biggest servers AWS offers are not terribly expensive if you need them for less than an hour. 
Thanks! Sorry i didn't post the code, i wasn't at home and considered the oneliner is easy enough. Was a shot into the blue, but at least it shows that your code doesn't abuse the cache too much. Thanks! Edit: Could it be that the linux version is compiled with gcc, which does the fancy calling technique for interpretation? Iirc gcc is the only one supporting it, though i might not be up2date. See this, back from 2008: https://bugs.python.org/issue4753 
You're a cuck
Wow that is a great resource. Looking at his bio however makes me feel very under accomplished lol
Very useful for newbies, thanks!
change the &lt;API KEY&gt; with your key
i currently own 'Complete Python Bootcamp' and i'm 29% through it. should i finish this before buy any of these?
Kind of agree. In my ideal code "?" stands for "default of my left thing": &gt;&gt;&gt; target ? expr -&gt; "default of target is expr" &gt;&gt;&gt; target = expr1 ? expr2 -&gt; "default of expr1 is expr2" And for attrs access: &gt;&gt;&gt; class A(): ... foo = 0 &gt;&gt;&gt; &gt;&gt;&gt; _ = A().bar ? expr "A().bar If bar exists and bar is not None" Bonus of this approach is, you have a built-in coalesce: &gt;&gt;&gt; lunch = pizza ? pasta ? burger ? broccoli -&gt; "my lunch is pizza, if no pizza, give me pasta, if no pasta, give me burger, no? Ok then, broccoli. 
If you are new to python but not programming go with this https://learnxinyminutes.com/docs/python3/ If you are new to programming and python try this https://automatetheboringstuff.com/
But uploading a gig can be very slow.
I've been using sqlalchemy pretty heavily for the last couple of years, and I'd like to offer a couple observations/some thinking about how we build things. First, having used 3-4 ORMs over the last 5 years (Eloquent mostly), SQLAlchemy is top tier. Really great, and produces very readable code in controllers. So, in some sense I'm a fan of it. On the flip side though, many joins/things we want out of our databases are not very simple, and whenever I try to get SQLAlchemy to handle those situations, I feel like i have to write it in sql in my head (or pgadmin), and then figure out how to translate that to sqlalchemy. This is generally a slow / buggy process that involves lots of looking at the query log and figuring out if the sql that sqlalchemy generated is equivalent to what I *think* it should be, but maybe that's just me not having enough experience with it. So the amount of time I've spent debugging complex sqlalchemy queries has led me to think about things this way: If the query I want to do is simple (a primary key / foreign key join, maybe a sum), do it via sqlalchemy. *Anything* more complex than that, I simply make a view in the db, and then add a sqlalchemy model. That way, I'm doing all the complex stuff in sql (which I had to do anyway). Thinking about things that way has also led to me wonder if I should be looking at a simpler ORM. If all I'm doing now is simple joins, do I really need SQLAlchemy? If I was starting a project from scratch today, I think I'd be leaning towards the simplest/stupidest ORM possible, but I haven't really solidified my thinking on this. What are everyone's thoughts on this?
Hey now... Want to see my queue of things that needs doing? :p
I'd probably get a Linode box or other VM and run your stuff there. Or, you could just use something like Google BigQuery.
well i'm still learning the basics so i think i'll finish my current one, have a look at automating the boring stuff and see how i feel 
If you aren't already, you want to look into using generators. Tldr; only one item at a time is processed, meaning you should save on memory.
You'd probably be better off using [nginx as a reverse proxy](https://www.nginx.com/resources/admin-guide/reverse-proxy/) to two separate wsgi applications (this django-based social-site and your Flask application). For a better user experience, you could [share the session between the frameworks](https://www.toptal.com/django/django-flask-and-redis-sharing-user-sessions-between-frameworks).
Building a heatmap of the plant I work at to show which depts have the most WorkOrders. Using Flask/Matplotlib/pyodbc/numpy
/r/learnpython 
What could go wrong?
Serious question: Does relying on SQLAlchemy make your skills less versatile? I am not arguing one way or the other; just asking. I know next-to-nothing about databases but my wife works in them all the time. I was telling her about this post and she pointed out that she can write the same (or close to it) SQL queries in .Net as she does in Java, etc (she doesn't use Python). The skill translates well. Is that an issue with relying on something like SQLAlchemy?
/r/learnpython is a better sub for this, but I can't imagine paying $110 for three books to learn something when there are years worth of tutorials, videos and text available on the internet for free.
You should absolutely finish the Complete Python Bootcamp before purchasing these. You're looking at a $100 (sorry, don't have your currency symbol on my keyboard) investment. In other words, you're barely a quarter of the way through your current course/book, and you're looking to purchase three more. The prices on these should be the same when you finish this one. When you finish this, grab another one, rinse and repeat.
is everything important? i'm currently looking at lists and dictionaries etc and it seems like A LOT to take in. are these the kind of things that are crucial to know from the top of my head?
requests for sure. Flask... 
https://github.com/zhebrak/expoff/pull/1 Needed this to get it working for me.
Peewee ORM! And huey -- task queue a-la celery with a tiny codebase and support for multiprocess/multithread/greenlet workers.
If you do heavy work on a laptop make sure your adapter is plugged in and your power settings are on Performance/Best/Max (or equivalent for your OS) or else your OS might throttle performance, clocks and all kinds of things.
PythonAnywhere dev here. I won't express an opinion about the service, since I'll obviously be biased, but we're happy to answer any questions and help you get started -- just drop us a line to support@pythonanywhere.com
I get that feeling. Norvig is a true frisbee champion.
This sounds a lot like a homework assignment...
I went and read the actual json data. There's not a single explanation, unless of course I am blind...which is totally possible. This is still super useful to quickly run against any of your projects, but I'd still like to know the *why*
bpython
thank you!
Solution: don't use automatically-generated admin interfaces. I'm risking downvotes with a "don't do that" answer, but seriously, that's how you solve this problem. Generated CRUD interfaces are an antipattern for anything but a short-term stop-gap. Effectively managing the data backing an application demands tools that reflect specific use cases. Generated CRUD interfaces can only satisfy the most common, generic needs. Once you introduce more complex functionality, you can't reasonably expect a generic tool to handle all the challenges you throw at it. The only reason Django is more tolerant is because the admin features are deeply intertwined with a vastly simpler ORM. 
Ask this in /r/learnpython. As the sidebar says: If you are about to ask a question, please consider r/learnpython. Homework-style questions will be removed, and you'll be encouraged to post there instead.
I have a hard time believing you're this far into a semester, getting a basic assignment like this, and they haven't given any instruction that would be relevant. Do you have a github repo of your existing work you could share over at /r/learnpython ? I feel like you need to show that you've put in some amount of effort before someone just hands you the answer.
Sorry, the stopping conditions should have been if len(s) == 1 or 0. I made the edit. I will also suggest you write out how this function works on paper or something. Removing the "else: return False" statement would destroy this function. The recursion occurs at the line return reverse(s[1:-1]) So focus your attention on what is happening there.
If you're on a 32-bit OS (or using a 32-bit python) you might be hitting an address space limit instead of just a ram limit, which would not be solved by adding hardware. If it were only a memory issue you could add more swap space and endure the extra time it takes. I haven't used pandas, but if there's any unused columns in your csv, I see there's a "usecols" parameter in its [read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to specify which you want, to save memory omitting the rest, and /u/sleisl mentioned a dtype parameter.
I think a big issue with flask-socketio is that it assumes that you are writing an application using flask and will be using web sockets to support that flask based application. Is that an incorrect interpretation?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Exactly - what I'm trying to say is that projects with more pull-requests that are flagged here are actually *more likely* to be secure.
Why -not- make it platform agnostic?
Somebody needs to make a curated database of nonfunctioning curated web databases of insecure Python packages.
I think the idea here is to catalog known and documented security vulnerabilities (e.g., for penetration testing), rather than to track packages that should be avoided.
&gt; Trying to find out the future of Python at work. That doesn't sound good.
This is a problem that is already solved by several applications. Splunk, elasticsearch, MS power BI, Tableau, etc.... I would use an off-the-shelf product. Supporting an end-user reporting/analysis program seems very messy, particularly when there are products that do it already. 
I have used selenium and bs4 a while back for a scraping project in the past. I had also used phantomjs with the project if i remember right. If you just need some quick, off the cuff help, i would be glad to help for free. Or i could help you out by writing a skeleton starter app - which you can customzie for your public data source. 
This would work if they can analyze each row of data independently in some simple analysis (e.g., trying to compute the average/max/min statistics of a bunch of data). But, if they are talking about doing data analysis on a O(1 GB) dataset with pandas, they'll presumably want everything loaded into working memory at once. This way they can make a selection on one aspect of the data, graph it, then remove that selection, apply another selection, etc without needing to re-read the entire 1+ GB dataset. Or they wanted to fit a model to the data, you need all the data in memory to get decent performance (or have to use more complicated techniques like mini-batch gradient descent when you have too much data for your hardware).
It all comes down to the particular software license that the author of the library decided to use. There are so many different options, here's a good spot to get started. https://its.uncg.edu/Software/Licensing/
&gt; There. MyString extends str, as requested. No. That's not extension of a class; that's inheritance of a class, and it does not offer the same benefits, and it presents several dangers.
&gt; If you depend on a library that checks for class membership with type(thing) == and it breaks stuff, file a bug or pull request with that project. Yes, and perhaps they'll see that. And having seen it, perhaps they'll think about it. And having thought about it, perhaps they'll try to fix it. And perhaps they'll succeed, or perhaps they'll make it worse. Or they might just ignore it (as is often the case.) Extension has none of these problems. string will behave exactly as string always has for anyone not using the extensions. &gt; If I get a str that's extended, not inherited, how should I check whether and how it's extended? There's no inherent need for you to do so. The class will not behave any differently for you. That's the (huge) benefit of extension over inheritance. An inherited class might do anything differently, providing surprises and incompatibilities at any point. An extended class not only won't, it can't. OTOH, if I extended string, and I wanted to share that with you, just as I'd provide any other import, I'd hand it over and you could potentially benefit from that. There could, of course, be an extension to the dir() and help() mechanisms to reveal whatever one might want to reveal in a general way, but it still doesn't cause any problems with standard use. It can't. As far as problems with the extensions go, if you choose to make them and use them, or use some that someone has shared, just as with any new code, you get what you get, and it does what it does. Of course, if I extend string and I am using those extensions and do not communicate that fact to you, it makes no difference to your coding whatsoever.
Building a data factory that deduplicates and normalizes data from disparate sources (various database/flat files). Performs ETL based on rules stores in a 'rules' schema on the main database dynamically. Automatically audits each step. etc etc.
Every object in python is a class. You can test it for yourself. A function is simply an object with `__call__` defined. &gt;&gt;&gt; def hello(): ... print('world') ... &gt;&gt;&gt; dir(hello)[:3] ['__annotations__', '__call__', '__class__'] &gt;&gt;&gt; hello.__class__ &lt;class 'function'&gt; &gt;&gt;&gt; hello &lt;function hello at 0x7ff657052620&gt; &gt;&gt;&gt; hello.__str__() '&lt;function hello at 0x7ff657052620&gt;' &gt;&gt;&gt; hello.__repr__() '&lt;function hello at 0x7ff657052620&gt;' &gt;&gt;&gt; super(hello.__class__) &lt;super: &lt;class 'function'&gt;, NULL&gt; &gt;&gt;&gt; hello.a = 'foo' &gt;&gt;&gt; hello.b = 'bar' &gt;&gt;&gt; hello.__dict__ {'a': 'foo', 'b': 'bar'}
Yep, missed that, thanks for pointing it out!
https://pypi.python.org/pypi/sh
 Python 3.5.2 (default, Dec 2015, 13:05:11) [GCC 4.8.2] on linux &gt; import nistbeacon Traceback (most recent call last): File "python", line 1, in &lt;module&gt; ImportError: No module named 'nistbeacon' So it's not every package because [mine isn't working](https://pypi.python.org/pypi/nistbeacon). Mind clarifying /u/amasad ?
All malware check has quite a bit of false positives. I thought it's better to be safe than sorry -- however, I'll make sure I'll fix those.
Tx, 
If you're getting things off of Pypi, why is the version of my [Pyro4](https://pypi.python.org/pypi/Pyro4) that is installed so ancient? It has 4.18 from 3.5 years ago. Current is 4.49
I understand. Very nice of you to explain it.
&gt; it offers sending, receiving, Now I'm puzzled. The notmuch website says, "It doesn't receive messages (no POP or IMAP support). It doesn't send messages (no mail composer, no network code at all)." Are you saying that statement is wrong? &gt; and people having huge inboxes are especially using notmuch! Out of curiosity, what storage formats are they using? I don't consider any of mbox, maildir, or mh to be good at handling both very large messages and very many messages.
This is a question for /r/learnpython! Here is the answer though: http://stackoverflow.com/questions/419163/what-does-if-name-main-do
I put in some more "research" *cough*. Quoted from arch linux forum: &gt; Notmuch is a mail indexer. Essentially, is a very thin front end on top of xapian.
Why is it a private subreddit? Because the mods made it one. Feel free to message them for an explanation. As /u/freshent suggested, /r/esp8266 is a reasonably good resource.
S3 to ec2 is pretty fast, if you don't have to constantly being the instance up and down
It was actually a good reply, no need to be rude, friend.
I found out the most straightforward for me is using gunicorn and whitenoise to serve static files https://github.com/evansd/whitenoise. No apache, no nginx configuration, only python modules. Then I looked into supervisord and Honcho (if I have a django app that needs another process running, like reddis). https://github.com/nickstenning/honcho
Lol what friendly community
A lot of people have done a lot of work to provide resources to you and to everyone else who visits these subs in the form of the sidebars, wikis, and by answering questions. The least you can do, you lazy fuck, is do them the courtesy of: a: making sure you're in the right place and b: at least making a token effort to see if your question has already been answered many, many, many times before In summary: go fuck yourself.
Bullshit. Your account is almost 2 years old and has 9 + 22 karma. So you're fucking lazy AND a fucking liar. Go fuck yourself some more! 
People disgruntled because you're scripting your work away?
No, we have s django app that's apparently going Node because... reasons, I'm not really sure. Some stuff might stay Python but Iunno. 
Did you already use supervisor? Just discovered PM2 with your post, and it seems a little bit more advanced. Any thoughts?
probably the easiest way to write self modifying code in python is to write soemthing to the file and then re-execute it. you might start with something really trivial like append a print statement each time it's run
Me too. Gonna see if there's resources for an official python sdk. Keep my sanity that way 
It's not that hard. You write a function and you allow access to the user to change said function. The open source GUI I wrote has a scripting interface. Go ahead, add security vulnerabilities. I don't care. It's an offline program. Python 3 is more of a pain. I forget exactly, but something like non-class variables lose scope or something like that. class A(): def __init__(): self.x = 4 class B(): def __init__(): self.x = 5 A = B it's that easy. You can do it with functions as well. It's easier to do it with classes and class-functions than pure functions. Just be careful, the second you allow that capability, the second you allow for arbitrary code execution. You basically can't stop it. 
First of all, use descriptive titles. Next time, consider posting something like "comparing lists with 'is' and ==". The title you chose is completely useless because it conveys no useful information whatsoever and is not searchable. And don't post images of code. Comparing two lists with `==` is asking about equality: do these lists contain the same elements? Comparing two lists with `is` is asking about identity: are these two names referring to literally the same object? And you can test this trivially in seconds. &gt;&gt;&gt; a = [1, 2, 3] &gt;&gt;&gt; b = [1, 2, 3] &gt;&gt;&gt; a == b True &gt;&gt;&gt; a is b False The two lists contain the same values (or more precisely, they contain objects that each compare true for equality), but they are separate objects. 
@phonkee, change the &lt;API KEY&gt; with your key , I use my own api &lt;API KEY&gt; = xxxx, api is unique that's not shown to other your are playing the game on primedice.com , just give a user name and start there you access your api , try please give a correct python working code please , to do this for me not much effort
Any plans for proper Cython support in paid version?
If you go to a university or work for a business you should inquire to see if you can get access to a remote machine. My university gives everyone (in CSC at least) an account on a machine with just shy of 20 GB of ram that is normally mostly free. 
&gt; If the query I want to do is simple (a primary key / foreign key join, maybe a sum), do it via sqlalchemy. Anything more complex than that, I simply make a view in the db, and then add a sqlalchemy model. That way, I'm doing all the complex stuff in sql (which I had to do anyway). one of the very first reasons I got into creating SQLAlchemy was to do away with the "we have to build a view" approach to things. Where I worked, everything we queried was a view, and the views had to be Created by Other People. So when the views did not give us the data we wanted in one shot (which was, always), we ended up having to write queries combining views together in joins and subqueries. And they performed like *total crap* (not to mention some of the views were over db links). The composability of SQL into the view, and then the views themselves being composed into bigger queries, is completely what SQLAlchemy is intended to replace. You use the builder pattern in straight Python all the way so that you can get a very deeply nested query while not having to ever deal with the entirety of the whole thing at the same time. I'm not familar with the need to deeply debug SQLAlchemy queries, *unless* one is dealing with relationship loading, which as an entirely separate extension to the normal workings of the relational model, makes things more complicated. But if you're writing raw SQL, you don't have any of those features available to you anyway. 
Yeah, I understand that , in fact the whole point of the undertaking is to see whether we can have arbitrary code execution using python bytecode.
You have a 5lb bag and 20lbs of data. If you get a 30lb bag and try to put 20lbs of data into it, it would work better. Unless you NEED all the data in memory, would it make more sense to take bites out of the data and work with smaller pieces?? https://github.com/jflaker/Useful-Python-Stuff/blob/master/ChunkyRead.py This is python chunking. It takes bites out of the data instead of the whole file.
hi what are you talking about?
I've been playing around with the Groupy module for Groupme and just making random bots. For example, [one bot I made](https://github.com/Hermje/Groupme-Bots/blob/master/groupmeBot/memer_of_the_day.py) takes all the messages from the day and tallies up the likes per each member of the chat. At the end of the day, the member who acquired the most likes is known as the "Memer of the day" I got a little lazy as I was excited to show this off to my friends, and made it so scores are assigned based on a name stored locally and not retrieved from groupme. So if a member makes even the most minute change, it will mess up the bot. So I guess it has a little work left. However, I'm super excited I found out about groupme supporting bots, and this specific module. As originally, i wanted to use beautifulsoup and scan through the source somehow???
Checkout Python Cookbook's metaprogramming section &amp; you'll get into all the black-magic you're looking for.
So you have to take your hand off the keyboard and grab a mouse? No thanks
Can I get the macbook prize with Debian already installed?
What have you done so far?
 def the_learning_process(your_work, your_effort): working = True while working: results = your_work + your_effort yield results get_to_it = the_learning_process() # pick a problem solution = next(get_to_it)
Yep, that's the chapter! Great find.
Choosing to enable self-modifying code is not a wise idea. Using exec is terrible unless you can control what is being executed. Allowing exec on a code which user supplies at runtime is a huge security hole.
oh wow thanks didn't know this :)
My phone has more RAM too, the Zenbook is almost 5 years old though, and still working like a charm (besides this python problem ;)) 
thanks, I think there are a lot. My dataframe has like 23 columns and I'm probably only using 6 or something =/ I will look into this, thanks!
yeah its soldered to it, I can't increase it, but I'll look into the memory sticks
I have the feeling that I might be abusing pandas a little bit, but here is a short rundown of what I'm doing. Every row is a particular instance in time, the data set is chronological, per event (one event is about 1000 rows). Some instances in an event are important (90%) and the rest aren't. What I want to do now look for a certain row and this row has a name, I want to find this name and the row in the next name to see how often two names appear after each other, given certain constraints (such as time elapsed between two events, and some other constraints based on the variables that I have stored per row). Next every instance is counted individually and added into a matrix where every row is the name of the person and the column is the name of the person that appears after the name in the row given all the constraints. I hope this makes sense?
Oh, gods yes. The last time I had 2GB ram in my laptop, I sported a mullet and Lehman brothers was a great bank. A side effect of programmers only buying pre-configured laptops and cloud VM's rather than building their own hardware rigs, is that they forget how huge a difference a hardware upgrade can make. [You can get a laptop with 32GB or RAM for less than $1400](https://www.amazon.com/gp/search/ref=sr_nr_p_n_feature_five_bro_1?fst=as%3Aoff&amp;rh=n%3A172282%2Cn%3A%21493964%2Cn%3A541966%2Cn%3A13896617011%2Cn%3A565108%2Cp_n_operating_system_browse-bin%3A12035945011%2Cp_n_feature_twelve_browse-bin%3A9521908011%2Cp_n_feature_five_browse-bin%3A13580788011&amp;bbn=565108&amp;sort=featured-rank&amp;ie=UTF8&amp;qid=1477632880&amp;rnid=2257851011&amp;lo=computers). If you measure a programmers' time at $100/hr, your new laptop will pay for itself in a couple of weeks. If you build a workstation, $4k buys you: [256GB RAM](http://www.newegg.com/Product/Product.aspx?Item=N82E16820239276) [2 x 8 Core CPU](http://www.newegg.com/Product/Product.aspx?Item=9SIAAEE40T5826) [4TB of SSD](http://www.newegg.com/Product/Product.aspx?Item=N82E16820147374) [Kickass MB](http://www.newegg.com/Product/Product.aspx?Item=N82E16813182348) That's not a lot of money to easily work with 100x the data you're currently managing. 
Thanks for making me feel bad about spending 1400$ on a zenbook. (Although i bought that about 5 years ago, and didnt think I'd ever be needing anything more important than a shiny case around my laptop...)
excellent - thanks... I'll have a prod at this and raise a ticket with JetBrains if I can reproduce any issues.
Armin Ronacher wrote a very good blog post about this: http://lucumr.pocoo.org/2011/2/1/exec-in-python/
I wasn't trying to make you feel bad. I was trying to be humorous. :) Sorry that didn't didn't come across. And, I think there's a very quick and easy solution to your problem. Feel free to ping me if you have questions. Happy to help. 
No. that's not it. 
[removed]
Pity really. But the way imports work make this kind of extensions impractical at best. They work great in objective-c and swift too. 
For an interesting (to me, at least!) form of self-modifying code, take a look at Sixty North's Python mutation testing tool [Cosmic Ray](https://github.com/sixty-north/cosmic-ray/). Part of what it does is load Python code from disk, parse it, modify its AST, and "inject" the modified module into the Python runtime. It might give you some ideas of what's possible.
Resharper is what you have to add to Visual Studio in order to bring it in line with other C# IDE products. You'd think Microsoft's flagship IDE would be great with their flagship language, right?
I'm researching self modifying code in python as well, but i'd not consider exec or eval a way to go. After doing it in freepascal on x86 and the Nintendo DS i can tell you that exec/eval are poor choices for proper self modifying. Bytecode- and object manipulation and having code objects at willfully chosen adresses in RAM, though, which is being worked by one core and modified by a different one... there it gets interesting! (and actually worth it if you care about performance)
Sounds like a scary movie, or forrest gump reference. What would have been your last words to the murdervictim? RUN BITCH RUN! Or maybe it's a joke about the classic Snake games?
Thank you :) All i understand right now is how to create 'options' in your code that users can select, albeit at the moment very selective..
[removed]
/r/learnpython is dedicated to helping new Python programmers. You will be much better off asking for help there.
I fixed an easy issue in AIOHTTP and am building a Django app. Anyone have a cookbook recipe for building a selenium functional test to test user login on Django? I am having trouble getting it to work. 
And in case this isn't clear, everyone here is talking about inheritance vs monkey patching, because we're talking about Python.
It is a requirement to use a while loop. i = 1 while i in range(1, len(L)): if L[i] == L[1]**i: i += 1 else: return False return True Does this make sense?
Wow this was really well written and useful and for me timely. I needed this right now and I appreciate you writing it up! I'm also impressed by your use of modern online tech (jupyter, and binder in particular). Thanks!
I actually did my dissertation at university on Self Modifying Code in Python, I will PM you with the relevant parts of my submission - they will give you a good starting point to experiment for yourself
This library sits on top of argparse and acts more as a framework to help you organize your code. Out in the wild most CLI's (that I have seen) aren't organized well and can be confusing for new people to pick up and contribute to, namely projects with tens or more commands. In that respect I've used Click before, but opted for something more lightweight that people can hopefully pick up on more quickly. For small-medium projects with a few contributors Click is great.
Don't feed the troll
what you might want to consider, if those libraries help you to cut down your cost and make income more easy - support them with donations and/or patches
1: why? For does what your while loop does, is more compact, and iirc runs in C so is faster. 2: please read the sidebar and then post this to r/learnpython
There are some great regex tutorial sites. I highly recommend you read through one.
I think you should check if `rw.findAll(attrs={'class': "housing"})` is empty. Also, are you sure `np.arange(0,100,100)` does what you want it to do? For future questions, please head to r/learnpython
Only if you don't have any means to properly sandbox that code. For example, Tcl has safe interpreters, languages (like Io or Newspeak) where there is no "shared global namespace" provide means to safely load / execute code in the same interp / VM ... In python, you are screwed.
Unfortunately there is no way to simply pip install PyQt4. You will need to use an installer or a package for your package manager. What operating system are you on? The easiest solution is to use https://www.continuum.io/downloads. It gives you a Python installation with PyQt4 and many other difficult-to-install packages.
I created a really simple type of self modifying code using the built-in __file__ object to use as a version check/self-updater for my script. versioncheck = requests.get('http://remote.host/version').text if versioncheck != version: from subprocess import call newscript = requests.get('http://remote.host/client').text with open(__file__, 'w') as f: f.write(newscript) call(['python3',__file__]) exit()
If you use Python 3.5, you can pip install *PyQt5*. PyQt4 is mostly not pip installable (except [on Windows](https://pypi.python.org/pypi/PyQt4_windows_whl), but even that's not supported).
As usual, I'm just working on BitMon. I've almost got a system for assigning wild encounters to the database, but I'm struggling on how to actually build a battle function. It needs to be something that runs on both the client and the server simultaneously. My other hurdle is going to be assigning these wild encounters different stats based on player level. I'll have to develop some type of standard database of monster stats at certain levels to pull the stats from. It'll take some work, but I'm confident that I can get a complete product together by around this time next year.
are you an unpaid intern, or do yhat pay you to post their spam here every fucking week?
Hahahaha wow. How old are you, 16?
of course not. that would be statutory rape
I have not use supervisor, but I have been through a lot of other process managers. PM2 is actually the simplest out of all of them that I have noticed. Grated it is slightly heavier than others, and it requires NodeJS to be installed, but being able to just do "pm2 start script.sh" and not having to worry about anything else is absolutely incredible, especially when there are more important things to worry about pm2 is very rich in terms of what you can do with it, but for many people the only two commands that are needed are "pm2 start &lt;script.sh&gt;" "pm2 stop &lt;process id&gt;" and "pm2 startup" I highly suggest you look into trying to use it, your life will be made much simpler. 
Looking forward to it :)
There's a number of bugs related to cython support https://youtrack.jetbrains.com/issues/PY?q=cython We're working on them. I wouldn't say Cython is in the top priority, but we're doing our best to fix bugs for Cython support. If you have any specific problems or feature requests, please file them to our issue tracker or point me to the existing ones. 
It's not open source. Send me a PM if you're really interested and I'll explain things. 
It is what I'm trying to do! Thanks for pointing this out to me.
I would like to have timestamps that are sortable and unambiguous and to have that, I would need something like [TAI](https://en.wikipedia.org/wiki/International_Atomic_Time), [GPS](https://en.wikipedia.org/wiki/Global_Positioning_System#Timekeeping) or [Loran-C](https://en.wikipedia.org/wiki/Loran-C) time, because they aren't affected by leap seconds like every UTC based timezone or the Unix time. Is that currently possible with Pendulum or some other time library?
Agreed, my main complaint is that while it does sync the general inbox, whenever I open in Emacs, the status is not updated on the phone. Also, replying is not so good (doesn't look as nice as gmail threads). So indeed, I'm totally with you regarding your post. Let me know when it's done :D
sounds like u didn't build it first?
The main problem is that sentiment analysis sucks :) Yes, there are *many* sentiment analyzers, but no, they are not very good.
Any plans for proper SSH key agent support? Or MFA support? https://youtrack.jetbrains.com/issue/PY-6311 https://youtrack.jetbrains.com/issue/PY-21090 Edit: I'll take this as a "no we still don't care about security"
 Thanks for your response. I do not have the option to build but if I click run to the cursor it runs the second program. If I f5 it runs the hello world app 
I think I found out what is wrong. I just open the second file into Visual studio. There is no option to add the file to Python as I have been doing for C++ I cut/pasted the second file into the new project. Until I know better this is what this newbie will do. thanks 
To any Linux user running their project in docker with docker-compose, if you're trying to use the Docker Integration, note that the API URL defaults to: `http://127.0.0.1:2376` but you might have to use the socket instead: `unix:///var/run/docker.sock`.
I've just begun dipping into NLP and have only heard of TextBlob. Could you recommend a better one, or perhaps elaborate a little on what makes them "suck" so much?
you need to define the function first and then use it you are currently have your order wrong : * first you set key to empty string * use empty key for your xor function * redefine key as a function * and calling the redefined funtion in your print statement you need to get rid of the *key = " "* and define key() at the top before calling str_xor() and use *key()* instead of *key*
&gt;Additionally weâ€™ve added a special code intention (invoked with Alt+Enter) to automatically convert comment-based type hints to variable annotations syntax That is a pretty neat feature. Looking forward to using it in community!
This is really cool! I also appreciate the detailed write-up. I'm fairly new to Python (been playing with it for awhile but only recently started really delving into it beyond a basic grasp of the language) and posts like this that clearly lay out process + resources are incredibly useful to me. So thank you! :) 
Leo editor: http://leoeditor.com Look at the site! Very interesting tool and concepts.
Well they also removed the cup holder that used to slide out to the side. So they must be changing their target demographic.
Brainstorming new ideas mostly. I've recently become interested in neural networks and evolution. I want to create a game/simulator of sorts that a person would run on their smart phone. The idea is really abstract, but I want it to be something you check up on every once and awhile, and it would somehow "learn" based on outside variables gathered by your phone. Nowadays phones have sensors of all sorts, so it'd be cool to have something "evolve" based on the environment where you spend your time. Kind of like a virtual pet, but it evolves and changes based on your environment. I've done very little coding for this project in particular, but I did do some fun tests with neural nets and evolution simulators previously. 
&gt; I really don't know where the first code in carpetuna's post came from Probably from /u/CarpeTuna's brainmeats. &gt; Also the code in kephir's post ain't mine just saying It should have been. #It's just that good ^^^/s
Take a look at [PyPatt Macro Implementation](http://www.grantjenks.com/docs/pypatt-python-pattern-matching/macro.html) and [MacroPy](https://github.com/lihaoyi/macropy)
There is a restriction that I have to follow, trust me if I had the choice of using a for loop I would.
Whoever gave you that assignment should embrace python and not solve that with a while loop. Not even to teach you "while loops". That person should come up with a better example.
Someone went on a little downvote spree i see ahahahah
I've already done something like that with sophistication and readability. Take a look! http://patstocklin.webfactional.com/compare/
Haha I agree, it's hilarious. I wish I could say I did it on purpose, but that's the only way I'm going to refer to my laptops from now on :D
They all suck because the human language is so complex that ranking text based on the words used doesn't really work well. Take this sentence for example: I don't fucking hate you, I want to fuck you Most sentiment analysers will only look at each individual word, and so they would rank the above example as pretty negative due to the words 'fucking' and 'hate', however it doesn't see that there's a negative in front of the sentence that inverts the sentimentality.
Now I wrote all the plugin with VimScript again and used findfile function to find manage.py. The plugin is faster a bit now.
Why no cool charts? I was excited to see the notebook, but wanted to see some cool graphs and stuff!
There's no reason why you can't do this.
It seems like a lot of time was spent trying to get the stock price from the csv. Why not use the [pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html) ?
This is how one would normally use Thread anyway :P (The alternative being to inherit from Thread)
Definitely going to re-purpose this for my own side-projects. Thanks for doing the write up!
 https://www.codingame.com
[removed]
Will be my first year attending. Have been wanting to go for years, but never been able to!
Posts like this are why I enjoy this sub, very informative.
rosetta code
www.leetcode.com
www.codeacademy.com
the thing is, most ppl dont have the shekels to get high quality granualr data. you can only do so much with yahoo finance/google data ^__^ 
But...why? In a real world scenario it doesn't make much sense. Which leads me now to believe this is homework, and you didn't read the sidebar. 
If you believe the method warrants a thread, sure. However, you may want to look into asyncio instead. Same concept, better performance. I did this with a class I'm working on, essentially the __call__() method for the instance calls 2 other instance methods, which are asyncio coroutines (basically a thread). These run side by side and eventually terminate together. If you are not sure why asyncio is good (and the threading module is bad) you should read up on Pythons global interpreter lock 
I've been doing checkio.org for a range of python problems. Start very simple and get more complex. Also offers hints and you can see other people's solutions. 
I'm loving the energy, but his entire thing is blind leading the blind. It's like hearing a kid say: "YEAH!! I'm going to jump to the moon! here I go!! ready!! Watch! OOF! OK watch out for the space martians! beep boop beep!". With the physicists be all like: O_o mmmmm kay. How are you dealing with feature reduction, curse of dimensionality, lack of data due to survivorship bias and how are you mitigating the problem of the efficient market hypothesis and back testing on data that's different than what actually happened at the time? And the kiddos are like: "LOL what are those things?". Put down the Caffeine man, it's making you think you're superman and you're not. A thousand people think they can step into the ring with the prize fighter. The most exuberant and excited ones like this are the first to fall. The developers and Quants who have what it takes in this department are quite dull. You may have passed one on the train and thought he was a hobo. You're a great cheerleader though. Word the wise, don't quit your day job until after the software is proven to work, not before. Not to be a downer though. Keep going, you'll learn. https://www.udacity.com/course/machine-learning-for-trading--ud501 Save this video and re-watch it in 10 years. You're going to cringe so hard you're face is going to melt off.
This is what moocs, bootcamps, and other get-rich-quick-schemes try to sell as "datascience on just X weeks!". People trained like this rarely ever get an actual data science position. They need several semesters of math at least and preferably a degree or two in math, CS, or stats.
Visual Studio can be used as a Python IDE...
past performance does not predict future performance. Stock prices have not individual patterns. The only value for this sort of model is learning what other securities to link a security to at what weight. 
Seriously. If this were possible to do well... well a lot of people would be doing it. 
I don't know enough about web dev to properly evaluate the recent API changes, but the fact that nothing like the atom plugin has been implemented makes me think it isn't straightforward.
are you trying to say they have small dicks over there? because it sounds like you're saying they have small dicks.
1. [Python Tools for Visual Studio](https://microsoft.github.io/PTVS/). 2. [PyCharm](https://www.jetbrains.com/pycharm/) Both have Community editions at no cost. 
Visual Studio Code has some good Python plugins. As long as you're regularly saving your files, it'll give you function hints. Use other plugins to color-code your tab sequences &amp; ensure they're saved as spaces. https://code.visualstudio.com
http://i.imgur.com/1cadzWC.jpg
Any Python interview I've had has the classic; reverse a string, sum of even Fibonacci numbers (iterative and recursive) with the optimisation, Binary search trees, linked lists and the number pair that add to a target problem( in O(N) time )
Well, trying different c values prevents overfitting. Right? What else do you need to know? Cross validation to solve the bias/variance problem and different c values to test how it is working. Maybe also feature translating, but that's basically all. You don't need to understand the whole internet, to build a great website. The same should apply for data science as well. One professor I spoke with told me, that in the future, data science will probably be easy enough to be taught in high school. I think he's right.
You mean www.codecademy.com :-)
Sophisticated methods do not do a simple tallying of the pos-neg words. A Char-RNN would for instance see that "don't" and recognise that the next words "fucking", "hate" should not be negative. 
What you mean for equivalent? A powerful code editor or a gui designer?
PyCharm is insanely powerful - even the free version is pretty damn good.
TIL about [next(iterator)](https://docs.python.org/3.5/library/functions.html#next) function. Very useful, thanks for that.
While you're waiting, you might want to have a look at this: https://www.mailpile.is/
I am working on creating some users in [Dell DRAC](https://en.wikipedia.org/wiki/Dell_DRAC) console. Though this is more of bash shell script work but I find text processing in Python very clean.
That's why I said 'most'
No thats not the thing. The thing is simple ml algos on stock trading doesn't work.
That is fucking idiotic. I'm sorry. How do you do cv on time series? A lot of people are literally gonna divide the data into random partitions, which is completely wrong for time series data. The guy in the video doesn't even understand why the EMH is a reasonable assumption in the first place. He doesn't understand what autocorrelation is, or why doing SVM on a single time series is completely insane. He doesn't know what stationarity and unit roots are. That is not data science. Your professor has zero idea what data science is. It requires deep knowledge of statistics and the underlying ML algos. And in addition, it requires domain knowledge. I am fucking sick of people thinking they can predict stock prices because they tried black box algos, even though they have absolutely no knowledge about finance. Just because I can boil instant noodles doesn't mean I am a chef. Yes, you can teach a high school student to be a McD frycook. But that doesn't make him a chef. Your idea of "data science" is what a frycook does. Even worse, the frycook is not properly educated in food science and safety, so he might serve you completely toxic stuff that will give you food poisoning, but he is too ignorant to understand the dangers and pitfalls. Edit: to illustrate my point, take the easiest of the data science algorithms: the linear regression. Sure, high schoolers can create a regression model. But do they understand the nuances and pitfalls of a regression model? Linear regression is one entire semester at a graduate level, fyi. People who think regression is so easy are precisely the ones who have no idea wtf they're doing. Data science is easy only if you do not have the requisite knowledge. It's the Dunning-Kruger effect at work.
Did you check the sidebar where is listed programming challenges?
Whatever the reason, the interest in Python for these uses is VERY old: https://mail.python.org/pipermail/matrix-sig/1995-August/000001.html My guess is this: people were looking for alternatives to commercial solutions (particularly Matlab). Python was an elegant language with an interactive interpreter. They "only" needed to add a proper array data type. Guido was an early supporter of this use case and added the multidimensional slicing syntax and ellipsis. The rest is history.
How is this different from https://pypi.python.org/pypi/dictdiffer ?
And then since they'd all be doing it, it would no longer be worth doing.
It doesn't really matter whether it is up to date or not as it only inspects the history of projects. It will tell you things like version &lt;0.6.1 of Flask had a security vulnerability in it. Updating the index will not change that. I think this is a good resource as it allows automation of checking which ones of your dependencies that may require updating.
I've started using PyCharm when teaching kids, and it's amazing! It's simple while providing so much utility
www.rosalind.info Especially if you're interested in bioinformatics/computational biology, you'll practice building real world applications in the field.
1) Can you not just get a github like every other damn programmer? . &gt;I would also like to add that Python is a terrible choice for coding malware, mainly because it's an interpreted language not a compiled language 2.1) The security community (both hats) use a lot of Python. Just google it. 2.2) There's a lot of effective malware written in Python. Just google it. 2.3) Being "interpreted" (whatever definition you're using for that) makes languages bad for malware? So why is there so much Javascript malware? 2.4) Python is a language grammar and is neither compiled nor interpreted. There's no reason you can't compile Python code to C (cython and nuitka both do it), or run Python on the dot net CLR (ironPython) and there's no reason you can't interpret C or C++.
Gotta get those plane tickets and hotel reservations early!
If you watched the video and are trading based on your new model's signals, let me know. I want to trade against you.
Have you tried it? Because I would expect that as long as my_method is running, the object will never be garbage collected, and hence `__del__` would not be called.
I talked to a girl who did this for a living and she gave me the impression that it wasn't about the prediction but more of identifying arbitrage that takes no prediction whatsoever. 
I have something similar in my program. It seems to work for me, but that may be because I added a kill method. 
Seems a bit complicated considering many routers run Linux or support it aftermarket. Would be less overhead using ssh. However, this is a neat tutorial/into to Selenium.
If it's a "daemon" thread (e.g. goes on forever til program exit) you should set the .daemon flag on the thread before starting it. ctrl-C will thank you.
Hi, You need to assemble the parts you need. Audio libraries - pysoundcard is a good choice for the raw audio as it's cffi based it will work in pypy. You can use fft from Numpy to get useful information back. Aubio can do things like feature extraction. Essentia looks interesting, I've never tried to get it working though. Graphics: There are many choices here, it depends what you want. If you want to render using Cairo, then Qairah has the best most sane bindings, though lots of Linux don't ship with opengl enabled Cairo, which means things can end up too slow as soon as you want to render something complex. OpenGL based libraries: There are loads, it depends on what constraints you choose. For me, ideally libraries work with virtualenv, "modern" opengl (3.3 and above) and are compatible with pypy for speed. Your constraints may be different. Modern GL compatible libraries Pi3d - comes with loads of examples Vispy - Looks like A really interesting choice, not yet compatible with the raspberry pi, but can be used with Jupyter which is a plus for prototyping. Bindings for SDL2 Haven't checked compatibility: Pygame Cocos 2d (python) .. A nice looking 2d engine, I haven't checked if it is moderngl compatible. Panda3d - doesn't work by default with virtualenv Pre opengl 3.3 Nodebox-gl Great 2d primitives, decent speed Pyglet - provides text, sprites. My current stack is pysoundcard, numpy, pi3d on python.
There is quite a bit of clicking on https://pyupio.github.io/safety-db/ to get to the date. would be nice to see a last updated value on the top-level.
&gt; I've always read asyncio should be faster due to some of the overhead with threads. where have you read that? &gt; What's the point of even using asyncio in that case? when you need to maintain concurrency across many hundreds or thousands of arbitrarily slow, sleepy, or idle TCP connections upon which you are waiting to receive data without needing to spawn thousands of threads.
This is extremely interesting to me. Is there a place where I can learn more about this stuff?
Thank you very much, appreciated!
what is wrong with you people, this is just a **sarcastic** video to help beginners get their feet wet in Data science. Not a &lt;Insert a proper scientific paper here&gt;
No problem :)
Also you might want to check out /r/algotrading
Okay? I also know people who day trade doesn't make it a good idea
Some men just want to watch the world learn...
Yes!
Maybe you should use this as a resume builder to get into quantitative finance...
I think "scraping" would be overkill. Consider using their API to get all sorts of stuff including posts (although it looks like you'll have to generate an oath token which is a pain) https://www.tumblr.com/docs/en/api/v2 Alternatively, if you only care about the post data, consider just pulling the RSS feed. I think it's something like my_blog.tumblr.com/rss. That outputs in easy to parse xml.
Ive been wanting to get into machine learning and sentiment analysis for a long time now, but i doubt it is ever something that i would be able to make a career out of. Would you say doing some free courses on the topics and stock trading is worth the time investment to get a rudimental understanding, since building great tools like this require a deep understanding of all of the above and years of experience? Great tool btw, will be checking it out :) 
OP is right as far as how difficult it would be to sell. There are many more variables outside of just cumulative daily returns that funds consider when selecting whether or not to deploy an algo. After all, it's their millions that are at risk. This is why I asked my original question. Because this isn't something that you can sell, so the only value in it would be for personal use. But once the system is made public then it turns into a no-arb situation and thus becomes worthless. Assuming quant shops aren't already doing these sorts of things, of course.......
I think Little Hype is ok for such posts. If people didn't hype and be realistic, then headlines would be boring. I wouldn't even click.
Okay good. Haha well I still think you have tried to sell this, since if it works the m as let will correct for it which will make this useless...
Can I ask you something? Why isn't Google into trading with all the RankBrain and DeepMind in its pocket? Don't you think Google SHOULD be in trading?
I'm sure they are. Simply announcing the fact that they're doing it will give outsiders hints as to how they're doing it. 
Put your money where your mouth is. 
Good, don't ;) Kudos either way
To build similar projects in your spare time, you don't need a degree, but you do need to invest time learning. The good thing about computer science, math, and statistics is that all you need to know can be found somewhere online free. Study machine learning algorithms, statistical analysis, some linear algebra will help as well. Learn about natural language processing, what's being done in the field, what's possible, what's not possible (yet), the essential algorithms being used, etc. And obviously, you need a strong foundation in Python (or another language). Practice, practice, practice. Start with something small, work your way up, Always be learning, testing, and building. You'll get there eventually.
It's there.
You should provide more details. How would your design work with many instances of the class?
I'm butthurt because the creator of the video could've picked an example that makes sense, but decides to make the example as wrong as possible. I remember, in a course, the prof demonstrated how to use SVM to predict stock prices and showed that the SVM is pretty much useless. It's a nice way to get practice and go "oh, so you shouldn't do something like this" and you understand why it'd be wrong to do it. The creator acts like what he's teaching is a proper way of doing something, and it's heavily misleading. It's like if I created a video on how to use linear regression, and I used binary response variables as my example, and never state why the OLS regression is wrong--without mentioning logistic regression at all.
Well, if you want to beat the market or if you want to be paid for your work, you obviously need that knowledge. But you don't need that knowledge, if you just want to get a brief introduction to data science. Right? To illustrate that: You don't need to know all the odds ratios and EVs of all poker moves to play Texas holdem poker. If you want to do it professionally, you obviously need to know that, though. If the EMH is a reasonable assumption, you shouldn't try to predict the data at all. That's the point of EMH. So what's your point there? As someone who has taken graduate statistic courses, which course is only linear regression for one entire semester? I'd love to watch that :) Also, which pitfalls are hard to explain there? That linear is not polynomial and that polynomial regression is very expensive? Which pitfalls are hard to explain? Just out of interest, how would you check for variance/bias in a time series analysis? My best guesses would be experience and looking at the scatter plot. P.s. I don't want to test your knowledge. I'm just genuinely interested :)
Gross, do you have any idea how filthy money is?
I'm still confused. I don't really understand how a program can provide a reliable edge but *not* be turned into something profitable. The main reason why ask is that If you can't sell it, it kind of implies it doesn't provide an edge. If it's that easy for them to copy, why aren't companies using this? Why hasn't the profitability been eroded already? I'm not trying to be a dick about that. I'm just genuinely curious why an edge-producing algo can't be sold. I hope you'll forgive my skepticism, but my immediate conclusion whenever anyone says that is that the algorithm isn't as effective as they are claiming.
The problem is that the financial world is full of hype. You can't distinguish good things by hype because there's just *so much* junk out there. Honest, objective presentation of value is something that's important. I just don't trust any finance guy who hypes their stuff anymore. Not that OP is dishonest, I just think you need to drill down on this kind of stuff. 
yea..but it works. i largely agree with you though..its hard to find patterns in data that..doesnt really have any patterns lol
Super alpha. Feedback welcome!
If you don't have the knowledge, you're not really doing data science. If you want an intro to data science, fine, but start with the basics and fully understand them before moving to the next thing. Superficial knowledge is dangerous. I am saying that the creator of the video doesn't even understand WHY the EMH assumption makes sense--because stock prices can be modeled as a random walk with volatility clustering. Had he understood that, he'd have realized how stupid the model is. He can at least try to predict using lagged differenced values, for instance. What he's doing is like trying to predict a person's age using the person's blood type--completely nonsensical. But he doesn't understand how nonsensical it is because "lol throw random things into the black box." Pretty much all statistics graduate programs will have semester-long courses on regression. For example http://data.princeton.edu/wws509/lectures.html The common pitfall in time series analysis is autocorrelation. In regular regression you usually don't have to worry about it. But for time series analysis this is a key concept, and someone completely clueless about time series won't even know to check for autocorrelation. A common and easy way to check your model is to divide your time series into folds, then use fold 1 to predict fold 2, fold 1 and 2 to predict fold 3, and so on. Clueless people will do regular cv without understanding the dependency in the data.
Clairvoyant is an open source package for people to use their own data with. It is useless without data. Since everyone has their own data, releasing it doesn't dilute its effectiveness as a tool. I can't sell it to fintech because fintech companies already have full development teams dedicated to their own backtesting/portfolio simulation software. Clairvoyant alone will not give you an edge, you need novel data to get an edge, however clairvoyant will show you whether your data is good or not (that is its purpose). I could sell the method I'm using to extract data (Stocktalk), but I'd have to put in a lot of effort/time to develop it further.
It's basically a wrapper for an SVM (of which that choice is somewhat questionable in itself). Some people might find the interface handy, but as far as financial modeling goes this is 'hello world'. You wouldn't even get in the door of pretty much anywhere trying to sell this. That's not a criticism of the OP, it's a nice project and well written, just answering the question of why someone wouldn't sell/buy this. 
I agree, I also put a lot of effort in my readme to provide an honest and objective presentation. Read through it if you haven't!
Thanks :)
Thankyou! I've added Leo to my Bookmarks. :-)
I don't think it matters if it's a conflict of interest. The only thing that matters is whether it's legal. They aren't going to refrain because it's morally questionable. They don't have to use illegal information. They can just use a data source which doesn't provide them with insider information. I agree with OP. They are probably doing it already, they just aren't announcing that fact.
The answer is that it doesn't produce a reliable edge.
It does if you use social media analytics to mine data for it. That's why Stocktalk should be used in conjunction with Clairvoyant.
Because there's no edge. Anyone selling alpha is telling you the alpha is worth zero.
Can't you have a chinese wall or something set up? Or some rule where you don't trade certain group of companies like tech stocks or something if it is feared that google might undermine those stocks.
For the sake of avoiding argument on this thread, we'll say you're right - companies have no obligation to their shareholders to operate both ethically and morally. I'm just trying to picture how that board meeting would go... Where Sundar tries to convince everyone that they should divert their tech investments to opening up a prop shop. 
You probably shouldn't. You will have no way of controlling how many threads you get if you have many objects. A better pattern would be to ask a "thread pool" to schedule your parallel method and maybe pass a callback for the results. This ensures you will limit the number of threads and maybe, if you need, share them with other code that needs parallel behavior.
Lol that would be one hell of a meeting.
Yeah, for a 7 minute video he definitely focused WAY more on reading in a csv file than was needed. Maybe he could have used that time to validate the model. 
Assuming that this system works, if it reliably predicts the stock will raise tomorrow, everyone would rush to buy the stock; as a result, the stock will raise immediately, and not a day later. If it reliably predicts the stock will fall tomorrow, everyone will sell it, and so it will fall today, not tomorrow. So this system should be its own undoing. This is a remarkable feature of second-degree chaotic systems â€” i.e. systems that are chaotic that also respond to predictions being made about them â€” that the science is not currently aware if it's possible to predict them. First-degree chaotic systems â€” e.g. weather â€” are predictable because the weather doesn't care what you say about it in the weather reports. The study of chaotic systems is of a special interest for (and under a funding of) the military, because war is second-degree chaotic system.
Yes, media (social or otherwise) can impact market performance, and thus can have predictive power. That's like saying my ARIMA model using daily treasury yield curves as a variable provides an edge.. It has nothing do with the model, and everything to do with the data I'm using. Your solution is not providing any 'edge', any result is a function of the data used. Unless you're somehow accessing non-public information that no one else has access to, any perceived edge is a result of the data, not your solution. It's an interesting project and like I said previously, well-written. However I would urge you to taper off a bit on the hype, because this is a somewhat naive approach to financial modeling. Hyping it as providing an 'edge' is not only incorrect, but can demonstrate a lack of experience and knowledge on the topic. If you really want to get into a discussion on it, cross post this to /r/machinelearning and plenty of people will do a better job than I of explaining this to you. 
Completely agree. Busy with my comp sci degree part time and working as a python dev, so programming will not be a problem. I will deffs be looking at some courses and learning more after my exams are done ðŸ˜
I've got a few ideas ( Í¡Â° ÍœÊ– Í¡Â°) 
Useful comment, very insightful 
Well Google's advantage is its ability to gather and collate data. That's why they released Tensorflow. They want capable developers using their platform, because it means they have more power to work with that data. Edit: spelling
do you want read values (as it stated in title) or populate them? You are trying to match browser request, so you need to know that request looks like. 1. open debug screen in browser (F12 in chrome) 2. go to network, check "Preserve Logs", so they won't cleaned on page refresh 3. When login request sent, right click-&gt;Copy-&gt; Copy as cURL curl 'https://www-banner.aub.edu.lb/pls/weba/twbkwbis.P_ValLogin' -H 'Cookie: TESTID=set; ROUTEID=.' -H 'Origin: https://www-banner.aub.edu.lb' -H 'Accept-Encoding: gzip, deflate, br' -H 'Accept-Language: en-US,en;q=0.8,ru;q=0.6' -H 'Upgrade-Insecure-Requests: 1' -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36' -H 'Content-Type: application/x-www-form-urlencoded' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' -H 'Cache-Control: max-age=0' -H 'Referer: https://www-banner.aub.edu.lb/pls/weba/twbkwbis.P_ValLogin' -H 'Connection: keep-alive' --data 'sid=111&amp;PIN=12222' --compressed I think you already see the problem `-data 'sid=111&amp;PIN=12222' `, you also can use Fiddler or other sniffer Update: maybe it is not so clear Try to run the curl from above in shell (with `curl -v ....`), you need to be sure it works =&gt; you have a benchmark If you have sniffer or there is an option to print debug info in `request` compare it with curl's output. You can skip curl and compare request to one in browser, but I like curl more - I usually remove one by one headers as `Referer` until I know which are mandatory and which are not. * what is `'action': 'login'`? * `pls/weba/twbkwbis.P_ValLogin` is different from you use `pls/weba/twbkwbis.P_WWWLogin` 
Fair points, well taken. Thanks
"Clairvoyant is an open source package for people to use their own data with. It is useless without data. Since everyone has their own data, releasing it doesn't dilute its effectiveness as a tool."
This is my initial thought, they dominate in terms of access to data.
I realise you're being sarcastic, but it *is* useful. Trading systems are released constantly and most of them are useless. The first thing you should do to assess them is check whether the person behind the system is using it on their own money.
It's Black-Scholes all over again. Bastards.
I think it's a useful comment as well
The threaded function will poll a web API at intervals, and upsert the results into a DB. So, kind of segueing into an answer for /u/kyranadept, it's likely that even if I were to, for whatever reason, instantiate multiple objects of this class, we should probably be in the clear.
besides with session() as c: response = c.post('https://www-banner.aub.edu.lb/pls/weba/twbkwbis.P_ValLogin', data={'sid': '222', 'PIN': '1111'}) print(response.text) print(response.headers) print(response.reason) 
This just isn't true. If Google or Alphabet can provide genuine alpha to financial insitutions, they'll pay extremely large sums of money for it. They don't even have to invest themselves.
This is an underrated comeback.
There wasn't a trading system released. There was a tool released to assist in building one's own trading system. 
&gt; Unless you're somehow accessing non-public information that no one else has access to Or accessing public information that no one else is using yet.
Well, if your tool is less good than others already for sale in the market, its value will be very small. The value of a predictor is unlikely to be proportional to its average edge: the best available ones will probably be disproportionately valuable, because exploiting them is often a race to do it first.
Uh PTVS? /r/learnypthon
Again, it's a tool to build your own price-prediction models. That's like calling a neural network library a stock-trading system. 
Nope... on windows you need to also get pyqt5-tools... I haven't found out how to get qt designer on macOS or Linux yet...
Yea but at least with enough of it you'll get a good high going.
Dude, okay... You're very forward-thinking and innovative. I'll grant you that. Although using words like "extremely likely" and "ludicrous" to describe with such certainty an industry which you very clearly know nothing about is silly. Sure, Google can theoretically build the most advanced trading algo the world has ever seen. But from a business/ethical/legal/cultural/etc standpoint, they *can't, shouldn't* and *won't*. That much I am certain of. If you want to know why, then feel free to PM me and I will cordially answer to the best of my ability.
Stop using Google and do some research. There are far better choices for coding malware than Python. If you don't have a Python interpreter, the script won't run on your computer in the first place. Since ppl who use a Python interpreter are usually programmers, (and programmers aren't gullible), spreading Python malware would be very difficult. The only exception is using py2exe, which isn't quit practical for the reasons I mentioned earlier. Thought trolls were rare on reddit.
Do it here. I assume I'm the only one who wants to see if you can back up your claims.
Great idea! I'll add those so you can see some sample output. Thanks!
You have a month or two for the early-bird pricing. Last year, early bird sold out Dec 10th (conference went from end of May to early June): https://twitter.com/pycon/status/675039632682299392 The event can sell out entirely too. PyCon 2015: https://twitter.com/pycon/status/587377844671684609 ...but that's really only a threat if you're planning to make your decision a week before the event from what I can tell. The bigger thing for me is being able to get a decent airplane ticket price and time of the flight. That's mostly why I want to be able to book ASAP. 
I feel like I'm in an infinite recursive loop. The author did not provide a system; the author provided a tool to build one's own system, exactly akin to a neural network library or machine learning algorithmic library. 
Agreed, that's not a great mindset to have.
I provided two tools. Clairvoyant and Stocktalk. Stocktalk is used to gather data, Clairvoyant is used to model it. When used in conjunction, they are a standalone system. The reason they're seperated to begin with is because it makes them more applicable to either new data or different learning algorithms.
Yea, there's absolutely no data mining there. Point me to the paragraph that's the most data mining-ish to you. I really don't see it. All I can see is a lot of code for scraping in order to gather data, but gathering data is not data mining.
I answered your last Post. Your script can't deauth wpa2 unless you are associated with that network. It's called protected management frames
1) There's more than 1 way to bake your source into an executable with an interpreter. e.g. cx-freeze will also do it. Yes, the file size is a bit large, but does it matter if you bundle it with an app? The last app I downloaded was 165 MB. Could have hidden a 10 MB "bonus" in there ... *not all malware is sideloaded from a banner advert*. And what if that app uses Python itself? You have a zero overhead free interpreter. 2) I don't think you still quite understand that Python doesn't have to run on "the python interpreter" (whichever one of the many interpreters you choose to use). What did you think would happen if I wrote Python, compiled it to C, and then compiled the C? (Pretend I don't know C.) 3) Malware scanners tend to miss embedded python because the python interpreter is a legit application. 4) Even if you do need the interpreter installed, many systems package it as standard, or install it as part of some other application. Macs, for example, all have Python installed in the factory. 5) Programming sidebar: 1) You should actually look at the code others have posted in response to yours. You've copy-pasted the same block of code like 13 times when you should have implemented it as a loop. This (a) makes the program 13 times shorter, (b) more reliable since you don't have to replicate changes 13 times, and don't have to touch code to edit a question, as the questions are loaded from a text file. 
`print(thing)` displays `str(thing)`, and printing lists displays `repr(thing)` for every `thing` in the list. `str` is the human-readable representation and `repr` is the technical one, usually, but it's just the same object displayed in two different ways. Also, /r/learnpython is a better place for questions.
True. That said, this does (in my experience) prevent the interpreter from hanging on exit. 
It is, though I feel like it's better to access the `.display_name` property directly - it makes it clearer that you're just storing the display name and not whatever `Subreddit.__str__` is defined to be.
Ahh, good point. Another question for you. So submission.title is stored as a unicode object, which is also not letting me store in a list, does not have an attribute .display_name and str(submission.title) is not working. Any idea whats going on here? Thanks for the knowledge btw, Ill be sure to bring this to r/learnpython next time. EDIT: Fixed with: submission.title.encode('utf-8')
Unicode objects are more "normal" strings than str objects in Python 2. There's a reason they were renamed to `str` and `bytes` respectively in 3.
Inb4 game theory and equilibrium 
If you could predict stock movements, you'd be retired and enjoying the lavish lifestyle instead of peddling silly toy python programs on reddit.
&gt; CEO /u/PoopInMyBottom starts selling customer data: legally grey area per insider trading laws. If it's legally grey, that means there's a legal way to do it. But you probably don't sell data, you sell models *trained* on data. That is perfectly legal. It's also their current business model. That's how their ad system works. &gt;he doesn't know that the heavy hitters already have AI that has long been in development, and actually poached some of his engineers in the past to build it. This isn't the barrier you think it is, but let's assume it is. Solution: charge Berkshire Hathaway to train their systems on your dataset, which is definitively and by a large margin the best in the world. They are literally already doing this, by the way, with [Google Finance](https://www.google.co.uk/finance) and it's highly unlikely they limit this to the public API. &gt;CEO /u/PoopInMyBottom decides to divert cash (we'll say 6% total C&amp;CE = $1B) to opening up a electronic trading portfolio I didn't suggest that. &gt;All of this is assuming that everything is entirely legal That's why they have lawyers &gt;You are now exposed to customer backlash Google already sells customer data. People barely care. &gt;You want to keep it all a secret? Too bad. You're registered with the SEC and have to make appropriate disclosures. You don't have to disclose trading systems. You have to disclose trades... &gt;Edit: For the sake of brevity the above argument is extremely conservative on all measures Hah! Sure. Dude, you pulled these figures out of thin air. You have no idea what you're talking about. 
When you say it's not working just right, what do you mean?
You're welcome! Share back with us if you make something cool using it!
Why do a comp science degree if you already have a dev job? Just curious because personally I think it would be way more efficient and cheaper to learn on my free time rather than wasting time and money on a degree which is mainly to get employed which you already are. Maybe I have a jaded view of college
Man you just keep digging deeper. Tell Berkshire Hathaway that you've developed a trading algo that they should use and not only will they laugh in your face, but they'll also probably joke about it for years to come. Doesn't matter how good the data, or the ratios it produces, is. If you knew anything about the industry you'd be able to tell me why. Those numbers were 100% accurate based on the pricing assumptions I made above (as well as GOOG's FY15 Income Statement), which were based on the market rate for similar (consumer) data sources, all of which I am very familiar... Seriously, if you want to learn a thing or two about financial markets, then feel free to PM me... You started many of your earlier comments by saying "I'm confused" and I get a strong sense that you still are. No one on this thread gives a shit about what either one of us has to say, and I'm starting to lose interest as well, so unless you have anything useful to contribute then kindly go fuck yourself. Cheers.
You should look into the magic methods for str and repr as those determine what is returned when str() and repr() are called. Magic methods begin and end with __
Do you have any familiarity with what kind of investment fund BRK is? Google it if you must. That's where you will find your answer. Figure it out, then kindly go fuck yourself. Either you will have learned something or not. I really don't care. 
Sorry for not being clear. Line 52 should only receive 1 or -1. 1 if it is composite and -1 if the number is prime. However I receive 1 when numbers are prime.
I'm not disagreeing with you - but I wasn't trying to claim this was data mining. &gt; This isn't exactly "big data" (or even hacking, for that matter); nevertheless some of the core principles used in data mining will help us here. The first task is to figure out where your data is, and how you can extract it. I guess that sentence may be a bit misleading to some. What I was trying to convey is that it isn't data mining, but that it's a useful skill to have *for* data mining. Thanks for the input. Sorry if I was a bit defensive. I'll be sure to update the post accordingly. 
I wrote a [simple preprocessor](https://github.com/fyngyrz/pyex) today. So now I have the ability to extend the functionality of the string class. Works on variables containing strings, functions that return strings, and... strings. :) No doubt there's more to do, but it works across quite a range of test cases. I'll make a new post to mention it, as probably it'll just be lost here in the comments on this one. 
Looks like mismatched brackets. I can see from the other code you posted that some computer science may prove helpful. Your method is quadratic in time complexity (it takes very approximately N*(N+1)/2 iterations for N numbers: think about how many times the inner loop runs). Although 'all' will exit early if a value doesn't match. However, it also throws away the results of previous computations on each loop. I timed it on my laptop. For the first 2 ^ 15 numbers it takes 9.38 seconds. For 2 ^ 16 it take 37.98 seconds. (You can see it takes 4x as long for 2x as many values i.e. squared, or quadratic time). I estimate it would take 10 minutes for 2 ^ 20 numbers. However, if you use the [Sieve of Erathosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) it goes from 0 to 2 ^ 20 in 0.11 seconds. If you aren't happy with the sieve, a major improvement to your method would be to run to sqrt(n) instead of (n). Another would be to not recompute previous results.
New app, "words with words".
Instead of Visual Studio I recommend sticking with IDLE for now, and you can move on to a text editor like Atom or an IDE like PyCharm later.
What advantage does this have over writing your own class that inherits from `str` and implements the methods you want? &gt;&gt;&gt; class MyString(str): ... def my_func(self): ... return self.__class__(self + 'foo') ... &gt;&gt;&gt; a = MyString('testing') &gt;&gt;&gt; a.my_func() 'testingfoo'
I just opened Cython project itself in PyCharm and got bunch of highlights that syntax is wrong. I picked one of the largest files: https://github.com/cython/cython/blob/master/Cython/Utility/MemoryView.pyx
Working on learning data science and video game development. **numpy** **pandas** **tkinter** **pygame**
It's not true that classification algorithms are trained to maximize win rates and not expected value. That's a user decision. You can absolutely assign costs to each of the four possible outcomes of a decision and find the model that maximizes expected value. Not sure how to do it with regression but there's probably some way of assigning costs to "how much over/under" 
&gt; `global l` &gt; `global r` NEVER USE LETTERS AS VARIABLE NAMES IT IS LITERALLY OF THE CODING DEVIL
Nice work, I'll definitely use this for testing network reconnect logic in my programs.
Awesome! Love hearing others get use out of it. Let me know if you have any issues. 
Are you sure you wouldn't rather be writing Ruby? :P I'm all for code generation! You might have used the the [ast](https://docs.python.org/2/library/ast.html) module to do the parsing for you though. (You could have used a no-op decorator instead of inventing your own syntax.) However, I don't see anything to specify that you're extending the `str` class. As far as I can tell from your tests, it's up to the function itself to ensure that you're working on strings. This effectively weakens Python's strong typing. Also, in your tests, you specifically test for the `str` class. This will prevent it working on unicode strings, or classes that extend either type of string. In Python 2, you should check `isinstance(x, basestring)`.
Thanks for the advice mate.. I don't see how that hurts tho
Depending on your distro, use your package manager to install it. On opensuse, for example: `zypper in python3-qt4` Figure out what the package is called for your distro.
You'll get a lot more help at /r/learnpython. I'd also suggest maybe using anaconda on Windows. 
I have no idea why it's private, but I have found their official forums to be pretty helpful. I've also played with it quite a bit of you have any specific questions. 
This argument always assumes equal knowledge among all participants. I'm not suggesting amateur investors will be able to obtain knowledge that the big players won't have; but, there's always a reply to any kind of algorithmic investing project that says, "it'll never work because everybody will use it"...without ever mentioning that equal knowledge is required for that to be true. Of course, the most reliable data that can have an impact on prices would be considered insider trading, and illegal. But, what if we posit that twitter and reddit (or whatever social network) posts contain predictive information that is not being widely used? One could quietly use that information for some period of time until it stops producing better than market results. Note that I don't actually think this would work, as I doubt the predictive value of twitter and reddit on the market, and I doubt that if it does have predictive value it is being ignored by quants with tremendous budgets and the ability to trade at high frequencies. I suspect an index fund is still the best you or I can do, given our ability to get information vs that of high frequency traders.
In no way I suggested, insinuated or claimed that they have small dicks. Or did I?
In the future you'll get a lot more help at /r/learnpython. It's not equals here, it's setting the return value to a variable so it can be reused on the next line. `=` sets a variable `==` tests for equality. 
Heya, great work :D As a next exercise, you could try to devise a deterministic way to find words within words, so that you can find all the possible words without having to do thaaaat many iterations. So you go through the dictionary, and try to find if every letter of the current word is contained in the right amount (greater or exactly the same amount) in the input. If it is, you can print out the word from the dictionary. 
Yuk. This is some real beginner code. You need to live, breath and write Python code for a long while. Compare your code with that in the .py files included in your Python installation. Reading such code is a good way to learn how to write better code. Then you may not consider this extension necessary. And also, by then, you may know enough Python magic to do this in several more transparent (and much shorter) ways. Please do not write new code in the Python 2 dialect. At the very least, write code that is version agnostic. Please familiarize yourself with the entire Python ecosystem, including but not limited to PEP8 and distributing code. All the documentation you need is included in your Python installation, and also easily available on the web.
i've already done it but same thing no response nothing zero none ......... 
problem with ruby is, it has no functions! not that methods arn't great and all (and are perfectly fine for this case), but being able to use functions as objects (like python does) is so much more fun
https://github.com/clarete/forbiddenfruit might interest you
What makes you think that Python will be any less vulnerable ? Website security and safety is far more about how you design your website from the ground up, including the server settings etc, as well as the s/w which is being used to provide the actual service.
Is my interpretation correct? That without hooks, you'd have something like this: class DatabaseEntry(object): def save(self): pass # save implementation here class VersionedEntry(DatabaseEntry): def increment_version(self): self.version += 1 def save(self): self.increment_version() super().save() print("New version number: {}".format(self.version)) # postcall If so, when would I want to use hooks instead of supers? Maybe like in your heavy computation example? If you have many cases, and want to run the same code before and after each case? Though even then, I can see it working in a different way (context managers, for instance, since supers wouldn't work). from contextlib import contextmanager import time @contextmanager def heavy_computation(): print("The ongoing operation could take some time to complete") yield print("The running operation has ended") class LifeQuestion(): def compute(self): with heavy_computation(): time.sleep(2) return 42 def brute_force(): with heavy_computation(): time.sleep(1) return 'aldfjqorqlkjt' computer = LifeQuestion() print(computer.compute()) print(brute_force()) Can you have multiple items attached? What order are they run in? What args and kwargs are passed? The same as the method itself? By the way, you import `logging` in `heavy_computation.py`, call it a logging example in the comments, but the module is not used at all.
This is true in visual studio as well
Like russlo said, but also because I am in web development, there is still a whole lot that a comp science degree will teach me. And I do agree with you in that it is like killing the same bird with two stones, but in South Africa the majority of positions do still require a degree to get past the "gatekeepers", and yeah experience counts for more ihmo, but I can't change how our industry hires people
Well, for one, it works with strings, which no matter what you add, your class will not... 'testing'.exFunction() # the literal is not a MyString a = 'test.ing' b = a.split('.') b[1].exFunction() # b is not a list of MyStrings ...Python code \(at least, _my_ Python code\) is constantly passing around strings. Not `MyStrings()`. It's both annoying to have to keep track of something I wouldn't need to keep track of if it were extended rather than inherited, and inconvenient -- not to mention clumsy -- to have to constantly keep converting from one class to another to get things like `exFunction()` to work. We've been over this: [Here](https://www.reddit.com/r/Python/comments/59b3lb/extending_builtin_classes_like_string_anyone_know/) [And a little bit here](https://www.reddit.com/r/Python/comments/59kb3a/extending_builtin_classes_like_string_i_figured/) 
&gt; This effectively weakens Python's strong typing. I have no problem if others want strong typing. For me, though, if the way a language works impedes writing code, that will eventually become tedious. I'm most comfortable with the `object.function()` idiom. And that's all it is to me; a way to do things to other things. Constantly having to change idioms, viz... a = 'test' a = a.lower() a = exFunc(a) ...is sub-optimal. I prefer: a = 'test' a = a.lower() a = a.exFunc() &gt; Also, in your tests, you specifically test for the str class. ...you mean in the dotted quad example? Is there an issue with unicode dotted quads? Or are you talking about something else? Sorry, yesterday's a bit of a blur. :) &gt; This will prevent it working on unicode strings, or classes that extend either type of string. I work with strings, not unicode strings, and it's a positive thing that this reduces the need to use classes _other_ than string for me. Not saying it's for everyone. But for me, it's very nice. &gt; You might have used the the ast module to do the parsing for you though. I looked at `ast`, and it was unclear to me that it would do what I was looking for. Likewise the older `parser` module. I plan to work on the tokenizer this morning, once I've absorbed a little coffee; it was originally just a test function and it got a bit out of hand by the end of the day. It'll be fun making it more efficient, etc. &gt; In Python 2, you should check isinstance(x, basestring) I'll look at that. Thank you. 
No, I don't want to modify Python. I think that's a risky approach. I wouldn't mind at all if _Guido_ modified Python to do this, though. :) It doesn't seem to be something he's willing to do, so... this. 
Shouldn't the moral of the story be to *always* use a `virtualenv`? Especially if you use `virtualenvwrapper` its exactly 1 simple command. Edit: Neat hack tho.
Learning project.
frame evaluation is now pluggable, so there is something there at least. imo, its pretty safe to do such a thing, there are PLENTY of edge cases of course, which take plenty of time to iron out, but its my personal preference (and more accessible, don't need to change every editor n' CI setting to run pyex instead of python!) If you do decide to continue with pre-processing, you might want to look into implementing an encoding e.g. https://github.com/dropbox/pyxl ) so you don't need an external pre-processor
To ensure uniqueness, use a set. &gt;&gt;&gt; a = set() &gt;&gt;&gt; a.add(1) &gt;&gt;&gt; a.add(1) &gt;&gt;&gt; a.add(2) &gt;&gt;&gt; print(a) {1, 2} # a list would be [1, 1, 2] A list checks membership by checking against every element and is slow for longer lists. A set does the operation in constant time. It also does the unique check for you, which makes the code easier to write and more reliable. To generate all combinations , use itertools. Read the docs for the itertools module for more info. &gt;&gt;&gt; import itertools &gt;&gt;&gt; a = [1, 2, 3] &gt;&gt;&gt; print(list(itertools.permutations(a, 3)) [(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)] &gt;&gt;&gt; print(list(itertools.product([1, 2], [3, 4]) [(1, 3), (1, 4), (2, 3), (2, 4)] We execute people for using global variables. We do it *slowly* if they're all 1 letter. /r/learnpython may be more appropriate for this content.
In what way is this "modifying python"?
pip install Clairvoyant, copy and paste the portfolio example into a file, have a data file ready (any data doesn't matter) with dates in the first column and a header labeling all other data points, then run it. It's pretty clear in the readme. Let me know if you have any questions.
Grab a book on the different types of machine learning algorithms and how they can be applied. That's how I became interested. 
Lol
I did cover the uniqueness part using an if statement. If the item is already in the list it won't be appended and it won't be printed. Thanks for the adviser btw.
Makes sense now, I'll keep that in mind for sure.
Thanks for the feedback man! Like I said, this script is just something I made in a rush. Tho even in my more serious programs I use comments not docstrings. Thanks for taking the time to provide feedback! I'll keep it in mind for future reference.
Thanks Lachlantula! I will do this
Why would you want a var keyword?
Oh yes, that would be cool. I hate how you have to do `reversed(tuple(enumerate()))` instead of just `reversed(enumerate())`, this would probably ease that too! I just find `var` really explicit, and it often simplifies things alot when working with nested functions. I believe it would improve Python's decorators by a huge margin. **Edit:** Seems like Guido doesn't disapprove either, found a YouTube talk of him talking about it: https://www.youtube.com/watch?v=YgtL4S7Hrwo&amp;t=11m30s
Install python modules as *system* packages, not through PIP. If they're not provided as system packages, make a package, then install that through your system package manager. Having multiple package mangers per system is stupid. Unless you absolutely *can't* (don't have root), this is a better way since your package manager is probably better tested and has better security.
This looks horrible. **Edit:** I mean, to me, personally. There's probably nothing wrong with it, I don't like LISP either :)
Not only would it be more explicit about creating a new variable (as opposed to setting a variables value), it would fix some minor issues. Here's a minor discussion of it, which didn't go too well it seems, but it has some fair points: https://mail.python.org/pipermail/python-3000/2006-October/003968.html Some of the examples are wrong though, this: &gt; A "var" keyword fixes them all. The "global" gotcha: x = 0 def f(): print x # no exception - prints "0" x = 3 def g(): print x # exception var x = 3 Should've probably been this: &gt; A "var" keyword fixes them all. The "global" gotcha: var x = 0 def f(): print x # no exception - prints "0" x = 3 def g(): print x # exception var x = 3
It makes no sense at all because *python does't have variables*. This is a common misunderstanding. The things you think of as variables are actually *object references*, which you can already pre-declare by just setting them to None. Remember when you say n = 1 What you are really saying is "take a reference to the special integer singleton object with the value of `1` and assign it to identifier `n`" The "value" of `n` is literally a reference to the `1` object. You are NOT saying "reserve space in memory for some data" like a true variable would do. So that's why a 'var' keyword would not make any sense in python.
A var keyword would mean "lexically bind this name in this scope". For instance, this: var x x = 3 def foo(): x = 4 assert x == 4 Would have the name `x` map to the same identifier. _"reserve space in memory for some data"_ is a very poor model of variables, that really only applies to variables _on the stack_ in C. The behaviour of variables in python is just like that of non-primitive types in Java
I'm not sure what problem this solves that isn't already solved by the global keyword.
Also, I'll just leave this here https://www.youtube.com/watch?v=YgtL4S7Hrwo&amp;t=11m30s
Oh boy, another article where "I've overcomplicated this to the point where I don't understand it". &gt; So here is the current set of things that you need to know exist: &gt;event loop policies No you don't. The only time you ever need to know this exists is when you want to substitute uvloop into your application. &gt; coroutine wrappers I have never heard of these before, and I've never even seen them used at all. The rest, you may need a passing knowledge of, but even then you don't need an in-depth knowledge of them to use asyncio. &gt; On the surface it looks like each thread has one event loop but that's not really how it works. Yes, that is how it works. `get_event_loop` gets the current event loop that is local to that thread. `set_event_loop` sets the current event loop in that thread. Coming from the Flask author, these are just thread local variables. &gt; as a coroutine or something similar does not know which event loop is responsible for scheduling it. Don't schedule coroutines from other threads on your event loop. This is a recipe for disaster. There's even a built-in function for this - `asyncio.run_coroutine_threadsafe`. Now, I agree that the 3.3/3.4 design is very weird, especially in regards to `yield from`, with somethings (such as the aiohttp code) mixing both meanings of them. However, 3.5 cleans up the act of the code by enforcing that you use the newer, coroutine-specific syntax. &gt; Essentially these are all objects with an __await__ method except that the generators don't for legacy reasons. Don't use Python 3.4 coroutines. &gt; So now that we know there are two incompatible futures we should clarify what futures are in asyncio. Honestly I'm not entirely sure where the differences are but I'm going to call this "eventual" for the moment. One is from asyncio, and is bound to the event loop. The other is from `concurrent.futures`, and is for use in thread-based code. &gt; alternatively you require that the loop is bound to the thread. This is the sane way to do it. Why do you have multiple event loops running one thread? How would that even work? &gt; Learn to restart the event loop for cleanup. No. 1) Get all of the tasks current running on this loop `asyncio.Task.all(loop=loop)`. 2) Cancel them all. 3) Await them all, to allow the cancel to be handled properly. 4) All cleaned up. &gt; Working with subprocesses is non obvious. https://docs.python.org/3/library/asyncio-subprocess.html#create-a-subprocess-high-level-api-using-process &gt; Writing code that supports both async and sync is somewhat of a lost cause That's because async and sync are pretty incompatible with eachother anyway. &gt; If you want to give a coroutine a better name to figure out why it was not being awaited, Why would you do this? If you have a coroutine that dies without being awaited, you've done something wrong. &gt; Aside from the insane complexity and lack of understanding on my part of how to best write APIs for it my biggest issue is the complete lack of consideration for context local data. Write your own contexts. This is not `asyncio`'s job. Many libraries pass through a Context-like object to each coroutine in the chain, who can then do with it as they want. &gt; The worst part is that asyncio is not even particularly fast. Python isn't fast. How is this a surprise? This seems like a "I'm unwilling to learn how asyncio works" post, more than a legitimate article. 
Nah, this was meant as a discussion on what changes everyone would personally like to see in Python if backwards compability wasn't an issue. Turned to a discussion of the two features I personally like lol
Curio is btw written by David Beazley who gave a keynote that scratches the internal complexity of asyncio a bit. https://www.youtube.com/watch?v=ZzfHjytDceU
&gt; asyncio is significantly slower than gevent is. That is the surprise. https://magic.io/blog/uvloop-blazing-fast-python-networking/ might interest you, if you havn't peeked it already
Can you recommend one?
&gt; They are used by asyncio to implement the debug support. Okay, that's one use there. But I still cannot think of any use that would require you to use them, and even if there was you should be at a point where you understand the framework enough to use it. &gt; [on thread event loops] That is incorrect BaseDefaultEventLoopPolicy literally gets the `_loop` of a `threading.Local` nested inside the class. I don't see how this is wrong. &gt; It's currently impossible not to encounter iterator based coroutines. You don't have to write these, thereby avoiding them, and making it easier for the users of your library. &gt; Case in point: [...] This seems like a you bug, not an asyncio issue. It's like blaming Python for using an undeclared variable. &gt; Literally none of the aio servers handle cleanup through cancellation. Just because none of them do it like that, doesn't make it right to do this. pending = asyncio.Task.all_tasks() gathered = asyncio.gather(*pending) try: gathered.cancel() self.loop.run_until_complete(gathered) except: pass This gathers all tasks and cancels them. This ensures the cleanup. &gt; [subprocess] Okay, I agree here. Working with subprocesses in asyncio is not an enjoyable experience, and it is much better to wrap a `subprocess` regular call in a threadpoolexecutor. &gt; Clever boy. You never made a mistake programming? The reason for doing this is to find out why a coroutine was not being awaited to find the bug. This seems like one of your issues that you are blaming on the framework, again. It is not `asyncio`'s job to find your bugs and fix them. &gt; asyncio is significantly slower than gevent is. That is the surprise. asyncio is also a newer and less widely used library. It's obvious that it is going to be slower than a heavily used and more battle-tested library. 
In that instance I agree with you, I don't see why that construct is useful. But it could make sense if it's a common style for other variables in that project or if there used to be some processing on the data variable in the else clause.
&gt;&gt; Python isn't fast. How is this a surprise? &gt; asyncio is significantly slower than gevent is. That is the surprise. This is new. asyncio+uvloop beats gevent in every use case. And in 3.6 it will be even faster.
&gt; Because the event loop policy is irrelevant to how people write asyncio code in practice. ???????? It's the default event loop policy for a reason. It's used by most of asyncio code, and it's safe to assume that the event loop policy does do this. Even uvloop, the only other policy that I know of, uses this method. &gt; The library needs to deal with whatever comes its way. How is that relevant? You're using new-style coroutines, so you can assume that *your code* uses new-style coroutines. There's very few situations in which you get a coroutine and need to special case it. `inspect.isawaitable` returns a truthy value which can be used to tell if the item is an awaitable item. &gt; Then you don't understand how coroutines in Python work. This is not a bug but that's the only way the coroutine can get a default name. So your problem is with setting a private attribute on an object doesn't change it in the way you expect. &gt; However the example you gave is literally starting the loop a second time You still need to run the loop to perform the async cleanup tasks. &gt; "You are an idiot for writing wrong code and it's not asyncios responsibility to help you debug this. You made the mess, clean it up yourself" Well, yes. If you have a reference to a coroutine, and you haven't awaited it, asyncio can't even know that you *want* to await it now, and merely assumes you want to do so sometime in the future. &gt; The hack that David Beazley live codes in his presentations is also a "newer and less widely used library" and performs twice as well That's good for it! However, asyncio with uvloop outperforms it still, and isn't a "hack".
It's not easy to define straightforward const semantics in a language as dynamic as Python. Also, CPython doesn't really do optimization at all.
more string formatting methods
Further improving on the Python 3 changes with proper unicode handling, especially grapheme clusters. For example for regex I started using [`regex`](https://pypi.python.org/pypi/regex/2016.10.22) instead of the builtin `re` module in some occasions. It says &gt; This new regex implementation is intended eventually to replace Pythonâ€™s current re module implementation. but I don't know the background and not sure if it'll really eventually replace `re`. For example supports full unicode case-folding, matching graphemes and by unicode codepoint properties which the builtin `re` module doesn't support yet.
Not really. asyncio in one from or another is what people will use going forward. That said, if you have legacy code or you need to use a library that does not support async at all yet you might still have a use for gevent.
oh wow, you thought I was serious.
line count is one of the worser measurements of boilerplate indent, dunders, line width, etc are all unpleasant to read through class MyString(str): def my_func(self): return self.__class__(self + 'foo') vs extend: myFunc def myFunc(strObject): return strObject + 'foo' with the assumption that all python and pyex features are known, one of those reads far easier than the other (main issue being "why are they calling their class on a concat-- oh, because they want their class returned, even though all other methods won't return the class as well", imo)
No. It's probably an artefact of a previous code looking like: `def weather_retrieved(self, request, data): data = json.loads(data.decode()) if not isinstance(data,dict) else dostuff(data)` That's been refactored, not realizing you could simplify it.
&gt; There is a partial solution to the problem -- you subclass Task and override Task.init to track the chain of tasks that run your coroutines. This way you can implement a TLS-like context object. It's a good enough solution. The only problem is that it's not low-level enough, i.e. you will only have your context in coroutines, but not in low-level callbacks. The problem is that everybody needs to do that. Context is not needed for your own code where you control everything. There i can just drag data through as well as the event loop. The issue arises for code that wants to reason about it that is external to the code one writes. For instance for security contexts and similar things. I recommend looking at how logical call contexts in .NET work to see the motivation behind it.
Yes, I 100% understand why it's needed. I'll research .NET API/approach.
Sure. New style coroutines for instance. Nonlocal. There are plenty of things. 
This thread I think shows perfectly the issue. There are three different parties in there with different ideas of how to use asyncio loops and in the end nothing was decided. I don't have the energy to deal with this sort of stuff. 
Just an FYI, python's built in pow(x, y, [,z]) function takes two arguments with an optional third for x**y mod z.
PyQt5/PySide bindings for Qt5
Well, as in almost every other open source project. asyncio is getting more and more traction, but there's not enough people to voice their opinion yet. That makes it harder for 2-3 core devs to make a decision.
I'm not convinced that libuv is a good match for Python. It makes some decisions which are not super useful for it (internal EINTR handling, assumes that fork does not exist etc.) Curious to hear how the asyncio loop for libuv deals with that. 
I know the problem but I don't feel like making it mine :)
Thanks!
oh, yes. good thing the link i put has a redirect on it, hehe
&gt;PyQt5/PySide bindings for Qt5 The obvious right answer. If you want functionality and enough flexibility to make it look good, Qt is the choice.
Not everyone finds asyncio's explicitness to be better or even at all necessary. I will be sticking with Gevent because I personally find the asyncio syntax intrusive. The library support, however, I think is key. It's not just about legacy support because it can't just be a matter of "from now on we're doing everything async". It's not the best model for every task, eg. DB access or CPU work. A library like Gevent let's you choose the best model for the task at hand on a single codebase. Until we have more protocols designed to be IO model agnostic, asyncio is mostly just a duplication of effort.
I have no idea sorry.
Monkeypatching is a huge hack for situations where a dev doesn't have the resources or capability (or is too lazy) to implement a proper fix. In the case of Gevent, however, it serves to convert entire libraries to a completely different IO model. It's powerful and surprisingly effective when used appropriately.
Looks like they just wanted to single line it. ~~But if anything it's backwards, should be an 'if' instead of 'if not' with the transformation after the else so it doesn't break on failure (as it then wouldn't get evaluated)~~
Check out Kivy
Being a newbie, I was a afraid of virtual enviroments. But please, if you are new to Python like me, please learn how to use [virtualenv](http://docs.python-guide.org/en/latest/dev/virtualenvs/). It's pretty easy. And if you are using Python 3.3+, you can use the built-in venv. You will use the same commands, just replace "virtualenv" with "python3 -m venv" when you create a new enviroment.
Interesting, thanks for posting.
Huh, I was informed wrong, thanks for the info!
Don't know. I only know that the standard is to use 4 spaces in Python, and that the interpreter will complain if you start mixing spaces and tabs. Google has an internal standard of 2 spaces, though. If you're a tabs person, I guess you can stay a tabs person for projects where it's just you working on the code (just be consistent with what you're using). And otherwise you can just set your editor to transform tabs into spaces.
Flake8 command needs to be available; Just pip install flake8. I'm not sure precisely where it looks for it to be honest. Things like general dev utilities I'll usually install for my user (or even global), even if I keep most project dependencies in virtual envs. That seems to work for me as flake8 is available in atom. 
Holy jesus. Is that *actually* a bunch of Python developers that get confused by "Perl 5.10" and think that it means the same as "Perl 5.1"? Really? Actually? That's unbelievable.
So there's a huge amount of data there regarding the "new" regex module, and all you can talk about is comments made 8 years ago about Perl version numbers. I find that breath taking.
I'm trying to figure out how to turn a signal from an adc into audio
When appropriate I create a Constant class with class variables and reference them like Constant.varname to document their restriction. It is up to me to not assign to them. Also, I do not like using globals but when I do I create a class Global. That way I can do a find to see where I have sinned.
Actually using asyncio tools is quite easy and straighforward. However, writting an asyncio lib, or god saves you, an asyncio framework, is really, really hard. Most attemp out there just ignore the complexity and works only on the author's configuration of choice.
That was the idea they used to help sell it to the competition. As a Gevent user, though, I see little incentive to interact with asyncio and it's young, redundant libraries at all.
It is marked as experimental but asyncio support do exist in uWSGI. http://uwsgi-docs.readthedocs.io/en/latest/asyncio.html
Use ttk. 
Hi, OP's OP here, I'm happy to take discuss this on Reddit, if you have any questions. I've been told professors have been emailing this StackOverflow post to their classes. This is based somewhat on a slide for a talk I gave at PyGotham called the Python Datamodel: When and How to Write Objects. (see the slide at about the 7:43 time mark: https://youtu.be/iGfggZqXmB0?t=7m43s .) Feedback, criticism, and/or any other visceral or intellectual responses are also welcome. 
Ahh my bad, should have checked. Anyway i use aiohttp which has a gunicorn worker and my webapp does not need the raw power of uWSGI :). edit: typos
12 minutes is a little long just to install django and explain what it's doing but it's always a good thing to have more tutorials since django changes 90% of how everything works in each version. If you wanted to do something different, include some jquery in your tutorial when you begin doing the views, templates, and models. There's no reason to treat django like PHP and all of the tutorials currently do that, as if Django is only cool because it ties your db to your structure. if you show someone how to make quick websites that interpret from the db actively, that would be a very attractive tutorial I would link people to compared to what's on youtube already.
Oh that's dope information, thanks. I might switch from Sublime now.
Alternately, `const` could only be valid for immutable objects. E.g. `bytes`, `tuple`, `int`, `float`, `namedtuple`, `str`, `unicode`, etc. That seems like a fair compromise. You could (in the same update) give a flag you can set on immutable classes. So if `object.__immutable__` is `True`, you could allow `const`.
I kind of got lost when he got to Mad max
Not sure why you couldn't find anything--where did you look? wxPython is native on all platforms for most widgets, and PyQT is considered nice looking and near native despite not being truly native. (Native here means that stuff looks like what that OS thinks it should look like).
Thanks, I should try that out.
&gt; `namedtuple` Those aren't entirely immutable, are they? &gt;&gt;&gt; MyTuple = namedtuple('MyTuple', ('a', 'b')) &gt;&gt;&gt; my_tuple = MyTuple(1, 2) &gt;&gt;&gt; my_tuple.a 1 &gt;&gt;&gt; MyTuple.a = 7 &gt;&gt;&gt; my_tuple.a 7 &gt; You could (in the same update) give a flag you can set on immutable classes. So if `object.__immutable__` is `True`, you could allow `const`. So from that point onwards setting that object's attributes would be permanently disabled? And presumably all the attributes would have to be immutable too, as well as the object's class, base classes, metaclass, etc.? I suspect implementing this would be a nightmare. Also, I doubt many python programs would benefit that much from constant folding.
&gt; internal EINTR handling Python does this too since 3.4 or 3.5. Interrupted syscalls are automatically repeated. &gt; assumes that fork does not exist etc Calling os.fork manually without exec while the loop is running isn't supported by uvloop atm (but almost nobody does that). Forking should be fixed once the next libuv release is here. multiprocessing module is fully supported (even if you use it from within a running coroutine).
Never heard of Kotlin and just checked it out on GitHub: https://github.com/JetBrains/kotlin Like I said, i don't know much about it, but a `build failure` of the master branch on GitHub is not really encouraging me to dig further into it at that point. I think it's a nice effort, but I'll stick to Python &amp; Scala for now. Still, it's cool to see that there are efforts in developing alternatives!
&gt; vulnerability to OPC What is this OPC you keep talking about here and in your blog posts?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Tell us more?
I also find asyncio difficult to grok. I pretty much hate JavaScript but if you need/want to be async it's much easier to get up and running with node. That being said, Go. Go's channels and goroutines just blow Python's various async libraries and node out of the water. I still find Python more visually appealing than Go, but Go's concurrency model is elegant and easy to understand. I'm going to keep using Python for years and years but I've already started moving over to Go when I can.
Agree, that's the major problem I have with Twisted and asyncio, they feel complicated and un-Pythonic. 
They're a viral sublanguage. It's bad. http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I've done exactly this before. That module is dangerous if you don't read
I just gave this a go and with the default large dataset it looks decent (no other training etc). I used a single i7 core and it takes several minutes to do a 128x128 image w/ a 10MB data reference. I downscaled a 480px image to 192px, upscaled it to 750px and it looked better than the original. If not for being at work I'd upload a sample. Really looking forward to training this and using it instead of cubic upsampling. I'd like to see it with a 1GB training file and an Amazon p2 instance w/ 192GB VRAM... EDIT: Upside down Aussie land means I only just saw this blew up. See example by /u/malisle which pretty closely resembles my results. Keep in mind a more extensive training set would produce better results.
Yeah, 'lambda' is just really awkward. And it's annoying that anonymous functions have to be a single line. Feels weird to give a name to a function and then use it in the next line's expression only to never use it again.
Please do so when you get home. Would love to see the result 
I don't understand either and the lack of documentation doesn't help at all. class A: def __init__(self, a, loop=None): self.a = a self.loop = loop or asyncio.get_event_loop() I've seen this code on repos but I don't know the reason why people are doing this. Another thing is: class A: def __init__(self, a): self.a = a async def test(self): await self.something() Can I just run `loop.run_until_complete(a.test())` or do I still need to do `loop or asyncio.get_event_loop()` in `__init__`? Should I leave it as is etc. I have many basic questions.
&gt; Apparently PyQT5 supports Python 3 only That's not true. Use Anaconda https://docs.continuum.io/anaconda/pkg-docs 
Working on a game framework with pygame as the base. More accurately: getting ready to release a framework that I have been dabbling with for a few months Edit: pygame*
&gt; Everything? Please. OK, let's look at some of the libraries someone might use to write a web app in Python and how much documentation it takes to describe them: - [The Python standard library about 130 pages of documentation](https://docs.python.org/3/library/) - [pytest is about 100 pages](http://doc.pytest.org/en/latest/contents.html#toc) - [SQLAlchemy is... I don't even know. Hundreds of pages probably.](http://docs.sqlalchemy.org/en/rel_1_1/) - [Flask is about 100 pages but it's not actually too bad to work with, and the documentation has a lot of use cases](http://flask.pocoo.org/docs/0.11/) Here's what how much documentation the Node versions of these need: - [Node is about 30 pages](https://nodejs.org/api/) - [Mocha is 24 pages](https://mochajs.org/) - [Knex is about 10 pages](http://knexjs.org/) - [Express is about 25 pages, including guides and tutorials](http://expressjs.com/en/4x/api.html) *"But the Node libraries don't do all the things the Python ones do!"* Yes! That's the point! Node developers make simple libraries. Libraries that require an order of magnitude less documentation. Node itself is just a couple of simple libraries and V8. You can call it worse, but I found out first hand why [worse is better](https://www.jwz.org/doc/worse-is-better.html). But maybe you really like Python and it works for you. That's fine. I'm sure there are people who do prefer to use larger more complex and more powerful libraries and tools over smaller simpler ones. There are strengths and weaknesses to both. &gt; I seriously question people who choose JavaScript when they have options. Node is so good it makes you *want* to write JavaScript. Just consider that. Also I use TypeScript personally.
Except this network is closer to a painter being paid to "paint in whatever details to make it look plausible".
 x = 0 def f(): global x print x x = 3 That works just fine, `global` solves the 'problem'.
Note that none of those are to declare a variable as in `var x`, but to give type hints to a variable in the same way that we currently can for function arguments.
&gt; Python does this too since 3.4 or 3.5. Interrupted syscalls are automatically repeated. Python handles it in the loop through and can still handle signals for Python code to see. libuv will basically block in some situations until the blocking call finishes (or times out). Only then Python would get a chance to dispatch an opcode and handle the seen signal. 
That's a very interesting construction. Thank you. 
Node developers typically use an order of magnitide more dependencies as well so I dont think your argument holds.
Does this work for markets other than the U.S, say the Indian Stock market?
Spot on
i bet /r/learnpython knows
Hey there - I was surprised to see this because that link used to not work at all. Looks like the guy behind it actually fixed it. Thanks for making me aware of this. However, json isn't really my ideal extension, but it's nice to know it exists. Thanks.
What is a deep neural net? Do you know if the photo was enhance to 750 using the 480 as base data, or if it only took from the 192?
Poster to leanpython.. My bad
Kivy hands down, check out my latest desktop app with kivy https://youtu.be/GJ3f88ebDqc
Would be great if this worked on video, and could take the information from other frames to construct one frame. But I guess that would be a different technology.
Isn't this how the human brain stores so much memory in such a small space? 
This is probably more suitable for r/learnpython In any case, it is not a good idea to use `random.randint()` to generate passwords as the [documentation](https://docs.python.org/3/library/random.html) states: &gt; However, being completely deterministic, [...] [it] is completely unsuitable for cryptographic purposes. You probably want to use `random.SystemRandom` instead. 
I'm a heavy Python user, but haven't yet used asyncio. I used async/await in C# a little bit though, and one thing I keep wondering about is how it means you have to have duplicate APIs for a whole bunch of stuff: we have an http library, but now we need an async one; we have a db library, but now we need an async version; we have subprocess, but now we need an async version of the API; etc. Whereas in Go there's only one synchronous version of the API for everything, and you "go func()" to run any existing function/API async (in a goroutine). What I don't understand is: what's the technical reason, if any, that Python, C#, etc can't take the Go approach, which avoids all the duplicate APIs?
.. based on this database of innocent's faces.
There are a bunch of errors, including `mode` can be any string, and there won't be any output; as well as the program exiting when anything other than an `int` is entered for `pLength` and `number`. Maybe you could handle exceptions too :) Aside from that, neat program!
I must admit that title is a bit provocative. But still there is a truth in it. Most people I know use Vagrant only as a wrapper for VirtualBox. There is little sense to use it as a wrapper for say KVM or LXC since in this case you can't transfer a VM to MacOS or Windows users. Also both KVM and LXC have a good CLI out of the box. I personally used Vagrant for many years and`vm` covers literally all use cases I had during that time.
As a rebuttal to this, I think it's fine for generating passwords, if you're seeding to time or some more random entropy pool. Because then a hacker would have to know about when you generated the password and that's just not really feasible to know. I don't think it'd reduce the search space much
Can somebody please run this * on drawings/paintings * on noise * recursively
Some people have a allergic reaction to monkey-patching. Others have difficulty seeing where IO happens. Somehow that was enough to motivate them to rewrite the entire network ecosystem.
Yeah, it's really kinda magical. 
No badness occurred. You are correct that the WSGI standard does not support async. uWSGI might have an experimental extension, but that is outside the scope of the original WSGI standard.
&gt; then the subset of asyncio that you actually have to understand is not that big. I'd say it is still way too much. I want to be able to write reasonably pure functions and operate on their results and have it "just work." `foo() + bar()` should be automatically parallelized without my having to do anything special, and a function of pure functions should be callable in exactly the same way from both sync and async contexts. The only things I want to annotate are those instances where I know I am doing something impure and need to enforce ordering, and those instances when I actually want to return and operate on future/promise/task instead of automatically awaiting its result [which is usually only in the outermost control parts of my code]. Instead to write any async function, I have to figure out my event loop, figure out how to submit tasks to the loop, figure out how to wait on the results, and figure out how to return results in both sync and async contexts, and then create two variants for every public function I write, and propagate the "async" nature of my functions throughout my code. UGGHH!! If I'm not actually doing the work to synchronize things that need to be synchronized (for instance if I offload that to a database engine), then I should just be able to call a function asynchronously and let the async context propagate down the stack.
i'm having the same problem as you right now. how did you get the spacepy packages to work. tried the suggestions above, but nothing is working for me so far.
ENHANCE
Your implementation of mixing numbers and other characters is not as secure as you probably expect. Right now numbers will be "overrepresented" in generated passwords, since there is a 50% chance of a number getting picked, despite the fact that there are less numbers than letters. What you probably instead want to do is to concatenate together the lists of possible password characters and then pick a random element from the combined list. This will also enable you to radically simplify your code.
Huh I saw and downloaded that earlier. Looks good but I haven't had the time to fully test it out.
Not valid as evidence, but still used as an intimidation or fishing tool during an investigation. So yes, this could be used in the same way as a lie detector.
Yes, this is one of the theories. We have a set of "schemas" which are essentially databases of information on general concepts. Schemas store general, generic information for things like what hair looks like. Memories are stored as a series of bullet points, and they are rebuilt from scratch using the bullet points and schemas whenever we want to recall something. I took an Intro to Psychology class once, so naturally I'm an expert on these things. 
Getting lost with David Beazley is my ideal vacation.
This is a very good idea. Thanks. I will definitely implement this :)
Yes I will definitely work on that! Thanks for the reminder :)
"In demand" for what type of job?
Common Lisp comes to mind. 
I'll add this too, right from David Beazley's mouth: https://www.youtube.com/watch?v=sPiWg5jSoZI
Where can I learn more about which software licenses allow software to be commercialized like you mention (while being built with open-source libraries)? If the software is free, but support is not, would I be in the clear as far as licensing issues re: the libraries I use?
Remindme! 24 hours
Sure, your initial comment is flamewar bait considering this is r/python. I should have just ignored it. :) Everyone is welcome to their own opinion, I fully respect yours although I disagree with you. &gt;My experience with Python was so bad that if I was interviewing for a company and found out they were a Python shop I would walk out. I would do the same at a Perl shop for sure, although there aren't too many of them left anymore. I could probably tolerate working in JavaScript part time, I wouldn't like it full time. &gt; Java people seem to be able to deal with over-engineering just fine. Not sure how much you've worked with Java but I'd say that over-engineering is one of the things Java people (those who are aware of alternatives) complain about the most.
A neat example: Children have been shown to learn by starting with a broad concept or schema, then gradually learning to distinguish variations of it . So a child may have a schema that tells them a "furry, four-legged thing" is a dog. Then one day they see a cat and shout "dog!". Their parents correct them and explain it is actually a cat. So the child creates a new schema for cat: "smaller, differently shaped dog". I took Intro to Psychology plus a few other classes that were *almost* enough for a minor, so I'm basically the foremost expert on all things psychology. 
As a security enthusiast, I will mention that: 1. I can crack your application and find out which password it's going to give next, and thusly the ones before mine that have been given. 2. I can just say that the more characters you're randomly choosing from, the more secure the program as a whole will be from reverse engineering in general, but **that's not all**. Random is a fun mathematical concept with nuances, it's great. Random doesn't mean random like "as different each time as possible". Random simply means every letter is just as likely to get picked, but this is hard to achieve for computers as they use arithmetic obviously to do anything (inevitably, there will be emergent patterns). So using python's 'rand' is sort of a black box. I'm not going to explain this part because you might already understand it at this point but here is a very valuable topic: http://stackoverflow.com/questions/2145510/random-is-barely-random-at-all Every random function in every language has *consistency* problems. You want to find out what python's is and fix it in your code to make better passwords over the entire worldwide use of it (make it into a django site!). Right now, it's useless in the context of security but if you read up and go back, it will not be and it will be much more impressive than even some of the commercial ones our moms and dads are buying. 
Ye i didn't see an installer so I wan't too sure what to do with it. I added the root folder to my path variable because of a post I saw online but that didn't work either.
If there ever was a reason to take a drill to a laptop webcam, this would be it :-) Whatever remote system you set up it'll still be a hassle. Suggest you try to get comfortable with a professional development tool that you'll be likely to use in your later endeavors. Nowadays, building and deploying a Django stack means having virtualenv, a local DB server (like Postgres), a virtual container service (like Docker), version control (like git), and a good IDE/editor with decent editing, refactoring, and debugging capabilities. You'll also need network access to look up docs and examples as well as a decent HTML/Javascript editor/debugger if you need to have a web front-end. Or a JSON visualizer and API tester if using DRF. Trying to do that all remotely will slow you down and make the whole experience annoying. If the objection to bringing your own laptop is only because of the webcam, I'd look into disabling or removing the camera. If it's something else you may want to carry an SSD drive with a bootable partition and boot your work machine to work off that drive.
Thank you, very much appreciated. Looks amazing.
Watch out with automated use of Google. They might block you for some time. No real problem, just speaking from experience.
You mention: &gt; I need to port forward, and thats not fun I created [loco](https://github.com/kootenpv/loco) a few days ago, I'll post about it soon here on reddit, but maybe it would be interesting to you as it is about port forwarding.
Thanks for your comment. You are right, there are plenty of alternative response surface models including probabilistic ones (Bayesian etc). I'm personally a bit skeptical about test functions. For example, an exact minimum along Rosenbrock valley is not very different from any other point along the valley (in terms of function value). So, if it was a real world problem, we wouldn't benefit that much from finding exact mathematical optimum, and it would require much more function evaluations. So, the method I'm proposing here is by no means the ultimate one, but rather a simple practical tool. But I agree that comparison with alternative methods on a set of test functions would be a good thing to do.
[Image](http://imgs.xkcd.com/comics/password_strength.png) [Mobile](https://m.xkcd.com/936/) **Title:** Password Strength **Title-text:** To anyone who understands information theory and security and is in an infuriating argument with someone who does not \(possibly involving mixed case\), I sincerely apologize\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/936#Explanation) **Stats:** This comic has been referenced 2704 times, representing 2.0295% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d9fndib)
Better to head over to /r/learnpython. But on Windows I would recommend you install anaconda. Basically everything should work. https://www.continuum.io/downloads#windows Edit: make sure to get python 3.5 not 2.7
http://choosealicense.com is still pretty good. Although I'm not happy they removed the BSDs as an option. An entertaining back and forth on the merits (or problems) of the GPLv3 is going on right now on slashdot: https://news.slashdot.org/story/16/10/30/2228250/wordpress-founder-accuses-wix-of-stealing-code#comments Look at any big Python company that is giving away stuff for "free". ContinumAnalytics, Jupyter, Numba, etc. All of them make money supporting big corporations. &gt; I be in the clear as far as licensing issues re: the libraries I use? No. Depending on where the code may end up you may not be.
Wrote a welcome bot for Slack - [allie](https://github.com/devupin/allie) Whenever someone joins your slack team, this bot sends them a welcome message. 
&gt; Not sure how much you've worked with Java but I'd say that over-engineering is one of the things Java people (those who are aware of alternatives) complain about the most. Yeah I had to retract that. The static typing makes it tolerable but it's still a big problem. I'd be very hesitant to take a full-time Java position.
I understand ASW takes into account the camera orientation/position change and probably requires a depth map of the render (at least asynchronous time warp prefers one), so probably not that applicable to just plain video.
How do you train it? Does that mean you just use it alot?
huh, this is actually useful
Thanks! Being able to keep running pycharm is my preferred solution
continuing to learn data science using Pandas and Numpy
Imgur is leaking to reddit for once.
The mechanism is actually exactly the same. In Python, sig handler is just setting a bool flag that there was a signal. The event loop periodically checks those flags and calls a handler if it was set up. So when you are making a syscall, say socket write, Python C socket implementation will quietly swallow EINTR and repeat the syscall. When eval loop starts to evaluate Python code again, the signal handler will be called. The situation is *exactly* the same in uvloop. In fact, I don't even use libuv signals API -- Python's signal module is good enough.
[Here you go!](http://imgur.com/a/QfVdw) The enhancer applied to random noise, cropped and recursively re-applied! If anyone got the model based on models (haha) working I'd like to know. I just get a prompt to download additional data and a link with a 404 when I try. =/
I was hoping someone would mention this! Very cool tool. 
This looks promising but you should post the entirety of the game (including assets) to GitHub, so people can easily play it. 
&gt; So when you are making a syscall, say socket write, Python C socket implementation will quietly swallow EINTR and repeat the syscall. When eval loop starts to evaluate Python code again, the signal handler will be called. I don't think this is correct. I'm pretty sure all EINTR checks in the c interpreter invoke the internal `PyOS_InterruptOccurred` check and set at least a `KeyboardInterrupt` exception and stop the read loop (or whatever else it's doing). Since this loop now moves into libuv the loop will continue to run there and not be interrupted at all.
The problem will be of course that you will still have to remember many low security passwords. I'm rolling my own password manager. I'll post about it on reddit soon :)
I am working on a twitter application where almost everything will be a plugin - including the gui, filtering and much more besides. The core app will handle the raw date from the twitter servers, and co-ordinate it through any selected plugins to get a resultant data stream (which may be tweets, but could be something else entirely). The GUI plugin currently being planned will allow the display of one or more data streams - which could be in tabs, or in side-by-side panels.
Very interesting, thanks a bunch!
And yet you reply :P
Seems like it's covering similar ground to celery. As an interested newb to both, how do they stack up? Which one should i choose over the other?
Im working on a meteorological application that uses our modeled output with bias correction approaches applied.
I guess it's cool, but something about it is bugging me. Maybe it's that it's a little cringey. I like Python, but when I go to a party or hang out with my wife and kid, I don't fly the geek flag so high. It's not that I'm embarrassed to be a nerd. It's more that something about this smells of desperation. Like you're begging for people to ask what it is so you can tell them all about it and they'll be impressed by how technical and smart you are. Geeky t-shirts with esoteric "jokes" make me feel the same way. They seem designed to make the person wearing them feel smug and superior to those who aren't in the know. Then again, maybe I'm projecting younger me onto you
What is the python version for cmd?
My guess would also be projection. Most people who partake in most things like to share their hobby/passion/idea. You don't see someone wearing a football jersey or have any given bumper sticker and think the same thing, I imagine.
Thanks! In the past I had problems with numpy while trying to run a simple script, had to download the precompiled files.
What error message does the shell give? If it's instantly closing, actually open a shell and run the program in it via the keyboard, instead of double-clicking it. I will guess your shell is running it in Python 2.
I generally consider my audience with my nerdiness and intentionally wear things that I expect will get recognition from fellow fans. I don't mind wearing a star trek shirt in public because it will usually get a smile or acknowledgement... While I chuckle at shirts like Link's Lawn Service or a Star Fox themed Air Force-esque shirt, I don't buy those because too few people would get the joke. Generic Zelda shirt or Mario is fair game and is now part of pop culture thanks in part to shows like Big Bang Theory. I also live in the very nerdy "rocket city" Huntsville, AL, so I'm more often among "my people" than nerds in normal cities...
For Archovies: guord -S pympkinpy-dev-git
I think it's fun to unabashedly indulge in my interests. 
It would be pretty cool to publish in this format: https://stixproject.github.io/
&gt;I can't bring in my personal laptop because it has a built-in camera. Drill out the camera.
The in-demand python skills are the popular ones. You can become a twisted expert, or IronPython King, but you're gonna earn half what someone with 3 years' django experience does.
Reddit bot that reverses gifs for comedy. Check out /u/gifreversingbot in a week or so Having trouble uploading large gifs to imgur though. If anyone has any experience with doing that programmatically I'd love the help
I think the problem is on Line 30 your While statement has "continuePlaying" instead of an expression. 
I just finished a little project called [GitHubLog](https://github.com/JoshuaRLi/GitHubLog), a visualization of where GitHub's userbase is over time on the globe! The web app is html/css/js, but I made several Python scripts to collect and process all the data consumed by the front end. [Here's a preview of what it looks like!](http://imgur.com/OfiRTxf)
Pandas, Pandas all the time....(maybe times to tensor flow...) 
Anybody know where that HD celebrity faces dataset would be? I want to try making a new glamour photography method: 1. Train neural net with celebrity faces 2. Downscale normie photos 3. Upscale normies using neural net 4. Profit?!
Thats what I was afraid of but I only installed 3.5.2
I will have to check tomorrow but 3.5.2 i imagine.
thank u i appreciate it!
You should be using r/learnpython (read the sidebar) but I'll humor you. 1: &gt;&gt; is not the appropriate redirection for /dev/null (even though it may work) 2: use the stdout keyword arg, not a bash redirect 3: use a for loop to iterate over the list
use numpy
this is interesting - it appears all the scipy/numpy pages are down
Some OS info could help.
Technical question- how did you get the two circles to float that way?
Maybe this will help? http://ba6.us/?q=cx_Oracle_easy_windows_install
Isn't it obvious that base64 encoding was meant to increase the length of the resulting string? Using sha512 alone isn't secure cause if I guess your password I'll be able to hash it easily, base64 encoding isn't meant to encrypt the hash, it's meant to produce a 400+ characters string, then the attacker will also have to guess the borders of the slice, the multiplication key, the seed, and the symbols you used. I really thought that was glaringly obvious.
But that's easier than memorizing a 30+ characters password.
Yeah I know, but I much prefer a better interface that will explain what the tool does and how it does that.
I appreciate this.
Are you installing libraries through pycharm to a local virtualenv? One possible error is using different version of libraries. Also please paste (to a pastebin and link) the exception and the source code.
You'll get a lot more help at /r/learnpython. 
Don't worry, you're not alone. Most of these are the poseur types. I've never seen the actually brilliant types so desperate.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Botoland. I'm using it quite a bit for some S3 work.
My open source library has lots of examples, but the PyPi package doesn't include any of them. If it did, they'd be buried inside site-packages, which is kinda dumb. Then just link to the examples on your github or do it one by one. It's pretty standard to do it that way. I'm even lazier, so I just say download/clone the actual github repository if you want everything.
If they know enough about you to know how you generate your passwords, and the seed word used, you're finished anyway because they've obviously got a camera on you. Your script can be easily done in bash: $ echo 2sexy2beh4cked | sha256sum | base64 | head -c 32; echo NDM4MjIzYTJkMzA1ZWYxYjA5MGJlNDRj I didn't have sha512 installed. edit: Now I do $ echo 2sexy2beh4cked | sha512sum | base64 | head -c 32; echo ZGUzMjZiMGVhMTE0YjFiNzc0YTc3MTYx edit: Want the middle N characters? $ echo 1234567890 | head -c 8 | rev | head -c 6 | rev 345678 
&gt; share data between different applications in a bit secure manner pickle is not secure. not even a bit. this whole tutorial is useless because it misses a crucial part of pickle, which is at the top of the official docs: &gt; The pickle module is not secure against erroneous or maliciously constructed data. Never unpickle data received from an untrusted or unauthenticated source. If you give a tutorial on how to serialize Python objects and you mention pickle, but don't mention that warning, you shouldn't be writing tutorials at all.
Some context: Morepath applications can be composed of smaller sub applications. Views are added to models dynamically. This makes Morepath powerful but it becomes harder to get an overview of what paths are exactly published to the web by your Morepath applications. To help with that I've created a command-line tool that can extract this information from Morepath's configuration system and dump it into a csv file which you can then view with your favorite spreadsheet program. Quite a bit of information is in there, including what model class is published, what permission is used to guard access, what request method was used and the source file and line number where this was declared. Without a configuration system to query this would be a lot harder to expose, so yay Morepath's configuration system! 
 from clairvoyant import Backtest from pandas import read_csv # Testing performance on a single stock variables = ["SSO", "SSC"] # Financial indicators of choice trainStart = '2013-03-01' # Start of training period trainEnd = '2015-07-15' # End of training period testStart = '2015-07-16' # Start of testing period testEnd = '2016-07-16' # End of training period buyThreshold = 0.65 # Confidence threshold for predicting buy (default = 0.65) sellThreshold = 0.65 # Confidence threshold for predicting sell (default = 0.65) C = 1 # Penalty parameter (default = 1) gamma = 10 # Kernel coefficient (default = 10) continuedTraining = False # Continue training during testing period? (default = false) backtest = Backtest(variables, trainStart, trainEnd, testStart, testEnd) data = read_csv(r"H:/Python/ClairVoyantTest/sbux.csv") # Read in data data = data.round(3) # Round all values backtest.stocks.append("SBUX") # Inform the model which stock is being tested for i in range(0,10): # Run the model 10-15 times backtest.runModel(data) backtest.displayConditions() backtest.displayStats() I have run the above code: The issue coming was ********* File "&lt;ipython-input-1-9e06f724c5c4&gt;", line 1, in &lt;module&gt; runfile('H:/Python/StockPredictionUsingClairVoyant.py', wdir='H:/Python') File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 685, in runfile execfile(filename, namespace) File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 71, in execfile exec(compile(scripttext, filename, 'exec'), glob, loc) File "H:/Python/StockPredictionUsingClairVoyant.py", line 30, in &lt;module&gt; backtest.runModel(data) File "C:\Anaconda2\lib\site-packages\clairvoyant\Backtest.py", line 72, in runModel data['Date'] = to_datetime(data['Date']) File "C:\Anaconda2\lib\site-packages\pandas\core\frame.py", line 1914, in __getitem__ return self._getitem_column(key) File "C:\Anaconda2\lib\site-packages\pandas\core\frame.py", line 1921, in _getitem_column return self._get_item_cache(key) File "C:\Anaconda2\lib\site-packages\pandas\core\generic.py", line 1090, in _get_item_cache values = self._data.get(item) File "C:\Anaconda2\lib\site-packages\pandas\core\internals.py", line 3102, in get loc = self.items.get_loc(item) File "C:\Anaconda2\lib\site-packages\pandas\core\index.py", line 1692, in get_loc return self._engine.get_loc(_values_from_object(key)) File "pandas\index.pyx", line 137, in pandas.index.IndexEngine.get_loc (pandas\index.c:3979) File "pandas\index.pyx", line 157, in pandas.index.IndexEngine.get_loc (pandas\index.c:3843) File "pandas\hashtable.pyx", line 668, in pandas.hashtable.PyObjectHashTable.get_item (pandas\hashtable.c:12265) File "pandas\hashtable.pyx", line 676, in pandas.hashtable.PyObjectHashTable.get_item (pandas\hashtable.c:12216) KeyError: 'Date' runfile('H:/Python/StockPredictionUsingClairVoyant.py', wdir='H:/Python') Traceback (most recent call last): File "&lt;ipython-input-2-9e06f724c5c4&gt;", line 1, in &lt;module&gt; runfile('H:/Python/StockPredictionUsingClairVoyant.py', wdir='H:/Python') File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 685, in runfile execfile(filename, namespace) File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 71, in execfile exec(compile(scripttext, filename, 'exec'), glob, loc) File "H:/Python/StockPredictionUsingClairVoyant.py", line 27, in &lt;module&gt; data = data.round(3) # Round all values File "C:\Anaconda2\lib\site-packages\pandas\core\frame.py", line 4335, in round new_cols = [np.round(self[col], decimals) for col in self] File "C:\Anaconda2\lib\site-packages\numpy\core\fromnumeric.py", line 2782, in round_ return round(decimals, out) File "C:\Anaconda2\lib\site-packages\pandas\core\series.py", line 1234, in round result = _values_from_object(self).round(decimals, out=out) TypeError: can't multiply sequence by non-int of type 'float' ***** What would be the cause of the error. 
I love Python. I mean, I really looooove Python (yes, NEEEEEERD) and I like to take something subtle with me that shows I do. I study at a university which teaches Java and only Java, so when I see someone else who loves Python I give him a wink, we are a secret community! But if nobody would wear these subtle hints we would never know...
Miguel Grinberg's https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world has to be one of the best I think.
Did you want a /s in there?
`numpy.load('thefilename.npz')` will do the trick. Docs are down but you can `help(numpy.load)`.
Numpy and scipy now have wheels on PyPi so installing them is not an issue.
http://isup.me/www.docs.scipy.org
I would be like, "Wait what? I need to see any and all evidence for this immediately. This may imply a very subtle bug that could be very dangerous in the future. We must investigate this as soon as possible."
The seed is a number not a word. If you start with a word like Johnny, the script will hash it, encode the hash in base64, then encode the resulting base64 string 2 more times to produce a 400+ character string. The script then asks you to chose the borders of a (preferably 20 character) string. The resulting character will include upper and lower case letters, and numbers. Then the script gives you the choice to insert 2 special characters in semi random locations within the resulting string (the seed is a random seed which when static results in Python's random module choosing the same numbers every time). Finally the result is printed and you have the choice to copy it to clipboard. Can't do that in a single line of code.
Actually, I just used toothpicks. You can kind of see one sticking into the bottom circle from below. 
Do you do any HovmÃ¶ller diagrams?
Hi, thanks for your answer. I will definitely work on the points you mentioned. 
rewriting a tool to backup docker-compose peojects.
Can't you run PyCharm off a USB stick? Other options are vim+jedi, visual studio code, sublime with the right plugins...
I wrote a sports betting bot using the Pinnacle API, and my first [tutorial](http://cyber-omelette.blogspot.ca/2016/10/the-programmable-web-vice-city.html) to go along with it. I've decided to start documenting all my projects, and trying to boil them down into straightforward reproduce-able steps.
Your Hipster nerd flag has been waved sir.
Heh cool. My grandfather is the inventor of it. Always fun to hear if people use it :P
Just because YOU can't generate that in a single line doesn't mean it's impossible. It could not be done in Python, but Python is not the world's only programming language. I just did a quick version in bash because it took 3 seconds to write. Realistically, is it any less secure for mid-length passwords(1)? Just do 24 chars instead of 20 to compensate for the lack of special characters. Of course those would matter in 8 character passwords, but it's really not that hard to add the commands to generate those. (1) I would say neither was truly secure. I'd use a true random string with NO human-derived input, and store it in a password manager.
Looks like it's down, you could try looking at the source: https://github.com/scipy/scipy/search?l=reStructuredText&amp;q=trapz&amp;utf8=%E2%9C%93
yup at https://techarena51.com/index.php/category/flask-framework-tutorials-and-examples/page/2/ or you can even check my project at https://github.com/Leo-G/Flask-Scaffold
1- stop argument for the sake of argument, this is a Python community, and 2- Python is the only programming language I know. If you think special characters aren't necessary, the script gives you the choice to skip them. Random password generators are nothing new and no one is telling you against using them, the reason why I made this tool is because the phone I was storing my passwords on got stolen, so I wanted something that's reproducible yet unpredictable.
I'm not sure that makes any sense, but if it makes you feel better to call me a bad word, I can live with that.
For me rice was just a shorter form of spaghetti until I was seven years old or so. I might have been special though.
The reason you are getting a hard time is that rather than post this in the /r/learnpython where people will politely tell you what is good and bad about it, you are trying to show it to professional developers in /r/python, where it is borderline spam, and then not understanding the responses you get. Your project is not bad, but it is in the wrong place filling up the wrong mailboxes. It's not that I don't like apprentice pieces but you have like five of fricking things in this sub and the code quality is not improving.
It's probably your data file. Make sure it looks like the one in the readme. Send me the first five lines, as I said in github issues.
Are you deploying on google app engine by any chance?
naaa singham
This is quite perfect, i think i found what im looking for, thank you alex
Single words is a dictionary. Sentences is super complex and really hard. Even google who is a clear world leader is so-so between indoeuropean languages and bad outside that family. That's why they're charging for it. Which makes sense: it was expensive to build. Probably not a good idea to rely on this to learn a language though. 
I don't see a problem with mutable. In in C/C++/Java object/array/struct/strings argument passed by reference. I actually use it a lot. to_be_json_message = {....} add_user_info(to_be_json_message, user) add_account_info(to_be_json_message, account) .... send(to_be_json_message) I don't see a reason, why I want to make copy each time the object updated. in the example you show `return a_list` is wrong and maybe the name `foo` def give_me_five(a_list): a_list.append(5) what is wrong and confusing - block scope is broken, if your example `a_list` leaked somehow to global. After years of using Python, I was surprised to find 1) if __name__ == "__main__": a = "val" `a` is global. 2) I can do if True: x = 0 else: x = 1 use(x) it looks so wrong to me - I prefer to add `x=None` on top level and for main I use now `def main()` and use it as entry point. in second your example `b` references `a`, what is wrong? I imagine, when you write language like Python, you think about tradeoff: keep reference syntax clean or make copy constructor easy and introduce `ref` sign or `new`. Python in that case did a good choice. Copy of object doesn't guarantee deep copy - look discussions about `clone` implementation in Javascript. Python has `b = list(a)` [copy constructor easy], for hard cases there is `import copy` lib 
&gt; a /s what does it mean?
you can, the topic of the post "Common Python pitfalls" 
/s denotes sarcasm, since there is no verbal tone in text sometimes it's difficult to pick up. 
I'd say your best bet is to optimize by way of building a specific application with web.py, profiling it, and then optimizing based on what the profiling tells you. Generic optimizations like running PyPy are useful, but they're generic -- they don't speed up what specific bottlenecks might exist in the application you've built. http://ubiquity.acm.org/article.cfm?id=1513451
It's been a while I looked at the code! You're right, there's a difference. To answer your questions: libuv will indeed repeat the syscall until it succeeds. But, libuv is all about non-blocking calls, so the syscall duration is extremely small. Whenever a signal occurs, a byte gets written into a pipe, which uvloop listens on. This means that signals always reliably wakeup the loop when it reaches the 'select()' phase. Overall the signals are processed slightly differently than in Python, but I don't see that as a big deal, since all syscalls are either non-blocking or fast.
You mean "write classes" or "use objects". 
Miguel also has lots of videos available! Long-form tutorials on YouTube: https://www.youtube.com/results?search_query=miguel+grinberg+flask - https://www.youtube.com/watch?v=FGrIyBDQLPg - https://www.youtube.com/watch?v=px_vg9Far1Y - https://www.youtube.com/watch?v=fUpBiGEIvfk Check out his comment history here on Reddit as well (/u/miguelgrinberg), he's a tremendously helpful guy.
I didn't know that. Thanks a lot! It's fixed now.
That's just it, I don't really spend much time trying to pimp my codes, Python is known for the clean syntaxes it forces you to stick to. I wonder how that dude who made a big production of telling me that Python isn't the only programming language would like to read perl source code (which is literally gibberish). The reason why I shared the code in the first place is because I'm interested in knowing what ppl think of the algorithm itself, the idea of taking a 5 letter password and turning it to a reproducible string of characters. I wanted to know if they think my approach provides acceptable security in that the result is practically unpredictable. No one has told me that. That is why I'm slightly annoyed, I know this isn't were ppl look for Python courses, but that's not what I want anyway.
http://bugs.python.org/
Have you looked at Flask-Admin? It may save you a lot of time: http://examples.flask-admin.org/
&gt; I've seen this code on repos but I don't know the reason why people are doing this. I'm not sure what's there to not understand. Essentially the constructor uses the event loop that is (in 10 times out of 10) a thread local, and it gives option to override that. &gt; Can I just run loop.run_until_complete(a.test()) or do I still need to do loop or asyncio.get_event_loop() in __init__? Should I leave it as is etc. I have many basic questions. In most cases, until you will try to do more advanced stuff with threading, You will only have a single event loop, which you can obtain by issuing asyncio.get_event_loop(). I wrote some asyncio code, and never really needed to even keep track of the loop. That argument is meant for advanced use cases.
&gt; I still find Python more visually appealing than Go, but Go's concurrency model is elegant and easy to understand. I'm going to keep using Python for years and years but I've already started moving over to Go when I can. Go concurrency model is more limiting. AsyncIO is lower level and intended to be more universal, you actually can use AsyncIO to implement Go's concurrency model.