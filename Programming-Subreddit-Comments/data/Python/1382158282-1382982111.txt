You should be prepared for some sort of magic when dealing with dynamic language frameworks. :)
I don't mean to be negative but this is why I love Python as a play language but won't use it at work. Every other production ready language has a done-and-dusted solution to deployment but there's no single simple solution in Python. Kind of disappointing considering Python prides itself on having a single and simple way to do most things.
I recommend using eggs. There's a lot of egg-hate about but it is invariably from people who don't have to deploy software on a regular basis. As a deployment format, egg are wonderful (at least there's no better option right now). 'wheels' might be the future but they're not so focused on being importable. In contrast to other suggestions, eggs support deployment of binary packages. This is crucial. Who wants to require a full SDK on every deployment target just so you can pip-install something which needs building. Build all your dependencies as eggs and stick them all in a folder in your bundle. When you run your app, just loop over all the eggs adding them to the sys.path. Usually a zipped egg will work fine but occasionally they need to be unzipped in case the library in question has done something silly with package data (like not use pgk-resources). 
Nice! I've never used execfile before... going to look that one up right now! 
At work we use git for this. Start a git repo for your whole project dir / virtualenv and clone it anywhere you need to use it.
Whoosh will do well with any framework that you're using. It's remarkably easy to use for basic search.
You need to learn and appreciate those parts of Python, but you should also know that most Python programs by programmers past the new-to-python stage *don't* use eval and exec all that much. Maybe you should look into the [multiprocessing](http://docs.python.org/2/library/multiprocessing.html) module, or how [ipython does parallel processing](http://ipython.org/ipython-doc/dev/parallel/). One of the ways that new users want to apply exec/eval is to create new names for data based on the data. Those questions are usually answered by people showing how the same effect can be more pythonically realised by storing the data in a dict with the dict keys being generated from the data. You seem like a learn by doing kinda guy, so have fun - I guess you'll learn along the way :-) 
I agree. I found PTVS 2012 unusable on my laptop. The indexing just brought my PC to its knees.
I'm considering a similar problem ATM. I've more-or-less decided to try Apache Thrift (http://thrift.apache.org/). ZeroMQ handles the low level networking, but you'd still need to chose a message / serialisation format (e.g. google protocol buffers (GPB)). Thrift handles both of these and was intended as a next-gen protocol buffers. Thrift supports C# whereas GPB doesn't. I found this presentation a useful intro: http://www.slideshare.net/IgorAnishchenko/pb-vs-thrift-vs-avro 
OP I just read your last post and I've got one thing to add. Knowing a language and knowing how to program are to different things. As others have suggested start with a project and while working on said project try to learn some useful paradigms like model-view-controller etc. everyone had problems like this in the beginning. It took me 4 month to understand oop when I started programming. Don't give up
generally these challenges are common in all of software development.
cool! I want to learn how to make music apps so I appreciate this.
Perhaps I'm missing something, but you really don't need build tools at all to do what you need to do. Bundling all of the dependencies in a subfolder of your project, and then adding that subfolder to sys.path at runtime will do the trick. Unless you want this to be deployed as a library, then you can use pythonpath. Other than that, keep it as simple as possible. Having a build process seems like it would just add complexity. That's the trick to software development - keep it simple! . ðŸ˜‰ sorry if this is a bit terse, I'm on my phone, but I wanted to chime in and help ðŸ˜„ EDIT: this is assuming that you don't have to build binaries on the box. If you do, I might recommend fabric or cuisine. But I would still keep it simple and just have a simple script that I would write to run the build. I've used some build tools before and then realized it would have been much more maintainable if I just wrote a script. Hope this helps! 
I don't get the downvote, because I agree PyInstaller et al are not good enough. 
I'm quite literally stunned (and jealous!) On a box with less than 8GB of ram it actually runs? O_O and runs well? Wow, that has so not ever been my experience with visual studio.
OP: I'm sure you are getting some great advice here. Here's mine: a) Don't give up! b) Solve challenge problems at ProjectEuler.net. c) Have fun too.
I have been unable to reproduce the error you are having... Results of running 2-passwordCrack.py &gt;[*] Cracking Password For: victim &gt;[+] Found Password: egg &gt; &gt;[*] Cracking Password For: victim2 &gt;[+] Found Password: egg &gt; &gt;[*] Cracking Password For: victim3 &gt;[+] Found Password: egg &gt; &gt;[*] Cracking Password For: victim4 &gt;[+] Found Password: egg &gt; &gt;[*] Cracking Password For: victim5 &gt;[+] Found Password: egg &gt; &gt;[*] Cracking Password For: victim6 &gt;[+] Found Password: egg &gt; &gt;[*] Cracking Password For: root &gt;[-] Password Not Found. &gt; &gt;[Finished in 0.0s] contents of passwords.txt &gt;victim: HX9LLTdc/jiDE: 503:100:Iama Victim:/home/victim:/bin/sh &gt; &gt;victim2: HX9LLTdc/jiDE: 504:100:Iama Victim:/home/victim:/bin/sh &gt; &gt;victim3: HX9LLTdc/jiDE: 505:100:Iama Victim:/home/victim:/bin/sh &gt; &gt;victim4: HX9LLTdc/jiDE: 506:100:Iama Victim:/home/victim:/bin/sh &gt; &gt;victim5: HX9LLTdc/jiDE: 507:100:Iama Victim:/home/victim:/bin/sh &gt; &gt;victim6: HX9LLTdc/jiDE: 508:100:Iama Victim:/home/victim:/bin/sh &gt; &gt;root: DFNFxgW7C05fo: 509:100: Markus Hess:/root:/bin/bash 
It has nothing to do with positions of users and everything to do with the fact that root's password is not in the dictionary. [*] Cracking Password For: root Word: apple / DFWnBavAebFoM Word: orange / DFLxqyp4Kja72 Word: egg / DFV1s9aC7EHaw Word: lemon / DFbvAVNj8uv2A Word: grapes / DFslWvHbYHibg Word: secret / DF2DT.ZFW5s96 Word: strawberry / DFfSzRsQPaTcc Word: password / DFkS2oDEJxgmY [-] Password Not Found. I modified testPass to look like this: def testPass(cryptPass): salt = cryptPass[0:2] dictFile = open('dictionary.txt', 'r') for word in dictFile.readlines(): word = word.strip('\n') cryptWord = crypt.crypt(word, salt) print 'Word: ' + word + ' / ' + cryptWord if cryptWord == cryptPass: print '[+] Found Password: ' + word + '\n' return print '[-] Password Not Found.\n' return If you look in passwords.txt, notice that root's hash is not one of those lines. Apparently, the author never intended root's password to be cracked.
If I wanted to optimize algorithm I would not go towards genetic algorithm but would reduce the complexity of the algorithm. An example here http://esr.ibiblio.org/?p=4861 The other way is to use idiomatic python as it is better supported by the language for example http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html
Can you provide a concrete example of these?
Thank you all, once again. And Please don't stop pouring your advices here or at my blog. Have a great weekend!
&gt; This part is fixed in python3 by making "unicode" as the default encoding Ouch. 'unicode' is not an encoding. Maybe you meant 'utf-8'?
Hey there, I just got started using alembic. I'm using Flask but the principles should be the same with anything else. You should use the env.py file in your alembic directory to do what you need there. In fact, the env.py file is what drives Alembic. You can tell Alembic to use a different config file by calling it using the -c argument option like *$ alembic -c development.ini* . It would still look for the [alembic] section but that can also be overridden by using the -n argument option like *$ alembic -c development.ini -n your_database_section*. What I did with Flask was simply to change the env.py and overwrite the sqlalchemy.url main config option with the config value I have in my Flask config file. I did something like this in my env.py file: from __future__ import with_statement from alembic import context from sqlalchemy import engine_from_config, pool from logging.config import fileConfig # Include current path in sys.path so that I can find myapp module import os, sys sys.path.append(os.getcwd()) from myapp.config import get_config # this is the Alembic Config object, which provides # access to the values within the .ini file in use. config = context.config app_config = get_config(config.get_main_option('app_config')) config.set_main_option('sqlalchemy.url', app_config['SQLALCHEMY_DATABASE_URI']) # Interpret the config file for Python logging. # This line sets up loggers basically. fileConfig(config.config_file_name) # add your model's MetaData object here # for 'autogenerate' support # from myapp import mymodel # target_metadata = mymodel.Base.metadata target_metadata = None # [... rest of the default env.py file]
you can reference one in the other... [section] use=config:%(here)s/other.ini#other_section 
&gt; b) Solve challenge problems at ProjectEuler.net. If he wants to get good at math, sure. But he won't learn how to program there.
Yes, that's an option. Serialization format is really a matter of personal choice from what I understand. Thrift is very concise and efficient; I use json because I want my messages human readable. There also tagged netstrings and other choices. What about libraries like https://code.google.com/p/protobuf-net/, they seem to implement GPB in .NET?
&gt; s.encode("ascii"): converts str object to unicode &gt; u.decode("ascii"): converts unicode to str. no ;) ... I guess the first one would try to decode s with default encoding (in python 2.x) and than try to encode to ascii. The second one make no sense... Maybe he meant u.encode("ascii"). It helps to remember that unicode is not an "encoding". Go there: [How to stop the pain](http://pyvideo.org/video/948/pragmatic-unicode-or-how-do-i-stop-the-pain)
I had the same error just a few minutes ago.
I think those error messages are just tests the installer executes, and not indicative of any actual error. Two possibilities (I ran into a couple of issues when I was installing as well):- - you had a corrupted download as well. Verify the executable you have downloaded is 194 MB (203,832,272 bytes) - You had some sort of pending uninstall/reboot action queued. The PTVS installer doesn't seem to like that situation. Try rebooting, and run the installation program in a freshly booted windows session. 
Just replying to you here so it gets picked up by your account, try my suggestions in the reply I made to honest-teorema's post.
yeah, this is mostly downvoted because its childish, but mostly its wrong :( i would write this the same way as: love_python = True while love_python: print("Thank you Python Community!") `lovePython` is not how it should be written. [pep8](http://www.python.org/dev/peps/pep-0008/) says that it should NOT be camelCase or PascalCase, but snake_case or lowercasestyle. Also notice that you initialized `lovePython` but never used it. I took a high school programming course and learned about the basic python syntax. I always felt uneasy about it; i knew the syntax, but not *programming*. it wasnt until i read a book on Java that i finally understood, it just clicked. I suggest you read a book :p
Thanks it was helpful.
http://www.joelonsoftware.com/articles/Unicode.html
That, unfortunately, will remain forever hidden behind the authentication page of the members-only [mailing list](https://mail.python.org/mailman/listinfo/psf-members) where the robed priests (and shiny metal bots) of Python perform their ancient rites. Only tantalizing glimpses such as this gem will occasionally be seen by the faithful to hint at the wonders of that secret shrine.
&gt; As python's default encoding is "ascii" A byte string, which is a ``bytes`` instance in Py3 or a ``str`` instance in Py2, has no encoding. It isn't encoded at all, and no one should pretend that it's anything other than a sequence of bytes. It could just as easily contain something like a bitmap image as it could a string of human-readable data. Internally, Python (that is, the CPython implementation) has traditionally used the [UCS-2](http://en.wikipedia.org/wiki/UTF-16) or [UCS-4](http://en.wikipedia.org/wiki/UTF-32) character encodings to represent unicode strings. This has changed as of Python 3.3 thanks to [PEP-393](http://www.python.org/dev/peps/pep-0393/), but I won't get into that now. This simply doesn't matter at all. You never actually have direct access to Python's internal representation of the unicode string. (Well, not unless you're doing something of a decidedly C-ish nature, be it ``ctypes``, Cython, or maybe use of the C API... but let's just not get into that.) ... Of course, you *can* call ``encode()`` on a unicode string with no encoding specified. This defaults to ``"ascii"`` on Py2 and ``"utf-8"`` on Py3.... except no it doesn't. In Py2, the default is actually the system's default encoding. You can determine this by calling ``sys.getdefaultencoding()``. You can even change it with ``sys.setdefaultencoding(something)``... kind of. The default encoding is set by the ``site`` module when it's automatically imported as part of the interpreter's startup sequence. The ``site`` modules also deletes the reference to that function, making it impossible to call it within your own code to avoid having the default encoding from changing while your scripts are executing. Unless you start the interpreter with the ``-S`` flag, preventing the ``site`` module from being imported. The ``site`` module also tries importing ``sitecustomize`` and ``usercustomize`` modules. I'm not sure at which point the default encoding is set and the function is deleted, but I'm assuming that at least the ``sitecustomize`` module could potentially set the encoding to something else. Because of all this, it just isn't predictable to call ``some_unicode_string.encode()`` in Python. Or rather, in Py2. Beyond Py2 just being weird, the default changes between major versions. Thus, if you're trying to write portable code, make sure to specify an encoding. --- **TL;DR:** There is no reliable default encoding. Spend two seconds to tell Python exactly what you want. ... Now, onto the subject of Python's ASCII codec's limitations. It's also known as US-ASCII or ISO-646. You could even reference it in python as ``"646"`` if you wanted. On the unicode side of things, the codec represents the [Basic Latin](http://en.wikipedia.org/wiki/Basic_Latin_(Unicode_block\)) unicode block, in all its 128 code point (``U+0000..U+007F``) glory. Unfortunately, that's *all* that it represents. I presume that it was made the default (in some cases) on Py2 merely to prevent people from making bad assumptions and getting into trouble. If, for some reason, you want to convert bytes to unicode and back such that ``b"\xFF"`` equals ``u"\u00FF"``, you need something else. You need unicode's [Latin-1 Supplement](http://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block\)) code page. It contains an additional 128 code points (``U+0080..U+00FF`` specifically). When you translate this into Python, you get the ``"latin_1"`` codec, also known as ``"iso-8859-1"`` or ``"cp819"``. Conveniently, the codec will translate the full range from ``U+0000`` to ``U+00FF`` for you. If you're wondering why you'd ever want to do that, my answer is ``bytes.format()``. Or, rather, the lack of it in Python 3. Saving data into bytes isn't as easy as I'd like it to be, which can be a pain for networking applications. Especially networking applications. --- Sorry, this has stretched on a bit longer than I expected it to. I've been working on updating my contributions to a networking library ([this one](http://pantspowered.org/)) to run across both Py2 and Py3 lately, and it has left me a bit opinionated on the subject. [Edited for clarity.]
Wow, I've never read that before... that editorial... That's something.
Thanks for your reply. Greatly appreciated. Here are few questions I have: 1. Why does python try to decode using "ascii" encoding in my system? I think, this is related to my second question. 2. Why is python not able to get the encoding of my system? http://pb.abhijeetr.com/QKFa 3. I read more about ascii and had a doubt. Is it that in the ascii era (1962), we didn't have fonts? For two fonts, I had to use two different spaces in the "table"? Eagerly waiting for the response. Thanks again. 
First off, let me say that I'm not an *expert* with the CPython implementation, and that I'm not overly familiar with its source code. That said... The CPython implementation doesn't actually attempt to detect your platform's default encoding, to my knowledge. In the source code, we find: static char unicode_default_encoding[100 + 1] = "ascii"; So, the raw executable without any of its libraries is hard-coded to use the ``ascii`` codec. That's not the end of it, of course. The ``site`` module could easily detect your locale and use it, right? Well... it kind of doesn't. It's really weird, actually, but this is the relevant code as it looks in my local Py2 installation: def setencoding(): """Set the string encoding used by the Unicode implementation. The default is 'ascii', but if you're willing to experiment, you can change this.""" encoding = "ascii" # Default value set by _PyUnicode_Init() if 0: # Enable to support locale aware default string encodings. import locale loc = locale.getdefaultlocale() if loc[1]: encoding = loc[1] if 0: # Enable to switch off string to Unicode coercion and implicit # Unicode to string conversion. encoding = "undefined" if encoding != "ascii": # On Non-Unicode builds this will raise an AttributeError... sys.setdefaultencoding(encoding) # Needs Python Unicode build ! Here, we see the same thing. It just blindly uses ``ascii``. Strangely enough, there *is* code to read the encoding from your locale. But... it never *ever* gets used because it's tucked away underneath that ``if 0:``. I can't tell you why it does that, just that it does. --- As for your third question, I have to say that fonts don't come into this at all. Fonts are all about rendering the text into something that the user can perceive. It's just at a higher level than character encoding. Unfortunately, I don't know a lot about the history of ASCII and character encodings, so I won't try going into that now. I couldn't do much more than regurgitate the wikipedia articles for you, and that just wastes everyone's time. I hope this answers your questions well enough, despite that. If you have any more questions, I'd be happy to answer them for you. Expect a bit of a delay, however, as I'm about to go to sleep for the evening.
ok will try it out
Thanks. I'll ask in a mailing list or IRC to get answer as to why we have it under `if 0:`. For the other part, I was confused b/w fonts and ASCII after reading [this](http://en.wikipedia.org/wiki/Code_point). &gt; &gt; This is because one may wish to make these distinctions: &gt; &gt; * encode a particular code space in different ways, or &gt; * display a character via different glyphs. &gt; Unicode uses code-point and wiki says that usage of that was one way of eliminating the relationship b/w glyphs and the way we represent them. I would be glad to see what's your say on this. 
I'm not surprised, ffmpeg's switches are really loosely documented, it's a black hole of experimentation and Google searches to tame that beast.
I'm surprised by this, I also do scientific programming in python and regularly use 100% of all my cores/run out of memory, yet I've never had an OS crash. What version of IPython/Ubuntu are you using?
1.Nuitka is working on annotation less type inference. And i believe RPython also does this, But reading criticism[a] about it might cast doubt on the value of the idea, but haven't tried it personally. 2.Mypy is more practical - it's working on an optional type inference.If you annotate the function signature , it will type check it(and code connected to it). If you don't it will be dynamic type. That way you can mix code as you like. The first step will be a lint like tool tool. The next step will be a compiler and VM to speed up the type checked code. [a]https://mail.python.org/pipermail/pypy-dev/2013-June/011503.html 
Note, Thrift supports JSON messages. It's multi-protocol so you can have binary, JSON or xml.
I'm failing terribly at the Markdown formatting for my post. Sorry if it's difficult to read as is.
You might like http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2011-how-to-sell-python-4900958
The standard library comes with a very simple interpreter creator: http://docs.python.org/2/library/cmd.html
I wouldn't go so far as to say you won't learn how to program there. It's certainly almost entirely math, but you'll get a fair amount of programming experience there, especially in relation to algorithmic complexity. Guess there's a lot of people out there with a serious grudge against Project Euler.
You can find these sorts of things in a number of packages if you search hard enough. Depends on why you need this, but here is my own which focuses on debugging applications. https://github.com/GrahamDumpleton/wsgi-shell I did a PyCon talk about this sort of thing. http://lanyrd.com/2012/pycon-au/swkdq/
why not just take examples from the model you wrote and compare it to the java implementation? i'm sure you can find many things (like, look at this short bit of code which does X, now see the same code in Java, it's 4 times bigger and...) to cover I wouldn't try to give a general "why python might be a better choice for modeling". This could turn out nasty especially when the Java devs get involved that don't want to do Python
Ah, the timbot. I used to read the python newsgroups back about this time: Tim Peters was so entertaining. Smart, funny, humble and had a great way of explaining complicated things simply. He's probably best remembered for "import this", I also remember one of his other quotes (probably not verbatim as I'm just winging it from memory): "we read Knuth so you don't have to". Does anyone know where he is and what he's doing now?
I bet there will be too many to even pick from. Here's some I have heard of: * Maersk Oil ($59 billion 2011 revenue) is advertising for a Senior Quantitative Interpretation Geophysicist, and includes, under "Who we are looking for", this bullet point: "General experience with Linux systems and programming â€“ **ideally Python.**" (emphasis mine). I also know one of the oil reservoir people, and most of his [copyrighted custom software for oil reservoir work] (http://xoomer.virgilio.it/infinity77/main/copyright.html) is written in Python. * [United Space Alliance (USA), NASA's main shuttle support contractor] (http://www.python.org/about/success/usa/) * One of the wxPython list members who is also a developer works for the National Oceanic and Atmospheric Administration (NOAA), and I believe uses Python in his work there. * Lastly, just check out this list: http://www.python.org/about/success/#scientific 
Python.org actually has a list of places in which Python is used, successfully: http://www.python.org/about/success/
I will also confirm this: I work for a software company that makes data visualization software for use by aerospace engineers and the like. We also have a product for the oil/gas industry. Our customers like the following languages: * FORTRAN * Python (with NumPy/SciPy) Java doesn't even rate, really.
I looked at the Cmd library earlier and it looks like a good start for sure. It seemed a little weird to implement...and the output is a bit ugly by default, imo.
Use ipython and pandas and do lots of graphs etc, on the fly ..
Nice! Just checked out your Github repo, I'll have to watch the talk too
I think this is a great idea for a module! I'd focus more on the menu/commands more than command line arguments. I wrote a basic menu driven interface for the Gate One demo at http://liftoffsoftware.com/ where certain sub menus had their own CLIs (e.g. domain checker, ping). Having a module to make it sure would have been handy.
What convinced your boss? That you could produce in a week what your predecessor produced in a month. Why would that same logic not convince top management?
IPython notebook.
ipython notebook to be exact, I recently made the switch to do analytical work as opposed to an IDE.
I don't think one language is generally "better" than another in a vacuum. Your use case, developer resources, company culture / infrastructure, etc. all come to bear when you're deciding which language is the best fit for your company. I think a successful pitch to management types would be very specific to the company you're working with, and would look something like: 1. We're trying to do X. 2. Python is good at X. 3. Our developers can use Python, and it works well with our existing infrastructure. 4. We should use Python. Trying to prove that Python is just *generally* better than Java is a herculean task; expert software developers can't even agree on this, how could non-experts possibly understand the nuances involved?
NO! Do not show management or execs code. Show them results.
Yeah that's um, not even remotely correct.
the most attractive argument for Python from a business perspective is that it facilitates rapid development cycles. If you can develop your model in 1/3rd the time the company can, with the same man-hours of effort test out 3 times as many models. 
Apart from the obvious utility if the scipy stack, are you doing any physical modelling? Differential geometry, PDEs, fluid flow, stuff like that? If so, allow me to plug the fantastic open-source project that is http://www.fenicsproject.org - an incredibly easy to use Finite Element suite, with the numerical algorithms written in fast C++, and everything designed to be accessible from Python via SWIG. Other than that, maybe just point out to then that Python is fast becoming the Lingua Franca of applied mathematics? 
Personally, you need to learn the idea of using the right tool for the job. If you are using java and want to use python, show why python provides a better environment for your problem. Are there better 3rd party libraries for soap in python versus java (if this is part of your implementation for example)? It is not about, 'look at how pretty/clean my code is' or anything else. Management does not care. Management wants results and if you can prove to deliver faster with lang x over y than so be it. However, there is still more context to consider. Are you replacing a decade of java with python because **you** like python more? Does anyone else on you team know python? How big is your team? These types of things are more important than code. 
Code *is* a result -- of programming. The idea is to show how there is less work involved. The output of the code is supposed to be identical for each language, by design. Maybe absolute time spent programming would be a better metric, but it can be roughly inferred from lines of code per task. 
I have a book 'Python for computational scripting', by Hans Peter Langtangen that lsts many of the advantages of python for this tasks, along with working examples. The book is googleable on amazon and also online pdf, I dunno if legally.
You're talking like a programmer, which is great when you're talking to programmers. But an exec doesn't (and shouldn't) care what your code looks like. Code is NOT a result, not for them. Code is something that gets them something. Yes, if you can show them that using tool A (a programming language is just a tool) means development time gets cut in half, that's something they'll care about. But they're going to be very wary (as they should be) of moving away from something that at least sounds like it's working. Python being incrementally better in some way just may not be enough to warrant a switch. "The way you're doing things is wrong/bad/slow/inefficient/old, let me show you this way newer/better/faster/smarter/cooler way!" is something that an exec hears roughly every 3 weeks. Almost none of them are good ideas.
I built a modeling language for biology a few years ago, and worked in biotech for several years. Here's my take. Management will be thinking in terms of company objectives which might include: * develop models quickly * develop reliable models * integrate with customers * reuse existing models * take advantage of external support &amp; community * minimize transition costs * handle complex models (?) Make a list like this. Your presentation should map these concerns to Java vs Python. You should honestly present the pros and cons of each. Models are scientific documents that are meant to be read, written and executed, so features that support those things should help the company. My guess is that you can make an excellent case for Python in terms of readability and writability. The easier a model is to read, the easier it is to reuse bits of it. You could also make an argument for speed based on your own initial work rebuilding the Java model. Developing models is an iterative process where a CLI will probably add a lot of value. I'd do a demo of using the Python CLI versus compiling/running Java code. Another good metric would be coverage and size of audience for related scientific libraries. SciPy/NumPy are obviously excellent and have huge adoption. A slide showing comparing adoption &amp; rate of adoption for the two platforms should be a powerful argument for Python, IMO. Look at numbers on GitHub. 
Didn't know about that (used Thrift only once to slap together a quick and dirty Evernote Chrome extension). Thanks!
Make graphs appear in ipython notebook based on your models / data. Then idly ponder out loud how you could ever do so as easily with java
Yes the language used is like a religion to some folks, so one needs to be careful.
here's something that's hard to understand. the management probably doesn't care what language you're using. at all. you have a couple of compelling points (for a developer) in the 'batteries included' implementation that python allows, but mostly -- they only care that it's faster for equal value.
Are these long-running tasks or quick one-offs? Do people work with the model and iterate over the data repeatedly? Are the models developed and then don't need modification in the future? Is the processing done in a parallel or distributed manner? These factors qualify or disqualify Python.
There's also https://pypi.python.org/pypi/cmd2
why do you use time.sleep() so often?
I agree with this. You'll be showing a real and relevant scenario to their interests. Maybe a small intro of why you chose it and then what you achieved with it (comparing it to the longer development periods and harder maintenance of the "old way").
Maybe this is his linkedin: http://www.linkedin.com/pub/tim-peters/46/2b4/6b9
I dont get it, is this is a joke that went woosh?!
If there is a common pattern among the queries and the queries themselves are limited (5-10), it may just be easier to code for each query individually. Such as a list of portfolios that you match against. WolframAlpha would be the next easiest if they can answer your queries, however, you would require internet access which can be a handicap. NLTK is the harder of the routes, since you would need to handmake the parser to work with it, but if you can do it, it would probably be the best way. I haven't worked with Quepy, so I can't say.
It helps set a delay between things, and give you time to read them before a new prompt appears. 
&gt; no single simple solution in Python Yes there is. pip + virtualenv.
I think the joke is that it tells you that you are too fat regardless of what data you input. 
That setup allows you to create a single JAR-like file that contains all dependencies and can be dropped onto a server to update it?
No. Who said it had to? You just complained about not having a simple solution for deployment. pip + virtualenv meets that criteria.
That's great advice, thanks! I'd probably prefer to do it through NLTK since that would be the best way to scale the solution, but if not, internet access should not be a problem if the solution is WolframAlpha. I think I will first play with Quepy though, since it looks closest to the solution I would want.
It was in the context of OP's post where the server in question doesn't have access to the internet to download dependencies. That's all well and good during development but at least where I work we favour a single archive that contains the application and all dependencies so that if a given deployment fails we can roll back by nuking the application directory and re-exploding the previous archive file. No downloading, no ambiguity, just rock solid certainty so we have minimum downtime and maximum confidence in our systems.
Regardless, i thought the code was a joke, and OPie includes this "I thought it might be amusing/useful to a few of you." Useful? What?
I don't see any reason why you couldn't do that with a virtual Python environment. The whole point of `virtualenv` is to simplify the creation of virtual environments, but there's no reason why you couldn't zip it all up into one archive. It would include all of your dependencies. The only external dependency would be Python itself, which is analogous to depending upon the existence of the JVM. Then you could just upload and extract the archive to wherever you want your app to live. Enter the virtual environment and run your app. Done.
My use of Pandas gets data crunching jobs done very quickly. My manager thinks I have near godlike powers when it comes to data analysis.
 from time import sleep from collections import OrderedDict def sleepy_print(messagelist, sleeplist): """ Takes two lists (assumed to be of equal length). messagelist is a list of messages to be printed sleeplist is a list of integers for time to be slept """ for message, nap in zip(messagelist, sleeplist): print message sleep(nap) def main(): """ The common time-wasting BMI Calculator. """ banner = ["Welcome to the Christian Carson BMI Calculator!", "Your BMI, or Body Mass Index, is an indicator of your general shape.", "Let's figure out yours!"] questions = ["So, how many feet tall are you? \ Don't include inches, please.", "OK, good. Now, how many inches? Don't include the feet.", "Almost there! Finally, how much do you weigh in pounds?"] stats = OrderedDict([('feet', ''), ('inches', ''), ('weight', '')]) bannernaps, resultnaps = [2, 2, 4], [2, 2, 2, 1, 3, 1, 1, 0] sleepy_print(banner, bannernaps) for question, stat in zip(questions, stats.keys()): stats[stat] = raw_input(question) results = ["Thanks! Let's process the data!", ".", ".", ".", "Data processed!", "Based on a height of %s feet and %s inches, \ with a weight of %s pounds..." % (stats['feet'], stats['inches'], stats['weight']), "Your body mass index is...", "Too fat! Put down the fork, lardass. Go munch on some spinach."] sleepy_print(results, resultnaps) if __name__ == '__main__': main()
just tell him this: "... re-wrote a model with all the bells and whistles(thanks to the libraries) in less than a week, that my predecessor took almost a month and a half to write in Java ..."
&gt; min() and max() now accept a default argument that can be used to specify the value they return if the iterable they are evaluating has no elements. That's pretty neat and it seems useful. Similar to next()
Its a good motivator to stop eating too much and go exercise...?
What fields do you guys work in? Scientific ? or other?
Agreed. Just the fact that it took him a month faster to reimplement a project should be a measurable benefit to the management already. On the other hand, reimplementing is usually faster. 
Piece of advice: rework an internal project in python and use it to improve said project. Nothing screams "we can use this" better than seeing your own products taking advantage of it. But the key is improvement. Using a language simply because you like it is just stupid. 
I think it is, judging by the python names there. I don't see what he's doing though ... maybe he's retired.
Market research. However I use a lot of the same techniques that I did when I was doing chemistry data mining.
Don't forget: It's very important to show that Python is very easy to learn and that you can either find enough Python developers or get current developers to learn it. 
Just a warning, NLTK is *not* trivial to implement effectively. It's not too hard to extract parts of speech, but it's much harder to figure out what a user is actually trying to say. If I can throw a suggestion in, you might consider PyParsing. I've used it for some naturalish language solutions in the past, and it served me well.
Hey /u/Redditor49 I'm sure you're amazed with what you've done and you had good intentions but programming goes MUCH deeper. First off, learn from /u/bobishardcore, he's demonstrated some pretty much essential concepts to be learning if you want to do anything. Look these up now * Functions * classes * loops ('while' and 'for') And, to really bring you down (I'm sorry) this isn't that far off a shitty 'hello world' program.
Management doesn't care about programming languages. They just want to know the following, in this order: * using python will not get them fired (google was built with it so it's ok, make a slide with some big company logos) * they can easily replace you if get hit by a truck, 'cuz no one wants to search for an experienced lisp programmer in rural Iowa (find some statistics: x python programmers in the world, y in your area) * python can accomplish the specific task at hand (your boss can vouch for this) Make sure you have a cut-and-paste-able quote from a famous person (that MBAs have heard of) and some pretty pictures.
Hello, thanks for the response. I enjoyed the book, and learned a lot about python and the history of cryptography. 
Bro, I hear you. The good news is that I don't know of a better language than Python to QUICKLY piece together some VERY useful, practical pieces of software. I'll give 3 tips: 1- you already have the basis for a solid web dev project. Django is an amazing web framework, and guess what you'll be using: html, JavaScript, Python. Learn Django TODAY! 2- Start understanding how to use Git, which is a version control system - why? Because you'll need to collaborate with other programmers when u land a job AND it can help u land that job as you can make contributions to open source stuff of GitHub that will beef up your rÃ©sumÃ©. 3- start keeping an eye on interesting open source python packages. Oh and learn how to create a virtualenv
Python for Data Analysis by Wes Mckinney.
If you want to just dive into it, there's a great tutorial [here](https://bitbucket.org/hrojas/learn-pandas) using ipython notebooks.
Thanks. A little research on internet and your reply helped a lot.
Heh. Maybe it should be numbered 3.4e4, then ;-)
A good introduction would have introduced the way you explained, then encapsulated the whole mechanism, then pointed out to the actual queue module, which precisely does what you were showing. There's no problem rediscovering the wheel, but at least point to a good wheel in the end.
First of all, congratulations on making the switch :-) Your code is surprisingly clean and makes great use of Python idioms, I was really suprised to see a context manager here, given that you've only just started to learn it, call me impressed! One thing that struck me, though, is that you use "os.system" to make calls to system commands. It's generally considered more idiomatic to use one of the functions available in the "subprocess" module to do these kinds of things, they are way more versatile than "os.system", especially if you're dealing with stuff like pipes or stdout/stderr capturing. Also, some minor stylistic nitpickings: * All those newlines after if-clauses really aren't neccessary :-) * Use a single underscore character to denote that an attribute is considered "private", double underscores are generally only used for Python's "magic" methods like "\_\_init\_\_", "\_\_eq\_\_\_", etc. * Some of those lines are really to long. Try to adhere to PEP8 and keep lines to under 80 characters. Remember that you can split a long string across multiple lines without introducing newline-characters in the output string like this: example parser.add_argument("--add", help="Create new domain or add alias|subdomain associated" " to it. ie [--add domain.com:80]", metavar="") 
Like a soliloquy? Alas, [poor Java](http://captainstlucifer.files.wordpress.com/2008/12/andre.jpg?w=460&amp;h=288)! (Get someone to flip off the office lights and flip on a lone spotlight at this point.)
Thank you very much. I do have a background in PHP (Yes I know it sounds bad), and doing it professionally. But not everything is bad in PHP, as long as you have discipline and follow the language the right way by learning from others and improving your code, you should be good. But thank you very much for your kind words. Well, I started to learn Python about two weeks ago. I didn't want to signup for any online classes, I'm autodidact, so I dived straight into the Python site to learn. On one example I saw the **with open(filename) as file**: ... I went to learn about it, and saw it as something useful. That's how I got to know. For the os.system, yes you are right, I did know about subprocess, but decided to use os.system. I guess my "newbieness" make me do it. But I'll definitely change it to subprocess. Thanks. All the other points you made are right on point. I will definitely make the necessary changes. I guess this is my first python code review :) Thank you very much PS: For anyone starting to learn Python, the Python site is a good starting point. 
Here are some more great resources for Python, especially concerning idiomatic usage: * [PEP8](http://www.python.org/dev/peps/pep-0008/): This is the "Elements of Style" for the Python programming language. Try to stick to it, unless you are absolutely sure ;-) * [The Hitchhiker's Guide to Python](http://docs.python-guide.org/en/latest/): This is a great resource by the ever-awesome Kenneth Reitz on various Python topics. I especially recommend the "Writing Great Code" section, which deals with questions of style and structure * [Transforming Code into Beautiful, Idiomatic Python](http://youtu.be/OSGv2VnC0go): This is an *awesome* talk by Raymond Hettinger on several Python constructs that can greatly simplify your code. Check out Raymond's [other talks](http://pyvideo.org/speaker/138/raymond-hettinger) as well, he is a great teacher. * [Writing Idiomatic Python](http://www.jeffknupp.com/writing-idiomatic-python-ebook/): This is a great eBook ($8.99) that collects a lot of "pythonic" idioms
I probably should have specified a lack of major memory competitors, but you're right I guess - pretty difficult to standardise. I was just thinking of the OS. 
I will seem biased, but you can simply show benchmarks of simplified models. Python has lower memory usage and speed that are more important in scientific computing then portability of Java. Lower resources usage should speak to management.
&gt; I'm writing a lot of functions that do a try/except routine. Don't. The point of exceptions is that you can catch them in one place somewhere near the root of your control flow, log the exception, exit the program. Most exceptions are not really recoverable from\*, so suppressing an exception and trying to continue execution anyway is about the worst thing you can do. Also, log important stuff; entering/leaving a function usually is not important stuff. You should log important stuff when you do important stuff/when important stuff happens, I hope this answers any questions you might have about preferred locations for your logging statements =) [\*] with an exception of expected exceptions (heh), like when you want to read a config file but expect that it might be missing. In such cases you usually have a `try ... except` block around a single statement.
CubesViewer 0.7 just released by Jose Juan Montes (jjmontes). Download at https://github.com/jjmontesl/cubesviewer To try with localhost:5000 server: http://cubes.databrewery.org/demo/cubes-viewer/htmlviews/gui.html
You could monitor the OS's memory-swap rate, and limit your python process the moment it gets above a certain level.
It's actually well structured and Pythonic in style. I wouldn't have guessed it was a first project.
I'm undecided. I consider 2 of the points valid criticism: (1) os.system is depreciated and (2) making up your own dunder (double underscore) names is asking for trouble. All the rest like extra newlines and line length are just "Blue makes me twitch, paint it red please".
Not sure if it would apply but EVE Online uses python heavily. 
Code length is not a good measure, considering the amount of code that Java auto-generates.
&gt; class VHost: This creates an old style class. Consider using `class VHost(object):`.
Well, I think as a community we have pretty much adopted PEP8 across the board, which reads: &gt;Extra blank lines may be used (sparingly) to separate groups of related functions. Blank lines may be omitted between a bunch of related one-liners (e.g. a set of dummy implementations). &gt; Use blank lines in functions, sparingly, to indicate logical sections. Note the use of the wort *sparingly*. Also, concerning line length: &gt; Limit all lines to a maximum of 79 characters. Just saying... 
Cubes is another OLAP solution which tries to be light-weight. It does not support MDX queries, as the other "big" OLAP solutions. It has simple HTTP/JSON interface which covers most of the standard day-to-day aggregation queries: http://pythonhosted.org/cubes/server.html. You can try to run your own server with an example data from: https://github.com/Stiivi/cubes-examples (you don't need to set-up any database, it runs from the locally stored sqlite file that you generate using the included script). Just run it as "slicer serve slicer.ini" and you can connect to it using the cubesviewer.
Currently you can use ROLAP on any star/snowflake relational database schema. The only thing that is necessary to do is to prepare the logical model. Here are more details and patterns ("recipes"): http://pythonhosted.org/cubes/schemas.html
If you have fast drives, why not [memory map](http://docs.python.org/2/library/mmap.html)?
Thanks!
Well, if you look at the header of the file, it says "Python version &gt;= 2.7.5". I guess it's wrong then...
I read on the online docs that a lot of stuff from 3.x has been ported to 2.7. And when I checked the class creation for both 2.7.x and 3.x it is `class MyClass:` and not `class MyClass(object)` Yes it is compatible with Python &gt;= 2.7.5 and the reason of print(...) is so it's compatible to 3.x 
May I suggest this? --- Open Sourcing a Python Project the Right Way --- http://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/
&gt; The point of exceptions is that you can catch them in one place somewhere near the root of your control flow, log the exception, exit the program Not even close. http://docstore.mik.ua/orelly/other/python/0596001886_pythonian-chp-6-sect-6.html
&gt; as a community we have pretty much adopted PEP8 Who is 'we'? The community? None such exists. What you are saying is "my community". Well, not all communities conform to your standards. Chromium OS uses 2 spaces for indents not 4. Which one of you is the One True Religion? It's kind of tantamount to saying all Americans who don't eat turkey on 4 July should be arrested or something. If you can't write a script to run reindent.py whenever you push or pull code, there are problems. 
This is not about porting but removing a legacy piece of functionality. Old style classes have existed in each and every 2.x release. Your code still works with old style classes but there are subtle differences; you can read [here](http://stackoverflow.com/questions/54867/old-style-and-new-style-classes-in-python). As an example, try this out in REPL for both 2.x and 3.x Python: class A: pass a = A() print type(a) class B(object): pass b = B() print type(b) So to conclude, if you want your code to create new style classes for both 2.x and 3.x, consider the suggestion presented above.
Now I am a little bit confused. I am pretty new to Python. So what did I do wrong in declaring the class? If it works fine in both, what is the problem then? 
I don't blame you for not using the subprocess library. Don't think it has clean api. There has been effort to improve it, https://github.com/kennethreitz/envoy for example, but that seems dead. I have tested https://pypi.python.org/pypi/sh which you might like. *Edit*: I don't think you should create dependencies for your module, maybe for some other time
I just wanted to say Thank you for those links! 
anyone has idea why in the page 24 it is w.write(b'GET / HTTP/1.0\r\n\r\n') not yield from w.write(b'GET / HTTP/1.0\r\n\r\n')
full logs are here: http://pastebin.com/iP8mdfdF
In the context of your code/application, there is nothing wrong with your class. It's just that old style classes don't play nice with the Python library ecosystem out there plus miss out on a lot of new features added for the new style classes [read here](http://python-history.blogspot.in/2010/06/inside-story-on-new-style-classes.html). All in all, if you want your code to be usable by others and are interested in doing *the right thing*, stick with new style classes. 
Seconded, what you are describing sounds like an ideal candidate for a DSL. If you can enforce some structure on question entry, then turning that into code will be much easier.
Are there videos of this? I'd like to see the examples section..
That falls under "expected exceptions" that I mentioned. Those are rare, and I'd say mostly pop up as workarounds for limitations of existing API. Or one's ignorance of the API: those `getattr` examples in the article you linked suck in my opinion, since `getattr` already has an optional `default` argument, and I would write it like this: def trycalling(obj, attrib, default, *args, **kwds): def default_method(*args, **kwds): return default getattr(obj, attrib, default_method)(*args, **kwds) Another approach is using sentinel = object() result = do_something(..., default=sentinel) if result is sentinel: ... The point of EAFP is to avoid logically complicated control flow, like in `if key in d: return d[key]`(on a side note, `dict.get` and `dict.setdefault` exist for this use case): imagine writing a static correctness verifier, it suddenly has to understand that it is safe to ask for the value with that key inside the body of the `if`. What is hard for a program to understand is usually hard and error-prone for humans as well. Point is, this is a particular pattern where you call a function that might return a value or an error, in an Ideal Language it would be implemented as pattern-matching on a return value (a la Haskell) with an option to get the return value directly or automatically raise an exception (a la Go. *edit:* it appears they have not used this perfectly fine opportunity, actually... I could swear someone told me it works this way), as if there was an assert on the other branch of pattern matching. As it is, better use the `default` argument or write your own wrappers which allow that. For the completeness sake, besides 1) unexpected exceptions that should be logged and terminate the program and 2) expected local errors that should be caught immediately (if they are implemented with exceptions, preferably in a wrapper providing a saner interface), there's 3) expected nonlocal errors. Say you're parsing something or processing a message or whatever, using several tightly-coupled functions. Then you'd want to have your own exception type instances of which you throw from those functions, catch them in the main function, and convert to a local expected error API. This is a use case for which that Java-like checked exceptions might be good. Anyway! If you read what the OP is asking, they appear to have this idea that for their functions they should use some template like: def do_stuff(...): try: ... except: log exception return None return result This is wrong. Nobody should ever do that in a blanket fashion.
You could start with [Dive into Python: Chapter 12 XML](http://www.diveinto.org/python3/xml.html) or [Python 2.7 expat module](http://docs.python.org/2/library/pyexpat.html). There may even be application-specific parsers file example BioPython has a parser for the XML output produced by a commonly-used search tool.
Personally I found "the hard way" overrated; complete the codeacademy track and look for a course that uses python on coursera, afterwards start building something that you're interested in
Probably. You might need to move some time critical tasks to C, but probably there are enough libraries for this already. BTW, [You might be interested in this.](https://www.udacity.com/course/cs373) (You won't be able to create a real Google Car with that course though, I'm pretty sure;))
If you are a 'web fiddler' you might want to investigate programming basics first. If you seriously want to learn Python try all the ways you hear about.
I like Python the Hard Way as a start and than I did Khan Academy and than I took up pandas for data analysis for work (What a time saver). Any language will work for robots other's more. I say don't reinvent the wheel find a project you like and than go from there. I think Lua would be a good robot language???
Arduino code is not Java. 
You probably wont program a robot with python. Some sensors need really high polling rates in which case you need C. Also you are going to most likely not use a PC to control it but microcontrollers instead which dont work with python. Pyhton is an interpreted language and as such slower than C.
Probably because socket is in non-blocking mode so the call does not block.
I've used pyserial in several projects involving python and arduinos.
A lot of people doing robotics in python. for exmaple: http://www.aldebaran-robotics.com/ The majority of programmers these days know more than 1 language. Don't think starting Python locks you into it for ever.
I think your quickest, easiest, cheapest bet of realizing the dream is with a raspberry pi. It comes with python and a python library for easily reading and writing to and from the gpio pins. You could use the gpio pins to control servo motor relays on your robot. And the raspberry pi is like 40 bucks shipped. Edit: also, find your local [hackerspace](http://hackerspaces.org) and see what they have going on with python robotics. They almost all have someone doing this already. 
Python is very popular in robotics. MIT (a US university) does a whole course on it http://courses.csail.mit.edu/6.01/fall07/software/ &gt; In this course, we'll be using the Python programming language. We'll also be using a Python package called SoaR to control the robots, both the real ones and in simulation. What makes you think micro-controllers will be used in a domestic robot? A raspberry pi is credit card sized. A small netbook and batteries would quite easily fit into a robot the size of a briefcase with wheels. As for sensors, the main problem isn't going to be polling speed. How many times per second do you *really* need to poll a sensor in a domestic robot? 25 FPS is fine for human visual navigation. The problem with Python in hard realtime is that garbage collection and exceptions mean you can't predict how long a piece of code will take to execute, and if you have to execute within a set time frame, this can be a problem. Anyway it's not likely going to be an issue for a robo-butler. It's not a guided missile trying to steer down the bad guys' base air vents at supersonic speed.
Cool, never thought it was fast enough.
Mmap functionality is built into SciPy's netcdf handling, I've found it very handy.
IMHO, python is a great all-purpose language and excels for rapid prototyping. It's a bit of a swiss army knife: You probably don't want it for specialized cases* and it might not be optimal in the majority of cases. But you want a swiss-army knife. YMMV depending on which problems you face and which other tools you have at your disposal. When I want to build a web app, I can use Django (/r/django), I can munge data using vanilla python, I can automate all sorts of system tasks, I can deal with databases of any size and shape (there are great libraries for *almost* everything in python), and I can do some pretty serious analysis in numpy. When I want do machine learning, I can reach for scikit-learn. I've found python to be a great utility belt for getting shit done. Bonus: all this breadth of the python ecosystem is mostly open-source. No expensive matlab toolboxes, no up-front payments to get a windows server up and running, etc. You basically need a laptop and the world is yours. *Just like you don't use a swiss-army knife for surgery. Sorry, robots/embedded probably fits here if you want to do low-level stuff. Doesn't mean you can't do it, just that there are limitations (mostly speed, sometimes w.r.t. interacting with whichever electromechanical system you choose).
Learn Python the Hard Way is a very, very good resource if and only if you learn by deduction and experimentation. It sets up the course in a way that you discover things yourself before they are formally introduced. For example, the way he teaches recursion. If you are the type that learns by memorising things by rote, LPTHW is going to make you unhappy and there are better materials out there, like Code Academy etc.
Yes, arduino code is based in C, but as you said you can use python or even scratch, but I digress...
I learned python largely at work (as needed), and then much more thoroughly through an on-site course taught by Dave Beazley (again, organized by work). Nevertheless I think it's a language that lends itself extremely well to self-study (though I also think that most languages do, in the right context). &gt; I one day hope to build a walking robot, and will need a language to create and fine tune the leg movements. Is Python a reasonable way to do this? Not 100% towards what you'd need for that, but I wrote a python library for controlling Arduino boards that includes support for Arduino's servo library (and a fair sized portion of the Arduino standard library overall): https://github.com/thearn/Python-Arduino-Command-API This (like other comparable microcontroller APIs for python) is really just a serial bridge, which communicates with Arduino using python's serial communication library. I tried very hard to keep the syntax 1-to-1 between Arduino code and the library. Eventually you may want to learn how to script your own serial control protocol, but this can at least get you started. Especially if you're learning both the basics of python and the basics of hardware control at the same time. 
Memory limits are usually configured by the user because it's difficult for a program to deduce a good memory limit from its environment on account of virtual memory, as others have noted. Add a configuration file setting for "maximum allocation size". Set it to something reasonable for anyone like 2GB, and then note in the instructions that people with beefy computers should increase that limit.
I'm going to go against the grain here. Python is a scripting language. You are concerned with robotics. You want an embedded systems language, probably C or C++. You will be probably using custom parts which will not have a way of running python and if there is a way, it wil probably be unsupported and require you to hack some things together anyway. Also, the scope of your project is very large. Such robotics will test knowledge in mechanical engineering, electrical engineering, as well as computer science. If you have no experience in any of these and are still interested, you should learn more CS/EE and come back later. If you do have experience, then I'm sure you can use Python. But it's one of those things where if you have to ask you probably won't know how.
I'm also a novice and have been trying to figure out what to learn. You can do anything in any language, and after rolling that around I decided programming is kind of like...magic, more specifically Magic the Gathering (bear with me). Green, blue, red, white and black to python, ruby, java, C and many others. You can do anything in any language, much like you can accomplish any feat with any kind of magic - however each of those has an affinity for a certain kind of use. More practically though, try one of them out - I enjoyed doing some very basic python and just enrolled in an [EdX](https://www.edx.org/course/mit/6-00-1x/introduction-computer-science/1122?utm_source=edX+Course+Announcements+Mailing+List&amp;utm_campaign=c637227f4a-October_16_Student_Newsletter_h_k_10_17_2013&amp;utm_medium=email&amp;utm_term=0_237694b56d-c637227f4a-46766165) course that started last week. Maybe check it out. The language you end up with is the one that feels the most comfortable, much like a magical affinity feels right. And much like an Archmage who uses multiple kinds of mana, seasoned programmers are familiar with more than one language. Also, if you're interested in robotics, check out the [arduino community](http://www.reddit.com/r/arduino) and microcontrollers more generally.
My favorite thing about Python: IPython. I haven't found a faster way to go from idea nugget, to sketch, to test, to full blown development in any other language yet. The other thing that can't be beat is pip. I have never had a dev system so flexible, but uncluttered at the same time. Python stands for productivity.
So I've only had the opportunity to mess around with a few robots: the NXT, Vex, and that Botball thing no one has heard of in years. As a Python person, I would recommend using the NXT and writing the code in nxj (Java wrapper). There is also nxc (c99 wrapper), but since you are inquiring about Python, I take it you like data structures as most of us sane people do. The NXT also has a Lua and Python wrappers, but both are primitive and last time I checked, very much in the alpha stage. Hopefully you find one that has a working Python wrapper, but until then keep reading about it. There's still a lot you can do like make video games about robots!
You can't do anything in any language, though. Every language is a way of piecing together assembly Language. The further you get from assembly the more restricted you get. Once you get to one of these walls, the only way to fix it is with a library made in a low Level language, which brings you to a dependancy on other people doing the heavy lifting for you, which is fine. It's just silly to assume someone will have a solution to all your problems though
I'm having a hard time grasping what you're getting at overall. I get pieces of your points...I think. I know that I'm taking issue with your definitive statements like "Most exceptions are not really recoverable from". I have a feeling that that means one thing to you, and another to me. Do you have a problem with this: def foo(...): try: do() except thing.exception: log exception (Just trying to get a baseline that we can discuss. I really appreciate you taking the time to write all this out!)
Personal experience here - I've been programming for close to 30 years, BASIC, Pascal, C, Java, C#, Smalltalk, Delphi, Python to name a few languages I've used in anger and/or professionally... With Python I find that there is less resistance going from idea in my mind, to working code in the IDE. The language has so many built-in types, and libraries that you can get a lot done with very few lines of code. Work wise, I've found myself doing a lot of prototype/exploratory work in Python, and then when I'm happy with a design, I write it in Delphi (the companies language of choice). One particular example I can cite was an algorithm I worked on recently, it was 157 lines of mostly idiomatic Python code, but 900+ lines of Delphi code. Sure, execution speed was not comparible, the algorithm could (on large examples) take up to 3 minutes to run on Python 2.7.5 32-bit, but only ~30 seconds on XE2 64-Bit. However PyPy 2.02 made for a very competitive comparison, it was about on par with XE2 32-bit. I just find the language really enjoyable to use, to code in, to think in. It's fun, it's the same sort of fun I have when developing in Smalltalk. I don't know how to really describe that feeling if you haven't had to use languages you didn't like because you worked in jobs because you had bills to pay. Sure, it has some warts, well, they're not so much warts as possibly features that don't exist (that I really liked in Smalltalk, non-local returns, multi-line lambdas). The variety of dev tools, and available code to learn from is also exciting. Python has a huge community, and I don't think I've found a friendlier one, it seems to me that most people who end up working with Python are pragmatic about it, and use it because it's the best tool for whatever problem they happen to be trying to solve, and not using Python because of any pure blind support for it. Having said all that, I'm not sure about modelling robotic leg movement in Python, but the shoulders you would have to stand on are huge. Even if you did something similar to me - prototype in Python, performance implementation done in C/C++/Something else, and then I'm reminded of the PyPy performance I've seen, if you could implement it in pure Python, PyPy could probably be fast enough as is!
&gt; [is there any sort of best practice for dynamically allocating how much memory a python process can use?] * https://en.wikipedia.org/wiki/Cgroups * https://www.kernel.org/doc/Documentation/cgroups/memory.txt
Since you are interested in robotics, good news for you: ROS, the robot operating system (one of the most used software in the industry), has support for python! The bad news, not every package in ROS is compatible with python, so be sure to check your dependencies. Also, it is still recommended to program the low level robotics stuff (processing sensors and actuating motors) in C++. http://wiki.ros.org/rospy/Tutorials
&gt;it does it the way you think it will Except when it doesn't. For example: def f(lst=[]): lst.append('test') print(lst) f() f() f() Prints: ['test'] ['test', 'test'] ['test', 'test', 'test'] Or another example: fs = [(lambda n: i + n) for i in range(10)] print([f(6) for f in fs]) Prints: [15, 15, 15, 15, 15, 15, 15, 15, 15, 15]
once you get the idea that python passes parameters by object reference those examples you listed do behave the way you think they will. 
If he wanted to avoid the hardware issues, there are a lot of kits and plans these days, and a lot of the plans are open source making them free. Mostly all COTS using desktop processors. A couple might be: http://thecorpora.com/ http://www.aldebaran-robotics.com/en/Discover-NAO/Key-Features/hardware-platform.html 
That last one is a poor attempt at currying. I saw an interesting one here recently: http://composingprograms.com/pages/16-higher-order-functions.html#currying
Once you understand closures, that's exactly what you should expect.
Why I will never read the rest of _Python the Hard Way_. From the intro: &gt; This book's job is to teach you the three most essential skills that a beginning programmer needs to know: reading and writing, attention to detail, and spotting differences. From the zeroth chapter: &gt; This exercise has no code. It is simply the exercise you complete to get your computer to run Python. You should follow these instructions as exactly as possible. For example, **Mac OSX** computers already have Python 2, so do not install Python 3 (or any Python). That is not the name of Apple's OS. Attention to detail, much? This is a petty reason not to read the book, but I find it insurmountable. 
If you have any programming background at all learning the basics of Python is fairly easy as basically you're coding in pseudocode. There are more powerful features of Python you can get into later.
That is true for any language. Daejo's response was to the guy who said that Python does everything the way you expect it too
&gt; callbacks are the lowest common denominator Nope. Sorry to say it, but I think Guido is on crack. You know what the lowest common denominator? A freakin socket call: sock.recv() that is the lowest denominator. sock.sendall() is the lowest common denominator. Not *sock.recv(....,callback)* not *sock.recv(....).setCallback().setErrback()* not *yield from sock.recv()* not *yield to sock recv()*, nope, none of those. It is a simple call to a socket running in a green thread. gevent does it, eventlet does. Here are examples of fast and concurrent IO requests done right. These are in production, these are working right now putting bread on the table: http://eventlet.net/doc/examples.html That is the lowest common denominator. What is that, an HTTP request came in? Do you need to set 15 callback chains? Nope. You need to spawn a green thread, handle the request, return the result and close the socket. In the meantime there are other green threads reading from DB or handling other HTTP requests. That is a sane way to organize a large concurrent system not with callback chains and yield from. "Oh but I like yield froms, those are cool". Yes they are, so are homomorphic monoid endofunctors, except that they put not bread on the table to to speak. Python is useful primary because of its batteries included. Need to parse JSON-RPC protocol, here you go, here is a library that does it. Have an exotic protocol, for data acquisition via serial port, you can probably find a parser in Python for it. Yeah with eventlet or gevent you have one dirty monkeypatching code in the front and then you are done. With Twisted or Tulip or yield from you cannot easily share IO libraries between projects. Let me repeat that **you cannot share IO libraries between projects**. You picked Twisted? Cool. You are forever going to be searching for Twisted version of each IO library you need. Now you'll need a Tulip version of the same library. 
If you care so much about this, then why not make a [pull request](https://gitorious.org/learn-python-the-hard-way) 
&gt; I have a rather specific task in mind, one I sometimes dream of, and may never get around to, but we all must have dreams, no? Sorry poet boy but programs can't give you a bigger penis
That sounds like a good option as well. Will have a good think about it after playing with these libraries for a bit. Thanks a lot for helping me out :)
Thank you for such an in-depth answer! It is good to know there are perhaps better choices for what I want to end up with.
Thanks for the clues! And handy links. Knowing where to start is half the battle.
Having something behave how you think it will must be the best possible hope. Too bad they all don't do that. Thank you!
I have heard a very little bit about raspberry pie. I had no idea they were so cheap, however!
That sounds very useful, and maybe just what I need. 
Speed is an important consideration, and one I had not thought of.
This is the info I was hoping for. Knowing that there is a better language for a certain task is very useful.
How about [a-python-proxy-in-less-than-100-lines-of-code](http://voorloopnul.com/blog/a-python-proxy-in-less-than-100-lines-of-code/)
Any particular reason you want to write it yourself instead of using a mature and freely available HTTP proxy like Squid or HAProxy? Depending on how 'high performance' the solution needs to be, Python may be your bottleneck if you write something custom. Don't re-invent the wheel unless you absolutely have to, especially where it's security related.
Python. Might as well. It's really not too hard.
I decided to learn Python about 2 weeks ago, and have just completed by first little script that takes snapshots of Amazon Web Services boxes and copies them across regions. I had previously coded in PHP at an intermediate level, but hadn't written a single bit of code in about 8 years. Learn Python the Hard Way is a good resource. I also took a few modules of the Udacity "Introduction to Computer Science" (https://www.udacity.com/course/cs101) course which is based on Python. It's probably the best place to start if you've never coded before, or at least haven't coded for a long time and want more exposure to programming principles rather than just Python examples. I found Python is very forgiving as a language, and I've had fun writing in it for that very reason. 
Been programming in python for about a year. It will probably be another year or two before I can concisely describe why Python will remain a second tier language good for prototyping but not large scale development. And yes I know there are large scale development projects in Python that persevere despite Python's shortcomings. I'm sure they'd be farther along using a more complete modern language.
Don't kid yourself, there's still a lot of magic in Django, even after the "magic removal" branch. I think django's trend is to magically do the shit that you pretty much *wouldn't* do any other way and leave the rest up to your preference. As much as all the trendy new kids on the block like to use Flask and shit, Django is still more minimal than Rails. I've used rails a couple times and really didn't like the amount of stuff it did behind the scenes, I felt like overriding/subclassing that behaviour would bite you in the ass and in my attempts, it did. Honestly, it's up to your opinion. I'd go where the ecosystem of third party work is, it saves my ass from common things that I just don't have time to fuck with. At this point, that's Django. It has a clear direction and a shit pile of competent devs writing packages for it.
Wait, I'm pretty sure it's called Mac OSX. Source: Worked for Apple for three years.
Hey there! The reason for Python is to implement all the custom functionality - such as authentication, per-user rate limiting, etc. Don't think I can do that with off-the-shelf proxy solution.
That first one is somewhat weird, I'll agree, but necessary. The second is actually pretty useful for splitting long format strings on several lines. The automatic concatenation of constant strings is inherited from C.
Can't answer for your first set of questions. For the last question, documentation on good neural networks is severely lacking. There is the pylearn2 library, which is quite good once you work out what is going on. It's built on Theano, so very fast once that is setup and working.
And you're sure it can't be done with some sort of custom plugin for an OOS solution? I would personally leverage as much mature, stable, secure code as I could and look heavily into customising something that's already out there via a plugin or modifying the source directly if need be.
&gt; Python has a little bit of OO, procedural and functional, so it doesn't stand out in any particular one. Python has more than just a little bit of OO and procedural. It has most of what one would want. It does just have a little bit of functional programming support. With decorators, metaclasses and classes being first-class objects, Python has very powerful support for OO.
[ Let me repeat that you cannot share IO libraries between projects. ] The slides are lying, then. They assert that one of the goals of Tulip is interoperability between frameworks (slides 13 &amp; 14). The "Twisted Effect" is a headache. I hope you're wrong.
&gt; closures still a black hole to me
What protocol is "api" using?
Yes, but complex is an adjective. 
API is served via HTTP or HTTPS in a REST fashion.
&gt; And you're sure it can't be done with some sort of custom plugin for an OOS solution? I was hoping someone here would know of a library/package/class or a service I can start off with. I'll see if I can find anything. Not Python, but I did come accross [node-http-proxy](https://github.com/nodejitsu/node-http-proxy) which seems to be what I'm looking for, but I'd have to learn nodejs and Javascript from scratch. Python I know more-or-less well.
Agreed 100%. If you want callbacks, stick to Twisted. It is a perfectly robust and full-featured library. The standard lib shouldn't be trying to write what is essentially half of Twisted features with a prettier API (though pretty APIs are certainly always a good thing). It would be much, much better if instead they added some sort of native support for green-threads a la greenlets, and then a wrapper library similar to gevent.
Ah ok, sorry I'm not sure how extensible those proxies are, especially in Python. If you go down the route of writing something yourself, definitely check out Twisted. It's a Python library/framework for writing high-performance servers just like you're looking for. It even has a three-line HTTP Proxy example in the examples: https://wiki.python.org/moin/Twisted-Examples Might be a good base to start working from.
It's not about what you expect, it's about consistency. The behavior of default arguments is the same everywhere. Similar arguments cannot be had for JS or PHP.
Consistency within Python, yes. Consistency with other languages, no. Other guy made an argument that if you write pseudocode you are basically writing python. I agree with him, but in this case that does not apply
&gt;after all, the expression for the default is inside the function definition No it's not. The function definition is the indented block. It's not inside that.
It is, quite honestly, unlikely that anyone would be using varargs or kwargs in pseudocode, although I think that part of the language could be handled better.
I've used Python a lot for the good reasons people mention here. I would like to bring two things that bother me and really make Python less fun than it should be: * The state of Python 3 vs 2. It's just not fun. Too many libraries I need are still Python 2 only. * The state of virtual environments and package management feels (to me) awkward and haphazard compared to, for example, the state of node.js + npm. I view both of these issues as historical artifacts associated with any mature platform. Nevertheless, the fact that Python 2 didn't "get things right from the start" and that package management has evolved along with Python makes both aspects more awkward than I wish they should be. It's also an aspect of the Python ecosystem being so big, one of its major strengths: There are so many libraries that expecting them to follow best practices and being "up to date" is perhaps too much to ask (or to try and fix yourself). Unfortunately, any attempts to fix these will likely suffer from something similar to "[15 competing standards](http://xkcd.com/927/)"...
Here, check this out: &gt;&gt;&gt; hometown = 'Outerville' &gt;&gt;&gt; def someGuy (): ... print "I'm some guy, and I'm from %s!" % hometown ... &gt;&gt;&gt; someGuy() I'm some guy, and I'm from Outerville! Let's notice a few things. When we define `someGuy`, we give him the ability to say where he's from (it's all he knows how to do). We didn't imbue him with this information, though. He looked to the place he was born - outside of his own function, to the outermost, global scope of the whole program (where he was created) - and found a `hometown` variable there, and used it. Now you might expect that when he goes somewhere else that has a different hometown variable outside of himself that he would find *that* `hometown`, get confused, and say he's from wherever he is at the moment. Let's see if that happens: &gt;&gt;&gt; def theTownOfInnerville (): ... hometown = 'Innerville' ... someGuy() ... &gt;&gt;&gt; theTownOfInnerville() I'm some guy, and I'm from Outerville! Huh... Even though he's being called to speak about himself inside a new scope - `theTownOfInnerville`, and there's a different `hometown` right there, right next to him ('Innerville'), he still knows he's from Outerville. Why didn't he look outside of himself in this new place and find the hometown of 'Innerville'? It's because functions (and that's what he is - a function) keep track of the environment in which they were created (i.e. they "close over" it - this is an example of a closure!), and therefore when asked to reference non-local variables (i.e. variables they don't have directly inside themselves - there's no `hometown` inside of `someGuy`) they always look to where they were born. The closure here comes from the fact that no matter where `someGuy` finds himself, when he talks about `hometown` he's always referencing the `hometown` where he was created. He's "closed over" that environment to retain pointers to the variables that exist[ed] there. This is usually done through a table of pointers, IIRC. So that's all interesting, but it's kind of messy, because we're dealing with global variables here, which are basically never a good idea - we shouldn't just have `hometown` sitting out in the middle of nowhere in the program's outermost scope, all vulnerable-like, waiting to be overwritten or deleted, or to confuse everyone who sees it sitting out there all alone. It's more common to use the scope inside of an outer, wrapping function to do this work. Here's an example: &gt;&gt;&gt; def createAGuyFromHouston (): ... hometown = 'Houston' ... def aGuy (): ... print "I'm a guy, and I'm from %s!" % hometown ... return aGuy ... &gt;&gt;&gt; someGuy = createAGuyFromHouston() &gt;&gt;&gt; someGuy() I'm a guy, and I'm from Houston! See what we did? We just wrapped everything inside another function to get it away from the main, outermost scope of the program. Now everything is in a new, smaller scope; it's inside the `createAGuyFromHouston` scope. We're still creating a `hometown` string, and a guy function, but now both are being created inside another function, and the guy function is an 'inner' function. That's not a special term or anything. We just have nested functions now, and `aGuy` is the inner one. Btw, we renamed `someGuy` to `aGuy` when we moved it into the `createAGuyFromHouston` function, because now we're not using it directly anymore; we're returning it from the outer function and assigning it to a new variable, which is now what we're calling `someGuy`. So that's another valid closure, done in a more traditional way, where we have an outer scope - this time the function `createAGuyFromHouston` instead of the global space of the entire program - and the inner function which 'closes over' that scope, retaining a pointer to `hometown` in the process. So now, even though that outer scope/function, and that variable `hometown` disappear once `someGuy` has been assigned the result, a kind of shadow-world still exists, from which `someGuy` is able to call forth the old value of `hometown`, because he's retained a creepy, detached version of the environment that was inside of `createAGuyFromHouston`, where he was born, like a lingering memory of what once existed there. Of course, we're really just talking memory, and a copy of the variables that were in that outer function are stored in a reference table that `someGuy` is still able to access, but I like my creepy version of the story better. So that's all quite specific, this guy from Houston. What if we wanted to be able to create a guy from anywhere? Well, that's easy now. Instead of hardcoding `hometown` into the outer scope/function, we can just pass it *into* that outer scope from outside through an argument, then let the inner function 'close over' that outer scope environment, trapping it and its `hometown` variable, so when the outer scope stops running and evaporates, the inner function that we returned from it will still retain pointers to the things that were local to it (the local variables around it) when it was created in there. &gt;&gt;&gt; def createAGuy (hometown): ... def aGuy (): ... print "I'm a guy, and I'm from %s!" % hometown ... return aGuy ... &gt;&gt;&gt; someGuy = createAGuy('Phoenix') &gt;&gt;&gt; someGuy() I'm a guy, and I'm from Phoenix! See? Same thing, basically, but this time we get to (have to, in fact) tell `createAGuy` what `hometown` is - from the outside - and then `aGuy` inside of there uses that `hometown` variable. Once `aGuy` is returned, we're free of the clutches of `createAGuy`, and its version of that passed in `hometown` vanishes along with the rest of the completed function, but we've retained pointers to the local variables in that scope, so `hometown`, which only should have existed inside `createAGuy`, lives on as a memory (a pointer, actually) inside of the returned `aGuy` function, which is now - out here, outside of `createAGuy` - called `someGuy`. I don't know if that cleared it up or made it worse, but I had fun.
Twisted is the Yngwie Malmsteen of libraries; I respect and admire the depth of the skill that went into creating it and the advanced state to which those ideas were taken, but I hate its aesthetic *so much* that I can't really tolerate it. Tulip has always sounded like a very milquetoast way of blessing Twisted without upsetting everyone else in the event-based Python space. The bottom line is, I can't use Twisted code in the console and I can't use it effectively from a debugger, I have to define two classes (one of them a goddamn *Factory*) to write an Echo server, and it makes all of my code look and smell like Java.
speed is not important for anything in your imediate future. You can make 3D games in python. Speed is not your concern now. The first lesson to learn in programming is 'don't prematurely optimize' aka don't worry about shit till it's broke. Don't stop learning though. Don't confuse the phrase for an excuse to stagnate. 
|That first one is somewhat weird, I'll agree, but necessary. Not when you consider that it's the commas that make a tuple, not the parens: twotuple = 'a', 'b' onetuple = 'a', 
List comprehensions / generators, tuple/iterator unpacking, `*args` / `**kwargs`, "functions are objects", decorators, currying/partial function application, metaclasses, context managers, plain-English syntax, extensive standard library, `pip`, etc.? Python has a very extensive list of cool features that may interest people. For people who are used to reading files with C, C++, or Java, something as trivial as this will probably amaze them: fd = open('file.txt') for line in fd: # do something with a line No `scanf` or `Scanner` garbage here! **edit:** `enumerate` is also pretty cool. for i, line in enumerate(fd): print(i, line, end='') (assuming Python 3. you'll need to do `line.strip()` instead of `end=''` if it's Python 2)
Nice explanation.
&gt; you cannot share IO libraries between projects. THIS. The last time Python community had [a pluggable pipe dream](http://lucumr.pocoo.org/2011/7/27/the-pluggable-pipedream/), it was a [disaster](http://dirtsimple.org/2011/07/wsgi-is-dead-long-live-wsgi-lite.html).
&gt; good for prototyping but not large scale development. [cut] &gt; And yes I know there are large scale development projects in Python that persevere despite Python's shortcomings. I'm sure they'd be farther along using a more complete modern language. Could you please get a bit more into this topic? (not rhetorical question) 
Wait, why would you change a NN like that? Wouldn't the changed size invalidate any results? I can see creating/sizing a NN at run-time, I'm just struggling with how/why you would change it after it's constructed. Admittedly, I'm a NN novice.
Good idea. You'll be printing an extra newline at the end of each line, however!
You are partially right, but you are also missing a point. One of the goals of PEP-3156 is to become the canonical event loop for Python frameworks. The event loop itself doesn't actually use yield from or any other Python 3.x feature at all, it can run on Python 2 just fine. What's the advantage of this? Well, event loops are not easy, specially if you want to support Windows, and there is a lot of wheel reinvention: gevent (wraps libev), eventlet (own loop based on select module), tornado (own loop based on select module), twisted (own loop based on select module + IOCP for windows + some others). See the pattern? All these frameworks could be implemented on top of Tulip's event loop. Does it solve every problem? No. Is it A Good Thing (TM)? I think so.
It wouldn't be efficient, and the function declaration if not part of the function, it's part of the the scope outside of the function so it makes sense for it to be processed at the same time as that scope (the easier way to look at this is that if it a the same indentation level it will be processed at the same time).
 .strip() Good point! But I guess all these details won't help in showing how simple python can be for reading data. I'm currently trying out Pandas in an attempt to work with a large data set and the simplicity is beautiful.
Interestingly, I find that the most useful part of python is the whitespace indentation. The rest of the language is really academic and honestly there are parts that other languages are better at (string processing.. perl). The whitespace indentation though make the language so readable, so easily debuggable that I feel it really should be more advertised.
&gt; write You don't need to block on writing, you are waiting for a response 
So you essentially expect a book to have no typos... not necessarily the same thing as attention to detail.
The fedora is strong in this one. If you can get python to run on the controller(A Raspberry Pi will run it) then i see no problem with it other than minor jittering. The raspberry also supports python pretty well when it comes to sending and reading values through the IO. But if you think of using a arduino you either have to use C or control the arduino with python kinda like what [this guy](http://hackaday.com/2011/05/04/real-time-robotic-arm-control-with-blender/) did
You can actually combine the two examples: fs = [(lambda n, i=i: i + n) for i in range(10)] print([f(6) for f in fs]) prints: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
Part of the python philosophy is about being explicit with everything one does. Lots of automagic behind the scenes wouldn't necessarily fit in with this.
Just add a comma after the print line statement E.g. `print line,`
I love python and use it every day. However, I would be reluctant to use it for robotics - it makes no real-time guarantees, and it might not react quickly enough for something like balancing legs. Having said that, it is possible to do in python, and maybe in the future (say, a few years from now) its performance issues won't be detrimental anymore.
I know the solution, but that's not the point :P The point is, writing an extra `i=i` parameter isn't intuitive (and if you don't do it, stuff goes wrong).
Have a look at Raymond Hettinger's [Why Python is awesome](http://pyvideo.org/video/1669/keynote-3). I find it quite inspiring whenever I want to remind myself or others what makes python special.
I don't see why it couldn't work. Rather than have two separate sources of the package (pypi and your website) you could instead ship the one distribution but have the cython version require a valid licence key. Then users can quite easily "upgrade" to the faster version. I don't know what the pypi policy is on doing something like this though. Also, i think a model based on downloads is a bad idea. You can't measure it accurately since proxies may cache content even if your server directs them not to, and worse than that you will have customers who will inadvertently go over their download limit even though the number of client hosts is less than the number of licences they've paid for. This is quite easy if you're dealing with multiple dev virtualenv environments or doing something like building environments from scratch in your jenkins build process, for example. With licensing you're reliant on the honesty of your customers to some extent. That means that yes, people may crack your native extension or go over the number of licences they have paid for. I think you should be more concerned about keeping in good with the customers you have who do the right thing and make their life easy - the rest won't give you much (any?) money anyway.
 1 in (1,2,3,4,5) "kg" in "80 kg" Also show set(), defaultdict, descriptor (access method like it is field/property). Requests library Wonderful things is that you can show more than few examples because many are very easy to comprehend :)
I kind of agree actually. After all, in Haskell let fs = [ \n -&gt; i + n | i &lt;- [0..9] ] [ f 6 | f &lt;- fs ] prints [6,7,8,9,10,11,12,13,14,15] That's because Haskell list comprehension create a new binding for the variable for every step, whereas Python list comprehensions mutate a single binding. Which is somewhat consistent since they're reusing the `for` keyword from loops which also use mutation, but maybe it would have been better to choose different semantics for comprehensions.
It's possible with a custom $PYTHONSTARTUP file, e.g. mine: https://github.com/mgedmin/dotfiles/blob/master/python
Who is your audience? I can't imagine a bunch of high school students getting excited about generators.
I think this model could work for some, but I do see some use cases where it may be tricky. Please take the following as food for thought, and not as discouragement. Your idea is worth exploring and trying, IMHO. The most obvious one is, what if I wanted to build software that depended on the faster version and redistribute that? What mechanism would be in place for the users of my software to know that they must pay for a license of your software? (Not saying that they shouldn't) The second one is a matter of how the software is used internally. For example the software I work on exists on a cloud based infrastructure. Scaling up often means creating new virtual machines to handle additional load, at which time the application and all of it's dependencies get installed to that server automatically. Those servers may only live for an hour before being destroyed - and your licensing system means that every time I add another 25 machines I have to pay for another 25 licenses as well as update the requirements.txt file with the new unique URL and redeploy. Lastly, how do you plan on handling bugfix releases? Would you just add more downloads to a user's account? I think this is a very interesting idea and I'd love to hear how you decide to go. You've got some challenges in figuring out the best strategy for you and your software, but I'm sure you'll get it worked out.
it's more that, being a garbage collected language, you can't get speed *guarantees* with python. A function might take nanoseconds 99 times out of 100, and milliseconds that last time. This is only a problem for certain *kinds* of real-time processing.
Well, one quick example. Python lacks a mechanism for data hiding. Everything in a python class is accessible to anyone. It has a "convention" of prefixing members that are supposed to be hidden with an underscore but it's just a convention. Access to data hidden in a class can be controlled and can be trusted. Data that is not hidden will be messed with in ways you don't expect and aren't good for the class instance. To me making everything accessible is only a step above making everything global.
Nice lib :) I haven't seen it before.
Hiding a return value from the compiler? That's not much of a patch. If that's the best example of how ugly it would be to bring greenlet into the stdlib, I'd say it's well worth it. I've never had a problem installing greenlet on Windows, Linux, or OSX. Maybe it has problems on other platforms, but I don't think you can fairly say it's "hardly portable".
Not a big fan of messing up subprocess namespace See Also: https://pypi.python.org/pypi/envoy https://pypi.python.org/pypi/sarge 
*nix-only
Python on the web. Flask, Django, etc. I've been getting into it over the past few weeks, and it is *hella exciting*
I was wondering where you were going with the "hometown" analogy, and I was pleasantly surprised to find that it helped quite a bit with understanding the concept of closures. Very well written!
And this is where /r/ruby is discussing this post http://www.reddit.com/r/ruby/comments/1oy2bn/django_rails_and_the_philosophies_behind_them/
&gt; Broadly, you can do anything you want with any language. Except where "language" is "functional language" and "anything" is "anything useful".
Thanks. This is the first time I've thought of it that way. It didn't occur to me until I started thinking of inner and outer as places in the first example, then suddenly the "where I'm from" analogy fell into place for me. Teaching is good learning.
Well, to me, for example those quantmod stuff are much better : http://www.quantmod.com/gallery/ This is the kind of stuff I'm looking for.
&gt; Python lacks a mechanism for data hiding. Well, C# has private, protected, internal and public... but has reflection too! Should data hiding be a help or a constraint? If it's a help, it may lack rigidity, if it's a constraint, you may need a way to break it. Python is designed with the help principle. And, actually, I don't see it as an obstacle for large application development. My point of view, of course.
Entry for week 104: * *Saw daylight today for the first time in months.* * *Decided to finally clean the brown matter residue from base of my coffee mug.* * *Wrote a Python script which solves a Prof. Layton puzzle using the Monte Carlo method.* :) mostly from experience
Show me an example how I can integrate it with gevent
If an infinite loop is causing you to restart your computer you're doing something wrong. You should be able to Ctrl-C. Are you running Python from the shell, from Idle, from IPython notebook, or somewhere else? (Suggestion: if you haven't seen IPython notebook, check it out.)
i was using Spyder.. I say infinite loop, but i mean just taking forever and then freezing.. and ctrl-c wouldn't work.. I mention in the blog that this made me start using Terminal. And yes to IPython Notebook - I really like.
And than there is web2py which follows the Ruby philosophy but based on Python. ;-)
https://code.google.com/p/tulip/wiki/ThirdParty There appears to be some work on integrating greenlet, but the gevent link on that page references Twisted, not Tulip.
It depends on the students and the level. Are these PhD students? Show them how to gather, parse, analyze or display data. Are they High School students? Show them how python can detect who de-friended them on Facebook. 
this was found on: https://bitbucket.org/jespern/django-piston/wiki/Documentation#!throttling
The event loop is not important though. Why make "the canonical event loop" if we have a perfectly good interface called sock.recv() that we can change either side of?
This is uncomfortably accurate (switch out Layton for [IoP puzzles](http://blog.physicsworld.com/category/physics-world-at-25-puzzle/)).
Monkey-patching is a red herring.
I think that everything they do in those plots can be done with matplotlib, but I don't think there's going to be a "here's my data, make it look like this" function. You'll have to write that on your own with the components provided in matplotlib or whatever package you choose. Other than that I don't think I'll be much help except for google searches. Sorry.
What plugin do you have that's making the change?
Hmm, I do like fedoras, especially when the wearer has chosen a nice outfit to be complimented by said fedora... so thank you... And thank you for the link. Everyone seems to find interesting things on different sites, much more than i would find by myself. As awesome as search engines are, the human brain is staggering.
OK, so what do you do next? In the code you wrote you log the exception and return None, that's awful, unless the entire point of the exercise is to make a wrapper that returns page-or-None instead of page-or-raises and use it when you expect a failure, so you don't have to deal with exceptions there.
I'm honestly just trying to figure out exactly what you're claiming is wrong/right.
Before you get too into Terminal by itself, I recommend iTerm2. It's a fantastic Terminal replacement that allows for me flexibility. Although at present I can't remember the specifics of why I decided to switch.
And I'm honestly saying that what is right or wrong depends on what you're actually doing and in what context. I can't say whether a function `foo` consisting of a try/except'ed call to a function `bar` is right or wrong.
I'm perfectly fine with coroutines. That part looks good. However, I don't see the point of having to make anything backwards compatible. Python 2 is dead in regards to new features, is it not? There is no reason why any new modules at this point should be backported to Python 2.
It's not a plugin, Bitbucket does that conversion by default as part of its notification system. 
Cool, now try Genetic Programming.
Odd, the first time I followed the link it hadn't done the conversion.
Why are people up modding you? You are wrong. There is a space in the name. 
This isn't a typo. He gets it wrong repeatedly. 
Without knowing your student audience, I think you could start with some websites or software they use that is written in python (reddit, dropbox, Pinterest, Instagram...) I think there is still somewhat of a misconception with regard to what can be done with python. Some see it only as a scripting language.
Because you are so wrong that you validate my fallacy in comparison.
Random question: I got into grad school in 2003 writing that I wanted to do genetic algorithms, but I never ended up working with them. Out of curiosity, what is the most impressive problem solved this way nowadays? 
The same with all Atlassian products. It makes a fun time at work trying to comment or do anything with certain special symbols in them
Students of what? How old? What context?
Using MongoDB as a replacement for your application data (user accounts, session info, etc) is probably not a good idea. I work on a large project where we store over 600GB of data in MongoDB, and our front-end is built with Django. What we did was to create our own API for accessing data within MongoDB, without having to make any pymongo calls directly, allowing us to drop-in a replacement if the need arises. This has probably been the best way to do it, because in my mind you don't treat MongoDB as a typical database, you should treat it as a document store. I've looked into the nonrel fork of Django, and it just makes things way more complicated and stupid than they have to be, not to mention the stability issues. In other words, use MySQL/Postgres for your application tables, and use MongoDB to store documents. There isn't any real need for mongodb integration in Django, since pymongo acts (in some aspects) like an ORM anyways. We do however put settings related to the mongodb server into settings.py and access it from within the API we created.
You can contact sales@jetbrains.com to get your full purchase price back.
Week 151: Have a great new idea, this will be an easy 3 or 4 papers Week 152: Disregard previous entry. Idea known in 1800s. 
this looks promising and the exact opposite as http://www.brython.info/. Can you write up a proper tutorial , maybe on recreating one of your demo applications ? I flipped through the example code and your ten thousand foot walk through but had a hard time visualizing doing complex actions.
Just a few things to look into and find what you want: * http://ipython.org/notebook.html * http://code.google.com/p/mplh5canvas/ * http://matplotlib.org/users/whats_new.html#webagg-backend
&gt; Not a big fan of messing up subprocess namespace Yep, that is really poor form. They should've just called it run. It'd be a cool name on its own. The tests could use a lot of improvement too. Not trying to bitch, just trying to provide constructive criticism.
I got directed here from /r/bestof, and I must say, I am so -very- glad. Closures are one of those concepts in Common Lisp that I was really struggling to understand intuitively. Your analogy here is perfect. Now I feel like I understand them perfectly. Thanks.
yep trying to do otherwise would be a recipe for pain. 
Hey /python, I come from LAMP, node.js, meteor, Java. Python is THE language for me and I think others would appreciate it for the following reasons: - i can actually write something once, and it will actually run without error. *this is because syntax is lax. - i can write 45 lines of Java in one liner python. - I can write 15 lines of Javascript in one liner python - fuck function(){}, lambda function ftw - pip &gt; npm - its like Java when it comes to open source libraries, all the wheels have been invented but without the attitude you get from JVM. - Generators and yield is so awesome. - no ugly .prototype to define classes in Javascript. - frameworks so many of them that are mature and working well dont get caught up with all the other bullshit languages. python is the only language you need to know. and javascript if you have no choice to but to use it.
love the two-liners. let's see that in Java :/ you could do this as well to return a list of tuples containing index and text for each line. map(lambda i,line: (i, line.strip()), enumerate(fd)) then you could do whatever you want with the results for later.
Typical Microsoft :P - Thanks a lot for the response. I'll try it later and get back to you. Thanks again
Wikipedia calls it a scripting language in certain articles, alongside Perl and Ruby and others. Mercifully, the article about Python makes no such claims and the article about scripting languages implicitly disagrees with such claims, but the usage it mentions pops up in interesting places, like the first class functions article. Apparently a language can be "functional", "scripting" or "imperative". Heh. I could use that as a "which one of these is not like the others" question some time. 
Easiest way I can explain is, python adopts to my thinking style very well. for the visual thinking type guys, python lets you code in a way that makes data structures and how things will behave without having to conform to a rigid set of plumbing code. because all of the otherwise verbose functions found in other languages are simple one line to two liners, it takes a lot of headache off the developer to focus on exactly translating their ideas into code. python lowers this barrier greater then any other languages imo. this means its faster and easier to do what you want with python.
About time! :)
I don't think I've found any other language since QBASIC which I would wake up the next day looking forward to using it. It's like I've discovered programming all over again (coming from PHP, Java, Javascript, Node.js) because it brings the JOY back into the programming. It lets you express yourself however you want without holding you back with bullshit missing semicolon or other junk you dont want to deal with.
ummm Google uses python. 
At last! It was such a pain to set it up on Windows (I have to use it at work unfortunately).
this is only a problem found when working with lot of other developers in a python shop, it's not even the fault of the language, rather the limited creativity of the said developers to discover the python way of doing things, not adhereing to a rapidly aging process of over engineering software
I tend to seperate from commonly used core to uncommenly used core. Like i would put os,sys... in the top part, while http.server,subprocess,json in the bottom part. Third party is grouped in with the uncommon core. Local imports are ofc at the bottom, and every segment is seperated by newlines, like this import os import sys import http import http.server import json import server
I downloaded the community edition of PyCharm a week ago and I like it so far. I pay more attention to Pep8 now than I did without PyCharm and like the debug and variable introspection features. Customizing the hot keys were easy and changing the themes was pretty fast. Quickly became used to using both the built-in terminal and interactive prompt. I could point to existing project directories and everything ported in seamlessly. Still getting used to it, but I don't have a lot of complaints. I have noticed that code completion at times was a bit slow but this was pretty negligible.
Thank you! I have been doing `git pull` on the idea git repo and came here to post this story.
&gt; I have to use it at work unfortunately Can I assume "Windows" is the unfortunate one you are referring to? 
Nice thanks. As i thought, pointing to the built in python. No idea what to do about that as I also have 2.7 installed. Having pip IN python seems sensible to me as you install to the running python instance rather than whatever osx decides. The paths in osx are pretty convoluted, sometimes hidden and seem to have changed recently. It is fairly trivial to RUN python, but to deal with all the other stuff to manage pip outside in the OS has been really difficult for me.
Does this work inside a running instance of python? eg "&gt; &gt; &gt;" pip install bs4 Installing to the running version?
&gt; Can I assume "Windows" is the unfortunate one you are referring to? I am really hurt by you even questioning it. ;)
/r/learnpython
Your project is a perfect example of where ZeroMQ should be used. Although JSON is great, you might want to look into faster alternatives, such as [MessagePack](http://msgpack.org/).
I agree that's it's poorly documented. However the information us there. A bit here, a bit there most standard use cases are in the examples. Still not ad much as there should be
Not sure if you know, but this was just posted a few hours ago.
FWIW, I build python from source and install it in ~/local , and ~/local/bin is in the front of my path. and that is where pip, and virtualenv reside for me. I create virtualenvs per project in the root of the repo at ./.env which is in my .gitignore I don't bother activating virtualenvs b/c merely doing... $ .env/bin/python is enough and I always know what i'm running. explicit is better than implicit right?
will this be backported to 2.x?
Past Talks/Videos: https://vimeo.com/pydata/videos
Read the abstract.
Here's a documented version: http://pastebin.com/qrp2tyEG
Yeah, it is really silly if that is indeed the case. 
Not a single Pip-boy joke?
Fully agree, in this case matplotlib is even looking better with its defaults (which are probably to blame for a lot of the mpl hate.). 
pip uses requests, so therefore hes saying that you can just use requests by accessing the 'requests' library that comes with pip
Yes, requests is a dependency of pip. Pip has quite a few dependencies (I think there are 6?). All of these dependencies are re-packaged as private libraries and are internally consumed by pip (I believe ... I haven't looked at this in detail, someone correct me if I'm wrong). They're made private so that if your code depends upon a specific version of requests and you upgrade pip and it upgrades requests then your code doesn't break. It would be dumb to pull more stuff into the Python Standard Library and try and put requests in there. Pip could soon start to depend upon a new version of requests and become incompatible with the version of requests that's been frozen into place in the std lib.
Funny how you mention pedantry, then promote adherence to a standard?
Playing with this is a lot of fun until you need documentation. Unfortunately it's limited to nonexistent depending on what information you need. 
Two teachers were once having a conversation about how difficult it was conveying a new topic to their students. One of the teacher said "You know I'm having real trouble communicating this idea to my students. Every time I do so I simply get blank stares. I go over it the first time, and they don't understand it. I'll go over it a second time, and they still won't understand it. After going over it a third time, *I* finally understood it."
Doing this is a bad idea. For one Every linux distribution in the world will probably remove the pip.vendor directory. For two we reserve the right to remove it at any time. https://github.com/pypa/pip/pull/1246 will rename this to ensure it's obviously private.
https://en.wikipedia.org/wiki/Concurrent_programming * https://en.wikipedia.org/wiki/Asynchrony * https://en.wikipedia.org/wiki/Asynchronous_I/O * https://en.wikipedia.org/wiki/Non-blocking_algorithm * https://en.wikipedia.org/wiki/Futures_and_promises http://en.wikipedia.org/wiki/Python_(programming_language) + http://code.google.com/p/tulip/ * **http://www.reddit.com/r/Python/comments/1owtli/guidos_sf_presentation_tulip_async_io_for_python/** * http://code.google.com/p/tulip/wiki/ThirdParty * http://code.google.com/p/tulip/source/browse/#hg%2Fexamples * http://www.python.org/dev/peps/pep-3156/ https://en.wikipedia.org/wiki/Go_(programming_language) * https://en.wikipedia.org/wiki/Channel_(programming) * https://sites.google.com/site/gopatterns/concurrency/futures * http://blog.golang.org/concurrency-is-not-parallelism https://en.wikipedia.org/wiki/Clojure * http://clojuredocs.org/clojure_core/clojure.core/future * http://stackoverflow.com/questions/4623536/how-do-clojure-futures-and-promises-differ 
* Is bitbucket identifying an `@decorator` in a Wiki page as a bitbucket username? * Should it be necessary to escape the `\@`? Paths for resolution: * Update the django-piston wiki: Click 'edit' and escape the `@` * https://bitbucket.org/support ("wiki username") * https://confluence.atlassian.com/display/BITBUCKET/Use+a+wiki#Useawiki-SupportedMarkupLanguages * **https://confluence.atlassian.com/display/BITBUCKET/Mark+up+comments** * https://confluence.atlassian.com/display/BITBUCKET/Mark+up+comments?focusedCommentId=411108092#comment-411108092 
Yeah, the documentation for this API is really weird. I had to guess around in the console (thank goodness for TAB-completion) to figure out the correct module and method names to use. Once you know, though, it's fairly simple to figure out where things are.
What the author of this does not realize is a lot of people heading up companies like this have no idea how most technology works and what processes it takes to implement and use things like this correctly. I worked for a finance firm writing trading algorithm code (mainly c++, c# and java) and my boss thought that the monitor is what stored your data for you and not the actual hard drive. He even admitted to me and others within the company he thought computers were useless and he didn't need to know how to use one. All he was ever concerned with was the money the trading algorithm brought into and out of the company. I got out of finance software development as soon as I could because I was annoyed about working with people who had no grasp of technology, let alone understanding how it helped speed many financial transactions up and moved money faster than humans on a phone ever could.
As someone who's still using 2.7 because it's familiar and "just works", I agree. I need compelling reasons to upgrade to 3.x.
So how is it included then? I install 3.4, but i also have 3.3, 3.1, 2.7 and apple default installed. I have pip already installed to apple default. What will happen with pip in 3.4?
I did a small pet project in Python 3.3 last month. I was surprised to find everything I needed (Flask, psycopg2, SQLAlchemy, Celery, Requests) working flawlessly. I think you should check if the packages you need build on Python 3.3 and if they do I'd go and give it a shot. It's not that different, to be honest :).
You can run `python -m ensurepip` to have pip installed for you, if that python is 3.4. Additionally, afaik it should be installed for you if running python's `venv` module.
So the people wanted something so you changed the code to make it harder for them? That's real sweet of you. :-( Next I guess someone will try to break ForbiddenFruit.... http://clarete.github.io/forbiddenfruit/
If you are running 2 functions on the same line, python will use 2 cpu's. def factoral(x): total = 1 for item in range(1,x): total = total * x return(x) print(max(factorial(500),factorial(250)) Will only take the time it takes to run factorial(500), assuming you have at least 2 cpu's. edit: it doesn't, i'm an idiot.
 $ pip install requests $ python &gt;&gt;&gt; import requests as requests
The probability of getting heads or tails for a single coin flip is 50% (obviously). The probability of events A and B happening in a row, when A doesn't impact the probably of B and vice versa is probability(A) * probability(B). Also, /r/learnpython. 
Sorry, I'm didn't know :S
Because it's blocking and doesn't scale. The only way to fix it is to use non-blocking i/o, but that's not easy to do cross platform, specially if you care about windows. With tulip, Twisted and Tornado can run on top of it. Eventlet as well, if you like that kind of interface. Gevent, however has it's core really tied to libev so it's harder, but probably doable. I don't think asyncio will render other i/o frameworks obsolete.
are you drunk?
Is this homework, by any chance?
You have to use Flask + Python with Windows at work to know how hurt it is :(
Checkout PyQt / PySide. Easy to use and looks native on OSX / Windows / Linux.
We use Traits for our scientific apps, which includes automatic GUI generation and interaction between the GUI and your model. There is a great tutorial [Writing a graphical application for scientific programming using TraitsUI](http://code.enthought.com/projects/traits/docs/html/tutorials/traits_ui_scientific_app.html).
Have you got a source for this magical auto-parallelisation? If python does this, then color me amazed. It's a *very* well kept secret if it does.
wxPython is very fine for making GUIs: easy and straightforward to use, interface looks native, has a non-restrictive license.
Choose PyQt or Pyside. I have used wxPython for a lot of interfaces but still it did not seem right for me so I tested PySide. First I thought that PySide was difficult but when I started using it I soon came to know that it is one of the best for writing GUI. It even has Qt Designer which allows you to graphically design your Interfaces. WxPython only has glade which in my experience is only Ok but not as much better as Qt Designer. And after the signal slot syntax has been changed in PyQt and pySide they have become more pythonic. Finally my advice is to try PyQt or PySide (both are same only their licenses are different) and wxPython and see which one fits in. It is just a matter of personal preference as well. Also check out [another discussion](http://www.reddit.com/1o89fl) on the same topic
It's not a "horrible side effect" - it's a deliberate design choice in implementing closures. It's unconventional to use it like this, sure, but that's because you are Doing It Wrong (TM) (for some value of wrong ;p) A better way IMO would simply be def take(pairs, wanted): for k, v in pairs if v in wanted: yield k, v [edit: code formatting] 
alpha=5, beta=4 (the mean alpha*beta=20)
 print("Probability: %s" % 0.5**int(input("Heads/Tails in row: ")))
People wanted to depend on an implementation detail that is subject to be changed at any time and is unlikely to be true on Linux distributions. I made sure they knew what they were getting into when using a private copy of something.
Seriously, OP? You managed to miss the huge, bright red block-lettering that says, nay *screams*, that such questions should be asked over in /r/learnpython? I just hope you read the homework question correctly...
What do you mean by complex actions ? Here is a tutorial to get started http://pythonjs.readthedocs.org/en/latest/tutorials/todo-list/index.html 
I do use 2.7 by default but I find the features from 3.3 onwards to be attractive enough to make me use it as a default, as soon as Ubuntu will have it packaged (I believe it hasn't yet) that is. http://docs.python.org/3.3/whatsnew/3.3.html http://docs.python.org/3.4/whatsnew/3.4.html
I used both wxPython and PyQt. But personally I like PyQt more. I think the signals and slots idea really help when you want to use a MVC development model. I definitely would go with PyQt..
Awesome. This is hands down, my favorite way to code with python.
This question comes up quite a bit and most people seem to prefer PyQt/PySide. All else being equal, you're better off sticking with the most popular choice.
I've used both wxPython and PyQt for simple apps. I started with wxPython because the documentation made it very easy to learn. I switched to PyQt for Python 3 support and because I kept seeing recommendations for it here. If you're new to programming GUI's or you just need to get stuff done quickly the wxPython Examples are amazing. The wiki also has a lot of examples, tutorials and how-to's. The PyQt documentation is much less satisfying for beginners in my opinion - it's light on examples and how-to's and heavy on API documentation. Both PyQt and wxPython have GUI designers (QtDesigner and xrced) that you can use to mockup the interface and auto-generate the GUI code and callback/signal-slot code for events. Then you just have to fill in what you want the code to do. Since PyRAF supports Python 3 I'd probably recommend going with PyQt and Python 3. In my opinion new development should be done in Python 3 if at all possible. 
You should care if you want to see someone else writing Python. If you have questions or problems in your own Python scripts and want to see how to solve them. Or if you simply don't have anything else to do and want to see some random guy writing crappy code and correct what he does.
I would like to know why so many people consider installing pip such a pain. I've done it many times on different OSes and never had any problems. It's just 3 steps, same on every OS and work for python 2 and 3: download http://python-distribute.org/distribute_setup.py run 'python distribute_setup.py' run 'easy_install pip' It worked for me every time so i would like to know why and what kind of problems people had with it.
If you're just wrapping scripts in some sort of "Click here" user interface, you might think about using tkinter and ttk. It's already present in Python's standard library, and it looks pretty alright (with ttk at least) on most platforms. If you need to throw in some plots or pictures, it's pretty easy.
&gt;Unfortunately, most people just do what they might in another language and loop by index (which should never be done in Python). Why should this never be done in python?
That's not quite right, though. It doesn't return exactly one of each item matching the things in wanted, in order.
Never got around to using it, but [Kivy](http://kivy.org/) always looked cool.
Ah, I thought I might have missed something, since my solution was very simple. 
Why do they have the intermediate machine learning course on the first day and then the novice machine learning course on the second day?
selfish and yet so forthcoming
November 8th is tutorials/workshops. Nov 9 &amp; 10 is talks.
Didn't distribute get merged back into setuptools (i.e. you should be using setuptools instead)?
There is not much documentation regarding core.async of Clojure, but asyncio is not like Go. Go coroutines are â€œsmartâ€ in the sens that they can get their own thread if needed whereas asyncio coroutines are only functions executed one after the other. asyncio coroutines won't get the benefit of multicore except if you provide your own framework which can use or not asyncio. asyncio is a framework for eventloop based programs nothing else, nothing more except the use of ``yield`` and ``yield from`` (that was already the case in Gevent and other more obscure frameworks like monolect) which allows to have an imperative code style instead of the callback style. E.g. the following code: def mutliply(callback): get_async_value_one(get_async_value_one_callback, callback) def get_async_value_one_callback(value_one, callback): get_async_value_two(multiply_callback, value_one, callback) def multiply_callback(value_two, value_one, callback): callback(value_one * value_two) Can now be written as: def multiply(): value_one = yield get_async_value_one() value_two = yield get_async_value_two() yield value_one * value_two
I wanted to mock up something in PyQt5 using PyCharm CE, but it turned out to be too much of a bother so I just used Xcode instead. Too much flim-flam :/
+1 The data binding features of Traits are some of the best developed of any Python GUI library I've used. IIRC, it builds on wxPython, so one can still make custom widgets if need be.
For wxWidgets, I recommend [wxFormBuilder](http://wxformbuilder.org/). Among other things, it can generate C++ and Python code.
Use a tornado server backend and write the UI for use in a browser.
Better yet, don't use IRAF. Use numpy/scipy/astropy instead of IRAF.
I'm going to be in a minority here, but stick with tkinter. Tk comes in for a lot of flack, but it's frequently the best choice for things like this.
wxPython Phoenix is under heavy development, and I think people are beginning to use it--it works with Python 3.
I just accepted a job as devops for a prop trading firm. Everyone I talked to seemed very computer literate and it was a big reason I took the job. I am hoping it will be a very tech focused, challenging career. This article is terrifying though and shows how quickly I could fuck everything up. 
I just watched this last night. It was great! Really got me excited to keep learning Python. 
No offense, I admire you for letting people watch you code, but honestly, would you like to spend tim watching a stream of someone editing a text file? Lol
It's certainly worth considering - it's included in Python, so it's one less thing to install, and it's fairly simple to work with. There's good, if dated, [documentation here](http://effbot.org/tkinterbook/). The downside is that applications look like something dragged out of the early 90s - though scientists often don't much care - and it has a lot fewer features for powerful apps than something like Qt.
It's possible to dynamically load .uic files in your python application. [Source](http://stackoverflow.com/questions/14892713/how-do-you-load-ui-files-onto-python-classes-with-pyside)
Traits is really great, but AFAIK there is no Python 3 support at the moment and no plan to add it in the near future. That is kind of a deal breaker for me.
I just did my first desktop python app with a gui recently with wxPython. I picked it simply because it was the first one I found and tested with mac, linux, and windows (the app will be deployed to all three). It was pretty straightforward and simple.
I would suggest an alternative choice: use a web browser as your interface. For the Server: Flask or Bottle is a really simple way to go. Alternatively, Django is more production oriented. For the display of data: flot or jqplot or possibly highcharts wxPython isn't something I would recommend. PyQT is definitely the way to go if you're deadset on a native GUI.
Python 2.7 has ttk which makes it look like 2002. 
wxglade also generates C++ and Python 2 (and 3) code, and in addition Lisp, XRC and Perl code. Myself I use it for Python and Perl GUI's. Runs like a charm
Traits(UI) is terrific indeed. But for new developments I'd suggest looking into [enaml](https://github.com/nucleic/enaml/) over traistui. Think of enaml as a dynamic, pythonic qml, and the bindings to attributes / function / methods is handled at the compiler level, which is vastly more flexible. Practically this means you do not require traits for reactive programming. A seriously powerful package.
I tried a bunch, the only one where the docs could get me off the ground quickly was wx. The docs are good and it's intuitive.
I've used wxPython, it's pretty good. It was a bit of a pain for me to turn it into a Windows executable because of various dependencies (I managed it eventually using py2exe). I also thought the learning curve for wxFormbuilder was pretty steep, although I was new to GUIs at the time. If I were doing my application again I think I would try to make it a web interface. Javascript can be used to make nice looking interfaces that are much more widely used than wx stuff, and then I wouldn't have to worry about distributing it or people being on different versions, just about maintaining a server. Don't know if it's feasible with your particular application. If you do decide to go that route, [Flask](http://flask.pocoo.org/) would probably be pretty useful.
 .rstrip("\n") `.strip()` removes leading whitespaces too
http://pythonjs.readthedocs.org MUST start with an **abstract** that tells us what PythonJS is and what it is good for!
Pickle is a serialization format, so you'd use it anywhere you'd use serialization in a different language. Yesterday I was revisiting a project of mine I hacked out in a weekend. It gathered information from an api, then wrote out an html template of some statistics. Since it takes a few hours to get all the data (due to rate-limiting), I designed the program in two parts - the first gathers the data, the second analyzes it. They communicate using a pickled object, so I can repeatedly run the second part without waiting for the first. Graphite is a metrics storage system. You can get data out of it as plain-text or json, but you can also get a pickled object. If you're using python, this saves you having to parse the data back into a python data structure. 
There are some pitfalls with pickling, but it's fairly useful. I'm currently using it to store some complex structures in a MongoDB document. Honestly, I haven't decided if this is a good practice or not, but it works well for the present. The reason why it might not be a good idea for long term storage is that it forces package paths and class/function names to be permanent. The way pickling works is it stores the things it needs to know to rebuild an object. If you change the path to the class, or change the name of the class, it wont be able to rebuild. 
Easily save and load [common Python data structures](http://docs.python.org/2/library/pickle.html#what-can-be-pickled-and-unpickled) to disk. Usually for when you need to hack out something fast and can't be bothered with or really should have used, but didn't, a proper (or at least sqlite) database.
PyQt is awesome. We used to use wxPython at work, but after we got a new Lead Technical Artist we moved over to PyQt due to how much easier it is to use and the code is much cleaner than the wxPython monolith.
Here are the benefits I see: 1. Web development skills are far more useful in a variety of contexts when compared to a native GUI 2. Web development has a very large body of support 3. It sounded like the original poster was looking for a way to present data to many people. 4. Setting up a web page is fairly trivial with the tools already available. GUI development can be really painful especially when mucking around with the event loops. 5. Finally, the original poster is going to have to learn something. I think with the benefits above, it's a relatively easy choice.... You're, of course, welcome to your opinion. Django has a learning curve, sure. But Django also has a nice community. So if there is a problem learning something, there's probably a solution someone else has already come up with. You can put together a new webpage in about 10 minutes with Django or with Flask without any knowledge at all. I'm not sure there's a real downside. 
I've been using wxPython professionally for 5 years. It's OK but has lots of little bugs and we have a lot of platform-specific code to work around different behaviour on different platforms. I would recommending steering clear of AUI (both the C++ and Python implementations) as it is full of bugs (many of which I have fixed myself) and the code is a disaster.
Thanks a bunch :)
I wrote [two tiny scripts](https://gist.github.com/draganHR/7123534) to convert all my ui and res files.
I have used it for saving the "state" of an application to the disk for recovering later after restarting the application. Basically, periodically I take a snapshot of the main application class and save it as a pickle to a temp folder. When restarting the application, it loads the main application class from the file and is basically able to continue as if the program was never shut down in the first place.
Care to elaborate on your Mongo structures? I'm in the process of rewriting a PHP backend in python and we use Mongo so I'm a little interested in what benefits you get from pickling.
Might want to note that pickling is often a considerable security issue, because a pickle can contain arbitrary python code, and an attacker can use this for code injection attacks.
It seems to be a lot more flexible than json, but it's python specific (I think). Also, why the hell can't json serialise classes?
Just used it recently as a replacement for ConfigParser (Python 2.7), because it doesn't fully support unicode (reading is possible - writing not), multiline entries with spaces at the start (just strips them) and a few other things. Created a dictionary for what I had in the ConfigParser object (which is basically a dict too under the hood) and pickled that dictionary to a file - works perfectly.
Python's standard library uses it for multi-processing. You can use it whenever you need to serialise data and/or transfer it from one program to another. Please note that pickle is insecure and also that changes on the hardware or software stack can break it. You wouldn't use it as a data exchange format or for persistence (saving to disk). This would be really bad. We have JSON or SQLITE for that.
Javascript has no classes, and JSON is meant for data, not code constructs.
I would agree with this. If I get time to expand in my thesis, I'll look into using astropy
Thank you everyone for your input! This is awesome :) I think I'll start out with pyqt! 
True, but it would be nice if python had a simple way to package the class into a list or dictonary. I know about the \_\_dir__ method, but that also packages hidden methods. 
I think it's important to mention that you don't necessarily need to use Qt Designer (at least with C++, but I'm pretty sure it's the same for PyQt). You can write the code for the interface yourself (place labels, buttons, etc. writing code instead of using the drag-and-drop interface that is the Designer).
How would it know what to package? Would you have another class variable that told it what variables to json? You might as well just implement as_dict and use simplejson, though I guess for that you still need a special constructor too.
The *body* is the indented block, but Iâ€™d definitely consider the argument list to be part of the definition as well.
I'll accept that correction! :D (I think I was thinking that *I* am simply getting too heavy and I need to pull a "fitness phoenix")
I use pickling to save the results of time intensive programs mostly. For instance, I made a naive bayes classifier for a class which took about 15 minutes to train with our data. I can pickle that, open it up and use it immediately instead of having to wait and retrain the classifier every time I wanted to use it. 
Thatâ€™s not the vocabulary that one can find in [the Python documentation](http://docs.python.org/reference/compound_stmts.html#function-definitions).
No, it's not. I stole it from C.
In theory, it serializes only data, but since you can also pickle methods and functions (which is necessary to allow for truly arbitrary objects to be pickled), it is possible to craft pickle files that will run Python code when unpickled. People have done it, it's not even obscenely difficult.
Well yeah, but at least it's thematically relevant in /r/learnpython. But your point is well-taken.
Just to make sure nobody does anything stupid: Please **never** load a pickle from an untrusted source (for example user sessions etc). Ever. It's trivial for an attacker to execute arbitrary python. Been drinking, but [this](http://www.cs.jhu.edu/~s/musings/pickle.html) seems like a decent explanation of the problem.
I love subprocess. I have used it to automate a huge amount of my workflow
Warning: The pickle module is not intended to be secure against erroneous or maliciously constructed data. Never unpickle data received from an untrusted or unauthenticated source. [Python 3.3.2 Pickle Docs](http://docs.python.org/3.1/library/pickle.html)
I have watched streams of other people developing and I find it interesting to hear others comment on what they're doing. It gives me an idea of their train of thought. I also like it when I can interact with other developers asking questions or pitching in on what the are developing. This is not like "the scene" series, it is live and I make an effort to interact with whoever comes up on the channel. *Although I have to admit I missed one viewer as the chat was covered by another window*
I use it for saving results/objects from long computations
Sign your pickles, people!
For example if you pickle a sorted dict, the order in which the items are unpickled depends on the order in which they were pickled, which depends on the hashing algorithm, which can vary by platform, OS or interpreter etc. You'd expect both cPython and Jython to read a JSON but what about a pickle? What about pickling on Windows and unpickling on Linux?
A lot of us prefer IRC channels for interactive development. Theres not much a stream can show you coding that copy/paste into chat or a github wouldn't also do. To each their own though. If its something you like to do, don't let anyone stop you. 
It's not like ZODB (although you showed me something new; pretty cool!). Basically, each document represents something that has a personalized workflow. The workflow maintains state and other data, but doesn't have a document representation of its own. So we're pickling the workflow into a field in the document. Eventually, I may "serialize" the workflow into a better, non pickled, representation for the database, but for now it works rather well. Edit: You don't need mongo to store a pickled string. You can use a text field in a SQL database too. Mongo is just what we're using. 
&gt; ooks native on OSX / Windows / Linux. Wx also looks native in my opinion. Qt lets you create MUCH cleaner code though.
And does backporting to Python 2 make that situation better or worse? The solution is to leave the popular libraries behind (as PIL found out) and make them realize they won't be popular anymore unless they move forward. MS didn't get people off of XP by backporting DirectX 11, Office 2013, IE, etc. 
I don't drink, and apparently Python users don't play games or laugh.
I have spent hours (well minutes, but I do this a lot) using sklearn to create a random forest model. Not wanting to repeat the experience, I pickle the object, so I can use it again later without having to learn it again.
Long story short, if you are 100% sure you will un-pickle with the same bytecode that pickled you can use pickle, otherwise use something else like json/xml/bson/protobuf/ASN.1. Slightly longer story: Pickle is good for message-passing when having several python processes, which share byte-code, communicating with each other. Don't use pickle as a general purpose serialize/unserialize format if you care about security. Use it for passing data between processes _you_ control, be it through database, filesystem or IPC.
[**+Guido van Rossum**](https://plus.google.com/115212051037621986145) [_2013-10-23T20:36:33.605Z_](https://plus.google.com/115212051037621986145/posts/YTUxbXYZyfi) &gt; &gt;I was asked on Twitter why Python uses 0-based indexing, with a link to a new (fascinating) post on the subject ([http://exple.tive.org/blarg/2013/10/22/citation-needed/](http://exple.tive.org/blarg/2013/10/22/citation-needed/)). I recall thinking about it a lot, ABC, one of Python's predecessors, used 1-based indexing, while C, the other big influence, used 0-based. My first few programming languages (Algol, Fortran, Pascal) used 1-based or variable-based. I think that one of the issues that helped me decide was slice notation. &gt; &gt;Let's first look at use cases. Probably the most common use cases for slicing are "get the first n items" and "get the next n items starting at i" (the first is a special case of that for i == the first index). It would be nice if both of these could be expressed as without awkward +1 or -1 compensations. &gt; &gt;Using 0-based indexing, half-open intervals, and suitable defaults (as Python ended up having), they are beautiful: a[:n] and a[i:i+n], the former is long for a[0:n]. &gt; &gt;Using 1-based indexing, if you want a[:n] to mean the first n elements, you either have to use closed intervals or you can use a slice notation that uses start and length as the slice parameters. Using half-open intervals just isn't very elegant when combined with 1-based indexing. Using closed intervals, you'd have to write a[i:i+n-1] for the n items starting at i. So perhaps using the slice length would be more elegant with 1-based indexing? Then you could write a[i:n]. And this is in fact what ABC did -- it used a different notation so you could write a@i|n.(See [http://homepages.cwi.nl/~steven/abc/qr.html#EXPRESSIONS](http://homepages.cwi.nl/~steven/abc/qr.html#EXPRESSIONS).) &gt; &gt;But how does the index:length convention work out for other use cases? TBH this is where my memory gets fuzzy, but I think I was swayed by the elegance of half-open intervals. Especially the invariant that when two slices are adjacent, the first slice's end index is the second slice's start index is just too beautiful to ignore. For example, suppose you split a string into three parts at indices i and j -- the parts would be a[:i], a[i:j], and a[j:]. &gt; &gt;So that's why Python uses 0-based indexing.
haha came here thinking this was on /r/culinary ...
I recently discovered the hard way that one should also be a bit careful when using pickling for speed. I have a JSON file of a few tens of thousands of objects each containing arrays that had anywhere from a dozen to a few thousand primitive values in arrays. It seemed fairly natural to pickle the dictionary so that I don't have to incur the JSON parsing overhead for it each time, for speed. Well, I was wrong. Lesson learned: if the object fits a JSON model fairly well then it isn't broke and don't fix it. JSON was faster both reading and writing and could be opened in a text editor (except the default JSON writer for Python didn't put carriage returns in).
Glad they did this -- been waiting to try Bokeh out for ages, but could never figure out how to use it due to the poor documentation. The [Javascript controls](http://bokeh.pydata.org/static/demos/detail/correlation.html) in plots are a godsend. BTW you may need to install from Git in Windows, else you might get an error about a missing CSS file (at least in IPython Notebook).
If it's only plain data you can use JSON and not risk the security or breakage issues with pickle. You also wouldn't have to translate the data between Python's formats and SQLITE's tables.
I am using wxPython for cross platform GUI development. I chose it because it allows you to define the GUI in XML and has a very nice GUI builder named "wxFormBuilder". 
Or install through Anaconda.
Pickling is a bad choice for storing documents since the pickle format can change between python versions and platforms, so your document format won't be cross-platform at all. Pickling is adequate for storing configuration settings but again, it won't preserve settings if a Python update comes along that changes the pickle format. What pickling is really good for, I've found, is different kinds of caches. A pickled file can store a complete representation of the in-memory result of any computation. Cache files are not normally transferred to another computer and users won't be bothered by a missing cache as much as by missing settings and documents. I am using pickled files to cache vertex data after computing it from voxel data stored in a Minecraft saved game.
When I saw a keynote from Continuum on PyData NY, first thing I though was "hopefully we'll have a bokeh update". And here it is! Loved to play with v0.1, can't wait to try the update.
I just started doing the Python course over at codecademy.com last week (I have downtime while I'm at my desk job and figured I would start trying to teach myself something useful/fun since I have the time). I'm just mentioning this to tel you where I am in my python experience: super noob. So take my input for what it is. Anyways, the first thing would be the most obvious: the screen is blurry and it's hard to look at. It strains my eyes and makes things hard to follow. I'd get that figured out first. Aside from the aesthetic issue: it's obvious you know what you're talking about, which is good, but you are kind of hard to follow. You are moving quickly and I feel like you are trying to do too much in too little time. What you are talking about and what you doing on screen are not always the same thing and, if they are, it's not always obvious. You're obviously making these videos for complete beginners, which I commend, but since that is your goal (to be able to teach total Python noobs how to use it) you really need to tailor your videos and the language you use around that. To fix these issues I think it's pretty easy: issue I'd recommend getting organized a little better for your videos. take some time to make a script and then work that script through on the screen. Creating a kind of lesson plan with a specific learning outcomes (today you will learn what a function is, how it is organized, and how it is useful, or something like that) will help you work through that. Also: don't be afraid to make it a little bit longer. I would easily watch a 10-20 minute video if the person presenting it were able to talk me through something new (look at some Photoshop tutorials, those things can be 20-30 minutes regularly) in an effective way. I'm sorry if this sounds critical, but I do hope it's helpful. I would love to watch some videos on Python catered towards the new learner. As someone who is learning on my own, on my own time, at my own pace, it's nice to have things like videos to watch. The online CodeCademy classes are decent, but it's just one piece of a pretty large puzzle and the more information that is out there the better. Keep up the good work, and thanks for taking the time to make a video. I think that you will be able to put out some good stuff with a bit of structure and a solid plan for working through your lessons. I'm looking forward to them.
Perhaps you already know this because you mentioned Python's "default" JSON writer, but you can actually make Python write pretty JSON by feeding giving ain `indent` argument (integer) to the `json` module's `dump` function. `indent=0` just inserts newlines where appropriate; `indent=&lt;some positive integer&gt;` indents by that number of spaces where appropriate.
That's where I installed from and the CSS file was still missing.
I'm surprised he felt the need to justify this.
He's a mathematician at heart. He will explain why he chose to put his left show on first if asked.
**If you are about to ask a question, please consider /r/learnpython**
I noticed there was already a bug report about this a few weeks ago, and the issue was apparently fixed. Guess the Anaconda package is just outdated.
also consider a more descriptive post title
Don't worry; it's in the comments. Guido responded: &gt; Cool, but EWD never even considered the option of start:size. 
Hadn't considered this before, how would you do it? 
Thanks a lot of the for feedback! First off, I'll definitely look to improve my vocabulary. I still need to get used to explaining logic in as simple terms as possible. Loops for example, it seems super straightforward to me, but explaining it to a person that has no prior knowledge of it was actually pretty hard. Secondly, about the quality; the first lesson was recorded using a pretty crappy program. The newer video's SHOULD be better (especially at 720p). Ill look into it though, 1080's always an option. Ill make another couple videos in a few days and make sure to plan a bit more aha. Thanks. 
Dict iteration order is explicitly undefined. If your program expects it to be consistent, then your program is buggy.
That depends on your application, but in general you can get by, but you may have to find a new library. &gt; Do we have all the Python 2.7 tools available in Python 3.3 (self.Python) Not even close.
I'd really like to know why brew is the best tool to do this. I'm against using a tool (brew) to install a tool (python) which will then run another tool (pip) to install tools and libraries from pypi. I do completely agree with discouraging the use of sudo on the system interpreter but I question the necessity to add something like brew to get up and running. OS X is a bsd based operating system which makes it a fairly easy task to just compile your own Python interpreter to which you can install pip and virtualenv on top of. Or you could do something similar to what virtualenv does by using environment variables and/or the sitecustomize to add your own paths to clean virtualenv/pip modules. Don't get me wrong, I think there are places for custom tools such as brew, but Python by itself is not complicated and it just seems like something else that can fail or do something unexpected when updated. **EDIT**: For some background, I work in C++/Python on Win/Mac/Linux but compile everything myself or use network mounted libs. I don't think this is to dissimilar from brew (compile wise on os x) but it gives me consistent control and for simple things I think it's easier. That said, I could be completely wrong without enough exposure to brew so I wouldn't mind the input.
We aren't here to do your homework for you
We are currently using DJANGO and Mongodb backend. with Django-nonrels to support our models. However, this is really backfiring on us. Django isn't built for MONGODB type applications. Mosty they are for relational type systems. I suggest using pymongo or mongoengine to call your mongo. Currently we plan on moving away from django and use flasks or bottle instead for more flexibilty. Sad to say, when I got here it was already implemented this way and in production. And the programmers back then don't know sh!t about mongo. that's why our design is so complicated that no one dares to change a thing about it.
Having to go through 3 steps just to install a package manager is a pain.
Interesting. I also come to Python from having no formal background in programming (law). But because I always used C-based languages (mainly Python, with a brief flirtation with JavaScript when I was a kid and a small bit of C and Java since) 0-based indexing was never an issue for me. In fact, when I started looking at Lua, the 1-based indexing there drove me mad. So I don't think it's about being a programmer as such; plenty of non-programmers like myself are fine with 0-based, and I'm sure there are some serious programmers (like the guys behind Lua or Matlab) who see the sense in 1-based. But *most* people who program probably come from the C family of languages so would be more used to 0-based.
&gt; [Its] setup for multidimensional arrays is terrible. and C's is better?
you actually do start counting with 0 apples. say you have ten apples lined up in a row for counting, how many apples do you have up until the point where you pick up the first one and count it? You may not *announce* that you have 0 apples, but really, that's how many you have.
Look at np.r_
Perhaps I am not understanding, but &gt;&gt;&gt; tenapples = ['apple']*10 &gt;&gt;&gt; tenapples ['apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple'] &gt;&gt;&gt; tenapples[0] 'apple' The 0th apple is an apple.
As Guido said, when you do a lot of work *calculating* indexes, 0-based is much more natural. That's probably something a programmer does more than someone purely interested in statistics.
The thing I like about brew is that I can easily manage the packages that I've installed (remove/upgrade). It might be my inexperience with OS X (I haven't tried mavericks yet) but I don't know of any way to do that easily with a pkg file or self compiled programs.
try thinking it this way 1 == 0 + 1 
Brew simplifies the management of your system. It isn't much more than that, that draws people to Brew. By the way building your own is perfectly fine if a library is critical to your development project. For most of us it is more important to have stable libraries and apps. Look at it this way, why would anybody hand build MacVim, when the package manager can setup a perfectly stable solution by itself. 
not sure how that helps...
[This is a popular way, I think](https://github.com/mitsuhiko/itsdangerous).
At least it's not fucking Visual Basic where both 0 and 1 based indexing are supported, so you never know which indexing method someone's going to use. 
Pickling is commonly used to create security vulnerabilities in software applications. i.e. don't do it. Don't even sign your pickles -- if you get that wrong, your app gets owned. "defense in depth" says to use a hopefully-safe serialization format like JSON, and then sign _that_. (Another security principle: "the principle of least authority": serialization formats don't need the authority to execute arbitrary code. Pickle is fundamentally bad. Don't use it.)
Agree 100% on the namespace thing, it's bad practice and make a lot of assumptions about the environment that this package will be installed into (such as the site setup doing what you expect or even running at all).
I'm actually curious what OP meant. Other than indexing, Fortran's arrays aren't really that much different from other low-level languages. I'm guessing OP was referring to arrays being column major, but that's just a matter of preferring whatever you learn first. Column major ordering has its advantages too (it's closer to the mathematical idea) and its quirks (it means that most people code a matvec incorrectly in Fortran on their first try). With some of the newer features in Fortran, I'd argue that working with multidimensional arrays in Fortran is a lot better than other comparable languages. Of course it isn't as easy as say Python or MATLAB, but it's hardly comparable to those and I personally prefer it to plain C. Arrays in Fortran don't really get awkward until you involve LAPACK... which is so esoteric and difficult to use that I can understand anybody disliking it.
You have a really data object that takes a long time to create and you want to work on stuff that uses the object rather than coming up with an output format to write it out and read it back it. Maybe you have a GUI program running on a local computer and you want to create a save file. The one problem with pickling is that it references the imports, so if paths change, it won't work. If you change functions, no big deal, but imports are a problem.
Most everyone you work with will probably be fairly knowledgeable and do the right thing. A lot of companies though have higher ups that do not understand proper software procedure and only view it as "do things the cheapest way possible." I wouldn't worry too much about your new job, it'll probably be fine. I also know a lot of people in the industry and they enjoy the job a lot. Only thing I will definitely warn you about is be prepared for long hours and a lot of coding. I hope you enjoy the job.
you could always write a def first(thing, n=None): return thing[0 if n is None else (n - 1)] function. I want the first thing = `first(thing)`. I want the 3rd thing = `first(thing, 3)`. xD Although maybe that's just ingraining some bad habits... You could try writing some C. All its loops are numeric, and starting at 0 will become ingrained much faster than you'd find with python as its loops just nicely iterate over iterables.
I raff, I roose
Well, it helps to balance the biased coverage you might get from other media sources. 
This history from C is two reasons: In C arrays are just pointers to the first element, and an access `arr[i]` means add `i*size` (where size is the size of an array element) to `arr` (a pointer in memory), so naturally `arr[0]` points to the same thing as `arr`, the first element in the array. The other options would be silly back in the day for slow computers e.g., always decrement the given index (cost of an operation) before computing an array memory access? Have the array point at the non-existent location before the start of the array (so adding one size gets to the first element)? There's also the [Dijkstra arguments](https://www.cs.utexas.edu/~EWD/transcriptions/EWD08xx/EWD831.html): 1. If want to specify positive integers (e.g., `unsigned int` in C) starting at 0,1,2,3 by two numbers, the lower bound should be inclusive. You don't want to have to do `(-1,4)` or all n such that `-1 &lt; n &lt; 4` as `-1` isn't an `unsigned int`. (E.g., switch from a machine with 16-bit unsigned ints to 32bits then your zero based array is (65535,10) doesn't have 10 numbers but 4 billion numbers). 2. If you want to specify the empty range, would you prefer all n such that `1 â‰¤ n &lt; 1` or `1 â‰¤ n â‰¤ 0`? Dijkstra argued the latter is unnatural and ugly. 3. If you want a set of `N` elements Dijkstra thought that the range `0 â‰¤ i &lt; N` is easier than `1 â‰¤ i &lt; N+1` And then there's Guido's argument for half-open intervals: 1. Breaking a list a into its first `n` elements and the rest should be like `a[:n]` (first n elements) and `a[n:]`(rest of elements). The only way to do this naturally with one consistent slice notation is zero based index and half-open interval. Granted that's basically Dijkstra's third point.
About Mongo: why are you using it ?
I actually liked that feature, and it's as easy as looking for the "option base" statement to see what's going on. It's particularly handy when you're trying to use Visual Basic with libraries built in other languages. If the library uses 0-based, no problem. If the library uses 1-based, still no problem.
Yeah...except with modern fortran especially, setup for multidimensional arrays are much better than C and Java from what I remember. It's not that great in numpy either. I don't like matlab as a language but it's array notation is very convenient.
Then it seems like you're counting intervals between apples but not apples themselves. When I count one, two, three apples and so on, I'm counting the apples.
If you make the reddit bot stop reading Google+, nobody will. But on a serious note, that but just copy pasted OP's message. It's just extra spam. :(
I'm not familiar with Fortran's. C's makes sense if you realize it's a memory offset. Similar concept to tiles in games.
Curious if for work you've used any of: [Pandas](http://pandas.pydata.org/index.html) , [Scikit-learn](http://scikit-learn.org/stable/) or [statsmodels](http://statsmodels.sourceforge.net/)
How often do you use indexing in python, though? I just did a quick grep of my personal project's directory and I only used indexing twice... literally.
no, the 0th is nothing. the apple with index 0, i.e. the apple starting after the 0th is tenapples[0] think of real numbers: at index 0.3 of tenapples, you are inside the first one, and have 9.7 in front of you. at index 1, there is one apple behind you and 9 before you, and youâ€™re at the start of the second. so index 1, length 1 = second apple.
[The article referenced in his first sentence is amazing](http://exple.tive.org/blarg/2013/10/22/citation-needed/), and well worth the read. To wit: &gt; ...because if the job didnâ€™t finish fast it might not finish at all and you never know when youâ€™re getting bumped off the hardware because the President of IBM just called and fuck your thesis, itâ€™s yacht-racing time.
In that case (and I mean this is the kindest, most helpful way possible), you're quite probably doing things incorrectly. [Here](http://nedbatchelder.com/text/iter.html) is a pretty good pycon video all about looping and iteration. That covers looping, but otherwise you should probably use list/tuple unpacking, argument unpacking, and pop/append methods. Direct indexing really should be an exception rather than a rule.
(Don't have mac but Perhaps support for colors, tab completion, fonts, history?) On windows I really was missing linux terminals, until I got ConEmu2 configured, or even just bash-git for the binaries and color support.
A nice thing about using partial vs using something custom is that you save a stack frame and thus tracebacks look like the partial never happened. Also, since partial it's actually a class, you can even inherit from it :-)
You need to think of "complete apples" -- how many complete apples have I gone past. If your arrow points at an apple, you're pointing at half an apple. Disclaimer: I wrote the above in all seriousness, but I know how ridiculous it is.
Yeah, it did. It should work with setuptools and You should probably use it instead. The version of distribute that it downloads is just a legacy wrapper around setuptools (https://pypi.python.org/pypi/distribute/0.7.3). I was using it for long time and it always worked.
FTFY &gt; Having to go through 3 steps just to install a package manager is a pain. /s
Tried messing with it in the past, but the plugin website was hard to use.
well done.
I am surprised that Guido is still using G+ after quitting Google.
signal processing? for statisticians using a lot of linear algebra, 1-indexing is their idiom.
&gt; I don't know why you were downvoted Meh, comes with the territory =) TBH though, It's not just about style and making things pretty. It's also about eliminating bugs and making things efficient. Clearly indexing is meant to be used casually since it exists in the language, but I think you'll get a lot more out of the language if you avoid it as much as comfortably possible. Anyway, glad you appreciate my unsolicited advice!
1-indexing is what they use in maths papers, I accept. My PhD was in signal processing though, and I still found that indexes always needed an off-by-one adjustment in MATLAB code. I'm simply saying, I've used 1-based and I've used 0-based, and 0-based always seems to end up with fewer fudges needed.
 def first(thing, n=1): return thing[n - 1]
&gt;It leaves the major use case for indexing as being slicing, which is exactly where the 0-based approach makes much more sense than ordinals. Exactly. I couldn't have said it better myself. In fact, I'd like to revise my original statement to say that I draw a distinction between slicing and indexing in the traditional sense (e.g.: `my_list[3]`). &gt;there are cases where you do want random access Yes, hence my wording. Indexing should be exceptional.
&gt; because Matlab sucks on so many levels I'm curious why you would say that. I've been doing stuff in Octave (which is basically a free clone of Matlab) recently and found it actually quite nice. When doing a lot of stuff with matrices, having direct syntactic support for many operations on them was very convenient.
I implement a lot of statistical algorithms and find it the other way around...
&gt; sorted dict I believe it's called OrderedDict?
Can you turn it on now ? :)
This is also what Ubuntu wants to achieve: https://wiki.ubuntu.com/Python/3
I had read the exple.tive.org article, but just didn't think the author's distinction mattered. He made the pedantic point that it's not due to C since BCPL didn't have pointer arithmetic like in C and used zero indexed arrays first. Instead, he argues in many paragraphs that BCPL had "address arithmetic" which is a totally different concept, except being identical to pointer arithmetic in all the ways relevant to the discussion for why indexing starts with zero (the only difference is its simpler -- only one size of typeless data element): p and p+0 both point to the start of an array. &gt;As for BCPL and C subscripts starting at zero. BCPL was essentially designed as typeless language close to machine code. Just as in machine code registers are typically all the same size and contain values that represent almost anything, such as integers, machine addresses, truth values, characters, etc. BCPL has typeless variables just like machine registers capable of representing anything. If a BCPL variable represents a pointer, it points to one or more consecutive words of memory. These words are the same size as BCPL variables. Just as machine code allows address arithmetic so does BCPL, so if p is a pointer p+1 is a pointer to the next word after the one p points to. Naturally p+0 has the same value as p. My view is that the history of C matters more as C is the language that lives on, pointers are the analogous to "address arithmetic". C didn't just steal BCPL's convention for kicks, it did it because that's the convention that makes sense in terms of machine level instructions back in the day where you worried extraneous decrement instructions. EDIT: Grammar.
It was so many years ago when Arch Linux switched that I can not even remember when exactly.
But EWD did essentially make GvR's point when starting from the first element; that is `a[:n]` makes more sense than `a[:n+1]` to take first n elements. &gt;When dealing with a sequence of length N, the elements of which we wish to distinguish by subscript, the next vexing question is what subscript value to assign to its starting element. Adhering to convention a) yields, when starting with subscript 1, the subscript range 1 â‰¤ i &lt; N+1; starting with 0, however, gives the nicer range 0 â‰¤ i &lt; N. So let us let our ordinals start at zero: an element's ordinal (subscript) equals the number of elements preceding it in the sequence. And the moral of the story is that we had better regard â€”after all those centuries!â€” zero as a most natural number. Yes, GvR said: &gt; Cool, but EWD never even considered the option of start:size. which is something that Dijkstra never specifically mentioned (as did python). But obviously both would get in the way [start:start+size].
I'll chime in with "interesting" behaviors that have caused me pain: You can't mix integer types in math operations &gt;&gt; int16(1) * int32(1); % Is an error No native "complex" type, it's just a weak property of an array &gt;&gt; A = complex(1,0); &gt;&gt; isreal(A); % false &gt;&gt; B = A(:); &gt;&gt; isreal(B); % true It's impossible to chain indexing. I believe my use-case was extracting a string from a cell array, then indexing into the string. The parser just falls over with an error. &gt;&gt; A = {'foo', 'bar'}; &gt;&gt; A{1}(1); % Error Similarly, if foo() is a function that returns an array, you can't do &gt;&gt; B = foo()(3); Because MATLAB servers a very specific niche, it's lacking a bunch of features that general-purpose languages like Python have. Specific annoyances are sockets (pay for the (slow) instrument control toolbox or use Java (slightly less slow)), XML (use java), and a unit-testing framework (new in 2013). On the other hand, the native array support means that some loops can be eliminated by just passing an array. I think the experience is probably good for people using it as a numerical language. The story is more mixed for those who need a general programming language. Edit: Fixed the return values in the complex example (thanks roerd)
http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2013-5942 Yes good example. The problem of pickle is: 1) compatibility 2) security 
At least they appear to be choosing the sane route by not calling python 3 /usr/bin/python
It depends on your attention span, really. If you want to launch straight into coding, you could try some project Euler problems, or maybe do something of your own design. If you want to get a more solid foundation on coding in general (which is not what codeacademy is about), I'd suggest Learn Python the Hard Way from the sidebar. It's really a general beginning programming book which happens to be in python.
what next? apply what you have learned to enhance your life. 
Yeah, sorry, I misunderstood your complaint. Your main issue is with the lack of inclusion of the endpoint, and np.r_ doesn't fix that. My bad. It is ugly but I'll usually do np.r_[0:N] + 1 to get the same result as 1:N.
Would I be able to use Python and Gimp to output a matrix of every pixel value and location from a picture? just curious...it's a project I'm working on.
I found the [news announcement](https://www.archlinux.org/news/python-is-now-python-3/). Exact date was 18th October 2010, over 3 years ago.
Ah, yes you're right. The reason is the same. But I guess the author makes a fair point, that the "decision" had been made before C existed.
About time... People need to stop using deprecated software and move on. 
We totally are. *highfive*
I use the following pattern in my hacks with db's a lot: if 1: conn = open_db_connection() with conn as c: c.execute('select * from some_ridiculously_complicated_query') rows = c.fetchall() pickle.dump(rows,open(filename,'w')) else: rows = pickle.load(open(filename,'r')) do_something_with_rows(rows)
Number 6, reporting.
What's the problem with `/usr/bin/python`?
$PYTHONPATH
Number 11 here, what's going on?
Arch user here, and my /usr/bin/python is python3. A decent number of configure and install scripts assume that /usr/bin/python is python2, and on several occasions I've had to mess with the symlink to get it to work. Edit: also shebangs in general tend to point to /usr/bin/python unless the script writer had foresight and an explicit python2 symlink.
That works like a charm! I remember googling for it some time ago and most of the solutions on the internet did not work.
One could argue that the scripts are broken. They should be using python2 instead of python. It's like using bash syntax and putting #!/bin/sh in a script. And it's not like Python 3 is super new. A distro has to pick one python to be the canonical one, might as well be the one that's getting future development.
just use virtualenvwrapper to create a python2 virtual env... quite easy and you don't have to mess around with symlinks in your system.
I wasn't complaining about the bot, I was hoping for a facebook bot to copy paste facebook posts so that I don't have to deal with facebook's actively hostile scripts.
Except that /usr/bin/python has ALWAYS been python 1/2, and python 2.x is backwards compatible with 1.x. Python 3.x is obviously not backwards compatible, and thus should use a different executable name.
Thanks for the bug report! FWIW, we removed the Anaconda/Anaconda CE split a long time ago. You should grab the latest Anaconda - it's got a much better package update system (conda), and this is now the base distribution moving forward. http://continuum.io/anaconda
even I am in the same position, i'd really like to learn django. what can i do about it
Oh yeah, I agree. I think Fortran is pretty graceful with arrays, especially with the convenience of having allocatable arrays, which you can achieve in say C, but it's way more awkward. And I'm with you on MATLAB too, it really wasn't ever designed to be a full programming language, but the notation for array operations is really convenient. Especially for operations like transpose, matrix multiplication etc. I've said it before, but modern Fortran is a pretty nice language as long as you are using it for what it's intended to do. If you are crunching numbers, it's very nice. If you are doing pretty much anything else, it's really bad.
So make sure you have correct symlinks for /usr/bin/python{,2,3} Do it by hand, if necessary. Not the most ideal situation, but it works. 
*just in time for python 4*
As a fairly new python programmer, I don't get the foot-dragging and agonizing over the upgrade. I mean I get it in that I've read and understand the reasons for the rift, but it's not like 3 is going away. Update your code for the new version and be done with it. But the way it is, anyone trying to learn the language has to learn two different ways because a lot of package devs won't upgrade or haven't yet, so we can't use their API in 3.x and have to maintain installations of both a 2 and 3. Deprecate 2.x and let it die, I say.
Whoah, python2 is deprecated? I prefer python3, but didn't hear about python2 being deprecated. Is there a post about this somewhere?
Depending on the package, it can be quite a lot of work to move a codebase from 2 to 3, especially if you're dealing with complex bytes/unicode boundaries.
Not officially... But the only reason people use it is because developers are too lazy to port their existing software to python 3. 
It's ridiculously straightforward if you are used to messing around with pickle: import os, pickle class Unsafe: def __reduce__(self): return os.system, ("echo 'I am a system call'",) unsafe = Unsafe() unsafe_pickle = pickle.dumps(unsafe) del Unsafe, unsafe, os # just to show we are not relying on anything being # defined in the environment where the pickle is loaded pickle.loads(unsafe_pickle) # executes the system call
The problem with this is that "python2" does not *always* exist on other distros. It is "python2.6" or "python2.7" or just "python".
And I understand it's not like snapping fingers and it magically happens, but it only has to be done once.
There's only one way. Start building things in Django. When you don't know how to do something, read documentation and StackOverflow questions until you find the answer. The only real way to learn to code is to code. You can read about an algorithm unitl your eyes bleed, but until you've implemented it yourself, you can't really understand it.
Many times it's not a matter of your code, but of a dependency that you have. For example, you have a codebase that relies on Twisted. Twisted is a huge framework that is very popular. You have thousands of man hours invested in basing your product around this. You want to move to Python 3 and that's great, but there's just one problem. Twisted doesn't yet support Python 3. It's not that the project is dead or that they are dragging their feet. It's that the project is huge and there are tons of [high profile users](http://twistedmatrix.com/trac/wiki/SuccessStories) like LucasFilm and LaunchPad and NASA using it. You don't want to leave them stranded, so you have to plan for a gradual migration. Change over pieces at a time and add backwards-compatible APIs so that they can take their time to migrate their code. The problem is one of momentum. It's much like the Perl 5/6 problem (though in their case, they don't have a GA release of Perl 6). Too much high quality code got into very mainstream use at a time when the language was a bit immature. The language developers want to grow the language and that means breaking backwards compatibility. In the case of Java, they choose to go the very long and slow route. They add new functionality, make it secondary, encourage it's use over the deprecated method and eventually start issuing warnings when the deprecated API is used. But that takes a very long time. There are deprecated APIs in Java from version 1.3 that they are still trying to rid themselves of. For Python, they decided that a clean break was necessary and to maintain two code bases going forward. They have a drop-dead date for the older code base and continue to add alluring features to the new version. Now they just need to give the community time to port all of this high quality, high profile code to the new version. They knew it would end up like this. tl;dr - Sometimes you use libraries that aren't yet compatible with Python 3.
&gt; But the only reason people use it is because developers are too lazy to port their existing software to python 3. on behalf of all working developers, and especially those who make their code available to humantiy no strings attached, I'd like to send you a mighty "Fuck You" 
yay 2 years after arch did all the work
Are you on windows? Did you install ipython or something similar? If so, then this is very likely a $PYTHONPATH issue where libraries are being installed and linked to one interpreter but not the other. IRC may be more helpful than /r/python.
Yup, it would be pretty simple. If you get the `Layer` you can call `layer.get_pixel(x, y)` to get the color of the pixel at that location. 
 #!/usr/bin/env python2 or #!/usr/bin/env python3 At least that works on *buntus. 
&gt; Update your code for the new version and be done with it. Upstream libraries You're welcome to contribute: http://twistedmatrix.com/trac/milestone/Python-3.x &gt; Make Twisted completely compatible with a reasonable Python 3.x release ... 59% complete.
It works with all CPython installs.
well that was helpful
related: Why does random.randint (x, y) return values from x to y and not x to y-1?
the comment i was replying to was some flask fan boys assesment of pyramid and the differences. the content of it clearly demonstrated that they had no idea what they were talking about and were merely regurgitating what they read on reddit. thus, every assertion could be responded to with my above helpful comment. one such assertion, IIRC was that pyramid was fullstack like django and flask was more micro. more helpful? 
I am not working on windows, I am in OSX 10.9, and the build environment for sublime text runs it in terminal, which is the interpreter I am using in interactive mode
2to3 is not magic pixie dust. If you use the ABCs in `collections`, 2to3 will not convert/split the import into `collections.abc`. I'm sure there are other issues.
Yup, that's pretty much it. And the resulting pickle can be injected into about anything that gets unpickled.
Disgusting... Enjoy keeping humanity back in software. There's a reason freetard software isn't dominant in the market.
My interest is evolution so i'd say things in that area but they do a lot of good optimisation things that I don't really know about
Yes, there are alternatives to playing with symlinks, however it's still an unnecessary pain to deal with.
I agree with you 100%, but we're in the minority. Guido and company made the mistake of being too nice and helpful (sad that can be a mistake, but some people take advantage of it). People decided all these backports, continued 2.x development, etc. meant that they could just never leave Python 2. And as one Python library maintainer said to me, "Why should we port to Python 3 when Python 2 is going to be supported FOREVER?" Then that holds people back, which holds libraries back, and the cycle continues. Python 3 is the way forward. Someday, you're going to need to upgrade. And that version you upgrade to is going to be 3.x based - or worse. A version is the future is never going to be more similar to 2.7, just more different. Additionally, the more code you write in the meantime, the larger the job as well. Therefore, the least amount of effort comes from porting today - right now. And if it doesn't support library X? STOP USING LIBRARY X. Or at least fork library X like they did with PIL. Either way, you're stopping the use of something - either the library or the current (and every future) version of Python. Given those alternatives, better to kick the library to the curb or convert it or use Cython to get it to work with Python 3. Sitting around waiting isn't going to make things better - see above.
you could try edx introduction to computer science and programming. Its an MIT course with python as the programming language. They're by the second week. Its a really good course really fast paced and very challenging. https://www.edx.org/course/mit/6-00-1x/introduction-computer-science/1122
The annoying thing about twisted specifically is that it has (had?) a lot of old code that doesn't meet the current contribution requirements (e.g. poor test coverage). I was going to help with the Python 3 effort a year or two back but I didn't want to spend time writing tests that didn't already have them, just so I could make tiny syntax tweaks. Also since it's an IO-heavy framework it has a disproportionately high impact from the Python 3 changes.
Did you check Udacity Intro to Computer Sci out? Their interface blows Coursera away IMO.
I know you are just trolling, but I'm actually surprised by how widespread arch is - for what it is. It strikes a really nice balance between giving you a ton of power and customisation, and also providing the stuff you want so you can use your system easily enough. Most of the power-users I know run Arch. It's just a good OS.
Yes, but given that it is now defined in a PEP, it's the standard way for Unix systems to work with Python scripts. (Windows has the `py` launcher program).
The problem there is the distro/package maintainer - [PEP 394](http://www.python.org/dev/peps/pep-0394/) tells package maintainers exactly how the commands should be set up.
I agree that Udacity's UI is the best of the MOOC so far
I've partially done the Coursera/Rice course and and now have started on this ED-X/MIT course. I have to say I'm digging the ED-X/MIT more as of right now, but it's only week 2.
It isn't even magic pixie shit.
they are good if you want to learn Computer Science using Python, but not so much for those who only want to dip their feet in programming for the first time as they move quickly from subject to another, especially the MIT course (I spent last summer learning Python from MIT and another paid service). However, Prof. John Guttag &amp; Prof. Eric Grimson are doing really good job, and try their best to make the course fun and engaging. It all turned out good now. Python is fun and easy to learn. **Edit**: There is a decent book that could be used with MIT course by Prof. John called "Introduction to Computation and Programming Using Python".
&gt; It's cheaper to simply maintain a working 2.7 build than to spend time &gt;porting to 3 No, because you're going to have to port sooner or later and the later you do so, the more work will need to be done. 
&gt; One could argue that the scripts are broken. If this were kernel related, Linus would [eat you alive](https://lkml.org/lkml/2012/12/23/75) for saying that. :)
I'm fairly sure the PEP is far newer than the distros that a lot of people are running on production servers. IIRC, the PEP was a result of Arch's original decision to point `/usr/bin/python` at Python 3.
I am sure that [pycrumbs](https://github.com/kirang89/pycrumbs) will keep you occupied for a long time :)
I hope someday to be skilled enough to help out. Judging by the age of some of the tickets, I will probably have that opportunity.
Either the interpreter is different or the environment is different, hence why everyone is saying "look at the $PYTHONPATH environment variable.
My current openSUSE: python -&gt; python2.7 python2 -&gt; python2.7 python2.7 python3 -&gt; python3.3 python3.3 python3.3m
* It's hard to read - iterating by index in Python is clunky (because Python is designed around iterating by iterator). * It's slower, as again, Python is optimised for iterating by iterator. * It means that your code only works with sequences, not iterators, making your code less flexible and useful. * It means you are more likely to get cryptic IndexErrors rather than more specific errors. * It will generally take more code to express the same things. * For some tasks (like iterating over two lists at the same time), it produces far more awkward edge-cases and awkward behaviour - doing it with iterators (`zip()` in that case) makes the operations well defined. In general - Python has a powerful and readable `for` loop that works with iterators - why try and side-step that and do what you want in a worse way?
Did you use cPickle?
Gentoo as well! I think it's a bit more recent than for Arch though.
I disagree. I think udacity has the worst interface. You can't download videos (like with most coursera/udacity), videos auto-play, can't just read homework problem (but have someone slowly read the text to you like you are illiterate, then be forced to watch a video of the solution), doesn't clearly separate out homeworks/quizzes/exams/ungraded in-class questions. Oh, and its nearly impossible to navigate. Granted maybe the udacity interface plays better on netbooks, and the edx plays better on people with large monitors. I'd say coursera &gt; edx &gt; udacity, except that edx discussion forums are pretty bad UI wise. 
I went through all the lectures and recitations for the Core Elements of Programming at MIT Opencourseware site: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00sc-introduction-to-computer-science-and-programming-spring-2011/unit-1/lecture-2-core-elements-of-a-program/ And I am currently 10 lectures into this class: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/ For me the pace of a classroom is too slow. I enjoy being able to digest a few weeks in a few days and I also enjoy doing without testing or false validation and instead just code and create projects on my own. Within a year I am developing with Django, Flask, integrating Jenkins, API's, and much much more. The lecturers are great and all the lessons are in Python. Before watching these lectures my only programming experience was javascripting / coffeescript. Best of luck anyway you go! Python rocks! Edit: As Yazeed92 pointed out for the MIT class, Prof. John Guttag and Grimson are also the lecturers in the Introduction class above. My assumption is that the material is probably the same as well. Just a class pace vs. self paced learning.
&gt;anyone trying to learn the language has to learn two different ways By your own argument, just use only the newest version: &gt;Update your code for the new version and be done with it (you see the problem?)
Interesting as it's different. In usage it looks like XML-RPC or SOAP. But some RESTish stuff that's hard to identify (as URLs are hidden) underneath. Puts requirements on the models. I need to think about this a bit more. 
This is the canonical way of writing portable scripts.
I am assuming you mean the word 'canonical' and not the [homonymously named company](http://www.canonical.com/).
same could be said about gentoo so many years ago i've yet to meet anyone IRL that uses arch *professionally* much less *deploys* to it. I'd be happy to see hard evidence.
This is actually the right way to do it. /usr/bin/env python is cross platform where /usr/bin/python is not.
I don't understand why? For viewers that don't have a readability client?
You're right, Debian only very recently introduced a python2 symlink
Only Debian, Ubuntu has that symlink for a long time
OP can't count, nothing interesting.
first time on reddit?
Still, it means it's not universally supported yet, which means it's hard as the author of a script.
answer: use random.randrange(x, y)
learn both? we use no python 3 at all! The problem is products built around python 32 and dependencies.
Actually related to this question since I have finished codeacademy and am now taking MIT's 6.00.1x course. If I want to start contributing to open source projects does anyone have any they would recommend that are friendly to newer Python programmers? The projects I have looked at so far I feel like I would be more of a hindrance than help contributing towards.
&gt; No, because you're going to have to port sooner or later and the later you do so, the more work will need to be done. If you port now, you have to port all of your code plus all of the code for all of your 2.x dependencies. If you wait til later all of your dependencies might already be ported and you only have to port your own code. 
Of course there are other issues. It's just that a shebang with python2 is almost certainly wrong in a python3 script. My only contribution to the python project was a (really simple) patch to 2to3. I think I'll attempt this and see if I can get another in.
And that probably was not a good thing. The first couple of Python 3 releases were *not* production-ready and were *not* meant to be, particularly; they were out there so developers could explore, test and try out the new version of the language. Python 3.0 and 3.1 would not have been good to do any sort of production software on; 3.2 was a bit better, and 3.3 is the first one I personally feel is really *there* in terms of being a deployment target. But if the date listed below is correct, Arch switched at 3.1. Which would be a frankly rather silly case of shipping new (but not good) things for the sake of shipping new things.
The software market? How can you justify using a deprecated version to start or continue developing and amending projects? You might as well go back to FORTRAN
Left or right?
If you want to serve multiple sites from 1 raspberry pi you could use nginx and uwsgi in emperor mode. The [instructions on this blog](http://tghw.com/blog/multiple-django-and-flask-sites-with-nginx-and-uwsgi-emperor) should give you a good idea how to get started. To serve multiple you would just need to put the flask or django apps on the server, add another uwsgi config files for each flask or django app and change the nginx config to redirect to each site. EG change location / { include uwsgi_params; uwsgi_pass unix:/var/www/run/flaskapp.sock; } to location /student_1 { include uwsgi_params; uwsgi_param SCRIPT_NAME /student_1; uwsgi_modifier1 30; uwsgi_pass unix:/var/www/run/flaskapp_1.sock; } location /student_2 { include uwsgi_params; uwsgi_param SCRIPT_NAME /student_2; uwsgi_modifier1 30; uwsgi_pass unix:/var/www/run/flaskapp_2.sock; }
&gt; The software market? which one? and who is dominant? &gt; How can you justify using a deprecated version to start or continue developing and amending projects? it's really easy actually. they pay me, and they dont want to spend the $$ porting because that wouldnt be a good businees decision for them.
Hence the lack of capitalization on the word. Otherwise he would have written "the Canonical way"
They didn't drop python 2 then, or force you to install python 3. They simply changed a convention in preparation for the future. One of Arch's primary goals is to be cutting edge in terms of software available, and in the ideal configuration for said software.
I hate to say it but RedHat is dragging its feet here. Python 3 should be the default in the next Fedora release. If you can't do it don't bother with a release. 
I assumed as much but due to the context I thought that I would ask for clarification. Some people make capitalization errors, especially if English is not their native language.
So? Really that is no excuse, Python 3 was more than ready at the 3.2 stage. The Fedora team should have started the conversion process then, by the time 3.3 arrived they would have been able to make the development mainstream in the next Fedora release. Instead we have the Fedora team acting like a bunch of frightened woman at a natural disaster. The reality is the state of Python is pathetic in Fedora. Interesting aside, my iPad automatically capitalizes Fedora. Apple must have a few Linux champions in its work force. 
Here is a page describing the differences between 2 and 3: http://docs.python.org/3/whatsnew/3.0.html One of the main reasons people are still using 2.x so much is that some of the third party libraries they use haven't been updated to be compatible with python 3.x. Another reason is probably that it takes time to learn the differences and update your own code to be compatible. I personally do a lot of scientific coding and require some older libraries that only work with 2.x.
These questions come up several times a month and one of the best answers I've seen to almost all of them is to take a look at the sidebar. To be more specific, they are usually referring to this link: https://wiki.python.org/moin/Python2orPython3 Does that page answer your questions?
Python 3 deliberately broke backwards compatibility in order to fix what the language creator thought were mistakes in the language. The result is that some Python 2 code may need to be substantially rewritten in order to run in a Python 3 interpreter. Some third party libraries and frameworks have been slow to port their code to Python 3. Also read [this](https://wiki.python.org/moin/Python2orPython3)
What do you mean professionally? I use it in my virtualbox at work and use it on my notebook to develop. Of course, at some point, I'll test things on Ubuntu as well (desktop) and I'll work mainly on win7 (dualbooted everywhere).
The only way you can support both Python 2 and Python 3 with the same code base and the same level of optimization (if you care; e.g. iteritems) is to use your own script. 2to3 is a porting tool, not a maintenance tool.
There are still a few really popular libraries that haven't been updated to 3.x yet.
What do you need this for? Homework maybe?
I for one am very happy with the transition to Python3. It has happened very slowly, and that's ok.
are you replying to every comment I've made today? lol and why are you bothering participating in a thread of a comment that is at -20 right now? Anyway, I don't know you, and I didnt say no one uses it. I said I haven't met anyone IRL that uses it for work(that's what professionally means) or deploys to it (meaning an app running in a data center on arch, presumably that is making some company $$) so spare me, because one comment or 20 downvotes does not prove the popularity of an OS. 
Thank god someone brought a little misogyny to the conversation.
Frankly, there is NEVER a good reason to use pickle. Its original purpose is to serialize an object so it can be stored elsewhere (say, in a disk file) so you can retrieve it later. But it has numerous downsides and no upside except "dead simple". As is pointed out elsewhere, you can't use it if there's any possibility that an attacker can change the pickle - because it lets you run arbitrary code. And it's not particularly fast, as someone else points out. And it's not particularly compact either. But, worse, it isn't guaranteed to be forward compatible between Python versions - heck, it's not even guaranteed to be forward compatible between minor versions e.g. 2.7.4 vs 2.7.5 - though in practice I believe it has been forward compatible each time. And since you can't just open the file with a text editor and read what's in there, it's annoying to debug issues. Use JSON for your serialization needs - simple, secure, reasonably compact, reasonably fast, and you can read and edit the files with a text editor. Or something more sophisticated - but whatever you do, avoid pickle.
Thank you for this!
Really? Fedora was on Python 2? That's almost, but not quite, as autistic as the people who wear fedoras.
Uh... bash is almost completely backwards compatible with /bin/sh.
because google plus is one of the most annoying sites to visit?
I've always held the firm belief that any computer science or arithmetic that can't be explained in apples is "too much magic" 
Mac in particular, unfortunately.
Yes, I remember my friend going through extensive trouble to get a particular script to work; what the script was eludes me now.
I agree with you completely. Udacity has the worst.ui.ever. The old Udacity was better but for some reason they went completely crazy with the re-design. It's really hard to track progress.
I feel like this comment needs to be enshrined somewhere, it's too hilariously....ironic? I guess? to not be.
So it's all about the money...
Awesome! I really hope this takes off.
ok, now you are boring. 
And thank you for bringing religion into it. 
`np.r_[0:N]` is interesting, but I usually do `np.arange(0,N)+1` or `np.arange(1,N+1)`. It's not such a pain in the ass, but I do it often enough that the extra syntax adds up and I don't want to define it in every script. And logically, none of those solutions makes as much sense as `1:N`. 
Right, it's a domain-specific language in a way, even though it is actually a very general language. I've heard its new (modern Fortran's) string functions are quite powerful, but still not the tool for heavy string processing.
I believe there is a pure python implementation of `partial` in Colin Winters' `functional` module.
One reason that someone might consider starting with 2.x is that nearly all of the tutorials &amp; code snippets you find on the web are written with 2.x in mind. So if something doesn't seem to work, a beginner isn't left with the extra step of determining on their own if it's a python version incompatibility. I would run on 2.x, but try hard for 3.x compatibility. 
aww yiss
Real example: pickles created by Python 2 cannot be safely unpickled by Python 3. There are some examples at https://pypi.python.org/pypi/zodbpickle 
&gt; You wouldn't use it as a data exchange format or for persistence (saving to disk). ZODB, the venerable NoSQL Python object database used by Zope/Plone, is based on pickles. This is going to make the Python 3 transition really interesting.
Some apps will break if you format your main drive as case sensitive. What I usually do is create a case-sensitive sparse disk image and mount that. Alternately, you can just use a second hard drive. [man hdiutil](https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/hdiutil.1.html)
I've found nginx + gunicorn to be very straightforward. I've written a step-by-step guide as a chapter in a book I'm writing. You probably won't be interested in the testing stuff, but it does show how to configure nginx, how it forwards to ports, how to configure gunicorn, how to make it start-on-boot with upstart, how to use unix sockets for each web app, instead of ports... http://chimera.labs.oreilly.com/books/1234000000754/ch08.html hope it helps!
Thank you. Much appreciated
Ha. I see what you did there.
no, I don't really look at usernames. You were unlucky. I post in a -20 comment because I try to look at everything (who says the majority is right?). I don't care about the popularity, I was disputing perception of archlinux and that it somehow was hard to use at work. The thing is, many work environments will favor something stable as opposed to bleeding edge. Which would leave arch out. spare yourself. Those were never my arguments. I just provided my own experience.
For the lazy: /r/ipython --- I provide direct links to lesser known subs mentionned in the title if one isn't provided. Let me know if I need to try harder: /r/LazyLinkerBot
You know, I was just looking for something like this. ..
Have you checked out [OpenHatch](http://openhatch.org) ?
There's also the [Python Challenge](http://www.pythonchallenge.com/), a series of puzzles that you use Python to solve.
The same way you collaborate in any other language - you use a vcs. Git with github is the most popular choice. They have their own introductory guides, and there are hundreds (if not thousands) of others on the web. You can also look at the resources in /r/git .
There a ton of tutorials you can look up on youtube when it comes to making a game in python. Or you can use the steps from another language and replicate them in Python if you dare to do so as well. There is also a pygame book that you can buy. It helps with the basics, and establishes some basic framework for games like pong, and I think the final project is something along the lines of a arcade shooter. If you are looking to collaborate on a project, I've been thinking of doing the same thing. If you like to get in touch, we can probably start with the basic games like the ones mentioned in the tutorial and then expand on it...baby steps... I also just re-read your post, and if you are specifically asking about how to share codes, then yea, git is the way to go.
Thanks for the feedback. &gt; How would I provide REST access to a SQLAlchemy database with this? You would have to implement [up to 4 methods](http://www.cosmic-api.com/docs/cosmic/python/latest/guide.html#rest-via-models) for each model to glue it to a database. A Cosmic.py/SQLAlchemy plugin can be made to make this easier. &gt; I think LibSaas does a good job of this. LibSaas looks good! For the sake of simplicity, we are not making our spec flexible enough to describe existing APIs. This means that you won't be able to use big-name APIs with Cosmic. (Not until they port them!)
I'll take a look around, thanks!
rename the file you are working on to not be `nltk.py`
Hey roger_, this has now been fixed in the packages on PyPI and in the conda repo. Please do "conda install bokeh" or "pip install bokeh" to get the latest package, and let us know if you're still having problems.
Jesus christ the comments on that post. These people truly need a hobby.
It is? I just read the article without any trouble, and came away again at the end of it. Seems ideal.
Thanks!
I'm a huge fan of [bitbucket](http://www.bitbucket.org/), but github is great too.
why bitbucket over git? there's a lot of negativity over bitbucket out there in that it copied much of github's interface and functionality. having said that, i like that they allow private repositories so i do use it. a lot. i'd like to know if there is any other reason.
Mostly the private repository thing, but also I prefer mercurial over git, and maybe that's not even an issue any more, there's probably a mercurial plugin to work with github... And yes, git is certainly winning, I know. Doesn't make it better, not even sure it's worse, it's just that I know how to do a lot more with Hg. I've always found myself banging my head less when using it, and the docs always seem to answer 90% of my questions.
i interpreted the OPs question as wanting to extend the models via enabling plugins, which is why I answered the way I did. it's a typical scenario. you build kick ass commercial project that requires an amount of data entry. You guess what fields a user might need. You release, first customer loves it but needs their own fields too to help map things back into their internal processes. So you don't want to put customers customizations into your product code because the next customer doesn't want it. Thus you now need to have some mechanism of extending your models on a customer by customer basis if you want happy customers. edit: as I mentioned above plone can do things like this, the reason is becaue it is built on top of the zope component architecture. pyramid uses the zope component architecture internally and that is one of the things that makes it so damn flexible. but it isn't really exposed as something for a user of the framework to use though the user could build their own on top of it if they wish. though there would still be a significant amount of work to be done after that. CRM's like ACT and salesforce.com do this already(and then some), openerp has similar features. 
This is exactly what I am talking about. The ability to have an amazing base application that a customer can freely ask for modifications on (and pay for) that may not be well suited for ALL the customers. Could be custom fields specific to customer integration, or could be completely new functionality that is unique to their process. Thanks /u/twillis1973 I will look into pyramid some and see if that is road to take! 
Simple: give everyone their own port! ...unless you're teaching over 65535 students. In that case you'll need another IP.
you are welcome but as I said before, pyramid doesn't expose the zca, it is more an implementation detail that most dont need to be concerned with. zope and plone use it more in userland stuff where it would help you achieve what you are trying to do. Though now that I think about it, [substanced](https://github.com/Pylons/substanced) which is built on pyramid and utilizes more zopeisms might be a nice candidate, though I don't think it's "prod" ready, and I hope mcdonc doesn't kill me for even mentioning it or implying pyramid is zope. :)
Good point - just proxy it up with nginx. Just wonder how many python instances can run at the same time on the pi.
At work, my HD is partitioned. The secondary partition is called `www` and case-sensitive. 
Alex, does this help with py.test without coverage?
No, this doesn't affect `py.test` if you're not using coverage (as far as I know).
I don't know if anyone here knows about this but the intro to CS course at UC Berkeley(CS61A) has you build a Logo Interpreter out of python as the last project. I've seen people who have had no programming experience whatsoever build one pretty damn well. 
Thanks for posting. 
It might be a small pet peeve, but I hate infographics like that subway map that don't really convey any useful information. Please allow me to rant for a moment. I mean, are they trying to imply that I should tackle each topic one by one, starting at fundamentals? Is it really necessary to understand ANOVA and the Monte Carlo method before I can do linear regression? Furthermore, what if I don't know anything about one of the nodes? It doesn't tell me how they fit together, nor what each node is. Surely there are better ways to provide an overview of the field.
+1 for pyramid, top notch documentation and great community, plus it's configurator was built to ease extension. Couple pyramid with sqlalchemy and you're all set. Here a video explaining how to make a pyramid extension: http://www.youtube.com/watch?v=VmfWkeUOuYY The guy explains it pretty well.
It's obvious in C because a[n] is mostly^1 syntax sugar for *(a+n). Other languages do the same because of tradition. ^1 I know there are deeper differences between arrays and pointers in C, but you get the point, it's a memory offset.
Python *anything* can do that. That's not a tooling decision. Multitenancy is a pretty basic, low-level requirement for a web framework (although it's on the list of reasons I hate Django), and inheritance is in every OO language.
In 61a projects, a ton of skeleton code is prewritten. Not quite the same thing.
1. The ability to download videos is not UI 2. Auto-play is a pro IMO 3. Their video explanation is helpful when I can't figure something out Otherwise, I agree with your other statements
Having a button to download videos versus having to parse out the mp4 link from the video stream is a missing UI feature. The real way that udacity prevents downloading videos is splitting a 30 minute lecture into 30 videos with 1/3rd of the videos going over answers that you shouldn't see until you've had time to pause and think about the potential answers. I primarily learn for MOOCs either (a) during my commute mostly without internet access (subway), (b) walking my dog, or (c) while exercising. I like to be able to split the lecture part (with a few questions interspersed -- e.g., one brief question every 10 minutes) from the other parts; and that's not possible with how udacity is structured. Giving feedback to problems is helpful. Basically every coursera/edx course does this; its just done with a quick one-sentence text explanation versus a two minute video where you have to watch someone solve the problem you just solved that was just read to you. Udacity assumes that you have one browser window open; which works pretty poorly for classes that reference old problems (and then since each video is identified merely by a dot and there's no PDF slides, or supplementary reading materials, its very time consuming to see where this was last). I like being able to read through the problems at my own pace. I find having a problem read to me, I have to re-play videos several times or get teh answer wrong, because assumptions for the question weren't written down. And [autoplaying videos](http://xkcd.com/1280/) is extremely annoying if you have say 100 tabs open, your web browser restarts (and tries reopening previously opened tabs) and video in several background tabs starts auto-playing.
[Image](http://imgs.xkcd.com/comics/mystery_news.png) **Title:** Mystery News **Alt-text:** If you find and stop the video, but you've--against all odds--gotten curious about the trade summit, just leave the tab opened. It will mysteriously start playing again 30 minutes later! [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=1280#Explanation)
I'm assuming the subreddit will be used for all kinds of numerical/scientific stuff relating to Python, not just statistics... But I'm still glad this exists! :)
why so many requirements... nice to support things like pandas, numpy or whatever; but i *only* want the plotting.
()))()())()()(No)()()(((()()))))
It seems, from a Google, that author Aahz was contracted to write "Effective Python" for Addison Wesley in 2003, but maybe it got canned? You might try emailing Aahz or the publisher. Here's a link: http://www.artima.com/weblogs/viewpost.jsp?thread=4967 
Build the core as a package; then build a base app as having a dependency on that core. As needs arise, build new apps that have dependency on the core plus app-specific features.
Don't have the links at the moment, but check out Idiomatic Python books.
Related: [Lisp as the Maxwellâ€™s equations of software](http://www.michaelnielsen.org/ddi/lisp-as-the-maxwells-equations-of-software/)
Why bother with Nginx? Just have every Python app host itself. Flask, Django, Tornado, etc can all act as their own web servers. That's how you get the best performance out of Tornado anyway. Nginx is only of benefit if you're mixing and matching many different back end systems and it also acts as a fast tool for delivering static assets. However, since this is just a classroom environment there's no point. BTW: in the real world you don't host static assets on Nginx either. You use a CDN :)
This. Don't let old timers bully you into using an old version of the language. Python 3 has been around for five years and isn't going away. Ignore the "this library is only in python2!" argument. Instead, pressure the developers of said library to stop being lazy and port their code.
wxPython is great until you want python3 support. Lol.
I want to apologize for the "bugs" in my examples, they were written from memory without an interpreter. I've edited the above complex example, and the indexing "fun" is below &gt;&gt; foo = @() 1:4; &gt;&gt; foo()(1) ??? Error: ()-indexing must appear last in an index expression. &gt;&gt; bar = @() {'foo', 'bar'}; &gt;&gt; bar(){i}(1) ??? Error: ()-indexing must appear last in an index expression. To some engineers, MATLAB is the only acceptable scripting language, so it gets used for things where it's not a good fit. Moreover, the choice of general-purpose vs special-purpose language changes the environment around your code as much as the code itself. In Python, I can use existing libraries for interacting with data sources, generating printed reports or building a web app. In MATLAB, these things are much more difficult or even impossible. A domain-specific language can be convenient, but it risks your code being trapped on an island. (Credit to William Stein of the SageMath project for this general idea.) 
This is exactly it. And working in the IT industry it shits me when companies use deprecated software from 10 years ago. Fair enough it costs a lot of money for an upgrade but 10 years seriously? It's just as bad as those people who treat XP like a religion and won't upgrade. About time Microsoft announces they pull the plug on security updates for it. In before all the old timers downvote this comment. Wake up, just because it works doesn't mean you should stick with it... there is always room for improvement and if you keep sticking to deprecated software, you're going to make the future generation suffer by having to port your software to something modern. Absolutely disgusting.
I would try using the unittest module. I'm assuming the solutions are all in their own py files and you can import an object or something, or is it set up different than that? Use can use dis to disassemble. Should check out this article for performance analysis: http://www.huyng.com/posts/python-performance-analysis/
Slides available at https://speakerdeck.com/mattcarkci/elements-of-dataflow-and-reactive-programming-systems#
If Raymond Hetinger's [Transforming Code into Beautiful, Idiomatic Python](http://www.youtube.com/watch?v=OSGv2VnC0go) talk were a book, it would be just the kind of material you'd be after.
Raymond Hettinger is an amazing developer and an amazing speaker. If he wrote a book I'd buy it in a second.
I'm too far into python 3.x to even consider switching. Plus, the argument to use 2.x is trivial. I made this thread to try and figure out why someone would use 2.x idealistically, but didn't really find an answer D: 
I recently (today) wrote a [three part tutorial covering the basics of pandas](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/). Doesn't get into machine learning, but should be useful for someone interested in data and python.
Doctests are by design intended to be tests embedded in documentation. Using them outside of that scope is going to be tricky. I suggest using `unittest` instead. From there, I recommend looking at `nose` to run your testing. That being said, `unittest` is for unit testing. To judge a submission I would - depending on how the challenge was designed - generally expect to need '**integration**' or ('acceptance') testing, not 'unit' testing. I'd usually do this by having a wrapper script that calls the submitted code and inspects the output. I generally see this done in the form of command line applications, like this: ./submission &lt; secret_input.txt | judging_app &gt; score.txt
(.)(.) yes
Both of these examples work as expected in Octave: octave&gt; foo()(1) ans = 1 octave&gt; bar(){1}(1) ans = f No idea why MATLAB doesn't allow these even though Octave shows that they can work in a MATLAB-like language. &gt; To some engineers, MATLAB is the only acceptable scripting language, so it gets used for things where it's not a good fit. That's unfortunate. It's probably to be expected that non-programmers that write their own programs for their specific domain will try to get by with as few languages as possible. They shouldn't put obstacles in the way of more knowledgeable people, though. &gt; Moreover, the choice of general-purpose vs special-purpose language changes the environment around your code as much as the code itself. It would of course be possible to combine different languages. (That's after all pretty much what the Unix philosophy is about where you combine languages like sed, awk, pic, troff with shell scripts.)
Did this on my own back when I first started university, in Borland Pascal. I got to the point that it had garbage collection and I could implement Eliza in it. Taught me a *lot*.
That is an awesome tutorial. Yours and this [article](http://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/) will be my favorite, book-marked resources for pandas.
Thanks! That's a great list too - I've had to refer back to it many times.
Definitely one of the most amazing talks I've watched.
Man, that was a great presentation. Thanks for the link! 
**If you are about to ask a question, please consider /r/learnpython.**
I got tired of tweaking my documentation everytime there was a minor change, so after some googling, and a few hours banging my head against the wall trying to figure out how to use the `ast` module, I came up with something that (I think) is moderately useful. It'll output to markdown or html. I tried to make both of them aesthetically pleasing as I wanted to make it friendly to non-techie end-users , but me not good at design. So if someone wants to add some better templates pull request are welcome! 
Off the top of my head I think pyhdf hasn't been updated for some time. I could be wrong though. Otherwise it looks like the other libraries I use can do python 3.x, but a lot of our own code needs to be updated. Sadly there is not a lot of funding for updating code so I try to do it in my own time. Since you brought it up, maybe I will talk to my supervisor and see if he has any reasons for staying on 2.x and we'll start using 3.x on new projects.
Sounds like http://pyvideo.org/video/880/stop-writing-classes
That's really informative. Thanks! I'm still trying to get a sense of how pandas makes things easier than just using standard python. 
This seems like the inverse of `docopt`: http://docopt.org/ docopt generates the command line parsing based on the documentation you write. Honestly, both seem to be pretty useful, though I think I'd personally prefer docopt.
Ah, that's actually pretty cool, and indeed quite the inverse of my project! 
Fantastic talk. That guy is an excellent presenter. M biggest take away from the talk was that I should *really* start using context managers. I've always used `with open` or `with mutex`, but it never occurred to me to extend and make for own context managers to clean up setup/tear down tasks. Time for a bunch of refactoring! 
Treading on Python Vol 2 covers closures, decorators, functional programming, comprehension constructs, iteration, iterables, iterators, and generators. (Huge disclaimer - I wrote it, but feel free to check out Amazon reviews or mod me away :) )
&gt; You can add two Series together, which returns a union of the two Series with the addition occurring on the shared index values. Values on either Series that did not have a shared index will produce a NULL/NaN (not a number). To people who know set-operations this is confusing, I think, since this is an intersection. And it adds the values, but there's no mention of addition or sum. (saying it takes the sum of the intersection of the series is almost but not quite correct since values present in one series but not the other are set to NaN) 
Did you ever build several arrays that contained related data? That's where you could have used Pandas. Pandas is useful if you ever search through those arrays, iterate over those arrays or saved/loaded them to/from a file.
Hi, sorry just came across your reply. Using latest iPython notebook (stable) version 1.1.0, and ubuntu 13.04 (actually upgraded to 13.10 now).
Why not just do a web front end connected to a Python backend using WebSockets ([Python end](http://www.tornadoweb.org/en/branch2.1/websocket.html), [Javascript end](http://socket.io/))? Pick your favorite Javascript SVG manipulator ([Snap.svg](http://snapsvg.io/), [D3](http://d3js.org/), [jQuery](http://keith-wood.name/svgRef.html), etc.), write your interface as a web page, run a [simple local HTTPServer](http://www.tornadoweb.org/en/branch2.1/httpserver.html) (or use [the standard library one](http://docs.python.org/2/library/simplehttpserver.html)), open up your local server using the system's default web browser, and transfer data using WebSockets. Basically like how IPython notebook works. As a bonus if it works then you can just deploy your server and now your app works over the web. As another bonus if you make your interface responsive then you can show it off on a phone or tablet. I really think this should be the interface paradigm that people aim for. There are so many advantages.
The author's language is a bit loose. Series a and Series b have non-equal Indexes. The result, Series c, has an Index == a.index.union(b.index). To produce c, both a and b are re-indexed to the union index. This produces NaNs wherever a new index element is introduced. These new series, a' and b', are simply added together to produce c (NaNs propagate). The Index object simply aligns the values, so the objects in the union are distinct from the values being added (former mapping to the latter).
I recommend Gaylord. It has a bit of a learning curve, but has great documentation so it shouldn't be too much of problem. Of course it's vector support is not on par with something like Illustrator, but I find it meets my needs well. The design choices is kind of clunky in some places, and unfortunately there isn't SVG support, but I'd say it's worth a try. Edit: I just remembered that the docu I used was in German, so I can't comment on it's English quality.
 class TitleItem(Item): title = Field() class TitleSpider(CrawlSpider): name = 'titles' start_urls = [] # your URLs go here rules = [Rule(SgmlLinkExtractor(), 'scrape')] def scrape(self, response): item = TitleItem() item['title'] = Selector(response).xpath("//title").extract() return item Haven't actually tested that, but it should work in a reasonable time. Where can I take my 10k/m? Edit: testing on `google.com`, it's going quite fast.
Slides available anywhere? 
Does this mean $10,000/minute?
10 Kelvin/meter, obviously. Don't you know SI?
Why are people down voting?
Does that mean Sports Illustrated?
They don't. It was upvoted twice, it's reddit fuzzing the exact number of votes. Also I wouldn't recommend this book, though I'm judging by TOC only. The most part of the book deals with really basic things, which are explained in the Flask tutorial (which it's free). Two topics deserving close attention are lumped into a single chapter, rest of important topics are not there at all. Flask is a microframework, therefore getting to know what's in there takes a little, but the real deal starts when you have to work with what's not there, or, at least, wasn't nicely wrapped for you. So the book is aimed at complete beginners, maybe even people just starting with web development in general. This is good indeed, but I doubt it's any better than the Flask tutorial and documentation. 
Not to poo-poo this, but I'm not so sure it's "just what was needed".. And that's a good thing. What I mean is that the official flask documentation is so good, easy to read and concise, while at the same time covering everything you might ever need to know, that I'm not sure a book is really so necessary. Of course, there are those of us who'd rather read a book than documentation on the web.
I'll have a look at Gaylord. Thanks. That's not one I've encountered yet.
Someone's gonna need to upsell this for me on why it's better than all the free documentation available. Anyway, half (or much more) of working with flask is not *in* flask; its on the thing you're serving through flask.
I've looked briefly at the Qt SVG canvas and its on my short list, but I was hoping to find something a bit more ... pythonic. But if I don't, I may go back to Qt.
I don't dispute the advantages you cite, but that solution doesn't work at all for my needs on this particular project. Thanks for the suggestion, though.
No clue, it's not the sort of thing I measure. Edit: I guess I should say, I doubt it's very many, I spend a lot of my day doing code review, debugging things, or giving advice to people, and not a ton "just writing code".
I forgot to mention that I'm looking for desktop UI, not web-based. But thanks for the suggestion.
indeed, the more senior you get the more you delegate.
Some days I *delete* hundreds of lines of code.
Those are the best days.
I don't think senior programmers use this metric. Perhaps look at open source projects commit history to given you a better perspective. 
You can probably just leave it scraping for a really really long period of time. What are you actually trying to do, if you don't mind me asking?
This is when I feel really accomplished.
Same. I don't even think about it anymore. On a "hundreds" day sometimes I'll look back and be like "goddamn I wrote an assload of code today", but past that I just... don't really even care. Also I misread you initially, I thought you ended with "but only comment one to fix it", which works just as well!
My answer tends to concur with the below in here, but really this depends on the kind of project you're talking about. I think most of the answers in here are oriented around the most common kind of work: maintenance. However, for greenfield, re-writes, ports, and generative techniques; the answers can vary quite wildly. I think what they all have in common though is chunking. The more experience you have, the more you tend to operate at a level beyond the the individual line of code. And that's where the real action occurs, and no one measures it that I've seen. Honestly, I don't know that you can measure it because you'd have to be able to dissect a programmer's line of thought to do it. I suppose this is possible somehow, but it would be difficult. If you want a more detailed explanation of this, I would read Graham's Hackers and Painters. I think that's come the closest to explaining it that I've seen.
I love deleting code. I'd love it if I could delete all of it!!
Pyqtgraph fits the bill
I believe Alex Martelli ( http://en.wikipedia.org/wiki/Alex_Martelli ) is for Python who Josh Bloch is for Java. Unfortunately, his home page (http://www.aleax.it/python_mat_en.html) is not up to date (read: 10 year out of sink with the reality) so you have to google for his talks by yourself.
That looks promising. I'll look into it. Thanks.
My coworkers and I just deleted ~19,000 lines of code and 20,000 files (mostly internationalized button graphics from back before CSS could do the job better.) Unless I'm starting a brand new feature with little supporting code from the existing code base, I'm always aiming for net negative lines of code through deletions and refactoring.
If you are using this metric, you are doing it wrong.
Someone will automate code deletion someday, throwing us all back to the 1940's 
A little late but I guess most who commented here will nod sagely when reading [this story] (http://www.folklore.org/StoryView.py?project=Macintosh&amp;story=Negative_2000_Lines_Of_Code.txt)
"One of my most productive days was throwing away 1,000 lines of code." - Ken Thompson
*One of my most productive days was throwing away 1000 lines of code.* -Ken Thompson
"I've read about how to cook, watched videos and studied cookbooks. What should I do next?". Cook something. All the studying in the world is no substitute for real world practice.
"I hate code, and I want as little of it in our product as possible." -- Jack Diedrich at PyCon
Mu.
Maybe like 20.
More importantly, if your management is using that metric or anything remotely like it, run...don't walk to the door. 
You should measure by revision diffs instead.
Since "Instant Django Web Development" by Packt was badly edited and published by Packt, this is shorely to be as bad. Pakt does the worst books!!!
There are a lot of similar problems available at http://rosalind.info/
Great resource. Could probably use a bit of updating for python3, but I think most of the advice is pretty timeless.
that still counts as AI. AI doesn't imply self-learning at all.
This should be the gold. People over emphasis LOC as a means to measure productivity. While that maybe a decent estimate for a junior developer, over time it becomes a rather poor measure of productivity. More so, it really depends at your shops. Some places a developer will be prototyping like mad, producing potential a thousand lines of code on a day but will turn around and redo hundreds of those lines in the next few days. Other places, you won't need to do much more than edit a few lines to fix a pre-existing system. In one place, many more LOC are produced but all cowboy coding and in the other you have low LOC but are in a structured environment. LOC is a good estimate of productivity but it's still falls short, similarly to how something like BMI really isn't a good indicator.
Anywhere from 500-1000 to -500-1000 Lines of code is a horrid metric by the way.
One of our senior developers actually just wrote about his experience on this topic if you are interested, its oriented around being an effective team leader. He touches on LOC / commits / pull requests briefly as well: http://www.davehking.com/2013/10/27/team-lead.html
I think you mean less than or equal to, for setting it to black. If you didn't do that, you wouldn't have a case for the number being 128
Well, if you had a lot of processing power, you could write a loop to randomly delete some lines of code, and see if the tests still pass. It would only find dead code, so it can't simplify code.
If you're writing 100 lines of code for something that can be done in 10, you're doing it wrong.
"Measuring programmers by how many lines of code they add is like measuring airplane designers by how much weight they add" (One of Bill Gates's, slightly paraphrased)
It's not clear why you want to know this. Do you want to know this to see how you stack up with senior software engineers? Are you trying to estimate the cost of some project? etc. As mentioned in other comments, how many lines one writes on a given day is a bad metric. One metric that is slightly better, but still not great, that I sometimes use for estimating work is the number of lines coded per day, that remains in a project over the long haul. A more experience programmer has a much higher chance of writing the code right the first time compared with someone with less experience. For this metric, I usually find the average programmer does about 40 lines a day, a 75 percentile programmer around 80 lines a day, and the best tend to be around 110-140/day. This is typical numbers over the life of a project while it is under active development. But these numbers don't tell the whole story as the better programmers write more elegant and concise code and thus on average each line of their code is more efficient at meeting a project's goals compared to those written by the inexperience who may do a lot of copy and paste, that can inflate their numbers, or other nasty bad habits that reduce the quality of their code.
If statements cause bugs.
*Diederich, I think :)
Pretty much this. It's a completely misleading metric to use. I might spend hours debugging an issue in some lengthy code via the debugger without writing a single line, end up writing a five line fix, and then spend another hour testing it before a commit, for example.
I have to disagree with the way he describes it as if you could either understand that it's an interface to Apache or you could misunderstand it as a web framework. There's plenty of room in-between the two viewpoints. I was a user of mod\_python back then, and I remember running across several instances of behaviour that didn't make any sense whatsoever. As in situations like this: &gt; &gt; &gt; &gt; Bug report: X doesn't work. &gt; &gt; &gt; That's not a bug. mod\_python doesn't do X, it does Y instead. &gt; &gt; But doing Y makes no sense. It's completely unexpected behaviour that doesn't have any benefits. &gt; But that's the way Apache does it internally. You don't have to think that mod\_python is a web framework to expect better than that. 
Upvoted the three of you. This matches my experience as a developer in large projects and as a teacher.
This is why `max` and `min` are sometimes coded without tests when sum/sub/div operations and `abs` have been formally proven right and when the computations cannot overflow: `max(a,b) = (a+b+abs(a-b))/2 ; min(a,b) = a+b-max(a,b)`
I've found most if my time is spent finding problems and rewriting big portions of it into smaller code, so a lot of it is actually code reduction.
AI doesn't imply learning. By definition, AI is something that sounds/looks intelligent. A neural net, however, is learning. Wish I under stood those :/
There is no inherent reason to prefer one over the other, but since I have 30 years of desktop programming experience and essentially none working with web-based UI stacks, I prefer to minimize the number of languages, protocols and conventions I have to learn for what is supposed to be a small project.
That looks *very* interesting. Thanks.
In my experience (as an engineer who isn't particularly senior, but as the most senior engineer in my dept) this is what makes a good senior engineer. The ability to mentor younger engineers and get the standards for developing a product to the point where those hundreds of lines of code never get written in the first place is immensely valuable. Recognizing that value is somewhat harder, though. I still beat myself up for days spent teaching rather than "working".
Yes! This is it! "I hate code, and I want as little of it as possible in our product." â€“ Jack Diederich
Thanks, added to my metaheuristic tower (and branchless coding bag of tricks). Are you a math teacher?
Upvoted the four of you. I just wanted to keep the upvote party going...
Slow is good. It's the fast "cowboy" programmers you have to be careful of. Quality over quantity, not just any day, but *every* day.
Lines of code written is not a really good way to measure how fast you are. As the other comments should help make clear. It's would be more interesting to see how fast a developer can provide a feature or fix a bug. But that's much harder to measure, and even then can be misleading. Sometimes you can go faster by incurring technical debt, meaning that you or others maintaining and extending the codebase may suffer a huge slowdown or other problems in the future. On the other hand a smart developer may come up with a system that makes future maintenance and extension much easier, but has a bigger up-front cost in time. 
http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyhdf
Not Python, but Java for me, I'm afraid. Most days I don't get to write any code at all. They disappear in meetings, emails, planning and design, debugging, administration, documentation and sysadmin. If I am lucky I will get a day a week where I can write/modify about 50 lines of Java code, plus 100 lines for testing. Now why on earth this is classified as "senior software development" is beyond me.. Edit: I realize that it all comes down to what those lines are. If a day I am writing thousands of lines of code, that is generally not a productive day because it means I am doing stupid monkey coding, say to fix hundreds of places where I earlier had dome something stupid. If on another week I spend 3 days to dig into some code and discuss a solution with colleagues, write a 10 line test that verifies broken behaviour and 20 that verifies my 1-line fix, then that is a very productive week - that could be a line that gives a 10x speed increase for instance.
This is similar to asking an artist "how many lines do you draw per day on average?" It's not about the number of lines, or their length, and as you become more experienced and confident you'll realize that is a nonsense question to ask. I don't mean to be insulting, because I know it's not an easy thing to grasp, but you really need to be able to embrace the fact that you are creating quality code that has had a lot of thought put into it and is maintainable and free of major and obvious bugs. It's not a race, it's never been a race, it never will be a race. Software is far more complex than that. If you find that speed does matter, you're probably doing low-thought assembly-line style programming and you should probably be using something off-the-shelf instead.
So is the main benefit that you can change the level and format in the middle of the script? Do you change the level and format a lot in your scripts? That seems like something you wouldn't want to change. Otherwise, I'm not seeing much of a difference. import logging log = logging.getLogger(__name__) logging.basicConfig(level=logging.INFO, format="%(asctime)s : %(levelname)s : %(message)s") # Run the rest of your code
First of all, no one I respect, including myself, pays any attention to LOC, other than as an occasional passing curiosity. ("Wow, I wrote a lot today", or "Wow, all that work for just two lines of code") Second, I'm surprised that no one has mentioned tests. Do you count lines of test code or just lines of app code? Often a feature will have more lines of code in tests than in the actual app code. This is a great sign, in my opinion. With application code, I'm a minimalist, and try to avoid writing more lines than necessary. But in tests, I feel good when I add lots of code. It generally means that I've tested more things and my application will be less buggy and less prone to regressions.
Changing the level interactively can be useful. I have a few scripts that *need* to run constantly or data is lost, but if I ran them in debug logging mode all the time they would very quickly fill up the drive with logs. Restarting them results in a loss of data, so I hacked something similar together so I can change it via my k/v store it connects to. I can't think of any situations where changing format would be useful, but hey, who knows? 
I like to measure my productivity in LPM (Lines Per Minute). My LPM goes up drastically when I take in caffeine and listen to electronic music while using vim on my custom written operating system that only uses the color green. On a good night (true coders don't work during the day) I'll peak at around 50 LPM. Of course, I can only accomplish this on the finest of mechanical keyboards, hand-built using rare solder from the farthest reaches of China's recycling scrapyards. If you want to reach this level of LPM I recommend you start eating a lot of Cap'n Crunch and throw away your mouse. 
http://imgur.com/ldGAFGg
Could you provide some information about these packages? It looks like these are all windows only packages which I don't use. Otherwise it looks like they have compiled the package for python 3.x, but there don't seem to be any notes in the change log of the zip file that anything had to be done to get it to work with python 3. So this makes me think I can probably install the public pyhdf and use it in python 3 (although I doubt it would work right away). Is there a reason these packages aren't more publicly available? Why they haven't been included in the public code bases?
"rm *"?
Ok I can see that, but since you mentioned logs filling up, have you heard of [logrotate](http://linuxcommand.org/man_pages/logrotate8.html) (depending on your platform)?
Yup. I use it for my supervisor processes, but the issue is that I really need to maintain the logs for INFO level on those particular scripts regardless of size. I could roll something to maintain INFO and discard DEBUG, but given that 99.9% of the time it's running in INFO it never really seemed worth the effort. 
\#Fix this bit here
This code.....scares me. To name a few it: * is not thread-safe * overrides sys.stderr * ~~does not take a file object for 'stream'~~ (and this is why code reviews should consist of more than one person...) * compares using == instead of 'is' in quite a few places * uses os.path.exists instead of being explicit with os.path.isdir * opens the same stream with two different file handles * level strings are lower case (standard library is UPPER) * levels/range of levels are defined in multiple places * iterates over the entire range of levels for every logging call * harcoded unix style line ending * double documents the arguments for \_\_init\_\_.py * doesn't document any private functions * defines an exception which is never used * logger's class name is the same as logging.Logger (it does not break anything but doing isinstance(somelogger, Logger) when using stdlib and this will be a pain) I don't usually rip into libraries, we'll ok I do more often than I probably should, but when I do it's because I believe people should learn to understand the standard library first....especially when it comes to logging.
Could someone please make a script which will calculate this based on my git repos? And yes, I do realize that I write more then I commit.
Astah Community
I really did define the levels twice... thanks, I'm going to fix everything I can. **[E]:** Stream definitely takes a file object as a value
The system I've been building for a year, and understanding better and better as I go has seen this happen constantly. I've been able to explain and defend beautifully every decision along the way, but there were always places the code couldn't go, things 'to figure out' in the future. It was several thousand lines long a few months ago, which was a great reduction from what it had been. Now, the whole thing is 220 lines. If I scrub blank lines it's 185 lines. Yet, it's more powerful than it's ever been, completely tested now, fully injectable, has shed every dependency, and the lines of code are an average 41.9 characters long. It's super readable, highly maintainable, and it completely follows a bunch of good practices, like single source of truth for everything. Also, that entire list of things 'to figure out' all just work now, and we've come up with many needs since, and all slot into the system perfectly, usually in a few lines of code that make perfect sense, with nice names. So yeah, if you plotted what I've done this year, I wrote about 10KLOC of carefully and rigorously chosen lines, then kept learning and learning, and brought it all down to the most perfect &lt;200LOC I've ever made. The only problem now is that it looks like anyone could have written it. There's very little cleverness, it's dumb, like git, with good, obvious, memorable names everywhere, and I don't think any function or method takes more than 3 arguments, though most take fewer than that. It doesn't *look* like really labored-over code, unless you've been coding for long enough to know how hard it is to make a system this clean (answer: *extremely* hard, originally, though now I think this way, so it's getting easier all the time).
http://folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt
if i'm `writing` new code or spec code from scratch or something, about 75ish lines of good terse code is a good day. most time is spent `fixing` or `polishing`, sadly.
I know what would happen. I wrote a genetic toy to plot a simple for loop for *i* from 1-n, transforming each *i* through a sum of cosines, with existence of each cosine function, and the 3 constants used by each being the 4 mutatable elements of the system. I was trying to get it to plot small phrases. It would get close, then just never move again for days. I think the code evolver would just sit there forever.
I found a bug in your one line: &gt;Less code == *fewer* bugs Bugs are always of a known, countable quantity.
Lines per day is tricky measure, and I know my variance would be sky-high over time. How about commits per day? I tend to commit about once every hour (or so) that I'm coding. I push / perform pull requests at the end of the day. Unless it's a personal project, then It's a bit more sporadic.
Does that include documentation??
Afaik packages in the repository use to work fine. I do not use pyhdf so I can not tell you about this application in particular but I will be surprised if it doesnt work. Golhke repository is well known for people in Windows and a must if you work on 64-bit. There are application websites which direct you to this repository in their installation instructions specially for windows 64-bit. It is maintained by Christof Golhke. Maybe you can ask him for more information.
Software is more that just code!
My best days are when my code shrinks 10%. That is when code that was in the wrong place naturally falls into an object. Or two objects merge beautifully into one. Or you find that perfect math library that replaces your kludgey home made one. 
What I want to do with logging: * send data to a file with my format and logging level (easy enough) * restart a logging process and have it clear out the old file (if it's the same path) and not have double logging It shouldn't be so hard
With all of these posts saying, "my best days are those where I delete hundreds of lines of code" it's kind of amazing there's anything left. 
And, honestly, I spend a lot of time stubbing out functions and classes for my Jr Engineers, who will then go through my code looking for stubs and writing the functions. We write lots of re-usable modules; I might set up the basic project, set up the sphinx doc generation, write the code in __ini__.py for what i want to externalize, set up some other files, write a class definition and handful of method declarations with docstrings... After that, I spend a lot of time responding to pull requests and writing whatever code I can in between. Some projects, I don't really "write" any code after this point, other than to massage and occasionally re-write my Jr Engineers' work ... other projects, I'm generating just as much code as they are. It just depends... The biggest difference between my work and theirs really comes down to how much I understand the entirety of the project compared to them. For the most part, they're just running around responding to tickets or looking for FIX and TODO tags in the code, but may not really understand what the full scope of the project is without having to ask or read documentation. On the other hand, it's my job to know eeeeeeverything the code does, what other projects it's expected to interact with, and blah blah blah...
Sometimes I don't write any and just spend the whole day designing a solution. But your question asks for daily average, to which I'll say about 50 per day on average. That assumes I'm not counting code deletion as a negative.
What does it do, then?
I would love to, but it's under an extremely strict NDA. What I can say is that TDD has helped a lot (950 lines of tests), as has moving things to data, especially shallow dictionaries, and learning from beautiful systems like Linux and git. I find the hardest parts now (and they always were, but now they tend to be all that's left over) are where to put things, what to name things, and figuring out exactly how much to abstract. You know the usual suspects. I'm also trying to follow Bob Martin's transformation priority premise. It's my next thing to really shake down and see if it's correct/worth it, though it smacks of common sense to me. Put simply, it states that you should let the tests grow the code only in the next, simplest way imaginable, and the transformations that get you to the next step are ordered by complexity (i.e. nothing at all to a null value, null to a string or int, one of those to a list thereof, etc). The places where I had big ideas myself and wrote something much more than passing the next test required caused me to abstract nicely, but on the whole incorrectly, which lead to wasted weeks or months fighting against a sub-optimal system, with levels of duplication that got in the way and stopped me from seeing what I was really dealing with.
Your intro is fine. I will add some problems about word counting (kmer frequencies) or simple ORF identification or enzyme restriction to use RegEx. Perhaps you cam get more feedback in r/bioinformatics or httt://www.biostars.org Cheers. 
/r/bioinformatics ***** ^This ^is ^an [^automated ^bot](http://github.com/WinneonSword/LinkFixerBotSnr)^. ^For ^reporting ^problems, ^contact ^/u/WinneonSword.
Whoops, sorry. I deleted and retyped the comment [here](http://www.reddit.com/r/Python/comments/1pbfys/senior_software_engineers_how_many_lines_of_code/cd0ylzq). (shame on me - I just force-pushed rewritten history!)
I've mostly been taught Python is an "ask for forgiveness, not permission" language. So I found it more correct to add some try, except clauses when I attempt to set the stream to a file.
I'd gauge more on functions of code; or possibly even views. You should negatively gauge on long functions that are complicated and have many lines. TDD might suggest you gauge based on how many tests you close.
I haven't looked at UML since I got out of college. (Even then I still found it to be an incomprehensible mess of meaningless symbols)
/r/datasets * http://biopython.org/DIST/docs/tutorial/Tutorial.html * http://scikit-learn.org/stable/datasets/index.html * http://statsmodels.sourceforge.net/devel/datasets/index.html#available-datasets
http://www.reddit.com/r/learnpython/wiki/books
/r/pyramid * http://cornice.readthedocs.org/en/latest/
Over the last 365 days, I've averaged about 190 LOC per day. (If I had only been working on a single project, that number would be much lower. But I've found that I tend to work on a higher number of small to medium sized projects.)
If anyone was having problems using pip, it's been fixed now.
It's could Mutation Testing. http://en.wikipedia.org/wiki/Mutation_testing
There's a lot of love in here.
Codecademy sucks IMO and Bucky's tutorials, too. Start with something like Udacity's CS courses.
Just pick a framework (At this stage, it doesn't supermatter which one you choose. I'd recommend either flask or django (I'm partial to django and think it'd be more appropriate for you, but these kind of opinions are a dime a dozen on the internet)), follow its tutorial, then try making your forum. If you get stuck, ask about the specific part you're stuck on on the relevent subreddit (e.g. /r/django/ ) or stackoverflow.
Most of my time was/is spent on convincing people why we dont need to write ANY code to begin with.
This is what I did to get into web development with Python, but I am a beginner myself: - learned how to setup my PC as a web server (years ago I setup apache web server) - learned how to do CGI scripting with Python - once I mastered CGI scripting, then learned a light-weight framework like bottlepy - I also had to teach myself html, css, and javascript (javascript mostly for input validation of my HTML forms) Learning CGI scripting first will force you to be familiar with HTML protocols and headers. That's why I wouldn't recommend jumping right in with a framework without first grasping CGI scripting. While you are at it, you might as well learn SQL too and subsequently, be familiar with using a database software like mysql or postrgresql. But I would start off simple using sqlite3 since you can start using it with Python right away without configuring sqlite3. Why learn SQL? Data is pervasive. It is everywhere. You'll eventually need to save/retrieve/modify data. A web application of any substance will undoubtedly have to communicate to a database. Learn how and why you should use prepared statements in your SQL for security reasons. Web development isn't easy and unfortunately requires many layers of different kinds of technology as I've already hinted above. In the web dev world, you can't do everything with just your favorite programming language. You will have to be a polyglot. I struggle with being a polyglot, but maybe you won't if you constantly do web development, which I don't since I am primarily a data analyst. Sorry, I don't have many links or references to share. I pretty much use Google. But I did use this [book](http://www.amazon.com/Python-Power-The-Comprehensive-Guide/dp/1598631586/ref=tmm_pap_title_0?ie=UTF8&amp;qid=1382923937&amp;sr=8-1) to get me started with web development with Python. IMO, I thought it was a good book. You can also go to this [site](http://www.it-ebooks.info/) for more programming books. I typically use the title search option at the top. Don't forget to join newsgroups or Googe groups or even IRC for help. Hope this helps. Good luck and have patience! There are people who are here to help.
Yeah their is just so many pieces, it's difficult to know where to even begin
The quality of your work is far more important than the speed. It takes a significant amount of experience to get there so don't become discourage along the way. Here are a few things you can do to improve quality. When you come across a bug just don't fix it and move on. Ask yourself what could you do different in the future to prevent you from making a similar mistake. Code is read, many more times than it is written, so make sure you code reads like a story. If it sounds weird, broken up or missing parts of the story its not written well. Don't abbreviate or choose short names to save typing but instead choose names wisely picking the best and most precise name for the situation. To see how well you do in writing code, go and review code you written 6 months ago and see what it takes for you to understand the code. If upon the first reading you understand it without much thought it likely reads well and your on you way to quality code. If not, ask yourself what do you need to change with the code so that the next time you look at it you don't have to waste so much time trying to figure out what the code does. Make sure you write unit tests and have good test coverage. Preferable write the tests first as it will lead to better SW design. First write a test for the "happy path" that is test for a particular requirement without worrying about the things that could go wrong. Then write the code to make the test pass. Next write the test case for the things that can go wrong and or to try to break the code you just wrote. Now write the code that satisfy this test case. Repeat and rinse over and over again. This technique will significantly improve the quality of code you write. Read through the source code of a few open source projects for projects you are interested in. Pick projects that highly value unit testing and continuous integration. Pay attention to the layout/organization of the code, the overall style of it and as well as how does it read. Beyond reading the code of the project review a number of their commits. Contribute to some open source projects. You will receive valuable experience and advise that will help shave years off the time it takes to become an experienced programmer. 
Upvoted the five of you. As a new programmer learning Python it sounds like an interesting and probably important concept to keep in mind.
Well. Countable quantity.
Just wanted to add, depending on what application you want to then make, you'll soon realize using a framework like Django would be overkill. For example, a To Do list or DVD collection library application. Bottlepy or Flask would be perfect for small to medium-sized applications. I looked at Django, but thought that is way too much bloat for what I needed. Plus I would then have to be familiar with ORM...meh, that's another story or opinion I don't want to express right now.
If you're looking for something a little more visual, [you could try this course on Udacity taught by one of Reddit's founders](https://www.udacity.com/course/cs253). It's still pretty code centric, but you're coding, so there's no avoiding that. It's taught on Google App Engine, which makes deployment a non-issue. If the course is too much, there are more beginner-friendly classes on the same site that lead up to it. Udacity's CS101 discusses web crawling and search while covering the absolute basics.
I tend to only use simplified UML to start the design of a project and often use a white board. So that is of no help to you. When I need to understand a new codebase I first take a look at the directory structure, look at the code browser from an IDE, insert some well placed "assert 0" statements and look at the tracebacks that are created from them. Some times I will profile the code and view it with runsnakerun if it is python code and then study the resulting square maps. It will give you a good sense of the overall structure and flow of the project. The pycallgraph project can also be handy to visualize the call graphs of the code.
The mongodb flask tutorial is really really good, though it packs a lot in and took me a while to get a good sense of why it's structured that way. The Django tutorial would be a better first start come to think of it. Just build a rudimentary blog type thing. 
don't compare it in lines, compare features developed and bugs produced.
I had a short "I wanna build a web app in Python" phase. To be precise, it was "small web app", so I eventually settled on Flask rather than Django*. The [official Flask tutorial](http://flask.pocoo.org/docs/tutorial/) (plus the guides linked on the site about deployment) is enough to get you started. You learn how to structure the project, how separate pieces communicate, a bit of templating, etc. It *seems* confusing at first, but once you finally get down to writing code, it's relatively straightforward. But anyway, you wanted pointers on where to start? Start with a tutorial. Don't think about deployment until you are comfortable with the chosen framework. *If I were to do it again, I'd go with Bottle or Pyramid for small, and Django or Pyramid for not-so-small. I recommend you find out for yourself. 
I would say anything by Alex Martelli, but his material is too old by now. So, now I'll say Beazley's *Python Cookbook*, though it's not quite the same type of animal as Bloch's *Effective Java*. 
why such question ? don't just say "just curious"
paragraphs, for Christs sake
Think of it as one long paragraph
why should we care ? it's all java right ?
 http://i.imgur.com/Oo8rnld.gif
I almost had an orgasm...then I thought hmmm "no fucking way...."
TIL S-Lang 
If anyone could compute an average, you'd think programmers could. But based on these comments, it's almost impossible.
In The Mythical Man Month, Brooks stated that over the life of a software project, developers average about ten lines of code per day regardless of whether they were using a high level or a low level language. Similar figures are given in the book Software Estimation: Demystifying the Black Art when discussing a selection of projects at Microsoft. My suspicion is that senior level developers actually write less code per day than their junior counterparts. This may be because they're involved in more aspects of the software development life cycle than just writing code, and also because less experienced developers tend to repeat themselves more.
Over the last year, my team wrote about 100,000 lines (in use today). Threw away probably an additional 20,000 to 30,000 lines in between in the last year or so. About 8 engineers on team. So about 60 lines on average per engineer? But I know the highest contributor contributed about 5 times more than the lowest contributor on the team.
I can not upvote this enough. Even once you get to the Indy 500, you've got to push your comfort zone to stay in the game. You think all the best programmers in the world are just sitting back, regurgitating some secret sauce that you're not privy to?? Hell no. They are busting their ass, getting out of their comfort zone, pushing the limits, discovering new ideas through their experimentation and building the next generation of innovative tech.
This comment review stuff never ends!
Hey! I'm the writer of the article and this is my first time getting on reddit! Quite chuffed. Thanks for the feedback. I'm planning a series of articles on this subject, so I kept the title as it is. The first article, as you rightly point out, is to help newbies setup their environment and you're right, it could be better worded. Hopefully, you'll enjoy subsequent articles when I put up some code.
I am currently doing http://www.realpython.com/ I really like it. Its fast paced so you keep learning new things!
 sudo rm -rf /* 
Hey buddy, I borrowed the infographic from another site (with full attribution). The article is geared towards newbies (business-types) who don't know head or tail of ML, but want to ramp up quickly. The infographic is TMI, but gives someone all the information about the field in one place and they can choose to follow through down the rabbit hole.
You could try building a small Reddit/Hacker News clone. That's what I'm attempting to do with Flask. Or build a mini online library catalog where you can search, reserve books on hold, mark them as on the shelves/checked out, etc.
It's almost halloween. This post is perfect for it. :P
Why not use Logbook (http://logbook.pocoo.org/)? It takes no configuration for the default use case of just outputting to console, and more complex uses are incredibly simple to achieve. It also has many features and advantages over the built-in logging package...
Sorry to beat this dead horse, but counting lines is a horrible way to measure yourself. Don't even worry about your productivity. Keep it simple: write code, review code, learn code, repeat. If you want feedback on how effective you are as a programmer, invite people in to collaborate. Experiment with pair programming (or do it full-time--I'm a huge fan), invite co-workers to review your commits, contribute to open source projects, write blog posts, get a mentor--whatever. These are all better ideas than counting your lines.
Epydoc is my goto for UML from an existing codebase. Although I don't like using it for documentation, it generates wonderful UML diagrams with very little intervention.
This was excellent. If I had any gripes, I'd like to see more examples of the split-apply-combine process. The pivot_table example could use more explanation on how it was constructed. 
Thanks! I've now cross-posted there.
If you're doing it all on a single host why does it need to be a pi? what's stopping you from renting a single VM to use for everyone?
If you're interested in Flask you could check out this tutorial also, http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world I recently wrote an app using python, Flask, and mongo for work with very little experience before hand. I'm no expert but I feel more comfortable now and feel like I could tackle a different framework if I feel like it. Just pick one, dig in and keep at it. Also checkout education.mongodb.org the have an m101p mongodb for python developers that uses bottle to make a blog project with mongo backend. It's a pretty good mini course.
Yes, you're right - I might need thread interop but not in the meantime at least. So right now my reliability problem basically boils down to implementing exceptions passing and graceful exit if an expected message is not received.
implement your crud endpoints in the format that backbone expects. 
I'm currently using [xlsxwriter](http://xlsxwriter.readthedocs.org/), could anyone with experience with both make a list of pros and cons?
https://github.com/notch-interactive/python-grapher
I tried them both, chose xlsxwriter: significantly faster than openpyxl.
You do, unless you want to --no-preserve-root
Money. We have a pi. 
IIRC openpyxl is the backend for pandas's excel read/write features, so it's useful if you want to make pandas frames pretty in excel.
[has been done](https://github.com/mattdiamond/fuckitjs)
But you can rent a VM for like $5 a month and it'll be more powerful than a pi. To run a course over 3 months (the length of a typical university course) that's only $15 and your users won't hate you and you won't hate yourself when it comes to doing system administration tasks like installing packages or compiling modules.
Thanks for the advice! I still think a http-based message queue with a separate broker is sorta overkill for my current task. Nevertheless I realize I might need to swap the transport in the future. I really like [ZeroRPC](http://zerorpc.dotcloud.com/) but it isn't available for .NET, unfortunately.
When you ask this: &gt; should I get super good at Python and then attempt using it It shows that you didn't properly read what you were replying to: &gt; you are expecting you know how to do it before you do it, but that's not how it works. Learn by doing. 
XlsxWriter is also available as a backend in the latest Pandas versions on the GitHub master and will be in the soon to be released 0.13 version. 
and xlrd/xlwt for xls format
Good we are not being paid per committed LOCs. :)
&gt; It's like wanting to make an "egg based breakfast" and then you are confronted with an omelet pan, a egg poacher, a toaster, hollandaise sauce double boiler, and about 5 other components. This is a perfect analogy! 
Web development in JavaScript suffers from the same problem as python. Why angular.js and not backbone.js, or one of the dozens of frameworks out there? Everyone has their own favorites (shout out to web2py for being simple) framework and that's the problem. The python is easy, but until learning the python is the hardest part it will always be more complicated than it needs to be. This is something that php has done right. My 11 year old could do a hello world webpage with php. It might not scale, It might be ugly code, It might have security risk, but those are all problems for another day... Python needs a dead simple way to program a webpage. It doesn't have to be perfect. We'll get to that later when were doing more than messing around.
If an .exe that pulls info from a database is your end goal, why even mess with web frameworks? 
&gt;should I get super good at Python and then attempt using it for Web Dev or what No. Just make something, even (and especially) if it already exists.
I've tried digital ocean recently and their smallest one is $5 per month for one core and half a gig of ram. If you need to scale above that the price is cheap enough that it won't kill you to double or quadruple it.
It is not related to the bugfix release 3.3.3; pyvenv was added in Python 3.3.0 (see [PEP 405](http://www.python.org/dev/peps/pep-0405/)). In addition, it is not (yet) similar to virtualenv, as Python 3.3 and pyvenv does not include pip (or a different package manager). However, this will change with Python 3.4 (see [PEP 435](http://www.python.org/dev/peps/pep-0453/)).
I don't understand your question (or comment). Are you asking how you get to the point at which you can implement something that's already been made before? If your asking that question, you're probably starting with something way too complicated. Start simple.
Will check those out! Part of the problem I have is not sticking with one language because I think the next one does something better
Any ideas for something simple? I have a problem in finding things to make 99% of the time 
I only need to write xlsx files and I'm in a limited memory environment. [The constant_memory option](http://xlsxwriter.readthedocs.org/en/latest/working_with_memory.html) is a blessing.
Why not try making a simple blog type webpage using Django. You can handle logging in, user profiles and permissions and go from there. Personally I think the most important thing is to make something that is really simple but actually has a purpose - even if you don't use it for that purpose after it's built, it will stand as a base of code for your to build your next project with.
Great I wanted to try out pandas for several months now and your tutorial got me started :) Thanks! The only thing I didnt understand was the difference between concat and merge
I'm new to using Python in a web environment and I agree with your point about CGI scripts. At the very beginning I was trying all the Django tutorials, but as many people say, there is a lot of 'magic' going on underneath which for me limits my understanding. Once I tried writing a very basic form submission script in Python using CGI, I started to grasp the underlying concepts. Django seems fantastic, but initially I don't need all the bells and whistles, just some simple input and output!
I disagree on what you say about Python not being easy enough for web development. I'm not sure about recently, but years ago it was easy to purchase a very cheap web site/server for PHP development compared to Python. Recently though, that has changed. I think back then the barriers to entry for Python web development was greater due to server support or availability and not due to the Python language itself. My young son prefers Python syntax over PHP. Yeah if you just want to print Hello World it is moot point with either, but everything else, PHP syntax is just hands down awful for kids to understand.
&gt; I got as far as downloading Django, but my confusion is more about what *other* parts I'll need to make a fully functioning site... Just follow the Django tutorial. You're worrying about things like whether you need a template engine, but if you spent a few minutes skimming through the tutorial, you would see that Django includes one and the tutorial shows you how to use it. You aren't getting stuck with technology issues, you're getting stuck because you downloaded Django then just stopped instead of doing the obvious thing and following the tutorial. That kind of defeatist attitude is stopping you from moving forward. Stop worrying about what you don't know and just follow the tutorial. Its whole purpose is to get people who don't know how to do things up and running. 
Nice, because the Kivy made tutorials leave a lot to be desired- and the online documentation is often inconsistent between kv language examples and pure python examples. Does the book teach both methods or is it KV focused?
Oh, i agree 110% that python syntax is easier for kids to learn. Hands down no contest. I think it's important for someone who is new to the web development scene to see big things with little steps. Small gains in understanding should translate to big things happening on the screen. With python it seems like you need to understand routes, MVC, ORM, etc.. before you can create anything worthwhile. All those should be a second step after the basics are taken care of. As far as languages go I am not a php fan. I think python looks, feels and flows much better. I just wish it offered a little more "Quick and Dirty" that might allow someone new to programming a chance to play around before being so committed to a framework. I still think it's easier to "get started" with php for web programming. It might not be the path to "get professional" in web development. In my small town there is a woman who makes a living creating brochure websites for businesses. There is a pretty big gap between her and Amazon &amp; it seems like python only wants to be used for Amazon. 
Just remember guys, deleted code is tested code.
except if you have more than 1 process logging to the same file and use files (instead of syslog that logs to file which actually gives the same results) you have to code a SIGHUP to release the file handlers to enable log rotation. Else, you will end up with file system filled at 100%. I have this kind of "logging" wonderfull class at works. Everybody is still wondering where the problem is. PS BTW hidden in the stdlib is the killer app dictlogging https://docs.djangoproject.com/en/1.3/topics/logging/ 
What the what? Everything should be free because a language is open source? What sense does that make? Also, if you go to Amazon, you can check out the Kindle version to see if it's something you could "benefit" from. "Taste testing" that book is about as hard to do as opening a new tab. I'm just letting you know, you're missing out on some absolutely *fantastic* fucking programming books with your weird free requirement. Note: I don't know if *this* book is one of 'em -- haven't read it, but still, no idea why you think it should be free. 
Or [xlrd](https://pypi.python.org/pypi/xlrd)/[xlwt](https://pypi.python.org/pypi/xlwt)?
The developer of virtualenv, Ian Bicking, has more or less abandoned Python entirely. He got hired by Mozilla a couple years ago and these days does Javascript. However, even in his glory days of Python he never really supported his projects. He'd throw off sparks in the form of these fabulous ideas (virtualenv, webob, pip, paste...) then at some point just stop working on them and move on to the next bright spark. When the project was too good to ignore someone else would pick it up and run with it, when it wasn't it'd die on the vine. He's a good guy, though, and I'm sure he's entirely supportive of other developers picking up his ideas and running with them.
By "both methods" do you mean with and without Kivy? The book is focused only on Kivy and comes with it's own set of examples. I haven't had chance yet to compare them to the official set. Surprisingly the final chapter develops a whole space-invader type game! 
Where can I find the repository?
Do you have a DRM free pdf available? $8 is that perfect price point for picking up a book without knowing much about it. However, after a few bad experiences with Amazon's DRM scheme, I've shied away from getting ebooks from them. I tend to go for O'Reilly these days as they offer good ol' drm free pdfs along side the other ebook versions. How in-depth do you cover functional programming? Do you go over functools and the like? That's definitely an area I've been looking to improve upon. By the way, your amazon page has a few typos in it. 
I was a bit of a web-dev in a previous life in what is probably now considered the dark-ages of web-dev (mid-late 90's). Got so sick of it I vowed never to touch it again but things have much improved and it now looks more fun than the endless grunt it previous was. So I decided on Django months ago but it was slow going mainly because of residual aversion on my part but also partly because it still feels like more work than it should be. So after a short break I likewise decided to once again review the options. I must have had the blinkers on when it came to web2py because I had never even visited the web site! (after a bit of digging I now think I understand why I hadn't looked into it before but I'm not going to go into that) So I'm now very happily getting along with web2py and it's pdf manual. Still plan to return to Django at some point but not for now. So the take-away lesson: pick one or two that look promising *to you*, stick with them until you lose the newbie feeling. Oh and how to progress your project: don't even think about it until the pieces of these frameworks start to fall into place and make sense to you. Then you will find reasoning about your own project much more easier.
About you comments, I'll definatly look into those. As for the PEP8 stuff, for whatever reason I didn't clean up the code, cause, u know, life.... I am aware of it though... ...Even if it doesn't show :p
You can read xlsx files with openpyxl. It's not clear you can do that with xlsxwriter.
That's for a different file format (pre-xml excel)
&gt;As far as languages go I am not a php fan. I think python looks, feels and flows much better. I just wish it offered a little more "Quick and Dirty" that might allow someone new to programming a chance to play around before being so committed to a framework. The quick and dirty is Python CGI scripting. Maybe someone will create a Rails-style Python framework or one exists already. &gt;I still think it's easier to "get started" with php for web programming. It might not be the path to "get professional" in web development. All my son does is drop his Python CGI script into a cgi folder. No different or harder than PHP.
You're right about the CGI. I wasn't considering CGI as a valid web development tool. Never even crossed my mind... Good point.
That's probably a bad approach for a first timer. Understand things at the level of the framework first and then, now that you have your own mental framework, dig a little deeper if that's really what you want. If you don't mind me saying, you need to be a little clearer in your own mind what exactly you want to achieve. Keep it focused, keep it realistic and then you'll make small steady improvements without getting overwhelmed. Edit: small edit ;-)
Yup. I think I am showing my age or people have forgotten that the interactive web years ago was done with CGI scripting. Nowadays, people just want to jump on the frameworks bandwagon without first realizing that you actually need to put in some work yourself in understanding the underlying technology.
This one is good too: [TwitterAPI!](https://github.com/geduldig/TwitterAPI)
Nice :) Could have really used this a month ago. One feature you might want to add would be the ability to use environment variables to override individual settings with something like mycompany_myapplication_database_dsn=foobar This could also be used to completely configure an app that only has 1 or 2 settings. 
Here you go: https://github.com/exhuma/config_resolver I added the missing links to the readme. Everybody should find it now. Sorry about that.
Read the backbone source code to see what kind of stuff it expects from a webserver. Then establish interfaces in your app that accept and/or return json data. In a sense, the backbone app replaces the view part of MVC in your Pyramid app. You'll have a route that handles serving the backbone portion(or better yet, configure your webserver to serve the static stuff - html/css/js - directly), then the rest of your routes will handle sending and receiving data. Furthermore, you should read up on HTTP methods, and how they are supposed to be used. There are plenty of blog articles and tutorials out there on this, and should shed some light on why backbone expects things to be structured a specific way.
Glad to be of service ;) Hmmm... but I don't know how I feel about the env-var suggestion. I don't know if that should go into this project, given that reading out one environment variable is a very easy one-liner. The aim of `config_resolver` is primarily to find files in a predictable, intuitive way. You could always do: if getenv('my_env_var', None): dsn = getenv('my_env_var') else: dsn = config.get('database', 'dsn') This does not strike me as complex enough to move into `config_resolver` and I believe, being a bit more verbose here would make it clearer. Less "magic". I'm always open for counter-arguments though ;)
Oh, sorry, yes it does seem to cover both but I couldn't say what the mix is yet, probably leans toward Kv. I don't really think of Kv (aka the "Kv Design Language") as a alternative, more an option for when you get to the point where you need that separation of interface from logic (the "V" and the "C" resp. in MVC) just to keep things manageable and sane. The declarative nature of Kv is a bonus if working with a none-programmer, eg, an artist could easily pick it up and work on the look &amp; feel while coder/s concentrate on game-play.
The newest xlrd (0.9.2) reads .xlsx just fine. 
This is just what I was hoping would come out soon.