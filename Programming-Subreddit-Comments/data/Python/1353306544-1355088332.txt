What makes that better than IPython? It looks like IPy's Qtconsole, but for scientific work the IPy Notebook is much better.
ah no worries - sorry for the misinterpretation
without bit of code and exception name? no.
What errors do you get? Provide full traceback please. It can be that value inside of your dictionary is not what do_something is expecting, for example you can have {'a':1, 'b':None}, and do_something don't allow integers or None values. But for the future, always provide tb it you want to get answer. 
 &gt;&gt;&gt;def do_something(value): ... print value &gt;&gt;&gt;dict = {'a': 1, 'b':2} &gt;&gt;&gt;for key in dict: do_something(dict[key]) 1 2 Works fine, the error is apparently not where you expected it. Post the relevant code and error.
Yes, thank you everyone! I pulled my code apart and discovered that indeed, for key in dict: do_something(dict[key]) does work, so I must be doing something else wrong. And then I succeeded in passing my argument as a parameter onto successive functions, so I guess now I just need continue adding pieces back in until I find what's breaking. Anyway, thanks for helping break through my little mental logjam.
Right... I forgot. I always though .items() was a better choice for the default iterator.
I'll use it when it supports py3k :S
Great. Unfortunately this idea has been rejected in our team meeting, fearing it would create confusion where the package comes from. I still plan to use this in my personal project though. Thanks for working on it.
&gt; PRAW works with python 2.6, 2.7, 3.2, and 3.3.
That's got to be new, I don't remember it supporting 3.3.
commit 1086a64357ddc82cf24812f86d4aa709a352553c Author: Bryce Boe &lt;bbzbryce@gmail.com&gt; Date: Thu Nov 1 12:47:30 2012 -0700 Fix load_module error so python 3.3 works. Simplify login api path. Version bump.
PRAW supports 3.3 as of version 1.0.14, that was released a few days after Python 3.3 was released. [Changelog](https://github.com/praw-dev/praw/wiki/Changelog) &gt; ## PRAW 1.0.14 &gt; **[FEATURE]** Extended functionality to Python 3.3
Ah right, I remember the first time this one bit ne :). Thanks for the clarification.
Is this how you guys do unit testing? I always just separate the processing from the file io. But then I'll end up just testing the processing and never the file io. I always just assume the file io would work.
So you always write a function which opens files and returns the contents for you? Interesting.
Or a generator.
That's the pylab mode - you get it either by starting IPython with the `--pylab` flag, or using the `%pylab` magic command.
I'd suggest you install the libraries from apt (there are PPAs and extra repositories around if you need the latest versions), and then create your virtualenv with `--system-site-packages`. That avoids having to compile everything in place and do special things for PyQt.
Most of the code for redditgraphs is in javascript, but if anyone is interested it is on [github](https://github.com/1wheel/reddit-comment-visualizer). There is a little bit of [python](https://github.com/1wheel/reddit-comment-visualizer/blob/master/commentbot.py) - I wrote a bot that responded to comments containing variations of 'your posting history' with a link to the referenced person's redditgraph. The account I was using to post got shadow banned though, so I would not recommend running it. Also - this is the first python code I've written, so if you see something egregiously wrong, please tell me.
Dude, come on.
why not just tmpfile?
I think the idea here is ease of publishing. Just save it to your dropbox and there it is. Mind you, there is a myriad of other options for similarly easy publishing, but as the gist says, this project is pretty opinionated.
Why a generator? Or do you mean a context manager?
None of the above -- a string is a sequence, so `random.choice('cde')` works fine. If the actual items are more like `['foo', 'bar', 'baz']` then that is the form that I'd use. Splitting a string literal at runtime just to avoid typing a few extra characters seems to be trying too hard to be cute. 
&gt; Splitting a string literal at runtime just to avoid typing a few extra characters seems to be trying too hard to be cute. it depends on the length of the string, though. If it's three items, like in the OP, then `.split()` is sort of lazy and sloppy. But if it's 20 or 50 things, then it is much more understandable to take the `.split()` shortcut. It can also make it more convenient to maintain/change. I don't think either is more Pythonic per se. It just depends.
Which you can find out by hovering over it.
You could make your string like such, not that I am advocating it. You would still get the list like potential for commenting etc. You also need to add a delimiter char to split on =\ foo = random.choice(("red " "blue " "green " "purple " # purple eats people "yellow " "black " ).split()) 
Is there any particular reason you put the css in a style block in layout.html? 
I agree =) I was just throwing out another unique way of doing it and an alternative to using triple quotes.
`random.choice(['c', 'd', 'e'])` This doesn't have anything to do with `random.choice`. Because some people like to use the `.split()` bit all over the place. This is, by me, insane, and it doesn't have to do with pythonicity. It's just a ridiculously confusing way to write code, I want a list, sooooo, I'll write a string and split it. Of course!
The Zen of Python: Beautiful is better than ugly. **Explicit is better than implicit.** Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. **Readability counts.** (...) I'd argue that the second version is more readable and more explicit than the former, which makes it more "pythonic."
Seems like the real question is "Which is a more pythonic way to store a constant" ? If this was a static list of choices, and the course of your program chooses one at random, then I would probably do: COLOR_CHOICES = ['red', 'blue', 'yellow'] and then later random.choice(COLOR_CHOICES) which is perfectly obvious what is happening. When you do it this way, with a list, (or tuple) It becomes really really clear that COLOR_CHOICES = "red blue yellow".split() is sort of silly and would give any programmer pause as to wtf was going on (imo)
Psh, you need to practice your google-fu ;-). I searched "lotka-volterra python code", and the first two results were [Lotka-Volterra in the Scipy Cookbook](http://www.scipy.org/Cookbook/LoktaVolterraTutorial) and a [Lotka-Volterra simulator in Python](http://code.google.com/p/lotka-volterra-simulator/). The Scipy page in particular looks excellent if you really want to understand both the code and the equation. The curve fitting site [zunzun.com](http://zunzun.com/) also has various biological models, with [the source code available](http://code.google.com/p/pyeq2/source/browse/trunk/Models_2D/BioScience.py).
Hey, thanks, this zunzun site seems really useful! Although, it is also really slow and difficult to navigate. I copy-pasted the von Bertalanffy growth function below. I was really hoping for something more elaborate like the Lotka-Volterra things you found (I never used that search term myself, just gave up instantly on Bertalanffy). But I guess I can expand on it myself. The zunzun site is a good start at least. import math def BertalanffyGrowth_model(x_in): temp = 0.0 # coefficients Linf = # put constant here K = # put constant here tzero = # put constant here # calculate temp = Linf * (1.0 - math.exp(-1.0 * K * (x_in - tzero)) return temp
Nope, generator. If you are dealing with a sequence of something (a file could be a sequence of lines), a generator is a good abstraction for that.
Agreed. It's a list of items. That you can store them all in one string and split them to get the list is perhaps convenient, but it's hiding the obvious: it's a list of strings. Type it as a list of strings.
Ill have to try this, i tried octopress but it was god awful, could not figure out what actually does what, ruby being silly, etc etc
I agree with all the other commenters that the explicit list is better. A silly reason: this 'c d e'.split() Feels too much like qw(c d e) Which triggers my PTSD.
Looking through this... It seems like everyone assumes you will hard code items? Why on earth would anyone do that? I assume you would store it in a text file or a database. Then you load it, and you get it as a list. Then you use random.choice on that list. Problem solved, and scales infinitely, and no ugly hard coding.
I actually use Mathematica as my main graphing software. Next year my employment is changing and I most probably won't have access to it anymore, so I've been looking for a replacement. I use Matlab for data vis, and Mathematica for model vis. I'm also looking into R and ggplot2, looks pretty impressive. Edit: in reply to your main comment, I haven't really come across anything I couldn't do in Mathematica in terms of "how is it that this can't be done".
Is it a static blog generator like [Pelican](http://blog.getpelican.com/)? Or am I missing something? 
Why isn't this the top comment? The pythonic thing to do is to save off a list to a local variable and then pass that into the function call. This also saves on width to keep things down to 80 characters so that we can see changes side by side on a single page.
Unrepentant offender here. Writing ['c', 'd', 'e', 'f', 'g'] involves too many keystrokes. 25 vs 11. 
You've gained nothing if you put one word on each line (and I'd agree). Most people use it to split a longer list over a few lines (as I did [here](http://www.reddit.com/r/Python/comments/13gxg0/help_me_settle_a_debate_which_is_more_pythonic/c741v46))
Please tell me you are not recoding the reddit uptime engine? It's been working pretty good lately. ;)
&gt;random.choice("c d e".split()) I can't believe that's even a contender. I feel like TheDailyWTF is leaking.
&gt;You read code more than you write it. I'm not a fan of "get everything right the first time". Probably 90% of my code will almost never be read again. Things that will get read over and over (at least by me) will improve over time. The next time I'm reading the code and if it looks ugly to me, I'll clean it up. If I don't read it often enough for that to happen naturally, the code isn't worth fixing. It's much better than writing everything obsessively neatly every single time. If this were a case where the code can confuse, I'd sympathize. This is not one of those cases where another programmer will look at it and get confused. &gt;If you're too lazy to type it out, open a shell, generate the damn code, and paste it into your editor. That doesn't really save keystrokes...
not that pythonicity really has anything to do with performance. It's more about simplicity &amp; readability.
When in doubt, I go for readability. The value of code being readable transcends the pythonic vs. non-pythonic debate.
If I *had* to choose between only those two, it'd be the second option.
Although random.choice('cde') is pretty cool. I would argue it is less pythonic. It is less clear than random.choice(['c','d','e']). At least depending on the context of who will look at your code some one without a signifigant python backround would be more easily confused by random.choice('cde').
I agree, it's way too straightforward. If you want to write your list as a string, do it right. random.choice("['c', 'd', 'e']".strip("[',]").split("', '"))
But we aren't codegolfing here, are we?
&gt;It's more beautiful to read code not full of quotes and commas. Unless your editor highlights them properly. &gt;It's simpler to type. Which is the only reason I prefer it. &gt;It's obvious to eveyone here the code does once you saw. Which is why I don't mind doing it. Seriously, I really do agree on readability, but I've never found a Python coder who'd get confused reading this. 
Better yet, write a regex to find the contents of things bracketed by ' in this string... random.choice("['c', 'd', 'e']".strip("[',]").split("', '"))
Thought it's *very* nice when they sync up, as they do here.
I have heard good things about: https://www.django-cms.org/
And then the next guy comes and changes your code to this: "one, two, three, four, five,six".split(", ") And wonders why it doesn't work. Personally, I prefer to have a separate line for each entry: numbers = [ "one", "two", "three", "four", "five", "six" ] The disadvantage is that it uses more vertical space, although I never found this to be a real issue. The advantages are that the list elements are visually separated and you can rapidly add elements by copy &amp; pasting one line, then modifying it. It's not as fast as the splitting, but faster and less syntax-error prone than the one-line approach.
Consider these: [collections.namedtuple](http://docs.python.org/2.7/library/collections.html?highlight=namedtuple#collections.namedtuple) (second line) and [the argparse documentation](http://docs.python.org/2/library/argparse.html) (search for ".split()") I think there's an argument for readability in some cases like these. At least some contributor to the python standard library thought so. Compare: &gt;&gt;&gt; parser.parse_args('--foo B cmd --arg1 XX ZZ'.split()) &gt;&gt;&gt; parser.parse_args(['--foo', 'B', 'cmd', '--arg1', 'XX', 'ZZ']) I wouldn't do this everywhere but in this case I like it better.
True. I find the parens of tuples less visually distracting than the square brackets of lists, though, so I quite like the tuple version.
I'd vote for the second formulation for all the reasons mentioned previously but also because you don't want future devs (who may be new to Python) getting blocked by wondering what the default behavior of `.split()` is. This is especially important when you consider some of the triple-quoted examples in this thread. "Does `.split()` work on *all* whitespace or just spaces?" Yeah, it's something everyone should *just know*, but why bother introducing the question?
http://gettingstartedwithdjango.com/ Their Kickstarter talked about showing how to solve real life problems and going beyond the Django tutorial, however it is not done yet.
Ugh. Code generation in order not to type too much? Ever heard of separating data and code? If you have 50 words, put them into a file, separated by newlines, and parse that.
If this is a constant, shouldn't it be a tuple?
I can't think of a scenario where you should have 20 or 50 literals like that. If there are that many I would expect them to be coming from a database, or a web request, or even just a text file on the local file system. Of course, if it might just be a one-off script, but the goal of pythonicity is maintainability, so the point at which you would start caring about pythonicity is the point at which you would move those literals out of the source code. 
Forget it. Every pythonista knows strings are iterable.
Maybe, but I wanted to install everything in an existing virtualenv, so I think it was the best solution. And even with a brand new virtualenv, I think using pip should be faster than gathering all the differents PPAs and extra repositories.
random.choice("cde")
I agree. Firstly, the syntax: random.choice(['c', 'd', 'e']) is clearer to understand that the alternative. And also, explicit is better...
What the shit are you talking about? Opening and closing quotes? Are you a caveman? Imagine this: L = [ "", # STOP TYPING, HIGHLIGHT THE QUOTES. COPY AND PASTE L = [ "", "", "", "", "", "", "", "" ] # OH SHIT, LOGIC L = [ "1", "2", "3", "4", "5", "6", "7", "8" ] You're stretching very hard to give a valid reason for being downright silly. 
Just random.choice("cde"). choice expects a sequence, and a str is a sequence of characters. 
While I don't agree with the formatting that BeetleB uses (for whatever my opinion is worth), I really don't think you need to be so confrontational about it, especially since the main reason they gave for not wanting to continually type opening and closing quotes was that it disrupted their thought process. Your method seems like it would be even more likely to break someone's flow and interrupt their train of thought.
I started out with "freemind" but found it way too clunky and full of mysterious stuff. I use workflowy.com because of that -- which is really a zoomable outline with tags/links and just the right amount of functionality. To me, the mindmap program are like the 3D UNIX Interface as seen in Jurassic Park. 
What's wrong with: random.choice("cde") str are iterable. Yours are both ugly.
There's a school of thought that says "lists are for homogenous data, tuples are for heterogenous data". Lists are arrays, tuples are records or structures. It makes sense to sort a list, but not a tuple. The position of an element in a tuple matters a lot, in a list not much. Etc. Consider a coordinate vector as a typical tuple -- position 0 is the X coordinate, position 1 is the Y coordinate. The length of a tuple is fixed, operations such as sorting or inserting in the middle make no sense (usually). There's another school of thought that says "eh, whatever". The Python standard library uses tuples as immutable lists in some places (e.g. isinstance accepts a tuple of classes, but not a tuple of lists).
My apologies for attempting to make civil conversation with you. I should have known, based on your previous comment, that you weren't inclined.
And it's *very* easy to forget the space at the end, mistakenly joining two words. Aside: This is partially why I've decided to always put the space on the new line when I split strings, to make it more prominent: raise ConfigurationError("If you specify the foo property" " then you must also specify the bar" " property.") 
Nah. It's a list of colors, why would it be a tuple? On a more serious note, I would make it a tuple -- but only if it were possible for someone to accidentally modify it (through aliasing to some variable, say). But a constant passed to random.choice? No, a list is fine (and feels more readable/natural to me).
To me "Pythonic" is short for "idiomatic Python", i.e. the way code would look like if written by an experienced Python programmer immersed in the cultural values shared by most of the Python community.
Here are some [hastily assembled, just now] vim mappings to help: vnoremap ,' :s/\%V\(\h\+\w*\)\ze\s*/'\1',/g&lt;CR&gt; vnoremap ," :s/\%V[',]//g&lt;CR&gt; Now you can select a set of space-separated strings, hit (in my case) `,'` and the words will be wrapped in ' chars. For example, if you were at the beginning of this line: this is a [test of converting strings] to a list You could hit `f[` to jump to the [, then `vi[` to visually select inside the brackets, then hit `,'` to turn it into this: this is a ['test', 'of', 'converting', 'strings',] to a list Then you can select in the brackets again and do `'"` to turn them back into space-separated strings for easy editing, reordering, etc. I like to let my editor do the work for me.
This is the first thing that came to my mind as well. I was seriously thinking I'm missing some important detail seeing this huge discussion start without this solution being mentioned. Good to see I'm not alone.
Best of all, write [some regex mappings in Vim](http://www.reddit.com/r/Python/comments/13gxg0/help_me_settle_a_debate_which_is_more_pythonic/c745xdg) to make it easy to convert on-the-fly as I'm editing.
I don't see how it's any faster to take the _extra trouble_ of typing .split(). If you have a string input, sure... but that's not what we're dealing with in the example.
Yep, jedberg needs to give us more context on the problem to really get the right solution.
Installing into an existing virtualenv is fair enough. I don't think it takes that long to add a couple of PPAs, though. If you can use Ubuntu 12.10, then the versions in the main repositories should be fine. For 12.04, the [IPython PPA](https://launchpad.net/~jtaylor/+archive/ipython) is the only one I'd tell a newcomer to worry about. And doing updates with apt is much nicer than with pip.
wow, over react much? I'm not trying to save typing, I'm trying to avoid doing a O(N) operation at runtime every time I need to use the data. Parse it once and it is a native data type that is parsed once by the compiler for the lifespan of the process.
Given one-letter choices, I'd probably do `random.choice("cde")`, but if there's a possibility that the choices will be longer, it would be `random.choice(['c', 'd', 'e'])`. Why? First, because it's faster. Second, and probably more importantly, because reading it requires a lower cognitive load. You look at it and say "I'm taking the choice of items in this list." In the first example you look at it and say, "I'm taking a random choice from this string. But the string is being split. And the things that are being split (since split doesn't have any arguments), are the strings `"c"`, `"d"`, and `"e"`. Simple is better than complex. And there should be one obvious way to do it.
I bought into that (first) school of thought until I started paying attention to their behavior in common operations. If the position of an element in a tuple is the relevant thing, then why does (a, b) + (c, d) return (a, b, c, d)? You've just changed the (important) position of the elements. Shouldn't it return (a+c, b+d), or just not work at all? I mean, I still follow that school of thought to some extent, but not enough to argue about using tuples as immutable lists. The implementation just doesn't support the theory. 
If I were working with, for instance, colors, and I wanted the list `['r', 'g', 'b']`, there is no way I would store that externally. My python code *is* a text file, and it's the most obvious place for short lists like that.
I wish it wasn't nessacary; I need it purely for Gtk + virtualenv. Let me know any issues you have, on github.
/agree. Immediately I was thinking of a Perl programmer trying to make up for Python's lack of qw() 
Perl Traumatic Stress Disorder
I started building wheel as a distutils2 command but decided to make it a setuptools plugin instead. There is also an unfinished implementation for Bento. The cool thing is that once you have the wheel, you can install it without also installing the build system (setuptools or Bento). The format is based on the packaging PEPs. As part of the effort, distribute (the premier setuptools fork) also understands the packaging PEP 376 at least as far as it is needed to parse dependencies out of wheels. distlib has a lot of the functionality of pkg_resources and some of easy_install or pip, but with a different API. pkg_resources is a mostly-independent module bundled with setuptools that serves as a runtime linker, contains the dependency logic, and lets you load resources from PYTHONPATH in an abstracted way. I don't think it will be horrible at all to have distutils (setuptools) and the new packaging world (Bento, distutils2?) meet by means of PEP 376 and Metadata 1.2+. These PEPs are a reasonably easy to implement packaging analog to how WSGI interfaces web servers and web frameworks - interoperability based on specifications and not on a single implementation.
Heck, I actually use gedit and my point still stands.
To further the arguments in this thread; this seems like someone is trying to translate a ruby idiom %w{"string string string"} to Python. Python isn't Ruby. I'm not making an argument for one or the other, it's just that sometimes things don't translate right. That is to say, another vote for not splitting the string.
I would opt for the explicit list. What if you wanted to choose the space character " " at some point? The list is easier to maintain for future development.
This is weird, why would you ever use split - random.choice('cde') Is completely fine. random.choice(['c', 'd', 'e']) # takes more characters. 
I have no idea why they'd do that; most times just using a string would be fine.
Do you really need .split() - a lot of times you just want an iterator - Just use 'cdefg' Not 'c d e f g'.split() OK, you *really* want a list do list('cdefg') Calling .split to go through and remove all those spaces is just insane.
well, here you're more comparing "creating nothing in PyPy" with "creating nothing in CPython"... and PyPy wins massively
Hello Redditors. I just bought a server and was wondering if anybody could help me? I have never tryed python before and was wondering if somebody could help Regards Henrik
That only works if all your elements are single charactors. 
It's like saying, "I have four quarters I could use right now, or I could get change for this dollar and then use those four quarters instead."
subprocess.Popen supports this. The constructor has a cwd argument. And it sounds like you want shell=False. 
You haven't really stated your question and the link in your title is broken.
Wat.
For simple uses, don't bother with `Popen` - use one of the shortcut functions, like `subprocess.call`. They take all the same arguments as `Popen`.
My first attempt at writing a blog post. Feedback is welcome, I hope I don't anger to many people with my first post and hope for helpful criticism. I have written several bottle apps, but wanted to try flask. I was having a hard time understanding flask-login, and learned from flask-security how to implement flask-login tokens, so I wanted to share. 
&gt; Cursors are cheap. Create one each time. I agree that cursors are cheap, but the decision to make one each time is more complex than the immediate resource costs. While working for my current employer on a Django web application that runs against a third party's MSSQL database, I encountered significant trouble with concurrent access with cursor-per-query logic. This was due to the volume of calls (99.9% of which were reads). Ours is a WSGI app, and we found that each session ended up with a connection and cursor(s) of its own. Access was done only in series, so the effective amount of open cursors is `number_of_users`. Now, in our case, there are many users executing mostly reads in series--but concurrent with one another and very quickly. While one of the daemon processes was running (executing a fast series of reads), we couldn't get a working cursor--almost as if the daemon were hogging them. The solution we have in place now maintains a single cursor for the lifetime of the connection, and since we only allocate `number_of_users` cursors we have so far avoided our previous predicament. 
I see "better" to be an invitation to discuss objective tradeoffs. I see "Pythonic" to be an invitation to debate a subjective label (usually by quoting Python Zen). Regarding speed vs. readable, I see things a little differently. Here is my operational definition of "better": By default, readable is better than fast. If profiling later shows that area to be a bottleneck, then it makes sense to later start trading readability for efficiency. 
While I agree that in theory "better" means nothing unless you specify a metric, in practice the "better" choice is so frequently the readable one, that readability is the default metric. Of course it sometimes makes sense to trade readability for other attributes, such as efficiency. I see "better" as an invitation to compare these objective tradeoffs (in a language independent vocabulary). I see "Pythonic" as an invitation to debate a subjective label, usually by quoting Python Zen.
My [least] favorite is implicit relative imports, which thankfully are gone in 3 although I'm still stuck on 2 for a long time. Not being able to name any module the same as any potential top-level package is really obnoxious. Even more exciting is when it combines with case-insensitive filesystems (e.g. the default volume in OS X, not just Windows) -- a module called 'crypto' normally doesn't mask a third party library called 'Crypto', but on OS X and Windows suddenly stuff stops working because 'import Crypto' becomes relative...
I agree. You're reinventing the wheel that the `libmagic` library (of which the ubiquitous `file` command is a client) has painstakingly already invented. That module provides Python bindings for the library. I would even go so far as to say that it would be better to run the `file` command as a subprocess and parse its output if you cannot for some reason use that module, compared to rolling your own. (But watch out for filename quoting problems and avoid shell injection vulnerabilities.) 
You're forgetting the final entry in "The Zen of Python": ... If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! Overreact on minor language issues whenever possible.
It's shorter .call is equivalent to common boilerplate with subprocess
It's not better, its just a convenience wrapper. Here's the implementation from subprocess.py def call(*popenargs, **kwargs): """Run command with arguments. Wait for command to complete, then return the returncode attribute. The arguments are the same as for the Popen constructor. Example: retcode = call(["ls", "-l"]) """ return Popen(*popenargs, **kwargs).wait() 
Thanks for checking it out. The intention of the library is to make some slightly intelligent decisions about what to do with inputs and their types on its own, instead of exposing that complexity to the user. Besides, there's really no type certainty in functions in Python anyway :)
Didn't see that one but I found its predecessor bug report in bugs.python http://bugs.python.org/issue11240 
I think I'm on your side of the argument (I'm a different guy than that other guy). For me, though, I work in Vim, and smashing things into lists and back out again like this is child's play.
A bit much but https://github.com/getsentry/sentry
When you use Flask use Flask-SQLAlchemy extension.
i think scipy/numpy has a [function](http://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html#numpy.polyfit) that should get you going in that direction.
Yeah, but I'm not sure that works. See, the point would be to keep the function fixed (i.e. unmodified von Bertalanffy growth) and just modify the parameters. I'm pretty sure functions like the scipy/numpy one will add parameters to make the function fit, instead of adjusting existing parameters?
sorry I misread you.
&gt; converting to and from epoch timestamps Well if you're on Linux... http://stackoverflow.com/a/2775947/564755
Speaking as the guy who had the original conflict with jedberg on this issue (and who goes for "foo bar baz".split() all over the place), I'm frankly grateful for the amount of feedback and opinions expressed by everyone here. I've been a big fan of that pattern, both because it actually felt more pythonic to me and -- more practically -- because it's vastly easier for me to type. It feels painfully slow and awkward to type a list the old fashioned way. That said, people's perspectives on this have swayed me to be far more conservative in using this. I'll try to stop using it; in the worst case, it should make people like jedberg less likely to weep as they review my code. Thanks, everyone! -roy
Maybe I'm missing something, but why did you make a whole new class to represent times? Why didn't you just make it a function that returns `datetime` objects?
Your code might be read by someone who is not a pythonista though.
Why don't you just make functions in your module to take care of all those things? ts = arrow.totimestamp(dt) dt2 = arrow.replace(dt1, tz="US/Pacific") I'd much prefer this to having to deal with yet another datetime format that I would have to explicitly convert to the standard library's every time I need to interoperate with something else.
A list. Practicality beats purity.
What follows isn't really Pythonic (I'd say `['c', 'd', 'e']` is), but this is an interesting way to bring qw to Python. Suggestions for improvements (or "improvements") welcome. class QW: def __init__(self): self.sofar = [] def __call__(self): total = self.sofar self.sofar = [] return total def __getattr__(self, name): self.sofar.append(name.lstrip('_').replace('_', ' ')) return self qw = QW() print qw.hello.world.this._is.weird.peace_out() # ['hello', 'world', 'this', 'is', 'weird', 'peace out'] 
At the moment everyone is unsure what it is you're hoping to achieve so the responses you've received haven't been very helpful. We really need your help if we are going to be able to help you. What is your goal? Are you hoping to learn python? Are you asking for help to set up a specific python based project? Are you asking for advice in system administration?
You don't really need to "convert" anything, arrow objects give you access to the underlying objects, so now just do "arrow.datetime" and it returns itself as an appropriate datetime object. At least, that's what it appears to do according to the docs.
Yeah I would rather not have to deal with that. If I have to pass `deadline` to `scheduleNextRelease` (a function that expects a datetime and which I have no control over) I don't want to have to remember whether `deadline` is an `arrow` or a `datetime`. Something that's fully, duck-typably interoperable with datetimes would be fine too, as would a datetime subclass.
Right. So a 3rd degree is something like a + bx + cx^2 + dx^3 And I assume the function puts whatever a/b/c/d that makes it fit (or no a/b/c/d if that is best). What I'm talking about is inputting something like a * (1 - e^(-b * (t - t0))) Where only a and b are adjusted to arrive at an answer. No additional a/b/c's and no touching t/t0. If I put that into numpy/scipy function, without having tried it, I think what would happen is it would take that expression by itself and then add a parameter to multiply it with to make it fit. Thus, the function is no longer the same.
&gt; Then there are SQLAlchemy sessions. Using SA, you get a "sessionmaker" which is basically a factory for sessions. This, to me, is a hint that you may want more than one session. But why? Should I go on the same feeling as I have for cursors/connections? this is a common question, so I maintain documentation dedicated to addressing this issue, which I update frequently. The current version is updated as of several weeks ago and can be found here: http://docs.sqlalchemy.org/en/rel_0_8/orm/session.html#session-frequently-asked-questions It's also refreshing to see the question posed such that it's apparent that this issue is really about database connections and transactions first and foremost, and isn't an issue introduced by SQLAlchemy, since it isn't. SQLAlchemy doesn't try to singlehandedly solve the issue of connection scope, since different applications will have different needs. The developer still needs to make this determination.
Sometimes I think the whole thing is a trap
My knee-jerk response is that OP is looking for a function that returns the number of bits that are set, or 1, in the binary representation of a number. Probably a homework problem, so I'll only outline: **Obvious Method** 1. While your number (x) is non-zero: - If the number is odd, increment the number of bits. - Right shift the number. **Not So Obvious Method** In the obvious method the loop runs n times, where n is the highest order bit set in the number. For example, to determine that 3220 has 5 bits set, the loop needs to execute 12 times. This performance can be improved. Try to think of a method of masking off just the lowest order bit. Your function would look like this: 1. While your number (x) is non-zero: - Increment the number of bits - Set X to the it's value with the lowest-order 1 bit masked off. Let's run through an example, using 27. The binary representation of 27 is 11011, so it has 4 bits. |Iteration | x |Number of bits| |::|::|::| |1|11011 (27) -&gt; 11010 (26)|1| |2|11010 (26) -&gt; 11000 (24)|2| |3|11000 (24) -&gt; 10000 (16)|3| |4|10000 (16) -&gt; 00000 (0)|4| 
Seems like the arrow function takes over everything..
I could be wrong, but doesn't the threading/multiprocess module handle this?
yes, very thorough thank you
I meant that I thought both would do what he wanted, albeit in different ways. Thanks for the link though I haven't used the modules, but from what I read in the manual either should do what he wants (which I thought was simultaneous code execution)
Sounds like something you want non blocking io for. Look into greenlets and gevent. If you have a server cluster it might be better to use something like celery that could run multiple task servers, perhaps each task monitoring a stock quote. Sorry for the Shitty explanation, I'm on my phone and it's late.
My usual multithreaded setup is make a function/method which spawns threads (threading.Thread) which call whatever function needs to be called with various arguments. One of these arguments is a 'return' queue (Queue.Queue). Set up another function (we'll call him bob) which responds to events/processes data/whatever inside a while: True type construct, and have it block on the 'return' queue we set up earlier. We can break the loop by putting a termination signal in the queue, if that helps. So, we have a bunch of Threads watching stocks. If they see a stock change, they will put that change (or some other data) in the return queue. The bob function is blocking on that queue, and so sees the change. The bob function dequeues the data, updates the database/writes a poem/whatever it's supposed to do with that data, and loops back to blocking on the queue. If you have certain data you need processed first, a very similar setup is possible with a priority queue. EDIT: Not sure how many threads we're talking here. This tends to work for smallish numbers, though.
I would like to use an off-the-shelf solution. However, I tend to separate database model (which includes all sqlalchemy stuff) from user-interface (which would be Flask) with two separate python projects. The main reason for this is that I can easily switch to a different web-framework if need be, or even write a Qtm or CLI app based on the exact same business model. This has proven to be very useful in the past. Unfortunately this means that I cannot use Flask-SqlAlchemy :( This is also why I ask this question. And before implementing it on my own, I want to eradicate all sources of doubt, all questions from my head.
then how do you close the file?
Use Erlang /ducks
But seriously, look into Erlang if you want to do concurrency. 
Multiprocessing would mean thousands of system processes per stock if he modeled it that way. He'd likely be better off trying gevent since monitoring stocks is a io bound operation. 
I love and adore Python for it's ease and simplicity in so many diverse use cases...but this might not be one of the times to use it. You'll be able to get something to work using gevent + multiprocessing (to take advantage of multiple processors) but it just doesn't scale as easily as a language designed for efficient concurrency. Use the right tool for the job. Maybe design the "watching" in Go/Erlang/Rust and then use Python for tasks that don't need to be highly concurrent or explicitly performant. However, since you asked in /r/Python ... This was best answered by denzen (http://www.reddit.com/r/Python/comments/13jwq8/nonlinear_python_programming_question/c74nfpj)
In a lot of the cases where I use this the choices come from elsewhere - usually a cut-n-paste away from some other window. This leads to the more natural thing being to split the copied string. You are left with a less manhandled bit of code that tracks back to a reference better. So I would prefer the split() in those cases. I would also prefer the split if the individually quoted words were short and numerous. But that is a preference. I wouldn't say that one is un-pythonic because of the reasons I have given. 
This post also generated [heated discussion](http://news.ycombinator.com/item?id=4811460) on Hacker News. IMHO, the guy is just desperate to promote his framework, just take a look at the list of blogposts [here](https://bitbucket.org/akorn/helloworld). Not saying that all of these benchmarks are completely useless, but they show nothing more than the fact that the web frameworks can not be implemented without introducing certain level of complexity in them.
I just wanted somebody to make a css script :) (eventscript)
this blocks, however. if you want to call it parallelly, you have to do it without waiting.
The magic word is: "callbacks" You want each subscription to be bound to a function, where that function handles the stock updates. You'll have a dict/list of callbacks and a single thread of I/O. The I/O thread parses the update and dispatches to the relevant callback. If you're running multiple I/O connections, same idea, but they share the callback table. Source: I build HFT systems. (*On the exchange side, not the trader side*) 
Erlang has OTP and better handling of errors than Go. Go is a nice second choice but I'd really suggest learning OTP and why Erlang's "let it fail" error handling is superior when it comes to fault prone things like continuously fetching stock symbols. For instance, for this, I'd create a process for each stock symbol that periodically wakes up, fetches the content and then hibernates until the next time I want to fetch. This is all really easy with a Erlang/OTP gen_server. I'd use an Erlang supervisor to watch over all these processes and if one of them fails hard, the supervisor would restart it and it'll continue on its mary way. Imagine if you got a unexpected stack trace in Python or Go, the whole thing would go down. Erlang will repair itself if something unexpected happens. Sorry, I'm done with the off-topic Erlang evangelizing. DM if anyone is curious.
This is true; was looking at the original question. If it's not single characters then I just create a list... random.choice(['yes', 'no' 'maybe', 'not sure']) The code is easier to read, ideally the code should do as little as possible.
They both wait until the process terminates. But `.communicate()` does something else in addition to that: it sets up the necessary machinery to read and write data from one or more pipes. This is necessary because a process that tries to write to a pipe with a full buffer will block. If your subprocess is writing its stdout to a pipe, then you must constantly empty that pipe by reading from it as the process runs, or else it will block. Simply waiting on the process to finish would deadlock. And if there is more than one pipe, such as the case where you're capturing stdout and feeding stdin, then you have another problem, because your program might block trying to write into the stdin pipe, and the subprocess might simultaneously block if it happens to fill up the stdout pipe, also resulting in a deadlock. `.communicate()` sets up the necessary loop (using `poll()`, `select()`, or threads) to simultaneously read and write from any pipes that were established to or from the process in a safe way that won't deadlock. However, in the example above, there are no pipes to read or write from, so all of the above is irrelevant, and calling `.wait()` is fine and sufficent. You can also avoid `.communicate()` if there is a single pipe, as long as you write a loop that continually reads from or writes to it until EOF, and then call `.wait()` to reap the process. (If you look at the source to `.communicate()` it has a special case for this situation that does just that.) 
well, well... if it isnt my arch FUCKing nemesis.... 
Your blog posts currently return 500. http://floatboth.com/where-i-compare-saas-to-something
**Q:** I want to do $NETWORK_THING with Python. **A:** Twisted. ...or gevent or Stackless or some other concurrency library.
Unless you have good reason to avoid that type of tight coupling. There are many good reasons.
Greenlets are just a different flavor of threads, with the attendant problems of multithreading (and less benefits).
No, the benefit is that they're much more lightweight. It is trivial to have 10,000 concurrent greenlets, but having 10,000 concurrent threads can often create problems. Also they context switch automatically instead of blocking, which gives you the same asynchronicity as callback-based engines.
May I suggest [sh](http://amoffat.github.com/sh/): a full-fledged subprocess interface for Python that allows you to call any program as if it were a function
A lighter weight alternative to eval is the ast module. It's pretty easy to parse an expression with it and manually evaluate it.
I don't understand what distinction you're making between "context switch automatically" and "blocking". The advantage of threads is that you can use them to cope with blocking APIs that don't have an async equivalent. There's no advantage to using greenlets/coroutines over just using async APIs directly, and there's the disadvantage of needing to cope with multiple execution contexts and synchronization issues.
The gevent API is similar to the threading API, though with much less boilerplate. I'd say the complete reverse of your statement: you get the advantage of using a synchronous API while still having completely asynchronous and nearly limitless communication, without any of the disadvantages of using an async API. Synchronization is an issue for anything you do that needs concurrency, not just threading. Greenlet APIs are generally, much, much nicer than any kind of callback-based API. I don't have time to give lots of examples and compare and contrast, but if you ever work on any kind of project (either a client or a server) in Twisted, then try and do the same thing in gevent, you will write MUCH less code, and the code you write will be much easier to write and to understand.
List....hands down. Unless you are going to refactor the whole thing into some kind of a function that expects a raw string (eg from a file, database or webserver)
that is really cool. have it posted on github or anything?
No, I just wrote it pretty much all today so it is a bit messy. Also I dont have a github. But I will reply to the people on here probably sometime tomorrow with, if nothing else, at least the webCrawler for reddit. linked either to github or pastebin.
Ha, yeah understandable. After I tidy up the code and make it somewhat universal I will put it out there. For the time being, I used urllib to query reddit, saved that to a regular txt file. Then processed the data using ugly string find() methods. After all the information was pulled from the reddit page I saved the data out as lists to a .p file using cPickle. For the visualization I used matplotlib in the first two graphs, and cairoplot for the last one. My graphing functions could use a lot of help, as it is only my first time using them.
Great to see the method, and definitely looks nicer. However, I find your old method more intuitive and can understand it much quicker without having to know the intricacies of how dict works.
I will have to look into that. The only thin I really require from the framework is to properly set-up the connection. The model and everything else is defined in the other project. But thanks for pointing this out. So far I have only seen examples of smallish demo-applications which all use `declarative` which I rarely (if ever) use.
With Python 3, you can use the new [ChainMap](http://docs.python.org/dev/library/collections#collections.ChainMap) class: newdict = ChainMap({'newkey': newvalue; 'oldkey': other_newvalue}, originaldict)
Yeah, especially since the key could be anything! If you saw: dict(originaldict, max_size=10) Would you guess that was a keyword argument to dict, or just setting a new key?
and a [tutorial here](http://www.agillo.net/loving-python/) !
For the Reddit queries, I would advise checking out [praw](https://github.com/praw-dev/praw), it's a nice library for using the Reddit API and would likely save you a bit of work.
&gt; Would you guess that was a keyword argument to dict, or just setting a new key? dict has no keyword arguments so...
Damn, upgrading to Python 3 or moving entirely to PyPy, that is the question.
Yes.
Generally I agree, but in the case of arrow, you try to do different things based on the input: current time in different time zones, time relative to it, and absolute time. I would split this up in 3 invocations: ## current time arrow.now('local') arrow.now('+01:00') #this is a timezone, no offset ## delta arrow.now() + '01:00' arrow.now() + timedelta(hours=1) ## absolute time arrow('27-12-2007T08:00+01:00') #isoformat arrow(time.time()) arrow(datetime(...)) arrow(2000, 12, 27) Btw. the only thing I really really miss about datetime objects is the lack of a constructor from iso format.
One day. As soon as numpy support is done people will be flocking to pypy I'm sure.
Is there any work being done to make it easier to port CPython modules (e.g. PyQt) to PyPy? 
That is good news. (I can't find anything that looks like a release announcement apart from that blog post.) 
oh, ok. I was hoping to see some mention of CPyExt on there. 
ARM support is fantastic news.
They're written in C.
No problem. I use matplotlib a lot but haven't had the opportunity to use the XKCDify module yet, but I think it looks cool :)
Some parts even call into Fortran! If I understand it right.
yes
as the release announcement says, it's coming along. To be more precise, there is quite a bit of mundane work to be done, like removing the global state from the JIT. This is the current focus.
but since CPython only has a interface to C and not Fortran, from my limited understanding cffi should be sufficient for both.
Porting scipy, pandas, and matplotlib will probably be easier once numpy is ported. But there are probably lots of little (but essential) field specific packages that will make migration difficult for most that use the current stack.
My personal taste is that more compact means more readable if it's still explicit and clear. But I agree that using copy() makes it even more explicit.
Thanks for the good work Maciej.
to be honest there is none of my work in ARM (barring the parts shared with x86 backend), most of the credit goes to David Schneider
Just because an interface is documented does not mean it is "explicit". The first version is confusing unless you happen to know the behavior of the dict() function. The second version (or luckystarr's suggestion) is explicit; the intent is clear and unambiguous. 
With the Numba project taking off there is now a way to selectively JIT just the numeric parts that need to be efficient, which I think will probably be a lot more feasible in the long run than trying to add a tracing JIT to the entirety of CPython and splice numpy support in.
Could CPyExt ever be rewritten using cffi, in such a way that it's as fast as it is on cpython? Or is the slowness absolutely inherent in having a moving GC? If that's true, could a GC be written that doesn't require the emulation?
it's not about a moving GC. It's about refcounting, moving GC, tons of internal details etc. etc. To have a fast cpyext would mean impose very serious restrictions on PyPy's datastructures for example. Lack of those restriction is something that we decided is worth starting PyPy in the first place.
Ah, too bad. What about offering a similar api, for porting purposes, that uses cffi? from what I understand, cffi is just as fast as native "cpyext" on cpython, right? edit: also, a cython-to-(python w/cffi) translator would be cool. I wouldn't imagine it'd be very hard, either. edit #2: rephrase: "from what I understand, cffi on cpython is just as fast as cpython's api on cpython, right?"
Thanks! I've been using Python to automate a lot of stuff at work - also using 'ugly string find() methods' (lulz) - and I have been looking into making graphs very similar to yours... just haven't had the time to do anything with matplotlib. 
Yay, github! Thanks for the link! I know what you mean about tidying up the code... I'm so ashamed of my hacky work code I feel like it will be years before I post anything on git :)
You should look in to [cairoplot](http://linil.wordpress.com/2008/09/16/cairoplot-11/) it has lots more customization and after the tricky install, it was very simple to get a finished graph. (some of the *args have the wrong name in the documentation though) Like 'v_bounds' is actually 'y_bounds'. If you have a windows machine follow the [first two answers on stackoverflow to install](http://stackoverflow.com/questions/8704407/how-do-you-install-pycairo-cairo-for-python-on-windows). If you have linux I think the install is very simple.
check out [pyiso8601](http://code.google.com/p/pyiso8601/source/browse/trunk/iso8601/iso8601.py)
I dunno, just because you don't know it is the first time you see it, doesn't mean that the second time won't be.
How well did your approach scale with the number of users? This always scares me, that I build a server that looks fine and hopelessly dies in the real world. Is there a lot if magic involved or will a python server with django or something similar work gracefully with many users?
Yes. The bottom of a Python traceback is the top of the execution stack. 
Generally people just plug into nginx or Apache and have no need to worry.
I thought that cffi was not supposed to be slow on CPython and was the point of it. That it was fast for both pypy and CPython but I might be wrong.
Otherwise the object reference is set for both variables... so they both point to the same object, so when you modify one it modifies both. You have to create a new object, not just assign with = 
Any plans for reducing the memory usage? Last time I checked PyPy uses considerably more memory than CPython in most use cases.
Oh, I misread your post. Thought you referred to numpypy... sorry about that.
I might be interested in helping with the numpy/scipy effort, where should i go to get involved? Is there a mailing list, list of tasks, etc?
One of the main reasons PyPy is faster is because of Just In Time (JIT) compiling. JIT-compiler gives you improved performance at the expense of memory.
whoa
Doctests that print dictionaries directly were already broken before hash randomization changes -- dict order differs on 32-bit and 64-bit Python builds because of slight differences in string hashing. That's what pprint() is for.
I recently [fixed](https://bitbucket.org/mgedmin/dozer/changeset/2c8f6aa1303e2f9495ffa22abcb4e33b) the same issue in Dozer.
and to mention a few other memort improvements, pypy has strategies for compact collections so a for example list of machine sized integers will end up as a integer array in memory instead of a array of object references to integers various other strategies are available for tuples and dictionaries
IRC is the best support channel. Just come and ask. One obvious thing to do is to add pickling support.
One thing I never figured out with gettext was how to translate nouns with the correct case. Code example. import random animals = ("Pig", "Goose", "Sheep", "Dog") chaser = random.choice(animals) chased = random.choice(animals) print "The %s chased a %s" % (chaser, chased) Internationalising this is tricky. Consider these examples in German (blame Google translate for errors) * "The dog chased a pig" -&gt; "Der Hund jagte ein Schwein" * "The pig chased a dog" -&gt; "Das Schwein jagte einen Hund" * "The goose chased a dog" -&gt; "Die Gans jagte einen Hund" * "The sheep chased a goose" -&gt; "Die Schafe jagte eine Gans" Ok, you might think that we could change the progam to store "A dog" and "the dog" but the problem is more complex. If the program changes to output "The %s ate the %s", you get other versions of "the". * "The goose ate the dog" -&gt; "Die Gans a den Hund" The articles change depending on the word's gender, case, count and whether it's definite or indefinte (the or a). You can find tables for looking them up, there's a 4x4 table for definite and for indefinite. But to look that up you'd have know the case in the sentence the word is used in, and the gender of the word. All quite complicated. A further difficulty is that in some languages it's not just nouns that change but also pronouns. In Icelandic the national bank can be referred to as Landbanki, Landsbankinn, Landsbankans and so on. This makes this very tricky if a company name is user entered data.
Please be in rhus next time :(
Alex Gaynor's blog post tell's us that he confirmed "with some CPython core developers" that his program didn't work because of a bug in CPython. But the blog post doesn't tell us that *Alex Gaynor never gave that problem with a CPython bug as a reason his "doesn't-work-with-CPython" program should be accepted.* Alex Gaynor's blog tell's us that "It's also not possible to send any messages once your ticket has been marked as closed, meaning to dispute a decision you basically need to pray the maintainer reopens it for some reason." *But that's completely untrue!* You can send messages when the ticket is marked closed! And you can open topics in the public forum! And you can click on a username and send email in 2 clicks. There just wouldn't be any story to blog about, if Alex Gaynor admitted that he could easily have told me -- *the bug is in CPython not in my program, so show my program* -- but chose to say nothing.
No, it's dynamic
I don't want Markbox to serve static files from its own directory, only from your directory.
This is actually thing I liked about php... to copy the reference you explicitly did it using the &amp; symbol, even in the function defs... e.g.: //* right there, the &amp; symbol! function foobar($a, &amp;$b){ $b = 1; $a = 1; } $c = 2; $d = 2; foobar($c, $d); print $c; 2 print $d 1 
i think there are some blog posts on the topic, im not sure if there is a comprehensive list
no, I meant, write a C api that is similar to cpyext, which uses python code and cffi to interface with the python interpreter rather than interfacing with c code directly. follow? :)
I don't care about any of it but this line: &gt; had been ruthlessly microoptimized for CPython It implies that all the implementations are likely microoptimized for their respective environments, which means they're a bad representation of how fast "idiomatic" code would be in the language. Personally I think the very concept that shootout is trying to do is broken - it's my opinion that, because of the sliding scale of "idiomaticness" vs "microoptimizedness" there's not really any sane way to compare the speed of two programming languages. So personally, all I'm interested in is having a resource I can point to to say "don't trust cross-language benchmarks". The fact that apparently there have been arguments in the past is a little bit irrelevant when I don't think the idea of cross-language benchmarks makes sense to begin with. I mean, even pypy and cpython, both exactly the same programming language, have completely different "sweet spots" - should you have different benchmark implementations for the different interpreters? should you have a single, "idiomatic" one which you test both against? should you perhaps have a gold standard written in C or such, which is then simply syntax-translated to other languages without regard for the language idioms? the "idiomatic" approach would work for a single language - I believe that's the kind of benchmarking that speed.pypy.org does, which would explain why it's not much of a difference - but how do you reliably define "idiomatic" for ruby, python, c, javascript, perl, etc in such a way that you can compare them all in a useful manner? what if the "idiomatic" way in one language rejects the use of a major optimization, such as python rejecting use of arrays? do you ignore that idiom and just use arrays anyway, considering that such use would make it slower on pypy most likely, or does it mean that since you don't have arrays in "idiomatic" code, the language is slower? if you go the "gold standard" route, then you risk writing highly suboptimal code in say, python, if you translate from C - because in C you have to do everything yourself, but in python you won't just be duplicating human work, but instructing python to do many things twice. And then there's the whole thing about "do you allow the standard library". Well, what are you performance testing, anyway? idiomatic code in many languages recommends use of the standard library for speed, which makes it seem like it'd be unfair to say "no, you can't use itertools" in cpython where itertools are faster than the alternative; but at the same time, now are you benchmarking the speed of the cpython core interpreter or the speed of itertools? There might be a sane set of answers for these questions, but I'm highly skeptical.
Guido suggested that the future of Python lies in the direction of projects like PyPy during one of his talks at Pycon 2012. Note: I tried Googling for the specific part where he mentioned this but was unable to as it might have been during one of the moments when the fan boy/girls cornered him with some question.
Sure. Say you start using a tool and get to know how it works inside, then one day a problem comes along in some other context, and you'd like to borrow some code from the tool. Why even bother making the investment when there are other tools around that do the same thing with fewer restrictions? I guess I don't make a distinction between tools and libraries. It's all just code. :)
Just fixed that. Thanks.
Well as I imagine using iternationalization, your app has a number of pre-determined sentences / phrases / words that have to be localized for each of the markets you want to support, so you aren't translating them "on the fly" (because you already know when you publish your app each string that needs translating). Therefore a service with a translation API doesn't fit, since an API implies doing each translation on demand. Instead one assembles the (pre-determined) strings that need translating and gets each of them translated for each locale, and then one bundles the translations with your app. There exist [useful translation tools such as transifex][transifex] for co-ordinating the business of getting all your strings localized, but that is about helping your translators submit the localized strings for your project. So I am saying the translations for the locales you support are installed locally and made available to your app's translation machinery. Does that answer fit with your question? I am wondering if I have overlooked a totally different way of doing translations. [transifex]: https://github.com/transifex/transifex/
I agree with the second part, but not necessarily the first. Python uses list comprehensions, lambdas, map, reduce, etc way more than I ever see in other languages. Saving a list to a local var makes sense when the list is large and will be reused.
Didn't hear about the `*` expression. (unless it was a func arg)
I've just added a .humanize method that handles this.
[This graphic from Georg Brandl](http://dev.pocoo.org/~gbrandl/py3pkgs.png) can be also interesting to get a feeling on the dynamics of py3k adoption. The figure shows a geometric increase on available packages on pypi and suggest that 2013 could be the py3k year
You're just repeating something you read somewhere else.
This is brilliant. Thanks for posting it. While on the topic of Python GIS does anyone know how to do centrality maps in Python. Fore example here is a map of the [economic centre of gravity](http://media.economist.com/sites/default/files/imagecache/full-width/images/2012/06/blogs/graphic-detail/20120630_wom941.png) Here is one of [The earths population](http://en.wikipedia.org/wiki/Center_of_population). I am just wondering if anyone has a good tool/tutorial on how to make these in Python Thanks!
What happened in April or May to cause that slight downtick?
I also prefer the tuple from a self-documenting code perspective: why would you use a mutable datatype for something that's not supposed to be mutated?
You could make a wrapper: def choice(*args): return random.choice(args) choice('c', 'd', 'e')
Free your mind from the shackles of mutable state. class QW(tuple): def __getattr__(self, name): return QW(self + (name.lstrip('_').replace('_', ' '),)) qw = QW() qw.hello.world.this._is.weird.peace_out # ('hello', 'world', 'this', 'is', 'weird', 'peace out') qw # ()
It would be nice if there was some kind of nomination process. I, for one, would love to see nltk on the list.
&gt; should you have different benchmark implementations for the different interpreters? The benchmarks game **did show** python programs optimised for pypy *alongside* python programs optimised for cpython. *What's "unfair" about that?* - On your broader comments: &gt; a resource I can point to to say "don't trust cross-language benchmarks" ... but I'm highly skeptical Seems reasonable to me; for many years these goals were stated on the website: 1. To show working programs written in less familiar programming languages 2. To show the least we should expect from performance comparisons 3. To show how difficult it can be to make meaningful comparisons Also - http://shootout.alioth.debian.org/dont-jump-to-conclusions.php &gt; but how do you reliably define "idiomatic" for ruby, python, c, javascript, perl, etc The benchmarks game allows more than one ruby or python or ... program for the same task -- so for the benchmarks game there's no need to define some *in the eye of the beholder* "idiomatic".
I also noted this behaviour at some moment last year and asked Brandl about it. It seems it could reflect a clean-up of the file collection in pypi. I have a similar figure made on an excel document. I fill it manually using the number of python files taken directly from py3k pypi web page and these ups and downs are also observed there. 
That would require the translator to create 16 translations for the example program. If the list were 100 animals long they would have to make 10,000. In the Icelandic company names example that are user data it is of course impossible.
Nope. Statistics on a manifold are harder than in Euclidean space.
This looks very cool. I setup wifi for a campground and I've often drove around with NetStumbler trying to map out their strong and weak points. Something like this could let me turn that data into an overlay map for their campground.
OK, that works, I just wanted to point out it's not as easy as it sounds.
Flask is an awesome micro-framework. Pip is the way to go. Dependancies are declared in a simple textfile usually named requirements.txt. Installing them is simple: pip install -r requirements.txt Installing modules in python is usually systemwide. You don't want that. That is where virtualenv will help you out. It makes a parallel universe in which the modules you install won't screw with your main universe. Flask comes with a builtin dev server. For production uses, you should check out the flask documentation for configuring nginx: http://flask.pocoo.org/docs/quickstart/#deploying-to-a-web-server The pdb module is pretty handy for debugging tasks but I prefer Pycharm's debugger. I find BeautifulSoup to be quite good in parsing XML. SQLAlchemy is your best bet as an ORM. 
Framework: Flask or bottle are small, Pyramid is a bit bigger, I'd compare it to laravel. Packaging: Pip is the python package installer, and you use virtualenv (virtualenvwrapper makes everything convenient) to contain package installations to projects [folders], otherwise it will install them in your global python distribution. Google some tutorials on setting them up, and look at their readthedocs pages. Easy_install is old, no need to worry about it. Web serving: PHP uses FastCGI mostly these days as it's protocol to interface with a webserver. Python, in same manner, uses WSGI. So you just have to get a server compatible with that interface. There are many python web servers built natively for WSGI that run very fast, such as Tornado or Gunicorn, and frameworks often have their own basic one. You can also have nginx run a WSGI application, for instance using [these instructions](http://amix.dk/blog/post/19689). Debugging: Tried pdb? (python debugger) Frameworks such as Flask also have debugging functionality built-in, just have to look up their docs. XML: http://wiki.python.org/moin/PythonXml ORM: SQLAlchemy is the main library to try. 
As I was reading this guys article, all I could think was why the hell is this guy so hell bent on making everything sooo complicated. His final output is 32 lines of code, just to mock the open function. Feels like he's writing friggen *Java*.
I'd also recommend Werkzeug debugger: http://werkzeug.pocoo.org/docs/debug/ And if you're working with Django, Django Debug Toolbar: https://github.com/django-debug-toolbar/django-debug-toolbar ([screenshot](http://juliocsm.files.wordpress.com/2011/10/4504920914_6b3522db6a.jpg))
If what you mean is count the number of bits that are set, an easy answer is: def count_set_bits(n): return '{:b}'.format(n).count('1') well why not? ;-)
I ve released version 0.5.1, mainly bug fixes, and improve by threading.
That's my cue to leave. 
Careful: object mutability and pass-by-reference are totally different beasts. Python actually has no equivalent to that behavior, where re-assigning a function parameter re-assigns it outside the function. I imagine that in PHP an object passed "by value" (a misleading term, since for objects you really pass a pointer by value) would mutate outside if mutated inside, unless explicitly copied.
&gt; I imagine that in PHP an object passed "by value" (a misleading term, since for objects you really pass a pointer by value) would mutate outside if mutated inside, unless explicitly copied. I forget how objects work there in php... their OOP stuff was bolted on so I wouldn't be surprised if it wasn't consistent with literals... especially considering the atrocious lack of consistency elsewhere :p *shrugs* 
I would recommend ipython and ipdb python shell/debugging. They're great tools and can really help when prototyping. I would second the recommendation for flask, although it requires more knowledge of python than something like django, where there are high level abstractions common tasks (form validation, upload/file handling, database, authentication, etc). If you choose flask you'll have a lot to learn along the way. Django gives you so much and the docs are excellent its hard to pass it up as a good starting place. You might check out (*plug*) the peewee ORM, it's lightweight, expressive and plays nice with flask.
Many are saying Flask, but I feel I should put in a plug for Pyramid. I've been working with it for years and it's honestly been a great experience. Much less boilerplate and setup then Flask. The security module has a learning curve though, so be warned. However, the community is great (both on the #pyramid tag on Stack Overflow and the Google Groups page.) and they should be able to help out if you get stuck. Despite what others might say, both Flask and Pyramid are quite similar and you really can't go wrong with either. If you're trying to get up and running as soon as possible, I'd go with Django, but if you're thinking long-term about scalability, etc, then go with Pyramid or Flask.
This really is a fantastic plugin for KDevelop. It easily makes it the best Python IDE I've managed to find and since I use KDevelop for all my C++ too it's great it's all in one package.
PHP actually did it that way at first, and then moved them into the function reference instead at some point. 
Actually, the whole point of a projected coordinate system is to approximate euclidian space. I was assuming a projected coordinate system (though I should have said that...) While it's less accurate for an area as large as the US, the difference isn't going to be terribly significant compared to the other decisions you'll have to make (e.g. point measurements vs. area measurements). The post you link to is just using an overly-simplistic (sinsuodial with a spherical datum) projection. At any rate, a weighted centroid is a _very_ close approximation in any area-conserving projection, so long as you don't have to worry about "wrap-around" at the date line (And if you do, just jump into 3D cartesian coordinates, as I mentioned. You can choose your datum and approximate the geoid as closely as you'd like and then do the calculation properly in 3D elucidian space).
Is this enabled by default? I remember having seen the specialized list strategies not being enabled by default.
You've recieved downvotes because this isn't really a programming or python related question. What you need is a VPN there are many around and they will be high speed (unlike what tor is for). But you will have to pay for it and depending on how much you use you may have to pay a bit but the price should be anywhere from $3/month to $20/month.
The main reason that you're being downvoted is that Python doesn't have that much to do with proxies. Python is a programing language; it can manipulate data, interact with a computer's OS, and even make connections to other computers, either directly via sockets or through HTTP(S). But it isn't a proxy. So I'm not sure exactly what you want from Python. A faster proxy? Well there's a VPN or the many free proxies that exist out there. Try looking around. EDIT: Sounds like you set up a personal proxy like [this](http://www.labnol.org/internet/setup-proxy-server/12890/)? The fact that you can't log into sites might be because the proxy is primitive and doesn't store cookies, but I'm just guessing. You might want to ask your question to a forum directly related to the proxy you're using.
Actually, I didn't read your entire link until just now, sorry. Ignore what I said about it "using an overly-simplistic projection". That's just the first method it discusses... 
Seems like it might be a good use case for [virtualenv](http://pypi.python.org/pypi/virtualenv) to create an isolated environment for Kivi.
My mistake on OrderedDict, I think(?) I knew that but didn't think about it when I skimmed over and banged out that list. Thrift and eventlet/gevent are blockers for us. I suspect Twisted is for a *lot* of people; Thrift for anyone who uses Cassandra, among other things. :(
I probably will in the near future. I am trying to learn SQL right now for a job.
What it should really do is facilitate parameter binding.
isn't that pretty much two sides of the same coin? EDIT: I was using those terms incorrectly... Thanks for the clarification all. 
Well, not really. Sanitization would mean every set and append method first runs an escape filter on all arguments, or something of the sort. With parameter binding, every clause would or could generate a prepared statement and then a second variable containing what to execute it with. Though that may go beyond the scope of the project, and would require a lot of additional code.
Bound parameters are guaranteed to be secure from SQL injection. Input sanitization is not.
Well, servers can stay on 2.x longer, but the desktop stuff is coming together nicely now.
I finished coding this as part of a bigger project for the company I start wih a friend. Let us know what you think about it and the ways we could make it a better solution!
I like that Kivy is entirely written in Python (and Cython), but it has it's shortcomings. It's based on pygame - no multiple windows (for now), no support for macosx menu or apps that run after all windows has been closed.
afair they are enabled in the builds since a while, i dont recall the exact point
Well maybe there's something here I haven't learned yet, but one case which I don't know how to handle with parameterized queries is when I want to insert a list of possible vales into a WHERE clause, as in SELECT * FROM GRADES WHERE COURSE IN ('P101', 'P102', 'Q201'); well you get the idea, the values for the IN operator came from the result of some previous query.
This is a complaint I hear often, yet I wonder what percentage of users actually need multiple windows.
I tried Elixir, which is kinda a wrapper around SQLAlchemy. I'm not sure about the current status of the project, but I think it's worth a look, as it is considerably simpler (IMHO) than SQLAlchemy (although I never tried the declarative syntax from SQLAlchemy, which seems to be fairly similar to Elixir).
&gt; The Flask/Werkzeug developer doesn't like Python 3 and thinks it's a sufficient reason not to port, so you shouldn't expect those any time soon wat? why is that under good stuff? also its ported and just needs to get pulled. * [werkzeug](https://github.com/mitsuhiko/werkzeug/pull/231) * [flask](https://github.com/mitsuhiko/flask/pull/627).
Can't you interpolate a list?
btw: the doesnt seem to mind bit is still misleading: he didnt want to do it himself, but will likely accept those pull requests (the post you linked to was made at a time where they werent ready). maybe he bitches around a bit and requires a few parts to be changed, but since the pull requests are polyglot instead of 2to3 plugins, hell accept them in the end.
What exactly do you mean?
I never really understood why people wanted to build an api on top of SQL. SQL is a pretty straightforward language, and the api ends up being even more complex than a straight query would. Plus you end up trying to take care of every single edge case and now you've wound up with hundreds or thousands of lines of code to support something that was pretty concise to begin with. That being said, I've written light wrappers around SQL, but only to do a select * from table where field = value &amp; the matching update &amp; delete. It was easy enough to work with a dictionary to push the query in and resulted in fewer errors. Past a simple WHERE clause (and order by) it just got too hairy and inconvenient.
This is not a replacement for the built-in modules and related bindings - therefore I did not even worry about injection. Simpler means fewer mistakes?
South's a pretty nice change management tool for Django, I just wish it's ordering system wasn't numeric sequential ( 0001 =&gt; 0002, etc ) as that make's it somewhat team unfriendly ( is Bob's 0002 change or Alice's 0002 change supposed to run first? ).
The [--merge](http://south.readthedocs.org/en/latest/tutorial/part5.html) docs. A lot nicer than Rails' date-based naming convention.
Which is fine unless they conflict... in which case there isn't any solution except you manually fixing just like a git merge conflict. 
Yes, It's very much like two sides of the same coin in that doing it one way, you win. Doing it the other way, you lose.
Just a heads up, some of the kivy dependencies have to be manually installed for the linux distribution like pygame. I was having all sorts of issues trying to get pygame working in my virtualenv with pip until I realized I could literally just manually extract pygame into .virtualenv/[my_project]/.../site-packages to get it working. --system-site-packages would probably work as well if you already have pygame setup in your base install.
 params = [1, 2, 3, 4, 5, 6, ...] qmarks = ",".join("?" * len(params)) sql = "SELECT * FROM GRADES WHERE COURSE IN (" + qmarks + ")" cursor.execute(sql, params)
I'm considering the purchase as well. However, one thing that is holding me back is the price ($25), considering there are only 68 pages. For that price, it better be more than just regurgitating the documentation. I have Python For Data Analysis, but its 2 books from the top of my reading stack. I can't wait to start it - I'm really looking forward to it. I have some experience with numpy and scipy, so hopefully I won't need to lean on outside resources too much.
Python for Data Analysis is wonderful; pick that up first and see if it satisfies what you need.
&gt; Simpler means fewer mistakes? No, not at all, at least not in practice. Not in that general sense. Simple counter-example: PHP's `mysql_*` functions are relatively "simple" to use. They have allowed for thousands, perhaps millions of mistakes in websites over the last ten years and even today. A simple API, though, is usually easier to use correctly than a complex one. That said, the library is meant for simple sql statement manipulation, not execution on a database. I think you should mention that in your readme.
All in all, I don't think you've explained the use cases this library is supposed to solve very well. People are expecting it to be a somewhat fully featured SQL library of some sort, whereas from what I can see all it is supposed to do is manipulate textual SQL statements. Because of this, you're getting a lot of criticism on features it's missing which I'm sure you never intended to be there... All people have to go on are some examples and a name, and the examples aren't even put in context. Hence all the misunderstandings.
No. PyPy has a lot of unnecessary overhead for 95% of problems. It's 5x faster, I'm still not switching because I'm not concerned about speed most of the time. I might use it someday for a very challenging problem, but more likely I'd just use numpy.
The whole book is on [Safari Books Online](http://safaribooksonline.com), so if you have that (or a two week free trial), you can read it there.
Yes, that is the #1 thing I learned from all the comments here. Thanks
Well everyone thanks for all the comments. I learned that I should be very clear in my readme what the purpose of the library is. I know I tend to be terse at best but I am working on it! It is really a tiny library and like most projects I wrote it mostly because I found it interesting. The main uncertainty in my mind when I wrote it is weather subclassing unicode was a good idea. Actually I am pretty sure it was not; but I was inspired by path.py and wanted to try subclassing an immutable type. 
I know the author, and from our conversations, he knows his shit about Numpy and SciPy (On another note: anyone in Sydney, you should come to SyPy)
Very nice, thanks for the pointer. Now, if they would just write a fake version, I'd never have to write code for dealing with the file system again. :)
What is this, an e-penis contest? Python is supposed to be easy to use. I've been coding Python regularly for probably around 8 years, and I keep fairly abreast of new features and changes to the language. (In other words, I'm not some stodgy old guy in a cave who is stuck on Python 1.5.) If it takes anywhere near that long to notice a feature of one of the most important built-in datatypes, then I think it is probably a bit obscure. But that's just like, my opinion, man.
That's not a bug, that's a feature! Seriously. The ability to import from .pyc and .pyo files when the .py source is gone is required to support distributing non-source code applications. However, in Python 3.3, the situation is much improved: .pyc files live in a special `__pycache__` directory, and are not imported if the .py file is removed. However, if you explicitly move the .pyc file out of the `__pycache__` into the source directory, it is importable just like in previous versions, thus satisfying those who don't want to distribute the source code to their applications. 
I don't see why I would. SQLAlchemy works perfectly even for small applications/libraries. SA does not force you to use the ORM, nor the `Declarative` extension. I tried to do what you did *once*. Only to realise that bit by bit, I was reinventing the SQL layer of SqlAlchemy. That library is still not ported to SA and I wish I had used SA from the start. I will port it as soon as I can, because in the end, SA is simple, easy to use and lets you do pretty much everything you want. As an example. I'm leaving out engine creation and usage for now... But that's just as easy: my_table = Table('customer', auto_load=True) s = select([my_table.c.name, my_table.c.last_name]) s = s.where(age &gt; 20) s = s.order_by(my_table.c.zip_code) for row in s: print s.first_name, s.last_name, s.zip_code This example is pretty much as simple as it gets. SA also deals with DB dialects for you, and properly binding the parameters, transactions, complex queries, custom function calls (SPROCs or functions made available by DB extensions), without touching SA at all. And no matter what project you write, if it is marginally successful you *will* sooner or later need more advanced DB stuff. **DISCLAIMER**: I have not used SA in a while, and I tend to mix up the ORM syntax with the generative syntax. So the code might not be copy/pastable :P
There's a memory filesystem that is effectively your 'fake' filesystem...
This is not the issue at hand. The issue is readability and mental load. My response to rdssassin was due to the fact that he didn't know about mutability (see thread below).
I replied a bit late yesterday (I live in Shanghai so it was around 2:30) but I just remembered one of the **VERY** nice features that this brings, I can update a variable defined in one file in another. So for example in `settings.py` I would define my generic `INSTALLED_APPS` table and modify it in `settings_dev.py` : INSTALLED_APPS += ( 'debug_toolbar', ) This, in my opinion, is a huge advantage that is not possible with simple `import` statements. on a side-note: yes, used to work in a online lingerie store in Beijing (http://www.lamiu.com/) and now starts my company in fashion (http://www.ledapei.com/). Will let /r/django and /r/Python know more when the product is mature enough.
If you don't mind reading an ebook, you can pick a copy for $6.50 using the code CYBERDAY at [O'Reilly](http://shop.oreilly.com/product/0636920020219.do).
Can you explain? You construct arrays from lists so it's hard to keep them separate...
right, that one. I math.
[Python](http://www.python.org/ftp/python/2.7.3/python-2.7.3.msi), [NumPy](http://sourceforge.net/projects/numpy/files/NumPy/1.6.2/numpy-1.6.2-win32-superpack-python2.7.exe/download), [SciPy](http://sourceforge.net/projects/scipy/files/scipy/0.11.0/scipy-0.11.0-win32-superpack-python2.7.exe/download), [matplotlib](https://github.com/downloads/matplotlib/matplotlib/matplotlib-1.2.0.win32-py2.7.exe) and [PyCharm](http://www.jetbrains.com/pycharm/) (paid) or [PyScripter](http://code.google.com/p/pyscripter/) (open source, Windows only) or [PyDev](http://pydev.org/) (open source, Java) as an IDE. Edit: all packages linked are official.
Ahh. thanks for reminding me. If used Python(x,y) before and heard about WinPython.
Using "c d e".split() is more pythonic. It's a little less efficient, but not enough to really matter. But it wins over the hand-written list for three reasons: 1) It avoids a common pitfall when writing out large lists of quoted strings. Quick, find the error here: ['abcd', 'bcde', 'cdef', 'defg', 'efgh, fghi', 'ghij', 'hijk'] The more tedious the piece of code you are writing, the more likely you are to make errors are, and there are few things as tedious as hand-writing lists of strings. 2) You probably already use Python to do intermediate calculations, instead of doing it by hand. You probably write (say): x = 64*1024**2 when you need 64 MiB, rather than x = 67108864. Creating a list of strings is the same principle: let the computer do the work. 3) This is just a slight variation on the common Python idiom for defining a bunch of lightweight string enums: RED, BLUE, GREEN, YELLOW = 'red blue green yellow'.split() You can call it lazy if you like, but that's not a bad thing. Simple, easy, quick, and it works -- that's why we use Python instead of less simple and easy languages. 
You used NumPy to figure that out, no doubt ;)
Okay, so that's pretty much how I've been doing it so far. Guess that's as clean as it gets.
[Python 2.7 windows installer](http://www.python.org/getit/) [Windows installers for every imaginable python module for all versions of python](http://www.lfd.uci.edu/~gohlke/pythonlibs/) [Komodo Edit for your IDE](http://www.activestate.com/komodo-edit/downloads) 
virtual Debian, edit from your Windows some packages have issues on Win
See also [the list of Scientific Python distributions](http://scipy.github.com/install.html) that include the whole 'Scipy Stack'.
Why not just use a virtual box and save yourself the hassle? 
[funding nltk on py3k](http://pyfound.blogspot.com.es/2012/11/grants-to-assist-kivy-nltk-in-porting.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed:+PythonSoftwareFoundationNews+(Python+Software+Foundation+News)) 
You could also do it as a list comprehension, which is slightly more readable IMO: ','.join(['?' for _ in params])
The only time I don't do this is when I have a piece of SQL that needs to be conditionally added - say, a subquery that returns a list of dates. In those cases, the string pasted in is selected from a `dict` anyhow, so invalid user input would raise a `KeyError` or return `None`, depending on how it was implemented.
nice! however, theres a technical issue: why the `from gridmaker import Grid`? the `if __name__ == '__main__'` part is below the definition of Grid, so you dont need to import it as its still defined.
[Python SDK](http://www.conceptive.be/python-sdk.html)
Christoph Gohlke is your friend. Google him. He's a god for windows users of python
I'm guessing that was a typo and the code was originally in 2 different files, but moved into one so it could be used in a Gist.
thanks, this is a copy/pste leftover. shouldn't be there
Linux
Been waiting for this. Thanks!
Python 3 support...nice.
We're still using 1.3.2 :( 
Take a look for a sixth item: https://docs.djangoproject.com/en/1.4/internals/deprecation/#id3
Ahh! Gotcha. Thanks!
I am now third on the waiting list for "Python for Data Analysis" at my local library
But, you do have a local library that bought python for data analysis as soon as it was released. That's a pretty hip librarian. The DC public library system has basically no contemporary programming books.
Someone should run this on a popular reddit thread
It's easy to miss that one key word...
What you should be doing in these situations is make your code as python 3 compatible as possible. E.g. Move to python 2.7 first and then add unicode literals and python 3 division etc, once that's all done, the next time you bring up python 3 just mention that half the work is done already and also include business benefits to using python 3. You have to convey that switching to python 3 will bring them some form of value (ideally monetary).
That's the general plan, of course it doesn't help that our team doesn't actually bring the company any monetary value, we're a tools team.
For us it's not only Django, but PIL, which AFAIK has no immediate plans for Py3 migration.
Beat me to it. It wasn't only django's fault. Most of the support libraries were ported just recently. I didn't know PIL had no plans for Py3, though. That sucks. I'm starting to port every package I need for py3 but having backwards compatibility just doesn't feel worthy enough. I'm tempted to mantain a stable bug-fix-only python 2 branch and keep development on python 3 only. 
The User refactoring is the most exiting news after python3 support.
I love this open process. Divio put together some really well thought-out mockups for this. I'd really like to see the top nav floated to the right rather than centered, and that's about all the critique I have for them. I'm excited. :)
I would make it a little lighter, but in the essence it is awesome.
Why? What's wrong with the current look?
I agree the site needs a makeover... but I honestly don't like *any* of the mockup designs. To me, they look entirely too much like some of the older Drupal release defaults (which always looked boring to me.) That last one especially. Compare to [this](http://www.disambiguity.com/images/Drupal10.png) and [this](http://0.tqn.com/d/webdesign/1/0/v/Q/1/drupal_install1.png).
To be honest, I didn't like this design. It looks like a website for a product or a startup. This is a "heavy" design and it's going to make website load slower. From the developer perspective, I can't care less if it's css-less plain HTML document as long as it does the job. This is going to be made for developers. It should be a simple design.
Now if only the same could be done for the PyGame website...
Is PyGame really that ancient? What would you recommend I use? Pyglet doesn't seem to have much of a user base.
So how would one use captcha without PIL in a django application? Any ideas?
Interesting this post of mine popped up on Reddit. I actually ended up regretting using MySQL, if only because of the administration hassle that comes with it. If I had used sqlite, I wouldn't have to worry about having to install a database in order to use my app. So I'm actually considering rewriting the database code so it can use sqlite instead, so non-technical users only have to install Python(x,y) to run it. Why Python(x,y)? Because it nicely bundles all the libraries I also rely on, such as wxPython, matplotlib and numpy. If you have any questions, feel free to leave a comment
We're working on Skins for all of them
[migrate](http://code.google.com/p/sqlalchemy-migrate/) is also a very good reason to use SQLAlchemy.
Pygame is a wrapper for SDL 1.2, and while SDL 1.2 has had bug fixes as 'recently' as 10 months ago, it's been pretty much the same since 10 or more years ago. I think it still uses DirectDraw 7 for rendering on Windows. Newer things rarely do have as big a community as older things, so you shouldn't let that hold you back from using something. But I wasn't recommending you change. I prefer Pyglet because it has OpenGL rendering with all the benefits that brings but if Pygame works for you, stick with it.
Playing devils advocate and if I was the PM, I'd tell you to just add to every file: from __future__ import unicode_literals from __future__ import print_function
True true. I don't see anyone doing this realistically unless they have really good code coverage on their test suite.
You might like to investigate iPython, which gives you a fully interactive shell like bash, except using Python. It is mostly aimed at scientific users, but it also makes interacting with the system shell simple. http://ipython.org/ipython-doc/stable/interactive/reference.html#system-shell-access 
Why the horrible name? and why python 3?
I do, actually. But only because I try to support 2.7 &amp; 3 out of the same codebase.
That would make sense if you're selling a product or making a library. If you're writing a webapp though...what's the benefit of supporting both versions?
Pyglet is easy to use for 2D. Its really a nice framework, though iv'e used it very briefly. 
Any mirrors of the content? I can't get through to the site.
The whole thing looks like it's based on one of the default twitter bootstrap bits. I actually like using twitter bootstrap for my web front ends, but very few people that use it break out from the sample layouts. So as more and more people use that css and js, more and more sites all start looking exactly the same.
No. I was talking about data transmission between server and the user.
I don't know how that box on the right helps any kind of audience. jQuery had put a rock-star logo and it didn't stand a day after lots of negative criticism. I'm 100% sure that that's what's going to happen to that box. This design is for a product or a startup. It's an irrelevant design to the target audience.
More a symptom of a bad monospace font of course, but I agree.
Thanks! I'm making a note here: "Huge Success."
Wouldn't it be much better to provide this as a patch against the docs and submit it to http://bugs.python.org ?
cool!
Seems like a good idea in some situations but not others. What if I want to open a data file for appending, and if the file doesn't exist, I want to create it and add a header to the beginning?
Armin Ronacher mentioned in a talk he gave on how he created Flask that marketing does indeed seem very important in the Python community. He thought he was playing a kind of joke by combining a few things together for a web framework, but the joke was on him when people actually wanted to use it. He attributes part of his success to the way he presented the system (and documentation).
yes, that's the workaround I think. but now, as we have a chance to redisign the who site, and the blocker wo cant asume to be solved in any near minute, do we really need .org/download? 
I'm only on p. 50 of the PDF so far, but am appreciating this writeup very much.
&gt; I am not sure you have stated what the problem is. oh, silly me I didn't tell what it was. The database is our main bottleneck right now, as this mysql table gets hit so hard, many workers end up waiting too much. The workflow is fully implemented, but I think I can make it faster. &gt; what is the idea behind a script giving up on a task, and marking it released itself? I mean, that task would just be picked up again anyways by a similar script, no? There's some special cases where the task needs a particularly specialized worker, or some services are not currently available but they will be soon. 
 &gt;&gt;&gt; import itertools &gt;&gt;&gt; files = ['aa', 'bb', 'cc', 'dd', ee'] &gt;&gt;&gt; itertools.combinations(files, 2) [('aa', 'bb'), ('aa', 'cc'), ('aa', 'dd'), ('aa', 'ee'), ('bb', 'cc'), ('bb', 'dd'), ('bb', 'ee'), ('cc', 'dd'), ('cc', 'ee'), ('dd', 'ee')] 
FDB 0.9.x should work with SQLAlchemy 0.8.0b1 http://docs.sqlalchemy.org/en/rel_0_8/dialects/firebird.html 0.8.0b1 is the first version that introduces fdb support 
Another thing going for SQLAlchemy is that you can use it as a broker for databases. I often write straight SQL, but I still use SQLAlchemy (engine.scalar, execute, etc...) to connect to the DB, because I can them switch from one type of database server to another with no code change (beside SQL dialects differences). 
That's not quite what they're talking about. But even in your case it would be far less work on your part to just use pickle.
Nice CSRF failure when rating the article. Strongly agreed with it anyhow. When storing settings, data and such, what already exists is certainly good enough. ini, json and sqlite should cover pretty much all use cases together and are extremely widely supported.
/r/learnpython 
Sounds good. What is the link?
Awesome! So this is targeted at people who have done a small amount of python but nothing particularly useful!
&gt; What could be more convenient than storing all your project files, history, and communication in a single file that you can freely clone, send, and merge? That makes me think of 2 names: system.dat and user.dat.
Everything I've done with python has been on the web, with apache. There's probably lots of people with that background, because it's the easiest way to make stuff with python, by using javascript as a front end. However, desktop development has always been a mystery to me. 
As much as I like the idea, SQLite fails at : * versioning * easy hand editing
Agreed, plus `print("Hello World")` works on both 2.7 and 3.x
SQLite can't be versioned easily, but there are a ton of simple editors for it. You wouldn't say that PNG or JEPG files "fail" at easy hand editing just because you can't open them in Vim, would you?
Firefox uses SQLite for all it's configs. Every time my computer crashes (usually due to a power outage) the configs get corrupted, leading to lost data and inconvenience. It's a known problem with SQLite over NFS. The use of SQLite for configs is one of the reasons why I try to avoid Firefox these days, so, no thank you, I think I will pass.
If you must use subprocess, at least stop using the dangerous and unnecessary `shell=True`. for a, b in itertools.combinations(files, 2): subprocess.call(['python', 'processor.py', a, b, 'output']) But really, you should not be doing anything with subprocesses here. The script is already in python, just import it and call the functions directly. 
Why do you actually need to do this? Can you paste bin processor.py? 
I use [pyres](https://github.com/binarydud/pyres) for job queues &amp; job workers. It uses redis as the backend for the queue, so if your database is the bottleneck, moving the job queue stuff into an in-memory DB like redis would probably be a good move.
Why don't you use relative import * rather than exec and file load? 
Wow - with an equal sign in the filename? I'm using Python 2.7.3, if that matters. On Windows Server 2008, but I get the impression the Windows version is irrelevant.
| Every time my computer crashes (usually due to a power outage) Psst: get a UPS. They're worth it.
Submitted as [issue16580](http://bugs.python.org/issue16580).
You can also (if you don't have MSYS installed) use move "xyz=abc.txt" xyz-abc.txt from cmd.exe
pickle has an ascii format as well. If you use protocol 0, it's in ascii, but it's not very easy to read or edit.
I used SQLite for this with an embedded (ARM) app about 5 years ago, it was great. Loading data, even static configuration data, from SQLite was faster than XML or any other text format I tried. For the initial data set, I checked in a version controlled text file full of SQL to load the database. You can either make this yourself or create a DB and then export. Importing the file and saving the resulting SQLite file then became a build step. So you can still have version control of your config data.
This sounds suspiciously wrong, or a problem outside of SQLite. Are your NFS mounts in synchronous mode?
Well, sharding would mean you would put the shards on *different* machines. So, your load (memory or IO) *will* necessarily be distributed across machines. The bottom line is that you either (a) optimize the computation, or (b) distribute it. You can distribute the load at the DB level (by sharding), or at another tier. The latter could be some kind of scalable queue. Or, maybe you can get away with some kind of a caching solution using memcache or redis, that can take the load off your DB.
Definitely use a database for this kind of stuff. Storing information like that in XML sucks... even worse in pickles. I would say JSON would be a bit easier, but SQLite will allow you to easily (and quickly) query your data and incorporate it into your app, over using a file parser.
Yeah. YAML and JSON are dead simple, have tons of rock solid parsers, and are easy to manually read and inspect. You can roll your own format just as long as you base it on something sensible.
&gt;Well, sharding would mean you would put the shards on different machines. You indeed are correct, I've been working on too many crap projects this year.
You should include a free and open source license with the project. Otherwise, people are legally forbidden from using it. However, it seems that this may be your intention (Copyright: Lars Schweighauser. 2012). If so, please reconsider freeing your software, preferably with a permissive software license (such as the [BSD 2-clause license](http://opensource.org/licenses/BSD-2-Clause), the [BSD 3-clause license](http://opensource.org/licenses/BSD-3-Clause), the [Apache 2.0 license](http://opensource.org/licenses/Apache-2.0), or a (legally valid) public domain dedication, ideally the [Creative Commons CC0](http://wiki.creativecommons.org/CC0)).
My bad, this is a whole new world for me. [Is this good?](http://creativecommons.org/licenses/by-nc-sa/3.0/legalcode) How exactly do I attach it? Do I name the license where I wrote my copyright comment? Do I attach a text version somewhere? Edit: I think I figured it out. 
It is not recommended to use Creative Commons licenses (except for the CC0) for software. Also be aware that licenses forbidding commercial use are frowned upon. What you probably want is something like the [GNU GPL](https://www.gnu.org/licenses/gpl.html), but in my opinion, this license is excessively complicated and restrictive. You can use the website [tldrlegal.com](http://www.tldrlegal.com/) to easily understand the consequences of different licenses. To license your software, attach a file called LICENSE or LICENSE.txt (COPYING(.txt) is also used sometimes) containing the full legal text of the license you have chosen. You should also mention (by name) which license you have chosen in your README file.
Ehm, done. That was what, about four changes in total I think. Run 2to3, make imports conditional, replace all open calls with codecs.open just to be sure. Also replaced some things to be more in line with PEP8 (is not None, chained comparisons), but that doesn't matter really.
GTK is really easy to start with (sadly most of the tutorials on the web are about GTK+2, and GTK+3 is almost the default on most of the current Linux distributions), wxPython is more cross-platform then GTK, but always looks ugly. Best for cross-platform would be Qt, but I find it more complex to understand then other GUI-toolkits. All in all Desktop apps are more lightweight then Web-apps - since I hate using a browser for something else then reading webpages. So go for it
The funny thing is, I'm not even worried about cross platform. They're just personal projects, I don't even think I'll distribute. But I do like the idea of saving my work on launchpad. My brother is also an Ubuntnoob and he might also use my PPA. However, again, I'm not worried about cross compatibility. And Qt is rubbing me the wrong way. GTK feels more in tune with the Gnome desktop. Your thoughts?
Yeah that's okay then :) (not an Ubuntu fan). For personal project - you're right - never cared myself too, but when I released them on bitbucket or github some people thought that these apps are useful for them too, so you never know. When you see someone liking your application and asking for a feature it doesn't have you find yourself doing it, not because you wanted it, but it's a challenge and you can only benefit. 
Why would I write free code, and then make it so that someone else can profit off of it? It seems like an oxymoron to me. 
You lose absolutely nothing when someone else profits off your work. Popular free software puts little restrictions to commercial use. That's a large part of their popularity: profit is a great driver for pushing adoption. Profit allows hiring full-time people to market, sell and develop. There is also a massive selection of free software that even allows the profiteer to not share the code. Most popular licenses for this type include BSD and MIT. Even as code-sharing is not a requirement, companies tend to contribute back to the original projects they based their work on.
There's no rule for that, if you want to make the profit because you think you deserve it for the time you spent on it, it's good. I was just commenting on the fact that it didn't seem logical for you to write free code and allow people to profit on that.
Congrats dude
Right - but where it's failing for me is in a Python script. I suppose if I had to I could call a batch file, but that is just hideous.
usually i agree that this is a bad idea, but when you write code that should be executable with python 2 &amp; 3, you want it to work as similar as possible. and the function i showed you behaves as compatible as it gets to both python 2 &amp; 3, using python 3s default codec.
json is a bit of a pain in its simplicity (`"` around everything), and YAML has a lot less well-integrated parsers, sadly. both are still far better than XML for human-editability, though. and when the most deeply-nested structure in the config is a setting pointing to a list, a setup.cfg-like ini file is awesome: [category] key = string value key2 = list values
youre right: sounds like something windows does: i also got one or two sqlite corruptions there, never on linux (although in the olden days i had to do SysRq-REISUB almost weekly)
It's a long discussion, but people or companies using open source licenses are not just giving away their work away for free. They add value to their projects by opening them up to a much larger audience of both users and developers. Remember that the main Python implementation itself has been developed and maintained mostly by a handful of dedicated programmers for decades. And people like you and I can use their work freely, even for commercial purposes. It's safe to say though that none of them have suffered financially as a result.
... on the other hand, using Tkinter lets you run it without using any external dependencies. For such simple GUIs I largely prefer this than pull in something as huge as Qt.
Leave Qt's size for the moment; the big, *big* advantage I see to Tkinter is its impact on your **consumer**. Share a Tkinter-based application with someone else, and you can reasonably say, "just install the standard Python--maybe as [ActivePython](http://www.activestate.com/activepython)". While I fully recognize how wonderful Qt and PyQt in particular are, configuring someone else's desktop to be able to run PyQt-based applications is ... not so easy. Installation is obviously an uninteresting, solved problem that is outside the scope of a discussion about how to program. ... except when it isn't.
You can use something like [cx_freeze](http://cx-freeze.sourceforge.net/) to create Python executables and then you don't have to worry about the consumer installing the right libraries to use your application.
|... licenses forbidding commercial use are frowned upon. Bleah--*any* discussion of licenses induces frowns. My upvote to posixlycorrect for his helpful details. It's just a drag having to sully the purity of the programming experience with the distraction of "intellectual property". posixlycorrect, what's the basis you see for, "people are legally forbidden from using" source which includes no license? 
have you tried escaping that equal sign?
This and exhuma's comments are a big part of the reason I used Tkinter. (Since this was a class project, it saved me a lot of hassle if everything worked out of the box.)* I also spent a large amount of time attempting to get PyQt4 running but to no avail. (I mean technically it worked but pyuic4 wasn't installed correctly which seemed like most of the fun.) *~~It should be noted that I'm just about the only Mac in class full of PCs so py2exe is out, unless I spend the time to set up a virtual box.~~ Nevermind it looks like cx_Freeze is cross platform. I will definitely check it out because being able to make .exes would be pretty nifty. Thanks mkdz. 
&gt; Have you ever needed to fix something in a server config somewhere and thought "this would be a lot better if I had to phrase this interaction in the form of sql"? Can't say that i have. I think you win this thread.
cx_freeze and friends are indeed wonderful. And they have their own liabilities ...
Yeah, and both are conditioned by nation-specific statute. Maybe I should care more about licenses. I doubt that it happens soon. I salute those of you with more patience.
It looks like you are using old-style classes. You should use [new-style classes](http://www.python.org/doc/newstyle/) instead.
I concur. The first thing that popped out to me is that some of your methods are defined in Like_This(). That's not "pythonic". PEP 8 says methods should be named like_this(). "Pythonic" and our community's entrenched conventions aside, your methods aren't consistently named. You may have a method_one(), a Method_Two(), and a MethodThree(). No matter what language you choose, those sorts of things make re-using your code difficult and annoying.
Any more so than if someone edits the config INI or JSON plain text file?
So long as you can rely on Python 2.6 and above, you can use `from io import open` to get an `open()` function that behaves exactly like the Python 3 version.
cx_Freeze is cross platform, but it makes the relevant type of application for the platform you run it on. So you can use it on your Mac to make a .dmg bundle, or on Windows to make a .exe application.
nice, didnt even know that! thats of course much better than my idea. turns out i never read more of the io page than `BytesIO` and `StringIO`.
no. codecs uses the builtin open if no `encoding` is specified, which opens the file in ascii-mode in python2 and in utf-8 mode in python3. but /u/takluyver [had an even better solution](http://www.reddit.com/r/Python/comments/141j91/my_first_python_app_also_my_first_app_in_any/c796ng1?context=1) i didnt know about: [`from io import open`](http://docs.python.org/2/library/io.html#io.open) imports the open function used in python3!
I don't see any reason why this wouldn't work, and indeed, I just tried it and it worked fine - python 2.7.2.5 / Windows 7. Is the above *exactly* the code you're running? If not, could there be something else going on in some other code that you're not realising (eg. something that replaces "=" with " " in oldfilename)? Try printing the values out immediately before the rename. Eg. to give a standalone example, running the following code in an empty directory prints "Everything worked as expected" for me - what do you get? import os oldfilename = "xyz=abc.txt" newfilename = "xyz-abc.txt" with open(oldfilename,"w") as f: f.write("test") # Create test file os.rename(oldfilename, newfilename) if os.path.exists(oldfilename): print("Old file not deleted!") elif not os.path.exists(newfilename): print("New file not created!") else: print("Everything worked as expected") os.unlink(newfilename) # Tidy up. 
I meant to ask, the fundamentals for pyGTK, between GTK2 and GTK3, are probably very similar, right? 
Huh, really? I am super-interested in the Hue but didn't want to invest until they released their APII wonder how much control this ad-hoc library provides for the devices? If he has full colour/luminance control in addition to on/off with his "third-party" script, I may have to see if I can get a set after the Christmas rush to make a sunrise-alarm clock for the bedrooms. Edit: The library does seem to control brightness, hue, saturation, and on/off. Nice. Edit 2: The bridge just speaks JSON via REST API, which is just brilliant; I wish more manufacturers/devices would do this (If you want an example of how not to write a control interface for an electronic device, try implementing the interface for Sony devices. [I have](https://github.com/isolationism/python-xbrhx909_serial); it isn't pretty.)
You have a performance bug. Encrypt.encrypt is O(n^2) in the length of the string. If you ever hit a really long line your program is going to hang. Instead of doing result = "", result += chr, write it as result = [], result.append(chr), return "".join(result). Also, unless I'm much mistaken, the key is always 9. From the looks of encode and decode, you may want to check out the % operator and what it does.
I think you can do this more cleanly using the multiprocessing library. http://docs.python.org/2/library/multiprocessing.html Are you trying to roll your own map-reduce? (You might be if you then summarize the results of the calls on each pair of files). Have a look at http://mikecvet.wordpress.com/2010/07/02/parallel-mapreduce-in-python/
Yes, at the gnome website there was a page explaining what is new with the so called introspection. If you are already familiar with pygtk check (the porting guide) [ https://live.gnome.org/PyGObject/IntrospectionPorting] 
Of course not! But neither should stevenjd keep letting his computer crash, seeing as there's such an easy/cheap way to prevent it.
I didn't even know there were New-Style Classes. I will look into it, thanks. Edit: I switched to the new style classes.
The key is intended to always be 9. Like the README says it's not really meant to keep your data secure. Using 9 for both the default key and whatever key the user generates, means only one Encode function is necessary. 
Yes, Kivy looks interesting, but trying to integrate it into my toolset is too painful to pursue. I use PyScripter and have had no luck. Even tried using version of IDLE they ship with the install, no go.
Are you on windows? The only reason we ship an entiore python distribution with the windows installer, is becasue there are a bunch of python packages and dependencies that are a real pain to compile on windows; and once compiled they need to match the python version their compiled against. its still just a plain python interpreter thats run, its just kept seperate from your system to keep it from messing anything up (kind of like virtuanlenv). I havent worked with pyscripter, but if you can tell it which python.exe to use (and maybe set environment variables, or alternatively set them using your OS), everything *should* work ok. to see how the env is setup, you can see kivy.bat here: https://github.com/kivy/kivy/blob/master/kivy/tools/packaging/win32/kivy.bat 
Thanks, I made the change.
It's entirely possible to write the encode function so that the key can vary. :-) I agree it's not going to keep your data secure. This is basically ROT-9 with some minor kluges.
-a maximizes the window, but doesn't go fullscreen. (Window bar, and Mac OS menu bar still visible above image.) But, yes, fullscreen with normal resolution (and no cursor) is what I want. The fullscreen mode seems to go fullscreen with some lower resolution (and no image). I don't really want smaller images to stretch, as that degrades image quality. But thank you for the tips, anyway.
&gt; -a maximizes the window, but doesn't go fullscreen. mhh it seems your right, this is hte behavious on osx; might be worth a bug report. you can get true fullscreen using -f. however, it will then use the resolution you have set in your config, unless you also specify it on the command line using --size. E.g. on my macbook air I would do: python main.py -f --size=1440x900 you can also edit the default settings in your kivy config which lives in ~/.kivy/config.ini (where you can also disable the mouse cursor) 
Well, not reaallll..... okay... you win that round! ;) However, since Python 2.7, it is bundled with a new theming engine (I don't remember the name). And from what I read around on the internet, you can make your apps look *much* nicer now. But to be fair, Qt really *is* great, and I doubt any other toolkit comes even close. Having said that, the Qt setup, especially if you want to build a windows executable, is a PITA. I say that speaking out of PyQT experiences. I don't know if PySide is any better. Especially if you just started programming, it might not be the most gratifying experience. In the end you have to decide by yourself *where* you want to sweat blood. During development (Tkinter), or during packaging/distribution (Qt)...
PyQt on Windows is no more difficult to build a "frozen" executable than any other Python script. I think there are a couple more options in `py2exe` you need to use. If you're talking about C++ Qt, then maybe, but it's Window's idiosyncrasies more than anything that make it annoying.
A better naming would probably "ancient" style classes... ;) They date back for aaaaaaaaaages, when the underlying C-implementation was still different. In my experience, for many applications it won't make any difference at all which ones you use. Once you have a more complex application things start to get more interesting. The standard library still contains old-style classes, and the difference may become important when you have class hierarchies inheriting from these stdlib classes. Another, related difference is how you call super-implementations of methods. You can either use the builtin `super`, or call the parent method directly from the class namespace. The semantics become important when you do multiple inheritance. From what I read online, using `super` is predictable where the direct call isn't. And that you always should use the same way of calling in your whole class hierarchy. Again, this gets hairy if you inherit from stdlib classes. **BUT**: These problems surface only *very* seldomly. In my whole carreer as Python developer (which is now somewhat like 8 years) I never ran into such cases.... but I have a sneaky suspicion that I soon will with a project I started about 7 months ago...
By the way... if you are interested in packaging and distribution, then feel free to read [my article about packaging][1]. I am still not happy about how I manage version numbers in that guide, but I have a better alternative ready in my brain. I just need to squeeze it out onto virtual paper... Keep an eye out on the blog... it may appear in a few weeks... ;) [1]: http://foobar.lu/wp/2012/05/13/a-comprehensive-step-through-python-packaging-a-k-a-setup-scripts/
Check out the [pep8][1] and [autopep8][2] modules. [1]: http://pypi.python.org/pypi/pep8 [2]: http://pypi.python.org/pypi/autopep8/0.8.2
btw, any chance to get Python 3 support anytime soon...?
Thanks man, sounds like it could work out well. I'll give it a look
we are working on it :)
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: http://www.reddit.com/r/Serendipity/comments/142qrq/my_first_python_app_also_my_first_app_in_any/
Well... obviously that is true, because I tried to reproduce it and failed. Hmm.
Congratulations on your first app! This looks really good. Some changes/additions you might consider: * Add docstrings to each relevant class and function explaining what it does (following [PEP 257](http://www.python.org/dev/peps/pep-0257/) preferably) * Fix your indentation and your newline usage to conform to [PEP8](http://www.python.org/dev/peps/pep-0008/). Syntax checkers like the [pep8](http://pypi.python.org/pypi/pep8) tool will catch many of the styles issues, but may not catch all of them. In general try to avoid 2 consecutive newlines except between module-level classes and functions and try to use 4 spaces instead of tabs * When you find you're using lots of whitespace to split your code into blocks within your functions that's a good sign that your function should be split into separate (more single-purpose) functions * I'd lowercase the module name (it's the preferred convention) * If you haven't already, put it on PyPI so everyone can download it easily using pip or easy_install * Try to avoid `from X import *` (use `from X import Y, Z` instead). * Consider using an [EditorConfig](http://editorconfig.org) file to denote your preferred coding style so others can contribute more easily (this is especially useful if you decide to go against some section of PEP8)
As you seem to be a Kivy dev who knows what's going on, what's the best matplotlib backend to integrate into Kivy?
I should clarify on your initial comment. I used the % and the decimal module to 100 places to make sure an incorrect key won't work. EX. 2674772281 % 9 and 2674772280 % 9 will return the same number with the default float length. This is the same idea behind the user key function and why I left the key to 9. Since I can't guarantee the key they enter will be divisible by 9, I just multiplied it by 9. Anyways, if the user chose their own offset I could use that as the multiple. But attempting to get an offset any other way would probably require division, which will be much less secure. Man I should really start commenting my code. That made perfect sense at the time but trying to explain it now seems a lot less clear. 
http://code.activestate.com/recipes/578353-code-to-source-and-back This contains an example of how to write a decorator to apply an AST transformation to a function.
NFS does not offer all the Unix filesystem semantics; it has issues with caching and locking. Why would a program work the same on all filesystems, when all filesystems are not the same?
Thank you for this (and the gist, and the cursor hint). It's much appreciated. With your changes everything works except that I get the wrong screen resolution. I can try to work around it (by looking up the resolution, as Richard_Judo suggests), but isn't that really a bug? Source code below for reference. import kivy kivy.require('1.4.1') import random, os from kivy.app import App from kivy.uix.image import Image from kivy.core.window import Window from kivy.clock import Clock from kivy.config import Config class PhotoScreensaver(App): def __init__(self): App.__init__(self) self.photos = [] find_all_photos(self) def build(self): keyb = Window.request_keyboard(self.stop, self) keyb.bind(on_key_down = self.key_pressed) self.image = Image() self.change_image() Clock.schedule_interval(self.change_image, 10) return self.image def key_pressed(self, keyboard, keycode, text, modifiers): self.stop() def change_image(self, whatever = None): self.image.source = random.choice(self.photos) def add_photos(self, nothing, dirname, files): for file in files: if file.endswith('.jpg') or file.endswith('.JPG'): self.photos.append(os.path.join(dirname, file)) def find_all_photos(app): os.path.walk('/Users/larsga/data/bilder/privat', app.add_photos, None) if __name__ == '__main__': Config.set('graphics', 'fullscreen', '1') Config.set('graphics', 'size', '0x0') Config.set('graphics', 'show_cursor', '0') Window.fullscreen = 'auto' Window.toggle_fullscreen() PhotoScreensaver().run() **Edit**: Actually, I tried setting the size explicitly to 1920x1200, but it has no effect. I still get the lower resolution. No idea why.
I personally think this comes down to muscle memory and future programmers who grew up using touchscreens will not have this same issue.
did you try to pass --size=0x0 on cmd line? 
No, I didn't. If I comment out the size and toggle_fullscreen lines in the code *and* pass -f and --size=0x0, then I do get fullscreen display of the images. Thank you! The cursor shows up, but I bet I can remove that too on the command-line.
The fundamental structure is basically the same, but there are quite a few minor differences in the API - where constants are located, which letters are capitalised, and things like that.
(you're missing quotes on your glob-string :) )
Probably 10 minutes to get the basics working (clicking to control the lights) and another hour or more to add some polish?
I see lots of references to a JVM backend in these slides. Can someone elaborate this wrt. Jython?
So, here are the coupons as promised: Enter **REDDITFREE4** to get into the course for free. If you are able to support me (I'm a poor college student doing this in my own free time), I'd very grateful if you could subscribe to the course for the fee listed. If you think that's too much however, here's another coupon: **REDDITSUPPORT** which lowers to price to only $9. Either way, I hope you'll enjoy the course :) **EDIT**: Join us at **/r/PythonGUI** for a talk! 
Can a python program using the QT framework be compiled to use under windows? 
Thank you! I have struggled with python GUI development before and cannot wait to take this course. 
Best of luck
Yes, it is possible, someone asked the same question. I will go over it as well. Basically toward the end we'll build or real application, and then one of the final videos will be packaging the application as an EXE and distributing it as a Setup.exe (along with the installation wizard). 
py2exe is one possibility. there are others when i looked into this a couple months back, pyinstaller is another -- just giving you some keywords to google. documentation is fairly horrendous all around. one annoying thing to note is that using py2exe on osx hardware (dual booting windows 7) didn't allow me to create a single file executable but i was able to do so on a garden variety HP box. also, compiling QT from source with the right flags enabled is the devil.
I have never had any luck with py2exe when it came to compiling the PyQt/PySide applications, but PyInstaller always worked just fine. 
I think that'd be honestly too much work while there's too little benefit, the code change really isn't that big as far as I am aware. 
FWIW - I've done the turtles module with my own kids (5 and 7) and it was a big hit...
Thank you! No worries, I love you just the same :D
Why? The definition of print (without ',' at the end) is to print a newline, so i don't see any connection to mathematical consistency. Python is inconsequential mostly (not always) for two different reasons: history and practicality. 
Thanks so much for this, I do a fair bit of python but never quite sunk my teeth into GUI's. I promise I'll subscribe next pay day :)
Please, no.
Actually, he's got a good point. The challenge is going to be taking these kids and moving them towards good practices... Javascript suffers from the PHP issue - lots of cut n' pastes who don't learn how to do it right. This drives out good developers. Recent developments (node, advanced UX) are helping turn the tide.
You can put Javascript on Facebook? I thought they escaped that stuff.
Not in comments, but into facebook apps which are hosted elsewhere. To get a game into an iframe on facebook you don't even need their API if it does not have to interact with the current user. There might even be a JavaScript based "what's the current facebook user" thing.
yay!
REDDITFREE2 is out :( EDIT: nvm, REDDITFREE3
This is a solvable problem in theory if you have a keyboard specifically designed for coding. When you start a new line in python, it has to be either an expression or a statement. If it's an expression, it needs to use an existing variable name. If it's an assignment statement, it can either reuse an existing variable name or create a new one. If you create a new one, add that to the keyboard's memory. If you do an `if` or `for` or whatever, it can auto add the colons and indent new lines, etc. In theory, a well designed software keyboard could be better than a hardware keyboard, since you so rarely have to type new variable names compared to manipulating existing variables.
I teach my nephews and young cousins Python. It is an easy pickup and go language. 
If you're interested I made the necessary changes. It effected a lot of the script so I made a separate repo for it. https://github.com/larz258/Scrypto
Very cool man, thanks for providing this for us! It's been quite a few years since I've done anything with pyqt so it'll be nice to see how things have progressed in that time.
I am a huge fan of all of Brandon's talks.
awww yeah. Will check this out when I get a chance after finals :)
Something to consider, postgresql has specific optimizations to be used as table work queues. You might take a peek and see if it offers a superior solution to that of mysql. You might find your solution is good but your implementation leaves something to be desired. Not saying that's the case, but doesn't hurt to explore.
Yes, but don't get misled. It's a powerful language and is professionally used. 
That's unfortunate. In many workloads where scalability is an issue, postgresql frequently stands heads and shoulders above mySQL. Postgresql also has some nice, and semi-recently highly optimized messaging capabilities which might further improve workflow. 
What is the place of nanotest-py vs nose2 ?
That `print` prints newlines is expected, but why does iterating over lines returns lines including delimiting newlines? When I say `for line in file` I imply that the file contains formatted data on top of a simple bag of bytes: a list of lines delimited by newlines. And no, I don't care about perfect roundtripping, stopped caring since `\r\n` and `\r` are automatically converted to `\n`. If I wanted perfect roundtripping I'd have opened the file as binary and sure as hell wouldn't think about iterating over its "lines". &gt; I'm not sure where you saw that code that printed two newlines, but I would report it as a bug. http://docs.python.org/2/library/stdtypes.html#file.close It's not exactly a bug, it's what normal people write and expect to work. In an ideal world the language would be fixed, not the documentation. &gt; &gt; Why is that last line different syntactically? &gt; Python is not 100% consistent, or 100% mathematically consistent &lt;...&gt; Sometimes there are special cases and special notation that you need to learn "just because" No, wait. Sometimes there are special cases and special notation because it's a better fit for 99% of actual use scenarios. It's like Huffman code: you trade uniformity for better performance on real data. Removing the `print` statement is a perfect example of what _not_ to do, of harm done in the name of foolish consistency. Add `__builtins__.print_function` and make `print` statement implicitly call it or the module-level override if you want the ability to customize printing (either by overriding it or by calling `print_function` with particular separator etc), but let me have my parenthesesless statement that I need in 99% of the cases. Having the del statement on the other hand is something that you need to learn "just because", because at some point Guido or someone thought that people are going to delete local variables or object attributes often enough that warrants a special case, but as it happens we don't and it doesn't. I think that Python is one of the most syntactically pleasant languages. I also think that it's important to admit that something is a wart instead of bending your mind until you no longer see it as a wart. Not only because admission is the first step to recovery, but also because doing stuff like that to your mind produces cracks in it, which reduce its general durability, so to speak. See also: http://zedshaw.com/essays/curing_pythons_neglect.html
See my [reply to u/lost-theory](http://www.reddit.com/r/Python/comments/1444nf/video_a_python_sthetic_beauty_and_why_i_python/c7a07n4?context=2).
He says all of this in the first video in the course which goes over resources.
yeah. Unfortunately it seems that the resulting code can't call into Java code, which is what I would need. What I hoped for was that I had a Jython alternative -- being still on 2.5.3 is a major PITA.
so the JVM backend in PyPy promises same interpreter with a different backend. There is some work on having it call into Java, not very much though and it's outside the core interest of the pypy people. There seems to be a real issue with the performance though - while the result can compare with Jython (in the future, I didn't even bother running the benchmarks now), it won't be able to compete with the PyPy JIT, which makes it "less interesting" for the core developers.
I'm getting this as well - did you ever find a solution?
If you just need a simple package that you can send and it'll 'just work', you can create a virtualenv, install all the packages you need in there, and then just send it together with your script. Bad idea for production, but it's good enough if you're on the same team. Also lets you develop the script in the same virtualenv, so you're absolutely sure nothing breaks.
[TortoiseHg](http://tortoisehg.bitbucket.org/), a GUI for the Mercurial VCS, is a good example. It's open source, so you can examine the code for it.
Have you done anything with python and the win32 library? I checked it it out and it was a bit daunting, but I do like the idea of the win32 native feel.
It's not intended to be vs. anything; it's just meant to work the way I'd like. In an attempt to better answer your question, though, I went and looked at the nose2 README. I would say that the main philosophical difference between the packages is one of configuration. Nose states that they are evolving toward a more loosely-coupled model, aiming for the project to eventually exist as a flock of plugins for unittest2. They also say they want nose to be more easily configured by its users. I, on the other hand, am designing for zero configuration (or, more correctly, for convention over configuration) and for the library to consume as little brainspace as possible for its users, which is why the entire exposed interface consists of 2 methods. Also, nose2 says it will continue to support Python 2. nanotest is Python 3.2+ only. If this sounds good to you, then you may want to check out nanotest. If not, then by all means, use nose2 (or anything else that fits your mental model well). Since nose takes the approach of calling functions with certain names as the mechanism for running tests, you could use the nanotest library _inside_ nose -- or any other testing framework of that style -- if you saw some advantage to it. The only important thing is to test your software _somehow_ :)
Pythonista has a keyboard with those keys on it.
I'm a university student. Working in a group project and seeing how people lay out their whitespace has made me come to the conclusion that CS needs to be introduced to students with python. Since whitespace doesn't matter in java, its just a big mess. If I didn't have an editor that highlights the scope of the brackets I would have no idea what the scope of what my group memebers had wrote. 
Thank you so much!, only through with the first 3 lectures but so far its been awesome! Compared to other online python courses I've taken (some of which gave collage credit) this one really impresses me!
Author helped on his Github page, [issue #2](https://github.com/myfreeweb/markbox/issues/2). &gt;Hmm, if it doesn't work without the uncache_key, clear the whole cache. &gt; $ heroku run python &gt; import os, redis r = redis.from_url(os.environ.get('REDISTOGO_URL')) [r.delete(k) for k in r.keys()] &gt; I think I should make it do this automatically when there's an error. &gt;I've had posts not working with 500, this helped... This fixed the issue for me. I'm hoping a later version will clear the whole cache on a 500 error automatically.
[Here you go](http://pyvideo.org/speaker/337/brandon-rhodes)
Hmm, how are you teaching them? Because I can never know how to teach someone python and make it seem "fun".
There are loads of auto indentors for Java, in fact there is one integrated into eclipse
Why not create a setup.py using packaging or distutils2, you could then host it on an internal PyPi instance
it's not my project nor it's a launch, just regard it as PSA or FYI.
Also, where is the documentation?
You are right, it is stupid to have native python bindings to the most extended gui toolkit.
I'm using it to do the most important things first, but this is the first I've heard of anybody else specifically doing it.
The idea is that I'm rapidly developing scripts and at any one point in time I say, ok I want joe to run this. It pulls in from some subset of the myriad of files I've written and I don't want to send joe all of these files, just the ones that are truly needed. So yes, setup.py might be the right answer in some cases but in mine I'm looking for a solution to the problem: "oh, I've been running and tweaking this script for a while without thinking about its dependencies and I just want to send it to someone right now without thinking too much because I'm gonna change it tomorrow anyways"
While you may balk at another module, have you seen [MooseX::Declare](https://metacpan.org/module/MooseX::Declare)?
I also love this, I had my eye on Venster and was considering updating it myself, I've have a case where I need to create windows in a very specific way which most frameworks don't let you do.
They're not exclusive. BASIC got a bad rep because while it was easy to pick up, it was hard to do anything useful. Python is both. Perl and Ruby might also be both (I started with Perl), but I think Perl lets people slip too easily into obfuscation, and for some reason Ruby always seems to encourage High Magic. You can invoke arcane powers in Python as well, but it's (usually) easy for someone who is reading the code to figure out what is going on, at least.
For what is worth, when you write a rebuttal of something, please take five seconds to link to the original. Lack of it usually means you did not take a whole lot of effort into making your point either.
Run code to make stuff go, not useful. Press button to make stuff go, more useful. I'm not talking about enterprise level UI design. But if people learn how to make a simple push-button-get-reward app, its more useful than running scripts all day. (Ironically, HTML is probably the best for that these days.) JS because of facebook just made my hairs stick up on end. I guess it gets young programmers used to the "corporate overlord bullshit" in an era when anyone touching a computer can actually rise above it and stand out, and that bothered me. Sorry!
Sometimes you want OS-specific capabilities and don't care to support other OSes. Sometimes you don't want the overhead of installing a big package when a small, pure-python one will do. Sometimes you don't mind if you're OS-dependent but you do want your code to work on CPython, Jython, PyPy, and IronPython -- which is possible with ctypes. 
Probably the linux you're using has package management tools (apt or yum or such). Try building Python and it's tool sets from scratch (./configure, make, etc.) and compare that to Windows. Most development environments are awkward to install/setup on Windows. It's just kinda how it is. It has been my experience that outside of using Microsoft's tools (VisualWhatNow), windows isn't designed for ease of developers. &gt; *have to set up PATH* Not to be "that guy", but that sounds like complaining you have steer a car when you drive. 
Is it? I download the MSI from python.org, double-click it, and it's done. I've installed and use Python all the time on Windows, and every time I've installed it, it just works. The installer even updates the PATH for you (by default). I don't know specifically about pip (I've never used it), but I've always been able to install packages either with their Windows installer (major packages come with them) or with "unzip file, setup.py install". That said, it looks like [pip itself is something of a hassle to install on Windows](http://stackoverflow.com/questions/4750806/how-to-install-pip-on-windows) (ironic, but nothing to do with Python).
Really? I use Windows all day, every day, and almost all programs install with "download installer, double click".
I agree with the ecosystem comments, but let me try to help you here. [Run this](http://python-distribute.org/distribute_setup.py), [run this](https://raw.github.com/pypa/pip/master/contrib/get-pip.py), and you'll have pip installed. Installing packages that include native libraries is tricky, but there are tons of prebuilt ones [here](http://www.lfd.uci.edu/~gohlke/pythonlibs/), complete with fancy installers. Hope that helps :)
Thanks for the comments. We'll be making substantial changes in the near future that will further differentiate us form them. Since we do stream from youtube/soundcloud we have already built up a substantial international community which our audience reflects as being incredibly important to the experience. You can play an unlimited amount of songs, but if you're in a crowded room we like to allow everyone who wants to DJ the chance to get up on stage which is why we limit to 1 song in that situation. Hope you enjoy!
Yum install python3 Fedora master race!
I don't think that's possible, as its difficult to drastically analyse dependencies with python. However setup.py works really well with a company PyPi setup, because with one command you can push a package to a server and get one of your colleagues to install it with a single pip install &lt;package name&gt;. Then you get to update it and ask them to download a new version when you change it
I'm very new to Python. I just installed it for the first time last week and it literally took me 5 minutes to get hello world running. Granted I don't even know what PIP is, but I have "pylab" up and running, no problem.
[Not to mention this page](http://www.lfd.uci.edu/~gohlke/pythonlibs/) full of windows installer for every version of python for every package imaginable. It is trivial to set up python in Windows. I dare say more so than Linux. Sure in Linux it's easy if the python package you want is in your apt repository. sudo apt get python or something. But what if you need a different version than the one that's there? Uhh....
But how do you manage the versions of all those packages and their dependencies? I could never develop on Windows. I find Mac hard enough but I'm kind of forced to at work.
No, I wasn't saying that. I meant it took me a long time to figure out exactly what you posted. If I would have run into your post right away it would have saved a lot of time.
Would be possible to have doctest-like functionality but separated from actual docstrings? Would it work just having a test module that uses doctests for importing other modules and executing the tests? I just tried it. I just fiddled with python console, importing stuff, copypasted it into a test.py surrounded by triple quotes and doctest.testmod() at the end. It works!
One use case I can think of.. many years ago I had a small handful of Windows-only utilities with minimal GUIs that needed to be very small for distribution. Py2exe with a ctypes wrapper for Windows API calls made the resulting executables quite small compared to WX. For anything with a non-trivial GUI you are better off either using something else. If your program is only ever going to run on Windows you are better off in .NET land anyway IMHO.
pip is just as easily installed on windows as on any other platform. as you said, the python installer modifies the path. then you can simply open up a command prompt and type `easy_install pip`.
In that case you may be running a system where sudo is incorrectly setup. Or make or gcc is not installed. Those are pretty much development necessities. Can't get anywhere without them.
http://jsfiddle.net/
I'm sure that the many poor transitions between sentences and paragraphs and the random one-word sentences that are tossed in don't help convince that it was even proofread.
`sudo apt-get install python` isn't Pythonic either and I'm pretty sure you can't install python itself through `pip`.
Is matplotlib the be-all and end-all of scientific plotting in Python? It's very good of course, but as R has three graphics systems (base, lattice, and ggplot2) with different strengths, I wonder if there are other high-level alternatives (e.g., in the way that lattice and ggplot2 are) that are being developed with serious consideration.
That's a great theory and all, but have you using pip on windows to install libraries written in C?
&gt; Define not very good. Failing silently (and/or failing but reporting success), failing with a message that does not detail the cause (often without logs), modifying the registry poorly, the installer does not automate configuration common to nearly every installation... In my experience, it is far more rare for a Linux install to be painful than a Windows install. &gt; If you don't want the default version that exists in the repo, you're SOL. Really? ./configure make su checkinstall
Javascript suffers from the PHP issue - a complete WTF excuse for a type system.
Go to http://enthought.com Grab EPD Free 7.3 It has: Python, an editor, ipython, a good selection of libraries and most of the nice toys.
a) that's *not* easy b) that fails with stupid errors more times than it works
Do you go over the model/view approach at all?
Depending on the package manager, the last couple versions could still be in the repository. Package managers also keep python up-to-date. I don't know if the Windows version has automatic updates or not, but that's one area where Linux is easier.
It might also be autotools. Or the package uses CMake rather than make, or something entirely different. Following the `INSTALL` or `README` advice usually works though.
Because windows was made by and for mentally challenged people.
I have never installed python on my OSX box: $ python Python 2.7.2 (default, Jun 20 2012, 16:23:33) [GCC 4.2.1 Compatible Apple Clang 4.0 (tags/Apple/clang-418.0.60)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; That was pretty easy. 
hm, no mention of cygwin in this discussion surprises me a bit. I use cygwin/pyvirtualenvs/pip with no troubles at all, mostly b/c I'm more familiar with the environment than I am Windows. 
What happened? is it too big of a mess?
Yes. * Your lines are too long and the code formatting is sloppy and inconsistent, making it difficult to read. Google for PEP-8; there are very thoroughly documented standards for this kind of thing in Python. * Where are your docstrings? They are there to help youand other programmersexplain what you are doing, and help you make sure they are doing what you say they are. * What is your entry point? If you want to make this runnable on a command prompt you need to make some way of executing 'myProgram()' when the command is called. There is a very common pattern for doing this that is documented all over the '.net. Look it up. * You're using unicode characters (like the elipsis: "..."), but are declaring ASCII strings (e.g. "asdf" instead of u"asdf") and have not declared a document encoding. * Don't catenate values with strings using commas. Use interpolation instead (e.g. "Well hello dear, %s" % (name,) -- not "Well hello dear," name) * What is the point of making a dictionary of english-to-spanish numbers if you never use the english values? Just use a list instead: ['uno', 'dos', 'tres', 'cuatro']. * You don't need to recast dict.values() to a list; it's already an iterable at this point. * The 'mirrorWord' function contains numerous errors: * The 'mirror' values (e.g. mirror = word) is never used. * Looping over each letter in 'word', then adding it to "image" on each pass, is woefully efficient. Try this instead: word = 'Hello'; print word[::-1] * You have string literals inside your 'if' statements that have no effect. Did you mean to `print` these? * Instead of saying 'if' twice with one clause equal to and the other clause not equal to, maybe you mean to write 'if/else'? * As for the raw inputs ... What's going to happen if someone enters anything but 'Y' or 'N' (with uppercase, no less)? Your application is going to exit. The correct commands should be in a loop that keeps you at the prompt until you answer satisfactorily. I think you have a lot of homework left to do.
such a tempting list! can't decide whether i should go to GTAC or Pycon 2013..
Right, I was vaguely aware of these libraries but most everything I see coming out of SciPy is matplotlib stuff.
Thanks for the link!
Even though I use Linux and always develop in it, I find this library very useful for small GUIs, for example for creating a configuration dialog for a game before OpenGL is initialized, or a progress bar for decompressing assets, whatever. In Linux I usually call kdialog/zenity for such tasks.
Excellent point. I'd also prescribe the following for a 12.04 user: sudo apt-get install cronutils man 1 runlock (the runalarm util is also nice. using runlock with runalarm together is a powerful combination)
Just use [homebrew](http://mxcl.github.com/homebrew/), and install all your packages that way. The only packages you install in your system Python should be pip, virtualenv and virtualenvwrapper. Then, you use virtual environments for any project dev.
well it's not that hard...it's a basic thing I didn't even download the installer, just got the zipped version updated my path and there it was ... is setting an environment variable so hard?
You have to configure the graphics *before* you import Window. It's a known limitation of the Window manager.
Holy crap that is a powerfull workstation. My specs are: * Asus M5A97 * 16 GB of Gskill 1600 (4x4GB) * AMD 965 Phenom II * Nvidia 460 GTX * Intel SSD 520 (120GB x 2) * WD Black 500GB x2 * KINGWIN STR-500 500W (80 Plat Certified) The Western Digital drives hold my data, while the SSD store system files. I develop web applications, and this system runs apache, postgresql, eclipse, and every majour web-browser at the same time without any struggle. (I have windows 7 running in a virtual machine to test with IE) Before I put this system together, I used the Dell Inspiron 1520. * Intel C2D 7500 (2.2Ghz) * 4GB RAM * WD Scorpio Black * nVidia 8600M GT It did the same tasks just as well, except a little slower. It served me very well during school.
Two reasons: Firstly it's hard, relative to linux, to install *most* development environments that aren't windows centric in windows. Linux distros and Windows involve different design tradeoffs. This isn't specific to python. The guys who work on haskell at microsoft research all run linux and haskell is apparently a bitch to install in windows as well. It's silly to compare a dev focused environment like most linux distros with windows in terms of how easy it is to do developer related things. Also, it's just generally much much harder to install *anything* on windows than on a modern linux distro. Windows is decades behind Linux when it comes to packaging software (as is most everyone to be fair). Secondly, most of the developers who make these tools are using linux or osx so they build things to work on the platforms they care about. There aren't many windows users doing this kind of work or it would be further along, although it is more work to support windows than a *nix or osx. Interestingly I bet OSX gets more effort put in than linux at this point, there are a lot of OSX using python library devs but also the linux support is very very easy and so it gets done quickly. tldr; writing software to manage these things is harder on windows and fewer people care, these two things feed into on each other.
*That* wasn't hard. But of course you would never do that. Because then you'd have an unmanaged bunch of files just spewed all over your filesystem with no sane way to uninstall it or upgrade it.
Jesus christ.
It depends what you're used to. How many of their uninstallers work properly? How many support installing multiple versions? How many notify you they have updates available? How many download their dependencies? Once you get used to a modern system for installing stuff downloading installers seems pretty awful.
Now now, to be fair once out of every 100 times you have to make your own package. That eats up so much time, like 5, sometimes 10 minutes.
Ugh, I don't know how I feel having someone who was a fan of Basic promoting python and comparing it to Basic. I also learned Basic early. I kept learning though. Basic was awful.
Popular because people *have* to use it. A lot of mistakes made in it's design. Young people like it because they can get started on platforms that are already available, familiar and widespread. A community/ecosystem that encourages patterns known to be mistakes decades ago. Javscript *is* the new Basic!
For my day job I develop regular software: telco and web stuff, all in Python. In my spare time I develop OpenGL games in Python with some cython thrown into the mix. All of this I do on a 2012 13" MacBook Air with 8G of RAM (which is probably way more than necessary.) It is more than capable.
Solution: Water cooling with a very large radiator/reservoir!
Well... [https://c9.io/](https://c9.io/)
You are having problems finding programming work? I haven't heard of that problem in a long time...
My setup is a last-of-the-Mohicans 17" MacBook Pro (April 2012) with 16Gb of RAM and an SSD instead of the optical drive. When this is not enough (frequently -- I do big data work), I rent boxes in the cloud and offload processing. I now have 80 cores crunching 1.6 TB per hour on AWS
I would *love* to learn from you the proper way to set up Python on the mac for personal development. I am always afraid of messing up the pythons that come pre installed with OS X.
Yo this is amazing Do you have any idea how I could import pygame into this? Is that possible? Or does it have to be a console thing. Please help. Forgive me for my noobery.
I *just* upgraded my workstation with a pre-Black Friday deal. Went from an Acer Timeline 3810t with 4GB of RAM and a very slow Core 2 Duo (the super low voltage kind) with a 5400RPM 500GB hard drive to a: Acer Aspire S5 with 4GB of RAM, dual-core (hyperthreaded) Core i7, and dual 128GB SSDs. Before the upgrade the only thing that slowed me down was the hard drive, really. The slowest-of-the-slow Core 2 Duo was actually plenty fast enough for developing Gate One (http://liftoffsoftware.com) and swapping was rarely a problem--even with loads of tabs open in Chrome. For reference, both laptops run Kubuntu. I use kate as my primary IDE with Gate One (vim) serving as a secondary IDE (which I'm using more and more often). 
After a lot of trials and errors with the native Python on OS X I have finally given up and do all my development in VirtualBox. Emacs works well over tramp, also there are shared folders. 
I did several runs of my machine learning on a netbook. Ran fine (had 4GB ram), using very lightweight linux.
You must've been training on some small datasets. I've got a similar setup currently and I find that 4GB just ain't sufficient for ML.
Keeping it in another room is clearly the coolest solution.
Only 2 cards I think, the ASUS ones are displays.
The fuck is that desktop used for?
According to SO: [sort of](http://stackoverflow.com/questions/39159/is-it-possible-to-run-mac-os-x-in-a-virtual-machine).
Depends entirely on how your ML is accomplished. Much of my data was kept on disk. Using a good index, and programming in a cache aware manner lets that have okay performance. The size of a dataset doesn't matter, so long as learning does not require one large structure in memory. You could train a neural network on a huge number of images, if you only kept weights, accumulated error and the current image in memory.
minesweeper, mostly
It's free to try, why not just try it out? I suspect you're able to install your own libraries. It might even support pip or easy_install.
Not sure if it's what you're looking for, but I develop exclusively on my Mac using Python. The built-in version sucks, but installing the latest version using Macports is a breeze. I installed the macports Python almost a year ago, and have been using it without __any__ issues since. You should definitely give it a try.
Your tablet is a thin client to a server basically or to say a input device to your server. You have a light weight device plus a box that can be powerful when you need it to be. You can be as mobile as you want and if anything happens to you tablet you don't have to worry because everything you care about is stored in the cloud. Cost wise it comes out to about the same price as buy an equivalent physical box.
Read the original post and you'll understand, it must be somewhere on his blog.
I had to figure this out recently because I needed up tot date versions of scipy and similar packages. After many failures listening to people who described 'easy' ways to do it, I installed everything from macports, with pip for the few things that were missing. Port will basically create a virtual environment anyway and leave the stock stuff alone. Install the select-2.7 or whatever package and it will work very much like virtualenv. 'port search' is your friend. You'll also need xcode and possibly gfortran.
For serious work any laptop is sub-optimal. The ergonomics are just so bad, unless you have an external keyboard, mouse, and display(s), and at that point you might as well just have a desktop. 
At some point the user fatigue of having an extra 25ms (minimum, much more if you're over the net) of extra lag will have a cost.
No. Chuck Norris.
Monitors are a total crap shoot, just like everything else I guessSome are just poorly made. I've had cheaper ones and ridiculously expensive ones go on me; ones in the middle of the road seem to last forever. If I stopped buying from manufacturers that had failed on me I'd be out of options for hard drives for sure, and probably for mice as well. :) I hold a grudge for a little while but you've got to forgive eventually and move on.
I write my software on a 400+ core compute cluster. Variety of hardware but the latest machines are 16 cores with 64GB of RAM or some silly number like that. I work on a 27" iMac desktop with a full-screen terminal logged in via SSH. 
First off, you should probably be working in a virtualenv; if you are not, you end up mixing all of your projects' dependencies up with your system Python. If you're curious, check this out: [The Hitchhikers Guide to Python!](http://docs.python-guide.org/en/latest/) So, starting from that assumption, here's how you install pygame and make it useful, assuming you're using virtualenvwrapper: brew install python brew install sdl sdl_image sdl_mixer sdl_ttf smpeg portmidi mkvirtualenv my_project pip install hg+http://bitbucket.org/pygame/pygame Basically, install pygame from their source repository, rather than a released package. I should note, I am shamelessly ripping this off from [StackOverflow](http://stackoverflow.com/a/8460209/23309)
Would your SAS drive RAID setup outperform one or more RAIDed SSDs? I don't know much about the high-end platter drives.
Is it well known? 
I code with a used laptop I picked up for $40. A gig or two of RAM (I never use it all) and a 2Ghz processor. Pretty much the opposite of isolationismcom's rig. It helps that I do my coding in vim on a small linux install.
Im a scientific programmer, so i have access to two big compute clusters. However, my home machine is an i7 980x, 16GB ram, and twin 1GB 460s in SLI. It serves well for development on smaller data sets, gaming, and video trans/encoding.
Only 24GB of RAM? I have 32GB in my modest desktop (the max for unbuffered DDR3) Servers are /minimum/ 64GB. And go SSD. They'll put the 15k rpm drives to shame in any comparison. Plus they're cheaper. And suck way less juice. 
It's "only" 24GB because it's a workstationnot a serverand I bought it two years ago; also, the RAM is all single-rank; your workstation is probably full of quad-rank memory. I could have trivially gone with 96GB+ for not much more money, but the IO performance would go down. I'd rather have REALLY fast 24GB than gobs of RAM I don't use. I've never even come close to hitting swap file, so I made the right choice on all counts. As for SSDif I bought several, probably. If you want to hire me so I can pay myself enough not to be slowly sinking toward both corporate and personal bankruptcy, I'd certainly consider it. For right nowand until drives start dropping off on me, franklyI'll be happy with what I've got.
[brew](http://mxcl.github.com/homebrew/) install python
It is a bit of a pain, but can be done. Mostly the hurdle is getting pip and virtualenv installed in such a way that they work. I have a bunch of non-Apple Pythons installed via homebrew which work very nicely. If you're not willing to muck about then the homebrew approach can be the easiest: https://gist.github.com/3179227
http://pyweek.org/u/richard has some of it. You can't see the current stuff though I'm afraid. I use http://pyglet.org/ and http://kivy.org/ for the OpenGL stuff; the library choice depends on the actual project.
Wow, I've seen Kivy mentioned in various posts over the last week or so but never knew what it was. Can't believe I'd never looked into it before. It looks perfect, thanks. :-) 
I had a feeling you'd have performed a thorough cost/benefit analysis. Thanks!
The cluster? No, it's nowhere near any of the top 500 and it's privately owned.
2012 13" MacBook Air with only 4GB of RAM. I've used the Retina MacBook Pro before the image retention issue appeared, then I returned it. I could feel no difference downgrading from rMBP to Air. (Except, of course, the Retina screen, that was a painful downgrade.) But then again, I'm only beginning to play with data, my normal work is Cocoa and web stuff. I'm thinking about building myself a Hackintosh for Christmas with the following specs: - i5-3570K - 16GB RAM - 128GB SSD Then hook up another 24" Dell and I'll be all set. :)
I concur with your COO. Python doesn't need much power at all, and when you need the beef, a laptop isn't going to be enough. http://aws.amazon.com/ec2/instance-types/ -- even at 90 cents an hour for a double extra large, that's a thousand hours for 900 bucks, and are you going to have that much extra computing that you'd do on your laptop? Honestly, just get enough memory and your CPU is going to be fine. Pay more attention to the screen and keyboard -- those are what matter most.
i feel sad reading all this. i use a 3 year old laptop which has * 250 GB harddisk * 3 GB RAM * intel Core 2 Duo, 2 GHZ * 2 hour battery but i am still happy with it as i mostly write desktop application using gtk or web apps using flask, php or use Drupal. Maybe i'll upgrade after next semester.
1. http://mxcl.github.com/homebrew/ 2. $ brew install python. It won't mess with your system's Python installation at all.
Except when you decide you want to undock/go to a meeting/go on a trip. Then a laptop + externals is awesome.
Sort of is correct. I did it, it works, not well.
I'm in a similar boat. 3 year old Mac with a 2.something GHz Core 2 Duo, 4 GB RAM, and 320 GB of HDD. That said, I find it rarely ever chokes, so I'm not exactly in urgent need of an upgrade.
I have roughly the same amount of hardware, but for me, I keep all that hardware distributed across multiple computers, and 80% of them are in the basement. ssh and VNC are wonderful things. :) My actual desktop only needs to do a few things: Drive a bunch of monitors at high resolutions (three 1920x1200 screens at the moment) and play games, because... yay games. :)
I've been debating throwing Windows 8 on my computer strictly for the new Minesweeper. You better believe I want me some adventure mode.
Yup... I have been trying different setups and currently best seems to be small &amp; light laptop with good docking station and good external display,keyboard&amp;mouse. And this setup is silent too, thanks to the SSD disks.
What's ML?
If I were gay, i'd totally throw my boxers at you!
Mines a 4 core i5, you don't need a beast to write code
A slightly pimped Latitude with an i5, 8GB of RAM and a 512GB SSD. But I do kinf of code in the cloud. I run a sshfs to the code on my dev server and edit it with a local gvim.
I'm a freelance Python developer. I do a mixture of backend work (servers, databases) and front end web development. All on a cheap Toshiba laptop running Linux Mint, with a dual core 2.53Ghz processor and 4GB ram. It's more than adequate for what I do. Honestly, I would buy a faster machine in a flash if I thought it would make my life easier.
Speccy.
Thanks!
I've worked with some seriously heavy spec servers, so that time on kernel compile I can confirm is legit.
Butterflies.
An HP Z800+, are you?
There is a service[1] for spinning up an aws instance with ipython and science libraries preinstalled. I think it might be simple enough to use for some one-off cluster computing. I wouldn't want to develop any (serious/non-experimentative) code in an ipython notebook though. [1]https://notebookcloud.appspot.com/docs
Hahaha. Make no mistake, I can't afford this computer *personally* either; I am not wealthy by any stretch of the imagination. It is a business investment. I am the sole provider for my family, and I love what I do for a livingso having hardware that could more than keep up with heavy demand during high-traffic periods (where I'm working on 2-3 different projects at a time) only makes sense.
&gt; Oh, did you perhaps have the well-known Samsung capacitor-plague monitors? I must have done, because that sounds like precisely what happened to both of them. One was still "in the process" of going when I RMA'ed it; it would turn on fine for 30 minutes then the backlight would die, and the technician just sent it back without doing anything at all! I ended up calling them back over it, and they couldn't even produce any documentation about what the engineer didmust have been a Friday job. I feel your pain; I am done with Samsung monitors for a while after that shitty failure and subsequently even shittier service. &gt; After that, I gave up and got some HP LP2475w monitors and never looked back. Mah nigga. I replaced two 19" displays with an HP LP2480zx (and a second one for my wife's desk, too, as she's trying to make a business of her photography hobby) and bought the 5-year care pack for both for a paltry sum. As you say, business expense. Both have blown up on me once already, but there's something really, really nice about having the tech show up with a new one under his arm at your front door.
Does your OpenGL code run correctly in the VM?
The best things I ever did, in terms of performance, in order of importance: 1. Use a flash drive 2. Have a lot of RAM 3. Use pypy
In addition to Kivy, [QtQuick/QML](http://doc.qt.digia.com/qt/qtquick.html) might be an option. It's a little more mature and provides a web/touch-style interface with transitions, rich graphics, etc. If you're in the FOSS world, it's what Canonical used to build Unity 2D and KDE uses it to draw their panels and desktop widgets.
Read this because it is a very interesting (IMO) read, it will definitely answer your questions and even concerns. http://yieldthought.com/post/31857050698/ipad-linode-1-year-later
I'm thinking principally (of course) of Rails, and how they monkey patch and override methods in common classes to have weird side effects run when you call them. Metaprogramming is fine. But it seems like a lot of people learned Ruby from Rails, said, "Oh, *this* is how you golf it!" and now their programs are difficult to understand. Imagine if every python object in a library were full of `__getattribute__`, and objects were often created via `type`. It would be a complete headache. I'm not saying you have to do this in Ruby, just like I'm not saying you have to write cramped code in Perl. I'm saying that I think this is where people lean when writing in these languages.
If you want something really easy, download the kivy executible from their website and drag in the .py file on top of the app's icon. Pygame is compiled inside of the app so it should run perfectly. But you should do what offby2 said.
Ok... Just got creeped out by reading the Brubeck documentation while getting an alert on my phone that Dave Brubeck died. 
.____. Shit, I just use a 2012 Macbook Pro, 15 inch non-Retina. That's because I'm both design and Computer Science though. 
&gt; PyPy JIT compiles your high level code (and more) into machine code by quickly generating C code on-the-fly and using standard C complier to generate machine code. I believe you're a tidbit confused on a number of points, which kinda ruins your entire post. * The JIT in pypy does not generate C code and then compile it, the JIT generates machine code directly. * You seem to be confusing the JIT with pypy's compliation step, making things more convoluted than they actually are. Here's my own attempt at a better description of what pypy is and how the JIT fits into that. pypy is actually itself two different projects. There is pypy the Python interpreter, which is the most frequent meaning of pypy. The pypy interpreter is an interpreter which is (mostly) compatible with CPython, but includes a tracing JIT compiler. This means that Python code which you run in pypy that pypy determines is in a hot-loop will be traced to lear types and other runtime information in your program, and eventually some portion of your code may be replaced with optimized sections of machine code. This is what results in a big speedup for some types of programs (you can see benchmarks at http://speed.pypy.org) The second meaning of pypy is a toolchain that allows you to write an interpreter for a language in RPython, a restricted subset of Python. When you've written this language in RPython, pypy does analysis on the interpreter that you have written and applies a series of transforms which eventually result in the output of C code which specifies the interpreter you wrote in RPython with the addition of a JIT compiler built-in to your interprter. The pypy interpter is an example of one of these interpreters written in RPython.
Yeah for anything on Linux I just use X forwarding over ssh. VNC is great for Windows though.
have they made an rc or anything available yet?
Actually, it's more like: * download and install Python * download distribute_setup.py, start it using a simple double click * run C:\PythonXX\Scripts\easy_install pip That's it. I've done this numerous times.
I am fairly certain that the key idea of PyPy's JIT is this: &gt; RPython badges itself as a meta-tracing system, meaning that the user's end program isn't traced directly [...] but rather the interpreter itself is traced. from http://tratt.net/laurie/tech_articles/articles/fast_enough_vms_in_fast_enough_time section "Optimising traces" (the situation is made clear when looking at the hooks provided to write any VM w/ JIT, as presented in article) this makes use of a high level representation of the PyPy interpreter (key portions are in RPython, not all must be in RPython to benefit). The combination of the interpreter's RPython and the type restricted user code special case RPython get optimized as a single unit, and a great deal of code melts away in the particular special case.
Oh cool, thanks. I was always interested in genetic algorithms in python but i could never get the performance to come close to c++.
I'm working on a DWH project for school. They provided me a VPS, so my workflow looks like this: 1. I write code locally, test it with local database. (That contains much smaller sample of data.) 2. `git push` locally, `git pull` on the server 3. Run code on the server in `tmux`. I'm not sure what's the deal with the "cloud", I assume you meant running your code on a remote machine? If that's the case, I think my scenario qualifies. :)
Here's some discussion and options if you want to use linode/ec2 instances: http://news.ycombinator.com/item?id=4083175 http://www.ymacs.org/ http://shiftedit.net/ Ideally I'd want to have both local and remote access so a dropped connection wouldn't be an obstacle to work. That might still require a laptop with a standard OS at the moment though.
Those EMACS, fuck them.
I have an iMac and a pretty fat Dell Precision laptop.
I run Linux, so even if I had free time for playing games it's not like I'm spoiled for choice over the best DirectX games. :)
Nope! Just Chuck Testa!
Isn't SQL pretty much already close to natural language? Except in cases where you're doing complex joins or subqueries, I suppose.
Anything that'll let you replace base components with image representations should do the trick.
If the author is reading this, I'd suggest adding a few quick examples on the front page of the documentation to demonstrate why this library is cool and why I should use it.
My personal favorite is [Spyder2](http://code.google.com/p/spyderlib/) but I keep a portable version of [PyScripter](http://code.google.com/p/pyscripter/) on a thumb drive with me and I like it's project support better but some parts of the interface and such I'm not too keen about so I only use it rarely.
nop, trackgcroot generates extra code for the garbage collector to do stack scanning - its not used for the jit machine code is generated in the jit backends
I use [PyCharm](http://www.jetbrains.com/pycharm/) and love it.
I'll assume you mean any general tool, not just IDE. Well, personally, good ol' IPython, several tabs open, alongside Sublime Text to eventually put everything together. I'm a minimalist type of guy, and IDEs just seem clunky and unnecessarily heavy...at least for my needs. 
I don't know if I am lazy but I love it when my IDE auto imports, auto completes and syntax checks all my code as I'm writing it. I don't want my code to be written for me but the features a full out IDE is really nice.
I just use vim and run it in a terminal.
Maybe so. I tried Eclipse way back many years ago and it seemed very slow on my machine (arguably I had a pretty crappy old laptop) so I really had to find a less clunky way. I haven't looked back since. Plus, my screen is already small. I don't need an IDE to take most of the screen with unnecessary toolbars and other elements. I need room to breathe. A plain, full screen console just makes me happy. 
I have been doing that for a while, too. Pelican is really awesome! I just wish it would work with Python 3.
sublime text 2 for small stuff or quick edits. pycharm for projects. wingide is also decent.
First, you buy a private jet. Make sure it has wifi. Then enjoy a trip to [Cloud9](https://c9.io/).
PyCharm is the best IDE.
First you have to install setuptools. Python on windows doesn't come with it for some reason. Then you have to ensure you install the right version that matches your python installation. Or use the easysetup.py script from the command line. Either way, installing pip is a hassle compared to: apt-get install python-pip
When I first tried to run pygame (or kivy) on Mac OS X Mountain Lion I kept getting the error that pygame only runs with 32-bit python. To fix this error I just deleted my current installation of python and installed the version that is only 32-bit. It says its only for Mac 10.3 to 10.6 but mine seems to work fine.
Dreampie is good. So is idlex.
I'd really like to try Ninja -- but it does not support python 3 yet.... I really like PyScripter, but updates are infrequent and small issues like lack of code folding come up for me. 
You should look at sublime text 2 as an alternative to np++. I switched a few months ago and don't even install np++ anymore. There is the annoyance of it asking you to buy it now and then, but I can live with it just fine until I can afford to pay for the license. 
Eric for big projects, vim for single scripts. I tried PyCharm, ran it for a week or so with all of my day to day work. In the end, I just couldn't get over the way completion works. I want completion to work the same way as in the interactive interpreter and the bash shell. I sent feedback about it and they just didn't care. Said something like "being consistent with the interactive interpreter is not a goal." So I went back to Eric and I'm much happier. It has lots of overlapping features like realtime inspection, and even has some unique features. Plus, if something bothered me too much, I could just fix it myself.
I actually like ST2's project management, the file switching is fantastic, and with a few plug ins you get most features of an IDE. 
Did you get it running with 64-bit python?
[Wing IDE](http://www.wingware.com/). I use the free "Wingware 101" version which has pretty much everything I need. Although, come to think of it, I'll shortly be experimenting with a multi-threaded program (via Qt QThread) and will have to pony up for the Personal edition to get multithread debugging.
Is that javaism? From what I have experienced it's not needed to really have those auto completion and checkers because everything in python could change....
yeah .. that's another thing -- pyscripter is windows only. I messaged the Ninja peeps who said that they will be supporting python3 soon. I'll be happy as I use a PC at work, but a Mac at home - would love something I could get familiar with for both systems.
Im in the process of moving from e-text editor to sublime. Love the sublime plugins, though I never really got into the IDE thing so I can't say how close the experience comes.
Cult of Emacs M-x 'represent'! Personal favorite autocompletion packages? I'm always super hesitant to try new ones out without a referral first.
PyCharm is an ok product. It's bloated and awfully slow, unless your machine specs make up for it. That being said, the features you get for it's price makes it a decent choice for personal projects, where I would also recommend it. Among other things, I do Python for a living, so I am glad I can shell out the money for [Wing](http://wingware.com/), though.
Compiling PyPy (including the JIT) creates C, except when using one of the other backends. The JIT creates machine code without C being involved whatsoever.
I really like how simple this is. I recently purchased UberWriter, and I feel it'll be great to write blog posts with that and this. Now, I have to decide if I really want to move away from WordPress... plugins are nice (for things like syntax highlighting) as are comments. Also, I'm really loving the clean simplicity of the default theme. EDIT: According to the GitHub, it does support syntax highlighting. Also, I could always use something like discus for comments. Two of my biggest issues are essentially moot.
Upvote for you sir! And pyflakes for quick and dirty syntax / name errors.
I use rope for autocompletion on emacs and it works quite well for me.
Last time I tried Ymacs it implemented such a tiny subset of Emacs commands that knowing Emacs didn't even help me to be productive in Ymacs. Do you actually use Ymacs for writing code? If so, how would you say it compares to real Emacs these days?
I started using hyde just before Pelican was born. Looking at the evolution of both I should probably have waited, but anyway most of the thousand static site generators in Python are quite nice.
"And I think they still have plenty of more optimization opportunities for the future if we compare it to the Javascript V8 JIT for example." what makes you think pypy does less optimizations than V8?
It was quite a long time ago so I don't recall exactly. What I can still remember is that I uninstalled it within 15 minutes and as a software developer let me tell you that I'm quite forgiving when it comes to software. I think the user interface looked pretty bad. It wasn't a neat minimalistic design, it wasn't a nice polished one either, it was somewhere in the middle, an ugly, typical Tkinter looking GUI. They probably have improved bits and pieces since then so go ahead and try for yourself.
no the jit generates machine code in the jit backends trackgcroot is for the translation of pypy from rpython to c - the asmgcroot gc stackfinder needs metadata about the c stack layout of gcc trackgcroot has NOTHING to do with the jit itself, its a tool that adds metadata for the garbage collector *edit* to clarify ther are different kinds of backends * jit backends -&gt; just in time compilation targets * translator backends -&gt; for turning rpython into c/jvm/cli 
Problem I have with wing is that I do web dev, I need comprehensive HTML, JavaScript, css, sass/less support as well. If I was doing pure python (especial pygtk or similar) wing would be a serious contender.
GVim.
thousand? :D what are the best(s)? Pelican looks great, i might try one.
For me, all I need is autocomplete symbols that already exist in an opened document, not intellisense-like capabilities. Don't get me wrong, when I had to code .NET, intellisense was great and wonderful, but I haven't seen an IDE do it as well as WingIDE for Python and VS for .NET. Because of that, I use Sublime Text 2 for 99% of my coding now. One feature that I now can't live without is good multi-edit. Instead of highlighting a large section and doing a find-replace, I can highlight some text, hit Ctrl+D a few times, and just type the new text. It's so much faster and easier than find-replace, and easier to control. My problem with Eclipse (other than being huge, bulky, and slow) is that there is just too much of it. You start off having to install a handful of plugins, like SVN integration, one for python, etc, and suddenly you have more panes than you know what to do with. Sure, I could play with settings for hours to get it "just right", but I don't think that should be necessary.
I'm not sure, how can I check?
we use python along with ember.js and appengine to build [this product](http://batterii.com/2-1-cocreation-platform/)
What is the host OS?
We used it to build our CMS, [Tendenci](https://github.com/tendenci/tendenci). We also built a deployment site with it, migrate databases, convert CMS systems, and a lot more. We have a beta installation script for any developers interested. It's a quick and easy way to get Tendenci up and running. Let me know if you are interested!
After doing some reading on Python that was what I came to the conclusion of. But I was kinda confused as to why it is not readily adopted in businesses. For example, every where you look you see job ads for java developers but I honestly don't think I have ever seen an ad for python developer in the same way. 
I think it's somewhat of a circular situation, the same thing happens with .net and php. Lots of people do java, so it ends up getting used a lot of places, therefore more people keep learning java because that's where the jobs are. There's not so much python, so fewer people learn it, this means fewer people pushing to use it in an organization and it's harder to hire developers for, so it continues to not be used and people who are just trying to be immediately marketable continue to not learn it. Where I live there are many Django shops, small startups, larger startups, and large established companies. There are still 500 java or .net job postings (probably more like 50 with 10 different recruiters posting the same job) for every Python one though and probably 50 PHP for every Python posting you see.
All of our tools can be scripted with python. We also write custom tools to parse through 1.5 million apks to look for indicators of malicious behavior.
Where I work all of our user management automation code is written in python, as well as a ton of other scripts that automate various other systems. I also use it a lot as an all purpose problem solver. For example, yesterday I was given a list of users who should go into a particular group, some of which may already be in it. I wanted to quickly figure out who should be added. I copied the proposed list of members and the list of current members to two files, opened them in the python shell and quickly wrote some code to figure out the difference between the two lists. I probably could have done the same thing from bash, but I find Python so much easier to use for this sort of thing. 
While all our sites run on Django (Python), I find myself using Python everywhere. I've used Python to automate directory/file creation, file renaming, task execution... even a calculator and image batch processor. You can do all sorts of stuff with Python as you already know, im sure. Keep in mind the different methods in which you can use it (interactive, scripts, compiled...) whenever you run into a problem, take 5 minutes and see if/how this could be solved with Python. Keep a code diary. This is a great way to strengthen your skills.
I definitely didn't read anything about that. That's an even bigger draw, so I don't have to figure out how to get things like images working right away. If I went to a static blog, I feel like my website would be faster and use less resources, as well as being "DDoS-proof" (not that I get that much traffic). Are these all reasonable assumptions?
You can't build multithreaded applications :P But yeah, Python can do almost everything. Heck I use it to build my C# applications!
You can build multithreaded applications no problem whatsoever. It's just that if it's 100% Python and none of it is I/O bound, then you won't see a speed increase. Then there's always the multiprocessing module... My code is typically waiting for files, the database, network APIs etc and so it does help to do multithreading.
That is an interesting idea about creating a code diary. never heard of that before
You got it! I'll DM you details.
I haven't used it, I was just responding with some suggestions I've heard of. There's definitely a need for an editor with emacs bindings that's much easier to set up. That said, you're right, I never use emacs bindings in IDEs because they're never right enough not to get in the way when you want to do something beyond copy and paste.
Does Ninja support HTML or any other languages?
Yes. Although if you want to make it *really* appear to be dynamic, it can get "expensive" to generate the site, as well as take up a lot of space. For example if your previously dynamic site allowed for a lot of queries by the user (many sorting schemes, show pages that have a combination of tags, etc), and you try to mimic all of that in a static site, you'll get combinatorial explosion. But you'll probably realize you don't need it to appear *that* dynamic. 
I don't think I was doing any of that stuff anyway, but that's good to know if I were. Thanks!
It's embedded in Autodesk Maya. I write tools for a computer graphics pipeline. 
Web services (via bottle and web2py) Back end data processing Quick scripts to automate a task
so you considered well-known product like Informatica ? Did you compare performance ? That sounds like a fun project. As a long-time database/ETL developer and recent Python lover, I would kill to work on such project.
So I take it this is why you're in #go-nuts more often than not. ;)
PyCharm doesn't do that? I use the Python plugin for IntelliJ (Basically a port of all PyCharm's features, but more for people that program in many different languages) so maybe IntelliJ has some extra language features that regular PyCharm doesn't have, but in IntelliJ, I have support for HTML, Javascript and the like. It even provides support for Jinja2 templates, or Django templates, as well as both of those frameworks entirely. Did you look and see if there are plugins for PyCharm that enable that functionality?
or if you work at apple
- Back-end for web APIs using tornado and MongoDB. - Mobile apps. 
I use it for a bunch of random stuff at work. A large percentage of that stuff is just working around the shortcoming of excel (like merging multiple files/fields based on different rules. Yesterday, I build a pdf scraper which did some fuzzy matching to find related data in an excel file. One of the weirder things I've done is build a local interface for one of our (horribly designed) admin websites. The thing is damned awful to use, so a couple hours with wxPython/mechanize later and BAM we've got a cool user-friendly, and multithreaded way of browsing and downloading form our admin page. 
One of the major trading systems for banks has a python API that customers (banks) use to customize the system. It's a major reason why it is among the top 3 most used trading systems (at least in Europe). Other systems for example require the customers to compile extensions in C++ and are much less transparent and much more difficult to customize.
Same here. Python is also embedded or has an API for many other major computer graphics software. Nuke, Motionbuilder, Shotgun, Houdini... the list seems to grow daily. 
Have to write a lot of middleware for our own software with other vendors.
I am in web development, and I've been working in that field since 2000. I've also worked in protocol software development, library information systems, and I've worked a project or two in games software development. Here are a few of the things I've seen: * Python service-oriented architecture using CORBA as a service publication layer. The SOA was originally built on ILU in the middle 1990s and was moved to CORBA later. * Python + Zope, Python + CherryPy, Python + Django as web application server. * Python implementing interface layer for a custom geographical database. The database engine was implemented in C++, and we used Boost to provide a Python API. Python then was used to publish the DB into an SOA and to command-line tools. * Python for release engineering &amp; systems administration tooling * Python for spreadsheet creation/manipulations * Python for a variety GUI user tools (using Qt and wxWindows) * Python for in-game scripting and level building. The stuff I worked on was nothing special, but a few big commercial games have done this; Civilization is the one I remember for sure, but I know others have. In short, I've seen Python used for a lot of different things. Most of my experience is in web development, but Python is being used in lots of problem spaces.
I have written a custom SOAP class for the Salesforce API for data dumps and replication using PyCurl and LXML and main reason was performance and reliability( I needed to be able to dump 500000 lines of data, about 1GB of XML!) The pythonic HTTP and Salesforce libs lacked gzip compression and were much too slow for large datasets using SOAP
I use it for text processing, either analyzing text files or transforming them. Our software has what I would consider quite a bit of "legacy" technology under its covers: most of our data is recorded in flat files as long strings of digits. I'm in QA/support, and honestly I think I would have snapped, or, at the very least, have gone blind at this point if I didn't know how to automate this kind of work. I made a little GUI front-end that loads plugins for the tasks that come up again and again, and some of my colleagues make use of it. One of the programmers that works here is a big Python buff and made another utility that handles other, related tasks. 
that sounds more like an SQL job to me?
Massive overkill. In Python in might take about 3 minutes to get the answer. If you use vlookup in excel you could probably get the answer in 2.5 minutes.
Hi, i'm one of the developers, we've just added to read-the-docs some more documentation and an example that was avaliable but only in github's readme file. Thanks for the feedback, any other comments will be really appreciated!
Ah right. I only say this because I had a similar task of finding the unique email adresses from two seperate lists of 80K+ emails (I tried a vlookup but it crashed excel) which I just used a subquery for. I gave it a go in python but I got a bit lost and so just did it in SQL instead. If its not too much trouble, would you mind posting your code?
The data in question wasn't in an SQL database, it was in LDAP. 
ah ok just googled it and it sounds confusing - suffice to say I've never used one
The framework is intended to transform questions directly from an end user, people without any tecnical knowledge.
I use Python for, well, almost everything at work. It's the "connective tissue" of the predictive analytics project that's my main focus at work. The REST API for said project is implemented in Python (using Flask), as is the daemon that manages the heavy lifting that goes on in the background. Our configuration automation tool is written in Python. I build bots with it. I use it multiple times a day for one-off scripting. In a nuts-and-bolts sense of "how" I use Python... I use it from within a virtualenv with the assistance of virtualenvwrapper, and you should too! Use pip to install dependencies; forget about easy_install. Speaking of dependencies, there are many excellent Python libraries for building web apps, scientific computing (numpy/scipy), interacting with relational databases (SQLAlchemy), Redis (redis-py), Excel data (xlrd), RabbitMQ (pika), R (rpy), the list goes on.
The [product](http://www.lavastorm.com/products/lavastorm-analytics-platform) I work with, developed by our sister company, uses Python and Java internally, quite a bit of development work can be done in the framework in Python.
&gt; I've never found absolute_import all that useful, The point is that it prevents you from writing code that won't convert to Python 3.x. Under Python 2.x, if you're a module Bar in directory foo and you want to import a module Baz from that same directory, there are two equivalent ways to do it: import Baz import foo.Baz Only the second mechanism will work under 3.x. Turning on "absolute import" will give you an error for the first case under 2.7. The second version is intrinsically better, because you can move your code anywhere in your tree and it will still work exactly the same. My from \_\_future\_\_ line: from __future__ import absolute_import, division, print_function, unicode_literals
Using the relevant ones will make your code more likely to work in Python 3, yes. But if you copy&amp;paste code from examples, it might not behave exactly as you expect. The ones that apply to 2.7 are: * `division`: 1/2 == 0.5, rather than 1/2 == 0. Use 1//2 to force an integer result. * `print_function`: `print(foo)` instead of `print foo` * `absolute_imports`: `import bar` doesn't look in the same package you're in. Use `from mypkg import bar` or `from . import bar`. * `unicode_literals`: `"hello"` becomes a unicode string, rather than a bytes string.
Web apps using Pyramid-SqlAlchemy-Postgres in an Arch Linux environment
I'm a scientist and I use Python exclusively. We record electrical spikes from neurons, then use python to load signals from the data files. From there, I use scikits-learn to cluster spikes from different neurons. I wrote a catalog with SQLAlchemy to store metadata about the recorded neurons. This allows me to easily pull out neurons with specific properties and batch analyze them. Once I have neurons I want to look at, I store the data in pandas data frames and do the analysis with numpy, scipy, scikits-learn, and matplotlib. We're also developing an LED tracking system with OpenCV. 
Why would that burst my bubble?
You guys must really love neurons.
My projects : one reactive languages and 3d modeler. ( Both are a bit young but are real business project ) When I am a mercenary : website &amp; heavy client stuff.
Ha, I was a little heavy with that word, huh? To be fair, I think about them for 60+ hours a week.
Building web applications. I'm using Django, but trying out the Google App Engine too.
 Here you will find the useful links about the project. Documentation [1] Code [2] Pypi [3] [1] https://github.com/machinalis/quepy [2] http://quepy.readthedocs.org/ [3] http://pypi.python.org/pypi/quepy/ And a nice example of Quepy making queries to DBPEDIA [4] https://quepy.machinalis.com
Um, think you mis-read my post :) PyCharm does indeed have support by default for JavaScript, less etc. Wing however does not (different IDE).
Every sentence contained the word "neuron" except for the first and last.
I do various knowledge-management web-apps written in Python with CubicWeb (to which I also contribute) at Logilab. Colleagues do lots of crazy stuff here, from machine learning to interfacing with crummy old fortan codebases, through semantic web apps ...
I too would like to know what this code diary is ... Is it just a transaction log with notes, or something more involved?
You see, YouTube is using massive amounts of bandwidth to serve its content. That means that if YouTube is using Python there's no bandwidth left for anyone else to use it, ergo your workplace cannot possibly use Python, unless you work at Google in YouTube division.
Basically, yes. Some informal testing using Nikola (similar to Pelican in this respect) here: http://lateral.netmanagers.com.ar/weblog/posts/nikola-is-fast.html
At the ATLAS experiment at the large hadron collider we used Python as a scripting language to glue together modules to run complex computations (data filtering, simulation, track reconstruction, ...). At my current job I use scipy/numpy/matplotlib like many people use matlab, in fact this works so well I cant understand why anyone uses matlab anymore... 
You can build multiprocessing applications, though.
[I'll just leave this here](http://amoffat.github.com/sh/)
What you just said + some additional things from the top of my head: - avoid using long() - instead of traditional str() you should also use bytes(). When unicode_literals are enabled, the first one you use when string can contain characters outside of ASCII, and the other when characters need to be 0-255. For example components in a domain name. - when you want to check whether the type of variable is a string, most of the time you would want to check that it is a basestring (it encompasses both str and bytes) 
X-posted for hopefully a bit more discussion. The above piece concentrates on a technique to load classes dynamically at runtime. While not quite self-modifying as self-extending, I'm interested in using python's introspection capabilities to write dynamic code. The more worthy of skynet, the better. Leaving aside the design considerations that make this kind of thing A Bad Idea, have you any/do you know of any cool usage of dynamic code creation in Python? Also, is the above link an example of monkey patching or how would that technique normally look in python?
That is awesome news! Thank you!
I use it to write in Web apps on DJango platform
Our flagship product (Tecplot 360) also has a Python API.
womg that's so much better than subprocess.Popen. Thanks!
Just what version of python did you install. The version that said it was for 32 and 64 bit machines? Or just the one for 32 bit machines?
We build web apps using web2py. Pretty neat for web services that talk to our iOS/Android clients as well.
thanks didn't know about sets, TIL.
This actually looks really cool! :D
We use it for scripting and control in parts of our software radio telescope: https://en.wikipedia.org/wiki/LOFAR The majority of our code base is in C++ and Java, but Python is gaining ground for scripts needed throughout our application, and is also being used to control our post-observation processing pipelines. Python helps us to: * Manage a distributed fault-tolerant application running on our cluster -- C and C++ tend to bury the user in complexity * Put a powerful scripting engine around key C++ classes -- a Python layer around our data interfaces allows for sophisticated data inspection * Create various scripts to generate/process meta data and control files -- Perl is good for that, but Python is simply better known and thus easier to maintain Also, pretty much all expert scripts coming from our users (astronomers) are written in Python. In my experience, apart from MATLAB, Python is pretty much THE programming language for non-CS sciences. If we'd rewrite the whole software tree, a lot more Python would be used. Our processing has to be done in C++ and assembly for performance reasons, but Python would make a lot of our control programs a lot shorter and thus easier to understand and maintain. Python's flexibility can also be its weakness though. Duck typing can be a bit of a risk, because its flexibility also adds some uncertainty about the code behaviour. The same goes for flexible behaviour of functions and libraries that sometimes really would require the rigor of C++ for us. 
I've been running 8 since it released and haven't seen this new minesweeper. I'll have to investigate.
Primarily for web apps, but I use it for most small scripting/prototyping jobs too. At the moment only our Billing application is customer facing, but we will shortly be publishing a front-end to a Cloud hosting service (I work for a hosting company). It uses Flask, Celery and Redis. 
Also open source stuff like GIMP, Inkscape, scribus and blender... 
I think you're probably looking at the wrong businesses. Java has been very popular in enterprise for a long time, and so naturally there is an inertia where there be many developers required for some time. However, you're seeing more and more people being taught it, a lot more academic usage and a lot of adoption in business. This is especially true of start ups like ours... and oh look, we're hiring Python devs: http://www.reddit.com/r/london_forhire/comments/13vfxk/hiring_awardwinning_fintech_startup_is_hiring/. Hope nobody minds the blatant plug! 
Thank you. One more question. &gt; Of course, if you're doing a lot of output, you probably shouldn't be relying on print in the first place. What do you mean by this, and what I use instead? I do "output" a lot, but I do that by returning HTML to my WSGI server, not by print. Nevertheless, I am curious as to what you meant.
hmm, what would a maximum-compatibility python2 header look like? something like that? #!/usr/bin/env python2.7 # -*- coding: utf-8 -*- from __future__ import absolute_import, division, print_function, unicode_literals import sys if sys.version_info.major &lt; 3: #py3-builtins str = unicode chr = unichr #open with unicode as standard-encoding and py3s parameter set/order from io import open
Every sentence in your comment contained the word "neuron". Every sentence in this comment contains the word "neuron". I kid. But really, I'm doing my undergrad in physics at the moment, and I also use python a ton for data processing and for labs using mostly numpy and matplotlib.
I opened that page just a few seconds before you replied... Thanks, it all makes sense now!
And antigravity, although that isn't from \_\_future\_\_. But I am privy to the joke. ;)
This may work now, but it's not future-proof. We are moving in a direction of lots of cores with each individual core being relatively slow. Having code that works with lots of cores by default will be very important in getting performance improvements in the future.
Test Automation. Our test harness started out with just a few scattered scripts here and there written in various languages, but mostly in python. Over the past couple of years we have built up a decent framework to interact with *almost* all the the boxes that make up our testbeds, and is now about 90% python code. Because of the heterogeneous nature of our testing environments, python has been a pretty formidable tool for piecing together all of our scattered scripts into a single place. Additionally, we've recently started using Robot Framework for test execution, which has the ability to use python (or java) code as if it were a regular Robot keyword, so we've actually recycled a lot of our old code to be used with Robot. 
&gt; The filesystem won't be the same, the network won't be available Emacs doesn't assume very much about the filesystem. You could create a virtual filesystem of network shares or whatever. Networking is "easy" with websockets. I see what you're saying but none of these problems seem insurmountable; I think the problem with most existing attempts to make a web-based editor with Emacs or Vim-like functionality is that they try to make a new editor and then add some Emacs or Vim-like features. If you actually wrote an elisp engine in JS, you'd instantly get most of Emacs for free (and it would be *real* Emacs, not some cheap emulation). The original implementation of Ymacs was just a completely new editor that happened to share some keybindings with Emacs; however, the author seems interested in actually making a real Emacs for the web. I really hope he succeeds (and I intend to help).
I don't particularly use python at work (I mainly use Java), but I have so python scripts that are doing some things automatically for me. Those scripts are very targeted so it's hard to explain what they do, but they mainly interact with my file-system, or are used to extract data from the web.
However, that's a CPython implementation detail. Doesn't apply to other interpreters. 
Yeah, um. No. If you have even *one* CPU-bound thread that isn't in GIL-releasing C code, you are fucking toasted. And it's not just that you won't see a speed increase, you'll see a *slow down*. And multiprocessing is a cop-out and simply doesn't work for a lot of things.
I don't, it's banned at my work for some completely insane reason. So I just quietly use it on the side for quick processing and parsing jobs (while the rest of them start week long projects to achieve what I manage in an afternoon).
I prefer [envoy](https://github.com/kennethreitz/envoy).
[My wing](http://www.broadinstitute.org/scientific-community/science/programs/genome-sequencing-and-analysis/genome-sequencing-and-analysis-) of the Broad Institute is a python/java shop. The python parts: - biggish-data web applications: [Olive](http://olive.broadinstitute.org) - gene naming: [Genepidgin](http://genepidgin.readthedocs.org) - script automation and history: [Speedrack](http://speedrack.readthedocs.org) - several internal applications - primary command interface to our genome processing engine - widespread genome mangling logic - and of course, glue and assorted scripts
What kind of example are you seeking? [Here's the code](https://github.com/reddit/reddit/blob/master/r2/r2/lib/cloudsearch.py) that sends reddit data to our search provider.
I laughed. 
http://github.com/openstack/swift :)
I work at a little tiny semiconductor company. I use python to: * Examine and manipulate GDS (think chip blueprints) * Parse and modify spice/verilog netlists. * Build SRAM and logic blocks by tiling together standard cells (NANDs, NORs, etc). * Interface incompatible tools.
I pulled the call detail record data from our PBX for last year, and loaded it into a PostgreSQL database (using SQLAlchemy and the CVS module). Now that the data is in a database, I'm running simulations to determine the best/most economical ratio of PRI to Sip trunk for us. I also use custom Python scripts to generate monthly reports for the Finance department. The reports are MS Excel spreadsheets created with the xlwt module pulling data from a PostgreSQL database (using SQLAlchemy). **edit:** I added a bit more information about the finance reports. 
You can fly with python.
While it is not documented, bytes() is available in python2.7 and works the same way as str. 
We use Tornado to build [ontheplates.com](http://ontheplates.com) Everything uses/built using Python: * app server using Tornado * custom redis job workers * web scraper using [pyquery](http://pypi.python.org/pypi/pyquery) * db migrations, thanks to [Alembic](http://alembic.readthedocs.org/en/latest/) * image thumbnailer thanks to [Pillow](http://pypi.python.org/pypi/Pillow/) * all the sysadmin tools are 100% python as well: * fabric for deployment and configuration management * supervisord for daemon manager * monit for watching over supervisord, redis, nginx, etc. * libcloud for instrumenting cloud instances The wealth if production-ready libraries is what makes Python awesome.
I work for a small telco called ekit, part of the JT group. I write telco and support software (calling, SMS, data management, billing, website, credit card charging, and so on.) Our sysadmins and networks folk also use Python primarily for their work. I also write games in Python in my spare time.
This! I'm drawing a blank right now but I've run into a good handful of libs and such that just can't be grepped or googled. It's a huge, yet poorly-recognized, usability issue. Google for '"sh examples"' '"sh examples" python' to see what I mean.
I've been using Python (via Flask) to develop an ad-hoc reporting system. I found pandas the other day, though, and now I'm on a mission to replace SAS JMP with it. Stage one is building a library that allows very fast creation of control charts - I played with that for about an hour, and already have (very) simple i-charts. I licensed it under Apache 2, and have been developing it in my off hours and will be using/testing it at work. It's nice to be able to contribute back to the community, even if it's in a small way. [Here's my repo](http://github.com/lyndsysimon/pandas-control-charts/), though it is *far* from a well-architected project. It's basically still in the "hack something together to see if it can be done" stage :)
Or just consider Google for example. Google like most companies that invest in their infrastructure build a lot of shared internal "tooling" to automate common management tasks. Python is incredibly popular for that. Google uses both Python and Perl extensively for those sorts of tasks and they are far from unique in that. Perl used to be king of that space and Ruby is making headway but at the moment Python is everywhere.
have a look at commands too. output = commands.getoutput("cat somefile").split("\n") 
I created a test framework for an embedded Linux In-Vehicle Infotainment (IVI) system.
Mostly for small tasks that can be automated (stripping header data from text files). I picked python up on my own for this purpose and it has worked out great. I would like to integrate a user interface with some of my projects but am starting to think learning some php would be nice if it is to be a based. Haven't made it very far with any python UI's but that had been lack of experience and time. 
I got it. I'm an ArchLinux user that switched to OSX. I totally understand.
90+% of people don't. 
I worked in a huge company that mandated it. It wound up being a huge clusterfuck. There'd be legacy work people who'd been fired were working on that would be picked up by people who didn't like python. Those people would blame existing bugs on python and say it was unfixable to the point where they had to switch to whatever their preferred language was. It was also set up in very windows dependent ways, which to me somewhat throws away some of the biggest benefits of using python at all. And they never told anyone that they'd be using python until they actually pulled the code to take a look. Which I think went a long way to creating the situation where people were using it who didn't want to be and looking for ways to switch things over. Really that says more about office bureaucracy than the language itself though. 
I've used python since stumbling across it in grad school. There, I used it to handle IO and control for C++ simulation system. Now, I'm using it in a very similar way at work: to connect all the bits of a large C++ financial analytics system together. I'm also using numpy/pandas/pytables to handle some data analysis jobs. Probably my craziest python use was at my previous employer where I used it to parse a lisp-like (SEXP-based) model definition DSL, then generated the SAS code to estimate the model, a python implementation for testing and validation, and a Java implementation for the production system. Saved me a lot of validation headaches.
Python is becoming big for data analysis/modeling. There are great packages like pandas, numpy, scipy and IPython that make python a great tool for crunching data. Also, there are a lot of companies hiring for it. http://techblog.appnexus.com/2012/pydata-2012-rapid-iteration-with-python-scaling-appnexus/
Pipes aren't bash-specific. They're universal in every unix shell. Pipes and i/o redirection (and the "everything is a file" architecture which is really the same thing) are arguably the big innovation unix brought to the world . And yes, they're awesome. 
Hey, I'm thinking about applying at Change.org! Mind if I PM you about it?
I write both Python 2 and Python 3, and in new Python 2 code I always import everything I'm going to use from `__future__`. The only downside is if you're working with a large codebase that won't be ported to Python 3 anytime soon; importing things from `__future__` in that case is just asking to inadvertently break something.
Amen to this. Python is much better for desktop application development than people give it credit for. The biggest hurdle is deployment. We do instrumentation apps on Windows. For deployment, we have created our own "python runtime" which includes the main libraries we use (e.g. the GUI extensions). Making the runtime proved easier than expected: we basically bundled everything under C:\Python27 into an installer and placed it in our own location and set the PYTHONPATH as appropriate. Now, with the runtime installed, we can deploy our in-house code packaged as an egg.
I work at [Twilio](http://www.twilio.com). We build many of our internal services using Python, Flask, and SQLAlchemy.
How on earth a project that hasn't released anything but a FAQ makes news here?
Although I have never used it, from my understanding 2to3 will handle some of those transitions for you, e.g. `print_function` and `absolute_imports`. So I feel like there is no point in importing these for compatibility. Especially if you are working in a 2.7 environment together with other developers it will probably introduce confusion. The only import that I feel would really help making the transition is `unicode_literals`.
what automation framework you use?
Which version of Plone are you on? In my company, we're about to upgrade a number of sites from Plone 3 to 4. Since we have quite a few custom content types, I'm not sure how smooth the transition will be.
`the_file.write('stuff')` seems to be more idiomatic than say `print('stuff', file=the_file)` in most situations. And if you're doing a lot of IO, you should be writing to a file/socket/window and not to stdout. (probably, there's a time/place for just about anything). if writing to stdout is an option you might do something like: if filename == '-': the_file = sys.stdout else: the_file = open(filename, 'w') (sidenote I don't like calling file variables `file` since it's a builtin, though it doesn't matter that much because of python's scoping rules) `print` is generally used by console applications to inform the user of something with the print('error!', file=sys.stderr) form may be used in a similar way to report errors, but heaving lifting of lots of bytes around is better served by the read/write (with more control over buffering, unicode handling, and line-endings) It's all pretty subjective though, what's "a lot" of IO? at what point do the reasonable defaults of the print statement give way to needing more control?
As a former, long-time Perl user I use Python whenever I can anymore, at home and at work, currently for wrapper scripts and such (often cross-platform). Why the switch? I grew disenchanted with Perl's slow and haphazard adoption of new technology (e.g., Unicode) though it certainly had a good run for what I used it for. However, the deprecation of normal functionality in the "threads" module in Windows starting with 5.14 was when I finally had enough... I got tired of beating my head against the wall trying to debug the weirdness I was suddenly seeing when it turned out it was a new "feature". As far as I'm concerned I have no use left for Perl beyond 5.12 (and that's only for some legacy scripts I haven't bothered to migrate to Python yet). Sign me, -- Python Convert 
I'd do &lt; 3 instead of == 3 on the off chance you're still using the code when python v4 comes out, or possibly do == 2 since the code will not work w/ python 1. I'm also a fan of != instead of not ... =, but that's nit-picky.
One that apparently never gets old.
delicious but deprecated
Are you going to be using this http://pypi.python.org/pypi/pyramid_celery/ or the standalone python Celery client?
Probably pyramid_celery. To be honest, this is slightly unfamiliar ground for me, so I can't really answer well yet. We have barely started this project, and it'll be the first time using both Celery and RabbitMQ. Very excited to see how it works out, though.
true, cleaned it up. also used named tuple (`sys.version_info.major` instead of `sys.version_info[0]`)
Nice, we just got acquired by IBM after writing a data migration tool + web interface using python...
I prefer using them via sqlalchemy. If you like stored procedures, you may find this experiment fun: https://github.com/rdunklau/pytoplpython
In many projects of mine what I do is getting HTTP request values, putting them in the right order to call a postgres function using those values as arguments, getting the results (which are returned differently if you have inout parameters or a return statement) and returning them as json. Over and over again. I have written this little flask extension to avoid repeating myself. It is certainly not meant to be any kind of framework. :)
I'm a software developer for a company that does document management. We have some java based thick client applications, but all of our server based applications are written in Python, and we use Python for writing logic needed for document generation and manipulation.
As someone who has experience trying to hire Python developers, this is largely because Java developers are a lot easier to find. Python developers are relatively rare, so if you're a company making decisions about what language to use for your software, the availability and price of talent may push you towards Java.
I just use a psycopg2 cursor. Works great and I can explain it to a new programmer in five minutes.
1.0 is an integer of type float. You mean "More specifically"
&gt; it's just truncated to the nearest integer. Kinda pedantic: not to the nearest, but towards negative infinity. It turns out that there are two different ways of performing integer division of negative numbers: divide absolute values, compute signs as for multiplication (the C way) and assume the remainder to have the same sign as the divisor, compute the result from that (the sane way). Python mostly but not completely adopts the sane way: &gt;&gt;&gt; -1.0 // 2.0 -1.0 &gt;&gt;&gt; -1.0 / 2.0 -0.5 &gt;&gt;&gt; int(-1.0 / 2.0) 0 &gt;&gt;&gt; -1.0 % 2.0 1.0 &gt;&gt;&gt; import math; math.fmod(-1.0, 2.0) -1.0 As you can see, `int` truncates towards zero and math.fmod uses the underlying C function which uses C rules obviously.
I found the blog post, and it was written by you :-) http://lostinjit.blogspot.com/2011/07/how-fast-pypy-really-is.html 
14 months back I bought a Dell Latitude E6420 for AI (NLP, ML, some computer vision - I run an AI consultancy in London), running Ubuntu (Linux Mint 13). I took it to StartupChile for my computer vision startup (since dead &lt;sigh&gt;) and used it for teaching High Performance Python in March this year (San Jose, US) then Parallel Python at EuroSciPy a few months back. I bought a beefy laptop (4 cores with hyperthreading, 8GB RAM, 128GB SSD, NVIDIA CUDA 4200M) for the parallel/high performance teaching and my own number crunching. The downside is poor battery life, wobbly Linux support (it *still* isn't 100% at sleeping) and it is *heavy* (2.5KG). The monitor lid is now also rather wobbly. I use VirtualBox for client projects so the RAM and disk is important. Now I'm back in London, rebuilding my AI consultancy. I'm looking to buy a Macbook Air 13" or maybe a MBP (for 16GB RAM) so I can run VirtualBoxes and only carry 1.3KG each day, with Ubuntu installed as the primary OS (as a MacTel). I now use Amazon EC2 for number crunching so having a many-core+CUDA laptop for daily use feels like overkill. Definitely consider the weight if you're carrying it every day - &gt;2KG even in a nice bag is *heavy* on a commute each day, and a pain if it needs a bulky bag on a commute train.
We've built a hybrid system, using ruby for the extract, and cascading on emr for the transform phase. cascading gives us a good middle ground between performance and maintainability, and since it runs on hadoop/emr, scalability isn't an issue.
Ok, go.
I've been wondering about cascading. I don't think I'd want to run our processing on emr because that sounds very expensive. But do you mind if I ask a few questions? * what's the latency like? can you get a file processed within 60 seconds of it becoming available for transforming? * do all programs have to run within the jvm? * can you run programs like daemons, with zero direct coupling to upstream/downstream programs, just waiting for a file to arrive? * if you can't break up a workflow into separate daemons, then your error recovery can get a lot more complex. How would you handle a final step unable to push a file to another destination because the disk is temporarily full? 
Seems folly to split the application logic between the api layer and the DB layer. This looks like something that would be of greater value to a DBA that a programmer, I don't know a single programmer who ever said "If only I could make the logic live in the DB this would be so much easier!" IMHO stored procedures should be reserved for small bits of highly optimized DB logic that can't be easily expressed as a relational query or modeled in an ORM. The example of using a stored procedure for something as trivial as fetching a username from a database seems indicative of some sort of really bad schema decision.
I don't understand
In my opinion, that approach leads to N+1 queries, slow page loads, and data integrity problems.
We did something similar, and it almost worked, but in a company with 10s of thousands of employees and applications that are only of concern to maybe 200, we had to depend on each person running our Windows installer to get the basic Python 2.7 environment set up. Traction was good until a single developer inexplicably wrote a tool with a hard dependency on Python 2.5 (the tool embedded Python, it wasn't a Python application itself). People installed Python 2.5 on top of our 2.7 which caused things to break (mostly because the 2.5 install didn't include the 3rd party libraries). The senior guys started shouting "why aren't we writing tools in Perl which always just works?!" That was the end of it.
I don't know how much freedom Guido had at Google, nor do I know how much freedom he's negotiated at Dropbox, but I would think that, simply because of the breadth of Google's technologies, he would have been better able to evangelize Python to a wider audience at Google. I do think this is great for Dropbox and I can't wait to see what comes of it.
Seven years is a long time to work at the same place in this industry. It is nothing personal probably to Google, he may just be bored.
Is the actual client written in Python? I didn't know python could be widely distributed to platforms like Windows.
For [some value](http://stackoverflow.com/questions/1646326/how-to-deploy-python-to-windows-users) of "widely".
Ok, **that** is strange.
The original bittorrent client was hugely successful on Windows. 
Stored procedures are procedural code  think functions like Python functions  that run in the database. Generally they're written in a language call PL/SQL, but in Postgres you can also use other languages, including Python. It's possible to just call these functions with SELECT, but more often you bind them to triggers, so they get called automatically when you INSERT, UPDATE, SELECT, or DELETE on a table. With procedures like this, it's possible to, for example, examine the values in an UPDATE and reject it if you don't like them. Say there's a "one way" flag you want to enforce  a user can be banned, but never unbanned. You can examine all updates on the `users` table and reject any where the new value of `banned` is `FALSE` and the old value of `banned` is `TRUE`. 
I like their Linux client over their windows client. 
`import dropbox` 
There is also a future_builtins module in 2.7. I don't use it because 2to3 doesn't handle it well; it doesn't remove the import line like it does for `__future__`, so you have to wrap it in a test for Python version.
So? Why would you expect otherwise?
Why on Earth would you leave google for dropbox?
There exist options on the continuum other than "a huge help" and "won't be much help". If the company used Java for everything, he would be a large help, not a huge help.
Also, I'm guessing equity for a pre-IPO company worth &gt;$1B. That's a lot of money to throw at someone.
Would be nice to have a commandline, non-x86 client.
wow dang can't imagine anyone leaving Google for *that* but then I can imagine how different Google must have become over the years.....coughahemIBM
This sums up everything I can't stand about commercial ETL tools. At my last job, while the ETL team was fighting Informatica for months, two of us could write the whole thing in Python in about a day. Then because of "enterprise standards" we'd wait a few more months before they could finish the Informatica work to actually launch the project.
exactly.
NP. :)
In addition to the set comprehensions sceadu mentions below, you can also do set operations using operators, so .intersection is represented by &amp;, union by |, difference by - and symmetric difference by ^: So with set comprehensions and operators, the code above can be rewritten as: emails1 = {user['email'] for user in userscsv1} emails2 = {user['email'] for user in userscsv2} for email in emails1 ^ emails2: print email
I've heard he'd done quite a bit on Google Code (which was then mothballed) and AppEngine (which is losing the war with AWS/Heroku/etc), and I think he's helped with internal tools / coding practices, but this is all anecdotal.
I thought app engine was cool as shit, but there's no way I would ever recommend a platform to anyone that you would be vendor-locked to
Great explanation.
AppEngine losing to AWS/Heroku/etc? Care to provide some more info? I'm asking because my company is doing a lot with AE.. 
what input are you giving for n?
I use ninja and I also write bug fixes for ninja if i see it. It's quite neat... though there are many small bugs that doesn't matter much but still annoying..
Considering how heavily vested Dropbox is in Python, I assume he'll be spending most of his time working on the language. Dropbox runs a custom memory allocater in its client; maybe we'll see some of that goodness released to the world. 
Have a look at [cx_Freeze](http://cx-freeze.sourceforge.net/) - it can make frozen binaries for each of the main platforms.
plz elaborate?
He got to spend 50% of his time at Google on Python. This is much higher than the 20% Google engineers usually get so I assume he negotiated that though it could have been a carrot from Google. That was right when "Python 3000" (Python 3) was starting up in earnest. Now that Python 3 is at 3.3, Guido probably doesn't need nearly as much time as he did 7 years ago. Still, I'm sure he'd like some time for it, and since Dropbox relies on Python even more than Google does, they're probably happy to let him work on it.
Dynasty Warriors use to be my go-to game for just mindless killing.
Why?
Fast-forward a year and that free space from Google now costs everyone $50 per year.
Test harnesses, automated tests, websites, back-end to various services, internal developer tools, build system, data analysis..
Yeah, just like what they did with Gmail. Oh, wait.
It's good in that it replicates the Windows dropbox experience on Gnome, but better would be a library that KDE and XFCE can use, command-line clients can use, and you can integrate into your own projects. The Linux dropbox support is just an application that integrates with Gnome. That isn't very Linuxy.
Well, I don't know that he needed to evangelize Python at Google. The second version of their crawler was reportedly written in Python when Scott Hassan realized how bad Larry Page's Java code was. :)
Yeah, at this point Google is a huge corporation. Probably a nice corporation to work for, yes, but it's no startup.
Mostly for build scripts: we have a set of libraries that can build right across about a dozen platforms. Only python (and Scons) were flexible enough to work across the whole range from PS3 to Blackberry.
Interesting, hadn't heard of that before [This article](http://highscalability.com/blog/2011/3/14/6-lessons-from-dropbox-one-million-files-saved-every-15-minu.html) briefly mentions it. [This SO question](http://stackoverflow.com/questions/5494178/why-doesnt-memory-get-released-to-system-after-large-queries-or-series-of-quer) on the problem it solves links to [this talk](http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2011-how-dropbox-did-it-and-how-python-helped-4896698) given by the Dropbox people
Don't want to go too much off-topic here, but how popular is this kind of validation these days? It seems to me that most validation is done in the "application" these days, not the "database"  where the latter is treated as little more than a datastore (perhaps unfairly?). Edit: Oh, just saw the comment below this one about this very topic...
"... Java handling front end ..." is liable to lead to confusion. Brief clarification: GWT-based coding is in Java which compiles to JavaScript.
 from reality import humour # FIXME: This doesn't work if you're American!
Very much so. In fact, it is so annoying that flask-moresql returns the element itself in those cases.
As an aside (since everybody has voiced every thought i've got on this already), that's an awesome t-shirt.
Yeah, my code is littered with stuff like: results = cursor.fetchone() return results[0] Or even more annoying, when I do a select of just one column, but for many rows, I convert the list of lists into just lists of the first element like this: return [row[0] for row in cursor] I love how the DictCursor subclass returns each row as an object that allows index and key lookup. It should be possible to subclass the cursor so that it modifies the returned data so that cursor.fetchone() really does cursor.fetchone()[0], and cursor.fetchall() either does [row[0] for row in results] or maybe raises an exception when there's more than one element in the row. Anyhow, I didn't mean my initial comment to come off so rude. I should have said something like "maybe can you point out some before vs after code so we can see how this approach simplifies the code?" One last point -- how do you handle authorization issues, like "matt is allowed to get user data for all employees in group A only" using this framework?
&gt; Anyhow, I didn't mean my initial comment to come off so rude. No worries, if it does not look particularly useful then I either have to improve the documentation, the library, or both. :) &gt; "maybe can you point out some before vs after code so we can see how this approach simplifies the code?" I believe that the value in this approach is more in the simplification of the processing, rather than the code. Quoting [the PostgreSQL documentation](http://www.postgresql.org/docs/9.2/static/plpgsql-overview.html#PLPGSQL-ADVANTAGES): &gt; Your client application must send each query to the database server, wait for it to &gt; be processed, receive and process the results, do some computation, then send further queries to the server. Whereas by writing pl/pgsql code you keep the processing inside the database, which IMHO simplifies things quite a lot. &gt; how do you handle authorization issues, like "matt is allowed to get user data for &gt; all employees in group A only" I am not entirely sure I understand your question. Users are not allowed to issue any query they like to the database. You could have, for example, a pl/pgsql function returning the results of a join between the employees table and a permissions table. If matt invokes that function via the API, he will only get access to the data he is authorized to see. 
&gt; But if the request just looks like &gt; select * from get_user_data(user_id=98) To begin with, the function get_user_data(integer) does not exist. Only get_user_data(integer, integer). Also, the user cannot just send her user_id, for obvious reasons. For example, the user might have to pass her username/password, and the stored procedure will think of doing the relevant checks. Finally, you can use any kind of authentication/authorization system in your python app. Saying that databases should be used more does not mean that *everything* has to be done by the db.
I don't think you're comprehending how many files pass through the Dropbox servers. They need to handle **1 billion** file uploads per day, that's **11,547 files per SECOND**. You try telling me that even with a boatload of money, the average student can build the architecture to support that much throughput? That doesn't even include serving the files back, or the public folder architecture.
I know Guido worked on http://code.google.com/p/appengine-ndb-experiment/ and its predecessor db.
You don't realize how useless such a number alone is. It's impressive if you have a smartphone as a server, but shameful if you have 11,547 High Class-Servers. It also doe'snt say anything about the connection-time each file needs, or the processing-time every file draws. So, tell me, what is the workload each of Dropbox Server has? And how many of them have they? &gt; average student can build the architecture No. Of course that was slightly exaggerated. I don't know about dropbox serverside. I just know the public facts how the system works and I can scale up from that and my own experiences. But in fact i know their clientside very well. I have already build software in the same field, even some that used dropbox as a storagetarget. And i can say how unimpressive their work for me is and how slow their features progress. And im still wonder for what they waste so many people with that state. But of course, i can understand the situation of that firm, and that they can't bring several features for certain reasons. But that still does'nt change the fact that dropbox seems to be a little unimpressive workground were someone like Guide seems to be below his capabilities. But, the point is *it seems*. I'm sure Guido knows himself better than any other what he do and where he go. So it's just my own first impression of that news.
Ah... That makes sense. I could probably run Nautilus in KDE, but it isn't worth it just for dropbox integration.
Yeah, no love here. TO CANADA I MOVE.
Firstly, I'd have thought ActivePython pretty much makes this a non problem. The pypm package manager seems to do roughly the job you would expect from apt-get and it has pip already installed. If you are using Visual Studio for your Windows development and you have some objection to using ActivePython then the package distribution system built into Visual Studio now can help. Install the Visual Studio Chocolatey extension from the Extensions manager and use that to install python. See http://chocolatey.org/packages?q=python for which python packages are already available - pip is one of them. Using this - you can arrange for your visual studio project to have a dependency that uses nuget to fetch the packages required to a developers machine. I've seen this done for xUnit with the git-tfs project so thats one open-source example to look at.
So what? They have some work do to, really? Great. Would be disappointed if they just worked with generic software... Still does'nt change the fact that there service is just some middleclass content delivering and without any specific details it's useless to throw around numbers. All you're show off with 1 Billion files per day here, 11,547 files per SECOND there is really sweet. After all it just shows how less you know about that business and its scale. 
How dare they charge money for a premium service when there's a free service already available!
What did I just read?
[We build systems](http://roxarsoftware.com) for [modelling oil and gas reservoirs](http://www.youtube.com/watch?v=CK28b9v07wE&amp;feature=plcp) in Python and C++.
Really informative talk, and very good speaker. However, I do not like the fact that to map relations to objects without losing in performance you have to check your logs and see which queries the ORM came up with, understand why, and find out the syntax to instruct it to run the query you need. I find writing SQL much easier than writing stuff like this: &gt; movies = db.query(Movie).filter_by(year=1981).options(subqueryload(Movie.roles)) to avoid N queries to the DB when 1 would have been enough.
As a beginner trying to learn 3, I find it annoying that its freaking difficult to change my python version on mac. If you are going to keep two versions going at least make it easy for me to choose. Superior text needs me to learn a language of its own to sort that out and most progs default to v2. Online tutorials (codeacadamy) are still using v2 Pygame not updated to a v3 binary osx I can understand the history, and how two versions exist. But please make it easy for a n00b to work with and make it clear what version code is in!
TLDR: Python3 is awesome! Yay!
* PyCharm or Eclipse + PyDev can have multiple interpreters per one project and multiple configurations to run it. * print(sys.version) should do it for any online tutorial. Looking at the way Python works on Macs, it doesn't seem too difficult. Linux is probably easier, but Windows works just the same way. Also, you should maybe read a book instead of an online tutorial. Books usually go into more detail and explain how to set up your environment, too. I'd recommend Learning Python by M. Lutz or [Learn Python the Hard Way](http://learnpythonthehardway.org/) by Zed Shaw.
Do yourself a favor and use Python 3 unless you *have* to use Python 2. If you do have to use Python 2, use Python 2.7. Python 3 has been out for a good deal of time and the community is causing a slow transition. Jumping on the Python 2 bandwagon at this point will only hinder the transition even more.
Installing Python 3.3 on Ubuntu 12.10, won't update the symlinks from 3.2 to 3.3. So you have to explicitly state `python3.3`. It was rather annoying so I searched through my entire filesystem and fixed everything.
What changed in 3.3 to change your mind?
Take a look at [Komodo Edit from ActiveState](http://www.activestate.com/komodo-edit). It allows you to configure Python 2 &amp; 3 individually, it's free, cross platform, feature rich, etc. It's a good, solid editor.
python 3.3 seems like what python 3 should've been.
This is unrelated to the topic, sorry, but how are you making the inline code in your comment? I know how to do code but not how to insert it in my comment... 
The question is really like: Should I learn [C89](http://en.wikipedia.org/wiki/C89_\(C_version\)#C89) or [C99](http://en.wikipedia.org/wiki/C99)? The answer: use the newest unless you have to use the older. In any case, they are both python so they only have minor differences.
That wouldn't be system-wide.
You can control / command click symbols to go to their definition with PyCharm.
http://wiki.python.org/moin/Python2orPython3
Very simple decision. Find the highest python version that all the libraries you will use need, then choose that.
How wouldn't it be? If you create your own symlinks it should be. Everyone's PATH should include the same few basic dirs.
Aliases are not symlinks, they are shell niceties.
20 mins of messing about still cant get it to run python 3. Python 2 no problem as-per-usual. My point really is about as a newcomer. It doesn't really matter what you are trying to push, because it seems like simple shifting of multiple versions has not even been considered properly.
Windows is much easier. I can just point to where it is installed DONE. Tried to do that with wing and had to ragequit it was so difficult. I am using a book: invent with python.
And now, try to install Python 2.7, 3.2, 3.3, Pyglet and lxml for all of them.
Great post!
Ouch !
Bo, I guess this is too late but next time: 1) Please Increase font size. I'm surprised no one gave you feedback on this before you went and complete the videos 2) Configure your editor setting so when you HIGHLIGHT code the colors are not blended all together
Use backticks. E.g. Replacement for `readline` for Windows. becomes Replacement for `readline` for Windows.
Why both uppercase and lowercase r?
Huh. I could've sworn they were different flags. I guess I confused them with -I and -i.
Try the 1.2 alpha, or report a bug.
Why do all these discussions always revolve around web development. What if you are a scientific programmer and dont do any web page GUI related stuff at all?