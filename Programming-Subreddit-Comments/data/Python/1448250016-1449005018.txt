It has its ups and downs just like most jobs, but overall it's positive. This has been since we did a major reorganization of the team at the beginning of the year, we split into a new development team and a long term support team, so I got a new boss and a new job role instead of having to spend about half of my time supporting systems that had been deployed for months or years. Since then things have improved quite a bit, but I will say that we all have pretty high stress levels. Everything is always urgent, priorities shift daily, there's loads of red tape, and there's never enough time to do it the right way the first time. On the other hand, there's opportunities to travel, the pay is good for the area, and the job is steady.
I didn't say "safely", I said "sanely"
I'm ok with going through a background check, but I'm opposed to filling out the SF 86 form. 
It should be using greenlets and not actual threads. I'm *pretty* sure that you don't need to worry about `self.counter` getting corrupted. With actual threads I suppose this is a possible concern as the `self.counter += 1` compiles to four operations, first loading 1 and counter on the stack and then popping them off with `INPLACE_ADD` and storing the result. I'm not sure exactly how python schedules the threads. With gevent each greenlet runs until it hits a `gevent.sleep(0)` that yields back to the hub (or some monkey patched IO that does the same thing implicitly). So you won't switch to another greenlet in the middle of incrementing and storing the counter. 
does plotly fit your needs?
Can someone explain common professional use cases for base 64 encoding
There are two practical use cases that I am familiar with. One is when you want to embed an image directly in to an HTML file. This lets you create a single standalone HTML file that contains images. &lt;img src="data:image/png;base64,XXXXXXXXXXXXXXX==" /&gt; The other is when you have to package binary data as an ASCII string for whatever reason. The constraint may be with an API, data types, or something else.
I like snake_case and PascalCase, but camelCase really bothers me for some unknown reason. Especially when there are more than 2 words. snake_case is a tiny bit more tedious to write, but IMO much easier and cleaner to read.
Please let py_swbattlefront be a real module....
Thanks!. And yes, probably true about `textwrap` ... at least, for me, as I didn't even know it existed until I was stuck! As far as resources go, I read these in the following order (I think ...) * https://docs.python.org/2/distutils/setupscript.html * http://peterdowns.com/posts/first-time-with-pypi.html and then once I knew what a `setup.py` was and how to get onto `testpypi`, I looked at [pip's setup.py](https://github.com/pypa/pip/blob/develop/setup.py) to figure out the rest.
Storing certificates (pem), storing PGP encrypted files, embedding data in HTML and emails, etc. Basically everywhere where you have to mix human readable and binary data. 
That depends on what you want to do with it. If streamed processing (i.e. reading file incrementally and processing individual pieces of data as you get them) is possible, then size is not the matter. Otherwise, using memory mapping (mmap module) might be a solution.
These pages must be helpful for you. https://en.support.wordpress.com/code/posting-source-code/ https://en.support.wordpress.com/gist/
As /u/dmishin said, it depends on what you want to do with it and what type of file it is. If it is a text file with line breaks, you can read it line by line like this: with open("file.txt") as f: for line in f: process_line(line) It won't slurp the whole file into memory like read() or readlines() does. If for some reason you want to read the file in fixed sized chunks, then try this: with open("file.txt") as f: for chunk in iter(lambda: f.read(128), ""): process_chunk(chunk) You can make a generator out of it: def read_in_chunks(f, size=128): while True: chunk = f.read(size) if not chunk: break yield chunk And you can use it like so: with open("file.txt") as f: for chunk in read_in_chunks(f): process_chunk(chunk) This should cover most scenarios. Btw I wrote a blog post about this [here](https://www.smallsurething.com/how-to-read-a-file-properly-in-python/).
They don't technically require an engineering degree in the US except for certain ones like civil or structural engineering, and in those cases you usually have to get your PE license too. We have a bit more leeway since we aren't designing systems that could disastrously fail and kill lots of people. Most of what we do isn't taught in any University anyway. The fundamentals are there, networks, integral transform theory, statistics, but no University has courses at the undergrad level for what I do. Besides, beyond test engineering itself there's a need for people who do know how to write data processing tools, you don't have to be an engineer to do those bits. 
Great, this version let you build an optimized cpython, see [Profile Guided Optimization](https://hg.python.org/cpython/file/7749fc0a5ea6/README#l54)
O'Really
note that you are not guaranteed to receive 128 bytes every time you read the file even if there are 128 bytes to read
Commenting for followup
Just found out about Anaconda plugin. All I can say is wow. It is awesome! ST3 + vintage/VIM mode + Anaconda is just perfect for me.
[Someone remembers!](http://img3.wikia.nocookie.net/__cb20120724082954/meme/es/images/5/51/Snowy_Owl_Nyctea.jpg) .. I feel kinda old..
This is true indeed. In this case OP should wrap the output with some "canonicallization" procedure. The documentation also doesn't specify that the eigenvectors are returned with any particular normalization. I would divide by the return vector length to the eigenvectors an orthornormal set. Then I would multiply by the sign of of the largest element. 
It really depends on what you want to do with the file. If reading though the file sequentially works for you, do that. If you find yourself thinking about the optimal way to seek around the file a random access pattern or the optimal size/behaviour for a in-memory cache, then mmap can remove a lot of the complexity from your program and give you all the advantages of the operating system's optimised paging/buffering/preloading algorithms. All exposed to your program as the file mapped into a continuous address space. Your program doesn't really know how much memory the computer actually has free, but the operating system does, and can balance the number of pages currently in memory accordingly. Your program doesn't know the optimal read size for the disk, but the operating system (hopefully) does. Your program doesn't know if the large file is currently opened by other programs, but the operating system does, and it can keep only one copy of the file in memory shared between all of them. Maybe you know your read patterns better than the operating system, but unless your program is the only program running on the box, and knows exactly what hardware is in the box (think database server) it's hard to outperform the operating system at the paging game.
Utah Valley University. The program seems to be gaining traction in the real world it is more practical programming than programming theory. The only issue I have with it is that I have a Full time job an the actual programming for school take a lot of time. That being said i am not afraid of taking on big programming projects in the workplace. A lot of things just pail in comparison to having to implement a stack frame...
The pandas library has a read_json method and a to_csv method. Over the last year, the pandas library has nearly completely replaced one-off data format parsers for me. The sample code below runs if you have a file called april.json that contains the example code you posted. This just gets the keys and values as extracting the month would require a small amount of text parsing. april_df = pd.read_json('april.json') print( april_df.head() ) april_df = april_df[['keys', 'values']] print( april_df.head() ) april_df.to_csv('april.csv', index=False) ------ If you expect the 'keys' values to be shared among all the sites (maybe it represents time or something?), then you can parse out the month for each file and use the month as the name of the values column. Set keys as the data frame index and generate a list of 500 Pandas data frames. Use panda's merge ability (the default is to merge on index values) to join all the data frames into a single frame where the rows are indexed by key value and the columns are the corresponding values for each month. dl_list = # a list of data frames indexed by key, each containing a single column # named after the month and containing the values for the month result = pd.concat(dl_list, axis=1) 
The few, the proud, the Pythonic! 
They an be found on google quite easily.
I'm on break and bored, will read and report back: EDIT: Ok just finished most of it, I mostly skimmed the end. Overall I'd say it was a fun read if you are into little anecdotes about coding and debugging (like the famous 500 mile email story or the Wednesday database bug). But to be honest, I don't think it will stop the reader from making the same pythonic mistakes as the author. It's one thing to read a section about how python auto returns None at the end of functions, and how this has caused the author countless headaches, but it's another thing to actually make that mistake yourself a few times. I think it's the latter that would actually cause someone to code a little more carefully in the future. The best part by far was section 4 on code structure. I learned some new things about pythonic classes and how to maintain internal integrity with the use of decorators. It also had a fun discussion about how in the end, it is probably better to keep internal data "implied private" with the use of a single underscore rather that rely on double underscore name mangling to ensure privacy. You just have to trust the client of your code to not use the underscored variables as public. Definitely take a look at this book if you have some free time, but it's not a must read. Hope this was a helpful mini review!
You can store PGP encrypted files unarmoured fine. It's the default setting. Only reason why you might need to encode it is to transfer it over something that can't handle binary files. Email attachments can handle binary files fine.
Amazon has bought [Ivona](https://www.ivona.com/) so I think you're referring to Ivona Text to Speech. They offer an experimental API for it but it's not free.
You can bypass registration by going directly to the PDF file: http://www.oreilly.com/programming/free/files/how-to-make-mistakes-in-python.pdf Table of contents: 1\. Setup * Polluting the System Python * Using the Default REPL 2\. Silly Things * Forgetting to Return a Value * Misspellings * Mixing Up Def and Class 3\. Style * Hungarian Notation * PEP-8 Violations * Bad Naming * Inscrutable Lambdas * Incomprehensible Comprehensions 4\. Structure * Pathological If/Elif Blocks * Unnecessary Getters and Setters * Getting Wrapped Up in Decorators * Breaking the Law of Demeter * Overusing Private Attributes * God Objects and God Methods * Global State 5\. Surprises * Importing Everything * Overbroadly Silencing Exceptions * Reinventing the Wheel * Mutable Keyword Argument Defaults * Overeager Code * Poisoning Persistent State * Assuming Logging Is Unnecessary * Assuming Tests Are Unnecessary I gave it a very brief skim, the majority of the points are fairly simple and targeted towards new programmers. Sections 4 and 5 have some useful advice on program structure, but that kind of thing tends to be language agnostic.
Seriously...except I wrote that like 4 years ago and it's super "un pythonic." Lots of redundancy too. Message me if you want help on your compiler next semester.
It's a file with say, medical registers and I need to sort it. I saw in an interview question!
yeah, I would have posted this but I didn't feel like using the energy, lol. here is something that Linus Torvalds has actually said about the subject on some mailing list (taken from here: http://yarchive.net/comp/mmap.html) &gt;From: torvalds@transmeta.com (Linus Torvalds) &gt;Subject: Re: mmap/mlock performance versus read &gt;Date: 5 Apr 2000 13:18:19 -0700 &gt;Newsgroups: fa.linux.kernel &gt; &gt;In article &lt;200004042249.SAA06325@op.net&gt;, &gt;Paul Barton-Davis &lt;pbd@Op.Net&gt; wrote: &gt;&gt; &gt;&gt;I was very disheartened to find that on my system the mmap/mlock &gt;&gt;approach took *3 TIMES* as long as the read solution. It seemed to me &gt;&gt;that mmap/mlock should be at least as fast as read. Comments are &gt;&gt;invited. &gt; &gt;People love mmap() and other ways to play with the page tables to &gt;optimize away a copy operation, and sometimes it is worth it. &gt; &gt;HOWEVER, playing games with the virtual memory mapping is very expensive &gt;in itself. It has a number of quite real disadvantages that people tend &gt;to ignore because memory copying is seen as something very slow, and &gt;sometimes optimizing that copy away is seen as an obvious improvment. &gt; &gt;Downsides to mmap: &gt; - quite noticeable setup and teardown costs. And I mean _noticeable_. &gt; It's things like following the page tables to unmap everything &gt; cleanly. It's the book-keeping for maintaining a list of all the &gt; mappings. It's The TLB flush needed after unmapping stuff. &gt; - page faulting is expensive. That's how the mapping gets populated, &gt; and it's quite slow. &gt; &gt;Upsides of mmap: &gt; - if the data gets re-used over and over again (within a single map &gt; operation), or if you can avoid a lot of other logic by just mapping &gt; something in, mmap() is just the greatest thing since sliced bread. &gt; &gt; This may be a file that you go over many times (the binary image of &gt; an executable is the obvious case here - the code jumps all around &gt; the place), or a setup where it's just so convenient to map the whole &gt; thing in without regard of the actual usage patterns that mmap() just &gt; wins. You may have random access patterns, and use mmap() as a way &gt; of keeping track of what data you actually needed. &gt; &gt; - if the data is large, mmap() is a great way to let the system know &gt; what it can do with the data-set. The kernel can forget pages as &gt; memory pressure forces the system to page stuff out, and then just &gt; automatically re-fetch them again. &gt; &gt; And the automatic sharing is obviously a case of this.. &gt; &gt;But your test-suite (just copying the data once) is probably pessimal &gt;for mmap(). &gt; &gt; Linus 
Ah I mean, is it plaintext or something like netCDF or HDF5?
&gt; it makes sense because python uses underscore as a delimiter, which is conceptually similar to space. Yeah! That's right. I find this interesting. But [NrMorrell](https://www.reddit.com/r/Python/comments/3twiku/using_shiftspace_to_input_underscore_character/cxa1tpj) is no wrong either.
I'm working with DMRG code so normalization of the eigenvector isn't all that necessary. Not really sure what you meant by, &gt; I would divide by the return vector length to the eigenvectors an orthornormal set. It's a little more than annoying that the eigendecomposition does this as I don't know if there would be a capable correction/work-around since the discrepancy would occur on every cycle.
What is with lazy stack-overflow cross-posts? 
You can look into the map/reduce paradigm... I'd recommend reading each file in chunks sorting those chunks and then writing the sorted data into smaller files than apply a merge like reduce step to build up the output file (read in the kth record of each file and determine the smallest element and that element to the output and iterate that files counter). You may want to buffer some of each files data in memory to help performance, but it may not be an issue, if you keep all the files open during the final write phase. If you want I can put together a mock-up... EDIT: Strategy 2 The key that you want to sort by will probably fit into memory. so you can read each line extract the key. Do the a sort that returns the index (e.g. some_idx_sort(['d', 'e', 'a', 'b', 'c']) = [2, 3, 4, 0, 1]) and then based on that index do repeated scans of the source data to pre-sort chunks and write them to the output file. So for instance if you wanted to do 5 2GB(in mem) scans you would iterate through all records loading into a sorted array those elements in the appropriate qunitile of the index. It's kind of like "paging" through the data... EDIT: Startegy 3. Use a database. Index the database based on the sort criteria. Write a query that outputs the data in sorted order. if you run into memory overhead issues, then use a where clause to filter for specific ranges and then sort those ranges and write to an output file the appropriate chunks (similar to the map reduce suggestion). 
Use a sorting method where the data can be broken up into partitions -- like merge sort. Each partition gets sorted then the sorted partitions get merged together.
as far as return values go, if you are using an IDE or mypy or whatever, writing a full signature will work just as good, and will be useful information that will stop you from having to look at the documentation (as much) while coding from typing import * def get_recent_voters( self, start_date:Optional[datetime.datetime]=None, end_date:Optional[datetime.datetime]=None ) -&gt; List[Voter]: pass
You can't read a file into memory when it's larger than memory. You can only read part of it. Therefore I think you're asking the wrong question. You've since said that it's an interview question, and the point of reading the file is to sort it. This question is really, given that you can't read the whole file into memory, how do you sort it? Think of a deck of cards, where you're only able to look at a few cards from the top at any time. How would you go about sorting them (Assume that the suits have an order)? You might: * Take each card and depending on it's suit put in one of four piles, and then sort each pile separately. Once that's done you just put the piles in the right order. (This is based on a radix sort) * Take a few cards at a time, sort them and put them in a pile. Repeat this until all the cards are in separate sorted piles. Then look at first card in each pile, and take the lowest one, and put it in another pile. Repeat until you've gone through all the cards and you've got one output pile. (Sorting chunks of the file, and then using a merge sort) I'm sure there's other methods, but often thinking about these problems in terms you can visualise (piles of playing cards) makes it easier to reason about them. Cards map to medical records, and piles of cards are files.
&gt; it is probably better to keep internal data "implied private" with the use of a single underscore rather that rely on double underscore name mangling to ensure privacy. You just have to trust the client of your code to not use the underscored variables as public. Hah! Totally agree. As they say in the Python community, "We're all adults here." Thanks for the review. Section 4 sounds good. I feel like I've finally gotten to the point where I'm really fluent in Python, and looking to pick up on finer points like that. 
Great reference; The purpose of this project is to add more serializers down the line (Tree output, XML, Yaml etc...) another feature I'll be working on is to clone pre-existing folder structures and create a template out of them for later use.
Thanks. I'll give that a look. Thanks again.
12 years is quite a while for a meme.
This just feels so unnatural and complicated to me after using something made for REST like hug, which has built in support for marshmellow types BTW: https://github.com/timothycrosley/hug '''API endpoint for managing user accounts''' import hug from models import Users, UsersSchema schema = UsersSchema() lambda users_data users: schema.dump(users, many=True).data lambda user_data user: schema.dump(user).data @hug.get(transform=user_data) def user(user_id:Users.query.get_or_404): '''Returns in individual user based on id''' return user_id @hug.get(transform=users_data) def users(): '''Returns all registered users''' return Users.query.all() @hug.post('/users', transform=user_data) def save_user(user_data:schema.validate): '''Creates and returns a new user''' user = Users(user_data['email'], user_data['name'], user_data['is_active'], user_data['role']) user.add(user) return Users.query.get(user.id) @hug.patch('/user', transform=user_data) def update_user(user:Users.query.get_or_404, body): '''Updates a user with the supplied post data''' for key, value in body.items(): schema.validate({key:value}) setattr(user, key, value) user.update() @hug.delete('/user', transform=user_data) def delete_user(self, user:Users.query.get_or_404): '''Deletes an individual user referenced by id''' return user.delete() is how simply the API logic could be written using hug, even better if marshmellow was leveraged for the validation / conversion of incoming data
I use Engauge Digitizer. It's pretty awesome.
The pandas intro is helpful: http://pandas.pydata.org/pandas-docs/stable/10min.html Also see the pandas documentation for concat(), set_index() and drop_index() The assuming that each file represents a unique year/month pair, this is the sort of thing I imagine you would do with pandas. If year/month is not unique to the file, then you should pull out some more information to use as column names. "data_path" is the folder where the individual .json files live. It is assumed that the only .json files in the folder are ones you need to process. It would be a good idea to convert months to their mm numeric representation (April == "04"), so that you can sort the columns and end up with a chronological ordering. As it is, the columns will be in whatever order is returned by glob.glob() or some arbitrary ordering imposed by Pandas. import re import pandas as pd import os import glob data_path = '/Users/xxxx/Expire/*.json' data_files = glob.glob(data_path) df_list = [] for data_file in data_files: temp_df = pd.read_json(data_file) month = re.findall(r'Months\(([A-Za-z]+)\)', temp_df.understood_expression[0])[0] year = re.findall(r'From\(([0-9]+)\)', temp_df.understood_expression[0])[0] temp_df = temp_df[['keys','values']].rename(columns={'keys':'site', 'values':"{}_{}".format(year,month)}) df_list.append( temp_df.set_index('site') ) result_df = pd.concat(df_list, axis=1) #print(result_df.head()) result_df.reset_index(inplace=True) #print(result_df.head()) result_df.to_csv('/Users/xxxx/Expire/merged.csv', index=False) 
80-100 hours sounds like a decent time investment. Is that roughly how long it would take to develop a basic understanding of how to program? I realize people get their degrees in this stuff so a few weeks isn't that involved, but I'm just trying to get an idea. Also, have you used OKCupid in the past?
In addition to solutions provided: you can use numpy to load it as a memmapped array (if it's binary, as opposed to ascii where some processing needs to be done). Alternatively, you can load it incrementally into an HDF5 file or sqlite database, then use normal sorting options.
the book is 66 pages long. you are telling me that the potential of learning something new isn't worth the few moments it takes to download a free resource, skim the table of contents, and make a decision from there? how ever did you find the time to post on reddit?
I'll rephrase... I consider my time more valuable than money. I can't speak to the value of yours. 
If css supports base64 description of an image, then a base64 image in css is pure css. Also, you are coloring each pixel individually in your approach... and base64 encoding does exactly the same - the information is right there in the css, pixel by pixel. I see 0 conceptual difference. Unless of course our aim is to test bloat friendliness of CSS, and/or our capability for bloatware. In that case, see Bogosort - https://en.wikipedia.org/wiki/Bogosort
N How do you use Hug with Flask?
Great question - I've been dabbling in automating tedious office tasks for myself and some other people in my office. They program even less than I do - I'd rather have any program I make for them be as user-friendly as possible!
This is perfect! I'm very much in the same position, trying to create programs for coworkers. Great tips, I'll give it a shot and may try to get back to you to follow up on the results
You can try to use open-source festival http://festvox.org/festival/index.html. I haven't tried yet, but there are several ways to integrate it with your app: http://festvox.org/docs/manual-2.4.0/festival_28.html#API
do your own homework /r/learnpython
You use it instead of Flask, there's no reason to use Flask for something that it's not best designed for. You can use Hug for the backend API and Flask for the front end, they're both uwsgi and interoperable
Thank you, did not find that at first.
Cool. Thanks. Right now the demo seems to be hugged to death, will try tomorrow
Thank you.
Good.
I am implementing it but I am having a really hard time thinking on how to merge them together now, here is my solution -&gt; http://pastebin.com/SfMDp334 Now I have the list files with a pointer for each of the sorted temporary files. But what do I do now? I know I need to merge them together in one file..
&gt; looking at stack overflow Not to be flippant, but if you're a novice and your only "source of truth" is Stack Overflow, you could be doing yourself a disservice. While SO is wildly popular, it also exhibits a wild variance in content quality. You'd do well to spend some time looking through the content offered at python.org: https://www.python.org/about/gettingstarted/
This is not nearly enough information, show piece of code, or at least share with us which protocol you use to remote in, which library and version of python you use. want to get helpful answer? [learn to ask proper questions](http://www.catb.org/esr/faqs/smart-questions.html)
Im trying but the bot isnt there. When i connect it says the host is the host i posted in my earlier comment
http://lmgtfy.com/?q=every+word+in+the+english+language https://www.reddit.com/r/learnpython
I didn't even know this existed! I'll add it to the Todo list. Thanks.
Good point. I wrote a script to test this by reading a few GB file in chunks. Tried n values of 128, 256, 1024, 4096. read(n) always gave me back the number of bytes I asked for. If I needed a bulletproof script I would of course take the possibility of getting &lt;n bytes back into account, but if I was writing a throwaway script to get a job done I'm not sure I would bother.
I see so many toy examples online with minimal to no preprocessing. I especially like this post because it's a practical use case and shows all the boring data munging. 
Yes, resizing the modal fitting with the content shown. . Now the modal is big canvas even for a few lines of news. .
You land it via a recruiter? They'll often give you guidance on what to expect and/or what to study.
here is part of my code: import urllib.request ROUTER_MAIN_PAGE = 'http://192.168.2.9/' DHCP_PAGE = ROUTER_MAIN_PAGE + 'lan_dhcp.stm' def checkOnline(MAC: 'MAC-ADDRESS') -&gt; bool: response = urllib.request.urlopen(DHCP_PAGE) for items in response: strings = items.decode().strip() if strings.startswith('&lt;tr&gt;&lt;td&gt;'): if MAC in strings.upper(): return True else: return False 
I can skip the authorization only if I login to my router by using browser
The advantage of using Super is that it follows your inheritance tree. An example that I would encounter in my code (using PyQt). First I create some widget. class MyWidget(QWidget): def __init__(self, *args, **kwargs): QWidget.__init__(self, *args, **kwargs) pass Later I decide I want my widget to be a QPushButton, which is also a QWidget. class MyWidget(QPushButton): def __init__(self, *args, **kwargs): QWidget.__init__(self, *args, **kwargs) pass Ooops, QPushButton isn't initialized properly (by the underlying QWidget is). This bug would probably be a real pain to find, as it would probably still work as a widget. Using super from the outset would never allow it to happen.
Here you go.... Here's my version with copious comments I couldnt really follow some of your code and i think you may be misusing file.readlines (it limits the length of a line it doesnt set the number of lines). And you may have been a little too literal in my suggestion on using merge sort, but here's my solution in 120 lines with lots of comments... https://gist.github.com/mkowoods/7b3d819c7298dfb3faac
Thank you so much, will study what you've made. The heapq part is the part that I don't understand anything, I am not familiar with it :( Thanks again
One thing not mentioned here is that Pandas does chunks for very large files. for chunk in pd.read-csv("mcsv.csv", chunksize=numberoflinesIwant): #Do all my pandas stuff
How does Rodeo stand against Jupyter Notebooks?
What do you mean by change the key? you didn't link to any specific code that has music in it to be changed to another key, rather, you just linked to the website for the library which has all sorts of examples. Are you aware of what it means, musically, to change the key of an arrangement? If not then you should start there. By this I mean, if someone put some sheet music in front of you with a series of notes or chords and asked you to put the series into another key, do you know what needs to be done to make that transition? If you answer yes to the above, and have a basic understanding of how python works: iteration, function calls, etc then - It looks fairly straightforward with that library to create a sequence of notes ( like shown here: http://ccpd.cs.cofc.edu/index-page_id=799.html) and then play them. You can change the key of the output by physically adjusting the notes that are being played so as to change the tonal center of the sound arrangement. EDIT: example... An example: A very basic 12-bar blues in the key of G might go something like G G G G | C C G G | D C G G then repeat ad nauseam [obviously this is simplified, no 7ths, no fancy turnarounds, etc...] To swap the key, think about the chord progression: I-IV-V essentially. So to put that into C would be: C C C C | F F C C | G F C C So if you understand the structure of the sequence of notes you want to transform, it should be simple in the code to shift the root tonality to a new key. You could make some type of cyclic data structure (linked list?) to represent the chromatic scale. Then it would be pretty easy to map notes form one key to another - so long as you understand what's going on musically
Sweet, just finished writing my own class to do the exact same thing (probably not as well) about a week ago. This will be nice for revenue high low tables.
Hello, I'm new at python. This is a very helpful picture. Thank you. After know everything in the picture, would I classify as a intermediate python programmer?
This is the one I use, http://www.filedropper.com/dictionarydump It's ~1 MB with 114465 entries.
Hopefully this will save my ass from being bitten by the code I write for the next week or so 
I'm curious about this since I am about to embark on the journey (again) to build a web app using Django. It'll actually be a basic web portal for a company that will have basic database CRUD operations and some dashboard like reports farther down the road. I had part of this project written before in Django and did feel at times that Django was just complicated in a lot of regards when it came to my models. I remember cussing up a storm trying to work with one-to-many, many-to-one relationships. Flask didn't seem too bad, and I'm also reconsidering Laravel. Would you be willing to provide some further insight? Thanks. 
You would be classified as a simplest beginner who knows the absolute basics of Python.
Check scrapy if you need to rewrite the scraping logic. To help yourselves understand how the current project works try running it with a more verbose logging level if available (look for logging usages on the code). The packages you list make me think that your current solution seems to be really in-house and based on mechanize, and doesn't seem to use a lot of other useful tools for the job 
So, I wouldn't have been quite so blunt as the person you are responding to, but that image is very incomplete for the python language, for example the github page where its from shows that its only about 1/10th of the size of the planned image: https://github.com/coodict/python3-in-one-pic All this said, I think "intermediate", "beginner", and "expert" in a *particular language* is actually not that meaningful, compared with general programming knowledge. Learning new languages is easy, learning deeper programming concepts (ADT, algorithms, complexity, real-world software dev practices, etc) takes a lot of time and exposure.
...just in case you haven't seen this: [super considered super](https://www.youtube.com/watch?v=EiOglTERPEo)
I said why in my post. It is more performant with cpython and works at all with pypy. I don't think opencv should drop it's other bindings in favor of cffi, just offer the option of using cffi if you have it installed.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Web Development is an option for me. I learned css and html before. Struggled with bootstrap, couldn't really grasp it. I started JS, but was interrupted by life. In high school they thought VB6 which was OK. Nobody seems to use it anywhere. So I started python by myself and now get thought it in University. Next year they teach c++ which im looking forward to. I would love to work for Facebook or Google in the Cloud site of things, but also interested game development and AI. I feel like I'm still early to fully decide but it will be one of those 3 up there. For my little game now I could incorporate a GUI that's on a website. I could learn a lot from that... I'm still indecisive.
Windows 10 &amp; python 2.7.10 here. Despite installing Anaconda and manually installing jupyter_client &amp; IPython, Rodeo still "can't start :(". Checked my path, all good there. Is there any hope for me?
The entire English language in regex .*
Why is the st = {} in the 'set' section? It clearly shows print(type(st)) &lt;class dict&gt;, so why is it in the wrong section?
Shitty shit post is shitty.
For me, this is offset by the fact that IPython takes several times longer than Python to start up, to the point that if I just want to check one thing, I could be done with it in Python before I would've had the chance to begin in IPython. That said, if you're a novice, the great informative features of IPython should definitely outweigh speed concerns.
Sorry about that...I'll try to complete it whenever I get a chance...
problem being that I don't know how to have python passively 'watching' for input that would allow me to make some condition true.
I'm not sure a big list of errors helps anybody improve by any interesting degree, for the same reason an essay returned full of red marks is unhelpful for those who want substantive and general improvement. The reason I think so is because I think that the common factor to a body of errors is often non-local, owing to a more general cause rather than an assemblage of tiny little causes making for tiny little errors. An incoherent jumble of quality advice is not good enough.
Try looking for keyboard polling routines.
Not to mention exceptions (`try` `except` `raise`) and the `else`-after-loops-if-not-broken thing
If you want to figure out their code I'd start by reading the [mechanize](http://wwwsearch.sourceforge.net/mechanize/) documentation as that appears to be the main scraping library they're using.
Thanks for the reply, I just finished coding mary had a little liam ( I know basic) but the tempo seems off
If you want to start over: If the sites you're scraping require JavaScript, use [selenium](http://www.seleniumhq.org/). If they don't require JavaScript but the job is complex, use [scrapy](http://scrapy.org/). If they don't require JavaScript and the job is simpler, use [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/).
If you want to keep it as a simple single threaded If you want to keep it as a simple single-threaded script, then you will need to read for input on every iteration. Otherwise, how else are you going to know when the user wants you to stop? What you should look into a way to read stdin/input in a non-blocking way. I believe by default, reading input will block, meaning that the script will wait forever until the user enters something (and the rest of your code won't execute until then). Non-blocking calls will read data if it's available, and otherwise continue through your loop. After a quick search, it looks somewhat complicated in the specific case of stdin/console input. [Here's a link I found with some options.](https://repolinux.wordpress.com/2012/10/09/non-blocking-read-from-stdin-in-python/) One alternative that would be really easy to use is the [KeyboardInterrupt exception class](http://effbot.org/zone/stupid-exceptions-keyboardinterrupt.htm). That's a specialized exception that is thrown when the user presses Ctrl + C. If you catch it, you can break out of your while loop and do anything else you want to do to gracefully stop your script. The only problem is that you don't get to decide the stop condition - it has to be Ctrl + C. An example of this you can test out: start_time = datetime.now() finished = False while not finished: try: # read data from serial port # do something with data elapsed_time = datetime.now() - start_time if elapsed_time.total_seconds() &gt; 604800: # number of seconds in a week, for example finished = True # sleep, if desired catch KeyboardInterrupt: finished = True # do work to finish processing 
The NIH is strong with this one.
What about unique constraints set on columns like username, how will I let the user know?
Check [this](http://stackoverflow.com/questions/29858100/program-that-either-waits-for-user-input-or-runs-at-defined-intervals) out. You could easily modify the top answer to exactly what you want to do. edit: notice that when you have i = raw_input() # (or input() in python3) defined the program is waiting for user input before proceeding.
Not quite, but no worries. Here's a link to learn Python in 10 years: http://norvig.com/21-days.html 
But ipython has tab completion, which makes up for any startup time difference.
Maybe this is something that could interact with MDTraj in the future
 &gt;The entire English language in regex .* Plus everything else that's not in he English language
Try 15 seconds (cold start). Warm start is 3 seconds. I'm usually just writing 1-3 lines. EDIT: For comparison, warm start Python takes about 0.14 seconds. So, 14x to 21x faster than IPython.
Wow. What are you running IPython on that it takes 15 seconds to start? That seems incredibly excessive even for a very low power unit. 
* Core 2 Duo, E4500, 2.2Ghz * 4GB ram -- ddr2? * IIRC an ex-server-box. Definitely not low power. * btrfs * Arch Linux x86_64 The (cold) start time for IPython is actually longer than GIMP -- which has to do a heck of a lot more stuff AFAICS. So it might be some specific thing that IPython is doing that causes the slowness. You probably shouldn't go by cold start times though, since you will only cold-start a program roughly once per boot cycle, unless you run out of memory.
Aaah understood. What I was doing was I looked at some tutorials on some websites and youtube and then tried doing it, it didn't work. Then looked at SO for similar problems that people might have faced. 
This is down to personal opinion of course, but I've heard from several sources that a person requires 10'000 hours of practice to become an expert at something. If we accept this as a fact and put the label "expert" at 10'000 hours, we can place "beginner" or "newbie" at 0 or thereabouts, and "intermediate" and "senior" at the 1/3 and 2/3 marks, respectively. According to this line of reasoning then, after 3333 hours of python coding practice, you're an intermediate python programmer. I think most people on the lower half of this scale will judge themselves further along than they are because of the [Dunning-Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect), while some will judge their skill too low because of the [Impostor Syndrome](https://en.wikipedia.org/wiki/Impostor_syndrome). But really, what does it matter? You're doing this for fun, right? So make sure you have fun! You'll be an expert before you know it. ;-) 
awesome, thank you. i was hoping to avoid the Ctrl-C but it looks as if doing it any other way gets needlessly complicated.
Thanks. I'm currently at work and importing pandas is not working on this windows system. Will try it on Ubuntu once i get home. Thanks a lot!
I use [Kivy.](http://kivy.org/#home) Documentation is scant and the setup process is... Interesting... at best, but you don't have much choice if you have your heart set on writing the app in Python. Once you get Kivy working, by the way, it's *fantastic.* -edit- Oh and you'll need Buildozer, too.
I did this a while ago, but I think there are a small handful of Kivy tutorials on youtube. As for Buildozer, that's the Python package you need to deploy your app to Android. I'm on mac, and that thing took a whole weekend of work before it would function properly. There isn't really a whole lot of information about this process, probably because the general opinion is that it's a bit of a rubbish idea. It *does* work, but expect to be doing a whole lot of troubleshooting.
Hm, I think we can skip all the "get_chain" etc. stuff since that's where the pandas syntax comes into play. But I think like structural alignments via least-squares fit, dihedral calculation, q score, etc. would be simple yet useful additions.
/r/learnpython
You should just fix this upstream instead of hacks like this.
You guys are talking about two different things. The ipython notebook and the ipython repl
Could you add some screenshots/examples for the output to your README, difficult to understand exactly what it does without that. Thanks!
Who's talking about ipynb? I thought we were both talking about repl; the thread is about REPL, isn't it?
Assuming you're talking about lists of values you can use the `pairwise` recipe from `itertools`: import itertools def pairwise(iterable): "s -&gt; (s0,s1), (s1,s2), (s2, s3), ..." a, b = itertools.tee(iterable) next(b, None) return itertools.izip(a, b) f = range(1000) print [c - p for p, c in pairwise(f)] or, if you want to skip itertools and do the grouping manually: df = [c - p for c, p in zip(f[1:], f[:-1])]
I know java's better. I'm doing this as part of an assignment for college. Also I'm already too familiar with python to just change language.
I'm assuming this going into your setup.py. Does this get backported to 2.7 by chance, or is it just going to be a part of some setuptools upgrade?
Our solution is using BeautifulSoup if that helps with your response. Does that mean anything more to you? Is that good/bad/indifferent? 
I will read up on mechanize. Thanks.
So you're suggesting doing something like: 1/sqrt(x^2 + y^2 + z^2 ) * (x y z) where (x y z) represents the eigenvector and then continuing on to multiply by the sign of the largest element. Apologies for the formatting.
&gt; Not incompatible. The extra characters added into your code are ignored by older versions of Python 3. Forgetting the fact that the entire typing module doesn't exist (edit: pre-3.5, I shouldn't comment when tired), means that you can be bit on the butt with using this
It means they are most likely just scraping elements from the HTML. This is good for you since it's the lowest complexity. Beautifulsoup is pretty friendly to pick up. You're probably going to need to learn what http lib they used as well, hopefully it's requests if you're lucky. Here's an [example](http://zevross.com/blog/2014/05/16/using-the-python-library-beautifulsoup-to-extract-data-from-a-webpage-applied-to-world-cup-rankings/) of a small project using BS4.
There is a [backport package](https://pypi.python.org/pypi/typing) that supports running back to 2.7. And setuptools can be configured to install it only when it is needed ([description](http://stackoverflow.com/a/32643122/210526)).
Mdtraj seems to be very cool! Now my heart is torn between mdanalysis and now mdtraj ...
So I have a unique validator that is implemented like this: Unique(MyModel, 'my_field') This does a good job of validating post requests but fails on puts. In order to get around this I do some interesting field marshaling. If the request object contains the same value thats stored in the model I don't pass the field. The value stays the same (as it should) and validation occurs for all the other fields. if request.b == model.b: fields = ['a', 'c'] else: fields = ['a', 'b', 'c'] result, errors = schema(only=fields).load(request) Admittedly, this isn't the cleanest way of handling the situation but it saves me from having to validate once in the schema and once again in the controller. I'm looking into better ways of handling this but, for now, this is what I have.
Did you file a bug report at least?
5 minutes of googling turned up this https://github.com/plotly/plotly.py/issues/353
Awesome, someone already filed this bug report. But in the interim, that doesn't make what I've posted any less relevant if anyone wants to leverage plotly now.
Question: will this be able to build a "wheel with dependencies" so I can take it to a host without any Internet access and just install every dependency (regular and transient) that my app needs?
&gt; this is not not not changing Python into Java Heh, python is more strongly typed than java at runtime due to Java's type erasure. You could actually get more thorough type safety than java with less type annotation (provided you write a module and the type markers to try and do a complete static type inference and report where it failed to do so) The only problem would be boundaries where types are directly provided by external sources such as serialized structures. You'd have to annotate accepted type hierarchies and endure a performance penalty for type checking during deserialization (I.e. runtime)
Take a look at [Django Mobile](https://pypi.python.org/pypi/django-mobile).
Following the recent rewrite of Kivy's python-for-android tools, it should be quite easy to create a webview-based bootstrap that would make it easy to have flask (or django, bottle etc) based apps. It's on my list of things to try. I'm not sure if cordova could do this, since the tricky part is compiling and including the python interpreter. On the other hand, if cordova supplies any important functionality, probably you could combine them somehow. You should also be able to use e.g. Kivy's normal pyjnius method to access java apis.
Wow, thanks for the response! Is there any documentation to create a web view-based bootstrap for flask based apps? I'm really open to learn and try anything at this point to streamline a cross-platform development workflow.
The link to the Python scripts is actually here: https://github.com/NARKOZ/hacker-scripts/tree/master/python https://github.com/NARKOZ/hacker-scripts/tree/master/python3
Whoop, found it. Answer: Raymond Hettinger. https://hg.python.org/cpython/file/tip/Lib/pdb.py Edit: no wait, that's who last edited it. Oh well good enough 
Sounds like fun, let's do this.
If you actually want to find more, you can start [here](https://www.python.org/about/success/). This is the top Google result for "python commercial applications". Python is one of the most popular programming language that ever existed, second only to Java. It should not surprise you to learn that there are actual products that use it.
I’m curious if their team has considered implementing a way to rip all of the annotations from a file and put them into a .pyi stub in one easy command. It doesn’t seem like it would be too difficult to implement, and would be valuable when inevitable complaints about verbosity come.
Use android studio, it's the official standard and if you want a job writing android in the future you'll probably be using it.
Flask-blogging has the same capabilities as flask-blog. The main advantage of this project is it makes it easier to integrate into an existing flask based Web app. While flask-blog is more of a standalone blog engine. I have seen users use flask-blogging in other projects as well as a standalone blogging engine.
I am surprised an IDE vendor got this wrong. They, and prog lang geeks, of all people, should be the ones most likely to get it right.
I knew that function annotations (which type hinting uses) existed before 3.5, but [PEP 3107](https://www.python.org/dev/peps/pep-3107/) says it started in 3.0, so I guess you have to update. I'm guessing the typing module supports 2.7 because there wasn't anything in it that required 3.x features.
I usually prefer simple solutions, but if you're unfamiliar with some of the other methods, and aren't under a huge time crunch, it's probably worth implementing them to help learn.
thank you!
I've opened this up and it's a wall of words, no separation between them! is there any way to fix this? are there line breaks that notepad isn't observing?
I'd really like them to fix the issue where you specify a requirement (e.g. `numpy &gt;= 1.8` and because `numpy 1.10` exists, setuptools decides you need to upgrade. It wouldn't be so bad if packages always installed properly, but they don't.
Hi, at the time I prefered Nikolas over Pelican because it had more features (Pelican catched up). https://getnikola.com/ It has groups and tags, it does provide a special category page to view posts of that category (and offer a RSS for that category), the syntax highlighting is painless. But I find jekyll faster on development server reloads. You can see a full list of static sites, filtered by languages and github stars here: https://www.staticgen.com/
I don't have much experience using jekyll, but I went with pelican since I didn't have to spend 5 min installing ruby. Pelican has both, support for groups and tags using markdown on your articles as well as provide special uri for seeing posts from a specific category. Syntax highlighting is not that bad, you just have to install the appropriate plug-ins which can be a pain configuring but once you do it'll be easy to use via the markdown shortcuts in your posts. 
Can you explain the difference between those?
That looks cool. I wonder: - is that page on readthedocs done with ablog ? - can we show permanent pages on the side bar ? - how would you create a site for documentation with many languages and versioning ? thanks !
Did you just come to this 3 week old thread to fuck with me? * I didn't say desktop application. You are misquoting me. * Even if you want this to be about "desktop applications", desktop application does not mean GUI application. Of those 41 applications on that page, I'd estimate 41 of them can be run on a desktop. * Even if you need "desktop application" to mean GUI application, quite a few of the programs listed on that page are GUI applications. Not just one. * I'm sure 41 of the 41 applications on that page are exactly what I originally said they were. Commercial applications. * This is not by any means an exhaustive list. This is just the first result of the Google search I mentioned above. I think I already mentioned this. * If you doubt the fact that Python is the #2 language, feel free to do any research at all. Every credible result you'll find is that Java is #1 and Python is #2.
Finally! Now I can start losing my money even quicker.
Thanks :D
It's more like a docstring. Type-hinting by itself doesn't do much. It's used to tell other tools (like linters, or IDEs like PyCharm) your intent. It lets PyCharm do things like alert you when using invalid methods or operators, and autocomplete attributes (type '.' and you'll get a list of all the attributes and methods for an object). PyCharm can already figure out a lot of things, but type hints let you give it more information (like specifying that a function wants a list of ints, and not any other kind of list). 
Got it... I guess you were looking for alternative ways to paint a picture (rather than purity of css). I agree... it sounds fun.
Explain your fucking buzzwords. I have no idea what these things are, why I should care, and what relevance they have to /r/python
Pandas does not intend to use more than one core at a time on its own. If you can reproduce this behavior, please file it as a bug report.
Does 1.08 work, maybe?
pdb most definitely qualifies as a debugger, regardless of your favorite debugger that is not pdb.
This actually is possible using python - for instance, from Kivy (or other things built with its python-for-android) there is an SDL backend function to get such a pointer. You need some C or cython code to access it and pass it around, but it's very possible and for instance is how pyjnius works to access android apis (see [here](https://github.com/kivy/pyjnius/blob/master/jnius/jnius_jvm_android.pxi) for the specific code). Of course that may or may not be suitable depending on what you wanted to do, but I think it's interesting that it's possible.
For the small project I'm working on currently I've decided to use heavily the path handling functionality of the pathlib module which is in the stdlib (and hinted at the beginning of the docs for the os.path module) https://docs.python.org/3.4/library/pathlib.html It wraps the paths in a Path object which has many useful attributes to get parts of the path (parent directories, basename, filename, extension...) I recommend considering it if sticking to the stdlib. Otherwise there are also other non stdlib path helper modules, however I can't say much about them since I've never tried them. 
That's a longstanding bug/feature request with pip. There's no reason that you should be forced to upgrade dependencies just because you upgrade a package, but pip does it anyway.
That is exactly what I need.
Eh, if you're just doing data analysis, then IPython is probably the right choice. If you ever want to do serious coding, then look into PyCharm. It really IS quite nice. :)
I like your flair. I just changed mine to the same. :)
Ah, you're right. I was thinking it was added to 2.7 because the PEP was way back in 2006 but it wasn't.
It is also likely they (Robinhood) are being paid by HFT firms to execute their order. The HFT firms like the order flow so that "jump the queue" (or lower their own transaction costs). Jumping the queue example: Someone wants to buy say BAC at the offer, they would execute against the person who was at that price first on that exchange. An HFT that executes that order will happily take the other side of the order (w/o needing to wait in queue on a public exchange) and wait for another retail order that wants to sell -- classic market making. They get first look at the order, and fwd it to the exchange only when they do not want to take the other side. Lowering the transaction cost case is when they execute against a resting limit order, and they can avoid sweeping the public exchanges at worse prices. The reason I don't buy the "we make money from interest" is because they'd need to have nearly a billion dollars uninvested at current interest rates to make a couple of million dollars a year. Whereas, HFT firms can pay up to 0.0050 ($0.50 for 100 shares) per share, depending on the "toxicity" of the flow (for which retail flow is the least toxic/uninformed). So, for 10 million shares a day, you can make much more money.
Disclaimer: I haven't read the article yet. But I believe he means explain the buzzwords in the reddit title or maybe no one will click on it or care. 
 from codecs import encode encode(encode(b"It's not as pretty in Python 3, though.", "zlib"), "base64")
"Because fuck you, that's why" (the official motto of Python 3)
Cool. I always thought Python could use some Haskel-style type signatures, but the official Python styleguide says you shouldn't include type info in docstrings. 
Thanks for explaining! Also, I'm not a Quantopian employee, but I do think Quantopian is pretty awesome.
Selling actual trade info before execution is illegal in US equities. This is why DirectEdge (an exchange) got in hot water over "Flash" orders. RobinHood could make money from HFT by charging HFT a fee per order that they will execute. This is counter intuitive to most people since they think that they'd have to pay HFTs to provide a service. But, in reality, the HFTs will pay for the order flow since they can make money on it in ways I described in my comment above (https://www.reddit.com/r/Python/comments/3u476r/quantopian_now_integrated_with_robinhood/cxc2qu5). 
Virtually all retail brokerages send their flow to HFT firms who then fill the orders. E-Trade, Ameritrade, Interactive Broker, Scott Trade, etc. I'm not aware of one that doesn't. This is how they make money.
Use py2app instead of pyinstaller. Or maybe there's something better these days.
The ultra-short explanation of static/dynamic is to consider this line of code: x = 3 In that line, `x` is a name and `3` is a value. In a dynamically-typed language, only values have types. In a statically-typed language both names and values have types, and must match (i.e., `x` would need to have a type compatible with the value `3` in order for that line of code to work). This gets difficult when you deal with languages that allow polymorphism, since even a statically-typed language often ends up implementing a runtime that resembles a dynamically-typed language in order to speed up runtime polymorphism (i.e., when you have a class `Cat` that's a subclass of `Animal`, the compiler may not be able to figure out ahead of time that some variable will always be a `Cat`, so it sticks to treating it as `Animal` and then at runtime the correct implementation gets looked up depending on what the variable is actually observed to be while the program is running). Strong vs. weak has more to do with when and how operations on different types are permitted. And is extremely tricky because it's common for either the language itself or implementations of its built-in types to define how operations should work on seemingly-incompatible types. One very loose guideline is to ask whether the language implicitly converts between types in order to make the operation work, or only works when the operation is explicitly defined (either in the language, in the built-in types, or in user code) for the given types and raises and error if not. So, for example, this doesn't work in Python: 'hello' + 3 and will raise `TypeError`, because `+` is not defined for string and integer operands. But this will work: 'hello' * 3 not because Python converts any types behind the scenes, but because the `*` operator is defined to perform repetition when given a sequence and an integer as operands (and yes, a string is a sequence type in Python). Python is considered strongly typed because operations only work when defined for the given types, and raise errors otherwise; languages which do implicit type conversions to force an operation to work are typically considered weakly typed.
i did, and i got a gibberish string.
Here is a simple [tutorial](https://kivyspacegame.wordpress.com/2014/06/30/tutorial-how-to-build-python-for-android-with-ubuntu-and-buildozer/) how to setup a simple android app with python, kivy, buildozer under ubuntu. It won't work under windows! But a VM is enough to get started. Be careful and choose a relativly big virtual harddisc for your vm, because you need the android ndk and sdk. In my first try the hdd of my vm was full. The installation and the compiling with cython will also take some time, but in the end it worked. As additional note, to prevent you from using the aweful java interface to use specific mobile features, there is a very pythonic wrapper called [plyer](https://plyer.readthedocs.org/en/latest/) also from the kivy guys. This will save your ass if you want to get gps data or the battery status ;) Just compare this [android sdk tutorial for gps](http://www.androidhive.info/2012/07/android-gps-location-manager-tutorial/) with this [plyer code](https://github.com/kivy/plyer/blob/master/examples/gps/main.py). Unfortunally you will go into the wastelands with only a handful of resources and alot of troubleshooting and simply trying. That makes me wonder why there is no real interest of bringing python into the mobile world... 
Do you know if there's anything stopping it from working on 2.6? I ask as someone who's forced to use 2.6 and couldn't use a package because of type annotations today.
I'd like to note that you don't need any plugins for syntax highlighting. It uses pygments, and you just have to prepend your markdown code with `:::LANG` where `LANG` is whatever language code pygments uses.
I was just going off what is listed in the categories section of the package page, so I don't have any extra insight. /u/sandwichsaregood seems to have come to the likely correct conclusion about he usefulness of the package pre-3.0 in the [above comment](https://www.reddit.com/r/Python/comments/3u2895/python_35_type_hinting_in_pycharm_5/cxbn0ia).
I use sqlalchemy to handle persistence. All of this is done in sqlstorage.py file. There are no models per se because there is no way to register them to your app at the moment. The tables for the blog are written out using the sqlalchemy core syntax.
Thanls! Seems to be the closest thing to what I was looking for.
Yeah, looking at it I can't see any reason why the backport library wouldn't work on 2.6 barring some minor fixups (disclaimer: haven't tried). The *syntax* is the big problem on versions before 3.0. AFAIU, the typing library doesn't actually handle that directly- the interpreter reads the function annotation syntax and attaches a dict attr to the function object containing the annotations. Function annotations are supposed to be kind of vaguely defined and usable for many things and the typing library just provides some specific machinery to classify argument and return types as well as providing a kind of interface for tools like IDEs and linters to go further with type checking. So it should be possible to generate the same kind of annotations on Python 2.* (remember, the annotations are just dicts), but there isn't a nice syntax for it and you either have to do it manually or by abusing decorators or even parsing docstrings. That's what the backport library provides- the standard pieces to build type descriptions of function annotations, but not the exact syntax. That said, the parent was saying that they found a library that wouldn't work because of type annotations. He/she would probably be able to get away with just deleting them if that's really the only thing keeping it from working on 2.6. They're supposed to be optional, so deleting the unsupported syntax is probably a better bet than dealing with the backport typing library and translating the syntax. Edit: looking at the [implementation](https://hg.python.org/cpython/file/3.5/Lib/typing.py) is pretty interesting, especially coming from the very type-fu oriented world of Haskell I occasionally visit.
Take that string, and invoke `. decode('base64').decode('zlib')` on it. You should get the original message back. OP is observing that it's really easy to compress and encode data using Python. 
Agree. Pythonista is great and I have it in my iPhone and my iPad. But, I think you should try Swift. 
Macs should come with python already installed?
Because .encode() was redefined to only operate on Unicode strings and .decode() on bytestrings, encoders were redefined to only ever return bytestrings and decoders to return Unicode. The previous semantics were batshit insane, but sure you could write trixxy Python if you wanted
All that sounds way too complicated. Why can't you just import the package, check the version, and then update if necessary?
Use the correct tool to do the job properly. Even if you're world greatest hammerman, I doubt you can solve all the problems as nails with your hammer. I'm comfortable with English, but I try to learn local languages too even if just a few phrases when communicating in other countries I visit. Most libraries in Python aren't that optimized compare to native libraries. You'll be more productive to learn Swift and iOS libraries. It isn't that hard. As little as 1 mth of about 8hrs a day you can create a fairly sophisticated app from scratch all by yourself via library books, and cheap online tutorials either torrenting, Udemy, Lynda.com, Pluralsight or even Coursera/Udacity. I assume you're targeting iOS platform first then later Android and then maybe Windows/Blackberry. The best return both in terms of effort and money spent is on iOS platform, after that Android. Others, are negligible and can wait.
I certainly didn't mean to imply that I wouldn't build an app in the native environment if I wanted to do it properly. I mostly just wanted to fool around with app building and thought a cross-platform framework would be fun.
The automatic type conversion of string to unicorn was insane. The encode and decode methods got lost in the shuffle to correctly diagnose the problem: automatic type conversion.
I also preferred the previous way. I wouldn't neccessarily describe this as "trixxy" code - it was merely code that takes advantage of the fact that codecs can and do operate from bytes to bytes or strings to strings, and this is a useful thing to expose in the API. I think it was *way* overkill to remove the method just to avoid the confusion as to which method to use. A runtime error would have been fine (and in fact, that's exactly what you get when you go through the codecs module and pass the wrong type) Originally, it was even worse, in that initial versions python3 removed non bytes-&gt;string and string-&gt;bytes codecs altogether from the codecs module. Fortunately, they went back on that decision at least.
The answer seems to be Guido. Thanks for the link.
Yeah I love the Ipython notebook because I split up my code and run it in chunks, show graphs etc
I started looking into Kivy just 2-3 days ago and I am really impressed with what I have learned so far (reading some books on [safaribooksonline](http://www.safaribooksonline.com), mainly [Creating Apps in Kivy](http://shop.oreilly.com/product/0636920032595.do) that I thought seemed like higher quality than the other ones, so I'm actually taking the time to do the exercises in that one, but the other books had some chapters on topics I want to get to as well later). I have not tried to run Kivy on different platforms yet, but it looks from what I read that it is stable and useful (and free) for iOS (and Android and Windows and OSX and Linux, at least), at least when using python 2 (there are some warnings about using python 3 not being supported yet on all platforms). What I like mainly so far is that the design is really nice. I was never happy with the way you design GUIs in various (many, many) environments I have worked with. It just seems very well thought-out, with different ways of doing layout and how you can specify even lower level graphics primitives in ways that can be interacted with (it is more like SVG than Canvas, to compare with web technologies). Now I admit I do not know how well it works in practice, and I need to come up with a few real projects to try it on before I can (or can not) run around and tell everyone how fantastic it is, but so far so good. Definitely at least worth a look if you are already comfortable in Python.
Kivy is great for me. Good tutorials and you can do a lot with it.
Am i already using the stdlib ? How can I tell ? It this just standard python built in stuff ?
I looked at it, but my point is that i kinda don't want to have a webserver running for the sole purpose of serving webpages to myself. But i will of course consider using it. just a question: would it be possible to write my own html and css instead of using the generated code?
To add to this. Electron also works, but as a javascript novice I have no idea how to make it do what I want.
It could be possible. In this case you can create a Widget appending plain html text to it. But, I suggest to avoid this usage if you want to interact with the interface. Because you will lose the events management automation. If you expect to write html css javascript, maybe you should consider to use flexx https://github.com/zoofIO/flexx, or Flask http://flask.pocoo.org/. Just one suggestion for the future (when maybe you will want to try it): Look at the examples starting from simple_app.py and the widgets_overview_app.py. The first is a simple overview on how to write the App structure, the other shows how to use the widgets. ;-)
I'm not a fan of this, but here is some more info about how to https://www.fyears.org/2015/06/electron-as-gui-of-python-apps.html 
Swift is being open sourced.
That doesnt mean shit . Objective C is open source too and that never took off anywhere.
[removed]
If you're interested in a description of the kmeans method of extracting colors, I wrote a post on the subject: http://charlesleifer.com/blog/using-python-and-k-means-to-find-the-dominant-colors-in-images/
Nice! Here is a more basic introduction (without objects) in Processing in Jupyter: https://athena.brynmawr.edu/jupyter/hub/dblank/public/CS110%20Intro%20to%20Computing/2015-Fall/Lectures/Study%20in%20Spirographics.ipynb
It has been my experience that text-based coding tutorials are generally easier to find (because they are indexed by search engines) and understand (because I control the pacing). Videos can be a nice supplement.
Zlib is an encoding/compression function iirc. Read the docs, but ask questions too!
Hi guys, I'm just trying to write a function that takes a matrix (lattice), then chooses a random entry in that matrix and decides if flipping the sign of that entry will lower the energy of that lattice. If it does, it flips the sign. If it does not, it decides whether to flip the sign depending on other factors. I think I have written that part ok, but I'm not sure how to then get the energy (using pre-defined 'energy' function) of that new lattice. Could you look at my code? I've tried something, but my demonstrator told me that the function, as it is, would return the energy (and magnetisation) of the old lattice, not the new one (the one we get after the function decides whether to flip the sign or not). Here is my function: def montecarlostep(self, T): # complete this function so that it performs a single Monte Carlo step energy = self.energy() magnetisation = self.magnetisation() I = np.random.choice(range(0, self.n_rows)) J = np.random.choice(range(0, self.n_cols)) #the following line will choose a random number in the rang e[0,1) for you random_number = np.random.random() numofcycles = 0 W = self.lattice[I,J] S = self.lattice[(I+1)%self.n_rows, J] + self.lattice[I,(J+1)%self.n_cols] + self.lattice[(I-1)%self.n_rows,J] + self.lattice[I,(J-1)%self.n_cols] interaction = W*S if interaction &lt; 0.0: self.lattice[I][J]=-1*self.lattice[I][J] elif random_number &lt;= math.exp(-int(2*interaction)/T) : self.lattice[I][J]=-1*self.lattice[I][J] else: self.lattice[I][J]=1*self.lattice[I][J] return energy, magnetisation Thanks.
There's tons of information out there. Did you have questions about what you found when you googled for it? Performance seems to be your priority, so cffi is faster from cpython (the interpreter essentially everyone uses) and works well with pypy (the fast JIT interpreter, often used to speed up web servers). But it's less user friendly to install, I've heard. If you're asking about automatically generating bindings, SWIG is a thing, but I think hand written bindings are preferred though I don't know much about it.
&gt; Is there any reason why you couldn't just use CFFI? Because writing a C shim to your C++ library is boring stupid work?
I'm not sure what your aversion to a web server is. I think it's a fine gui paradigm. Perhaps you assume it is system overhead* or harder to write/maintain/execute? I don't think these are the case. Actually, building web kit into your project is much more all of those things. If you're on linux or osx, you can probably go to localhost:631 and see your CUPS interface. Bitsync or something like that has a similar interface. *you don't need to install apache or nginx. Just serve your html/css/js over a socket. Flask and django have servers built in. [Also]( https://www.reddit.com/r/linux/comments/3u764e/ubuntu_finally_dropping_python_27_in_the_default/cxcm77q)
Another point - if you use a python framework, you're locked into that framework, which is much more restrictive. If the framework you're using stops development or has bugs they're slow to fix, you're completely stuck. Apple already has stringent requirements when it comes to accepting apps into the app store. If your framework is causing a crash, leaking memory, or just making it hard for you to meet Apple's UI standards, and that is blocking you from getting approved, there's nothing you can do. I've had native apps I had to recode simply due to changes in new versions of iOS. And even then, I only had to update the code of the specific components I was using. The framework, however, would have to update every component they supported. You would have to wait a whole development and bug testing cycle before even dealing with how it affects your own code. Apple could easily release a beast of an update and you could be fucked for a long time. Granted, if you're just making a hello-world app for yourself, you might not care. But if you're going to invest the time and money into making an app for app store submission and approval, it's a serious risk worth considering. It already costs a yearly fee to be part of their developer program. Apple purposely creates a high barrier to entry and they are proud to admit it.
You misunderstand a lot ctypes and CFFI wrap *C* ABI, not C++. If you want to wrap a C++ API you need to first expose that as a C ABI. Bad advice is worse than no advice.
is it out for linux yet?
It seems like swig and cython are the only good options. 
For one thing I saw this when I googled swig and c++11, http://www.swig.org/Doc3.0/CPlusPlus11.html#CPlusPlus11_threading_facilities
can you list some iOS apps written using which look great which are on AppStore?
That was a concise and easy to follow tutorial. Thank you for sharing.
1. Shitty title. 2. What is this list of buzzwords supposed to be? Why is it sad?
I'm a big fan of [Supervisor](http://supervisord.org/) for managing services.
Libraries, data files and/or different interpreter versions.
You're welcome. Glad you got something out of it. 
Like I said, I don't know much about this. But, do you need to wrap your threading capability? Or are you just going to provide an interface for code that handles its own threading? I would think if its the former that this isn't an issue, but I don't know. You might check out the swig mailing list to get solid feedback on something so specific.
Nice. I've used slides.com in the past for controlling my presentation "remotely" but that goes over the Internet, which of course leads to lag or outright failure at a lot of conference venues. Doing things over the local network is way nicer!
To be fair, even if you are getting skimmed 0.01-0.5 cents per share, trading is still orders of magnitude cheaper than it was even five years ago for a retail client. Its just less transparent.
Considering most Linux systems today have systemd and you can readily get systemd to handle it the same way all the other services are handled, I don't really see the need to have init launch a secondary manager to manage one thing. Telling systemd to run a program on boot and keep it alive is a few lines and integrates into systemctl.
For small projects it generally doesn't matter, but on larger ones usually you'd never touch a log file directly, you'd have a logging system so you could write something like log.warning("unexpected something or other") log.notice("that's been deprecated") log.debug("the value i is currently %s" % i) log.error("syntax error") and you can easily change where you log in one place later, and can easily include the option to only log errors instead of every little thing from one place.
Let's say the requirement is numpy&gt;=1.8 So in my code, I can do: import numpy if numpy.__version__ &lt;= 1.8.0: # update Obviously that has to be slightly more complicated to be dynamic, but that's the jist of it. This `__version__` stuff is standard. There are a few popular exceptions, but it's also standard for the package name to be the same as the import. Do what pyInstaller does and have a few special cases for legacy reasons, specify the requirements for everyone else in a setuptools/pip PEP and be done.
My designs are still ugly. But a few companies are interested in my work. I think it helps as soon as you replace the default grey buttons. [Like this ugly thing](http://i.imgur.com/wncats0.png) **Edit**: It looks like [u/inclement](https://www.reddit.com/user/inclemnet) knows what I mean.
You can also make an Access Point with your phone if the local network is not working as intended!
I use android so I only know of one, but its pretty popular. [2048](https://itunes.apple.com/us/app/2048-with-kivy/id841404915?mt=8)
wat
Search your computer for pyinstaller.py. You need that file. Sometimes it's in \Pythondirectory\pyinstaller-X.X\ You should also consider using a spec file instead of a run configuration. It is much quicker to tweak pyinstaller builds. https://pythonhosted.org/PyInstaller/#using-spec-files 
This looks much better than the default :) I looked for something more like goodles material design. So iam now editing the background pictures like /u/inclemnet mentioned. Iam not sure if it will lead somewhere :) I also saw there is some kind of kivy material project but it is not documented and more like an alpha thingy 
A little tip for your title next time, you should give us a little summary of what the plugin does.
Oh yeah, if the up to date versions in a repo that's always the best route. Just looked and it looks like it's in the Fedora repos as well.
&gt;Or use your experience in research to leverage that into a developer role. Lots of companies have an R&amp;D division What kind of software company can afford R&amp;D? I kind of assumed it was only the commonly recognized big league companies but you're implying that it's more common? 
Very nice! :) Now do flappy bird in less than 87 please.
Nice :) Good fun programming. I've completely forgotten how to do that. If it was me, I would have spent 1 day fretting about file/folder organization, then a week overarchitecting some generalized design :(
Perl lets you do things like: "1"/2.0 =&gt; 0.5 1/"0" =&gt; 0 Python does not unless the type of 2.0 (let's say it's an object) overloaded division. You can make Perl strong typed by typing `use strict`, but of course that breaks everyone's Perl code. Python just lets the value of say `self.x` change from an int to a string to a float to an object, but division rules based on type always apply.
Wow after discovering Dracula theme for vim. I got thinking about colors and decided I wanted a vim theme based on lucky charms cereal. I think this might help me get it. 
well, yeah, I invested some time in swift but I have given up on locked down languages. I would love to write a full app in swift that works on iOS and has a web backend in swift as well.
I have successfully bundled (semi-complex) python scripts into OS X executables. Can you elaborate a little bit more on what errors you received? One issue I have encountered (maybe is easier to do nowadays but was hard/impossible in the past) is that you generally need to build on the OS you are targeting. Ie, if you are running Ubuntu and wanting to package your script for OS X or as an OS X .app file, then likely you will need access to an OS X machine (or a VM) to do the build. I have always been able to work my way through the errors generated by pyinstaller simply using a little google-fu. For instance, pyinstaller will often complain about scipy packages an files - so you can play some tricks with the '--hidden-import=' parameter passed to the commandline in order to get pyinstaller to fully build the project EDIT: with regards to your final statement / question You can absolutely make a simple bash script like #!/bin/bash python /path/to/my/script.py save that as a .sh or .command, give it the correct permissions, etc... Now you have an executable file which will run your python code The problem, as someone else alluded to, is that if your python code requires certain libraries, modules, external files, etc - which are not present on the target machine you want to run the code on, then your bash script will be useless because it will call the target machine's local python distro which likely will not have the correct libraries installed. so if you script says import numpy as np and the target machine doesn't have numpy - then when the bash script executes your code you'll get an "ImportError: no module named numpy" from the local python distribution This one of the reason things like py2exe, py2app, pyinstaller, cx_freeze exist. They take YOUR local python distribution and bundle it with your code. So the code executes using the exact python distro you bundle with it irregardless of that distribution is installed local to the target machine. Thus your 20kb python script might become a 300Mb app because it has bundled with it an entire python distribution. 
Like I said, you just have to go for it. Say "fuck it" and do it. 
In Python - nope, but there are options for JS (which is a decent language since ES6) like Cordova or React Native.
Vim 4 lyfe bruh ;P
Be open source and have given the author craptons of programming experience? 
Very cool. One thing that bothered me was "for enemy in enemy: enemy = enemy[1]". There was also a "for b in b:" somewhere in there.
Yeah I know, it's sloppy. It was a stream of consciousness and I didn't really think about neatness. It was all about the time on this one.
Good. `zlib` isn't a text encoding, and neither is `base64`.
`python3.4 -m PyInstaller [...]` EDIT: See my answer on your stackoverflow question!
I got caught in that too, I think its just a stage most programmers go through. I recently started a personal project writing a pebble watchface and its in C. Because C is so much simpler and limited its kinda forced me back to the "Just do it and leave a comment about how it works, who cares if its a little ugly". That's been carrying back to my work stuff and I've sometimes stopped myself over-engineering.
Agreed. Working on the text format. Will publish it shortly along with part 2 of the tutorial.
Like a PyCharm, got the joke? ... oh never mind and thank you!
Ever heard of `snake_case`? You are using `camelCase` which is really messy considering Python is an elegant language, and always uses it's style guides. (except `unittest` unfortunately, which is a port of Java's JUint)
Vim is love, vim is life
It honestly shouldn't be that hard. I have been using vim for over 10 years at this point. If its something you are having a hard time with then don't bother, use something like sublime text. It's not going to make you any more productive really.
You might wanna check out [Bugjar](https://github.com/pybee/bugjar) also. It seems to be picking up some steam.
At this point, I use pretty extensive IDEs. My productivity would drop severely without proper debug tools like breakpoints, xdebug, etc.
1. Make it work. 2. Make it elegant. 3. Make it fast. 2 and 3 are optional.
It looks like the last updated [version of pygame is from 2009](http://www.pygame.org/download.shtml). Has the project stalled, or did it reach perfection such that it has needed no updates in 6 years?
Can you link the songs in the description?
It's an old library. It has matured and doesn't really need frequent updates. The community is very large though I'd suggest using it.
A fellow VIM lover &lt;3
I was always taught that camel case was the more elegant casing to use. For the next video I will try snake case out. Thanks for the suggestion.
I use millejoh's `ein` package fairly happily.
Well, for your code to be PEP-8 compliant you must implement snake case on identificators. I think it was chosen over camelCase because a study found it was more readable :) It's good for distinguishing i's and L's: NilIterator vs nil_iterator (although good monospaced programming fonts make this a non-issue)
And i'm just sitting there doing a hitbot which serves no purpose at all. [Source for the interested](https://gist.github.com/Admicos/62c7b6c5705aeecfac8e)
The [Quantopian help docs](https://www.quantopian.com/help) are a pretty good place to start, and we (disclaimer: as noted below, I'm a Q engineer) recently rolled out a search feature in our [forums](https://www.quantopian.com/posts) which can make it easier to search for specific issues. If you're interested more on the technical side of things, there are some tutorials in the [Zipline docs](http://www.zipline.io/), and there's a [Zipline Google Group](https://groups.google.com/forum/#!forum/zipline), as well as a [gitter channel](https://gitter.im/quantopian/zipline)) in which you can generally find some of the Quantopian dev team. There's also a user-run [Slack channel](https://quantopianusers.slack.com/messages/general/).
Good job! Would be interesting to see one of those time-lapse videos coding a hard disk driver.
`pip install requests`, then `requests.get(url).text` is the body of the response. (url is your string, the rest is literal). 
It works but what I want is notebook.
Check your privlege, space invader shitlord!
:w saves lives
right, but in the world where you do need production speeds, cordova doesn't work fine. Essentially it comes down to, which would you choose to ALWAYS work and which would you choose to sometimes work
CEF Python is also an interesting choice if you want to do some python processing of data client-side, whereas the UI can be done with HTML.
According to /u/bastibe， `ein` is my first link.
re.findall finds everything that matches a single regular expression, however you *could* possibly write a single regex that matches all three of those possible forms, but it would be tricky and unreadable. If you want to be a showoff, you could do it, and your professor will think you're a little shit for doing it. As a hint, it requires the use of backreferences.
I could see that. Plus with Cordova you're held hostage to whatever version of the webview that is available on whatever platform and there are some bizarre bugs in Safari/Android Webview.
It'd be really neat to see some examples. Those docs are a bit sparse. I'm very curious what the output looks like.
The #1 thing you have to do is commit to using it.
(Not a programmer) But I get absorbed in the How (It Works) rather than the What (I'm doing / producing). 
You're not kidding 
There is [python build reasonableness](http://docs.openstack.org/developer/pbr/) from the openstack project. It does version numbers as well as authors files, changelogs and a few other bits. It might be a bit big if you only care about versions though.
this ^ u/Ocelot713 take attention or it will bite your behind 
I can't believe that actually works, with python's lack of scoping in if statements. Definitely a wut moment, but neat to see code working that I wouldn't imagine writing let alone even working.
If you want to make an apple pie from scratch, you must first create the universe.
That's actually a mistake a see a lot in real-world systems: overgeneralization. I think it's a good rule of thumb to not generalize before you need it.
Thanks! The link looks like it covers it all. Yeah the reason is i think it can be hard to install opencv, an it takes a long time on the raspberry pi. But it seems like it is the easiest way though. I'm looking to build a vision system that discards components that are orientated wrong. 
Its called: [FlatKivy](https://github.com/Kovak/FlatKivy) It also has a nice [Vid](https://www.youtube.com/watch?v=I81r_iDEswE) 
Absolutely. I've learned that over the past few years. Even worse is when you try to do that in a startup-like environment, where assumptions and requirements change rapidly - even at the foundations. You waste a lot of time with such generalizations, and later it just isn't worth it, or sometimes tou end up with an overly complex system which is hard for others to get into...
*shuffles guiltily away*
I'm the hacker named 4chan. I usually just build a gui using tkinter to track my victim's IP address.
I can confirm that.
Not strictly Python, but Ansible is my main move now. I try to do everything I can with it. If Ansible doesn't fit then I'll look at a custom script or something. Best perk: vendor lunches and happy hours.
You can use gedit instead if you want a quicker setup. It's pretty decent.
[Don't let your dreams be dreams](https://www.youtube.com/watch?v=es47SMRaztc)
I specialize in Linux administration and use Python to build little webapps, or scripts. Mostly I try to build scripts in Bash, I'm a Bash grammar nazi and well read on best practices. But to list a few python projects lately. * Sync-script from Vcenter inventory to an inventory management tool we use internally * Aforementioned inventory management tool written in python but I'm not the author so I only submit PR's * Another sync-script from Keepass to the new inventory management tool, a step towards getting rid of keepass for password management * Various automations, like uptime-reports * Our new monitoring system is also python so various things done against that API I try to do in Python, like automating tasks, pulling out reports, bulk changes * Wrote two collectors for the aforementioned monitoring system lately, one for HP RAID and one for Citrix Licenses So plenty of small scripts, not many larger projects. The larger projects are something I do in my free time, like building an alternative to Ansible Tower. Also as someone else mentioned, I use Ansible heavily so I'm always prepared to write a module for Ansible if I run into a difficult use case. We have some perks, mainly in our work hours and ability to work from home if we need to. Also gym membership is payed yearly by the company, health but that's generally good here in Sweden, invites to various events, networking, leased company car that pans out to a pretty good deal if you want to let someone else handle all the administrative things of owning a car. Edit: I have one regret from all this, neither our inventory management system, monitoring system nor ansible are written in Python 3 so I'm still forced to use Python 2 for most things I write. 
And here I am, 10 hours into my Space Invaders emulator (Intel 8080), and I'm just starting to generate video output. Cool video, keep up the good work.
It doesn't work! I'm using python 2.7.3, and this is what it prints "ï»¿" when it should print [this](http://k30.kn3.net/9/E/3/2/3/8/E1C.png) large text. Also, .content does the same thing
This is how you flash an LED using GPIO Zero: from gpiozero import LED from time import sleep led = LED(17) while True: led.on() sleep(1) led.off() sleep(1)
Seems that there are few examples in the "data" folder https://github.com/michigan-com/summarizer/tree/master/tests/data
I'm a sysadmin on the trading floor for q large foreign bank with US operations. I use Python to automate tasks, build reports and maintain inventory databases. Perks: 7 weeks paid vacation, 10% match on my 401k, salary plus bonus, 2x annual salary for life insurance, shopping rewards, legal counsel, deals on mortgages, auto loans etc. travel discounts. More but I can't think of them right now The shopping rewards are basically through a web portal - you shop and get discounts. For instance this week we had a deal for Dell laptops that were at a 30% discount. Lots of vendors participate in this sort of program
This question might be more suitable for /r/learnpython or even in a more general programming subreddit. /r/python is about python news while /r/learnpython is about python-related questions (contrary to what the name might imply, this is not only to learn the basics, far from that).
I agree. While I think pandas is an incredibly useful tool, quite frankly I find the API insanely difficult to work with. I have to refer to the documentation far too many times to do useful things with it. But even then, pandas has its toes halfway in the water anyway of SQL like syntax. I'll probably f this up because I'm doing it from memory, however: series = df[df['column_1'] &gt; 40].groupby('column_2').sort('column_3', ascending=False)['column_4'] Compared to something like: series = df.where('column_1 &gt; 40').group_by('column_2').sort_desc('column_3').select('column_4') Pandas' API syntax has three different "ways" you manipulate information: 1) the df[df['column_1'] &gt; 40]] syntax 2) the functional way like the sort() function, and 3) the last selecting list-like syntax, ie ['column_4']. Compare that to the SQL like code I made up. Which one of those is easier to comprehend if you don't know Pandas syntax? Not to mention data analysts should already be expected to know SQL. Why learn a whole different syntax for the same domain area?
Recently I finished a python program that accepts a list of hostnames and a list of shell commands then executes the commands on the remote computers. I have 8000 linux machines to manage. Sometimes I need to get very specific information from them that our other management tools can't quickly provide.
The pandas API syntax isn't too bad if you came from using numpy which pandas rely on heavily. So I'm not saying pandas API syntax should be re-done or replaced. However an option for SQL-like syntax would be nice as part of the pandas library, some how make a SQL wrapper of some sorts. Seems like the API syntax changes recently in the past year are converging on doing just that. So the pandas developers are definitely aware of a subset of users wanting a more SQL-like syntax and are doing their best to achieve this despite the numpy dependency. I know it is definitely hard to achieve this while maintaining high performance, so I am not expecting this any time soon. But one could hope.
Any reason for using selenium+chrome+ a download manager instead of ~~[scrappy](http://scrapy.org/)~~ [scrapy](http://scrapy.org/) + [wget](https://pypi.python.org/pypi/wget)? EDIT1: added links to the wget package and ~~scrappy~~ scrapy framework. EDIT2: fixed the typo in Scrapy
Neat. I found ([via stackexchange](http://gamedev.stackexchange.com/questions/108998/pygame-for-python-3-5)) a [link to download pygame for python 3.5](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pygame) which works for the anaconda distribution of python 3.5 under windows. All that's needed is a "pip install pygame‑1.9.2a0‑cp35‑none‑win_amd64.whl" and you're set.
Have you looked at Kivy? I have used pygame a little in the past, but when I was looking around for some interesting library/engine now I was really impressed with Kivy. I have not used it very much yet, so I don't know how it is in practice or how it performs, but it looks like something that you could develop very fast in. One of the books I found had a chapter where you write a space invaders clone. Would be fun to hear a comparison from someone that knows pygame so well.
That's essentially what bundler does except you don't write code that updates or installs dependencies. I don't think the code approach is appropriate because 1. It's prone to user error and 2. Makes updating the tool itself dependent on user code -- not something you want when the tool itself is what is going to update the user code!
Its something I need to try again. I tinkered with it once some time ago but could never get it working properly and eventually gave up as I didn't have an actual need for it. I still don't have a direct need for my research its more just a curiosity. It seems like a useful skill to learn.
I hate autocomplete because its always popping up when I don't need it. I find that you adapt to remembering things fast and for the things you don't, you can quickly find out in a terminal session or via googling. Then, that method becomes easier to remember. Wash rinse repeat. Also, its kind of like remembering the tar flags. You mostly don't forever but sometimes you do.
Yes, Pygame is quite beautiful and great for prototyping, even actual game development. 
Yep! Feel the same way, but started reading [Game Programming Patterns](http://gameprogrammingpatterns.com/)(book) last night and in the intro right at the bottom it said: &gt;Abstraction and decoupling make evolving your program faster and easier, but don’t waste time doing them unless you’re confident the code in question needs that flexibility. That really made me reconsider how abstract or how generalized I want to make classes and things.
I don't want my reddit account to be too associated with my real identity, but I will throw you a link in a pm. It's a really fun project and I cannot recommend doing it enough. I'm doing it to get into emulator development. 
Yes! So this is like knitr for Python?
Emulators fascinate me as well. The stuff you can do with it is crazy.
https://vine.co/v/iaWWlKxgwzz Might do your space invaders one next! (if that's okay?)
Important note : The README may let you think it's a pure Python implementation of a latex converter, but it uses commands like pdflatex to do the job.
Well subclassing is for reusing and extending code, yes. But the ruby community also has that. Also, imagine you've got yourself some weird framework who wasn't built with extension in mind (meaning they instantiate classes all over the place for example). Bometimes it would simply be way easier to just add methods to those classes at runtime. This way you wouldn't have to worry about replacing huge amounts of code with copy-pasted version, where you changed 1 line. Of course, the down side is that you should be careful to have the code that adds the method run after the extended class has been loaded... and you couldn't really do it reliably on more dynamic classes.
This is called [monkey-patching](https://en.wikipedia.org/wiki/Monkey_patch), and is my understanding is that it is usually frowned upon. Do you have a scenario that wouldn't work with simply subclassing, with the subclass adding only the new method, or by using a wrapper class that overrides `__getattr__`?
I came across this inconvenience: the django forms, when treated as a dict `form["fieldname"]`, for fields that exist, return a `BoundField` instance. This is instantiated directly in the `__getitem__` method. This means that if I want 1 simple method on the BoundField, I have to rewrite the entire `__getitem__` method, AND subclass the `BoundField` class. I understand that this is the orthodox way of doing things, but I think it would be a good idea for me to just be able to add a simple method. If you're not familiar with django, the context where you'd get the `BoundField` instance is inside a templating engine. To add just a tiny amount of custom functionality I'd have to perhaps create a module, import stuff, modify my template, create a simple function... A lot of stuff for when you just want a trivial piece of extra logic.
I think the abc module ( https://docs.python.org/3.5/library/abc.html#module-abc ) is doing something similar. Maybe...
&gt;I wonder why this pattern grew so big in Ruby, but it's considered a Hack in Python. I mean what could be so hard about adding another extension pattern? It's not so much that it's hard, it's that it breaks something that's nice: when you can tell precisely what an object is and is not by reading the class definition or official docs. If you make it standard that you monkey-patch things on here and there then someone coming into a system they ostensibly know can be very surprised to find seemingly broken code working. &gt;Also, since we're here, you can't add methods to the types implemented in c, like the list, dict, int, etc... Wouldn't it have been a good idea for Python3 to export provide dummy python proxy for these classes, so that you can add methods to them, if you want? The stdlib and extremely commonly used facilities are the last thing you'd want to let people mess with; most anybody that's done any Python will at least know the basics of how a dict or a list works and doesn't work. foo = {'thing': 'thing', 'other_thing': 'other_thing' }.bar() would be really bothersome. Most Python programmers would see that, say "wth?", check the docs, realize it's not supposed to work, then have to go hunt down your monkey patch. If you just subclass a dictionary then it conforms to expectations and all the tools can readily help you find where MyDict was defined or whatever. It also prevents breakages to other code. If some code runs in the context of your monkey patch, but the programmer doesn't know that when writing code they can easily cause confusing and unexpected behaviour and then they have to go hunt it down. 
The breadth of the operations it supports is much more expansive now. ... so you will probably have better luck if you tried again. also better docs 
So funny, I just saw an /r/homelab post using a Raspberry Pi and decided I should finally get one. I saw this post and got excited - but do these ship for $5 to the UK only? I'm in the US.
the comparison with pypy is really quite a bit skewed. Few points: * the benchmarks are a bit hand-picked. I'm ok with hand-picking benchmarks, but I'm not ok with saying "web loads" and then running them for 1.5s (that's the best one for pyston for example). * pypy is not really microbenchmark-oriented. We're trying to address quite a few of web loads as well as other loads in the python world. Just look at the list on https://bitbucket.org/pypy/benchmarks/src/770e56a1296f88db9addd08a57783d0c14832543/own/?at=default to see our list. We should definitely integrate benchmarks that are in the pyston repo that are not in our, I'll probably do it in a few days. * future is notoriously hard to predict, let's not go there.
Thanks! I will check into this during some free time this weekend
The company is based in the UK, everything is done there. Even the boards themselves are manufactured in the UK, not in Asia, which is pretty impressive. 
Yep, super fun. Also gives you a really easy way to start interfacing software with the Physical realm, with very little experience. The Raspberry Pis work very nicely with the Python RPi GPIO package, allowing you to communicate with the GPIO pins. 
AFAIK Pis are perfect for python, not sure about any other languages tho
Well, you could connect an ESP8266 to the gpio pins. But yeah, I wish they released a headless raspi with ethernet instead of hdmi.
Can't you connect with existing IRC libraries?
Hey there, I just created the first post on my blog detailing how to automate some common tasks when developing PySide applications in PyCharm with a simple toolchain. Please let me know if there are any issues or questions (or comment on the site)!
Neat. This looks like a really nice way to generate Beamer presentations. Took me about 10 minutes to figure out how to create a class for the `frame` environment and get a little test working. Very nice.
pdb/ipdb works too. 
Those are my concerns exactly. But then Ruby (or at least the rails community) as I hear, have a very strict way of defining these monkey patching techniques. That's to say, there's one file where these should all be defined. So after 2-3 times looking for methods in the official documentation and not fiinding anything, people would get the reflex to just check for the extension. I think that monkey patching isn't as as thought. Now of course one concern remains: What if you use 3rd party libraries, that add method 'foo' to the string class, and you ALSO want to add 'foo'... or another 3rd party ALSO adds 'foo'... I think this is the only case I'd agree it's actually a bad thing, but maybe there's a solution for this too.
Yes, and you need a hub if you want to use a keyboard and network at the same time. I'd gladly pay double if it had built-in wifi.
Why `pdflatex` and not `xelatex` (the second one handles Unicode and has other niceties)?
you are in luck as the newest version of pandas has [conditional html formatting](http://pandas.pydata.org/pandas-docs/version/0.17.1/whatsnew.html#whatsnew-0171-style) read up on it and you’re set!
Because pdflatex is much more common to be on the system. However, you can easily pass any compiler you want to the generate_pdf method of the Document class. https://jeltef.github.io/PyLaTeX/current/pylatex/pylatex.document.html#pylatex.document.Document.generate_pdf I suggest you the compiler_args argument though and pass it this list: ['-xelatex'] that way it will use latexmk with xelatex.
Oh, it is not meant to give that impression. Could you let me know what made you think that, then I can change that. (or send a pull request)
This is the first release with actual documentation. If you think it can be improved, or is just plain wrong in some places, please make an issue or fix it in a pull request.
The big strength of python is interactive analysis. You do some analysis, it raises some questions and ideas, and this leads you do some more analysis. Python is ideal for this as it can be changed on the fly with few commands and no compiling. If you are always doing the same analysis and producing a standard format result then Python can still be used but there is no real advantage over java. In this case many businesses stick with java because it is robust e.g. strong type checking and testing infrastructure; and because the skills are more widely available. 
Very nice article. I like how the hard part of the code -- implementing all those binary operations &amp; whatnot -- is just shoved off onto Python. The result is a simple program that serves as a good explanation of what is going on under the hood. One peeve: this is not a Python interpreter (any more than -- say -- the JVM is a Java interpreter, or a processor is a C interpreter). It's a Python bytecode interpreter. It would be simple enough just to call it what it is.
did these guys not hear about [the set type?](https://docs.python.org/2/library/stdtypes.html#set)
They are great for learning Python because the hardware API is available in Python with many references including tutorials and example code. https://github.com/adafruit
The bloom filter takes a fixed amount of memory, while the set takes up the memory of the N items it contains, but can yield false positives. Different data structures for differents use cases. What's more, it's an educational post, written so you can understand bloom filters, as writting your own is useless given pypi hosts several robust solutions. Also, if you like the idea of the bloom filter, check the hyper log log (no typo), another interesting probabilistic data structure which counts unique elements without storing them.
* The interactive prompt * Libraries (pandas and scipy in particular). Part of this is integration with C to do heavy lifting. * Expressiveness, particularly list/set/dictionary/generator comprehensions and operator overloading * Duck typing - these projects tend to be small and the extra syntactic weight of most type systems doesn't pay off for small projects. Haskell would be pretty good for this type of work too, since it has types but they are inferred for you, but it has a steeper learning curve.
Would be happy to get you one and ship if you pay, i'm in uk. 
All the code is in the \_\_init\_\_.py file.
&gt; it's prettier than R You take that back! It is prettier for general computing, I do concede that; but for functional programming, parallel processing, and especially statistics-specific things, R is a wet dream. 
And you forgot the prettiest plots seen using std. libs!!
Let the battle begin!! R vs. Python: round I can't count...
They run a full fledged linux. I did a presentation using the Pi with video coming out the hdmi port.
I got the original pi running with a [tiny usb wifi dongle.](http://www.ebay.com/itm/EDUP-MTK7601-2-4G-802-11n-150Mbps-Wireless-WiFi-USB-Nano-Adapter-WIN-MAC-Linux-/311398591545) But I think you bootstrap first using the ethernet port.
Do they come with a Linux OS pre-installed?
You load the OS on an SD-card so you can have a bunch laying around ranging from a full linux build to media center to Console emulator and arcade emulator. just swap out the SD card for whatever you want to be doing at the time. 
he is. python tutorial god himself \^\^
Also please don't copy this and claim it as your own...
Let me try to hit your other question here Perl. Perl would be decent too. They probably don't have the hardware API but I doubt that is RPI singling out the language as much as Python just has a bitch'n community (probably the best of any language with RoR maybe comparing). More so, just think of the PI as a small computer. You can setup a webserver on it such as RoR, a python solution, or even something like apache. This is different from something like a beagle board or arduino where you are at a "lower level" and thus are forced to use something normally in the C family. I even hear there is some fun work going on with Elm and Node on RPI.
&gt; '&lt;-' &gt; '=' 
python -m SimpleHTTPServer
Or you can do all of that stuff minus the Linux on that windows laptop that is probably 10x more powerful.
All of the other reasons plus it's a very powerful general-purpose language and models can be operationalized quickly.
A laptop 10x more powerful would cost at least 20x more. Not that you need even a fraction of the performance if you're just learning. Also for those who want to move away from privacy infringing proprietary systems this Raspberry is a perfect starting point without any need to commit any serious resources or waste a lot of time trying to make things work.
Will have to find out dimensions, assuming it fits in a letter should be less than $10
Did you leave your credentials in this by mistake?
I'd love to see the script. I'd love to do something similar
Sounds like your friend is at a cool company to work for. What/where is that?
Sounds like Salt's remote command execution. Coincidentally, Salt is written in Python as well.
I've looked at salt, but just getting something like implemented is a nightmare at the place I work. There's several levels of management approval, server requests, change controls, ad nauseum. I had to implement Puppet under the radar but when they saw it in action, they liked it. They even wanted to go Puppet Enterprise, but balked at the price. Typically, I'm limited to whatever tools SuSE, IBM and Oracle sell; even then it's an act of God to get the tools. So I wind up rolling my own pretty often.
I have come to the conclusion that if you have to ask which one of these to use, the answer is both. Though python is probably a lot more convenient to connect with other services.
You can run python on the JVM - see jython. You can call java libraries and classes the same way you call python libraries and classes as well. It's really handy just for this, eg: import os # this is a python library os.getcwd() # '/Users/frank/Desktop/frank/hg/jythonbook~jython-book/src/chapter8' from java.io import File # this is from java stdlib f = File(".") for x in f.list(): print x As for statistics, well, others have attested to its usefulness but I'll add. I do lots of data analysis, genetic and molecular modelling, and scientists/analysts/engineers use the language because what you're thinking and what you're writing look almost the same. The cognitive overhead is small, and it's easy to share your code with your colleagues. At least, that's my two cents.
Yeah this is basically what I'm doing. I know lots of people love to make themselves irreplaceable by doing obscure shit, but I like my coworkers being able to do my job when I'm not there rather than calling me when I'm off. Ansible makes everything better 
I've just had a look and realised that the python bits for that where just to strip out the useless bits and extra entries I didn't want. Otherwise it's a bash script and zprezto wizardry. host -l domain.com nameserver That grabs all the entries. I then munge it through python to get rid of some crap. dump it in a .custom_host_completion file and point zpresto at it by editing the init file for completion here: .zprezto/modules/completion/init.zsh I added a line in the completion section so it now looks like this: # Populate hostname completion. zstyle -e ':completion:*:hosts' hosts 'reply=( ${=${=${=${${(f)"$(cat {/etc/ssh_,~/.ssh/known_}hosts(|2)(N) 2&gt;/dev/null)"}%%[#| ]*}//\]:[0-9]*/ }//,/ }//\[/ } ${=${(f)"$(cat /etc/hosts(|)(N) &lt;&lt;(ypcat hosts 2&gt;/dev/null))"}%%\#*} ${=${${${${(@M)${(f)"$(cat ~/.ssh/config 2&gt;/dev/null)"}:#Host *}#Host }:#*\**}:#*\?*}} ${=${(f)"$(cat /home/USERNAME/.custom_host_completion(|)(N) &lt;&lt;(ypcat hosts 2&gt;/dev/null))"}%%\#*} )' ...Hope that helps lol Edit: I'm pretty sure that last bit is somewhere on the internet already but I wasn't able to find it for you sorry. Edit 2: OH and then the bash script is run every 15 mins by a cronjob. Forgot that bit.
That's not surprising. R is used for statistics a lot too.
Yes, but R has a lot of historical baggage which can make it harder to write bug-free/performant code. That being said, all of the cutting edge stat stuff will be written in R well before it makes it to python.
sorry to be immature, but I read this as Playtex lol!
Python is one of the four supported languages at my company, and is heavily used by all the sysadmins (we also use Go). It's use to write anything from scripts that run on hosts themselves, or to implement service backends, or to implement tools for users to use directly. We have lots of perks. Pretty much you name it we probably have it.
Actually writing code on them isn't amazing since it's pretty slow. It's definetely good for projects, though.
.
But you can't use numpy and scipy from jython, can you? 
Not sure, though I've heard of the JyNI package, and JNumeric. I believe it's also possible to embed CPython within a java project, so you wouldn't even need jython if that's the case, and then you can have numpy and friends with all the conventional setup methods.
There's lots of ways of doing that. def decode_bin(string): return re.sub(r'[01]{8}', lambda m: chr(int(m.group(), 2)), string) def decode_bin2(string): return ''.join(chr(int(string[offset:offset + 8], 2)) for offset in range(0, len(string), 8)) 
Sure but most people have laptops/desktops in their home already. 
Would you recommend using the $5 or if you have the dough go for the better model ? What model do you feel is best to start ? My grandmother heads south for the winter so I just had Thanksmas and I have the money. I know python somewhat. I've done many beginner tutorials but I'm looking for that thing to push me to an intermediate level. Sorry to assault you with questions! 
I keep hearing how awesome sickit is, what's the best way to get started with it?
Or you can download the planet osm from OpenStreetMap and get coordinates from it and then maybe use bokeh to map it. Sorry I cannot include the links I'm on my phone
I found [this tutorial](http://youtu.be/L7R4HUQ-eQ0) by Jake VanderPlas to be super useful.
I mean, when it's just a challenge it's fun.
That's probably the main divergence when it comes to pandas' syntax. There are two main subsets of people who utilize pandas, I feel like. There's the scientific community, which already is familiar with and comfortable with numpy. Then there's the data/business analyst side who mostly start out with SQL and move up in their skillset. Personally, I have been using Python for 3 years. The last time before my most recent analysis stint I used Numpy was about 3 months into my learning experience when I was making a game. So.. it was a hard transition for me.
I haven't seen much of Ibis, but it looks interesting. In an ideal world, there'd be a unified syntax across ORMs, SQL connection libraries, and analysis libraries so you can minimize the amount of context switching that has to happen and you have a single interface to multiple DB systems. It seems like the most Pythonic way to handle it. However, I realize that's a pretty complex job.
I think that's what Ibis is aiming for.
Did you use an IDE on raspberry pi or how did you feel it's slow? I've never had any performance issues while programming on my pi.
Thank god for Hadley Wickham. The Hadleyverse (e.g. dplyr, ggplot2, lubridate) has made my life so much easier.
Does the WiFi adaptor work for the $5 model?
Yes, I didn't have to download a driver.
That's really cool! I'm researching a little on MCMelectronics.com and these things are a LOT cooler than I initially thought. Not to say that I didn't think they were cool, but the Raspberry Pi 2 Model B looks amazing for $35 - only problem is I want more than 1! :p
[removed]
I did a presentation with Raspberry PI using [LibreOffice Impress](https://www.libreoffice.org/discover/impress/), with a USB wireless presenter like [this](http://www.staples.com/V7-WP1000-24G-19NB-Professional-Wireless-Presenter-with-Laser-Pointer-Red/product_IM1UU5130). From memory it included a video. Nobody had a clue it wasn't Windows.
[removed]
[removed]
Why you are getting downvoted i have no idea... 
very cool. Playing with it now
Mostly straight forward stuff. I disagree a bit about their simplicity threshold for list comprehensions. Of the two examples in the `No` category, the simpler one I'd be fine with, but I agree that the other is a definite no-no.
Looks like a good start. Have you taken a look at [Ren'Py](http://renpy.org/)? They describe it as 'visual novel engine', but you can do text-only as well. I haven't used it yet, but I found [this interview](http://podcastinit.com/tom-renpy.html) with the creator interesting.
`bundle` was last updated 3 years ago. It's had 12 commits on Github. Does it handle wheels? Does it work on Windows? Is it a thing you'd like or something that's practical? It just seems too good to be true that something that isn't popular, maintained, and only 300 lines of code is anything special. `setuptools` and `pip` are the standard and are bugged and have been for a long time. That's sad.
The rules are neat but the website itself is a bit hard to work with.
My perhaps cynical view is that people want to justify not learning something new. I do remember long ago the days of trying to get my pet language to do everything, even things that are awkward for it. I would think: "I can already do `X` in my language, why should I learn something else?" And that, I think, is where the downvotes come from. These days, I use both python and R (and several other languages) every single day. They all have their strengths, and there are countless things that are better done in one than another. I can still do `X` in language `Y`, yes, but I can do `X` in language `Z` with so much more ease. 
It's no fun if you can't write your entire program in one list comprehension. ;-)
Really? I thought both of the "no" examples were fine. The more complicated one is exactly the same as the nested loops they have in the "yes" section, except for the "yield" statement and no rightward drift. I don't think it's any harder to read than the nested loop (which is itself a little bit complicated, but that's just the nature of that particular loop).
You can't use jython from ipython/jupyter, which makes it much less useful for this sort of interactive work. 
Went into the comments and found my TIL... Thanks!
so where should i put them? this is a desktop app.
lowerCamelCase is the standard for Java style guidelines but not for Python I think.
I would replace the whole 'style rules' section with 'Use flake8'. Why require humans to read, comprehend, remember and then apply something (probably inconsistently), when it can be done by the computer? pylint, in contrast to flake8, tends to produce many, many false errors. Running it over 1800 lines of a module in a Django project produces about 100 'errors', all of which are incorrect. In addition, there are hundreds more very unhelpful warnings/recommendations - for example: * "too few public methods" (for a Django 'Meta' inner class) * "Class has no `__init__` method" (not needed because it inherits one, although pylint doesn't seem to be able to detect that) * "missing docstring" (many methods simply don't need them - functions like `Cart.product_list` are pretty self explanatory, and a linter that forces you to write them will simply result in many pointless and uninformative docstrings, which are just noise) The number of false positives makes pylint useless for any real project I've been involved in - you'd have to spend a lot of time turning these warnings off somehow, or end up with the real errors drowned in a sea of noise. 
I use flake8 to check my code. This isn't much more than saying typical best practices + pep8. The 80 char limit is stupid as fuck. Any reasonable person agrees. s3_connection = boto.s3.connect_to_region('us-east-1', aws_access_key_id=AWS_ACCESS_KEY, That's 88 chars right there. Don't tell me that's too complicated. Sure I can put it on another line...
flake8 is a wrapper around PEP8 and pyflakes (and another thing).
I'm not able to access the source PDFs at the moment, but if there are tables, [tabula](http://tabula.technology/) may help. It is Ruby based, but could be used as a step in the pipeline when extracting the data.
Use import tables See http://www.pytables.org/usersguide/tutorials.html.
Try [this link](http://docs.opencv.org/3.0.0/d6/d00/tutorial_py_root.html) as a start. 
Fun fact, PyPy - a fast python interpreter - is written in Python (Sort of).
Works perfectly after a bit of tweaking. The help is great! Thanks a lot!
Take a look at [yapf](https://github.com/google/yapf) as well. I agree with basically every change that it made (`--in-place`).
I like to think my whole function out as a list compehension, the break it apart and give the intermediate steps names, seems to keep my code pure better than any other strategy I've tried (in python).
Hey, sorry to single you out like this, but I thought I'd follow up on you since I can't really ask anyone else. Did you get the toolchain described in the post to work? Any issues (if you got around to setting it up already, that is)?
Scrapy. The verb is also called scraping, and not scrapping. Yes, I'm being an asshole by pointing it out, but I read this so often I just had to.
&gt; edit: I am interpreting downvotes without replies as "I don't like it that you're right" sounds about right for an R user.
R is not new, it's outdated and dying.
Also, PyFlakes wraps around pylint and other Python style checkers (like those for PEPs 8 and 257).
&gt; Yes, I'm being an asshole by pointing it out, No you're not, i actually appreciate it, i'm actually ashamed for making the same typo twice and not noticing it.
&gt;The 80 char limit is stupid as fuck. Any reasonable person agrees. You're in [good company](https://youtu.be/wf-BqAjZb8M).
*Web* API
Now I understand everything. Might as well die off: &gt;&gt;&gt; import dis &gt;&gt;&gt; def a(x): return x+1 ... &gt;&gt;&gt; dis.dis(a) 1 0 LOAD_FAST 0 (x) 3 LOAD_CONST 1 (1) 6 BINARY_ADD 7 RETURN_VALUE &gt;&gt;&gt; 
Oh good lord, where would I even start! I run I.T. operations for a manufacturer that relies heavily on inbound phone sales, so as part of my duties I am in charge of what I've developed into a distributed phone system that can interface with in office sales staff, at home staff, 3rd part call centers, etc. Since we have two different call center partner companies currently in addition to our own staff, we needed a way for executive staff to get a top level view of performance data in near real time, so we developed a Django application for the purpose. Or partner centers automate report drops via SFTP, which kicks off the import jobs that can handle any file format they use. Numerous reports and charts are then available in a simple, consolidated interface. Once we have a few weeks of individual sales agent data we can import data from the media team to predict call volumes by half hour, import agent schedule data, and based on individual agent performance predict revenue, abandoned calls, individual agent commissions, etc. We've also developed an automatic scheduling algorithm that uses individual agent scheduling preferences and performance and various parameters (min, max shift length, splits allowed, etc.) to auto generate the "ideal" schedule optimized for either max revenue (sales) or maximum call handling capacity (customer service). Typically the algorithm schedule will yield 5% to 25% more revenue with a 10% to 15% reduction in man hours compared to hand created. It also is created as soon as the app has data for both agents and media, so it just appears magically there for the end users as compared to an hour or so each week to create it. All python, and not even really scratching the surface of total python use at my company. We use it for everything.
The 80-char limit is about readability not necessarily screen size.
I think I [got](https://i.imgur.com/InZTu3B.jpg) [it](https://i.imgur.com/spngTbN.png). It needs some work but I'd love to help your cause. Send me a message.
I'm sorry, but since you didn't actually ask any specific questions this looks an awful lot like you're asking us to do your homework for you, and that most certainly is not appropriate for this sub. My help to you is this: Grab some coffee, your favorite python code editor, Google, and any notes or reference material you have on hand and just dive in. If you can't or won't take that approach to completing this assignment you are going to find programming to be a brutal slog with very little reward.
a set is a combination of a bloom filter and a list. I suppose if your use case requires limited memory use the set is of no use. speedwise however they are very very close.
Either supply them on the command line or put them in a config file. You need to disable those keys on your account.
Not a list, as lists are ordered while sets are not. Plus, bloom filters have false positive while sets have not.
just because it doesn't guarantee order doesn't mean it doesn't *store* order. I'm fairly sure a set is a linked list combined with a bloom filter. the bloom filter is to filter out negatives, and positives are looked up in the list which is most likely sorted so it can be binary searched.
Not on github!
Wait. I thought pyflakes was competitor to pylint and flake8 is what you're describing. What is flake8?
Let's not debate and check the source : http://svn.python.org/projects/python/trunk/Objects/setobject.c
Keep in mind that Raspberry Pi B Models are the only ones with native network interface (Ethernet) - so if you want to use it on a network, you should go with one of those (or buy a wifi dongle for the A / Zero Model). For the Zero you'll also need HDMI &lt;&gt; miniHDMI and a microUSB &lt;&gt; USB adapter to use those ports. Using the GPIO ports is more difficult on the Zero, as it comes without the presoldered male GPIO headers (so using those on the Zero would require soldering). Last but not least: The Zero only has a little more than 1/4 of the latest Pi B's processing power and half it's RAM.
Lower camel is still the standard. There's an internal linter that will prevent you from committing if you use underscores. Supposedly it can be told to accept underscores if you're not mixing styles in a file but I never figured out how.
sorry, I thought you were referring to this [wget](https://www.gnu.org/software/wget/). I never tried the python one, will try it out and see if the download is fast. 
If you're using Vim for writing python, try out python-mode for it. Note that, as with any linter, you'll need to tweak the rules away from the crazy defaults. It's well worth the time and effort, though! 
That code is for Ruby. &gt; Bundler makes sure Ruby applications run the same code on every machine. What's the Python equivalent? When I looked it up with Python, I found something with 12 commits that was last updated in January 2012. It's old. As such, I guarantee it doesn't support wheels. Wheels are the new recommended way to package eggs that supports binaries that I had never seen a package actually use in the wild (e.g. numpy) until about a year ago. https://pypi.python.org/pypi/bundle/1.1.2 https://github.com/ask/bundle/ https://www.python.org/dev/peps/pep-0427/ Maybe I'm not being clear. The current tools for Python are deficient. They could do less and be a lot better. I think that's inane.
You can do that in R now too, even with just RMarkdown.
I remember [this thing](https://github.com/google/google-api-python-client/blob/master/samples/analytics/core_reporting_v3_reference.py) confusing the hell out of my editor. Good times...
Lol
Just wait a short while (a month or so) and they'll be available.
This was my thought as well, but I bet it was a value judgement. Notice the 2nd micro usb, you can get a micro usb to full usb, and plug in a wifi dongle. Unfortunately, those converters are 5-10 dollars as it is. Woulda been better I think if you could choose @ checkout if you wanted HDMI out, USB, or ethernet. 
That was my personal thinking of how I would do it. Would be really cool to see in the future the ability to customize the available ports. I'd really rather have usb, ethernet....or built in wifi out of the box than HDMI out. It'd be pretty easy to setup the SD card on another PI/computer, then move it to the purely wifi pi when it's ready to just auto connect to wifi.
My company's internal standard is 100. But even then, this and ours are style guidelines, not hard and fast rules. Exceptions can be made.
This is so creepy.
Did they change this recently? I could have sworn that exceptions were flat out unwelcome.
And i could have sworn they used two spaces for indentation rather than four. 
Yeah, I know that page. The problem is that these are selected cases and by far not a complete reference. If you click on any function name on that page, you end up at the C++ function reference, which differ from the python functions.
It's stupid to use 80 as a limit because that's what some ancient terminal did, we have larger screens now. That doesn't mean it's a good idea to use the same approach though and fill up a modern screen with a single file or that the 80 limit is bad. I think 80 is still a good limit today, just for different reasons. It allows good workflows even on a 11"-13" display, which many people are working with. You can comfortably display 2-3 documents side-by-side this way. Invaluable for doing merges, writing tests, having documentation on screen and keeping a terminal next to your editor that can display code without wrapping. Also at 80 characters and beyond it makes sense to reconsider the complexity of your code and whether it doesn't make sense to express yourself in a different way. You might be able to increase that limit slightly but you can't go much bigger without losing sight of the tools you're working with, telling people without desktop-size screens to go fuck themselves or making it easy to write overly complex code.
`tzinfo` is not a metaclass and a metaclass isn't like an abstract class. 
Also [PyLama](https://github.com/klen/pylama). 
And the award for "most appropriate username for this post" goes to...
&gt; oh it shows imgur links.. what could that be *click* &gt; http://imgur.com/a/7B7w9 ^NSFW great.
Obviously. You will agree though that the fact that most of the most popular languages (c, c++, c#, java, javascript, python, matlab) use dots as subobject dereferencement instead of part of the name makes it look really weird for most programmers by default
There's two areas where I find pylint can be difficult to keep happy. First is the code complexity measures. It doesn't like code that has branches in it, even if those branches are short and shallow (i.e. not nested). Code like that isn't nearly as hard to understand as large blocks, deeply nested, but it seems to score a branch the same regardless of context. Second, I've seen it get mouthy about class methods not existing because it's been unable to work out the type of an object correctly. Apart from those I think it's a great tool. Far better than pyflakes (and so by extension flake8)
Try pylint -E. Errors only mode
&gt; Sickit Sick.
Maybe you need to filter the ones with urls? &gt; I'd like to submit to the drawing lol.http://imgur.com/a/7B7w9 (nsfw) 
Normally there's far more comments that are regular compliments. I think the onslaught of Thanksgiving posts have ruined the ratio a bit.
That is a pretty impressive schlong though. Nohomo
In addition to the other suggestions, register as a developer on AngelList. It's fairly startup centric, which can be good or bad depending on what you're looking for. 
That one not maxing out your connection is actually even weirder since I've managed to saturate a 1Gbps connection with it a few times already.
"You look delicious. Please sit on my face" Instructions unclear. Phone screen now broken.
Stop using the Werkzeug built-in server. Now. All it would take is for one person to send a siege/AB request down and your entire server gets blockaded.
It must have changed. I remember that, too.
Yes, I agree that the tools for python are deficient, although there are some solved that wheels does that bundler does not such as the binaries being shipped since bundler does not handle that. I'm not sure what the equivalent in python is. When I was doing research, I ran across [pbundler](https://github.com/zeha/pbundler) made by a developer in Vienna. I talked to him a bit over twitter and it sounded like he wasn't working on it himself anymore because his work didn't need it. The things that I find lacking from requirements.txt are this: * no sub-dependency conflict resolution or notification (e.g., you need package A and B that both have a dependency on package C, but the version used by A is 1.0 and the version used in B is 2.0) * needing to specify specific versions (`=`) to ensure that everyone uses the same code when they install from requirement.txt I believe the `bundle` python package you linked doesn't do what bundler does.
&gt; I originally thought that a datetime object represented a single point in time [The Problem with Time &amp; Timezones - Computerphile](https://www.youtube.com/watch?v=-5wpm-gesOY)
OK, now using gunicorn.
A limit is a good thing. 80 is way too narrow though. There are way too many "standards" based on shitty ancient terminal limitations that do not matter in 2015. No one's actually using a VT100 anymore. edit: Personally, as someone who uses 1080p displays for the most part, I like 160 character terminal width. That ends up going around 80% of the way across my screen, which is about where I tend to set my web browser windows as well for readability. If people insist on matching an old terminal standard we could go with 132 instead, that'd be fine with me.
Comments with 'http' now removed ;)
I thought the same thing for a while, but I don't mind it too much since everything in R uses functions instead of method calls, and because I can just look R code and immediately know it's R.
Yeah, I saw that. It's checking if 'http' is in the body, so.... that shouldn't happen. Weird.
Thank you for noticing.
I post on dice.com only and let the jobs come to me. 
When I said readability, I wasn't talking about the "standards" of the terminals. I was referring to text readability. If you google "line length readability", you will see a bunch of articles talking about the optimal line length of text. I tried to find some studies to back up this wisdom, but nothing came up.
So much bullshit.
[Redis maybe?](http://redis.io/)
&gt; Oh yes, I have room and would love to taste you. And have you for the rest of the week too. I guess that's a complement.
We'll see :)
My first "compliment" simply said, "Hi". My next one says: "Please gender tag your posts (example -- [f], [m], [?] or [cd] -- rule #6 in the r/gonewild sidebar). Untagged posts get auto-filtered, so you should delete and resubmit. Cheers If you have problems reposting a valid picture try verifying your email address with reddit at https://www.reddit.com/prefs/update/" ... that's a strange compliment. Anyway, I'm envisioning /r/gonewild finding out about this, and trolling. Which is rather amusing to think about anyway. Think about how the people posting submissions in there would be unaware and then their comments ar full of even weirder shit than normal. EDIT: Oh god. And the next one was, "Only question is which hole first?" D-: No thanks!
something something sharpie...
For some values of wet dream.
For a moment I thought somebody had stolen Popeye's forearm. 
I struggled with this a lot. If you just need a simple Cartesian mesh, I would just generate it manually yourself. I think there are two decent options that are both painful to use -- PyDistMesh is great but I've found the results really good, but it can have weird situations where the algorithm won't terminate. I also remember it being very difficult to get working on Windows if that matters. I also had a lot of luck with the Triangle library, which is written in C -- I think there's a Python port of it but I don't remember what it's called off the top of my head. I ended up generating the meshes using Triangle in C from the command line and then importing them via a NumPy array. Also, I think some very basic meshing routines (Delaunay algorithm) are implemented in SciPy. If your meshing needs are relatively simple, you can generate points yourself and then mesh the points using the simple Delaunay algorithm in SciPy. Hope this is helpful -- feel free to PM me or reply here if you need more help.
Hah! Gonna tell this one to my girlfriend.
Next step..... Pipe through cowsay to generate login banners
Definitely, please! These are great and very fun to watch.
Don't forget iPython, er, Jupyter Notebook
Thank you for subscribing to /r/buttsharpies!
Seems like overkill for this, an in-memory cache works just fine.
&gt; So in my dream there was a dude living in my house who treated me like shit but I still found him attractive. And after ages he mentioned that he wouldn't mind fucking me so I was over the moon but discovered I had no condoms! Everything was ruined. But then I fell asleep in my dream and got transported to a Pokemon training gym &amp; I had to go through task levels that were al sexually orientated and when I reached the end I was granted a condom which I would find in my fridge when I woke up. I ended up waking up in my dream, finding the condom &amp; had just started sitting on hot dude's dick and then I woke up for reals. wat
`while [ 1 ]; do say $(curl -sk http://compliment.b303.me) -v "Zarvox"; done;`
You wandered into the wrong neighborhood, kid. *[flicks /u/TheSwitchBlade intimidatingly]* ...Wait
Sick-it-- It's a library that allows you to easily configure your dog to attack things.
/r/toastme might be a bit better here, if you are serious. ;)
Thanks, to whoever is trying and failing to SQL inject me.
Thank you for your comprehensive response. If you were to advise essential topics to learn, what would they be from this [list?](https://github.com/open-source-society/computer-science#curriculum)
I don't know which is creepier. The results that come out of this program, or the fact that OP seems to sincerely think gonewild posts are a good place to find compliments.
&gt;You look maybe a little top heavy. Nothing at all wrong with that
&gt;Please use a gender tag ([f], [m], [?] or [cd]) in the title of your posts (rule 6 in the r/gonewild sidebar). Untagged posts generate reports and get filtered - titles cannot be edited so it is best to delete and resubmit. Cheers If you have problems reposting a valid picture try verifying your email address with reddit at https://www.reddit.com/prefs/update/ I don't feel very complimented.
I like the idea, but my first try gave me this gem: &gt; fuck off, lol
You're a few more lines of code away from every Tinder conversation ever
&gt; You look amazing and I can't believe you have so few likes. Is it me or are you way more then sweet? Here's a replacement compliment with our sincere apologies. Thank you for shopping with B303 Compliments.
Where I worked GIS and their databases seemed like a place where data just sits rather then analyzed and aggregated to anything of actual value. Processes that should be able to be done easily in GIS sometimes can’t even be done at all, for example area partitioning, point comparison, and then summation to get densities. Any value from GIS at the end of the day is data analysis displayed on a map and should be treated as such, all the “tools” really just obfuscate from the whats really happening. Often times the tools are sort of just sandboxes that can’t be chained together, you can’t do higher level processes on them, and if they can be it feels like a hack. Say I have a list consisting of a starting and ending point and attributes associated with it. I want to route that get the alignment (GIS can do that) break that alignment up into subsequent parts or segments that the GIS database already has, and at the end of the list take each route and its subsequent segments associated with it and the attribute associated with that specific route and sum all the attributes of like segments (sort of folding overlapping sections of routes on the map over one another) to produce a heat map. Thats a real world problem that GIS has a tough time doing. I could be wrong though, if so I’m sure I’ll find out. I also just hate the GUI and viewing stuff is 10000x times more consumable on Google Earth then GIS.
I'd put clothespins all over your upper body, each with a filthy word written on them, then fuck you hard so that they all shake as you sway back and forth.
https://www.python.org/dev/peps/pep-0008/#method-names-and-instance-variables
What are you talking about? That's an awesome compliment. I think if I showed my tits on /r/gonewild, a.) People wouldn't care, because I'm a guy, and b.) that would be one of the best compliments, alongside "wonderful shading of the areolae".
Yeah, you're right. I mistook it for [pylama](https://github.com/klen/pylama). I knew there was one linter that combined the lot of them but forgot which one it was.
I use numpydoc for documentation, especially when working with robots or other hardware. It's much more powerful than googledoc.
redis is in-memory
&gt;All you're good for is sucking cock. Dumb slut Well that wasn't very nice
True. I meant that the global array in the app memory works fine, I think it's a bit silly to use an external cache for something this simple.
[&amp;#3232;_&amp;#3232;](http://i.imgur.com/2D3wKbl.gif)
You don't need a Webserverice for everything bro
I thought I might chime in here and say that Blender is a possibility. I hadn't heard of meshPy and I'm glad for your post. I intend to look into it. I wrote myself a little addon for blender that uses python to send a mesh from blender to tetgen and read back the results into blender. [It is only a rough experiment](https://github.com/dustractor/miotet) with very little interface added but it could be useful if you need a template for getting data from/to blender. Like I said, I hadn't heard of MeshPy, and now that I have, I may revisit this old project and make it to use that instead of a precompiled binary of tetgen. edit: there's also [this](https://github.com/kromar/Blender_Addons). Looks like somebody actually put some work into this one (and within the past week)
I'm not sure this question makes sense. If you have performance issues with unity games on the rapsberry pi, how exporting to python could solve the problem? Besides, doesn't Unity export to native GNU/Linux games? You should try to run your Unity game at least once before considering changing technology. (as usual, sorry for my english)
GIS is a discipline (geographic information science/systems), not a product - maybe you were thinking of ArcGIS? If so I feel the same way, and may well end using this at work. Thanks!
Ya as we speak I'm writing a I'm loading a shp file containing a roadway database into goole earth saving it as a kml then parsing outing the attributes and coordinates and putting it in my own file structure all as flat csv files, its a little (a lot memory wise) inefficient, but data is very easily mutable and I banged out the code in under an hour. (so far) I may have to post a picture of a route layer in a second you never know. I just want to see what its like at scale an experiment if you will. 
&gt; so ummm black dudes yes or no? ok...
I'd look at ogr2ogr, it can take almost any geospatial file type and convert it to any other.
&gt; doesn't Unity export to native GNU/Linux games? Only for x86.
Also [Falsehoods programmers believe about time](http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time) and [More falsehoods programmers believe about time; “wisdom of the crowd” edition](http://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
ctypes will not integrate well with setup tools deployment, or will it? I rarely see it in packages for whatever reason. 
Google Earth and KML are my go to format when I need to check any spatial mucking around I do. Google Earth and Google Maps(now that they support KML better) are really great tools to bring GIS to a wider audience.
Well, I am talking about stuff like automating boring and repetetive tasks I have to do (Go to a website, download latest item etc.)
Found this useful. Thank you and Forking.
What about XHP? http://codebeforethehorse.tumblr.com/
'from spam import eggs' is fine in OpenStack. People do that everywhere. 'from spam.eggs import Egg' is not fine in OpenStack. People do not do this. Notice that Egg is actually a class, not a module.
pandas numpy scipy
numpy, scipy, pandas, matplotlib, seaborn, jupyter notebooks, rodeo IDE, and still learn R or know how to call R from Python via rpy2, only because R will probably have a statistical package that Python doesn't have. Take a look at [this]( http://www.mitchcrowe.com/learn-data-science-the-hard-way/) for more ideas.
sounds like a GIS problem to me... python has many map making libraries... you can use matplotlib basemap, shapely/fiona... or just do your work in qgis or arcgis. 
https://google.github.io/styleguide/pyguide.html?showone=Naming#Naming
You're probably talking about this then https://code.google.com/p/soc/wiki/PythonStyleGuide#Naming_convention. Although it's last update is 2 years ago and it differs very wildly from both pep8 and google's own updated style guide. If I were someone learning right now I'd just go with the updated one or pep8.
Line 4, why do you assign a variable that you don't use?
Automation isn't automatic if it needs user interaction. I'd suggest keeping GUIs separate from your automation scripts. It's a good rule of thumb to keep the number of "moving parts" (i.e. libraries, modules, classes, etc.) in your automation to a minimum: this makes it easier to maintain and less likely to fail. As for libraries, languages, etc. this is all highly task dependent. Python is a great framework for doing automation; it's the go-to language for everything from QA automation to IT and Devops automation at the companies I've worked for...
Name your variables better
I often replace the anything that looks like following code with a generator for flexibility of being able to stream large lists: x = [] for thing in anything: x.append(thing)
Don't be so sure. I put my money on Intel to figure this out as they are the only ones who ever could. They are well aware of this small dilemma. In regards to my project, this is all free. All computers involve theories that work in practice. It's not all about books written by people who know the facts of the practice. I'm just here to make more theories people can play around with.
Everything in this project I created is open source.
Hi /u/Decker108 I'm still learning Python and it's syntax but I have a question on your script, which I did some google search but not sure exactly how to find it. First, you used the variable "result", which looks to be the data from your file you were parsing. However, you do not use it in the script. I sort of assumed that it would have appeared on line 8 in your for loop, instead of the variable g. What am I missing here? Second, on line 8, you have "for _, _, obj in g:". Normally I have used for loops with only one child variable. For exmaple: for fruit in fruits: In your code you have additional place holders in the beginning of the for statement, what is happening here? Thanks!
Jupyter notebook, pandas, scipy, numpy, and matplotlib. And then some. These tools make number crunching ridiculously simple, as well as easy to share your results. Want that output in a pdf or html file? That's like... 3 clicks. Or you can share the notebook with them so they can make changes and fiddle with things themselves. I can't recommend Jupyter notebooks enough.
Commands|Function :--|:-- /u/JewBot9K add subreddit|Add a subreddit to your list. /u/JewBot9K del subreddit|Remove subreddit from your list. /u/JewBot9K list|Sends you a private message of your followed subreddits. /u/JewBot9K code|[Replies with this link to the github repo.](https://github.com/JewsOfHazard/update-me) /u/JewBot9K foobar|Replies with this table.
Wow, that looked really neat. Will def (pun intended) give it a try!
I haven't looked at the actual data he's reading in, but taking a very quick look at the script, this is what I think: 1) 'result' isn't used, but the parse function is necessary and returns a value. It is straight out of the library's [quick start](https://rdflib.readthedocs.org/en/stable/gettingstarted.html). 2) If what you are looping through contains a nested structure, like a tuple you can unpack them into variables. In this case he doesn't care about the first two items so he gives them both the same variable '_'. A simple example you can easily run is: some_list = [(1,2,3), (4,5,6), (7,8,9)] for a, b, c in some_list: print(a) print(b) print(c) You'll get: 1 2 3 4 5 6 7 8 9 NB If you are using python 2.x replace **print(a)** with **print a**, etc.
Thank you for sharing! I've never ever heard of Tabmix Plus, or RDF files (although perhaps I've been living under a rock) but I just came here to thank you for posting your work online for the next person who gets into this tricky situation. 
Matplotlib is more powerful than you might think. In notebook use: %matplotlib notebook To make plot interactive. If you have styling that you tend to like to do create a [matplotlib style file](http://matplotlib.org/users/style_sheets.html) and add what you need there. Yes, it's not all pointy-click, and it never will be; but then none of the other options (plotly, bokeh etc.) are either.
/r/learnpython
welcome to the beautiful world of [floating point arithmetic](http://floating-point-gui.de/)
Settings -&gt; Editor -&gt; Colors &amp; Fonts.
This is nice, cool idea. One thing though: When I started working with python I was always wondering why PEP limits line length to 80 and I was against that saying that it is too small but nowdays when I see code that I have to scroll left and right small part of me dies.
&gt;By theory, SSD's should exceed the maximum BANDWIDTH of 6Gbps (or 600MBps) You can't even fucking convert Gbps to MBps properly, and yet we're supposed to believe you've somehow magically discovered something? 6Gbps = 750MBps not 600. FUCK OFF.
I like that you used Guake for the whole thing 
Well, Guake is awesome.
Just wondering why you want to use a gui to change those things on the plot? Matlab has those features but I never used them, not even once. I'd much rather have everything in a script so my "style" is more reproducible. Once you get a lot of the defaults setup the way you like it, you use the same script over and over.
Nice! What's your vimrc for highlighting the current line? :)
Sweet, thanks :)
If any of you guys do end up using it feedback would be greatly appreciated! 
Ok I see what you're asking, let me rephrase: What I'd like is to change the things on the plot with the gui, and then have the ability to print those changes/settings out somewhere so that I can put them into a script (this is what Igor Pro does, each time you drag something on a plot or change a setting it prints it to the command history so that you can copy and paste it into a script if you like). Then I can run that script over and over, sure, but if I want to make small changes to it I can just do it on the graph directly with the gui instead of looking up the commands. The other thing I don't like about matplotlab is that you can't drag and click things -- for instance, if I want to zoom in or out of the data by a few pixels I need to type in and try different axis range settings with matplotlib until it looks good -- and this is sort of a guess-and-check procedure. It's much more straightforward to just drag or zoom in on the data or axes until it looks the way I want. Finally, with matplotlib you either have to memorize the commands, or look them up each time you use them. I haven't memorized all of the color and dash/dot/line commands in matplotlib, and when I was more heavily using matlab I didn't do it then either. I don't even remember how all of them look. With a reasonable gui you can pick the colors from a grid as they're shown to you and pick the line styles from a list as they're shown to you (these are just a couple of examples). Having a gui removes the guessing and saves time looking things up.
Touche, that's a reasonable request.
So...?
I'm sorry I don't have any real advice. Just wanted to stop by and say your lil cousin rocks and you too for teaching him. Maybe you could show him [CodeCombat](https://codecombat.com/) to learn the basics of the language and every week or so arrange a day on which you can help him with some concepts he didn't fully grasp using some of the tools you mentioned (Don't know if git thou, something more "live action") When he's comfortable enough, make the leap to making some games. Maybe remaking some classics. EDIT: Some words and stuff
I'd suggest the Raspberry Pi don't they have some game coding example on there? (I've never looked at them) I own two raspberry pi 2's and there really fucking cool. I wanna say theres even a a Minecraft written completely in Python on the standard Raspbian flavor/distribution of linux it comes with! Seems like a perfect example to me. link: https://www.raspberrypi.org/learning/getting-started-with-minecraft-pi/ He may need a pi himself though :(
Thank you for following up. I appreciate that. I will take a look at Celery thank you for your response!
With these Flask being another layer how scalable is it going forward? I was also wondering what do some of the larger companies that need to send tasks via python work on sending it through their web console.
A lot of people have been asking for videos on where I talk about more stuff such as this. I should probably make a video that discusses everything. I think I'll make that the "Channel Cover Video" or whatever it's called. Discussing who I am, what the channel is about, and what I do. Also the .vimrc that I use because that seems to be interesting to people. 
Not very related, but sort of. Which services or websites would have people who could use joinme and conference calls to go over code or talk over problems etc? I use a lot of pandas but I'm probably not so efficient. I literally Googled how do I do this specific thing and found code examples and slowly I built a lot of workbooks ( which has been effective) . But I want to get better. 
I had a lot of tabs (80+) and some of them were things I had saved to read later. If I didn't recover them, I would probably not remember the names of the websites.
I admit I have had very little experience with generators. Should I open the file for iteration inside of it or send in a file handle? Edit: As /u/Atrament_ pointed out, the list-building loop could be replaced by a generator. I've updated the gist.
A remnant from the library tutorial code, I'll remove it.
I did mean python beginner, as you wrote, but I didn't realize we were having a pissing contest. I've only been publishing in the big 5 using python for a couple of years. Guess I should check out igor, it sounds like a treat.
Man ive been seeing these a lot lately. Could you make a tutorial or guide to one of these? I'd like to see how you think and go about it.
Why..?
Tableau extract api is only for 2.7. Just create a mapping of dtypes to tableau types.
Is it possible to find some kind of theme to import? Since its one hell of a work to add each color 
Fedora has long (always?) been a bleeding-edge distro. IIRC, it serves as a testbed for RHEL.
Can you provide context as to why you want to do this? The obvious solution is to run node.js and call your functions via HTTP from Python.
Ok. It was a badly formulated one word question. I am currently at the starting page of teaching myself python and most of the source code I study is in 2.7. Is it advisable to make the switch to 3.5 for me? Or should i just go along with 2.7 and switch to 3.5 at a later stage when it is more mature?
Do you just add that at the end of your file? Like instead of to_csv you would import the api and export to .tde? Is there a way to switch to 2.7 within the same notebook that's running 3.5? I would rather not go back to 2.7 fully just to make tde files. 
No, I had to create a dictionary of mappings. Then row by row add it to the extract. No idea about Python 2 to 3 stuff. I would like to use 3 but there is still so much not ported over.
Python 3.x is the future. The 2.x and 3.x series are similar enough that it will be easy to learn 2.x afterwards.
Why are you doing that when it is so obvious it is dead technology? If you bought a new computer would you load DOS 6 on it? Any beginner who starts with Python 2 is simply incurring a learning debt to be paid in the future. You seem to be struggling with your decision to learn Python 2 - it was a bad decision. Now you need to start paying off the debt of that decision and start learning Python 3. Your effort so far is not entirely wasted no but there's absolutely no point in using version 2 - why are you doing it?
Two functions that I find very useful in my scripts (Similar functionality to `sh` and `fuzzywuzzy` packages): subprocess.call &gt;&gt;&gt; subprocess.call(["ls", "-l"]) 0 &gt;&gt;&gt; subprocess.call("exit 1", shell=True) 1 difflib.get_close_matches &gt;&gt;&gt; difflib.get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy']) ['apple', 'ape']
see https://www.reddit.com/r/Python/comments/3pzf1f/teaching_python_to_middle_school_students_advice/
Teach him git. In fact, there's a nice GUI version by GitHub that seems pretty intuitive. http://desktop.github.com/
At first I was delighted but looking deeper into the code I noticed that semaphore actually executes the ansible executables. Which is obvious because it has no Python code, only JS. What I'm trying to do is create an interface that makes use of the ansible library to run playbooks. It might be a small detail but it's important to me. 
Unfortunately I don't know of any. I'm using the included Darcula theme anyway.
Check out [turtle](http://openbookproject.net/thinkcs/python/english3e/hello_little_turtles.html): i helps with learning concepts like loops and basic geometry and is real fun to experiment with. The great thing is it creates an app window with a single line and you can immediately draw on it and visually see the effects of your code on the canvas.
I love seeing how other programmers work :)
BTW, invaluable python vim plugin I found: https://github.com/klen/python-mode More like collection of plugins integrated into one, but it's very convenient and amazingly useful. It adds linting, refactor tools, opening documentation, and a ton more. It's awesome to be able to highlight a few lines and extract a method, and it seems very smart about it as well. Turns vim into a full fledged Python IDE minus a debugger, but you can always use pdb/ipdb. Something to check out if you haven't seen it already.
asyncio
I made a virtualenv, but the library isn't in the list when i click the + sign.
LPTHW is wrong, and at this point irrelevant.
HOw about IPython Notebooks for a collaborative scratch pad: http://ipython.org/notebook.html
you should install it with pip instead of simply placing it in the project/venv folder. pip install git+&lt;git link&gt;
Does this work on a Windows computer? pip install git+https://github.com/intel-iot-devkit/mraa ^ SyntaxError: invalid syntax
Yes, but you don't see people developing new dos-based software. That's the difference.
I find a lot of people miss out on collections.defaultdict
And collections.namedtuple. Psst, it's actually collections.defaultdict, not collections.DefaultDict. However, collections.OrderedDict *is* CamelCased. That inconsistency bugs the hell out of me.
functools (especially functools.partial)
Pip for windows says "Cannot find command 'git'"
collections.namedtuple
I said namedtuple too. So underrated.
&gt; `subprocess.call("exit 1", shell=True)` What's the difference from `sys.exit(1)`?
I'd love it if people were to just let WindOS X die.
[Image](http://imgs.xkcd.com/comics/exploits_of_a_mom.png) **Title:** Exploits of a Mom **Title-text:** Her daughter is named Help I'm trapped in a driver's license factory. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/327#Explanation) **Stats:** This comic has been referenced 976 times, representing 1.0840% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cxgq8pa)
The examples I gave were straight from the Python docs. That example you asked about was just to show the return value of the `call` function. Anyways, `subprocess.call("exit 1", shell=True)` opens up a new shell and promptly exits it - but the script keeps running, while `sys.exit(1)` obviously terminates the python script that called it.
Thanks..finds really helpful :)
IIRC, namedtuple is written in Python.
I use functools.partial way to often :) Should probably try out a real functional programming languages some time. Also, reduce() and map() of cause. Only that my coworker forbid me to use reduce() because he never understand what it does.
Are you saying that commodore 64 isn't legacy because new software is still being developed for it? How about cobol. It's as legacy as it gets and people in the industry still swear by it
&gt; Also, reduce() and map() of course I disagree. Map should be avoided in favor of list comprehensions (or generator comprehensions). Simple calls to reduce() are often their own functions already (sum(), any(), all(), etc.). And complicated reduces are often hard to read and would be better off as explicit for loops, as [the BDFL has remarked](http://www.artima.com/weblogs/viewpost.jsp?thread=98196).
depends what you mean by factory. `namedtuple` is a function that returns a class, whereas `defaultdict` is a type.
It has not been removed. It's just not a builtin function anymore. You can try for yourself: from functools import reduce from operator import add reduce(add, range(1, 11)) # 55 
I would suggest supervisor. It is quite easy to use and supports nice features like autostart
This one's great, you can call modules as command line arguments if you pass the -m parameter to python: echo '{"json":"obj"}' | python -mjson.tool As long as you don't have to mangle your quotes its very useful.
You can save yourself a couple of lines of code (by obfuscating them) when using a collections library like Counter or defaultdict, but two items from the standard library that open up new functionality are frozenset and frozendict- they make an immutable version of the dict or set you've created. The draw is because immutable dictionaries and sets can be hashed, so they themselves can be used as elements of a set or keys to another dictionary. Sometimes getting a set of sets or dictionaries is really useful, without going through the mess of walking across your collections by hand.
It's quite possible you just never run into the need for it based on what you use Python for. I use it constantly for partially applying arguments to async callbacks. Ie. I can have three different subscribers use the same callback, but partial lets me include which subscriber is calling the callback.
It's interesting isn't it?
Edit sorry misunderstood. `namedtuple` is a function, `defaultdict` is a type. functions != types.
What an incredibly confusing and arbitrary convention. 
[textwrap.dedent(text)](https://docs.python.org/2/library/textwrap.html#textwrap.dedent)
How do you tell if a string that was passed into your function has variable substitutions? 
The second one is valid. The first one would have to be written something more like this: company_name = models.CharField(max_length=128, blank=True, null=True, validators=[validate_company_name, validate_something]) Also, ask questions at /r/learnpython.
I can't exceed the limitations. The best I can do is work around the weaknesses. If I am managing to do that the limitations are much higher than what others say, I'm just doing it in a different way.
Sometimes I have scripts where I need to print to stderr a lot, and it's nice to make a specialized version of print just for that: print_stderr = partial(print, file=sys.stderr)
indeed it is; I remember reading the change log …it annoyed me more than it should. It now needs to keep the name for backwards compatability within in 3, let alone 2.
Yeah! Though it would be even better if it also removed the first line (and required it to be empty/whitespace), instead of requiring a backslash. I've recently implemented the same function in C++ (since we now got multiline/raw literals as well) and did it that way, because putting something on the first line and then dedenting relative to line start just doesn't make any logical sense. Also I'd say that this is an actual hidden gem that pretty much nobody knows about instead of something that any professional Python developer should know like itertools and many other suggestions in this thread =(
The `.strip()` would also strip the trailing newline, which I think is not what you want usually (as per UNIX convention that newlines are terminators, not separators). So it's better to just open the string with `'''\` instead (or write your wrapper that removes the first line).
It's interesting you bring that up. I've thought about this before, but I found that I am nearly always passing these messages to `print()` eventually, which adds the trailing newline. Also, I don't add trailing newlines to single-line strings, so this makes things more consistent for me.
Wasn't all that info in your history anyway?
Faut bien parser la phrase.
Certainly seems nifty, but I've never really used multi-line strings for anything other than docstrings. For multi-line text, I tend to default to this: text = ( "First line of text that will " "remain unbroken unless a line break " "is entered." "\nLike so." )
If I call a function a lot of times where the same parameters are being used a lot. Let's take an I2C bus. If I'm always going to write to device `0x32` I can do. device_addr = 0x32 from functools import partial dev_write = partial(i2c_write_16, device_addr) dev_write(0x12, 0x1) # Write 1 to register 0x12 dev_write(0x13, 0xFF) # Write FF to register 0x13 ... See how the function call is much shorter?
That makes sense. I on the other hand was using them in unittests for the most recent example, and there I needed my newlines. For more examples, if your multiline string is something you want to write to a file or something, you want those newlines. Or if you want to concatenate such strings. But if you want to insert a string into a template, then maybe you don't want it to have an extra newline, since you already have them in your template. Programming is hard, let's go shopping! **edit:** though in context of making a New and Improved `dedent()` in particular, I think you certainly shouldn't strip the trailing newlines, because if you don't and want to not have a newline it's trivial to just put the closing `'''` on the last line, while if you do and do want a newline, things get ugly.
The first style (after it's been PEP-ified like /u/ingolemo suggests) leads to large swaths of irregular whitespace around the left edge of the code, which IMO impacts readability. Therefore I'd prefer the second approach.
Jeff, the pandas developer said it was out of scope for pandas unfortunately too
Thank you so much for this example. I will do this from now on!
Yes, but I'm pretty sure only Python 3 comes pre-installed, since none of the the bundled packages should depend on Python 2. However, as soon as you install something that depends on Python 2 it also gets installed.
I saw the video. 20 minutes of jumping around in vlc with no sound. Post a link to the repo.
I've worked with a few kids with [Snake Wrangling for Kids](http://www.briggs.net.nz/snake-wrangling-for-kids.html) in the past - it's a bit dated, but is still good. edit: I've also heard good things about [this video](https://www.youtube.com/watch?v=HgpsmOpZfD4), but haven't checked it out myself.
Other than allowing humans to be able to read the code they write what exactly is wrong with threading or gevent that necessitates asyncio's existence?
The xmlrpclib client and server are an excellent quick way to add basic IPC without introducing any external packages, especially if you use the threading mixin with the server object.
&gt; There isnt simple toolkit like wxpython that can easily export exe, pkg, deb whatever....all this shit for people who use different OS', its a program for people who are disabled. Stop whining and run the available options for the platforms you're targeting.
 
No habla espaniol. 
It does. Fedora -&gt; RHEL -&gt; CentOS
&gt; allowing humans to be able to read the code they write 
I don't really find much of a point for `shell=True` except for quick-n-dirty throwaway scripts. Besides the obvious vulnerability, there's also the fact that you can't be sure that the shell is actually bash, dash, zsh, ksh, tcsh, csh, or even Command Prompt (!). So it's usefulness is rather limited. You would likely get more consistent results if you simply ran subprocess.call(["bash", "-c", "echo hi | grep h"]) 
one final suggestion (which /u/tonnynerd mentioned): instead of doing the string concatenation like you're currently doing, append them to a list, and then join the list at the end. the reason for this is because strings are immutable, so when you say 'result += char', what python is doing is creating a new string object that is the concatenation of result and char, and then rewriting result as the new object. then you're doing that in a loop, so you're creating (potentially) a lot of strings. python can handle the list-join approach more efficiently (although the strings would have to get fairly long before you'd notice much of a difference). here is a [crude graph](http://imgur.com/nMOz4js) of the difference between the two methods, with the x-axis being the length of the string, and the y axis being the amount of seconds. the bigger values are the concatenation method and the smaller values are the list-join method. so if you do the list-join method, and you had a string 10,000 characters long, you'd save something .003 seconds, which admittedly is not a big deal. but it isn't bad to learn more efficient ways of doing things. also note that the times here are reflective of the logic in your function (using a for loop to test each character for vowelness). if you use generator expressions + the join method (blue line), you get a [slightly better version](http://imgur.com/sDqHFDk) (efficiency-wise, and it's only one line). and if you completely ignore the vowel logic and just focus on the joining/concatenation methods themselves, the [difference is more pronounced](http://imgur.com/DuM0Ejy). in this graph, the red line is repeated concatenation, the green line is appending to an list, and the blue line is pre-allocating an list to the right size, which should give a slight efficiency advantage, not sure why it's not here; maybe python internal optimization).
I have used difflib a bit and the larger the data set the longer it takes (naturally). I used it to check misspellings in city names based on a list of city names in the US. it was ok, but I wouldn't use it for that again. When you have that many items in a list, the possibility of false positives increases, which decreases it's accuracy. 
No.
pathlib was new in 3.4 right? probably explains why not many people are familiar with it yet.
You don't need python to do this. In chrome go to the page that has the saved password, then highlight the password and right click. Choose 'Inspect Element' and change the input type to 'text' and hit enter. Once you do that you will be able to see your password. Hope that helps.
I find that generator functions scare people more than they should. Python 3 does such a great job of moving generators into the spotlight I wish that was reflected more in 3rd party code.
Thanks so much for this! I haven't tried it, but I've written a shitty version difflib.get_close_matches() of my own and this has to be better!
There is a JSON api to get either the wiki text or the html text.
Yeah that's what I was talking about. Doesn't return it as JSON content like say, Wordnik's API or Urbandictionary's API. It looks like [this](https://en.wiktionary.org/w/api.php?action=query&amp;titles=overflow&amp;prop=revisions&amp;rvprop=content&amp;format=jsonfm)
Can't believe I never thought of that. Normally I just have a `root_path` or something defined somewhere and then use `os.path.join` with that. This looks cleaner.
I'm pretty sure `frozendict` is not in the standard library. It's not in the [documentation index](https://docs.python.org/3/genindex-F.html). All I could find was a [rejected PEP](http://legacy.python.org/dev/peps/pep-0416/).
I like the layout and formatting that you use in your blog. It's clean and easily readable. What do you use to create it?
Yes, but it was difficult to find as the history events were spread out over 3 months. It would take a lot of time to manually dig through thousands of events.
Some time I read lines in python and they are so damn overcomplicated.. One contractor told me ones: &gt;Maybe python developers make it look complicated to make sure they cannot be replaced easily.. or to show they can;) ps. I am not programmer, I am QA ;) 
The former is interactive. (beyond that neither do I) 
Though /u/pvkooten is right that it was demoted because it was considered confusing. Guido has said that whenever he sees a `reduce()` in code, he has to stop and mentally rewrite it to a loop to work out what it does. It's not as easy to understand as `map()`.
I'm speaking from memory and not from experimentation but I remember reading somewhere that using a list instead of a string saves on some conversion step from str-&gt;list when you do the call to __contains__.
I'm sure there's actual useful improvements, but `ipdb` has pretty colors and cleaner output. `ipdb` is part of the `ipython` project.
Python rules for general data analysis with pandas, numpy, scikit, etc. But for statistics, R is still king by a long shot. Python is slowly catching up but R has a *much* deeper and more thoroughly tested archive of statistics libraries than Python: https://cran.r-project.org/web/packages/available_packages_by_name.html The question is: are you analyzing data or doing actual complex statistics? 98% of the time you'll want Python to work with and clean the data, do some preliminary analysis, visualizations, etc. Python is just simply better for this stuff a it's a general purpose programming language. The other 2% of the time, bring the data into R to do the complex, specialized stats stuff.
In terms of proven libraries for actual statistics work, R has Python beat [by a long shot](https://cran.r-project.org/web/packages/available_packages_by_name.html). If by "statistics" you simply mean "doing stuff with data" then Python is just all around more practical, useful and easier to work with.
/u/desmoulinmichel is saying you don't need to call `partial` any more when you can just do it with `lambda`. add = lambda x, y: x + y var = 1 add_1 = partial(add, var) add_1 = lambda y: add(var) They're equivalent. 
&gt; correct way of debugging What do you mean by that?
Just go live your life bro, don't worry about mutual admiration from strangers and an arbitrary social platform.
Take that up with the devs. It's not too inconsistent. You likely don't care that `int` , `float`, `list`, `tuple` , `dict`, `set`, `frozenset`, etc., are not `Int`, `Float`, `List`, …, `FrozenSet`. `deque` and `defaultdict` are just following the same conventions of all these primitive data structures. `OrderedDict` is no longer primitive as it is a `dict` with a `list` to retain the order of keys (or something like that).
This is similar to a previous comment. See my reply: http://www.reddit.com/r/Python/comments/3uoy8f/what_is_an_underused_tool_from_the_standard/cxha7u7
That's an unfortunate example because you picked numbers that can all be exactly represented by floats...
Ahh okay that makes sense. Dang, thought you were about to unload some crazy Python metaprogramming knowledge on me =P
Yes, it somewhat more confusing than map and Guido seems to be against some of the functional constructs in the language and of course in my example it is not necessary and one should write that as `sum(range(1, 11))` (there's no need for `reduce` in most situations as someone else mentioned as well). However /u/pvkooten's comment clearly suggests that it has been completely removed, and that is not the case.
My use case is "github password is in LastPass and I can't easily copy paste it to the machine I'm on"
You can't really do good functional programming in python because it doesn't have persistent data structures.
However, the upside to Turrble's approach is that it avoids an extra function call, if/when that matters.
So long as he's working with OS paths and not URLs!
Curated lists are turning into the link farms of yesteryear. Best to be avoided if one is looking for answers.
Yep. I use this for writing sql queries.
In this case, why would you create a list comprehension inside of `''.join()`? Also, if the list of vowels is not changing, why not create a constant variable? I read that sets should be used to check for membership, maybe I'm wrong. I thought this was how this problem should be written: VOWELS = set('aeiou') def anti_vowel(text): return ''.join(a for a in text if a not in VOWELS) 
Pretty easy to do using requests and lxml
Isn't that equivalent to the lambda: command = lambda: display_name("Luke", "Skywalker")
Why not `VOWELS = frozenset('aeiou')` if it's a constant? ~~Python will actually do this optimization automatically under the hood and convert the set to a frozenset.~~ Edit: The conversion only takes place if it's a literal.
&gt; command = lambda: display_name("Luke", "Skywalker") Actually, that is! Didn't realize that lambda was capable of holding the state like that as well. Thanks!
Ctrl Shft C and then save the image that way. Definitely `requests` and `BeautifulSoup` though, no questions asked. import os import requests from bs4 import BeautifulSoup response = requests.get(r"http://example.com/gallery") soup = BeautifulSoup(response.content) for anchor in soup.find_all("a", class_="album"): album_response = requests.get(anchor.attr("href")) album_soup = BeautifulSoup(album_response.content) title = album_soup = find("h1", class_="title").text os.mkdir(title) for img in album_soup.find_all("img"): img_response = requests.get(img.attr("src").replace("thumb", "images")) with open(title+"/"+img.attr("src"), 'wb') as f: f.write(img_response.content) Anyway, that was untested, idk if `.attr` is even a thing in bs4, but that should get you started.
One use case is multiprocessing.map in python 2.7 only accepts functions which take 1 argument. Of course multiprocessing.starmap, is in python 3 now.
map can be parallelized by just using multiprocessing.map, but list comprehensions cant. 
Couldn't you maybe run a little Beautifulsoup script that scrapes the page and grabs the element holding the text or are you talking about the meme-ish text on the image?
I'm talking about images with text. I was thinking about doing some research on the bots that read /r/AdviceAnimals posts.
Decided to try it out in a time trial to see which way is faster. I suspected you were right but the results seem to favor my solution. python -m timeit "''.join(x for x in 'aabecidofu' if x not in ['a', 'e', 'i', 'o', 'u'])" 100000 loops, best of 3: 3.97 usec per loop python -m timeit "VOWELS=set('aeiou');''.join(x for x in 'aabecidofu' if x not in VOWELS)" 100000 loops, best of 3: 4.58 usec per loop My guess is that the difference is the creation of the set and that over a large enough series of loops the set method with a constant would be faster.
https://pypi.python.org/pypi/pytesseract
Have you tried to uninstall it then install it again? It's happened to me before and after I reinstalled it, it worked
Interesting. Thanks for the clarification!
Do you have access to the database that stores the file/gallery data? You might have better luck with a server-side approach rather than a client-side if you're comfortable with making a few SQL calls to a database and traversing the web server's directory structure. The client may ask for more than just gallery info (original upload dates, image upload users, etc...) which would be simple additions to the server-side approach, and less likely to be possible from the client-side. 
Where did you get that info from? I've just taken a look at the bytecode and what happens is that Python converts the list to a tuple first before it stores it as a constant. Then it calls `COMPARE_OP` with `in` as argument, but I don't know what's going on under the hood (I guess you have to look at the C code?). Here's the string version: expr1 = "'i' in 'aeiou'" dis.dis(expr1) print('------------------------------') print(dis.code_info(expr1)) # Output: 1 0 LOAD_CONST 0 ('i') 3 LOAD_CONST 1 ('aeiou') 6 COMPARE_OP 6 (in) 9 RETURN_VALUE ------------------------------ Name: &lt;module&gt; Filename: &lt;disassembly&gt; Argument count: 0 Kw-only arguments: 0 Number of locals: 0 Stack size: 2 Flags: NOFREE Constants: 0: 'i' 1: 'aeiou' And the list version: expr2 = "'i' in ['a', 'e', 'i', 'o', 'u']" dis.dis(expr2) print('------------------------------') print(dis.code_info(expr2)) # Output: 1 0 LOAD_CONST 0 ('i') 3 LOAD_CONST 5 (('a', 'e', 'i', 'o', 'u')) 6 COMPARE_OP 6 (in) 9 RETURN_VALUE ------------------------------ Name: &lt;module&gt; Filename: &lt;disassembly&gt; Argument count: 0 Kw-only arguments: 0 Number of locals: 0 Stack size: 6 Flags: NOFREE Constants: 0: 'i' 1: 'a' 2: 'e' 3: 'o' 4: 'u' 5: ('a', 'e', 'i', 'o', 'u')
This is looking up a single character in the two different data types but the original problem was iterating over a string and returning another string minus the vowels. Your tests show there isn't much difference in the comparison part of the problem but it leaves out the iteration.
now am not 100% but maybe that could be the problem.. here are two things you might need to try. * go to C:\Users\ and try and create a virtual env from there and see if it works.( this step is more of a sanity check) The second option would be to : * move your virtual env to the folder "scripts" same one as the python interpreter in your C:\python27&gt; (bin) since your path is pointed on there it should work. Third option: * copy the virtualenv.exe and virtualenv.py(the script) and paste it on the desktop and try that to see if it works. Tell me if it doesnt work and amma rack my brain for more solutions.
Bokeh doesn't yet support 3D plots (forecasted for around mid-2016) and matplotlib won't give you the fluid interaction that Plotly example gives you. Why not use plotly itself? You can easily export static plots like the example you showed and embed that in a website, they even open-sourced Plotly.js recently. Just look at the plotly.offline API and you should be able to piece together an example pretty quickly. Edit: I was working on putting together a [Plotly backend](http://philippjfr.com/work/work-in-progress/plotly/) for my own library recently (shameless plug: [HoloViews](http://holoviews.org/)), and came up with a function that will turn any Plotly figure into a static HTML (mostly borrowed from their plotly.offline.iplot): import json, uuid from plotly.offline.offline import utils, get_plotlyjs def plotly_static_html(figure, width, height): jdata = json.dumps(figure.get('data', []), cls=utils.PlotlyJSONEncoder) jlayout = json.dumps(figure.get('layout', {}), cls=utils.PlotlyJSONEncoder) config = {} config['showLink'] = False jconfig = json.dumps(config) header = ('&lt;script type="text/javascript"&gt;' 'window.PLOTLYENV=window.PLOTLYENV || {};' '&lt;/script&gt;') divuuid = uuid.uuid() script = '\n'.join([ 'Plotly.plot("{id}", {data}, {layout}, {config}).then(function() {{', ' $(".{id}.loading").remove();', '}})']).format(id=divuuid, data=jdata, layout=jlayout, config=jconfig) content = ('&lt;div class="{id} loading" style="color: rgb(50,50,50);"&gt;' 'Drawing...&lt;/div&gt;' '&lt;div id="{id}" style="height: {height}; width: {width};" ' 'class="plotly-graph-div"&gt;' '&lt;/div&gt;' '&lt;script type="text/javascript"&gt;' '{script}' '&lt;/script&gt;').format(id=divuuid, script=script, height=height, width=width) return '\n'.join([header, content]) 
Saving for later, thanks!
Mean, we're just having an interesting discussion below and some more participants would've been nice. :( Now you also have to delete half of the other posts in r/python. ;)
Oh I think a coworker told me that when you use "in" and the magic method __contains__ is called the string is converted into a list (since a set isn't necessarily appropriate) and then the list's __contains__ method is called. I'd have to download the source to verify that's what's actually happening.
This is such a great tool. Makes it really easy to build unix utilities with Python. 
Awesome, the first one didn't quite work. The second I moved two folders *.idlerc* and *.virtualenvs* to C:\Python27\Scripts this didn't make a difference but looking in the two folders I have: in *.virtualenvs* 10 windows powershell script type files. While in *.idlerc* I have two files : breakpoints.lst , recent-files.lst . Moving the virtualenv.exe to the desktop did not help. It is my guess at this stage that the install from powershell is the issue. Note pip freeze still gives virtualenv==13.1.2 having made aboves advised changes. 
Ahh yeah maybe try command prompt.. I never use powershell personally
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
Thanks again for your help
&gt; Also, list comps can easily be extended later on if you realize you need to [...] Every single time I've used map, this kinda stuff happens. `toolz` and `whatever` helps a bunch for this but still, so frustrating sometimes compose(map(str), "Length: "+_, print)(lengths)
well, its more that they've already re-written it in gevent (e.g. you don't use sockets, you use gevent sockets.), Same for asyncio, except they decided to bring that to the main code itself. So in gevent you do your code normally, with some parts being parallel. In asyncio you code parallel for the entire program. If the usecase is like, downloading a bunch of files, I'd opt for gevent, if it was more along the lines of writing a server or the such, where I get no benefit from being able to dip into and out of parallel code, then I'd go with asyncio. That is how I understand the differences to be, at least
Gevent can monkeypatch the standard libraries to be non-blocking. I discovered how awful asyncio's programming style is when I used TorandoIO for awhile.
I used to use that, but I now use: import IPython; IPython.embed() Seems like a better repl environment. 
&gt; because R will probably have a statistical package that Python doesn't have. really? Like what? scikit learn has always had what I need
1) Just put the funtion in a file called linsolve.py 2) Do you mean the first parameter to your function will be an augmented matrix? Let's say you're trying to solve the equation `Ax=b`, then the augmented matrix is created by just placing the column `b` to the right of A, which makes it easier to row-reduce. You may need to extract out the `b` column, depending on how you implement your algorithm.
oh lol i didn't know that the first question is just that. thanks!
first, r/learnpython is probably the better place to ask. as for your question, the dictionary is basically just used as an annotation, so you may get the headers. getting the result without the print function is trivial, just *return* the result (literally, put return in your python file) then you may call it like this result = linsolve(args) as for the important part, I've no idea what you're talking about and can't help you with that I'm afraid 
&gt; now that we got lambda The archived Python documentation only goes back so far, but Python has had lambda since at least version 1.4 (1996): https://docs.python.org/release/1.4/tut/node79.html#SECTION001151000000000000000 Meanwhile the first reference I can find to functools is in 2.5 (2006): https://docs.python.org/release/2.5/lib/lib.html
As I said before the other bash script and python script are pre-existing and I'd rather not re-write completely. The path is a bit different. For me it is... Call("sh script ARG arg") Where the script is Adb log | python other.py Echo "I should see this message after other.py is done" Where the other.py has a line that exits a loop by doing print "done" sys.exit(0) If I just call the script from terminal the inner script completes and I see the second line. However if I call it using call I do not see the second line output. 
How exactly are you calling the bash script? I've had a problem but using subprocess and shell=true solved it. Try it as this: args=["sh", "script", "ARG", "arg"] subprocess.call(args, shell=True) Edit. Saw your Call.
Sorry for the wrong sub just a follow up that I seemed to find a workaround on [stack overflow](http://stackoverflow.com/questions/33928549/virtualenv-venv-not-activating-or-creating-the-required-folder)
Use subprocess to capture stdout and stderr with PIPE.
Apologies, but what would the value of that be
Thanks. I'm using the API from TMDB.
What can you do with partial you can't do with lambda ?
What can you do with partial you can't do with lambda ?
You're assuming I was talking about paths. I was not. But yea, I should have chosen some other separator I guess...
If you're referring to adb logcat then it never exits. It just continues to collect messages. If you want to get all of the current messages and exit then use adb logcat -d http://developer.android.com/tools/help/logcat.html
They're equivalent. Different ways of expressing the same thing. Arguably partial() is slightly less verbose when dealing with *args, but really it's just a matter of preference.
Oh right. I'll probably change it in the future.
But do you see the "done"? In my experience when things fail in a subprocess that work on the command line, it often comes down to things like processes not acting the same when not connected to a tty (eg output buffering), or a difference in environment variables.
Nothing, partial is just shorter and often simpler.
Have you tried redirecting `STDOUT`/`STDERR` on the call? Filled buffers can cause scripts to hang - if you're not interested in the output you can direct it to `os.devnull`.
Yeah, a lambda is just a function with a single return statement.
itemgetter and attrgetter are great options to replace lambdas as key functions.
bisect can replace some big if-elif blocks like [this](https://www.reddit.com/r/learnprogramming/comments/3uta9p/python_is_there_a_way_to_shorten_andimprove_this/).
Well, you still have to import it, so it's more verbose, unless you have several partial to create, which is rarely the case.
Well, you still have to import it, so it's longer, unless you have several partial to create, which is rarely the case. Plus of course, I never remember the parameters for partial, so "simpler" is debatable. But it's true that partial : - clearly state what you are doing; - display an explicit repr.
&gt; Well, you still have to import it, so it's longer I meant at the callsite, sorry if that wasn't clear, especially if there are lots of non-partially-applied parameters and as partial can be aliased. &gt; I never remember the parameters for partial What else could it be but `func, *args, **kwargs`?
[Image](http://imgs.xkcd.com/comics/standards.png) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 2232 times, representing 2.4758% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cxhv721)
I'm going on a practicality. Benchmarks are not practical. It's all just a gimmick really. The only SSD's to (possibly) achieve that speed aren't commonly used. On top of that it's never a constant speed. That's a part of the issue.
If you have ipython: import IPython; IPython.embed() 
[operator](https://docs.python.org/3/library/operator.html) is very useful if you want to be able to choose different operations at runtime (such as using a dict to return an operator when making a calculator program). You can do it with lambdas, but since the operators are all already defined for you hereit can save some typing if you need more than one or two and it is something simple. [string](https://docs.python.org/3/library/string.html), such as `string.ascii_letters`. I see a lot of people manually typing out something `'abcdefghijklmnopqrstuvwxyz'` for various tests, but this (and other similar groups of strings) are already defined for you. [logging](https://docs.python.org/3/library/logging.html). I see a lot of people using print statements that they comment out when they don't need them, when they could be using `logging` to control how much information is printed much more easily. [glob](https://docs.python.org/3/library/glob.html) and [fnmatch](https://docs.python.org/3/library/fnmatch.html). Yes, you can manually sift through files and directories using `os.path`, but `glob` and `fnmatch` simplify many file and folder queries.
The nested script actually monitors logcat until it hits a particular log, then exits. I know for a fact that the log is actually being sent. 
They can be used similarly, but lambda cannot do everything that functools.partial can: [StackOverflow: functools.partial](http://stackoverflow.com/questions/3252228/python-why-is-functools-partial-necessary)
They can be used similarly, but lambda cannot do everything that functools.partial can. Additionally, even the things that it can do the same as functools.partial, it may not be able to do them as "clearly": [StackOverflow: functools.partial](http://stackoverflow.com/questions/3252228/python-why-is-functools-partial-necessary).
Your code doesn't work. You'd have to write `sorted(d.items(), key=lambda item: item[1])` and compared to that I find `sorted(d.items(), key=itemgetter(1))` more readable.
Why I love Python and hate JavaScript.
The `weakref` module in general. It's quite nice for automating cleanup of resources in certain cases.
And the lambdas only allow a single expression.
XPost Subreddit Link: /r/visualization Original post: https://www.reddit.com/r/visualization/comments/3uurp2/chord_diagram_visualization_with_python_plotly/
Well, yes, but: arrow [still don't properly handle timezones](https://github.com/crsmithdev/arrow/issues/72). Stuff like that give this feeling that arrow only fixes the form, not the substance.
If someone is just looking for a great Python IDE, then I recommend something besides Emacs, like PyCharm. However, I use Emacs because I get a uniform environment for all of the languages I use. I also use org-mode for all of my planning and time tracking, erc for IRC chat, mu4e for email, and a few other miscellaneous utilities. Basically, don't get into Emacs simply expecting to get a good Python IDE. Treat learning to use Emacs like its own investment, and maybe you'll like using it for all of your text editing. Every time someone shows a language-specific Emacs setup on Reddit, half of the comments are variations of: "why should I do this when I have great IDEs available for X language? This is a waste of time, I am a *practical* developer and I need to write code *now*, not futz with elisp!" Learning Emacs is definitely a labor of love at times, but there are also *real* productivity gains.
In 50% of the situations, yes. There are other situations where pictures change from portrait to landscape, in which case the 2 pictures do not overlap. This means the outbound picture (img1) starts at full alpha and would never decrease, so it would show up in the black area until the very last frame when it would just vanish in 1 frame.
https://en.wikipedia.org/wiki/Betteridge's_law_of_headlines This won't be a popular opinion, but someone should bring it up already. With so many great python editors and IDEs out there, that do all the things you need, and more, right out of the box, you really have to wonder why someone would advocate the use of an editor that requires so much tweaking and still ends up highlighting the print built-in function as a statement, as you can see on several images in the original article. The right programming tools for anyone is largely a matter of scope, context and preference, with a huge spectrum of valid possibilities, and sometimes that includes using a low-level editor like emacs or vi. However the majority of times someone advocates the use of these 'medal of honor' editors, they do it with the thinly veiled objective of showing everyone that they can, rather than should. So to me this constant stream of 'emacs/vi is a great IDE for language X' articles is resembling more and more simple self promoting bullshit, rather than genuine expert advice.
Did you mean vim?
Seconded. I invested the time to really learn Emacs about a decade ago. One of the smarter tactical decisions I've made it my career - it's paid massive productivity dividends over time.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. Cheers &amp; best of luck with Python!
I'd had a couple things to the article: - [refactoring](http://wikemacs.org/wiki/Python#Refactoring) - remind that we can interactively go to methods' definition with [helm-imenu](https://emacs-helm.github.io/helm/) - indexing sources and interactively going to tags with [helm-cscope](http://wikemacs.org/wiki/Python#Interactivity_with_helm-cscope) - [and more](http://wikemacs.org/wiki/Python#Other_tools): set the current venv, sort import statements, pip-requirements mode, using `M-x shell` where everything is text, programmatically move around code,…
Hey, I'm really sorry about that. I should have checked the sidebar first. So, assuming I manage to build this thing and get it all working except one or two things, would I ask how help here or at /r/learnpython?
Guido is also against learning anything new shown by his aversion to functional programming so I don't take his word as gospel on here as many do. The fact that he thinks `reduce` is difficult to understand speaks volumes.
[StackOverflow functools.partial](http://stackoverflow.com/questions/3252228/python-why-is-functools-partial-necessary) functools.partial can be "picklable" for starters. In the past, Guido wanted to remove lambda but later changed his mind. That already proved that lambda didn't make functools.partial useless.
No apology necessary! I definitely you ask any questions over at /r/learnpython. Not that there aren't helpful people here, but for any "how do I do [this thing]?" style questions of any skill level, /r/learnpython is the superior subreddit for questions. There are some highly skilled and dedicated individuals there who can help you whether you're just starting out or have been doing this for 15 years.
1. What use cases (all?) is bottle &gt; [flask, x, y, z, other similar micro frameworks] 2. Is Arrow as coherent as NodaTime/JodaTime?
Author here. Couldn't agree more. Thanks!
&gt;What use cases (all?) is bottle &gt; [flask, x, y, z, other similar micro frameworks] Sometimes, you want to setup a simple web service. And doing that in Django takes roughly six billion hours of work. With Bottle, you can have something up and running in minutes.
This seems to be geared towards Python web devs more than just "Python programmers".
https://github.com/vinta/awesome-python
Same for Flask.
Is fabric deprecated? Any reason to still use it for new projects?
But that's because functions are first class objects in Python. Since it's so easy to throw around functions, why use lambdas? I (personally) refrain unless it's for a key function (such as `sorted`). If you need more complex logic than a single expression, it's much more readable to just create a full fledged function.
I'm trying to point out that the article is silly. It didn't go into detail about why those libraries are better. It only gave us a high level "this is what it does". Because of that, the value judgement "everyone should know these libraries" doesn't hold up. And instead I pointed out some more important libraries that I think "everyone should know". For these reasons, I'm out. I did just see that Invoke mentioned fabric in the article, my bad.
Only allowing a single expression has nothing to do with functions being first class members of the language. Every other language that has lambdas lets you write multi line lambdas that also have statements and they handle it just fine. A lambda can be written directly into a function call as an argument rather than having to write the full definition that is then exposed to the scope of the surrounding function.
&gt; With Bottle, you can have something up and running in minutes. Same for django
My point is that since functions are cheap to create (and allow you to easily reuse them) and they are (arguably) more readable than lambdas, why not use them for anything more complex than a single expression?
Why doesn't Guido just fix lambdas?
Look at the offline mode for plotly to work in the notebook. [This](https://www.reddit.com/r/IPython/comments/3tibc8/tip_on_how_to_run_plotly_examples_in_offline_mode/) was posted a couple weeks ago for adding plots to notebooks. I also posted a link to a notebook on extracting the html and modifying the javascript for personal offline use. 
EMACS and VIM: The best user interface the 1970's have to offer. 
You might not believe but both of them have a GUI very similar to modern text editors.
If you include the name is main thing in the flask example, also add it in the bottle example. It's not like it's required for either
Those are their home page snippets.
TUG? It still has the SQL Alchemy queries in there... And it follows all correct REST spec standards. Things like jsonapi.org are just noise... There's so many competing ones and none of them provide anything of real value. 
What is your favorite “modern” editor? Can I run it anywhere in the world over SSH? Or at least on a modestly-specced machine (that chokes on Atom and is completely unusable with JetBrains garbage)?
If you are fine working only in the notebook offline, then it's entirely possible to keep everything private (you can even modify the javascript to disable the export link). If you want the features on their site, then yeah, you're a bit out of luck :/ The open sourced version of plotly, including the offline mode, is only a couple weeks old, so more features will probably be introduced down the line for notebooks. Another option you may want to look at is bqplot, which is bloomberg's plotting library built for ipython notebooks.
&gt;simple self promoting bullshit pretty much the definition of everything posted on reddit including these comments. let's bitch about our favorite libs instead.
Old doesn't mean bad. I use VIM when I ssh onto our local super computer. 
lol hope you're having fun being a jerk in the internet, big guy ;)
I run into this occasionally and its a fairly hard problem to solve. It seems like globals are the accepted solution when your API gets heavy enough (ex: database connections). For situations where a global connection will greatly simplify the code I've started using this pattern: _db = None def getDatabase(): global _db if _db is None: _db = Database() return _db def defaultConnection(func): """Decorator which will automatically populate the 'db' argument of a function if it is None.""" @functools.wraps(func) def wrapper(*args, **kwargs): sig = inspect.signature(func) bnd = sig.bind(*args, **kwargs) for p in sig.parameters.values(): if p.name not in bnd.arguments and p.default is not p.empty: bnd.arguments[p.name] = p.default if 'db' in bnd.arguments and bnd.arguments['db'] is None: bnd.arguments['db'] = getDatabase() return func(*bnd.args, **bnd.kwargs) return wrapper This provides the convenience of globals but allows you to pass the API yourself when necessary. @defaultConnection def foo(a, db=None): return db.get(a) foo('Hello') # Uses default connection foo('Hello', Database()) # Uses passed connection There are a couple other ways around this problem. In general I try to have functions operate on the *results* of API calls instead of needing direct access. If a function requires a large number of API calls, you can wrap the API in an adapter class that factors out that section and packages the result. The goal is always to break large problems into smaller (cleanly separated) pieces without introducing too much complexity.
I didn't realize it was only a couple of weeks old. It worries me because it makes changes seem more likely, but it seems like they're leaning in the right direction at the moment...
By using a higher level language you are probably more likely to see high level optimizations you can make - new or better algorithms - rather than getting lost in the weeds trying to save a clock cycle or two. Then later you can choose to optimize any bottlenecks. "We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%" - Knuth
&gt; The best code is good code that I didn't have to write. And that you don't have to debug, which could take a lot longer than writing it.
You'd need to set up a variable so you could track the "Up" and "Down" state of the spacebar. For example: # default state spacebar_is_up = True def on_spacebar(): # toggle the spacebar value spacebar_is_up = not spacebar_is_up if spacebar_is_up: # do something if the spacebar is up pass else: # do something else if the spacebar is down pass wn.onkey(on_spacebar, 'space')
This assumes that the developer already knows Python, and does not already know how to use C or Fortran. 
How does it compare to MDAnalysis?
No, it's vi(m).
That's Shakespeare for you.
Have you/they tried numba? You can compile imperative python numpy code to fortran speeds, with multithreading. https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/
The Raspberry Pis have a ARMv7 multicore processor, which is a processor used in some phones. Apparently Unity doesn't support builds for that chip architecture from what I've read. Python is the native launguge for the pi as well, apparently. Since Unity may not work, I was looking for another game engine that would have similar features or capabilities. 
Haven't used that personally, sorry.
That might be worth looking at! Although looking at the code they give as an example, I don't really see how it would be that much more complex in Fortran. Like this bit: for i in range(x.shape[0]): xi = x[i] % (2 * np.pi) m = 1 + int(xi // hx) xi = (xi - hx * m) E1 = np.exp(-0.25 * xi ** 2 / tau) E2 = np.exp((xi * np.pi) / (Mr * tau)) E2mm = 1 for mm in range(Msp): ftau[(m + mm) % Mr] += c[i] * E1 * E2mm * E3[mm] E2mm *= E2 ftau[(m - mm - 1) % Mr] += c[i] * E1 / E2mm * E3[mm + 1] In Fortran this would be: do i=0,size(x,0)-1 xi = mod(x(i),(2 * PI)) m = 1 + int(xi / hx) xi = (xi - hx * m) E1 = exp(-0.25 * xi ** 2 / tau) E2 = exp((xi * PI) / (Mr * tau)) E2mm = 1 do mm=0,Msp-1 ftau(mod((m + mm),Mr)) = ftau(mod((m + mm),Mr)) + c(i) * E1 * E2mm * E3(mm) E2mm = E2mm * E2 ftau(mod((m - mm -1),Mr)) = ftau(mod((m - mm -1),Mr)) + c(i) * E1 / E2mm * E3(mm + 1) end do end do which is a little bit messier and verbose, but only a little bit. The Python version is a little easier to read, but you're not making huge gains here. Also, by "multithreading", is it proper MPI-style distributed memory parallel computing? I don't want to be limited by the number of processors I can fit in a single box...
I am finding hard to tell if Peewee has everything I need to make a restful api out of your PostgreSQL schema for JSON Request/Response documents, or even query logging :/
The only things that will be changing are in the notebook offline mode. All of the plotting libraries are already well established, and all of them should be usable online and offline. The only thing that changed last week was additions to the offline library, which added their javascript to the library (before it processed on plotly's servers) and a function to add the offline plots into iPython notebook.
You have not shared any code. Showing screen shots is not sharing code. &gt;You can think of this as an gift from me to Reddit. Honestly, no one cares. Post some code or post a job listing for a paid position on a closed source project or go home. No one wants to watch videos of your wild claims without being able to reproduce it themselves by executing code.
I don't know the answer but if I had to make an educated guess I would say it's because of cache and memory performance for the use-cases CPython has in mind. * You can precompute all possible bucket locations and fetch them concurrently. The alternative is walking a linked list of buckets one memory fetch at a time. * Having a giant array preserves data locality on the CPU cache. The address of each bucket is in a continuous range so the CPU cache can more effectively prefetch and purge useful data. Since so many problems are IO bound, having code that makes efficient use of memory hierarchy can increase performance by MANY magnitudes. 
My first thought upon hearing about TF was how long will it be until it is incorporated into sklearn as a computation engine? I guess Google didn't want to wait for that.
Great article! /r/pystats and /r/statistics might like this too.
&gt;it's all the code around it that you can leave unoptimized that looks so much better than the equivalent fortran. I can see how that's true, and how it would make the code a bit tidier. But when most of the code is the intense stuff that needs optimizing, it doesn't seem like a huge savings. Like, I can see it helping, but maybe not helping quite enough to be worth learning a new language for.
Just like all libraries!
To go off topic entirely, is the show any good in your opinion? I'm in need of a new series to binge watch!
Yeah, I love it. Watch the first episode and you'll see what it's like. It displays the hacking scenes quite realistically, which is rare in movies (e.g. Hackers and Swordfish are far away from reality).
It's a good show, goes pretty quickly. 
I recently discovered the datetime reader, super powerful, it picks up just about any reasonable date and can convert to whatever you want. Very impressive for a built-in module.
I haven't watched it, since I don't watch too much TV, but my work colleague (who is a network security analyst &amp; developer) finds the technological bits to be pretty accurate (not 100%, though), which is something that doesn't happen much in TV &amp; Film. He recommended it.
To be fair it says to "*check them out*" not use them haha
What web dev would use "multimedia and windows graphics in pure Python"? This seems to be completely random.
I actually was in this exact situation (transferring from Igor to python) not that long ago. I like bokeh for interactive stuff but matplotlib is nice because: 1) It is more developed (at this point) 2) A lot of people use it, so you're more likely to find examples of how to do something. 3) It's more amenable to making figures programmatically I recently found out about [mpld3](http://mpld3.github.io/) which offers interactive plots but uses the same api as matplotlib, which means you can easily transition code between scripts and ipython notebook I haven't used it yet but it looks pretty promising.
True, I agree with you that it can be helpful if one did know one or both of those languages. I use C from time to time when I need the raw performance.
You don't actually seem open to sharing. "According to US law" blah blah. 1) a repository is necessary for collaborating. How are you going to collaborate with these people you pain stakingly skype one on one with. 2) actually sharing your code would demonstrate your process is repeatable. This would attract qualified programmers. I suspect any solid programmer is turned away from your project based on your delivery: abstractions vs runnable code. Notice your posts are removed from the computer science sub reddit. This is because you aren't engaging with computer scientists in a legitimate seeming way. You think compiling code is too big of a hurdle for others, and so no one who knows how code works takes you seriously. But there's no point in debating with you. You have no actual contributions to share. Code that only you can execute and understand is not real. It doesn't make sense. I agree with others that you seem clinically delusional, and reddit can't help you.
I love you too.
I am not /u/idlecore, but I think idlecore's point was that title and the way it's written is self promoting. If title read something like "Emacs setup for Python development" or "here is my setup" and went straight to the description of installed packages and .emacs files, not pretending to cover needs of the entire community, it'd be more honest.
Admitting to use a glue language would use the proper wording "Why I use Python for **calling already written high performance c code**"
According to that theory all Python programs should be faster than all c programs because of consistently more optimization potential. Reality is that being a dynamic language causes so much unpredictability that even syntax checking can barely be done correctly.
Some people think that they became better programmers simply because the language didn't report errors until later at run time. That gives the illusion that one wrote bug free code BECAUSE of the better language.
I was eager to discover this article because I have been wanting to do something similar for NOAA buoy data in California. There's so much data out there. Unfortunately, I don't have good records on which days are "good", so I've been meaning to (and failing) keep a journal.
Yeah but it's more informative than if it were to say "Hey do you know about the collections library? You should check out."
Ok that's promising. Thanks.
Once you know django it probably takes about 120 seconds. 1) generate site 2) generate app 3) edit `settings.py` 4) `./manage.py runserver` You're off and running. Granted, if you're wanting a simple API that may be a little much and instead you'd use a scaffold app with flask, flask-restful, amebic, and SQLAlchemy (I usually just clone a local repo of my default flask config) and am up in about 30s. Both have their strengths and weaknesses.
Maybe one of them would be useful for me. The rest are not something that would concern me. 
/r/nocontext
Anyone using a REST API, at least.
Maybe I'm missing something but where is the Python? 
The black vertical bar on the left. It's light. 
You can use selenium with xvfb for headless testing. But Casperjs is a lot simpler. 
Notice how you have two "defvar" blocks in your init.el. The defvar block must come before the "mapc" block, where it is used. Since you define elpy only in the second (unused) defvar, elpy is not installed. Hence your left error. Your right error says that it can't load "package", which probably means that you are running emacs 23. Package was introduced in Emacs 24. On your screenshots, this error only happens in the console emacs, which is probably still your OSX default Emacs. Install emacs from `brew`, or add your graphical emacs installation to your path to fix this error.
"Similar"
To add another reason, from the [CPython source](https://github.com/python/cpython/blob/master/Objects/dictobject.c#L420): &gt;Open addressing is preferred over chaining since the link overhead for chaining would be substantial (100% with typical malloc overhead). Python actually uses tons of small dicts internally (e.g. keyword args), so chaining (with all the malloc it implies) would most likely be overkill here.
Just a small suggestion: you can avoid the "if"s at &lt;__get__api__link&gt; method by mapping &lt;api names&gt; to &lt;api links&gt;. api_names2links = { "wordnnik":"http://api.wordnik.com/v4/...", "urbandict": "http://api.urbandictionary.com/v0/...", ... } if api in api_names2links.keys(): return api_names2links[api] else: return False Edit: formatting
Which is ridiculous, because GUIs are not where the power is. "Modern" doesn't mean "better."
We have found [peace](https://github.com/syl20bnr/spacemacs/tree/develop). Oh, and [this](http://boyanangelov.com/spacemacs/layers/+lang/python/README.html).
never trust a man with emoticons in commit messages
Thanks man, I'll post it over there now
&gt; Making high performance routines accessible to high level languages simple enough a child can write scripts in I would say is quite an achievement. It's not an achievement, it's a basic requirement of any language other than C.
A reply from /u/madboy1995, which I am failing to edit the markdown of correctly: `Wordnet` having been around since a while is much mature but I think `Vocabulary` does a pretty decent job in providing you what you want in a structured manner. Say for example you would want `synonyms` for the word `car`. Using `Wordnet` from nltk.corpus import wordnet syns = wordnet.synsets('car') syns[0].lemmas[0].name &gt;&gt;&gt;'car' [s.lemmas[0].name for s in syns] &gt;&gt;&gt;['car', 'car', 'car', 'car', 'cable_car'] [l.name for s in syns for l in s.lemmas` &gt;&gt;&gt;['car', 'auto', 'automobile', 'machine', 'motorcar', 'car', 'railcar', 'railway_car', 'railroad_car', 'car', 'gondola', 'car', 'elevator_car', 'cable_car', 'car'] Now let's try out the same using `Vocabulary` from vocabulary import Vocabulary as vb vb.synonym("car") &gt;&gt;&gt;'[{"seq": 0, "text": "wagon"}, {"seq": 1, "text": "motor"}, {"seq": 2, "text": "cart"}, {"seq": 3, "text": "automotive"}, {"seq": 4, "text": "automobile"}]' Now I don't know about you, but I like to achieve the same thing writing less lines of code. `Vocabulary` does this for me. Plus you get the data in `JSON` format! I am not saying `Vocabulary` is better than `Wordnet`, but it can be a decent substitute. Hope you find it useful. :)
What's the use of having a `seq` over returning a list which has an implicit index built in?
&gt; Place that doesn't allow you to select your tools? Brush up that resume, and find a better job. An employer who doesn't understand basic software development economics is going to make for a shitty employment experience sooner or later. I came to write this.
My point is, it gets you what you want in a quick and dirty way. `Wordnet` is obviously the default choice here. But `Vocabulary` can give you the same thing by putting less effort. Hope that answers your question :)
Thanks, looks neat now :)
Thanks, this really clarifies on the maths a whole lot more. And actually seeing how the list values for the bounding box makes much more sense.
Use virtualbox and continue being productive. Or take a risk and dual boot your machine on your own. I have done that at my last two jobs and other than some IT folk trying to claim root on my system I haven't had any major pushback. 
Came to say Virtualbox, but I am also able to get things done with Xming and PuTTY. I work for a company that requires (if I'm not in the office) me to work over a VPN and that no local traffic is allowed from the box connected to the VPN. That means once I connect the computer to the VPN, all traffic goes through the company's proxy. Yeah, no. I run the official Linux distro in VirtualBox and connect to the VPN in that instance, leaving my host computer's traffic unaffected. I also have an RDP window open to the company-provided Windows laptop so I can do whatever Windows-centric work I have to do. It works well and satisfies the security requirements. BTW, if you're writing in Python, PyCharm's pretty nice! I've used it for a couple of years now and it's helped me be a better Python coder. 
Right! Its just my use case - since I use venvs on server side and the apps on workstations. Why I need both - I don't "install" the django projects. I just prepare the env with the requirements.txt Then again - its just my usecase - eg. installed apps via pip manage their own requirements. 
Yeah, sure. But no matter how you install something, it shouldn't have to be defined in a special way. Especially when both ways (requirements.txt and setup.py are specific-to-python ways).
I primarily use pycharm over SSH. I don't find it slow at all. I settled on Anaconda for my workstation distribution. They have pre-built binaries for everything I've needed so far. Canopy is slightly better, but I don't think it justifies the annual subscription.
I didn't understand you. What is your particular problem with pip or conda?
Yes, you right. But, now the "recommended way" is venv + pip + requirements.txt, just for convention.
I think it depends on who you ask though. Lots still use venv + pip + requirements.txt + setup.py, because reasons, just like /r/RamirezTerrix mentioned: https://www.reddit.com/r/Python/comments/3uzl2a/setuppy_requirementstxt_or_a_combination/cxj12jm
I use Vagrant for all my Python development and just SSH into staging servers with vim. If X-forwarding is too slow for SSH connections, you can try sshfs to mount your code and edit locally. Also, managing compiled libraries and expecting them to work cross platform is an unnecessary nightmare... personally, I wouldn't recommend installing the Python stack on windows - especially if you're going to use other linux tools anyway (nginx, apache, etc.).
I will be correcting the `JSON` inconsistency now. Thanks for your time @swissfreak :)
There are people like you and me who cannot live without vim - i cant stand those ide's that force you to use a mouse ugh there are some options for must-have-vimmers: * Install Cygwin. Mintty, openssh, and just about every unix tool under the sun runs in this environment -- including vim and pathogen to give you an awesome vim experience * Install VirtualBox and inside it install a linux distro. Enable sharing drives from your PC and you can do everything, inlcuding guis, in a linux environment * Install gvim * If you must have an IDE, I've heard NetBeans has a jvim plugin ... but I dont know if its any good 
Use Hyper-V (it's builtin). Virtualbox sux, both in terms of integration and performance :) Although there's one inconvenient thing about Hyper-V: it's has no builtin NAT support. I use [VMWare Player's vmnet8](http://thomasvochten.com/archive/2014/01/hyper-v-nat/) for that. It work's great. But if you still insist on Virtualbox, you prolly need stuff like [this](http://blog.ionelmc.ro/2014/01/04/virtualbox-vm-auto-shutdown/) ... Also, don't bother with desktop Linux, just enable X11 forwarding in Putty and use a [local X server](http://sourceforge.net/projects/vcxsrv/) - it integrates way better with the Windows desktop. 
This is BOFH stuff right here.
Hyper-V only built in on windows 8 AFAIK. For windows 7 you'll need to see about getting [Microsoft virtual PC](http://www.howtogeek.com/56158/beginner-how-to-create-a-virtual-machine-in-windows-7-using-virtual-pc/) if your required to go with MS tech. 
Vagrant is a good option for spinning up a new fresh dev environment that matches production. There's a lot you can automate there to make things efficient and your tests match the target environment. Docker is more fiddly but will give you some more power at doing this. I'd recommend sticking with Vagrant, though. Also note that Vagrant just automates VirtualBox as far as I understand. Pycharm is the IDE of choice if you're on Windows and you're not a Vim/Emacs guy. If all you want is a text editor with some additional bells you can tweak, Sublime and Atom.io are popular as well, but JetBrains products are really quite good if you're working with a team and need to share experience. If you want to be able to mount a folder over SSH or NFS or something on Windows, I recommend Expandrive. I don't recommend it at all unless you're only over a LAN, but otherwise it has good support for the small group they have and it works pretty awesomely for Windows folks that need to do Linux filesystem work but don't get command-line (I don't care to criticize them or anything, they exist and have their place, I'd rather make their lives easier than complain they're not like me). Last but not least, there's a myriad of packages you'll have to get fiddly with. For instance if you want psycopg2 on Windows... well, find a binary distribution and use that. Basically pip will fail you in odd places where it wants to compile things. I would also avoid virtualenvs and stick to Vagrant-like full VMs instead. Windows and Virtualenvs aren't as straightforward as on Linux, and it will get dicey. You'll have to figure out that side of things, or Vagrant, and supporting both will not be as fun. edit: I didn't mean NFS, but said it, and it's been a week, so I don't know what I meant. Expandrive mostly does ftp/scp style protocols, and NFS would be a wildly different animal to tackle, so it makes sense that it's not supported. FYI, Windows has some support for it natively, but not great.
Cygwin is a must have for ssh on windows, but don't do vim out of there. Just hop into a Linux flavor on VirtualBox and ignore windows. 
Solved : Hi, the original installation had been done with pip3. I did pip3 list and can see it. Thanks
Collecting pillow (from mezzanine) Downloading Pillow-3.0.0.tar.gz (9.6MB)
The newest version of Pycharm allows remote environments. That's probably your easiest out.
Virtualbox + Vagrant + Puppet/Chef/whatever all the way. It's already been covered here, but it's a lifesaver in general and should be used no matter what your host machine runs.
Personally, I prefer MobaXterm, which wraps Cygwin and avoids the (long) installation process. It's also really easy to uninstall, unlike Cygwin.
Sounds more like a lazy IT director than a fundamental lack of understanding software development economics. Probably heard somewhere that he can get by with fewer headcount by inflicting Windows on the workplace so they can group policy the hell out of the users and not have to be troubled by pesky rogue Linux boxes. It's a bit like living in old Communist Europe. 
Two main options I see: Use virtualbox (or vmware if your company has a license... and make sure the virtualbox license allows corporate use too) and just run a simple ubuntu server VM. SSH into that as you normally would, but even an xterm will run as though it were a local machine (can't imagine why). or Just bite the bullet and use windows. The atom text editor is like a free version of sublime (that runs like poo poo, but is getting better) and has a lot of great python related extensions. Virtualenv does indeed work in windows ( http://virtualenv.readthedocs.org/en/latest/userguide.html ), and line endings can be resolved through git (you should be using version control software anyway, and all the major ones either support line ending conversion OR have a git front end). Packages that rely on compiled C code are indeed an issue, but it looks like it is fairly easily resolved http://blog.ionelmc.ro/2014/12/21/compiling-python-extensions-on-windows/ As for file permissions: git to the rescue again, http://stackoverflow.com/questions/1580596/how-do-i-make-git-ignore-file-mode-chmod-changes and, as before, I assume hg has similar features and you can use git-svn if you guys are using svn. So yeah. Aside from having to change your workflow a bit (which sucks, but isn't the end of the world), everything should work with minimal hassle. One of the biggest advantages of python is it is cross platform, and modern version control systems already take into account most of the file related issues.
Subvert it (VirtualBox with Vagrant) or leave. Ain't no time to waste on trying to compile C extensions or fiddle with confusing Windows design decisions unless you're running Python 3.5. 
I normally just read the requirements file to a list in my setup.py script and set that list as the value to setup_requires kwarg. 
I have successfully used Vagrant and Docker for my development environment. It works on Win/Mac/Linux and uses a proxy-vm when needed. All my source files are synced in realtime to the containers and everything works beautifully. It was not easy to set up as you said, but when everything works, it's very easy to use. And yes, you should find a new job. That policy is unacceptable.
Is this a joke question? :0)
Vagrant, docker's a pain in the ass to use in development without having a relatively good grip on it. I do a lot on windows, it's been getting better with wheels and there are [unofficial](http://www.lfd.uci.edu/~gohlke/pythonlibs/) package builds.
At my company we use Junos Pulse VPN and RingCentral, so my outside box is Windows, but I only see that if I'm in a meeting. Otherwise it is Arch all day in VirtualBox. Works great. 
What I do is edit the files on the remote server with my local editor. You can do this in most ftp clients by setting the editor. The ftp client downloads any files you edit to a temporary local file. Changes to those files are automatically uploaded to the server. I use winscp as my ftp client and it works well. Here are instructions on how to do it in winscp. https://winscp.net/eng/docs/integration_editor
Look for a new job. There are plenty of jobs available. You can pick the stack you want to work on. Don't stick around with a company that makes bad decisions such as this.
Rust's HashMap also uses closed hashing, but rather than Hettinger's map it uses Robin Hood hashing with a somewhat ridiculous load factor of [90.9%](https://github.com/rust-lang/rust/blob/master/src/libstd/collections/hash/map.rs#L48).
Get a new job.
If you just use SSH, then this doesn't seem like a huge issue to me. Just find a good Windows SSH client. Check out [MobaXTerm](http://mobaxterm.mobatek.net/), from my understanding it's pretty popular, cannot be beaten. Or use Putty. If you want a whole new dev environment just use a VM like others suggest to install your preferred OS.
Hyper-V is rather annoying to use for a workstation virtualization solution since it has extremely limited graphical capabilities. If you use Hyper-V plan on using a remote desktop solution of some form to access your guests, because otherwise it will not be a fun experience (and even then, no 3D acceleration, so expect some performance issues if you want to use modern DE's). VMWare Workstation Pro ($250)/ VMWare Workstation Player ($150) is probably the best solution right now, the main difference between them being the former can connect to VMWare's server virtualization technologies (which we use extensively, so the price difference is justified to me). If you want a free (literally and as in beer) solution there's still VirtualBox, but it's still behind the curve as far as performance and in particular graphics performance compared to VMWare.
I've had an excellent experience editing code remotely with PyCharm. I just connected it to the server's python interpreter and an FTP account, then every save I make gets automatically uploaded to the server and when I run it in PyCharm it gets run on the server with a little console window displaying output. It pretty much acts the exact same way as if I were editing a local project. 
holy shit bofh is still a thing? I've not heard that it like 10 years.
Hey, I'm looking at your source code, and I tried to import it into my environment to study it. everything imported correctly besides "if key[K_RIGHT]:" Where "K_RIGHT" is an unresolved reference. Know whats up? (Also "K_LEFT", and "QUIT" were errors) Edit: I guess its just throwing the error for no reason? It runs just fine
I'd get a new job, personally. They want you to develop for Linux but don't want you to develop in Linux? Anyways, if you really want to stick with a company that has no foresight, and if you have permission, I'd install some form of SSH Mount (I'm almost positive there's a Windows application) and just mount the remote directory and treat it as it's your development folder, and just use your normal Windows IDE on it. If you really want vim, use gVim.
I can see why that'd be annoying. Not trying to advertise, just saw someone who seems to really enjoy the same tools I use and figured I'd reach out. In hindsight a PM would have been better, so I'll do that instead. Sorry about that, honestly.
Ir go rougue. Our IT group rolled out a new VPN solution last month. The day after, four linux devs was accused of stealing the certificate from our Windows machines. It spiralled down from there, so we have IT scheduled to come and defend their position at the next group meeting. If you're likely to be fired for such uppity, go and find a better job.
now I'm annoyed, because if you were sincerely sorry, you would delete it and pm him.
the approach where i worked was that everyone just kept using linux and getting shit done, and management just let it go. eventually it became officially supported. but that's gonna vary from place to place. honestly i agree with others about considering a new place to work, but it's not always that simple. as a first step i'd try to get everyone together to appeal to management about the decision. maybe you can get some sort of exemption. otherwise, a VM seems like the most painless approach. If you need some sort of directory sharing you could try local samba/CIFS sharing, but given that a bare-metal linux install previously worked for you guys I'm not sure why that's necessary. another approach is continue with linux development remotely. you can work around others' needs for a graphical environment by setting up vncserver sessions for each user on the remote box and them just VNC'ing in. could be a pain for anyone that's telecommuting though.
&gt; Sounds more like a lazy IT director than a fundamental lack of understanding software development economics. If you're lazy and you *do* understand the economics, you'll understand that giving your developers what they want makes them more productive, *and* they will take care of their machines themselves, so you won't have to hire a highly-paid consultant to manage your group policies for you. Could also be some sort of exclusive deal where you outsource your IT and sign for X years, promising to not run anything but Windows, and in return you get very reasonably priced Windows licenses, cheap PC hardware, and 24/7 on-call support. Of course whoever offers such a deal has no interest in supporting 20 different operating systems.
And in the mean time, get everything you do signed off, document what you're doing in case you need to explain things later, and ask lots of questions.
Still ticking along AFAIK
First Reddit is not your personal hacking team. Second if you want software (however illegal the software is) then pay for it.
This looks like a promising project.
It might of been. But even then it is easier to automate his project with Python.
That's understandable.
To continue what he was doing.
Thanks for sharing. But is there a beginner book? I'd love to see a beginner book by the same author.
Thank you for being one of the few people in this discussion who actually seems to be trying to help. Seriously, as someone who develops on Windows and deploys on Linux all the time for unrelated reasons, using Python on Windows mostly just works. There are any number of decent editors and IDEs. Just pick one you like. In my experience the text-handling stuff is a complete non-issue. As you say, the few changes that might be necessary are handled by any modern source control system anyway. And those all run just fine on Windows these days, too. Tools like pip and virtualenv work normally the vast majority of the time. So do the major test frameworks and associated tools. There are a few minor changes because of the host platform, which you mostly run into if you didn't abstract filesystem- and process-related details very well in your code, but these are easily fixed. The most frustrating area usually seems to be deployment rather than Python itself, because a lot of the automation tools for deployment were written by people who use Linux-ish systems and aren't portable. If you really need these tools, you might need to investigate Cygwin and friends or some sort of VM. Then again, if your whole organisation is going Windows-only, tools that can only deploy on Linux probably aren't very relevant anyway. In any case, I don't understand the overwhelming majority of responses here that seem to think either turning Windows into as much of Linux as possible or giving up and quitting are the only options. Doing normal, day-to-day development productively on Windows is perfectly possible, it has been for years, and you can be up and running in a matter of minutes.
&gt; If you're lazy and you do understand the economics, you'll understand that giving your developers what they want makes them more productive, and they will take care of their machines themselves, so you won't have to hire a highly-paid consultant to manage your group policies for you. &gt; &gt; This depends greatly on the nature of the company. If the programmers are just a small portion of the whole company and the majority of folks are admins, marketing folks, HR, accounting, etc., you really can't count on them to know how to maintain their boxes and avoid tons of nasty. The obvious solution, of course, is to make exceptions for certain departments or individuals on request.
I'll check this out later.
I could just import imaplib and email you that way. I'll look up what this Google text is 
- setup.py for production environment - requirments.txt for development environment
This happened at my first internship and I found it simpler to bring in my macbook instead - I no longer had to fight installations and everything was just so much easier. Technically I was stealing company IP by putting it on my personal laptop, but no one cared. Another internship had the CTO who was a Windows only maniac, and convinced the CEO that Windows (as opposed to OS X) was the way to go with the justification of security, more available programs and the fact that Office worked better on Windows. He created far too much work for everyone below him. There's a reason nearly every big software company use Macbooks and Linux. Granted Windows development is easier nowadays than it was a couple of years back, but I agree with a lot of the commentators - any place that has a large number of developers and forces Windows upon you is most likely not a good long term place to work.
Quit the job is great advice...rarely. My income and bills are such that quitting is likely to cost me a lot. There are creative ways to make things work better. And to prove them to decision-makers.
It helped a lot that our manager stood up for us :-) Besides that, we all managed to find a way of giving a negative answer to the mandatory IT policy a year ago. So if worst come to worst, I get 9 months of pay plus compensation for wrongful termination.
Super cool. I particularly like your windrose plots.
While windows development has come a long way, I've never had a good experience at a company that only allowed Windows. It's more a predictor of bad things to come rather than just a hindrance and inconvenience.
Do what I did for years and hide a Linux box somewhere. You can [mount the Windows share drives on a Linux box](http://www.cyberciti.biz/faq/access-windows-shares-from-linux/) so you can have access to the data you may need, or at least have a place to put it. Drop as many inbound packets as you can just in case you are running something some kind of network scanner like my old employer used to. No Linux. That's just... weird. I'm sure there's a reason to drive that kind of stake into the ground but I can't for the life of me figure out what it may be. You can hide a Raspberry Pi in all kinds of interesting places. I once hid one in a chassis-based switch that had half the chassis unused. Not a good idea, in fact a very bad one so don't get that creative. No Linux. Huh.
Well yes, Python does not scale in codebase size well, and to my knowledge no dynamic languages scales well in that area. I wouldn't have described that as unpredictable or impossible to syntax check. Its a pitfall of dynamic languages, the computer isn't checking the type correctness of it for you. In my opinion if a Python project starts getting massive the team designing it should take the time to split it up into smaller chunks so that changes don't ripple through touching all the code. This is true with any language though, just because Java type checked the app doesn't mean its going to work as expected. Python is just more painful when this type of poor design takes hold.
Wait, they want you to develop for Linux but won't let you boot a Linux box? 
&gt; What do we need to know to stay productive. 1. That there is demand for talented developers, many positions available, and many companies that won't be shitty. 2. Virtual Box. Run full screen Ubuntu / whatever and never look at or deal with windows after it boots. The performance hit is not an issue (not that I ever noticed for desktop).
Maybe I didn't pick the best word for it: When looking just at source code most uncertainty about what the code does (and it correctness) comes from not knowing the data for all real life cases. In a lower level language it a variable content decides about if or else taken or pointer being valid. With object oriented additionally you have to guess which method in inheritance tree is actually picked. With Dynamic you can't even guess if number, string, list, dictionary or None will work with the operator you apply. Each uncertainty increases potential for failure the bigger the code gets. For a small program it is fun to not worry if you feed number or string into it but when your 1 + 1 is 2 or "11" depending on lucky guesses the pain grows. I like Python the best from all script languages. But it is no exception to all script languages growing fast first and becoming very painful once big. I am more bothered by the hype making it look like others languages issues just disappear - essential complexity just moves from one spot (careful typing) to another (more unit tests). Whether some languages invite accidental complexity is up for debate.
&gt; Doing normal, day-to-day development productively on Windows is perfectly &gt;possible, it has been for years, and you can be up and running in a matter of minutes. You would think that Windows isn't a widely-used operating system and that no one develops for/on it the way people are carrying on. I guess Visual Studio must be a fringe IDE too....
That's why I've said "enable X11 forwarding in Putty and use a local X server". I've tried Workstation Pro's "unity mode" - it's a nice idea but it don't really work well. All sort of focus issues and glitches. Graphical mode is gonna be slower than a remote X11 server for most cases where you just look at text (like an IDE). 
But Windows is the most popular desktop operating system in the entire world. Most companies only allow Windows. By this extension, most companies are on the verge of ruin because they only use Windows. 
Oh hm, maybe they did...
Those people won't run Linux though. A person who chooses to use Linux can likely maintain their own machine.
I too can't use a Linux DE for development. I currently have Sublime installed on a Linux server, ssh into it via putty then export the display to my Windows desktop and use Xming. Not the nicest option, but I'm limited as to what I can use.
Until you've done dev on both, you can't know how painful Windows development is. The poor folks out there still using Windows just don't know better. Also, C# is not exclusive to Windows (see Mono).
I'm never surprised by workplace policies that deem a Windows-only environment. I work at Continuum, and we put a lot of effort into building usable Python environments on Windows using conda (as a robust alternative to virtualenv). You might want to also look into using VNC to connect to your Linux machines, which will allow you to run full applications from your Linux boxen. Unless you're building containers for Docker, you definitely want a good VM application. Spend the bucks for the nicer ones like Parallels or Fusion, and you won't even notice that you're not natively running Linux.
These are unrelated to disallowing Linux for development and forcing developers to use Windows.
Did you make them with the windrose package, or what?
&gt; nd scripting in python ... at which point there's no need to learn a new language. If you don't know python it may not be worth your trouble to learn it for the gains ... then again if you gain it as an extra tool for data-wrangling and munging, text file parsing, and scripting and glue; well that might be worth it, and then the single environment to do it look Actually Numba can auto paralellize vectorized functions.
All of the points you raise seem to either apply to situations of poor management or regular office workers. License violations and support issues shouldn't be a problem if the people installing the software are computer literate, as your developers should be. Dependencies on obscure tools also shouldn't ever be an issue, because you should make sure that either the whole team can use the tool, or that appropriate documentation is left for future developers. But as the other commenter said, none of this is really relevant to disallowing Linux.
Neat. Can it do it across several machines?
Send me a private message. I'll send you a link (I'll upload the pdf to Dropbox or Google Drive and share it with you
Jibe
I saw it but I would prefer a paper book if possible :/ I saw that some of those books have a printed version, do you have any idea on which on is the best ?
MobaXterm is the best thing I have found for ssh with xwindows support. 
But don't try to tell your sysadmins that virtualenvs are a security measure. They're a convenient way to organise separate sets of modules, but they don't make it any safer to use modules that you don't trust.