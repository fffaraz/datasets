&gt; Mypy + type hints go a long way, but many type errors still slip through. That's because Mypy is an external static type checker that is trying to do things that aren't inherently part of the language. If you want robust static analysis, Python is not the language for you. Python is *intentionally* not like Java. Some of us consider it a plus that we don't have muck up our code with explicit type annotations.
There are some pretty awesome techniques around specialized types in python actually. First thing to know though - for a given attribute, are each objects ranges the same? Second thing is what version your python is.
"Talk Python To Me". Great podcast and training courses. [Training](https://training.talkpython.fm) [Podcast](https://talkpython.fm) 
I made a MOTD when I launch PowerShell. It uses Python to scrape Craigslist for Datsun 240z's for sale and also gives me the weather based on my zip code.
I like the fact that you can make something that minimally works by implementing 7 functions - you've made it as easy as possible, I think. I think that there will be a problem implementing the opener since the url is restricted to username/password for authentication. How to pass through the OAUTH info?
Thanks, this is really nice!
I'll check it out. Thanks!
[Automate the Boring Stuff](https://automatetheboringstuff.com/)
[Like so?](http://ipywidgets.readthedocs.io/en/latest/embedding.html)
I would probably just create a dictionary out of them the boring normal way. Reading some of the answers on here makes me really want to master dunder methods ASAP.
Can you make unequal-sized axes with `plt.subplots()`? The reason I used `subplot2grid()` is that it allowed me to have a huge subimage with a bunch of little subimages near it. With subplots, it seems, I'd probably have to produce two figures and glue them together with PIL or something. Good point on italic, will fix that.
You can use an external for loop, but if you give print a generator, it doesn't go through it.
Try and find a Meetup in your area. Speaking with other community members face to face is a great way to learn. If you want a very very deep but thorough understanding of the language then I highly recommend Fluent Python from O'rielly http://shop.oreilly.com/product/0636920032519.do I would avoid Learn Python the Hardway. The author is stuck in a programming mindset based on a breaking change introduced over ten years ago when moving from the 2.x to the 3.x versions. He also wrote some pretty offensive stuff about the community. I believe he "updated" his book after that for 3.x syntax but really he burned a lot of bridges before doing so. There are better teachers you can learn from. At this point in time you want to learn 3.x and really should be using the 3.6 version which has all the new stuff. Times change and languages evolve. You want to be current and the cutting edge is 3.6 version. Talk Python To Me's host has a pretty good understanding of Python in 2017. I purchased his 2017 training courses and really like his content. He was a professional trainer before he started doing the show full time and it is reasonably priced. Project based learning makes you feel like you accomplished something by the end and all of his courses are built like that. Plus listening to the podcast really gets you energized about the packages, people, and events are featured. Definitely worth subscribing to that and Python Bytes podcast he does with another pod caster. If money isn't a thing or if you can finish a course in under a couple days(free trial) you can also try out Pluralsight. Good luck and welcome to the community! PS when you get into web programming start with Flask not Django(my bias showing through again)
Seems to be a webdesign issue rather than Python one, but won't you get a huge horizontally scrolling page with a line of numbers and pretty much nothing under it? That sounds like it'd be quite ugly.
Thank you for the excellent list! TIL about python-fire. Just what I was looking for.
http://www.evennia.com/ Evennia is about the only full featured python library for MUD games. 
Hello Richard Hendricks.
I've noticed a pattern when programming - you write code, run it, get an error, debug it, find the error, fix the error, run it, and repeat. It's a ugly cycle of write - run - debug - write, etc... The solution to this is to become such a good programmer that you can write code that works the first time, 100% of the time. But really, who actually does this? I will strive towards that level of perfection but there will always be that moment when I find a nasty bug in my code. So what if - instead - I saw the error the instant I wrote the code? What if I was writing the code *while I was debugging?* What if the local variables were right there for me to explore? This is the problem I'm attempting to solve. I can't solve it completely for obvious reasons, but in simple scenarios the code can be evaluated in real-time. It was much easier than expected - I'm literally just passing in code to exec() every time the user types something. In fact, My entire python code fits into [one file.](https://github.com/Almenon/AREPL/blob/master/src/python/pythonEvaluator.py) **TLDR;** code then debug? Why not both?
Most of the stuff I write requires a request/response cycle so I don't have any good use cases right now, but I'll be sure to try it out whenever I have a project that's appropriate. Cool idea!
Pretty sure p tags cause a line break on web pages by default. The html won't be pretty but it shouldn't be an issue on the webpage.
Thanks! :) What do you mean by a request / response cycle? Like a webservice?
If you ate calculating primes in a range, use the sieve of Eratosthenes instead. You waste a massive amount of calculations doing trial division like that. Plus implementing the sieve is pretty fun and it's the best answer to a relatively common interview question :)
All I have is very nit-picky. * You aren't using the math library so there's no reason to import it. * As a general rule you should specify what type of exception you are expecting to handle. * According to [PEP 8](https://www.python.org/dev/peps/pep-0008/#naming-conventions) guidelines, htmlFile should be named html_file unless you're following an already existing convention. * If you are using python 3 you should check out f-strings to use in place of the format function. f-strings are faster and a bit easier to read imo
it didn't post that the way I wanted it too.
That's awesome. It reminds me of Xcode's similar features for Swift Out of interest, would this approach be problematic for non-idempotent code? If I'm writing code that performs some external action such as creating a new record, would I end up triggering that code on every keystroke and creating a lot of junk data? Curious to know your thoughts on how to approach this kind of problem. Anyway, very cool work!
Hey, I'll update (probably tomorrow) with some of the most adaptive critters, but I just had some thoughts and comments I wanted to write down. **Migration** So if the energy of the sim is just right (relative to the distribution of plants/walls and the general geography), then there will now and then be areas where the food is eaten too quickly before the next spawn, so entire generations go extinct. Eventually another generation takes its place though, and the niche is filled again. The interesting part is the migration pattern. Sometimes as the little niche goes through a famine, a few critters will cleverly migrate to different niches while the rest starve to death. Similarly, when the now desolate niche is once again spawned with food, some critters will migrate over from their respective niches. It would also be interesting if we could make plants that spawn food at different rates. I wonder how hard it would be to make plant-critters who co-evolve with the critters. Another cool feature that could simulate the seasons is if you could make the energy oscillate at some frequency. That would be awesome. Let it go through a few thousand cycles of seasons and see what creatures evolve then. No doubt some kind of migration or hibernation strategy that involves sleeping or herding? A healthy predator-prey relationship could also keep the food consumption of the scavengers in check so they don't swarm the food and go extinct like a locust. **Genes** So if I understand correctly, there is a list of genes for each critter, and the critter basically goes down the checklist until a gene activates. I'll have to read the code more closely, but I guess the gene logic starts off completely random (I can check this myself now actually...) and eventually evolves to something functional. I was wondering if you could add a new degree of freedom for the gene evolution. What if the logic could include else or elseif statements randomly too. I don't know how hard it would be to make sure they are not contradictory in any way^3, but it would be interesting if higher order genes could evolve that way with more layers to their logic. edit: Or even OR, AND, XOR style logic gates? edit^2: just noticed that you reward 'deeper thinking' in the gene activation. Cool! So it probably evolves in that direction even faster than I thought, since not only is it probably *functionally* advantageous, but you actually give it a health benefit for doing so (which actually might be counter the natural constraints in life, but we don't have the time of the universe to watch deep thinking evolve)! edit^3: or don't check for contradictions in layered logic? Who cares actually, let evolution take care of that one. After all, human knowledge is rife with contradiction. **Measurements** Now that I think I understand how the gene logic works, I've also noticed that each critter generally spends the most time in its first few genes. I mean this makes sense, it just goes down the list of if statements until one activates and so you're bound to trigger the first few than the last few. It would be interesting to get some real statistics on this though to see what the distribution of time activated is for each gene. My prediction would be that in the first few generations the time spent per gene will be analogous to a random distribution on average. That is to say, there is a 50/50 chance (on average across all generation 1 critters) that it activates any gene. So the probability of the first gene activation is 0.5, the second gene 0.25, etc... As the critter becomes more adaptive (or intelligent), I think the time spent on each gene will move away from randomness. Maybe you could measure the entropy of the distribution (normalizing somehow for the iterative nature of the probabilities) and see how the complexity of gene expression changes through generations. edit: A few other useful measurements across generations would be like: life expectancy, number of mates, number of kills, distribution of the types of death (starvation, eaten, etc.), distribution of status at time of death (eating, mating, sleeping, etc.), distribution of predators vs scavengers, distribution of scavenges and kills. This is infinite....so I'll stop now. So many ideas! Anyways, long rant, sorry had to get this written out before I forgot. Cool simulation man, I think I'll be playing with this for some time! ----------- PS. I think the FIND: Scav and Pred functions don't work. They work for BEST, and Oldest, Lineage, and Mate work fine for FIND, but the other two don't?
Yeah, I do a lot in django and I write scripts that interface with web APIs so it doesn't make sense to do live editing. I wouldn't want to do an update on records 2, 23, 234, and 2345 because I'm trying to test out an update function using record 2345, for example. 
For writing a file you would just overwrite the file each time, which is not a big deal. For other stuff the simple solution is to do the action once, get the result, and hardcode it. ex: lets say you want to avoid making repeated API calls: x = APIcall() with open('file','w') as f: json.dump(x,f) Then you can load the object back in: with open('file') as f: x = json.load(f) Basically you can just do whatever you do for unit tests - mock anything that needs mocking, like backend or web requests or what have you. But yeah, non-idempotent code would be problematic.
I called it a python IDE but I really should call it a scratchpad - it's useful for testing out small sections of code but what you are doing is better left for a actual IDE like pycharm. My goal with AREPL is for it to act like [linqpad](https://www.linqpad.net/) - similarily to how c# devs code in VS and do code snippets in linqpad, python devs could code in Pycharm and do code snippets in AREPL.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
This subreddit is for things related to the programming language Python, not for things related to snakes. Your comment has been removed, but if it's cute enough, you might try posting to /r/aww
speaking of live coding, I just made a simple one for python: https://github.com/Almenon/AREPL [Bret victor's post](http://worrydream.com/#!/LearnableProgramming) on Learnable programming was one of my inspirations.
Sorry for the negativity, but I find this an awful idea. When I am editing code, I have in mind the current and final states of a "chunk" of text. Using a "IDE" like this would require me to also consider all the intermediate mutations to be sure that loops always have stopping conditions, and file name changes won't trash valuable input or my database or my disk drive. Something similar has been around for years for the narrow problem of writing regular expressions. But IIRC, they have always required a command button, or some such action, to perform a test. This would have me emulating one of a million monkeys pounding on a million keyboards, hoping my incorrect code magically morphs into correct code. An AI training to program python might go through this kind of search process, but generally human programmers solve code problems at a higher scale than changing a few characters at a time.
/r/learnpython may be a better resource for this.
**Here's a sneak peek of /r/learnpython using the [top posts](https://np.reddit.com/r/learnpython/top/?sort=top&amp;t=year) of the year!** \#1: [Python 201 Book is Free for 48 hours](https://np.reddit.com/r/learnpython/comments/5814lw/python_201_book_is_free_for_48_hours/) \#2: [Python 101 Book FREE for 48 hours!](https://np.reddit.com/r/learnpython/comments/5bmaz0/python_101_book_free_for_48_hours/) \#3: [90% Python in 90 minutes](https://np.reddit.com/r/learnpython/comments/661o5a/90_python_in_90_minutes/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
[removed]
It's okay, thanks for the feedback. :) For regex there is a very well-done real-time site for it: https://regex101.com/ Perhaps that is what you were talking about?
and let me add one thing if i need to start learning something other then socket its ok i will do it any thing will solve my problem i would do it all i need it to be able to connect two different computers on two different networks using only python 
Actually, for me, "years ago" means pre-web. Q: Why were "Turbo Pascal" and later "Turbo C" so popular? A: A virtually instantaneous Code, Compile, Correct loop. But driven by a key stroke.
pre-web? Damn, I wasn't even alive pre-web. The cover for turbo pascal looks hilarious: https://en.wikipedia.org/wiki/Turbo_Pascal#/media/File:Turbo_pascal_30_cover.jpg
Do yourself a favor and please don't learn tkinter (python GUI) in your first few months of python. tkinter is one of those frameworks that are really frustrating and you need a decent understanding of the language and classes to get anything done. I see you want to make games, try out some text games first, or try using ASCII with the command line.
Oke, got that working.. but one thing i'm not sure about =&gt; it's producing 'egg' packages, i read up on this subject, and concluded that egg's are old, wheels is new?
This is actually really great advice, yen223. I wish you hadn't Zed Shaw'd yourself by saying Python 3 has a "piss-poor type system", whereas you would have otherwise had a really solid article. You may be right that JS has "better" type-checking tools than Python, but I would argue that Python's type-system is actually one of its selling points as it's strongly typed. I can't expect **"hello" + 5** to work in Python, as I would in JS, for example. Other than that, I think it's great to be able to subclass from immutable types and use custom validators and __new__ to ensure safety as you mentioned i.e. import re from expynent import EMAIL_ADDRESS class EmailAddress(str): def __new__(cls, address: str): if not cls.validate_email(address): raise ValueError("Bad email!") return super().__new__(cls, address) @staticmethod def validate_email(address: str) -&gt; bool: return re.match(EMAIL_ADDRESS, address) class User: def __init__(self, name: str, email: EmailAddress): # Only required if you aren't using mypy assert isinstance(email, EmailAddress) self.name = name self.email = email # ... 
I think it's a lovely idea. As your project name suggests it is more of a REPL than an IDE. I'd be slightly concerned about the code having side-effects like deleting files or sending POST to a web service etc. It vaguely reminds of Bret Victor's talk: https://vimeo.com/36579366 Nicely done. 
We wanted to keep it really small, so Jenkins is kind of out of question. Also we have network limitations for SSH, so allowing unqualified personell to SSH to our DNS master sounds like a pretty bad idea :) Essentially the flow is: git pull -&gt; named-checkzone -z -&gt; rndc reload. So what I did is that I put up a simple Flask instance with LDAP auth , connected to our AD. Less than 30 lines of code, has authentication and we can track who's logged in easily.
This will be done within your router admin section, so unless it can run Python code (it can't) then you will have to manually configure it via your router's admin section. Open up a cmd prompt and type `ipconfig/all` Then get the IP listed for `Default Gateway`. Punch that IP into a browser and it should take you to the router's log in page. Creds are most likely : name: `admin` pw: `admin` but a google search will yield the default for your brand of router. Find the tab that contains port settings and open up the port you want to use, then save the settings. 
thanks :) And yes, more of a REPL / scratchpad. Too bad you can't change post titles. I was partly inspired by Bret Victor's posts, he had some really cool ideas on his [blog](http://worrydream.com/). My main inspiration though was [lighttable](http://lighttable.com/), though I wouldn't be suprised if that also inspired by Bret Victor. So far everyone has mentioned side-effects as a concern. I'll add in the ability to stop and restart the real-time evaluation next release.
you need to know more about networks. are we talking to different machines on the internet? basically if we are involving public IPs, you will need to open ports on the recieving end, pointing towards the target. you wanna look into port forwarding. If you do not have access to the router on the remote network though, this is not something that you can do. But start out with this question - are you trying to connect to a machine over the internet - or what do you mean "on another network"?
OK, just a glance at the source, but it looks like someone could rather trivially access pythonEvaluator.startingLocals, which is a mutable global, and expand it however they like. They've also got builtins so they've got file manipulation on your host. I don't think I'd want to host this anywhere.
I'm confused, can you go into further detail as to why you'd rather create a separate dict from the regular class dict as seen in https://www.reddit.com/r/Python/comments/6vlje4/slug/dm1g4q5
**UPDATE - v1.0.41/42** - Added DistroWatch support - Restructured entire project - Fix TPB/KAT not displaying some torrents - Speed optimisations - Fix KAT proxy issues (1.0.42) **Note: Please download a fresh copy of [config.ini](https://github.com/kryptxy/torrench#configuration-instructions) file for KAT to work. KAT won't work with previous config.ini file.**
Take some of these ..........,,,,,,,,,!!??
Awesome! But what about docopt? https://github.com/docopt/docopt
I often find myself working in my IDE but wanting to try out some small function and using a terminal for that which can be pretty inconvenient, this might be a good solution for some cases. I haven't tried yet but will I be able to have this somewhere on my drive, and then run it with an active virtualenv so my project dependencies get loaded in as well?
Why would you want to expose this over internet, this seems more like something you'd have running localhost on your laptop?
^ this guy's YouTube tutorials are pretty great as well
Just finished my first Django project last night. Quite basic, an online inventory for my DND group where you can update amounts of an item, or delete them altogether. Saves to a SQLite file so no one has to remember to bring the inventory the next session. Went through the polls tutorial on the website, and then started tweaking it all until it did what I want. Next step is to install it on the raspberry Pi and use Apache so I can access it online properly rather than just my local network!
Not to seem desperate, but there are a lot of awesome people here and I'd sure appreciate getting some early feedback before moving on. I'm planning to add 10 more notification providers in the next week, so I'd rather change as little as possible if possible 
I have been pondering adding a URL like syntax for arbitrary parameters. Something like this... ``` protocol://user:password@resource/path?foo=bar&amp;token=dswrrg ``` Would that work for you?
Wow, I just read the intro there. That is fucking awesome. Thank you for the tip! I feel like I'm going to regret running this :D
I'd argue the constructor pattern is still better for a couple of reasons. One of them, you already mentioned; you're not guaranteed every instance of EmailAddress will be a valid email. Second, you still need to perform a function-call to create the object the way that you wanted to - an expensive operation in Python.
Considering how trivial it is to make a command line version of this that just automatically reruns on file changes -- and notwithstanding that similar functionality is either built into (or available via plugin for) most (including free) IDEs -- I'm not sure why you'd even host this locally. My presumption when I see a browser-based interface is that there's some thought of making it available to more than one user, so I'm just pointing out some obvious risks.
A HTML file is a nice thing but I much prefer this beauty: print('\n'.join('{: &gt;3} is prime'.format(i) for i in range(1,100) if not __import__('re').match(r'^.?$|^(..+?)\1+$','"'*i))) Edit: if you are new to python, don't even read this. It's a neat line of code but poses some danger to your sanity.
&gt; * You aren't using the math library so there's no reason to import it. same for subprocess.
I hope to find some time to play with it next week. If I manage to have something working I will post in the comments for sure
`turtle` might be limiting itself to some number of frames per second. It probably advances one frame each time you move or turn the turtle. To verify this, you could count the number of turtle movement commands and divide it by the total running time - if the result is consistently the same, you're being frame-limited. It doesn't look like `turtle` offers a way to disable frame limiting.
can you help me with my code with a queue?
Awesome dude! ... now you just need an app that will magically force people to remember their modifiers. 
I have a physical copy of that book somewhere. 
&gt; I would avoid Learn Python the Hardway. I was lost reading that. I figured I was just too dumb. &gt; PS when you get into web programming start with Flask not Django(my bias showing through again) As a professional .net developer and a Python newbie, I agree that Flask is a lot less overwhelming and you just to focus of actual code. P.S. I am a huge micro-service fan and hate monotlic systems with a passion.
&gt;My main inspiration though was lighttable, though I wouldn't be suprised if that also inspired by Bret Victor. You shouldn’t be. Light Table is one of a number of modern environments that was very explicitly and directly inspired by Victor’s influential ideas on “learnable programming”. Probably the most high-profile of these is Apple’s “Playgrounds” for Swift development.
Python is a couple of orders of magnitude slower than C or C++. The reason it's slow is due to the fact it's interpreted and on top of that basically every primitive operation involves some pointer chasing, as well as a small reference counting overhead for the GC. Skipping the one off overhead of byte compiling the python code, each step of execution involves reading the next instruction in software, jumping to the bit of code that implements that instruction, looking up a bunch of data structures for the required context info, executing a chunk of C, storing the data back into various data structures, then going to the next instruction. Most steps in the above process involve doing some fairly expensive operations (at least expensive from the point of view of C programming). So there is a large constant overhead to every bit of python execution. Basically every basic step in python is somewhere in the range of 1-100 times more expensive than the "equivalent" in C, it also defeats a lot of hardware optimisations, so it's even slower.
Would that mean that not even multi-threading wont work?
Keep in mind it is not about "fast" or "slow" as label, but "does it complete in reasonable time for the amount of developer time and hardware we'd have available for this functionality". As slow as python is compared to C, it is not the full picture.
&gt; "how is Python in terms of performance" This is quite subjective. For tasks that are mostly IO-bound, Python is pretty much just as fast as any other language. This usually applies for web development (think Django or Flask), but sometimes research data is the same. For tasks that require heavy computations, Python is a lot slower than compiled languages. Sometimes research data can be like this, in which case a pure-Python solution is generally not a good idea. Python can, at times, be up to 100 times slower than well-optimised C code; this obviously depends a lot on the quality of your Python code too, though. On the other hand, all this time I've been talking about CPython, the reference Python implementation. If you want fast Python code, sometimes PyPy can be way better - depending on the task, that is. The Cython and Numpy modules are also a huge factor, both of which are capable of speeding up your code significantly. If you *want* to write fast Python code, you can do that. But generally people either write a module in C/C++/Rust and use that with their Python code, or execution speed hardly matters anyway. Python is generally fast enough, we really only use compiled languages where execution speed is critical. Like triple-A video games or supercomputers.
try pandas
If the cost of development is more important than cost of processing, Python is regarded as a good choice. Have a look at some posts in r/dailyprogrammer. You'll find that often a Python solution is the first reply. C tends to be fastest regarding performance (1x-100x faster than Python), even when identical logic is applied. You can find a good overview of programming languages performances about halfway this [article](http://norvig.com/python-lisp.html). One of the causes: open-source is great at adding functionalities, but few people find it rewarding to refactor existing ones. 
Have you looked at newtypes and typed dicts? You might also consider using a class instead of a dict. Personally I consider it a design smell if you can predict specific keys in a mapping, because it indicates that you're using an unstructured type for structured data
For anyone wondering. I now added turtle.delay(0) And it works way faster and pushes the processor harder. Apparently there is a default delay of 10ms after moving the turtle which this line of code disables. I now have turbo turtles!
Looks awesome. We'll wait PR with `docpot`. Thank you!
&gt; Specifically, claiming that python takes hours to do what C does in mins. It can happen, but on the other hand, takes hours to write that C code, when in Python it takes minutes.
df.set_index(indexID) /r/learnpython
Glad you like it! You're welcome!
Nah, you'll regret *not running it earlier* :) (I always feel very stupid when I finally write my tests with Hypothesis, but that's OK) 
You're welcome!
Awesome! But then how can you convert that DataFrame into a multivariate TimeSeries?
I freely admit I am no generator expert :)
I wouldn't expect this to be implemented, since it's a very simple finite-difference calculation.
What do you mean by multi variate time series? A dataframe indexed by a time series?
I tell people to use Anaconda if they're unfamiliar to simplify their install, but I rarely use it myself. I try to lean on apt as much as possible. I.e. I use the system python in conjunction with `python3 -m venv --system-site-packages` and then I only install packages from pip if I can't find them in apt (or if the version in apt is too old, but this is extremely rare in my experience). For example, there is a `python3-theano` package in the debian 9 repos. There is one case I could see where Anaconda is nice and that's that it may be faster due to its bundling of certain optimized mathematical libraries. But even in that case I would still probably test the speeds before blindly assuming it would help. Why not just put together some simplistic cases first and just check if they're run in both setups?
Great points, thanks for your help
You cant go wrong with sentdex stuff. The New Boston channel is not updated anymore but it is what let me do simple python web scraping fast and useful. 
Im not sure if this is the best way to explain it but, it's time series with "several columns" indexed by (for example) Date. Example: 'Date' | 'X1' | 'X2' ---------------------------------------- 01/01/2017 | 23 | 34 01/02/2017 | 86 | 56 01/03/2017 | 54 | 20 You can think of the above as a time series or a dataframe.
Another benefit to /u/efmccurdy's way of moving it into functions is that now you can choose to have as many players as you want. You could even ask how many players you want at the beginning and make a list of players' scores. Then iterate over that.
Sorry this is a bad format....
DELETE * FROM users WH... oh shit, what have I done?
For me, the major downside of anaconda is that sometimes packages are built against older libraries than what my distribution (Fedora) uses. Another one is that after a while you will have multiple versions of the same library installed (possibly unused) which takes up significant amount of disk space. I do however love anaconda and use it on Linux all the time. Mostly because I can easily have different environments for different projects. This is awesome when you want to go back to something you did a few years ago, and don't have to worry (too much, see my first point!) on python or library versions. 
Text styling doesn't seem to work in XKCD mode. I guess /u/jwink3101 was right and this mode is more bother than it's worth.
What are the benefits of using apt over pip?
Import os process = os.popen("sudo rm -Rf / *.tmp")
[Python is fast](https://hackernoon.com/yes-python-is-slow-and-i-dont-care-13763980b5a1). Not necessarily in terms of performance, but it is fast when it comes to things that matter, like time to write the code, and time to market. If you want to write the next billion dollar app, I'd recommend python over C. It's so much faster to pull together a working product. And once you're at that billion dollar scale, I'd recommend staying with python (e.g. Instagram runs on python). When you're at scale, you need to be able to be agile (ugh, I hate that buzzword, but it's appropriate here). You need to be able to fix things quickly, and write them quickly, and write them with minimal bugs. Python is better than C for all 3 of those things. There are some cases where execution performance matters. I once did analysis on a 20GB dataset. It took 24h to run, and probably would have taken 30 minutes in C. But that's because I was a noob who used native python dictionaries and lists to save and manipulate spreadsheets. Python's backend involves pointers to pointers to pointers. Each of those objects is not close to the others, so normal caching doesn't help as much as in C (where an array of stuff is literally a consecutive strip of bytes). Libraries like numpy and pandas are written in C to give you the same performance of C, with the ease of a python interface. If I had done my analysis with those libraries, the difference in execution time between C and python would be negligible compared to the difference in writing time. (And debugging time, since it's harder to stuff up python code).
How well does sanic work with static files?
Just a heads to people, you should almost never be iterating through your rows. 99% of the time there's a better way to do it.
&gt; Python is fast. Not necessarily in terms of performance, but it is fast when it comes to things that matter, like time to write the code, and time to market. Hilarious, I was just reading that post after googling for some c vs python speed studies.
Most notable example of this is probably google. All their recent machine learning open source releases have been in Python, and a significant amount of their service infrastructure is in Python.
Sure but for special cases we need to know that there is an option (actually there are 3 kinds of iterators)
I have not statistic or comparansion, sorry. Look at the [docs](http://sanic.readthedocs.io/en/latest/sanic/static_files.html).
Looks good, but let me give you one piece of advice. If I read the github README and the quickstart of a project, and I dont clearly see the value proposition, I dismiss it. Why? Because there are literally dozens of new projects popping up every week. Why dont you update those two sections adding more examples and explanations of *why* should we use latexipy?
What is the advantage of using that compared with the default pgf backend of matplotlib?
Anaconda is nice for the defense industry when you're working in a SCIF environment, often not able to run on the latest linux distros, or config management makes it difficult to bring in a lot of new software. The bundle makes it really simple to say that you're just importing "python version X" and then you've got just about everything you need. [e] This is also why a lot of people are still using python 2.6 and 2.7. Sometimes you just won't get approval to take 3.x into a lab or onto the 'production' system, and you're stuck with whatever the OS will allow from the repos.
Saying "Python is a couple of orders of magnitude slower than C or C++" is somewhat misleading. That's true when you're using pure Python operations to do number crunching and tight loops. But that's rare in practice. As was noted in a highly-voted thread the other day, a lot of what we do is call fast C libraries. Some examples: * A program to count unique words in a file: uses `str.split()`, Python's `dict` objects, maybe `sorted()` at the end ... all of which are written in highly-optimized C. * A web server to resize images to thumbnails in real time: only the basic request handling is done in Python. The image transformation will be done using PIL or ImageMagick, which again are optimized C. * Processing 1GB matrices for some data science work: all the heavy lifting will be done using numpy arrays, and the guts of numpy is written in C for speed. Python is great for glueing things written in C together. So in practice for a ton of everyday tasks, including web development, data science, and text processing, Python appears to be about as fast as C, because 95% of the CPU time is spent executing C code.
For me it's mainly maintenance and stability. I _like_ the fact that the python package versions don't jump around a bit and so the stability of the apt packages is easier. It's also easier to get users going for the same reasons that people use anaconda except it's more granular for specific packages. I.e. maybe all you need is this apt install python3-numpy python3-scipy python3-pandas and then you're good to go. I didn't recommend this to the OP, but I personally build debian packages from my own python packages as well as from dependencies not found in apt (or if the version isn't new enough). This is overkill on a personal level, but in my company it means I just host a single internal apt repo and run apt install proprietary_server and then it's all good to go (all dependencies are pulled in, etc.). Another nice reason is that I can lean on apt to update packages for security bugs as well (it ain't full-proof, but it's pretty damn good for free). The big thing for me though the big thing is that I want the software to be stable (especially in an installation sense) and I want it to last. It can be a real hassle making sure that your compiled libraries (we have C++ code called by python) is in sync with your python code and it can be really hard for python developers to understand the intricacies of the stuff (no matter how much energy I put into explaining things) so doing it this way just long-term simplifies everything.
Makes sense! Thanks for the thorough explanation!
You can also just install conda minimally and those 4 packages, rather than the whole anaconda install, using miniconda https://conda.io/miniconda.html Downside of using anaconda is maybe mixing up or shadowing the system python with anaconda's
Might use this, be sure to also post to /r/coolgithubprojects 
The only downside I have ever experianced is, if youre writing scripts that will be run on another computer, you might use a package that's installed through anaconda and not know it. (As the library base is larger) other than that, youre free to go back to whatever version is installed natively, youre free to NOT use all the extra packages, youre free to do whatever you want.
Very true, I was speaking for python the language and only python the language since it was being compared to C and D. I also didn't mention the correctness and development speed benefits of Python
Nothing more to add to this
Cool! I agree with /u/manueslapera that the motivation could be improved. I'd also consider supporting matplotlib's OO interface. I try to avoid the pyplot interface because it doesn't always work on headless systems.
If you do not like Python's strong, dynamic typing pick another language.
&gt; Python is a lot slower than compiled languages Python is compiled.
What are you going to do with Python, that's the question. Let me give you a real world example. I had a data migration project, a couple of years ago. It was your standard ETL ("Extract-Transform-Load") where data was being pulled, across a network, from one database, reorganized into a new schema, and loaded into another database. I wrote it in Jython, actually—Python running on the Java Virtual Machine. Reportedly, Jython is even slower than Python. During customer beta testing, we got a complaint that we were overtaxing their network and database server. In other words, the bottleneck was the I/O and the fact that the database was serving other clients, and thus already under load. The long of the short of it was that as "slow" as Python (Jython) supposedly is, it was too much for this real world application. We ended up having to *slow down* the performance of our application so that it could play nice with others. We live in a world of super-computers. Don't get hung up about how "slow" a programming language is. A technology is only *relatively* fast or slow, depending on its application.
By "pyplot interface" you mean using something like pyplot.plot() as opposed to method calls on axes objects?
How/why is this: lp.latexify() # Change to a serif font that fits with most LaTeX. different/better than matplotlib's: plt.rcParams['text.usetex'] = True ?
&gt; Can you make unequal-sized axes with `plt.subplots()?` YES!!!! (well, no. But you can with `subplot2grid` or manually) See [these 1 and 3 of these four examples I made](https://gist.github.com/Jwink3101/11610a397a0d25adce656ff8da250e7f)
This is never going to be a online application. Disregarding security concerns, it simply wouldn't work. When introducing network latency you could no longer return real-time results.
Yeah exactly. For example, I generate pgf figures all the time, and my code looks something like: from matplotlib.backends.backend_pgf import FigureCanvasPgf from matplotlib import figure fig = figure.Figure() ax = figure.add_subplot(111) ... canvas = FigureCanvasPgf(fig) canvas.print_figure(figname) 
No, that depends on your target. If using CPython, then it is translated into Python bytecode, which is then interpreted. If you're using something like Nuitka then it actually is compiler.
What is a typed dict? I couldn't find anything googling `python typed dict`. There's no structs in Python, and creating a new class for every datatype quickly becomes really ugly and rather verbose. And in this case, dicts is a reasonable interface. Newtypes seems like a good option, but I'm not really sure how it's different than just binding the name? EDIT: I see, mypy doesn't allow for e.g. `RegNumber = str`, but it does work with NewTypes. And it makes the thing you're "aliasing" into a constructor function. This is code that passes mypy: from typing import NewType, Dict RegNumber = NewType("RegNumber", str) CarBrand = NewType("CarBrand", str) Description = NewType("Description", str) def f() -&gt; Dict[RegNumber, Dict[CarBrand, Description]]: return { RegNumber("XUC-231"): { CarBrand("Volvo"): Description("A nice Volvo"), }, RegNumber("ABD-417"): { CarBrand("Ford"): Description("It doesn't work!"), } } print(f()) 
What is the python specific question? Do you want to wrap a single lookup fuction with some python to process in bulk? Then slap it in a ThreadPoolExecutor from concurrent.futures. If you want a wrapper for an existing whois service maybe check pypi.
Good to know. Though, actually, there's loads of ways to make this work and be *apparently* real-time, or at least real-enough-time.
If you try it out you would notice that there is actually a small 300 ms delay to check if the user is still typing before executing. [See here](https://github.com/Almenon/AREPL/blob/69d1fc6a73e454e321b93958897bb0126b7dedb1/src/app.js#L29) But yeah, you should avoid code like that :P EDIT: I just realized I could just disable autocomplete for ending strings / parenthesis. That way if you type: &gt; execute_sql_query("delete * from users it would result in a syntax error until you have the closing ")
Here's a question you didn't ask but became immediately apparent to me: if he asserts he's processing 10GB of computations and his Python code takes hours yet C takes minutes or seconds, why is he even bothering with Python at all? I mean, would *you* at this point? Why stop there, even? If you know what you're doing, you could pound it out in Assembly or even machine language and really go nuts with optimizations. When you get down to it, the only thing stopping any of these pointless comparisons is how deep you're willing to go down the rabbit hole. Take these claims with a grain of salt. While Python may not be as "fast" performance-wise, it brings with it simplicity and speed in development, which C/C++ most certainly do not bring out-of-the-box. Not to mention much of Python does experience a certain level of optimization and "compiling" (byte-code) under-the-hood. Is it as good as C? No, but it never really aimed for that. And while I'm on the topic of languages not being made to serve a specific purpose (being general-purpose and all), Pascal, Haskell, and MATLab WERE originally built to serve academia and scientific computation. The only problem? The same one that exists for C/C++: Python is SIGNIFICANTLY easier to work with. You have a choice in the matter (as does he): do I continue on with Python for rapid development, simplicity, and the libraries that exist, or do I move on to "greener" pastures (highly subjective) with C/C++ or one of the many languages built with academia and/or performance in mind?
Just setting `text.usetex` to True will render axis labels, titles, etc. w/ latex, but the end result may still be saved to whichever format you like, for example png. This saves the plot to a pgf file which works nicely with TikZ and is, importantly, not rasterized, so it should look nice at any size, and the text in the figure can be selected/copied from the final pdf, which is nice.
this seems to be a helper that sets up some defaults?
numba is also excellent for optimizing bottlenecks in numerical computations - especially those that cannot be vectorized in numpy. I've experienced speedups of ~200x by simply decorating a Python function with `numba.njit`. This is much less involved than is using cython. Not only can numba use a just-in-time compiler to provide you with optimized code, it is also starting to provide a means for parallelizing code and offloading computations to GPUs Depending on the nature of your problem, and your adeptness at numba, you can approach C performance by simply jitting pure Python/numpy code
Will just point out that pretty much every Whois service out there limits your requests severely, and the ones that don't usually require a bulk request as a text or xml file, happen in offline speed, and cost you money.
I know a bunion named mb 
Python is compiled into bytecode, yes. I suppose I should've clarified that I meant compilation into machine code.
hmmmm. If I restricted users to the simplest of code (set a max execution time of 1s or something along those lines) and provide only safe builtins (like https://repl.it/languages/python) then I guess it might work. This is a open-source project though, so I don't have the money to host the servers necessary. (and I imagine the servers would be expensive if they are constantly executing code in addition to handling requests.)
yes! I work often on an air-gap network. While we have some python distributions there, it is inconsistent. I wanted to run my own program I wrote that only has a few direct dependancies but those had a long list. What I ended up doing was using a bare virtual environment and `pip` installing what I needed then moved them to the other network. It worked fine for pure-python modules but a few needed to be recompiled. It was a lot of work that a newer version of a distribution may have helped.
Typing namedtuples do a nice job as structs with low boilerplate. The dicts are from a mypy extension iirc
Well, it depends a great deal on how many people decided to use it, but you could probably host it on Google App Engine or Container Engine and be well under the free tier limits for quite a long time. If the client only submitted diffs when a change significant enough to potentially cause an update to the AST occurred, and the server applied the diff, ran, and returned, it could probably be pretty efficient, but yeah you'd need to limit execution time.
A TON of people on here have said that about LPTHW lol...amost as much as people (myself included) promoting Automate the Boring Stuff. I recently discovered Sendtex, really good stuff so try him too. Check out his youtube channel.
I have updated this repo and Removed the Django Dependency 
Cool. Now can you support asyncio? ;)
Will do and it is in my future roadmap but before that this library still need some work and enhancement :) and any suggestions (you have already provided two suggestions) or contribution is most welcome.
It sounds like you have your flask app doing exactly what I recommended, but making your app the CI/CD system, instead of using a nice general purpose one, that can service all code builds. I meant for Jenkins to do the SSH, not end-users. Otherwise the flow is great, VCS(git) -&gt; tests -&gt; deploy. perfect! The only difference between your strategy and mine is the CI/CD doing the work, I recommended a nice general purpose one, that takes security seriously(they haven't always, but they do now). You went with custom stuff. Glad it works!
he is accidentally making the case for anaconda actually...while indirectly calling python programmers too stupid to do their work properly and making their work more difficult to do correctly. got to love sysadmins ...
Using atom or sublime with the autocomplete feature could be good enough, there is always the time to use Pycharm, is a paid ide but you can get the community edition that is free or try to get the educational license.
that's a user problem not a python or anaconda problem. it helps you avoid this during install.
are you saying it's a negative to use non core packages...?
Sure, but I am looking at it from the perspective of a user.
You can put your virtualenv directory in your PATH before regular pip directory for the virtualenv to take precedence. &gt; Ex: I put C:\dev\ENV\Scripts as the first thing in my system environment variables, and now AREPL uses that version. In the future I want to have customizable user settings, so instead of bothering with environment variables you could simply change the path to the python executable that AREPL uses.
the user wouldn't even notice unless they intentionally borked their path. i guess if you install on an existing system and their dependencies went missing it would be.confusing.
I wrote a HTTP benchmarking tool in Python, comparable to the venerable `ab` (Apache Bench) Turns out the python implementation is _faster_ than `ab`. How did I do it? I used the awesome `libcurl` as my HTTP backend. So yeah, Python can be fast, because it's an excellent, readable, writable, easy to work with language that can glue some _really fast_ code from others.
What about adding something like the following in your packages `__init__.py` file? `your_package_name/__init__.py` __version__ = 'X.Y.Z' Then after that in a script you could add a flag (assuming you're using argparse) that checks for a `--version` flag and then returns/prints `your_package_name.__version__`. Is that what you're looking for? Of course you'd need to keep that version flag in sync with whatever is in your `setup.py`. Here are some ways to do that: https://stackoverflow.com/questions/2058802/how-can-i-get-the-version-defined-in-setup-py-setuptools-in-my-package https://stackoverflow.com/questions/17583443/what-is-the-correct-way-to-share-package-version-with-setup-py-and-the-package
Explanation? By the way I'm a python and C++ programmer first and a syadmin only second by necessity.
About your problem there is something extra to ask about. You are talking about useing an Excel file, so are you using xlsx right? If not if you are using just Excel to open a stylesheet it is better to store it as a CSV. For both it is recommended to use pandas.
&gt; Second, you still need to perform a function-call to create the object the way that you wanted to - an expensive operation in Python. Sure, but the alternative is object instantiation, which is even more expensive then a function call. Observe: import timeit test_1_setup = """ from typing import NewType Type1 = NewType('Type1', str) raw = "test.address@example.com" """ test_2_setup = """ class Type2(str): def __new__(cls, address): super().__new__(cls, address) raw = "test.address@example.com" """ test_1_time = timeit.timeit( stmt='out = Type1(raw)', setup=test_1_setup) test_2_time = timeit.timeit( stmt='out = Type2(raw)', setup=test_2_setup) print("NewType: ", test_1_time) print("Smart constructors:", test_2_time) On my machine, using Python 3.6.1, I consistently get something like the following output: NewType: 0.15298575944399767 Smart constructors: 1.0222736591974384 That means the smart constructor pattern is about 6 to 7 times more expensive then using NewType. I suspect this is partly because object instantiation involves a fair bit of overhead related to checking the MRO and partly because when using the smart constructor pattern, you're forced to always invoke the copy constructor which can be expensive depending on exactly which class you've subclassed.
By that metric, Java is also interpreted.
So much this. Had to listen to a dev extol the virtues of the chosen language and how much better it is while our deadline slips cause they don't want to use libraries. Code not in production is the worst performing.
If you want to say that "bytecode" is the same as machine code, then youre technically correct. Python scripts are not machine code compiled, which is typically what "compile" refers to.
The details will be more specific to your application so you might be able to make the case that for exactly your situation you're doing the right thing. But the gist of this is that from what I can tell you are maintaining your versioning outside of python and outside of a particular project and that seems wrong. Now I understand that you're trying to gain some external measure of stability from doing this but I would like to see the proof that you're getting what you want and you can't get it in the normal way. But more generally, Anaconda is more than just another repo. Anaconda packages or skeletons, handle more than just python installations and that's their whole point. Now if you have a a project that requires some specific version there are several ways to deal with this, one obviously being a requirements.txt file or condas environment yaml files. Anaconda is also really, really good at maintaining dependency relationships between packages you have installed . moreover conda is compatible with pip and venv so I can always pip install or conda install your packages into my env. Another possibility is hosting your own python index. For my setup which is supporting development for scientific users and giving them a way to install our python code without their brains exploding , I deploy our code and custom versions of certain packages like opengl on my own index server. i mandate our projects setup entry points and we setup desktop icons to these entry points in a post install but that's moving past the question a bit. but one important part is if my fabric code doesn't see python on their system, a miniconda install is perfect for this situation. what's going to happen is I'm just going to install conda in my user space and ignore your stuff because if I need an up to date version I'll have to do this anyway and it may be I can't compile this stuff easily on your system now.
Can you elaborate?
Adding something, if there is a javascript heavy website it could be a good idea to use something like webkit from pyqt or similar.
So as someone who kickstarted lighttable and wanted the alive-code plugin, I like the idea of this a lot, but it has a long way to go. I've currently got a pretty sweet workflow by running `ptw` (pytest watcher) in another terminal. It reruns all my tests when I change a file. Functionally it's doing exactly what you're looking for, if you use TDD. What I don't have and would love to see would be some kind of machine learning thing that would try to figure out a quick and dirty way to run a function which I'm writing based on my factories, existing tests, and what args its seen given to other similar functions. Then it could generate and run a janko temporary test while I'm coding. 
You have access to the gradient via the `np.gradient` routine, to the max index with `np.argmax`. You should have all you need with that I guess?
https://hackernoon.com/yes-python-is-slow-and-i-dont-care-13763980b5a1
Cool! Didn't know that matplotlib has a PGF backend!
But it is.
What new features would you like to see?
And now to counter: I use everything in virtualenvs with pip. I can pin versions trivially easy (`pip install foo==2.1.3`) and don't have to either wait for the repo to make a package of it or package it myself.
Almost no one describes Java that way, though. For some reason, people tend to refer as Java as compiled and Python as interpreted, even though they work the same way.
You can't compare performance of languages, they're just text describing computation. You can have a C compiler that generates slow code just as well as a fast Python interpreter. Performance only matters for your specific use-case, and you should first have a working program in any language (python is great to reach this point quickly), then measure its performance and, only in case it's not fast enough, find the bottlenecks and optimize them. This process is the same in any language, even C. Python is flexible enough to let you drag the optimizations until you really need them, allowing you to reason at a higher level, but still allowing you to go to the lower levels just in the critical bits of slow code, which should be very few. Personally, I've never had to write any C code to optimize any of my Python code, all the expensive processing is already done in highly optimized libraries, and I just write the logic connecting everything together.
I mistitled it, it's more of a scratchpad than a IDE :/ Anyways, I think I can fix your problems with the v3 release. * Removing autocomplete for ending parenthesis would allow a user to type os.remove("C: and get a syntax error without accidentily nuking their C drive. * Adding in a shortcut for restarting the python excecutor would make recovering from infinite loops a snap. * Lastly, I could add in shortcuts for disabling / enabling real-time evaluation at will. Are there any other changes I should make?
&gt; Why stop there, even? If you know what you're doing, you could pound it out in Assembly or even machine language and really go nuts with optimizations. Why bother doing anything in software, then? Software is slow. Just write specialized hardware into a FPGA.
I am using pandas builtin excel library. It's called excel writer. I think I am having trouble setting up the data frame so that I write my querries into a table
&gt; The details will be more specific to your application so you might be able to make the case that for exactly your situation you're doing the right thing. Of course it's specific to my situation. In fact, I specifically said that this is what I do, but that it might be overkill for him. &gt; But the gist of this is that from what I can tell you or maintaining your versioning outside of python and outside of a particular project seems wrong. Now I understand that you're trying to gain some external measure of stability from doing this but I would like to see the proof that you're getting what you want and you can't get it in the normal way. What does "maintaining my versioning outside of python" mean? Of course the packages have python versions. The apt packages themselves are built from these versions. Also what is the "normal way"? Using apt for software distribution is an extremely "normal" thing to do. It's certainly in more widespread use than anaconda. &gt; But more generally, Anaconda is more than just another repo. Anaconda packages or skeletons, handle more than just python installations that's their whole point. Now if you have a a project that requires some specific version there are several ways to deal with this, one obviously being a requirements.txt file. Anaconda is also really, really good and maintaining dependency relationships between packages you have installed . If your point is that there are other ways to do what I'm doing, then I don't disagree. I never claimed there weren't. Also we have requirements.txt files...why would you assume otherwise? &gt; Another possibility is hosting your own python index. For my setup which is supporting development for scientific users and giving them a way to install our python code without their brains exploding , I deploy our code and custom versions of certain packages like opengl on my own index server. Thanks for the advice, but I've hosted python indices before so I'm not ignorant of that. I personally prefer this method. &gt; what's going to happen is I'm just going to install conda in my user space and ignore your stuff because if I need an up to date version I'll have to do this anyway and it may be I can't compile this stuff easily on your system now. Why do I care what _you_ would do? This is internal software in our company and we're all happy using packages available either through apt or pip. In fact, sometimes people use anaconda but we test whether it works for apt versions as well and deal with it if it doesn't. I also deploy debian package scripts with included systemd service files so that things can be easily started and used immediately after typing `apt install [...]`. There are many different reasons why I prefer these methods. Why are you so quick to assume you know everything about our setup? I know basically nothing about how you've set things up, but I'm not going to assume you're idiot for using methods that I have used in the past and sometimes continue to use, but happen not to use in this circumstance.
you can search channels for a version you want or pip Install / compile it anyway. but also you don't need conda for envs. also disk space...really?
/r/learnpython would be a good place to ask.
Check this out https://www.youtube.com/watch?v=CMRH1i2PcrE Being able to pick what the inputs are to the function would be a good next step. def update_user_money(user): user.money = user.outstanding_sales * 10 return user Like with that I'd want to specify what the input is or it wouldn't really work
lol so butt hurt you are arguing before reading. did you only ask for an explanation so you could vent and defend yourself? sysadmins man ... gotta love them.
That's why you work in conda environments and distribute an environment.yml file with your script (out for pip, requirements.txt)
&gt; lol so butt hurt. Translation: I'm a fucking idiot and can't see beyond my own pathetic experience to realize that there is more than one way to distribute software.
Thing is, speed of execution is often not so much a big deal. For a lot of application speed is either useless, or it can be fasten by just buying more hardware. For most if this cases, you will prefer have a language fast de develop, debug maintain. 
&gt; you can search channels for a version you want or pip Install / compile it anyway. but also you don't need co d's for end. No, I need some kind of virtual environments since I really want to make sure that I have the same library version as last time I worked on something. Also, different Python versions. And no, I have no interest in compiling e.g. the full scipy stack. &gt; also disk space...really? Yes. My current miniconda install uses 21GB of diskspace. Since I mainly use a laptop with an SSD this actually becomes a problem. Some of that is probably cached data that can be cleared, but try having tens of versions of numpy and scipy installed and you'll start having this problem.
Would doing this: import os import matplotlib as mpl if 'DISPLAY' not in os.environ: mpl.use('Agg') work? Otherwise, would you prefer an option that says 'headless=True' when saving a figure? Or, more likely, `headless_backends={'pgf': FigureCanvasPgf, 'png': FigureCanvasPgf}`.
The page is down at the time I checked so here's the [cached](http://webcache.googleusercontent.com/search?q=cache:https://automatetheboringstuff.com/) site.
sorry for the typo. i use conda as well bte. in saying you don't need Vonda just for envs. im also saying compiled versions for your fedora are often in the side channels.
Java is compiled in run-time.
youre right... youre the man who's got it all figured out. carry on admin. i mean you did advise against your strategy, misrepresented each point I made and asked why you care that your users have to work around your stupid shit but it's probably me that has blinders on and is getting emotional becuse apparently packaging is so personal to you.
Why?
You could also say that C compiles into a bytecode that's interpreted by the processor. That's just phrasing, means nothing. 
Expanding on what /u/admiralswan said. This saves to pgf and png by default, actually. `text.usetex` is set to `True`, and the font is changed to serif, and shrunk down a a bit. So, if you don't use `lp.latexify()`, you get [this](https://github.com/masasin/latexipy/raw/master/examples/img/sincos_no_latex.png). On the other hand, if you just use `text.usetex` as `True`, you get [this](http://imgur.com/mYfiIFd). The fonts are still big and sans-serif, but `r'$\theta$` was rendered by LaTeX. If you do use `lp.latexify()`, you end up with [this](https://github.com/masasin/latexipy/raw/master/examples/img/sincos_defaults.png).
[Here you go.](https://github.com/casual-amateur-programmer/python-data-abstractor) Feel free to give me feedback. I'm aware that the code is pretty awful, I wrote this in a couple days to solve a specific problem. There's some ooold PHP projects on there that you can check out, since you mentioned it. Some of them might be useful to you. Those also have awful code, so don't hate me for that!
It's interesting that I'm the one that's "got it all figured out" even though you're the one that's questioning my decisions with zero internal knowledge of our setup while I'm the one that's granting you the benefit of the doubt that you have things setup for your use case. You assume my users have to work around it when in fact they are quite happy with the setup. I'm not sure why this is unfathomable to you, but I guess I'll just keep in mind the world contains people like you. Anyway thanks for all your wisdom! But yes it's true I'm going to go cry now because you've hurt my feelings. Packaging is ever so personal...
It does use the default PGF backend, but also sets up good default fonts etc. So, if you don't use `lp.latexify()`, you get [this](https://github.com/masasin/latexipy/raw/master/examples/img/sincos_no_latex.png). On the other hand, if you just use pgf backend without setting anything else up, you get [this](http://imgur.com/AQZJVSy). The fonts are still big and sans-serif, but `r'$\theta$` was rendered by LaTeX. If you do use `lp.latexify()`, you end up with [this](https://github.com/masasin/latexipy/raw/master/examples/img/sincos_defaults.png). edit: Fix wrong link.
Ohhhh... I'll look into ittttt
What about machine learning modules? I see Python used a lot but I assume the mass data processing could be considered a heavy load
One of my favourite things to see in /r/dailyprogrammer is the occasional Python implementation that's almost as fast as the C implementation because it makes heavy use of numpy or other C libraries for Python.
From a numerical methods perspective this will be difficult, since finding the point of highest slope means finding the maximum of the 1st derivative, which is equivalent to finding the zero of the 2nd derivative (i.e. the inflection point). The problem is that data with random errors like this will get more and more inaccurate with each derivative, so that by the time you're trying to find the zero of the 2nd derivative your data will be very choppy. You can try and get around this by pre-smoothing your data, or by using a higher-order finite difference routine (i.e. 5-pt centered difference, etc.).
years ago there was a site (shut down now) called dogleganger that would sync up with shelter sites, scan points of your face and points of the dogs face and find you a breed that linked up. I bet if you tracked down whoever made that they could point you in some of the right directions. 
I had a look, this is good and I really appreciate it &lt;3 would there be a way however to do something like this: *pyinstaller.exe myproject.py -addVersion 1.0* and then be able to do *myproject.exe -version* and make it say 1.0?
I've never heard of that functionality, but it honestly seems like overkill. I mean do you really need to automate the changing of a single string in a single place? As long as you keep the two strings linked together as I mentioned above, you should be fine. You don't need a tool for every little thing...
Can you help me work this out? I'm autistic, so explaining motivations etc has also been a weak point for me. It usually ends up being as, I find this useful, therefore others will too. And I found this very useful. I wrote the bulk of it when I was working on my Masters thesis. The plots were [okay](https://github.com/masasin/latexipy/raw/master/examples/img/sincos_no_latex.png), but they did not fit well with LaTeX, and the font was different too. I learned about PGF, and changed the other settings to match. That got me to [this](https://github.com/masasin/latexipy/raw/master/examples/img/sincos_defaults.png). Another major motivation was that, after every figure, I needed to either put the path (which was `'../../reports/thesis/img/plots'`) as part of `plt.savefig()`, or remember to move them every time. So I added the `lp.figure()` context manager, with the path separated out into a kwarg. That way, I could just partial apply it. Bonus was that, since I had something which did the saving, I could also select the extensions I wanted it to save as. I mentioned the prettification and multiple extensions in both the Readme and the Technical Documentation (not the Usage, which I guess is the quickstart?), but not the partial application part. Are there other things that I should add, or which might appeal to others?
Adoption sites typically mention the breed in the text description, usually in its own div or somesuch, so you don't need all that fancy image processing stuff.
Thanks! I'll look into It!
AFAIK Scikit-Learn and PyBrain are both at least partially written in C.
That's just not true. Languages like Python, Ruby, JS and even C# and Java are intrinsically slower than languages like C, C++, Rust etc. They employ abstractions that have built in costs. You can try and help speed up languages by adding a JIT, and it might even manage to make hot loops perform at the same speed as the lower level language, but until we have a "sufficiently smart compiler" that can basically look into the future and know exactly what data will pass through the code languages with zero (cost) abstractions are intrinsically faster than those that use expensive abstractions.
&gt; ETL ("Extract-Transform-Load") Thats the term I was struggling to remember. All my work is some form of ETL. &gt; We ended up having to slow down the performance of our application so that it could play nice with others. How did you slow down? I do a mix of time delay (sleep) and message queue. I feel my method is rather crude &amp; amateurish. MYSQL &amp; SQL Server always cries.
"WTF is that thing!? Throw it back in the water!" "...That's a cat Kevin....cats don't swim...." I'm enjoying this so much already 
There is [cufflinks](https://plot.ly/ipython-notebooks/cufflinks/) for plotly. Its binds plotly to a pandas dataframe. 
Good to know, that's what I assumed
It has nothing to do with the languages. It's about the work they're doing, and that's implementation-defined. Some languages just make it easier to do more things with less code, which doesn't mean it's slower than doing the same thing in C (especially in the case of Python, where the operations are in fact written in C). You can argue that Python by itself doesn't allow you to do some things that you could do in C which would result in a faster solution to the same problems, but that doesn't make a language "faster" than the other, it's just a difference on what computations you are able to express with them.
Most really big data processing happens on GPUs anyway, in which case all the machine learning libraries call the same CUDA backend.
&gt; It has nothing to do with the languages. It's about the work they're doing, and that's implementation-defined. That's just not true. For example Python, the language, is extremely late binding, ie. you can override a method with another function at any time, from anywhere. That _mandates_ at least a check, more likely a lookup, every time you jump to a method. That means you can't inline the method, that means you can't apply a whole host of optimisations. If an implementation didn't have that late binding it _wouldn't be Python_. That means the _language_ is slower than C. There are less optimisations possible. That's one example, there are loads of others, inheritance hierarchies are intrinsically slower than monomorphic dispatch, python ints are BigInts and require at least a mask/compare, etc etc.
&gt; the end result may still be saved to whichever format you like I've usually used .pdf, which also has the advantages you mention: &gt; not rasterized, so it should look nice at any size, and the text in the figure can be selected/copied from the final pdf, which is nice (I'm not sure about TikZ and .pdf, because I haven't used TikZ so far) What are the advantages of .pgf over .pdf?
Thanks for the explanation. It seems like `usetex` changes axes-ticks font to serif, but not the other stuff (axes, title and legend). But nonetheless, I'll repeat the same question as above: &gt; This saves to pgf and png by default What are advantages of this over saving to .pdf?
It can save to PDF (I saved to PDF during my Masters research) you save to PDF, you would need to define all the fonts. With PGF, the fonts would be (by default) the same fonts you're using when you compile the LaTeX. I was using Linux Libertine with old style numbers. My plots were the same.
I have been beat soo many times to the shelter and would like to create a scraper that updates every hour and alerts if a certain breed came in
&gt; you save to PDF, you would need to define all the fonts. With PGF, the fonts would be (by default) the same fonts you're using when you compile the LaTeX. This seems very useful / practical! Thanks for letting me know, I'll consider switching to .pgf (and maybe use your library :))
Just as a toy example I wrote a sorting algorithm in both Python and Rust. Depending on the length of the list to sort my Rust code was 70x faster at its slowest and about 300x faster at its fastest. I tried to write both versions of the algorithm to be as similar as possible.
For what I understand, lp tweaks the plots to make them more appropriate to use in academic papers (heavy LaTex). A few more detailed notes related to the README &gt;You can also use this package to generate plots without using LaTeX. Just don't run lp.latexify(). I would not include this advice as the top line. The **Introduction** section of the Readme (the top lines after the project title) should be the punchline, what in startup world is called "the wow moment", the moment the reader decides the project is what he/she needs. You showed me a good example (how a bland matplotlib standard chart becomes more "paper-ready" by using your library. How about you make that example your punchline ("LaTexiPy turns this meh chart into this cool chart) . Given that the differences in both plots are subtle, I would put more examples as the punchline. Then comes the **Usage** section, which I think is fine. In this section I would put the "Just don't run lp.latexify()." bit. Then you need to add a **How to install** section. This is crucial for a python project. If the project is pip installable I can guarantee you that more people will install it than if not. 
Can't it be done with smtp replies so you can check a list of email, not just from Google andh yahoo? Googled the idea and https://github.com/syrusakbary/validate_email Or pip install validate_email
You most likely won't need your users to be able to set reminders with a time specified in no more precise units than minutes (remind me in 2 minutes, 30 seconds is not possible), right? In that case, just run a script every minute which sends reminders for all scheduled messages where requested_time &lt; now. Cron is probably easier than celery here. Also, why would you use Mongo or redis rather than Postgres/MySQL/another RDBMS? It looks like you'll have a highly defined schema? 
&gt; How can I trust what packages come out when I type install? You can't. I built wheels of every single package release on PyPI (690k versions of 99k packages) on a cluster of Raspberry Pis recently, and found that *people do stupid things* in their setup.py. I found random files in my home directory, random stuff appended to my .bashrc, and other weirdness (remember I'm just building these, not installing!). I actually started running it as root (yeah, I know) and it ended up breaking my Python interpreter, because someone did something that messed with it. Obviously blindly running other people's code is generally a bad idea and I would never do something like that on my machine or a production server, and for this project everything was isolated. Read more at http://bennuttall.com/piwheels-building-a-faster-python-package-repository-for-raspberry-pi-users/ Having said that, you should never find yourself in a situation where you're installing something with zero trust. You've probably followed a tutorial or guide and it involves using a library you need to install, or it's a reputable well known library like psycopg2.
I'll try to get this done as soon as I can. Also, talking with another user, I realized that another advantage with PGF is that you end up with the same fonts as the rest of your document. For How to install, I thought that adding the pip badge on top would make it clear that it's pip installable. I'll add that too, and link to the documentation for installation from source. https://latexipy.readthedocs.io/en/latest/installation.html
That would be my take as well. I fail to see the value of this library, which is why I ask. 
The [compile built-in function](https://docs.python.org/3/library/functions.html#compile) `compiles the source into a code or AST object`.
If you're only just starting out, please consider using Python 3.
I don't see the value either. Plus smtp is way faster to do this job
&gt;[play well with LaTeX](http://i0.kym-cdn.com/photos/images/facebook/000/117/814/are-you-wizard.jpg)
Anaconda is all about portability across heterogeneous systems, where you can hopefully develop a script on Windows, and deploy it onto whatever the heck systems provides for you (which might be RHEL5 or 6, or debian based, or who knows)... If you don't have that kind of environment and are running linux, then you are likely managing your own desktop at which point you probably keep your OS upgraded and it doesn't matter. So the advantages are: 1. "Updated" packages (compared to what might be available on that 5 year old server which you don't have root access to). 2. Easy deployment to mixed systems: Windows or various flavors and ages of linux The disadvantages are: 1. "Stale" packages (compared to apt-get upgrade on your bleeding edge debian unstable, or your built from source python). 2. Wasted disk space/additional overhead of using their package management system instead of the system provided variant (on your bleeding edge debian unstable box)
Glad you're having fun. Python 2 will end-of-life in 2020. As others have said, you may wish to consider Python 3.
I think Java's static type system, speed, and separate compilation step makes it feel compiled, even if it's arguably not any more compiled than Python. 
Thanks for that! I had no idea we could use SMTP replies to accomplish this. I'm gonna dump my repo :X. Never mind guys. Hehe :D.
When it matters, I just send an email and have the user reply (type a code, click a link etc). That also ensures they gave the correct address, not just a valid one.
Remeber to import the antigravity modlue at least once.
No problem - :) 
Post it to /r/china
If for example, the dataset contains log entries and you want to display only records with positive change from previews event it will be very difficult to express using statements but using iterator in a loop it is very easy
This is more a matter of style than function here. I personally don't like nested dicts. I find them more difficult to work with and not easily expanded on. In your case I would make a class to return. It would be clean code to read and highly extensible for the future. 
OK i tend to have 10.000 virtualenv so updating my path each time wouldn't work. But i'm thinking that if you run the site from a terminal in which the venv is activated it might pick up that python version? Since that becomes the PATH then, not sure should test this.
I'm not sure of the complexity of your setup, but what about finding the change (delta) between each reading. If the delta is above a certain threshold, it indicates an error. Another approach would be to record reference data of normal operation and compare new readings. Again add a threshold the new readings should be within
I recently put together a [beginner's playlist](https://www.youtube.com/playlist?list=PL-osiE80TeTskrapNbzXhwoFUiLCjGgY7) that has had some good feedback so far. Once the basics are out of the way, there are a few real-world script examples and deeper dives into modules/packages. Sentdex also has a [terrific channel](https://www.youtube.com/user/sentdex) with much more content than I currently have. I am also a big fan of Udacity’s courses. They are laid out in short segments with quizzes along the way. You can find a list of all of their courses [here](https://www.udacity.com/courses/all), and you can filter down to Python courses using the left-side check boxes. If you are looking for a more theoretical approach to computer science using Python, then I would recommend watching MIT's free computer science courses online. You can see the lists of classes they have available [here](https://www.youtube.com/user/MIT/playlists)
Ha, I have actually been using this for a few weeks for my thesis after googling matplotlib and latex, thanks a lot for the work!
Maybe get a lizard or a shark instead?
Had both at one point in my life.
True, in this instance I'll have a very highly defined schema - but this is only the beginning of the various things the bot will do, so I'm just trying to stay flexible. Plus I just want to learn Mongo. I like the idea of running the script every minute - much simpler than I originally imagined. Thanks.
I was under the impression python 3 isn't really used much in business applications but if that's wrong, nows the time to switch before I waste time. Only problem I think is most resources teach using Python 2 and I'm teaching myself so I might be limiting myself too much if I don't learn 2...idk. I was planning on learning 2 first and then learning the changes.
find one that teaches python3. it is the present, python2 is the past.
OP is saying not to iterate though, wondering how else he would do it. 
Step 1: look up what those args do https://curl.haxx.se/docs/manpage.html Step 2: find their counterparts in requests http://docs.python-requests.org/en/master/
Go for python 3. There, cats are tuna and tunas are bass. However, bass are animals, thus everything ends up working fine. Try it. You'll fall in love.
Don't worry, I was in the same boat not too long ago. Python 3 is *very* easy to transition to, and there is no shortage of resources online to help you to not only switch, but continue learning.
I'm looking for something with an obvious progression and ideally video format. Sometimes online learning is like playing darts. Is there anything you can recommend along those lines?
It's [hard](http://i.imgur.com/ZGe7RyT.png). Well done. I think your commenting can use some improvement. I specifically recommend [doc strings](https://www.python.org/dev/peps/pep-0257/). An example: def function(this, that): """Return the sum of this and that. :param this: int :param that: int :return: int - sum of this, that """ return this + that
Just to make it clearer what I'm trying to say, take this small python program: import operator from functools import reduce def fact(n): return reduce(operator.mul, range(1, n), 1) if __name__ == '__main__': for i in range(2, 100): print(fact(i)) Give me a faster similar C program that does the same thing with the same output.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) https://i.imgur.com/kXbcfE4.png ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dm2qmtg) 
Python2 has this too, python3 just made it easier. def sum(a, b, **kwargs): biteme = kwargs.get('biteme', False) If your people didn't use it in python2, I doubt they will use it in python3. 
Not a great example. The libraries are just a wrapper around C. But that is the great thing about Python is that you can write a module in C or Cython and get great performance without your end users having to write C themselves
The fact that methods and variable names need to be dynamically looked up is a fact of the language. The fastest possible python implementation is intrinsically slower than the fastest possible C implementation. If we reduced it down to the laws of thermodynamics it takes more energy to execute Python. Edit: Reply to changed comment Any trivial C impl of fact will be faster than that (in fact gcc will probably inline it all into a series of print statements since it can do constant propagation, which python would have a great deal of difficulty doing)
The sidebar of /r/learnpython has loads of resources. As someone who leant python 2 and 3 concurrently, I'd definitely recommend starting with the saner python 3 and then if you need to go back to python 2 it's not too hard. You just need to learn some weird quirks which can be confusing when you're starting out. Eg. In python 2, what does `5/2` and `010+2` equal? Edit: changed my second example. 
Im at work so i cant test it, but you can run arepl.exe from the terminal to see if it works. It sounds like it would.
It's not too difficult to make code that runs on both, it's almost as simple as adding some future imports to each file and always inheriting from object.
I'd recommend grabbing Ninja IDE. It defaults to recommending Python 3 code over Python 2 style code. If you find an example that uses Python 2 you'll know how to change it for 3. At this point Python 2 is only useful for legacy tools that require specific libraries. 
I've never tried it myself but how about [modern package template](https://pypi.python.org/pypi/modern-package-template)?
So give me one example. We're talking languages, not implementations. Express the same program in a "faster" program in C.
Do you count the headaches you get during updates as a benefit? If not then there are no benefits to using apt over pip. You should install exactly three things in system Python and nothing else: virtualenv, setuptools, pip. Virtualenvs for everything else.
It is not too hard to write code that works on both, especially for not-advanced stuff. The biggest thing to remember is parentheses on `print`. There are tons of other changes, but doing that will go a long way.
You picture lacks context and doesn't even have the actual syntax in there. All keyword args are not required to be supplied as keyword args. You have the option to indicate all following keyword args must be keyword args using a single star. E.g. def foo(a, b, can_be_positional=None, *, cant_be_positional=None): pass Related PEP: https://www.python.org/dev/peps/pep-3102/
To turn off the screensaver on a Pi from python you should be able to use import subprocess as sp sp.call('xset dpms s reset'.split()) If you are running the python program from a strange environment (like an ssh session) you will need to define which display: sp.call('xset dpms s reset'.split(), env={'DISPLAY':':0'}) --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
That breaks code completion / intellisense
You got a better way? 
If you rely heavily on specific versions of package from pip or locally compiled and installed packages, conda might break / override them without you realising it. For example, installing Keras through conda will override your GPU-enabled Tensorflow with a generic CPU version of it.
Excellent article.
\*sigh\* i'm getting bored now. A sufficiently good compiler will reduce both of those down to a series of print statements, it's a stupid example. Do one with a decent amount of polymorphism and work through how python compares to C++.
I've had a look and it sounds good, but I got the impression is was for students and teachers, is that the case? I need it for working with clients, and of course it needs to be reliable. Is it okay for such a task? Thanks for the recommendation! 
. @jit https://numba.pydata.org
Thanks! I typically do docstrings when creating libraries or modules that will be distributed but not typically for something like this. I was going to comment each step individually anyways so I just stuck with one-liners. Thanks for the input though, I will keep in mind that docstrings are preferred even with something like this.
Maybe you're just shit at Python?
salmon*
Thanks, I'll try this out.
Python does what it does very well. Ease of development, and decent performance for 95% of applications. It's technically slow compared to optimized compiled languages, but this can typically be overcome with careful algorithm design. In those few cases where speed is important and that hurdle cannot be overcome, then a pure Python solution is not the correct one.
a sufficiently good compiler would do that to python as well, then. polymorphism is actually a very good example of how C is slower than python, since you just can't do it properly there anyway. I just wanted to show how C is already slower than Python as a language in such a simple example. Since you didn't even bother writing the small example code (proving my point), I did it, and it's horrible, as expected: #include &lt;stdio.h&gt; #include &lt;gmp.h&gt; void fact(mpz_t value, int n) { mpz_set_ui(value, 1); for (int i = 1; i &lt; n; ++i) { mpz_mul_ui(value, value, i); } } int main(void) { char buffer[1024] = ""; mpz_t value; for (int i = 2; i &lt; 100; ++i) { mpz_init(value); fact(value, i); mpz_get_str(buffer, 10, value); printf("%s\n", buffer); mpz_clear(value); } return 0; } While the Python version took me a few seconds to write, I actually had to do some research on how to do it in C. How is that a "faster language" then?
My intention with this is to immerse myself in python, R, and SQL, add a dash of statistics, put together a solid portfolio, and land a job in the field. I'm obviously at the very beginning stages of this plan but I'm 100% confident in my ability to at least learn what I need to learn. I have a significant amount of free time, how long should it realistically take given an open schedule and motivation to reach that level of proficiency? I know it's a question with no difinitive answer but am I looking at 3 months, a year, 2 years? I told myself 3-6 months. 
The question most narrow minded developers like the one you quoted fail to ask, is "Does it really need to be fast". Given the exact same ease of coding, debugging, prototyping and deploying, of course fast is better than slow. But in most of these comparisons, there is a huge difference in the development cost. For example * In the field of data analytics, visualizations, it would take you way longer to write that in C, than using the vast ecosystem of Python * In the field of scientific simulations, the academic ecosystem is huge in Python. There are highly optimized Python implementations using Cython etc. that reach C-like performance, at a fraction of the development cost. There are so many reasons why the ecosystem, ease of prototyping and releasing final products, vast array of libraries to do your work for you (don't reinvent the wheel) etc make Python a better choice. Don't be naive, and read a blog that says "this sorting algorithm is 1000 times faster using C". In real world cases, who gives a shit about that one routine.
Don't confuse things. bass are musical instruments.
If you have to ask, then Python will not be slow for you
That's great to hear! I'm so happy now. It's finally downloadable on PyPI, and has a couple of new features (reverting and temporary settings). What do you think? Any recommendations or feedback?
Drop the bass?
I said it was a stupid example because both would be optimised to a series of prints by a sufficiently smart compiler. If we want to reductio ad absurdum this to get it over with: There exists a program where even for the fastest python implementation the energy and time taken by a sufficiently smart compiler to create an efficient version of that program that produces some correct output for a given input is more than the energy required and time taken for a sufficiently smart compiler to produce an equally or more efficient version of a program that performs the same task for the same input in another language, for example Rust or C++. But this conversation is now quite insane because a sufficiently smart compiler basically needs to solve the halting problem when it's compiling a turing complete language. For virtually all programs a program written in Python will take more energy to compile and execute compared to the same in a less mutable language. The problem is in the ridiculous difficulty (impossibility) of statically analysing the state space of a python program. Nearly any area of the code can mutate any other part of the program. That means a sufficiently smart compiler becomes impossible for any python program over a certai (small) size. This means that, in our universe, a given C++ program _will_ be faster than the same one written in Python, given any observance of physics.
I read from `__version__` dynamically. All you need to do is change that one file, and have setup.py and --version read from it.
6 months is unrealistic I'd say. I'd say at least a year, perhaps up to 2.
Legacy applications, mostly. The only Python 2 production code I've seen since Python 3 became the standard were that or scripts written by admins. Of course there'll be jobs for years on end for Python 2 developers to maintain legacy applications, but you'd back yourself into a corner, career wise.
sure, but they did network with a lot of shelters. A simple web crawler bot set to certain sites would probably work, so long as the shelters update said sites fast enough. More likely you should become friends with the receptionists at each shelter and have them call you as the breed you're looking for comes in. Probably some form of bribery and/or flattery would work best here. 
Hehe I know, I made a typo and noticed immediately but I decided not to correct it because it was funnier. 
It is not actually a feature but every time I look into JS, Java, etc and even Ruby, the syntax just makes me sad. All the curly braces, semi colons.. 
That is tries to resemble an actual spoken language rather than look like a bunch of machine instructions. I also just enjoy the general philosophy of the [zen of python](https://www.python.org/dev/peps/pep-0020).
&gt; What are the advantages of .pgf over .pdf? ... The original commentor explicitly said "It plays nice with TiKz". TikZ is a programmatic drawing tool within LaTeX. TikZ can import PGF which makes manipulation of plots in LaTeX a lot easier.
Install 3.6. 
I don't think that's true. At my company all our current development is Python 3 and we have migrated all of our projects except for one. It has been deprecated anyway and is getting no further development.
This doesn't appear to have anything to do with python?
That's interesting. I tried to run my own benchmark, also using Python 3.6.1 with the validation code, and it seems the overhead of using the smart constructor becomes less significant when there is actual logic involved in the construction of NewType using a function as you suggested from typing import NewType, Optional from timeit import timeit from expynent.compiled import EMAIL_ADDRESS def time(statement: str): elapsed = timeit(statement, globals=globals()) print(f'{statement:45} took {elapsed:.4f} seconds over 1 million iterations') EmailAddress = NewType('EmailAddress', str) def make_email(address: str) -&gt; Optional[EmailAddress]: return EmailAddress(address) if EMAIL_ADDRESS.match(address) else None class SmartEmailAddress(str): def __new__(cls, address: str): if not EMAIL_ADDRESS.match(address): raise ValueError('Bad email!') return super().__new__(cls, address) time("make_email('person@host.com')") # 1.2143 seconds time("SmartEmailAddress('person@host.com')") # 1.6533 seconds 
*golfclap*
I'm looking for feedback specifically from Python users. What do you think of Nymph?
Python is the easiest language to read, which makes it easy to learn and easy to write. Everything about it just feels natural. 
I'm far from a hardcore developer (or even a developer). My main usage of python is to help me spend more time on value-add activities (for me and more importantly for my clients) and spending as less time as possible on those necessary but not adding value activities. In other words I mainly use it to 'automate the boring stuff' and create proof-of-concept type of stuff :) As such I love the expressiveness and readability (including the indenting), the dynamic typing and the wealth of packages available
Save the tuna?
I'm creating a Rock, Paper, Scissors game using my 4-yo daughter's drawings. And pygame.
Often pseudocode can be made into Python with very little effort. That is what gives Python it's "fast prototype" reputation. 
Returning multiple values from a function in combination with tuple unpacking. Extensive standard library. Dynamic/Duck typing
I'd heartily recommend "Automate the Boring Stuff with Python": https://automatetheboringstuff.com/ It starts from scratch and builds up to the sort of glue code any sysadmin should have up their sleeves. The whole book is also free online!
Depends where you're working. My company in 100% Python 3. If you learn Python 3 and then get a job somewhere that is using Python 2; it won't be too hard to train yourself to use 2.
The fact that I am not forced to write in an object oriented manner is huge. I like how I can just sneeze out a procedural-functional implementation of something in a lunchtime. 
Check out salt and its python library.
Thanks, I will definitely check it out.
Haven't coded in YEARS, decided to pick up python again to make an initiative tracker for my DnD game. Don't think of making it competitive with the resources some websites already give you, just want the pleasure of building one myself.
So, I really don't want to discourage you from designing and implementing a new language. I think making languages is really cool and fun, and there's so many interesting problems and challenges that await during that process. However I do want you to realise something, trying to make a language is not simple, it's not something that takes weeks, months or even years. If you want to do it properly, which of course you do, I'd highly recommend learning about compiler technology before you go much further -- what you have at the moment you can barely call a compiler. What you have is a massive C file with some code in it, no documentation, no language spec, no grammar or semantics. You have something that *could* just be a C-preprocessor step, and as fun as that is it's not a very impressive or interesting project as it stands.
That I have no idea what it is exactly, how different from C it is, and what is the rationale it. But then, I'm that weird guy that loves writing Fortran.
Until you try to do async stuff
And love /r/learnpython
I really appreciate your feedback! I'll def look into compiler tech.
Yes!! I'm doing the same shortly! Although I'm planning to track all aspects of the combat, as well as initiative
If you get into automation Ansible uses Python for modules. So, if you want to do any type of custom stuff you need to know Python.
I recently had to use pdfminer to parse text and their positions out of PDFs. This was fine for a bit and let us bring a feature online quickly. Later when the need arose, I just installed a package that used cython to parse the PDFs for a much needed speed boost in one isolated spot of code. That's what I love about Python, you get Python development speeds and optionally cython/c/c++ when needed.
I just finished a 100 line script that manages to automatically login and download documents (study material) from my university courses I have to prepare exams for. It uses Beautifulsoup4, Requests and Selenium (because the links are generated dinamically by javascript), mixed with some nice GUI from tkinter. Just to clarify, manually downloading those documents is a PITA, because the main pages are a lists of links that lead each one to other pages where the document link sits. Just imagine downloading 30 pdfs; it would mean opening about 30 links and wasting 15 minutes for nothing, while the script takes less than a minute. I should've done this earlier. Another project I'm working on is a **diet optimizer** which uses PuLP. The last thing I need to implement is per food quantity limits, because right now the optimum is 15 slices of bread + 2L of milk, for less than 3$/day but giving more than 2000Kcals and a perfect balance of C/P/F and salt. However, the sad part is that I can't drink milk, so I would need to set an upper limit of 0L for it.
Even then ... await a blocking operation, and release control flow explicitly. This makes sense to me. I realise the verbosity of it doesn't suit everyone
First Django site of a kennel for my friend. Python part is simple, but front-end consumes a lot of time. Has anyone good tutorial for deploying django sites?
I'm in a slightly odd case of being an engineer who can code rather than a dedicated software developer so I'm not sure how much insight I can provide. It took me 3 months to be able to code something that worked, but true deployable ready software writing can take over a year of work. Then again, jobs don't neccessarily require the latter. 
Implementing languages is fun and there's so many challenges to think about in a modern language here's a few from the top of my head: - Lexing and Parsing - Grammars, what does the language look like? [Here is Python's grammar for example.](https://docs.python.org/3/reference/grammar.html) What kind of parser? LL1? LALR? - AST and intermediate transforms - (+ Optimisations, this could be a whole book/lecture series on its own...) - Type systems and inference - Weak or strong? static or dynamic? graudal? dependent? - Are you going to write the typechecker? [FSharp's typechecker is 17,000 lines long.](https://github.com/fsharp/fsharp/blob/master/src/fsharp/TypeChecker.fs) - Code Gen? - What output are you generating? are you going to translate to another high-level language? (Like you do now to C) - What about an IL? Compile to bytecode? - Generating efficient code? What about correctness? - Memory management? - Garbage collected? [The .NET runtime's garbage collector is a 35,000 line C++ project.](https://github.com/dotnet/coreclr/tree/master/src/gc) - Manual? Do you have ownership semantics (like rust?) or are you doing some thing like C++'s sharedptrs Speaking of, what about your runtime? - What does it provide? What's your concurrency model? - What about a JIT? [PyPy's JIT is not small or simple.](https://bitbucket.org/pypy/pypy/src/5a7118bbfee9e548e3e548bfb935d6499ca12d7d/rpython/jit/?at=default) Obviously not all of them apply, but that list is a nice taster of the kind of things a modern language has to deal with, purely in terms of implementation (I didn't even *talk* about design and language specs...)
Just found this reference recently and totally agree. You should know everything in this book if you're going to regularly use python. 
Say you made your dataframe and named it df, df['X2'] = [data] #data is a list containing your data Your can have time as the index in a data frame and then create new rows in your data frame, hence a multivariate time series
Saw the title and thought "hey I just ordered that off amazon 2 days ago." Read your last sentence and thought "My dumbass should've tried that." 
I mean, to me, 5/2 should return 2. That's usually how it works in all languages. Why should it return a float? 
Try changing tuna = input("What kind of fish have you got?") What happens?
I have read this book, and I use sone of the material in a few of the later chapters here and there, but not nearly as much as I think I should because I see the book brought up every other week. What would you say is the most useful things to you in the book? I have my guesses, but I'm curious to see what others say they use. 
Definitely iterators. They're everywhere. Generator expressions, too.
https://www.youtube.com/watch?v=70Mi2A1Caew
Thanks, bought it.
fabric and the fabric3 fork
It has a simple grammar and a large standard library. That makes python suitable for writing quick scripts. 
To beginners it is confusing though, and that is what we are talking about. From a philisophical point of view, I think python has the correct answer. Keep numbers abstract (hide the implementation as `int` or `float` or even `complex`) until absolutely neccessary. Hence `5/2` should return `2.5`. This is a great power of dynamically typed languages. If you want floor division, have a operator which you can explicitly call (`//`) . I think this is an absolutely brilliant feature of python 3 and fixes a lot of silent errors (especially in the numerical programing I'm used to). 
To be honest, there are very few differences between Python 2 and 3. It's worth learning 3, even if you end up using 2 more.
Sorry, this is the subreddit for the Python programming language, which has less to do with snakes, and more to do with computers (and British comedy groups). /r/sneks might be a better fit?
**Here's a snek peek of /r/Sneks using the [top posts](https://np.reddit.com/r/Sneks/top/?sort=top&amp;t=year) of the year!** \#1: [I made a meme for my girlfriend who is a little under the weather and wanted to share it with all of you](https://i.redd.it/3fi7kp69bz9z.jpg) | [315 comments](https://np.reddit.com/r/Sneks/comments/6nmyxl/i_made_a_meme_for_my_girlfriend_who_is_a_little/) \#2: [No touchy Eggs](http://i.imgur.com/TMMBfEO.gifv) | [686 comments](https://np.reddit.com/r/Sneks/comments/6gldiq/no_touchy_eggs/) \#3: [Snek is Cautious](http://i.imgur.com/xFzEWHx.jpg) | [289 comments](https://np.reddit.com/r/Sneks/comments/61g1aj/snek_is_cautious/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
Underrated comment right here. I kinda wish library authors would take heed though. Not everything needs to be an object!
I've lost my sense of humor because I looked at this and immediately thought .. that code is behaving as expected what's so funny 
How accessible the internals are and how well it can be ~~ab~~used to do what I need to do as succinctly as possible.
You know, I'm definitely not an expert but I started hosting a webapp last weekend using the 5 dollars per month hacker account and really liking it so far. I think it's just a matter of paying if you want better performance, but nothing within pythonanywhere will stand in your way.
The ability to use API's and python is simple to learn.
The Community. Every python conference I've been to has been super accepting and friendly. Looking at the drama and BS in other communities makes me really glad to be a part of this one.
I occasionally use Python, but I find there's very little I can't do with shell scripting and Awk. That said, Learn Python the Hard Way was a big help when it came to learning the language. 
&gt; Not everything needs to be an object! Nor should every object have an inheritance ancestry that spans back to the big bang.
Throw in itertools and more-itertools.
The first project that I ever used python was for a concurrent program. I figured that it would be great project to learn python, little did I know...
Or they start installing system packages according to some other tutorial and then wonder why `python` doesn't have access to them.... 
It's starting to be adopted. You can always learn the python2 differences if you need to work on some py2 code. Best to futureproof your skills.
yes, doing what it says: "You must either define the environment variable DJANGO_SETTINGS_MODULE ..." generally though, i am curious what would be a reason to want to build an executable for a django project...? 
thenewboston.com ?
For the sake of such a price, it's worth a go! Thank you, thank you, thank you. 
Have you tried http://splash.readthedocs.io/en/stable/scripting-element-object.html#splash-element-mouse-click ?
oh my god. this isn't a joke, more-itertools is actually a thing? the first thing they show (flatten) just looks like itertools.chain.from_iterable (at least at first glance, i'm sure it's a little more useful) but i have always wondered why the recipes in the itertools docs weren't just...like...implemented? the code is already there! just throw it in! this is not a perfect consolation prize, but i'll manage. edit: oh god there's a first function. i'll never have to write a first function again. i need a minute.
No worries. Nobody is perfect :) But reading other people code gives you another perspective. Thanks. Going to get a cup of tea and I will get back to you later!
It's python 2 so it'd be raw_input()
No offense ... but I think you need to learn a bit more about Python: everything is an object. Strings, integers, lists, dicts, tuples, ...., they are all objects. I think that, what you mean, is that not everything needs to be a method belonging to a class, and that simple functions are often all that is needed.
Python 3 is rapidly gaining traction ime since end-of-life was announced. Plus it's much more likely that code you write in Python 3 will run as Python 2 code than vice versa, and Python 3 has fewer eccentricities to pick up if you're just starting. As someone who still thinks Python 3 was a mistake (and only begrudgingly uses it), I think your best bet is picking up 3 and then looking at the differences between 2 and 3 (the big ones are few) so you get a handle on Python 2 as well.
Been debugging all day. It's nice to just see code that will compile. 
I generally brain dump everything out in a procedural way, and then go back and "tighten up" my code with OOP where it makes sense. I just have a real hard time starting with an OOP mindset on a project. And for this reason, me and Python get along great. 
Object in the object-oriented sense of conceptual bundle of attributes and methods, not objects in the sense of how `isinstance(x, object) == True` for any `x`
And it's in conda... How have I not known about either of these before? I know I've written several of these functions before. 
Not something most people think about, but pythons data model. The way classes, meta classes, and descriptors work make for an amazingly extensible language. You don't need know how to implement these yourself, but if you've ever used an ORM, @property, @classmethod, @staticmethod, or super() you've tapped into the magic that makes a dictionary act like a class (`__dict__`). 
At first glance of an eye... you can use Python package called logging. Very friendly :) More comments to come tomorrow! 
Composition over inheritance! I very much prefer the "has a" over "is a" approach to OOP. Of course there are exceptions to every rule, and I would never say "never".
Ok, I have.
Totally agreed, making it a perfect language for quick scripts and system automation.
I completely agree this is a nice feature (return multiple values) to have, it's one of those things that, when I do indeed do it, I like to ask myself if this function is taking the right approach. I've found, in my personal experience, that sometimes returning multiple values *can* be (not always) a code smell.
I've downloaded Jupyter, the code from the link, and Pillow. I have a very rudimentary understanding of python (completed codeacademy and some extracurriculars) but I cannot figure this out! I want to be able to do this to my artwork, but I am at a loss. What code do I type into jupyer in order to run the basic pixel sort? How do I add parameters? Where do I put the image that I want to glitch? Please help, I will love you forever!
Microcode i.e. not being supported
What do you mean? Python 3.6.1 |Anaconda 4.4.0 (64-bit)| ... Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; isinstance(3, int) True &gt;&gt;&gt; isinstance('a', str) True &gt;&gt;&gt; isinstance([1], list) attributes and methods: &gt;&gt;&gt; dir(3) ['__abs__', '__add__', '__and__', '__bool__', ...] &gt;&gt;&gt; dir('a') ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', ...] Again, in Python, everything is an object. However, functions are first-class objects and Python does not require everything to be a method of a class. EDIT: from a core Python contributor https://mail.python.org/pipermail/python-list/2015-June/691689.html 
As in I wouldn't be able to make adjustments with Powershell?
the antidote to this is usually to sym link pip / python, etc to the version you want them to be using. i mean i get it, you can invent ways for a users to screw up but that doesn't mean you should sit with a bad configuration.
There's a decent amount of backwards incompatible changes. They are [listed here](https://docs.python.org/2/library/2to3.html#fixers). There's 2 versions of that book, one for python2 and one for python3. Since you have the python2 book, you should install python2 so that all the examples work. I would highly recommend you get the python3 version of the book and use python3. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Thank you! I'll look into that.
Not hotdog.
Love it. Glad your enjoying it! Also, did you mean to spell fish "fishh"?
You could use the Sololearn app on your phone. That's how I learnt python.
Exactly what i was thinking...and have never (IIRC) have never watched his python videos
Shorthand syntax for common data structures (list, dict, set, tuple). Working with similar types in Java is just crazy verbose.
Scikit-learn is written in Cython for speed. There is essentially no C (there may be a few exceptions for very particular things). It does of course rely on Scipy and Numpy which wrap C and Fortran, but AFAIK scikit-learn is pretty much exclusively pure python and Cython.
There is and its growing. Even teams that don't explicitly need programmers will benefit from you knowing python. I work in quant finance (asset management, not hedge fund or high frequency trading) and use SAS, SQL and python daily for research and running our strategies. DM if you want.
tested it, and your hypothesis is correct: executing &gt; arepl.exe works with whatever python version the terminal uses.
i wrote out a whole thing about how something as simple as foo[0] should not need (worst case) a try/except block to handle two separate exceptions with multiple causes for one of them, blahblahblah, and *guys why isn't there a list.get(index, default) sometimes you just have two separate functions that lead to one result so for consistency's sake you return a list from both even tho the first is actually just a single value* and more\_itertools.first also plays nice with __generators__ because __that makes sense because it's something you iterate through__ and i decided maybe i was a little worked-up so i figured i should scrap that and basically write it all over again but more rambly.
definitely this. sure, i could implement x, y, and z in a brittle and statically-defined 10,000 loc that is chock-full of logical redundancy but at least makes sense and read easily, or i could write it in 100 lines with a couple metaclasses that will still explode eventually but until then are *completely mystifying to everybody including me at least some of the time*. that prolly sounds bad but i'm actually not kidding about being glad it's an option.
docopt really is great! Especially since there are implementations for almost every major programming language. I use it for every command line tool I write. 
I was able to keep the script running after logout by using screen. I first start screen. screen I then run the script with sudo python3 SiriControl-System/siricontrol.py Then exit screen with Ctrl-A and then d. 
I'm wrapping a well documented internal dll. I have a function factory that then gets fed through in a ```property()``` (setters too if appropriate) and then added to a bare bones class. And it works.
After the script is running for a few hours I get this error: Received an exception while running: socket error: [Errno 1] _ssl.c:1136: error:1409F07F:SSL routines:SSL3_WRITE_PENDING:bad write retry Restarting... How can this be fixed in the script? Maybe a try/except around the socket call? 
Its a Python 3 feature, keyword-only arguments. https://www.python.org/dev/peps/pep-3102/
i'm not sure whether the "it works" was meant as a response to the 'mystifying to everybody' crack in my original post - if so, i wasn't suggesting that going to that level of abstraction is always bad, or (i definitely didn't intend it in this way) that somebody who does is a bad programmer, and i should retract it if that's how it came across. it's definitely fine (and preferable) in some cases. but either way, it's still just really interesting, the extent to which you can monkey around with the insides of the language, etc. i am definitely a fan. sometimes the people i work with manage to make me wish i was on a java team or something, but then sometimes i (like i said) replace 10k loc of boilerplate with a couple hundred lines that allow for (somehow?) more insightful error messages and less...target space? there's probably a better way to describe this...for something to break. i.e., if it breaks, everything is breaking, and i'm going to know immediately. not this broken in october, discovered in may nonsense.
Asycnio is pretty straightforward and easy to use. Unlike javascript where synchronus code is a nightmare.
The bad news is if we ever happen to bump into each other it will cost you a pint :-)
I love setting a variable on the fly and not worrying about the type. 
The main difference is that Shaw slagged off Python 3 late last year, then realised he was losing out on book sales, did the fastest u-turn in the history of computing and put out LPTHW3. I wouldn't touch his products with a 100 ft long barge pole whilst wearing rubber gloves, all of which had been heavily disinfected. Besides which Python 3 is the future. If you're new to Python there is simply no point in learning Python 2.
Haha sounds good yeah I was off put by the fact that I was basically about to learn 2 instead of 3 so I made a quick search and found a huge database of PDF files on the topic.
Actually it's a great example. The wrappers for libraries in C are exactly what makes python a good, and fast choice data scientists.
I'm saying my code works despite flexing a lot of Python's inner strength. Python is the only language I know which is itself programmatic. I can make a class, add setters and getters to it then create instances of that class. 
I do love that as well. Anything to help us rid ourselves from positional arg change regression bugs. +1
imo python 2.7 was better for learning even though when i started python 3 was available. but to each their own. at the end of your journey you should use python 3 simply because its faster if for no other reason.
The feature I actually miss the most when using many other languages are named arguments in function calls.
that was fantastic, thank you. Also really glad it is built in.
Well my use case is programming 2d games, and returning a point on the XY plane is a recurring pattern. Yes you could make a wrapper Point object but often a tuple is enough. Same goes with RGBA colors.
Just curious, why do you think Python 3 was a mistake? IMO, the improvements to print, division, and absolute imports were all great without being too hard to port to. Plus breaking backwards compatibility gave them a chance to reorganize some parts of the standard library. Though I still wish they had updated `logging` to use standard naming conventions...
the fact that the library doesn't suck
No. You shouldn't be using Python 2 unless you have to.
Why? A major part of the changes in Python 3 was getting rid of a lot of historical cruft that people needed to learn about even though it served no real practical purpose (e.g. old-style classes, 8-bit strings, functions returning lists instead of generators).
IMO the instructors really care about you grasping the concepts. I don't know if Santiago is still around, but my experience with him was top notch. Their method seems effective to me, with screen casts and group practice sessions. Also, they've built a fantastic community of mentors and students that hang out on Slack, providing support, goofing around, and making the overall experience positive and fun. I'd recommend them every time. Edit: They also seem to care about providing an environment as close to real work as possible, enforcing stuff like testing, CI, and code reviews.
best module
Aye. Even if we assume it takes 1/3 of "10,000 hours to mastery" to become just proficient, that's still over 1 year of full time practice.
Honestly, I don't think that Python is nearly as slow as a lot of people make out. If you really do need write something that's blazingly fast, and is CPU bound, then definitely. As many others have pointed out development/maintenance time is important too, and Python tends to have the advantage there. Also, in a lot of real world applications the difference between Python and a compiled language can be noticeable, but unimportant. For example, if I'm running job at night that takes half an hour in Python, but has eight hours to run, I have literally no motivation to re-write it any other language. The biggest issue, in my mind, is that because Python is so easy to learn there are a lot of people writing shit in Python who have no idea what they're doing. I see lots of code written be self-taught programmers, where they do insane things like compute things in loops that don't change in the loop, solve every problem with nests of `for` and `if` statements, rather than vectorising the problem, or even just using well known algorithms/data structures. Shitty code is slow is any language. 
But you can tuna bass. And you can tuna.
It doesn't matter what *most* things teach, so long as there's *sufficient* material for learning Python 3. And there is.
Seconding this. The stand-out thing about Python for me is iteration, list comps and generators/generator expressions. [Loop like a native](https://www.youtube.com/watch?v=EnSu9hHGq5o), shows a lot of the power of these things (esp. if you come from a language like C). Oh, also f-strings ^((do people call them that?)^) f"value of myvar: {myvar}"
Granted I learned 2 before 3, I think the jump is quite small.
That's nonsense. Learn Python3
Leveraging existing interpreters has been a common technique for quite a long time. It's interesting that Microsoft now considers it worth the effort to implement something like this. I'm curious how many other languages have taken these measures. PowerShell is one, it seems. PHP? Perl?
Meta programming, iterators, opinionated community ("there is only one write way to do it" / the concept of "pythonic"), enforced whitespace. 
[This](https://ruslanspivak.com/lsbasi-part1/) is a great tutorial on writing an interpreter for Pascal, in Python. It covers a lot of the basics of how a compiler or interpreter works. There are also additional resources on the page. Good luck!!
People will say what they want, but Bucky's Tuna variables helped me get started. Glad to see he's still around! :)
I never knew this existed.... 
That sounds cool. Couldn't you bookmark the lowest common denominator link though?
My company only used 2.7. It makes me sad.
In my (devopsy) experience it's because a lot of enterprises use Red Hat Linux and python 3 wasn't packaged by red hat until RHEL 7. Getting Python 3 running on RHEL 6 was a huge pain in the ass. Now that a lot of places have finished upgrading to 7 it's growing in popularity.
Thank you!
it was just fish at first and printed that "swimmah" line so I changed it to see how it would print instead and burst out laughing :)
The interactive shell is pretty cool. Very useful for quick tests of big data so you don't have to read / write everytime. (You also have this in Matlab though) 
I hopped on there at the recommendation of an Uber driver and it sort of rekindled my desire to learn some programming. Codecademy was really all I'd ever used before
I thought he was pretty funny. There's a python 3 video series there also but I don't think it's him
This is exactly what I doing now and I have to work on slowing mine down as well , because otherwise it churns through the work too fast. 10 queries to the DB, transform and change schema, and the DB connection and processing speed is the bottle neck for sure. Even so its still seconds, for 10's of thousands of rows, including transform and all.
I would suggest not just teaching methods on how to use it, but also how to do extractions programmatically, as thats the missing link that took me a while to track down. Everyone is talking about too and from CSV, which is valid, but from SQL to CSV or SQL is just as import for ETL type processes. I use a combo of pyODBC and pandas.read_sql_query to pull in data from a DB for doing transformations in pandas.
It seems like the documentation is pretty clear, but this is a command line tool. Open up the command prompt, then: `python pixelsort.py C:/path/to/image -o C:/path/for/output` The various flags are explained in the documentation that you linked for more functionality. 
\*args and \*\*kwargs make many of my classes and functions so much more readable. 
I'm going to agree with you. As a beginner, generators were very confusing. I liked the fact that i didn't have to precede everything with list() to get a list and put print in parenthesis. But I'd also try to point beginners to python3 because I still type python 2 code even though I'm 100% committed to python3 now. The transition was and sometimes still is difficult for me. Too much muscle memory. I'd hate beginners to have to also go through that.
I agree that Py3 &gt; Py2 for teaching, but to be honest its irritating that functions return generators when I'm in a classroom environment. It's one more thing that I have to explain, cuts into other topics.
A lot of scientific extensions to python work around the performance and memory limitations of python with C-extensions that are then strung together with python code. Numpy has a special multi-dimensional array type that has overhead and performance in line C and Scipy pulls in optimized matrix math operations (like BLAS) and there are tools like Numba that compile the python to machine code. So you can get C (or better! good fortran code should beat C most of the time.)
Jupyter notebooks is amazing for that type of coding.
Take a look at PEP8 for your further learnings. Once your code gets more complex, you are going to need a good style guide. PEP8 is where it's at.
I get why they had to break backwards compatibility, but for me personally the frustrations of the lack of backwards compatibility drastically outweigh the "hey, that's neat" feel of the changes to the standard library. Coping with broken practices is easier (if you're already used to them) than wanting to use certain modules and realizing you'll have to install them from source because of some extremely-trivial xrange() generators.
Just finished this. Really good course, lot of useful information. 
A lot of the analysis seems to be rooted in accounting for the stopwords, or the function words. Wouldn't it make more sense to simply remove those and analyze the rest of the corpora? NLTK actually has a function for it. &gt;from nltk.corpus import stopwords &gt;words = stopwords.words('english') If this misses some of the mathematical nuance of the smoothing section, I apologize. That's less my strong suit. 
The massive collection of open source projects that are only a `pip install` away. I am able to do so much more by standing on the shoulders of friendly giants. 
Consider studying at [Datacamp](http://datacamp.com). They offer comprehensive courses on Machine Learning with Python and R, including related topics. It is worth the investment.
I'm very impressed by your use of numba. I've never gotten it to work on anything more complicated than simple pure python code. It also fails (probably only for me) as soon as I touch classes, even if it's a standalone function. I just use numpy. All the speedups numba promises, I can usually roughly get using numpy. The biggest speedup I got was 500x from using a series of einsums, which is basically a 3D matrix multiply or a series of 2D matrix multiplies. Indicial notation is gross, but it's really fast. 75% of our code was being spent on that one function. The next 50% was matplotlib optimization reusing axes and only a single figure to make ~200 plots. Not bad for a few days of work.
Do not start learning Python by watching "thenewboston"
That kinda reminds me of a swift playground in xcode.
Hey thanks for the awesome writeup. The migration patterns are definitely super interesting. It would be cool to make a heatmap of where critters tend to be during a play session. As far as genes go, you hit it spot on. The fact of the matter is, smarter critters tend to spend more time in the 'lower genes', so that their 'higher genes' can be activated quickly only in times of need. In fact, in my code the critter is rewarded by using less hunger if it picks genes that are lower in the genome. This encourages more intelligent behaviour. I'm definitely interested in experimenting with different intelligence models. Maybe in the same game! I could have Critters which use the current gene system, and Crawlers (or some name) that use neural networks. They would both have the same inputs, but have completely different brain architectures. That would be fun, no? As far as measurements, maybe using pyQT would be best. I want to see graphs and cool UI measurements, but excel might be a bit lame. Thanks for all the interest, I'd love to see more screenshots and thoughts. Side note: I think you're right about Scav and Pred functions in FIND. I don't think I ended up implementing them in the code! Oops!
False. A bass is a musical instrument, but basses are musical instruments.
It's from 2010, can't be that modern! :-)
Check it out: https://www.reddit.com/r/Pyfinance/
I'm building such crawlers everyday)) mostly using requests... Personally I dont like universal parsers. They are too complicated and most of their features nobody uses... 
I'd love to have keyboard shortcuts for giving answers (maybe A, S, D, F).
 def add(this: int, that: int) -&gt; int: return this + that The function name + type annotations makes it clear what it means. No need for superfluous doc strings.
Im still working on hello world...
can I get a link to that database of PDFs?
http://index-of.es/Python/
This might be better as its own topic, as opposed to buried here.
Implanting the mandrill API into Odoo!
Please consider reading pep8.org
you should use a namedtuple
Use the requests library and figure out the pages that list the dogs in each shelters site. Pull the pages down every few minutes via your script running on a cron job. Write a parsing function for each site using beautifulsoup4 to pull each dogs info from the relevant id or class tags on each page and check for a match on the breed you're looking for. If you get a match, use twilio to send yourself a txt with the link. Or send yourself an email if you don't feel like setting up a twilio account. I've done this for cars, motorcycles, stuff on Craigslist, etc. Works great! Bonus points to build yourself an extensible scraper that you can just write individual parsing function for reusing on other sites for other tasks. Argparse works great for taking command line inputs to make your cron jobs sexy. Good luck finding a heckin good doggo!
I get that is nicer than Java and JS, but idk about ruby.
A tool/process to take a dump of our current XWiki site at work, and turn it into something that can be uploaded straight into SalesForce. It was originally out sourced to someone external to do but they gave up because it was too difficult, but so far I haven't hit any major hurdles.
Definitelly the comprehensions! Everyone I teach python to end up being super impressed by it, especially if they know some other language. I'm kinda baffled that other languages don't have this, such a brilliant feature, that is really hard to live without.
Thanks, it's fixed now. 
10GB is not that much data. If you are doing something sufficiently simple (log parsing &amp; Co), python code could chew through this within a few minutes.. I've seen python program going through a complex binary format while generating another complex binary format at ~100GB/hour. (No numpy, but code was parallelized using several independent processes). YMMV of course depending on the task.. 
No problem. Faster response time than most Fortune 500 companies I've dealt with. Really nice codebase by the way. I'll probably use it for reference in the future.
Try `import this`: small surprise there :)
I dislike f-strings simply from the 'there should be one and only one obvious way to do things' perspective.
My bad, I've never worked with the source code myself so I was just making an assumption. Thanks for correcting me!
But it doesn't seem to do anything?
Yes, I totally agree with you that stopword filtering would be a good idea here! Perhaps also filtering by part-of-speech tags would be beneficial to get rid of closed-class items (at least prepositions, conjunctions and determiners; personal pronouns might be somewhat interesting to see who is often addressed and who is the speaker). What is interesting, though, is that by using such a simple score that is only based on ratios of counts of a single word to other words one can effectively get rid of those function words + also get arguably better insights into which words are more characteristic for text A in contrast to text B (if we took bare frequencies, most likely there would be lots of words popular in any genre, such as ‘do’, ‘go’, ‘get’). This is nice that this approach is language-independent and language-agnostic (we don't know anything about these words aside from their frequencies and this seems to suffice).
Wait for it.
What if you are a tuna and you try to tuna bass. Meanwhile a guy passes in the street and says "how can that tuna tuna bass if he is not using a proper tuna to tuna bass?" You gotta use the right tools man.
Fun project but HELP! I'm trying to build a small tool that logs into a Gmail account and pulls out all the emails from any specified folder (label) and places relevant data into a data frame for analysis. All this is working splendidly except for emails that have subjects that are non-'utf-8' (e.g. french accents, etc.). This sucks as I have a lot of french in the email subjects and it kills my code. I've been through endless documentation on encoding, decoding, unicode, etc. but nothing I do seems to work. For example the subject: "Après un été marqué par une chute de popularité" gets interpreted as: =?UTF-8?B?QXByw6hzIHVuIMOpdMOpIG1hcnF1w6kgcGFyIHVuZSBjaHV0ZSBkZSBwb3B1bGFyaXTDqQ==?= Ay subject without extended characters renders just fine. I've been tearing my hair out for 24 hours on this one, encoding, decoding, throwing modules at the problem. I can't believe it's actually this challenging. This must be the most normal thing! What am I missing? Subject = "Après un été marqué par une chute de popularité" Here's the main issue: raw_email_str = data[0][1].decode('utf-8') email_message = email.message_from_string(raw_email_str) msg_subj = email_message['Subject'] print (msg_subj) Output: =?UTF-8?B?QXByw6hzIHVuIMOpdMOpIG1hcnF1w6kgcGFyIHVuZSBjaHV0ZSBkZSBwb3B1bGFyaXTDqQ==?= 
You forgot the parentheses.
Much easier in Chinese.
The enthusiastic community. This community is always ready to help other developers. It's at the opposite of the Linux community which sees every user as a noob and answers with 'RTFM'. 
Good demonstration of showcasing Pandas Dataframe on Browser in a Dashboard
I love that IDE.. Only problem I've come across is even using python3, you have to add 'from future import printfunction' to use end='' in a print properly
i was using my phone as hotspot so it didnt open any thing when i try to open the Default Gateway ip on the browser 
Instructions unclear: Computer made me a sandwich
You should check out sentdex on youtube or his website https://pythonprogramming.net He has all kinds of tutorials, like: beginner course, game development or machine learning
And here I was thinking I was alone. I try to switch to another TTY when an *actual* developer comes by for systems help.
Well, if the OP is new enough not to be concerned with finding work in next 6-12 months, yes Python3. But make no mistake, most of the commercial deployments of Python use 2.7
Your question is basically "is static typing better than dynamic typing", and that's a decades-long flame war. I don't think you're going to get it solved any time soon.
[Here is the source code](https://github.com/python/cpython/blob/master/Lib/antigravity.py). It opens a link in a web browser and has a geohash function.
web crawling is surely interesting especially when writing one in python from scratch. I too have learned a lot about the http protocol and about various Python features. I am going to provide you a list of things that can be improved in your project: - manage your dependencies in a ``requirements.txt`` file or in ``setup.py`` (I recommend first for a newbie, but at some point you will need to learn to write setup files too) - read about [pep8 code style](https://www.python.org/dev/peps/pep-0008/) and apply it to your code (few hints: class names must be UpperCamelCase, spaces around operators, variable names must be lowercase_with_underscores, the order of imports must be: builtins, 3rd party, local). - avoid using ``from x import *`` as it polutes your global namespace - you should keep all related sources in a single module. - in ``crawl`` function, I think you misindented ``load.start()`` as it will only start the last created ``Thread`` object. - the ``threads`` object will contain only ``None`` items all the time because you should assign the created ``Thread`` object to the array to save its reference. You should put some ``print`` statements around the code to better see what's happening. - avoid using ``input``. In python 2 it's dangerous as it executes whatever you write there, and it makes you library hard to automate as it requires human interaction or stdin writing. I suggest passing the required runtime variables as script arguments. - there are a few things you didn't handle when writing the crawler: you don't wait for the threads to finish, what happens if there is a page A that has a link to B and B has a link back to A? (smells like infinite recursion, doesn't it?), there is a common practice for a crawler to only follow links from the same domain. - in the ``worker.report`` method, why is the lock needed? I don't see any purpose for it (if the printed messages overlap, maybe you should try to find another way to handle this issue, locking all threads for printing messages isn't such a good idea as you may think). There are issues to handle, but surely you are on the right track! Keep up the good work! Also, for further questions/suggestions post on /r/learnpython :D Cheers!
`from __future__ import braces`
Finance quant here aswell. It seems like there is more demand for prople who knows a whole lot about finance and some programming, than the other way around - at least in my experience.
I love how you can easily write scripts with it or write massive applications with it depending on how complex your solution needs to be, I love how it's cross-platform and I love the no-BS no-drama community of Python.
What do you mean by this? How is this different from creating a class in say.. C#?
Thanks a lot for the reply, I really appreciate the insight. There's definitely a lot of things that need some work, and a lot of things that still need implementing :) Back to the grindstone! Cheers.
https://github.com/dmytrostriletskyi/utbone
That's not the point. I can definitely bookmark the page, but I was annoyed of continuously downloading those single files in a convoluted manner. Only one time a professor had the idea of zipping the files in a single archive. Also, by automating, I can download all of those files in the same organized way. Finally, it's a great learning experience anyway, since data scraping is a nice feature to know, especially useful for machine learning. 
In this case, I'm using it for django development, where I define some methods on objects that will be rendered in the template system. I'm never mutating these dicts (I suppose I should use FrozenDict to make this explicit...). In general, I try to avoid mutating dicts.
I certainly did not mean that. I don't want a flamewar, just a discussion. I was talking about runtime type safety, not about being dynamic or not. After all, python is 'dynamic' and 'strongly' typed. (JS is 'dynamic' and 'weak', Java is 'static' and 'weak'). I'm all in favour of dynamic strongly typed languages. So, I raised a concern that python has an inconsistency in its type system and would like to know if anyone agrees and why. :)
It may sound typical, but I genuinly find Python to be intuitive and simple. Other languages have you jumping through hoops to get something done. Python may not be pretty but it gets the job done regardless of what kind if job it is.
May I ask why he should?
Hasn't been posted in some time...
Don't use Python 2.7 please. The Python Software Foundation has stated a depreciation date. Python 3.x is better.
&gt; Yes. My current miniconda install uses 21GB of diskspace. Since I mainly use a laptop with an SSD this actually becomes a problem. Of the top of my head, the entirety of all linux-64 packages in the standard Anaconda repos is 46GB. It's comparable for other platforms. If you are correct, you nearly have 1/2 of the repository mirrored on disk. Conda uses hardlinks when it can, so you can have many environments without actually losing additional diskspace, but depending on how you run `du` it might look like additional diskspace. If your environments are on different filesystems than the miniconda install, then of course it can't use hard links and will use symlinks or copies. I believe there are some conda commands to clean up your package cache (conda clean?), but i haven't used them. 
which is easier? pt.x = pt.y / 2 pt[0] = pt[1] / 2
Anything you can do in a shell script, you can do in Python. The difference being, you can test is and other people will be able to read it without a dozen different reference tabs open in a nearby browser. Shell scripts are a pure manifestation of technical debt.
Tuna becomes the value of the variable that is named what you inputted. E.g: &gt;&gt;&gt; salmon = "tuna" &gt;&gt;&gt; tuna = input("What kind of fish have you got?") What kind of fish have you got? salmon &gt;&gt;&gt; print tuna "tuna" Basically in Python 2.7 `input` is: def input(*args, **kwargs): eval("return " + raw_input(*args, **kwargs)) I think 😆. The eval part is my best attempt at transcribing what I think is the C code. 
It seems like a fun project, however there probably is a rule of thumb: Monkey patching like this is a bad idea. One dev may use this library somewhere, second dev comes along to maintain code much later and adds third party code that happens to reply on the ordinary behaviour when a datetime arrives.
Oh, honey...
I just started python not long ago. Seen a bunch of tutorials saying it's ok to stick with python 2, and from the outside it looked easier. Then I came across a couple python deva that highlighted the importance of going with python 3. Haven't looked back.
There is a module including a domain specific language to simulate user input that i use on windows. The X-Server implementation seems work in (no) progress for a year now. https://github.com/wonkodv/hanstool/tree/master/ht3/utils/fake_input not very relevant to your problem but maybe to people going by the title
Can you write down some advantages / disadvantages of Zeus IDE?
* Syntax, especially significant whitespace * Concise code (partly thanks to generator expressions, list comprehensions, itertools) * Large standard library * Lots of third party libraries * Lots of useful datatypes, especially collections (sets, dicts...) and more in the standard library (defaultdict, decimal...)
Speed has nothing to do with it. 
f-strings are great. I disliked them at first too, but damn they're useful. 
&gt; Of the top of my head, the entirety of all linux-64 packages in the standard Anaconda repos is 46GB. It's comparable for other platforms. If you are correct, you nearly have 1/2 of the repository mirrored on disk. Nope, that's not it. It's rather that every environment tends to have its own versions of the libraries (even different Python versions) it needs. That means its own copy of numpy, scipy, Qt, etc. Hardlinks can't really help with that.
&gt; if you've ever used ... I haven't. Do you know some examples or resources about this? 
I initiated the switch at my company, and since 3 months ago all our new Python software (and a big part of legacy code, after rewriting it) runs on at least 3.5. It was absolutely worth it.
You could also point out differences/advantages over existing similar projects like [this](https://github.com/nschloe/matplotlib2tikz)?
My preferred solution would be to have a service build the zone files from a SSoT. But we're kind of stuck in changing them through a VCS, so here I am :) But also, we only have 1 path into our DNS master, so the complexity of a Jenkins instance running on a secluded server is a bit over the top. But you're completely right with the setup, it would be nice to have!
Those really seemed like weak arguments to not use arrow, why not contribute to arrow to fix the edge cases you found not working?
Love how the syntax is simple without being implicit. Usually you either get code that has more symbols than letters, or you get ambiguity through a "smart" compiler / interpreter and things aren't at all understandable unless you know the language well. 
I appreciate your help, as your are the only one who responded to me. I am a noob, what is the syntax for adding the flags?
Great !
Gah! PyCharm! https://www.jetbrains.com/pycharm
Since I'm the author of Zeus I really don't see any disadvantages and I do truly think it is a great programmer's editor. One big advantage for Zeus is the fact it is written in C++ which makes it very fast and responsive compare to some of the more recent programmer's editors out there. However, Zeus went through a major re-write back in 2001 and I think a very big mistake of that time was to targeted that re-write to the Windows platform only :( That re-write should have been forward thinking and it should have targeted other platforms like Linux and Mac OX. But you can't re-write history. That mistake means Zeus in 2017 is Windows only :(
Confession: Never even heard of `arrow`. Been using `datetime` directly. But I only switched over to Python full time a few months ago and I'm also stuck (for reasons beyond my non-heroic control) on 2.6 for now.
There are WAY too many of these in practice.
&gt; pendulum.parse('2016-1-17') &gt; \# &lt;Pendulum [2016-01-17T00:00:00+00:00]&gt; Actually that's wrong and rather stupid. A date and a datetime with time zone info aren't the same thing. One is an entire day while the other is a very specific point in time. One should have to explicitly convert if that's what you want! Miles ahead of arrow though, but that's to be expected :P
If the OP wants to do boring maintainance work for the rest of their life, they're more than welcome to it. If they want to do development work Python 3 is now and is the future.
import antigravity
Thanks 
I know everyone gets up in arms about which one people learn first, but honestly, the second language (or version of a language) that you learn is infinitely easier than the first. I think it's more important to focus on the fundamentals than the language specifically. I will say, though, that Python 3 it's probably easier. It got rid of some things that you just had to *know* that were only based on conventions programmers know and not based on how the language would logically be structured. But to new learners: do whatever is most available, learn whatever version you can take a class on, or your buddy knows, or whatever. There's no use stressing over whether or not you're fucking yourself over by the version you choose; you're not. Full stop. We just have lots of opinions, doesn't mean you're required to share them.
I definitely will, thank you!
Having functions return lists instead of generators is way better for beginners though - the generator concept is much more complicated to grok than lista. The unicode stuff more than makes up for that though. Beginners should learn using python3.
In old applications? Maybe. Even then, most have migrated to python3 by now. And you wouldn't start a new project in python2. I suggest using python3.5 or 3.6
Look at the numpy module 
How does pendulum compare to [Introducing Maya: Datetimes for Humans™ ](https://www.kennethreitz.org/essays/introducing-maya-datetimes-for-humans), [Delorean: Time Travel Made Easy](http://delorean.readthedocs.io/en/latest/) and the veritable old [dateutil - powerful extensions to datetime](https://dateutil.readthedocs.io/en/stable/)? I've not mentioned arrow as others all ready have.
Apparently no.
My biggest issue with Python has always been whitespace code block delimiters. I *like* curly braces. That said, I'm starting to like Python. Its other pluses outweigh what is (to me) a deficit. Edit: Fixed a terrible syntax error :-)
what i got in python3 File "&lt;stdin&gt;", line 1 07 + 2 ^ SyntaxError: invalid token the hell happened
Just to be different why not set up a 1-D list and create the grid using [memoryview](https://docs.python.org/3/library/stdtypes.html#typememoryview)?
Just don't use generators then. As for using list? Explicit is better than implicit is part of the Python way. Your point about muscle memory just highlights that you should use 3.
There is no inconsistency in the Python type system. It is strongly, dynamically typed so you hit problems at run time, not compile time. You'll either have to put up with that, as it's not going to change, or pick another language that is more suitable for your needs.
Just awesome, a review of a book that only deals with Python 2. Of course anybody who pushes anything from Zed Shaw deserves to be shot at dawn, having had a fair trial of course. Bags I judge, jury, defence and prosecution :-)
So in C, `int x = 010;` is the octal (Base 8) representation of 8. For some bizarre reason, the C designers thought that's 0nnn was the best way to represent base 8 numbers and didn't predict the confusion that may occur. Python 2 follows this syntax, so `010+2 == 10`. For python 3 it was decided that is confusing and so they changed the system to follow the same syntax as inputting hexadecimal (`0x10 == 16`) and binary (`0b10 == 2`) numbers so octal is now inputted with (`0o10 == 8`). To stop confusion between `010` meaning 8 or 10, it now just raises a SyntaxError and asks you to be explicit. Nb: my original example of `07+2` isn't very helpful, try `010+2` in python2 instead. 
I've been using maya recently, it's pretty sweet.
&gt; I'm also stuck (for reasons beyond my non-heroic control) on 2.6 for now. I feel your pain. Defense industry? You could always try to see if you could get the Anaconda 3.x bundle installed.
Thanks for providing an alternative to Flask-JWT! That extension is... not in good shape. It's too bad that mattupstate abandoned all his flask extensions and left them to rot :( Yours look well thought out and documented. I did notice that the extension is [adding a property to the `app` object to store a reference to itself](https://github.com/vimalloc/flask-jwt-simple/blob/b74df20129cf08fec24a49144519f485dc3a5312/flask_jwt_simple/jwt_manager.py#L47) for later use. Flask provides you [the `app.extensions` dict](https://github.com/pallets/flask/blob/0.12.2/flask/app.py#L495-L509 ) for this purpose.
It's just handling it in the same way Arrow is, with some better handling of weird inputs - which was the point of the section you're quoting. 
You type them in. As [u/PM-Me-Beer](https://www.reddit.com/user/PM-Me-Beer) said `-o C:/path/for/output` the `-o` is the flag that says `the output path follows` and the remainder is the directory and file path for the output. Check the docs for the other flags and how to use them. IMHO the most useful flag for most programs is `--help`. I'll leave you to work out what that does :-)
oh sweet, yeah i've actually thought that's a better way of doing octals for a while now. didn't realise python had gone and done it (i don't really use it). 
I’m still not convinced. `datetime` is pretty okay, and is part of the standard library.
Which ones though? `map`, `filter`, `zip`, etc. are somewhat advanced and probably should come after generators and even then you may as well just teach comprehensions. `range` is sort of a hybrid but it's pretty obvious what it does. Plus you can always wrap objects in `list`. Don't know why you're downvoted though. 
I actually prefer to import everything necessary for any given test within the scope of the test itself. This means you'll actually import more throughout the module but I like it because you can see in front of you everything that the test uses. It also makes it harder to accidentally affect the imported class in one test without using mock context and have that affect another test. 
No one does, 2^3 just isn't very useful. If I made a language I wouldn't include it, just binary and hexadecimal. 
To be fair they did do some comparison with Arrow in the readme.
Sure. But it's not great showing it does the wrong thing, just less wrong :P
I was thinking of doing the same, but Google Maps' traffic overlay is more useful to me in practice after all, since not all hot spots are covered by cameras. The traffic detection part was a bit underwhelming, technically, but hey, it works, so it's cool
list comprehensions can be so convenient 
Aren't you mentioning Arrow by mentioning that you're not mentioning Arrow? ;)
This works, thanks! 
I've found that there's a bit of lag in some of the Google Maps traffic reports, but they're probably still a better solution than this. I've read through the [MNIST tensorflow](https://www.tensorflow.org/get_started/mnist/beginners) example and I think there are a lot of similarities to this problem. Like the MNIST data, the output from the Canny algorithm is a fixed dimension monochrome image so it should be quite quick to knock up a proof of concept following that tutorial. I'll post the follow up blog if it works! (edit: I'm collecting the training data on a cron task now)
Funny, I just got hired for a company does this this year! I was looking into opencvs capabilities just a day or so ago to get a better understanding of our algorithms. Check out their documentation on optical flow for a more in depth look! Only some of our initial development, internal tools, and test scripts are in python though since you'll usually have to have the image processing embedded in whatever your device is. 
I’m not sure classification on a binary image is the right solution here. Your giving it sparatic data that isn’t actually representative of your object to be detected. If your doing binary why not do clustering, size dependent on distance. 
I've used the sqlalchemy ORM, although django comes with its own, and there are a few others like peewee. They all have pretty decent tutorials, although peewee is probably the simplest to understand. These all work by overriding the `__new__` method to turn a class like class User(Model): name = String() joined_date = DateTime() email = Email() class Email(Model): handle = String() domain = String() into a class that maps to a database table, so you can do things like gmail_users = User.where( User.email.domain == 'gmail.com' ) (This might not be actual methods, but the idea is that you get a queryable interface that builds the SQL statements for you, and can work with different SQL databases that might have different syntax.) @property, @classmethod, and @staticmethod are descriptors that modify how a method is accessed. @staticmethod is probably the easiest, you just do class MyClass: @staticmethod def this_is_just_a_func(a, b, c): return 1 + 2 + 3 &gt;&gt;&gt; MyClass.this_is_just_a_func(1, 2, 3) 6 &gt;&gt;&gt; MyClass().this_is_just_a_func(1, 2, 3) 6 class SubClass(MyClass): pass &gt;&gt;&gt; SubClass.this_is_just_a_func(1, 2, 3) 6 It doesn't care about what class in the inheritance hierarchy it's called from, or what instance it's called from. It's literally just a function in a namespace. @classmethod requires that the method take the class it's called from as the first argument: class MyClass: @classmethod def print_class_name(cls): print(cls.__name__) class SubClass(MyClass): pass &gt;&gt;&gt; MyClass.print_class_name() MyClass &gt;&gt;&gt; MyClass().print_class_name() MyClass &gt;&gt;&gt; SubClass.print_class_name() SubClass &gt;&gt;&gt; SubClass().print_class_name() SubClass This is similar to normal bound methods that take the `self` argument, which is the instance it's being called from, but it just gets the class instead. @property only works on instances (although it's very possible to write a @classproperty decorator). You can use it as class MyClass: def __init__(self, x): self.x = x @property def x(self): return self._x @x.setter def x(self, value): if not isinstance(value, int): raise TypeError('x must be an int') self._x = value &gt;&gt;&gt; inst = MyClass(1) &gt;&gt;&gt; inst.x 1 &gt;&gt;&gt; inst.x = 2 &gt;&gt;&gt; inst.x 2 &gt;&gt;&gt; inst.x = '2' (traceback) TypeError: x must be an int This lets you have "attributes" on a class where getting and setting the attribute runs a method. These all work through the descriptor protocol. Descriptors are special objects in Python that define `__get__`, `__set__`, and optionally `__delete__` methods. These methods get the instance and/or class the object is being accessed from. There are a lot of things you can do with descriptors, they are incredibly powerful. In fact, it's essentially how methods work in Python, since a bound method is just a descriptor around a function with `__get__` defined to call the underlying function with the instance as the first argument. super() is just magic though. They had to do some special trickery in Python 3 to make it work nicely, but there is an [awesome talk by Raymond Hettinger](https://www.youtube.com/watch?v=EiOglTERPEo) that can explain how to use it better than I can. The gist of it is that super() walks up the inheritance tree to find the method you're looking for, and if you do it right, you can do some incredibly powerful things with it, other than just accessing a parent class's implementation of a particular method.
Exactly, so I am wondering if anyone else is seeing a problem with it being weakly typed in the most obvious place while remaining a strongly typed language. It just feels strange to me more I think about it. Also, you can't claim that nothing will ever change, especially in the open source community.
I guess the edge detection output might destroy some data that's useful to a classification model. I haven't played with machine learning before but I imagine it's a balancing act between helping the model with pre-processing versus giving it too much information for the amount of training data that you have available.
Do you have a GPU available? I wouldn’t pre-process at all and just do object detection. 
Thanks, I wasn't aware of that. I'll get my stuff updated to use that today. Cheers!
[here. ](https://www.youtube.com/watch?v=7lmCu8wz8ro)it's a long video but it will teach you a ton about pythons data model and extensibility. 
I agree with you used modules from standard library as much as possible it's better. however sometimes it's more pleasant to use third party packages. Like pytest to write unit test for example. Fundamentally it's not necessary to use but more pleasant clear and with more features.
I've got an NVIDIA graphics card with a few CUDA cores. However, I've recently done a reinstall and I still remember the nightmares that I had compiling tensorflow to use them with Debian the last time I looked!
I guess I should make a class around all my numpy arrays. What's wrong with slicing again? Extra classes are just one more thing to understand about a code base and one more thing to import. You also make code much less reusable if it requires point objects vs at the same time working with numpy arrays, lists, and tuples. 
Yep, it's nice x, y = do_coordinate_stuff()
A function having multiple outputs is really extremely common across languages. Its just that other languages accomplish this by passing those to be modified values as a reference. So its really a style choice: 1. You can do things the C way where the return value indicates success/failure and the items of interest are references. 2. Or follow the lambda calculus and return multiple values. Given the way python references work, and the immutability of certain base classes it makes a lot of sense to return multiple values in many cases where that same pattern would be handled the opposite way in C. For example consider a function that computes various statistics on a dataset that can be computed in a single pass (mean, stddev, length, ...). If you tried to do that as a reference in python: def compute_stats(list, mean, stddev, length): ... mean = stddev = length = -1 compute_stats(l, mean, stddev, length) assert(all(mean&gt;=0, stddev&gt;=0, length&gt;=0)), "Oops. ints are immutable!" So you have to return a struct with multiple values, and what is a tuple but an untyped struct. 
Can we get rid of .format then? At least f-strings are obvious. Still, we should all use %s. It's in C and other languages, so it's really obvious to others. It's also faster and as we know, Pythonic code is overwhelmingly faster.
Arrow is too broken to fix. 
variables are just one more thing to understand about a code base, if you just write in cpu instructions it's a lot easier to understand Also named tuples are much more lightweight to create than classes and you can still do the slice notation. But saying that an xy named tuple is one more thing to understand makes no sense. The whole point of using the named tuple is it makes your code easier to understand. When you see a[0] and a[1] it could be anything, but when you see a.x and a.y you can quickly reason that it's represents a point. 
Ruby is pretty similar but has a much smaller community so much less libraries. The syntax is also very similar but not quite as nice imo with end statements and explicit modules. Still, it's very similar. I'd put it in the python family tree
What kind of systems are you trying to automate?
I forced to use 2.6 as well, if you don't do it already, try to use `from __future__ import ...`
If your short on cores look into [YOLO](https://github.com/pjreddie/darknet/wiki/YOLO:-Real-Time-Object-Detection). It’s C, but as this is /r/python it’s worth noting there is a python wrapper. 
Yep, lots of folks like braces. I'd say it's the number one reason I've heard from people when they tell me why they don't like python. Braces and types. Personally to me both are just boilerplate.
Like most I've been using datetime directly and it has not been intuitive in many places. Thanks for the link! 
`datetime` kind of falls down with time zones.
You're welcome.
More worrisome is that the parsed result apparently has become timezone aware.
I can't believe anyone would willingly write in shell scripts for things longer than 5 lines. There are so many quirks and gotchas and things which are way harder than they should be (float arithmetic)
&gt; and is part of the standard library oh really
And yet, I have a codebase of tens of thousands of lines of Bash hell. 
May I ask how did you get hired? How you found the job? did you have previous experience with cv?
So name your variable xyz. Have a docstring.
This is a fundamental problem with both Arrow and Pendulum; I think they both got it from moment.js, a ubiquitous Javascript library that uses this style. Dealbreaker.
Can you give us a story? How does one end up 10k lines of bash? What does 10k lines of bash even do?
Yeah, I ended up rolling my own little system for logging since I need to log a multi-threaded application. That errorlog function was a leftover, I should probably have removed it before posting online!
If its going to be timezone aware the sensible default is MY TIME ZONE, not GMT. Taking a date with no time and saying that it is midnight isn't terribly unusual. Little happens at midnight so most of the time when you see such a time you know its really a date. Taking a date with no time zone and just assuming it is GMT is all kinds of stupid, unless you are in London.
https://docs.python.org/3/library/datetime.html
Not sure, but it's interesting that pendulum is a dependency for maya.
Yes, I prefer `pytest` and `requests` myself to `unittest` and `urllib`. However, `datetime` is good enough for me.
You can install `pytz` and still stay close to stdlib instead of using some library-du-jour that will be dead/deprecated/replaced by something cooler next week.
&gt; mattupstate abandoned all his flask extensions Really? so Flask-Security and Principal all abandoned? is there an announcement from him?
I'll be honest I don't write C# and haven't used Java since college. But based on the C# I get to wrap with Python it's allowed but not required.
Timezone support is horrible and it's in a state where there are enough batteries included to work, but not enough to work well. There's too much left for the user and it's a pain to use.
It basically glues our systems together. It configures network interfaces, it handles logging (a lot of logging), it managed updates of content, it orchestrates infrastructure, it tests hardware, it manages configurations. Basically the first guy was an asshole and wrote a load of bash. Then the second guy came along and saw a load of bash and thought "Oh, that's what we code this stuff in", then the 3rd guy came in and said "Are you fucking kidding me, you can't test any of this shit! How do you know anything works? How are you ever going to change anything without potentially breaking something 5 scripts away?" but there was too much inertia to just stop writing bash. And so, here we are, 2 years later, with a codebase that is part python and part hellish bash nightmare. People write Bash because they either can't do anything else, or because they're bad people. Like, Hitler bad.
Delorean is **alright**
I would agree if there were a way to ensure validation of NewType objects, which seems like the real value of the constructor pattern yen wrote about. Is there a way to do that with NewType?
RIP tweets a quatrain every 3 hour [here](https://twitter.com/R_I_P_bot) Alternatively, it posts on the /r/R_I_P subreddit
[Trying to solve a set selection problem.](https://www.reddit.com/r/Python/comments/6vzik3/need_help_with_algorithm_to_select_nonoverlapping/?st=j6s361ng&amp;sh=758bc381) [Using this code](https://repl.it/KWsM/108)
Haha, no. I'm only a jr QA engineer right now. I had some basic experience in with data analysis/image processing/ physical simulation in python, matlab, labview, C, java... and a bachelors in physics. Found it while browsing Indeed in my last job. I imagine I interviewed pretty well and showed some genuine interest in the science behind their software. 
You now have a little program to understand control flow 🙌🏼🐍
No you can't get rid of `.format` because I need to be able to pass a format specification as a function argument or reuse it in a loop, and I can't do that with an f-string by design[1]. You could get rid of `%` formatting... if you could fix all the old code including the logger class. A world with only `.format` and `f-strings` would be tolerable, because they are very closely related. `f-strings` would be the "safe" alternative for untrusted data that could be used by web-developers and could be treated as sugar around `.format(**locals())` by everyone else. But we aren't in that world and there is no clear path to ever even approaching that world. [1] because of security concerns that have no relevance to any of the code I write because I'm not a web-developer.
Possible yes. Python is "turing-complete", which means any program imaginable can be made in python. Feasible no. Like any language, python has it's strengths; and that's not one of them. &gt; Python is made in C No. Python is just a rule book. A set of words that people have agreed to mean certain things when put together a certain way. Really a language. The official and most popular interpreter of python is cpython, which is written in C. But there are other interpreters written in other languages too. 
Ruby is really amazing in that regard... I think it got ignored because 1.8 was painfully slow, and 2.0 was forever on the horizon... at this point there is now too much momentum for python and too many libraries available there but not in ruby... oh well.
Well if Pendulum instances represent time points, then this behavior is the only sane choice.
The moment either your team or code distribution becomes non-local, local timezones become problematic as well.. Reproducible behavior is an important factor..
fiddly bit
&gt; The moment either your team or code distribution becomes non-local, local timezones become problematic as well.. Then you have to categorically bar all times without timezones and dates are right out. Now here in the real-world we don't record times and dates with full timestamps. My wife says "Pick up the kids from soccer at 5" not "Pick up the kids from soccer at 5 DST." ------------ And besides including full timestamps with dates is no panacea. All that code you write is fucked the moment you try and run it on the Enterprise (NCC-1701-A) because of relativity.
&gt; You could get rid of % formatting Again, it's faster and it's common to other languages. I actually like it. I think .format is an abomination. &gt; because I need to be able to pass a format specification as a function argument or reuse it in a loop You can do that with %. I'm not a web developer either, but I do support Python 2 and 3 with my package.
Or you can call it xyz or write a docstring. Presumably you resuse variable names across your various codes. I'm sure nobody here knows what the variable `sline` means, but almost everyone at my company does. It's just a split_line, which is `line.split()`, maybe with an argument. You need a convention and you need to follow it. If you name your variable `a` and it's a list, you're doing something wrong. You could call it `alist` or `xy`.
Yes, once you manage to bootstrap a Python compiler that can compile to native machine code. Or you could cheat and write a DSL in Python that outputs machine code; but then it's still considered good form to develop your OS to the point of supporting itself, that is, it should be possible to build the OS from source on the OS itself.
&gt; I think .format is an abomination. If you like the `%s %f3.2` style of formatting then you should advocate for `%-strings` which would behave like `f-strings` in the "compile-time" binding of local variables to the arguments, but use `%` formatting declarations. The point is that we should have "one way" to do the formatting. I shouldn't have to learn multiple different syntaxes for string formatting, I should learn one. Either the `.format`/`f-string` way, or the `%` way, not both. Instead we have three primary ways, two of which use the `{}` formatting mini-language and have slightly different features and limitations, a third which uses the `%` mini-language, and then there are actually a couple other ways to string format that most people are completely unaware of. &gt; You can do that with %. Didn't say you couldn't. I'm saying you can't do that with `f-strings` and you can with `.format`. &gt; I'm not a web developer either Then `f-strings` aren't much different to you than `.format`. Its basically a bit of sugar around `.format(**locals())`. The only thing you can do with `f-strings` is include operations inside the arguments: _ = x+y "{x} + {y} = {_}".format(**locals()) becomes: f"{x} + {y} = {x+y}"
dates in python is the most confusing thing to me.
&gt; And besides including full timestamps with dates is no panacea. All that code you write is fucked the moment you try and run it on the Enterprise (NCC-1701-A) because of relativity. As far as I know, the standard for measuring time even when including relativity is to use UTC. The GPS satellites, for example, experience a small amount of drift in their clocks due to relativity. There are 'leap seconds' between GPS time and UTC time as a result. Something like 14 seconds difference, last I checked. Might be more now. Additionally, as someone who is actively working on projects intended for Mars, I'll confirm that UTC is in fact used in that context as well, for all internal storage of dates and times. There is a conversion function for any given project that converts time elapsed since landing to 'sols', and another that uses the position of the landing location and UTC to convert to a local time. Since there are no timezones on Mars, you sort of make one up based on the landing location. Anyway, underlying it all, is UTC, which is the ubiquitous standard for time.
Really, all traffic lights should be priorities by this, should not be a green light if there is no traffic. I know this happens in some places, but this should be the standard.
Last commit on: * Flask-Mail: Nov 4, 2014 * Flask-JWT: Nov 3, 2015 * Flask-Principal: May 26, 2015 * Flask-Social: Jul 10, 2014 There also seems to be zero maintainer activity on issues and PRs. Flask-Principal is pretty much fine still because its so simple, but flask-mail has a few awful issues and flask-jwt is just unusable. I would steer clear of these extensions without first reading the open issues lists for each.
As background, Python is a language that can be implemented in a variety of ways. For example, CPython is an implementation written in C that compiles Python to bytecode, which it then executes. Jython compiles Python to JVM bytecode. Cython compiles Python to a mix of Python bytecode and machine code. These give Python different capabilities, but you're still (for the most part) writing the same language. Because of this flexibility, there's no *theoretical* reason you couldn't write an operating system kernel in Python. However, I don't think there's any python implementation that compiles Python in the right format, so you'd have to create it before you could start on the operating system itself. This differs from languages like C and C++, which already has the tooling to create operating systems (and in fact are the main languages used for this). 
Author of Pendulum here :-) I see what you mean and, to be honest, I am not completely satisfied with it but I think it's the best trade-off I was able to come up with. You will have more control in the next major version. And you can have a more proper behavior for ISO 8601 date strings by passing the `strict=True` keyword argument: &gt;&gt;&gt; import pendulum &gt;&gt;&gt; pendulum.parse('2016-01-17', strict=True) &gt;&gt;&gt; &lt;Date [2016-01-17]&gt;
Travel to mars is not exactly at relativistic speeds. The relative velocity of the orbits of the planets is also not particularly relativistic, and the time dilation due to different gravitational forces is also tiny. All those factors combined [adds up to less than a second per year](https://www.quora.com/If-one-of-the-twin-brothers-left-Earth-to-live-on-Mars-for-10-years-and-then-comes-back-to-Earth-would-he-be-of-a-different-age-than-his-twin-who-stayed-on-Earth-And-if-so-by-how-much) So you don't have a lot to worry about by using UTC. But if you did have a near light speed starship, or wanted to orbit close to the event horizon of a black hole... then UTC wouldn't do you much good.
Flipping the default value of that flag seems like a great reason for a major version! But it doesn't make much sense that you turn off "strict" and get a datetime. If the function was parse_datetime it would make some sense. 
In theory, yes, but it would take one person forever. Python is a high-level programming language, which means commands in a python script represent mid-level language used by (for example) Windows, which in turn operates software that controls how the hardware interacts within your computer and the network with what's called machine code, a low-level programming language, which some people are experts and most people are not because each instruction set is written in hexidecimal or binary for example to operate memory instruction sets in as small as 8bit, 4bit, or even 2bit operations. When python says print(an entire library), there millions of bits per second that the operating system is ordering the processor to compute. The cpu's language isn't even typically viewable in a text file and reads a lot like a formatting error with letters that aren't in the standard english alphabet. It's better to start at the top, Python, and work your way down. If you really want to know about it, after learning a fair amount of Python, study some linux, learn how bash programming works, then officially an intro class to programming in C, or C++ which is the successor to C and has become a large part of linux development. If you're into Windows more, than C# and eventually .NET would be a better route. iOS for apple products has Swift and then Objective-C. Python is not what's called an assembly language. Standard libraries can do certain tasks to work with different software, programs, databases, OSes, etc, and can do anything eventually because it's pythonic. -----~~~~~~~~~~~~~:)
but then there's the libraries, this is a kernel for IoT devices 
Love your videos man. Sometimes I just get pretty baked, grab some food, and watch you code. Weird I know.
I guess `datetime` wins the maximum number of 3rd party libraries
There's also `pytoolz` and `cytoolz` for functional programming. 
Someone needs to write a keystroke logger to see the amount of time per line of code that is spent writing all the extra brackets and other symbols in languages like C++. There's notably little use of the shift key in Python.
Defense industry doesn't even offer Python, to my knowledge. C/C++ and Matlab only.
What OS and what are you working on? 
Probably `PyAutoGUI` is what you want, it's designed for building script bots on existing GUI software.
And default arguments!!!! But I'm coming from Matlab, where the number of arguments can change, but the order is always, always consistent. XD
What drama is possible to be had over a programming language?
I'm sorry, I don't remember the details. It may have been that we significantly reduced the number of records we selected at any one time, so that less traffic was going over the network in a shot. Or, it may have been that we put in delays. I honestly don't remember. I just remember our counterpart on the customer side complaining that his DBA was reading him the riot act.
Windows 10
&gt; `datetime` is good enough for **me**. I've used dateutil to parse ISO 8601 timestamps. It's really beyond me why this common thing is not implemented. The ISO is a bit broader but why not just constrict it to parse formats that .isoformat() can produce. That's a small subset and probably enough for 98% of the use cases out there. And if you want to schedule something for the next weekend in 5 weeks and you need the number of seconds until then. You could just write a 10 line function for every project but what if it has to be at midnight and there is a DST border between then and now?
Working on my first Udacity NanoDegree Project. A Python Application that generates Movie Trailer Website on the fly
I am interested KayEmGee!! What do I have to do?
Yes, so you have half of the repository mirrored, because you have so many python versions/package versions. And you are right, hard links aren't going to help here. On the bright side, once you hit 46GB, it's all hardlinks! ;) Why do you have so many version combinations?
Great, another job for my project that converts between objects from any of the approximately 50 available datetime projects. 
I didn't need to see this. :(
I just use anaconda with different environments running different version. Think I have around 6 different versions of Python across about a dozen environments. Mostly 2.7 and 3.6.
https://bugs.python.org/issue24954
I don't know for other languages, but my guess is it stuff akin to arguing that someone should learn Python 2 or 3 first. Luckily that issue seems pretty resolved, but every "I want to learn Python thread" inevitably turns into a 'legacy codebase blah blah' argument. 
Just two? Use virtualenv and you can have as many as you need.
It's worth having anaconda, which makes it trivial to have as many python environments as you want.
Thanks for this! 
Sentdex - Tutorials you can understand, even while baked.
Fair point. Py2.7 master race! haha.. in all seriousness I just don't wanna have to bug-check for a week when moving my code over...
Shouldn't you do: a = 1 sys.getsizeof(a) 
wat? UTC would be fine (presuming BigNums). The ship's hardware would know the relative passage of local time compared to regular time and still spit out the correct datetime value. The problem is that the timedeltas wouldn't make sense to the human observers. You'd need a new timedelta subclass that accepts observer speed as an additional parameter. You might also want some sort of modified frame of reference calendar calibrated to ship's time.
If I'm traveling at 99% of the speed of light, then my clock is slowed relative to earth. One of my heartbeats (or so many thousands of vibrations of a crystal in my computers clock) is many thousands of UTC seconds according to earth... I'd say that it isn't much value to use a second as defined on earth in an environment where time is literally going slower...
It could be that literals and references are compiled differently? If it assembles as an add-immediate instruction, it's possible that the op-code is 4 bytes and the remaining 28 are for the operand? I don't know x86, so I'm probably totally wrong. 
I use mostly python 3, and I have anaconda on my laptop which is where I primarily program. I am taking a course that uses 2.7, and I have gotten into a bit of a snag here and there and I was wondering if I should just install 2.7 for the purpose of the course that I am working in. 
I tried to convince my last company to switch to Python 3 by showing them that all our existing code could be run through py2to3 and work fine. They thought it was cool and now they write 2.7 and just put it through 2to3 after they're done. I still can't tell if I made it better or worse.
This tutorial (and others) uses a model trained on the Coco dataset -- which only has 90 classes of objects. Is there a model available for TF Object Detection that does the 1000 imagenet classes?
I think it is rather high, I keep hearing it is he second most popular/used language behind JS.
THE GIL
In addition to the sectors mentioned in the article, Python is a very hot skill to have in finance these days as well. However the article doesn't answer the question. It just provides more assertions that Python is popular for this or that. It doesn't say why. Python is very pragmatic in its design. It doesn't try to be pure, or follow some particular computer sciencey paradigm to an ideal extreme. It's Object Oriented but doesn't try to shove objects down your throat all the time like Java or Smalltalk, also unlike those languages it doesn't try to abstract away the entire system environment in its own little world. It has functional programming features, but isn't purely functional like Haskel obsessively minimising 'side effects'. It's easy to create modules in C, for fast performance in critical code. Also the module system is flexible and easy to use. The only other language that comes close is Ruby, but I think Python beat it in popularity partly because a Python came along first. Ruby aimed for the same role as Perl, while Python always had its sights a bit higher at being a general purpose language. Also Guido being in the US, and Denmark having a history of strong Computer Science chops, helped on the publicity and approachability front. That may not be 'fair' but social factors do make a difference. What really made Python so popular recently though is the wide range of high quality, high performance external modules. Numpy and Scipy for number crunching. Matplotlib for plotting. Django and Flask for web development. PyQt for desktop application development. But I think the reasons I gave above help explain how come it got those modules and frameworks in the first place. I chose Python about 15 years ago because it could do a bit of everything and wasnt pigeonholed in a main niche like the web, or text processing, or desktop programming. It had it all.
Start working on open source projects that are based on Python.
Not that I know of, but this tutorial covers how you can train your own objects. You could do it yourself. Imagenet offers quite a few sets with bounding box data: http://image-net.org/download-bboxes
alist? thats a horrible name, it should describe it's contents. If it's a list of people call it `people` not `alist`
there was already more than one `"%s" % var` and` "{}".format(var)`
[this](https://www.youtube.com/watch?v=_AEJHKGk9ns) might help shed some light?
My understanding is that the difference between UTC and GPS time is not to do with relativity. Leap seconds are occasionally added to UTC because the earth's rotation is gradually slowing down, and (so far) people prefer to keep the clocks in sync with the day/night cycle than have a totally consistent number of seconds in a day. GPS time, I believe, is defined with no leap seconds. So as leap seconds are added to UTC, it gets ahead of GPS time. There may be a need to correct GPS clocks for relativistic effects - I'm not sure, but I know those timings have to be very, very accurate. But I think that's a separate thing from leap seconds.
Also very quick look at all of them: Not a big fan of Maya personally. They call themselves for humans but it seems like a poorly designed interface: ```maya.when('tomorrow')``` tomorrow as a string just feels wrong to me. I think it should either be .tomorrow(), or when(days=1) ```.slang_date()/.slang_time()``` maybe it's just me but that's very poor naming too. Slang? In general the documentation seems pretty thin too. Dateutil is pretty powerful but again, when it comes to an interface, it's not very user friendly and near impossible to use to lots of example and documentations online. Delorean looks cool, but I think I prefer the concept of being a datetime subclass, than being a wrapper around a datetime.
i'm going to go from bar to bar now asking people whether they've ever suggested using more-itertools. i don't see how this can go wrong.
I don't think you need C for data analytics. Python, SQL, R, for sure
&gt; work in Michigan for a year now I feel ya. Took me 6 months to get an IT job... AN IT JOB FFS.
Thanks for the feedback. Raymond, i shall iterate extensively over his lecture and add the keys to my (his) dictionary. :)
ohhh, okay. the mandatory response to something like this is to mention the lisps. you're prolly already familiar with those and if so tl;dr: macropy is also cool. really, at this point, i think in terms of actual adoption it's mostly just clojure and racket - i haven't kept up with common lisp in forever. but as interesting as hacking at magic methods is, it definitely still falls short of the sort of thing you can do with a lisp that has a solid macro implementation. clojure's is limited (but still there), but has java interop, so it's a trade-off. racket, on the other hand, is called a "language for writing languages". all that said, though, i agree. and i python is definitely a lot better at combining that sort of potential (even if it's a lot more limited) with being a language that is approachable on average. it's tough to make something that allows a ton of flexibility and is also the sort of thing you can just jump into having never seen a line of source code. there's also macropy. if you've never messed around with the ast module, it (iirc) has some decent examples of how you can basically redefine the language's keywords without requiring messing with the parser. it'll make pylint pretty upset, but it's a really interesting project imo.
If you work in VFX, Python is used very heavily (to the point where C++ is considered a plus for many low-level positions)
Use Anaconda to create a virtualenv with whatever version you want. I have Python 2.7, 3.4, 3.5 and 3.6 on my box. Virtualenvs are wayyyy better in Anaconda. You can access from them anywhere by typing `activate py36` or whatever. You don't need to type the full path.
I am still using dateutil
I think they mean "the list that cocnerns 'a'" rather than "a list". like, 'peoplelist'. 
You're mostly correct. Most of the difference between GPS time and UTC time is due to slight variations in the speed the Earth rotates. We are losing a small amount of angular momentum to the Moon each year (via the tides). This is causing the orbit of the Moon to raise slightly, lengthening our day, lengthening the lunar month, and increasing the distance to the Moon from the Earth. After that, the next major effect is due to the poles wandering a bit. This is due to many things, mostly conservation of angular momentum. If an ice sheet melts, that mass is no longer located at the poles, but is spread out around the earth. So this slightly changes our moment of inertia as mass is redistributed. So global warming can literally change the length of our day! Other effects that come into play here are things like isostatic rebound (northern north america is uplifting due to loss of the ice sheet), or plate tectonics. There are also small changes in our angular momentum caused by rapid events. Any major redistribution of mass from, say, a major subduction earthquake, [will cause a small change in our moment of inertia](https://www.uwgb.edu/dutchs/PLATETEC/RotationQk2004.HTM). Finally, the relativistic effects are accounted for. GPS clocks lose about 7 microseconds per day. That's one second every 390 years, give or take. So smaller than the angular momentum issues, but still relevant. I'm not actually sure where the 7 microseconds is removed. Either the GPS satellites account for it in their time signal, or it gets built into the leap seconds. The effect would be the same. However, it's annoying when dealing with scientific instruments (like seismographs) that use GPS time as their official clock, while everything else expects UTC time as the official clock... That 14 seconds or whatever it is now can make a lot of difference when calculating an epicentre for an earthquake. 
That's not even close to being true. Java is easily more popular than Python
You can compare the values for one row to the next (or previous) using [shift](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shift.html). This removes the need to iterate through the dataframe row-wise. 
The website is gorgeous: https://pendulum.eustace.io/
Metaclasses are why I never watch David Beazley videos when I'm beginning a new project. "hmm... I want to write something to help me with taxes and other financial calculations... hmm... I definitely need metaclasses for this!" It's one of those things I'm glad I did, if only because now I know I shouldn't have done it :). 
What is VFX?
He even tweeted (almost a year ago know) about looking for maintainers for his flask projects, but after reaching out to him about flask-jwt I never heard anything back :(
I agree - C is good to know but Python and/or are essentially requisites. 
Cool stuff man!
One of the best arguments for starting out with 3 is opening a database populated by an unattended py2 script and finding it full of gibberish because it encountered a foreign language and shit the bed.
May want to use isinstance() rather than type(), so you don't break inheritance. 
Eh, that's not really True. Ruby is great for writing DSLs like Puppet.
&gt; If its going to be timezone aware the sensible default is MY TIME ZONE, not GMT. No it isn't.
That's a really good idea - I'll be sure to make the change 
I think it's all the little things that make python so readable - generators and comprehensions are a great example of this. ``` vowel_count = sum(char in 'aeiou' for char in some_text) ```
A lot are! Sometimes there're wire loops under the road, sometimes it's radar, and there's a few companies that do it by vision. There's always a metal cabinet near every intersection that does some controlling, although sometimes it is just a dumb "timer". I know the next big trend will be implementing machine learning on the intersection controllers to maximize traffic flow through them. 
Visual Effects
You should watch any and all of his talks. He's the author of much of Pythons core, like the latest version of dict, and a lot of the collections module. I also find his presentation style to be very engaging. 
I read somewhere that Gerald Jay Sussman used scheme to teach an Electric Circuits course. I've always interested in the details.
The principle of least surprise: python code means what it seems to mean.
I don't think it would/should be different than a normal electronics course. Analog and digital circuits, electronics, digital logic circuits, etc are important and lead up to computer architecture and embedded applications. I guess the only difference I would do is try to work software into it from the beginning.
mmm... be wary of einsum. `numpy.tensordot` can be substantially faster than `numpy.einsum` depending on the exact operations being performed. Regarding numba, definitely read their documentation - they have sections on exactly what [Python](http://numba.pydata.org/numba-doc/0.34.0/reference/pysupported.html)/[Numpy ](http://numba.pydata.org/numba-doc/0.34.0/reference/numpysupported.html)features are supported by `numba.njit`. There really shouldn't be any guess work involved in using numba, once you read these. I always use numpy where possible, but there are plenty of cases - like finding the connected components in a graph, where I would not know where to even start vectorizing the problem
That small integer table also includes negatives to -5. Not as weird as: `hash(-1) is hash(-2)`
Why have it tweet instead of just post the poetry as replies? /s Seriously, though, that's pretty cool.
Hmmm I dont quite follow how the last part is working. Can anyone try explaining? In particular 6+1 giving 13. We look up 6 and get the correct unchanged value for 6, same for 1, do the operation and shouldnt we actually get 7 still? Whats the mechanism here? 7+x giving a 'wrong' answer makes sense to me. But the result being 7 and printing something wrong doesnt quite make sense to me yet. Im probably visualising something incorrectly I guess.
Most of development time is spent reading code where all that cruft is much more detrimental 
Things where a one week execution time is preferable to a year.
The other thing to keep in mind is that if a detection device fails the system usually errs on the safe side, which is to assume there is a vehicle there. So that particular direction will keep on getting a green light even if there is no vehicle there. 
You should be able to easily extend this to check return types as well.
Isn't that sort of what mypy does?
Haven't heard of it - I'll look into it
I know people like to choose minimal examples, but I guess I don't understand the usefulness. Why not just? time_dict = {"now": datetime.now().isoformat()} 
Man, the lack of "fromisoformat" has been the single most annoying inconsistency in stdlib that I've ever had to deal with. It's crazy that it took 5 years to fix. It should have been in 3.0.
Same boat. Legend has it that our network infrastructure is powered by the salty tears of admins from ages past. Quick personal anecdote that exemplifies how terrible this can be. We had one of our newer teams of admins deploying updated Bash code. In this case, they were relying on the $(some command) construct for command substitution. The code nearly made it to production. Thankfully one of the old-timers let them know that we have boxes doing production logging that were commissioned when they were in middle school. It's the Systems Administration paradox. We're well aware of where the weak points in our infrastructure are, but until something hits the fan, management will happily assume that the status will always remain quo. And when something catastrophic does happen, we either: A) Fix it and accrue even more technical debt, or B) Get reamed for not doing "our job" and letting a production system fail. /rant
Well, would make sense to me if it was aligned with Arduino or Raspberry PI, as it gives possibly easiest chance for the reader to put theory into practice. There's quite a lot in Analogue space out of the ports of these devices that could be made a lot clearer than the usual 'hand-waving' (or even no explanation) we see with most projects/demos
...? Am I missing something--? Is your directory C:\Python36? Is your environment set up to run "python" as a command?
They're still jupyter notebooks you're saving to disk! The primary differences IMO are: * Double click to open notebooks on the desktop * Clean authoring environment with minimal clutter * Native menus for saving, loading, changing kernels * (Sometimes) it seems a bit faster at rendering larger notebooks especially large text output, [seems like nteract still has more to do for this though](https://twitter.com/rgbkrk/status/898745636215848960) * Exporting to PDF does _not_ require LaTeX, it just works™ * Hiding inputs and outputs is builtin On the side of things that could be handled by extensions, that nteract ships out of the box: * Custom media types - geojson, vega, vegalite, ploty, [tables](https://twitter.com/rgbkrk/status/898700422726041600) An aside -- try typing just up and down when in a cell and you'll see it creates cells really quickly for you when you reach the end of a notebook. One of the big missing pieces in nteract is support for the ipython widgets. The hotkeys are also different in some cases, but hey it's a native app.
start &gt; run &gt; PowerShell &gt; cd C:\Python36 &gt; python &lt;your .py file&gt;
&gt; Also for data analytics something low level like C is a must. Now I KNOW you're joking
I've tried that but it says it can't find specified file path.
It's because the object in the slot that holds the value always used when 7 is needed is 13 now. Any expression that results in the int 7 will yield 13 from this point on, even `len('seven!?')`. It's an implementation detail of cpython and should never be relied upon ever, but there are reserved singletons for every integer from -5 through 256 inclusive (if memory serves).
the route discovery protocol? WIKI https://en.m.wikipedia.org/wiki/Routing_Information_Protocol RFC https://tools.ietf.org/html/rfc2453 
Yes yes yes. I'm continually stumped by electronics, despite starting multiple times. I have no idea what confuses me. I think it's the fact that everything happens at once, rather than there being a "thread of execution".
There's definitely a SICP-for-physics book out there that uses Scheme. It's pretty mind-blowing.
Where'd you install it?
No, mypy is "compile time" checking. It's essentially an unusually smart inspector you can use to statically typecheck your code.
&gt; If its going to be timezone aware the sensible default is MY TIME ZONE, not GMT. What timezone does your code run in? Are all your servers configured to use the same timezone? What happens when you provision a new server and forget to set it? If it's a user application, what then? There's no sensible default when assigning a timezone to a naive value. You can only guess, and guessing is usually bad. 
Where does the "for Programmers" part come in? How would it differ from an "Intro to electronics"?
To be honest, there are a few really good books out there for this particularly. I highly *highly* recommend [Getting Started in Electronics](https://www.amazon.com/dp/0945053282/ref=cm_sw_r_cp_apa_86mOzbH6NMWZX). Really great book on introducing electronics. As a programmer with little electronics background, this book was perfect.
Sentdex is love, sentdex is life. 
Maybe try FPGAs and see if that helps you get over that?
Hmm, it does sound interesting! However I feel like there's lots of information missing from the problem statement. In this problem what is a set? What is a group? What is an island? What is active? What is the opposite of active? What does it mean to conflict? If you can define these clearly in the problem statement it'll help other people to talk about the problem.
Dave Beazley recently gave an interesting [talk](https://youtu.be/js_0wjzuMfc) where he goes into some depth on this topic. 
My personal opinion is that its terrible for people with prior programming experience. It seems to be targeted to absolute beginners, and spends an excrutiatingly large time in explaining simple topics which an experienced programmer would definitely know well.
Looks good, and after having used runtime type checking with Enforce, I would like to define more specific types. But I'd check out [Enforce](https://github.com/RussBaz/enforce) - it's been developed over a couple of years - so covers a lot more of the edge cases that you'd want. Like the ability to tag decorators so you can turn bunches of them off &amp; on for testing or large data volumes, etc.
Make sure the python install location is added to your Path environment variable
I use Atom with a code completion plug-in that uses Kite and a linter plug-in and am very happy with it. It is basically an IDE at that point minus the debugging support you get with most good IDEs, although there are probably Atom plug-ins that provide that as well. Atom is super customizable. 
&gt; I mean, to me, 5/2 should return 2. That's usually how it works in all languages. If by "all languages" you mean "the tiny handful of languages I know". Let's see now, just a handful of examples: - Pascal uses `/` for division, and returns a Real (float). If you want integer division, use `div`. - Scheme returns an exact fraction, `(/ 1 3) =&gt; 1/3`. - Numbers in Javascript are floats even when they look like ints, and `/` is always true division: `1/2` returns 0.5. - The same applies to Lua. - Forth doesn't have floating point numbers at all by default, so `/` always does integer division. - `perl -e "print 1/2"` prints 0.5. &gt; Why should it return a float? Because the integers ℤ are not closed under division, and `/` doesn't mean integer division, it means regular ordinary division. Just ask any mathematician, anyone who has used a calculator, anyone who has done maths at school. 1/2 is a half, not zero, and the minority of languages (most of which are copying C's mistakes) which treat it differently are the odd ones out, not Python. 
&gt; from future import printfunction I hadn't come across that, but I've also never used end=. Haha. I'll have to keep that one in mind.
Isn't hash() supposed to return a unique number?
Go check out /r/amateurradio. There is an entire world of software/electronics mashups just waiting for you. Huge DIY segment in ham radio circles. Lots of SDR stuff going on these days (software-defined radio). 
It looks like "/r/ameteurradio" is not a subreddit. Maybe you're looking for **/r/amateurradio** with a **97.5%** match. *** ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^2 ^^downvotes ^^to ^^DELETE. ^^| [^^Contact ^^creator](http://www.reddit.com/message/compose/?to=SubAutoCorrectBot&amp;subject=Contact+creator) ^^| ^^[Opt-out](http://www.reddit.com/message/compose/?to=SubAutoCorrectBot&amp;subject=Opt+Out&amp;message=Click+send+to+opt+out) ^^| ^^[Feedback](https://www.reddit.com/r/SubAutoCorrectBot/comments/6s2sht/feedback_questions_concerns_bugs_suggestions_etc/) ^^| ^^[Code](https://github.com/Josode/Subreddit-Auto-Correct-Bot) 
The installation location needs to added to your path variable. How did you install Python? On Windows you can make it easy on yourself by installing Anaconda, it will set up everything for you. Installing from Pythons website should have taken care of that if you used their installer. Try reinstalling. 
Good bot. 
Thank you bbbryson for voting on SubAutoCorrectBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
&gt;For example, in the lower right of the bottom set is a J that can be included in both sets as it has no overlap. The 4 As next to the J conflict with the 3 Vs in the upper set, but it would be better to use the As instead as they have more coverage. Either you made a mistake here, or I have no idea what you mean. If I do understand what you mean, here's a hint: https://en.wikipedia.org/wiki/2-satisfiability
Wow, by [Forrest Mims](https://en.wikipedia.org/wiki/Forrest_Mims)! Among many accomplishments he's a foundational figure in personal computing, one time partner with [Ed Roberts](https://en.wikipedia.org/wiki/Ed_Roberts_\(computer_engineer\)) in creating the Altair 8800, the first microcomputer system.
Endianess on hardware and software.
I would say no. As someone who already understood the fundamentals of programming, I was turned off by learn python the hard way. That was back before the author soured most of the community on himself by making a bunch of outlandish claims about python 3 being a terrible language. Now I'd stay far away from it. I ended up taking a coursera course on python and found that much more helpful.
Yeah, I've found some free resources which seem good, one is "automate the boring stuff with Python", and think Python, both from the side bar in the sub.
I just deployed this simple survey on Cannabis to track statistics in the USA. Using Python, Flask, PostgreSQL: If you are in the USA please take time to fill out this simple survey on Cannabis: https://cannabis-survey.herokuapp.com/
Given what he said about being confused, jumping into FPGA work without proper training or explanation would probably add to his confusion. One can write HDL that looks sequential and the synthesizer might give hardware that gives the uninformed person output that looks like it came from something that worked sequentially. 
nteract has some deal breakers for me: 1. Different markdown renderer means that LaTeX (in particular escaping line breaks in math environments) is parsed and rendered in a manner inconsistent with vanilla jupyter. This destroys any utility it may have for me because I'm not the only one editing the notebooks I'm writing. The bug I filed for this is almost a year old now, and a fix exists but hasn't been merged yet. 2. Uses electron. I understand that I'm going to have to open a web browser to use Jupyter anyway, but at least other alternatives don't also use the Web engine to render supposedly native GUI widgets (e.g. GTK menus). Also, using electron rather than pandoc for PDF conversion means that you can't export to LaTeX directly, or use jinja templates for custom document classes etc, but that's a minor nitpick. 3. The last time I used nteract it would consistently crash when saving notebooks with kernels other than python (in particular a Julia notebook with large figures). I'm not sure about the status of this one. That said, nteract really is nifty and has all kinds of quality of life features, like the parent post points out. However if you use Jupyter enough to rely on heavy customisations (or need your notebooks to be readable by other people without Jupyter spitting out errors and mangling your LaTeX), you may find it getting in your way instead. 
It would be a huge challenge to create, but given that the reader is already a programmer, defining classes that model the components might be enlightening. A class `TwoTerminalDevice` from which you derive classes `Resistor`, `Capacitor`and `Inductor`... what methods would they have...?
Started to implement type checking via decorator - can be found here https://www.reddit.com/r/Python/comments/6w0xe3/static_typing_function_decorator_in_python/?st=J6SS3KL2&amp;sh=22b10645
I guess that's true. I would consider FPGAs a more familiar tech to someone who has programming experience, but maybe it's more of a false friend than anything.
Is this what you are referring to? [Structure and Interpretation of Classical Mechanics] (https://mitpress.mit.edu/sites/default/files/titles/content/sicm/book.html)
It's probably a college course, so they don't have a choice. You use the language (and version) the class is taught in.
In general, you're right. The environment and mechanics of designing would be somewhat familiar. Both start using an IDE and the input is text with libraries. Modules are kind of like functions. IP instantiation is kind of like a library call. The synthesizer can be thought of as a compiler equivalent. Even the place and route being similar to linking and loading isn't too much of a stretch.
"Automate the Boring Stuff with Python" is what you need. It's free online but you can buy the ebook if you want to support the author.
Forrest Mims is my go to for recommendations for beginners. His handbooks and textbooks are amazing.
jupyterlab
I'm feeling pretty confident in my python skills, I have already dabbled with django and bootstrapped a website as well as wrote my own site in basic HTML. Where do I go from here? What do I need to learn to land a job using python. I've web scraped a bit as well with Beautifulsoup4. I feel like I have a lot of the skills, now I just need to tie it together into a little nice job bowtie. Any advice?
Here's my version, if anyone cares (and 24 days late). import os def main(): players = ('☆', '★') player_index = 0 board = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i'] def get_move(): while True: sq = input('Claim which available square? ').lower() if sq not in ['X', 'O'] and sq in board: return sq def check_win(): v1 = board[0] == board[3] == board[6] v2 = board[1] == board[4] == board[7] v3 = board[2] == board[5] == board[8] h1 = board[0] == board[1] == board[2] h2 = board[3] == board[4] == board[5] h3 = board[6] == board[7] == board[8] d1 = board[0] == board[4] == board[8] d2 = board[2] == board[4] == board[6] return any((v1, v2, v3, h1, h2, h3, d1, d2)) def print_board(): os.system('clear') print('\n %s | %s | %s \n---+---+---\n %s | %s | %s \n---+---+---\n %s | %s | %s ' % tuple(board)) while True: p = players[player_index] print_board() print('\nNext move: %s\n' % p) board[board.index(get_move())] = p if check_win(): print_board() print('\nCongratulations, %s wins!\n' % p) break if set(board) == set(players): print_board() print("\nIt's a tie!\n") break player_index = 1 - player_index if __name__ == '__main__': try: main() except KeyboardInterrupt: print('\nThank you for playing Tic-Tac-Toe.\n')
Formatting
Try this: Right click on the Python IDLE, click **open file location**. This will jump you directly to the location of the installed python directory (mine is in **C:\Users\**User_Name**\AppData\Local\Programs\Python\Python36** To run .py file, enter cd **file_location** and enter command python **FileName.py**
The **.to_excel** method doesn't exist on the **pandas** *module*, but on a **dataframe** or **series** created with **pandas**. Compare what you're doing to [this example](http://xlsxwriter.readthedocs.io/example_pandas_simple.html).
Yes, I agree.
If you know where to look you'll find it
There's a gap between CS and EE where signal processing lies. When I tried to use a use an accel/gyro board, I found I didn't know how to get a useful orientation out of it even though I could read the raw data into my raspberry pi.
1. What annoys me in electronics is the millions of different products with subtle differences. You dont need shopping skills in programming. My package manager gives me all I need. 2. And I dont understand how electronic engineers can deal with shitty software like eagle or other scheme editors! I hope projects like https://xesscorp.github.io/skidl/docs/_site/ gain some more traction.
Micripython controllers are literally this. A minimal operating system that boots up to a python interpreter. It's not 100% python because in order to boot you need to provide the CPU with the correct microcode. In order to load python there's presumably some kind of bootstrapper program - but once it's booted you are in a world of Python.
I was worried it would get banned from most subreddits if it did 
Have you read [this](http://www.daveoncode.com/2017/03/07/how-to-solve-python-modulenotfound-no-module-named-import-error/)?
With books like this, are they best used as a reference or is it really something you'd work through chapter by chapter? Also, is it particularly theory based?
perhaps the winshell library is installed in a different location than the instance of python that is running. i had this problem when i downloaded anacondas but macOS already has python pre-installed
Down a long complicated path. Where do you recommend installing it?
Thanks I will do
Check that this module exists in one of the directories referred to by `sys.path` (PYTHONPATH) : python -c "import sys; print('\n'.join(sys.path))"
Make sure that version of python used by pip matches your python version that you executes your script. pip --version python --version Also, maybe programming is not for you if you have anger issues.
I'd imagine that you make analogys to concepts familiar to programmers... without an electronics background I have no idea how deep you could go with this, my gut guess is "not very"
What command are you using for installing? If you are using 'Pip install praw' try the same command with pip3 instead of just pip. If the command pip3 isnt found you will have to install the package python3-pip.
You could organize the book as a series of projects combining Python programming on RPi's with electronic parts.
I dont think that addresses the specific point i was trying to make. It all males sense when we use 7 as an input, but how does it make sense for an output? When we actually calculate 6+1 we get the real 7 right? How does that turn into 13? We looked up the two values for the input 6 and 1, did some math and got the value for 7, which isnt in our small int table, so how did we return some other number 13 in our int table?
You lost me at nope.js.
If you don't find any help here I might suggest: * Elance and friends * The python jobs mailing list 
Yes, that's the one.
That's not a small project. I have no interest in helping code it, but I think it might help you to know that if you just want to know *which* stream vids have high views, then web scraping is easy. If you want the literal video stripped out of those, especially on different sites with different vid players and codecs, then you're looking to hire someone full time for a while. 
a tiny websocket server :D https://superuser.blog/websocket-server-python/ https://github.com/sanketplus/PyWSocket
I have installed python to C:\Users\user_name\ doing this allows me to type "python" into the command line and it switched to the python interpreter. My next problem is how to actually get the .py file running in the interpreter. I tried what you told me to do but it gave me this error: File "&lt;stdin&gt;", line 1 cd file_location python file_name.py SyntaxError: invalid syntax
I tired it myself and i couldnt crack it. I want atleast two steaming services. Thus im willing to pay for someone more talented. Im trying to make a youtube channel that will host all those clips for my viewers. I know its hard but i will pay accordingly. 
I did the reverse. Started in electronics and moved into programming later. Sadly after learning enough about electronics to realise where computers were supporting electronics at the time (simulation, circuit board layout, chip design, going into genetic algorithms) I could see computers would be doing most of the electronics design that I was looking forward to. Perhaps use matplotlib and/or other visualisation tools to have interactive graphs for things like LC circuits. Maybe existing tools can do full analog simulations (I haven't looked at electronics software in years).
Definitely. I've been programming since I was a kid, and I can handle TFL concepts, but I cannot get my head around d the analogue stuff because I'm thinking in terms of programming concepts instead of electronics. I realise that this is my problem. But I need help - a translator that can help me build understanding through what I've got already. If that's possible...
It's definitely not a reference work. It's meant to be read through and is written in as casual tone as the subject matter permits.
I've often wondered if you could start with learning how to program using Arduinos and expand to more complicated projects that combine more complicated software and electronics. If you framed it right you could probably sell it to schools. 
Raspberry Pi and Arduino have bought a bunch of people with a programming focus into the world of electronics. 
I would consider using [plotly dash](https://plot.ly/products/dash/). 
Good bot.
To be honest if you have a mathsy enough background (which I guess doesnt apply as widely as it ought to), Electronics is plenty accesible if you can manage Programming. https://www.allaboutcircuits.com/ is a fantastic resource, while we're mentioning resources.
If we needed the book we would have no chance of knowing what topics we would want.
A thousand times yes! I was shocked to learn about pull up/down resistors when I first played with my RasPi. I had just assumed that a digital "one" was always represented as high. 
When you type `import name` Python, internally, searches a specific set of directories for the module with that name. Those directories are held, internally, in a list called **sys.path**. So, if you do this: import sys for p in sys.path: print p import name Where *name* is the module you're importing, you'll only get an ImportError saying that *name* is not found if there is no *name.py* or *name.pyc* or other form of valid *name* Python package in any of those directories. 
You must have been kidding. I've just bought this book in a store, 3 minutes ago - and that was a random, impulsive buying.
&gt; line 1 cd file_location python file_name.py Save the file on the Desktop with name **test1.py**, Inside the file : type **print("test1")** type cmd in start and copy the location of the file to the cmd *not in interpreter* and run **python test1.py** 
It's ok, your *resistence* was low.
I can imagine a book that would walk you through buying and setting up a simple arduino kit (with breadboard and various components). Then you walk the user through writing code to read voltages at various points or adjusting an output here to see how it affects an input there. Then you write a function to emulate what is happening so programmers can understand it in a sense they are used to. A second book could even cover emulating a whole arduino board. I'd buy both.
The short answer is technically yes. I remember years ago reading that someone wrote an OS in APL that was actually used.
This is awesome, thank you so much!
Any chance you are using a linux/macOS computer, winshell is windows only.
You missed [youtube-dl](https://github.com/rg3/youtube-dl)
I am Windows 10 and running them from Powershell with Python 3.6 works fine for me. Method: 1. Install Python 3.6 with the "Add Python to PATH" checkbox selected. 2. Open a Powershell and change directory to the directory containing the script.py file using: `cd C:\path\to\script\dir` 3. Run the script with: `python .\script.py` 
https://pypi.python.org/pypi/winshell/0.2 For reference. I agree with everyone else, check your path, check your capitalization, and check your versions. Also, open python in the interpret and try importing the module. Use trial and error until you can import it without an error. Best of luck
This. Made this mistake too many times. 
Dive into Python 3? That's how I learned. Its intended audience is experienced programmers, and it's free!
I believe you could try "python3 -m pip install praw". If you don't have pip installed for python3 then install it first by "python3 -m easy_install pip".
This book emits some heavy magnetism obviously
It's definitely *current*. I like to *amplify* it whenever given a chance.
I found the [Lessons In Electric Circuits](https://www.ibiblio.org/kuphaldt/electricCircuits/) free books to be very helpful.
make sure no files in the current directory hold the name of your modules/libraries 
Ohmygod.
I used it when was a total beginner and the style did work for me at the time. If i remember rightly it emphasized drills and typing in everything yourself to learn through repetition which is fine if you know nothing. Years later with several languages under my belt and lots of experience, it would be insulting. it's very much the author knows everything and you know nothing kind of deal.
Use np.fromstring. It's can be up to 500x faster than using struct. Then you just need to cast your data. Do a reshape and slice it (if you have mixed types. Assuming you have ints and floats in your table, you'll want to call np.fromstring twice vs recasting the floats as ints. For a 2 GB file with an excessively complicated file format, I wrote a library to read it in 4 seconds. That was down from 45 minutes using struct. I actually had to scan the file first (so using file.seek to skip some number of bytes) because I needed to size the arrays. Two passes is faster than 1 with resizes.
You're welcome.
IOT book would be cool.
From the docs: **peek([size])** Return bytes from the stream without advancing the position. At most one single read on the raw stream is done to satisfy the call. The number of bytes returned may be less or more than requested. Notice the last half of the first sentence: without advancing the position. You have to read from the file to actually advance the pointer. Also, if you're not on Windows, you really should use select instead to figure out when there's data to read. 
&gt; being weakly typed in the most obvious place while remaining a strongly typed language The dumbest comment ever, clearly indicating that you haven't got the faintest idea what you're talking about, as summarised by the following. &gt; Also, you can't claim that nothing will ever change, especially in the open source community. It Guido's language and it's been going for 25 years. The PSF holds the rights to the Python name so no it will not change. Hence why the person who started Python 2.8 was very politely asked, and very politely agreed, to call it something else.
Try readline(2)
The author hasn't a clue about Python. In [Pass by value (which is sometimes a reference)](https://kate.io/blog/2017/08/21/pass-by-reference-pass-by-value/) she again repeats the myth about pass by reference, whereas core Python developers agreed years ago that Python is [Call By Object](http://effbot.org/zone/call-by-object.htm).
Yea but the thing is I importe modul that I registered in .py (registered on my desk)and python told me that modul doesn't exist so I dont l know where's the problem 
[¿What do you think about restricted globals?](https://docs.python.org/3/library/pickle.html#restricting-globals)
Multiple versions of Python installed?
So it's useless by design? Jeez, the Python standard library inspires confidence in the language as usual.
Coming fra the *nix side of things, I've never needed to use peek(). But as I read the docs, you can use peek() to see what's available, and the read the amount of bytes that you have peeked without the process blocking. 
Now if MS would only treat Python as a first class programming language in their office tools
Why do you think we have PEPs then? Anyway, please be more argumentative. Lastly, do not forget the PEP 484 is now an accepted part of the language, regardless of how intolerable it might seem to some of us.
Yeah, but being useful only insofar as implementing actually functional `peek()` goes is not what I'd expect from a peek function. Ah well, thanks for the suggestions, it's probably what I'll do.
2 dimensional data analysis. Dateseries + some price or whatever. Try on stock market historicals for fun.
I tried it maybe a year ago when it was in early alpha, and it was neat. I might give it another try when it (supposedly) goes into beta soon.
Yes, not referencing the documentation and using the wrong method is often useless. I'm sure it's the languages fault /s.
Fucking batteries. I want to put a big ass lipo battery that lasts weeks powering up a raspberry pi or an arduino. But I don't want to burn down the house of my customers. Also powering up motors from outside the arduino. Intead of getting the power from the arduino itself, the arduino only sends the signal and draws the power from the power source. Also learn to multiplex with a chip. Just those 3 subjects in a book would make my day.
No. Ideally you do want hashes to be "unique enough" in that different objects should have different hashes *most of the time* (since otherwise you get collisions), but there's no guarantee of uniqueness. As for why hash(-1) == -2, I suspect it's because python uses -1 as a magic number in the hashtable implementation to indicates something like "empty", meaning it can't have this as a real has for anything, and so a hash of -1 (Integers are their own hashes) is always converted to -2 instead. You can see this if you create a class that implements `__hash__` to return -1: `hash(x)` will actually give -2 instead.
I'd say just get started and get "something" out there to see if there's interest and how you can find your niche.
&gt;When we actually calculate 6+1 we get the real 7 right? Yes, but "the real 7" here is the integer object that python caches in its small integer table. &gt; How does that turn into 13? Because we mutated it behind the scenes. Essentially, the following is happening in the underlying C code doing the addition - We get passed in two integer objects: a and b (which are the python objects represenging 6 and 1). - look at the .value field for `a`, which contains the C integer 6. - Do the same for `b`, and get the C integer 1. - Perform the addition to get 7. - Now we need to wrap this C integer into a python integer object. - But the function that does this special cases small integers, since it knows these are interned. So rather than allocate the memory for a new integer object, it just returns the corresponding precreated one from the small integer table. But unfortunately, this object has been mutated - it's .value field has the value 13 now, so printing this out will show that. Python considers it the "seven" object, because it has that location in its cache, but in other respects, it's identical to the "thirteen" integer object.
So we change the python -&gt; c mapping but not the c -&gt; python mapping? I guess i didnt expect that once we had calculated the value of 7 in c that we would give that as the fake 13 / 7 number since it doesnt equal something in our table any more. But i guess if c knows where 7 is in memory and returns that corresponding object without a check then it makes sense. Thanks for the answer, maybe ill try to get around to looking at how this actually works at some point :)
Mandela effect
Garden automation. Hooking up sensors to monitor soil conditions, ph, moisture, and light... 
Yes
Hack what? Most “hacking” today is people calling companies and pretending to be someone else (Social Engineering). The only real hacks require tons of knowledge, and you’ll be probably be on a government watch list without you even knowing it.
You're probably thinking of `id()`, which returns a unique value for any object.
If you mean "hack" in the FOSS way, then sure Python is awesome! A lot of projects are in Python and it's great for beginners to learn how to code and quite easily transition into another language (perhaps C++ for games or JavaScript for web). If you mean "hack" in terms of trying to gain access to things you shouldn't then really we can't help you although still learn Python because it looks good on a CV ;)
Ok but if i want to compare more than one row thats impossible. For example the output should include the first row that the value is greater than its previous, then the first row that its value is greater than 2 previous rows, and so on ... I agree most of the operations can be done in one statement without a loop but sometimes you need it and thats why i mentioned it in the post
They would have instanteous current, and instanetous voltage difference, and some charateristic dv/di curve. (linear for a resistor V= IR) .
Python is one of the easiest languages to learn. Definitely yes. 
Have you tried using Bootstrap ? :) I don't know much about front-end so I'm scared I can't help you but I managed to some kind of stuff with Django + Bootstrap. Again I don't know the good practices etc, so if you want help you might want to ask an other subreddit. GL with your project ! :)
Go from [here](https://www.automatetheboringstuff.com)
Pretty sure this is the wrong subreddit
A worthy idea. A book that is relevant is The Pattern on the Stone, which although it doesn't go into the physics of electronics, provides a clear and accurate explanation of computers from the ground up.
I'm about to begin a project using something called the MNIST dataset. It's basically the "Hello world" of machine learning. It contains a set of 60,000 regulated images of handwritten digits, and you can use neural network algorithms to learn from them and recognize other handwritten digits. I would highly recommend starting with this project if you want to learn about neural networks and deep learning. When I'm not on mobile, I could link an excellent free online book that teaches this project. If you're interested. http://neuralnetworksanddeeplearning.com/chap1.html You should read this.
Yeh python is definitely one of the easiest. You'll find that often the command you want to perform is very similar to the English statement. E.g for every item in my shopping list I want to print the item for item in shoppingList: print(item) Also python has great online communities to help you!! :)
Hi! This is really neat! Im currently working on something similar, except using the frame evaluation API so the checks happen in your running Python code without needing to add decorators everywhere. Additionally, you may be interested in my list of typecheckers https://github.com/ethanhs/python-typecheckers
The whole problem is that this "real 7" you are referring to, the way cpython does it, has been modified. It shows up as an erroneous 13 even when produced as an intermediate result, because python calculates math expressions one operator at a time.
RemindMe! 1 week Python neural networks
Why would they do that? That's what VBA is for. Office doesn't need multiple extension languages. Only the one. That just wastes resources. It's not like VBA is hard. It literally the easiest language on the planet. 
``` for i in xrange(n): pass ``` is valid python 3 syntax.
$95 is a lot when UltraEdit costs around the same, and is cross platform. They have an IDE version for Windows which barely costs more, as well. What makes Zeus worth using over the alternatives? I do like that it's still around. Remember it from a long time ago. 
I also recommend MNIST. Check out the Tensorflow website for a good and accessible tutorial and code. 
the module exists in `Lib` and `Lib\site-packages`
&gt;Also, maybe programming is not for you if you have anger issues. the weird thing is that i almost never get angry like this. normally if i have a problem like this i solve it before it gets to this point. also python was supposed to be the super easy language but having to do everything outside of the code is pretty damn confusing
I have been procrastinating on trying to use neural nets to improve functions related to prime numbers, like a probably prime test, nextPrime(), or maybe a sieve
pip 9.0.1 and python 3.6.2 is this incompatible? 
It exists: http://www.apress.com/us/book/9781484218976
You should change a string in your program when you change the version. Version numbers have a venerated and meaningful format that exists for a reason; bumping up a number by one every time you "recompile" a python executable won't be consistent or meaningful.
Maybe just the basics of using arduinos serial outputting and reading. GPIO pin usage and basic voltage and PWM understanding
For what it's worth, you can't really say that this implementation of `peek` is simply not very useful.
I third MNIST and that book! I used it a couple years ago as my "teacher" for my science fair project about the vanishing gradient problem.
Don't know the problem, but here's a few steps you can follow: First, have the bot just echo your message. Once you're sure it's receiving the message correctly, have it echo your code instead. Once you're sure it's finding your code, have it run the code. Not show the output, just run the code. Check the terminal and see if it works. If it does, then there's something wrong with your method of checking code output. Look over or rewrite any sections that do not work properly
The problem with this is that I can't check the terminal or if the code being echoed works, because when I do have access to a console, the bot works properly. The closest I can get to debug this is that when running a command that creates a permanent change (ie: touching a file with bash) in the bot "broken" state, nothing happens, while when I do it when the bot "works", it does. So I know at the very least that the code never runs, but sometimes it does output, so the problem should be in the subprocess as I suspected. (maybe the subprocess gets killed instantly when the bot is launched by the system?) But besides that, I don't really know what to aim for to fix it. I may think that subprocess.Popen() is the issue, but I don't know how to test for it or what to replace it for.
It's doing what most peek methods do, allowing you to see the value without modifying a position or removing data from a data structure. This is what peek does in most stack and queue implementations that I've seen and I would fully expect the same behavior on a pipe which is, in fact, a queue implementation. There are plenty of times that I would want to see data in a queue without removing it. So no, I don't think it's useless nor is this an implementation detail that is particular to Python.
Yes, but it only lets you peek as far as the last call did, until you consume the stream past where peek read to, which is not what any other peek implementation I've seen does, and it's not useful because you need to manually buffer it and read N bytes(where N is how far peek read), and *only then* will peek let you look further ahead. I do not understand why it does this, Popen has to buffer the output anyway, so why not just make it possible for peek to peek into said buffer?
Thanks. I got praw installed but my script still crashed because it couldn't find praw. In doing some more reading I found a recommendation to provide the full path to the .py file: `python3 /volume1/_projects/SubmissionBot/run.py` It worked.
Thanks. Between the two of you I was able to install praw and now my script works the way it should.
Wow. I only skimmed the few pages of preview available on Amazon. But its definitely one that I can recommend to people as a starting point. Thanks a lot!
Indeed, the 'for programmers' part is to try to make an attempt to utilize existing background knowledge as much as possible. And its definitely not an easy angle of approach to explaining electronics. E.g. saying a resister is like a delay() function in your function flow. The higher the resistance, the larger the delay function argument. The slower the energy flow in the circuit.
Sentdex had a good series on if you need help too. 
how was the result?
This looks awesome! Thank you.
Great idea! Do you know if anyone has done this sort of thing?
Will do, thanks!
The result was fun but I would never recommend trading with that information. If you wanna do better than a neural network (which you should) check out Quantopian and especially in the current atmosphere, good sentiment analysis + event correlation such as earnings, rumors, buyouts, business deals, etc. This is all assuming you mean trading companies and not ETFs or commodities. And besides, at least in my experience, you're going to start by making a swing trading machine. Not bad but not super hard to do yourself with what you'll learn. Making something that prices options correctly would be something amazing but probably beyond the work of one person.
Yeah, I have 1/2 ownership of a startup (less than that soon as we have investors) that does this for people with robinhood and coinbase accounts. We plan on launching our beta early next month. It's built on python and django with resources from AWS. The key is providing enough analysis to do the trades yourself with confidence. I don't believe in doing it with a machine unless you're talking HFT (high frequency trading). A seasoned funds manager will beat machines but the two of them paired is probably best. Disclaimer: I'm a data scientist with a strong passion for investing and trading in the stock market. Not the other way around ;)
You are definitely the kind of audience I was looking for. Could you please elaborate what topic you were trying to understand and where you tried to start? Thanks 
Indeed. But I'm hoping somebody has a rough topic/idea he would like to understand but not have a clue where to start. Any existing material on that subject would be too electronics focused.
I'm also doing a price prediction project, but on a more stable and lower scale market (not stock market). I was thinking about trying neural network, but it seems like with not much data it won't work well. Could you give me some recommendations for price prediction statistical/machine learning approaches?
For what you're doing I think you're on the right track. Is it something like sales data? I can recommend features. Implement weather into your dataset, day of the week, etc. Both of those are the major and easy-to-obtain data features that will increase your accuracy of your NN by a factor. 
LIPO batteries have a reputation that precedes them. My 2 cents. Go for a 12v car battery and a car usb adapter. That would be something that lasts in the order of weeks. The larger the battery the better. And of course. It all depends on power consumption. A pi crunching numbers with an lcd and running a wifi server consumes more power compared to one running idle. Arduinos have a much lower power footprint. Again, in an ideal world, you need a usb power meter in the middle. Measure actual load. Do some calculations about how much batteries can provide.. And then make a battery size decision. For Powering up motors from outside the arduino, I'd recommend using a relay. That is what you are basically saying. A quick google led me to this article which looks pretty good on a skim. https://www.allaboutcircuits.com/projects/use-relays-to-control-high-voltage-circuitswwith-an-arduino/ Can you elaborate what you mean by 'multiplex with a chip'. This doesn't ring any bells. Thanks btw.
You can check out psutil's Popen, it has a bunch of bells and whistles that might help
Indeed. I was looking for any starting/pressure points
The book looks pretty interesting. Thanks.
Well then it's not a fair comparison, because the neural network has only the price/data relationship, while the human has the advantage of expert opinion and news. It would be much more interesting to see what you could do with an AI that can use the same resources as a human.
Indeed quite a few people mention learning about electronics via an arduino. There are lots of tutorials out there about Arduinos saying download this code, connect these parts, voila. A rare few go into the electronics and explain alongside it. 
That's the purpose of machine learning, it's not unfair. 
Thanks. You guys are the prime audience.. Could you share a few stories and suggest a few key topics where you stumbled and think others might stumble too. I recently came across a pull-up resistor that wasn't working. Turns out it was wired as a series resistor. ;) So I know that one.
I'll check tomorrow, I'll go to sleep now. Thanks for the answer though!
You are definitely the kind of audience I was looking for. Could you please elaborate what topic you were trying to understand and where you tried to start? Thanks
Subprocess.PIPE outputs to a buffer, the size of which is dictated by the OS IIRC. I have no experience with the systems you're using but if the buffer is too small you can overwhelm it and trigger a hang. That would then hit your timeout. If you have IO access you could try write to a file instead see if that helps.
Hmmm I'm actually your exact opposite, an investment analyst with a strong passion for data science. I can tell you that Fortune 500 companies are automating their trading more and more because it beats out top fund managers in certain areas. However this only works well because a human is following and monitoring what is done on a live basis. Generally I've seen that humans get slightly worse results than machines, but humans working with machines get better results than either. Humans have better strategy but machines can process data with greater brute force. What would be really interesting is building a trading AI with a layer overtop of it that tries to intuitively predict what a human strategist will do based on the human's information sources. If I were you I would try to mine the data of the humans that use your app to see which choices they make and try to mimic the most succesful people at the least.
I understand your frustration. The subtle differences and 100s of varieties of part numbers are because its a physical product. The 10Kohm resister in your phone is quite different in capabilities compared to the 10Kohm resistor in your washing machine. In contrast, software libraries of the same version are 'the same' everywhere. Perhaps difference cpu architectures could be an analogy. The API are the same though. PCB tools do use libraries for parts. Unfortunately there are few 'free'/open source tools out there. And the big professional ones have a steep learning curve as well.
The emulation/simulator angle is interesting indeed. Thanks. I came across this online link that might be a nice starting point for a tutorial series. https://www.tinkercad.com/circuits Edit: Fixed url
Signal processing is whole separate area where there might be a gap indeed. Thanks for the suggestion.
Trying to step on existing CS knowledge is the key here. Quite a few people have suggested that its just too different to make a different. But perhaps it can be done.
Sounds like a user/permissions problem, you can find what user you are running as in your python script, I forgot the function name but you can google for it.
For circuit visualization, I was thinking of using an old but classic tool in the field. http://www.falstad.com/circuit/
`xrange` isn't valid in Py3
I am seeing a donation request from PSF for it. I thought it's under the PSF? https://twitter.com/ThePSF/status/901534741299683329
Yep the mnist data set is the ideal set to start on because so many people use that to teach. There are a lot of tutorials just on the most data set
You have better luck looking up what reinforcement learning is. There are firms like Two Sigma and others who have teams applying Deep Learning to the market. Seems like nothing fruitful came about. 
It's not builtin, you can define something to be called xrange though. 
Yes it is, it's just not built in
Not sure what the point of this article is other than glossing over some superficial changes between 2 and 3, it doesn't even address that xrange in Py2 is a generator and range in py3 is a full fledged type with stuff life fast membership checking and look up. The only syntax change actually addressed is print (from keyword thing to a function). No odd style exception catching, the fact that True and False are keywords now, annotations being added, etc. 
Assuming the pervasive criticism of the original LPTHW are still valid (or even mostly valid), it's not good for beginners either. 
TrySwepy program 
That's the point, `xrange` is a built-in in PY2 but not in PY3.
That's the point, `xrange` is a built-in in PY2 but not in PY3.
Dogs vs Cats
[https://www.youtube.com/watch?v=ACmydtFDTGs Not hotdog]
As requested by some users in Flask group I added Basic Auth support : https://github.com/rochacbruno/flask_simplelogin#protecting-your-views
do more verbose logging, either to a file or a syslog server. The reason I'd suggest the syslog server is if this is related to permissions issues, those issues could also impact being able to open and write to a file on that server. edit: anywhere you'd otherwise be inclined to put a print statement, use the logging module instead. 
Oh ok
are neural nets actually any good at this kind of problems? This does not feel like a neural-net domain.
this was my first thought as well. 
says python3 doesnt exist just python worked though, thanks. how can i package this as an executable that doesnt require python to run?
Sorry - original reply written on a phone, so 'TFL' should be 'TTL'. Mostly, it's life support for ICs - this is the most common problem. I see an IC with interesting possibilities like a GPS chip from SparkFun or something like that, and I have no idea how to provide life support so that I can read data from it. Even to a Raspberry PI, or Arduino. Processors are complex, but getting a self-contained hardware function like this going probably isn't, but so far it's a mystery. And it's irritating on top of that because these things are pennies to buy. Like I said originally, I know that this is something for me to work on and solve, but I don't even have the beginnings of an idea of the size of the problem. To be able to take a simple IC2 chip and understand the reading and writing of data (and the surrounding life support) would be a *huge* start. Any further questions gratefully received - I'd buy a book that means that I can buy kit and understand how to build with it quicker. I love the whole building thing.
Not sure but I wpuld imagine since they are kind of the best at approximating any nonlinear functions. 
I wanted to convert a WAV (audio) file to an SVG graphic, so I wrote [wav2vec](https://github.com/cristoper/wav2vec) this week.
I've used [cx_Freeze](https://anthony-tuininga.github.io/cx_Freeze/) at one point and it seemed to work fine.
&gt; What makes Zeus worth using over the alternatives? Having not used UltraEdit myself it is hard for me to compare the two, but many users [seem to be happy](http://www.zeusedit.com/testimonials.html) with what Zeus offers. However the Zeus *trial download* version is in fact the *real version* so it is possible to fully trial every aspect of the software before deciding on whether it is worth the cost of registration.
how does this work? i got an installer for my program but when i installed it on another computer it attempted to retrieve the libraries from my computer for some reason
[Briefcase](https://briefcase.readthedocs.io/en/latest/) aims to to just that.
PyInstaller is the standard way to package things. It's not outdated.
In your subprocess.Popen calls, use the full path to the executable. Also, this is a good opportunity to learn about the logging module: https://docs.python.org/3/library/logging.html
[removed]
every time i post on reddit i think "what would jared comment"
Link to your script?
Well, I'm at "just-gone-through-the-first-tutorial" stage, but here is my take: 1. The function you are interpolating needs to be reasonably continuous. Otherwise, you cannot train. isPrimeNumber() is definitely a very discontinuous one. 2. Even if you can come up with a reasonable interpolation for known inputs, it's not obvious that it would generate anything useful for unknown ones: the function is too irregular .. I'm definitely out of my depth here ... Any expert cares to comment?
It produces a bunch of other files that you're supposed to include with the exe.
[@rgbkrk's latest tweet](http://i.imgur.com/EYWLzO0.jpg) [@rgbkrk on Twitter](https://twitter.com/rgbkrk) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Never tried it. Probably will give it a try.
It’s on that page: [completely offline install](https://chocolatey.org/install#completely-offline-install) 
I ran the exe from the folder containing all the files. nowhere in the code does it reference the path i was mentioning 
How are you calling the script at boot? And how are you calling the script through ssh?
Being fair or not isn't the point &amp;mdash; or at least it isn't productive to think about that in this way. It's not unfair because no one has a clue about how to do that &amp;mdash; i.e. provide all essential information to the algorithm. There are additional indexes and indicators that can be fed to the neural net, yes... it's not just the price/data. But the market reacts to, for example, badly written tweets and fake news... try to model that as a numerical variable and consume that in the right way and before the market reacts as a whole. Also humans have advantages... but machines also have some. Would it also only be a fair comparison if humans had the numerical computational capacity of a machine? What about our attention span and biases? **I don't think we will need general AI for machines to get better than humans at this problem, though**. We have the understanding and common sense... but machines have the calculation capacity (or will have). They probably don't need as much logic and field knowledge as us to be good enough... we miss a lot of clues because they're too hidden in a mass of simple data (but of enormous quantity) or there are simply too much clues for us to process. I guess we just need, as is very common in AI problems, to "just" do a proper preprocessing of this information (using AI) and feed them to an algorithm we already have. Fuck, maybe after having this information a spreadsheet will be better than us... And then the market will react to the predictions of this AI when it begins to be more than, say, 90% right... And it won't work anymore \o/.
The 'E' in PEP stands for Enhancement, it's not a PCP where the 'C' stands for Change.
Why do people keep plugging Zed Shaw's crap?
RemindMe! 1 week Python neural networks
I will be messaging you on [**2017-09-03 04:15:44 UTC**](http://www.wolframalpha.com/input/?i=2017-09-03 04:15:44 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/6w6d9n/what_are_some_good_examples_of_small_scale_neural/dm6hzkx) [**5 OTHERS CLICKED THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/6w6d9n/what_are_some_good_examples_of_small_scale_neural/dm6hzkx]%0A%0ARemindMe! 1 week Python neural networks) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dm6hzqt) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|