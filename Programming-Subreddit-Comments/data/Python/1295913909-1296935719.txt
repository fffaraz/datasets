I strongly disagree. MVC, for anything but desktop apps, is bound to cause you more headaches and cost you a ton of useless boiler code. Even trying to do MVC in webpages, due to the level of integration between the "model" and the "view", end up creating more problems than their worth. For a project of this type, I highly recommend breaking things up by their function. Screen interaction on one level, data interpretation on another, and rules on a third. This way you can manipulate your rules without touching the data interpretation &amp; interaction. If they change the GUI, then you can change your interpretation without having to touch your rules.
Never tried South but have used [Django Evolution](http://code.google.com/p/django-evolution/) for a similar purpose over many years.
Newton Rhapson can be used for equation solving. An example I used just a couple of days ago to spare me from having to work out the quadratic equation: `solve("cos(64*deg)=x**2/sqrt(x**2 + 580**2 + 320**2)")`
I wasn't under the impression people GPL'd there modules because they wanted other people to use them... Sorry.
I agree that named parameters are nicer in 3.0, along with the ability to execute some basic code in the template string. I guess my main complaint is that I have to learn a new syntax which isn't obviously better. That being said, I think it will grow on me once I get a chance to use python 3 for real work. Hell, I'm still stuck with 2.4 most of the time.
Interesting. I didn't know the operator was just deprecated. That being said, I would feel a bit dirty using it in new code. Certainly is nice that not all code would need to be changed over (I still need to add python 3 support for a few libraries on pypi). What does 2to3 do with format strings? Also, how do these format strings works with delayed formatting in the logging module? I use that functionality extensively in some of my (python2) code.
http://pypi.python.org/pypi/StringFormat/
This guy is really great about complaining and not doing anything else to help. Submit a patch or move along, jackass. Also, taking some time to catch up to trunk is perfectly normal; it's *your* edge case.
We did make a "microframework" as a (kinda jokey) proof of concept using Pyramid named Groundhog, which uses Flask-y syntax and semantics (see also http://bfg.repoze.org/videos#groundhog1). I've added a rendition of your code above as a Groundhog app to https://github.com/Pylons/groundhog/blob/master/demo/moritz.py (runnable after setup.py install of groundhog as "python moritz.py"). It doesn't handle the functions-as-wsgi apps bit but does everything else. Pyramid is really a lot more flexible than people tend to give it credit for.
As TFA says, the fix in question was applied in a released version. Which is not on PYPI.
PIP makes VCS dependencies a one-liner in your requirements.txt, so I think this argument is moot. That said, if you're going to go to the trouble of submitting your package to PYPI, I don't know why you'd pride yourself on letting it slip out of date, at least as far as stable releases are concerned.
Without knowing anything about the specifics it is hard to give good, detailed advice here. However, one general technique I can recommend is that you look through the code you have written to see if there are any blocks of code that could be split up into multiple smaller blocks (i.e. separate functions). If so, you should definitely do this because it has a couple of advantages. Firstly, it makes it easier to improve all the separate blocks of code because they will be smaller. Secondly, it means that all your other functions will be able to re-use those smaller blocks of code - thus making your overall task easier. Apologies if I've been too general or simplistic. It's hard to know what's best to do without much information.
Oh I thought you actually meant there was a bug in Pypi and you need it fixed. So it was just some random package? # pip install -e svn+http://svn/url#egg=packagename or even better: # echo svn+http://svn/url#egg=packagename &gt; pip install -r
Your questions would be just as tiring as the answers we would have to give you that have already been answered over and over.
Uhm, I love python but think this is a terrible thread. Also, installing an environment is oftentimes the biggest barrier to entry. 
There was a *five year* roadmap for P3 adoption. We are in year *two* or there abouts.
I don't think it is going to work that way at all. Once the major frameworks move everyone else to some degree will follow suit. Just to be clear, all the major frameworks have plans in some stage of development to move to P3. Also remember the move to P3 was to happen over a *5 year* period and we are just into year *2*.
That's cool. I'll have to look at that. The thing that appeals to me with microframeworks like Flask is that there is basically one simple way of doing something. Often things tend to fall apart when we need to bundle apps together. Perhaps one issue I have with Pyramid is that there seems to be a few simple ways of doing things. It's a bit overwhelming when all I want to do is something like a showed.
1.- sqlite failed because you were lacking dev libraries to compile the gem. (probably libsqlite3-dev on Ubuntu). 2.- With rvm you got "no command 'rvm' found" because you didn't looked at the 'installation documentation'. You have to add some text to your .bashrc to load rvm on following sessions. Good to know you're happy with django, but this childish complain was uncalled for. Just use whatever makes you happy. 
I'm sorry this adds to the discussion how?
http://docs.pylonsproject.org/projects/pyramid/dev/designdefense.html#pyramid-provides-more-than-one-way-to-do-it Not really sure where you got the idea that Pyramid was meant to be a microframework from the start. We must be doing a really poor marketing job.
Downvoting you hard. Flask, bottle, Tornado, web.py. How many more do we need?
You guys need to be copy and pasting this: https://github.com/Pylons/groundhog/blob/master/demo/moritz.py A LOT MORE OFTEN.
If it is indeed "oftentimes", then you're working with exceptionally shitty software packages. I've found that the biggest barrier to entry is inadequate documentation, or overengineered monsters that require 2 hours of reading just to get an inkling for how to create the equivalent of a "hello world". Django's URL mapper is example of such complexity, although I wouldn't say it's overengineered. It's easy to use the examples to make simple regex -&gt; callable associations, but stuff like generic views, URL namespaces and the variation in calling conventions (with different semantics) can be frustrating for the newbie.
He has one major incorrect assumption: &gt; Why do we open source our code, let alone GPL it if not to have as many people use it as possible? There are many reasons to open source and via the GPL relinquish control. At the simplest it can be because the code might be useful to others. Another is because it is a way of doing collaboration. Having as many people as possible use it is a *lot* more work. For example that means covering more operating systems, having i18n/l10n, more comprehensive documentation, an open bug tracker and mailing lists/irc etc. pypi is useful for pure Python packages but far more difficult for others. This is partly due to distutils etc. I have a Python extension that tracks SQLite. Generally you need the latest version of SQLite for it to work. I even added an extra setup.py command that will go and get the most recent SQLite for you as well as another that does tests. But if I added the package to pypi there is no way to indicate that the extra fetch and test commands should also be run.
Yeah, don't do that for quadratic equations, work them out by hand. I promise it's better that way (for a few reasons including that N-R is only going to give you one of the roots, depending on starting position and it occasionally fails). Also, massage the equations as much as you can before you pull out the solver. Really, it's okay so long as you know what you're doing, as the method isn't perfect. That said, more than half my engineering class got so addicted to Mathcad's solve functionality that they couldn't solve a system of equations by hand. So, I'd suggest you use it to check your hand solutions. 3rd order polynomials and higher, go ahead and pull out Newton Rhapson. Presuming you're studying engineering... what kind?
&gt; Even trying to do MVC in webpages, due to the level of integration between the "model" and the "view", end up creating more problems than their worth. Huh, how do you get view and model to have high level of integration? That's by far the easiest distinction in the MVC pattern. Most web apps have some sort of persistence, like a database, that's where your M is. Model is very well defined. MVC is very well suited for web development.
I agree. I find Java to have have the biggest barrier of entry as far as installing the environment goes, at least as far as setting up a web development stack. For a language that's all about "write once, run anywhere" it's pretty amazing it's that bad actually. I've seen experienced Java developers spend days just getting the "project" setup before they actually start writing any code.
In my statics class, our answers are never nice numbers; I am not going to compute the square root of of a number that isn't a perfect square by hand. The solver also takes an estimated answer, which I do use, and since it is not a symbolic solver, I do have to do some work by hand. Nonetheless I am perfectly capable of doing algebra without a calculator, but when it becomes so rote as the quadratic equation in every situation, I lose interest in rearranging them when I am going to have to punch them in the calculator anyway so I can find out what the square root of 671.851 is. In my classes that produce nice approximate answers, it is my preference to leave thing in log / radical form and work the math out by hand. EDIT: Also, I only need one of the roots anyway. If I need the other, I can just adjust the initial guess of the N-R solver.
From what I can gather from the source tree this issue still exists within the Python 3.x branch, I just haven't had the time to test for it.
Good. And, let me be clear here, I'm in no way suggesting that you, er, calculate an irrational root by hand. You'd end up using something like Newton Rhapson anyway. I -- an experienced aerospace engineer and programmer -- was just trying to warn you a bit (and admittedly, not very clearly) about the dangers of relying too much on solvers as they can hide some issues. And you clearly understand Newton Rhapson pretty well. Sadly, at the 2nd year level undergrad level, I didn't see all that many people who did. If you have some time, you might consider implementing a multidimensional Newton's method like Broyden's method or a linear system solver like Gaussian Elimination. They'll be really useful and I reimplement them myself for both work and play every couple of years.
Nothing lead me to believe it was a microframework. I just hoped that it was a microframework based on the tools that Pylons used. Webob being the primary one.
I can appreciate pedantry, but I think this is just too pedantic to be worthwhile. Even with all that extra support code you now have in the automain module, and the extra package dependency, you still wind up with no fewer lines of code in your script. You're also now vulnerable to any API changes that may happen in the `inspect` module, and readers of your code will be completely confused about what's going on until they figure out what this automain module is. This will be especially annoying to experienced Python programmers who are used to, and enjoy, the "no magic" philosophy.
How can from automain import * @automain possibly be nicer or shorter than if __name__ == '__main__': My solution to the problem is to define a shortcut in my preferred editor. I just press a key and i have this line inserted for me, with proper indentation. Why make it complicated when it can be kept simple?
&gt; I'm just stunned. Programmers certainly have a reputation for arrogance, but to see it so clearly on display from the author of a GPL'd module is just shocking. Stunned? People that license libraries under the GPL *are* the kind of bunch that would show this elitism.
That's kind of a generalisation.. I doubt somehow that using a particular license dictates your personality.
If you release a *library* under the GPL it says a lot about your personality.
This is a much less ugly of doing it, and one of the reasons I like Python is because it generally isn't ugly, so this helps. Thank you, don't let the naysayers get you down.
It's not *pedantic* at all. Seems more like OCD to me.
Nerd wars are funny. Does Guido need to put you in timeout. 
You can indent your code by four spaces or use `backticks` to make it readable: if __name__ == '__main__': pass
I'm curious: how often do you write a module that needs `__main__` at all, in any form? Also, I don't think the "ugly" form is ugly at all.
I have this construct in all my modules, just because everything i write has to be tested. It is not ugly but it is very easy to mistype, hence this is why i defined it as a shortcut.
&gt; readers of your code will be completely confused This. `if __name__ == '__main__':` may not be pretty, but it's easy to recognize. The `@automain` decorator is hardly recognizable on a quick scan.
(You - refers to the author of the post, not the above reply) agreed, blaming your inability to install ror is stupid, rails is being installed by 1000's of ppl without many problems, that just means you have no clue as to what you have to install, some one go about how it is hard to find a consistent way to install things on python.
Yep, they're the same kind as the modders who threw a fit recently about someone daring to make their mods actually easy to use with morrowind. 
I'm not sure it's that simple. Case in point: The PyQt library is released under the GPL (as well as commercial license), even though Qt is LGPL and its head-on competitor PySide is LGPL, too. I'm not sure what that says about the *personality* of PyQt's creator; perhaps all one can infer is that perhaps he thinks GPL+commercial will pay the bills where LGPL won't. (Of course people have made a living out of releasing LGPL software too...) 
I remember that a period of years was anticipated indeed (I certainly did), I'd just like to see the original plans from 2007/2008 instead of a party line message from 2011. Note that I miswrote above, I meant the hard part will be when some libraries will stop supporting Python 2 (Python 3 only) and others won't support Python 3 yet. 
Gosh, if you can't stand `__name__` just make separate, executable file (fx. manage.py) and don't import it from anywhere.
I prefer to just do: python -m unittest something_to_test If I want to isolate a specific test module to run.
thanks for the tip
idiomatic code &gt; non-idiomatic code
Is your [`_`] key broken?
What exactly does it say? That you are the kind of person who doesn't want the work, which you are releasing for free, to be hijacked for profit by some unscrupulous individual or company?
Sounds like locals() should be the default behavior, kinda like [eval](http://docs.python.org/py3k/library/functions.html#eval)
...or, more likely, your lack of understanding OSS licenses.
i sorta expected he meant view and template (design/layout) are often very(too?) tightly integrated
[http://docs.pythonsprints.com/python3_porting/](http://docs.pythonsprints.com/python3_porting/) might be of help to some people, although it's not complete and it might be absorbed into the core Python documentation.
&gt; python, i will never doubt you again! Um, its a programming language, not a religion.
It's spelled django.
In the embedded domain many modules are GPL so you can contact the authors and get a commercial license.
Did you know you can get rid of 'if __name__=='__main__';" completely? It's only there if you decide to import your script from somewhere.
&gt; That you are the kind of person who doesn't want the work, which you are releasing for free, to be hijacked for profit by some unscrupulous individual or company? That's one of the things it says.
Of course there are exceptions. But if you release a library under the GPL there are three reasons for this: 1. you want to sell commercial licenses. I can understand that 2. you are a “freetard” (someone please come up with a better sounding word and one that is less insulting) 3. you have a GPL dependency (that is annoying, and that can happen)
You are aware of the fact that playing around with frames will drastically lower performance if you use an implementation like PyPy? Did you test how performance is affected in this case? Not to mention that is this unidiomatic magic and certainly not a more elegant solution.
I'm not sure why you'd need this for testing. Sure, for a module or two here and there, but for *every* module there are, IMO, much better options--namely, a test suite coupled with test discovery (for which you could use Nose or unittest2 amongst other options). I couldn't imagine maintaining a `__main__` section in every module I write. That sounds like a nightmare. In all the Python code I've written over the past several years, I can't recall a single `__main__` section.
Out of the box, it uses [WebApp](http://code.google.com/appengine/docs/python/tools/webapp/), but some folks like to use [Django-nonrel](http://www.allbuttonspressed.com/projects/django-nonrel).
I came here to post "Old but excellent" I think you covered it. The presentation on [coroutines](http://www.dabeaz.com/coroutines/) by the same person is also awesome and very informative.
I think MVC/MTV need to be defined once and for all within the Python community. Rails and Python differ on their names, and I'm starting to feel the MVC term is a bit useless.
Is WebApp well supported ? I mean, if tomorrow I find a problem and try to google it, will I find answers ? I know Django has been around for a while, is it the same with WebApp ?
web2py works well with GAE and is easy to learn
Tipfy
pyramid
You should check out [web2py](http://www.web2py.com) -- it's a full-stack framework that's very easy to set up, learn, and use. It was designed to run on Google App Engine out of the box, and there's a [whole section in the online book](http://www.web2py.com/book/default/chapter/11#Google-App-Engine) dedicated to GAE (there are also other references throughout the book discussing a few special considerations when developing for GAE). There's even a "Deploy on Google App Engine" button in the web2py browser-based IDE (see the IDE demo [home page](http://www.web2py.com/demo_admin/default/site) and [GAE deployment interface](http://www.web2py.com/demo_admin/gae/deploy)). Your web2py GAE apps will also be portable -- you can deploy them on other platforms (e.g., a Linux VPS) without changing your code (though you may want to make some adjustments once you're off GAE and no longer subject to its limitations). If you have any questions, you'll get lots of help from the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/web2py).
did you get anywhere with your Riak ORM. I just thought about it again. Here's the gist I made that afternoon, but forgot to post, https://gist.github.com/779788
Thank you very much, I will check it out!
Note, webapp is the framework that Google provides with App Engine, so Google supports it. However, they describe it as a "simple" framework, so it may not have all the features you need. Also, it may not be the best option if you think you might want to port your app to a different platform at some point.
[Flask](http://flask.pocoo.org/). Great documentation for beginners!
Does it work on GAE out of the box?
apparently... this post upset everyone... those who like python, hate me for saying ill never doubt it again those who like RoR hate me for failing those who like django hate me for mis-spelling its name ill go work in silence now... alone... in a corner... snif snif...
I really like flask :)
http://www.franciscosouza.com/2010/08/flying-with-flask-on-google-app-engine/ Perhaps?
Note, Flask is a "microframework" and does not include an ORM or database abstraction layer, so you would either have to plug in one that works with GAE, or use the GAE BigTable API directly. Actually, the web2py [DAL](http://web2py.com/AlterEgo/default/show/272) (database abstraction layer) can now be [used with Flask](https://bitbucket.org/rochacbruno/dal_on_flask) (and other frameworks) and works with GAE, so that's one possibility.
Also, [this](http://www.franciscosouza.com/2010/08/flying-with-web2py-on-google-app-engine/) might be a helpful example. If you scroll down to the first comment, you'll see that the code (which is already quite concise) can be made considerably more concise thanks to web2py's built-in default behaviors. For comparison, you can see the same example coded using [Django](http://www.franciscosouza.com/2010/08/flying-with-django-on-google-app-engine/) and [Flask](http://www.franciscosouza.com/2010/08/flying-with-django-on-google-app-engine/). Note, because Flask is a microframework, it doesn't include some of the features of full-stack frameworks like Django and web2py, such as an ORM, a forms system, and an authentication system. As a result, the Flask example relies on the BigTable API, the GAE users API, and a WTForms extension. Also, the Django ORM doesn't work with GAE, so it requires using the Django-nonrel fork of Django.
LOL Good, I'm not on the list.
It depends on your requirements. If you're just starting out, I think the best option is to go with something small like WebApp or web2py, because 1) learning a webapp framework takes a while and 2) learning GAE takes a while. I've been programming in Django for 2 years before I tried to deploy it on GAE, and it's still been a pretty steep learning curve adapting to the datastore (a non relational db), learning which django modules do (forms, unit tests) or do not (auth, django admin) work, and figuring out best practices.
[Running Pyramid on Google’s App Engine](http://docs.pylonsproject.org/projects/pyramid/dev/tutorials/gae/index.html#appengine-tutorial)
Okay, there are various: * Tipfy is a microframework built specifically for GAE, but docs are out of date, not very detailed and I don't think you gain enough from it to tolerate the bad docs. Also, it's unpythonic in the way it does views, which I hate. * Flask is another microframework, but it's much better, in my opinion. If you want to start with Flask on GAE, get this: https://github.com/kamalgill/flask-appengine-template * Django-nonrel is just Django on GAE. Anything that doesn't use the ORM will work out of the box, and most of the things that do will also work. The only things that won't work are things that use ImageFields or ManyToMany fields. Django is a bit heavier than Flask, obviously, but you gain an amazing amount of batteries and the ability to move off GAE whenever you want. If you're writing a small app, like this one I wrote [to host multiple static sites with different domains on GAE](https://github.com/stochastic-technologies/static-appengine-hoster), use Flask. If you want something more content-driven or more complicated, go with Django. The size doesn't really matter, and I found I had to reinvent quite a bit of Django when using Flask on GAE. However, **do** create a small app from scratch using Flask (not even the template above) to get the hang of the application structure of GAE and to understand how it works at a low level. If you want to see some things I built on GAE, [this app tells you if a comment is stupid or clever](http://www.pythiafilter.com/) (written in Django), [this is my static company website](http://www.stochastictechnologies.com/) hosted with the app above (Flask), an app [for greeks to file their receipts](http://www.taxbonus.gr/) (Django), and there's another one I won't divulge yet. I haven't used web2py or other frameworks, so I can't comment on them. From the few things I've written so far, I'd use Django, and I'm not going to develop for anything other than GAE if I can help it (I am very impressed with what I saw and with the free usage tier, does anyone know if it will go away when GAE is released?).
Here's an automation by Jason Giedymin of the above steps: https://github.com/JasonGiedymin/Pyramid-Scripts
web2py seems to be the way to go then.
Perl holds a fond place in my heart. It was the first programming language I got paid to develop with. I learned object-oriented programming from the Camel book. The biggest compliment I've ever received on my programming was from a client who said he had never seen such beautiful, readable perl. That being said, I haven't written anything significant in perl in 10 years, mostly because no one I need to collaborate with knows it. It acquired a reputation as being difficult for newbies, and after a while it just sort of died of attrition. Whether or not there are valid technical reasons with modern perl is moot. No one uses perl because no one uses perl. 
I can understand the desire to get rid of something you type over and over again. I just use snippets, though. I type in **ifscript&lt;tab&gt;** and it prints: if __name__ == "__main__": import sys submitArgs(someFxnAbove, sys.argv) The *submitArgs* fxn submits as many arguments as you supply. Best of all, snippets will automatically move to someFxnAbove so I can replace that text. Maybe you should give it a try: http://www.vim.org/scripts/script.php?script_id=2540 It may be a better solution than importing your own module everytime.
just use webob and quit whining. :) http://blog.ianbicking.org/2010/03/12/a-webob-app-example/ 
just one that has sweet resource traversal in it
"and where's the reusable apps for god's sake?" :)
Could you mention some reason why Tipfy in upythonic? I think it really is pythonic. It uses decorators, everything has its class, a good app organisation, it uses buildout, it appends kwargs almost everywhere the only downside are the docs. I think it is a good proposition if you want to build a fast (more api heavy app on GAE)
Anyone tried the [Kay Framework](http://code.google.com/p/kay-framework/) yet? It's built specifically for GAE and it has some very nice features.
&gt; Note, because Flask is a microframework, it doesn't include some of the features of full-stack frameworks like Django and web2py, such as an ORM, a forms system, and an authentication system. However there are tons of extensions for exactly these purposes: http://flask.pocoo.org/extensions/
The only people more annoying than those who license libraries under GPL are those who think they are in any position to complain about other *authors* choice of license. I plan on releasing any software under BSD or similar licenses, but being a "freetard" is a perfectly valid ethical position. Complaining about is just self-entitled thinking that the author *owes* you complete rights to the code just because he decided to open source it under his terms.
Tornado runs on GAE as well.
Can it do "at most N workers", like *make -j N*? There are lot of implementations that can do exactly N, this also seems exactly N after quick glance at the code. Last time I tried something like this, I used processes, because GIL completely killed the performance.
[Tipfy Framework](http://www.tipfy.org/) is built specifically for GAE.
Now C++ needs something like this (interactive shell + restore). I used cryopid, but it is kind of clumsy and does not always work (gdb refuses to debug created binary later).
Yep, exactly the fact that everything has its class feels less Python and more Java. Having a class for each view doesn't fit in with the Python way, as a view isn't an object per se. I much prefer the views-as-methods paradigm of other frameworks. You can use buildout with the other frameworks as well (especially with microframeworks, as you basically just put everything together yourself). That said, I haven't used Tipfy enough to dismiss it (partly due to the bad docs). My only pet peeve is the view-as-class, really, so I can't fault it too much. Also, get on Gtalk, I want to ask you something :p
Anyone have experience with Pylons on GAE?
Never heard of CryoPID. That looks quite nifty.
I was out of town over the weekend, but I've done a little work on it. The code fetches lazily, and it supports queries that return lists (like searches or mapreduce's). It also relies on some changes to the micromodels API that I don't know if have been released yet, and definitely haven't been documented yet. https://github.com/lightcatcher/riala/
It does exactly N. Not sure how would "at most N workers" work? Do you mean starting less N workers if there are less than N work units? This implementation uses both threads and processes. It will start a number of processes and each processes will have a number of threads which will do the work. I wrote this module initially for a crawler. It had better performance (on 8-16 cores machines) than just processes or just threads.
Is it just me or do links to groups.google.com not work when you are already logged in to Google Groups?
Isn't a better title "How Django willen on-be ported to Python 3"?
&gt; … but being a "freetard" is a perfectly valid ethical position. Where did I say that it wasn't a perfectly valid ethical position? I merely said that licensing a library under GPL says a lot about ones personality. Nothing more, nothing less. I didn't complain, I didn't judge.
I don't know what it is that I'm logged into that's making me fail, but google groups links never work for me.
Yes, that's a good point -- Flask does a good job facilitating the development of extensions to help fill out the functionality available. Still, sometimes there are benefits to a more comprehensive, integrated framework. For example, web2py's forms system is tightly integrated with its DAL, making form processing very easy. Of course, there's also room for flexibility -- you can replace the DAL with SQLAlchemy, but then you don't get the benefits of the forms system. Also, when everything is part of the core framework, there's one locus of responsibility for documentation, support, maintenance, bug reports, etc. That can make it a lot easier to stay current, get help, and resolve problems.
Flask with [this skeleton](https://github.com/blossom/flask-gae-skeleton) for GAE.
Agreed, it's still way too early for general use. It successfully parses a few very basic formats, but the features you mentioned (and many more) are still in the works. For what it's worth, I hadn't intended to blog about it at all yet because it's so early in the process. But I needed to give some background for a couple other blog posts, so I just wanted to do a brief summary. I certainly never expected it to end up on Reddit. :)
Exactly like make does it. You tell it the maximum concurrent processes, but it does not matter if there is "less work" to do, i.e. less jobs than workers. This can be done manually, of course, but it's PITA. Last time I used [forkmap](http://honeypot.net/multi-processing-map-python), it did the job, but it was not pretty. EDIT: The GIL thing was with parallel FFT/PSD computation, there was a synchronized queue (with about one message per second). Ran slower in more threads than in just one.
I'd urge you against web2py: http://www.reddit.com/r/Python/comments/ex54j/seeking_clarification_on_pylonsturbogearspyramid/c1bo1v5
Eventlet is great. Wrote a load test for a comet server using eventlet. I was able to run 40000 tcp connections using a single process and less than 200mb of RAM. 
Calm down people. Given a module ocd.py, here are a dozen ways to get this behavior without that nasty idiom: if 'ocd' not in globals().values(): main() if __name__ != 'ocd': main() None if main.__module__ == 'ocd' else main() 'main' in main.__module__ and main() 'main' in __name__ and main() if 'ocd' not in __name__: main() if 'main' in __name__: main() 'main' in globals()['__name__'] and main() {False: bool, True: main}['main' in __name__]() 'main' in globals().get(*[i for i in globals().keys() if hash(i)==0x3cfa8ed9]) and main() m='main';eval('m in '+'name'.join(['_'*2]*2)+' and eval(m+"()")') z=13;q=[chr(ord('a')+w)for w in list(range(0,z,4))+[z]];\ eval('{}=="{}"'.format(*map(lambda k:''.join(q[p]for p in k).join(['_'*2]*2),((4,0,3,1),(3,0,2,4))))) and main() 
As I [chosen](http://www.reddit.com/r/Python/comments/f8so6/best_framework_for_gae/) web2py as my framework to build web apps on GAE, I found this link to make web2py runs on Eclipse
@uber77, unfortunately kingkilr is pointing you to pure [FUD](http://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt). Do yourself a favor and at least try web2py for yourself. People who actually use web2py tend to really like it. A lot of good options have been mentioned here, and you would probably do well with many of them. Different frameworks and approaches appeal to different people depending on their needs and preferences. You'll have to figure out what works best for you, but you'll be doing yourself a disservice if you listen to folks like kingkilr.
Are you setup for the "new" groups? 
why would a single line executed at the very start of a console script, which only looks at the current frame's parent, have any meaningful performance penalty ? even if pypy does this ten times more slowly, it makes no difference.
You might also find [this](http://stackoverflow.com/questions/4075758/a-good-development-environment-setup-for-web2py) and [this](http://code.google.com/p/voa-web2py2eclipse/) helpful.
The only design pattern I know is MVC, so I sort of built my app with that in mind, but only on a very superficial level. I created classes based on model view controller. I've decided since it's the only pattern I know and its being recommended, that I will separate my code out to several modules based on MVC. The main problem I'm having now is replicating the autoload magic method that I use in PHP, in my Python code. How am I to manage importing dynamically whenever I create a class that's in a separate module? Do I just import every python module at the beginning of my main app file? That seems a bit inefficient to me.
I would recommend against GAE :P. That's a personal preference though. My experience with GAE was 'ok' and you can review our djangodash project [Django for forms, views, urls..and native datastore APIs for GAE...which were good, and the admin panel was good.] This is our code, you can review or use what's useful. https://github.com/justinlilly/permachart 
I through this one out there [bottle micro framework](http://bottle.paws.de/page/docs) I have had fun using this for small projects. very quick and easy to learn. 
You might as well disclose (for the sake of the newbie asking for information) that you are a (main?) contributor of Django and jacobian the author of the link you gave is the lead developer of Django. It's very interesting to hear these kinds of words from a competitor.
I think Flask is a very good microframework. But you've got to realize that a microframework is not a full-stack framework. Your users will be very experient programmers who are willing to experiment with different components, putting things together and possibly (as you open claim) modify Flask itself to fit their needs. These are really different expectations, different users and different applications. I do hope to see Flask turn into something like a full-stack framework or partially-full stack framework. But until then, it's in a different category with web2py or Django.
Seconded, used with GAE on a couple projects.
Unfortunately that post makes a great disservice to the Python community. It is criticizing web2py for making different design decision than Django made, completely missing the point that those design decisions were motivated by the will to be different. Whether or not those design decision are right or wrong (and any design decision has pros and cons), attacking the competition for being different than the mainstream is shortsighted and divisive. The Python community is neither shortsighted nor divided. I know the Python community is a community of early adopters who are not afraid of experimentation. You should give a try to web2py and judge for yourself if you like it or not. You should also give it a try because our community if very friendly and inclusive. Whether you decide web2py is for you or it is not, we will treat you with the same equal respect.
I think you should spend sometime to try out Django, web2py, Flask, bottle, and maybe Pyramid. Maybe 2 days each, to build a small prototypical application of your choice. At the end of the days, these recommendations mean very little in terms of how different from each other these frameworks are. Unless you try them out, you will never know what suits you the most. 
Look at gevent too. We've tried both at work and found gevent to be more stable. It does not have zmq support though.
Take a look at https://github.com/traviscline/gevent-zeromq/ if you need ZeroMQ in gevent
Better but I don't see what Willen has to do with all this.
OK I did not know that this was unpythonic. Other aspects I like is the global config module and the possibility to create micro apps so that you can split your code into different apps with their own routes, controllers and even models. I also like the fact that there are some recipes like auth, sessions and so on. That said though I may give a look at Flask once again. I believe Django is not a great option on GAE as you do not see the metal so much.
Note that it will work also with other python debuggers, you just need to play with it for a while.
Then you might like the [attach to running python process and debug in python](https://www.reddit.com/r/Python/comments/f98rn/attach_to_process_and_coredump_equivalent_in/) hack.
&gt; `_` refers to the return value of the last executed statement Pedantic, but this works in the regular Python REPL also, $ python ... &gt;&gt;&gt; 24+5 29 &gt;&gt;&gt; _ * 2 58
Debugging race conditions almost always goes away with mutexes and shared state threads... People keep on using those horrible constructs, for some reason...
If you have pure CPU bound workloads (like FFT), then probably you'll be better off just with processes (you can specify 1 thread for my module if you want to use it). The crawler I wrote was somewhere in between. While it did some heavy I/O (therefore threads make sense), it also did quite a bit of processing on the pages so the combination of processes and threads was serving the purpose very well. Why do you need such a feature? Do you have really a lot of cores? Otherwise, I don't think a few processes which are blocking on the queue would make any impact on the performance.
I propose you consider less constrained alternatives to GAE such as [ep.io](http://www.ep.io/) and have a look at [Flask](http://flask.pocoo.org/).
All frameworks I know have a global config module, and creating micro apps is just Python, it's not specific to the framework (if you import other URL dispatcher modules into the main one, they will be included because that's how Python works). Flask does all this too. About the recipes, I agree, but I found that most (Facebook was one notable example) were out-of-date and poorly documented, and writing my own took less time (and I had a far better understanding in the end) than trying to figure out how to use Tipfy's. Flask is great, but I prefer Django for most things. You don't really need to see the metal, but there's nothing preventing you from doing it. You can forgo the ORM and use the datastore API or any other API directly if you want, it's just Python. As long as you don't *start* with Django on GAE (because then you won't know what goes where), you can just swap in or out any components you like.
No sign of coroutines....
and running like a champ on appengine. 
"SSL Hell?" How about simply changing the permissions on the key file so you don't have to elevate yourself to root? Those restrictive permissions are a feature, not a bug, intended to help protect the key.
[Damn 8 ball pos...](http://i.imgur.com/oKXCu.png)
It'd be less useless if it included a link to the site in the blurb. 
It's a school exercise. This C-like code looks like an exercise in defining a hash data structure. Just roll with it as is. 
Well, one thing is to start "on the green ground" and other thing is to get to maintain a piece of horrible mess that holds together "by the force of will". Actually, the bug I needed this for was somewhere in ffmpeg/libavformat. Everything worked perfectly, I proofread the code numerous times, just "length" kept getting random values ocassionally. Maybe unintentionally "shared" variable in .so or something similar. EDIT: changing code couple of million lines long is not always an option
I know you already have a `printTable` function, which looks decent, but try using Python's `pprint` to inspect the hand-rolled hash table: def word_count(filename): # etc., etc., etc. if answer == "y": #printTable(hTable) from pprint import pprint pprint(hTable) # etc., etc., etc. `pprint` is really handy for debugging. Edit: Oops, `pprint` assumes that whatever it prints has sufficiently helpful `__repr__` methods. So, for quick and dirty, change `__str__` to `__repr__` in the `HashTable` and `_Entry` class definitions. My point is, you need to inspect the hash table without relying on your prof's `printTable`, `get`, `_locate` functions and stuff. 
Are there tutorials for that?
Holy crap! Jeebus. Thanks to you, I just realized the link to http://south.aeracode.org was not part of my link. Sigh. Dammit.
Obsessive Computer Disorder?
Might be outdated but this might still work: [Running Pyramid on Google’s App Engine]( http://docs.pylonsproject.org/projects/pyramid/dev/tutorials/gae/index.html#appengine-tutorial) and then the a link to a [automated script](https://github.com/JasonGiedymin/Pyramid-Scripts) of the above tutorial. 
&gt; But until then, it's in a different category with web2py or Django. Flask will never be in the same category as Django and it sure as hell will not try to compete with web2py in any way. The point I was making was that it does not have less features just because it's a microframework by design. In fact there are many ares where Flask outshines Django already (HTTP header parsing, WSGI compliance, flexibility of the template language, interactive debug screens etc.). And things that go out of scope for the core framework are in extensions which undergo the same test rules as the core framework and for the application developer, there is hardly any difference between Flask core and Flask extensions. I am not saying that you shouldn't use Django when it's a good choice. But SQLAlchemy on top of Flask with Flask-SQLAlchemy in no way more complex than Django's ORM.
So basically just bug fixes I'm interested in Pyramid for ~~two~~ three reasons: * The pylons(a active) community are behind it. * It allows you to choose your ORM, Template language, etc. * It is really well documented. I see allot of people recommending flask or web2py. But flask is lacking documentation in using the sql alchemy extension and web2py is using its own ORM engine. Any other Web framework I must be aware?
I use the buildout recipe http://pypi.python.org/pypi/rod.recipe.appengine all that does though is make sure my dependencies are in the app directory. other than that, everything else is stock pyramid until you get to datastore stuff, and I just use the appengine sdk for that. 
bug fixes, *and* close to being 1.0 if not the end of january ... very soon after /crosses fingers. 
Isn't AppEngine meant for smaller frameworks? 
I agree you're probably right, but who said he elevated to root? Maybe he elevated to a user that has group privs to access to key, but doesn't otherwise have permissions? Fat chance, I know ;)
Flask also lets you choose your own ORM, and the flask-sqlalchemy extension is just for convenience purposes and is a wrapper around the SQL Alchemy API, so I don't see why you would expect a lot of documentation from it. Also, SQLAlchemy is extremely well documented.
Yes you are correct. smaller frameworks like django http://code.google.com/appengine/articles/django.html
and micro frameworks like web2py http://wiki.web2py.com/Deploying_web2py_on_Google_App_Engine_GAE_ 
It's just by my sheer coding talent that I have managed to get something as HUGE as pyramid to run on appengine. You should buy my book I will show you how.
Just because it's available doesn't mean it is any good on the AppEngine. A few weeks ago there were some rants about how AppEngine sucks. Most of the defenders of AppEngine said it was the fault of the programmers who were using big, fat frameworks. 
Is web2py really usable on GAE? A few months ago there were some rants against GAE because it was unreliable. Some of the comments said this was the programmers fault for using big frameworks instead of the webapp framework. 
I had some misgivings about Pyramid after the merge, but it's growing on me. It has a good solid design and a lot of flexibility. In particular it has a very flexible authentication/authorization system. I'm not sure it will appeal to the average Django or Rails developer though, who might want the structure and bells and whistles. However Pyramid would be a very good foundation for a higher level framework - maybe the next version of Turbogears or something else.
I don't understand why you would take a Python class and learn "C-like code." You want to define a hash table structure in python? foo = {} Bam. Done. 
yes it certainly does suck for java. you did notice that the link you are replying to is from google, don't know if you know this, but they are the ones behind app engine. :) what has lead you to believe that somehow pyramid is a "big" framework? 
i believe turbogears will be the full stack solution that most people want to believe pyramid is. And long term the tg folks have indicated a desire to move that way. 
This comment is far more useful and interesting than the article :)
When Pyramid was announced I thought it was going to take much longer than this to get from where they started from with Repoze.bfg to where they wanted Pyramid 1.0 to be. This is great news for Python web development.
On reflection, it might be better to move beyond the TurboGears brand and start afresh. The migration from TG1 to TG2 (based on Pylons) was a major shift that left a lot of people behind - who went on to Django - and dissuaded more who were not sure which one to bet their project on. TG also suffered from pisspoor documentation and release management. Probably the way forward is: - better "core" solutions for common things like form validation, SQLAlchemy integration, email, message queuing (celery etc) - a good selection of paster templates for specific custom situations. Take form validation for example. The problem with Pylons in this area was that there was no consensus, so everyone did their own little thing - everybody hated @validate, but some people went with FormEncode, some with Tosca Widgets, etc. A single, well-designed form library would be a start - a "SQLAlchemy for forms" if you like. In other words, stand behind an opinion and build a kickass form validation/generation library (or pick and leverage an existing one) and make that the default for Pyramid. Sure, people can still swap it out, but newcomers will have something they can get started with from day one. Form validation is fucking important - it's one of the most time-consuming and frustrating aspects of web development, and one thing you need to get right, because it's the most complex interaction of users with the system. A good form library is one that takes all the pain away but gets the fuck out of your way when you need to get down and fiddle with the HTML. Unfortunately outside of Django Python form libraries are too cumbersome, too complicated, or badly documented, or some combination of the three (ToscaWidgets, my pet hate, was like trying to paint the Sistene Chapel with giant crayons). Same applies for things like email utilities and other bits of functionality people need. Django and Rails do these things because people actually need them. They need not be part of the actual core but at least are the default "goto" packages. Flask extensions point the way. Next, and this is already underway, have a set of paster templates for different requirements. These can range from bare minimum URL dispatch+sqlalchemy up to a complete CMS like Plone. With better components however you'll get less duplication between templates. Probably best to let TG die a slow death though.
These are good points. I think vph was just suggesting that "glued" frameworks and full-stack frameworks each have their pros and cons and may be appropriate for different users and different scenarios. Sometimes a glued framework, for all its benefits, can require a little more effort and expertise on the part of the developer. For example, Flask-SQLAlchemy (FSA) might not be more complex than Django's ORM functionally, but the workflow might end up being more complex. To use FSA, you have to install/update Flask, SQLAlchemy (SA), and FSA, and read three separate sets of docs. If you have a problem, you have to figure out if it lies with Flask, FSA, or SA, and you may potentially have to go to three different places to ask questions, report bugs, etc. (and each one may think it's the other's fault/bug). If the maintainer of FSA decides to stop working on it, you're out of luck (I know it's you in this case, but for the sake of argument). If SA makes an API change, you have to hope FSA will be changed in a timely manner. And that's just with one extension -- when you've got half a dozen external libraries, these headaches can really multiply. You don't worry about this stuff as much with a full-stack framework. Also, when you rely on external libraries for various functionality, it's less likely that the separate libraries will be well integrated with one another. For example, in web2py, the forms system, auth system, and DAL are all well integrated with one another, which can really simplify things for the user. It's also worth noting that full-stack frameworks don't necessarily lack flexibility. For example, you can use SQLAlchemy with web2py, and someone could even write an extension to make the integration easier. &gt;for the application developer, there is hardly any difference between Flask core and Flask extensions. To the extent that that's true, then perhaps such extensions should really be thought of as part of the framework. In other words, if a given extension includes only code written specifically for Flask (no third-party libraries), is maintained by the Flask developers, and is documented with Flask, then it really is part of the framework and not a mere "extension". I don't know if there are many extensions like that (FSA wouldn't qualify because it relies heavily on a major external library).
I'm not the OP, but I don't think the OP is taking a *Python* course. In other words, I don't think learning Python is the purpose of the course. This appears to be a course in algorithms and data structures, which is a whole different kettle of fish. These courses are usually taught using pseudo-code, but there's no such thing as running pseudo-code in a real computer. The prof has decided to have the students do some exercises using Python 3. The code you're complaining about is very C-like because most real-world hash table data structures happen to be written in C anyway. The OP is learning how to create and manipulate a hash table data structure from scratch. S/he's learning what a hash table *is*, not necessarily how to do useful stuff with it, such as count words. Using a `dict` or the `collections.Counter` would defeat the purpose of the exercise and defeat the purpose of the course. 
I cannot think of a reason why big/small frameworks matter for AppEngine.
I think a lot of people have used web2py on GAE with success, though I don't know how the performance compares with the built-in webapp framework.
About as much as yours. That's the point.
If you have something of substance to say do so, otherwise you just come off as a condescending douche. There are plenty of people who disagree with what you seemingly consider objectively true. You're reply adds nothing to the discussion other than an empty retort whereas I was criticizing a statement made by the author -- you know discussing the article at hand. It seems more people agreed with me than didn't which can't be said of your replies. If it's not worth the effort to try and inform me of your position, perhaps it's also not worth the effort to write a reply stating as much. 
Fair enough.
This is interesting, I've got a project where we are using the Google Protocol buffers and this could come in handy when we need to get more speed out of it.
http://protobuf.googlecode.com/svn/trunk/CHANGES.txt &gt;Added an experimental C++ implementation for Python messages via a Python extension. Implementation type is controlled by an environment variable PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION (valid values: "cpp" and "python") The default value is currently "python" but will be changed to "cpp" in future release apparently something similar is being implemented in the main protbuf codebase as well... unless it's actually BASED on the above :D
In that case by the time I need the extra speed it looks like I can get it free with a simple upgrade! That is a win!
Load time of the complete app. One article said that their web application couldn't make it within the limit. 
I use django non-rel for my personal projects. I wanted something with an ORM that I could take and run on a traditional web server with minimal effort if I decided to move away from AppEngine. I've been using Django for a couple of years, so django-nonrel seemed like the logical choice.
pp. 91 in http://bit.ly/eBJjaO shows how to define a main() that allows the application to stick around for a while... this makes startup time matter less. "always on" ($9/mo or so) makes it more or less not matter at all.
At least the article has this much going for it: TIL about the inspect module. 
Try http://stackoverflow.com/
The readme isn't terribly helpful if you don't know what protocol buffers are (as I did not..) http://code.google.com/apis/protocolbuffers/docs/overview.html &gt; [...] protocol buffers – a language-neutral, platform-neutral, extensible way of serializing structured data for use in communications protocols, data storage, and more.
For the standard solution to your problem, you may want to give a look at the PYTHONPATH environment variable (http://docs.python.org/using/cmdline.html#envvar-PYTHONPATH) or to the sys.path module variable (http://docs.python.org/library/sys.html#sys.path). For a more complex solution you may also want to look at PEP 302: http://www.python.org/dev/peps/pep-0302/. But I'm pretty sure setting python search path in the correct way is what you really want to do.
[Solving Every Sudoku Puzzle](http://norvig.com/sudoku.html). I think the code in that post is very inspiring. [Hidden features of Python](http://stackoverflow.com/questions/101268/hidden-features-of-python#sort-top) has good stuff, though they shouldn't be called "hidden".
the official tutorial lol.
I think books like [Python in a Nutshell](http://oreilly.com/catalog/9780596100469/) can give you a broad overview on the qualities and potential of the language. As a newbie to programming, especially the official tuturials and documentation seem to be well done. **edit:** but I'm also looking for a quicker and funnier way to learn!
Yes I'm on it, but I wanted to know if there were something perhaps more adequate to my situation and maybe quicker and funnier.
I found something interesting: http://python.computersci.org/ A quick java to python tutorial. I just hope it's not too concise. 
is there a magic method that fires off anytime you try to instantiate any class? Kind of like the autoload method in PHP.
From php docs of autoload: Many developers writing object-oriented applications create one PHP source file per-class definition. One of the biggest annoyances is having to write a long list of needed includes at the beginning of each script (one for each class). No python developer creates one source file per class.
Nope. The only way to do that would be to have a custom module dictionary, and that is hard-coded at the C level. 
Mark Pilgrim's "[Dive Into Python](http://diveintopython.org/)" sounds about right.
I think « magic method that fires off anytime you try to instantiate any class » is a bad idea. I like to see at the beginning of module what are the dependencies. This instruction below are better than auto load mechanism : import … from … import … from … import … as …
Obviously the answer by danielenicolodi is the correct one - you should set PYTHONPATH and not have code that does not make it clear where anything comes from which would be horiffic to maintain. ... But I've had a disgusting, evil thought and need to share it with people. It is in no way intended to be implemented (I did some limited experiments). exec and execfile let you specify globals and locals. I figure you could: class AutoLoader(dict): def __getitem__(self, item): try: return dict.__getitem__(self, item) except KeyError: self[item] = __import__(item) # Or whatever return dict.__getitem__(self, item) execfile('filename.py', AutoLoader()) Obviously this is untested and impractical. But something interesting to think about.
s/LLVM/Clang+LLVM/ LLVM itself can't build Python
What do people generally use protocol buffers for?
I have to second this, I learnt python using dive into python with around 10 years experience with other languages. xxxx is how arrays are done in python was a nice change from the normal tutorial.
Thanks for the link. I've seen this project before but never used it. I just ran it on a large project I am working on. And it did a great job. Mostly finding unused variables and global variable scope problems. It didn't work on checking my cherrypy code. It didn't seem to be aware of the classes used by cherrypy and gave a lot of strange errors.
"Finally"? Didn't this project go public years ago?
Is this going to be another "GNU/Linux"?
It's quite different. LLVM and Clang are different tools. Yes, Clang is a sub-project of LLVM and is used as its main front-end, but LLVM is a project on its own right and is used for much more than just being a backend for Clang. My intent was just to clarify
There is [PyFlakes](http://pypi.python.org/pypi/pyflakes) too, which you might want to try. PyChecker attempts to import the file, whereas PyFlakes attempts to parse it, so it may give more meaningful error reporting when something fails to import.
Perhaps I'm missing the point of protocol buffers... that wouldn't surprise me in the least. But I've got to ask: why should I use Protocol Buffers as opposed to JSON or even a shelve/pickle? What's the #1 attraction?
Do you get to claim "you're 10-15x faster" when you don't implement the whole protocol?
I've been going to [code.google.com/edu](http://code.google.com/edu) . The videos and walkthroughs for Python and all sorts of other languages are pretty nice
If you like PyChecker, you might also be interested in [pylint](http://www.logilab.org/857). It's a static code checker, which can also check style or convention violations, and is highly configurable. Its output can be a bit daunting to new users (or at least, that was the case a few months ago - don't know if they've made any big changes since then), but it's a very powerful tool.
1) Use iPython 2) http://swilliams.ca/python-tutorials/ and then go to blip.tv and search for Python 101 and 102 from PyCON 2010 by Stuart Williams 3) Python Osmosis - http://www.youtube.com/user/ryanmshea#grid/user/4B416E115B44D973 Start from Episode 18 4) http://www.dabeaz.com/generators-uk/ and http://www.dabeaz.com/coroutines/index.html 5) Dive into Python 3 by Mark Pilgrim for XML processing etc. 6) Bit dated but the book Core Python Programming ( grab the errata ) has some good treatment of Python Standard Lib. That should get you up and working on Python.
It's a good way of saving/transferring data in a language agnostic way. For example, we have large data objects (&gt; 15mb) that describe a certain signal. We can create a protobuf message that describes this data in C++, serialize it to a string, send it through a pipe to a Python client, and retrieve the data on the other end very easily.
Thanks for the explanation!
Yes, but Google's wrapper for Python was very slow. This new one is much more efficient.
For JSON: smaller size. think of PB as setting a convention for chunks of data. For shelve/pickle: not 100% on this but I'm pretty sure these two are python specific. I'm sure there are many more.
Yeah, I haven't seen non-Python bindings for shelve/pickle, so I could imagine this would be an attractive option in a heterogeneous environment. For what I'm doing, this isn't a huge concern, as everything is in Python. Size isn't an immediate "ah ha!" for me; I'm not tossing huge messages around often, though I could see how this becomes attractive. It is mentioned that serializing/unserializing JSON can be "5 times slower" but I'm interested in seeing a comparison to a C-bound JSON implementation or CPickle. I guess I should run my own tests :) Thanks for the details!
The actual news is that a company called Greplin open-sourced their implementation which is supposed to be much faster.
tl;dr In order to do something like eval/repr for functions: * Use "address_tools.describe" instead of "repr" * Use "address_tools.resolve" instead of "eval"
I second the PyFlakes suggestion, exactly by the reason given by chupish: it (PyFlakes) doesn't attempts to import (and run) your code. I have plenty of scripts that are meant to be run by other programs, modules that depend on the said programs to be properly initialized, etc. In cases like these, PyChecker provides, sadly, no help at all.
The implementation is the same. Read the installation steps; the first one is "install Protocol Buffers". This is only a lower-level [faster] Python wrapper, similar to the one that Google is in the process of releasing externally as well.
yes, as the article states.
I find several points interesting: 1) Discussions about pure style and design: There was an interesting discussion yesterday on the python tutor list about class design. Steven D'Aprano (one of the Guru-tutors) posted a reference to a blog post about architecture astronauts. Nice read about pure design. http://www.joelonsoftware.com/articles/fog0000000018.html I think the author of garlicsim (cool-RR) has a good point when he says on a certain stage you have to get things done. It's the 80/20 rule. But then, the point of discussion forums or stackoverflow is to be technically top notch. Sometimes people need to be pedantic. In my opinion they need to be to keep the value of those discussion forums. 2) Being downvoted: He shouldn't take it too seriously or even personaly. Often, people show their disagreement more than agreement. For example I thought several times: "Damn, that garlicsim stuff looks like a pretty cool project. Only the name is a bit ... hmm ... strange ;-)" But I never commented on it. Probably a lot people think the same without ever telling the author. 3) The address_tools module: Actually, to me it's a bit too magical. However, creative thinking. I just wonder about the namespaces. Maybe I didn't fully understand how it's working (didn't read the source). But how should the address_tool be able to distinct between two different modules with the same name in different packages without the full absolute path within the namespace? Anyway, keep up with your project and postings. They're interesting. 
Bears a striking resemblance to Scipy.
FYI Sho means "shut up" in several dialects of Latin American Spanish. 
Describing protobuf as JSON++ is pretty silly because protobuf isn't meant to be human-readable at all (i.e. JSON and protobuf aren't competitors except in the most naive sense possible).
I've used protocol buffers in a server/client system that broadcasts structured messages from one Java server to dozens of Android clients using UDP broadcasts over WiFi (it was a school assignment so was never actually put to real use but it worked surprisingly well!).
so I started reading the manual and found this "As you may know, Python is not a strongly typed language". Those static guys are still seeing us as some loosely lousy creepy dudes. 
I would recommend you to start with David Beazley's python essential reference - if you know how to program, it will get you up to speed quickly and still provides a good reference. http://www.amazon.com/gp/product/0672329786/ref=pd_lpo_k2_dp_sr_1?pf_rd_p=486539851&amp;pf_rd_s=lpo-top-stripe-1&amp;pf_rd_t=201&amp;pf_rd_i=0672328623&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_r=0VPRA9R4NQAN39563V8E
Maybe I could use this in Attest?
Also defeats the creditability of the author.
Dive into Python 3. Read the section on porting from Python 2, and you'll know Python 2.6+ also.
sho
That's how I learned as well. For advanced topics like metaclasses etc., there's a very good Google Tech Talk called [Advanced Python or Understanding Python](http://video.google.com/videoplay?docid=7760178035196894549).
Nice, I was just running some code through pep8 &amp; pychecker. Now I've got pyflakes &amp; pylint to also check out. I'd like to use these for code reviews in which these programs can take care of 100% of the style issues, 90% of the programming errors, and the review can focus on the basic approach to the problem. 
I REALLY like this, good work!
I would also love this answer. 
there has to be unique urls. perhaps you guys are using POSTs instead of GETs. First you need to install firebug or some other form of packet sniffer. Look at what ajax is going on if forms are being submitted and retrieved via javascript. You can use python and the urllib2 module to make requests. Basically don't think about filling out a form on a webpage. All you want to do is send the POST variables to the correct url. I hope this makes sense. 
Out of place, but I love Attest! I wouldn't want something like this on by default, but it could be nice while inspecting failing tests.
I solved a similar problem (form created by javascript) with this last week. What you need to think of is data being sent to the webserver, and that the form or Python is just an interface for doing that.
This man speaks truth. Capture a session with wireshark and it will show you exactly what HTTP transactions are travelling back and forth. 
[LiveHTTPHeaders](http://livehttpheaders.mozdev.org/) is your best option.
Interesting. I installed Firebug and logged into our admin site. It seems it does request unique urls. It just doesn't update the address bar for some reason. Hopefully with this I'll be able to work out using selenium to fill in what I need. Thanks!
..This model of thought may be a little beyond me at the current moment. I'm just starting to get into GET and POST requests in their most basic forms. I'm still a bit new. If you wouldn't mind, could you point to any good books on the subject? All my knowledge of the process thus far has come from Learning Google App Engine (just started it). It outlines the basics of what's going on, but I'd like to know more. 
It may be a bit heavyweight, but it's easily possible to script [QtWebKit](http://doc.qt.nokia.com/4.7/qtwebkit.html) via [PyQt](http://www.riverbankcomputing.co.uk/news) or [PySide](http://www.pyside.org/). It's even possible to do this headlessly from the terminal, with no GUI windows in sight. The benefit of this approach is the site cannot tell, without significant effort, that it's being scripted, so things will just work as if you're running Chrome or Safari. Using something like [QWebElement::findFirst](http://doc.trolltech.com/latest/qwebelement.html#findFirst) to locate the &lt;form&gt;, then subsequent findFirsts on the form to populate its fields, you can mimic the exact behaviour of a user. If Qt looks scary to you, there's also a few pre-canned tools, e.g. [PhantomJs](http://code.google.com/p/phantomjs/).
Have you tried Selenium2? It doesn't have the same sandbox limitation as Selenium 1.
It might actually be harder to get it to work using something like Selenium, whereas figuring out where and what to post to a URL shouldn't take too long at all with FireBug. Shamless plug here, but I wrote about accessing online content on my blog a while back. [You might find it useful.](http://everydayscripting.blogspot.com/2009/09/python-back-to-basics-accessing-online.html) Feel free to PM me if you have any specific questions. I really enjoy stuff like this!
Once you have the URLs and parameters figured out (use firebug or livehttpheaders, as has been suggested already), you can automate it in python with [Twill](http://twill.idyll.org/).
When I run it on a decently large directory of images, I get all different hashes. When I run it on your two sample images, I also get two different hashes. Does this simplified version have the same problem? hashlib.new('md5', file('filename').read()).hexdigest()
I'm not able to reproduce the error you are reporting. It would be highly unlikely that you would be able to produce a collision with md5 on two different images. &gt; $ python hash.py . &gt; Renaming 1.jpg to a1bb51d3666cfa56cafdfd36db654f1f.jpg &gt; Renaming 2.jpg to a288173779c5c53ff33a7abcff341634.jpg &gt; Renaming hash.py to 573fbe0ef345e92bde04025b76847e1d.py Your code seems to work fine on my machine, sorry I can't help you any. 
Yes, I get the same problem
I downloaded the images back off imgur, and got Renaming JyKfi.jpg to 1ffd9074b67ac6fd6de732cdbc42a49b.jpg Renaming OYhKU.jpg to 1ffd9074b67ac6fd6de732cdbc42a49b.jpg Which are different hashes from what I get from the original files, but still identical. This is very odd.
While using urllib2 or selenium will probably work fine. Depending on what and how you're automating things, [Sikuli](http://sikuli.csail.mit.edu/) might be another option.
Upvoted for Twill. Although it doesn't seem to be actively maintained, it is an excellent Python tool.
Looks like microsofts attempt to get into the scientific programming space except that (unlike all the CPython scientific programming tools) this one: - isn't open source - isn't free for commercial use - isn't cross-platform - isn't well documented - doesn't have the breadth of tools available to CPython Basically, if you're a .Net person who wants to do a bit of linear algebra, this is a good option. If your a scientist or engineer, use the CPython stack.
 ** Using LiveHTTPHeaders &amp; PyCurl (Low Level) ** * Get LiveHTTPHeaders addon for Firefox. * Goto Tools&gt;LiveHTTPHeaders * Perform the action you want in your UI. * Find the action in the Headers tab. * Example: POST http://www.foo.co/form_action.do?user=bar&amp;pw=baz * The part before the ? is the URL, the part after are the arguments. Each argument is in the form key=value and they are separated by an ampersand (&amp;). Code it up... import pycurl import urlliib import StringIO curl = pycurl.Curl() curl.setopt(pycurl.URL, 'http://www.foo.com/form_action.do') args = {'user':bar, 'pw:'baz'} encodedArgs = urllib.urlencode(args) curl.setopt(pycurl.POSTFIELDS, encodedArgs) response = StringIO.StringIO() curl.setopt(pycurl.WRITEFUNCTION, response.write) print("Performing POST on %s with %s" % (siteURL, encodedArgs)) curl.setopt(pycurl.POST, 1) curl.perform() responseCode = curl.getinfo(pycurl.RESPONSE_CODE) effectiveURL = curl.getinfo(pycurl.EFFECTIVE_URL) responseData = response.getvalue() print("Response: %s @ %s --&gt; %s" % (responseCode, effectiveURL, responseData)) (Code should work as I pulled it from some old automation, but if you have other questions feel free to ask or PM me. I actually do UI automation for a living, so I have dealt with this quite a bit. BTW PyCurl also support cookies and many other fancy things, and you can play around with manual curl requests in your shell) ** Using Twill (High Level) ** * Install Twill (on Linux *sudo yum/apt-get install twill-sh*). * Explore the page in the twill shell @ terminal type *twill-sh* help go http://www.my_page.com showforms fv 1 1 my_username fv 1 2 my_password submit fv stands for form value. fv 1 2 &lt;value&gt; will put the given value in the second field of the first form. fields can also be targeted by name. Once you know what you want to do, you can import the twill module into your code, and then go to a page, fill out some values, and submit the forms. 
Don't do this. Wireshark is great, but it is not the right tool for this job. Use LiveHTTPHeaders or Firebug.
cambridge, mass or cambridge, uk?
Are you on Windows? On line 16, what happens if you change file open mode from 'r' to 'rb'? It might not be related to your problem, but I'd like to eliminate any uncertainty first.
Mechanize is good, however note that it uses an XML parser, and HTML != XML, so there will be elements that do not appear. The way I made it do what I wanted to on a form that was similarly uncooperative, is dig into Mechanize and you'll find how to add tags into its form hierarchy, so you can then post what the website expects. You will have to break out Firefox + Firebug to figure out what the page expects. So basically... * Mechanize pulls down the form page in question * You insert into the Mechanize form object the missing nodes * Submit form as usual
Yes I am on windows, and yes this solves the problem. Brilliant, thanks.
[Read this chapter of Dive into Python 3 on web services](http://diveintopython3.org/http-web-services.html) for a good introduction if you're new to HTTP stuff. 
You should probably use a read mode of "rb" rather than just "r", otherwise Python may translate what it thinks are line-endings and otherwise mangle the file. I doubt that alone would cause duplicate checksums however. Hmm, I wonder what happens if you use Python's "read" to copy the files? Do you get two identical images when you view them (as the identical md5s would suggest)? Does the md5 change again after the copy? file('out.jpg', 'wb').write(file('in.jpg', 'rb').read())
http://who.godaddy.com/WhoIs.aspx?domain=pydra.com&amp;prog_id=godaddy Going by that I'd say Massachusetts.
I solved this last week with opener = urllib2.build_opener(urllib2.HTTPCookieProcessor()) # for dealing with cookies data = urllib.urlencode({key:data}) f = opener.open(url, data) # for a post f = opener.open(url + '?' + data) # for a get I used firefox addon "[tamper data](https://addons.mozilla.org/en-us/firefox/addon/tamper-data/)" to examine my posts. My application required another get request first to obtain a CRSF middleware token to use for the post requests. 
check here, maybe some of those still work (tho they seem outdated). http://wiki.python.org/moin/FreeHosts
[Webfaction](http://www.webfaction.com/). It's more managed than a barebone VPS (which I think is good), but it'll give you enough flexibility to host your python app (and it'll gladly support any libraries which you might need to import).
I've got though half of it and found it good for understanding generators, decorators and the likes. It seems like a good way to get a broad understanding of the features of python. The explanations are pretty thorough and it's quick to get though. However I want to *really* know it well. After I've finished I think I'll read and complete the exercises in [Learn Python the Hard Way - Zed Shaw](http://learnpythonthehardway.org/index). I think mistakes can be a pretty good way to learn, and I'd much rather do them in a sandbox than production software. I still have some misunderstandings about what is a copy and what is a reference. For example, I saw this puzzle on stack overflow. x = ['foo', [1,2,3], 10.4] &gt;&gt;&gt; y = list(x) &gt;&gt;&gt; y[0] = 'foooooo' &gt;&gt;&gt; y[1][0] = 4 &gt;&gt;&gt; x ['foo', [4, 2, 3], 10.4] &gt;&gt;&gt; y ['foooooo', [4, 2, 3], 10.4] WTF I thought, the nested list object changes yet the string does not. It seems that list() creates a new list, but any list objects inside are really references while strings are stand-alone copies. It could be me skipping a few paragraphs but the python tutorials for programmers never seemed to cover this. http://stackoverflow.com/questions/2573135/python-progression-path-from-apprentice-to-guru
I use the Enthought distro with matplotlib, scipy and lots of other libraries. It's really good. I wonder how Sho is different?
good show, sir.
First, yes I wrote this blog post. My question is, has anyone else encountered this problem? If so how did you manage to work around it?
I remember seeing something similar on /r/python a while ago... also invite-only ah yes found it, it was [ep.io](http://www.ep.io) they're having some kind of problem atm though, showing an error page over here makes me wonder... what's the difference between these two? obviously since it's not out &amp; no one has tested both yet, we won't get any definitive comparison, but I'm just curious
This looks good. Is it easy to set up? I'm not home and can't try it right now.
especially important to clarify in the light of "pure-llvm" projects like pypy or unladen swallow, where the frontend is python and llvm acts as the "bytecode".
I thought that, up until recently, it wasn't a wrapper so much as a native python implementation? (whereas the linked article is a wrapper to the C++ lib, hence a lot faster)
Yes I am certain I am saving. It will open in the text editor but not the shell. I'm 100% positive i'm saving within the correct folder as this is idiosyncratic to some file at random intervals. Some work some don't. Also when I resave it will open the edited file within the text editor but the old one in the shell.
Definitely Webfaction. I was actually JUST using my account, setting up the 6th Django app on there. They have lots of good documentation if you're not sure how to set something up too. One thing to note is that you can only have HTTP servers hosted there - no IRC/XMPP/etc. but that's true of most shared hosting anyways.
Go buy a cheap linux based vps, it should only cost around 5$ a month as you won't need much resources. 
Hooray for fragmentation! They could have contributed to scipy, but no, they had to create a brand new, .Net-only library. Will Microsoft ever learn?
I've put my email address down for both, and I'm happy to take a Redditor's simple python web-app and try both.
OK, I've found a GAE application which uses web2py. It's just a demo and I guess it isn't accessed very often. 1\. access by me needs about 3 or 4 seconds. After that it's instant (without browser cache). (Timing subjective and not total load time, just the subjective delay.) That's acceptable for most sites. 
appengine doesn't allow long running processes or sockets, so an IRC bot is certainly not going to run.
I am not installing Silverlight. 
Or wanting a lightning fast and 100% safe solution + good night sleep.
ep.io probably down ATM because of crazy load, specifically django-cms just launched a new site which features the ability to automatically boot a sandboxed site on ep.io for an hour, so they were spawning instances more quickly than ep.io was ready for. Having used ep.io I've been sure happy with the service, really makes deployment as easy as it should be and Andrew is a super smart guy.
Update... 1. Complete - Previous code had a lot of combined UI, data, and data manipulation. New code uses a class to hold and manipulate data. The class and a couple of related functions are in a package, all UI is in a separate script that imports the package modules. 2. Still researching. 3. Complete - Decided to keep it simple and use plain distutils. We use so much code that require the same dependencies it pretty easy to ensure everyone has python/numpy/scipy/wx/matplotlib pre-installed.
I use redis for problems like this. It's fast and scale well.
How should I separate the codes? Just stick all the class definitions for a module into a single file?
&gt; Pydra is deploys Djano, Flask, Web2py, or any Python framework easily to the web for testing and production. Misspelled Django.
Sho 'Nuf
Is there any cool example code? Or how the compiled code looks like? Or some interfacing example? With macros, maybe.
Use the [__init__.py](http://effbot.org/pyfaq/what-is-init-py-used-for.htm) file. Read [this!](http://docs.python.org/tutorial/modules.html#packages) 
unittest2 already uses something of the sorts. Python's regrtest for 3.2 uses it and it's terrific.
Amazon EC2 micro instances are now free for one year.
Interesting though I'm guessing it's not written in python? Looks like that would work, but then I break my preference to easily have everything contained in one place.
https://github.com/metageek/adder/tree/master/samples
Showing an error? That's slightly worrying, since it works for me! Still, until everyone else opens up as much details as we have (I'm Andrew from ep.io), I can't really compare fairly - still, of course, we're confident we're the best platform. It would be silly if we weren't.
You also [can't use libxml](http://code.google.com/p/googleappengine/issues/detail?id=18) on GAE.
Either the URLs are being requested via XMLHttpRequest (AJAX) or the server-side scripts were written by someone with a functioning brain and send redirect headers in response to the POST data. That avoids having silly intermission pages a la phpBB (cargo cult programming ftw? this seems to be the most copied anti-pattern among '00s web applications; maybe they're afraid of HTTP/1.0 clients or something) or being stuck on pages that warn the user about resubmitting data on reload.
Interesting. But couldn't this be implemented as a decorator? Something like: def recursive(f): @functools.wraps(f) def wrapping_func(*args, **kwargs): result = f(args, kwargs) while callable(result): result = result() return result return wrapping_func This would avoid having to worry whether a function is recursive or not when calling it. i.e. no trampoline needed, just a plain old function call. You could probably implement this as a generator, too.
Thanks for introducing me to Twill! I've been wishing for a tool like this for a while now; shame that it isn't actively maintained. I'll consider branching/ adding features if I find myself with some time on my hands =).
also, "is deploys"
# # Semi random ramblings in response to your advice, you can skip to below # Personally I like a MVCG pattern. Model, View, Controller, GUI. View and GUI are more tightly linked then in the other layers, GUI is all the setup and layout code and View is all the interaction code. This allows me to rip through the layout code and reorganize it any way I want, it also means that I can create a new gui version by just creating a new layout and playing with it. Finally integration and functionality tests are a joke to do if you have a GUI class separate from the view functionality. Since I mostly use wxpython I built a tool for functionality testing. What it does is when handed a GUI class it opens it up, finds all the wxpython related controls then creates click utility/visibility methods checkers. I do resizing calls and my framework does a bunch of random clicks in the gui and checks to see if the gui fired the correct buttons in response. So if i do a layout change and something overlaps something else, I get a fail. All automatically. Throw that together with a few automatic scripts for compile and run on linux/mac/windows and I've got a pretty decent 'does this look roughly right' checker. It's not strictly needed, and mostly I could just reorganize my GUI class into my View, but this nice separation works for me. Just something to think about. # # end semi-random ramble =-P # As to the specifics of your suggestion I would highly suggest going with the models controller and outputs idea. I've built something similar and this is exactly how I went about it. methods like 'buyAllWeapons()' are really high level, and the abstractions you want to be working with at the highest level. This is where your buying/selling code script should be working at. The script should almost read like English. The next level down should be some kind of controller that handles things like 'here is the searched data I've currently got' and 'current price trends for this item' etc etc. Slightly lower level but still not dealing with outputs and clicking. The last layer down should be where you handle things like 'where to move mouse' and 'the auction window is in such and such location' etc etc. You should be able to see how higher abstractions rely on lower abstractions. Hope that helps.
It was showing an error like this: &gt;ep.io: Unknown app &gt;It seems the URL you've used points to our servers, but we don't have a matching app to serve. &gt;We're terribly sorry about that. When I tried to access ep.io (&amp; which led me to) www.ep.io (yes, double checked for typo on "www") It was only for a short while so I figure probably temporary routing problem? Well it's a good thing you're confident you're the best! I'm patiently waiting to see &amp; compare :)
Nice try Andrew. Kidding aside, it's back up now!
 import this Prints out the [Zen of Python](http://www.python.org/dev/peps/pep-0020/) 
for i in range(1000000): print('Happy Birthday!') Who wouldn't want to receive a million happy birthday wishes?
I'm not really a developer but I've played with it. I converted the example blog to use sqlalchemy. I think i started working on authentication before the real world squeezed my balls for time. I've also played with django in the past and flask has a lower learning curve.
I **highly** recommend this. My instance is my first ever VPS, and I'm loving it. It's hosting [my website](http://dylanstestserver.com) and a [gitosis](https://github.com/res0nat0r/gitosis) git server. I even manage my website through the git server, commits pushed to branch *live* are pushed into Apache. It also comes with free storage space, so you can set up backups to Amazon S3 with rsync. You can have 5 IP addresses to! It's a bit complicated if you've never used a VPS, but learning has been tremendous fun, and has helped me feel a lot more confident in linux and working with remote boxes. Also, the nature of Amazon instances makes it *super* easy to throw away your instance and start anew. **WARNING**: only Amazon Linux AMI (based on CentOS) is free, it's pretty unclear, since the advertisements boast a "free linux instance", and then after running standard CentOS for a week I noticed charges on my account. However - Amazon nicely waived the fee after I called them and switched to the right image.
From your description, it's indistinguishable from Google App Engine or ep.oi. Come back when you have something to show us. 
 Traceback (most recent call last): File "life.py", line 43, in calendar Celebration: Happy Birthday! This kind of sucks.
 if user == "[your boyfriend's name]": print "Happy birthday", user And yes, we are interested in pics, but only if you appear in them.
this is by far the best idea, though it's a bit long for a cake. as somebody whos been developing an app in python for the last few weeks in my spare time, this is the only comment that made me laugh. I would also change the line number to match his age. if you're not a programmer, this is basically what you see when you run into an error in your program, or you're debugging. it's called a traceback and shows you exactly where you are in the program. print 'happy birthday' # is painfully played out :-/
If you're looking for other reasons: [Mike Driscoll of blog.pythonlibrary.org fame](http://www.blog.pythonlibrary.org/2011/01/28/pycon-2011-you-missed-the-worm-or-why-you-should-sponsor/) [Steve Holden, PSF Chairman](http://holdenweb.blogspot.com/2011/01/pycon-no-dead-kittens-this-year.html) [Brian Jones, who's teaching a Python 3 tutorial, and is part of the Python 3 Cookbook effort](http://www.protocolostomy.com/2011/01/28/pycon-2011-predictions/)
I don't think the print function is that bad, especially since it's the Python 3 way. Let's say his name is Mike: &gt;&gt;&gt; import mike &gt;&gt;&gt; if mike.is_birthday(): print("happy birthday!") happy birthday A picture would rule.
upvoted for twill, easiest way
 import whoisawesome Also, write a python package called "whoisawesome" and install it on his machine. Have it print "You Are! Happy Birthday!". Even if you aren't a programmer it's not *that* hard to make a python package this simple, although it's a lot harder than just writing on a cake.
What happens with really deep recursion? I guess I'll have to look at the compiled code.
The chicks are way hotter than the BoostCon ones too. (Goddamn you nerds have no sense of humor.) edit 2: White Knighting theoretical potential chicks... goddamn.
This is my vote as well. Nice one. Bookmarking so I can see the pic of the cake!!!!
Doesn't he reads python reddit?
Please none of this. One of the major goals in the past year or two has been to make the Python community (and, by extension, PyCon) as welcoming to everyone as possible, and this type of comment flies in the face of that.
I used this :) Looks a bit derpy on the cake though...I respect bakers a lot more now!
Yeah, so this is precisely the opposite of the tone we hope for at PyCon. I can't do anything about your boorish behavior on Reddit, but if you are indeed coming to PyCon please know that this sort of misogyny isn't welcome there. At all.
 &gt;&gt;&gt; import datetime &gt;&gt;&gt; import mike &gt;&gt;&gt; if mike.is_birthday(datetime.datetime.today()): print("happy birthday!") happy birthday
Your code is *literally* barely readable. :P
hi five brosef
&gt; It has one bit of non-Lispy syntax: foo.bar.baz means exactly what it does in Python, and .bar.baz is a function, defined so that (.bar.baz foo) is identical to foo.bar.baz. Can you make it so that it works for parameters too? Something like foo.bar.baz(a, b, c) Is the same as (.bar.baz a b c foo)
I disagree. I agree with the origin of PHP is a overblown scripting language. But current version of PHP offers enough tools and language support to create a coherent, well-engineered, enterprise-quality solutions. It is undoubtedly poorly (if at all) designed as a language, but not so much that it doesn't stop you from putting together properly designed product. The main problem I encounter most often with PHP (which is related to the problem you describe, in my opinion) is not the quality of language but the quality of developers. Because it grew out of a glorified templating/page-scripting language, there are a lot of developers who come into PHP from a front-end design or non-engineering backgrounds. Basically, everyone who's read "How To Write a Visitor Counter" tutorial calls themselves a PHP programmer on their resume. When placed in a large scale project, these "programmers" struggle. If you got a team of good engineers and use them on a large-scale PHP based project, they would produce something that approximates a high quality product they would have produced in any other language. If you can keep them from killing themselves, that is. TL;DR: PHP language is bad, but not as bad as most people who use it.
'Readable'? I thought you wanted 'Edible'!
I've got code running on satellites, helicopters, missiles, even a submarine and a robot, but this is the first time I ever had my code on a cake! I'm just so proud!
[Jython](http://www.jython.org/) seems like a nice place to start. I'm also going to go out on a limb and say you might be interested in [VASSAL](http://www.vassalengine.org/), if you haven't already heard of it.
&gt; misogyny I really wish people would stop misusing that word. Women in technology may not welcome such a comparison, but it is not [misogyny](http://www.merriam-webster.com/dictionary/misogyny).
Are any of these tutorials going to be posted online?
The videos end up online, and I think the tutorial materials going online is up to the tutorial giver to distribute them (not 100% sure). I know some of them have ended up online, e.g., Beazley's [Mastering Python 3 I/O](http://www.dabeaz.com/python3io/) from last year, also appearing this year.
No clue about or much interest in the service (meh, cloud), but credit where it's due: that's a darn good "py"-name. Witty, descriptive, and doesn't sound like I'm tickling a baby when spoken. Good job. 
&gt; before the real world squeezed my balls for time let me quote you from time to time please.
Wavicle, I'm sure that if you put your mind to it, you can imagine how one could consider it misogyny to imply that "chicks" are important at pycon just for their looks, and how the gp of your comment could be interpreted to do just such a thing. Further, I bet that if you stretched a little further, you could imagine why conference organizers and attendees, and anyone desiring to build a community of **people** interested in programming, would be particularly sensitive to such a *hilarious* joke. -llimllib
I prefer round bottoms, 24/40 if possible.
Excellent girlfriend is excellent. He's very lucky to have a girlfriend interested in Python.
Because Microsoft is evil?
Yes he told me it looked like I compiled it into byte code. I got an "aww I love you" for it though. 
It's shit like this, douchebag.
It's douchebags like this, douchebag.
For each special method, you should show what syntax magically invokes it. Something like this: * `foo.__iter__()` is invoked by `for x in foo` * `a.__iadd__(b)` is invoked by `a += b` * `a.__rmult__(b)` is invoked by `b * a` when `b * a` fails. * `foo.__len__()` is invoked by `if foo` when `foo.__bool__` or `foo.__nonzero__` is not defined. * `foo.__repr__()` is invoked by `'%r' % foo`, also by `pprint.pprint(foo)` and deprecated \`foo\`. It's also invoked by `__str__` magic when `foo.__str__` is not defined. * etc. Putting the above info in a table would also be helpful. 
this salad isn't going to toss itself.
Zed's book is for noobs and doesn't say a whole lot. If you *really* want to understand Python, you want to read Alex Martelli's *Python in a Nutshell*. It's kind of old, but I think Martelli is the deepest and most thorough explicator of Python out there. 
Wish I could make it. No budget. Anyway i will attend PyCon through blip.tv and carl f karsten's twitter feed. Thumbs up to the PSF.
Might want to mention that in Py3K `__nonzero__` -&gt; `__bool__`.
`iter(foo)` will also invoke `foo.__iter__()`
Indeed, but the built-in functions strike me as performing the obvious, not performing "magic." That's why I didn't mention the built-ins. The built-ins would be a good column in the table, though. foo.__iter__() iter(foo) for x in foo foo.__repr__() repr(foo) '%r' % foo foo.__bool__() bool(foo) if foo foo.__len__() len(foo) if foo (when foo.__nonzero__ is undefined) etc. 
&gt; I'm sure that if you put your mind to it, you can imagine how one could consider it misogyny to imply that "chicks" are important at pycon just for their looks, and how the gp of your comment could be interpreted to do just such a thing. Oh, i suppose we could, but for starters let's deconstruct your strawman: &gt; how the gp of your comment could be interpreted to do just such a thing. Here I will focus on only a single word of that post: &gt; too I assume you are capable of going to Google and figuring out what that word means. Therefore: &gt; one could consider it misogyny to imply that "chicks" are important at pycon *just for* their looks Is simply a strawman argument. If someone says "Ben &amp; Jerry's ice cream is rich and creamy too!" are you going to assume that the only positive aspect of this ice cream is its rich and creamy texture? Do you think this person hates all other brands of ice cream? I suppose if you're just plain dense you might. Considering something to be misogyny doesn't make it such. But even if we ignore all that, and we shouldn't, misogyny is hatred of women. Shouting out something you perceive as a value of one group of women over another is not hate. I regularly read comments about how European women are more beautiful than American (generally stereotyping on American obesity). Is that hatred of women? Misogyny is not "anything that offends some group of women." &gt; Further, I bet that if you stretched a little further, you could imagine why conference organizers and attendees, and anyone desiring to build a community of people interested in programming, would be particularly sensitive to such a hilarious joke. Oh, you mean like if I said Women in technology may not welcome such a comparison? Oh wait. I *did* say that. I see; it's another strawman you are creating. You're stretching my dissatisfaction with calling something misogyny when its not to suggest that I am ignorant of a whole host of other problems involved with building an inclusive community when someone is making comments about the superficial appearance of some of them. Of course I am not, nor did I make any suggestion of such, but hey, it did make your rebuttal look really good. So if your comment offends me, do I get to say you are engaging in hatred? Or is there a difference between being offensive and being hateful?
Finally, the speed of Python with the syntax of Lisp? :-/ The `yield*` thing is a cool idea, but there's already a PEP to add something like it to Python (3.3? 3.4?) under the name `yield from`. 
closing files on deletion is exactly what the _ _ del _ _ method of file does, so the example is a bit superfluous. (The problem with Jython and IronPython is that the _ _ del _ _ - i.e., finalize, method may never be called for objects that are not referenced anymore). Other than that, what's wrong with http://docs.python.org/reference/datamodel.html#special-method-names as a list of those special methods?
The biggest problem I have with Flask is the tight coupling with the `app`/`current_app` object, which makes unit testing more complicated than it has to be.
ah come on, we got that few days ago!!
I cam here to say this! If you do sign up, do you mind using my affiliate link? [Here](http://www.webfaction.com/?affiliate=mbesto) Thanks!
Jython is a good idea, as sigtoat mentioned. However, if you need C-extension or have other CPython-based requirements, you might want to look at [XML-RPC](http://en.wikipedia.org/wiki/XML-RPC) libraries for [python](http://docs.python.org/library/xmlrpclib.html) and [Java](http://www.ibm.com/developerworks/xml/library/j-xmlrpc.html).
&gt; (The problem with Jython and IronPython is that the _ _ del _ _ - i.e., finalize, method may never be called for objects that are not referenced anymore). No, that's not the problem, it will be called alright (except on interpreter shutdown maybe, not sure about those semantics). The problem is that *when* it's called is indefinite and unknown, so next time you try to open the file the first object may very well still be around, holding and locking the file you're trying to re-access.
Awesome year indeed. Unfortunately I haven't been able to get an invite to any of them.
I'm *really* partial to App Engine. The free tier is just too good to pass up on.
Here's something I wrote last night. It's sort of the "Keep it Simple" take on the problem: https://github.com/ericmoritz/micromodelsext-riak
My problem with it is that it's just that: a list. There's little explanation of the motivations for why you'd want to use some of the magic methods and there's few examples. It's also in the language reference, so most of the material is a bit intellectual for some, particularly the beginner. And thank you for your suggestion of `__del__` -- I'll try and add some of that into the guide.
Good suggestion. I'm thinking of adding this in an appendix.
Right now, this isn't a Python 3 guide (though most all of the material works with Python 3 with minor changes). I think I'll mention this anyway, though.
You can run python in JVM with jython or run JVM in cpython with [JPype](http://jpype.sourceforge.net/) Some games (chess, robot wars, ...) uses a stdin/stdout for comunication with logic process. I like this solution. You can use many rpc implementations: xml-rpc, json-rpc, soap, thrift, protobuf, zeroc-ice, ...
Thanks, this sounds like what I need! VASSAL also sounds very interesting :)
Another fun `__del__` note, on PyPy (and maybe Jython/IronPython, not sure) you cannot monkey patch `__del__` onto a class later, it will just send a warning, it must be declared with the class itself.
&gt; Not only do we have existing reliable providers like WebFaction, but we now also have a gaggle of Python specific web hosting services coming online Just got stuck on gaggle of snakes. While I enjoy that I think the official terminology should be one of: den, bed, pit, nest, slither, knot, brood, or troupe. 
Thanks for writing this. For some reason I never really even thought about using `__contains__`, etc to make the APIs I write easier and more natural to use. I definitely will now. Oh, also: here's a bit of CSS that I use with [Stylebot](http://stylebot.me) to make unstyled pages like this easier to read: p, h1, h2, h3, h4, h5, h6, ul, ol, dl, pre { width: 640px; margin-left: auto; margin-right: auto; } h1, h2, h3, h4, h5, h6 { font-family: "Hoefler Text", serif; } body { background-color: #fafafa; color: #111; font-family: Georgia, serif; font-size: 17px; line-height: 23px; } pre,code { font: normal 15px/20px Menlo, consolas, mono; } pre { border: 1px solid #ddd; background-color: #f5f5f5; padding: 15px 20px; overflow-x: auto; } code { border: 1px solid #e5e5e5; background-color: #f5f5f5; padding: 0px 4px; } a { text-decoration: none; color: #D63500; } h1 a, h2 a, h3 a, h4 a, h5 a, h6 a { color: inherit; } h1 a:hover, h2 a:hover, h3 a:hover, h4 a:hover, h5 a:hover, h6 a:hover { text-decoration: none; color: #D63500; } a:hover { text-decoration: underline; } dd { margin-bottom: 10px; } dl:first-of-type dd { margin-bottom: 0; } 
{ }
Wow, I tried this and it makes the guide look INFINITELY BETTER. Immediately added to the guide. If anyone can improve on this style, lemme know.
I initially saw the styled version, so I wondered why stevelosh was suggesting CSS for a site that looked rather good. :) By the way, a nice tool to make most sites instantly readable: http://lab.arc90.com/experiments/readability/
Total credit goes to stevelosh. Cool tool btw :)
Cool. With any luck, by the time my django site is done at least one of those sites will be out of beta. :)
`__exit__(self, exception_type, exception_value, traceback)`, it's missing that last arg.
100% agreed. Even though this probably isn't how {{ researcher }} meant it, naming is one of the more difficult parts of computer science.
I wouldn't mind seeing that poster.
&gt;# Flask will announce a merger with another web framework in 2011, in part due to conversations and activity at PyCon. If it's Bottle, it's going to be very interesting. 
I'm not familiar with how they work. Do you have shell access?
We need a distutils (Distribute)/pip replacement already?
Might want to include pickling support: `__setstate__`, `__getstate__`, `__reduce__` With descriptors, I think the distinction between "data descriptors" and "non data descriptors" is important, i.e. if `__set__` and/or `__del__` is present or not changes the behavior of the descriptor dramatically when the same name is assigned to `__dict__`. Background on that at http://docs.python.org/reference/datamodel.html#invoking-descriptors . 
have you tried /bin/env python?
Distutils isn't distribute. Distutils is why Distribute was necessary.
What do you mean by already ? Distutils has been there for a decade now.
so?
Tried, yes... Successfully, no. 
I've already started adding pickling. For that, I'll be documenting `__setstate__`, `__getstate__`, `__getinitargs__`, and `__getnewargs__` (`__reduce__` is only for extensions, which isn't real in the scope of the guide). As for the descriptors, that's on my todo list (as of now).
5 seconds of googling turned up this: Me (person requesting earthlink tech support): "I understand that I am supposed to be able to write CGI scripts in any scripting language. I can't seem to find the Python interpreter on my server, and keep getting a 500 internal server error with the following shebang lines: #!/usr/local/bin/python #!/usr/bin/python #!/bin/python #!usr/local/bin/python2.4 #!/usr/bin/python2.4 #!/bin/python2.4 Is Python just not running on the server that hosts my site? If it is running -- where is it?" __ Daniel P (earthlink tech): "I am sorry, EarthLink provides support only for CGI and Perl scripting."
Saw that. Other than as a commentary on Earthlink's customer support, I didn't consider it relevant. 
Why would you want to build CPython with Clang/LLVM. Portability, speed ...?
I'm not going to comment on the feasibility of this, or the algorithms you used, but rather critique you based on the code that you've written and how it follows the 'pythonic' coding style that us pythonistas like to employ. Firstly, instead of using `print` to print everything, maybe try using `logging` to properly log the messages. Secondly, I notice that you're redeclaring static dict and list objects in `comp`, `dest`, `jump` and `ctype`. You should consider moving them to the global module namespace. Also, when slicing, instead of doing [0:2], you can just do [:2]. Instead of returning strings and comparing them, you could instead define your constants as an `object()`, for example: A_Command = object() def foo(): return A_Command print foo is A_Command Now for more precise line errors, as I spot them. You don't need the `string` module, as all the functions you are calling from it are built into the `string` type builtins. On line 23 and 50, you don't need to slice the line and compare it, try using `line.startswith(r'/')`. On line 28 and 57, you can just use `if not line:` On line 64, I don't see why you enclosed the comparison in parenthesis. On lines 73-75, I don't see an efficient way to do this with out duplicating code, but you could just replicate `newFile.write`. On lines 85, concatenating strings is usually frowned upon and inefficient in python, consider using a string formatter. On lines 89, 91, 113, 125, 158, and 170 you can just use `'=' in input`. On another note, I wouldn't overwrite the `input` builtin. On line 135 and 136, what exactly are you doing? Instead of using `input in hashTable.keys()` you can just do `input in hashTable`. On lines 154 and 156, you can use `c.startswith()` and `c.endswith()`. On lines 155, 157, 159 and 161, see my suggestion above. On line 166, (the only time you use the string module) you could just do `input = "".join(input.split())`, but really why not just `input = input.replace(" ", "")` It's always good to wrap the actual execution part of the code in an `if __name__ == "__main__"`. It's late. These are basic improvements that I spotted out while scanning over your code. Thanks for reading :) edit: instead of using pastebin, why not gist.github.org? It's waay better. 
I should note that bento is not a replacement for pip at the moment - it only deals with the distutils side of things. I have some idea for the installation/deployment parts that pip deals with, but too little code to be worth mentioning at that point.
Can you explain why string concatenation is frowned upon? Java was the first programming language that I fully learned so I always found it odd that python string concatenation is a pain (have to wrap integers in str()). Do you know the reasoning behind this?
Now write a Python interpreter in Hack!
We like to use (in pythons prior to 3.x) a printf type approach. So to place an integer in a string we would do. print 'I have %i apples in my %s' % (5, 'bag') As for the reason behind it, each object in python is well an object. The behavior of x + y is determined by the magic method x.\__add__. when you attempt to concatinate a string with an int or vice versa, it tries to either mathematically add a string to an integer, or concatinate the integer onto the string with out casting it to a string first. For this reason, and the fact that python is funky with string concatination (slow because it builds a new string object for each concat) we usually use the formatter. It also takes care of all the type castings. However, suppose you want to build a string by looping through something. Instead of using mystring += stuff. make a list and append the stuff to it, then at the end do ''.join(list). Way faster, benchmark it yourself. 
Use Perl to search for the Python executable.
I'm not a Py3K user, but if I'm not mistaken these also hold * `__div__` -&gt; `__truediv__` (ditto `__itruediv__`, `__rtruediv__`) * `__long__` -&gt; `__int__` * `__oct__`, `__hex__` -&gt; `__index__` * `next` instance method -&gt; `__next__` * `__unicode__` no longer exists * `__cmp__` no longer exists * `__getslice__`, `__setslice__`, `__delslice__` no longer exist 
Another reason for preferring `''.join` is that each time you add two strings it creates a new object in memory, so if you write `"A" + "B" + "C"`, first it creates the object `"AB"` then it creates the object `"ABC"` then it throws out the `"AB"` object it just created. For three things, that's no big deal but when you're concatenating a lot, it can be pretty inefficient (although I've read that they made in more efficient in recent Pythons, maybe 2.7 or something).
If you want a so-so chunker and POS tagger, you could also take TreeTagger. Getting a _good_ chunker for German is not as easy, because you have front-embedded NPs (e.g. "[NP the bottle] sold in [NP the store]" would be "[NP die im [NP Laden] verkaufte Flasche]"). EDIT: If you want to know about chunking approaches for German, here's the PhD theses of two people explaining what and how: Hannah Kermes: Off-line (and On-line) Text Analysis for Computational Lexicography http://www.ims.uni-stuttgart.de/~kermes/diss/03_diss_Kermes.pdf Frank-Henrik Müller: A Finite-State Approach to Shallow Parsing and Grammatical Functions Annotation of German http://tobias-lib.uni-tuebingen.de/volltexte/2007/2758/ 
Basically. If you use google's bigtable api, it's ridiculously easy (although you have to do some hackish things to store proper decimals and not floats for things like currency)
I felt that the interaction of cmp with the individual methods (le, gt and so on) was glossed-over.
Yes, I think I did. When using multiprocessing for the first time, back when python 2.6 was just released, I experienced weird lockups. After some messing around, I figured is was caused by the large amount of data I was passing around. I solved the problem by reducing the size of the data I was passing around by putting that data in a file (sqlite database) and then pass reference IDs in the queues.
Thanks. I'll keep this on the todo for Python 3 gains widespread adoption
How so? From the guide: &gt;It actually implements behavior for all of the comparison operators I didn't give an example because it's not the preferred way to define comparisons. The preferred way would be to define `__eq__` and `__gt__` and then use a `@total_ordering` class decorator.
The module installer ecosystem has been a complete mess for months, and this does little to rectify it. Unless Bento can unanimously replace distribute/pip/distutils, it just worsens the problem of mutually incompatible install systems.
Excellent idea, wish I'd thought of it before. Thanks!
A reverse proxy cache will be 1000x faster than apache under any circumstances. Unless you are serving your static site on a CDN, apache will be slow as shit no-matter if your site is static or not ... apache is *THE* major bottleneck... more-so than python, your database, and maybe your shitty code (probably not though, but that's where varnish comes in). ie: I can get 1000 req/second on a pure python server that is moderately equipped... there's no way I would ever see that in apache on any set of hardware (well in the future maybe, but by then we'll have flying cars and shit so we won't have to worry about this knd of stuff).
Though in that case, your app will not be portable to other platforms without some re-coding (might not be a big deal for relatively simple apps). If you want easier portability, you should use an ORM or database abstraction layer that works with GAE/BigTable as well as with other data stores (though even then you may need some refactoring to port).
&gt; For this reason, and the fact that python is funky with string concatination (slow because it builds a new string object for each concat) we usually use the formatter. It also takes care of all the type castings. I feel like these are things the language should be able to handle and abstract from the user, particularly since python is so object oriented. Java/C++ can both understand that an integer in a string context should use the string representation and Perl adds an additional operator for concatenation. Having learned these languages first, python's treatment of string concatenation seems poorly implemented. I definitely appreciate the power of string formatting, but string concatenation/operator overloading seems intuitive to me and I feel like both this and string formatting should be supported in the way I would expect. Thanks for providing some insight into it, but I still can't help but feel that the reasoning is flawed and that the implementation should be reworked. Is there a deeper reasoning for int/str concatenation not being supported in the way I described? Thanks for your patience, this is something that has been bothering me since I started using python a couple years ago.
Did it work? Is Python even there?
That's fantastic, I have high hopes for PyPy. I would love to try it, but there are no Ubuntu PPAs. I think it would gather *much* more mainstream adoption if there were a PPA, maybe you guys need to increase that priority a bit. I know I'd use it pretty much for my main Python if I could get a deb.
I stopped reading at BaseHTTPServer.
Why?
Congrats to team. Docs can be found [here](http://docs.pylonsproject.org/projects/pyramid/1.0/).
I use `__reduce__` in several non- extension instances where `__getstate__` or `__getnewargs__` doesn't cut it (a `dict` subclass that overrides mutator methods to not be callable, for example). it's definitely worth including as it's essential in some edge cases.
Apparently you did not google. https://launchpad.net/~pypy/+archive/pypy-weekly and also there are release builds.
Ah, thanks. All Google found was a ppa for 1.2. EDIT: The weekly PyPy PPA has failed to build for a while now, I installed the PPA but apparently it provides no packages.
Awesome work, great thanks.
"Pyramid is a small, fast, down-to-earth Python web application development framework. It is developed as part of the Pylons Project. It is licensed under a BSD-like license."
Great news! Congrats to team. It was sure a lot of work.
Well, first of all, what you've just written here would be useful information to have in the guide! I don't think it has anything about @total_ordering. But what I meant was, what happens if one implements both `__cmp__` and (eg) `__eq__`? Does one of them take precedence? Since `__cmp__` seems to be enough to derive all the others, what is the advantage of writing them separately? I think Haskell is smart enough to derive (eg) `__le__` as `!__gt__`, but does Python do so? Are there cases where it makes sense to have different semantics than this? If not, why do they all exist?
In web2py complete code def myfile(): path='/where/files/are/' # &lt;&lt; edit this import os response.headers['content-type']='application/vnd.ms-excel' filename = os.path.join(path,request.args(0)) return response.stream(open(filename,'rb')) call them with http://domain/appname/default/myfile/monthlydata_2010.xls where appname is the application name, default is the default.py controller name (the file where you put the above code). You can also eliminate the "/appname/default/myfile" from the URL by editing the routes.py configuration file. This is not the place to discuss it in detail but if you ask on the web2py mailing list, we can tell you how to (there is a value in the longer path since you can host multiple apps).
Did anyone else notice that *iterate* went from 60.ms to 6.0ms, which the table claims is a 12x speedup? It's probably a typo...
Python is somewhat overkill for this. curl has support for this kind of thing built in, but I usually just use wget + shell expansion: wget http://www.example.com/monthlydata_{2001..2010}.xls
Eh? The OP seems to be asking about downloading files from a client perspective, whereas you seem to be saying how to serve those files from a webapp using web2py. Or have I missed something?
This isn't really a problem. Sending a value to the workers to tell them to stop is what you should be doing. Using queue.get(block=False) will almost never work right. Think of the case where you are using a slow generator to feed work items to the workers. If you use block=False they will exit before they even got the first work item. The only thing I do differently is send work items as a tuple of a boolean and the work item.. like: for item in items: jobs.put((False, item) then the workers do: stop, job = jobs.get() if stop: return that way you don't have to worry about a job item being None. I suppose you could alternatively do stop_item = object() and then if job is stop_item:
I agree with you on the `total_ordering` decorator; I added it last night. My only apprehension was because it's only available in 2.7.x. As for the `__cmp__` and `__eq__`, `__cmp__` will implement whatever was not explicitly implemented, so in this case it will implement `__ne__`, `__gt__`, `__lt__`, `__ge__`, and `__le__`. The advantage of writing them separately (which I touch upon in the guide, but not with respect to `__cmp__`) is finer control. Often behavior for equality is different than desired behavior for comparison, so if you just define `__cmp__` you often get stuck with some odd behavior. It's just not encourage practice IMO because it can really back you into a corner.
Yeah, correct--Justinsaccount answered my question above
Ha, I use Dataset as the name of my python tabular library (closed-source currently) too! Essentially a Dataset is just a python in memory database table so one thing I've played with is storing the data in a SQLite DB. The only trick I had to do was add a pickle adapter to handle arbitrary Python types. I don't know how this will cope with 8 gig files though. For really big data you might be able to do the same thing but with a distributed back-end. It doesn't look like the current API does things that would have unexpected runtimes (joins) so that would probably run as expected. If you want to keep things self contained, take a look at [streaming algorithms](http://en.wikipedia.org/wiki/Streaming_algorithms). EDIT: by "distributed back-end" I meant one of the established NoSQL projects.
Indeed, why? It's not deprecated, it's included in the base install....what could possibly be your problem with it?
Beyond legitimate, legacy projects that had trouble at one point getting a release that worked with PyPI and the install tools (SciPy, NTLK, those kinds of big, old projects that have all long since fixed these problems) I think the usual issue is that people see the packaging folks bashing on setuptools/PyPI/easy_install/etc and think thats what the Cool Kids want them to do. They seem to miss the part where those of us that complain about these tools also say that they are a part of a life and we need to replace them, not abandon them.
Bravo! Can't tell you how many times I've been directed (via Reddit or others) to this great new python module, only to get there and find that there's nothing there that describes what it does! Or, how to do what it does with it, or how to install it... 
What python module are you referring to? 
`urllib2`, anyone?
Great info, thanks for this and for the guide itself. Again, I think your reply here could be added to the guide!
No real news there. Who would use some undocumented, untested code from github? Nobody. Also, I disgree with the need for a twitter account. How can you answer support questions via twitter? A wiki or mailing list would be appropriate.
Good idea.
Hmm, this is a very interesting idea. I wonder if SQLite has optimizations in place for such use cases...
That's how I did it for the Python Challenge.
That's how I did it for the Python Challenge.
It sounds like the opinion is that SQLite is [fine for large data](http://stackoverflow.com/questions/1033309/sqlite-for-large-data-sets). SQLite claims it's [not appropriate for very large data sets](http://www.sqlite.org/whentouse.html), but they quote a 2 terabyte limit.
I can only agree with 1, 2 and, 7. The rest seems pretty superficial and has nothing to do with the quality of the project.
Seriously; are you suggesting a web framework to download a damn file? Sometimes your aggressiveness to promote your work (whether it is quality or not is another topic) does not know boundaries.
I'm sure this has been answered before, so feel free to point me to the search or LMGTFY... Could someone explain what Pyramid is? As someone looking to learn a Python web framework, with little to no experience in any of those available, why would I pick Pyramid over Pylons or Django? 
Related: http://lucumr.pocoo.org/2009/7/24/singletons-and-their-problems-in-python/ [disclaimer: my blog]
PPA might be outdated. I think we more hope for debian/ubuntu to pick up packaging ;-)
well if you picked pylons at this point , you would be choosing pyramid. :) other than that it depends on how much you want done for you. Django gives you big building blocks that work well together, but become a hindrance when you get into a situation where you need to do something that the apps you are using were never intended to do. Then you end up fighting or forking. http://djangocon.blip.tv/file/4112452/ Whereas pyramid provides lower level features, but is not opinionated about things like database access/orm or form generation/validation etc so YOU as the app developer have ultimate control over the choice and execution. So you would only have yourself to blame if you managed to code yourself in a corner that was hard to get out of... :) It's a matter of preference in the end and learning one certainly doesn't mean you can't learn another. read the docs http://docs.pylonsproject.org/ For me, for jobs where I would have traditionally chosen drupal (content heavy website) I pick drupal, because I want to get it done quick, and in my opinion that's DJango's strength. For things where the site may be more logic heavy or actually be a service interface, I'll go with pyramid. If there was a cms that ran on top of pyramid, I would probably use that instead of django, but there isn't at this time so I don't. Rather I avoid those projects all together because I find them boring and repetitive and not very rewarding. 
Thanks. The Drupal comparison is particularly relevant, as that's what I've been using for the last few years. &gt;well if you picked pylons at this point , you would be choosing pyramid. :) So is that to say that when I set up a Pylons project in a virtualenv using go-pylons.py I have access to the Pyramid framework, or that Pylons and Pyramid are one and the same? 
Well I guess it's more correct to say that pylons 2.0 if a thing existed would be pyramid. pylons 1.0 is still pylons 1.0. the author of pylons explains things here http://be.groovie.org/post/1558848023/notes-on-the-pylons-repoze-bfg-merger and one of the pyramid/bfg authors thoughts on the matter http://plope.com/bfg-becomes-pyramid Hope that clears things up. :) 
Yes, that helped. Thanks again!
Is this a smart, polite and elegant way to say you really love buildout and diazo?
I apologize. I misunderstood your question. I thought you asked for the server prospective. I was just trying help.
&gt; 6. You don’t have a Twitter Account fuck. you. guy. edit: in the article it's 6... if you quote it reddit turns that 6 into a 1... I want my whitehat.
That does the trick :) &gt;import urllib2 &gt;urllib2.urlopen('http://www.example.com/*.*','PATH') Thanks
Didn't know about the {2001..2010} syntax. That would save me a lot of time if I can remember it.
Looks useful, but I haven't seen anything about *importing* in the user guide... only import_set() in the API doc. eg. can it read CSV files into Datasets? How does that work? Also, what kind of data can i safely add? What happens when exporting a Dataset with some object()? (\__str__?)
Lack of WSGI support makes it completely worthless with any type of web application framework. If you look at the source, you'll see that it's actually only capable of doing one request at once, meaning that if you open a connection and do nothing it'll block the process. Try it yourself. `python -m BaseHTTPServer` `telnet localhost 8000` Then try to connect in your browser. I'd use something worthful, maybe `Twisted`, `gevent`, `eventlet` or `Tornado` (just to name a few off the top of my head) 
It appears to be documented in an offhand way in the formats section, e.g. [for CSV](http://tablib.org/api.html#tablib.Dataset.csv): &gt; A dataset object can also be imported by setting the Dataset.csv attribute.
11 - I use Windows?
In the same vein, push your stable versions to PyPI. Some packages are terribly out of sync with the git repositories. If the change isn't in the package, it might as well not exist at all, because that's what 99% of your users will be using.
So is the HTML/js served from the python server? Why don't you just have one server running which both serves the HTML and deals with backend stuff. If you wanted to, it could only serve 1 page - the HTML/JS page you mentioned - and it would mean that you don't have to have 2 separate web servers running.
yep, I shoulda used the word "singleton", that's exactly the big problem. :) Also related -- http://glyf.livejournal.com/70684.html (warning, livejournal has annoying ads now)
Fuck you. The last thing I need is more reasons to be sad about not being able to afford to switch continents for a bloody convention. At least some of the good stuff will be posted online, right? ... Right?
Hell yeah! PyCon posts most or all of their talks online at pycon.blip.tv - you can find their 2009/2010 talks there right now. Also SuperProfundo is most likely going to cover the event through twitter and end-of-the-day articles
what I don't get is what are the differences between pylons and pyramid...
Not a direct answer, but: http://docs.pylonsproject.org/faq/pylonsproject.html#why-not-just-continue-developing-the-pylons-1-0-code-base
I &lt;3 cherrypy. It performs pretty well, too. http://nichol.as/benchmark-of-python-web-servers
do you know anything about inter process communication? it seems like this is certainly doable. I can code you a little demo once I get to a computer.
The worst thing about PyPI is that I keep getting it confused with PyPy. The cheeseshop was a better name.
Haha, I did exactly the same thing! I thought, "who would ever have a problem with PyPy?" Then I started reading... What ever did happen to the "cheeseshop" designation? Not enterprise-y enough?
The price is still kinda steep for students.
thanks.
Wow. Thank you for creating my future platform. This is a great direction to take Pypy/Python in general.
what about [this](http://ipython.scipy.org/doc/manual/html/interactive/reference.html#matplotlib-support) or just ipython -pylab
Actually, yes, there is a way to do it. Make sure you are using the Tkinter backend. Here's how: from matplotlib._pylab_helpers import Gcf as __Gcf __TK = None def _gui_update_matplotlib_tk(): global __TK if __Gcf.figs == {}: __TK = None else: if __TK == None: __TK = __Gcf.get_active().window __TK.update() Every time you plot a point, call "_gui_update_matplotlib_tk()". Don't use "show" since it blocks. 
Wouldn't using interactive plotting mode (pylab.ion / pylab.ioff) suffice? Stripped of all niceties (including fixing the axes), something like the following should work without calling show() while you're simulating: import pylab, time pylab.ion() for i in xrange(10): time.sleep(1) pylab.plot ([i], [i], 'r+') pylab.draw() pylab.ioff() 
$225 for a 3 day conference and up to four days of development sprints with some of the worlds best programmers? Other than getting student tickets to the JQuery Conference (good luck, that shit sold out like 4 months in advance) or the A Better World By Design Conference (Which isn't strictly about programming) I don't know of any conferences that are cheaper or more worth the cost. Edit: Still, I see your point. However, I'd be willing to bet that if you've got a teacher you know or someone involved in the field that knows you can't scrape the money but really need/want to go, there's a good chance they'd be willing to sponsor you.
Care to explain more on why the multiprocessing module does not work ?
You raise a good point. Unfortunately, it doesn't change the fact that if you look at the wealth distribution for students, costing $225 (plus travel, which may well be a large portion) probably eliminates the majority of them.
Thanks. I really appreciate this. I am new to Python but not programming. I have been going through your answers and I am likely to reply again with more questions on your suggestions. 
I guess it depends on where you are. Coming from Frisco, I'll probably be spending $200 (early bird) + $140 (hostel) + $250 (airfare). $600 if you're living off Ramen? Yeah, that's a bit too much. If you're living on the east coast or the south? Couchsurfing + Rideshare. I think the main issue will be time investment - skipping class for a conference isn't the best thing in the world. But... not much choice, eh?
Oh, wow....maybe that should be in the documentation.... I will consider migrating to a different server, since I probably still can now. Thanks for the suggestions. EDIT: Yeah, definitely need to change. If someone big uses this, they would definitely go down easily. I'll work on shifting it to Twisted instead of adding new features, I guess :P Hopefully most of the infrastructure doesn't change.....
Yeah, the choice is pretty much, "Go or don't". This is my last term of Engineering, and I live in Canada. Even if I had gotten the earlybird registration rates, and the same hostel as you, I'm looking at $550 for airfare. That's almost $900, not counting the fact that I have to eat while I'm there, and then there's missed classes. It's not in the cards. Maybe next year. Even though I won't be a student, presumably I'll be working, and better able to afford the 50% price increase. Anyway, it's not all bad news. I've already learnt a lot from watching PyCon videos online. I loved Raymond Hettinger's video about [AI with Python](http://us.pycon.org/2009/conference/schedule/event/71/). I'm looking forward to watching this year's videos, even though I can't be there live.
I see some merit in having a separate backend and frontend, since it means that I can move more stuff to the client side. But like I said, that architecture was largely influenced by another project I've been working on. Maybe I should consider using only the web server with CGI scripts, but I sort of like this setup--it does help that I don't need to muck around with apache to play with the backend. I'm not particularly sure that the single server would help particularly. To answer your question, most of the HTML is served from the Python server, but the JS and associated libraries are straight from Apache. My goal is to separate the webpage serving from the data serving. I'm not sure if that will ever have any advantage, but I doubt it would cause much performance decrease (especially since both processes are pretty light).
I'd try to go with the aspiring `gevent`. It's probably going to be the easiest to shift to with out changing much code. Also, it's stupidly fast.
If you're serving static files only, maybe consider a lighter httpd? Maybe `nginx`? 
I had a similar challenge and eventually used [LiveGraph](http://www.live-graph.org/) with the subprocess module. LiveGraph is written in Java so I call it with something like: subprocess.Popen(["java", "-jar", live_graph_binary, "-dfs", live_graph_config_file])
import matplotlib matplotlib.interactive(True) 
I am the main developer of this site. We developed this site during a [BangPypers sprint](http://mail.python.org/pipermail/bangpypers/2011-January/005746.html). I am looking forward to your suggestions for improvement. The code is hosted in [github](http://github.com/baijum/getpython3) .
I go to school at Georgia Tech and am literally 10 minutes away from the convention area. That along with the fact that I've been TAing a Python class for several semesters makes this so much more enticing... but even then (and I know I've got it good compared to other students) the $200 is steep. Maybe I can persuade my parents for an early birthday present?? ahhhh....
Well, then I'll consider that!
I haven't even looked at it! But if someone wants to change it, they could easily do so. I'm not requiring any specific server for the frontend files--so they can do whatever the hell they want! Want to host it at http://example.com/r/e/a/l/l/y/l/o/n/g/p/a/t/h/n/a/me/stattr.html? No problem. Enjoy yourself. I guess that's one huge advantage to not putting any of the backend files in the same web server--host it where you want!
Ask your professor to hook you up with some funds to go.
all abstractions leak, this is where object orientation and python leak from the object creation code below. It can be improved (and if i remember right it is in 2.7+) but though one abstractions leak has been fixed, there are others and always will be. Abstractions leak, you should know them and be prepared for them. For security reasons alone (all technical security breaches I would dare to are abstraction leaks).
 def test(f): print "Hey everybody, I'm running when the function gets defined" print "I could register this function as an event handler." print "The function is called " + f.__name__ + ", by the way." return f # look ma, no stack frame inspection! @test def spam(): return 'Albatross'
I think this may be an elaborate joke, given the name of the blog.
This only works from the python and ipython prompt, not from within IDLE.
yay import-time side effects in a convenient, easy to use library
I know this is not the direct solution to your problem, but I would highly encourage you to get off shared hosting asap. You can get your own VPS on Linode for $20/month, where you can have complete control of the server. 
What's that wooshing sound I seem to faintly hear?
Cool post
That should be fixed in PyPI. Just allow for specifying a URL that changes when a new release appears. Debian packages allow/require this.
Why don't you just link straight to the article about scoping rather than a blog post that basically only says "I didn't understand it but then I read about it and now I do!"
This worked. I tried using ion() before but it didn't work then for some reason. Cheers.
[What's new in Python 3.2](http://docs.python.org/dev/whatsnew/3.2.html)
Thanks for posting- have you done any twitterbots? I'd like to see one of those. 
Yes, many times. It's written in Perl though. But I will write a good python one. Thanks for the suggestion.
congrats, very interesting website :) It seems there's a problem with chrome (9.0b), it doesn't show tabs. And how can I provide a feedback for a working package ? Forum ?
In fact, I am also using Chrome (9.0.597.67 beta in GNU/Linux), I can see the tabs. I wonder what's going on. To provide feedback, browse all packages and pick one (otherwise search for package names), then you will see a form where you can enter feedback. For working packages, "works for me" radio button can be selected with value as True. For example see this package: http://getpython3.net/package/datadiff
ok. not really a package (since you don't have to install it) but I wanted to add [waf](http://code.google.com/p/waf/). For Chrome, I'm using Chrome on Windows. It looks like the CSS isn't loaded, I see the 2 tabs as a list, and both content below.
I removed Tabs now :) Well, so there should be a way to give feedback about stuff which is not there in PyPI. I will put this in my priority.
&gt; White people, black people, brown people, yellow people, get rid of 'em all &gt; All we need is a voluntary, free spirited, open-ended program of procreative racial deconstruction &gt; Everybody just gotta keep fuckin' everybody til they're all the same color 
Wireshark-&gt;Follow TCP Session Works just as well, so long as there's not HTTPS. But yes, LiveHTTPHeaders is a better fit.
I don't get it, though, how would you do it on an instance method instead of a function?
Glad to see you guys got started on this!
In this case, there's no difference between the way to do it for a function instead of a method, because the method isn't actually decorated/wrapped, but just returned as-is. So you would do it just the same: class Brian(object): @test def am_i_brian(self): return False To make a real, decorating decorator that works on both functions and instance methods [is a little more complicated](http://mail.python.org/pipermail/python-list/2010-October/1258680.html). The secret is that there's no such thing as a 'method' in Python; it's all functions that get wrapped into bound or unbound methods as you access them through `Class.method` or `instance.method`. A decorator has to deal with this, because of the `self` parameter.
No, I don't believe it is.
I am adding a question here: It is more valuable to learn the ropes and find all the actual concerns of the OpenGL API than try to find something that would solve all that for you? This is coming from someone having tried to find 'the final solution'.
Yes, that makes sense of course. A decorator that tells you when a method was bound to a new instance though is what I mean, that is, when a new instance of a class containing the method was created. I don't see where you could hook in without stack inspection.
Like this: class Brian(object): @listener def am_i_brian(self): return False a, b = Brian(), Brian() get_listeners() == [a.am_i_brian, b.am_i_brian] I don't know how to do it without stack inspection when the decorator is called to get the class scope.
Using \_\_del\_\_ in your code: [don't!](http://www.mail-archive.com/python-list@python.org/msg157580.html)
Why not just manually convert tail recursion to the loop? It's pretty straightforward actually.
&gt; Support multiple entry, feed, and source authors Finally! Time to drop lxml.etree for arXiv parsing ...
I freaking love Celeryd. Makes my life so easy.
I think I would prefer to put an extra decorator on `__init__` over stack frame inspection. L = [] def listen(f): f.is_special = True return f def register(f): def register_dec(self): for name in dir(self): attr = getattr(self, name) if hasattr(attr, 'is_special') and attr.is_special: L.append(attr) return register_dec class Brian(object): @register def __init__(self): pass @listen def am_i_brian(self): print "I'M NOT BRIAN!" a, b = Brian(), Brian() assert L == [a.am_i_brian, b.am_i_brian] Not all too pretty either, I admit. Sorry for my bad reading comprehension skills, you specifically mentioned instance methods as opposed to methods in general.
I have added the functionality to add non-PyPI projects/distributions. The link to add non-PyPI thing is given in the main page, search result page and browse page. I changed the /package URL to /project to make it more generic. **Update:** Plead add the "waf" and other projects now :)
Okay, what the hell is: eval code in context ? I've never seen this. I know the "in" operator that checks for membership, but I can't parse this. How does it work?
Fantastic! &gt; celeryd: Now supports Autoscaling of child worker processes. &lt;3
(I assume you mean 'exec', not 'eval'; this doesn't work with the eval function). I have _no_ idea, and I know a reasonable amount of Python. I can't even seem to find anything about 'exec' in the manual, except for: execfile(filename[, globals[, locals]]) This function is similar to the exec statement, but parses a file instead of a string. It's probably a built-in statement, which would also explain the 'in' part. I personally always used: eval(code_str, {'__builtins__': None}) if I *absolutely* had to use eval. (or if I was just lazy). If this 'exec' thing the guy mentions is anything like eval (syntactic sugar perhaps?), passing an empty dictionary as the namespace might be a very bad idea, as the code you evaluate has access to the builtins. But that's just me guessing; I never heard of 'exec' before. (PS: The eval bit above is **NOT** secure. Don't use it).
Looking at the code, that's what this package looks like it does, decorate __init__, but by doing it at class definition time rather than looking for a flag on instantiation.
Read http://docs.python.org/reference/simple_stmts.html#the-exec-statement In this case "in" is part of the syntax of exec, not the contains operator.
I do mean exec, thanks. The one time I did use exec, I used exec(code[, globals[, locals]]), as you said. However, why is passing an empty dictionary bad? Python will recreate a namespace there, so your code won't have access to the local/global scope, but what harm is accessing the builtins? Also, I find it hard to believe that exec would have its own syntax just for creating a namespace (it's unpythonic). However, I don't see any other explanation for this... 
Imports are in place, but it's not very robust yet. If there are any weird dialects that the csv module won't detect automatically, your data won't import correctly. The plan is to expose the csv configuration in the api to allow for better customization. 
Because you can still access ``__builtins__`` (the very core of Python) from evalled code if you don't supply a dictionary with the ``__builtins__`` key removed: e = compile('print __builtins__', 'foo', 'single') eval(e) &lt;module '__builtin__' (built-in)&gt; Versus: eval(e, {}) {'bytearray': &lt;type 'bytearray'&gt;, 'open': &lt;built-in function open&gt;, [..] Versus: eval(e, {'__builtins__' : {} } ) {} That means evalled code can still reach the parent namespace. Heck, it can probably do anything it wants. **edit**: &gt; I find it hard to believe that exec would have its own syntax Python has plenty of Syntactic sugar going for it. Even things such as ``foo = {}`` is syntactic sugar for ``foo = dict()``. **edit 2**: updated for completeness sake.
``context`` is a dict-like object which will serve as the namespace for the execution of the code. &gt;&gt;&gt; exec 'print a' in {'a': 'Hello World!'} Hello World! &gt;&gt;&gt; ns = {} &gt;&gt;&gt; exec 'a = 42' in ns &gt;&gt;&gt; ns['a'] 42
Wait, I made a mistake in my previous post. When passing an empty dict, you get this as the namespace for the empty dict: e = compile('print __builtins__', 'foo', 'single') eval(e, {}) {'bytearray': &lt;type 'bytearray'&gt;, 'IndexError': &lt;type 'exceptions.IndexError'&gt;, 'all': &lt;built-in function all&gt;, 'help': Type help() for interactive help, or help(object) [....] 'open': &lt;built-in function open&gt;, 'quit': Type quit() to exit., 'basestring': &lt;type 'basestring'&gt;, 'UnicodeError': &lt;type [..etc] So passing an empty dict will not get rid of the ``__builtins__``.
Setting `__bultins__` to None will not gain you anything. You can still get to object and using `__subclasses__` you can access any type and/or function available.
Do you have some code to demonstrate that? Because: e = compile(''' class Foo(object): pass ''', 'foo', 'single') eval(e, {'__builtins__': {}}) NameError: name 'object' is not defined I'm not saying my method is secure. Far from it. I would never use it in production code. But as far as I know, it'll get you a *little* extra 'security'.
I know what context is, the "in" operator looks odd, though. Someone explained it below, thanks.
That explains it, thank you.
I'm not sure how this happened. I selected no subreddit. I apologize.
I'm not sure how this happened. I selected no subreddit. I apologize.
You still have literals, so you simply create any object to get it's type `{}.__class__`, as these are new-style classes they all inherit from object, which is the last in the method resolution order getting it now is trivial `{}.__class__.mro()[-1]`. Now as I said earlier almost anything is a subclass of object, armed with this knowledge we can do something like this `[f for f in {}.__class__.mro()[-1].__subclasses__() if getattr(f, '__name__', None) == 'file'][0]('/etc/passwd').read()`
The title made me laugh! It was basically telling your to be careful with that loaded pistol and that liter of jack. Yeah, no shit. :P
IDLE isn't something you should use.
Let me rephrase: I'm a graduate student living on a teaching stipend. I can't really afford to go. 
I just found celery. I can't wait to see what 2.2 has for me.
Impressive. Thanks for sharing the knowledge.
code from the article: def func1(param=None): def func2(): if not param: param = 'default' print param # Just return func2. return func2 The issue is that the param = 'default' on line 4 creates a new local called *param* vs assigning to the argument passed in the outer scope. This causes the 'if' statement above to reference a local that does not yet have a value. A simple fix is thus: def func1(param=None): def func2(): loc = param if not loc: loc = 'default' print loc return func2 I will add that this is probably a good thing. Otherwise it'd be too easy to trample over args and cause all kinds of hard to debug side effects.
Yeah. The article did have a number of good points, and was rather informative about *how* python eval, import, and compile processes work. But I felt it should have started off with the rule that's served me well in *every* programming language: find the nearest eval command, and pretend it will painfully electrocute me every time I even think about it. So much traceback mangling, run-time syntax errors, and having to worry about sanitizing *everything* that gets near it. Eval just isn't worth it except for the millionth case where there is *no other way*.
I hear ya there! I know this isn't python related but you may find it amusing (and by amusing I mean terrifying). Coldfusion (*shudder*) has a function [IIF](http://livedocs.adobe.com/coldfusion/8/htmldocs/help.html?content=functions_h-im_05.html) that *literally* hides an Evaluate() within what appears to be a ternary operator. So, what happens if you do something like this: IIF(true, "Hello, " &amp; URL.username, "Fart.") You end up with whatever was passed through the URL being evaluated **twice**. So, if username contained code (denoted by '#'s) it will get executed. Remote code execution on the server. &lt;/rant&gt;
The security implications of eval are well understood. There is no point in reiterating that.
To you, to me, yes. But I've seen way to much code needlessly and dangerously using eval. Enough to realize that it's dangers aren't actually as widely understood as I previously thought. Enough that it warrants disclaiming before any article that's about to hand someone details about how to efficiently use it, just to make sure anyone reading knows why they shouldn't. 
SOAP is horrible. Reading WSDL is really extra horrible. Scio is a SOAP client my employer developed that mutes the horror a little. It can talk to a lot of real-world SOAP services, but probably can't talk to some others (yet) because ... SOAP is horrible. Maybe the best part is the included [Sphinx](http://sphinx.pocoo.org) extension that lets you autogenerate pretty decent documentation from a WSDL file. Useful even if you don't want the to use the rest of the package!
Well. It does say in the introduction the following thing: &gt; Also: “Yay, another post about the security implications of eval/exec.” Wrong! I am assuming that everybody already knows how to properly use these two, so I will not talk about security here.
Well, actually, I think exec is far more of a security risk than eval (arbitrary values vs. arbitrary code? hmmm)
They are both equally dangerous, exactly the same actually.
Ah! I missed that :) It soothes my eval-nazi heart.
orly
I'm surprised how many web frameworks have broken Python by abusing these sorts of things... Or more like disturbed than surprised.
Have you looked at distutils2? I wonder if it solves any of the issues you brought up or if you think they're not taking the right approach?
namespace:
You are relying on the builtin `getattr`.
I found [suds](https://fedorahosted.org/suds/) to be a pretty nice SOAP library to work with as well.
I don't think performance is an issue as much as configuration. If you're running this in a production environment, it would make more sense to either serve the python through apache either running the python backend through fcgi, or acting as a reverse proxy, or in low traffic volume situations to roll all file serving into the python web server. Most python web servers are capable of serving static files in some form, and if the traffic received is very low (which for this project I'd imagine it would be), it would make running the system much easier. Rather than having to have apache configured and running on the machine in addition to running the python server, you'd just need to run the python server script and would be able to access the entire software package. Maybe I'm misunderstanding exactly how this operates, but I don't think from a server administration point of view using multiple web servers makes any sense.
From a quick look at the code, it seems like this irc bot only works by accident. (Also, it uses double underscore everywhere. Ick.)
At this point I think we're better off suppressing SOAP libraries than releasing them. It's finally dying, and we don't need to give it oxygen.
I was coming here to say the same thing.
Ditto mitsuhiko, eval and exec provide the same risks, with an example to demonstrate: &gt;&gt;&gt; eval("execfile([file('tmp','w').write(\ ... 'exec \\'print \\\"hello world!\\\"\\'\ ... '),'tmp'][1])") hello world! &gt;&gt;&gt; Since execfile is a function, the whole thing is an expression. There's a slight difference in environment, but I've just used eval to invoke exec -- anything exec can do, eval can do too!
"Magic numbers" can mean a lot of different things. There's a good summary of most of them, including the kind that I think you're referring to, [on Wikipedia](https://secure.wikimedia.org/wikipedia/en/wiki/Magic_number_(programming\)#Unnamed_numerical_constants).
Seems like a smart idea for saving memory and keeping quick `len` and slicing for most cases.
Seems like a smart idea for saving memory in most cases while keeping quick `len` and slicing with added accuracy for non-BMP characters.
I definitely see how the book could be using that definition. I'm not really sure why I didn't think to try Wikipedia. Thank you for the link!
Double underscore was to indicate that the methods should be used privately.
Single underscore is the convention for that. Double underscore shouldn't be used.
Oh, I thought it should be double underscore. Didn't know, thanks.
 class myClass(object): def __init__(self, w): self.v = w #self.v is a variable pointing to reference of variable w passed in on object creation of myClass b = 'bob' #variable b points to a string containing a string of 'bob' mc = myClass(b) #creates a new instance of object type myClass passing variable b by reference
Of course SOAP sucks, but it seems to make SOAP to suck less, and I like the Sphinx extension especially. Upvote!
Ah, good point--I will definitely roll all files into the python server, after shifting it to gevent over BaseHTTPServer. Thanks!
There are magic/special methods but I've never heard of magic numbers http://www.markus-gattol.name/ws/python.html#special_methods
the online version is imo very good http://diveintopython3.org
All of those are good. Once you feel comfortable with python, http://www.amazon.com/Scientific-Programming-Computational-Science-Engineering/dp/3642024742
Dive into Python is amazing. But I haven't really checked out the other two.. If you want something concise: http://www.lulu.com/product/paperback/a-byte-of-python/3640650
'Magic numbers', when used in a programming context, denotes unexplained constants inserted into calculations as 'tweaks'. They are almost always an indication that the calculation is fundamentally wrong. As an illustrative example of this, say you've looking at the implementation of a print preview-type dialog that allows you to see the data you're about to print on a virtual paper and that this preview allows arbitrary transformations on the data in conjunction to the viewport that is the paper area, so that the user can freely position the data before printing. In an implementation like that, there's going to be a number of linear transformations performed. Say then, that somewhere in there, for instance during a coordinate system conversion, there's a multiplication by some scale coefficient by a factor of 1.4. The meaning of that number - a magic constant - is not described by any comment, nor is it explained by the system being modelled. A constant like that is a very, very good indication that something else isn't right. Edit: Sometimes such coefficients *are* perfectly legitimate, because they represent some facet of what is being modelled. In this case, the problem is that any raw numeric constant doesn't explain *what*, making the logic of the code almost impossible to follow for any subsequent maintainer. This can - and should - be alleviated by assigning the constant to some sort of descriptively named entity (variable, enum or something else depending on the language used), providing adequate comments or preferably both.
I recommend taking a look at the link provided by noahmedling [elsewhere](http://www.reddit.com/r/Python/comments/fdkt4/magic_numbers_what_are_these_socalled_magic/c1f4t02). If you don't know what a magic number is, or why they're best avoided at all costs, you'd be doing yourself (and others) a huge favour by checking it out.
&gt; So passing an empty dict will not get rid of the __builtins__. Yep, because if python gets KeyError in locals and globals it will just go get the (interpreter's, I'm guessing) builtins. You can "solve" that by passing a defaultdict as locals mapping: &gt;&gt;&gt; eval(e, {}, collections.defaultdict(lambda: None)) None
SOAP is default in the enterprisey world and with this attitude the Python community just get locked out. Suds saved my butt because our encashment service provider accepts SOAP only. I grant you as much as we should concentrate on clients only and not help people set up new services running this abomination. ;)
Actually it's the only usable not abandoned years ago one. :)
Magic numbers usually are numbers placed in code when they should be a variable. Usually only 0, 1 and sometimes 2 are the only numerical constants that are ok to use in code. There tends to always be exceptions to rules like this though. An example of a magic number is the following def calculateTax(cost): return cost * 0.0825 It really should either be a parameter or identified somewhere in the code. I would probably do something like the following def calculateTax(cost, tax=0.0825): return cost * tax
You'll want [Dive Into Python](http://diveintopython.org/) rather than Dive Into Python 3 - Python 3 is a backwards-incompatible advance on Python 2, which will eventually replace it, but not for a good while.
Sadly, there isn't really a definitive book for learning Python. Both 'beginning' and 'learning' are quite good, and would probably serve your needs acceptably well. *Dive Into Python* is very good at showing off the features of Python, but in many cases the examples it gives utilise the features of python in pretty bizarre and inappropriate ways, for the sake of showing off what the language is capable of. In other words, the code in DIP is not very *pythonic*. For that reason, the book is probably better for established programmers who just want a quick primer of the language. Since you say you're new to programming, I'd recommend [How to Think Like a Computer Scientist - Learning with Python](http://openbookproject.net//thinkCSpy/). It starts off very basic, but teaches programming technique and how to effectively use Python very well.
Double underscore results in name-mangling, which is usually never what you want: &gt;&gt;&gt; class A: ... __foo = 42 ... _foo = 123 ... &gt;&gt;&gt; A._foo 123 &gt;&gt;&gt; A.__foo Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: class A has no attribute '__foo' &gt;&gt;&gt; dir(A) ['_A__foo', '__doc__', '__module__', '_foo'] 
I wonder if Pylons maintainers will start neglecting Pylons in favor of Pyramid. 
[It will be maintained, but not improved](http://docs.pylonsproject.org/faq/pylonsproject.html#what-does-the-pylons-project-mean-for-pylons-the-web-framework).
Well that kind of sucks. From what I understand repoze.bfg is quite different from pylons and Pyramid is a terrible name.
Yes suds is the only SOAP library worth a damn in Python (not sure about the one that was just released, I haven't tried it). The problem is it's only a client. SOAP in general is so terribly boring that none is willing to work on a server library. I am seriously considering moving to Jython and using Java's Spring Web service libs, every time I need to implement SOAP services. As of now, there is no Pythonic way of actually providing a SOAP service from Python, it's really a shame.
It's open source - I'm sure if you want to pick it up and run with it, you can improve it yourself. Obviously, the Pylons developers think Pyramid is a better foundation, or they wouldn't have made it the centrepiece of the Pylons project. Martin
Sure. I am being too negative perhaps. I'll keep my eye on this one.
Me too. Here's a link to [suds](https://fedorahosted.org/suds/). What I needed in the past but couldn't find is a good Pythonic SOAP server module.
I have been successful using soaplib http://pypi.python.org/pypi/soaplib in the past. Very easy to set up. See if it works for you.
Definitely, suds is a great project. [Simple soap](http://pypi.python.org/pypi/PySimpleSOAP/1.02b) is also good. It just happened that neither of them worked for the specific needs of my employer, so we wound up rolling our own.
Because of magic reason.
They explain their reasons for doing so here: http://docs.pylonsproject.org/faq/pylonsproject.html#why-not-just-continue-developing-the-pylons-1-0-code-base
Agree with HTTLACS. I'm using this as the text for my CS1 course (Just switched from Java.) I also have videos and notes available for free from my own book (More of a game dev book, but the first four chapters are an intro to Python) http://www.aharrisbooks.net/pythonGame/ 
&gt; Web development done right, your way! A little dig at [this tagline/subtitle](http://apress.com/book/view/143021936X)?
Quite possibly. Is there a "rivalry" between the two projects for some reason?
Great! Thank you for the recommendations. I hadn't heard of "How to Think Like a Computer Scientist - Learning with Python." This looks like an excellent resource!
Many thanks; I'll take a look at it.
Yes, I really enjoy the online version. Having something hand held to supplement the online version is what I'm looking for.
Great! I hadn't heard of that. I will check it out!
&gt; maybe even read it on the toilet. without a computer in front of you ? if no, you're going to miss it if yes, watch out for hemorrhoid 
No rivalry with any projects, Pyramid is not development done right but «with style» :)
You can use handlers if you want a more pylonish development style, that's what pyramid brings you, a way to do things the way it fits your brain.
rivalry amongst python web frameworks? you new here? :)
Magic numbers are number literals which are used somewhere in the code without documentation. The problem is that for the reader of the source code it is not obvious what the number does or more specifically why this number was chosen. Usually you should use either a parameter or a constant instead, in rare cases just a comment might be enough.
I guess there's always some rivalry amongst followers of different techs. One of the things I like about the Python community is that it's usually not too belligerent and snarky.
rivalry is good, the end user usually wins. 
Thanks for releasing this. I'm going to check it out when I get off the bus and home.
link to the original thread?
Yeah, healthy competition drives innovation. It's fanboish bashing of others that isn't good for anyone.
Definitely. Content will most likely be the hardest part.
Thank you, sir.
It is very pretty! Sweet progress
Barry's interview starts at around 12:20 into the podcast.
are you running markov simulations of baseball games, looking for an appropriate convergence time? If so, lets talk :)
these are all interesting answers regarding general coding practice, but in the context of Python, the "magic number" is an identifier in a .pyc file that tags it against a certain interpreter version. Docs: * http://docs.python.org/devguide/compiler.html#introducing-new-bytecode * http://docs.python.org/release/2.6.4/c-api/import.html#PyImport_GetMagicNumber etc.
Haha no, training a neural network on cancer survival data actually. But you've intrigued me, tell me more :)
It's easy to convert Pylons project to Pyramid project.
Right on. I typically do a: from pdb import set_trace as stop
In other words, assigning to an undeclared variable creates a variable with that name in the local scope, thus shadowing the outer variable with the same name, thus making the earlier access within the same scope an access to an uninitialized local variable (the name is found inside the inner function's dict but the variable hasn't been initialized at this point). This seems quite similar to what JavaScript does to its function-scoped variable declarations (all declarations are "moved" to the beginning of the function, but JS is silly in that it treats undeclared variables as global and thus pollutes the global namespace upon assignment to an undeclared variable instead of throwing an error like Python). Does this mean all names inside a scope are known prior to the execution of the code that originally contained its declarations? To the newbie Pythoneer it would seem as if variables enter the scope dict as they are declared (because that is what happens in the interpreter).
Lutz's book is very good, it would be my first pick. Slightly older but also very good would be Core python. After you're done with either one I'd check out Lutz's other book and work through some of the code to get familiar with the python way of doing things...
Learning Python by Lutz is by far the best book in my opinion.
I am overjoyed at all of the recent developments with pylons, bfg, and soon TG. Honestly, I feel like I got a present. Keep up the excellent work!
I've personally used scapy and pylibpcap. I would suggest scapy for the sake of usability and documentation, as pylibpcap is essentially undocumented. I'm actually using pylibpcap right now (for licensing issues) and have found that dpkt is extremely helpful as a packet-crafting library. Scapy ships with most packet-related utilities you may need.
Its also a great way to compare the frameworks. I've always used Django when I need a content management system working, and pylons when I needed something more detailed and customised.
Its also a great way to compare the frameworks. I've always used Django when I need a content management system working, and pylons when I needed something more detailed and customised.
Thank you, everyone, for all the responses! Hopefully, in time, I'll be able to repay it forward!
better to get rid of *all* SOAP servers, so we never need to use any SOAP client library...
I was disturbed to learn that none of the above mentioned packages work with 3.0 and most have been discontinued.
if you go by debians popcon.. #rank name inst vote old recent 17333 python-pcapy 124 8 102 9 22318 python-libpcap 63 3 54 6 26580 python-pypcap 38 1 33 4
Propose or vote on questions for the chat [here](http://www.google.com/moderator/#16/e=5615c).
yeah can you elaborate on that ? we'll have a need for a SOAP client/server in the near future and don't know what the various libs are lacking. 
This is entirely for the best. Guido's heart hasn't really been in the last couple of keynotes. Last year's ripoff of Ian's famous 2009 talk didn't work that well; this structure sounds much better.
Google for Pygame. Enter its website. Look at the *dozens* of games out there - varying level of complexity and awesomeness, all coded in Python. Most have source code available. Read some tutorials. Download some games you like and poke in their source code. Enjoy.
Perhaps Time to fork one and maintain it then.
In the movie version of Guido's life, I hope Zach Galifianakis goes topless for this scene.
I started learning programming python with Mark Lutz book. It is a big ass book so be prepared. But I think that Dive into Python is a good choice as you want to do some excersizes to learn the language. Also watch the [MIT open courseware series](http://www.youtube.com/watch?v=k6U-i4gXkLM) and do the homework assignments. Then you can say you learned to program at MIT. You can download the homework at MIT open courseware site. Good to here someone talk about iterators etc. Long series but if you watch one a night and do the homework, you will be up an programming in a month. 
I was quite negative about the merge as well - they're taking away my beloved Pylons ! And replacing it with a framework that is based on - horror of horrors - Zope ! However having played with Pyramid I can honestly say that it's growing on me, and I'm even trying out repoze.bfg features like traversal. 1. Don't worry about the Zope. There is a strong folk memory in the Python community about the ol' Z-shaped learning curve, and the difficulties of running Zope-based sites. However although Pyramid uses some libraries from the zope namespace it's not zope. 2. Traversal is a very cool idea, and it makes adding authentication and authorization a snap. No more AuthKit, thank God. When you get the idea that a context is just a dict-like that exposes URLs through items on the dict, and provides a set of what is allowed through an ACL, it makes locking down your application very easy. It plugs straight into whatever backend and data model you want. Oh, and you can use it with URL dispatch (the old "routes") if you want to. 3. Configuration. You have a Configurator object, to which you attach your views, database setup, etc. This allows you to easily reconfigure your application for different requirements - for example if you have different customers but the same basic application you can just create different configurations on the fly. The config object can return a WSGI callable that you can drop into your favourite server setup. It's like Django settings, but on steroids. You also have subscribers - equivalent to Django signals - which likewise make it easy to reconfigure your application for different needs. 4. Design. Unlike Pylons with its global threadlocals like "c" your views are passed a request object, same as Django. This makes testing a LOT easier. Views can be configured with renderers and usually just return a dict, which makes unit testing easy - instead of using a "test client" object, just call the view directly in your unit test and pass in a dummy request with any variables you need. Overall Pyramid has a clean, maintainable design. It's not all unicorns and rainbows, however. Some issues: 1. It's a new framework - well, it did exist as repoze.bfg, but it's new to most people. It's also merging in ideas from Pylons such as routes/dispatch. Therefore it's a bit confusing for newcomers as to what is the right way to do certain things - do I use URL dispatch or traversal ? How do I manage per-row authorization ? etc. Although there is a cookbook, it will take a while for common patterns to emerge. 2. Some major features people have come to expect of frameworks today are lacking, or are hard to find, evaluate and integrate. Whereas in Django you have one form library that everyone uses - for better or worse - form validation is badly fragmented into a number of narrowly-implemented, poorly documented, or unmaintained solutions. There badly needs to be an equivalent to SQLAlchemy in this space (and others) - a single, best-of-breed solution that 90% of people can get started with, but swap out later if needed. This isn't the fault of Pyramid, but it has inherited it from the Pylons community. All in all, however, it is a major improvement over Pylons and well worth the effort. 
Python on Android, FTW!
And by hard, he mean's you'll need teams of slaving pixel-artists on round the clock gangs to pump out enough material for even a few levels.
Awesome answer. I agree that a form/validation library would be awesome, but that's not a goal of pyramid, that would be like evaluating a new linux kernel based on what it offers in the way of a desktop environment. FWIW though, I think ToscaWidgets 2 is pretty close. Someone would need to to do some work to build some integration between that and SQLAlchemy to get to the level of what some people like about Django. But again, not pyramids goal. 
Sure, but more people use Linux arguably because of better distros and desktop environments. A user will choose, say, Ubuntu or Gnome not because the underlying kernel is good, but because it lets me use Firefox or Open Office or Compiz or whatever it is that I need. While a good form validation library is certainly not the goal of core Pyramid, any more than a good tile manager is the concern of a Linux kernel hacker, having one under the Pyramid umbrella would encourage more people to use Pyramid.
It is stagnating. Unfortunately, the developer does not seem to have time to maintain it. It made me very happy during the brief period I could use it, then I hit a blocking issue and now I am back to hand coding soap calls.
I hope he doesn't mind being called "Eddie Baby".
I believe the goal will be to have the good high level stuff like that under the pylons project umbrella. pyramid = solid kernel, and hopefully a 1000 distros/web frameworks will bloom from it to meet everyone's needs. :)
The only bug I've encountered was fixed by...me. :)
That's irrelevant (sorry to necropost). The matter here is that (disclaimer: I haven't used web2py and I first heard about this namespace injection here) Django and the other frameworks that work in this way are Python, and so you can treat them as such. This means that you can rely on importing working as usual and that there's very little magic in importing your own packages or importing Django's packages from elsewhere. With the way web2py does it, you can't reliably name things or import things without being afraid that you'll either overshadow some builtin you didn't explicitly import or that something else won't break. The reality might be different and web2py might be completely comfortable for someone who has developed in it, but it makes me very worried and wary of writing anything in a magic environment where all the assumptions I have about the language have broken down.
I had hoped to do the pixel art myself. :3
Thank you, sir.
I understand your concern, but as you point out in your second sentence, you don't really know web2py. Please read [this response](http://www.reddit.com/r/Python/comments/ex54j/seeking_clarification_on_pylonsturbogearspyramid/c1bp5th) to Jacob. You have never used web2py. Many other people have used it successfully over the past few years, and the potential problem you imagine really isn't an issue.
I did read that response, I'm not so much worried about the added globals as I'm worried about the *way* they are injected in the scope. When writing code I assume my module is initialised in a certain way, and these assumptions might not hold when doing things like these.
Maybe you should move it to some settings file, and have this instead: from settings import DEFAULT_TAX def calculateTax(cost, tax=DEFAULT_TAX): Whenever you want to change the tax you just change the settings file, instead of searching for "0.0825" through all your py files. 
What you want is a bash script that loops through the filenames and calls wget.
Perhaps you could elaborate. How does the *way* the globals are added affect your importing your own modules? You can still import your own modules just as you would in any Python program. Sure, you have to be aware of the few web2py globals, but that was my point -- there's not a lot to be aware of. And even if the web2py objects were explicitly imported, you would still have to be aware of them and make sure your own imports don't have any name clashes. If you want, you can even paste some dummy web2py import statements at the top of your files (maybe inside a comment or an 'if 0:'), just to remind yourself of the globals -- certainly that's no harder than using real import statements.
I agree that it's a good book. It was my first Python book, too. But as others have already said, it has a lot of text and chapters. That doesn't seem to be a bad thing, especially for a beginner book. If you don't mind reading a lot of text and getting things presented step by step, go for it. If you're more the "formula" guy that likes the big picture in shorter presentations and get lost/bored by reading to much text, I think Dive Into Python might be better.
To emphasize your post in addition to upvoting: The MIT course is a really great resource.
**Introduction to Python Programming 3.0** http://www.qtrac.eu/py3book.html The book gives a good introduction to Python (Python Hearts) and provides chapters on actual language application (Threading/Multiprocessing, GUI, Networking, Parsing, and Databases.
It's not about the actual names that get imported, I can live with a few more things in my namespace. What makes me uneasy is the magic way they get imported in. As someone who (ideally) doesn't know the internals of their framework, with Django I can see everything the framework is doing. The imports are right there on the header and I know how they got in my namespace. Not so with web2py, and the way they're using to import things might change behaviour in unpredictable ways (see [Armin's post](http://lucumr.pocoo.org/2011/2/1/exec-in-python/) for examples). That's what makes me uneasy when magic comes into play.
True, that's a good differentiation. I do think Lutz goes into a TON of details that are necessary to learn in order to write Pythonic code (vs. java, etc. type that you see often at the beginning) and explains some of the quirks very well. I guess my point is that everybody should read it at some point...
I've found "Python Essential Reference" to be worth reading, though it's not really an introduction. For the most part, Python is so easy to learn that you don't really need a book. Try writing a few dozen Project Euler questions in Python (they're short, and have a check that you did it right). After that, numpy and scipy have OK docs. As far as online references, I've found Doug Hellmann's Python Module of the Week to be very useful, with worked examples of commonly used modules.
what device ?
I'm very surprised about how easy it is to use. A five minute look at [this page](http://epydoc.sourceforge.net/manual-usage.html) was all I needed. Applying the following command, my whole package was documented. python .\Scripts\epydoc.py --html C:\Users\Ph4g3\workspace\Project\ -o C:\Users\Ph4g3\workspace\Project\Doc\epydoc\ --name Project --url "http://myprojectwebsite/" --graph classtree --inheritance grouped Take that, lecturers wanting complete documentation!
i prefer the semi-automatic way of documenting with sphinx and autodoc http://sphinx.pocoo.org/ext/autodoc.html
Very insightful reply. You just gave me hope. Pylons is my framework of choice which I use in many projects and I care very much about what happens with it, this is perhaps why I was a little worried. Thank you!
Since we don't have profilers in standard library...
I would like to know if this is a common practise of Pythonistas using Sphinx? Personally I don't use autodoc but have no particularly strong reasons to refuse it. It is probably something aesthetic. Longer code comments feel like clutter or source bloat to me, whereas Sphinx documentation can be quite comprehensible, equipped with examples, explanations, references etc. Documentation of a single function may become a mini-tutorial I want to read myself.
My main problem with epydoc was it's rigidity. It makes good reference documentation... assuming literal description of your package's layout is the best way to reference things. I've found most packages are more complicated than that. They need an introduction if you're new to them, and even if you aren't, the structuring of the information (from a human perspective) frequently does not correlate directly with the package's structure (constraints by use-cases and import cycles). This is rather foreign to how epydoc (and javadoc, which it was inspired by) does things, and I've found that style able to generate lots of text, but little worthy content, which is then hard to get to. Those limitations are why sphinx &amp; it's autodoc module (see fdemmer's comment) came about, I believe. It allows you to loosely follow you package's structure, but deviate where you need to, and ignore details that don't need documenting.
So where's some code to read?
Uh. This was meant to be a sort of ... trial balloon to see if there was any interest at all in the code and the concept. Getting this comment 1.5 minutes after posting I guess must indicate at least some sort of interest in the code. But note what it says at the bottom: the code is a mess. It's the concept that's interesting. If any part of this is interesting, that is. But, sure, I could stick it on Google Code or something.
1. Title should mention the (person, feed)-specific recommendations, since that's the most interesting feature. 2. You should consider launching this as a service. Maybe there's a reader out there that already does this, but I don't know about it. 3. Screenshot not working: http://www.garshol.priv.no/blog/images/whazzup-screenshot.png 4. Given "news stories including the word Manchester are mostly about Manchester United, and so the score for that particular word is very low," you should consider using n-grams instead of unigrams (that is, lists of n consecutive words instead of individual words). You'll have combinatoric growth in the size of the weight database, but you won't have this problem as much.
&gt;It's not about the actual names that get imported, I can live with a few more things in my namespace. OK, but to be fair, Jacob (and the earlier part of the thread) *was* referring to the namespace, and *that* is what @lorinrivers and I were responding to. &gt;Not so with web2py, and the way they're using to import things might change behaviour in unpredictable ways. But you can use regular imports in your web2py applications, and they work as usual. &gt;That's what makes me uneasy when magic comes into play. I wouldn't say it's "magic" -- it's just a different way of doing things. The framework is a Python program -- it takes your application code and executes it in a prepared environment (populated with a few framework globals). Granted, this is different from the way most Python web frameworks work, so perhaps the web2py documentation could make this distinction more prominent (though it is discussed in a few places). In any case, I think @lorinrivers' reply *is* relevant here. His point is that he has been able to switch between web2py and other Python environments without any problem (as have many other users). It seems that most people worrying about these issues have never actually used web2py, whereas those who do use it don't seem to have any problems (and, in fact, generally seem to love it). That's not to say that web2py will suit everyone's preferences -- it's simply offering an alternative that at least some people find appealing. There should be room in the Python community for different approaches, which will enable Python to meet a diverse set of needs and preferences as well as drive innovation.
A profiler is great for some use cases, but will not help or be even available in others. Think about a production web server where you do not have access to tinker with it, you can only look at logs. Also think about some things that are fast 999 times out of a 1,000, where that one time happens semi-randomly and depends on several conditions being met at the same time on a complex setting you may not be able to reproduce 100%. For example, something that only happen in a multithreaded application when more than X threads are active, Y number of threads serving files of greater than Z at the same time where client speeds are greater than W while a certain large object serialization unexpectedly hogged the GIL for too long and the system load is above V.
"Wow, h4x0r". No code, no talk.
1. Maybe. I like this title. :-) 2. The code as is doesn't scale, and I don't have time/inclination to fix that. It could be fixed, but it would be a lot of work, and ... well, I don't care enough to do it. 3. Thank you! Fixed now. 4. I thought storing scores for every word ever voted on would be prohibitively expensive, but it turns out it's not so bad. After 3 years, words.dbm is only about 3 MB. So n-grams for a low n might be feasible. I'll consider this. It might conceivably help dramatically. Another improvement I've considered is to use the automated classifier this is based on, since that can actually propose compound terms on its own. However, that wouldn't work so well, since most texts are too short. So n-grams probably would be better.
I'm hitting "mark all as read" way too often lately, so I'm interested in at least seeing the code that ranks the posts.
Hi, John here, developer of turboweb. I wanted to apologise for the controversy regarding the TurboWeb icon. The tornadoweb.org site is indeed creative commons as polly_morf mentions and tornadoweb.org _was_ actually credited in the appplication as required by the license so "steals" is probably not the right word. I can see now however the general consensus is that it was pretty bad form. I have relaunched the app with a PD icon. It's nowhere near as suitable but I will try to contact tornadoweb.org to see if they are prepared to condone the use of their project icon in the future.
I use autodoc for API documentation, but combine those with written docs.
Well, you could launch it with no real scaling (though I guess you'd have to add support for multiple users, at least, if you don't already have it), and if it takes off enough that scaling is an issue then you can hire someone to scale it. :p If not, do you mind if I steal your idea one day? (Not your code, of course.)
Should be noted that Sphinx 1.1 (in development) [has a sphinx-apidoc command](http://sphinx.pocoo.org/latest/changes.html#release-1-1-in-development): &gt; “Added a sphinx-apidoc script that autogenerates a hierarchy of source files containing autodoc directives to document modules and packages.”
I could, but I think it would hit the ceiling very quickly. Using ~200 MB of memory with one user is not good. I don't mind if you steal both the code and idea. (Once I release the code, that is.)
Here are some other similar tools: http://wiki.python.org/moin/DocumentationTools (says EpyDoc no longer under development).
That code is not very interesting on its own, because it depends on too much else that produces the basis for the computation, but here it is, anyway. Note, it really is messy. def get_word_probability(self): self._list = [] probs = [] for (word, count) in self.get_vector().get_pairs(): for ix in range(count): ratio = feeddb.get_word_ratio(word) self._list.append("%s : %s" % (escape(word), ratio)) probs.append(ratio) try: if not probs: return 0.5 # not sure how this could happen, though else: return compute_bayes(probs) except ZeroDivisionError, e: print "ZDE:", self.get_title().encode("utf-8"), probs def get_site_probability(self): return self.get_site().get_ratio() def get_author_vector(self): return vectors.text_to_vector(html2text(self.get_author() or "")) def get_author_probability(self): author = self.get_author() if author: author = string.strip(string.lower(author)) return feeddb.get_author_ratio(author) else: return 0.5 def get_overall_probability(self): word_prob = self.get_word_probability() site_prob = self.get_site_probability() author_prob = self.get_author_probability() #prob = word_prob * word_prob * compute_bayes([site_prob, author_prob]) prob = compute_bayes([word_prob, site_prob, author_prob]) return prob 
Cool...I have a three-char .net domain that I've been trying to work out what to do with. Also, I was assuming that you'd write the user prefs to disk...if you're keeping it all in memory then I agree that'd die pretty fast.
Actually, I do write the user prefs to disk. What's kept in memory is all the posts from the various feeds. I think it should be possible to reduce the memory footprint quite dramatically, but it would require work, and as long as it works for me I'm happy.
Don't worry, all code is really really messy and yours isn't that bad. If you try and write perfectly clean code all the time, you'll never get anything actually working.
Formatted a little incorrectly. But I always do, it's more readable. Not sure what PEP8 says though
Cool. Thanks. 
Why do we still stick to a 80 character line width?
better than doxygen?
My production code is a lot cleaner than this. It's not that this is horrible or anything, but it's anything but clean. It shows all over that it's been typed up in a hurry just to test the idea, then never cleaned up. That "if not probs: ... else: compute_" is pure brain-fail, for example. That should be inside the function. And so on.
Even there you can use standard python profilers which are by far more reliable than using wall time of execution. See how Django [uses it](http://code.djangoproject.com/wiki/ProfilingDjango) for [example](http://www.rkblog.rk.edu.pl/w/p/django-profiling-hotshot-and-kcachegrind/).
Sticking it on Google Code would be great. I'd be very interested in hacking around on it.
I'll do that. It'll take a couple of days, but I'll do it. Will send you a message when it's up.
If the string is really long the convention I typically use is: cursor_patnhom.execute(''.join(['SELECT STATION, HOFFAM, CVGLINK, ', 'ADMDT, DISCHDT FROM PATNHOM'])) Though if it's not really long, I prefer to use a temporary variable for the string: tmp = 'SELECT STATION, HOFFAM, CVGLINK, ADMDT, DISCHDT FROM PATNHOM' cursor_patnhom.execute(tmp) Edit: I just realized that long strings can be broken up across lines if they are in parenthesis and _not_ comma separated. I think I may now use this convention, thus I would do: cursor_patnhom.execute('SELECT STATION, HOFFAM, CVGLINK, ' 'ADMDT, DISCHDT FROM PATNHOM')
A Bayesian RSS reader sounds awesome. Would be really interested in trying it out.
I agree launching as a service would be great. I've been screwing around with PubSubHubbub for the last few days (pushing rather than polling for RSS/atom) and I would be interested working on something like this. If some sort of work queue is used, and posts aren't added until they are sorted (just store a list of posts for each user, and sort new posts into it), I think this could be made quite a bit more efficient.
&gt; I would like to know if this is a common practise of Pythonistas using Sphinx? Pretty much all serious projects (serious about documentation anyway) do. &gt; Personally I don't use autodoc but have no particularly strong reasons to refuse it. It is probably something aesthetic. Longer code comments feel like clutter or source bloat to me True, but autodoc offers quite a bit of flexibility, and you can switch to a more manual style as needed. It's a powerful tool, but still nothing more than a tool.
Good question because in Python an indent is essentially the same as adding an extra { in C. Aren't we just flirting with disaster with other interpreters?
&gt; Take that, lecturers wanting complete documentation! s/complete/shitty/ I loathe autogenerated documentation, and one of the things I love about the Python community is Sphinx and the number of projects using Sphinx to write their documentation. Conversely, the dreadful state of documentation is something I loathe in the Ruby and Java communities.
Having an 80 character line width is consistently viewable on many devices and editors. For instance when I view code on my Android device it has no problem with 80 characters. Personally I use a vertical split in emacs so I have two 80 character width windows. Even if I weren't to restrict my lines to 80 characters, approximately 99% of my code would still fit that width. Therefore I can maximize screen real estate through a fixed maximum width and multiple adjacent windows. Also I would say if you have a ton of code with lines &gt; 80 characters you are doing something wrong.
&gt; Good question because in Python an indent is essentially the same as adding an extra { in C. No. Really, it's not. Unless prefixed by ":", not within a long string and not within matching structures (parens, braces, brackets) and not when using newline escaping/line continuation. And unintended indentation in the other cases will generally lead to a parsing error. You might be thinking about Haskell's offside rule. Python does not work the same way (also, Haskell's offside rule works extremely well so even there it's not really a risk) &gt; Aren't we just flirting with disaster with other interpreters? Only if other interpreters are not even able to implement the provided Python BNF.
&gt; I just realized that long strings can be broken up across lines if they are in parenthesis and not comma separated. You can also use line continuation (/newline escaping) outside parens, though that's a bit more risky. tmp = 'SELECT STATION, HOFFAM, CVGLINK, '\ 'ADMDT, DISCHDT FROM PATNHOM' 
Because that lets me put 2 or even 3 files side-by-side.
PEP8 example: class Rectangle(Blob): def __init__(self, width, height, color='black', emphasis=None, highlight=0): if (width == 0 and height == 0 and color == 'red' and emphasis == 'strong' or highlight &gt; 100): raise ValueError("sorry, you lose") if width == 0 and height == 0 and (color == 'red' or emphasis is None): raise ValueError("I don't think so -- values are %s, %s" % (width, height)) Blob.__init__(self, width, height, color, emphasis, highlight) Indent at the paren if you're in a parenthesized expression, unless you went to the newline right after the paren: rect.rotate( RotationFactoryManager.rotation_factory().rotate_left_90_degrees(), pointless_second_line ) after a line continuation, use standard indent.
Perhaps this will help?: http://www.reddit.com/r/Python/comments/fet7g/tips_on_how_to_afford_pycon/
Profiler is too heavy-weight and slows the application down too much to use in production.
Very cool idea. You might enhance your ranking algorithm by having your code actually download each page and consider the words inside of it as well. Then you could up/downvote after having read it, and your algorithm would work with a richer data source.
In most languages, in most situations, a line written with 40-50 characters can be understood at a glance. If a line is longer than 80 characters, usually you really have to focus on reading the whole line in order to comprehend it. Code that keeps its lines under 80 characters is much easier to scan (with human eyes) and understand. This is *not* based on a scientific study or anything; just imho.
It looks like you're coming from Perl when you wrote this. There's so many things wrong with the implementation of this, to the way you parse the commands. It's just simply unpythonic. For a few general pointers. `socket.recv` does not receive one line at once. You might want to break out of your infinite loop when it fails as well, as it's probably lost it's connection. You don't need to parse anything if you've replied to a `PING`. Don't import anything in functions, especially functions that are being called often. It incurs overhead. Python has an `in` statement, use it instead of `string.find` if you need to check for the presence of a substring within a string. It's extremely stupid to open and iterate over a file each and every time you call `_checkResponse`. It's also bad to overwrite python `__builtins__`, you overwrote `file`. It's bad practice to concatenate strings in Python. Consider using the built in string formatter. You can unpack lists and tuples, consider doing `matchStr, mType, msgStr = line.split(' ~ ', 3)`. There's no point to initializing `response` as an empty string either. There's also no point to modify `msgStr` before you're sure you're going to use it. It's just a waste of cycles. 
Personally I'd do a variant of the temporary variable. Especially for SQL, which can get really long, and parts are sometimes reused, but may need to be uniformly changed later. table = "PATHOM" cols = ["STATION", "HOFFAM", "CVGLINK", "ADMDT", "DISCHDT"] sql = "SELECT " + ", ".join(cols) + " FROM " + table cursor_patnhom.execute(sql) I might even go so far as making a function for it def makeSelectSQL(table, cols): return "SELECT " + ", ".join(cols) + " FROM " + table But that's me. I like breaking things into unnecessarily small functions and stuff.
Yes, I know that can be done, however I really dislike using '\' for line continuation.
Ugh. I really don't like its output. It tries to copy Javadoc, except Python isn't Java. I find the usual sphinx-based documentation (i.e. anything that looks like the official python docs) much easier on the eyes and the mind. As warbiscuit already said, most packages are more complex than what you can easily learn from looking at the classes (besides, many packages primarily provide functions and classes usually aren't what they are in Java). Who needs an entirely machine-generated Javadoc style documentation when you can readily inspect the classes and functions and packages and modules and globals (and ...) in the interactive Python shell? The stuff I can't learn from `help()` and `dir()` isn't the stuff epydoc would tell me. Provide good doc strings and wrap it up with good documentation (not just an API reference -- the API reference is part of the documentation, it's not the whole of it). I don't just want to know what I get, I also want to know how I'm supposed to use it and which parts matter in what context.
read these for more info: http://effbot.org/zone/python-objects.htm http://effbot.org/zone/call-by-object.htm
This should not have been posted. rantingrick is just that. Don't feed the trolls.
[This blog post](http://musingsaboutlibrarianship.blogspot.com/2009/11/bayesian-filtering-of-rss-feeds-can-you.html) has more details on bayesian filtering of RSS feeds.
Don't get discouraged but look at the [wikipedia page](http://en.wikipedia.org/wiki/Terranigma). It took no less than 3 artists as part of a larger team! You're an amateur (I assume), who's looking to create what he (as well as I) grew up on--beautiful, fun video games. You may need to readjust your sights a bit.
&gt; Does this mean all names inside a scope are known prior to the execution of the code that originally contained its declarations? To the newbie Pythoneer it would seem as if variables enter the scope dict as they are declared (because that is what happens in the interpreter). Yes. The thing that's missing here is that python is compiled to bytecode before it's executed. Code again, with names modified for clarity: def f0(param=None): def f(): loc = param if not loc: loc = 'default' print loc return f d0 = f0() def f1(param=None): def f(): if not param: param = 'default' print param return f d1 = f1() ----- f0 and f1 are the wrapper functions and d0,d1 are the returned functions derived from each. d0 is the one that works, d1 causes an unbound local error. Looking into the bytecode of each, we can see a bit more clearly exactly what is happening. Here is the bytecode for f0: &gt;&gt;&gt; dis.dis(f0) 2 0 LOAD_CLOSURE 0 (param) 3 BUILD_TUPLE 1 6 LOAD_CONST 1 (&lt;code object f at 0x33a5c0, file "legb.py", line 2&gt;) 9 MAKE_CLOSURE 0 12 STORE_FAST 1 (f) 8 15 LOAD_FAST 1 (f) 18 RETURN_VALUE Of particular note are the lines labeled 0 and 9, LOAD_CLOSURE and MAKE_CLOSURE, respectively. When the inner function is created, this pair is what allows it to reference the 'param' var from its closing scope. ----- Bytecode for d0: &gt;&gt;&gt; dis.dis(d0) 3 0 LOAD_DEREF 0 (param) 3 STORE_FAST 0 (loc) 4 6 LOAD_FAST 0 (loc) 9 JUMP_IF_TRUE 10 (to 22) 12 POP_TOP 5 13 LOAD_CONST 1 ('default') 16 STORE_FAST 0 (loc) 19 JUMP_FORWARD 1 (to 23) &gt;&gt; 22 POP_TOP 6 &gt;&gt; 23 LOAD_FAST 0 (loc) 26 PRINT_ITEM 27 PRINT_NEWLINE 28 LOAD_CONST 0 (None) 31 RETURN_VALUE You can see in the bytecode for d0 how it gets the value of param from the closure via LOAD_DEREF. ----- Bytecode for f1: &gt;&gt;&gt; dis.dis(f1) 13 0 LOAD_CONST 1 (&lt;code object f at 0x35e9b0, file "legb.py", line 13&gt;) 3 MAKE_FUNCTION 0 6 STORE_FAST 1 (f) 18 9 LOAD_FAST 1 (f) 12 RETURN_VALUE Here there is no closure created ----- Bytecode for d1: &gt;&gt;&gt; dis.dis(d1) 14 0 LOAD_FAST 0 (param) 3 JUMP_IF_TRUE 10 (to 16) 6 POP_TOP 15 7 LOAD_CONST 1 ('default') 10 STORE_FAST 0 (param) 13 JUMP_FORWARD 1 (to 17) &gt;&gt; 16 POP_TOP 16 &gt;&gt; 17 LOAD_FAST 0 (param) 20 PRINT_ITEM 21 PRINT_NEWLINE 22 LOAD_CONST 0 (None) 25 RETURN_VALUE Because it hasn't been compiled with a closure, d1 tries to LOAD_FAST the 'param' value - this is where the error occurs. The local hasn't been created yet via the STORE_FAST later on. 
Thank you for the reply. Where did you get information on the development team? 
Readability. 100 character lines look like shit, guaranteed.
cool, thank you
[Plenty of examples here](http://learnpythonthehardway.org/index)
aaaw... its the hard way lol... okay I will go there and start trying stuff... Thank you
My hope would be to create a graphical analog to an RPI MUD.
I would use triple quoted strings + indenting: cursor_patnhom.execute(''' SELECT station, hoffam, cvglink, admdt, dischdt FROM patnhom ''')
i second that. the book is totally worth it if you are a python newbie.
Two things to add to that. One, PyCon has a pretty big pool for financial aid and absolutely encourages people that can't afford the trip to apply. We can't make any promises, but everyone on the committee will do everything in their power to get you to the con. Two, volunteering is awesome and everyone should join the PyCon organizers group, but we don't get any special treatment and have to pay our way just like everyone else.
 name = raw_input('What is your name? ') print 'Hi ' + name if ' ' in name: print 'It looks like you entered your full name.' else: print 'Just your first name, ok.' # no comments needed
&gt; Pretty much all serious projects (serious about documentation anyway) do. That's a pretty bold statement in particular when it comes without numbers ( poll, rst-file search for appropriate hints ) and without arguments. 
Why not Atom instead of RSS ?
Awesome thanks!
Nice observation, and yes, I do came from Perl. Thanks for the pointers, and I will keep that in mind. :)
I'm not self promoting but i have wrote a tutorial in python http://www.tutorialcadet.com/a-crash-course-in-python/ which may be of interest actually.
I will be sure to check it out.
I'm also e` on rizon.
[Google Python classes is where I first learned.](http://code.google.com/edu/languages/google-python-class/)
+1 please. I'd love to play with this.
Yeah i saw those and thats where i was learning from... but it just wasnt clicking...
If you don't use an orm, i suggest you extart your request outside, and use a """. (That's what i do) SQL_GET_PATNHOM = """ SELECT STATION, HOFFAM, CVGLINK, ADMDT, DISCHDT FROM PATNHOM """ ... ... cursor_patnhom.execute(SQL_GET PATNHOM) 
An example on splits name = raw_input("What is your full name?") if ' ' in name and len(name.split(' ')) == 2: first, last = name.split(' ') print("First: %s" % (first)) print("Last: %s" % (last))
so if i had Floobagobon, and i split it around the g, it would return flooba and obon?
yes
any way to split it at a certain number from the left or right?
I allways wondered why str.split(" ") and str.split() are the same thing, going against at least 2 points of the python zen Explicit is better than implicit. There should be one-- and preferably only one --obvious way to do it.
You can splice the string...like this name = "monstradogirrrrrrr2" first, second = [name[:9],name[9:]] :9 = from first character to ninth character 9: = from ninth character to the last character
This is one of my biggest problems with Flask, actually. Been trying to write a proper test harness for a project for a while and I just can't hack it quite right...
yeah, try this: &gt;&gt;&gt; "a b c d".split() ['a', 'b', 'c', 'd'] this give us a list &gt;&gt;&gt; "a b c d".split()[0] 'a' I can reach the first element with the zero index &gt;&gt;&gt; "a b c d".split()[-1] 'd' I can reach the last one with -1 &gt;&gt;&gt; "a b c d".split()[0:2] ['a', 'b'] I can slice the list with start_index:end_index &gt;&gt;&gt; "a b c d".split()[2:-1] ['c'] this says "from this index to the end of the list". now that I see is not *THAT* illustrative, but I think you can get the idea &gt;&gt;&gt; "a b c d".split()[::-1] ['d', 'c', 'b', 'a'] list[::] is a way to get a copy of the current list, the -1 tells it to get it backwards in all the examples I'm using split() to get it as a list, you can obviate this and get it as a string &gt;&gt;&gt; "hello redditor"[::-1] 'rotidder olleh' 
Actually str.split(" ") and str.split() are not the same. text.split() alone removes all common whitespaces...example # Split by " " text = "this is some test text\t and now there is a tab" text.split(" ") ['this', 'is', 'some', 'test', 'text\t', 'and', 'now', 'there', 'is', 'a', 'tab'] # Just Split text = "this is some test text\t and now there is a tab" text.split() ['this', 'is', 'some', 'test', 'text', 'and', 'now', 'there', 'is', 'a', 'tab'] 
nice, I didn't realize that.
Thats pretty cool and reasy to remember.
I made it a one liner...the way I wrote it returns two values in an array. You can write it into two lines if it helps name = "monstradogirrrrrrr2" first = name[:9] second = name[9:]
I think you're supposed to use the factory pattern to avoid that. Of course you can't unit test views generally, but that's no different from, say, Pylons or Django.
I've thought about following the link and downloading the story to get a more complete data set to work with, but the trouble is that most real web pages contain a lot of garbage text in addition to the story. I have some ideas for how to automatically extract just the real text (and not all the menu bars, navigational links, "related stories" and so on), but haven't done more than a trivial experiment so far.
I should have made that clearer. The tool supports both. However, at the moment it needs to know, before reading the feed, which format it is. That's perhaps the biggest weakness of the tool right now. It's not too hard to make it autodetect the format, but I haven't done it yet.
Yes, I've thought of the queue approach, and I agree it would make this scale a lot better. Once you vote on a post you need to requeue all posts, but that's not necessarily a show-stopper. Queueing would make this far more suitable for a many-user service, and would also get rid of UI lag in a single-user scenario. (I'll release the code, btw. It'll take a couple of days, but I'll get it out.)
That was interesting. The guy who wrote it wonders what vectors are, and in this context it's basically a {word : count, word : count, word : count} dictionary. The values don't necessarily need to be counts; it could be weighted in various ways, but that's the basic idea. One could use LSA on these vectors instead of the Bayesian approach, but that seemed harder to do and to scale, so I went for Bayes in the short term, and it worked so well I never bothered to change it.
Think of it as a performance monitor for production systems. You wouldn't run profilers in production code, so it makes sense to watch out for slow function calls that weren't anticipated. These could result from changes to parts outside the system -- say, changes to the database (e.g. heavy access from another service you weren't aware of) or network latency. If these issues arise frequently, at least they are logged and easily recognizable.
&gt; As a result, more than one instance of a module can be created from the same source file. We have this already and it confuses anyone who starts using Python ( and occasionally it bites also experienced users who know the problem): a module object is created relative to its import path. This seems to be basically an artefact of the way modules are cached in `sys.modules`. &gt; When you want a new module with updated code, you just load it and have a new module object. All the old objects still exist as long as you want them to; there's no orphaned-instance problem. So there might be different versions of a module in the runtime dependent on the execution state of the code? 
Okay, I made [a placeholder Google Code project](http://code.google.com/p/whazzup/). There's no code there yet, because I'm busy at work, but there will be. Edit: Now there is code, but zero docs.
Made a [Google Code project](http://code.google.com/p/whazzup/), but no code yet. In a couple of days.
It probably is a celebrate for [Lunar New Year][1], the biggest holiday of [Sinosphere][2]. [1]: http://en.wikipedia.org/wiki/Lunar_New_Year [2]: http://en.wikipedia.org/wiki/Sinosphere
&gt; I find the usual sphinx-based documentation (i.e. anything that looks like the official python docs) much easier on the eyes and the mind. `epydoc` precedes Sphinx for about a decade. &gt; I don't just want to know what I get, I also want to know how I'm supposed to use it and which parts matter in what context. Sure, but all the reST markdown and Sphinx directives in the docstring isn't supposed to be read by the user of the function either. 
I never said Sphinx was older. I just said I don't like Javadoc style API docs for Python. With Java you know a lot about a function if you know its signature and argument names; for classes it's useful to know what classes it inherits and what interfaces it implements. With Python, not so much. With Python libraries, you can easily find out about the package structure by using the interactive shell and you can easily check the API docs of whatever you are looking at by using `help()` (even when there's markdown or reST in it, it's still readable -- can't say the same about Javadoc with HTML in it). When I look at the docs, I want to know _how_ I'm supposed to use the library and which parts I should be using for what. Sphinx-like docs allow focussing on tasks rather than package structures and they can integrate API docs where necessary (e.g. ORM frameworks). tl;dr: I find epydoc style docs redundant because they provide me the information my Python shell already gives me in the same structure, except it puts it in an HTML frameset in my browser.
Couldn't they just run pypy on top of pypy until it somehow evolves?
\* on a carefully crafted example
I'm learning game design in Ruby and didn't know where to start. Someone suggested that I find games on Github and look at their commit history (start from beginning). Can't believe I never thought of that before. Been learning an incredible amount, especially when the coder made a lot of smaller, well-documented commits. 
and becomes self aware?
Good. Now if you only make Numpy to work with PyPy ... 
This "withOverrides" looks like monkeypatching 2.0 to me...
\* which has its advantages evaporate as soon as you turn on whole program optimization in your C compiler Don't get me wrong; I love Python, I really, really love Python, and Pypy is a great idea, but I am *really tired* of hearing how latest JIT-compiled language X is faster than C in benchmark Y or contrived scenario Z.
It says that whole program optimization doesn't work for shared libraries.
 def fib(n, s=[0,1]): # s is an optional parameter with a default list ''' return the nth element of the Fibonacci sequence ''' # a doc string fib.s = s # set the list as an attribute of fib if n &lt; len(s): # len(s) is the number of elements in s -- its length return s[n] # return previously calculated value else: # recursively call fib for n-1 down to len(s). # append s[len(s)-1] + s[len(s)-2] on the way back up # until the list is filled up to index n s.append(fib(n-1) + fib(n-2)) # store for future access return s[n] # return s[n] = s[n-1] + s[n-2] help(fib) # the help system shows the doc string # Help on function fib in module __main__: # fib(n, s=[0, 1]) # return the nth element of the Fibonacci sequence print fib(0), fib(1), fib(2), fib(3) # print some Fibonacci numbers # 0 1 1 2 print [fib(n) for n in xrange(4,10)] # a 'list comprehension', range of n is 4 through 9 # [3, 5, 8, 13, 21, 34] print fib.s # the fib.s attribute references the stored list # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]
No, the benchmark above is measured **with optimizations turned on** It's the whole point of the article - C can't inline code across file boundaries, that makes pypy faster for this scenario
py-net? 
Whole program optimisation *does* inline code across file boundaries and then apply optimisations. C *can* do that. It just can't when you're using pre-compiled, shared libraries, which is where a JIT compiler has the advantage.
I came here to say this, mostly because once I opened the link I realized the link text had been sensationalized. &amp;#3232;\_&amp;#3232;
"Whole program optimization" is in the linker, so yes, it *can* and does cross file boundaries. I did say "turn [it] on in your C compiler" though, so that is my bad. It is a option for the linker.
This article is dumb because it's comparing python to C. People don't use python for the same things they use C for, so why compare them. I'd be much more interested in how a realistic chunk of python code is now faster thanks to the added optimizations.
spy-net. (!!!!!!!)
Well, no, because shared libraries aren't being linked into your program. So in those cases, yeah, that code isn't inlined. However, the example is still a pedantic case. He is using a module to add two numbers, and using it over and over and over. Of course, patterns like this do occur in real code, but they are not the common case, and in the common case, C and other fully compiled languages will have the edge. My feeling continues to be that you need to choose the right tool for each job. The bulk of code in each program will be just fine if written in Pypy or even CPython, and when you get to a performance sensitive area, maybe you choose a new tool. I'm just tired of the attitude that seems to be pervasive in certain circles these days that JIT is the solution for all things and that it will replace native code based on the results of some contrived cases. In reality, both are valuable. Basically, the title of this post is what rubs me the wrong way. The blog post itself has a much more reasonable title, and the actual information conveyed by the article itself is still valuable.
That's a pretty big advantage...
&gt; People don't use python for the same things they use C for, so why compare them. For C-worthy things (i.e. algorithmically simple and performance-critical), I usually use a mixture of Python+numpy, Cython, and C++ code. If PyPy were somehow able to turn idiomatic Python code into the equivalent of moderately optimized Cython code, that would be highly welcome.
Yeah, the content (and title) of the article itself are more reasonable. It fully admits that it is a 'carefully crafted example', and presents useful information.
It's been there for a while.
thats not small lol
It's there to circumvent the Great Firewall, as [python.org/download](http://www.python.org/download) is [blocked](http://twitbrowser.net/49).
Oh, I didn't think that every single one of the user's posts ranking would need to be recalculated. I could easily see only calculating the new order for some of the users top posts though. No need to recalculate posts from months ago.
The difference with Exocet is that modules it loads are _not_ cached in `sys.modules`. You're responsible for managing modue lifetime yourself if you load a module this way. And yes, there can be different versions of a module loaded at the same time.
It does: from zope.interface import Interface, implements Do you really need this dependency?
I just wrote a remote ping daemon in Python. Years ago I would have done it in C.
Can people stop complaining about how simple this example is? They are doing a great job and we know it. Give them support verbally or programmatically instead of questioning their work.
Is it a big deal? Most of the software I use and write depends on z.i; it's terribly useful.
zope.interface is a small pure-python library packaged separately from the rest of zope. It is a very small dependency, and really useful.
It can inline across file boundaries if you define your functions as "static inline" in included headers.
Please no "vi vs emacs". I already use Vim but want to see what Emacs can do.
vim rules! Just kidding.
No, it isn't. It would be simple to enable inlining across pre-compiled system libraries. But by _definition_ those libraries become mutable, and hence can't be shared. So instead of every single process on your OS mapping in the same piece of memory into its address space for glibc, every single process would get its own copy. Memory usage from Glibc alone would cost a a few hundred megs. Your standard desktop system would use a few Gigabytes extra memory, but under certain scenarios, programs would run a few percent faster. OS makers chose to trade a little performance for a huge memory saving a long time ago. This trade off is nearly impossible to make in Python. Every process will have it's own copy of every library it uses. This is one of the reasons why Python, while a _great_ language, can never ever replace C for many small, long running programs.
The emacswiki is a great resource: http://www.emacswiki.org/emacs/PythonProgrammingInEmacs
You could checkout my .emacs.d directory. Put it in your home directory as ~/.emacs.d. (assuming unixy os). git://github.com/cswank/dotemacs.git 
make this a snippet in your editor
Those sort of information you can find on speed.pypy.org. There are real python programs that got speed up. This particular optimization doesn't scale that well yet to large examples (that's also mentioned in the blog post). What I wanted to stress is that you can make programs that you would normally write in C in Python and expect them to run as fast or even faster.
Plus, for an "X is faster than Y" article, this one is highly reasonable. It's very clear about the scope of the test, gives a plausible explanation for the findings, and makes no claims regarding performance in larger applications (which are oftentimes polyglot anyway). I think the pypy team is aware of the amazing job they're doing, and wouldn't diminish that by making inaccurate claims about their work. edit: "polyglot" apparently does not mean what I think it means; substitute that with "written in multiple languages".
Still, jit has much more potential than static compilation because no matter how dynamic is your code you can obtain some runtime information and use it to optimize only common paths.
I can neither confirm, nor deny that we are currently seeking funding for work on py-net.
I don't know if Cython does this optimization, but if/when PyPy gets NumPy one of our big goals is to remove temporary allocations, specifically given something like `a + b + c` (where all the variables are NumPy arrays), make sure not to allocate the intermediary array for `a + b`.
Yeah, they could call it Pypypypy.
Well now that's a bit harsh. Sure it's not the prettiest documentation, but it's easy to use and better than nothing at all. I don't have a whole lot of experience with large (not relatively large) projects, so I was quite happy about my find. I find it fairly easy to navigate as I had my beginnings in Java programming. av201001 pointed out that it's no longer in development, which is a very valid point I hadn't heard of Sphinx or autodoc, but I'll look into them. It seems to be the general consensus that it is a much better tool. I guess I better get used to criticism and take it on board.
**I N C E PY T I O N**
&gt; This article is dumb because it's comparing python to C. What? &gt; People don't use python for the same things they use C for, so why compare them. What?
try import antigravity 
 from __future__ import braces
Thanks!
http://gabrielelanaro.github.com/emacs-for-python/
I don't really know what I was expecting, but I should have expected this. Simply brilliant.
Yes, replacing need for native code with the JIT is our goal :) For less contrived examples go to speed.pypy.org and see how fast things run compared to CPython. Those programs however have no C equivalent, because noone sane would write them. Really, the main source of our reasoning is running large Python programs and not small contrived examples. This small contrived example shows particular limitations of gcc and of static compilation in general. Turning the whole program optimization (-fwhole-program) does work for this small example, but doesn't work in general because of memory usage (we tried and failed to use it).
&gt; but it's easy to use and better than nothing at all. No, I do not agree, no documentation at all tells me "fuck you, go read the code". Shitty autogenerated doc gives me hope and then dashes that hope against hard rock. Several times.
Thank you for suggesting my project! More information for the submitter: it's a collection of emacs tweaks to have a drop-in emacs for python developement environment, most packages are bundled so you won't install much stuff. In the wiki there are suggestions about the best practices and workflows (also TDD). And if someone have some problems with it I'm here to help out. Check out the https://github.com/gabrielelanaro/emacs-for-python project page.
Profile guided optimization (PGO) in GCC/G++ can do a lot of this stuff as well. I use it along with its guiding macros in extreme cases (directing it to which branches are more likely than others, for example).
Requires python 2.7+ it looks like
Thanks!
Most of Numpy's routines are written *in* C; it's speedy, so long as you vectorize your code and don't do unnecessary iterations.
Hey, 24 is on the horizon, is that compat with it?
Yes, and probably there is nothing to argue about, but pgo is inferior to (ideal) jit because you rely heavily on representativity of your profiling run. 
it's up [here](http://code.google.com/p/whazzup/source/browse/) on google code
thanks
[Right here](http://en.wikipedia.org/wiki/Terranigma)
I haven't tested it on 24 but I can check it out! It much depends on the various packages included in it (which I can patch, btw)
Oh, it is on the side panel! I was wondering what the heck you were talking about. :D But here is the deal, I will not have to worry about having to cram data into a small cartridge. And I will not be using a terribly obfuscated language, like assembly, to make the game. :3 
Yes, but I doubt those three artists were concerned with data compression. That's three people, working full-time, in a field they know well, to create the artwork necessary for **one** video game. All I'm trying to say is that for you, one person, to create a game *like* that, you'll have to do the work of approximately 13 people, all of whom are probably very good in their specific fields. Go take a look at what games were produced by a single person back in the 90's. They do not look very good. But, take heart, [Cave Story](http://www.cavestory.org/) was created by a single person, and it's one of the most beautiful and fun games I've played! It took him five years.
Thank you, sir. I am just sick of never seeing the ideas I have for games coming to fruition and knowing fully well that they likely never will.
Thanks for the clarification.
Why are we comparing runtimes to languages?
Start small. Very small. Elementally small. You want an assignment? I'll just assume the right to give you an assignment. Produce for us the most simplistic mario clone: * No art, just simple colored blocks. * Keyboard control * No sound * Simple gravity physics * No scrolling (one, one-screen level) * Only three, on-screen, game entities: "mario", blocks (to stand on), and one exit (door) * No optimization. None! The player will begin, standing somewhere in your level. He will jump around on the blocks, until touching the one "door" entity. When he touches the door, the game is over. When you think of a feature that you'd really like to stick in there, stop, flagellate yourself until the feeling passes and then proceed with on plan. Always go with the simplest implementation. For example, if you wonder whether the player should have "air control", go with whatever is easiest to program. Allowing "air control" will probably be easiest. Then, congratulate yourself, you've written and entire, complete, video game. You have to be able to get something like that off the ground before you can even think about making the next Terranigma.
Hello Prof. Di Pierro! I think creating a WSGI app from a web2py app would be an interesting topic to cover. 
We weren't talking about small long running programs but high performance computations. &gt; This is one of the reasons why Python, while a great language, can never ever replace C for many small, long running programs. This is one of the reasons why C, while a great language, can never ever replace a JITed language for high performance computations (well in practice the JIT might add too much overhead).
Haha, those are all neat. Python is so kick ass. I'm glad she was my first. 
WE NEED TO INTROSPECT DEEPER.
Because there is an obvious canonical way how optimizing C compiler would compile this given a calling convention (which is defined by a standard). You can't do much more here. However python runtimes differ quite a bit here and this is one that has the most interesting results.
Yes, it is.
Try [RUR-PLE](http://rur-ple.sourceforge.net/). This program teaches Python to children. Works on adults, too.
Programs have thousands of lines of code. If anything, Python is extremely terse, which sometimes can help to minimize bugs (but can make things worse if you don't have a clear understanding of what all the 'magic' is doing for you). Here's the fib function stripped of all comments, documentation, and examples: def fib(n, s=[0,1]): fib.s = s if n &lt; len(s): return s[n] else: s.append(fib(n-1) + fib(n-2)) return s[n] ...seems very small to me.
OTOH you don't have to wait for it to warm up, since you've trained it off-line.
I use emacs almost exclusively for python programming because you can easily communicate with a REPL in a separate window or buffer. These shortcuts should be useful: C-c C-z -&gt; Open up a REPL in a split window C-c C-c -&gt; Send buffer to REPL C-M-x -&gt; Send context (e.g., class, function, line) to REPL C-c C-r -&gt; Send region (I rarely use this, but you might find it useful) 
Many thanks!
Much better than starting with Visual Basic...
Where exactly was the discussion limited to high performance computations? As for your comments on the superiority of JITet languages, these days compilers like GCC have both full program optimization and profile driven optimization, which negates the two main advantages of JITed languages. You just have to make sure that libraries that you spend significant amounts of CPU time in (Linpack, Lapack) aren't dynamically linked, and you're good to go.
On the other hand, some C runtimes (or rather, some C compilers, including the latest GCC) can actually perform inlining across module boundaries. So what we're really comparing here is the latest and greatest Python runtime against an old and stale C runtime.
methinks someone is conveniently ignoring the fact that all the things done with python were once done with C and before that Assembly. The very categories of "things done by python" compared to "things done by C" is volatile and contingent on various limitations of the two. One of those limitations has traditionally been performance gains (which is why libraries like numpy still heavily leverage C for a lot of their number crunching). So, demonstrating that PyPy now performs on par with and in some cases better than C in a subset of usages traditionally viewed as "things that should be done in C" serves as an indication that the categories are changing….again.
For those who don't want print as a function. from __past__ import print 
Although, if you're in law enforcement, it's awesome for whipping up GUIs to track IP addresses.
LOL at us old fucks now ? 
Vim has a series of great .vimrc/other .vim* stuff which are great for Python, FYI. It also comes with syntax highlighting for Django templates, although there's an Emacs module or whatever it's called for that too.
It should just work by default. The latest version of emacs will do syntax highlighting, indentation and integration with version control systems. You can learn other fancy commands later. For now just open the editor and enjoy ! 
Thanks!
"下载" means "to download" in chinese
Psh, starting with C is the only way to go.
A wise C programmer would just do something like "static inline double add.." on performance critical code. Whereas a wise python programmer has no way to semi-directly control the generated assembly code, specify heap vs stack allocations, etc. I seriously doubt a java/python/etc JIT can ever consistently beat a highly experienced C programmer with deep knowledge of the processor internals. It is great to see the gap shrinking though.
Similarly -- it is much more power efficient on a mobile device.
Do i smell bacon?
This is a minor mistake, an easy one to make. The short version is that you need to say: if player == 'P' or player == 'r': A slightly longer version is to show you a little bit more about how a computer "thinks" about an if statement. It's really saying: If (whatever I write here is a true statement): (do the following thing). If you put parentheses around your statement, it will become a little more obvious why: if (player == 'P') or ('p'): Without getting philosophical about it, Python will always interpret 'p' as True, which means that no matter what you input, you're going to print "Hooray!". Similarly, it will also always interpret 'r' as true, meaning that you will *also* always print "Oh no!". if (player == 'P') or (player == 'p') is now two separate comparisons to python, and can be evaluated properly. Don't forget, for computers, "or" really means "either or both", not "the first one OR the other one, but not both", like we use it in English. Happy coding!
You can also say: if player in ('P', 'r'):
Thanks a lot! 
I don't quite understand how this works.
Another solution would be to normalize the input. I.e. player.lower()
I appreciate your will to find a solution for the reload mess. I do think import in Python is complicated and messy but since it is also very flexible one can find a cheap workaround most of the time. So I don't think one really needs to bypass `sys.modules`. Instead one can load the same module under different names: import imp class ModuleLoader: def __init__(self, name, fs_path): self._name = name self._fs_path = name self._version = 0 def load(self): self._version+=1 v = str(self._version) return return imp.load_compiled(self._name+"_v"+v, self.+fs_path) The implementation is ad hoc. One needs to handle the case where a `pyc` file is not yet available. One can mangle the names more cautiously and much much more. But the idea shall be clear. Loading module `foo` the first time yields `foo_v1`, the second time `foo_v2` etc. When loading `foo` the `sys.modules` cache will never return a cached instance. Instead of returning the module itself one can return a proxy to the module instance. This retains the singleton with respect to the objects holding the module but hides the proper module instance and enables reload. 
Actually, '==' happens before 'or', because according to the table, 'or' has lower precedence. &gt;&gt;&gt; False == 4 or 4 4 &gt;&gt;&gt; False == (4 or 4) False &gt;&gt;&gt; (False == 4) or 4 4
This one is slightly tricky to explain, but the concept is that Python supports something called an "iterable". All of python's primitive types that can be thought of as "holding more than one value", like a list, dict, set, or tuple support testing of whether or not your variable's value matches any item *inside* the iterable. draconian above is putting "P" and "r" inside of a variable called a "Tuple", which is kind of like a group of variables. The technical details are unimportant at this stage, but because he put them together like that - the parens are Python shorthand for creating a tuple - he can now check if your variable "player" matches any of the values inside that tuple, in this case, 'P' and 'r'. Imagine, for a moment, that we each have a deck of cards. I take one card out of mine, and you take 20 cards out of yours. You now have a nice little stack of cards, but I want to know if the card I've taken from my deck matches any of the cards you've taken from yours. So, I show you my card, and then you flip (iterate!) through your 20 cards, one by one, ignoring them as they go by if they don't match, but if it does match, then you'd say: It does! That's kind of like how the "in" keyword in python works.
The basic way to use "or" is with boolean expressions on both sides of it. if (expr1) or (expr2): doStuff() You do not use boolean expressions on both sides, you leave expr2 simply as 'p'. Python does not know how to map the == operator over both possible options; you have to be more explicit and use == on each side. But, of course, the "pythonic" way to do it has been mentioned by others if player in ('p','P'): print('yay') In Python, "or" actually gets tricky and can evaluate to a value, even if the expressions do not evaluate to a boolean (true/false). If you try something like that in Java, it will tell you it's an error. if (c == 'p' || 'P') { stuff(); } // &lt;-- Compile error, 'P' doesn't evaluate to a Boolean value.
Just a minor correction: player == 'R' or 'r' gets turned into (player == 'R') or 'r' which is True if player=='R' or 'r' if player != 'R'.
So in this case. if player in ('P', 'p'): would mean, if player exists in the list of 'P' or 'p' the statement is true. I would then extend that list to say, if player in ('P', 'p', 'pot', 'pebble', 'porcupine') if the input is porcupine then player=porcupine and the statement is true. Am i understanding that correctly? edit for my terrible typing haha.
Sure... happy coding.
as long as no one goes for this: import skynet
Yes, a programming "or" means basically "and/or" in English. A programming "xor" (exclusive-or) is closer to the English meaning of "or".
Oh man, I want to understand this but I do not. I guess you are saying that since the "or" was used incorrectly it defaults to using the first option? Kind of confused.
You are correct!
You're right! Also, you just debugged someone else's code - I didn't even notice that he had used the wrong mix of letters :-). An eye for detail is super important, so good catch.
Especially when the IP addresses are &gt;255
&gt; Python does not interpret " 'p' " as a true statement. It's just a &gt; string to python. 'p' evaluates to True in a boolean context: http://docs.python.org/reference/expressions.html#boolean-operations
Ah, you're right. I'll edit my response to be more clear.
He/she said the wrong thing.
 if player=='P' or player=='p': print ('Hooray!') elif player=='R' or player=='r': print ('Oh no!') 
Ah, i had elif on my program and didn't write it here in the post. That was a mistake on my part. Thanks for correcting me!
&gt; The implementation is ad hoc This is the problem. I want a principled implementation that does stuff the right way. The solution to a mess is not more mess.
Indeed. Antigravity is a rather recent development.
Dont try emacs if you are learning Python. Just learn it first. Just looking for frustration as Emacs full capabilities are only good when you know the language. Stick with a simple editor like Eclipse or something then move on when you realize why you would need Emacs. It is liking a teenager saying "I am learning to drive but I want to learn it in an F1 racecar"
By chance, have you read Learn Python The Hard Way? It's an excellent book for learning Python. http://learnpythonthehardway.org/index
The implementation was done in the tiny comment box of `/r/python` and is only a means to explain the basic idea. 
BTW, ``or`` is an operator (I think). ``if`` is a statement.
I found Dive into Python much more in depth. It might be a good intro for a beginner though. http://diveintopython3.org/ 
Python is too lenient and allows 'p' as a boolean value. In Haskell, the compiler would catch your mistake earlier :-)
Now you're thinking with python :) &gt;if player exists in the list of 'P' or 'p' Just a note, ('P', 'p', 'pot') is a *tuple* not a list. A list would be written like ['P', 'p', 'pot'] and works a bit differently, this might seem like an unimportant distinction right now, but it's important to get the terminology right from the start. (http://diveintopython.org/native_data_types/index.html) should give you an overview of the differences and why they matter. Btw, I think a tuple is correct in your case.
you could use if player in 'Pp': do something
This is a good point. Python could be made a little more friendly if, in this situation, it tells you that "p" will always evaluate to True in that context, and that you must rewrite it to something more reasonable, like either True, or "p" == something.
This is also one way of doing it Put the raw input directly to uppercase print 'Press P or R' player = raw_input().upper() if player == 'P': print ('Hooray!') elif player == 'R': print ('Oh no!') 
Thanks for the correction. I briefly skimmed over lists but did not read into detail how they differ. This seems like a good time to make that distinction so thanks for pointing it out. I feel like I am catching on pretty quickly but the terminology I am reading in the books I have make it hard for me to understand. 
A small advertisement for Python 3.x, which supports "if player in {"P", "p"}". Set membership tests should be faster than lists for all but very short lists.
 from __future__ import barry_as_FLUFL 3 &lt;&gt; 4 
I would suggest trying to use it without any tweaks or existing config - just default emacs. Go through the built in tutorial to learn the basics (how to move the cursor around, how to open/save files) Then start playing about with Python. Then start wondering if emacs could do `[something]`, and look around [EmacsWiki](http://www.emacswiki.org/) The [PythonProgramming page](http://www.emacswiki.org/emacs/PythonProgrammingInEmacs) has some good things - such as using pylint to highlight errors on the fly (using flymake)
Eclipse isn't exactly simple, nor is emacs.. but to do the basics in either is about the same difficulty (assuming you use a non-command-line version of emacs, in which case it'll have all the same GUI clickyness as Eclipse)
Actually, that's not going to be any faster (and in fact, is going to be slower), because python has to first create the set, then iterate over it. Creating the set is going to have to iterate over every member anyway, and will also have extra overhead in the set's structure. Tuples, however, have an optimisation that allows them to be cached off in the function locals (since they're constant), so they're only created once at compile time. This isn't done for sets (though it potentially could be). You can see this if you look at the disassembly: import dis def test_set(x): return x in {1,2,3} def test_tuple(x): return x in (1,2,3) &gt;&gt;&gt; dis.dis(test_set) 2 0 LOAD_FAST 0 (x) 3 LOAD_CONST 1 (1) 6 LOAD_CONST 2 (2) 9 LOAD_CONST 3 (3) 12 BUILD_SET 3 15 COMPARE_OP 6 (in) 18 RETURN_VALUE Note that it has to manually build the set. Whereas: &gt;&gt;&gt; dis.dis(test_tuple) 2 0 LOAD_FAST 0 (x) 3 LOAD_CONST 4 ((1, 2, 3)) 6 COMPARE_OP 6 (in) 9 RETURN_VALUE You'll note the LOAD_CONST, which is fetching a reference to a pre-built tuple cached off in the function's constants. This means that it doesn't have to build it every time, so just has to iterate it at most once (and fewer if it finds it early). When the item is not in the iterable the times are: &gt;&gt;&gt; timeit.timeit('test_set(5)','from __main__ import test_set', number=10000000) 3.126133918762207 &gt;&gt;&gt; timeit.timeit('test_tuple(5)','from __main__ import test_tuple', number=10000000) 2.4784011840820312 A 20% reduction for the tuple. The difference is even bigger when it can bail out early: &gt;&gt;&gt; timeit.timeit('test_set(1)','from __main__ import test_set', number=10000000) 3.1142520904541016 &gt;&gt;&gt; timeit.timeit('test_tuple(1)','from __main__ import test_tuple', number=10000000) 1.6864550113677979 Almost twice as fast - and would be even better on larger tuples. 
I found this talk pretty useful in describing what z.i is used for. http://pycon.blip.tv/file/3257477/ maybe you will too. :) 
"or" separates independent evaluations. "player == 'P'" evaluates as true or false. 'p' evaluates as true. This doesn't do what you think. if player=='P' or 'p': print ('Hooray!') elif player=='R' or 'r': print ('Oh no!') These would work. if player in ('P', 'p'): if player == 'P' or player == 'p': A good programmer would write: if player.lower() == 'p':
What's the point of this review? what *does* it explain about coding for mysql in python? "how to perform the same commands in python"?
Started first with Pascal here. Oh, the memories..
just a little gotcha.... &gt;&gt;&gt; '' in 'pP' &gt;&gt;&gt; True 
I think it helps me to understand the functionality of code if I do it the long way first. That way when I understand how to use the shorter methods I will better understand how the shorter code is working and doing for me. Do you agree or disagree? Thanks for this information. This already shows me how much work I could've saved in the program I just wrote. Haha. :(
Whipping up a quick site in flask is refreshing :) and fast. Someone once said, if the only tool you have is a hammer everything looks like a nail. 
&gt;Btw, I think a tuple is correct in your case. Why? In this case, what does it have over a list?
It is immutable, and in this usage it does not need to be modified.
[Brian explained](http://www.reddit.com/r/Python/comments/ffne7/help_with_if_and_or_statements/c1flcbs) this quite well :)
Django is awesome, but there are projects for which it's not the best choice. If you only use Django, then either you can only work on things for which Django is a good fit (and there are a lot of those), or you'll have to shoehorn your project into Django. For example, I'm working on an app in Pylons right now. I considered Django and rejected it because I needed to support a tricky publishing workflow and some complicated data models. It seemed to me like the work required to accomplish those things with Django would be difficult.
I've used all three. Flask is great for whipping up small projects fast. It is NOT a full-stack framework. Attempting to use it for anything large-scale you're going to run into a lot more pit-stops than your would with something like Django or Pylons/Pyramid. Pylons/Pyramid is good for people that like Django but prefer another Templating Language or ORM. Otherwise they're practically identical in theory (but Django has a few more selling points which is why I prefer it). I've never had a problem with Django's templates. Writing custom tags is kind of a pain, but django-classy-tags makes that fun again. Especially after the latest few patches of improvements, there's really nothing I can't accomplish using Django's ORM and Q objects. And if I do meet a query that's too complex, it's probably better to just drop down and write it raw anyway. The tight integration with the Forms and Admin is too much of a win for me to ever consider using anything else, even if I thought Django's built-in one wasn't good enough for a particular use-case. Django's ecosystem of developers and pluggable apps is also much more mature than anything I've ever seen for Flask or Pylons/Pyramid. Nowadays the only thing I ever have to write is the unique business logic specific to the site at hand, and cut up a template for them. Everything else is boilerplate and easily installable/customizable from someone else's or my own reusable work. TL;DR: Why it wouldn't hurt to broaden your horizons and play around with other frameworks, in my professional opinion Django is the best of breed, across all languages. Stick with it, you're not missing much.
Fundamentally, you must linear scan through a tuple to check for membership. The cost of set construction is amortized over repeated membership tests. In the OP's case, the membership check was only being done once, so I agree that a tuple is better there. However, we should be very clear about the differences between sets and tuples. dalke specifically mentioned that set membership is quicker to check for large sizes, but failed to mention that this will hold only for repeated tests. The disassembly is misleading because the `COMPARE_OP` in the set case will in general be faster for complex items, or large set sizes than the `COMPARE_OP` in the tuple case. And I have the numbers to back me up: &gt;&gt;&gt; def item_in_tuple(tuple_size, item, repeats): ... t = (n for n in range(tuple_size)) ... for i in range(repeats): ... item in t ... &gt;&gt;&gt; def item_in_set(set_size, item, repeats): ... s = {n for n in range(set_size)} ... for i in range(repeats): ... item in s ... &gt;&gt;&gt; timeit.timeit('item_in_tuple(10, 2, 30)', 'from __main__ import item_in_tuple') 4.863246917724609 &gt;&gt;&gt; timeit.timeit('item_in_set(10, 2, 30)', 'from __main__ import item_in_set') 4.172131061553955 &gt;&gt;&gt; &gt;&gt;&gt; timeit.timeit('item_in_tuple(100, 2, 30)', 'from __main__ import item_in_tuple') 14.598160982131958 &gt;&gt;&gt; timeit.timeit('item_in_set(100, 2, 30)', 'from __main__ import item_in_set') 11.414110898971558 &gt;&gt;&gt; &gt;&gt;&gt; timeit.timeit('item_in_tuple(100, 2, 100)', 'from __main__ import item_in_tuple') 19.891393184661865 &gt;&gt;&gt; timeit.timeit('item_in_set(100, 2, 100)', 'from __main__ import item_in_set') 16.059064149856567 &gt;&gt;&gt; The problem with your usage of `timeit` is that your set had to be reconstructed every time. In my case, I used the repeated test, thus amortizing the set construction cost. **tl;dr** - if you intend to check for membership within the same set of more than a few items repeatedly, it is faster to use a set/mapping type over a sequence type.
Do you have some useful references for Django methods and automatically generated keywords? I've had a hard time developing anything with Django quickly and the documentation is really strange -- too many specific examples and no generic descriptions of objects.
10 years ago I worked as an IT consultant for an engineering company. I was the MCSE on staff and the next cube over was a CNE. The guy was a Novell Netware god. He was well-paid and clients really liked working with him. However, he hated Microsoft and for that reason alone refused to learn anything about Active Directory. Now, I'm also a CNA (basically a "lite" version of CNE) and agree that NDS is/was superior to AD, but I could also see which way the wind was blowing. Management strongly encouraged him to learn some new skills, but he stubbornly refused. A year or so later, he was laid off after one of last remaining Novell clients migrated to Active Directory. Don't ever cling to your tools. To be truly successful, you have to enjoy learning new stuff constantly. Now that I run my own IT shop, it's one of my most important hiring criteria. If during an interview if you excitedly relate the cool things you're doing with Flask, or Erlang, or other stuff outside the mainstream, it's a *huge* plus. We might not be doing any production work in Flask anytime soon, but it demonstrates that you are eager to keep updating your skills and are motivated by that challenge.
 print "Hooray!" if raw_input("Press P or R") in ('P','p') else "Oh no!"
The last time I checked, which admittely was quite a long time ago, Django kind of forced your apps to adapt to its own way of doing things. There's a certain kind of directory structure, you do stuff with the admin scripts etc, you use Django's ORM, you use Django's templates. Now I'm not a freedom-zealot, but even I want to set up things in my own way. I've got my own little support library for making web-apps in Python, my own little project-template-kind-of-thing with its own directory structure. I like to use SQLAlchemy but at a lower level than ORM, and I sometimes want to call something in a template. So I've settled on CherryPy, SQLAlchemy and Jinja2. They're _excellent_ tools, and give you all the freedom you want, but in a gloriously elegantly designed way. Django has its advantages, of course. But there's only so much abstraction &amp; reusable components you can have before they just won't suit your needs anymore. 
IMO, it's a mistake to compare a minimal microframework (one that lets you do it your own ways) and a fullstack framework. Fullstack frameworks will inevitably make their own assumptions about how things should be done. Sure, the minimal frameworks are flexible; you can pick and choose. You can even modify the frameworks themselves to your taste. But such things come with their own baggage in terms of long-term maintainability, sustainability, and upgradability, among other things. And last but not least, you'd better know what you are doing. Often, by the time you put together a load of libraries to build a non-trivial system, making sure that they work together, making sure that they are all up-to-date, etc., what you have is even worse than a full-stack framework. I hear all the times how these little micro frameworks are better than those fullstack frameworks. Well, unless these little frameworks provide all the features in those full stack frameworks, they are not comparable. 
&gt;The cost of set construction is amortized over repeated membership tests. No, it's not - that's my point. Your code is a different case: manually creating the set outside the usage and caching it off. However using a literal within the `in` clause as in dalke's post won't do that. It will for tuples or lists though, thanks to an optimisation python performs, which means using "`x in &lt;set literal&gt;`" will always perform worse than "`x in &lt;tuple literal&gt;`". There was a [ticket](http://bugs.python.org/issue1548082) to add this optimisation for sets too, but it was rejected.
&gt; Usually only 0, 1, -1, and sometimes 2 FTFY
If you relegate yourself to one thing and one thing only you will stagnate.
Django is great but it doesn't work with all apps, one reason is the inflexibility of the built-in ORM. You can replace much of this with something like SqlAlchemy but it won't be fully integrated. I work with spatial databases and Django's geospatial capabilities (GeoDjango) are at a very early stage. For now I'm still using .NET for "n-tier" applications where performance and scalability might be important, you name it .NET can do it albeit not as eloquently as Python frameworks.
I also started learning python and have been practicing it on Ubuntu. If it helps, I like gedit. I have no experience with vim and emacs, but found gedit to be extremely simply to use. P.S. New to linux and hence ubuntu as well.. i guess that's why i like gedit..
I absolutely agree - I even mention that in the OP's case, the membership test was done once, and my tl;dr repeats that point. Thanks for the link to the ticket though.
Either that, or it indicates you have AD or are easily distracted from doing real work by constantly learning about every new thing that blows by. :)
...and some [screenshots](https://picasaweb.google.com/kgingeri/Wep2pyOnIpad?feat=directlink#).
what is AD?
How will you make matplotlib window appear in the first place? Can you provide a full example?
could you explain in a bit more detail about the issues you where facing with django? i am wondering about "complicated models" mostly
It's a minor psychological disorder that inv- OH, HEY, LOOK, SHINEY THINGS!
&gt;Python treats decorators that don’t take any arguments slightly differently from those that require arguments, False. &gt;so this complicates things a bit. True. There's no special case here. Python evaluates the expression after the @, which is assumed to return a callable. Without arguments you can just put the decorator name because it evaluates to a function that takes the function to be wrapped. If you want args, you have to say @my_decorator(arg), which gets evaluated. It must return a callable that takes the function to be wrapped. So Python treats both cases the same, but you have to write them differently because you want different things. Just remember that the expression behind the @ must result in a callable that take the function to be wrapped and you'll be okay.
Specialization is for insects. If you dabble with these other things, you might just learn something useful or even begin a new career you can't imagine at this point.
Happy coding.
ADD, but I got distracted between D's. 
That's it. I don't know if it's really minor or not, though. I think it may be an actual problem. 
Yes, there is a reason to learn something else. You don't know where the tech world is moving, and where it will be in a few years time. Consider what happens if building websites becomes much easier, or rather much cheaper - while you could still do it, many other people could do it just as well as you, and then it won't "cover your bills". As I see it, we should always: 1. Hone our skills, to stay ahead of the curve, and 2. invest in something that will pay the bills once 1 fails (and it will fail).
Django takes the Python way of doing things, "There's only one way of doing things, if you don't like it, screw you." This approach actually makes working in teams easier because it forces everyone to abide by a common convention with little freedom. I personally want to be creative solving the hard problems, not in the way the framework is laid out. My biggest complaint about Django is it's Request/Response objects, they're really limited compared to webob.
You lost me at MCSE
Didn't know this one. You took my != ..! Any relation to Candy Mandible?
I was going to say that learning other ways of doing things always gives you perspective on what you are doing now, but yours is short and to a similar point as well.
Well, what you _really_ need is: 1) HTTP handling, with cookies and file uploads 2) Something that calls your stuff in response to a requested URL 3) Something that helps you operate a database 4) Something that helps you manage the presentation of your application. For example: 1) CherryPy / Werkzeug / Flask / etc 2) CherryPy / Werkzeug / Flask / etc 3) SQLAlchemy / Something else 4) Jinja2 / Genshi / Mako / etc vs 1) Django 2) Django 3) Django 4) Django But aside from those four things, everything else is extra. Django covers all four, but it's unlikely to thoroughly satisfy you in all four areas. All applications are unique in some way. You can't just take Django, set up some tables and tweak some settings and have an application ready. The Django Admin is quite neat, but using it will get complicated soon, and it'll be impossible to use it for _some_ things - it just won't be able to handle everything you need. In a way, it's a leaky abstraction. A leaky abstraction is too high-level. All "components" or "apps" or whatever they're called for Django are useful to some extent, but will be inadequate or inapplicable to _something_ you need. Now I admittedly have no idea about all the "apps" available for Django, but I'd wager most of them are too high-level for most uses. If I'm wrong, it would be nice to see examples. In any case, using hand-picked libraries and frameworks for all of the four areas is a good idea, because it gives you the flexibility you need. You've got good tools that provide you with the basic infrastructure that's absolutely necessary in any case, but after that they'll just get out of your way. At that point, it's time for you to whip up some of your own abstractions, on top of which you'll build your application. Your own abstractions might be reusable across projects, or they might be project-specific. But either way, they'll be more likely to fit your needs much better than Django and whatever 3rd-party abstractions you can just plug into it. 
 from matplotlib import use use('tkagg') from pylab import * ion() _show = show show = lambda: None from matplotlib._pylab_helpers import Gcf as __Gcf __TK = None def _gui_update_matplotlib_tk(): global __TK if __Gcf.figs == {}: __TK = None else: if __TK == None: __TK = __Gcf.get_active().window __TK.update() a = linspace(0, 1, 100); b = sin(a); plot(a,b)
I love Flask. That said, always remember the right tool for the job, and don't go around building huge siges in Flask, or you'll be reinventing quite a bit of Django. However, I wrote [a simple script to host multiple domains on a single AppEngine instance](https://github.com/stochastic-technologies/static-appengine-hoster) and it's much faster with Flask.
Active Attention Deficit Directory.
Probably the quickest way is going to be [Django](http://www.djangoproject.com/), as it's kinda the "kitchen sink included" framework, with usually one specific way of accomplishing anything. Reddit uses [Pylons](http://pylonshq.com/), which is much more of a pick-and-choose framework - you can decide what you want to use for the database, the templates, the ORM, etc. That said, the only Python framework I've had much use of is [CherryPy](http://www.cherrypy.org/), so this comment should be disregarded.
TIL about [classy-tags](https://github.com/ojii/django-classy-tags). Thank you.
Isn't the promise of JIT (and any other compiler optimization) is that *you* as the programmer don't have to optimize? Yes an experienced hand at a lower level language can often beat the compiler, but how much experience is necessary? How much time will the optimization take? And how recognizable will the resulting program be afterwards, and will devs' not experienced in the optimization techniques be able to understand and modify it? This situation is not a new one. In the good old days, people looked at C and its compilers then scoffed saying: "A good programmer will always be able to write assembly that out performs this". That is still true today, but most people don't inline assembly because the compiler is "smart" enough for their needs versus the cost of actually performing manual optimzation. I hope in the future, the same situation applies to Python vs C---yes it'd be possible to beat Python by dropping down into C, but hardly anyone will do it.
Are you saying Django because that's a fast way to get most web projects off the ground, or because you think it is particularly relevant to the project I described? My take on Django is that it is fairly skewed toward DB-driven projects, and given my situation, I'm not convinced a DB back end is the way to go.
Yes, but don't only venture out of Django, but Python too! Think of it like this: many people pay the bills with PHP, but I'm sure you'll agree that those people could learn a lot from adventuring into a language like Python. And the same goes for you. As primarily a Rubyist, I see many areas which could be improved in the Python world by learning from Ruby's ways, and vice versa. To be honest, I only use Python for this reason, since I much prefer, and am much more productive in, Ruby. Python has some awesome tools and libraries which are far better than the Ruby alternatives, so I learn from, utilise, and occasionally port those said items and ideas to Ruby. A tool, whether it's a framework, language, or OS, is just a preference. It's the ideas which thrive in a tool's community which are important.
I agree, it doesn't sound like you need a database for this. Technically, it sounds like something you could even do in Javascript, if you had the JS chops for it. Are people going to be uploading SVG's, and will they be accessing SVG's you have on your server? Really, any of the web frameworks would work, but I would recommend Flask. Its a microframework, and comes with no database layer, and not much beyond routing, templating, and a WSGI implementation.
Primarily because it's a fast way to get things off the ground. While your site doesn't sound like a DB is going to be a primary focus of your development, you need to think how are you going to store and share the content that users of your site are creating? You're going to need to store those file locations somewhere, not to mention giving yourself administrative access with some authentication scheme. Django could take care of most of that with ease.
I'm not opposed to Django. In fact, having taken it out on the dance floor a few times, I'm more than a little anxious to buy it a double and take it home for the night. But part of me is also quite aware that there are other, younger options on the scene that might be even more exciting. (Okay, that metaphor got a little out of hand, but I'm sticking with it. :-)
Yes, I agree that much of this could be done in JS, but I'm a bit old school and prefer to keep my scripting on the server side. No, users will not be uploading their own SVG files as they require some custom content in order to be usable, so I have total control of the content. I haven't delved into Flask yet, but your words entice me strangely, so I will go now to investigate the truth of them.
Are you a freelancer or do you work for someone else's company?
And Django runs on my iPhone! [running](http://i.imgur.com/ZvV6s.png), [mobile_terminal](http://i.imgur.com/5JgGq.png). I got bored at the mall over thanksgiving. Vim and screen on the iphone actually works out pretty well.
I was also going to recommend Flask. Also, you probably need some database (user management and all) so look at SQLAlchemy. But, beyond all else, Django, Pyramid (Pylons and Repoze recently merged to create Pyramid), &amp; Flask are all good. Just pick on and do it. 
It's a question of economics, really. The question is spend your time learning more about Django, or spend your time learning other things? This sounds like a no-brainer to me--learn more Django. If it won't work for everything, you can't and don't need to do everything, that's fine. If it turns into a wasteland, you're in the habit of learning, and you can pick something up then. That's just my opinion. I think the 'ZOMG ALWAYS BE LEARNING NEW FRAMEWeRX AND SYNTAXEZ' people really miss the point. If you can think, adapt, and move, do so when necessary. Don't blow your energy on every fad.
What about web2py? I'm currently reading the official online book and it seems pretty interesting, and quite suitable for your needs... Plus, you can install web2py applications in Google App Engine, which may suit your heavy traffic needs.