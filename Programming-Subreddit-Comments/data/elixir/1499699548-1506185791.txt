Sure, it has actually pivoted a bit from when I posted it. It is going to be an forex algo trading platform. Right now, I have the the code pulling the real time quotes (from Oanda) while only looking at a few major pairs. I have it architected so that each currency pair has its own gen server that is pulling quotes on a regular time frame (every minute currently) which is supervised. The plan is to utilize gen event and possibly gen stage to handle the algo side of things so when quotes come events will fire based on the current state of pricing/positions
Great ideas! It is always hard to include "all the awesome" and keep the videos short enough to remain enjoyably "bite size". So I skipped over how child_spec/1 is indeed implemented in several modules as you mote. I will highlight this in episode 4's "Extra", which are sort of becoming "last week's errata" :) I will also cover the debugger once It is in a (pre-)release, as that is indeed a great topic. Thanks for all the feedback! 
deleted ^^^^^^^^^^^^^^^^0.8146 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/52677)
This is interesting. I've been mildly annoyed that with CI the merge into master typically happens first, and then the specs are run. I haven't felt that it's a huge crisis, since the branches themselves are all tested as they are committed as well, but it would be pretty cool to have that extra assurance. 
Interesting. What do you want this to be used for if you don't mind me asking? I have to admit I don't know too much about blockchains, but I do know that Elixir and Erlang aren't too computational by nature, so it doesn't seem like a great fit for the language. I'm just curious. 
This is mostly a side project to learn more Elixir and understand how a blockchain works. I want to keep working on this to build simple smart contract / crypto currency on top of it. Indeed Elixir is not really good at heavy computation but that's ok because the only thing that requires good performances is the proof of work. And the proof of work is by definition something that should take time to come up with. So obviously in a real world example miners would want something better like C or Rust to mine blocks but except for that Elixir seems a good fit. I could try to implement the PoW algorithm with a nif that allows native C code to be called from the erlang VM. 
This is a perfect example of good usage of a NIF.
Supervisors and workers!! I recently started learning phoenix it's all magic to me
We are coming there sion, i think I'll have time at the end of the week to write it in detail 
Thanks for your tutorials/challenges :)
Would you agree that your "relaxed" approach is aimed to people learning a second (possibly third or fourth) language? A usual intro involves the tedious (but necessary) steps of picking an editor, installing the language, showing how to type in a basic Hello, World program, defining a few basic concepts in programming, etc.
gigalixir.com now has a free tier and there's no need to get a beta invite. We also now offer postgres hosting and configuration.
welcome ;) will write more :) also live coding sessions should be fun :)
Yes, it's for programmers who want to learn Elixir. It is more like exercise to get feeling how language works. Reading Elixir intro helps learning syntax but doesn't give simple examples how to try one thing or another. So that's idea of teaching of idioms of the language in a gradual way. Actually most books on Elixir are great in doing the same :) 
It may be useful to imagine what changes you'd have to make if you were writing the introduction to a new programmer. It might be a little aggravating to write, though.
yes, it can be interesting mind exercise ;) but this is not my purpose. python, basic, pascal are excellent entry level languages for anyone. starting programming in Elixir can be somehow tough 
yeah, but what's he done lately?
OMG!
Epic
[ðŸŽ¶ Isn't it ironic? ðŸŽ¶](http://imgur.com/a/Io41c)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) https://i.imgur.com/u2M0PUI.png ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[state_of_imgur](https://np.reddit.com/r/u_imguralbumbot/comments/6i1huv/imgur_has_gone_to_shit) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dk3mz0x) 
Makes me glad I decided to use Elixir as the backed for my game. Being able to break projects apart and spin off into separate processes is very powerful.
Awesome work.
Damn, reading this really makes me want to get a job at discord.
Why compare?
Yeah! Read a couple of positive articles lately regarding Elixir in production. Very excited about it and I think more firms will follow suit. It is tech a lot of people are excited about using. Pretty awesome.
I use Discord a lot. Very fast + lightweight. Doesn't look quite as good as Slack, but much less laggy.
I know, I knowâ€¦ different tools for different jobs. I still love Ruby and think it's great for lots of applications, but the juxtaposition of titles was too perfect. Nobody asks "Is Elixir Too Slow For Web-Scale?"
Why would you sayt it's a function, not a macro ? https://github.com/elixir-ecto/ecto/blob/v2.1.4/lib/ecto/query.ex#L489
I know that the JVM is a modern marvel of software engineering, so I'm always surprised when my Erlang apps consume less than 10MB of RAM, start up nearly instantaneously, respond to HTTP requests in less than 10ms and run forever, while my Java apps take 2 minutes to start up, have several hundred millisecond HTTP response latency and horde memory. Granted, it's more an issue with Spring than with Java, and Parallel Universe's Quasar is basically OTP for Java, so I know logically that Java is basically a superset of Erlang at this point, but perhaps there's an element of "less is more" going on here. Also, we're looking for Erlang folks with payments experience. cGF0cmljaytobkBmaW5peHBheW1lbnRzLmNvbQ==
Basically the update on the website... But in video form.
What is the URL of your game?
Are you the same guy who made this exact same comment on hacker news?
Where was the update? The last blog post I see was from 1/5/17
No URL just yet. I have my first alpha back-end done and I'm working on the front-end client now. I was working on a Phoenix site but never had time to get it running.
What kind of game?
Hybrid turn based/real time MMO. Its like a city builder but on a board and interacting with other players puts you on their board able to move in real time with the use of turns that you accumulate over time. That's the jist of it.
Sounds interesting!
Thanks! I'm hoping to have the front-end client working in a few months. I'm building it in Unity. It wont be very pretty but it'll be enough for me to let people playtest and give me some feedback.
Hell yes. I'm fairly new to elixir in a lot of ways but the way dependencies are handled without an npm i equivalent seems backward.
Microsoft Spam, seriously?
&gt; Phoenix.View.render_to_iodata TIL!
one reason I tend to prefer self-expiring LRU caches
Not really a specific website, just the changelog in the repo. https://github.com/elixir-lang/elixir/blob/v1.5/CHANGELOG.md
Not really a specific website, just the changelog in the repo. https://github.com/elixir-lang/elixir/blob/v1.5/CHANGELOG.md
What does "NIF" stand for in this context? A simple google search brought up all irrelevant definitions...
I like the thin GenServer around the functional core module. If you don't need `handle_info` then using Agent reduces the boilerplate a bit further.
Native implemented function 
In multiple languages now I've found value in splitting up the "how" and "what" and "when" parts of a task. "Synchronous &amp; Async version", "Simple API &amp; Specific Data structure", and similar. So I like this :) 
It's a bit unclear to me what ends up in `KV`, and what ends up in `KV.Impl`. He moves the impl code down into kv, but then in the final tree labels `KV.Impl` as the implementation. I'm guessing he moves it back, then `defdelegate`so again. Not a bad pattern, but the article could be better written.
Look at the section right after "Finally, we change the API in the top-level kv.ex file". Basically he uses the root `Kv` module for the GenServer client API. Typically those public functions would reside as on the GenServer module itself, alongside the GenServer callbacks, etc.
Yeah, but then he still shows `impl.ex` in the tree.
I was already in the middle of refactoring a few layers of GenServer code today, so I took a stab at this layout. I think it makes a lot of sense â€“ the GenServer module stays clean and tight, the functional implementation is easy to understand and test, and the client API exposed to the rest of the application has room for application-specific logic that the GenServer need not worry about. Neat.
Yes, the `Kv.Impl` is the same from above â€“ it's the pure functional module that contains the logic for looking up and storing data. One level higher, the `Kv.Server` utilizes `Kv.Impl` to maintain and modify its own state. Finally, the highest level, `Kv`, send messages to an instance of `Kv.Server`, and is expected to be exposed to other parts of the application.
Ah, I see; server is a wrapper that holds state and proxies to `Impl`. I didn't look at that code closely enough, assumed he was just separating server and API. I like it. Don't know how popular it'd be as a general practice in a team, though.
Maybe this repository will fit your needs (even if there is no ranking or rating for the libraries) https://github.com/h4cc/awesome-elixir
Thanks
"ORM" -&gt; Best in class. Ecto is amazing and I'm pleasantly surprised at how little code I have to write around DB access. We use JSONAPI at work, and implement our JSONAPI resources as Ecto schemas over Postgres Views, and it just behaves perfectly out of the box. Not a real ORM in traditional sense, but I think it's better. Testing -&gt; Mature Erlang has Quick Check and friends, ExUnit is built in, PragDave has written Elixir Quick Check stuff, and they're trying to bring in Quick Check natively in later versions of Elixir. Doctests and such are pleasant and easy to use. Web framework -&gt; Mature Truthfully, we don't use a ton of Phoenix, though we use Plug a lot. We try to keep the web layer very high in our application, and we've been able to lean on particulars of router to have our application generate routes based on a config and run CRUD requests through a single central controller. Plug/Phoenix never got in the way of this endeavor. Sockets -&gt; Best in class. Phoenix channels are amazing. If you need real time, use them. Don't think twice. Concurrency -&gt; Best in class Erlang's story around concurrency is one of the strongest stories in any language that exists. Immutable data structures and message passing enable really powerful abstractions. Distributed systems -&gt; Best in class. Single machine concurrency is really just a special case of message passing to a different machine in the Erlang model. It's quite lovely to not care where a process lives, delegating that logic to things like `pg2` to figure out. Debug Tooling -&gt; Best in class Erlang was written for being able to debug and hotfix phone switches while people don't lose their running calls. I feel like I'm cheating when I have to debug running systems and can just inspect all the state or kill misbehaving processes. DSLs -&gt; Best in class We have Lisp-style hygenic macros. If you've never used these, they're the original DSL and are the best. Education -&gt; Good not great Elixir is very easy to get started with. Phoenix makes it easy to get a web app off the ground quickly. You run into issues quickly if you don't understand OTP, and while there's some literature around this, there's not enough. Little Elixir OTP Guidebook and Designing for Scalability with Erlang and OTP (I forget the exact titles) are very good. The docs are generally very good though they need some improvement in certain places. They're usually good enough. IDEs -&gt; Immature I use emacs, and the language itself is extremely greppable if you structure your code in certain ways. For example, prefer `alias` to `import`, and if you do have to use `import`, make sure you import with the `only` keyword. And don't have macros exist that only import modules into your namespace. That's lazy and I see it all over the place in tutorials, and even the autogenerated Phoenix code. That said, coworkers use VSCode and it seems to behave well there. They're working on a language server, which will help this endeavor. Numerical -&gt; Bad/Immature Don't do math in Erlang. That's not what it's for. Call out to C bindings and get the best of both worlds. GUI -&gt; Bad That's not at all the domain of this language. I don't even know where I'd start there. You don't commute to work with a spaceship; that's about as far as those are. Embedded -&gt; OK NERVES is a thing, though I haven't used it. People seem to be happy with it. Packages -&gt; Immature/Good Hex is good, hex is not great. You can install deps from GitHub, and it has locked dependency versions built in (Looking at you from a few years ago, NPM). Unicode -&gt; ~~Not sure~~ Best in class. OTP 20 allows UTF-8 variables, though I haven't used them in real life yet so I don't know how they work in practice. Read the replies to this comment for more details on general UTF-8 string support. 
This was a fantastic write-up. Thanks!
Sure thing. I'm sure I missed a few bullets from the Haskell article, and I didn't even go into Erlang's supervision trees or soft real time (look into the scheduler and preemptive scheduling, it's great) which are the thing that makes Erlang based systems amazing. Feel free to ask my opinion on anything else specific you might need. https://github.com/happi/theBeamBook
One thing to point out is Elixir can only do embedded Linux (through Nerves) and not other sorts of embedded development.
Fair enough! I have only briefly looked into it because I do server side and don't generally have a use for embedded anything. 
You mention that the ORM is "best in class"... coming from Rails, I've been struggling to understand the thinking behind the design and use of ecto. Do you know of a good write up or resource to help me learn "the ecto way"?
I haven't gone through [this](http://pages.plataformatec.com.br/ebook-whats-new-in-ecto-2-0) book, but it's from plataformatec, so it's going to be excellent. The mental shift you need to have is the mantra "data &gt; functions &gt; macros" that the Lisp community has. Rather than structuring your application around your database, your database exists to support your application logic, and the data is the king for interacting with your ACTUAL application. Ideally, you should be able to unit test your entire code base by just shoving structs into all your business logic, with it not ever having to touch the database; it should be an implementation detail that you should be able to swap to flat files or whatever as you discover your app boundaries. Look into some of the Erlang blog posts around using mnesia or ETS tables as a backing store; they often are confused that people are as obsessed with databases as they are. I recall [this](https://www.youtube.com/watch?v=cZYatAblrdo) talk being relevant. That said, we have our Ecto layer a bit higher than I'd like and I don't completely practice what I preach in this regard. It's a constant work in progress to pull things out to boundaries. [This](https://www.youtube.com/watch?v=yTkzNHF6rMs) talk should give you ideas, and it's even at a Rails conference! Also, Changesets are one of the nicer abstractions I have used in any system, and they are pervasive through our application at work. Not having callbacks to your database calls is extremely freeing, and makes reasoning about a large system much easier. I think the thing about Ecto that is hard to see until you've been burnt by other tools is that you'll eventually hit walls with things like Active Record, where your logic is so tied up into your database that changing that behavior gets more expensive as the application grows. Pulling the database out to an implementation detail allows you to hide that from your application, and it lets you pivot extremely quickly on large applications. Schemas are JUST data. Your functions shouldn't care where that data comes from.
I love Ecto. But there are things about it that can seem off-putting to new users. The major thing that I can think of is that there are essentially two different styles of writing Ecto queries: either using the macro-based API which sort of looks like you're using LINQ (from C#), and the pipeline-based API. So something like: (from u in User, select: [u.first_name, u.last_name]) |&gt; Repo.all(query) vs User |&gt; select([u], [u.first_name, u.last_name]) |&gt; Repo.all Sometimes I feel like I should be more consistent in how I use it, but I'm not. The pipe style looks nicer and cleaner (and more Elixir-like), and for simpler queries like that I prefer it. But usually I think of these pipelines as data transformation pipelines, especially the longer they get, and that seems (to me) kind of at odds with what an Ecto query is. So for more complex queries I find myself going for the more LINQ-style query, for that reason and also just because it starts to look more like SQL when it's longer than a line or two. I'm curious how others think about this, or if others just pick one API style and use it for everything. Another thing that I find missing from Ecto, and I admit that this is probably a small nitpicky detail, is the lack of a query API that returns something like `{:ok, result}` or `{:no_result, nil}` that can be used in a `with` expression. There might be some good reason for this missing, or maybe it's just as simple as Ecto predating Elixir's `with` expression syntax. One thing that I love about Ecto are fragments. It's not something that you typically need, and in fact I just recently wrote my first Postgres CTE fragment in Elixir. It really makes it easy to incorporate almost any raw SQL into your queries without having to write the *entire* query in raw SQL. That's what I was doing previously.. I had something like: sql = """ WITH foo AS ( ... ) SELECT u.* FROM users as u ... WHERE u.id != $1 """ res = Ecto.Adapters.SQL.query!(Repo, sql, [user.id]) res.rows This is obviously super gross, but it's what I was doing before. And now it's more like: Repo.all( from u in User, ... join: f in fragment(""" WITH foo AS ( ... ) SELECT foo.* FROM foo """, ^user.id), on: f.user_id == some_other_join.id, where: u.id != ^uuser.id ) Sorry for all the `...` stuff, just trying to highlight the parts I think are interesting. I like that I can do `join: f in fragment(...), on: f.user_id == whatever`. I can escape into raw SQL for minimal parts of the query and keep using the Ecto query APIs for everything else. I could still compose my queries using Ecto without being disrupted by escaping into raw SQL, and that feels pretty cool to me.
&gt; Debug Tooling -&gt; Best in class &gt; Erlang was written for being able to debug and hotfix phone switches while people don't lose their running calls. I feel like I'm cheating when I have to debug running systems and can just inspect all the state or kill misbehaving processes. This is interesting, and it's something that I still know very little about even though I've been using Elixir for awhile. Can anyone share some good resources on debugging Elixir?
&gt; Unicode -&gt; Not sure. Also, I'll add that this is something Elixir is very good at. There's a pretty good write-up of this here for anyone interested: https://www.bignerdranch.com/blog/unicode-and-utf-8-explained/
* Handling UTF-8 - best in class, the code that handles utf strings is built directly from the spec * 3rd party libs - immature, there are some, just not as much
&gt; OTP 20 allows UTF-8 variables, though I haven't used them in real life yet so I don't know how they work in practice. Yes, Unicode is now allowed in code sources, that's a new addition. String Unicode support however is also best in class and has been since the beginning. The running joke is be cause the creator of Elixir, JosÃ© Valim, has the accented e in his name. It is one of the few standard libraries that can properly convert his name to uppercase like "JOSÃ‰", whereas Ruby among many other languages for example will produce "JOSÃ©".
That was fixed in Ruby a long time ago, I think in version 2.2? 
We only just got REPL history and break points, so I would disagree with the best in class statement. Erlangs concurrency debugging tools are very good. See Chris's talk on getting to 1,000,000 connection. 
Those are dev time. Things like observer, trace, dbg, redbug are decades old at this point and very battle tested. 
Some other nice things: * Exometer for process metrics, and VM metrics * Process managers like gproc or pg2 which let you manage systems with millions of processes * The ability to get a console on a production system and figure out what is making it unhappy
Note if you're going to do Exometer with Elixir, the best way is to use the Pinterest wrapper Elixometer. You need to do some massive dependency pinning, unfortunately, but here's a deps list: https://gist.github.com/anonymous/5a147ef2ae6806e4fe692bf7bc95ef84
Exometer is nice by itself, though, and the architecture is quite good. I am mainly using it to generate Prometheus metrics (with the very useful ability to go in on the console and get at the underlying histograms). After a couple of rewrites to make it more "Elixir style", I realized that Exometer could do what I needed if I wrote some modules for it. Architecture beats interface, and Ulf Weiger is my hero :-). I hope to release my library soon.
Also, please ignore my call to printf in the assembler 
Hey :) can you link to a more specific snippet of code, or describe what the problem is with an example?
I am new to Elixir, and I really appreciate your answer, since it's the kind of answers I'm looking to convince my team to start with this awesome language. Can you elaborate about using C bindings for numerical calculus? How can I find additional resources about this in order to get started?
On mobile, sorry for the short post. https://www.reddit.com/r/elixir/comments/66lrh7/introducing_reactphoenix_make_rendering_reactjs/?ref=search_posts Haven't tried it myself yet. It's on the todo list to play with. Also https://github.com/airbnb/hypernova
Elixir is insanely good at handling bits and bytes using its binary type. Intro: https://elixir-lang.org/getting-started/binaries-strings-and-char-lists.html Bitwise module: https://hexdocs.pm/elixir/Bitwise.html Examples of binary pattern matching: http://www.zohaib.me/binary-pattern-matching-in-elixir/ Also it might go without saying, but you can write hexadecimal numbers like in C-style languages using the 0x prefix, e.g. 0xDEADBEEF
I haven't done it myself, truthfully, but I think [NIFs](http://erlang.org/doc/tutorial/nif.html) are where you want to get started.[This](http://erlang.org/doc/tutorial/users_guide.html) section of the Erlang docs goes into interop in greater detail. 
That URL is actually correct. Note that in the `{:error, changeset}` clause you don't do a `redirect`. Here's what's going on behind the scenes: 1. `GET /users/new` 1. User fills out invalid form and clicks submit 1. `POST /users` with the form details 1. The controller sees an invalid form and just renders the `new.html` view, even though we're still in the same `POST` action. No redirect takes place. Notice if you click refresh in your browser, it will ask to re-submit the form details. That's a good hint that you're doing a POST action. Fire up the developer tools in the browser and check out the Network tab to see it all go down. Again, this is actually the correct behavior and is how other frameworks like Rails have functioned for years.
Ohhh, that makes sense. Thanks for the explanation!
Others have already posted some helpful things but I wanted to correct one misconception. The hexadecimal string parser isn't parsing into base 10. It's actually parsing into base 2 -- binary. In memory and registers the integer is just a collection of 0s and 1s. It's the debugger and logging code that is converting those bits back to a string and defaulting to base 10 as the method of representation. All this doesn't help point out the problem but more helps you understand the mechanism in more detail which might help you discover the true source of the problem.
&gt; 3rd party libs - immature, there are some, just not as much I'd agree with that. We library shopped pretty early and found analogues for just about everything, even a year ago, though not everything was designed to fit together necessarily. It's matured since then, as things have gotten battle tested and niches filled, patterns standardized, etc. It's not Ruby, but it's getting there, slowly. That all said, I find I don't need to reach for libraries as much. The OTP tooling and the standard lib cover an absurd amount of surface area, and I find I need libraries for only very bizarre things or for things like 3rd party integration (like Stripe or AWS). 
For a recent project, I chose to deploy NodeJS but only use it to render the markup. I send information about the connection (host, path, and query params) and any data that may be needed to render the markup (like stuff from database) over TCP to a small server written in NodeJS which replies with the rendered markup (or an error). You could replace communicating over raw TCP with, for example, something like Redis pub/sub, RabbitMQ, or gRPC, but the idea is still the same: send only what you need to render the markup to NodeJS and get a reply back with the markup, keeping the NodeJS server as minimal as possible. Most of the other solutions I came across seemed a bit flimsy, seemed too early to be reliable, or had drawbacks, which is what led me to take this approach instead. You can read over the NodeJS server library I build here (pretty small at 149 LoC): [https://github.com/chncdcksn/isorender-node/blob/master/src/index.js](https://github.com/chncdcksn/isorender-node/blob/master/src/index.js). It may not be the optimal or most elegant solution (and I'll probably revisit it someday to improve it), but it got the job done. :) If anyone reads over it and has any critiques/suggestions, please post them!
This article may be of help. They used react-stdio to render the components. [Render React with Phoenix](http://blog.overstuffedgorilla.com/render-react-with-phoenix/)
Thanks guys. Gave me some ideas. Here's a snippet, I'll try to explain it. Sorry it's not formatted I'm on mobile defp parse_instr(&lt;&lt;"loadi r", register_char, value::binary &gt;&gt;) do imm = to_hex(value) "1#{&lt;&lt;register_char&gt;&gt;}#{imm}" |&gt; String.to_integer(16) end This is from the assembler. The assembly it takes in is: loadi r0 #100 the idea is to take that string and encode it into a bytecode. I assigned loadi the value of 1, then the register we want to use is 0, then the imediate value is 100. I want to concatenate that into the bytecode, but it only can be viewed in base 10. So I have to print it as hex as a string, and then concatenate it, then parse the entire string as base 16. (Which is then displayed and manipulated as base 10 again anyway). I end up with 0x1064 as the encoded value which is converted to 4196 for use in my program. So then back to the VM implementation: (again sorry for the formatting) @spec decode({State.instruction, state}) :: state | error defp decode({instr, %State{} = state}) do %State{ state | instr_num: (instr &amp;&amp;&amp; 0xF000) &gt;&gt;&gt; 12, reg1: (instr &amp;&amp;&amp; 0xF00) &gt;&gt;&gt; 8, reg2: (instr &amp;&amp;&amp; 0xF0) &gt;&gt;&gt; 4, reg3: (instr &amp;&amp;&amp; 0xF), imm: (instr &amp;&amp;&amp; 0xFF) } end Here instr would be that 4196 (0x1064), but when I do those bit wise operations I don't get the correct output because it's shifting base 10. Hopefully this gives a little bit better context. 
Proliferate your controllers so you can authenticate on a per-controller basis. Don't try to overload the same controller for both reading and writing. So, for example, you might have `PostController` (`show` and `index` only) and ManagePostController (`edit`, `update`, and `delete` only), where the latter has the authentication and authorization logic. This is just a good application design, in general. Try to get out of the mindset of having exactly one controller for each schema â€“ you'll code yourself into corners like this. Instead, remember the controller is just your application's interface to the outside world. There's a really great [interview](http://www.fullstackradio.com/32) with DHH where he explains why Basecamp 3 has 179 controllers â€“ that greatly influenced how I lay out my web apps.
That....is the one thing that did not occur to me. At all. Thank you! Along similiar lines, how would you handle authorization? I just need to restrict modification to the owners of a resource. I've gotten this far, but I still need to call this method inside of each action, which makes this a stop-gap at best. def authorize_user(conn, [id: id]) do user = Guardian.Plug.current_resource(conn) cond do user &amp;&amp; user.id == id -&gt; {:ok, conn} true -&gt; {:error, :unauthorized, conn} end end
We manage permissions with [canada](https://github.com/jarednorman/canada) and [canary](https://github.com/cpjk/canary) while managing authentication with [coherence](https://github.com/smpallen99/coherence). Permissions are based on user role, action and either resource or controller and is really easy with pattern matching. You can check our work [here](https://github.com/digitalnatives/course_planner). If you don't want to use libraries and such, check canary to see how it uses the plug to intercept the incoming requests to the controller. In phoenix, you can easily implement a `before_action` with plugs.
Nice! Canary looks like it would be perfect, and it works well with some of the flow I've already built around Guardian. The way you've stubbed login for tests....is that really all you need with coherence? Because that's one of the (many) other things I've been struggling with, and that solution is fantastic. It makes me want to rip everything out and just start from scratch. I can't say I didn't know what I signed up for, learning a new language, a new framework, _and_ a beta version of that framework at the same time.
Sometimes it's worth rewriting stuff, you have the previous knowledge and your code will be way simpler. We paid the price of groundwork but missed the benefits of failing, so, again, a trade-off :)
Ah so turns out my bitwise operations weren't the problem. i had 2 problems. 1) my fetch operation incremented the program counter before actually executing the instruction. so my test program skipped the first instruction then did *loadi r0 #100* then *add r3 r1 r2* then *halt* 2) my *add* implementation used the number of the register i was accessing, not the actual value of the register. all seems to be well now. Would love any more feedback also. Thanks friends!
Was thinking about creating an elixir client for hypernova - https://github.com/airbnb/hypernova Seems like an elegant way for SSR of react, separating node from the elixir server if necessary
I'd say it's too soon. A lot of the duplicate code can be moved into ordinary functions. Some specific notes: * Do you have control over the `prices` before they're passed to your functions? If so, you should "correct" them before your function is called, thus eliminating the need for one line of code in each of the up/down functions * `case` is unnecessary here; you can pattern match in the function arguments. For example: def calc_low([cur | next], nil, count), do: calc_low(next, cur, count + 1) def calc_low([cur | next], low, count) when cur &lt; low, do: calc_low(next, cur, count + 1) # ... * I'd turn `number_of_periods` into a `num_periods(prices)` function, then call that directly in the math you've got going. That eliminates the other repetitive line of code from each up/down function. At that point, you'd be much more ready to try using macros to generate the up/down functions. I'd still consider it to be overkill in this case, though.
I agree with /u/northrupthebandgeek that this is not a good use case for macros. However, I'd take the "pattern match in function arguments" a step further and note that you can use Enum.reduce for this, and pass the reducing function as a parameter to a generic calculation. Other style notes: I try not to use the pipe operator for just one call. "count prices" reads more like most languages than "prices count", unless you are all into RPN or are a fan of how Yoda speaks ;). I took a rewrite of this as my morning kata, here is what I came up with: https://pastebin.com/8n7rbjNm There is no repetition anywhere, and I believe it is immediately clear from reading the code what that the difference between up and down is. It is around half the lines of code of the original. For me, this is one of the fundamental differences between declarative and imperative programming. With declarative programming we're trying to describe what we want to do, rather than give a list of instructions telling the computer how to do whatever it is we want it to do. So while in your code you have a list of things for the computer to do, in the version I wrote I tried to instead note what I wanted done: reduce the prices to find a period; the definition of the extremas (the anonymous functions in up and down). The delta/2 function becomes the only place where the code is telling the computer which steps to take in which order, and that's just 5 lines, which are the core of the computation. And really 3 of those lines are for readability rather than actual "instructions" per se. hth ... edit: clarification on the core idea that shaped my rewrite
Wow..just wow. Thank you so much for your reply. I'm definitely impressed by your rewrite. I thought of using reduce but I just couldn't think of the best way to do it. How much elixir experience do you have?
Thanks for your response. I didn't think about pattern matching in the function arguments. Thanks for that tip! You also made me realize I need a better way to handle the reversing of the prices because I don't have control of what is passed in but I assume it will be earliest-&gt; most recent but that may not be the case that the user has.
Been using it for a couple of years, and before that erlang. Both at home and work. My primary background up until that point was object oriented languages, inc lots of C++. IME the initial step into Elixir is pretty straight forward thanks to its syntax, consistency and tooling, but really getting a deep feel for the language takes a while. Not unlike any other langyage/framework really. Keep practicing and things like reduce will soon be second nature :)
Ah ok. I have a few months experience with Elixir and then dabbling with other functional languages. I've used reduce before, in C# too, but not to the extent you did. That's pretty awesome. Thanks for creating a code sample as well as teaching me something new today
Check out [Bodyguard](https://github.com/schrockwell/bodyguard), with the full disclosure that I'm the author. :)
Hardly ever you'll find a use case for macro. Avoid them as much as you can.
Hey :) here is the link to supervisors article https://medium.com/learn-elixir/supervisors-and-workers-in-10-minutes-83fbad6f16d1?source=linkShare-8553b3a3d54-1500307080 Feedback is welcome:) !
You can do `plug :authorize_user, [id:id] when action in [:index, :show]`
I would have gone a step further to show why. For example: somefunc(name: "help_computar", is_helpful: false) Can also be written: somefunc([name: "help_computar", is_helpful: false]) Both are actually represented as: somefunc([{:name, "help_computar"}, {:is_helpful, false}]) Edit: Code formatting
This is nice, especially the tying of permissions to contexts. Very 1.3.
This is a great rewrite! I love the idea of solving someone's problem/helping teach with a daily kata too. It's a pretty elegant seperation of pieces also, but I'm left wondering if there's a cleaner/alternate pattern for the `starting_state = {nil, nil, nil, f}` mirroring the first clause of `reduce_period`, `def reduce_period(value, {nil, nil, nil, f}), do: {value, 0, 1, f}`... I think I see why you did it that way, but curious if you or anyone else have an alternate pattern there. It's arguably "not DRY" but obviously that's not a real/practical concern, it just feels like a minor aesthetic wart in this otherwise beautiful refactor that feels like an itch... I might try playing with myself, but just thought I'd see if it bothered anyone else or anyone else had a good alternative.
that is also my least favourite part, so it is probably not just you ;) and looking at it again I can see a nice way to get rid of that clause altogether. want to give it a try? If not I can update the paste... but I think passing the code around is more enjoyable, to see how others tackle it... 
I had an idea how to, but wasn't 100% sure it would work, so will try to, but at work now where I feel bad enough spending time on reddit, but will try and take a crack later
cool.. looking fwd to seeing your revision!
Also, non-sequiter, I'm excited about your auth-pipe library, I currently have a funny-requirement situation for auth in my side project [OpenPantry](https://github.com/MasbiaSoupKitchenNetwork/open_pantry) where I might give using auth_pipe a shot, or if you're interested in getting involved would love to see your take on using it in place of the current weird Guardian thing I'm doing with JWT's and a basic auth for admin....
It's often recommended to use maps instead of lists when passing options like this. One reason is that when you use a list, the arguments needs to be in the correct order which could be annoying since they are "named" with the atoms anyway.
I'll take a look at OpenPantry when I get a chance .. probably will have to wait until later in the week .. I'm finishing up the next episode of Exploring Elixir tonight (delayed as I had to debug one of the libraries being used in the episode .. oy veh!), and then there is the usual day work .. but certainly interested in looking at more real-world use cases for AuthPipe. I mean .. the reason I'm doing it is because I am not happy with the current options, and I'd prefer to not create another option that doesn't satisfy :) Looking at projects that are in need is probably a good way to help make sure of that.
&gt; Are variables in function parameters assigned once and hold their value across each parameter and then re-assignable within the function? Awkwardly worded, but yes. This is part of the parameter pattern matching in Elixir. It's also the reason you can have something like this (at least for primitive values): def same?(o,o), do: true def same?(_,_), do: false The pin operator is used within the function body instead of the parameters, since you can reassign values within it. Edit: changed variable name, since the code example looked like it had a dead owl in it. Now it's alive :)
Thanks, I did not know that this was allowed. 
I agree that they aren't the "go to" solution in nearly all cases, as there are usually better solutions (as in this case), but metaprogramming can be insanely useful. Some examples: You can create the equivalent of mixins with macros due to the __using__ macro. See here: https://yos.io/2016/04/24/mixins-in-elixir/ You can perform calculations at compile time rather than runtime. This is fantastic for memoizing expensive to calculate but otherwise constant sets of expressions. You can create simple (or .. not so simple) DSL's which can give greater expressiveness and readability to your code. Just look at what Plug and Ecto manage to do with them, i.e. So, yes .. they are not the solution for everything, I agree. But I wouldn't recommend avoiding them. In the right places they are absolutely awesome. (Especially since Elixir's macros are hygenic.)
OK, here's what I had in mind, and quick tries with fake data show same results.... https://pastebin.com/vmz1LeNN
Yeah, I haven't been totally satisfied with the two sort-of-polar-opposites of Coherence vs Ueber/Guardian, though I haven't tried Coherence yet. OpenPantry may eventually want/need a more standard auth solution, but we need to serve people without email addresses including the homeless etc, so we want a flow for Admin's to just identify someone and log them in on a tablet etc, but also be able to email links to people who DO have email addresses to do their selections ahead of time. We're also hesitant to collect any more PII than we have to in the system, in case any tries to use the system to get info on anyone undocumented who may be getting food from a pantry using our software, though that will probably be a per-pantry decision and we just want to support flows that don't require email or other PII, not necessarily require they're the only way to go.
Nice! It's very similar to what I was thinking: https://pastebin.com/9mAQGKNa The only real difference is I put it in the function header, which removes the need for the is_list guard. I also added a function header for the empty list to be on the safe side.
When visiting the repo, I noticed what your organization does, and I have to say it's fantastic. World needs more good in it like that. I also really respect how you are considering privacy and personal security. I'll definitely be taking a look later this week :)
Ah yes forgot about empty lists :-) though aren't you undercounting periods now because excluding head of list?
Technically it's not "my" organization, just a pro bono side project for me, my friend/collaborator Thia is an employee, and they pitched the project at Recurse Center where we're both alums... The hope is for many other organizations to use it, so wherever you are, if you have small-to-medium size local food pantries/food banks that might benefit, we'd love a warm intro, as I worry we'll overfit to Masbia if we don't get other organizations involved before too much further along. We're also working/hoping to work with means database to integrate with them and test with some of their pantries, but we're at an early stage of user testing at the moment. We'd love to have you and anyone else in th community involved!
Kinda, sorta, not really, it depends. The Access pseudo-protocol is implemented for keyword lists already, so this will always work: opts = [foo: 1, bar: true, zaz: "b"] IO.inspect opts[:zaz] # "b" And of course you can just use the [Keyword module](https://hexdocs.pm/elixir/Keyword.html) directly. Order matters very little in the end. The main thing with keyword lists (or proplists, in Erlang lingo) is that they are lists, so any access operation is essentially a list traversal, which is theoretically slow, but in practice, since options lists are usually very short, this barely matters. Also keyword lists are much more space efficient, and generate much less garbage when used. Finally, keyword lists are already used everywhere in the Erlang ecosystem, so I suspect that the Elixir devs chose to make the syntatic sugar like that so they can give some sugar when interoperating with Erlang libraries and because in the end it matters very little in terms of performance and usability. I prefer to follow the leaders in this case and just use keyword lists, and have prettier code.
This is why I couldn't get into Elixir. While others couldn't get past Lisp's parentheses, I couldn't get past Elixir's "optional" syntax.
i see the pin operator as a "don't rebind; pattern-match" so you're right that it makes less sense when not used in argument lists. I wasn't a huge fan of it when I first learned about it but I have just gotten used to it I guess. The ability to re-bind names within a function (unlike Erlang) is why this "syntax hack" was needed I guess
it is creating the same initial state, it's basically just the loop unrolled once 
Sorry, I may not have been clear... the Enum.count in yours is counting a size one less than it was in your first refactor... the output is different... though I also just checked against the original, while comparing ours, and the original may have a bug, or else is otherwise different from both of our original versions... http://elixirplayground.com?gist=810b03f848a28c9577dd3f0718fb5d07 (or the gist if its easier to read https://gist.github.com/elixirplayground/810b03f848a28c9577dd3f0718fb5d07 )
ah, could well be. didn't rerun my test data after that last change. and yes I think the original code has a few subtle bugs in it. many matching conditions can be hard to reason about ...
Yea, I was unaware of this nuance. Do you have any other possible quirks that you encountered when learning Elixir?
That's pretty much it. Everything else is internally consistent. It's functions and pattern matching all the way down :)
&gt; is why this "syntax hack" was needed I guess Yes, that is exactly it. It is a downside of rebindable names in a pattern matching language, and is also on my "Elixir warts" list .. which is thankfully pretty short. Another is variable scope leakage in with/for .. see https://elixirforum.com/t/elixir-version-of-a-safe-navigation-operator-navigating-nil-in-maps-structs/6023/12 for an interesting discussion of that. But yeah, rather few annoyances over all compared to what else is out there. 
I misunderstood what the author of the article was saying. I thought it was about when _defining_ a function. My point though, was that you shouldn't do this: def foo(bar: bar, baz: baz) IO.puts bar IO.puts baz end you _must_ call it with the arguments in that order. The following will not work: foo(baz: "baz", bar: "bar") but this will: foo(bar: "bar", baz: "baz") This can be confusing for people coming from Ruby for example. In Ruby the order of named arguments does not matter. If the order matters, the atom names are kind of redundant to me. You can just have regular arguments then :) If you want "named" arguments you should use a map: def foo(%{bar: bar, baz: baz}) IO.puts bar IO.puts baz end But you can use a list for other options (which is what the article was actually about I believe :) ) def foo(%{bar: bar, baz: baz}, args \\ []) IO.puts bar IO.puts baz IO.puts args[:blargh] end
I agree it is kind of hard to grasp intuitivly. A lot of thing fell in place for me after reading "Programming Elixir". The optional syntax is kind of inspired by Ruby I think, so easier to get if you come from a Ruby-background.
https://github.com/joshnuss/xml_builder
Have you used this in conjunction with sweet xml before? Does the xml produced in xml builder deserialize nicely in sweet xml?
Of course, it's list of tuples :)
In phoenix, for example, `render` function accepts list of tuples as the last argument, in phoenix guide, author used such syntax, and this is reason why I started to investigate what's going on :)
https://www.reddit.com/r/elixir/comments/6ntzwk/til_you_can_omit_parenthesis_when_passing_lists/dkdlf3g/
"developers developers developers" - Ballmer
Can you elaborate on education and ide? I'm interested in improving both - and i started writing articles about learning Elixir and also I am building Elixir IDE on top of Vim (obviously not most common editor:) but good for now
I'm not a huge fan of this optional syntax. That confused me for so long when I learnt elixir For instance ["Content-Type": "application/pdf"] # Looks like [{"Content-Type", "application/pdf"}] # But it's [{:"Content-Type", "application/pdf"}] # And it's hard to differienciate a list from a tuple ["Content-Type", "application/pdf"] ["Content-Type": "application/pdf"] # Much easy to recognize and more obvious for a beginner [{:a, "Hello"}, {:b, "World"}] [{"Content-Type", "application/pdf"}, {"Content-Length", 0}] Like ruby I liked this "short" syntax at start. But it makes things harder to recognize and I ended up hating it. 
I kind of agree, I don't like (actually at first really hated) this kind of syntax in Ruby too. Was one of the most confusing language features for me, and especially makes DSLs appear more magic than they actually are (in Ruby). I guess you get used to it though, but for beginners it's certainly a very potent source of confusion.
Just waiting for Elixir#. 
I'd love to see more of these!
The functional influence comes from the plug library that phoenix builds on. The HTTP request/response state is represented by a Conn struct. Plugs are essentially functions from Conn -&gt; Conn. Phoenix Endpoint, Router and Controller are all plugs. You can even route to a plug module instead of a controller. For simple API servers not requiring web sockets or HTML views, you can build the whole thing with just plug and Ecto to get a better understanding of the foundation.
Phoenix is an archetype of Elixir code. It is clean, concise, and well-modularized. The only difference between writing code for a Phoenix app vs a non-Phoenix app (with maybe the exception of Channels) is that one is not require to know anything about Processes or OTP to effectively use the Phoenix Framework. One of the things I've noticed about Elixir is that there is not a lot of jargon in the community about functional paradigms such as currying, functional purity, partial application, etc, etc. etc. In my opinion, most of these concepts are not valuable when one has real-world considerations to contend with (i.e. deadlines, feature-requirements). That being said Elixir is more than capable of (and in fact excels at) handling the requirement of statefulness. Some tools for handling state in Elixir are: [GenServer](https://elixir-lang.org/getting-started/mix-otp/genserver.html), [Agent](https://elixir-lang.org/getting-started/mix-otp/agent.html), [ETS Tables](https://elixir-lang.org/getting-started/mix-otp/ets.html), and [Mnesia](https://elixirschool.com/en/lessons/specifics/mnesia/). After using Elixir for a few years now I can honestly say that the only reason I use other languages to accomplish anything is that there are some requirements that have not been met by the Elixir ecosystem. For example, machine learning; If you require machine learning, you're probably best using Python for that part of your app. However, I would not switch part of my app to Python simply because I needed statefulness. At the end of the day each dev must maintain her/his own code. So if you think your app would be better suited to use Java or Python in places then use Java or Python in those places. **TL;DR Elixir handles state well, but use what you are most comfortable with.** EDIT: Your vs You are
As for state management, check out Ecto Changesets and Ecto.Multi. These separate the process of constructing the commands that need to be sent to the database from the execution of those commands, allowing you to push the side effects to the edge of your program, rather than having state modifying operations scattered throughout the code.
I need it too! I'm writing an api library wrapping XML (not SOAP). - I may use different library for parsing and serialization, but I want to have single representation for two way conversion. When I wrote it in Go, all conversion info is in struct tag, and I can just use std lib xml methods to marshal or unmarshal. 
&gt; Phoenix framework looks like any other framework in OOP based languages. .. -ish &gt; defmodules are used like classes and functions as class methods. This is because processes are quite similar to objects: they encapsulate state which the code run inside the process can access, and which code "outside" the process can only access via whatever public API the process provides (via message passing). With the ability to call functions on modules (including defining interfaces via behaviours) you get something that looks a lot like objects and classes, but which are different (and imho rather better) in a few subtle ways. (In a rush atm, no time to write the required small novel here .. :) &gt; But if I were to use the languages that they are based on, would it be wise to use elixir for scalable, &gt; functional parts while use Python/Java for stateful parts (database, authorization, administration etc) No; and the reason is simple: every language you add creates a new surface which data must cross between; it means one more design driven by a different architecture for you to keep in mind as you develop. All of this increases impedence and lowers productivity. Elixir does state absolutely fantastically, moreso thant he options you mentioned, btw. Not only do you have processes that can hang out quite cheaply in memory to hold state, but you have ets tables which are essentially a built-in redis and a variety of state-managing tools like Registry and Ecto. I highly recommend building your application(s) completely in Elixir to reap those benefits and the benefits that come from being able to effortlessly and efficiently pass data (state) around "natively" (no serialization, middlemen, etc). It also keeps your testing story simple: one set of suites to run :)
Don't you interested in doing work like [this](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md)? I want it, but sadly I don't know elixir well.
I would create structs for each of the data contracts. I dont know if it is the correct way of doing it in elixir, but it makes your code easier to understand, and thats always nice..
I'd recommend using embedded ecto schemas. Structs give you a a structure and enforce_keys but no method for managing types and casting of values. Using Ecto.Schema to define the structs gives you changeset and validations which is nice... but it also gives you cast which will be huge in converting JSON to the correct types.
One more vote for structs. Returning a HTTPResponse would be a partial solution. Also, I would suggest using Structs for inputs, e.g. when a user wants to create a customer, they should be using a struct from your package to create a customer, this stops the users from making all kinds of errors.
can you share your repo with us?
I haven't looked into Ecto.Schema yet. Does it require a database or form of repository to use?
Yep, this was another reason why I was wanting to do it that way. It becomes self documenting in a way for what the inputs should be. Edit: I've looked into it and it does look pretty nice. There wouldn't really need to be any client side validation as it's all handled by Xero's API server side, but being able to define the types of the fields would be awesome
Nice! I was thinking about rebuilding a very simple site for a small association I'm part of and was probably going to use Jekyll. I'm currently learning Elixir, and don't feel like taking time off from that, but now I might be able to combine the two. :)
I am very happy to hear that :) Glayu is far to be as mature as Jekyll, and it is still a work in progress. Some pending features are a dev server, and the hability to suport multiple layouts per post or page. But I am sure it will do the job. It is my first Elixir project too, so there are a lot of things that could be done better. I am really enjoying working on it :) In case you use it, I will be happy to give you support with your site.
It's private commercial project :(
Ok! Impressive that you are doing this as a first project! It will surely suffice as I will keep the site as minimal as possible, and it would not take much be a vast improvement over the current site. I might be trying it out within a week or so. Very kind of you to offer guidance if needed, I will try to get the hang of it without bothering you, but might post a support request if I encounter something I can't get my head around.
Great :)
But i may do some live streaming of writing pubsub in Elixir. Not exactly the same, but shares same ideas. For now follow me at medium https://medium.com/learn-elixir as I'll post announcements about streaming there.
You won't need to define a repo or database connection, but it will bring in the poolboy and decimal packages as dependencies. Another alternative is to define dialyzer types for each struct and put a typespec on each function. This makes it clear to the user what is expected in each field, and they can optionally use dialyzer to statically check it.
Installed. Love it. 
&gt; GUI -&gt; Bad &gt; &gt; That's not at all the domain of this language. I don't even know where I'd start there. You don't commute to work with a spaceship; that's about as far as those are. It's worth noting that that you can build GUIs in elixir. Erlang has the wx module (wxErlang even includes support for OpenGL), or there's some other GUI wrappers available. So if you ever need to build a simple interface to one of your applications, then it's not so bad (think of something like the observer tool). For building a standalone GUI application, I wouldn't recommend it, but it certainly is possible. A good project to look at is the 3D modelling application Wings3D which is built entirely in Erlang. The only place where it's definitely ill suited (because of the underlying VM design), is with realtime graphics. Because you can't be certain when your code is going to be executed, you can't optimally make use of the CPU and GPU. While you could certainly do it, you're just not going to be able to structure it as efficiently (you'll have sub-optimal utilisation of the CPU/GPU, compared to something like C where you can know how they'll be utilised and so optimise you code accordingly to make sure they're always busy doing work and minimising stalls). 
I installed this and really like(d) it. What I don't like is that it replaces the 8 most recently viewed websites, a feature I use very heavily. Is it possible to have both? 
&gt; One of the things I've noticed about Elixir is that there is not a lot of jargon in the community about functional paradigms such as currying, functional purity, partial application, etc, etc. etc. In my opinion, most of these concepts are not valuable when one has real-world considerations to contend with (i.e. deadlines, feature-requirements). While I agree these things are not mentioned as much, I believe thats slowly changing. Elixir doesn't require these things as forcefully as other functional languages, allowing developers to experience them when they're ready. I disagree however that they have no value, but they are difficult to learn and do get pushed for the reasons you mentioned. I think Elixir strikes a decent balance however allowing you to decide when to keep your functions pure and when not to. The general advice I've seen is to limit side effects as much as possible, not to not care about them like other languages might do.
.
Hi, Thia here! Thanks for your comments and thoughts! I got hired to a Soup kitchen called Masbia after volunteering for them for a while. They're a pretty interesting place to work it is amazing how political trying to feed people ends up becoming. The bright side of being in the position I'm in is I was able to start this open source and I'm doggedly determined to keep it that way even if a SAAS model happens eventually. Maybe something along the lines of Odoo's model where anyone can host their own version, or you can rent an instance on ours if desired. We're one of the larger organizations in NYC in terms of meals provided and several different locations with wildly different clienteles and methodologies. One is a preschool where we're testing this system at the moment. that may shift to a delivery method of fulfillment, another acts almost like a shopping experience. a third and our main location at the moment is more the standard wait in line get a uniform package system. Our fourth is being renovated and will be almost independent of the soup kitchen attached to it. Currently though we roll up with a van and disburse meals and pantry packages from essentially a pop-up. We're currently rolling out the plentiful app (http://www.plentifulapp.com)in our locations (2 down, 2 to go). We are in discussion with them to integrate and let their client management and scheduling database drive connection to these orders. That's about a year out.. So, for the moment that's where things lay. I can think of about a billion things that need doing, and getting time to do them all is very hard. Lately, I seem to spend 70-80% of my time dealing with managerial issues and various operations management. Speaking of which while my boss is gone and things are a bit quiet, I'm gonna go and figure out a sass thing I've been meaning to fix on this ^_^...
Some details about the chapters and content in this [Elixirforum thread](https://elixirforum.com/t/phoenix-inside-out-series-of-books-booklets-self-published/5473). No connection to author - just a happy customer. 
I've been dabbling on and off with Elixir for just over a year now. My background is PHP and more recently JS. I believe the JS knowledge I had helped, and has been improved by learning Elixir. For learning Elixir, predominantly I have used Exercism, which I cannot recommend highly enough. I've been through the 'Programming Phoenix' book, along with the docs from the website. I find Phoenix conceptually hard to work with, though I am confident a huge amount of productivity and power lie beneath the surface. Like anything worth learning, I've resigned to the fact that truly understanding it is going to take me a long time. Others learn faster, and that's ok. I took a step back (in February this year) and considered why I was finding Phoenix so challenging to gel with. I concluded this was because I didn't know Elixir well enough. If I were to switch from Symfony (PHP) to Spring, I would fully expect a similar outcome - first learn Java, then learn Spring. I see others suffer from this fate all the time (let's learn React without knowing basic JS as an example). All of this is a roundabout way of saying - for me - trying to get myself to an intermediate or ideally greater level of proficiency with Elixir is goal #1, and then from there Phoenix should (hopefully) be much easier to learn. 
Phoenix isn't going to teach you FP if you don't actively practice it alongside learning a framework. Try building some simple thing using Elixir without a framework. That definitely helped me.
I had exposure to functional programming prior to learning Erlang (and subsequently Elixir), so I have a different way of looking at it. Elixir is actually quite light on the functional concepts (compared to some of the other languages in this paradigm), the real complexity lies in the VM and OTP. For the language itself (if that's where you're struggling), first get comfortable with pattern matching, as that is absolutely crucial to working out how to implement your logic. The other functional concepts (recursion, immutability, etc.) shouldn't be too difficult to pick up. The next area that needs a lot of focus is then OTP. 
The switch wasn't that hard and it was a very "fun" experience at start, learning a new way of doing things. It felt like learning how to program from start again. The main problem is the fact you will try to "translate" OOP concept into elixir and obviously it won't work. You have to put aside everything you learnt in OOP before trying elixir. But don't try to jump on Phoenix without learning elixir first. This was a mistake I did and it was hard to figure out how things worked internally and how to test things. Try to experiment with elixir first with small project (learning how macro works helps) and then try phoenix. 
I did a short course in F# before picking up elixir so my switch wasn't that hard. As long as you understand how to write recursive function it shouldn't me too much of a pain. 
Purchased! Thanks =)
&gt; defmodules are used like classes and functions as class methods. Not really. Think of modules as just collections of functions. This is an important distinction because classes are blueprints for objects, which are often stateful. You don't instantiate modules; they're just a means of organizing your functions. The concept is similar to Python and JavaScript modules.
Thanks to this post I've just bought the complete edition and are looking forward to checking it out.
Bought! Thanks for the tip.
http://exercism.io/ has Elixir exercises that helped me learn FP really well. 
I'd recommend going through Programming Elixir to get a feel for how functional programming works in Elixir. It's somewhat different from other languages since it's not strictly typed like Haskell or other ML languages. It's probably closer to Lisp, with a sprinkle of Ruby syntax.
I bought one too!!, Finishing Elixir-Udemy and this is one is going to be next. 
I finally got around to trying out Elixir+Nerves and made a Phoenix+Nerves application that now serves as a garage door opener I can access from my phone https://github.com/MainShayne233/garage_door_opener
I had some experience with F# but not with any pure (side-effect free) functional languages. [This](https://dc0d.github.io/2017/03/24/elixir-to-start-with/) is my experience with learning Elixir. Starting with Phoenix would not help. So I decided to write a Telegram Bot. I do not use Elixir in production yet (mostly Go these days). But from bits that I've written, I could say Elixir makes things a lot simpler: * Amazing task and dependency management tool, the *mix*; * Immutability actually makes things far more clear, there are no actual magic there because nobody **can** change things; * Application structure is far more clear, you do not have to get *creative* (*reinventing the wheel*) about app structure, on every single project as we do in many other PLs; That was my yet little experience with Elixir so far and it seems that it is going to find it's place among other tools in my toolbox.
I have a PHP / JS background but my switch to Elixir / Phoenix wasn't that hard... because I learned Elm just before, and THAT was painful, as Elm is pure, typed and sometimes I felt that I was doing more theory than code :) To grab Elixir / Phoenix, I've read Programming Elixir and Programming Phoenix and done most of these books exercises. They allow you to get good practices and understand FP (the Elixir Way, though). When you have to code the `reduce` from sratch, you need to understand what you're doing. And code kata is good for health!
Just when I think elixir can't get any better....
&gt; Moon.Juice.Sex.dust/3 FTFY
No docker-compose? I think it beautifies the process a bit.
https://github.com/vic/params Found this too. It's a wrapper around ecto schema for this 
Brb learning me some Elixir.
I'm kinda worried about what Moon Juice Brain Dust is.
JosÃ© Valim's next business venture!
I thought ads were relevant to your search history.
Busted for looking at moon fairy porn ðŸ˜±
I think it's some Gwyneth Paltrow backed ridiculous mineral smoothy powder that's supposed to give your brain some energy or whatever. Yes, I watch too many Buzzfeed videos.
The big problem with this approach is you end up with a 700mb docker image. I recommend instead using https://github.com/Recruitee/mix_docker to build the image, which will end up being closer to 30mb.
Does anyone have a guide for building docker image for an umbrella app with Phoenix 1.3? 
Will port my buildtool [MBU](https://hex.pm/packages/mbu) to use [file_system](https://hex.pm/packages/file_system) instead of `fs`, as the latter does not have good Elixir compatibility. Also working on a major revamp of my site https://codestats.net/ but that is taking ages and ages it seems.
I'm working on [Taex](https://github.com/jhartwell/Taex). I was refactoring and my Mac got a little shower so I'm back to where it is now. I plan to use the library for a algorithm forex trading platform I'm working on
I have been working on implementing a rust library for reading and working with BEAM bytecode in the last couple of days. As far as I know the BEAM bytecode is mostly undocumented, so this might serve as a easier to read kind of documentation than the otp source itself. It can also generate pretty neat visualizations of the control flow of the bytecode, which might help others understand how the bytecode works. [Generated CFG graph for `Enum.reduce/2`](https://drive.google.com/open?id=0BxacSJTw6Pf1S3dtWWF1ZTZVcGs) [The library itself](https://github.com/hansihe/beam_code)
Really boring Phoenix API for my Windows app (will also be Android &amp; iOS eventually)
A phoenix app that uses [Toniq](https://github.com/joakimk/toniq) to upload videos (a lots of videos 500+) on multiple video platforms (Vimeo, Vid.me, Youtube and Dailymotion). This is a perfect use case for my new favorite toy elixir :). Here is [my youtube worker]( https://github.com/Grafikart/video.grafikart.fr/blob/master/lib/youtube/worker.ex#L15) **Spoiler alert :** Upload quotas are a pain to work with, and I have to delay upload tasks for weeks...
Not that hard after reading Dave Thomas' book Programming Elixir. Very recommended. But also, I had been reading up on FP concepts for a while, and was trying some out in Ruby, and liked them...
This is the type of thing I've been looking for. Thank you.
Been back to working on my Satellite tracking/prediction app thanks to some new life being breathed into it from /u/schrockwell!
Oh, cool! I finally got 2 ICOM radios rigged up here, but MacDoppler only supports doing one radio at a time, so I was planning on writing a little Elixir CLI app to automatically do the doppler shift for 2 rigs at once. If you can find a good way to calculate the radial velocity from a given observation point we should be golden (I think this might be as simple as using the ECI-to-ECF coordinate conversions on the velocity vector).
/u/dplummer is right I've got updated Dockerfiles for Erlang 20 and Elixir 1.4.5, with some minor tweaks: - I'm running behind a very conservative corporate proxy so I added args for making mix and rebar work through a proxy rebar was particularly tricky, there's very little documentation about it - some of the erlang packages need `make` to build (for example `idna`), so I added `make` as well I've also added some more tasks like `docker.deploy` to transfer your release image to the server and `docker.run` to start the image remotely RemindMe! Tomorrow 
I will be messaging you on [**2017-07-25 09:00:00 UTC**](http://www.wolframalpha.com/input/?i=2017-07-25 09:00:00 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/elixir/comments/6p1dhl/how_to_use_elixir_with_docker/dko5t3h) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/elixir/comments/6p1dhl/how_to_use_elixir_with_docker/dko5t3h]%0A%0ARemindMe! Tomorrow ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dko5tx0) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
The video explains it really well, thanks for sharing.
Does Frank Zappa have any grandchildren? 
A few quick ones: 1. All the failure conditions are not being handled 2. You can use `URI.encode` instead of the `String.replace` for spaces 
Changelog with more info about new things: https://github.com/elixir-lang/elixir/blob/v1.5/CHANGELOG.md Especially excited for the IEx breakpoint stuff and exception blaming. Good job Elixir team!
Please use the release announcement instead of the GitHub link: https://elixir-lang.org/blog/2017/07/25/elixir-v1-5-0-released/
Exception blaming on NoMatchError with extensive details... YES PLEASE
I've done a little programming in OCaml and have read about functional programming over many years. I'm using exercism as well. I don't know whether it's teaching me to program exactly. To me, they are puzzle problems, but that's OK. Puzzle problems are still problems, and forces you to think about stuff. I think it's useful I know map, filter, and fold and can use that as the basis of doing stuff in Elixir. I bought the Elixir course at Pragmatic Studio, and that isn't too bad, though I haven't looked at the latest few lessons. I think what's been challenging (so far) is that I'd normally start writing a class, and I'd have a good idea of what libraries I have to use. Most FP languages like immutability so you're generally passing structures (for me, it's usually Elixir maps) as arguments. My initial suggestion is to learn how map, filter, fold work (maybe zip) because these often form the basis for processing lists in functional programming (rather than the usual looping mechanism). Also, Elixir seems big on using its pipe mechanism, so try to use that more.
I'm looking into how GenStage can help with better batching data being imported into [PryIn](https://pryin.io). It's using an Elasticsearch backend and batch size has quite a big impact on performance, so this could be really useful.
I've recently released [Recipe](https://hex.pm/packages/recipe), a library that helps building side effect rich workflows. Some basic ideas: - isolated, testable steps - compile time checks for a recipe structure correctness - built-in instrumentation hooks Docs and source links are available in the package page. The repo has also a few examples that show some different ways you can use the library.
Maybe JSON Schema is something that you can use for this. https://github.com/jonasschmidt/ex_json_schema
/u/Swanros link is bork! 
To be honest, both are nice. I probably would not have made the effort to learn Elixir if not for the stellar language design AND performance. If just had one or the other I (personally) would probably not be motivated enough to make the transition. I agree language design is the most important of the two though.
I thought about the same when I was first introduced to Elixir/Phoenix as well. But that's kind of the bait. Without the niceties that other frameworks have, it's hard to get people to "think differently". Same for Elixir with the ruby-like syntax I think. Instead of reinventing the wheel, they use the wheel and build on top of it. The "new way of thinking" that you are looking for comes with more maturity and time when you look into what BEAM and the abstractions Elixir/Phoenix provides to make that easy to use. I often say to people interested in Elixir: You come because of Elixir, you stay because of Erlang.
Youâ€™re right in one aspect, Phoenix is another web development framework focused on developer joy. Whatâ€™s important to know is the Elixir/Erlang actor model (and OTP framework) will change the way you think and build highly concurrent systems. Phoenix does all that work for you, so you can theoretically not deal with it. If you want a new paradigm of thinking, start with learning Elixir first, not Phoenix.
Many new frameworks make the mistake of improving one aspect, but neglecting things that already worked well or are already solved in others. Ruby on rails (for example) is great when it comes to early productivity and canned solutions for common problems. It has issues though. The good thing about Phoenix is that it solves a lot of these issues, but does not lose the good parts like productivity or ready to use solutions. Also the stability and simplicity of Phoenix is imo unmatched by any modern frameworks of similar scope.
&gt; With all the hype from Phoenix I thought it was going to present us with a new way of thinking and solving problems. If the hype is the full extent of your knowledge of Phoenix, you're left judging it on the shallow similarities to other frameworks. 
old link is broken: http://engineering.teacherspayteachers.com/2017/05/24/a-refreshing-tonic-realtime-updates-with-phoenix-channels.html
In the described case, there's no need to leverage `docker-compose`.
Stay tuned! I will post it here soon.
&gt; This guide was created for CircleCI 1.o version which does not officially support Elixir. If you want to see configuration for 2.0, please visit the official CircleCI documentation for Elixir. Bit confused (and unfamiliar with CircleCI) if they support Elixir with v2, why would you setup with v1??
I also said that I'm starting playing around with this framework and these are my first impressions. I would like to know more from people that already learned something.
That is exactly it! I'm going because of Elixir but Erlang will be always in my heart.
Did you create or follow any interesting Elixir repos?
V1 is more plug &amp; play with a lot of assumptions about your project and (because of all this) easier to setup. V2 is Docker based (afaik) and you have to enable &amp; configure each tool/checker in more verbose ways. 
Well it's hard to explain concisely what the real seller is, but the main attraction when you're coming to Elixir is that it's a process oriented language. This means that a lot of the task queuing and asynchronous pains of other languages are much more manageable.
ah right, thanks :)
I've done a blog post about using v2 for Elixir: http://blog.12startupsin12months.in/2017/06/16/how-to-setup-ci-for-elixir-phoenix-using-circleci/
Docker multi-stage builds work quite well too. Use the official elixir image to build a release, then copy the build output into a vanilla alpine image in the second stage. 
Lots of good reasons to love elixir. One nitpick: &gt; You have to specify a view by name and explicitly pass parameters to it: Not quite - Phoenix View module names are inferred from the controller module name (unless you explicitly pass an additional parameter to render), but the template is passed explicitly.
Haha now that's what I call back pressure! ðŸ˜„
I highly enjoy Elixir itself. I don't think Phoenix will be the last word in Elixir web frameworks. You could write one easily in Plug, for example. Macros, sigils, pattern matching, immutability, all fantastic
1.3-release today? :)
not sure. I haven't seen any news so far.
I'm using Guardian with Phoenix 1.3.
I keep getting a conflict when deps.get'ing claiming that guardian requires 1.2.
Try doing: defp deps do [{:phoenix, "~&gt; 1.3.0-rc.3", override: true}, {:guardian, "~&gt; 0.14.0"}] end Edit: Or whatever the latest version of Guardian is. That's just what's in my mix.exs file right now.
Yes, but: Your Phoenix app can be an application next to your other microservices and they are ALL supervised. So.instead of cramming everything under your Phoenix app's supervisor, the services can (and should!) be written as their own Elixir components ("applications"). They can share a supervisor tree still, but this way you can also easily spread tgem.out over several servers if you wish later while also keeping coupling down. See: https://www.dailydrip.com/topics/elixirsips/drips/phoenix-is-not-your-application http://www.elixirconf.eu/elixirconf2016/lance-halvorsen 
Got it. strand |&gt; to_string |&gt; String.graphemes |&gt; Enum.reduce(%{}, fn(letter, acc) -&gt; Map.update(acc, letter, 1, &amp;(&amp;1 + 1)) end) Thanks guys. output: %{"A" =&gt; 3, "C" =&gt; 1, "G" =&gt; 1, "T" =&gt; 1}
That's a bad idea. You are probably need solve this problem with OS process supervisor like systemd or even supervisord. Elixir has entirely different concept. 
The override is what I was missing. Thanks so much!
This is a really good answer. Unless you need something web facing, there's no need to reach for Phoenix.
Cool!!! 
As a side note, for multi-line usage of the pipe operator it is good practice to put it at the beginning of the line strand |&gt; to_string |&gt; String.graphemes |&gt; Enum.reduce(%{}, fn(letter, acc) -&gt; Map.update(acc, letter, 1, &amp;(&amp;1 + 1)) end)
Hi, folks. I am currently working on a telegram bot https://storebot.me/bot/tvee_bot that will help you track the latest episodes of your favourite TV shows
To answer your original question, you can get the integer value of a character in Elixir by using the `?` operator. For example: ðŸ‘‰ ?A 65 ðŸ‘‰ ?a 97 Also, a great way to learn more about functions is to use the `h` function in `iex`. It auto completes so typing `h Enum.` and hitting tab will show all the functions in the Enum module. For example: ðŸ‘‰ h Enum.count/2 def count(enumerable, fun) Returns the count of items in the enumerable for which fun returns a truthy value. ## Examples iex&gt; Enum.count([1, 2, 3, 4, 5], fn(x) -&gt; rem(x, 2) == 0 end) 2 Hope you're having fun with Elixir!
Elixir books are becoming obsolete very fast. Are there any resources that are constantly updated with changes we can use to learn?
The guides are a great place to start: https://hexdocs.pm/phoenix/overview.html
&gt; ~~Elixir~~ books are becoming obsolete very fast "programming" Pretty much every book is obsolete by the time it gets to print. They're still good references on some of the bigger concepts but not for up to date APIs
This series by Shankar is the most up to date Phoenix book to my knowledge: https://shankardevy.com/phoenix-book/ The current version is targeting Phoenix v1.3.0-rc.2. The author has already announced that he will try to update it soon after the official 1.3.0 release. I got the collection a few days ago and I'm really enjoying it so far. 
C, perl, fortran, cobol, and php books are pretty much the same.
I feel like many apps dont start off needing a web interface but the need arises later. So I often spin up a Phoenix app even when I don't have a need for it.
This is correct. Elixir/Erlang processes are completely different than OS processes and Elixir supervisors will be useless here.
&gt; C, perl, fortran, cobol, and php books are pretty much the same. What do you mean? If you mean PHP never changed it really did. ~~Am~~ Was php dev. I did php 4 and php 5. IIRC php 5.3 to 5.4 and beyond was really crazy changes. 4 to 5 they added class iirc. 5.4+ they added closure, namespace, etc... 
&gt; But I wouldn't be surprised if Phoenix sets the bar on what means to build a web realtime application with persistent connections such as websockets and right now it seems way ahead of everyone else. Yeah but people are still buying that koolaid node.js web scale stuff. Nonblocking the hell with thread is such a terrible solution imo. 
I'm also reading through this series now and I think it's really solid. I like the idea of the Garuda book too where it walks through building a phoenix clone in order to get a better grasp of the internals.
If you haven't already, you should take umbrella apps for a spin. It is a rather nice way to do things like add a Phoenix app to a project later on.
Indeed; I misunderstood the question to be "if I were to write this in Elixir..." That said... having a "zero config" OS supervisor for BEAMs would be nifty (even if it is just integration with sysyemd), as would some cluster self-healing by watching node loss and attempting restarts via ssh if there is consensus on the loss. Crash prone systems like nodejs have offered such things for a long time, and while they are less critical for single node applications on the BEAM, for clustered apps it would be rather nice. 
don't listen to this "different concept" purist BS. 1. throw out Phoenix. 2. get https://github.com/saleyn/erlexec on board 3. supervise what you want. but are you sure systemd can't handle it for you?
Check out my Discover Elixir &amp; Phoenix course on Ludu :) https://www.ludu.co/course/discover-elixir-phoenix
Why does it need to be written in Elixir? Just pick any CMS that meets your needs.
The primary need for this application is to be web facing, actually.
So what's the point of an elixir supervisor then?
So I should just write my own server?
I assume because you need a CMS, your main need is something that is easy for non-developers to interact with. The question that raises is: Why does that need Elixir? There are decent CMS'es in existence already or even halfway-CMS options like Django.
Well the project currently consists of several web based micro-services. I wanted to be able to split the services into different projects and only have one web project. Edit: Also, I'm not sure what CMS stands for.
I thought I was replying to another thread and I didn't double check. To reply to what you were saying, if your project actually is web facing, Phoenix can be a good solution, but generally, if you want to manage other services, i.e. non-BEAM applications, look into something like [erlport](https://github.com/hdima/erlport). Erlang (and by extension Elixir) can be very well suited to managing other languages, but you need to do it outside the context of Phoenix (or whatever web frontend you're using). Use Phoenix as the web component only and let vanilla Elixir handle the rest.
whoray! now re-read my question.
Just read it somewhere around 5 times and I still don't understand why it needs to be in Elixir. 
I'll look into this, thanks
I made this - I do a lot of Elixir security stuff. I think the tool is pretty self explanatory, but I'm happy to answer questions if anyone has any!
Looks like I was correct lol
See if anything on the awesome-elixir list meets your needs: https://github.com/h4cc/awesome-elixir/blob/master/README.md#static-page-generation
I'm currently building a cms in elixir for our company, but it's a special use case, and it's going to be one huge distributed application that hosts all of our clients sites. For a general purpose cms to just run one site on one box you're going to be hard pressed to find something with as many features as WordPress. 
If you're asking how to make a skeleton for only JSON, you can make one by `mix phoenix.new name --no-html --no-brunch`
is there any way to remove the dependency on postgres? I don't even have it installed :/
 mix phoenix.new name --no-html --no-brunch --no-ecto This should do it.
thanks!
Nope, the other comment is correct!
You can always use raw Plug with some JSON encoder. 
I've managed to setup a simple server with plug and cowboy, I'm not totally sure about the plug's role though, I'll read about it more carefully later. What would you say is the most popular JSON parser?
Cowboy is only server implementation. Think about it as like Passenger or Unicorn, and Plug is more like Rack with elements of Sinatra. 
So it's like a package of utilities? Is it ok to use them in production or they are for development only?
They are definetely for production use. Instead of asking you could have [Read The Friendly Manual](https://hexdocs.pm/plug/readme.html)
Definitely! I was busy reading the Elixir guide. Thanks for your help!
Do you also mean Elixir School? Or is that not a sufficient resource beyond the basics? https://elixirschool.com/en/
kudos.
It sounds like [Thesis](https://github.com/infinitered/thesis-phoenix) might be what you're looking for.
I'm using Coherence but that's mostly because I don't need jwt tokens and really like the auto-forgot-password auto-account-confirmation auto-throttling emailing stuff He has a phx-1.3 branch but since 1.3 got released yesterday, it might be merged into his master by now
It supervises code running in Elixir's VM (the BEAM) which uses a model similar to OS processes, and it can handle faults as crashes which supervisors then handle
many of us use plug to provide web api's in production applications. when you don't need everything Phoenix bundles, plug is a go-to option. 
Great, I'll be using it for sure. Thanks!!
&gt;That's a bad idea. You are probably need solve this problem with OS process supervisor like systemd or even supervisord. Elixir has entirely different concept. Now I'm really confused. If its similar, why would I use an OS process supervisor, if elixir has it built in?
 for your elixir code they are indeed the answer. for the vm it runs in, or for external services written on other languages you need a different solution. elixir supervisors are for elixir code :)
Okay, so since I'm rewriting everything in elixir, I should use elixir supervisors. Thanks
and you don't need to
Phoenix is great because you can feel productive quickly without having a full understanding of all the parts. If I were to build a simple API server now I might just use Plug and Ecto.
Amazon S3
Have you seen https://github.com/Recruitee/mix_docker/issues/36?
Look into genservers and ets.
As Secretmapper mentioned, you can look into GenServers (Agent or Registry actually) or ETS tables. ETS tables are probably a much safer bet because you can access the data concurrently, without serialization. You can also look into FastGlobal, but that is a good choice only if the data isn't changing a lot. FastGlobal: https://github.com/hammerandchisel/fastglobal
Yea. I haven't looked into it much, my build pipeline (CircleCI) doesn't support the latest docket version yet. But it does sound like multi-stage will replace mix_docker.
If the data never changes you can even compile it into a module using a module attribute and that will be your best performance option. This would just mean to change it you'd have to recompile. As others mentioned FastGlobal is a similar approach to the above but can be changed (although there is a significant performance cost to changing the data). If you expect to need to modify the data at runtime as a feature, an Agent is the simplest option. You kind of treat it like a global variable in the sense if you register it with a name you can access it anywhere in the code then, or update it for that mater. Agents run serially though, the more concurrent access, the bigger the bottleneck the agent will become. That applies to reads too. If concurrent read access is necessary, ETS tables offered by erlang are what you want. The Erlang API is a bit rough, I suggest using ConCache as its a wrapper around ETS but with a nicer API and a few more features.
As already mentioned, for simple write and read you can use Agent module. For more advanced usages look at ets or even mnesia. Mnesia is built on top of ets and offers quite a few improvements: multiple indexes, transactions, ability to store data to disk, ecto adapter, etc. My advice would be to start with Agent. 
I'm using [Cachex](https://github.com/whitfin/cachex) successfully. It basically gives you a key-value store that persists through requests. It's easy to use, I think. I'm running a production web app and I actually haven't yet needed to get into the nitty-gritty of OTP, because enough libraries exist now that give you an easy interface and just do all that stuff underneath... I think it uses ETS tables. Seems quite performant, I'm using it to cache scaled images on the app side.
Since this is a learning exercise I recommend creating a GenServer and wiring it into your Application supervision tree. Then once it is functioning you can refactor the implementation to Agent to reduce some boilerplate or introduce an ETS table to improve performance.
Plug is pluggable middleware. It also comes with a router. (To break that down, the router matches incoming requests against the specific controller or function meant to handling it, and middleware provides a modular way to implement specific portions of a request lifetime such as enforcing SSL, handling CSRF protection, or dealing with sessions.) Try using the [poison](https://github.com/devinus/poison) library for JSON. You can also use [httpoison](https://github.com/edgurgel/httpoison) if you need an HTTP client for interacting with external APIs or whatever.
For those stopping by here later, this changed in Erlang/OTP 20 (https://stackoverflow.com/questions/45405070/how-do-i-save-iex-history/45405071#45405071)
.
Yup, and it seems like that is exactly OPs use case. You do an import at startup and then just access the data later on.
Interesting to write a tutorial for Elixir as a first language. Most Elixir tutorials are aimed at people learning a second language (or something much further on). I think it leads to an interesting dilemma which is figuring out how to talk about functional programming. There's a section on pattern matching. For a beginner, maybe that is fine, but if someone knows another language, like C or Java, they might wonder why they can't access a list element by index, which I think is worth addressing. Sometimes one teaches the features that are there, but sometimes, people wonder why a certain feature doesn't appear, and how Elixir handles it. For example, due to a lack of a for loop, you need other techniques (recursion or foldl/foldr) to process a list. Also, it might be useful to talk about building up a program. Many tutorials focus so much on syntax, they never get around to programming.
I'm new to Elixir/Phoenix and just started learning this past weekend coming from Node land. Are you referring to the current Programming Phoenix book being out of date now? I know Programming Phoenix 1.3 is under development now, should I wait to read that one? Thank you!
How many columns do you need to filter on? If it is a simple id based lookup, I'd use an ets table. Which would be populated when the phoenix server starts.
All terms in Elixir are comparable, even if the types don't match. This has bitten me before. AFAIK you can't define the comparison operators for specific types, either. I'd recommend using the Timex library and using Timex.compare/2.
If you use vim, upgrade [alchemist.vim](https://github.com/slashmili/alchemist.vim) to 2.8.0 as soon as possible!! There's a bug that allows any website to take over your computer. 
No complaints! Plus it's cheaper than AWS.
Most people still code in ANSI C or C99, though.
You make an excellent point about being able to access a list's element by index. I'll include this probably in Chapter 9 where I talk about the List and Enum modules' functions. The particular function I would use for that is List.at/2. For loops (and comprehensions) do exist in Elixir, but since I'm on my phone I don't have a good example to share ATM. The final chapter of the book will be all about building up a program. I talk about some of my ideas for that here: https://github.com/radar/joyofelixir/issues/9 Thanks for your comment :)
For loops do not exist within Elixir. As you mentioned, we have comprehensions. Despite the fact that comprehensions use the word `for`, it is vastly different from an actual for loop. To name a couple differences: * Comprehensions actually returns a value, whereas a for loop (traditionally) does not Elixir comprehension iex(1)&gt; numbers = [1,2,3] [1, 2, 3] iex(2)&gt; for number &lt;- numbers do ...(2)&gt; number * 2 ...(2)&gt; end [2, 4, 6] Ruby for loop 2.3.0 :001 &gt; numbers = [1,2,3] =&gt; [1, 2, 3] 2.3.0 :002 &gt; for number in numbers 2.3.0 :003?&gt; number * 2 2.3.0 :004?&gt; end =&gt; [1, 2, 3] * Comprehensions can act on multiple enums at the same time. A for loop cannot Elixir comprehension iex(1)&gt; numbers = [1,2,3] [1, 2, 3] iex(2)&gt; map = %{a: 4, b: 5} %{a: 4, b: 5} iex(3)&gt; for number &lt;- numbers, {_key, value} &lt;- map do ...(3)&gt; number * value ...(3)&gt; end [4, 5, 8, 10, 12, 15] Ruby for loop (This also translates the map keys into the `value` variable) 2.3.0 :001 &gt; numbers = [1,2,3] =&gt; [1, 2, 3] 2.3.0 :002 &gt; map = {a: 4, b: 5} =&gt; {:a=&gt;4, :b=&gt;5} 2.3.0 :003 &gt; for number in numbers 2.3.0 :004 &gt; for value in map 2.3.0 :005?&gt; number * value 2.3.0 :006?&gt; end 2.3.0 :007?&gt; end TypeError: Array can't be coerced into Fixnum from (irb):5:in `*' from (irb):5:in `block (2 levels) in irb_binding' from (irb):4:in `each' from (irb):4:in `block in irb_binding' from (irb):3:in `each' from (irb):3 from /Users/USER/.rvm/rubies/ruby-2.3.0/bin/irb:5:in `&lt;main&gt;' Now, I realize that this attempt at a direct translation based on the `for` keyword between Ruby and Elixir is bad and quite unfair to Ruby. This was more meant to show that a comprehension is **NOT** a `for` loop. Obviously there are better ways of doing these same things within Ruby and other languages. On a different note, you mention using `List.at/2` when needing to get the Nth element of a list. This function does not exist, I believe you meant to say `Enum.at/2`. I would avoid mentioning this function when talking about lists. While it does work, it should be avoided. Lists are not arrays, and as such, you should not attempt to treat them the same. Array lookup is `O(1)`, whereas list lookup in `O(N)`, where N is the element you are attempting to get. You may not notice this on small lists, but you will pay for it on larger lists. If you need random access to the elements of your list, you should probably think about using a different data structure.
&gt; The particular function I would use for that is List.at/2. Enum.at/2, but in general in Elixir if you find yourself wanting to access list elements by index then you probably don't want to be using a list in the first place. Lists are linked lists so accessing an element by index requires traversing over the elements up to that point. *edit - sorry, just noticed Ankhers already covered that in their reply
If you are planning a complete re-write and the code will be in elixir, checkout umbrella applications. https://elixirschool.com/en/lessons/advanced/umbrella-projects/ here is an example that uses a bank for a complete umbrella app(microservices) https://github.com/wojtekmach/acme_bank
Hey guys, I'd like to share with you the toolbar for Phoenix projects we've been working on lately (https://github.com/kagux/ex_debug_toolbar). It's a drop-in package that injects a toolbar in html pages with various information about request: timings, logs, ecto queries. As a "fun" feature, it allows placing breakpoints (`ExDebugToolbar.pry`) in your code and prying into them right from the toolbar (similar to `IEX.pry`). Project is in its early stages and under active development. Contributions to code, feedback and suggestions would be much appreciated!
Cool! Reminds me of miniprofiler.
[mp4 link](https://g.redditmedia.com/zelcARr-Hq7roDUOqolxQ_4o6etI8Wk3K3CIt0JbmcA.gif?fm=mp4&amp;mp4-fragmented=false&amp;s=d9a57507988e04d965ba2af9a8247730) --- This mp4 version is 63.51% smaller than the gif (389.56 KB vs 1.04 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
Hey guys, I'd like to share with you the toolbar for Phoenix projects we've been working on lately (https://github.com/kagux/ex_debug_toolbar). It's a drop-in package that injects a toolbar in html pages with various information about request: timings, logs, ecto queries. As a "fun" feature, it allows placing breakpoints (`ExDebugToolbar.pry`) in your code and prying into them right from the toolbar (similar to `IEX.pry`). P.S. Sorry, had to delete previous post as I realized a link to github image was showing my avatar instead :|
Looks great. [Laravel has something similar](https://github.com/barryvdh/laravel-debugbar) and it makes debugging much more enjoyable.
Wow, this is so cool. Will definitely be using this in my projects!
This is amazing. I love the 'time-travel' breakpoints. Eagerly awaiting the Phoenix 1.3 compatible release.
Dang, while writing this I was in my head "Should I mention the difference between views and templates" and went all like "nahhh". Sorry for the mixup, will edit and thanks for pointing it out! :)
Man, this is so awesome.
Same here, went to install and start using it only to find no 1.3 support. Eagerly awaiting it because this looks fantastic!
Keep in mind that beginners want to program sooner than later. Your approach is a little like showing an aspiring chef (or home cook), how to use a knife, how to make various cuts, talking about the various kinds of vegetables, cuts of meat, spices, talking about a food processor, a blender, a spice grinder, a grater, a peeler, etc. before you finally get to cooking. Most beginning cooks want to cook something quick and easy first, so they can feel like they're cooking. I think the same can be said about beginning programmers.
thanks man! poison will suit my needs!
Ah, good thing I haven't bumped into List.at/2 yet. But yeah, I read about a list being a linked list, so I do use other operations (unless the list is a fixed small size, in which case, sure).
wow, great job, phoenix and elixir community needs more people like You!
Working on my first Phoenix website project for a client which is a conglomeration of real-estate agencies. It's not a very complex site (simplish domain model), just a lot of work (the main table/form is up to 180 fields!), so I figured it was a good first Phoenix project, so far that's been the case. I'm struggling here and there, but that's to be expected on something where everything is basically new, and I'm making progress. Since I'm currently working solo, the elixir slack channel has been very helpful (there's also a Discord server now, FYI!)
Since you can use all non-emoji unicode characters in names now (at least as of elixir 1.5/otp20), you should try to French up the source code a bit! :) Vive la libertÃ©!
It really depends on these things: 1. How much time do you have every day to dedicate to these learning efforts? 2. What's the scope of your "first project"? 3. How do you define "average" developer? 4. Do you have development process that helps you produce "stable" software in a timely fashion, since that's really language and framework independent, and probably more at the crux of your question. IMO, pick up one of the many Elixir + Phoenix books (or just read elixir-lang.org's guides), set aside regular time to grind through it (at least 30 min/day), next thing you know you're dangerous ;) I was fortunate enough to have mentorship, and learned enough Elixir in four months to use it on my next project. Worked out pretty well, project was mostly stable. I have about a decade of experience across a few frameworks, languages, and industries.
I also have fond memory of Laravel 3 thanks to that debugbar. Too bad Laravel 4 came and composer was a mess back then.
Thanks a ton dude, this is great!
Thanks! Laravel and Symfony were inspirations for this package
Thanks guys! I'm working on 1.3 support, should be available soon!
I'll be dedicating about 2 hours per day. I'll pick up a book and get to work. Thanks for the feedback!
I'm not very good at Elixir but if I can help let me know :)
Is the existing Programming Phoenix book still worthwhile now that 1.3 is out or has there been too many changes? 
I've just published an update with 1.3 support. If you could give it a spin to verify it works, that's be very helpful!
Not long, I'm a .NET dev with no functional experience and following the tutorials picked it up enough to write an API with a Postgres backend.
I would wait for new 1.3 book, the guides / docs are now fully up to date (thanks phoenix team!): https://hexdocs.pm/phoenix/overview.html
.
Haven't seen one of these since Medium. Well done! How about pairing with Facebook's create react app? For simplicity, and standardization?
I didn't realize how much boiler plate there is to setting up a react app. Good write up. Didn't realize how easy I have when I use ember-cli.
&gt; I would generally recommend converting the â€œfull-blownâ€ application libraries into a callback-module style discussed above. Unfortunately it's easier to build a globally configured application than a callback style library. Many of the Hex packages I depend on make this mistake. 
That's quite cool! Thanks!
Spin taken, issue raised on Github :)
This looks spookily similar to ex_rated https://github.com/grempe/ex_rated
Most people use create-react-app which scaffolds everything out for you and works great.
I don't mean to be disrespectful but why on earth would you use Redis while ETS is already available as a fast &amp; efficient K/V storage system in the runtime? 
Why not? 
It adds another dependency and another piece of software to set up despite the simplicity of the task. Of course it's going to scale better than ETS but considering the usecase I fear it's a tad overkill to deploy Redis. But maybe I'm just addict to the ETS system ^^ Very good tutorial appart from that :)
&gt; But maybe I'm just addict to the ETS system Yeah. I feel like there is a big crowd of people coming from ruby that create libraries based on redis because they don't know ETS. Just look at the different libraries for job queues.
Very clever. Thanks!
Glad you enjoyed it!
i feel like all this could have been avoided by constructing a single proper query into your database joined on product id. you still have many queries slamming the database youve just pushed the bottleneck elsewhere. maybe im missing something obvious? the final product is just a join more or less
Ah! Good observation. I left a bit of context out of the post to try and focus on the core performance improvement. Let me try and explain here... We're using GraphQL. GraphQL enables the consumer to decide what fields they want in their response. Since our "product" is consumed in lots of different places, some consumers ask for far less information. We've built the ability to only execute DB queries if a field was originally requested. In the join you propose, we'd be hitting tables and increasing network payload size unnecessarily. Does that make sense?
Task.yield_many is cool stuff, we use it too to parallelize a bunch of HTTP requests and the result handling (including timeouts, it does that too!). Made my life much easier for sure. We do not use Task.Supervisor but hey, now that I think about it... maybe we should.
Give it a shot! Our code running in production looks more similar to the [yield_many example in the docs](https://hexdocs.pm/elixir/Task.html#yield_many/2-example): fn ({task, reply}, acc) -&gt; case reply || Task.shutdown(task) do {:ok, result} -&gt; Map.merge(acc, result) {:exit, reason} -&gt; handle_thread_error(reason, acc) _ -&gt; handle_thread_error(nil, acc) end end
sure, reducing the network overhead is likely to be the bottleneck for time to first paint but say dynamically constructing the join based on needed tables would solve both -- of course you have views into tradeoffs i dont. but unless theres something crazy going on, constructing the optimal query for the requested data shouldnt be too hard and its what graphql resolvers should do lower db load = lower cost = more money for you! edit: GraphQL was really designed for the case where the people making the client and the people making the server simply could not coordinate without massive overhead, but if you know all endpoints then doing the global optimization by hand can be worth it
Cool, this is definitely awesome food for thought and something I'll look into. Thanks for the feedback!
would this need to be done for channels as well? I thought that already was parallel? or is it only concurrent? (I'm new to phoenix/elixir so I don't really know how internal stuff works yet)
Depends how many logical cores are available. The VM allocates by default 1 scheduler per core, and each one executes processes mostly independently, with some exceptions. So the answer is sometimes both, sometimes just concurrent.
Backend time is response time, and the title should be updated to say so, for lasting appeal and stickiness, IMO.
This code path is actually utilized across a number of different endpoints. For example, our search endpoint first generates a list of relevant IDs before executing this path to retrieve the associated product information. In that case, this code path is simply part of the backend time spent and a fraction of the total response time. That was my logic when phrasing the title this way. Do you think that makes sense? I'd be happy to update if you think response time is more accurate. 
"Backend time" is ambiguous at best, and doesn't match usual descriptions of durations. From who's point of view is the duration? The browser? 
I definitely see your point. I originally used "time to first byte" to make it clear the browser was the consumer. Then, I felt the fact this was part of an API wasn't particularly important in conveying the utility of `yield_many` so swapped to "processing time". I landed on "backend time" as a compromise between the two but agree it's ambiguous. I'll swap the title in the next couple of days after the reddit hug loosens up (don't want people to feel misled or like they misclicked when the post title doesn't match the reddit title!).
More tongue and cheek than anything, but I wrote a minimalistic test suite for my MIPS Project Euler solutions using a single Elixir piped expression that works perfectly with Travis.CI [ {"problem_1.s", "233168"}, {"problem_2.s", "4613732"}, {"problem_3.s", "6857"}, ] |&gt; Enum.map(fn {file, solution} -&gt; with {result, 0} &lt;- System.cmd("spim", ["-f", "src/" &lt;&gt; file]), [_stuff, answer] &lt;- String.split(result, "exceptions.s\n") do if answer == solution do IO.puts("#{file}: #{answer} is correct! âœ…") :correct else IO.puts("#{file}: #{answer} is not correct! ðŸ˜“") :incorrect end else _ -&gt; IO.puts("#{file}: had an error! ðŸ˜±") :error end end) |&gt; Enum.group_by(fn status -&gt; status end) |&gt; Enum.map(fn {status, problems} -&gt; {status, Enum.count(problems)} end) |&gt; Enum.into(%{}) |&gt; Map.put_new(:correct, 0) |&gt; Map.put_new(:incorrect, 0) |&gt; Map.put_new(:error, 0) |&gt; IO.inspect |&gt; case do %{incorrect: 0, error: 0} -&gt; exit({:shutdown, 0}) _other -&gt; exit({:shutdown, 1}) end
I'd say that GraphQL was designed for rapid front-end iteration, to the point where even if you do have good coordination between teams on a traditional hand-coded endpoint architecture, it's still slowing you down. This type of rapid iteration is only going to become more prevalent as more businesses fix their design processes. That said, in my experience optimising GraphQL servers, number of database queries for a typical UI query is rarely the main issue. You tend to end up with a relatively stable and low number of queries
We've considered using ETS, but I decided against it because it's not persistent on disk. Therefore we'll lose user preferences on node reboot/crash. The second option was to use Redis because it's familiar and it's already used by ruby apps on the server. So there's no need to deploy it just for the bot separately.
That's the case here as well! I think that erlang core libraries suffer from poor discoverability. I've heard about ETS from elixir-lang guides, but I've just discovered the alternative - DEST that could've been used in our case. But somehow I missed it during search, I suppose.
OK :) By the way, the bot is great.
Thanks! I only wrote a small part of it, but I'll pass it to the bot's developer :)
Indeed, that's why it was needed at facebook, but if you and all your frontend devs are sitting around the same table, it loses some of its charm. A small number of stable queries that don't change often is perfect for storing as e.g. stored procedures with optimized mappings to and from application data structures. Again it comes down to whether you want to save DB/app server computational time, which will reduce latency and costs. That's a tradeoff with dev time that needs to be measured, but straightforward SQL stuff like this is usually a win.
Anybody have input or discussion on this? As the author of [an authorization library](https://github.com/schrockwell/bodyguard/) who was about to [change the recommendation to move authorization into contexts](https://github.com/schrockwell/bodyguard/pull/34), I'm curious what folks have had success with. Obviously we can trust Chris with his Phoenix experience, but there are good arguments for any of the various authorization designs.
A bit of background, my most recent production apps are written in RoR, so when I came across bodyguard in phx 1.2 it felt *right*, as I use pundit there. I will prefix this by saying *thank you* for your time working on bodyguard. Now that said, I started using contexts before bodyguard had support. I spent a fair amount of time experimenting in my application and have currently reached a point where my authorisation is in my contexts. This works for me because it feels like I'm just not repeating myself over and over again; Being able to call the same functions from API controllers, a traditional frontend, from iex and mix tasks and I knowing my business rules are still applied is great. The "downsides"; 1. My contexts are larger than I would really like at the moment. I extensively use pattern matching to apply my various rules (i.e. using todos as an example `list_todos_as(%User{admin: true, active: true}) .... list_todos_as(%User{active: true}) ... list_todos_as(_)`). But this I can probably clean up using `defdelegate` 2. For my scale of application I specifically chose to be happy about coupling my accounts context to everything - it's a completely closed application and I really struggled with the idea of loading things multiple times just to keep something separated when realistically in my case they won't ever be - for some people this
Like this: ``` rows = File.stream!(file_path) |&gt; Stream.map(&amp;String.trim_trailing/1) |&gt; Enum.to_list ``` (see [StackOverflow](https://stackoverflow.com/questions/39939642/how-do-i-read-all-lines-in-a-file-into-a-tuple)).
Thanks! The first part seems like it refers to an explicit file in the file system (thus, file_path). What if it's standard input?
OK I found a solution based on yours IO.binstream(:stdio, :line) |&gt; Stream.map(&amp;String.trim_trailing/1) |&gt; Enum.to_list Turns out that DOS (Windows) doesn't seem to handle end of file correctly with respect to Elixir so this program hangs when using input redirection. It works fine if I read from a file, and I suspect it works fine in Unix or Macs.
If you donâ€™t need the stream eg file size is reasonable, File.read!(:stdio, :all) may work to force the :eof to happen, on mobile canâ€™t check.
Thanks for the info â€“ all your points sound like reasonable tradeoffs. Since the library already supports both auth models I'm just going to leave it as-is and update the docs to help guide users to best fit their applications.
Forget about the "CRON" you can achieve that from elixir directly. Without using an umbrella app you can create a phoenix project and add some GenServer in your "lib" directory to handle the parsing. This is an idea : - Create a GenServer that receives an url and additional option and parse it (this will be your "worker") - Create a superviror that creates a pool of worker (you could create one parser per site, but I don't think it's a good idea since you'll end up with a lots of processes, limiting the pool size, or having some kind of back pressure could improve the performances) - Create a queue (using toniq for instance) to store the feeds to parse, and use quantum (https://github.com/c-rack/quantum-elixir) to enqueue new feeds to parse every X days. - Create your phoenix app and use the database to show the data you need. You could also "call" the queue GenServer to get what's being processed, what failed and what is waiting. When someone want to parse a new feed, you can call the worker to do it directly or insert it into the job database. 
Correct me if I'm misunderstanding, but when it says you can "distribute actors across several nodes in the cluster and interact with them using their logical identifier, but without having to care about their physical location in the cluster"... it sounds like you have an identifier for the actor and don't care which node it's located at, and want to send messages to it. Is that basically what this means? If so, Elixir/Erlang already supports that out of the box. When you look at a PID in Elixir you see something like `#PID&lt;123.456.0&gt;`. You don't have to do anything with any of those numbers, but the `123` there refers to the node number. So that's baked into Erlang's PID automatically. You can just send a message to that PID and not have to worry about whether it's on your current node or not. If I'm misunderstanding the question then ignore whatever I've said. :)
Hey there, thanks for responding. To follow up, let me give you a more concrete use case. Let's say I was representing Member Actors that were using UUIDs as ids. In order to send messages to a particular member actor (let's say id=1a901cb8-f0f3-4da1-86b2-c92bbb31b767), I would message the cluster sharding manager which is a well known address (eg. I need to talk to a member with id=1a901cb8-f0f3-4da1-86b2-c92bbb31b767 and send him message X) and it would forward the message to a node where that Member actor is present (if its not up and running, then the actor will automatically be created) regardless of where it was in the cluster. The main point being that the requester is completely unaware of which physical node is hosting that particular Member Actor. Is that what you are saying comes out of the box?
You can use a global registry like gproc or syn (third party libs) for looking up processes across the cluster based on arbitrary values. In theory you could have a process running on every node that registers itself as the handler for a particular partition, then somewhere else on the cluster you look up that process pid by partition, start it if necessary, and send the message along.
No need to pull in gproc, just use Registry in Elixir 1.4.
Lookup riak_core, it's an erlang library that does something similar to what you're describing.
I thought the same thing, but Registry is only for the local node.
I think what you're looking for is probably swarm (https://github.com/bitwalker/swarm) and libcluster (https://github.com/bitwalker/libcluster). GP's point was that you can send messages to any process located on any node in the cluster that your node knows about it. What cluster sharding sounds like is not just network-transparent messaging but distributed process groups. The messaging facilitates the use of distributed processes; what it doesn't do is handle the grouping, handoff when moving a process, instantiation if needed, etc, which I believe swarm will do for you. 
yes, Registry is not distributed.
It seems like libcluster compares to Akka Cluster whilst swarm is more comparable to Akka Cluster Sharding. Will take a look, thank you ðŸ˜€
[removed]
Riak Core is sadly hard to get started with, but a great piece of software once you overcome the initial hurdles. Swarm is a lot easier I would say, but not quite as sophisticated (yet).
The custom supervisor and worker pool sounds a bit advanced for a simple project. Just quantum for scheduling, toniq (or exq) for job queue and Ecto for persistence should be all you need.
Thank you for your fantastic reply. While I think it might be a little overcomplicated as well I feel like it would be a good learning exercise to get the basics of GenServers under my belt. Thanks for taking the time! 
https://github.com/bryanjos/aws_auth Can help with the header creation and signing stuff for AWS requests. 
The Programming Phoenix book is the way to go: https://pragprog.com/book/phoenix/programming-phoenix
Is it applicable to 1.3 or has too much changed?
Only three (mandatory) things really change in 1.3 from a developer perspective: mix.phoenix becomes mix.phx; the web/ directory moved to where the rest of the code is; the base Phoenix generated modules now have Web. in their model names. Nothing particular else IME, with contexts being optional filesystem layout sugar. So while some translation is needed it is primarily root paths and adding Web. to various module names... Nothing too big and all the main concepts remain as they were in 1.2
I've been working through the book and have observed some warnings for deprecated functions, but the errors tell you what to use instead. The tests section also has some tests that fail due to different generated functions, but in each case a search of the Elixir forums has provided the answer. These short diversions have also helped me understand the language better.
I'm vehemently against running database migrations as part of a docker executable command for your app, no matter the language or framework. Sure it's convenient not to have to set up another deployment step, but all the savings are out the window at the first time you encounter a non-standard situation. DB down? Can't start the app. A large migration? Can't start the app until it's done. Boot up multiple new containers at the same time? You'll either get long boot time or corrupted data, depending on how smart ecto is about migrations. And it will bite you on the ass at the very moment your ass is already on fire, like when you really, really have to recover from unexpected downtime right now. Nothing besides starting the server process should happen on container start. Just add another line to your deployment script.
It's interesting what people want in a "gentle introduction". For example, you seem rather sophisticated (having programmed in Clojure). What works as a gentle introduction for you would be quite different than someone that doesn't know how to program. A few weeks ago, someone posted an intro to Elixir (https://www.reddit.com/r/elixir/comments/6qm8rs/joy_of_elixir_a_gentle_introduction_to/). Still, that person opted to write it from his(?) perspective (which may be comparable to yours). That's fine, one can write whatever they like, but that tutorial is not aimed at someone that's never programmed. So, it's gentle, but not that gentle.
My needs in this situation are *much, much less* about the programming language. In fact, my questions right now exist almost entirely independently of Elixir and Erlang as a language, my questions are about Phoenix as a framework/platform and the structure etc. Also, I'm flattered ;3, but Clojure is probably the easiest language I've used in my life. ^^^in ^^^conclusion I get what you're saying, but my questions have nothing to do with Elixir the programming language, it's about the structure and flow of Phoenix specifically.
Some number of years ago, I read (parts of) a book called "The Design and Evolution of C++" written by the guy that wrote C++, Bjarne Stroustrup. In it, he explains decisions he made (for example, whether to preserve C's philosophy of making the declaration of a variable's type similar to its usage) and why he made them. I wish more authors would do that. For a web framework, I'd like to see "this is what web frameworks try to do, and this is how most of them are set up, and this is my idea for running it differently", sort of a big picture, and the decisions made along the way. Anyway, I hope you find something that helps you out (I'm supposed to look at Phoenix at a training in a month's time).
I tried this out. Turns out it complained about two things. First, File.read! has an arity of 1 (you supplied 2 arguments). I removed the second argument, then it complained that the first argument wasn't a path. If you find something else, let me know. 
https://blog.lelonek.me/how-to-run-phoenix-framework-application-inside-a-docker-container-b02817d860b4
That's a very good point.
Whoops that should have been: &gt; IO.read(:stdio, :all) Edit: which will read the whole file at once as UTF (should be fine even with big lists, but test and check) and then you can process from there. Edit: I think this will force the Windows :eof to happen, will check shortly.
I ran it like elixir test.exs &lt; input.txt in DOS (on Windows 7), and it hangs with IO.read. I wonder if it runs better in bash in Windows 10.
So I'm just curious as this is something I've been thinking about lately: what's the "right" way to do this? Not directly related to elixir, but I've been toying around with GraphQL + Postgres + an ORM using docker swarm and the one thing that's keeping me from going all in is I don't know how to manage migrations with docker (in a painless way that's not: "ssh into the container(s) and run migration"), which is important to me especially since I know the schema will be evolving fairly frequently.
Any advice on what the alternatives are?
First and foremost: write migrations that can co-exist with different versions of code. Don't remove a column alongside the code that uses it, but only after the code has been deployed. Don't rename columns, do add-update-remove steps. Yes, it's annoying. But if your code is in use, it soon becomes a necessity. Next step is largely process-specific. First up, write a shell script to automate ssh-ing into the container and executing the migrations. Then look into what your infrastructure provides. I haven't used swarm, but for example dokku provides pre-deploy and post-deploy hooks to run commands. I think swarm had a concept of one-off tasks? Spawn a single container with same image but different command? When your app doesn't get broken if it's not running on the exact schema version, all kinds of patterns become feasible.
Hmm. Not a Win guy, sorry but Iâ€™m sure it would run on the bash subsys if you have it available.
.
Validating the reason of error has no sense in production. It just slows down the application. This can be used in rare specific cases, but I should have mechanism to turn it off. Have you checked your library in Distillery? If not - it's not "production ready". Imagine the situation, that I want to use the library throw 'with' pipeline. How can I understand, that the error tuple is sent by the library? {:error, _, _} can match another libraries, so I have to specify each of possible atoms on the second place of the tuple What will do, if I'll pass this string: " "? Why numeral_pairs are visible outside of your library?
I recommend the phoenixframework site's Guides section. Phoenix is actually not as complicated as it sounds, you need very little code to make it do something useful. It includes some web-applicable abstractions but if you understand the http requests response lifecycle it should make some sense. It works like a pipeline, a series of filters which each transform the request (instantiated in the form of a Connection), until the request becomes a response which you finally render or redirect. It's is best thought of as a middleware stack. I use Phoenix everyday but only for websockets, the web part isn't used except to accept the initial connection (as one does). It's very modular and "plugable" so you are free to mix and match different parts of the system without having to adopt it all. The various Plug modules are used to implement specific features like what content types to accept and such. The difference between 1.2 and 1.3 is mostly in removal of the Model part of MVC from Phoenix, it's just VC now. The rest of your Elixir application forms the M part. This change is reflected in the reorg of the generators and where things get put on the source tree. Good luck. 
Yeah, my main issue comes from the fact that it takes so little code. There's a ton of shit just.. there, and you only need to supply a little bit of Elixir Lego to make it go, but that level of abstraction can make things so alien. And as a side note, jesus, reading about phx and following along with old tutorials just to realize "OH HEY WE'RE IN A NEW ERA NOW OR SOMETHING" is incredibly confusing.
Thanks for your feedback, it's very helpful. I'll run it through Distillery, I hadn't considered that. Good point also on the compile time purging: I'll look into implementing something similar to `Logger`'s `:compile_time_purge_level`. Regarding using the `with` pipeline, though, my understanding is that if you want to know what triggered the error, you wrap the calls within tagged tuples: with {:roman, {:ok, val}} &lt;- {:roman, Roman.decode("F")} do val else {:roman, error} -&gt; {:error, _, message} = error IO.puts "Got message '#{message}' from Roman" end Is that not the usual way to do it? Elixir's standard library uses tagged tuples with `:ok` and `:error` in several modules: if you want to know which function caused an error in a `with` pipeline, you face the same challenge regarding directly matching the return value. Attempting to decode "" will return an error. There is no need for `numeral_pairs` to be visible outside the lib, but how can I share it with the `Encoder` and `Decoder` modules while keeping it invisible to the outside? Or do you mean I should simply have `@doc false` for that function? Thanks again for taking the time to look at the code and help me improve.
This ^ is why I recommend using the guides and tutorials on the phoenixframework site. The books are obsolete since 1.3 and need updating. The site is up to date though. I suggest you drink the koolaid at the beginning and then dig into some of the moving parts to see how they work as you go. The abstractions are required, if Phoenix didn't provide them out of the box you'd end up rebuilding them yourself. Elixir/Erlang have many higher level abstraction frameworks, OTP for example, you'll build your apps from. The language elements of Elixir are very simple. Most of its appeal comes from the robust abstractions and frameworks. 
I have a couple of questions: 1) It looks like you are generating functions for all possible arabic numbers (up to 4000) by iterating through the hard-coded list in numerals.txt. Why did you choose this approach over writing just a single function that converts any arabic number to a Roman numeral? It seems you are creating a lot of code for functions that might never get called. 2) Why do you have a limit of 3999? Surely Roman numerals are capable of representing numbers greater than that? 3) Why is "IIII" considered an invalid numeral? There are plenty of clocks in existence that represent 4 using this notation.
* How do you connect to iex so you can eval things directly? On a elixir buffer you do `, s i` and that brings up iex. If that buffer belongs to an elixir project you can also do `, s I ` which runs `iex -S mix` For the other questions I don't know the answer. As for credo, I saw a blog post once, how to use it with Git hooks but haven't seen anything else. Useful resources: * The alchemist that brings the Elixir goodies to Emacs and is the basis of elixir layer in spacemacs. https://alchemist.readthedocs.io/en/latest/basic_usage/ * Spacemacs wiki in elixir forum https://elixirforum.com/t/spacemacs-general-discussion-blog-posts-wiki/109 * Emacs wiki in elixir forum https://elixirforum.com/t/emacs-general-discussion-blog-posts-wiki/427
IIII Is a invalid number is the Roman format. 4 is written as IV (Remember Niko Belic ?)
Not on [some clocks and watches](http://mentalfloss.com/article/24578/why-do-some-clocks-use-roman-numeral-iiii)
1) In my first iteration, the value corresponding to a numeral was always computed, but then I realized that I could generate a function for every case. I went with generated functions as the main feature, because pattern matching is more performant, and the correctness of the conversion is easier to check: if the file is correct so is the code, no need to step through it. Generating many functions, of which many might not be used, didn't seem like having a significant downside in contrast, or am I overlooking something? 2) "The rules" state that in a roman numeral a given letter cannot be repeated more than 3 times in a row. 4000 would be MMMM which would be invalid. Per wikipedia, there are writing systems that exist to encode larger numbers, but handling these would require handling how their format was transcribed (e.g. letters with overlines) which would be relatively specific to a given use case (e.g. wikipedia uses HTML tags and CSS). In addition, the 3999 cutoff point seems like it would accommodate most uses: Roman numerals don't seem to be used often to represent large numbers (but see below for a solution). 3) IIII is considered invalid due to the repetition of I as above. But as you mention, there are some alternative forms for writing Roman numerals (e.g. https://en.wikipedia.org/wiki/Roman_numerals#Alternative_forms). I think I'll add a `strict` flag: that would allow decoding of IIII and larger ascii-based numerals such as MMMM. Thanks for your questions/feedback!
**Roman numerals: Alternative forms** The "standard" forms described above reflect typical modern usage rather than a universally accepted convention. Usage in ancient Rome varied greatly and remained inconsistent in medieval and modern times. Inscriptions dating from the Roman period sometimes use "additive" forms such as IIII and VIIII for "4" and "9" instead of IV and IX. There are even instances of both forms appearing within the same document. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/elixir/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
This is what you're looking for: http://erlang.org/doc/man/global.html and also this: http://erlang.org/doc/man/gen_server.html Each gen server can be registered locally (accessible via name only on that node) or globally (accessible via name in the whole elixir cluster) There are no sharding managers in Erlang/Elixir. Maybe EPMD could be called that - but not sharding. In case you're worried about the overhead of copying messages between nodes in a cluster, theres _something like a sharding manager_ https://github.com/hammerandchisel/fastglobal
Don't worry about 1.2 vs 1.3. The main difference is the structure of the boilerplate it generates for you, separating the business logic from the controller. It was always possible to write phoenix apps like that, the framework just encourages it now :)
Thanks, that's very good to hear. 
Haven't dine that but keep in mind that in Elixir `'foo'` and `"foo"` are different.
Omit the "wss://" part. It wants a hostname, not a URL.
Nice resource, well done.
Use the guides on the phoenixframework site. They are up to date. As said, the difference between 1.2 and 1.3 is how the code the generators is structured. Less Rails, more Elixir. Functionally the API is little changed. 
Since I am calling an Erlang library I believe that the single quote marks are correct. 
I use docker with Phoenix. We have a script that will ensure schema is setup etc... Then we compile the app via Distillery. This means you don't have to put the source in the docker image and just use the compiled version
And once you've done that bear in mind (if you didn't know already) that you'll need to do an HTTP connect and then upgrade the connection to a websocket. It isn't hard (I've done it on an Arduino) but if there is a specifically Websocket library out there, I'd use it. 
You'll need to pass in websockets connection upgrade headers to get it into websockets mode. 
I was not aware of that do you have any reference on how to do that in Elixir? I saw some libraries which I will take a look at later but I had successfully played around with :gen_tcp and was wanting to try out Websockets for fun. Definitely more of a learning project than a real world production one.
https://en.wikipedia.org/wiki/WebSocket is quite good and succinct, and then you have https://tools.ietf.org/html/rfc6455 which is one of the better ones. Elixir would be really making a TCP channel and then doing the handshake, probably with a state machine. 
You don't mention which library you're using.. but it's not uncommon that elixir wrapper of erlang library takes string and then pass charlist to erlang library. You should check the source. You may find type info as well! For example: https://github.com/meh/elixir-socket/blob/master/lib/socket/ssl.ex#L140
I think https://docs.docker.com/engine/userguide/eng-image/multistage-build/ could be relevant for you.
nice, I might use that in some of my projects. Right now we have a custom build image for use jenkins &amp; k8s worker pods. So the elixir building is simple and lightweight.
"IIII" is valid.
hmmmm, I am not sure but I think You have to just use ajax call to your contoller method, then the stuff that used to go in some_view.js.erb will go to success or error ajax callbacks. something like: do controller_method // do stuff and respond with json response end var request = $.ajax({ url: "/controller_method_url", method: "POST", // whatever You need data: { dataFromFormIfNeededEtc }, // dataType: "json" }); request.done(function( res ) { // do stuff with response }); request.fail(function( jqXHR, textStatus ) { alert( "Request failed: " + textStatus ); });
This is probably a stupid/simple question, but since there's already a thread here for spacemacs: How do you change the indent level for .html.eex files? I'm used to using 2 spaces to indent but in spacemacs it's indenting 4 spaces.
OK, so I got everything working and it was very smooth sailing for most of the way. I ended up using Drab: https://github.com/grych/drab Basically it establishes socket connection on the page and updates html from the backend. Basically there's no ajax and no javascript (the one you need to write). It's just fucking black magic. Check the demo page: https://tg.pl/drab The only thing I didn't not like is being forced to use eex template instead of haml. Here's really all the code I needed to get it going: https://github.com/GBH/loaded.bike/commit/bf267978d236d2321ae43b7bdc1290090e1aca82 I opted for "Load more" (like imgur) instead of infinite scroll. Here's it in action: https://loaded.bike/tours/11-washington-state-vancouver-island-sunshine-coast 
Someone finally created Chris McCord's sync gem for Elixir. Bout time...
Sounds like a pretty great role and Iâ€™ll certainly get in touch. On a side note, we run Elixir North in Leeds which might be of interested. Itâ€™s recruitment-free zone but still a good chance to network with some other Leeds Alchemists :) http://meetu.ps/e/D73zT/B4CbP/ahttp://meetu.ps/e/D73zT/B4CbP/a
If I could ask, why are you using Phoenix only for websockets? 
Phoenix.Channels and Phoenix.PubSub. Websockets is a transport layer protocol, Phoenix adds higher level abstractions on top of that which I would have to build myself anyway. This is what I mean about Phoenix being modular, more of a toolbox than a deeply structured, monolithic framework, like Rails. Edit: manual-correct auto-correct, fix typo
You don't have any ability to acquire visas do you? I'm an es6 JavaScript/.net mvc full stack developer with side experience in ember js and Phoenix for my home projects.
I did run it on a Mac, and it worked fine (the solution I posted, that is with binstream).
Glad to hear. I read something about console or stdio buffering likely the cause, aka the :eof not being sent by the win pipe but didnâ€™t see an actual fix fwiw.
It is slightly annoying, so for the stuff I'm doing, I just write the data to a file and read from the file, and that seems to work.
Thanks Jordan, that event looks cool. We're using it in embedded IoT and also Phoenix web projects, so have a bit to chin-wag about although I'm personally only using it for fun side projects (management, tut). 
Sounds good. Where you based? We've done European visas, others can be much more expensive &amp; difficult I believe. 
&gt; performance profile of Elixir/Erlang is similar in a lot of respects to node Really? I'd been led to believe it was significantly more performant.
Ah. I'm in the US. Feel free to pm me if needed
More or less performant does not contradict performance characteristics being similar. For example, most apps where you are just waiting on IO to complete, node and the beam will look more similar to each other than to ruby or python.
When you compile with Distillery the environment variables have all to be already known right? I want to confirm my understanding that you cannot use regular environment variables when running the container to configure things like the database URL, and app environment, right?
You do not. Look into REPLACE_OS_VARS It's how it gets slipstreamed in like normal docker images. That tied with alpine. It makes some nicely sized images that boot up in about 2 seconds
This is what I have in my `user-config` in my `.spacemacs` file ;; Configure web mode indentation (setq web-mode-markup-indent-offset 2) (setq web-mode-css-indent-offset 2) (setq web-mode-code-indent-offset 2) (setq web-mode-js-indent-offset 2) (setq web-mode-js2-indent-offset 2) Now everything from js, css and html is indented with 2 spaces.
Thanks! So, I didn't have a `user-config` section in that file. But near the end there was a `(defun dotspacemacs/config () ... )` section. I put that stuff in there and now it works perfectly. So, big thanks to you!
Follow the link https://github.com/danzan/manualsbrain.com for source code
I haven't done any property based testing before, so this is obviously quite basic, but I spent half of today playing with the new StreamData library and thought I'd post a little write-up on that.
You can also use kubernetes. It can handle the orchestration of the microservices quite well. however you don't want to create a lot of elixir microservices ( because of the beam vm it doesn't make sense ) So if you have something like, a db, a redis backend, a java microservice, and your elixir app, you can have all of them be orchestrated via kubernetes
Hi, I wrote [monk](https://hex.pm/packages/monk) for the exact same reason, but I used the pipe operator because it seems more clear with it that the functions accept arguments.
Nice project ! 
Hello mate, We've done with our bot for https://manualsbrain.com you can use our source code if you need it https://github.com/danzan/manualsbrain.com 
If you know for sure that Phoenix is what you're after, I'd say Chris McCord's book is the way to go as it's solid, and he's written most of Phoenix. HOWEVER, caveats: 1. I'm not sure that I'd recommend reading a book on Phoenix before really grasping the OTP foundations that it's built on. Phoenix will be accessible if you've worked with any kind of modern Rails-like MVC framework, but I'm not sure that you'll really be approaching the ecosystem from the correct angle if you head to Phoenix first. Elixir's a great language, but again, it's just a language - Phoenix and many Elixir libraries are built on OTP, and understanding OTP is vital to understanding what Phoenix is actually offering you. 2. Depending on what you're doing, you may not really need Phoenix at all. It's a really nice toolset if you don't want to have to think about server-side backend at all and just put pieces together, but because it's not as polished as something like rails, it's not always an easy path forward when you're leveraging it to do even slightly advanced things. Be prepared to dig into source code, update stale dependencies in support libraries, and get your hands dirtier than you would with something like Rails. 3. Phoenix is not Rails. It offers an eerily similar set of paradigms, but it's a much thinner toolset and relies on you for much more of the main system library and architecture, especially with the better division of the `Web` module in 1.3. It certainly does the job as the back-end of a site with a robust javascript front-end in React, Vue, Angular etc, but be prepared to use it more as a part of a larger Elixir application (which it is), than for it to be your whole application in the same way that something like Rails strives to be. 4. Chris McCord's Phoenix books hits all of the essentials, but doesn't go into them in a lot of depth. Again, if you've used any kind of MVC framework this book will feel a lot like a tutorial on how to use THIS flavor of MVC. There's a lot more depth in terms of the use of channels etc, which goes a long way toward explaining how you might use Phoenix.Presence to build something like Slack, etc, but don't expect the book to hold your hand much on anything beyond that. I personally read SaÅ¡a JuriÄ‡'s great Elixir in Action book (Manning), which gives a really nice foundation of using OTP. If you prefer to be closer to your metal, you could easily forego Phoenix and build a pure-Elixir OTP application that's just as fast or faster. Similarly you could just use Jose Valim's Plug library, which Phoenix also depends on, to get the same data-transformation-oriented call stack functionality that's really handy in Phoenix, without having to Grok the rest of Phoenix. There are also a lot of REALLY smart guys in the Erlang community who have published books about OTP in recent years, which for a long time was not a convenince that new Erlang developers had. Francesco Cesarini and Eric Merritt both have outstanding books on OTP. Joe Armstrong, one of the co-authors of Erlang, is also just an all-around-brilliant guy and probably has more experience writing with and about Erlang than anybody alive. Fred Hebert is another insanely smart guy and wrote the popular Learn You Some Erlang For Great good. Justin Sheehey is the CTO of Basho (creators of Riak and Webmachine), and he's another "I'll listen to anything he says" guy in the Erlang community. ALL OF THAT SAID I just finished a very basic Phoenix 1.3 application and am very happy with the stack, though I was leaning on my front-end more than my back-end, and was mostly using Phoenix to build an API. I liked Ecto more than I thought I would, especially since Ecto 2.0 got rid of the idea of models entirely (structs don't have to be objects, and shouldn't be in a functional language), and would recommend its usage with or without Phoenix. I also consider Rob Conery's awesome Moebius data access tool, but for this particular project I was going out onto other technological limbs and thought going with a straightforward Phoenix build made the most sense in terms of budgeting my time. Sorry if I've strayed from the matter at hand here at all, but I found myself in your precise shoes once, and wish that I'd been told what I've just offered.
I don't want to negate the effort put into an open source project, but I'm having a hard time seeing the value in bringing in a dependency for a library where the with macro works perfectly well. It seems that this only really exists to obscure what's happening at the language level. Is there a use-case I'm not seeing?
&gt; I don't want to negate the effort put into an open source project No no, I absolutely understand your point. To be honest, this project is just a "experience" around the macro. I'm pretty sure that I continue using "with". So I totally agreed with your point. 
Thank you :)
` def __using__(_opts), do: quote do: import Deal` Seems a bit heavy - users can just `require Deal` ?
And only $20! That's a steal.
All my Shopify apps will be prototyped in Elixir / phoenix. It will give me purpose and not just follow some tutorials.
Still working on my hybrid turn-based/RTS game. I have the server in an alpha state. Just working on getting the Unity client to feature parity and fixing server bugs along the way.
Neat! I've been building something similar this week with Ecto, Postgrex and GenStage: https://github.com/mbuhot/ecto_job/ 
[EctoJob](https://github.com/mbuhot/ecto_job) A transactional job queue based on PostgreSQL, GenStage and Ecto. Very early work, but it's been great fun to marry up GenStage with Postgrex.Notification and Ecto.Multi. Maybe one day I'll be able to drop a redis dependency :D
The best design is generally one that models the natural concurrency in your application. So if you have, e.g. a chat server, then it would generally make sense to have one process per connected user. That allows the server to keep the transient state of the user (e.g. authentication) in a process, and kill the process when the connection is lost. Similarly, in a HTTP server, you would have one process per request. In a perfect world with no shared resources, then that's all you would have. The process that handles the request also generates the response to the client and returns it. In practice, we tend to have state shared between users/requests. We can put that in e.g. ETS, and then the Erlang VM handles concurrent access to the table. Or we can put the data in a relational database. Then the db becomes the bottleneck, as databases have trouble with lots of concurrent requests due to locking. So we end up with a connection pool which keeps a number of connections open to the db which the db is happy with. Then we have a concurrency bottleneck as each HTTP request handler process needs to check out a connection, use it, then return int to the pool. There is a fair amount of useful infrastructure in OTP to handle tracing, etc. So generally any process you spawn should probably be a gen_server or more specialized type like a state machine. But if you are making a "server" using gen_server, the fundamental effect is that you are keeping state in the process and serializing access to it using messages. The gen_server can only handle one request at a time, and it will become a bottleneck under load. So I sometimes say that "gen_server is a code smell". People use them when the don't have to because they are coming from an object oriented background, or they think it's cool to run more processes. Answering your specific questions: I would not expect a gen_server to be useful for parsing an XML file and inserting records into a db. I normally do stuff like this using a custom mix task. For the db connection, you can just use Ecto, which will give you a connection pool under the hood. If you do spawn a process, then you can register it under some atom, which allows you to call it from other parts of the app by name. And you can use a more sophisticated process registry like gproc. Symbols are global.
Thank you so much for your answer. All is more clear now. Can I add a last question? I tend to parse big log files, and i was wondering if using multiple processes would use more core and gain in speed?
You can often just use [Task.async_stream](https://hexdocs.pm/elixir/Task.html#async_stream/3) for parallel processing
Yes, as far as I know, it is discouraged to provide a "use Foo" when all it does is "import Foo". Just tell users to import the module instead.
There was a great talk at empex that explained when concurrency was worth it. There is overhead in spawning processes which _could_ lead to slower processing speeds such as when you're doing something simple like `1 + 2`. Also for parsing large log files, you could look into `Flow` which is pretty much a concurrent Map Reduce abstraction.
Is the plan to eventually hook receive into WebWorkers?
&gt; You can often just use Task.async_stream for parallel processing Which, FWIW, does create multiple processes. If you can build your data import pipeline to use [streams](https://hexdocs.pm/elixir/Stream.html) throughout, then you can pipe everything into `Task.async_stream` and have that task do the DB insert operation. I just did this with a large log file import and saw a 4x speed improvement (and 400% CPU usage!) with just that one extra call, because everything upstream was architected to lead up to that point.
WebWorkers aren't ideal for a few reasons. The thought right now is to either use generators or some other unknown way. For instance, I think think the way tail call recursion is implemented may lead down some path to an eventual implementation, but nothing specific just yet.
Thanks for the explanation. Itâ€™s an interesting problem space, and Iâ€™ve been watching the project evolve, keep up the great work.
good article on the subject http://theerlangelist.com/article/spawn_or_not
Currently, it's because `Process.info` is a simple wrapper around `:erlang.process_info`, as can be seen [here](https://github.com/elixir-lang/elixir/blob/v1.5.1/lib/elixir/lib/process.ex#L640). Erlang itself has this in [the docs](http://erlang.org/doc/man/erlang.html): badarg If `Pid` is not a local process. Emphasis on "local". So it could be argued that it's for backwards compatibility, I guess? It could be easy enough to add remote functionality to `Process`, but I can't help but wonder if there may be some underlying gotchas with that, possibly with performance.
We do something similar on one project. We have a set of static data which gets read on start up and loaded into an ETS table. It's stored as a CSV file with a text key and and about 1kb of JSON. It's about a million lines, so about 1GB of data. As the amount of data grew, it started to take four minutes to load. I optimized it to use parallel parsing, and now it takes about 15 seconds. One of the most important things is to avoid interleaving I/O and processing. So having a single process read a line, parse the csv, then parse the JSON, then insert the result into ETS is *much* slower than separating the process into multiple stages, one of which reads the data from disk, another which parses, and another which writes to ETS. This obviously gives opportunities to parallelize across multiple CPUs which sped things up a lot, but the big win was avoiding task switching when doing I/O and thrashing the scheduler. A similar process generates the CSV by reading records from a database, joining with other tables, transforming the data, generating the JSON and writing it to disk. Optimizing it to use parallel tasks and batching I/O took it from 30 minutes down to less than four minutes.
Should definitely open it up to people who want to work remotely. Specifically from Glasgow... haha
I got the vue webpack template working with phoenix for a project, which makes hot reloading work during development. It's a blast to get the best things of both worlds
cool!
In that respect then, I salute you :) I've got plenty of open projects that were basically learning experiences for me as well.
&gt; Calls to Erlang functions that the Elixir standard library make have to be reimplemented in JavaScript. I'm curious why, if they have to be reimplemented, you're requesting they be reimplemented in JS instead of Elixir?
There are many calls in the Elixir standard library that either call Erlang functions or are compiled inline to Erlang functions. There is the possibility of ending up in situations where there are circular references if implemented in Elixir. There is another way to help though. There are places in the Elixir code base where some calls to Erlang functions could be replaced with calls to other functions in the Elixir standard library. Making those kind of contributions to Elixir itself will help Elixirscript out. There is only so many places where those changes can be made though.
Higher level functions like :sys.get_state are implemented in plain Erlang, using message passing, so it doesn't matter what node the PID is on. However :erlang.process_info is a BIF, a low-level function implemented in C that directly inspects the process in memory. So it doesn't make sense to pass it a remote PID. https://github.com/erlang/otp/blob/aa8df5238a20a539bc90deb68aa39050197ba725/erts/emulator/beam/erl_bif_info.c#L971
To give a bit more context from the Elixir side, a good chunk of the functions we call from Erlang are actually implemented in C or inlined by the Erlang compiler. Those are typically functions in the `:lists`, `:maps` and `:erlang` modules. Those need to be implemented in JS also. All others most likely can be reimplemented in Elixir.
To Gary Rennie - what is your favourite git command, and why is it git reflog? 
We are working in a bank building with Elixir.
what bank are they hiring mine isn't using elixir that I know of and I want to!!
Yes and yes.
Registry lets you use any term, not just atoms, so you can use it for dynamically created processes. Process.register is more like a way to register singletons.
Thnx for your hard work!
So long web folder! You won't be missed!
When are we getting the `h` iex helper for erlang modules :)
Some good notes on what Elixir is, what it is good at / not so good at. 
Image made me think this was a just google it shitpost. Love it
My team (Pocketworks) is still working on an IoT gateway product that forwards data from sensors to the cloud. And the cloud product that receives sensor data and sends that onto another data store, and also provides UI features for managing the gateways I'm not a coder by day, but one Elixir side project is a web crawler that finds niche products for sale so I can find the best prices from boutique shops. I'm hoping to get more into OTP on this at some point. And another is a Phoenix web app that allows people to create online competitions. 
We're considering it carefully :)
I'm not sure if I missed something, but it seems like this article is telling a story of ignoring thoughtful system architecture, because you can just use a faster web framework. Rails is certainly slow, but if I'm going to need a close to real time as possible system, I don't think I'd write another monolithic app in a language/framework that's simply faster. I would look at ditching the all encompassing CRUD application approach and focus more on designing a system around CQRS.
Next up, a post on why we resized our font from 14px to 18px
&gt; You have made some really good points there. I looked on the net for more info about the issue and found most people will go along with your views on this website. &gt; - Chad
But can there exist an elxir blog post with no mention of pipe? The world may never know.
I think reducing the Rails v Elixir comparison to slow v fast dilutes the contrast between the two platforms down so much to essentially ignore exactly what the Erlang/Beam/Elixir platform strengths are.
You might wanna take a look at https://github.com/imranismail/turbolinks
You already know there are two ways with pros cons. Both works. If it's UI heavy app, you cannot avoid to use client-side rendering libraries such as react. Also if the app will provide the api then it may be better to use api with client side rendering. If it's simple app then just let server return partial html and replace the existing dom element.
They look wonderful! How big are they? 
Thanks :D They're 8 x 5 cm
Would be perfect for the [Elixir With Love](https://www.elixir-with-love.com/) conference coming up in November.
Sounds like an amazing conference :) Unfortunately I wonâ€™t be able to attend but Iâ€™d be happy to work with the organisers to get some printed for it.
Sadly not :( I am looking at prices for shipping them to people though :)
Woo! Gay elixir!
Wonderful &lt;3
Regarding building that ring: can't you build another ring with updates? So you look at the update ring first then the full and then rebuild the full ring once in a while in the background. 
Gaaaaaay
"no" |&gt; probably()
"shipping" should cost no more than a stamp.
Correct ðŸ‘ðŸ»
;-) BTW, nice stickers!
lsd elixir, i didn't see that coming.
Not quite ðŸ¤”
Check out this: https://robots.thoughtbot.com/how-we-replaced-react-with-phoenix
GenServers carry their own state already, why would you want to do this? If you really do have more complicated concerns, you should probably have a supervision tree anyway to reflect your needs. 
&gt; GenServers carry their own state already yes, of course. that's what this blogpost is about. :)
Sure, sorry, didn't mean to imply you didn't know that. I'm just failing to understand the motivation for this particular topology, as opposed to a single GenServer, or a larger supervision tree. What I mean by that, is that the state you're carrying around here isn't a separate operational concern, it's a conceptual concern, so the breakout should usually be at the module level, and then you can carry that state with you, and invoke functions on the module instead. 
thank you for the response. i understand that i have to learn a bit more then. :) i will most definitely dig deeper into supervisors and Elixir in general and will come back when i will manage to write something more comprehensive about both of them.
amazing, i want one!
Drop me a message. Iâ€™m happy to ship these on a small scale :)
For data-structures, the official rule is that we call the Erlang one for performance reasons. Some of the functions are implemented in C, because the underlying data structure is implemented in C, such as the maps module and some other functions are inlined by the compiler (such as the lists module). If not one of those cases, then it should be implemented in Elixir.
So if the Erlang version is implemented in pure Erlang, the Elixir version will be implemented in pure Elixir, but if the Erlang version uses C/NIF/native/etc. then the Elixir version calls the Erlang version. That makes perfect sense. Thanks for the reply, Jose!
Also, I think its important to point out that for the `Enum` module at least, some of these functions are "delegated" like you showed in order to support polymorphism.
I did! I actually even wrote a blogpost about it https://zorbash.com/post/elixirldn-2017/
I've removed this article as I didn't like the avatar that came with it. I'll republish it in a minute
So while I have been waiting for Phoenix 1.3 to break from release candidate to write the next article in this series [Create an Elixir Phoenix API](https://medium.com/everydayhero-engineering/create-an-elixir-phoenix-api-part-1-initial-barebones-setup-7c840a6c4c5c) I thought I'd write an article on lenses. I started wanting to learn what is a profunctor, contravariant vs covariant function and the other FP goodness, and how to apply it to Elixir. Props go out to https://github.com/purescript-contrib/purescript-profunctor-lenses for inspiring this. Along with https://github.com/tpoulsen/focus for already having a pretty nice Elixir Lens library.
I don't really understand what you mean here. Can you elaborate with an example? I'm also having trouble understanding when to use the Erlang functions over their Elixir counterpart. Very interested to know in which cases calling an erlang function has a ton of increased performance 
Phoenix 1.3 is out for a month already, no?
If a function is implemented in Erlang or Elixir, you should not see a performance difference. There are some few functions that are implemented in C but Elixir conveniently wraps or inline those. You should not worry about this, Elixir handles it all for you.
It has been yeah. This has been sitting in my draft for a while, plus some other ideas and learnings for the last few months. I wanted to get this out and now move back onto phoenix
Any progress? I'm working on a similar project, kinda stuck at nested comments (and then preloading associated users as well to display names, in the whole tree). Here's a discussion with more context from another dev: https://stackoverflow.com/questions/45497655/elixir-phoenix-preload-association-with-self/45819254?noredirect=1#comment78606494_45819254 Looking forward to your reply :)
Hey, nice post! And thank you for the kind words about focus.
Loving it!
Happy to hear this still being tracked. I'm actually planning to open source everything probably as early as the coming weekend along with linking the production site that uses the libraries (woulda been last weekend if I didn't tweak a back issue). I can tell you that for my nested comments query it's one of the few I did as raw sql. I used postgres WITH syntax and have found that to be pretty flexible and it certianly does work (with user). I think it well work well with plans I have to add a caching layer to it as well but I'll be interested in opinions of how it will perform at scale. Anyway, unfortunately I don't have any insight into your specific issue with ecto there, I do use ecto a lot but maybe not deeply enough to help debug that one at a glance. So maybe not be going exactly the same direction but I'll try take another look and do let me know if you think I can help somehow before the source is all available
[EctoJob](https://github.com/mbuhot/ecto_job) A transactional job queue based on PostgreSQL, GenStage and Ecto. Very early work, but it's been great fun to marry up GenStage with Postgrex.Notification and Ecto.Multi. Maybe one day I'll be able to drop a redis dependency :D
It's certainly being tracked :) How will you communicate the source: new topic or a reply on this topic, or something else?
Once it's made availabe on github I'll make a follow up new post here describing what was done since this post and maybe double it up on the elixir forum. Posted the query on stack btw for now before you can view the full source 
[Playing around](https://github.com/rhnonose/swarm_test) with [swarm](https://github.com/bitwalker/swarm), learning how these things works. Next step is to use something like Kubernetes.
[ExGdax](https://github.com/bnhansn/ex_gdax) an API client for GDAX. Working on the websocket client for use in real time crypto trading.
Real time request monitoring platform with metrics like requests per second. Online interval checking and triggers that will fire webhooks based on the criteria set. Most importantly build for speed and to scale. Please take a look and if you have any recommendations for what would be cool to see tell me now. http://g.recordit.co/9KhT1dvWWs.gif EDIT: for whatever reason the gif recording software I used sucks so the link above you may get a 403 by clicking it. Just copy and paste it in a new tab should work
I get this on iTerm 2 on macOS, as well. Might be worth filing an issue on GitHub if nobody here has a solution.
Ok, I've filed an issue. I hope it's an IEx/Elixir thing. I have a bad track record of posting errors, and it being due to something else and getting reamed in the github comments for it, I'm always hesitant for file bug reports haha. But if you're getting it in iTerm, and for the reasons I listed above, I don't think it's an OSX thing. 
I get this in Terminal even outside iex. It happens even when I ssh into a remote server. Sometimes terminal even crashes if I hit up to a multi-line command then hit down. Not sure why, assumed it was something on my Mac.
Its a terminal thing. It happens to me a lot dealing with ruby consoles, as well as remote consoles like shelling into heroku. I think its an issue with readline, and happens primarily when i resize terminal windows after the shell has been opened. So mostly I don't do that and ignore it. :)
This has happened to me a lot too since 1.5. iTerm 2.
Good reading! However (sorry there is a however), IMHO what algorithm challenges lack is the ability to train you to properly abstract real problems in the language you are learning. For example, after these algorithms challenges, try to write a client for a restful service with a intermediate level complexity. You probably still feel difficult to decide when to use functions or macros, when to use those OTP patterns, how to organize modules / applications, etc. 
Yeah I totally agree. Maybe I can update the article to keep it clear that this kind of challenges are more useful when you're just starting to learn a new language and need some exercises to practice in order to test and internalize the stuff you're learning. After understand the basics of the language, the next step should be create throw away apps and keep moving :) 
Good work! Looks like it was [tracked down to a bug in Erlang](https://github.com/elixir-lang/elixir/issues/6504#issuecomment-324788871) which has already been tackled.
This seems more like a framework to test your learning, rather than the actual learning. That is, it's a kind of test-driven development. It doesn't necessarily tell you the best way to solve the problem or think about the problem in Elixir.
The intention was to show a way to practice what one is learning.
Thanks, I think it should prove useful.
Just finished up setting up a Phoenix app on google's container engine. I can't imagine actually setting up the kubernetes cluster myself tbh. Experience was pretty good. I've setup circleci for CI/CD which is probably my favorite part. Very slow cycle of development but worth it once it was setup. 
Thanks and you're welcome!
Looks neat. The menu to the top right does not work on mobile safari on iOS 11 public beta. 
Doesn't work on chrome for iOS 10 either, but still nice. 
Getting a 500 error on the reddit app browser on iOS 10
Good to know, I'll look into it!
Yeah I've had a bunch of people tell me they're getting 500s and yet I haven't been able to see issues with it running. Ill have to inspect the Heroku logs when I get home, thanks!
Also get a 500 (android, reddit sync browser)
Looks like it was tracked down and it's an Erlang thing, not a Terminal thing.
Did you have any programming experience before? How long did it take you to learn Elixir/Phoenix?
Yes! I've been a professional software engineer for the last 8 years and it took me only a few weeks to learn it since it's very similar to Rails, which I also know. Getting some of the paradigms of doing things the "Elixir way" took a bit longer, but in general it was fun and productive from pretty much the beginning!
Any browser on iOS is technically a wrapper around safari. So this sounds like an iOS Safari bug :) Hope that helps!
I'm guessing you have `priv/static` commited because you deploy to heroku? You should hook it up to CI like Travis. Edit: You got some keys showing: https://github.com/acconrad/peergym/blob/master/config/config.exs I hope those are not important in any way. 
Yup I scrubbed the important keys, good thoughts on using CI! 
I am currently building a little phoenix website and have trouble with the simplest of things as it's not always easy to find where to look for answers. I'll use your source files for inspiration thanks!
fixed!
these should be fixed! 
went into the logs and got those fixed, thanks!
I haven't used elixir for a while now, but I'm pretty sure you shouldn't commit `priv/static`. IIRC there is a heroku buildpack that will compile the static assets before it deploys. That way you don't have to run asset compilation (in production mode) every time before you commit.
Ooh good to know! I'll look that up tonight when I get home, thanks!
Generally you should avoid using process dictionary, implicit state is not something appreciated in erlang/elixir. But, there are cases when this implicit state is just a right tool, like logger or metrics metadata. You do not want to pass this things through your explicit state full of business logic. Speaking of OTP keys in process dictionary, I've never seen any use of `$ancestors` and there was rare case of overriding `$initial_call` to make crash reports more readable. 
No problem, I believe itâ€™s mentioned in the guides. https://hexdocs.pm/phoenix/heroku.html#adding-the-phoenix-static-buildpack
It is!
We are trying to set up a regular meetup in my city. This will be the first event, and we're trying to get enough interested people that we can have more in the future. :)
IIRC Ecto uses the process dictionary as a side channel to hold the current connection during calls to Repo.Transaction. I think the Logger metadata system also stores data in the current process dictionary. Basically the same uses as when you might have used a thread-local variable in Java/.Net app.
Nice! Wish that there was something similar in Sweden (Gothenburg).
There can be if you start one! There was nothing here, so I just got a friend and myself to talk and invited people. There is literally no quality bar to get over, we just want to meet other devs and hang out.
Yes, there really are no excuses, It would probably not be very difficult to get something started, there already is a hackerspace so could probably just ask around there. I have quite severe social anxiety though and engagements like these no matter how minor are absolute terror for my mental health. But if someone else takes initiative I would be happy to participate.
saved-you-a-click: yes
There is an Elixir meetup in Gothenburg! It's hosted by Football Addicts. Check out @elixiraddicts on Twitter :) 
Wonderful :) A quick google search could have informed me about that, very sloppy to just assume there was none.
When Rails just once gives me sub-ms response times, I'll start buying into the FUD. So that's never.
Yeah, I know that difficulty. I've always been shy and hated public speaking, but I agreed to hold an Elixir presentation earlier this year just to at least do it once. I thought if it went badly, I'd never do it again but at least I'd know. It went surprisingly well and I got positive feedback so now I'm doing it again. :) You can also just be an organiser. Even just setting up a chat online or a topic on the Elixir Forum could land you contacts that could hold a speech. PS. I like Gothenburg. Been a while since my last visit.
Haha, the problem solved itself! :D
Nice! :) Drop me a pm if you are ever in gbg and I would be happy to buy you a beer.
Haha thanks, I will keep that in mind. I will do the same in case you ever come to Tampere.
I came from /r/Tampere and I'm first time hearing about this language. What are the main selling points why I should choose Elixir instead of like Rust?
Good question! Things I like: The language itself: * Functional programming with immutable data, makes reasoning of code easier * Lovely syntax (in my opinion) * Syntax helpers for often repeated things (`|&gt;` for pipes, `with` for nested conditions) * Full unicode support * Macro system for expanding language * Useful things like GenStage in standard library The virtual machine (BEAM): * Unparalleled distribution features (actor system, light isolated processes, soft realtime, distribution to many nodes) * Easy to take advantage of distribution for problems (thanks to the above) * OTP framework with ready made boilerplate for usual distribution things * Programming model guides towards fault tolerance * Hot code reloading The ecosystem: * Language comes with buildtool / task runner (Mix), unit testing framework (ExUnit), documentation generator (ExDoc), de facto package repository hex.pm, and is easy to start with (generators for typical project templates) * Most popular web framework Phoenix is very well done and has realtime features with WebSockets builtin * Ecto is one of the few DB libraries that don't get in my way It's not really a question of why you should use Elixir over Rust, since they are aimed at pretty different things IMO. Elixir is mainly for implementing highly distributed systems (and even basic websites can benefit greatly from its distribution features). I'd like to see BEAM implemented in Rust some day. :P
Thank you for briefing! I'm going to look more into Elixir. Sounds like something you could maybe do some nice web service with.
Yes! I've made my own blog engine and a programming statistics website so far.
I hope I get the opportunity to take you up on the offer. :) It took me until now to realize that Tampere is Tammerfors (in Swedish). :)
Going to take a look into your voting part tomorrow.
Out of curiosity, are most postings in Finland written in English?
Many dev meetups are in English because there are many foreign or immigrant employees of IT companies that don't speak Finnish that well. Mobility between countries is much higher in this industry sector I think.
my impression is that at a minimum you want a vm.args file for each node, and a config file for each node that tells it which nodes to be aware of and the timeout to wait (before either failing your node or giving up). That's all I've needed to concern myself with at a minimum and that functionality is exposed through build and deployment libraries like edeliver/distillery. Not a direct answer to your question but maybe some things to start with? You could check what your current platform does toward booting up each env within the beam and see how flexible it seems. Personally I do more manual labor than you'd want atm but have successfully been deploying a system with 7 nodes (4 redundant services, another set of 2 redundant and 1 other) on different servers and it has involved few issues. You can probably get going no problem but you'll likely want deeper knowledge of OTP/BEAM for any troubleshooting 
In my opinion OTP principles are in many cases orthogonal to the mentioned (and some other) cloud solutions. Erlang virtual machine is designed to perfectly utilize hardware resources, it allows to bind schedulers to the physical CPU's according to the CPU topology, tune memory allocaton, etc. All these optimizations lose their power in virtual environments. Also it is often more difficult for Erlang nodes to communicate in virtual networks. It seems to me that the best option to make Erlang shine is to provision Erlang apps directly to hardware resources or use cluster orchestration tools which allow direct access to the hardware for the apps, like Mesos.
Creating a minimal docker image from a distillery release is a breeze, just build and copy the archive in. If you're looking at Kubernetes, I suspect you can get quite far without needing to cluster the erlang nodes at all, ReplicationController/Service/Endpoint mechanisms in Kubernetes. [this blog series](https://blog.polyscribe.io/a-complete-guide-to-deploying-elixir-phoenix-applications-on-kubernetes-part-5-clustering-6c30fcd35ce1) has a fairly detailed guide. 
AFAIK, all that matters for TCO is that the absolute last piece evaluated in the recursive function must be the call to itself. Having multiple heads shouldn't matter, they're all compiled down to one function with separate clauses in BEAM, and should be just as optimized as a single function directly calling itself. I don't know whether there's any possible TCO for a pair of mutually recursive functions though, I would assume not but curious if anyone knows definitively.
The Erlang VM actually implements last call optimisation, so as long as the last instruction is a call, to any function, in any module, it will be optimized away.
I use kubernetes actively on 2 elixir based projects. I highly recommend it. Distillery like /u/mbuhot said + that guide is a great place to go. For quick setups I actually use helm to deploy things like let's encrypt and postgresql. More complex I will actually define them all out. 
Somewhat true, but more importantly is to just deploy it in the least frictional way, which may imply containers, and then measure and check if you actually need that extra omph - and then if you have to go through the pain of whatever
Mesos has actually been an extra layer of abstraction that doesn't buy you much over just doing a distillery release on a VM. Our team has had a lot of trouble with it; beam doesn't behave nicely in a container (ran into lots of issues with it thinking it had more memory than it really did). Deploying on regular old EC2 nodes has been painless. The only reason our team deployed to mesos with containers was to match the rest of our engineering organization; the only thing we've gotten out of it is pain. 
As much as I like seeing articles about Elixir in general, this is such a sensationalist TL;DR ("amazing built in feature") and long-winded article for, well, just plain old usual doctests as seen in most dynamic languages like python, ruby, etc. Don't get me wrong, I use doctests all of the time and am glad Elixir has them, but the whole article feels like a beginner programmer just discovering Elixir and trying to make headlines out of the most basic, unremarkable features the language has. Edit: Not sure why that irks me, but it does. Maybe because this kind of blogpost participates to the increasing pain that reading "news" in the programming ecosystem is becoming more and more. Feels like eternal september is still getting worse decades after it started :-(
Try configuring `ex_json_schema` resolver using a module instead of an anonymous function: config :ex_json_schema, :remote_schema_resolver, {MyModule, :my_resolver}
Thanks! I find k8s very daunting at first maybe I should read more about it. I wanted a zero configuration setup like heroku but not sacrificing the part of clustering. I've used Nanobox.io but I'm not sure if that is any good? Thanks for the link to the blog post!! 
Thanks for your detailed answer. Very helpful. I'm currently using distillery and docker and was looking for an automatic way of scaling the nodes, maybe after all it won't be so bad to do manual labor. I'm currently stil looking into otp and what all the things are which it can do
&gt; "but the whole article feels like a beginner programmer just discovering Elixir and trying to make headlines out of the most basic, unremarkable features the language has." You nailed it. Sorry to bother you. It was not sensasionalist though. The languages I had exposure, none of them I saw such features so I really liked it. In the same way I have never seen it, maybe it could show those features for some even more beginner than me. Who knows? And also a great motivation I have to write articles is to register it for the future-me. I always check those articles to remember something. I didn't know what is "eternal September". Just read it here now. One more time, sorry to generate such pain for you, I'm working hard to improve my knowledge and create more useful stuff. Many thanks for the feedback, I really appreciate it.
That's really interesting experience, since we a currently trying to consolidate our dedicated hardware resources with Mesos, but not yet sure (have not made enough experiments) whether to move Erlang services which occupy whole hardware servers into cluster. Could you please tell, were you running beam in Docker or under cgroups?
You should open up an issue in distillery. They should parse the config files after they generate to check for any malformed syntax. Better to find that at build time rather than in production.
Ah, that makes sense. (No need to remember/store anything so free to reuse stack frames)
I've been having this debate recently too. Doesn't seem like a language that looks more or less tailored to be an API to begin with would benefit much from a large framework.. elixir gods that can provide insight much appreciated
Hi! First of all, Phoenix is not "another monolith like Rails". In fact, Rails is far from synonymous to monolithic applications, too. At my previous employer we've had great success in building very small single responsibility web applications (micro services) in Rails. However, where Rails is more of an "all in" approach to building web applications, and has very strong conventions to make you do the "right thing", Phoenix is comparably small and basically adds more advanced features to Plug (which is comparable to Ruby's Rack, in some way). If you're interested in building micro services, that can be easily done with Phoenix. It's trivial to _only_ use Phoenix's router, for instance, or the JSON response wrappers, without including any other features. Phoenix is pretty modular, exactly because Elixir has no global state and because Phoenix is built around Plug's architecture. Obviously you could also just use plain Plug for that, but Phoenix has some features that make building these applications more efficient. To answer your question: yes, Phoenix very much benefits from the powers of Elixir. Elixir's stateless nature and the functional programming aspects combined with Plug's architecture make it the perfect framework for high performance web applications (wether they are micro services or full blown front end apps). Hope this helps!
This. Phoenix is not a heavy monolithic framework. In fact it's easily decomposable to what you need. You can think of it as a Plug (think Rack in Ruby) project with some boilerplate, helpers, and conventions. If you look at the Endpoint module in a Phoenix project you can see all the extra plugs that Phoenix adds and you can add/remove them as you need. As the parent mentioned. You can only use the JSON response wrappers without using other features and you won't have to worry about the overhead of framework code you don't use. [edit] Said Elixir, meant Phoenix.
`s/Elixir/Phoenix` in your first sentence ;-)
Ooh whoops good call :)
Elixir/Erlang/the BEAM is a platform tailor-made for writing microservices, before the term ever got popular. Every Elixir application is inherently based on microservices. Think about it like this: Every Elixir application uses a ton of GenServers (even Phoenix, although you can get away with using it without realizing that). Every GenServer is, effectively, its own microservice. Phoenix itself is not your application, and this is one of the reasons for the big change in the default project layout and generators in 1.3. Phoenix is a microservice (or set of microservices) that provide a layer to translate your application logic (almost certainly composed of many more microservices/GenServers) into HTML or JSON over HTTP. Basically, break away from thinking that microservices have to talk to each other over HTTP and run in separate OS processes and think of the BEAM as the platform for your microservice architecture.
For a heroku style experience that works with clustering and hot upgrades you might want to try [gigalixir](https://www.gigalixir.com) which is built on Kubernetes. 
http://ferd.ca/on-the-use-of-the-process-dictionary-in-erlang.html
Oh! Duh, yeah that makes sense... I just kind of forgot it was the stack frame no longer being used that matters, not what's about to run on it... Now you phrase it that way I assume pretty much all TCO must work that way, because why wouldn't it/why would it ever matter what function is being called as long as it's the final instruction? I heard Ruby has a compile time flag to enable TCO years ago but never investigated, and forget/never heard why it's not enabled by default... Curious if anyone knows offhand.
your https cert has expired
Awesome work! 
The documentation is absolutely abysmal. 
Whoa â€“ slow your roll there :D The readme includes a nice architecture diagram, and well formatted examples and options to the main public interfaces of the library. That is above and beyond the majority of projects already. As this is a young library, I'm sure docs could be improved, but this is being offered to you free of charge, on the back of fredwu's free time. Reading these kinds of comments as a maintainer after you pour yourself into a piece of work is not a fun experience. In the future, try to be constructive or, gasp, help out with docs where you find gaps! /rant This library looks awesome! Great stuff.
Hey thanks, this worked for me! I just wanted to follow up
Now i have a extra reason to dive into elixir even further. 
Also, disregarding all the true and constructive stuff youâ€™ve already said, regular Elixir source code is incredibly self evident, and I donâ€™t think there should be too many problems or it should altogether be unreasonable for most developers to simply add the dep and open the library. Edit: words
Speaking of a crawler, I'd like to have your babies
&gt; Not only does homoiconicity give us powerful metaprogramming tools, but itâ€™s also sublimely beautiful. &gt; ... &gt; If this has shown us anything, itâ€™s that homoiconicity is something special. Homoiconicity is a complete waste of time AFAICT. I cannot relate to this ideology at all. 
&gt; If Elixir were homoiconic, we would essentially be writing these abstract syntax trees by hand, bypassing the lexing and parsing phase of Elixir compilation. I strongly disagree with that. While the code is more similar in structure to the AST, it is still getting parsed and converted to a much more verbose form in Clojure. That's also why Elixir wouldn't be as verbose as your example if it was homoiconic. A lot of metadata (like the context) would be left out in the actual code. Homoiconicity is really a great feature once you get used to it. But they probably decided to not go with it because a lot of developers are scared away by foreign looking syntax, which is a real shame. But I can understand and would probably have made the same decision. 
Any guides/pointers on the distillery + docker part?
Yes, because being able to add language-level extensions via macros as opposed to having to update the compiler itself is a complete waste of time. 
&gt; Yes, because being able to add language-level extensions via macros as opposed to having to update the compiler itself is a complete waste of time. You can add language-level extensions without macros (e.g. Mathematica) and you can have macros without homoiconicity (e.g. OCaml). 
&gt; Homoiconicity is really a great feature once you get used to it. Great for what? 
You could argue that LISPs syntax is objectively simpler, because there are virtually no special cases, there's just lists. And I did observe a few times in the past that people unfamiliar with any programming language understand LISP syntax more easily. But that doesn't work anymore once you are biased because you already know a "normal" syntax language. Also, structural editing like with paredit is a blessing even greater than Vim keybindings :)
I like the multi-stage docker build setup, since it guarantees that the build and deploy OS is the same. https://zorbash.com/post/docker-multi-stage-elixir-distillery-releases/
Great! Another one of those tricky differences between running with mix and making a release. I wish mix would warn when code in config files would break a release, eg calling `System.get_env`
Awesome sauce, thanks man.
A simple roll your own Public folder on your Dropbox. Did this after paperplane.io was sunsetting www.github.com/owyongsk/chameleon
&gt; You could argue that LISPs syntax is objectively simpler, because there are virtually no special cases, there's just lists. And I did observe a few times in the past that people unfamiliar with any programming language understand LISP syntax more easily. But that doesn't work anymore once you are biased because you already know a "normal" syntax language. Right. And pretty much everyone is biased by the age of 5 thanks to addition and multiplication in math. &gt; Also, structural editing like with paredit is a blessing even greater than Vim keybindings :) I'm guessing Mathematica's structural editing is equivalently-good even though nobody in their right mind uses its homoiconic syntax. 
I've read requests in Clojure-land to make a variant of Clojure for the BEAM.
There are a handful of ways to approach this. In order of increasing complexity: 1. Use a single Phoenix (Elixir) application and carefully define your contexts to provide a microservice-style architecture within a single "monolith" application. Basically, draw a hard line in the sand by providing good boundaries in your code. This is probably the best and easiest approach, to start! I highly recommend reading up on [Phoenix Contexts](https://hexdocs.pm/phoenix/contexts.html) before diving any further. 2. Use an umbrella project. This is a slightly more complex setup where your application still lives under one code repo, but within that you have separate Mix applications (supervision trees) that handle their own dependencies, supervision trees, configs, etc, but still run together in the same runtime and can communicate freely. Again, it's all about knowing how to draw boundaries in your codebase. 3. Create multiple, independent applications. This is another whole discussion as you'd have to make careful decisions about all the questions you mentioned above â€“ who can access the DB, the API between the applications, syncing state, etc etc. This is almost never the right answer for beginning any project, because the inherent complexity outweighs the potential benefits.
Thanks, seems the context solution is perfect for isolating services !
I would avoid sharing a DB between apps in a micro service architecture. These apps should community via their exposed endpoints only, not access data directly from their respective data stores. Checkout something like CAS (https://en.wikipedia.org/wiki/Central_Authentication_Service), or OAuth2 for authentication.
**Central Authentication Service** The Central Authentication Service (CAS) is a single sign-on protocol for the web. Its purpose is to permit a user to access multiple applications while providing their credentials (such as userid and password) only once. It also allows web applications to authenticate users without gaining access to a user's security credentials, such as a password. The name CAS also refers to a software package[1] that implements this protocol. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/elixir/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
already understand genserver but think that if reading this explanation would have got into it quicker than the others I've seen. Plus it points out useful functionality
any update on how far you got? I'll try and help if you haven't found a happy solution. I may not know enough about your env if using kub or docker but if you just want a start with some gulp/console tools or something I'll gist what I have
Supervisor module is named wrong. Also where's github link?
How long of a time do you need for this approach to stop making sense?
I think Kong may fill part of your needs. It's an API gateway based on nginx (essentially a reverse proxy with Lua plugins including oauth). It also allows you to add custom ids to your consumers. This means that when you create a consumer you generate a custom id, say serialized json object containing the username, user id and other info. Then when a user makes a request the upstream service that the request is routed to (your service) gets passed the custom id in a special header. Kong therefore does authorization (checks if a user is signed in and can access a protected service) and passes custom data upstream which lets you take that further, say role based permissions or something. This prevents you from having to hit the user service to get user info per request. 
How is the supervisor module's name wrong? [Here's the repo](https://github.com/pcorey/hello_recurring).
There are a few options for other situations. If the task is a "one-off" adhoc kind of task, using the `Task.Supervisor` module to start up a new process under your supervision tree that will just exit when its done. This is great for when you don't know when the next one will be or don't have the data to schedule it. If you'd like cron type functionality, there are packages like https://github.com/c-rack/quantum-elixir that will do that for you. Most of what you need however is available within Elixir itself, so check for that first.
For a current project I've been approaching it using a microservices approach. This is however my first attempt at microservices so there is likely better ways to approach it. How I approached authentication was by creating an identity service. This service has its own database, and all it contains are the users login credentials, access tokens, and a unique ID that represents that user that can be exposed to other services (this should never change). I opted for a UUID for the unique ID, as it was the simplest approach. But you could manage things differently internally, as long as externally you present it as the same unique ID (whatever that may be), so other services that depend on it won't need to concern themselves with changing IDs. How it all connects together will be if a user is logging in, they'll talk to this identity service. Upon successful login they'll now have an access token. When making another call, they'll pass along this access token which will be authenticated by the identity service, after which the external ID will be passed along to any other services that need to be spoken to. I also chose not to handle authorization in this service directly, but instead to handle that in another service. If curious you can checkout the [identity service](https://github.com/ZURASTA/gobstopper), however it should be noted it's far from being ready (not distributed yet, not optimised yet, missing a lot of important features still, etc.). 
I disagree. While this isn't Elixir related, in a game engine of mine I found homoiconicity to be a really nice approach for managing assets and code. So the scripting language I made for it, I structured it as a lisp-like. So my data assets (fontsets, asset loaders, UI, etc.) all became perfectly valid executable code. This had the benefit of simplifying the amount of engine work needed to integrate with all this stuff (only had to support one language/data structure vs many), made it easy to understand (not need to understand different formats), and made it very user friendly (could write this data explicitly, or might save time throwing in some other operation here or there, etc.). The biggest downside is it's not optimal, as you could make a much more optimal structure for each situation than this more generic form (but for my use case that isn't so much of an issue). 
Interesting, how do you handle deployment so that they talk to each other ?
I'm learning elixir and have a need for something like this. I've seen tons do examples of this kind of behavior but I have yet to see any examples of what tests would look like for the recurring process code.
While I'm not up to that stage yet. A gateway service will be created to expose the services to the outside world. As far as linking all the services together, they have weak dependencies with each other by using of each other's APIs (this avoids making the service itself a dependency), and release builds will simply package which services should be together on a given node. 
I see. I'm still quite new to Phoenix/Elixir, so this question may seem obvious. But what exactly are you gaining from this method besides decoupling projects ? Why is this method better than the new 1.3 context coupling ?
I can decide how the services should be distributed, so can scale up what's needed (you can achieve that with the other but not in the same manner). Although main benefit is my codebase doesn't have to be in Elixir. This was as much of an organisational restructuring as it was a technological one. For instance, elixir isn't going to be the most appropriate choice for every service, so this structure does help break those ties a little. But more importantly it gives people the flexibility to choose, as I've found Elixir is not a great choice when it comes to supporting other developers. While I knew it would be difficult to find Elixir devs, I figured devs could pick it up, but from what I've found many either aren't interested enough to do so, or struggle too much with this (the functional) way of thinking. As far as just structuring services like this in Elixir. It's unlikely the best way to go about handling it, it was just the way I landed on when playing around with ideas for how to approach it which had the qualities I was looking for. Phoenix contexts are a great way to structure your project. 
Last week we hosted our bi-monthly meetup. Here one of our presenters shares his usage of Elixir to create a shadowsocks proxy server to help avoid the great firewall.
Last week we held our bi-monthly elixir meetup. This is the first presentation where Matt discusses Macros. He's journey into discovery, how to use them and language features for how to debug them. This is the first time we've recorded and shared the presentations. If that's not cool to post here don't hesitate to let me know!
The key is to separate the timer scheduling from the event handling. Then you can test the code that handles the timer events by just calling the functions directly. You can then test the GenServer code by passing in a stub timer module to the start_link callback, validating that it starts the timer with the expected interval.
Great, thx for sharing
All of the main concepts in Elixir are still the same. It is less like moving and more like staying in the same place and evolving. New releases contain useful features but I don't think any of them invalidate previous learning materials. You can definitely pick any book and then read the release announcements on the website to catch up. The guides for Elixir are always up to date as well. As soon as 1.5 came out we have updated it to rely on some of the new language features when applicable.
All of them, as far as I'm concerned. Changes will be minimal at most.
Why did you not used the standard handle_call callback for the GenServer? Just curious, it is working anyway with handle_info. It's just that to me the more natural way to use a GenServer is via handle_call and handle_cast callbacks.
I believe it is because the GenServer handle_call and handle_cast callbacks are only called when the message is sent to the destination process using GenServer.call or GenServer.cast. Messages sent to a GenServer through another mechanism (such as `!` or Process.send_after) land in the GenServer's handle_info callback. Here's the documention section that explains this: https://hexdocs.pm/elixir/GenServer.html#module-receiving-regular-messages
Unless you are very beginner, official guide + some OTP resource (Little Elixir &amp; OTP Guidebook is my favorite) + personal projects are enough. Elixir won't break until 2.0 so at most you'll get warnings.
I'd really recommend not doing Elixir, and I say this as a self-taught engineer who does Elixir full time. The elixir community and workflow really depends on someone knowing software development right now. Even if you persisted and got through that, the companies that are hiring junior developers for Elixir are going to expect you to know another language fairly well, since Elixir and Erlang are so unusual to the rest of the community. Sincerely, learning new programming languages isn't hard, the important thing is not getting stuck or discouraged along the way. I remember how frustrating that was to hear when I was learning, but it's true. If you want something good to learn in that will also make adjusting to Elixir easier, Ruby has a fantastic community attitude toward people trying to learn and has infinite resources for it too.
Elixir is great, but it has it's strengths and weaknesses. &gt; It was recommended i use elixir Based on what? &gt; i dont want to waste too much time on python etc... if im going to end up using elixir Elixir is a functional language, it is a bit more challenging to understand the functional programming approach than an imperative/object oriented approach like python. I would not suggest Elixir unless your needs were closely tied to Elixir's strengths (high concurrency and fault tolerance).
I just went through a spree of reading on elixir and bought the following books and will give a small description on how I liked each. The Little Elixir &amp; OTP Guidebook: I really liked this book because the project it gave you to work on(worker pool) was more my style. I will say I think the chapters on distributed nodes was the best of the 4 books. This one was also second best when it came to learning otp concepts. Elixir in Action: This was my favorite book of the lot but in my opinion also the most advanced. If you are needing to deep dive into the syntax of the language this book will not help you as much as programming elixir 1.3 but is by far the best at covering otp concepts. Programming Phoenix: Productive |&gt; Reliable |&gt; Fast: I had some issues with this book. While it did what it advertised and I learned a lot from it. It drove me nuts that using html templated views was how the whole thing was wrote. The only reason I mention this is because it took a bit to "just write an api" while figuring out what to do with changesets because the book just shows using the changesets in phoenix views. Programming Elixir 1.3: Functional |&gt; Concurrent |&gt; Pragmatic |&gt; Fun: This is by far the best book for learning the syntax of the language and very well wrote. Does not go that deep into otp though and I think that is a bit more important and hard to understand then just learning the syntax. as for relevance because of version. They all still work just find. I would say that you might wait for the new programming phoenix book but still not much has changed other then folder structure. I was writing a 1.3 project while reading along in that book. As for the others the syntax may have changed slightly but nothing glaring that I can remember. But otp concepts are 100% the same and that alone to me is a reason you can use any of these books and find yourself in a good place with elixir. Edit: Only thing I remember to be out of date was elixir in action used HashSet in a lot of examples but that should be easy to just think in terms of MapSet when seeing it.
Funny that you mention "a basic rock paper scissors game", I actually put together a screencast on just this in Elixir. You can watch it here: [https://elixircasts.io/command-line-applications-with-escript](https://elixircasts.io/command-line-applications-with-escript) Hope it helps.
&gt; Tbh i dont want to waste too much time on python etc... That's silly, every programming language has an interesting twist. You can really fill out your mental toolbox by understanding concepts in different languages. I take every opportunity to learn new languages even at the most basic level. I like this site for the basics: https://learnxinyminutes.com/ As for elixir I recommend checking through: https://www.udemy.com/ If you use the 'Honey' chrome extension it can usually find a deal that brings the price down to around $10. Most of the prices on udemy say they're around $200 but I've never paid more than $10, and I've also gotten tons of free courses. I recommend this course: https://www.udemy.com/the-complete-elixir-and-phoenix-bootcamp-and-tutorial/ 
While I love Elixir, young language with a more difficult conceptual paradigm (BEAM / OTP / FP) might be more discouraging than sticking to Python, Ruby, or Java. Depending on if you're looking at programming as a next career, or if you're just a hobbyist, I find it difficult to come up with compelling reasons why I would choose Elixir first. To me the real appeal to Elixir is the fresh take on typically difficult problems in computing right now - concurrency, resource management, scaling, and failure resilience. The way Erlang / Elixir handle these issues makes it compelling to learn, but only after spending time trying to figure out why your Dropwizard SOA system keeps falling over (jargon intended). This is basically just to say that learning Elixir first will likely make your programming journey more difficult than it needs to be compared to starting with Python or Ruby.
Why put the test into the lib folder. What is the benefit of this ? 
In that way it's easier to open/find both files IMO. edit: I actually prefer to group files by feature.
"Being a programmer" is several distinct skills, only one of which is knowing a programming language. * Splitting a problem down to be solvable * Defining the problem well enough * Knowing computers &amp; the internet (shell, how http works, lots of small to medium sized things). * Understanding the structure of programming (loops, functions, recursion, etc). * Understanding external tools (databases &amp; their design, serialization formats like json or yaml, consuming APIs, etc). * Knowing a language (Python, Elixir) Only the last one is language dependent. And it's the easiest to switch back &amp; forth. I did Java in college, then learned Perl, C#, VB.net, Ruby, Elixir, Haskell, and others on my own. Each language you learn makes it easier to learn another. But that's mostly because the other skills are constantly getting better as you learn. I'd say to do your first few programs in python, then flip over to elixir for a few small things, then do Java, and you'll find yourself start having opinions on which is better / worse / more for you. Then go with it.
Hmm. Thanks stunt_penis. Python does seem like the "do this first" language to deal with. Next year i wanted to start cs so i thought learning a language and revising some maths now would give me bit of an edge.
Do note that Comp Sci is only sorta related to Programming. &gt; Computer Science is no more about computers than astronomy is about telescopes. Comp Sci will teach you algorithms, logic, set theory, state machines, formal definitions of parsing and languages. You'll do that with programming, but that's not the part that they *want* to teach you. In my course-work (12 years ago at this point), I had to teach myself source control, testing, debugging tools, command line, and more. The coursework taught me how to think about algorithms, searching, parsing and such. This does come in handy while you do a day-job of programming, but not as often as simply being able to talk with a customer &amp; break down their problem into small, clear pieces. Don't skimp on soft-skill classes like writing, history, psych, or speech. I skipped those and I've had to work on those skills on my own.
Happy to hear you liked EiA :-) Just a small correction. EiA uses a lot of HashDict and this has since been deprecated in a favour of the Map module. The API is completely the same, so wherever you see HashDict, you can just replace it with Map and it will work. Another relevant change is the recent addition of the Registry module. When the book was published, this was not present, so I used gproc library for that. While gproc can still be used, and is a great battle-tested library, I'd recommend using Registry these days. Other than that, the book is IMO still up to date. I should also mention that I'll start working on an update of the book around November. I hope it will be finished by the 2nd quarter of 2018. But regardless of the update, I believe the book is mostly up to date, since it's focused on concurrency and OTP, and this part of Elixir/Erlang is pretty stable. Thanks for the positive feedback!
When I first started with elixir I started with creating a [phoenix](https://hexdocs.pm/phoenix/up_and_running.html) server. They had wonderful tutorials for getting started that were easy to follow and easy to build off of. My end goal was to use elixir for a server though. So your mileage may vary depending on what you are trying to do.
Yes, sorry about that was trying to remember what it was off the top of my head but loved the book and will most definitely check out any elixir related book or update you do in the future. The depth of coverage on otp was awesome!!
You should do it right way. You're including tests as parts of your apps, and ends up require test deps in prod. For your needs: we should have editor plugins to help navigating between lib and test files. Most ruby plugins do that for minitest or rspec based on file paths. Actually files can be placed anywhere in lib regardless of actual module structure. However if you group files not following the module structure, then you cannot use tools that work based on the convention. It's not a big deal for toy program, but I think it's better to stick with good practice in most cases :)
Yeah, I'll stop to do this haha \^\^' Thanks for your comment
Yes, here enjoying it. 
Thank you very much. Excellent article. 
Hmm. Thanks for the info. Isnt ruby a bit dated though? Would i be better off starting at python? While still poking at elixir till i get the hamg of it? Computer science is something i wabt to do next year so i thought learning some useful language would be a practical head start 
Hi Guys, so Would starting with Ruby be a good way to go in order to have some simple beginnings with material to refer to? sounds like its easy to translate over to elixir later on and a lesser jump than from Python? because after even more reading, Elixir sounds like a solid language to use. I have little motivation for C++ and well, the other option is Java. 
Ruby is newer culture-wise than Python, and will include less hurdles because of community missteps (Python 2 V 3). Python's actually the language I started with so I know it's a fantastic language, but there's a few things about it that end up standing in your way: * It's behind in web frameworks. Django came before Rails and it shows. There's a reason Rails is the gold standard. * The package system is a much worse hurdle than Ruby's bundler. * Testing as a culture is less ingrained. No popular libraries lack it, but many small libraries do, and many projects at companies are. * Jose Valim was a Rails core contributor and the main source of energy on one of Ruby's biggest projects. Elixir was clearly inspired by Ruby in a way nothing else can claim, even though Elixir takes from many places. It's a bit easier to learn for sure, and it's a great language, but Ruby just is a bit more of a practical choice right now. Start with the Rails tutorial book: https://www.railstutorial.org/book From there, read the pickaxe: https://pragprog.com/book/ruby4/programming-ruby-1-9-2-0 It's important you learn to be a ruby programmer, not a Rails developer. Being able to live outside the framework is huge for helping architecture skills.
I personally love Ruby, it's a solid choice for an introductory learning language. Python is perfectly fine as well. Java is also good. It does things in very verbose, strict ways that may be good for learning. I personally learned in C and then C++, and then Java. What would be really helpful is to have an idea of what you want to do. If your goal is solely to get ahead of the curve for starting at University, maybe see what language they use for their course work. But to really give your self some skills to write code well in University setting, learn about how to write good unit tests as well as how to use source control like git.
What kind of app are you building? How many users?
I've been using it in production for probably over two years now. Elixir is great but compile times can get pretty long in larger projects. I'm starting to lose faith in Phoenix though. Contexts are an extremely poor default and seems like the functional equivalent of early Rails mistakes. Namely fat model skinny controller. Beyond that, Elixir is incredible to work with on a team. The explicitness prevents a lot of the confusion that other technologies I use can cause.
&gt; Contexts are an extremely poor default How so? Fat model / skinny controller is also better than million-line controllers I used to see way back.
Both are "bad". A friend of mine wrote this up, which I agree with. http://christophilus.com/blog/mvc/web-development/2016/08/07/skinny-controllers.html
Web app, several hundred thousand.
What's even better is a controller per action (instead of a controller that handles index, post, put, delete, etc). Then, all action-specific functions and context is in one place. Much, much easier to reason about.
Right, I think both are bad. The way I start is by building out the feature in the controller. eg: Save the model, send an email, maybe a few other side effects. I take that logic and I extract it into its own well named module. eg: `PostCreator`. Now you have a nice, reusable module that's clear in intention as well as being easy to test. Modifying it is also easy since it's not going to have dozens of methods because it has one responsibility and is easy to reason about.
That's an interesting thought and I haven't tried it so I can't say much about it. The big downside there opposed to extracting some kind of service object/module is that you lose reusability. eg: You add an API and want the create action for a specific endpoint to have the same side effects as one of your existing controllers when creating a model.
I should mention, that I have someone who can help me with elixir, and so for that reason I might just dive right in. At the end of the day, I'm not starting the course until next year, and everything I do this year is basically extra prep. and If i find a different language more suitable later on in Uni, then so be it. Road less taken and all that....
&gt; The construct for structuring code in functional languages are functions, not modules I disagree to an extent. Modules are the context, functions are the actions in Elixir land. Just because it's functional instead of OO doesn't mean we should throw good practices or organization out the window.
&gt; And to be fair, even if people did dump everything in a context, that is likely going to be less messy than dumping everything in a model because you are at least keeping the data (schemas) apart. I disagree. Now instead of it being only related to a specific model it's now related to a loosely defined range of schemas. The problem with contexts is that it's a good pattern when you need it and when it makes sense, but it's not a good default.
we've been using it since 2014. if i could do it all over again, honestly-- i might have waited 6 or so more months to start using it. we started when it was still in beta and the amount of basic stuff we had to build on our own definitely slowed us down at first, and now some of the tooling that's eventually been standardized, we have our own hand-rolled versions of, and now we have to make the decision of whether to change the way certain things work to reap the benefits of standardization, or to put additional resources into maintaining some of the tools we built for ourselves when no standard solution existed. what we get in exchange for this cost, however, is that we started a project that is likely to continue for many years on a tech stack that does everything we need and should serve us well for a long time without becoming outdated. but you didn't ask about starting in 2014. you asked about starting TODAY. would i start a new project in Elixir today? absolutely. the language and tooling is definitely stable enough now to begin a new project now without the vast majority of the hassles we encountered back in beta. and you also won't have the problem of needing to forget the old and deprecated parts of the language that existed before it was stable. you can just learn it the right way the first time.
&gt; I take that logic and I extract it into its own well named module. eg: PostCreator. &gt; &gt; Now you have a nice, reusable module that's clear in intention as well as being easy to test. Modifying it is also easy since it's not going to have dozens of methods because it has one responsibility and is easy to reason about. What you have just described is a context.
Yes, and my problem with "Context" is that it's too broad. It's a grab bag of functions for a wide range of schemas that ends up becoming a mess that's hard to reason about and doesn't help understanding.
&gt; It creates an artificial boundary. If both PostCreator and PostUpdater share a lot of logic, which is very likely the case, I will probably need to have a third place for the shared logic or have an awkward dependency between those modules while everything should likely belong to a single module. That has yet to be the case, in practice. &gt; You are shutting down the possibilities for your software to grow because you imposed hard boundaries upfront. I 100% disagree with this. Your code isn't set in stone, you can easily refactor it.
&gt; You should only group schemas that associate to each other and that are typically managed together. That's the opposite of loosely to me. Most of the contexts I've seen are *very* broad and can easily grow into being a dozen or more schemas. Once you get beyond a basic blog example it really falls apart (which brings up a funny point, most people are confused as hell by contexts for good reason). &gt; As I said earlier, if you assumption is that people will misuse it, then no software principle will pass the test. I'm not saying people will misuse it, I'm saying it's not good as a default. tl;dr context is a function bucket which I believe is a poor default.
&gt; I guess we are both been biased against each others experiences. Hah, I think that's a good way to put it. At this point since context is the default all we can do is wait and see how it pays off in a few years. :)
I'm very conused. If you don't like the context pattern, then why do you use it? 
That's just a code organization problem, though. If you see 2-3 places doing the same sort of thing, move that thing into a module for reuse. But don't prematurely build everything for reuse. Doing that leads to code that is hard to follow (jumping through 10 files just to perform one simple business task, wading through abstractions that don't need to be there, etc)
My team is converting a legacy application to elixir, and this book was _the only way_ we could effectively tackle the job. Thank you!
Agreed, it's really easy to over-abstract from the beginning. :)
I gave it a try and after a while of using it became sad that it's the default in Phoenix. That's what I'm getting at. You also don't have much choice when you're a consultant or join a new team that's using them.
The folks over at Discord have built a pretty impressive and large scale system with elixir. They have several blog posts about their experiences. 
I've had a similar experience to this. Would absolutely use elixir again.
I disagree with so many points in this blog post, but it is a very interesting conversation I've not had so maybe you can further the blogs intent if I'm not getting it. &gt; Controllers should do one thing (create or update or deleteâ€¦) this blogs controllers are doing more, not less - moving stuff into different modules is nice for organization of code, but it does nothing to increase context and only adds tons of files with a few LoCs which can be messy and decrease controller context, not increase it....UpdateUserController provides nothing more than a UserController with an update function for context &gt; Controllers should do most of the validation. Here's my biggest gripe....a controller should validate the data will work inside your application because it's the entry to your app...and guess what...all controllers in every major framework I've seen does _just_ that...what the author is saying here is that you should validate data coming into your app so that it is validated for going into another layer of your web stack (like the DB) and that's just wrong on its face...you don't validate for the DB in the controller because if you add another layer later you may have different validation needs...the author is correct in saying you validate at the edges but is conflating application validation with persistence validation....persistence validation is at the edge between your app and your persistence layer **not** between your client and application layer &gt; Controllers are the coordinators for your system I disagree again...controllers are the **entrypoint** into your system from some clients...not the controllers of your entire system....if you have a super heavy business logic application with a lot of composition between processes you don't go to your controller to serialize actions and coordinate do you? Of course not...you _only_ do that with requests from the client...I expect that's kinda what the author means, but that isn't what the author _says_
Delete all the codes. Level up. 
I've been using it since 2014, but only on a serious application (but not yet production level) for nearly a year. &gt; What has gone well? Even though it's a fairly new language, the community and support around it is great. There will be at times where you can't find the Elixir version of something, but more than likely there will be the Erlang equivalent. The codebase has been able to stay relatively clear and concise, and taking advantage of the design benefits laid out in OTP is not near as much work as achieving the equivalent in another language. So you still feel quite productive in it. &gt; What hasn't? Getting other developers involved in the codebase. As I was the only developer who knew Elixir prior to beginning, it's been difficult for others to get into it. So if your team is quite new it, it may take them awhile before they're back at their original level of productivity. &gt; If you could start your project over, would you still use Elixir? Yes. The benefits of being provided with the tools you need to achieve distribution, concurrency, fault tolerance right from the beginning is really nice. Compared to having to look into alternative tooling you can leverage alongside your language of choice to achieve the same. 
&gt; I'm starting to lose faith in Phoenix though. Contexts are an extremely poor default and seems like the functional equivalent of early Rails mistakes. Namely fat model skinny controller. Based on your other comments in this thread, I'm going to suggest the problem isn't contexts but the way you design applications. Contexts aren't a giant grab bag of functions, nor a dumping ground for schemas. They are a boundary around a business domain. If your domain interface is composed entirely or even mostly in terms of schemas, then you *really* didn't learn any lessons from Rails' mistakes.
&gt; &gt; Controllers should do one thing (create or update or deleteâ€¦) Oh my, I hope I never get to work with that guy/team.
&gt; I'm going to suggest the problem isn't contexts but the way you design applications. Thank God I didn't write most of the code I'm complaining about. &gt; Contexts aren't a giant grab bag of functions, nor a dumping ground for schemas. They are a boundary around a business domain. So, a grab bag of functions around a business domain. Still a grab bag, just with a flavor. &gt; If your domain interface is composed entirely or even mostly in terms of schemas, then you really didn't learn any lessons from Rails' mistakes. With contexts, I think that's impossible or at least incredibly difficult to do.
&gt; So what would you recommend as a default then? In my opinion Phoenix is definitely better off with contexts but maybe you have something else in mind? That's a really good question. I like how it was before, and am totally aware about aversion to change and whatnot. I think I'd have to look a bit beyond what the framework provides by default and find a way to warn people when they should look into extracting functionality. A simple, but potentially error prone solution could check if you're over (arbitrary) 8 lines in a controller action, calling `Repo` in a model, etc. Maybe helpful instructions on where they could go from there. I think it'd be better than trying to push contexts as a one-size fits all pattern from the get go.
I find it very exciting you want to get started with Elixir! There is also good feedback in this thread. Learning Python is not a waste of time and it will definitely be an easier path than Elixir. After all, there are plenty of resources for those interested in learning programming in Python. If getting a job in the short time is a priority, then Python/Ruby/JS are all safer alternatives. In Elixir there is one resource recently announced to learn programming and it is still in development: https://joyofelixir.com/ On the positive side towards Elixir though, the following come to mind: 1. You mentioned you have someone that can help you with Elixir and a good mentor is worth many books 2. The Elixir community is still young, which means you can cause a positive impact if you decide to get involved. For example, the Joy of Elixir folks would very likely love your feedback if you decide to go on that road 3. Learning Elixir will be more challenging than the other languages mentioned. That may end up being fun but it can also be frustrating 4. Elixir has advanced concepts but you don't need to worry about any of that right now My first contact with programming was when I joined university. I had 4 months of C and then I pretty much self-taught myself everything else. The first language I learned on my own was ActionScript which is probably defunct at this point. I guess what I am trying to say is that the chance you will end-up doing something very different later on anyway is quite high. If you have the opportunity to experiment and try things out, then do that. :) 
Happy to hear that, thanks!
Even if you don't like contexts, there's nothing forcing you to use them. Phoenix is quite modular, so you can use whichever parts of it you like and ignore the rest.
I used Elixir since a few years, and something like 2 years in production. And, to make a tl;dr, I am very happy about it. It provides a good development environnement, it is reliable, and fast. The community is growing, mostly thanks to Phoenix. That said, I think were you can have a hard time is when you have to do something "old world" related. Something like saml login for example. Here, Elixir, and even Erlang does not provide an ecosystem as rich as Ruby, Python and other. Here, you may have to implement it yourself. It also depends on your need. Elixir is really good for web stuff today. Where Go has the lead in system programming (Docker, Terraform and so on).
Web app just means "web interface to _something_", unless I guess you're literally building a CRUD app. Either way, Elixir is a solid choice.
True. I wasn't sure whether "what kind of app" meant, "desktop vs embedded vs website vs ..." or whether it was assuming I'm building a web app, and was instead asking, "what market are you serving?" Our application has e-commerce, rich content, live webinars, chat, discussions, and more. It's currently a monolithic Rails application that has some impenetrable parts. The implicit dependencies make it pretty hard to reason about, and there are definitely plenty of areas where it's easy to make a seemingly small change that cascades in unforeseen ways. I don't like dynamic languages (and Ruby has only intensified my dislike). I wouldn't even consider a dynamic language, except that Clojure's approach seems as if it would solve most of my problems with Ruby/Rails, while still giving me the benefits of dynamic typing. So it's on the list. Elixir is on the list for similar reasons, though I like the language less (subjectively), and it has a decent migration path away from Rails.
I'm the author of the blog post. It was more of a thought experiment than a dogmatic statement that everyone should do this... That said, I've built a *ton* of web applications. I've used ASP.NET MVC, Rails, and Node (Express), and have prototyped in a few other platforms. In every codebase I've worked in, tracing the path for any request meant hopping through 4-5 files at least, often more. You have the controller, a view-model, a validation layer, various helper layers (such as decorators or form objects), the data model, often a whole set of domain objects, a responder, etc. Quite often a few of these other layers are not actually reused or reusable, but are specific to the one operation (say, processing the "create user" scenario or whatever). The typical controller (let's say in a Rails app) has a bunch of before_filter, delegate, and a handful of private methods. Each of these things generally applies to only one or two of the actions. In OOP, whenever you have a class with a bunch of methods/props, each of which really only pertain to a small sliver of the class's use cases, it's a code-smell, and a sign you should move things elsewhere. In MVC, we are told that we should have skinny controllers, that is, we should move those aforementioned methods/props out into request-specific classes, and the controller simply takes an HTTP request and passes it along to one of these request-specific classes, and lets it do its thing. I have done just this in ASP.NET MVC, and it was indeed clean. But at that point, my controllers were basically nothing but boilerplate. So. My thought is do exactly what the best-practices suggest, except remove the boilerplate controller and map the request directly to the processing class itself. Does that help clarify the blog post?
Author of the article here. I got the idea after reflecting on what was making our controllers so hard to reason about. It may indeed be a terrible idea, but I think you should think about it before dismissing it! [EDIT] I've prototyped some things that follow the model I suggest, and it does seem to be simpler and an over all better way to organize things. 
I don't think that really matches up 1:1 with your post though. What you're essentially suggesting here is removing controllers and using the router to call into your application, but in your post you're suggesting breaking controllers apart by "action" and doing more per action. The problem with that as I tried to state in my middle point is that you're ultimately going to start conflating edges of your application....the entrypoint for http requests isn't the entrypoint for every request into your application for the lifetime of that application...just off the top of my head many apps will start using websockets to get into the app...not only that but conflating the edges means that while you'll probably start off with only one other edge, which is persistence in some sql db, but that too might change and if you're validating on the "front" edge for the "back" edge you very well might add another edge that needs different validation rules and then you're refactoring your entire entrypoint validation to accomodate and likely having to use nasty nested logic to make all of it work without rewriting the whole thing
My blog post was misleading, somehow then, as this is what I'm suggesting. Do the work on the edge, as you put it. When you have 2 edges that have overlap (meaningful overlap, not just accidental overlap), you move the common logic into a module. This approach (which I've used in Node, but not other systems) does seem to produce more explicit, easier to follow code (in my opinion).
that's a problem for me though...if you do two different things to your data coming in - then you're passing two different version of that data through your application when the only part that would want/need a differently parsed/validated/whatever would be the backend edge **or** more likely you're just appending a bunch of unnecessary data to a single struct Imagine you have a "backend" edge for persistence and a "backend" edge for logging and lets say you want t oadd some metadata to your logging edge, well if you're doing that on the front edge then you're passing around unnecessary data to the persistence edge...now when some new developer joins the team they see "logging_meta" in the struct you're passing around and have no idea why it's there until they search around and figure out it is used inside the logging edge - it's just not necessary and I'm not talking about a performance hit either, I'm talking about a mental context of dealing with data coming into some context of your application and developers having to sift thru which parts of that data are actually needed by that portion of your application and which parts can they ignore
X-Post referenced from [/r/graphql](http://np.reddit.com/r/graphql) by /u/mtndewforbreakfast [Pre-release book now on sale: Craft GraphQL APIs in Elixir with Absinthe](http://np.reddit.com/r/graphql/comments/6yp8gc/prerelease_book_now_on_sale_craft_graphql_apis_in/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Currently I use nanobox but I don't like the restrictions. I'm looking into gigalixer but if you have some handy startup scripts to things myself that would be nice to try out! 
honestly not sure how much they would help but feel free to take a look. The two tasks that may be good are create_node_sync_config and create_vm_args. They take the configuration loaded from the top (there is an example config in the project as well) and create vm.args and config for making nodes aware of each other. It's a bit early and all the ssh/sftp helper tasks in that same file aren't debugged and probably wouldn't work yet :) but it does expose some of the stuff i do manually https://github.com/smileys-tavern/smileys_umbrella/blob/master/gulpfile.js 
For anyone like me who's only seeing the keynote: [Link to the full playlist](https://www.youtube.com/playlist?list=PLqj39LCvnOWZMVugtyKlHMF1o2zPNntFL)
huh, I could have sworn I grabbed the playlist link. Thanks! I can't edit the link, but if a mod could update it that would be nice.
I am not really against the idea in general, and it could be a good idea for an especially heavy controller (maybe), but most controllers are CRUD or simple enough that this idea does not seem good to generalise IMHO. Too many files is worse than a few long files.
GOT Spoiler Alert ! Loved the article though.
That talk by Boyd Multerer has me all tingly. 
[JosÃ©'s keynote](https://www.youtube.com/watch?v=Wa7_I_pc0yo) is up. Some highlights: ### Elixir Design Goals [Starts at 17:59](https://youtu.be/Wa7_I_pc0yo?t=17m59s) Elixir's original design goals were: 1. Productivity (when writing Elixir code) 2. Extensibility (of Elixir and Elixir code) 3. Compatability (with Erlang and the existing ecosystem) But now the language has matured and both Extensibility and Compatability are mainly solved problems, and Elixir development is focusing more on: 1. Productivity (when writing Elixir) 2. Maintainability (of being able to read and reason about and modify existing Elixir code) 3. Reliability (and fault tolerance of Elixir software) ### Elixir R&amp;D (The Future) [Starts at 44:58](https://youtu.be/Wa7_I_pc0yo?t=44m58s) 1. Code Formatter (planned for Elixir v1.6, due ~Jan 2018) 2. Data Streams and Property Testing (planned for Elixir v1.6, due ~Jan 2018) 3. Releases (planned for ???, we have Distillery, etc that reduce pressure a bit) 4. Cross-language Docs with Erlang/OTP (planned for ???)
Lines! Triangles! Rotated sliders!! The future of that project looks awesome. He should call it ExBox.
Javascript might be a good choice to learn alongside Elixir. If you develop in Phoenix, you will definitely need some JS skills, so time spent with Javascript is never wasted. JS as a language is welcoming, and well documented enough that it can provide a good counterpoint to Elixir. I can see your dillema with Python/Ruby. JS occupies a different part of the stack to Elixir so there's less "relearning" if you're eager to get developing ASAP. A lot of NodeJS tutorials are well written. Node is a backend language but Phoenix still uses npm extensively. I mainly use Elixir, but I learnt a lot about programming by messing around with Node servers. Learning Ruby/Rails might be a good choice, as others said. OTOH, Elixir/Phoenix is becoming so mature and stable that its becoming more newb friendly every day. The language needs more new people who can jump in and ask the basic questions, to leave a trail for other beginners decades down the line. I never saw a Stack Overflow question that wasn't answered within 30 minutes. Elixir badly needs more basic questions to make a paper trail for the future. Ruby is popular cos every question, no matter how "stupid", has been asked at least 3 times on SO. Right now, learning Elixir can be like trying to climb a ladder with the first 3 rungs missing. More beginners are needed to help make those first 3 steps.
Ruby/Rails background. Played with Elixir on side projects for over a year before taking on my first production for-pay Phoenix project (about 70% done currently). There is a learning curve, but everything I have come to understand makes sense, and there are a ton of things I've discovered that I've liked along the way. While I've been stuck here and there, the biggest hassle has actually been Brunch, but that may be more the cost of my lack of recent frontend experience. It has been relatively easy to implement most features (such as 304 HTTP support, file uploads with an app-side document cache, enum types at the Postgres db level usable in Ecto, etc.) and deploying on Gigalixir and Google Cloud Postgres has been trivial. I use Sparkpost for email, Timber.io for production logging, everything works great and I'm currently on the free tiers of everything (but this app will only have 900 users). Did I mention that everything seems extremely performant as well? (especially from a Rails background) Also, once you get used to the deep pattern-matching in Elixir... you will miss it in *every other language ever.* I think you should dive right in! Check out [Bleacher Report's blog post](http://www.techworld.com/apps-wearables/how-elixir-helped-bleacher-report-handle-8x-more-traffic-3653957/) on their Elixir experience, and [Pinterest's](https://medium.com/@Pinterest_Engineering/introducing-new-open-source-tools-for-the-elixir-community-2f7bb0bb7d8c).
That's a great idea!
I've maintained apps in the past that used that principle and found it to be suboptimal especially over time. Controllers with only one method are isomorphic to command classes (aka service objects) that have a well defined set of parameters in the form of properties, and a single #perform method (or equivalent). They have the added benefit of being reusable throughout your application, unlike controllers. A Controller's job is to mediate between the transport to the application layer. Move parameters in and results out. That's not best served by artificially chopping it upâ€”in fact, I recommend expanding it to cover all actions that belong in a particular resource boundary rather than limiting it to REST-blessed verbs.
Thanks, glad you like it - sorry I really forgot to add the "spoiler warning" notice to the post.
Why politicize an event like this? Shouldn't an event like this just be focused on the technology? Isn't focusing on the tech already inclusive by default? Isn't manipulating ticket prices to achieve someone's arbitrary definition of aesthetic diversity actually somewhat exclusive? I have been to a few tech conferences, no one is shunning your marginalized groups. Everyone there is just interested in the tech and happy to be there. Elixir doesn't need this nonsense, it already is, and should remain, a very welcoming community focused on the technology. Let's recognize people for their contributions to the community, their ideas, and their skills with the technology instead of making it about race/gender/etc. 
Thanks for the response. Yeah i feel like im one of very few who went this path because usually there is nearly too much noob info that you get distracted, but for elixir it seems the opposite. I will have help on board to get me past those 3 steps. I might keep a blog going or something to make a rough trail of do's and dont's for others to follow. Also ill definitely take a look at js in the future once i get myself a bit more setup.
I'm working on a new API for my library [Hammer](https://github.com/ExHammer/hammer). The original API is pretty clumsy, and I learned more about OTP in the meantime, so hopefully this new version will be much more pleasant to use.
I appreciate that opinion, and I expect that you're not alone in holding it. Thank you for representing that view. Achieving an inclusive and well balanced community is not automatic--although I absolutely agree that we have an amazing Elixir community. But let's make that intentional; something we work on consciously, so that it stays that way. Also, if we can do some things better, we should. As developers, we aren't required to have a heightened sensitivity to others. So, this is welcome exercise. I expect that there will be a lot of learning and inspiration as a result of the event. The organizers, the speakers, the attendees and the community as a whole, lose absolutely nothing by having events like this. It's a net benefit and I hope you see that! Thank you again. P.S., It's going to be an awesome event. We are going to have great tech talks (including talks from core team members) as well as talks from well-respected inclusion advocates and organizers. It's going to be at a historic hotel in a historic city center with lovely New England foliage. :-)
I was going to see if there were student passes. But I guess I have to pay a price for my skin color (being white), my sexual orientation (why is this even a factor) and wanting to learn about cool tech. Maybe I should deliberately change my orientation to become LGTQIA123ABC so I can afford to attend. Sad to see this valley BS clouding what "true" diversity and inclusion really should look like :(
We offer discounted tickets for economically disadvantaged members of the community, which can include students. Sorry to see your animosity, but hope you can attend and gain better perspective on our mission and its importance. Thank you!
Is this even really about elixir? The featured keynote speaker doesn't seem to have any experience with it.
If you are mainly trying to hear tech talks, a core team member James Fish is keynoting on what's to come in Elixir 1.6 and half the talks generally will be traditional Elixir tech talks.
Our featured keynote is a mental health advocate and awesome speaker. Whether he writes code in Elixir is one question, but what's most important about his contribution to our conference is that we'd like to encourage discussion about mental health in the Elixir community. 
&gt; we'd like to encourage discussion about mental health in the Elixir community that seems pretty oddly specific but you do you
Doesn't Elixir already have a deployment library coming out every month or so? I don't doubt DockYard because of Chris McCord, but is it still really a problem? I feel like I've seen at least three or four deployment solutions in the past six months.
I'm not doubting you at all, but could you point me to some good resources? Everything I've seen about deployment of Elixir seems very complicated :(
Elixir has a definite problem with this. It was easy to deploy erlang by copying the beam files to the servers with rsync, but this has never truly been solved at a consumer grade level I think. This isn't an elixir problem, this is a beam deploy issue. One thing to keep in mind is the hot loading available for erlang vm. A good deploy system will not follow the standard route of versioned directories with symlinks and restarting the server, but would take advantage of hot reloading while preserving what devops are used to having with the rollback and versioning perhaps read to CI builds.
Distiller does a great job of building releases. There are some tricky bits, mostly around realizing when your config.exs gets run/expanded and a bit of a hack around 12fa-style environment var injection, but to me it's pretty much a solved problem.
Thanks for putting on an event like this. There are many conferences that focus exclusively on an aspect of tech, so it's great to see one breaking the mold and helping to steer the ship toward a more diverse and inclusive community. To the other commenters here, you'll likely notice there are few folks from minority groups who would share your opinions, and that should speak to the need for something like this. 70% of the industry are "white dudes." It takes some intentional action to reach a point at which "focusing only on the tech" can actually be inclusive.
I tested Distillery and it worked as it said... but I do think there should be better way to do deployment. "The first class" - it sounds like it may involve changes jn Elixir internal to make things happen, which is not surprising for me.
Given that 99% of distribution issues revolve around people struggling to understand Erlang's distribution, any first class solution will most likely flow back into OTP and might not even have to touch Elixir. It seems there are good working relations between the Elixir and OTP core folks (yay for that!), so that would be a very nice move - Erlang is, literally, from a different era so could use a brush-up in this respect ;-) 
This is part of the requirements we are going to outline. While I expect this solution to be written in Elixir, we are going to actually target erlang builds in general. In other words, there shouldn't be any reason why it needs to be "Elixir only".
Elixir has a very straight-forward way to create a self-contained tarball for an app: distillery. From that point on, why do we need elixir-specific tools just to ship a tarball to a server? Is it really so different to Java self-contained jar files?
It is important to say that all events *exclude*. The most obvious exclusion factor is the economic one, since many cannot afford the cost of a ticket+travel+hotel. Sometimes we exclude by affinity. For example, some prefer small events, others prefer larger ones. We even exclude by idiom - my talks would be much easier to prepare if I could just give them in Portuguese! At the end of the day, we are all inclined to participate on events that we are more likely to identify ourselves with. As someone who lives abroad, I have a tendency to go to activities where other foreigners are also involved, even though I have never been discriminated. Sometimes that can be achieved by a "foreigners welcome" sign, but other times you need stronger initiatives than that. I am not saying all of those factors are comparable. Just pointing out that we exclude in more ways than we would think. A diverse community is not one that tries to fit everyone in the same umbrella but one that recognizes and welcomes that we all have different tastes, different priorities and different needs.
Why not modify nerves a little to produce a docker image rather than a firmware.
This was mentioned at Elixirconf. The guy speaking for Dockyard said he likes the ideas in Nerves for deployment and would ask the person implementing it to use Nerves deployment as a model.
So did you enjoy your dip in the deep end?
I think the parts I liked best were meeting people and the trainings. I thought the talks were a little uneven, but perhaps that's not so surprising. It's sometimes hard to decide who to listen and why. For example, my former boss told me to attend the Nerves talk on an artificial pancreas which I thought would be uninteresting, but it turned out to be both interesting and touching. I've been practicing some Elixir via exercism.io which I think is a good way to learn some Elixir (alas, it doesn't use mix). I haven't liked a lot of the material I've seen because they haven't been focused on programming. Exercism's weakness is that it's purely about exercises. Its goal is not to teach Elixir. I think there's still some room for an intro course in Elixir as a first programming language (which isn't where I'm at, but I've taught intro programming, so I have some ideas). Did you attend?
I was there. I would have done (and recommended) the Nerves training but I did it last year. My favorite talk was probably the OpenGL one.
&gt; 70 % of the industry are "white dudes." People like you are the ones racist in any community. Always have to point on "white dudes" like it is a crime to have a skin of certain color. What's wrong with you that you have to discuss someone's skin color or sexual orientation all the times? Why can't tech conference be just tech conference without all this political bullshit? Truly for everybody, for the same price, no matter your skin color or sexual orientation?
You've read exactly ONE comment I've written, and yet, you're able to determine I'm racist and always point out skin color or sexual orientation "all the times." Nothing is wrong with me, and I don't always talk about race and sexual orientation. Actually, I talk about those things fairly infrequently. So, I don't think anything is wrong with me, just like I don't think there's anything wrong with straight "white dudes." My point is that it takes intention to create an environment that makes people who aren't in the majority feel comfortable. As a person often [perceived to be] in the majority, I recognize that it sometimes takes some extra effort on my part. In my opinion, it's worth that effort, because without it, I wouldn't benefit from the knowledge and perspective I can gain from people who aren't like me. Also, I don't see an effort to be inclusive as "political bullshit." I see it as being a good human. I hope to meet you at the conference and we can discuss our different views in more detail.
This was the Elixir Native UI by Boyd Multerer? I was at that one too.
The deployment story is the one hesitation I have with introducing this language to my coworkers. So much about elixir is great, but deployment is bad compared to every other semi major language I have used. I don't think it is elixir's fault per se, but rather erlang's. If that were fixed, the entire ecosystem would be unstoppable.
Sorry, i didn't mean you personally, rather "group of people with these opinions". I'm also not a native english speaker, as you can probably tell. This, combined with the fact that i get angry when i see these assumptions that everyone who is not majority must be "positively discriminated". Anyway, sorry, i won't meet you at the event because i'm not a minority and thus can't afford a ticket at the moment. :(
Dear friend, please feel welcome to purchase a diversity ticket, if that discount allows you to attend. Non-native speakers of English are routinely at a disadvantage in an ultra English-centric industry, like this one--and I only wish we had more talks submitted from folks overcoming this barrier to entry. Also, we wrote an intentionally broad definition of persons qualifying for a diversity ticket. Here is the language from our ticketing vendor Ti.to: &gt; Tickets reserved for members of underrepresented group(s) in tech: women, people of color, LGBTQIA+ people, people with disabilities, veterans, the economically disadvantaged, and other marginalized groups. Tickets available here: https://ti.to/elixir-with-love/2017
In the Python world is the same: you can watch the PyCon talks online a day later, the real value of the conference is in meeting people and get inspired.
either you live in a fucking dream world or you're not affected by the power dynamics in tech conferences. Here's the product of the 30 seconds of my time I'm willing to spend to educate you : https://shift.newco.co/what-its-like-to-be-a-woman-at-a-tech-conference-8a1a299ac82b. Have fun in wonderland.
I am finally back with another episode of Exploring Elixir. Sorry for the long wait! My August was split between vacation and starting a new adventure at work, so EE got punted for the month. Back to weekly episodes now though ... Hope you enjoy, as always! p.s. Even for those who have used these tools before, there may be a couple tips in there for you yet, such as how to get the prefix to use inside of a Triplex migration ..
Yep!
I think it's important to have people from all groups represented in an inclusive environment. If the difference in cost of the ticket, between the standard rate and the discounted diversity ticket, is really the obstacle, that shouldn't prevent you. If you purchase the diversity ticket and send me your confirmation, I'll cover the difference in the scholarship category and send a note to the organizers explaining.
Do you know how Triplex compares with [Apartmentex](https://github.com/Dania02525/apartmentex) ?
Okay, as a Random Average Human, I have to askâ€¦ WTF is a SegWit?
It is ironic how the linked article talks about the "importance of being approachable" and "how we should be able to have a healthy conversation about this" yet your reply was the opposite. If you are not willing to spend more than 30 seconds on it, you should probably let others with more time in their hands handle it. I understand how talking about those issues over and over can get tiring and repetitive but it is important to keep it healthy and open. Have a good day.
A long-awaited upgrade to the Bitcoin protocol that separates signatures (segregates witnesses) from the transactions themselves. The earlier design allowed the TX ID to be mutated by a third party before being accepted, preventing chaining transactions. In addition, the new design frees up space in the original block for more transactions, and opens the door for new signature types.
Boyd's presentation was great. "Black triangle" and more! I happened to bump into him in the hallway after his talk and he showed off two more demos that were equally impressive. 
They are quite similar, with perhaps the main difference being that Triplex gets out of the way and just let's you use regular Ecto API where apartmentex provides a wrapper API. I am not sure that is the best idea when Ecto is quite a large and complex API itself which is still evolving. It also makes migrating existing code bases a little more difficult. Triplex also appears to have more development momentum right now. Both are reasonable choices imho, but I found Triplex find for my needs and closer to my own design sensibilities.
Thanks! That sounds like a better approach to me as well. Also how did you find this hex package? I usually google or check the awesome elixir git repo. There's no multi tenant helper packages in awesome elixir and most of the googling leads to apartmentex. 
I usually search on hex.pm itself or from the command line with `mix hex.search`. The website has more info on stats and makes getting to the source repo and docs quite easy, so when just exploring I usually go to hex.pm in a browser. In this case they are all rather hidden unfortunately... I also find ElixirForum.com to be a great source, and I believe that is where I first found Triplex.
Haha, yeah that's a great idea.
Seems like docker is an ideal solution. It's not as good as having a single binary like go or crystal but it's widely supported.
Why exactly the focus on mental health? Mental health problems are highly prevalent in general population, and a large cause of morbidity and even mortality, actually. I wonder if there is anything special about mental health in tech? It would be cool to have an anonymous survey of the Elixir community regarding mental health, preferably before the conference so that the speaker could have some data relative to the most pressing topics to address.
Trying to diversify on certain axes is certainly your prerogative as the community leaders. Different ticket prices might be part of that. I'm personally uncomfortable with the idea of different prices based on something other than the person's income, but different strokes for different folks, I guess. &gt; my talks would be much easier to prepare if I could just give them in Portuguese! Please don't xD English is nice. English is cool, even though it's an unholy amalgamation of letters that somehow resolve into pronounceable sounds. On a more serious note, the point about the language barrier is very interesting. After all, technology is meant to serve people, and people don't (in general) speak in ASCII. Maybe having people from lots of different countries in the core team helps Eixir deal with character encoding issues better (Should have had a Greek person sooner, maybe?), or even with assumptions related to network reliability, or other physical constraints of the systems where Elixir code will be run.
I was thinking he doesn't even have to use it just for UI. Ian Duggan talked about making an editor, and I think he's thinking of using this for his editor. It could be used to make something like Powerpoint, too.
If you can go (the conference isn't super expensive...about $400, but hotel is a touch pricey), I think it's worth attending such a conference. It helps to talk to people if you can, even if you're a beginner. I met a guy that said he just started learning Elixir, but he was somewhat familiar with Erlang. It seemed like there were people who primarily knew Ruby, but not a ton of Elixir. Of course, there were a handful of Elixir experts, and some who use it in work, but that wasn't everyone. I took a training class, as mentioned, and that was useful to kickstart things. I do recommend trying to do some work on your own if you can to get more out of the class itself.
Using Docker for Elixir/Erlang-deploys seems so weird to me. A VM in a VM in probably another VM.
Some interesting parts of Jose's talk. * There is a "blame" feature which is useful in iex and running the app. When you make a function call, and it fails for all functions of the same arity, it displays the list of all functions with the same arity and syntax highlights the errors. It also displays what values were passed in. This was apparently accomplished by adding information about the Elixir AST into BEAM which required Elixir team to collaborate with Erlang. * There is support for break points via iex. It's not quite at the level (as far as I can tell) of IDEs in Java (and presumably C#) where you can step line by line in the code, then step in or step out, or do conditional breakpointing. * There's supposed to be a feature to essentially pretty print the code to create a consistent indentation. I did (barely) ask Jose why there isn't a standard editor with Elixir (like IDLE for Python, but hopefully something better), but he had to run by the time I asked. Even though editors cause religious wars and some argue that it's not something a language should care about, I think working on such an editor would work a different avenue. Where one thinks about a language helping you write better programs, the editor is part of that experience, and so thinking about that might give opportunities to provide interesting information to the code. This would, of course, not prevent others from writing their own editors (e.g., an Elixir plugin for Atom or emacs or Visual Studio Code which exist). This would be especially helpful for beginners who have to decide which editor to pick. There was a talk (by Ian Duggan) about writing an editor in Elixir, though it looked like it was meant to be a generic editor (as most text editors are).
Honest question: if you are building for scale should you be using the schema/user strategy or shared tables? I am not that familiar with using schemas but I know shared tables is pretty easy to scale by just sharding.
This is a valuable perspective, but perhaps only sees half the truth. Speaking only for myself, I believe ordinary behavior needs to be approachable, but legitimate indignation does not. There is nothing wrong with expressing dismay in authentic terms with the status quo. It's the status quo that should change. And the reason we're organizing this event (with your support, we hope) is to improve the status quo. &lt;3
Schemas are inherently a nice unit of sharding: each schema could be thought of a shardable entity, just as shared tables keyed on users/tenants could be sharded by those user/tenant ids. Schemas are self-contained, which makes it conceptually rather easier to deal with in my opinion, and means upgrading systems can done per-tenant quite easily based on metrics either than sort (i.e. sharding) ordering. It also makes backup/restore of indvidual tenants trivial, which is a huge benefit at scale. It's also easier to introduce different classes of tenants with different sets of tables active / created based on e.g. their service level purchase or similar. At the worst, schemas are equal to shared tables in terms of complexity, but IME they are rather simpler to manage if building multi-tennant software. Where they are more difficult is if you want ad-hoc interactions between tennants, as you need to then build queries with the relevant prefixes in joins rather than just expanding a where clause on the same tables .. 
Believe it or not, facility with a language has never been a decisive criteria with regards to selection of a keynote speaker. I remember my first ever RailsConf, and the keynote speaker was none other than Gary Vaynerchuk. Great speaker, and I remember some of his talking points to this day (my favorite was the give-a-shit economy.) You could be forgiven for not really knowing him though. He sells wine. And books. Probably more books than wine these days. But no code.
docker isn't "quite" a vm in a vm. It runs at a much lower level on linux. now on a mac or windows machine, yes a vm. 
Or something similar for a pattern of distribution. ( deb, rpm, docker etc )
One possible solution is to start Phoenix.PubSub in your core application and ask your Phoenix endpoint to reuse it. This [how the endpoint wraps it](https://github.com/phoenixframework/phoenix/blob/ea891262a260e471ef3894113ff1e1fec91123b4/lib/phoenix/endpoint.ex#L489-L541). Then to have the endpoint use it, all you need to do is to pass the `:name` for your pubsub configuration in the config file but you do not pass an adapter. Another option is to have a fake PubSub in the core app that mimics the endpoint API. Then you configure the core app to use the endpoint after the endpoint starts. You could do that on the `init/2` callback in Phoenix v1.3 endpoints where you would do something like: `Application.put_env(:my_core_app, :pubsub, MyApp.Endpoint)`. However, I don't think any of those solutions are good because Phoenix does the broadcasting directly to the channel. This means you will couple your core logic to the web, which is probably what you wanted to avoid by putting them apart in the first place. So it is probably best for you to do the broadcasting from your controllers, when necessary, since it is all part of how the web part of your app works anyway. If you also want to use pubsub for internal events, then you can start a pubsub for the core app, specifically for those events and ignore the endpoint one. 
Thanks for sharing
Hm..., it seems like all these solutions are not optimal. Is this broadcasting at random intervals not done normally in web apps? Because it seems like a very normal thing to do. TLDR: Am I structuring my app completely wrong?
The Nerves Project is using Circle Ci for our builds and release management too
Got side tracked one day and made a logging solution because I hate using aws cloudwatch. https://loggb.in http://recordit.co/BTZi5GEvfk
&gt; Do I need to learn both side by side? No, if you want to go to the 'expert' level with elixir, you'll probably need to learn some Erlang eventually, IMO. Sometimes packages exist to accomplish things in erlang that don't exist in elixir. I am not an expert, but thats [the impression that I get](https://www.youtube.com/watch?v=NIGMUAMevH0).
Node's socket.io is not really a clustered thing, and afaik, doesn't have presence functionality at all. I answered some on the cross-post, but this work is fairly nontrivial if you want multi-node support on the backend.
You might wanna watch [Chris's talk from last year](https://youtu.be/qPiZTxUAaVM) He talks more in details about what makes Phoenix Presence unique around [25 minutes in](https://youtu.be/qPiZTxUAaVM?t=25m23s). The videos have very low audio quality due to some technical difficulties.
Presence uses some pretty novel tech under the hood, something called Conflict-free Replicated Data Types. For presence specifically it uses an Observe-Remove Set Without Tombstone (ORSWOT). Why use this? The advantage of something like this is that you get something that's being called "strong eventual consistency", but more importantly you get it at the data type level. Eventual consistency means that if all data stops getting updated, all processes will reach a consensus on the data in a finite amount of time. Strong consistency means all processes agree on a value at any time a value is available for an operation. An ORSWOT implementation is essentially a key-value pair where the value is a tuple: the first element is a list of version vectors and the second element is a list of dot pairs. The version vector is of the form `{ActorName, Counter}`. The dot pair is of the form `{Data, ListOfVersionVector}`. Some people refer to the list of version vectors as the dot, because it's usually just a list of one, but it can be more occasionally. It supports three operations: add data element, remove data element, merge two types together So to add an element: * Increment version vector for unique actor, or add it to the list set to 1 * Updated tuple is stored with the element as a dot pair, if it already exists then replace it Let's say we have an ORSWOT of the form `{[{x,1}], [{Data1, [{x,1}]}]}`. If we want to add `Data2` from actor `y` then we would have a ORSWOT like this `{[{x,1},{y,1}], [{Data1,[{x,1}]}, {Data2, [{y,1}]}]}`. The values that the client is interested in are of course `[Data1, Data2]`. To remove is pretty simple: * Version vector does not change * Elements entry is simply removed For example we have `{[{x,1},{y,1}], [{Data1,[{x,1}]}, {Data2, [{y,1}]}]}` and we wish to remove `Data1`. We would then simply have `{[{x,1},{y,1}], [{Data2, [{y,1}]}]}` Merging is how the strong eventual consistency is achieved thanks to the version vectors and the dot pairs. Say we have two ORSWOTs A and B * Version vectors of A and B are merged in the following way: common tuples are kept, tuples in one but not the other are kept, tuples with same actor but different counter takes the one with the higher value (if you read up on CRDT this is the partial ordering). `[{x,1},{y,2}] + [{x,1}, {y,1}, {z,2}] -&gt; [{x,1},{y,2}, {z,2}]` The dot pairs are a bit more complicated but here goes: * Common elements are kept if: - common dot pair in A and B - dot pair for the element in A where dot pair count is greater than any count for same actor in B's version vector - dot pair for the element in B where dot pair count is greater than any count for same actor in A's version vector * Elements in one but not the other: - element's dot pair where the count is greater than any count for the same actor in the other's version vector As an example let's take the same version vectors as before for our two ORSWOTs `A = {[{x,1}, {y,2}], [{Data1, [{x,1}], {Data2, [{y,1}], {Data3, [{y,2}]}]}` `B = {[{x,1}, {y,1}, {z,2}], [{Data2}, [{y,1}]}, {Data3, [{z,1}]}, {Data4, [{z,2}]}]}` `A + B = {[{x,1},{y,2},{z,2}], [{Data2, [{y,1}]}, {Data3, [{y,2},{z,1}]}, {Data4, [{z,2}]}]}` Dots are just version vectors so they're merged just like the ORSWOT version vectors, but instead of comparing dots to the other dots, they're compared to the other's version vectors. So for `Data3` in A, `{y,2}` is greater than B's `{y,1}` in its version vector, so it gets kept. Similarly for `Data3` in B, `{z,1}` there is no `{z, _}` entry in A's version vector. Now this isn't quite the implementation that Phoenix uses, it uses a delta mutator implementation which means instead of passing entire ORSWOTs, it sends instead the delta mutator which tells the receiver how it should change its own ORSWOT. /u/chrismccord and/or /u/asonge can chime in for more info and also to correct me because I'm still relatively new to the idea. So for presence, it should be pretty easy to see how to use this kind of data structure. Each `key` is a channel topic, and the data entries are the users/sockets subscribed to the topic. Now, can you do this with Socket.io? Probably but you'll be using something like a redis backend so it might be overkill. You'd probably just want to have a separate redis Hash for it. Each time you subscribe to a topic, you add to it, when you disconnect you remove. Pretty simple. As for learning Elixir, you don't need to learn Erlang, although it'll definitely help. Only thing is learning how to read the erlang docs because it'll be a little bit different than the elixir docs. 
Welp, I wasn't expecting a CRDT tutorial in a comment, but there you go. That looks right from here.
Oh, also, the state machine for knowing when to send deltas and when you have to send a whole CRDT state to sync is also non-trivial to do performantly, though the CRDT solution works fine if you just spam updates hap-hazardly.
Wow, really thanks. You should totally make it a blog post or something, so that people can find it if they need it.
Yep. Thanks.
Awesome. Thanks.
I'm not an expert, but my first thought was that's not what you should use umbrella applications for. If two apps both depend on each other to that degree then they probably shouldn't be separate apps.
TLDR: Presence is *distributed* to nodes using the Erlang VM rather than using a shared external database. That means it doesn't require any external dependencies, maintains net-split fault-tolerance, and in that respect there are no real equivalents on other platforms. 
You don't need to learn Erlang to be *advanced*. Elixir is not a subset of Erlang. You will use a lot of Erlang libraries but not write Erlang code. 
Yeah, I agree with you. However, in this case, shouldn't game logic and the web interface be separate?
Is there a reason you couldn't just use an existing log shipper (syslog, filebeat, etc)? Then you could just use the standard logger and it would be language agnostic. I saw you mentioned `frustrating to use the native logging solution`. Can you explain this or give an example of when this would be the case? Overall interesting idea, the service seems like a simpler version of something like the ELK stack which is not necessarily a bad thing if you only need to stream and you don't need queryable logs.
It is a very normal thing to do. But because the data broadcast is sent directly to browsers/clients, you probably want to do the broadcasting on your web app, not on the business one. Think about it this way. Imagine that you want your JS clients to receive a new field on broadcast. Should you change the business app or the web app? To me it should be the web app. Hence that's where the broadcasting belongs.
Mm. Broadcasting belongs is the web portion yes. But I want to trigger certain events in the game logic section, and broadcast data based on those triggers.
Check the Registry module in Elixir then. Your business app can publish events with the Registry and you can consume those events and broadcast them using Phoenix' PubSub from the web portion.
Sure an example and the reason why it was made in the first place was for logging to find a but in a pretty substantial aws lambda. Cloudwatch is very not user friendly and has quite a large delay most of the time. I wanted to make something that would be a drop in 1 liner to have a better more responsive logging service for during development.
I wanted to build something basically that has no set up and just works for quick solution when the native out the box does not cut it. So create bin..add line that includes bin code. This is not for production logging as buckets stay around for 48 hours.
&gt; You will use a lot of Erlang libraries but not write Erlang code. I think this is the root of our disagreement. I didn't say that one needs to "know Erlang" to be advanced, I did say that one would "probably need to learn some Erlang eventually". To me, concretely, that means the ability to read Erlang code well enough to understand how an Erlang library one might call is working. I'm by no means advanced at Elixir, but I have found myself learning Erlang to facilitate understanding some of the OTP stuff. That might be an atypical route; since I'm not using elixir professionally, rather, I am toying with ideas in it. /shrug
&gt; Getting other developers involved in the codebase I suspect this is mostly because of the paradigm (processes, asynchronous messaging). Most of the formal training done today around programming _still focuses_ on a single threaded algorithm to solve a problem. Concepts such as communication, concurrency and parallelism are only briefly introduced. (I think it is improving a bit now, though) You are expected to develop these over the years. What you have noticed is that this doesn't seem to happen (sometimes because the systems worked on previously do not require it, or because not everyone solves problems at scale). I have encountered the same challenge, working on a similar system (in my case an akka application). I am positive about this though. I think we will get there. Today, more and more systems require you to deal with events and asynchronous communication. We just need to get better at disseminating the knowledge acquired, while building these systems. I suspect something similar must have happened when there was shift from procedural to OO systems (I confess I am a bit too young to know about that).
I think this is not a disagreement. We both said you need to read some Erlang but not write any. Reading != Writing. I can read some French but I can't write a word of it. Same for Erlang. As a full-time Elixir developer I have never written a single line of Erlang code and probably never will other than for personal interest. I've read plenty of it, and I can do that well enough to read the Erlang docs and know how to call a function. It's all you *need*. All the languages which run on the BEAM are compiled into Erlang AST, not Erlang, and then finally into byte code and so forth. Erlang, Elixir, LUA, Prolog, LFE all get compiled down to the same common AST and from there are finally compiled universally using the same tools. This isn't the same as inlining ASM in C code, Erlang isn't faster or more efficient than Elixir, it's exactly the same. It's also not the same as using JavaScript from elm, Elixir is a complete language except for the supporting libraries which made no sense to rewrite or wrap, just call the functions as _:lib.func/arity_ Levelling up in Elixir is going to come from embracing concurrency, mastering distribution, thinking functionally, understanding the BEAM, expertly utilizing OTP, and maybe, it depends on you, extending the BEAM using a Port Driver or NIF written in some other language, like C++, C or Rust. Unless you need to maintain legacy Erlang code then learning Erlang, IMO, is a path back to where you started, not forward. It's a symbolic, less expressive syntax for saying the same thing, Shakespeare basically. What's awesome about Elixir is that if you do have a legacy Erlang codebase, and you are already levelled up, above, you can immediately add new code to that project written in Elixir without any side effects, it's a perfect, seamless fit and a massive upgrade. Elixir is an exceptionally good and productive functional language with excellent tools and documentation running in an exceptional concurrent, distributed, soft-realtime, fault tolerant OS/VM called the ERTS (or BEAM) with an exceptional, proven, and bulletproof framework for building fault-tolerant, concurrent applications called OTP. It's bloody marvellous. Master those and you're in the 99th percentile. 
Allow me to introduce you to [gigalixir](https://gigalixir.com/) which I've successfully used for a few months now. It's like Heroku deployment, but geared towards Elixir apps (no daily restarts, hot-upgrades possible, etc.). It's hosted in Google Cloud, as is my postgres DB (this is a new offering from Google, btw). I'm currently on the free tier but I'm willing to pay a few bucks for single-command deploys.
Is there any issue with using dynamic languages with financial/mission critical stuff? From what I've seen most finance/ecommerce companies tend to use statically typed languages because avoiding small bug becomes way more critical.
Docker doesn't seem like an ideal solution if you're building an app that wants to use hot code swapping.
I've never used aws lambda but if you can't redirect log output, the only think I can think of is to implement your own [logger backend](https://hexdocs.pm/logger/Logger.html#module-custom-backends). It's going to be a little more involved but it's definitely possible.
You can how swap containers I guess...
But Erlang lets you hot swap code without taking down the runtime and it has mechanisms to maintain state. So you can have a GenServer running and maintaining its state and then do an upgrade and let it maintain its state. I don't think there's any way to do this with containers, it'll necessarily start a new instance of the Erlang runtime.
Thanks this looks super helpful!
Why couldn't you replace the individual nodes one at a time with kubernetes? Wouldn't that achieve the same thing.
Sure if you want to pay for deployment. This really interesting. It's not the same as having a library you can use on your own systems though. The fact that this service exists proves the lack of support for deployment solutions.
Heroku still exists and has for years now and made it easy to deploy Rails apps though...
I don't think so. I guess it depends on what your app is doing though. Here are some scenarios I can think of: - Your app is maintaining a number of long-lived connections. You upgrade by starting a new node and your old node stops accepting new connections, all new connections go to the new node. Once the old node's connections are all disconnected you can remove that node. - Your app has some GenServers that are maintaining some kind of business logic state. If you just replace a node that this GenServer is running on then you lose its state, you need to keep the node alive and let Erlang load the new code and call `GenServer.code_change/3`[1] to transfer the state from the old version of the module to the new version. If the data structure of the state is changing in the new version of the module then you need to write a custom `code_change/3` in order to transform the state from the old data structure to the new one. - You're writing a Phoenix app that's basically just responding to requests like a normal REST app, not really maintaining any custom state or channels or anything. In this case you can pretty much just start a new node and take down the old one, just like you probably do with a Rails app. [1]. https://hexdocs.pm/elixir/GenServer.html#c:code_change/3
Does it need to?
For the FUD to hold up, yeah, it does.
Dude, what do you use to make github.io your blog?
Another alternative is to find an existing project that excites you, develop a deep understanding of the code base (that way you will probably learn some Elixir ideoms and best practices), and contribute with possible improvements. There is almost always something to be done.
https://pages.github.com/
Is it possible to then build a release there and push it out from Circle CI?
Has been fixed, thanks!
Connect n arduinos over amqp to an elixir backend on a raspberry pi and control LEDs or what s.th. else with it. That's pretty interdisciplinary and still feasible for one person. (a friend did it) 
I have not tried this yet, but it should be possible provided you use the same OS setup in your docker image that you use in production (and you should be doing this anyways). Then you can test, run a build step at the end, and CircleCI can give you a download link to the build artifact to throw up on production.
Hello domnikl! When you first start learning Elixir, its really tempting to reach for a GenServer when writing a new app/library. However, I don't think this situation really calls for one. Since the API layer doesn't require any state, it is simpler to just expose function calls that call the API directly, rather than going through the GenServer. The missing piece is the api_key, which you can use the Application config to set/get.
Yeah, working on Open Source projects have always been on my radar! Thanks for the advice :)
[removed]
 good bot ----- [^Not ^a ^bot?](https://np.reddit.com/message/compose/?to=goodbot-bot&amp;subject=not_a_bot&amp;message=not_a_bot) 
I'd love to work w/ Arduino, would be my 1st time working so closely to hardware. But I live outside US and getting one is pretty complex/expensive. I rather do something web oriented for now :)
I had similar challenges when I wrote a library for http rest apis. My two cents from short experience so far is to make a very thin layer first, and build helper functions or genserver on the top of it. For example, all functions for external request should take authentication info as an argument. Then it's easier to test (e.g. those functions now do not care about any authentication state.). Then you can add genserver to manage state or retry requests and so on. But frankly, I wish there is a good "idomatic" small library example.
Thanks for your feedback davydog You are right, it is very tempting to use GenServer and I just haven't seen the simpler solution. Guess I was just on my way to over engineer a simple HTTP call. Will remove the GenServer. Thanks again!
Thanks for your feedback, its much appreciated! My goal was to keep it a very thin layer but at some point I must have started to over engineer it. After all, it's just a simple HTTP call anyway.
That's how we learn new thing, isn't it? :) I realized my code was doing too much (e.g. bad abstraction) when I found it is hard to test, and I might need to use it in different ways (e.g. with or without genserver to keep some state, or talk to different endpoint from one app).
The functional paradigms eliminate certain classes of bugs. So does static typing. I would argue that immutability, pattern-matching, guards, specs and unit tests will get you most of what static typing would (but without the guarantees... yet with a bit more flexibility/ease of implementation). It's just too bad Haskell is, all things considered, suckier than Elixir. ;) /opinion
Thanks for this.
Awesome write up! Lots of useful information and love the reference format with lots of links
Guard expressions are a sub-set of normal Elixir boolean tests. They look a bit different for the same reason function definitions look different: they are a unique bit of syntax. The main thing to learn with guards is what can and can not be used as a guard. But I don't really see them as being syntatically all that different. For you, how do you see them as different? Typespecs are always going to be a bit "strange", and in pretty well all languages I know that support such things they have a slightly unique syntax due to the unique requirements they have: they are describing the code rather than declaring the code. It doesn't help that typespecs have to follow the conventions of Erlang's typespecs, so there wasn't much option in the exact syntax used. That said, typespecs are optional. Good to have, but certainly not required. Protocols, like macros, are advanced topics and as they present means to polymorphism and metaprogramming (respectively) they are going to carry their own magic with them. Again, this is common for languages that provide such features. I think perhaps what Elixir stand out for you in these ways that it does have support for such things in the first place (not every language does), and the core syntax has so few obvious warts that the complexities stand out by comparison. (It isn't 100% wart free; what language is .. but imho it is far better than most with a remarkably small number of oddnesses) At the end of the day, this is mostly about becoming familiar with the language. With practice and more code under your belt, it'll all sort itself out. Learning curves are fun :)
I agree that there are three different languages but I would change one of them: * Standard Elixir code * Patterns (as in pattern matching) * Typespecs You could include guards inside patterns but guards are not really another language. They have the same syntax and semantics as Elixir code, they just restrict on what is allowed. It is an annoyance until you internalize them but they don't really require learning new concepts. Typespecs is the types language. All languages with types usually require you to learn the types syntax and rules. Typespecs are optional in Elixir and used to mixed degrees in the community. So if they are making learning Elixir harder, I would recommend you to drop them and revisit it later if you and your team can't live without types. Protocols are just a language abstraction which you'll use as you advance. All languages have a series of constructs and abstractions you eventually need to master.
There are only two languages - Erlang as base and Clojure for metaprogramming and some additional dynamism. Just learn those two. 
I think Java's much worse, esp. with Spring. Spring changes how Java behaves by adding annotations all over the place that are called mysteriously. I think, by contrast, Elixir's additions are palatable. For example, you can live without guard expressions. I do find it odd that only certain expressions can be used as guards. For example, String.length(s) &gt; 0 isn't permitted (I don't think).
I've really enjoyed this series so far. Thanks for making these.
Thanks for the feedback! :) I make them in the hope that people find it interesting and useful, so that's great ...
Nice writeup! 
Writing your own protocol for establishing the connection is pretty easy too! Made one that writes into a rabbitmq exchange, because gossip didn't work easily in a docker network.
There is one more pretty tiny language, Matchspecs (used for tracing or querying ets'es).
I was having a hell of a time tracking down a bug in aws lambda because I despise cloudwatch so decided to put together something that helped with that(helped find my bug). Here is a gif in action if you don't feel like setting up some code to try it. http://recordit.co/BTZi5GEvfk Hopefully someone else can find use out of it like I did because I plan to keep it forever free.
These videos a great, on behalf of the community, thank you :-)
[removed]
Honest question: why not use CloudWatch?
It seems the identicon library does not depend on egd at all: https://github.com/rbishop/identicon/blob/master/mix.exs#L23-L25 They are probably expecting you to bring egd in some way. They should either update their installation instructions or depend on egd accordingly. EDIT: It seems it was part of OTP and it has now been extracted to this project: https://github.com/erlang/egd
I don't think that's a proper way of describing or learning Elixir. You don't need to learn Erlang and Clojure in order to learn Elixir and I would say most likely don't.
very nice! did you consider pushing it upstream or making it available via hex? I am sure others would also find it useful!
Haven't found the time to do that yet. EDIT: here's the gist of it: https://gist.github.com/narrowtux/d1b01b50713ab525ddfa280f905e51de
the identicon library does depend on :egd, look at [this](https://github.com/rbishop/identicon/blob/0fa658d30b450adfea5eecf13a16aa81c8f6e2d2/lib/identicon.ex#L61)
Don't start trying to learn typespecs. Get comfortable with Elixir and OTP first. Typespecs are very useful but they will distract you from learning things that make apps function The predicates for guards are fairly concise - they are basically only Erlang primitive functions, and the full list is here: https://hexdocs.pm/elixir/master/guards.html. In general - you can only check types in guards and very primitive things (like tuple values or list values) If anything I would argue that Erlang is requisite to getting your hands really dirty with Elixir more so than any of the others you've mentioned. You don't need to learn how to write it, but you should learn how to read it and it would be extremely beneficial to understand the Erlang toolchains and patterns
You certainly don't need Clojure, but it would be detrimental to not learn Erlang considering OTP is written Erlang. You can certainly get by without it, but it would be hard to go beyond blindly believing the Elixir docs
I think parent means the dependency on `egd` is [not explicitly listed](https://github.com/rbishop/identicon/blob/master/mix.exs#L24) in `mix.exs` file of `identicon`. You'll have to add `egd` to your project's deps to pull it in.
&gt; how do you unit test a GenServer if it gets registered with a name? The simplest approaches I've found are to either only test the underlying functionality (i.e. separate the GenServer from the library) or allow GenServer options to be injected, and make the user (usually a Supervisor) responsible for deciding the server's name. Then your tests usually just don't inject a name (allowing them to run in parallel) If you want it to have a name (and essentially be a singleton) you can instead make your test run sequentially with `use ExUnit.Case, async: false`
What makes you say that?
Somebody at twitter replied as "egd was in the Erlang/OTP release earlier but has been moved out. Perhaps this is what tickles." So if it's moved out, how to make it work now?
 I personally hate cloudwatch. It is not realtime and needs to be refreshed. It can have a huge delay of when the logs are being wrote and there is no easy way to see what logs are from what lambda. All I tried to resolve with loggb.in for development.
Add this to the `deps` list in your `mix.exs`: {:egd, github: "erlang/egd"}
For another alternative, you could stream cloudwatch logs to elasticsearch via lambda and use kibana for searching/filtering/aggregations. This is a fairly common practice and has built in support in the aws console (more details [here](http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_ES_Stream.html) )
This looks interesting! I should mention though that I made this not just for the reason of cloudwatch and have a couple other places I use it so it was more met as an agnostic tool with little to no setup.(use it to debug electron development builds where dev tools are toggled off)
I am sure we agree given some definition of "Learn Erlang". You need to learn the runtime concepts, which are the same in Erlang and Elixir. And rudimentary understanding of the Erlang syntax helps reading OTP docs. I don't think you need to be capable of doing software development in Erlang though. 
Using Docker with Elixir is as fine as with any other technology. Immutable infrastructure is at odds with some VM features such as hot code swapping but you most likely don't want to use hot code swapping anyway. You have more than one option to deploy and that's good.
Any reference on matchspecs?
Personally I donâ€™t like Docker, but containers are good solution for deploying Elixir applications (you can use for example `rkt` or `systemd-ndspawn` instead of Docker). I am 99% sure that you do not need hot reload (replacing code in running app) and hot swap (replacing whole instances in running cluster) will be perfectly fine. 
I did that already, didn't work. :(
There's a misisng libraries and tools section here https://elixirforum.com/t/missing-libraries-and-tools/2179?source_topic_id=7945 on elixirforum including my own project :-)
Copied from my [Quora answer](https://www.quora.com/Erlang-egd-not-working-inside-Elixir-on-Windows/answer/Bangash): *Because `:egd` isnâ€™t the part of Erlang-OTP release anymore, so youâ€™d need to add `{:egd, github: "erlang/egd"}` to your dependencies, which you already did (as you said somewhere in the comments), but just in case anyone else with similar problem is reading the answer.* Once :egd is added to the dependencies, youâ€™d need to install rebar, the erlang build tool, as this library depends on rebar. Run `mix local.rebar --force` to install rebar (and rebar3). After installing rebar close and re-open your terminal and run `mix deps.get` inside the project folder. Thanks for A2A!
It's actually a great idea, thanks to how Elixir works in clusters. In combination with Peerage for DNS-based discovery, it's totally possible to use with K8s for orchestration. We're currently building on a running K8s cluster with a container for our API using Cassandra and GraphQL (Absinthe) (however this isn't in our cluster, we want to keep our data layer separate), another container running our supervisor and then running a couple workers from the same codebase (all domain logic), then another container for the dashboard running Phoenix. We're only running Phoenix on our dashboard, the rest are just Elixir apps. Here's a the gist of our docker-compose.yml file on Gist: https://gist.github.com/jacobwarren/14986bbbf639caf1eea5c1cef1950a39
This one worked! The main thing was the command `mix local.rebar --force` , may be Windows doesn't install rebar for Erlang by default.
Here it is http://erlang.org/doc/apps/erts/match_spec.html
Nice blank page with a blue header on top...
How I typically structure it is each application is actually split into two projects. The main application/logic, and then a light API project that is simply responsible for sending messages to that applications' processes. This way I have projects that would've depended on the main application, instead depend on the API project. But the API itself doesn't need to depend on the application (it just needs to know where to send messages, so you could do this in various ways such as naming, setting up a registry, passing in a pid, etc.). So all of your applications depend on the APIs they require. And the APIs don't depend on the applications. So you're able to break the cyclic dependency. You could get rid of the APIs and simply handle sending messages yourself, but that can get clumsy. 
Bump, anyone?
I strongly suggest you also post at https://elixirforum.com for more visibility.
Didn't know that existed. Thanks for the link!
Wow, neat project! I wish had projects like this when I was in school. I don't have much experience with remote nodes, but the rest of the code looks good to me. However I think you misunderstood what constitutes a valid coin. If k=4, that means hashed strings with 4 *or more* leading zeroes are valid. It looks like is_coin?/2 only returns true when there are exactly k leading zeroes when it should return true if there are &gt;= k leading zeroes. Essentially you're throwing away valid coins. This is the line that I think you should fix: https://github.com/vaibhav-y/parascoin/blob/master/lib/paras/miner.ex#L58
I haven't been able to get docker containers to connect together, do you have a gist or example of doing that? If so, can it be done without external dependencies like rabbitmq?
Damn, that's a good point. Rereading it without being rushed, it makes sense that it should be &gt;= k. I'll correct that for my reference, thanks!
hey, unless things changed since last year, the only thing you really need from Phoenix to integrate with turbolinks is a redirection header. Back then I wrote this package to handle it https://hex.pm/packages/turbolinks_plug 
We don't have any plans for turbolinks support in core, and as kagux pointed out, this is already trivial to add to your app with the above plug :)
Thanks for putting this together
[ElixirConf 2017 Youtube playlist ](https://www.youtube.com/playlist?list=PLqj39LCvnOWZMVugtyKlHMF1o2zPNntFL) for the rest...
Thank you Sir Chris McCord for the comment and thank you @kagux for the link. When I checked hex I saw two packages, the one kagux showed and another one called just turbolinks which is newer and with more downloads, which one do you recommend between these two?
Yup.
The rabbitmq strategy is really only necessary if you're using docker swarm set up as a scalable cluster, because you won't know the hostnames of the nodes or even how many of them there are. I do not know exactly how to set this up because our devops team did that.
I will say that of the Elixir mailing lists I'm on, this one is usually the least good. The Plataformatec one and the Elixir Weekly ones are usually much, much better. 
I have no experience with them so try one or the other and see how they work. The code shouldn't be complex so I'm sure both options are great.
Not to knock this one, but I have to agree that those other two are really solid week in, week out. Links for those curious: http://plataformatec.com.br/elixir-radar/weekly-newsletter https://elixirweekly.net 
The OpenGL one was super cool as well!
Yeah I'm really excited about that one. Who know's if it'll find a use case but it definitely shines a light on what elixir/erlang/beam can do.
Usually I think these lists are dumb but this is actually pretty good
For something very small, ie just a handful of routes, using Python + Flask in a single file is much â€œlighter weightâ€ than any Phoenix server.
I only use Phoenix if I need a web frontend/API. Other than that, straight elixir umbrella apps for all types of networking applications, and things that can use the BEAM concurrency model (I usually put my Phoenix app in one of the apps of an umbrella app). As for other languages, when a new project comes up, I have a look at the requirements, and choose the best option from what I'm familiar with. Also, if I know it's a good use case, I'd consider a language I have little experience with e.g. I've never written rust, but if I had to write a bulletproof system application, I'd consider it for that, particularly a small one that I can cut my teeth on. I always use `irb` as my calculator, and python for doing filesystem stuff.
I needed service that would redirect all HTTP requests to HTTPS version (as due to bug in proxy, I have no way to determine if incoming connection is HTTPS or not) so for first time in my life I used go for program that has at most 15 lines. 
Same with Sinatra in Ruby land. Also, for non dynamic sites, Middleman for the win.
how about a forum or blog? --- or internet shop.
You can also just use Plug. It ships with a router and it has all the building blocks you may need (logger, static, session, etc).
Both of those are relatively complex services. You could build them in Phoenix just as well as any framework, but the nature of them (basically CRUD apps with mostly static data) doesnâ€™t necessarily exploit the strongest parts of Elixir/Erlang e.g. real-time stateful services. But if you like Elixir and Phoenix, by all means use it!
I'm trying to understand if I should use Phoenix for a blog or forum or internet shop. Or perhaps it'll be better to use something simpler, lighter and faster such as Rust, Haskell.
Phoenix is definitely a valid option. As someone who is comfortable in Elixir, I would consider it strongly. None of these projects you are describing require any particular speciality in a language, so its best to just choose what you will enjoy writing in the most.
IMO Rust and Haskell are not much simpler than Elixir, and very often by far more complicated.
*IMO Rust and Haskell are* *not much simpler than Elixir, and very* *often by far more complicated.* ______________________________________________________________________________ ^^^-english_haiku_bot
for whom?
the question isn't whether or not you can use Phoenix. It's "when you wouldn't use it"?
This is probably the correct answer. But I would still use Phoenix, personally, just because it's so simple to put something together with its generators and stuff. If I want to use Plug directly then I feel like I'd actually have to work harder to achieve what is ultimately about the same result.
For a blog or an internet shop I may possibly backslide and use Rails just because I might be able to do it faster, and I don't think those projects will benefit much from Phoenix's speed. But I just like Phoenix better and I'd rather maintain an Elixir project going forward so the reality is I wouldn't *actually* use Rails here unless I were super, super strapped for time and really thought I could go faster with Rails. I wouldn't use Rust alone for web projects. But if I'm writing something in Elixir and I get to something that needs higher speed computation or something then I'd pull in Rust in addition to Elixir. Like let's say you're building a game server and have some kind of simple but frequent velocity/bounding box checks to make sure the user is in the area they're supposed to be in and not trying to cheat and teleport to a different part of the map. You could probably write a first iteration of that in Elixir, but Erlang isn't good for math computation so maybe you'd rewrite that code to a Rust NIF for performance reasons. I hear great things about Haskell but don't have much experience with it. I probably won't get much experience with it either. I feel like if I want that kind of type safety I'm more likely to use F# because then I can use the same language for backend (Suave), frontend (Fable), and mobile (Xamarin) and have a good type system. I'm not likely to use Go for anything. I know a lot of people love Go, but I just don't get it. It seems like a much nicer C (but with a GC), and that's just not what I want for *anything*. For web apps I'd rather use Elixir. For system stuff I'd rather use Rust. For native GUI stuff I'd use C# or F#. I don't mean to dump on Go, it's just that for anything I want to do I don't really feel like it *fits better* than languages I already know better. I'd use Python if I have any sort of machine learning requirement. I personally don't really like Python as a language that much, but it undeniably has a nice toolbox for machine learning tasks so I'd choose it for that.
thx. And then for what kind of web applications specifically Elixir is the best fit?
Yes, so my point is, for the example applications you gave, I donâ€™t see any particular reason not to use it. 
It's not inherently bad, though if you are using Docker to achieve a [Twelve Factor App](http://12factor.net/) type of architecture, you may be losing out on one of the biggest strengths of Elixir/Erlang i.e. building stateful services.
and I don't see a reason to use Elixir in particular 