Phoenix is graceful and modern
I only tried Excel files that have been saved with Pages or LibreOffice. Submit Excel files to test if you want.
So sweet...but how do I upgrade my 0.17 app?
Yay, congrats!
Sorry, life got in the way of my mailing list post. 0.17.1 was a code-freeze/rc, so all you need to do us bump your phoenix dep to `{:phoenix, "~&gt; 1.0.0"}`, run `mix deps.get` and you're all set!
Well, I looked at the code changes from [0.17.1](https://github.com/phoenixframework/phoenix/compare/v0.17.1...v1.0.0) and it shows no change at all. :) Different if you are coming from [0.17.0](https://github.com/phoenixframework/phoenix/compare/v0.17.0...v1.0.0), but I have really no idea if there are things to upgrade/change to make it work. Sure /u/chrismccord could tell better than me if there is something to change. :)
I know at least on comparison-heavy code I've benchmarked, my elixir implementation ran 20x faster. This might be due to pattern match optimizations, but it was very relevant in the problem domain
Elixir is built on the BEAM VM and it does very little which isn't very optimized for this environment. If you want to research this in-depth, look for similar discussions on Erlang and everything will apply. BEAM's biggest blind spot is on tight, computation-heavy functions. Things are going to be much slower than in machine-code compiled optimized code. This isn't to say it is too slow for most tasks as well-written Elixir is still going to be faster than Ruby or Python by an order of magnitude. Elixir uses immutable memory structures and singly-linked lists, so certain algorithms are going to be difficult to implement efficiently. This can also be a problem for folks who are new to this style of programming as different tricks are used for efficiency and it can be very easy to write very bad code before you know them. Of course, BEAM is implemented in C and can interface with C libraries if you want. For many of the cases which get caught by the previous efficiency problems, this is a solution which allows the best of both worlds. Even adopting everything the Erlang community has to offer, library support is still a bit thin, so there are going to be solutions available in other languages which have to be custom-built in Elixir and it is rare to have many choices when looking for a pre-built solution. Now the good parts. Elixir is great wherever you want to write software which can scale across hardware and networks with a minimum of fuss and which can isolate and recover from faults with ease. If you think that these are the problems of the near future (and many people do) then Elixir is an interesting solution. There really is no competitor for the BEAM VM and OTP for their focus on doing concurrency right and Elixir provides a modern way of accessing them with a robust macro system, an alternate (argueably friendlier) syntax, and some smoothing of the edges around a decades old set of libraries.
My advice, read up on Erlang and the areas its best in and the criticisms of it. Then remove anything that negative about the web (solved pre-phoenix, but phoenix solves it really nicely), tooling, or meta-programming as Elixir makes those parts really nice.
This is resolved now. Figure I'd update this thread for anyone else trying something like this. You can pass `[recv_timeout: :infinity]` as an option... like `HTTPoison.get!(url, %{"Accept" =&gt; "application/json"}, [stream_to: self, recv_timeout: :infinity])` 
Yea I meant shipping a single execuatable to an end user with all packaged dependencies
The "single threaded" performance of Erlang may actually be worse than Ruby but no one uses Erlang single threaded. By it's very nature, it's built to be used with 100's or 1000's of BEAM VM processes--which, be careful, are not the same as OS threads. They're much more lightweight. TL;DR Comparing single threaded performance of Erlang with anything is a bogus comparison.
Do you know of anyone who builds a monolithic executable image anywhere any more? I mean Windows apps all ship with DLL's and Linux (and as far as I know) Mac OS/X apps ship with .so's. Yes, it's a little annoying to have to bundle some of Erlang's VM but .Net packages have to have the CLR and Java packages have to have the JVM. The BEAM VM is integral to Erlang's terrific concurrency story anyway so this hardly seems a big burden to me.
I make no claim that I wish i could ship an executable. The question was about what elixir is good at and what it is not good at. It is not good at creating an executable, standalone application for an end user. It is good at creating a server application. That is what I hoped to convey. 
I've also created a Vagrant-based setup for getting Phoenix (and MySQL because one-step-at-a-time for me) up and running quickly in an environment to play around with: https://github.com/sbarre/phoenix-mysql-vagrant If you don't want to use MySQL, you can modify my `scripts/bootstrap.sh` file to swap out for Postgres. You'd also have to change the `scripts/install_phoenix.sh` file to remove the `--database mysql` part. I hope this helps someone. It's still a WIP and I can't promise it will be perfect for everyone. I'm just starting to learn Elixir (and Phoenix) so I wanted an easy environment to tinker.
But that's kind of my point--almost no one ships a "standalone" executable any more. Almost every executable has dynamically linked code (whether that be DLL's or SO's) and many rely on a VM for functionality too. 
The easiest way to have a supervised process that doesn't need to handle messages is using a supervised task. See [here](http://elixir-lang.org/docs/stable/elixir/Task.html) for more info.
And at least in my head, it makes the most sense to have the data operated on as the first argument. So you *always* have `function_name(data, fun)` Also syntax-wise you often have anonymous inline functions, which have arbitrary lengths (aka characters required to write them), which produce some "noise" in the code. This is simplified when they always come last, eg: a = map list, &amp;(some anonymous function call) b = filter a, &amp;(another anonymous funtion call with arbitrary length) c = reduce b, &amp;(a short anon func) And of course, this way the piping operator "|&gt;" works best: list |&gt; map(&amp;(some anonymous function call)) |&gt; filter(&amp;(another anonymous funtion call with arbitrary length)) |&gt; reduce(&amp;(a short anon func)) Which I find more readable than even ruby. (of course, this specific example could be simplified further through a for-comprehension...) A counter example is not only erlang, but also PHP, where I have to look up every single function because the ordering is different every time. PS: A "bad" choice for me is the argument ordering in Elixir's `map_reduce` function, where the reducee comes before the mapping function, I find this counter-intuitive just by looking at the functions name. :/
I can certainly see the appeal of that. Makes installation dramatically simpler and hence less error-prone. 
Elixir isn't "fast" - in fact, it can be slower than Ruby for some things -- but it makes concurrency trivial (thanks to Erlang) and combines it with a beautiful, Ruby-ish syntax.
It's possible to write slow programs in any language. I think you can call a language fast if it's possible to write more performant applications with the language. If you go by that definition Elixir could be considered a fast language for many use cases.
The subject of the function is always the first argument and is typically the data being acted upon. This allows you to easily chain multiple data transforms using |&gt; .
Do let me know if the implementation can be improved in any way in terms of performance or even better, contributions are welcome.
Why build this with Rails instead of Elixir?
&gt; But you'll probably never see Elixir used as a simple glue language. What makes you say that? :)
 _x = Blanket.Supervisor.start_link Is this a pattern? Since the value is discarded immediately (the function ends on the next line)
"use" just calls the \_\_using\_\_ function on the specified module. It's a hook you can write. http://stackoverflow.com/questions/28491306/elixir-use-vs-import
Thanks, updated it.
Yeah, just a quick 1.0! I'd really like to get a responsive version up at some point, but I was more focused on proof-of-concept release. I think scrolling / zooming would help mobile work, otherwise you'd have a really small area to draw in. I'll also have to update the click / drag handling, as you observed it doesn't work at all right now on mobile. Some other ideas I had: * Private canvases * Infinite scroll * Time lapse Feel free to fork the source on github if you want to play around, I'd welcome any patches.
Anyone know when [Code Wars](http://www.codewars.com/) will add Elixir? Currently it's listed as a request among a long list. Code Wars has been fun for Python, Clojure, and Haskell. Also using Exercism, but Code Wars is more fun. Anyone know of any other interactive community polyglot challenge sites besides these two?
It is production ready, though bare in mind that you will have fewer libraries available then if you were using more established languages, such as Java, Python, or Ruby.
The website is down :/ Also, you should put a link to Github here. You know, in case the website is down.
Back up now! Apparently the instance is too small... I'll be making some adjustments later.
http://www.phoenixframework.org *
Phoenix provides some functions for simpler form generation http://hexdocs.pm/phoenix_html/Phoenix.HTML.Form.html And if you use the Phoenix generators to create your controllers, they'll actually generate a form for you to to match your model. 
First, we should not confuse strong typing with type safety. Honestly, 'strongly typed' is so convoluted in its usage that it is often difficult. BEAM operations are strongly typed aside from comparison operations (e.g. 1 &gt; :foo). What you are wanting is a type safety system where the compiler uses some sort of type algebra to validate that types sent to functions are correct. The only difficult thing about implementing this for a BEAM language is that type definitions for functions written in other languages are often missing or inadequate for a more robust type algebra. There is a type checker for BEAM called Dialyzer which is compatible with Elixir. Go read up on the @type and @spec module attributes if you are unfamiliar with them. There is also the [dialyxir](https://github.com/jeremyjh/dialyxir) project which introduces mix tasks for running Dialyzer. Regardless, there are many limitations to this type checker and it would certainly be nice to have something better.
But for test you would have to do some magic, cause .exs files are not compiled to .beam files and hence they are not analyzed by dialyzer. This post describes that magic: http://learningelixir.joekain.com/dialyzer-and-integration-tests/
Good reason to use LFE - Lisp Flavored Erlang - true macros with all the goodness of parentheses :)
This isn't a BEAM problem, and it's certainly not a strong vs weak or static vs dynamic language problem. It's an API and expectation problem. The only difference between static and dynamic typing is that type checking happens either at compile time or run time. If you want compile time checks, both Elixir and Erlang (any BEAM language) can support "records" for compile time checks about the explicit type of result (when combined with Dialyzer or Dialyxir). If the ambiguity of ExUnit API expectations are too much of a pain, then you can always request that the authors change the API to an explicit record type (similar to structs in other languages). But remember that *you* have complete control over what you return from functions. If it's not a compile time check, then it can always be a run time check to ensure the output you wrote for that function matches the API's expectations. For example, if "result" is the implied result from your function (which we'll explicitly write here): result = {:ok, %{a: 1}} case result do {:ok, obj} when is_map(obj) -&gt; :okay obj -&gt; :not_okay end There's no ambiguity if you resolve the ambiguity by checking. To summarize, maybe you need to look more at "records" if static checks are a concern. Maybe the ExUnit API needs to use them. But aside from any of that, you can always explicitly perform the check at run time to satisfy the API, if needed. At the end of the day, it's all about invariants. Programming languages usually take one of two strategies: 1) make the perfect language and type system that catches all mistakes, or 2) make a language that runs reliably despite software errors and hardware errors. Erlang and other BEAM languages took option 2. In order to have hot-upgrade distributed capabilities, Erlang made the trade-off of allowing a system to be temporarily inconsistent, and dynamic typing helped with this. There was an earlier attempt to make Erlang a static typed language, but it only made the language slower and more complex, so they ditched the experiment. So this wasn't an oversight, it was an intentional decision. The way most things should be handled is that results returned from functions should exactly match the checked expectation (via "case", etc.) or it should mismatch and fail intentionally and let the process (which should be minimal in responsibilities) restart. If you want to avoid restarts, then be more explicit in handling the error (or otherwise use monitoring or trap errors from linked processes, etc.). So please be conservative in criticizing a language before you've mastered it. It's much more likely that there is a reason for why things are the way they are, and it pays to learn common practice and idioms. If the documentation isn't clear enough about the reasoning and trade-offs, then perhaps the documentation needs to add further clarification for why things are the way they are. If the reasoning is still wrong, then is the time to criticize. (Edit: mention of Dialyzer/Dialyxir)
This is more a bug in ExUnit that should return a better message by using a case statement as others have explained. Static typing vs dynamic typing is a trade off. Dynamic typing gives you more flexibility, static typing gives you more strictness. However, Elixir strikes a nice balance giving you the ability to be strict where you want to be with pattern matching, and loose when you want to be. Yes, it can trip you up, thats a downside. But with tools like dialyzer, type specs and good documentation (and tests) its basically a non-issue.
Also check out bitwalker's https://github.com/bitwalker/exirc for handling IRC connections in Elixir.
Awesome. Thanks!
I have since changed my viewpoint on `httpc`... it does not support many basic HTTP operations, such as `PATCH`, or sending a http body with `DELETE`.
I feel that goes without saying when you undergo a project using elixir :)
Very nice. Thank you!
Its interesting that you brought that up- I always thought that Delete/Patch/Put methods were all 'faked' by putting a _method parameter in the body of the request since they aren't actually part of the http standard. Httpoison uses [Hackney](https://github.com/benoitc/hackney) for its requests, and I took a look through Hackney's erlang source code and I have not yet seen where the send_request function alters the body of the request for certain types. I'll dig through it a little more, but it would be interesting to find how it works.
I've built a lot of multitenant apps in rails and a lot of other languages and frameworks, and I've never used a gem like apartment. These kinds of dependencies tend to create the illusion of progress in the beginning, then inhibit it after the initial phase (usually an early prototype) is complete. The short answer is that you can do multitenancy in just about any language and framework that allows you to scope a query. Edit: this gem uses a definition of multitenancy I've never heard before, in that you're actually changing schemas (which most devs would understand as 'database'). The definition I've always used is a common database to all users. Still, the point stands: you can almost certainly achieve this in almost any language/platform.
Some web frameworks (like Rails) use the `_method` format like you described, because not all web browsers support `PATCH`. The `_method` is *not* part of the HTTP standard and is an implementation of those frameworks only. `PATCH` is a proper HTTP method on its own, no less than `PUT`
The complexity you'll introduce by relying on both Postgres and OrientDB is frankly, in all likelihood, not worth adding OrientDB unless you REALLY need it. Chalk that one up to "problem I'd love to have" and build it with just Postgres first. If you want, build in a layer of abstraction so you can swap out part of the stateful storage with your alternative document database of choice, later. EDIT: He's dealing with a graph problem, so he does kinda need a non-relational database
Nice post. I want to learn elixir and you are completely right: Finding a link to `some_great_lib_ex` would definitely get my attention!
I REALLY need OrientDB, it's not a "problem I'd love to have" since it has nothing to do with scalability. My problem is a graph problem. Trying to solve it with a relational database will not work. The queries over that many nodes are just too slow. And with that I mean really, really slow even with one person using the site. It is just the wrong database type.
[This article gives you a good idea why sometimes relational databases just don't work](http://blog.everymansoftware.com/2011/07/performance-of-graph-vs-relational.html). There are better ones out there but I don't remember where right now. &gt; Right around the 54 minute mark, Emil talks about a very interesting experiment showing the performance difference between a relational database and a graph database for a certain type of problem called "arbitrary path query", specifically, given 1,000 users with an average of 50 "friend" relationships each, determine if one person is connected to another in 4 or fewer hops. Against a popular open-source relational database, the query took around 2,000 ms. For a graph database, the same determination took 2 ms. So the graph database was 1,000 times faster for this particular use case. Not satisfied with that, they then decided to run the same experiment with 1,000,000 users. The graph database took 2 ms. They stopped the relational database after several days of waiting for results. 
Just noticed there is no way to get to the monthly archives in my blog yet, but there is support for it in the engine. Here's a direct address: https://blog.nytsoi.net/archive/2015/05/p/1
Thank you for the feedback! I've updated the code. Off topic: Do you perhaps know of a good Elixir web crawler? Edit: I've looked over at hex.pm, but the any mature ones..
Thanks! :) Performance numbers are pretty good. On my single-core Linode server (with a bunch of other stuff running but low loads) serving a single post takes around 300–600 µs, whereas serving a list page takes about 1–2 ms. The response times are really quick because the content is pre-rendered and there is not much the engine has to do to render it. I tested it by running it on a Raspberry Pi 2 with Arch Linux ARM (no nginx in front) and was unable to max out the performance. The best I could generate with my laptop were 2000 concurrent clients, which resulted in about 220 reqs/s with an average response time of 20 ms. Though I did not compare it with any other engine so the numbers are somewhat meaningless. When booting the server or refreshing it, on my Linode server with 8 pages and 22 posts, it takes less than a second to build the database. All the posts are rendered in parallel with earmark, so it should be fairly fast. It does not have transactions so if there happens to be an unlucky request during that time, it may get an empty page as a response (ideas for fixing that are welcomed).
I'm not sure now that the functionality exists. I'm thinking to branch ecto and make all the calls explicit in setting the schema intended. Digging into the source might reveal that the functionality exists. Better yet, maybe create a library to wrap in like apartment and use the modified version of ecto if I need to.
Cool. I'm a big fan of overengineering hobby apps to learn concepts. Looking through your code, I especially like how this is a good way to learn about gen servers: not just the how, but also the why. 
What are your goals with "multi-tenancy"? Are you just looking for an way to scope your queries? What do you need above and beyond scoping models to the foreign key of the main resource? 
I'm looking to make a multi-tenant application and do it while leveraging postgres schemas instead of using scoped queries.
This looks awesome! I'm just starting out with elixir, thanks for opening the source so I can learn from it.
Note that for the password confirmation which is implemented, the confirmation field does not need to be added to the schema [acccording to the docs.](http://hexdocs.pm/ecto/Ecto.Changeset.html#validate_confirmation/3)
I'm not sure I follow. How does templates being implemented as functions change what functionality you would put in your views?
Thanks, it could be useful :)
This is really cool! I will definitely be thinking of integrating this into future projects.
Yes, Phoenix was started from day one to tackle the realtime web. We have a "Channels" layer to do just that. This 90s clip of a collaborative editor should give you an idea what's possible: https://www.youtube.com/watch?v=GLa9gtvP13Y 
The video says it took about 100 lines of code including the javascript.
Ok, so i've pretty much gotta know 2 languages to make this work. Was just wondering if this was implemented with Elixir only but i'm guessing not as you need Javascript for the client side. Thanks
Thanks :D Will google around to understand channels. I have been trying various peoples react + Phoenix, ember + phoenix tutorials. 
My suggestion on the matter is: start _vanilla_. Start using vanilla javascript, and then switch to a framework. The _hows_ will be more clear. Adding layer is always (well, most of the times) easy, while taking away is *always* a pain in the ass. [Here](https://github.com/phoenix-examples) you can find some small applications written in Phoenix. [Here](https://github.com/jhstatewide/pixelwall) you can find an application that leverage on websockets for drawing on a canvas collaboratively. Have fun!
Yes, unfortunately multiple language is a must, because the browsers understand javascript and little more. I really doubt it exists a Elixir =&gt; JS transpiler. The only way to escape the multiple languages "problem" is using nodejs as backend. :)
Cool, very cool. I am digging my heels into LFE - Lisp Flavored Erlang instead of Elixir, but I keep an eye on Elixir too, since it has so much activity on the forums. LFE is very cool too, considering Robert Virding created it, and is one of the original people working on Erlang. It's a Lisp 2. It just needs a good book like Programming Elixir...
How are you managing environment variables and where are you hosting your database for Digital Ocean?
Nice thanks for the guide, I was just looking for something like this actually. Currently I have only found this one so far: http://hady.svbtle.com/setting-up-elixir-on-digitalocean You seem to cover the same points, but your seems simpler to understand. Would you say he does something you don't? First time dokku user as well, so just curious.
I save it, as I will probably use it in the future. Might comment on this sometime in the future if are still into Phoenix :)
Checkout the change log for the details about the release: https://github.com/elixir-lang/elixir/releases/tag/v1.1.0 
It's tutorials like this that i need. Thanks so much for this!
Well, long post, long(ish) answer! But let me recap your post in a sort of TL;DR (so if my premises are wrong, you could correct me without reading through all :P): you have never really wrote code, tutorials aside, and you want to start somewhere building web applications, but there are so many choices that you are uncertain on which direction take. My TL;DR response: _don't use Elixir/Phoenix, start with something else like Ruby/Rails or Nodejs/Whateveretheyuse, then come back here_. Please, let me expand my answer. And let me start saying that what lead to my answer is your lack of experience and the young age of Elixir (despite being based on something that is 20+ years old, like Erlang). Elixir is a beautiful language and I love it, enough to say f\*uck it and build something that we use today in production, so is not my lack of love for the language/ecosystem that drive my answer. The main problem is that you are a webdev by extraction, and probably you will stay on track, and soon move from building site with wordpress to build also the backends of your sites. And when you will start, you will start to face _problems_. Problems lead to frustration, and dealing with frustration could be a deal breaker. But older environments got you covered! For almost every problem, there is a _solution_! Someone smarter than me or you has already figured it out and put that piece of information somewhere, be it a gem or a node package or a blog article. This will keep things moving fast and prevent stagnation that could lead to frustration. And then, when you are experienced, you will feel more confident on making choices, and suddenly the lack of existing solutions will not be a problem, because you know the solution and you will be that guy who wrote an article on his blog or published a library on hex.pm! Elixir has a growing ecosystem, but the hard truth is that, as today, there are **938** packages published on [hex](https://hex.pm/), when the listing of the A letter on [rubygems](https://rubygems.org/gems?letter=A) give you **6808** results, and [npm](https://www.npmjs.com/) boost (holy shit) **188282** packages. That said, if you want to start with Elixir, that's fine! You will find that the Elixir community is very welcoming and full with people that will help you if you are stuck. Anyway, have fun! :)
&gt; "Don't choose an older platform, go with with the new popular one." That's unfortunately a mistake that many do, thinking that the hip techy thing will be the next big thing. There's always a reason why old platform are still used, even PHP^(please don't kill me). &gt; However, you're right in that RoR is much more stable and well documented with many more gems and tools. Plus I am just learning JS but am also so attracted to the backend that I'm also thinking of learning Ruby - but I doubt learning two languages at once is a good idea as it could confuse me. Learning two languages could be "too much", but I don't advise against. If you start _small enough_, with little steps knowing your limits, you could do it easily. RoR and JS go hand in hand, so it won't be a problem writing small snippets of javascript at time. And before you know, you will be proficient in both of the languages. :) If you need any specific help, feel free to drop me a PM. 
Whatever you do, don't learn framework-first. Phoenix is amazing at what it does but it's not the whole of the language nor even a representative subset. Elixir is a great language if you're new to programming because it teaches you that there are other ways to do things than the one true OOP. But it can't stand alone. No language is a silver bullet, but most have something to teach.
Let me give you my perspective of learning various languages over the last couple of months. By learning i mean i tried and failed. I really like functional programming it just seems structured to me, i love seeing function, then function then function. I was attracted to learn Elixir via Phoenix. Problem is, finding tutorials is hard, it's really hard. That for me makes it really difficult to learn passed the basics, i just cannot get enough of the basics. With Python, Ruby and Node (meteor) i have found sooooo many tutorials i cannot keep up. How to use React with Ruby, easy, Django with Ember, easy. Authentication, got it, uploads, database support. They all have it as they've been around for 10+ years, meteor hasn't but it's really quite easy due to the huge amount of Javascript developers. So i've kept Crystal(seems amazing for it's speed) and Elixir(probably the easiest functional programming language and best community hands down) in my mind, but in the back, i wait for new tutorials and i just learn a little. I'd say the easiest to learn is Python, the most fun for me is Javascript or Go and the one i just didn't click with has been Ruby, due to the fact it's heavily coupled with Rails, but i still kick on with it. Golang is also a good mention, it's fairly close to learning Javascript, the community is large and it's very simple to install, setup and get going, it also has formatting which is actually amazing. So i'd say, Ruby, Python, Javascript or Go, if you want fast and future proof, i'd say Go is a great choice, i say that as many companies are switching Rails to Go API's but it's not going to be as easy as making these things in Rails. Totally up to you! Be careful of the Golang community they are harsh usually to newbies as they seem to be from the old school programmer club. At least they were harsh when i was very new to it. I am eagerly waiting for more and more tutorials from all angles. Today one about posting to Digital Ocean was great. So simple, but it's what we need. We're totally new.
As a beginner? A lot. People tend to play safe when learning and use whatever could avoid write yet another line IMO. with experience come the choice to say no to another dependency and yes to write it from scratch (When necessary).
There is probably more than one way to do that :) First thing, that blocks me from creating multiple games are processes registered with a name. So I would have to get rid of global names. This requires saving all pids of processes, which I am going to communicate in process state. Alternatively, I can store them in ETS table and look up every time or use gproc as in the tutorial. Second thing, I have to add top level supervisor, that will be supervising other games. *simple_one_for_one* strategy would be good (it allows you to dynamically add children).
gproc (which relies on ETS) is a good choice for rich process registration and discovery. You could register a GenServer using so called _via_ tuples: def start_link(game_id, ...) do GenServer.start_link(..., name: {:via, :gproc, {:n, :l, {:game, game_id}}}) end Which uniquely registers your process under `{:game, game_id}` alias, where `game_is` is arbitrary Elixir term (though I suggest keeping it simple and lightweight). The attempt to start another server with the same `game_id` will return `{:error, {:already_started, pid}}`. If the registered process terminates, the registration will be removed. You can use this via tuple to issue calls/casts: def some_action(game_id, ...) do GenServer.call({:via, :gproc, {:n, :l, {:game, game_id}}}, ...) end It's worth extracting the via tuple formation to a separate function, to reduce this noise. As tomekowal mentioned, you'll want to start these processes from some `:simple_one_for_one` supervisor. If you need to do "get or create" operations, you can simply do: def get_or_create(game_id) do case Supervisor.start_child(:game_supervisor, game_id) do {:ok, pid} -&gt; pid {:error, {:already_started, pid}} -&gt; pid end end 
That looks like it would work for handling getting the game from a top-down perspective, but it doesn't really look like it helps with inter-game communication unless I did `{:via, :gproc, {:n, :l, {:game, :component, game_id}}}`, but then each component needs to store the game_id and at that point, why not just store a local ETS table PID?
See also this [Stack Overflow Q &amp; A](http://stackoverflow.com/questions/18011784/why-are-there-two-kinds-of-functions-in-elixir/18023790#18023790) for more detail about why the decision was made to use the f.() notation. Especially the answer from the primary creator of the language. 
If you make your videos for absolute beginners, i mean the newest of the new, i swear you will get a lot of buyers! I'll be among them. The Elixirsips for newbies!
So this is like turbolinks for Phoenix? Has anyone tried it out yet? :) Shame it has a jquery dependency.
thanks :)
Dumb question I guess but is it "Numerino" (github page) or "Numerico" (headline of this post)?
pjax is the thing that turbolinks was originally inspired by. I was never sure why they went and implemented their own thing instead of using pjax, but whatever.
&gt; Just looking over the code, if the queue gets to any significant length you're going to exponentially increase runtime, I think The behaviour depend on the ratio between push and pop. If you push an huge number of element and then you start to repetendly push and then pop and push and again pop etc... the structure will be very slow, however if the ratio is ~1 you will get good enough performance. As the ratio between push and pop grow, a lot of push and not many pop, you will see worse performance. In another [branch](https://github.com/siscia/numerino/tree/list_implementation) a better data structure, performance wise, is implemented, however I haven't seen much gains running the benchmark. 
Sorry, is "Numerino"
You are definitely right since is not the data structure. However the focus should be on the priority sort and not on the message passing...
String.jaro_distance/2 looks super interesting, I wonder how it is for performance. 
Just ordered the beta of this book and am reading it now :)
An idea I've been playing round with is making processes more unreliable to force me in to thinking how the supervision tree will work. This is heavily inspired by netflix's chaos monkey. What does everyone think about this approach?
I just ordered too, looks good so far. It's nice to start seeing more documentation about elixir/phoenix.
Let me get out my crystal ball... Drat, I left it at the office. At a guess, I'd say that it will. It's as accessible as python or ruby, and it brings functional goodness at the same time. And then there's all the stuff that comes with BEAM like OTP. I haven't personally used Phoenix, but it sure seems nice and people say great things about it. Oh, also, Elixir is kinda fun. Really. But nobody can tell for sure if any language will catch fire. Just learn interesting languages and build interesting things. If you do that then you will be able to find a job, even if it's in another language.
I would say it will bring much needed life into the Erlang world, but functional languages are far from becoming mainstream. Scala is probably as close as it comes to mainstream functional programming - and even that has spotty integrations around the business world.
I'm seeing more and more ruby job ads saying elixir is bonus points. I get the sense that ctos at ruby startups are eyeing elixir. There are still relatively few 100% elixir positions, but I think it will become alot more mainstream. Phoenix is just easy, and heading to where rails is in building stuff quickly, I just don't see anything that easy in the newer languages out there, especially not in functional languages. People will take the path of least resistance in building something that nets them the best capacity possible. Phoenix is arguably *already* near the top of that list today. 
Hey. Thanks for some great feedback. Glad you've found the project amusing :-) I've logged 1 and 2 as github issues (I think 2 may be related to named processes). That's a pretty good idea around the config flags. I'm still in the very early stages of this but I suspect one of the next few steps is going to be around making this easy to confgure
My prediction is, Elixir will be the "new ruby": hot stuff for Startup and small shops, a freakin nightmare for large(r) shops. Don't get me wrong, it's not a bad thing per-se, and I'm investing personally on learning Elixir. Sometimes is not the lack of of jobs that determine the size of the market; more frequently is the lack of applicant that determine the lack of jobs. Is a catch 22. Not enough people are applying to became a master alchemist because there aren't enough jobs, and there aren't enough jobs because there aren't enough applicant. Do you want more Elixir jobs? Start studying Elixir today! And convince people to study it. Coworkers/friends/random people at your (university|college). Seems silly, but I know a lot of shops that converted from Rails to PHP/Java because they cannot find enough _qualified_ Ruby dev, and at a certain point became cheaper to rewrite the application than find new people. And rewrite an application is more or less always a nightmare.
I think elixir needs phoenix in order to break the mainstream, that is to take away anything from Rails top position in startups, although we have 2? core members of rails on the project, Chris and Jose were both core members? Jose i know made devise and a bunch of other really influential gems, so if you're gonna take a bet i would say Elixir and Phoenix is here to stay. But i actually hope crystal makes it there as well for non web app or even web app applications. I love the fact Crystal is FAST and it compiles, but it's also totally written in Crystal, so that is great. People seem to be frothing over GO but i just cannot stand that style of syntax. 
So turns out my theory for 2 wasn't right. Not sure why it wouldn't be killing it. The "no pids to kill" message makes me think it hasn't registered the pid correctly.
It is what I think too, we should be active as a community. Ruby and Python has cool stuff like PyLadies and RubyGirls, so I think that the community will probably grow. However, Elixir has meetups all over the places :D
Well, but it seems people are starting to talk more about functional programming, don't they? At least at big confs, there's always someone "how language x is a little bit functional" or how to use language y as a functional programming. Do you think that this can open doors to Elixir?
I'd be very disappointed and sad, if elixir would get mainstream only because of Phoenix. One of the main reasons I did not get in Ruby is practically all jobs are about Rails. I see so much more potential in Elixir/Erlang. It would be sad, if Elixir would equal Phoenix, just as Ruby = Rails now.
It certainly has the right buzz about it IMHO to have a shot at that. It feels a bit like the early days of Ruby. Complete with Dave Thomas. ;) I think there may be a critical mass of people who are ready to learn an easy-to-use, easy-to-read functional language, and who were turned off by Erlang's syntax, and who perhaps consider Haskell still a bit too esoteric. Clojure... that's a curious one, but it's not purely immutable and it depends on the JVM, [and I think it's dangerous to rely on the JVM too much](http://www.infoworld.com/article/2987529/java/insider-oracle-lost-interest-in-java.html), plus JVM spinup time is a problem. Plus Clojure has the same adaptation problems that Lisp always had, namely, most people just prefer actual syntax instead of working directly with an AST. Go, I hate the lack of any exception model; Scala, it tries to be too many things to too many people. I was already using "functional patterns" when I was doing Ruby- because I found them to be more robust from a maintenance, testing and complexity-managing standpoint. What Elixir gives you in addition is true immutability, easy concurrency, true macros, and a ton of other goodies out of the box. In practice I haven't found as many kinds of programming tasks as I would have liked which can benefit from concurrency... but it's there and easy to use if you need it and can take advantage of it. Phoenix is 2-10x faster than Rails *out of the box*, so then there's that, too.
I'm currently working on my first non-trivial project with Elixir. The additional data point here is that it is *not* a project that will use Phoenix nor should it persist information to a database. The traditional model for a program is "input&amp;rarr;process&amp;rarr;output". And when you are sending output as fast as you're reading input, i.e. stream processing, Elixir works *great*. But if you need to store state along the way ... or you need to buffer things ... or anything that is not just stream processing then problems that might have been trivial in other languages seem to be much more complex in Elixir. You need to create an Agent or a GenServer. You need to create a message passing scheme and worry about the server getting swamped or becoming a bottleneck. It ~~could be~~probably is that I'm just not familiar enough with The Elixir Way&amp;trade; yet ... but I could see someone getting turned off of Elixir when encountering what I'm seeing. When people make a change from one language to another they want to be able to say, "It can do everything I need it to do **and** it makes some things I want to do easier." If something they do a lot gets harder in the process, that's going to be a problem. But ... it is only at v1.1.x right now so I think there is plenty of room to grow into something that can become a mainstream language.
For permanent storage there is ecto, which works with most mainstream databases. If you need something like cache, there are ETS tables or you can store things directly in the process. Buffering is done for you, because every actor has its own mailbox, so it consumes messages as fast as it can and other requests are buffered in the process mailbox. Agents and GenServers are there to make your life even easier :) For example they give you ability to call another process, automatically wait for reply and if the reply does not come in 5s, time out and return an error. So it is basically as you are saying: Phoenix makes writing webapps almost as easy as rails *and* it makes scaling and parallel processing much easier :) Yes, you need to model in message passing scheme, but in return, when you see a bottle neck in one step, you can simply add more workers there. I remember when Hadoop was criticised for forcing developers to express everything as map and reduce functions. At the end pay off is more than worth it. It is the same with learning OTP patterns like GenServer.
Every language has its own goal. GO was designed to squeeze every last CPU cycle and make writing huge systems in Google easier. It is syntax is a little bit strange, because it made compiler faster. Elixir was made to solve scaling problems with Ruby and Rails, so it is unfair to compare its speed with languages, that are made for system programming. However, it is fair to compare what is the request latency of two services in different languages and here Erlang/Elixir shines. (yes, you can have lower overall latency in slower language https://tkowal.wordpress.com/2015/01/27/the-unintuitive-latency-over-throughput-problem/ )
I love it!
hi tomekowal that was my original goal but I think if this was something I was going to run in prod I'd at least want some control over what could be killed (as you've mentioned - top supervisors for one). The mid term goal for the project is require as little change as possible to each module to enable chaos. Then have config required to switch it on for each module. But this was very much just a random idea I had and coded up. So heavily still in the experimental phase. 
&gt; Phoenix makes writing webapps almost as easy as rails and it makes scaling and parallel processing much easier :) Yes, I agree that Phoenix is awesome ... for writing web apps. But if I need a command-line utility to move files around on my system, I wouldn't use Phoenix. &gt; I remember when Hadoop was criticised for forcing developers to express everything as map and reduce functions. At the end pay off is more than worth it. For certain classes of problems, sure. But again ... if I was writing a command-line utility that took user input and moved files around, you wouldn't suggest that I spin up a Hadoop cluster to do that, right? Basically, there are some classes of problems that Elixir is really good at addressing right now. If those classes of problems are what you're working on all the time ... great! But if you're not working on those classes of problems, Elixir can look overly complex. Which is a hindrance to becoming a "mainstream language".
You haven't understand the approach.
https://github.com/hassox/guardian is the best plug lib for auth. Hands down
&gt; But if I need a command-line utility to move files around on my system, I wouldn't use Phoenix. Totally agree! But I also wouldn't use Java for command-line, either. Similarly to Elixir, it has to start entire virtual machine, which makes it too slow for one off command line utilities, but perfect for long running systems. And it still became mainstream. &gt; But if you're not working on those classes of problems, Elixir can look overly complex. It is still easier than OO programming though. There is a study that shows, that it is easier to teach people functional programming first. Like in this course: https://www.coursera.org/course/proglang Elixir even with OTP is less complex than Java. The problem is, that Elixir is so different, that it *looks* more complex and overwhelming. However Akka and Reactive Programming movement make actor model more and more popular. We will see, what comes out of it :)
Chris, since you are in Austin for elixirconf, if you'd like to meet and see some code in my dev environment rather than over a spotty internet connection, let me know via pm. I'm also at elixirconf.
Forget where I heard it but someone (Jose?) said that most developers will never use as many processes (i.e. GenServers) as they should. They are cheap and lightweight, use them on a much finer scale than you would in any other language.
Checkout www.phoenixwebframework.com for guides in building channels. Channels work seamlessly for basically any client. You can find info about clients built for iOS and Andriod here: https://groups.google.com/forum/#!searchin/phoenix-talk/andriod/phoenix-talk/UOuEpHvB__k/eToGbOrQ4RUJ
According to the [1.0 release announcement](http://www.phoenixframework.org/blog/phoenix-10-the-framework-for-the-modern-web-just-landed) Chris thanks Eoin Shanaghy among others for their work writing channel clients. The others listed have not released a Java/Android channel client. My feel is that it's not 'official', but it is the current recommended client for the platform. IMO, they dropped the ball a bit in their communication of the 1.0.0 release.
It's probably because the upcoming book. I think that when the book will be complete, communication will rise and shine again. :)
Using lots of processes is great advice. Also you want to model things by responsibility, not by data like you would in an OO language. This I think is probably the harder concept to get right.
thanks! Typo fixed...
I have a noob question. I know that channels work on websites using websockets, but does android and ios native clients work on websockets too? 
not my project, but found another example project that uses guardian. https://github.com/JadenH/PhoenixReact
I wonder if there's a way to do this without running the `eval`
I think this is a feature ever language should have, very cool. My worry here is that using a sigil makes it unclear what is happening to people reading the source code that are unfamiliar with this library.
Yep, Ecto is very well built and will handle as many queries concurrently as you have pool workers (and the Erlang VM can handle a lot of processes, like millions). I built an example supervised producer consumer here: https://github.com/mgwidmann/elixir-producer_consumer It is already setup to handle clustering (since its so easy to do in Elixir &amp; Erlang). Which could be easily tailored to become a map/reduce worker set. Add Ecto, set it up clustered with several machines hammering your database. Now you basically have your own hand rolled (easier to understand and configure) hadoop cluster. The better question is actually, can your db server keep up?
Yes, Elixir is made for this. Elixir can handle as many concurrent processes as you like, but there is going to be an optimum number depending on the number of cores in your server, disk i/o and latency of requests to external servers/processes. If you are talking to a database, then there will be a limit on the number of simultaneous connections that the db can handle efficiently. In a recent project, I have been using the process farm in the Erlang skel library: https://github.com/ParaPhrase/skel We read records from a file, then handle them in parallel in a pool of 64 processes, which was optimum on a machine with 32 cores. results = :skel.do([{:farm, [{:seq, fn(row) -&gt; process_row(row) end}], pool_size}], data) I am working on combining skel or a similar approach with Elixir streams to make a cleaner abstraction on the process and allow incremental reading of data. Speaking of your shell pipeline example, I have had luck with xargs's ability to run processes in parallel, e.g. "xargs -n 1 -P 8" and the Pandas python library. So you can get quite far with "old school" OS processes. 
Just posted a comment on your blog. Interesting article but it seems the code contains an error : when you return *Nothing* from a function, the implementation will wrap it in a *Just a* anyway.
They will still take some time :) https://twitter.com/confreaks/status/649374568579244032
Two to three weeks to upload videos? boooo -1
Could you provide an example? I'm just starting out with Elixir. Thanks!
there will be great if a ember cli build tool will be available with phoenix, like https://github.com/rwz/ember-cli-rails
Not sure what you are asking... Are you asking how to build your entire app?
Nice post! One note, it's spelled "arity" and it comes from Ruby and likely other languages prior... It wasn't invented by Elixir (or Erlang for that matter)
And there you have it.
Cloud 9 does. Haven't tried it though. http://blog.danielberkompas.com/elixir/2015/08/28/how-to-run-elixir-cloud9-ide.html Though for $5 you could just get yourself a Digital Ocean box and use Vim or Emacs.
It's been said, but [Cloud9](http://c9.io). Your workspace on Cloud9 is just an Ubuntu VM so running it is no more difficult than just installing the compiler like you would on any Linux.
Looks very cool!
There is also Chocolate for Windows, supposed to be kind of like Homebrew which makes it easy to install Elixir. Also another option is using Virtual Box. Virtual Box with Vagrant is quite nice, if you are comfortable using Linux command line.
I ended up using Floki for parsing the HTML document. Works like a charm.
This is why I never cut confs short. I was at that presentation and it was fantastic.
Yea. There was a mistake made in booking flights at the wrong times. :-( 
The enumerable in the name is slightly confusing to me. I'd rename to something closer to enumerated (https://en.wikipedia.org/wiki/Enumerated_type). Enumerable seems to close to Elixir's Enum module.
I was struggling with figuring out a name for it. `Enumerated` is awesome.
Can I ask why?
While it's cool that Elixir can do this, I'm a little ambivalent that we should be doing our tests this way. I think we learned a lot of lessons with Ruby, and I'm not sure if we should be bringing Rspec into Elixir. (Not that BDD is bad! Just the matcher hacks that end up biting you in the ass... remember `should` syntax?)
Just that `expect` syntax in Elixir is hacky in nature and ExUnit's `assert` methods and macros are perfectly fine for most use-cases.
I am concerned about people trying to make Elixir into Ruby as well.
Won't it become a problem essentially trying to make modules behave as objects and function as methods?
Just because it was mentioned: https://chocolatey.org/ 
I don't know if it proves anything but Elixir 1.1.1 is (by far) the most downloaded version of Elixir on Chocolatey NuGet (https://chocolatey.org) so far. It's not even close. It's averaging slightly more than 18 downloads per day. Next closest was just above 12 downloads per day. That said, there are always more downloads of the latest version right after it's released so the number is probably skewed upward. Still it's a good sign for Elixir adoption.
Didn't know about `--trace` that's great. I've been using `@tag timeout: :infinity` up until now.
YESSS Edit: Only 10 so far, and not including the embedded-Elixir talk which was awesome, sigh EDIT 2: Most if not all of them look like they're up now! I especially liked the Garth Hitchens "Embedded Elixir" one, the Elm one and Jessica Kerr's keynote, but all of them were fairly awesome, high signal-to-noise
I just tried something similar, and had some success using [iconverl](https://github.com/edescourtis/iconverl): `:iconverl.conv("utf-8", "GBK", gbk_string)`. Bit late, but oh well, maybe more Googlers will find this.
But even if. Would it harm the language? I like Ruby because of the language and I like Rails because I get fast, solid results in my daily job. Nevertheless I use Ruby for a wide variety of things. I honestly would love to see that happening with Elixir and Phoenix, too.
Great input, thanks. I wasn't aware of Enum.into, very cool.
Enum.into is particularly useful in conjunction with Streams allowing you to force a Stream to run and collect in the appropriate shape.
Are you sure this is a good idea? Atoms are not garbage collected so use of this function would cause you to leak memory with every new key received. A malicious user could bring down your application by sending requests with randomly generated additional keys.
Awesome, something like this is exactly what I was looking for.
Thanks for sharing, I'm keen to move away from js and into elm for my phoenix front ends. Hows the progress on things like ajax requests in elm without calling Js?
&gt; ajax requests in elm without calling Js Quite straightforward once you understand how tasks and ports work. Here is a live example: http://elm-lang.org/examples/flickr
You are right, in my mind rails=monolithic webapp, but perhaps that's not the whole story, I'll see if I can get a hold on him.
A example http://testedanswers.com/questions/-K0r2CWtbTPLHu-K7rJT
I think this is a bad idea in Ruby too, which is why Rails uses `Object::HashWithIndifferentAccess`
It is good for both messaging systems and web services. See the phoenix framework for a great elixir web framework. Elixir is great in an SOA contexts. Instead of reading my words on this topic, you can read Jose Valim's: http://blog.plataformatec.com.br/2015/06/elixir-in-times-of-microservices/
I think you could use `elixir-pipe`: result = pipe_matching x, {:ok, x} user |&gt; assert_not_purchased_yet |&gt; create_stripe_customer(stripe_token) # From Stripe.js |&gt; create_stripe_charge |&gt; update_database
That's awesome, and exactly what I wanted to hear. Can you point me towards some reference material that described this process? Thanks!
Or you could use towel (https://github.com/knrz/towel) or monk (https://github.com/niahoo/monk) or ROP (https://gist.github.com/zabirauf/17ced02bdf9829b6956e) or control (https://github.com/slogsdon/elixir-control) or ... Just as I wrote a comment in this article http://insights.workshop14.io/2015/10/18/handling-errors-in-elixir-no-one-say-monad.html , which is about exactly the same topic as your article - this is so common practice, that we really should be thinking about making this part of Core Elixir and stop inventing the same thing.
as it turns out, there is already a discussion about it :D https://groups.google.com/forum/#!topic/elixir-lang-core/jt4rM8ac4qI
Well said. Only store state in the database which you can't easily recreate in a system restart. Also, most dbs don't have this problem, and since you aren't writing code for the db why should you care if they use mutex locks? Maybe also consider looking at Mnesia as well...
Where is a good community around LFE? It feels like clojure get's all the Paren Preferrers....and elixir gets all the hype
I'm quite new to Elixir, but given the sample 1 on the readme, wouldn't you want to include the filter as part of the for statement? It seems a bit weird to break the filter into a different step than the generator in such a simple case.
I was referring to the generator and the filter. They could be piped together either through a for statement or result = [1, 2, 3, 6, 7 ] |&gt; Enum.filter(&amp;(&amp;1 &gt; 5)) Forgive my untested pseudo code, but this is the gist of what I was referring to. I'm only bringing up this point to understand if there is an idiomatic way of writing Elixir code. Is it considered good practice to put items into a list, then filter in a separate command, then print to stdout or is piping the preferred method?
The code in question is a test and therefore the balance between telling a clear story and writing maximally efficient code is a bit more on the story side. This is why the test data gets its own name assignment. The filtered data needs its own assignment (low_nums) because it is going to be used in two separate ways later (the IO.puts and the test assertion). The comprehension which prints the values is... odd for a test unless you are troubleshooting. Still, I think that a comprehension is less ideomatic here than using: Enum.each(low_nums, &amp;IO.puts/1) The assertion being separate is very common in tests because otherwise assertion lines can become unreadable very quickly.
Thanks :)
Nice app and well thought out! OP, if you are the developer: I'm learning Elixir/Phoenix and have a few questions 1. How many max concurrent connections have you been able able to handle? 2. Is this a single server application? 3. How is the performance in terms of memory and CPU connections?
[**@chris\_mccord**](https://twitter.com/chris_mccord/) &gt; [2015-10-24 00:33 UTC](https://twitter.com/chris_mccord/status/657716607578472448) &gt; Calling it quits trying to max Channels– at 333k clients. It took maxed ports on 8 servers to push that, 40% mem left. We’re out of servers! ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
it's like Django/Rails. There are some 'lighter' ones listed here: https://github.com/h4cc/awesome-elixir#frameworks that said, Phoenix is awesome (in my limited exposure to it). If you have time, take a look at the overview video here: http://www.phoenixframework.org/docs/overview
It's... difficult to compare. Phoenix certainly has more of an opinion about some things than a Flask or a Sinatra, but Phoenix has much less 'magic' than Rails or Django and thus is lighter and highly modular. The way this is possible is that the simplicity and composability of Plug is at the center of Phoenix which does nothing to hide this fact. The result is that Phoenix provides, if nothing else, a template for a composable web framework which one can learn from. The open question is, as the Phoenix environment grows, will both the core framework and third-party additions maintain this composability? It is difficult to say.
Have a look at https://github.com/tallakt/codepagex which is propably the `iconv` of Elixir.
Excellent, thanks. I realise it isn't always black &amp; white and I appreciate your attempt to explain. I'll try to learn a bit more for myself.
Yeah, I think more research is required. Thanks for the response though. I'm a little concerned that my experience with Django might be repeated though I realise such frameworks certainly have their place.
I think the answer the OP is looking for is that Phoenix does not "take over" the application like Rails or Django do. If you are wondering if you can take an existing application built without Phoenix and add a web component to it using Phoenix, I have personally done that myself and it worked fine. All I did was add phoenix as a dependency to my app, copy in the default generated files/folders from a new app and I had a web layer in no time...
That sounds promising. You're right that it is that feeling of taking over that troubles me. I wish Django allowed me to manage the program start up instead of taking control over everything. Thanks!
Phoenix web applications slot in as just another OTP application. You can have other OTP applications started and running in the same OS process. E.g., https://github.com/havvy/gald/ has both a "gald" application and a "gald_site" application. Right now I have startup being just the gald_site app which starts the gald app as a dependency, but I could load the gald_site app into an already existing erlang ecosystem without issues if needed.
Language abuse. I like it, but it needs more agents and tasks. This inspires me to work on a nine nines fizzbuzz with hot code swapping and supervision trees, 
Its difficult to compare because much of phoenix is a collection of macros and dependencies which themselves are mini apps. When compiled, you end up with some highly efficient functions derived from the macros and a set of supervised microservices-like apps. 
If you do this, please share it! Would be great for Elixir newbs like myself to review.
Now do it in LFE (Lisp Flavored Erlang)! Write new structure definitions and be prepared for true AST manipulation!
The more I think about it the more I'm convinced the answer is a more nebulous "it depends." I tend to trust the database as my source of record for important details like whether someone is an admin or not, and the check as it exists right now is not particularly expensive. That doesn't mean it won't be expensive later, however, and at that point it may make more sense to cache the admin: true setting and do something with session invalidation should that value ever change for a user. In this case I'd say that you can do whichever you're more comfortable with.
Looks good! Is the source available, for us learners? 
I'm by no mean an expert, as I'm still learning and some parts of the language are still obscure to me, but I'm willing to help you if you need and if your level happen to be below mine. feel free to drop me a PM. 
I enjoy a lot reading your elixir posts. I'm new to elixir and have been playing around with application that checks Urls health in a sitemap. And your blog is spot on, touching most of my pain points. Thank you for doing this! 
I'm new to elixir and official Slack group has been super friendly and helpful. I encourage you to join it. 
Great! Thanks!
This is a bit meta but in the last six months I wrote a lot of projects in Ember.js - Dockyard had an amazing number of open-source tools to make my life easier. I've been writing Elixir the past couple weeks and now I find Dockyard is there to save the day again! Cheers, Brian and the team!
Is this key something the user of your library may want to save to their database? (Such as a refresh token?) Or is it purely an implementation detail you want to keep hidden?
I've actually had to deal with this on a project I'm working on that uses the Spotify API. My initial approach was that I'd created a table in postgres that I would store "settings" (it was basically a simple key/value store) and I stored it in there and then read it out whenever I needed it. This worked pretty well, but every time my app needed to make a request, it'd hit the DB. For a small, learning app, I think this is fine, and even a small app that's only got a few users would be ok. Once I got the basis of the app working, I rewrote how I handle keys and I now have a SpotifyAuth GenServer process that maintains the key state in memory and only persists it to the DB when it changes and only reads it when it starts up. The nice thing about this setup is that this process also handles refresh tokens transparently, so if it sees that a token will expire, it'll refresh it and then hand out the updated token. But I'd say for starters, doing what I initially did is fine. Make a `KeyValue` model that has 2 columns: `key` and `value`, both strings. and then make `KeyValue.set` and `KeyValue.get` functions for easily accessing your data.
I want more websocket clients!
I was actually thinking of switching them to atoms, thoughts? I originally was using binaries but ran into issues with Dialyzer and the TypeSpec. Thanks for the feedback!
Thanks! I got it working.
&gt; The best way to write a faster Rails app is to write it in Phoenix. when you start to see sub-millisecond response times, there is no going back!
This is fantastic, I can't wait to hear what modifications it took to Phoenix to be able to do this. Its pretty wild that we are at a point where we can whip up essentially whatsapp with an off the shelf framework. 
I point this out in the article. This isn't the point, however. It took only a week for a team of Ruby devs to start working on a Phoenix app. We had someone that has been working with Phoenix for over a year oversee the contributions and make sure everything was done correctly before being merged.
It's the love child of Erlang and Ruby and (IMHO) potentially better than both! Erlang/Elixir handle state (something fundamental to all programming) in a fundamentally different way than OO langs like Ruby do. That's the biggest hurdle IMHO. You have to get used to passing state around "out in the open" as args instead of stashing it away everywhere as instance/class attributes. Fortunately, this seems to lead to better code, because as it turns out, state being polluted everywhere is a pain that should be felt because it leads to unmaintainable spaghetti-code dependency hell. There is also the immutability paradigm shift, and the "multiple defs of the same function but with different arguments" paradigm shift, which supports pattern-matching, and pattern-matching is AMAAAAZING.
It's funny how sometimes you solve a problem (or at least improve the situation) by refusing to cater to it. Re state pollution, I mean.
:crypto.hash(:sha256, "foobar") is correct. It's an erlang call. Base64 is not text, it's a binary encoded as Base64. 
Would love to see the throughput at that high of a level of number of connections!
Does remote include remote in UK? What is pay compensation range like? 
I am pretty sure that is inherited directly from Erlang, from what I remember.
I think when someone calls Elixir "the bastard child of Ruby and Erlang" he's failed to grasp the essential ideas of Elixir. Maybe @johnorford should read [this](http://zeroclarkthirty.com/2015-11-01-elixir-is-not-ruby.html) to see how shallow his understanding of Elixir is. There's a lot more to Elixir than Erlang with Ruby syntax. I think a lot of the other ideas he trots out in the blog post are similarly suspect.
"BEAM virutal machine"
I'm picking up elixir again after not really touching it for nearly 2 years, so I've had to re-learn a lot (and a LOT has changed, so I had to do a lot of first-time learning, too). In the project that I'm currently hacking on, I've been following #1 and #2. After a bit of trial and error with interchanging data between models, those 2 points make a lot of sense. I'm still learning and as the code is getting more complex, I find that earlier approaches break down, and these work great. points 3 and 4 don't apply to me right now because I just have the one app, but I'm trying to keep everything separated so I could, potentially, break these out into libraries at some point.
It's very cool to know that Phoenix Channels could scale to 2M+ users connected, but what I'm really looking forward to see are the other benchmarks, the ones listed at the end of the post! :)
Great post. I was considering the idea of developing a wrapper for the Reddit API. Rolling your own stream for proper pagination is a neat idea. I am just starting to explore OTP after playing with Elixir for months (*finally!*) and was wondering if using a GenServer would be another good way to implement pagination? After a request is made, a GenServer process is started with the `after` ID as the initial state and it's updated as you ask for more listings. Good idea? Not so good idea? Just a thought.
You can configure for dev, test, and production in Phoenix. The other features you list, some of these aren't provided by Phoenix (and as far as I know some of them won't be, like authentication; which on a side note I think is the right choice) but there are third party libraries available for them. For task scripts, have a look at mix; I wasn't too sure what was meant by it though. As for the documentation, both elixir and Phoenix have their own documentation and guides. I think they're pretty good, but I'm not sure what your grading criteria is, especially when you have Ruby's language documentation the lowest score (which I think isn't bad at all, and is on the better side of docs that are out there). As for open roadmap, the core team is pretty open about what features they have planned. But I'm not too sure what it is exactly you require to be there for that point to get ticked off. 
Thanks for the feedback. For sure, I don't think a framework needs to have all of these features built in. They're the ones that I find myself making use of frequently, and so I'm looking at how much custom work I'd need to do to use a framework. But balancing that out are less tangible factors like the community, and pleasure of using the language. This is why I'm really interested in Phoenix and Yesod. FYI, I've been using Rails for years — that's where I'm coming from, and I want to give another framework or two a try. I'm going to transition the spreadsheet into a real app/site, and yeah, I definitely will describe criteria for the grades.
&gt; Exrm Thanks! I really need to add info for each rating of why I chose that, and the sources I looked at. I went back and re-read the exrm docs, and I see why I gave it one star: exrm does packaging, not deployment. It looks very cool, but isn't hitting the particular thing I'm looking for here. Here's Rails for comparison. I gave it two stars because while it's not built-in, there's a very popular gem called capistrano. After configuring it similar to how exrm is configured, your workflow looks like this: 1. Write some code ... 2. Commit your changes ... 3. On the command line, run: `cap deploy` Capistrano will then ssh into your server, pull down the latest version from the repo, update libs, and restart the server. It can also roll-back to a previously deployed version, deploy to staging vs. prod, etc. tldr; what this point is looking for is that last part that exrm doesn't seem to provide: getting the latest code on to the server, shutting down the old version, and starting up the new one.
The beauty of exrm is that *you don't need to shut down the server to do updates*. I know there are great deployment tools out there, but: * scp the tar.bz to the release folder * untar * /bin/app upgrade 0.0.1 To hot update a running app is no burden. 
Hey have you found any? Ive been looking for those as well.
Nice i will start my own )
I don't know that any Elixir project I've run across is not "newb"-friendly. I mean they're not newb-friendly in the sense of requiring technical know-how but I've not run across any yet that aren't willing to accept help from anyone. I'm a newb with elisp (emacs macro language) and Samuel Tonini was very gracious about me trying to contribute something to Alchemist. As it turned out I just didn't realize the something I was trying to add was already there. I say, dive in and try. Don't wait for someone to give you permission.
Usually the best way is to start your own project, in your project you will need to use some external libraries and most likely those libraries don't have all the features you need... However if you feel adventour and don't have many ideas right now, it happen that I tried to work with esqlite3 which is a library that let the BEAM VM talks with SQLite3, but it lacked a feature that was pretty important to me, flags in the opening of a connection, so I added that features. However I didn't have any time to make a serious test and be sure that everything keep working as expected and that the new feature really add velocity in case of concurrent read and write. If you feel like to help all the information are here: https://github.com/mmzeeman/esqlite/issues/30 and the pull request is here: https://github.com/mmzeeman/esqlite/pull/31 I modify the wonderful NIF driver written by mmzeeman, really great code IMHO, so most of my work was in C, however the test should only use erlang code and maybe try some benchmark between the old version and the new one in case of concurrent access, either write and read, with the right flag the new version should behave better than the old one. If someone has some time to work on this and need more info, just reply here below or write me a PM.
I would not use a language that doesn't have a full static type system for things handling money. I want to have assurance that my abstractions are right from as many points of view as possible, even if it sacrifices computing power at runtime.
This is super cool. :)
Happy to accept pull requests and do code reviews over at Dogma. :) https://github.com/lpil/dogma There's a beginner friendly tag in issues too.
I have to say, while this is highly appreciated, coming from Python, the fact that you can just require three different modules and you won't have any idea of what exactly it's bringing into the local namespace is still an issue for me. Globbed imports are a general antipattern and it's dissappointing to me that Elixir doesn't have better syntax for importing just the needed module members.
You're misunderstanding what `require` does. It does not transfer bring functions and macros into the current namespace, it instead allows you to call macros from other modules in the namespace. http://elixir-lang.org/getting-started/alias-require-and-import.html#require What you are describing is an an unqualified `import`, which I agree, is less than ideal. However, you can just import the needed functions quite happily, like so: import List, only: [duplicate: 2] x = duplicate(:ok, 10) Or, better yet, use `alias`, which gives you a shorthand for qualifying modules, rather than polluting the namespace at all. alias My.Long.Module.Name x = Name.foo() alias My.Long.Module.Name, as: N x = N.foo()
Check out http://thepugautomatic.com/2015/11/elixir-scoping/
- Chris McCord (Phoenix creator) http://www.chrismccord.com/ - Elixir Status http://elixirstatus.com - Learning Elixir http://learningelixir.joekain.com/ - Planet Elixir http://planet.elixircentral.com/ - The Erlangelist (http://theerlangelist.com/)
Excited to follow along! If you haven't already, take a look at Microsoft Orleans for their work on dynamic placement and location of grains throughout the cluster. It's an interesting approach they took
&gt; This is good shit. Great article, thanks for that. Joe does a good job of explaining many of the differences there, and why most of them are good.
Thank you very much for the pointer! I haven't checked yet, but definitely will.
It should be noted that data within a process in Elixir *is* immutable, it's just that names don't have single assignment. This is certainly a bit controversial despite Joe's blessing. From my point of view, there are common enough cases where multiple assignment makes code simpler and easier to understand, but there is plenty of room for people to use it poorly and make more confusing code. My advice is that whenever you might reassign a name, ask yourself if there is some other way of doing this that doesn't make things less clear. In particular, |&gt; and small transformative functions are your friends in a large majority of situations where you might think you want to reassign a name.
1.) They're not really mutable as others have explained below. 2.) Erlang wasn't conceived as a theoretical exercise in creating a functional language. It was created as a practical solution to a problem that Ericsson needed to solve. If they had realized they'd need rebinding of values they probably would have included a simple mechanism to do it themselves in Erlang. Mutability isn't the issue. _Default_ mutability is the problem. When developers get mutability by default and they're unaware of it, guess what--everything will be mutable. Likewise if the language is default immutable then you'll see lots more code with everything immutable. In my experience most developers don't usually have time to change things from the default because they're too busy trying to meet arbitrary deadlines. 
It is to prevent poorly written code like this (and I'm sure you've seen this in erlang): data = transform(original) data2 = another(data) data3 = again(data2) # ... Like others said, the pipe operator helps with this as well.
I love thinking and talking about distributed systems! While I'm sure Orleans is quite different in design goals than what you're looking for, they've put a lot of work into clustered communication that might be useful to look at. Orleans is much more than a whitepaper - it's an [open source implementation](https://github.com/dotnet/orleans) as well, (though currently being actively modified by the core team to work on the .NET Core platform - so it will work on Linux) and quite complementary to Riak in many ways. Some of the particular details that I like about the implementation: * What initially drew to me to make the comparison: Rather than a strict consistent hashing distribution (Riak), they chose to add an extra layer of indirection in the form of a Registry. This allows for individual processes to spawn throughout the cluster according to pluggable criteria - Whether that's memory/cpu load, random distribution, or even co-located (on the same VM) as another process for efficient message passing (Orleans messages are immutable, but it can optimize scenarios in which passing by reference is allowable and thus not copy the message). * Processes spawn when needed. Let's say you are using a cluster of nodes to handle intensive business logic, where each process represents a particular entity. When the Orleans runtime detects a process hasn't been used in a while, it can shut the process down. When requested again, it will transparently re-activate and respond to messages, ideally saving memory usage for seldom-used processes. * Processes use an ATOM mode of sorts ([a decent description](https://github.com/celluloid/celluloid/wiki/Glossary#atom-mode)) by default, but this behavior can be changed to be more in-line with Erlang processes if desired. This makes it very easy for developers to use, as there is no concurrent logic to consider when waiting for external I/O to respond. I've been playing around with Riak (in Elixir) a bit and got a working version up and running (though releases and exrm do not), and I've been very interested in using an Elixir cluster for a number of reasons. Maybe there's an opportunity for us to work together more during smallscale's development! A more digestable document to read: http://dotnet.github.io/orleans/Introduction
Same exact assets, no build process, no brunch. The exrm one runs about 30-50% slower. Approximate average page ready for non exrm is ~1.2 seconds. Approximate average page ready for exrm is ~2.0 seconds I cant understand why there should be a difference, unless the static path routing is slower in exrm??? In fact, ill set both up at different ports so you can load both to see if the difference is equivalent in your browser too. Will post back up tonight.
Although I think cloud 9 support is probably better for this question, might be a good idea to provide more details. What size instance are you running? 
The semantics of Erlang's messaging is a bit different from messaging oriented middleware. It's roughly an async style RPC. If that matches your application's requirements, then Erlang all by itself will be fine. And you can use client libraries in Java, C, or .NET to talk the same protocol. If what you want is something different, or you are implementing someone else's protocol, then Erlang is a great platform to write it in. For example, see the RabbitMQ AMQP server, which is written in Erlang. Erlang is commonly used for telecom protocols for things like signaling. It is quite common to use Erlang to manage and orchestrate high performance messaging systems, where the low level processing logic is in C or C++. This is how a lot of high frequency trading systems work. At my company we have done similar things for real time video processing of satellite television streams (SDI). 
I went ahead and implemented the back end code, like in their 'http' branch code (it's nothing much more than phoenix.gen and ecto.gen mix tasks), but their Elm code seems to be broken, and I have no idea how to debug it. https://github.com/CultivateHQ/seat_saver/blob/http/web/elm/SeatSaver.elm Actually makes me think about going vanilla js. 
Thank you for the explanation and real world use case. This makes sense. Most of my exposure is with integrating multiple systems where a MOM is dispatching messages and invoking services. If I understand what you are saying, a MOM is not necessary if your software stack is being built on Erlang or can utilize its messaging patterns through clients.
In terms of the core architecture of Erlang, which Elixir is based on, look at the OTP libraries. They are very mature and powerful libraries. So that's one place to look. Looking at the source to projects like Phoenix is another. I think to some extent *everyone* is trying to figure out the right way to build practical systems with functional programming. Elixir is actually in a leading position with this. I think the key is to get higher levels of abstraction. I am really looking forward to the way that Elixir is building streams and concurrency into the language and runtime, e.g. see the end of this presentation: http://www.elixirconf.eu/elixirconf2015/jose-valim 
This is amazing. Any chance of this turining into a fully web-based observer? 
NodeJS is divisive territory as back-end-only people tend to hate Javascript and don't tend to see its advantages as being worth its disadvantages, but people who need to do front-end stuff as well are often happy to have a language they already know with tools to make their lives easier. My take on it is this: If you are having to learn a bunch of stuff already and Javascript is on that list, then it can be great to not have to learn something else (e.g. Elixir/Phoenix, Ruby/Rails, etc.) at the same time. Node reduces the amount of stuff you need to know to get up and running. Node support for moving Javascript execution from the client to the server is (arguably) the best out there and it is certainly not nearly as pleasant an experience in the Elixir world. The biggest downside is that Javascript is a pain in the ass when you start moving to larger deployments. You *will* pay for this if things get big. For most people, this is the sort of problem you dream of having, and you might just have to rearchitect everything once you cross that bridge. In that case, Elixir can totally save your ass. IMO, if you enjoy learning and playing with Elixir and you just can't avoid trying to do your project in it, then please do. If you are feeling the weight of learning all of these different bits and just need to make some progress, using Node on the server will certainly reduce your load in the short-run.
I agree that nodejs can be hard to big projects, but Paypal uses it, and they are big :). In my opinion the worst part of Javascript is the inconsistencies (e.g. "" == 0) and the fact that refactors are painful (but most of the dynamic languages have the same kind of problems). Also, JS is very good because of async, but is terrible to use a lot of processors (http://stackoverflow.com/questions/2387724/node-js-on-multi-core-machines), forcing you to resolve the issue. Elixir for other side, resolve it for you because of Erlang :) 
I agree, but he used "larger deployments" without specifying what that means. There is no silver bullet :)
Node.js is fine for plenty of use cases, and I've used it for more than a couple projects in the past, but... That being said, Node.js is ultimately single-threaded. You will have to run more than one copy of your app in order to take advantage of multicore processors, which wastes memory. Elixir as a language is also, in my opinion, much nicer to work with. The syntax is more readable and the semantics make it easier to solve problems elegantly. (I'm sure you'd get a different answer from the folks in the Node subreddit.) If you want to develop websites, either one will be a fine choice, but if you have to choose just one, I'd bet on Elixir.
To be fair I think most banking has moved away from COBOL, and most financial institutions (I'm thinking of fintech and essentially institutions that have not existed for hundreds of years) use stacks that aren't outdated (C#/java/C)
see below for links- so the speed is overall much faster than I was thinking now that I'm on a decent connection, but the difference remains. 
Thank you very much. I was read all comment and know. I will use Elixir in web development. I'm was read 5 chapter of book Programming Elixir By Dave Thomas. And read code in 30-days-of-elixir in Github. It quite basic but when to read this book. I know many a thing, all concept is really nice. But, In elixir have few library. A number of people star and Watch in GitHub is small. Library in elixir is good? When I see in NodeJS/Javascript. &gt;1000 star/1 repository. I often evaluated 1 repositories based on Star and Folk. And I had difficulty when to find the resource to learn elixir. Almost is premium like elixirsip. Has anything resourced to learn elixir like elixirsip?
Reminds me a **lot** about rustc's error handling and the rust-clippy project. And that's a good thing. The more friendly tools to improve code quality, the better.
Ecto is a great ORM, arguably better than ActiveRecord in Ruby. Things are still ramping up in the Elixir world, so I wouldn't be so fast to judge a repo based on stars or forks. Look at hex.pm and you can tell how often a package is used by its number of downloads, ect.
oh this looks awesome. really like the approach to linting. Also covers a much wider set of considerations. Instead of the normal range of "this should be that" its also a bunch of things that "hey, have you thought about doing it like this??" Just great!
Im seeing the difference in speed as well. Taking one sample file it looks like the content download is taking longer, where as the Waiting(TTFB) is around the same. This is in chrome. Although I have no idea for the discrepancy there are a number of solutions to this problem. The first would be concatenating the many seperate javascript files you have, minifying them and you will see a significant speed boost. If you want it to go even faster using a CDN is a good choice too. I realize that doesnt help you with why, but if you need this to be faster now then it gives you some options.
I was find out internet. And I think Elixir is better. I'm only need use to development web or web application. Then, I think elixir make better in NodeJS/Javascript. I'm like create application using python or C# in windows. I'd really like customize all component in application with HTML + CSS (React Desktop like Electron is powerful to create application in MacOS or Windows). But, my opinion, C# can make better because library(.dll) of producer write to communicate with hardware like camera, Adruino or Timer keeper is good. With python, can use this to analysis data, use library very big to write application. I was think Electron need API from this to do like this.
this is an amazing tool. used it in a project and loved it. :)
yup. I thought you might, but put it out there just in case. If you find an answer if you can post it back here that would be great, as I personally would love to know.
This is great. Thanks for sharing. 
*facepalm* yes I had wondered where my comment had gone :) 
The article is in response to a growing sentiment that Phoenix is simply a Rails clone built in Elixir. The author of the article is also the creator of the Phoenix framework. He details how and why Phoenix deviates from Rails.
Only by people who don't read. It says on the Phoenix website: &gt; Phoenix is not, however, simply a Rails clone. http://www.phoenixframework.org/v0.7.2/docs/overview Seems to me that the headline wants the rails name in it for some reason. 
Author here. The article has "Rails" in the title because the entire post is addressing the issues I lay out in the first two paragraphs :) Not sure what else to say. There's no hidden agenda here. We're finding we have to constantly repeat ourselves wrt our Rails similarity and it is leading to wrong assumptions from folks about what Phoenix is all about.
It's similar to what we see from Ruby folks who glance at Elixir. The on the surface similarities make it easy to form wrong assumptions. Also given José and my proximity to Rails (José was rails-core, I built Rails apps for six years), this can cause people to assume we just recreated Ruby on Erlang or Elixir on Rails. Once someone digs into Elixir or digs into Phoenix, I think those assumptions are quickly removed, but it's the ones that only glance at things and then form publicly wrong opinions about it that this post hopes to address.
You're mixing concepts here. V8 is not a JS specification, maybe you're referring to ECMA? I don't really care how many days took to write V8. It suffers from almost all the laughable hiccups of JS, such as prototypal inheritance, a toy typing system, inaccurate floating point operations, and a large large etcetera. Mostly because V8 is a VIRTUAL MACHINE that runs JS, NOT AN IMPLEMENTATION OF IT.
It's definitely worth it, even if you only learn a new way of looking at things. Started at a new job 6 weeks ago, and we've got a huge group of devs who can't wait to do something with Elixir.
http://elixir-lang.org/learning.html
is the short form of fn(a) -&gt; a + 1 end http://elixir-lang.org/crash-course.html#partials-in-elixir
the explanation in the docs is quite good: http://elixir-lang.org/docs/stable/elixir/Kernel.SpecialForms.html#&amp;/1 in general, I find elixir documentation really good and easy to follow. 😊
Note that it (frustratingly) doesn't work for creating 0-arity anonymous functions.
Not really. Functions which require a 0-arity anonymous function (e.g. Agents) can't take a 1-arity anonymous function even if the argument isn't actually used for anything.
Also there is Programming Elixir and Programming Phoenix from The Pragmatic Bookshelf. I especially like (read a few chapters so far) Programming Elixir book and its approach to the audience who has OO background like myself. 
I'm a huge Elixir fan, but I do want to point out that lambda on AWS may be a solve in the "if this thing gets big" scenario, both from a cost perspective and an architecture perspective. https://aws.amazon.com/lambda/
Thank you. That documentation is very nice. I'm not sure I would have found it easily given it is under Kernel.SpecialForms. Still plenty to learn.
Thank you for your reply, that was really helpful. I'll probably go the shared-generic-functions route then for the \*DB modules. However, ideally, this will reduce the contents of each \*DB module to just 3 or 4 wrappers (~10-15 lines, maybe?). Do you think this would be a *good reason* to put them all into one file, or should i stick to the a-file-per-module rule even for modules this small? Thanks!
IMO, err on the side of too many files instead of too few.
Your app loads 4.98s on your production server, and 3.19s on your dev server. (From my location, northern Europe) Theres a lot of javascript involved, in fact it adds up to 1.3MB. To compare, facebook (using React.js) has a very large app, with a lot of javascript, and their front ends up being 1015Kb. I would suggest using a build-tool, and bundle all your scripts in to a single file, using something like webpack/browserify etc. Also, have a look at Googles Closure compiler, its killer feature is tree shaking, so all your unused code gets shaken off, and you end up only using what you really need.
I'm even newer than you. Not written any code yet apart from the tutorial. Maybe something in this list would help? https://github.com/h4cc/awesome-elixir#testing 
Check out Guardian: https://github.com/hassox/guardian
Its a single page app, so the entire app is loaded into your browser unlike something like facebook which are server rendered with lots of JavaScript on each page. I will bundle this, but this was really a post concerning how the same assets could load slower in the exrm release
ExUnit ships with the language and is well done and should suffice for most projects (Phoenix uses it), you should read up on it. If you're looking for BDD, Pavlov is well done but I haven't checked in on it in a bit. Generally it is idiomatic to try to pass in or configure things rather than mock them, but if you absolutely feel the need for a mock (as I'll admit it happens), there's a library called meck written in erlang and mock I believe is an elixir wrapper for it that cleans meck up a bit. You can find the libraries I've mentioned at hex.pm and the docs for ExUnit at elixir-lang.org
Easy... This is for global things like stuff you want to use in your layout file: In your controller: conn = assign(conn, :foo, "bar") In your view: &lt;%= @conn.assigns.foo %&gt; Note, this can be done in a plug so the controller need not be aware if so desired. OR, for stuff specific to this controller/action: In your controller: render @conn, "index.html", foo: "bar" In your view: &lt;%= @foo %&gt;
Phoenix doesn't actually enforce many conventions, only suggests them. For example, you don't need to match the route name with a corresponding controller name. You can name the controller whatever you want. The file name for that controller can be whatever you want too. In fact, you could define multiple controllers in the same file if you'd like. In theory you could put your entire application in the same file. The conventions that come from the application template are there to give most teams a lingua franca when it comes to the project, but you are free to deviate from this if you wish at the risk of increasing the ramp up time for any new developers unfamiliar with your deviations. Much of the Rails "magic" comes from the implicit assumptions the framework makes on how you are naming classes and files. Phoenix/Elixir stress explicit over implicit and thus remove the magic. However, on a cursory inspection of a Phoenix application that may not appear to be the case.
This list is fantastic! Thanks for the link! I only wish their was a way to identify which one was becoming the most popular in each category.
True, but for what i noticed (not sure how big your app is, and what other pages are involved) the size seems quite large for what i saw. Maybe you could also try to depend less on external libraries, like jQuery. However, the exrm release being slow is a fact, and unfortunately i have no answers for that. Maybe try to serve your static assets via something else, like nginx?
This is great. Thanks for mentioning it. 
I haven't actually used it yet but guessing from the way it's designed, I think Überauth is going to be a default solution for me: https://github.com/ueberauth/ueberauth.
Yeah I'm pretty sure he meant it like "I am lucky to have the time to focus on what I want to exclusively." Show some grace?
That's a great point, thank you! No grand plans at this time. I've been using this as an opportunity to reinforce the material in my head while helping out those getting acquainted with Elixir. This is certainly catered to those with some programming experience. I'm not a fan of long winded tutorials or blog posts so I've tried to keep the text to minimal and rely more on code example. I want you to be able to read along if you want or skim the examples are still come away at least knowing where to start. I'm currently working on two lessons: OTP behaviors (GenServer, GenEvent, Supervisors) and executables (escript). Topics I'd like to cover (in no specific order, feedback welcome): + Distribution + OTP Architecture + Documentation (@moduledoc, @doc, doctest) + Hex Packages (using and creating) + JWT / Guardian + Metaprogramming + Protocols Thanks blubberface_jr
Change feeds, which aren't touched on here. You can register queries as a change feed and any updates will be pushed to your client in real time.
&gt; But I find all tutorial use Emacs. I don't know why Emacs is better? Elixir draws a lot from the Erlang community and that community rallied around Emacs a long time ago. Erlangers who wanted to dip their toes into Elixir wanted Emacs support, so they got it. &gt; Or why Vim? Sublime Text? There is support for both [Vim](https://github.com/elixir-lang/vim-elixir) and [Sublime/Textmate](https://github.com/elixir-lang/elixir-tmbundle). I can't say I have used them so I'm not sure how their support sets compare. &gt; And why all people use Linux instead of Windows? In windows, using git bash also have any magic. The world often gets broken up into the POSIX vs. Windows development environments. Erlangers have not traditionally been Windows folks and Ruby on Rails has tended to be very OSX focused. Elixir draws heavily from both of these communities, so POSIX support tends to be stronger than Windows support. 
I don't know Vim or Atom will better in Elixir?
I faced the same exact question 2 months ago, and my choice has been vim. Here's why: I've used Sublime Text 3, and next, Atom, for front end development, but for elixir I wanted something more than a text editor, something with more features, something that can speed my dev time, something.... like vim! I've always heard beautiful things about vim, everywhere I searched people talked about it with passion and enthusiasm, and this marked me with the idea that has to be an awesome tool, but with a steeeep learning curve. So, two months ago, when I had to face this decision, I forced myself to choice vim, and to try it at least for 1 month, without interruptions... And here I am, 2 months later, recommending this awesome tool to another candidate in the same position I was :) I highly encourage you just to try vim, It's really a mental changing, and I have only 2 months experience :) Another advice is not trying *pure* vim, but installing macvim (really awesome) and using it with some plugins. If you are more interested I created a repo with my settings, consider that I'm still a newbie vim user, so is not all perfect, but for me it works very good :) p.s. The vimrc file is partially commented, you can read some commands from there.... Repo: https://github.com/gabrielgatu/dotfiles
Awesome @gabriel_dny. I'm also newbie Vim. I don't know config or setting plugin for Vim to work better with Elixir. Like auto complete, catch error to debug. Can you help me any resource or guide me to do this? Thank you.
It really depends on what you like in an editor. There is a reason that people have called Emacs vs. Vim the editor *wars*. Atom is popular with Node developers, so Javascript support is very good. Vim is difficult to learn, but very powerful once you get there. I am not aware of any particular editor being a must-have for Elixir development. I would look for syntax highlighting and code completion. Fast-swapping to test files can be nice as well. Between the existence of the mix build tool and the explicit nature of Elixir, many of the bells and whistles of text editor support are much less necessary. One other thing of note, if you like Vim, but want some feature that is currently only in Emacs, you can try [Spacemacs](https://github.com/syl20bnr/spacemacs/tree/master) which makes setting up a vim-like environment in Emacs simple and includes a one-line configuration for getting Elixir set up as well.
I was using Sublime Text, but the current Elixir package for it does not support umbrella applications well (goodbye most features) and eventually started causing Sublime Text to hang on me. I switched to IDEA community edition, and while it's a bit slower to start, it runs fast. Only really miss the search and replace UI from sublime text.
 Erlang/OTP 18 [erts-7.1] [source] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false] [dtrace] gist of two modules here: https://gist.github.com/mwdiers/1f5637361b8e66a31e72 Called like this: Parallel.reduce(1..100_000, 1, &amp;(&amp;1 * &amp;2))
What you will have to realize is that you are asking it to do near trivial work in comparison to the cost (even though extremely cheap) of spawning a process. Try timing multiplication vs spawn_link. You'll find that the time difference is like 5-6 microseconds vs 30-40 microseconds, which means you'll spend all your time spawning processes, sending and receiving messages, and next to no time doing work. That's why it appears to be happening single threaded, all the workload is on the iex process that made the call. 
There is also the problem that the final reduction is multiplying some huge numbers. Toss an inspect between [lines 28 and 29](https://gist.github.com/mwdiers/1f5637361b8e66a31e72#file-gistfile1-txt-L28-L29) of the gist and you will see how much work is still remaining even after collect_replies finishes.
I would suggest learning about :observer. Load your code in iex and run :observer.start. If you click on Load Charts you will get some charts of how much work each scheduler is using. Running your test you should see that all of the schedulers take on some work as they run their independent reductions, then all but one will drop off as the reductions are in turn reduced together. This final reduction occurs in a single process and thus can only run on one core. The Processes tab will also tell you what processes are running and what function is at the root of the current execution stack. With some sorting you should be able to find your processes and see where they are. This should help you figure out where to put inspect or puts arguments to get more detailed information. You could get even more information if you were using OTP instead of just direct spawning of processes. As far as I can tell, the problem is that BEAM is getting stuck doing the final reduction where it multiplies 8 large numbers sequentially in a single process.
Yes, if you have lots of work for 8 processes then it will keep all cores busy. But this is Elixir! There's nothing wrong with creating lots of processes! A real use case of your gist would turn up better rewards. Another simple example, using your gist, would be to give it actually some CPU intensive work. The standard example of Fibonacci is a very inefficient one. You'll have to find a memoized version of Fibonacci to gain efficiency back, but this way you'll see the effect you're looking for. Something like this should do: def fib(0), do: 1 def fib(1), do: 1 def fib(n), do: fib(n - 2) + fib(n - 1) Then run it for the range 1 to 50/60/70 or so, it's terribly inefficient so don't give it too big of a number to crunch.
Try to search on google "helptags not working vim" and try different solutions :) For the auto-setting line number: that is a feature called relative-number (super handy), but you can disable it by removing the "set relativenumber" line inside .vimrc :) Also try this: "http://stackoverflow.com/questions/9468914/vim-helptags-not-working-for-nerdtree"
As @perishabledave said, you can create a model with no migrations, just run *mix phoenix.gen.model ..... --no-migration*. You can find more informations at: http://hexdocs.pm/phoenix/Mix.Tasks.Phoenix.Gen.Model.html
Absolutely. As /u/perishabledave points out, you can define models with whatever you need and (interestingly, for read-only legacy) nothing you don't out of the existing database, and you're good to go. I'm doing exactly that at work ATM: legacy MySQL (no different for postgres, of course) read replica served out of a Phoenix app. The side-by-side with the old rails app is... hilarious, I probably should do some proper benchmarking and publish, but I'm too busy writing the new functionality into the Phoenix app to take too long laughing at the old stuff. 
Another: you're probably writing distributed apps, or will be, which is the big reason to look at beam vm languages, right? Well, RethinkDB is supposed to have a good distribution story.
This is great, I'm using it as a hub to steadily learn the language. Thanks!
I can vouch for this approach. I do the same thing with a legacy MySQL system that is primarily used for a rails system. I hand-rolled models to match the schema and use Elixir/Phoenix to interface on new projects where it makes sense. No migrations at this point are done from the Elixir side. 
Because Rails is good at some things where I don't need the power offered by Phoenix/Elixir. I am also concerned about painting myself into a corner relying on an early-adopter framework. Similarly, there are things I want to do in Python, because it's got the best support in certain technologies (e.g., NLTK). The biggest unknown for me is message passing between Elixir, Ruby and Python. 
Actually I could probably just use protocol buffers over websockets for message passing. 
You could try to use something like RabbitMQ https://www.rabbitmq.com/. There are both ruby and elixir libraries available to connect to RabbitMQ. But you probably shouldn't share the DB between the apps with this approach.
Right, my question was, what specific things do you think Rails is good at that Phoenix/Elixir wouldn't be suitable for?
TBH I don't know enough about Phoenix to say, which is why I'd consider hedging my technology bets. I assume the maturity of Rails would trump Phoenix on things like, say ActiveAdmin and Devise. If I created a user profile editor for example, it seems like this type of simple, non-performance intensive feature would be done quicker and more reliably in Rails (e.g., using mature components like CarrierWave). However I would think Phoenix is better for high-throughput features such as group chat. I think this approach would also help me climb the learning curve and get my app out quicker. 
Why do you think sharing the DB is bad idea using rabbit ?
Part of my thinking is this approach would help me learn quicker and get the app out quicker, and give me a hedge on technology choices. As I learn more about Phoenix it may become clearer, but I wondered if there was merit in this dual approach and if others have tried it. 
It's definitely feasible, but it's 100% impractical. You'd end up making the application much more complicated with no benefit.
My answer: ``` IO.puts String.length(input) - 2 * Enum.count(String.split(input, ""), &amp;(&amp;1 == ")")) ``` It would be shorter if Elixir has method String#count like ruby 
I have tried emacs, IntelliJ, Sublime and Atom. Emacs has the best integration and best code completion (with alchemist) but it is emacs, and is only really great if you are comfortable with it. IntelliJ I use every day at work to write Java and I was excited to use it for elixir because I love it, but it doesn’t work (for me). The syntax highlighting is a bit weird, there is no autocompletion, even on functions inside the same file, no navigation around functions etc. So it is not worth the overhead. Atom and Sublime have basically the same features. Autocompletion is good for standard lib’s, not very good at autocompleting across files in your project. Nice syntax highlighting etc. Atom has nice integration with iex, with a console availbale in the editor, but I never use that and I am more comfortable with the Sublime snippet system (very important for me when writing HTML) so I have gone with Sublime as my elixir editor.
Streams *can* be infinite, so you shouldn't use it unless you are confident that the Stream you are getting won't be.
I'm really enjoying this blog series! Around Part 1 I actually was working on my own implementation of Poker but since have found myself still not grasping OTP concepts fully and finding myself in deadlock situations. That and I've gotten more busy so haven't had time to work on it :) Keep up the good work, so I can steal your code later and claim it as my own!! :p
Thanks /u/MrPopinjay, Glad you enjoyed the post. I'm looking forward to using "with" also.
Saw that and it's interesting but the number of options is part of the problem! I want to use the thing that everyone else is using, not get comfortable with something that's convenient but nonstandard.
I was thinking about using https://github.com/centrifugal/centrifugo for some realtime features in an app I am writing. It's written in go but you could write it in Elixir.
I'd say your DB should just be an agent.
Good feedback! I just pushed an update. I was so focused on playing with Supervisor+GenServer hierarchies that I overlooked the abstraction. Thank you.
Just wanted to mention that Joe Kain has been putting out some really helpful write ups on his blog. Looking forward to this.
Thanks /u/perishabledave!
I haven't read that particular book, but based on the descriptions I can see of it, it is going to start from a basic level, so you don't need to already understand OTP to understand what that book is going to cover. Elixir in Action (on the sidebar) is also a great introduction to OTP and distributed programming in Elixir. If you can handle reading Erlang code, [Learn You Some Erlang For Great Good](http://learnyousomeerlang.com/) is also a great resource for OTP. I also find the Elixir docs to have rather good descriptions of how things work while the Erlang docs have detailed, if sometimes arcane, documentation of all sorts of things which one may find useful.
The Mapping maps thing should really be a function, not an idiom.
Oh, certainly. It is still ultimately running the anonymous function and it has the overhead of the protocol dispatch. The BEAM is not going to be great at huge amounts of calculation or executing tight loops compared to other languages which emphasize that more. In exchange, you get a bunch of very nice tools for concurrency, fault tolerance, and availability. Similarly, Protocols have a cost, but they make it much easier to build a single library which interacts with very different sorts of data structures, including user-defined structures.
FYI, 1.2.0rc1 changedocs are out. It seems that consolidating protocols is automatic as of the next version (can still be disabled).
That seems like a nightmare to me. Implicit changeset updates?
In theory it'd be great not to do such things (so maybe it's a benefit to this approach), but why else would ecto require you return the changeset unless it wanted to allow you to modify it. In practice, even though it's not desirable to use, it may still be useful. 
This video contains content from SME, who has blocked it in your country on copyright grounds
I'm not sure with genevent that you can predict which module would get the changeset first. Changing it could get you inconsistent results. 
Forgive me in advance for my tired writing... :) Thank you for the valuable feedback. I have started incorporating it with thoughts in commit comments as I went. It's a bit late for me now, but I did start moving DB logic out of the Engine; after an hour or so if playing with that, I realized what you meant about the supervision setup. Basically, you are saying that the Interface should be responsible for starting new games. You didn't explicitly say this, but it seems that when the Engine goes down, I can take its DB out along with it, since starting a new game means using a fresh DB state to init. Overall, I wonder how much of my implementation came from trying to use a bottom-up design approach with this project. I tried to think about my processes first, even splitting them apart, and came up with the interface afterwards. However, I think if I had started with the interface and then refactored it step-by-step to use processes wherever I felt there were going to be issues that needed some crashing, the control would be in the interface instead. I may try again from the opposite perspective, but I'd like to wrap up the current approach with the big supervision revision. On the way, I did run into a trap that other new Elixir developers should be aware of. :random.seed is only valid for the process it is called in (and also, use the crypto approach, not the easy :erlang.now approach). Calls to :random.uniform need to be in the same process. As I moved my randomization from the Engine to the DB, I neglected to remember that my Engine process was crashing, so if my external DB API was going to generate random numbers, it also needed to reinitialize the seed. Buuuut... That is because I was still sending it "new game" messages from my Engine, which I realize now is not the approach recommended.
Thanks! The main module which is doing all the magic is Kaguya.Module, and I don't think it'd be too hard to repurpose and use for something like Slack.
Very nice code to learn from.
&gt; Overall, I wonder how much of my implementation came from trying to use a bottom-up design approach with this project. The recommended way of thinking about OTP supervision is as a matter of fault tolerance and recovery: "If this thing crashes, what should crash with it, and how do I recover?". The other insight is that recovering from a crash and starting up often look very similar from the perspective of many of your processes. Use this to simplify your code. &gt; :random.seed is only valid for the process it is called in Use [:rand](http://www.erlang.org/doc/man/rand.html) instead of :random. It auto-populates a seed in ETS and shares it across processes. It is slightly slower, but solves many of these problems.
It provides the standard newbie process of explaining the major building blocks of OTP and having you put them together into a sample application. Other books cover things in similar depth, although some cover a few more parts (such as custom process registries). This is useful information, but I don't know of a good resource for where to go next for most users.
Certainly, and there are quite a few bits and pieces like this all over, but where is the organized, reasonably comprehensive explanation of common practices and pitfalls? I liken this to learning how to design kitchens. We do a very good job of teaching people what the components of a kitchen are and how to set up a simple kitchen. However, we don't have a good guide which teaches things like how complicated putting a sink in an island can be, or how to manage air-flow for an external vent, or how to make a kitchen accessible for someone in a wheelchair. Instead, we skip straight to looking at poorly annotated albums of kitchens designed by others and scattered blog posts which might describe how people of difficult-to-determine ability solved specific problems. It is possible to learn this way, but it seems rather inefficient and prone to all sorts of misunderstanding and error.
If you have a question about the design or anything else related to this bot's development, I'll be glad to answer :)
I'm confused. Where did I explain a GenEvent?
No. You use a service module. It's named after an action: "UpdateUser" within the that module you trigger stuff (fire up a worker, send an email, push to your data warehouse.) You shouldn't rely on implicit magic to handle orchestrating actions that trigger side effects across your system. Redux for React does a good job explaining why a clear single flow through your applications state is easier to reason about, simpler, and easy to test. In your case this service module should call the GenServer or whatever is handling update notifications. 
Sorry this was directed at the author, not you.
Would you recommend then making a service module for all models regardless if they need after hooks so that seeing a plain Repo.update becomes a code smell or how would you enforce usage of the service module?
I wouldn't recommend a net that wide. In my rails apps for example, I have objects that represent shifts in state. They are all actions: "UpdateUser" "CreateOrder" etc. they do have similarities. Which are 1. they accept a validator. 2. they accept a hash that we validate and use for creation. 3. they call a method if the execute action was true (passed as valid, and rails save was true) or if it was false set errors from the validator. 4. the happy path method starts a job that was passed in "UserCreatedWorker" for instance. So there is shallow inheritance via a BaseAction That's it for what I call actions/completions. Let me drill through a few things in actions: Why is validation a first class citizen? Because validations in your model is cool... until you need to validate in a slightly different context. Aka change. Example: validate email, password length, name, etc. when creating a user. Now a spec comes in and users should be able to invite other users, and a user can only have 3 pending invites at a time. Invites only need an email to be added to the system so the rest of the validations in the model are useless in this context, and in your way. It fights you. Unless its first class... If it is, you just make a new validator called "UserInvitePolicy" with those rules, and that is that. A job after every successful action in the system? Not always. Sometimes it's a noop. This is there because from my experience in building big systems, what you want to do _after_ an action always changes, and from what I've seen for the past 10 years is that it just grows. Fire off an email, index them, push info to a data warehouse, enqueue the csv to be processed, etc. etc. The actions themselves are simple, and do not rely on callbacks, or the framework. You own the API, so when your action is in an http controller, and you then need to build a versioned API. You just make a serializer, and move the action to a new home. Up and running super fast. Another bonus with this approach: Testability. Now when I test the model **nothing unexpected happens**. Stuff doesn't try to implicitly send emails when I was just testing something on the model, and testing the action is easy. No mystery guests. Pass in a dummy validator that always returns true. Assert model received save with given params. Assert dummy worker received perform_later with return from model. Etc. You can also test validation policies in isolation, and your workers. What happens in the worker is another story, but the basic approach is that the worker instantiates a composite that has the CoR pattern in it, and the links in the chain are units of work(push to mix panel, deliver email, etc) which is nice to because your units of work are easy to test since their API is so simple. This, plus some other approaches have made larger systems easy to reason about, maintain, and most of all allow change. I use it in smaller systems as well, but the benefits really shine through on the former. [edit] Sorry for the long ramble (was trying to get the kids ready for the day, and respond.) Multi-tasking is a myth :) 
I am eagerly looking forward to this book - and I hope there will be a stable and flourishing ecosystem around this. I am an amateur and I dabbled in Ruby and Rails long ago and I confess Elixir and Phoenix is holding A LOT of my interest being everything Ruby and Rails were not at the beginning. Please allow me to help in whatever way I can. I am not particularly comptent in programming but I am very determined to learn whatever I can since this looks like a very worthwhile endeavor. I would also like to contribute to the community as well as the authors.
No worries
This can also be achieved with a fold (reduce) unless I'm misunderstanding what's going on here. defp filter_values(map, filter_params) do Enum.reduce(map, %{}, fn({k, v}, a) -&gt; case is_binary(k) and String.contains?(k, filter_params) do true -&gt; Dict.put(a, k, "[FILTERED]") false -&gt; Dict.put(a, k, filter_values(v, filter_params)) end) end I think this is a more general solution because you can transform something of type `a` into any other type, not only things that implement `collectable`. Still, this is a neat trick I haven't seen used before and will remember. 
As others have said, elixir is not like coffeescript, it does not compile to erlang. It compiles to the very same beam bytecode that erlang does, and has such suffers 0 overhead over erlang code. You can call erlang code from elixir, and elixir code from erlang. It's all the same bytecode.
Thank you for implementing "Take advantage of extra space on large screens by widening sidebar". :)
Yep where I work (big public traded company) were using it and it's great. Not using Phoenix though but with cowboy. 
More than a few people use it: https://github.com/doomspork/elixir-companies
so Erlang? Or both erlang/elixir?
Elixir but we do have some people who use pure Erlang. You don't have to use pheonix in order to use elixir. I hope elixir won't become like ruby where it's used only with rails.
I agree with this. My understanding is that Phoenix is only just sort of a layer on Cowboy and nowhere remotely as thick as Rails though
I am planing to use elixir for microservices. I have two choices elixir or golang. Golang ecosystem is awesome, I do not know anything about elixir.
[**@elixirstatus**](https://twitter.com/elixirstatus/) &gt; [2015-12-18 17:39 UTC](https://twitter.com/elixirstatus/status/677906047638618112) &gt; Open letter to Piotr Solnica - \#rubylang @\_solnic\_ @josevalim http://elixirstatus.com/=ce7M \#elixirlang ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I like having a flagship thing like Phoenix to get people into Elixir. I got into Ruby because of Rails and I have started poking around in Elixir because I heard about Phoenix.
&gt; I hope elixir won't become like ruby where it's used only with rails. I don't think it's accurate to say that Ruby is only used with Rails. But it is probably accurate that everything Rails-related dominates the discussion. For a lot of people, Ruby is the most natural successor to Perl, much more so than Python. But nobody does conference presentations on quick and dirty scripting.
We rebuilt our Rails API with Elixir and Phoenix in only 2 weeks and running that app now for 3 months in production. We are very happy with the result. And btw, our response times are now in microseconds range instead of 50 - 100 ms :)
You're right, in devops ruby continues to dominate the scene, but python is slowly but surely rising to dominate this domain as well.
What about microservices?
Yes. Agreed. Jose handled this very well.
As to the well noted computational inefficiency with elixir/erlang, I've found it true in comparison to things like node, however as soon as some part of it can be parallelized, all advantage for other things is gone. In other words, if you are doing long, single path computations, you may run into this. In many real world scenarios though, you end up doing sets of independent calculations, which give a massive advantage to being able to spawn lightweight beam processes to do them all at the same time. My previous company has a server that regularly maxes out at 12gb ram doing *hundreds of millions* of calculations in parallel. Something that might have taken hours in ruby takes 3-7 seconds in elixir.
Right, I've read a few comments indicating that it works in a larger system, but I'm confused about how it works with respect to SOA/microservices. I've read a few things describing how Elixir processes are like microservices, but I have a hard time understanding how exactly that works? How do you isolate certain processes to certain machines, so that you can independently scale out certain aspects of your backend? Also, was curious how it scales with codebase size/team size.
Awesome, thanks for the links, I'll take a look.
We also have a microservice that we wrote in Go (other requirements), and we are REALLY happy with it. Close to zero issues in almost 2 years of deployment on various hardware (one of the requirement was the system portability). Writing network related stuff in Go is really awesome, the standard library is VERY rich. Sure has annoying stuff in it, but as far as I am concerned, it has also many pros that you should considered. You have to stop and evaluate the situation: How would you deal with node communications? Scalability on multiple node is an issue you must address? How about deployment? Also, the tooling in Elixir is very very good, but the tooling around Go is _crazy good_. **My** rule of thumb is: if I have to deal with really small unit of computation, self-contained, with a layer of network communication or if i need to do computation fast (number crunching is not good with Erlang), I go with Go¹. If I have to write APIs, web applications, or I need to be able to scale on multiple machines out of the box, Elixir is the choice. If I have to write something fast for building a small prototype, I choose Ruby. For libraries or system level programming, I'm flirting with Rust. What kind of microservices are you trying to build? Are they really microservices or are you forcing the microservices on an application that should be monolithic? Sorry for the wall of text. ¹ sorry that was not intentional 
First of all, thanks very much for your answer. I want to build microservices, that based on monolithic, for example a microservice, that only responsible for authentication. I want to build a system, that scales very well. I think too, that Go is my choice. 
This might be of interest to you: http://blog.plataformatec.com.br/2015/06/elixir-in-times-of-microservices/
From the article: _The system that manages rate limits for both the Pinterest API and Ads API is built in Elixir. Its 50 percent response time is around 500 microseconds with a 90 percent response time of 800 microseconds. Yes, microseconds. _ As someone who has focused on development using Python and Ruby, these numbers simply melt my brain. While the whole thing with Actors, nodes, and processes takes a bit of getting used to, the code is as terse and readable as any good Ruby/Python that Ive read over the years. 
Any good books to learn elixir? I have OOP background Java, C# usw. I want to learn about functional programming. I have an other question, are channels in Go the solution for safe concurrency instead of functional programming for example elixir? I have hear about that functional programming is thread safe.
Fantastic news :)
Thanks, I read that while going through the tutorial. I think my fuzziness is more about deployment. What is the process like when you want to deploy services on isolated nodes so that you can allocate resources based on load? How painless is that? From what I've read, it seems like Elixir/Erlang makes that easy, but I haven't actually set something up to do this yet, so it's all fuzzy. I think what I need to do is just to actually try it myself on real machines and go through that experience. 
That's exciting to hear. If you can answer...how many persistent connections are you aiming to achieve? Also, why did y'all decide to go with Cowboy instead of Phoenix?
Several millions, about a million per server. I chose not to use pheonix channels because it didn't fit the use case, I love pheonix and I think that it's one of the most exciting web framework around but channels weren't flexible enough, I needed a one to one communication and not a topic based communication.
We have some big plans for Riffed; we want a real Thrift implementation, not just a wrapper around the existing erlang implementation. 
Awesome, thanks for the details!
Definitely agree with your organizational value point, it'd be great to keep everything nice and tidy, but sometimes you gotta keep it dirty and abstract around it properly.
This is (IMHO) the best one: [Elixir In Action](https://www.manning.com/books/elixir-in-action). But everything in [this page](http://elixir-lang.org/learning.html) in very good. :) EDIT: haven't read the second bit the first time, sorry. I'll try to respond. No, channels are NOT the solution to safe concurrency, neither is in general functional programming. Channels in Go implements a messaging pattern that you could use to write safe code, but this does not protect you from deadlock¹ etc. And functional programming is built on value passing instead of reference passing (you do not pass the **variable**, you pass only it's **value**), but it does not protect you from side effect as a whole. In fact, Erlang solve this problem with the OTP and his internal scheduler. If you adhere to the OTP standards, your are quite good to go. ¹ go has tools for detecting race conditions.
You'll find this usage of = more prevalent in function heads where you are attempting to destructure data at the same time as capture it as a whole... For example in Phoenix you might match on the params map like so %{"user" =&gt; user} = params. This is useful for capturing the user data but if you had some optional params you could still access them with params["the_flag"] and you'd get nil back when it wasn't there. If you put "the_flag" in the pattern match it then becomes required to supply that parameter which may not be desired.
Undead labs (a gaming company) had been running elixir at a scale of like 150+ nodes or something crazy like that since the early days of elixir.
In the talks section, there is this talk: http://remotetalks.com/#talks. Probably this talk will be tomorrow! You can vote in the poll!
Microservices are what elixir does by default. As for rpc, check out erlangs rpc libs, as I'm sure it will have a lot more mature libraries for you to use.
Looks interesting! Will give it a read through later!
If you have existing infrastructure that you need to interoperate with, you can use Apache Thrift and our Riffed library. https://thrift.apache.org https://github.com/pinterest/riffed
Nice article, but couldn't find the source used in the example, which is a shame.
So I can import erlang libraries into elixir without any problems?
Exact same here. I am trying very hard to find productive and non-annoying ways to evangelize my colleagues but have come short so far.
The context switch between imperative and functional is killer. As was the context switch between structured and OO back in the early 90's. As was the context switch between manual memory management and automatic memory management a few years later. Some days I wish I could build a time machine to take developers who've grown up with OO back to around 1990. They'd see there was as much debate and turmoil over using OO back then as there is now about using FP. Ed Yourdon, for whom a lot of folks lost respect due to his reaction to Y2K, was a very vocal and early advocate for OO. At some point if you want to produce better code you need to adopt newer ideas. Newer ideas are always a little scary because there's an element of the unknown there. Moving to functional removes the entire class of side-effect errors. Moving to Elixir/Erlang removes a lot of the accidental complexities of concurrency and scaling. Neither of those options are some sort of panacea because writing good software is hard work but they do remove some accidental complexities.
And as long as they compile on OTP 18 from what I understand.
It's an interesting question. In Brisbane, Australia, I would know how to answer it. I believe Elixir, as an employment vector, is now starting to turn from the thing you introduce into your existing job into the thing that becomes a preferential factor in being hired into a new one (along with some other tech - ruby, for instance). Jobs where elixir is the key skill will be, I believe, still relatively rare. In my shop, though, we would definitely consider someone who kicked ass at Elixir and had "decent Ruby", for instance. I'm not sure I could push a hire on Elixir alone, though. 
No, they are not, according to people I know who are familiar with both. Goroutines and Go threads (channels) are inferior to Erlang pid's and OTP process management. [Read this blog post for an imperfect comparison.](http://joneisen.tumblr.com/post/38188396218/concurrency-models-go-vs-erlang) One thing he forgot to mention is that while Erlang/Elixir's error handling LOOK similar, Erlang/Elixir's comparison operator will actually fail out and kill the process if the result is unexpected. This is actually a recommended pattern because it only takes a microsecond for the supervisor process to restart a new node, and is considered resilient in real-world conditions. [Here's another article about the two, albeit 2 years old.](http://blog.erlware.org/some-thoughts-on-go-and-erlang/) The problem is that shared process state (which Go has and which Erlang does not) is bad for long-term code stability, period. It makes things faster, like array processing, but it's bad from a bug-free standpoint.
There is job channel in slack chat. And also http://jobs.elixirdose.com/
I'm working in a company that's developing https://semaphoreci.com - a continuous testing and deployment platform and we're hiring developers willing to work with Elixir and/or Ruby - http://renderedtext.com/jobs/2015/lead-engineer/. Let me know if you have any questions about that. Cheers.
I guess he means if you are an asshole you still won't get hired even though you know elixir
I think he means that his company wouldn't hire someone who's primary programming language was Elixir. And if they did, that person would spend most of his time in Java or Ruby or C#. Right now Elixir is not very popular. I believe it will get stronger and there will be more all-Elixir jobs out there eventually, but most places are going to want you to know (and expect you to use) a more mainstream programming language on a daily basis. If you find a full time Elixir job today you're going to be getting paid lower than you would get paid for a more mainstream job because **nobody** *needs* Elixir programmers.
Would the book Introducing Elixir: Getting Started in Functional Programming an option for beginner or elixir in action would be better?
And as pdf?
I think we're still well into the early adoption phase of Elixir's life cycle. If it parallels Ruby and Rails adoption curve, as I think it largely will, you'll see the momentum building primarily in consultancies that get to choose the platform for their clients, and startups where the initial team is technical and likes Elixir. Also Elixir will get pulled into places Rails did not, such as highly concurrent performance-sensitive services at companies looking at scaling technology, and I think we're likely to see an uptick in embedded systems that we never did with Ruby or Rails for obvious reasons. As the first generation of Elixir developers spreads out (e.g. leaving job at a dev-for-hire shop, having startup acquired) its going to start being part of the requirements for a new hire. Over time, you'll see it become a commonplace tool at larger and larger companies. I personally think this that is 3-5 years away, making right now a really good time to be investing in the skillset. Insofar as finding the job in the near future, other responses have mentioned a few good places—but the best way to get a job writing elixir is to make it for yourself :) Advocate for it in your company, or start a conversion project, or start a new app in it. The further the seeds are spread, the faster there will be plenty of jobs to choose from.
Sorry, I noticed it but did not have time to fix it :-/
Landing page doesn't appear to be responsive. 
I've had a look through the first few chapters. I like the presentation - having a narrative does make things a bit less dry than a straight tutorial. There's a few typos I've spotted so far, and I'm not sure the code is as idiomatic as it could be, but I'm willing to put that down to it being V1. Also, it assumes some knowledge of algebra so be warned if you struggle with that. Edit: it uses `[1] ++ [2,3,4]` as an example and doesn't mention `[1|[2,3,4]]`... my opinion is lowering 
Why is there no Linux version? Also why did I have to click 4 times before it told me a price and that my OS is not supported? 
Thanks, that's good info! [Edit] I'm not sure what's up, but I just copy-pasted that code and ran it myself. These were my results for two separate runs: iex(1)&gt; ConcatTest.run Append took 51750000 Prepend took 0 concat took 16000 :ok iex(2)&gt; ConcatTest.run Append took 60937000 Prepend took 0 concat took 16000 :ok I didn't believe this, so I copied the prepend code out, verified it was working and ran it by itself. It returns instantly for me. 
Seems to work for me right now.
While I use a Mac, I do think it a bit sacrilegious (or at minimum incongruous) for something that is supposed to assist with an open-source language not run on an open-source OS
That's odd! Not sure how it can take 0ms :) Here's what I get - there's less difference so maybe performance has improved recently. Append took 33527119 Prepend took 8745 concat took 8693 
Just to verify, I ran the prepend function 20 times. Here's the code I ran and the results (just the times): :timer.tc fn -&gt; ConcatTest.prepend end 15000 0 16000 16000 16000 0 0 15000 15000 16000 0 16000 15000 16000 15000 0 16000 0 0 31000 I'm not sure what's going on, but I have some programs actively processing data for work which probably contributes to the larger numbers, but the zeroes don't make any sense to me. The ConcatTest.prepend is just the copy-pasted code from the link you provided. Each iteration ran and returned results. My guess is some strange bug in the timer code perhaps. I'll work on some further tests to see if I can isolate the source of the zeroes.
Testing is dead? This is not a serious option. The option should be: "TDD is overrated."
Wow, thanks! I generally use the [h|t] method, but it's good to see detailed explanations of how things work.
I asked 3 different sources to tech check this for me (José being one of them). I hope to squeeze out any weirdnesses and thank you for bringing this up. I do use [h|t] later on and I wanted to show it in some kind of useful context - this is my goal with this tutorial (not overloading with syntax dances - just getting code out there and refining as we go).
As /u/phughes notes, even if I and another chap spend most of our days coding in Elixir in our present project, there's no guarantee we will continue to do so in the next one. So *just* knowing Elixir (and being a good communicator, and have some business awareness, etc.) won't guarantee you a hire at my shop. On the other hand, knowing some other pertinent technology in our stack *and* knowing Elixir will get you hired ahead of a guy who may actually be a little better than you with our core technology.
There's a sticky post on this subreddit for people to advertise Elixir jobs. You should add your job there.
Elixir is fun, but programming good HTML/CSS is still hard lol
Is it possible the compiler is detecting a normal, properly formatted list and generates the correct list at compile time rather than actually prepending elements? 
It compiles to bytecode that the BEAM virtual machine understands. Both Erlang and Elixir run inside the BEAM VM. It's *not* what you might call a "transpiler" that turns one language into another programming language that you could read in a text editor.
I suppose that is possible. I'm not sure what's going on and don't yet know enough about Elixir to properly isolate it.
I went with https://github.com/chrismccord/mailgun since Mailgun was free for up to 10k emails. I didn't have any trouble getting everything setup and I was able to get text and html templates ready for all of the emails in no time. On the other end, getting Mailgun configured for my domain was easy as well.
Get someone else's API to do the heavy lifting for you, like Mailgun.
Switch your app structure to a microservices-based architecture. Then you can swap out components driven by any language or technology you want, at will.
yeah anyone who thinks testing is dead is not going to get very far very fast
Pytest fixtures in turn were probably inspired by Rails fixtures. There has been some debate about fixtures in the past few years as a way to set up test states. Fragility IIRC was one of the arguments against them. If possible, I'd structure and test most of your code to not even have to talk to the database directly at all, allowing you to test simply by handing the code its state as a literal, as if it just came from a database. As an added win, you can "async: true" that test suite as it's no longer mutating a global state (the DB!) (I am wary of Elixir repeating test design mistakes, the lessons of which were learned in Rails but which echoed back to Elixir by way of Python :O )
Is there an advantage to using a HTTP API over SMTP? Seems impractical to write a special wrapper when they support the standard method of email sending.
Some interesting points, I definitely agree that avoiding the database in tests where possible is an excellent idea. I don't think there's anything in this project that would prevent you from doing so however. py.test fixtures may have been partially influenced by rails fixtures, but I'm not convinced they are quite the same. As I understand it (though this is from a brief read of the documentation, please correct me if I'm wrong), rails fixtures are bits of YAML that represent database models, that rails can load into the database? It sounds like it might do this automatically on every single test, which would explain your comment about fixtures causing fragility - I imagine every test depending on the same test data being a cause of many woes. Fixtures from py.test are a slightly different beast - they're just functions that tests can say they depend on. Those functions can have side effects, or just return some data the test needs (or both). There's nothing intrinsic that ties them to database models, though they can be used that way. They also only get loaded when a test specifically says it requires them. So the scenario you describe with handling state as a literal could easily be achieved using py.test fixtures (and therefore ExUnitFixtures). You'd simply set up fixtures to return the literal data that you want to operate on, and not go anywhere near the database.
That would be fun and all, but when you have to coordinate an engineering team to be able to support all these services, you pretty much need them to be in on or two languages. Any more than that and you start having problems with only having one or two people able to work on or solve a problem in a service, which is not maintainable for a production system.
Any opinions on VSC? I literally haven't used Visual Studio since intellisense was new
For now, I'm just piping mails in the Unix `mail` command.
I'm doing this right now. Short answer is that the Rails app is still in charge of the database and schema, with the new api server (elixir/phoenix) connecting to the same DB instance in production/dev. In testing I'm just copying the schema into a new database manually and pointing the repo in phoenix at that, but I'm not doing a ton of stuff yet with models in the API app. As far as models go, I'm taking a least-required migration route, copying the minimum attributes required to perform in the API server. Part of the reason is to trim down a lot of legacy fields that aren't used anymore. As I get more and more functionality ported over I'm taking a hard look at the implementation to see if there's a better way to do this kind of thing in Elixir. Its been hard to resist the urge to reflexively port over code directly, but I think I'm seeing some benefits from it.
I use Visual Studio for all my development at work and I really like VSC for my side project/at home development. The elixir integration is great for VSC but is not as great as the sublime integration. 
As for debugging, I suggest you start up the iex terminal and run :observer.start ... This will open a GUI with lots of info on the current running system. Fire off your long running command and then take a look at the processes tab. Likely you'll see your iex process at the top (maybe try changing the sorts) with too much memory usage. Maybe a more solid approach, instead of jamming a million entries in a two dimensional array (which is the more imperative approach), would be to create a single process (likely a GenServer or actually an Agent will do nicely) for each light. Then you can use stuff like GenServer.multi_call to broadcast a message to turn on/off individual lights. Now you're using all cores too! Plus this is simpler to code since all you have to do is figure out which processes to mutate and send them a message. Additionally, the final answer of how many lights are on is simply solved by broadcasting to all processes and asking to send back true/false if they are on, then count up the trues!
&gt; Imagine you repeatedly copy 4MB worth of data for over 1 billions times &gt; Elixir/Erlang or other immutable functional languages aren't suitable for a problem that need to mutate data frequently like this one. Strictly speaking, it's not true that immutability implies copying the underlying data. Clojure, e.g. uses its immutability to allow for structural sharing. So it depends on the implementation of the data structure. I'm not sure how Elixir's Map fares in that regard. My point being: I think the conclusion that immutability precludes problems like this is a bit harsh. 
From what I understand you are initializing the dictionary as a native Erlang Map ([here](https://github.com/iszlai/AdventOfCodeElixir/blob/master/lib/adventDay6.ex#L24)). IIRC large maps are not well supported, yet. Have you tried using a HashDict instead? I would be curious what your results are.
Thanks, wow I didn't know about observer it seems useful, are there any other popular profilers? 
Yeah that was my backup idea I just wasn't sure if that would help a lot since the indexing 
Well if it copies the whole tuple if you update an element then that wouldn't work lol. But access would be fast But there has to be some way. What are you *ultimately* trying to do? Maybe that would help inspire a different less-OO-typical approach
any reviews? the lander makes it look interesting, but there's not much info about it for the price.
With this particular problem, one updates contiguous blocks of elements where ordering is irrelevant. I found it quite efficient to use plain old lists for storing elements along with a custom split function. Split into three, map the middle, attach them back together. &gt; By replacing the per-light table with some sort of span-list, you could probably get quite a significant boost still. This was my preferred solution to the problem. I actually did a 2d span list. I found that, single threaded, it runs just a bit faster than the best I was able to manage with per-row processes, but it uses *significantly* less memory.
Yeah, using lists and splitting is a clever idea -- I like it! Should be faster than the "per-pixel" ETS-table that I was using without the complexity of span-lists. Did you benchmark how it performs against an ETS-backed implementation? Another interesting approach would be to use integer bitmasks (each bit representing one light). If I was writing this in C, then I'd definitely go for that as it has very low memory footprint (one bit per light), which typically leads to very fast execution times as there's very little cache thrashing. Not sure how well the Erlang VM would be able to handle bitmasks. Also, bitmasks handle rasterizing lots of tiny rectangles much better than span-lists. Another alternative to splitting the lights to processes would be to just chunk it into 20 or so groups and have each group handle 50 rows (either consecutive or interleaved). That should give most of the benefits of parallelism without costing too much memory.
I tried implementing the bitmask version. Granted, it gets a bit tricky with the second part of the problem, though it's still possible with multiple bit-planes. The results are quite impressive if I say so myself. :) The execution time went down to about 0.1s (from about 1.1s for the fastest list-of-bits I was able to conjure). Everything now happens within a single process, as process-per-row overhead was just slowing things down. I'm storing the rows as a list, operated on with a custom mapper that only touches the middle elements, i.e., rows in range y0..y1 -- the same trick you used on individual bits. I'm guessing the major reason for these speed-ups is that the Erlang VM probably has native-code implementations of the bitwise operations, and that they're stored in memory as a single continuous chunk, thus being extremely efficient to access.
&gt; it gets a bit tricky with the second part of the problem, though it's still possible with multiple bit-planes. It would seem to be particularly tricky unless you guess the upper bound. &gt; I'm guessing the major reason for these speed-ups is that the Erlang VM probably has native-code implementations of the bitwise operations The actual bitwise operations are native, but there is a bit of overhead to allow for the big integers that the VM uses.
I will hopefully have enough time to work on my blog engine [Mebe](https://blog.nytsoi.net/mebe). It needs a better way to override the default styles, releases, and a user's guide to be more useful for other people. I might also try out something creating something new with [Elm](http://elm-lang.org/) and Phoenix.
I'm doing a complete rewrite of our current (rails) API (work related) , and for fun I'm writing a reddit headline extractor, with builtin album downloader for imgur.com. I've little time to spare, so my side project is almost dead at the moment, but I've already learnt a lot building it. 
was it hard to get work on board for elixir?
&gt; It's not that difficult. You can conceptually compute the adder with one extra bit-plane, and then at the end just prune out all the highest bit-planes which are full of zeros. Yep. Did it, thanks for the inspiration. A bit of a performance hit, though, vs. the simpler part one case. My algorithm is rather simple, so there is is quite likely performance to be gained, particularly for the :off command. &gt; Wouldn't that overhead be similar to what you'd have for each node in a linked list? Roughly, yes. A bit of overhead, still quite fast.
I am taking a stab at this literally the second my GF stops scheduling shit for us to do on every fucking day of her week off
What types of projects would I chose Elixir over Go?
I just purchased the LearnElixir.tv since I'm completely new to Elixir. I've been enjoying the videos quite a bit. ElixirSips appears to be more for folks who already have some experience with elixir and FP in general. Not 100% on that since I'm not a subscriber.
Clojure exists, in large part, because Rich Hickey wanted a Lisp that *wasn't* mutable by default. There are mutable data structures buried in there (plus, of course, all of Java), but the core data structures are persistent and immutable - ie, they have exactly the characteristics mentioned here (structural sharing). In one sense, this is indeed an 'implementation detail', but it's a detail of which Clojurists are immensely proud, and you won't get twenty pages into any clojure book without hearing the persistent, immutable gospel. And it's not just a compiler optimisation, like some bit of JS getting inlined as a machine instruction by V8 or something like that which may or may not happen given the compiler, the code context etc. It's written into the semantics of the language. In fact, clojure (IME) makes very little effort to hide the implementation characteristics of its data structures - whether to use a list or a vector or a lazy-sequence or whatever is a decision the programmer is expected to be able to make based on typical reads/writes in the program. We have abstractions over all of them, but we still want to be able to use a list if everything's getting conj'd onto and read off the front of the damn thing.
Is the code formatting going to be improved? For instance, to use a sans serif, monospaced font, with decent syntax highlighting? I've just started with Red4 &amp; it's currently pretty uncomfortable to read.
Reading Programming Elixir, Programming Phoenix, and Metaprogramming Elixir books !
I used Elixir Sublime, but that actually caused Sublime to hang randomly for me, so I switched to the elixir plugin for IDEA which is pretty well made.
Check out Guardian and Ueberauth. I'm on my phone so I can't get you link, sorry.
CRUD web apps are good for any framework like Django, Rails, or Phoenix. One thing that you can do easier with Phoenix is out-of-the-box API support, so if you wanted to try out React Native or a front-end framework like Mithril, this would make your development much easier and faster. Another obvious use-case would be real-time applications via Channels: stock ticker, chat, multiplayer-game, that sort of thing. But honestly, if you don't have an itch to scratch, maybe you should hold off on building something in Elixir. For me at least, if I don't have something to build that's made for a particular language, I don't force myself to build it. Only when you have a project do I feel like you actually grow, because often your project has things you may not have originally accounted for, and those are the opportunities for you to really learn and grow from the language.
I'm afraid that what you see as one of the main point for elixir, hiring, I see as a liability right now. I think that the simple fact that the pool is small, doesn't necessarily mean that is filled with competent developer. the only fact that they took their sweet time to learn a new language isn't a guarantee that they are proficient in that language. from my experience one of the main point of elixir is the ability to_attract_ new ruby developer (as the elixir survey show), and the fact that we could teach to a junior ruby dev to write elixir in a week, so one could also fish in the ruby sea. I know, I know, elixir is not ruby; but it _feels_ familiar to rubyists, and it's all that matters. a small hiring pool favors always the developer, raising it's price, not the one who hire, that has less choice and much more competition on the fewer good ones. 
Cool! I mentioned the problem to a friend who came up with another interesting algorithm: do a y-ordered of all the input rectangles and keep track of list of rectangles affecting the current scanline. The bitwise operations are probably the fastest way to convert the list of active rectangles into the final rasterized scanline. With this approach you wouldn't even need to store the full rasterized image anywhere, which might provide some cache benefits as well. Though due to the immutability of Elixir, a lot of garbage would be generated along the way, so not sure how much this actually helps. Given that there's 300 rectangles in the input, there's a maximum of 600 scanlines where any rectangle on/off events happen, and thus the rest (400+ scanlines) are identical to the previous one and have the same count as the previous one -- you can essentially get them for free.
Solve some problems in your life. Is there a tool or library you miss from another language? Well try building something that helps with the same task.
spacemacs with the default stuff for the elixir layer
&gt;Is mnesia a credible data store for elixir web apps Yes, some people use mnesia by default since it's in memory and move to something else if their data grows enough that they don't want it in memory anymore. &gt;If I use mnesia will it hinder or complicate my deployment? No. &gt;What if I want to run more than one server? mnesia, relative to other common databases, is very easy to cluster &gt;So many questions.... Good thing there is plenty of documentation for you to read, then ;)
I thought that mnesia also had a disk option. Also if there is a sample app or some docs on elixir and mnesia I'd love a link. Thanks.
One of the best examples we have of scaling erlang/elixir applications is whatsapp and they use mnesia.
I'm a bit behind you in my Elixir learnings, but I have an idea I've been thinking about... A chat app similar to those live support chat apps you find online. Basically, a user requests support from a specialist. Eventually a chat session opens between the requesting user and the support specialist. This involves a set S of support persons of category C. A user in the set U requests support in category C. You can complicate or simplify the chat system as much as you like. For example, a support person can have a certain capacity for simultaneous chats or you can get rid of categories all together. Another idea: A tic tac toe game with online matchmaking by skill. You can rank players and they can queue up for games.
Nice, this is just what I'm looking for. Thank you.
I watched most of those and they are really well done. 
Learn Elixir The Fun Way http://shop.redfour.io/
Yes https://github.com/erlang/otp
Of course, man. It's the future
Since you have to pay, it seems reasonable to expect the makers to update their videos. 
I don't equate them completely. Perhaps it's more accurate to say that there's less of an impedence mismatch between Erlang and Elixir because they are isomorphic, due to compiling to the same AST. Consider the recent improvements to map performance in Erlang 18. Elixir gained the same speed boost for free. If Java updated its map library to be more performant, I wouldn't expect clojure to benefit (though it might, I'm not familiar with the implementation). As you said, its an implementation detail, and it won't always be the case, but Elixir often benefits from improvements to Erlang the language, not just BEAM the VM more often than a JVM language will benefit from improvements to Java rather than the JVM. Does that make sense? Or am I completely wrong here?
Open source projects have been slowly beating closed-source projects to death for a long time now
Sure that may look good, Ill try it out once I get home
Yeah, I have never had this much fun developing with a stack. Currently the amount of data and statistics is fairly limited, and plan to add more soon (which is trivial now that the infrastructure is up and running).
That is called the pipe operator and as someone that also recently started playing with elixir and comes from a PHP background it can be confusing as hell. This explanation might be useful to you: http://jessewolgamott.com/blog/2015/11/20/explaining-elixir-pipes-through-the-magic-of-turduckens/ 
`|&gt;` takes the expression to the left and supplies it as the first argument to the function to its right (called pipelining). If the function to the right takes additional arguments, feel free to supply them, totally ignoring its first. In the simplest use, you can say `"kebab" |&gt; eat`, which means exactly the same thing as `eat("kebab")`. `"kebab" |&gt; cook |&gt; purchase |&gt; consume` is functionally equivalent to `consume(purchase(cook("kebab")))`, it's just more readable because it appears in chronological order. It really becomes useful in the situation you describe, nested calls where everything is taking lots of arguments. Say that you have a list of functions and arguments: - `def consume(item, speed)` - `def purchase(item, price)` - `def cook(item, temperature` You want to eat a kebab. You would traditionally call `consume(purchase(cook("kebab", 20), 4.5), :fast)`. In Elixir (and F#) you can instead call `"kebab" |&gt; cook(20) |&gt; purchase(4.5) |&gt; consume(:fast)`. After every pipeline operator (`|&gt;`), the next function is implied to have its first argument already satisfied by whatever expression is to the left. So `cook`'s first argument was the string `"kebab"`, and `purchase`'s first argument was whatever `cook("kebab", 20)` returned, you get the idea. This is useful because in any functional language, you will wind up writing functions that are composed solely of pipelines of other functions.
The |&gt; (pipe operator) macro addresses a common problem in programming, the difficulty of reading nested calls. Here is an example: foo(bar(baz(input), n)) It's ugly, it is easy to misunderstand, and it happens very, very often. Here it is written using pipes. input |&gt; baz |&gt; bar(n) |&gt; foo It does use more lines, but it is also more readable and it requires much less mental gymnastics to understand. In Elixir, many things are macros, and |&gt; is no exception. In case you aren't aware, macros are compile-time functions which take code as input and transform it into new code. The |&gt; macro simply takes the second example and re-writes it to the same code that the first produces.
any thoughts on how you'd unit test react within a phoenix project like this? what about integration tests? cool project!
I'll take readability over less lines any day, lol. Thanks, it makes a lot more sense now too as to why it's used a lot.
You might want to try the Elixir mailing list, the core team frequently respond to posts on it and might be better suited to answer this.
Also do you have a need to lookup the children by a keyword or string? If not tuples give you constant time access to an index since they are fixed arrays (contiguous in memory) rather than a linked list.
do you know if `|&gt;` is related to what's called currying in other func languages?
Hrm, here's where my knowledge falls short. Maybe they say that because appending and removing elements is O(n) or maybe it has something to do with how data is passed between calls. I forget if it passes by value only between different processes or on function calls within the same processes as well. I know different processes have their own heap/stack. Are you trees wide?
The short answer is no. Currying is taking an expression that takes a series of arguments and expressing it as a series of functions that take exactly one argument. A curried elixir function that adds two numbers together might look like this: def add(x, y), do: x + y def add(x), do: fn y -&gt; x + y end add(3, 5) # 8 add(3).(5) # 8 I *believe* the |&gt; operator is a macro, which means it receives the AST of the surrounding code as an argument, and literally rewrites it. (If not, please correct me.) So, to take our example above, 5 |&gt; add(3) gets rewritten to add(5, 3) There is a very similar construct in clojure called the thread first macro (-&gt;): (-&gt; 5 (+ 3)) ;; rewritten to (+ 5 3), basically and another handy variant called thread-last, which does the same thing, but adds the preceding expression as the last argument of the next call: (-&gt;&gt; 5 (+ 3)) ;; rewrites to (+ 3 5)
I am running R18, though I think most of the enhancements were speed, not storage. I had run across some references to ETS, but what I read didn't seem like it would be the right fit. But, since you mention it, I should probably give it a more thorough look -- if it is more space efficient, it might be worth extra code or complexity to use it. Thanks!
It's different in F# than in Elixir. In Elixir the left-hand side of the pipe becomes the first argument while in F# it becomes the last argument. For example: &gt; let foo x y = printfn "x=%i y=%i" x y val foo : x:int -&gt; y:int -&gt; unit &gt; foo 1 2 x=1 y=2 &gt; 1 |&gt; foo 2 x=2 y=1 This is because F# allows for partial function application: &gt; let bar = foo 1 val bar : (int -&gt; unit) &gt; bar 2 x=1 y=2 &gt; 2 |&gt; bar x=1 y=2 
Here's some details on Erlang's memory usage per term (which might explain some things if you're using tuple nodes in a map): http://www.erlang.org/doc/efficiency_guide/advanced.html
Ideally I want spawn_monitor and spawn_link. However, those functions aren't available when you spawn processes under supervision. What would be best practices? For example: defp acceptor(listen_socket) do {:ok, socket} = :gen_tcp.accept(listen_socket) {:ok, pid} = SomeSupervisor.start_child(self()) :ok = :gen_tcp.controlling_process(socket, pid) send(pid, {:start}) ... ... end Acceptor's parent process can shut down Acceptor as any time. Acceptor is not linked into SomeSupervisor supervision tree. I want the new spawned process to shut down if Acceptor is terminated before sending {:start}. My current solution is to send Acceptor's pid to the new process so that it can monitor Acceptor. However, I have no gurantees that Acceptor won't shut down before the monitor can be establish. There are probably many solutions to this problem, just wondering if there is already an established convention for this type of problem. Thanks.
Yea, old school erlangers tend to be a bit condescending towards other languages.
An early implementation of the Synacor VM and a debugger in Elixir. If you're not familiar with the [Synacor Challenge](https://challenge.synacor.com/), it's another fun little programming challenge by the man (/u/topaz2078) behind the recently popular [Advent of Code](http://adventofcode.com/) challenges. You can find a short demonstration clip [here](http://webmshare.com/VNGOP). (SOME SPOILERS INSIDE)
Fair enough! I was thinking server side stuff (because that's where I work), can see how it'd be too painful to expect users to admin a server for your app. If there was a lightweight alternative a'la SQLite, I feel like it'd be a great fit. Good luck getting your data structure right in elixir terms =)
IMHO is better learn first Elixir, that is more approachable, then, when you are confident enough with the core concepts of Erlang (like OTP, that is reproduced 1:1 in Elixir), you could learn some Erlang. [This](http://learnyousomeerlang.com/) is a good starting point for learning Erlang (and is also free).
Looking forward to part 2 with the testing. I haven't seen anyone talk about integration testing in phoenix yet, would be nice to see that.
Thanks, thats good to know. It's been a year since I listened to it. Maybe it's not as helpful as I remember.
Looks like it's only if you purchased the eBook. It's not showing up for me, as I only purchased the physical copy. Not complaining, but it would be nice if book companies did what record companies do. When you buy a record, it includes a coupon for a free digital download.
The piper operator. It is currently also being proposed as a new feature in JavaScript.
I emailed their support asking if they would supply a coupon for a physical purchase (with proof). We shall see...
I had no trouble learning Erlang "as I went along" with Elixir, a lot of the semantics are the same even if the syntax is different. If you learn Elixir, you'll kind of automatically learn some Erlang, and then all you have to do is learn a bit of syntax, it's really nothing hard. Any competent developer will just pick it up as they go.
I find OOP code to be generally quite buggier and harder to maintain than "pure" functional code. I'm assuming that's where the condescension comes from... experience. I seriously doubt that ALL those guys have ever done was FP/Erlang.
process table - shared runtime atom key-value pool, non-persistent ETS ("Erlang Term Storage") - efficient in-memory db that is tuned for Erlang data types, tables can be shared among processes as a form of IPC, non-persistent DETS ("Disk ETS" or something similar) - ETS but with the terms stored on disk (or copied to disk) using a linear hash table, persistent, 2G size limit Mnesia - distributed transactional DB built using ETS/DETS, persistent but is CA on the CAP diagram, prone to split-brain if the conditions are right, and node rejoin can be tricky Riak - distributed database that provides tunable eventual-consistency, CRDTs for safe updates, and other magical goodness but needs tuning for your specific use-case, persistent using LevelDB as the default back-end iirc. Local storage is not really that difficult (ETS is really easy to use and DETS is equally simple, plus there are numerous wrappers for just about every single-process DB out there in addition to generic DB wrappers like Ecto) and if you wanted an immutable datastore you could probably rig up something using the CRDT tools provided by Basho and DETS to store your list of transactions to apply to the DB to get it to 'now'.
&gt;Riak is built on... Mnesia and unicorn blood. You couldn't be closer from truth. They also have a patched BEAM to make it work :')
Is there going to be a hardcover version?
[**@josevalim**](https://twitter.com/josevalim): &gt;[2016-01-06 09:23:33 UTC](https://twitter.com/josevalim/status/684666602294521856) &gt;Also do you find Elixir compiler warnings: ---- [^[Mistake?]](/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=/3zpa3z%0A%0APlease leave above link unaltered.) [^[Suggestion]](/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
Also https://twitter.com/josevalim/status/684666326456098816 though I think it's a bad question, because different people compile at different intervals.
[**@josevalim**](https://twitter.com/josevalim/) &gt; [2016-01-06 09:22 UTC](https://twitter.com/josevalim/status/684666326456098816) &gt; When you compile Elixir code you just wrote for the first time, does it usually have: ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Hey, I just wanted to let you know that your articles are really good for someone who's new to Elixir and wants to pick up the Elixir thinking style. Thanks man!
Found the basho sidejob libs, that seem to be doing service pooling I was expecting.
I've been looking at parts of the Jepsen series, but I worry Kyle Kingsbury is too smart for me to even really appreciate what's going on. Which is to say I - among other things - don't trust myself to really have understood what partition tolerance entails.
A caveat to the CAP theorem, is that CA is in practice impossible. Network partitions will always occur (via network latency, garbage collection, os failure, hardware failure, natural disaster, you name it) Can you describe more about what you mean by Mnesia being CA?
Great answer, and this microservice strategy is what I think I'll be moving towards. Right now, for me, a combo of Node, Go, &amp; Elixir sounds really appealing... Node for tooling &amp; serving up web apps, Elixir for the majority of all backend services, and Go as an alternative option for anything that needs heavy crunching. My reasoning? Mostly, Elixir is functional &amp; Go is not. Also, Elixir is more concise, like you said. Go is multiparadigm, but leans heavily towards imperative &amp; OOP style... it's probably the best OOP language available right now due to its inherent compositional style &amp; speed, but I just prefer the functional style (as I think probably most Elixir fans do). So, Go can be the last resort for heavy lifting when needed, IMO.
The first example of pattern matching in function is in fact not an example of pattern matching. defmodule Hello do def say_hello, do: "Hello, Elixir!" def say_hello(name), do: "Hello, #{name}!" end # Hello.say_hello #=&gt; "Hello, Elixir!" # Hello.say_hello("Bob") #=&gt; "Hello, Bob!" Functions in Elixir have both a name an an arity, and thus the two function bodies defined there belong to two entirely different functions, `Hello.say_hello/0`, and `Hello.say_hello/1`.
As someone who works for a poker company and is just learning elixir (as a side project) this has been a great series for me! Thanks for putting this all together. This plus the elixir learning docs has been a great help.
@gabriel_dny I was try: :VundleInstall in vim but it show error. I was capture my screen. Here is: http://imgur.com/a/1i5qC
Thanks @MrPopinjay, I'll fix this! :)
Thanks!
Thanks for that. I love vim. I will find this error.
Alternatively you can inject dependencies, removing the need for a complex mocking library, and allowing you to run your tests concurrently. def mul(x, y, mod \\ SomeDependency) do mod.mul(x, y) end As a bonus, I find this method encourages you to think clearly about the dependencies and boundaries of your modules. :)
Nice write up! I noticed something while reading your section "Bonus: Pattern matching with recursion" and wanted to share a word of caution: Your `sum([head|tail])` function is not tail-recursive, because it does not call itself as the last operation. When you do `head + sum(tail)`, the last operation is the `+` operation. This means that your sum function will not be tail-call optimized and will run into stack overflows if you use it on a long enough list.
Someone commented in a forum posted ? What ? Hex is perfectly stable and usable package manager.
One could argue that it's actually much more stable. Hex packages are completely immutable in the registry. That means you can cache them forever with no worry, whereas npm packages can disappear or change out from under you.
Where was this posted? Elixir and Hex are exceptionally stable.
Exactly my reasoning! I played with Go for a couple months some time ago, but could never warm up to the idea of writing my whole backend in it... It looks not very readable after Ruby. So spoiled... ;) But Elixir gets syntax just right! 
It's very easy to swap brunch for webpack.
Nice to hear Chris is also still working on channel presence.
I actually prefer webpack too. If you are looking for the "How To", check this out: http://www.phoenixframework.org/docs/static-assets#section-phoenix-without-brunch
If your on a mac. brew update brew install elixir To upgrade: brew upgrade elixir If you don't have it installed, I highly recommend it. Go here: http://brew.sh/
Does webpack get you anything besides hot code injection when stylesheets etc change? Why is the react world so crazy about webpack?
A |&gt; B |&gt; C == C(B(A))
It's been updated AFAIK
I like keeping my scratch-buffer in elisp mode, so I've taken a different approach, as seen in my emacs elixir setup: https://github.com/gausby/emacs.d/blob/master/setup/elixir-setup.el#L41-L51 When I am in alchemist mode I can quickly open an elixir scratch buffer (a buffer named *elixir-scratch*, with the elixir major mode and alchemist activated) by typing `C-c a i s`; type in some code; and evaluate it with `C-c a v q`. When evaluated it will pop up a new buffer with the result of the last expression.
That's an excellent idea @gausby. Thing is for me I never use emacs for elisp (I'm not that advanced at emacs and may never be) so hard-coding it the other way made some sense to me. Still that's a very cool approach.
Nice to see Phoenix and React go so well together!
React renders your component tree starting at a given element. This can be any element on the page. It was originally used by Facebook for their notifications section only. At my job we've used React in a hidden div and used it to add newly designed modals into a legacy part of the app. React is pretty versatile when it comes to how to use it.
I'm glad he made this clarification. I often run into people online who seem to think Elixir introduced mutable variables to Erlang. I also have a new appreciation for the explicit match operator, which I was averse to at first.
Can we move this over to the official Phoenix docs?
Hot module replacement?
I actually tried this with [react-leaflet](https://github.com/PaulLeCam/react-leaflet) but the map doesn't display although the element exists in the DOM tree. Maybe a compatiblity problem with Bootstrap ? 
Any thoughts on Corsica vs Cors Plug(https://github.com/mschae/cors_plug)? I needed to drop one in and ended up grabbing Cors Plug. They seem to be pretty much the same.
You want webpack.
You might try [erlang-stdinout](https://github.com/mattsta/erlang-stdinout-pool).
This post didnt work... $ brunch build 14 Jan 13:40:16 - error: Compiling of 'web/static/js/app.js' failed. Couldn't find preset "es2015" relative to directory "web/static/js" ; Compiling of 'web/static/js/socket.js' failed. Couldn't find preset "es2015" relative to directory "web/static/js" Tried installing babel-preset-es2015, no luck. Tried removing the es2015 preset, crashes as well.
I didn't get it to work. Maybe I did something wrong?
In my exp its easier to test the source files, not compiled assets. You have to pick a test runner that supports babel, most of them now. Ideally you also, lint your JS too. I'm a fan of eslint these days. I'm sure it's all possible, just a question of how easy it is to get all setup. It's been on my to-do list for a while.
https://github.com/alco/porcelain
Figured it out... See here: https://github.com/phoenixframework/phoenix/issues/1410#issuecomment-166001866
Thanks again for the comment! I've updated the guide just in case anyone else runs into this specific issue.
Whenever I search for a utility written in a certain language I refer to the awesome repository family: https://github.com/h4cc/awesome-elixir http://lockys.github.io/awesome-search/#repos/h4cc/awesome-elixir It looks like there isn't much. Honestly, I would just go with Phoenix. I haven't seen an Elixir micro framework that is actively maintained. A lot of them seem like one off side projects.
Honestly, if it's super bare bones you can try [Plug](https://github.com/elixir-lang/plug). Or you could try to pick one of the microframeworks and hope for the best. Or you could just use Phoenix's controllers and call it a day.
Why not use cowboy and start from there? Also perhaps you can start a phoenix project excluding certain pieces, such as the ecto layer, making it more lightweight. 
problem is I installed successfully on a W7 VM machine, so I seriously don't know, I like to solve misteries... but this... is confusing.
I think it is worthwhile to consider what you are trying to avoid by not using something like Phoenix. One uses Sinatra over Rails because Rails comes with a big pile of cruft which complicates things and hurts performance. Phoenix has *much* less of this than Rails and what is there can be much more easily disabled.
Phoenix is not a framework per se (well, technically yes, but it's not indicative of its size at all!). It's a relatively thin layer on Plug and Cowboy. You should check the lines-of-code count of Phoenix and Rails before you make that judgment. Here, I collected some stats using the "cloc" utility which pretty definitively proves my argument: PHOENIX FRAMEWORK ================= 208 text files. 207 unique files. 30 files ignored. http://cloc.sourceforge.net v 1.65 T=0.66 s (271.3 files/s, 34372.2 lines/s) ------------------------------------------------------------------------------- Language files blank comment code ------------------------------------------------------------------------------- Elixir 165 4000 707 15881 Javascript 8 209 425 1327 CSS 2 11 16 62 JSON 3 0 0 28 YAML 1 0 0 16 ------------------------------------------------------------------------------- SUM: 179 4220 1148 17314 ------------------------------------------------------------------------------- ** RAILS FRAMEWORK =============== 2958 text files. 2817 unique files. 369 files ignored. http://cloc.sourceforge.net v 1.65 T=8.76 s (299.2 files/s, 34345.8 lines/s) ------------------------------------------------------------------------------- Language files blank comment code ------------------------------------------------------------------------------- Ruby 2068 45161 40815 202051 CSS 36 180 376 4385 YAML 141 264 554 2362 ERB 302 277 10 1866 Javascript 45 225 523 1205 HTML 19 15 3 198 CoffeeScript 7 58 89 195 yacc 1 4 0 45 SQL 1 6 0 43 DTD 1 0 0 1 ------------------------------------------------------------------------------- SUM: 2621 46190 42370 212351 ------------------------------------------------------------------------------- So the number of Elixir lines in Phoenix is about 1/13 the number of Ruby lines in Rails. (Interestingly, Phoenix has more JS, though...) Anyway, the JSON output you'll probably be looking for can be considered a "view" on the data, anyway.
Plug offers the functionality asked for, and is one if the most popular libraries for Elixir. :)
With an API the structure of your JSON or XML is still the view. Just because it's not HTML doesn't mean it's not MVC.
So, the Y-Combinator, basically?
A framework in the vein of Sinatra is just a router, which Plug provides. :)
Except you can't pass this to an API which doesn't know how to pass the function to itself. You have to end up wrapping it in something like this: fn n -&gt; fact = fn f, 0 -&gt; 1 f, n -&gt; n * f.(f, n - 1) end fact.(fact, n) end Which gets a bit awkward. This could all be solved just by having a name to refer to "this anonymous function", which is what Erlang provides and we will hopefully be getting in Elixir soon. Honestly, I think this article is more interesting to see someone extending the language using macros.
the latest package. I don't understand, seems like it doesn't compile the exe for it on my main system.
It's awkward enough that if I saw it, I would immediately rewrite it to: def fact(0), do: 1 def fact(n), do: n * fact(n - 1) &amp;fact/1 
if it's not too late, there is an erlang cartridge with elixir out there on github https://github.com/wozniakjan/erlcart
I respectfully disagree about installing on Linux or Mac OSX for "serious" Elixir development. While we've got plenty of issues running Elixir on Windows, there are lots of rough edges on Linux too. I run Emacs with Alchemist on Windows and everything works pretty well for me. I do the same on my Linux laptop and neither one nor the other is vastly superior.
Just use Phoenix :)
Records are only really around for compatibility with Erlang libraries which use this data structure, please don't use it in a new Elixir project except for this purpose. Before Erlang had maps, use of records in Elixir (pre 1.0) was a bit more common, but structs are their replacement and would totally replace records if not for this compatibility requirement. The order of elements is not guaranteed, so using it as a normal tuple is not recommended. If you have to use records, please use the record macros which are able to properly map values. 
What's Erlang 17's solution for "this anonymous function"? EDIT: Nevermind it's likely [funs with names](http://stackoverflow.com/questions/23199177/funs-names-in-erlang-17)
Yes, see the Transport.Serializer behavior https://github.com/phoenixframework/phoenix/blob/master/lib/phoenix/transports/serializer.ex Channels abstract the transport protocol as well as the serialization format for the data on the wire. By default we use JSON, but you could write say, a MsgPack serializer, and configure it like this in your UserSocket: transport :websocket, Phoenix.Transports.WebSocket, serializer: MsgPack 
@chrismccord is the serialization over phoenix-pubsub-redis JSON as well? I'm looking at how to integrate well with a legacy rails app, would like to leverage that if possible
Nice mix task bro
Good deal, thanks for the advice!
Unfortunately, they have to be extracted in the pattern match, there are no guard functions which can access map elements. To solve the problem in this post, there are only really two options. One is to write a macro which is able to handle the pattern matching as well, which would be a bit ugly and not best-practice. The other is to move validation into the function. Create a validation function and pass the whole map over (on the first line so you can fail fast). While not nearly as clever or fun, it works. Given the scenario presented, there is no alternate function clause which handles invalid dates, so one doesn't *need* to do it in the function declaration. It also provides an opportunity for a better error message. There is also the issue of how defensive one should be when programming something like this. While it is a good idea to provide a "valid?" function so that one can check validity at key times like getting from or putting to a database, writing too defensively can cause other headaches down the road as things need to change. There is no easy answer here, it is a matter of deciding how likely risks are and how to manage them. 
Thanks!!! This now lets me install dependencies using hex behind the firewall now. However, but on a fresh installation of Elixir, hex is not installed. Mix is giving an error when trying to install hex for the first time. The command provided above configures hex.
I agree. My perception is that when network communication is involved I cannot be defensive enough.
Nice mix task bro
pseudo-coding it def valid(your_struct, more_data) do if (validity checks) do :ok else {:error, :invalid} end end def valid!(your_struct, more_data) do case valid(your_struct, more_data) do :ok -&gt; :ok {:error, message} -&gt; raise ErrorModuleName, message end end def useful_function(your_struct, args) do valid!(your_struct, args[:foo]) ... end 
You might need to implement it starting with something like https://github.com/trustatom-oss/erlang-secp256k1 but that only calls into the bitcoin core code. Not sure if there is yet a natively-implemented version of the Bitcoin protocol or even public/private key generation. It's not hard to generate the public/private key manually, if that's all you need (the bitcoin network doesn't even have to be aware of your keypair until you spend bitcoins into it), but you'll lose the mathematical relatedness that the native Bitcoin implementation provides: https://en.bitcoin.it/wiki/Private_key
If at all humanly possible, structure your code in such a way that you can avoid as much browser testing as possible (yes, including phantomjs). Those tests are almost always single-threaded and slow. Push as much logic as humanly possible out of views and into independently testable/loadable components that ideally have database-connection doubles (is it necessary to test SQL parsing and the ORM in every darn test in your suite? No.) Lastly, default your test suites to "@async true", and revert that only if absolutely necessary and if there is no other option (seriously, have you considered other options than forcing that one suite to run singlethreaded? If it has to talk to a database or otherwise "run impurely," perhaps you can fake some things out...) When you have a new codebase, these suggestions don't seem very important, but assume your codebase will grow, and that you won't have time to refactor everything again later at some point... Just some advice from someone who's worked on Ruby codebases that grew to be very large (and grew to have very slow, impossible-to-parallelize single-threaded test suites along with them).
I've never understood why people aren't just compiling the templates into html and checking the html without loading up a browser in the first place. What's the point, exactly?
I've also worked on bigass Rails projects with tons of integration tests, and at least to me, integration tests still seem very much worth it. Yes, it's nice to have most of your coverage come from fast, parallelized unit tests. But at the end of the day, they only test implementation details. The value comes from users logging in, adding an item to cart, pressing the 'buy' button and having the payment flow kick off. That's what integration tests cover, and make sure all the small, independently tested modules are working together to handle the business processes. You shouldn't call out to the browser to verify that 2+2 still equals 4, but no amount of unit tests will tell you that with addition of the latest feature, the BUY button has been pushed off-screen on the minumum supported screen resolution.
Thank you for these, much appreciated :-)
I believe integration tests are the other side of the same coin as unit tests and that, of the two, unit tests are easier to maintain since they are more granular/modular. The tradeoff is that, generally speaking, integration tests -- at least before you have to maintain them to handle more than one or two ideal scenarios -- are easy to build. Why are they basically the same thing? If an integration test tests the code path from A -&gt; B -&gt; C, so does a unit test for the same inputs to A, B, and C. If tested code in your language of choice isn't strongly typed, you'll need additional unit tests to verify the interface has not changed: next to tests for B, you would have tests that A's outputs match what B expects for inputs (see Sandi Metz's POODL for examples of this style of testing in ruby). 
Does a new node need to connect to all existing nodes or just one of them at random? I was wondering what would be the best/most reliable approach when using aws autoscaling, either relying on this method or having an external redis server. 
The way Erlang distribution works is that once one node knows about another node, everything meshes together from there.
Fat-client, javascript-driven websites. The more of your app functionality is JS, the harder it will be to test it as part of a comprehensive test suite.
Actually, *not even integration tests* will flag your last example (at least if they're just screen-scraping content and asserting it... in which case you still don't need integration testing). But you DID argue for a QA team LOL Thick-client, JS-laden websites muddy the testing waters quite a bit unfortunately
BEAM will start an OS process on each host called epmd, which will track names and relative liveness of each node it connects to. When a new node joins, this information will automatically replicate to all other running epmd processes. As long as you don't have too many nodes, the overhead of adding a new node is very small. Once you get up to hundreds of nodes, you'll want to do some tuning to avoid problems when adding and removing nodes which can introduce instabilities (a discussion a that's a bit out of scope here). On the Erlang side, you can use the net_kernel and net_adm modules to take a look at these things or control them dynamically. For example, you can start net_kernel dynamically if you can't give a proper name on boot for some reason. See net_kernel:nodes_info/0 and net_adm:names/0. There are a number of ways you could use the AWS intranet endpoints to get both your local hostname as well as host names of locally available nodes in a group. It wouldn't be hard to wrap this up in a small app to manage cluster membership.
Ah so it actually simulates clicks at coordinates. Well yeah, in that case, that would work :) (I'm secretly anti-QA-team)
Thank you for the explanation. I suppose I can use the hostname and a fixed string to build a node name, assuming there's one per VM, but what options do I have to find other nodes to connect to? Is there a gossip protocol implemented?
run the server with `iex --name name -S mix phoenix.server`, and then you can invoke a command like the `Node.connect` there.
Code is organised in erlang and elixir by putting it in a module. You call elixir functions in another module like this: Module.Name.function(arg1, ..., argn) And erlang functions like this: :module.function(arg1, ..., argn) 
Well, you can compile some Erlang, and then import it in your Elixir program and just use the atom caller syntax: :module.my_function("wat") But afaik there's not way to embed Erlang directly in an elixir file.
Programming Phoenix walks you through building a simple Phoenix app. You're right that it isn't super long, but Phoenix isn't an enormous framework either. I think it's a good way to get started.
Downvoting because the title for this doesn't actually say what the article actually is.
/2 is the arity of the function using Erlang's notation. So it's basically using the anonymous function + (sum) with two arguments.
Elixir is powerful enough that you can probably write a macro to inline Erlang code
This idea has actually been tried before :-) For example, it was used in [mochiweb](https://github.com/mochi/mochiweb/blob/master/src/mochiglobal.erl), where putting is implemented by compiling and reloading a module. I'd say this technique should be avoided almost always, Relying on ETS is more idiomatic, and it shouldn't be too slow. But it would be nice if we had some comparison, so we could learn whether some perf can be gained, for example in cases where a bunch of processes frequently read mostly static data. That's the only situation I can think of where we might get some benefits, but this needs to be verified by measuring :-)
Isn't the idiomatic way to rely on a stateful server process, like [this one](https://github.com/sasa1977/elixir-in-action/blob/master/code_samples/ch05/todo_server.ex) described in "Elixir in action"? 
/u/rizo_isrof has already replied, but maybe I can shade a little more light. You can define reduce as reduce([h | t], accumulator, function) -&gt; reduce(t, function(accumulator, h), function) reduce([], accumulator, function) -&gt; accumulator In our case &amp;+/2 is just like `fn a, b -&gt; a + b end` Where 2 indicate that the function takes two arguments (`a` and `b`). In our example: reduce([1,2,3], 0, &amp;+/2) -&gt; reduce([2,3], (0 + 1), &amp;+/2) -&gt; reduce([3], (1 + 2), &amp;+/2) -&gt; reduce([], (3 + 3), &amp;+/2) -&gt; 6 Note that the evaluation of the accumulator is not precise, it is just for illustration...
That would be the default way yes. However, if the operations are to simple get/put and a k-v based approach, and the "storage" is used by multiple client processes, ETS table will perform better, because there's no single process bottleneck. Many people dub ETS tables as the optimization technique, but for me it becomes the default choice under the conditions described above (and some similar conditions). This doesn't mean processes are useless of course, quite the contrary. You can do way more with processes than with ETS tables, but for some simple concurrent operations (such as concurrent k-v store), ETS will frequently work better. Spoiler alert: If you're reading EiA (full disclosure: I'm the author), this will be revealed in chapter 10 :-)
ETS is great! I recently created a [PR for ex_rated library](https://github.com/grempe/ex_rated/pull/8) to add support for DETS and persisting the in memory table and it was deadly easy to do. I'm working on a new project targeted to small businesses and since ETS/DETS are built in in the language, I'm strongly considering of switching for the data layer, instead of using a real database or sqlite. &gt; Spoiler alert: If you're reading EiA (full disclosure: I'm the author), this will be revealed in chapter 10 :-) I'm almost there :) 
Don't get people to try languages with pattern matching, they will only be disappointed when they have to write in languages that don't have it.
Yes. I briefly mentioned using GenServer or ets. I suppose gen_fsm also, depending on the use case. But @sasajuric pointed out even this hack may have a place. Learn something new every day ....
Thanks, I will definitely check it out, my needs are really basic at this point, simple is very much welcome.
Not relevant, but just want to append [rust](https://doc.rust-lang.org/book/patterns.html) to the list of pattern-matching languages. It's defiantly next on my list of languages to learn ....
I was using anonymous as a synonym for lambda! :)
This is not mixing Erlang and Elixir code syntax. That cannot be done. It is calling an Erlang function (timer:tc/1) using the Elixir syntax for doing so, and passing it an Elixir function.
Hi @Tallakt thanks for this. I've actually had https://github.com/meadsteve/white-bread/issues/20 open for a while because I'm not really comfortable with the level of macros either. The steps with regexes are harder to remove the macros from but I do like your suggestion for the setup and teardown functions.
It doesn't reduce it, it just makes it look different.
I think there are plenty of valuable resources right now to pick up elixir. To get yourself familiar with the language I would start with pretty good tutorial on [elixir-lang.org](http://elixir-lang.org/getting-started/introduction.html) It's worth investing some time in books as well, good starting point is [Dave Thomas's book](https://pragprog.com/book/elixir/programming-elixir). A little more advanced but still worth checking out is [Elixir in Action](https://www.manning.com/books/elixir-in-action). Nice free online alternative is [Etudes for Elixir](http://chimera.labs.oreilly.com/books/1234000001642). If you prefer to watch videos, [ElixirSips](http://elixirsips.com/) would be a great choice. It's kind of similar to good, old Railscasts. [Exercism.io](http://exercism.io/languages/elixir) has section for Elixir, so you can work on your skills there as well. Elixir is a great language, I'm sure you gonna love it! 
As there are already fine suggestions here for learning resources, I will skip those. I am just a tiny bit concerned with your perception that Elixir and Phoenix are like Ruby and Rails. Knowing the latter does almost nothing to prepare you for the former. The big similarities between them are more related to a focus in providing a developer-friendly workflow and their approaches diverge wildly. For example, where Rails tries to be nice by hiding complexity from the developer to allow one to focus on what makes your project different, Phoenix achieves something similar by using a simple, repeatable, composable pattern and sane defaults while making everything explicit. I think you would be well-served not thinking that anything in Elixir is going to be like Ruby except for a dedication to making a developer's life a bit easier.
Many thanks ! 
I probably did not express myself well, I know the paradigms, languages and frameworks are completely different. I just said they are similar because elixir's syntax is ruby inspired and Phoenix architectures is similar to Rails.
Please don't misunderstand my tone, I'm trying to avoid coming across as condescending. Elixir and Phoenix were created and written in large part as an exodus from Ruby and Rails and this has created a link between the two worlds and has created a great deal of misunderstanding of how Ruby and Rails-like Elixir and Phoenix are. Please understand that I write this with only kindness and a desire to help. &gt; elixir's syntax is ruby inspired About the only similarities are the terms 'def', 'do', and 'end', that function call parens are optional, symbols and atoms begin with colons, and a relative lack of punctuation. The similarities in syntax are so superficial as to be almost meaningless. One common example is that folks coming from Ruby will only write a single function declaration and then put all of the conditional logic inside it using if statements. The syntax of conditional branching in Elixir is so totally alien to Ruby as to be difficult to compare. &gt; Phoenix architectures is similar to Rails It really isn't. There is a sort-of-similar MVC structure, but the models are *totally* different and the views are just functions. REST in phoenix is highly controller-centric compared to Rails. In Rails, there is a mantra of "Rails is not your app", but this tends to be very difficult to realize because of how Rails is architected and how it has to be deployed. In Phoenix, the web parts of the application are just OTP processes and this creates an architectural and logical separation from the business logic of the application. If you write your Phoenix app like you write your Rails app, you will get the worst of both worlds. So, my recommendation stands. Knowledge of Ruby and Rails does not help in understanding Elixir and Phoenix. There are superficial similarities, but relying on those to guide you at all are very likely to lead you to bad decisions. The true similarities between these worlds isn't anything to do with how you write code or design projects, but in their philosophies about making software enjoyable to write.
If you want to flesh out functional concepts, try also learning Haskell or Clojure.
If you just want to see examples of the benefits of the BEAM VM+OTP runtime for parallelism, most of those examples will probably be written in Erlang, not Elixir, since Erlang is the one that's in heavy production use. I'd suggest looking at CouchDB's view indexing or ejabberd's pub-sub for examples of Erlang parallelism engineered to work "at scale." Once you see the point of the *Erlang runtime's* approach to parallelism, you just need to learn how Elixir allows you to *express* that parallelism. ...though it's important to note that you often won't *need* to code any inherently-parallel operations yourself. If you're coding something like a RESTful API server, for example, the "parallel part" consists of the Erlang HTTP-server application's connection worker pool†, and your code just provides a delegate module for those parallel workers to call into. You almost never need to actually do anything parallel *for the sake of performance* yourself; there are libraries to give you solid abstractions for every occasion. (You *will* still be declaring supervision trees with multiple children, but not for the sake of parallelism. Rather, for *fault-tolerance*. Load-balancing operations to a set of worker processes means that your requests can trigger edge-cases which crash worker processes, or stall them for long periods, without that impacting the availability or performance of your service as a whole.) --- † With the most common HTTP server app, [cowboy](https://github.com/ninenines/cowboy), Cowboy is *itself* a delegate module. The real parallelism exists in [ranch](https://github.com/ninenines/ranch), whose workers are handlers for raw TCP/UDP sockets. Socket events from Ranch are passed to Cowboy, who in turn translates them to HTTP events and passes them to you. It's ridiculously elegant and extremely fast.
thank you for your work on elixirschool. I just finished it up a couple days ago. Very well done
I don't think elixir is 'like ruby' any more than english is 'like french'. just borrowed some words / ideas, but very much it's own thing. I would actually recommend starting with [learn you some erlang for great good](http://learnyousomeerlang.com/content). Erlang &amp; elixir share the same vm and most of the same core concepts, including OTP. The syntax isn't really all that different either. If you ingest all the concepts in that book you really only need to do the tutorial on elixir-lang.org to get what's different and you will be good to go. 
Thanks, that's great feedback. I would eventually like to cover more advanced topics like OTP architecture and more on the topics of concurrency and distribution. I don't have a "finish line" in mind for Elixir School. So long as the language continues to grow I'd like lessons to grow with it. Thanks again :) 
Not only does it reduce conditional logic, not only does it reduce the amount of code you must write... it also reduces the potential bugs from that logic you're no longer writing, which also means you may not need as many tests. Guards also help with this.
[Alias, require, import, use](http://elixir-lang.org/getting-started/alias-require-and-import.html)
Ahahha thanks a lot ! From what I have seen, pattern matching seems to be awesome :D
At first it's like wait, I'm defining this function multiple times?? Then it's like, *EVERYTHING SHOULD WORK THIS WAY*
No, different. There are cases where you could use pattern matching instead of conditional logic that would make the code less readable. That's why Elixir and Rust still have an `if` statement, even if it desugars into a pattern match.
I don't think a lot of people really think a function being defined is that weird. For instance, Java has method overloading and the basic concept of method overloading is like pattern matching lite.
I would use a pooling system like poolboy or sbroker. The pool is responsible for knowing which processes can take on more work and directs it to that process.
It's great that you can define nodes to cluster with so simply, but what if you want to provide these nodes on the fly, and remove them from the list if they go offline (for example, if you have servers running inside an Autoscale cluster in AWS), and you don't know which nodes exist at runtime (`mix.exs` is being built at compile time if you're using `exenv`, from what I read)?
&gt; but thinking at the wrong level. I never stated a level. I dont believe that RoR knowledge will help in a major way to learning Elixir/Phoenix (I'm still learning Phoenix so I couldn't even make such a claim). All I was saying is that, the following statement: &gt; Knowing the latter [RoR] does almost nothing to prepare you for the former [Phoenix]. is not very accurate. RoR knowledge will make learning *some* (a agree only a few) aspects and concepts of learning Phoenix, faster than it would be for someone who only has knowledge of a framework like, say, Sinatra. 
The help is really helpful, and I rarely program in Elixir without iex up: iex(1)&gt; h File.stat def stat(path, opts \\ []) Returns information about the path. If it exists, it returns a {:ok, info} tuple, where info is a File.Stat struct. Returns {:error, reason} with the same reasons as read/1 if a failure occurs. ... The Erlang/Elixir approach is to check the status by binding: {:ok, stat_info} = File.stat(file_name) stat_info.access But you can still do the one-variable thing... awkwardly: result = File.stat(file_name) elem(result, 1).access The status check is preferred because it gives you error-checking while simultaneously providing the data you want and being explicit about exactly what scenario you intend to handle.
TIL of `s`! Very useful!
&gt; {:ok, stat_info} = File.stat(file_name) Question for you about this line. Absolute beginner with elixir here. This would match if the first element in the tuple is `:ok` but would not match on `:error`. What would happen in that case? An error/exception throw? Can you do something like this? If not, how do you handle the error case gracefully? if {:ok, stats} = File.stat(file_name) do # something else # handle error end
If you want to conditionally handle the 2-tuple calls, the idiomatic way is to use pattern matching with case: case File.stat(file_name) do {:ok, stats} -&gt; IO.inspect stats error -&gt; IO.inspect error end You can even deep-match into the actual stat of the file struct so you can match on multiple conditions in a really terse but expressive way.
I think a lot of your questions revolve around the differences between behavior and state generally, so I'm going to try to address them individually and kinda sum up things at the end. And just to make sure you're not confused, when I say behavior, I usually mean what the app does...the code/functions you define. **Behaviours** So, one thing you might have to break yourself of is the mind-link (this was tough for me to break when learning Erlang) between a module and a class. Classes encapsulate state and couple behavior to that state more generally. You can *almost* think modules as a class that only has constant static methods. The analog of Behaviour in the classical OO world is an Interface. It's a way of compile-time checking that you obey a contract. You tend to use behaviours to have the compile enforce that you have implemented the contract. But you are right, behaviours do not do anything but enforce contract correctness (that you've defined functions that obey the type signatures in the behaviour specification). **~~Mix~~ OTP Applications** So, you can think of applications kinda like libraries at first. But there's something slightly different about them. Applications are just the way that modules are grouped together, and all the libraries on hex.pm are OTP Applications. Applications can also implement a start callback if they are going to be maintaining some internal state on their own by managing processes on your behalf. And because they have state, and because applications might depend on other applications, applications also declare their dependencies which must finish starting before they can themselves start. These declarations ensure that when you start your app, after you've declared your dependencies, so that you can't accidentally invoke a function that messages a process that doesn't yet exist. When mix starts your application, it figures out how to start different apps in the correct order for you. Also, if you package up a "release" (a way of bundling your application into a redistributable tarball with start/stop scripts/management), the tools will read your application dependencies to try to keep the code size small. If you don't depend on it, it won't ship with the release. tl;dr: All libraries are applications. If they have state, then these applications can be started, which acts kinda like a per-app "main". If they don't maintain state, they just don't register a start callback, and are just like a normal code-only library. **Agents** Agents are basically about state. State only lives as long as the process it is in. If you were to break a class into component parts, 2 of the most important of those parts would be state and behavior. All the behavior is in functions. But processes hold on to state. Agents are a simple API to have a process just wrap a data structure and wait for updates. They are built on top of GenServer. If you were using a webserver, and you wanted to keep track of all the hits across all your processes, you can keep track of the state inside of an Agent. I think you're really close to understanding this. One of the things that doing anything fp-ish does is it gives you another set of primitives you use to think about programming, and these seem (to a lot of people, at least) to be slightly more fundamental primitives than the ones OO gives you...and by more fundamental, I mean that you can "build" OO on top of them...whereas it seems a lot weirder to implement a FP language with an OO one (though it is obviously possible).
+2 for Dave's book, *especially* if you have a Ruby background. The thing I really like about his book is that he explicitly goes into all of the Ruby conventions that Elixir borrows (e.g. keyword map shortcuts, implicit maps when used as arguments, etc) making it a very easy transition.
I can tell you that you're close to understanding these things. Keep going! One thing that was difficult to wrap my mind about, coming from OO, is how to handle state (values). In OO you can just stick it everywhere (class instance attributes, etc.), but it turns out that that is (arguably) bad because it leads more rapidly to deep technical debt as a project grows, more difficult concurrency, etc. etc. It literally took me YEARS of Ruby dev to realize why "sticking state everywhere" is bad (in fact, I started programming Ruby in a "functional style" without even realizing it, as a natural consequence of realizing these things), so it was pleasant for me to discover that Elixir/Erlang handle state very carefully, almost like a "live" thing that has to be managed carefully (such as putting it in an Agent process which basically passes the state back to itself as an argument or message). I believe this is a good architectural decision/language feature. Hope you enjoy your learning process! BTW, "application" is almost a misnomer (coming from other languages). Dave Thomas has a blurb about that term in Programming Elixir, if you have that book.
It's interesting to note that the gen_server code doesn't actually know whether or not a module implements the behavior. The compiler is the only one who knows whether a module claims to implement the behavior. From that perspective, behaviors really are just for developers to be thorough.
I got it when it came out. It's fun enough but there's other books I'd buy first
Generally, would it be better to be more specific about the return value on the off-chance that something other than {:error, reason} is returned (future API change)? It seems like a classic case for crashing because it is completely unexpected.
Or it is liter-alley a defiant entry on the list 
This is great. I was running into an issue parsing some maybe-there-maybe-not nested map from a JSON response yesterday, and the odd control structures and fallback assignments I built were very ugly. `get_in/2` supports non-existent keys and will just return `nil` if nothing is found. Fantastic. 
I did actually solve it! Thanks to help in #elixir I removed the auth header that was already in the code and then the bearer-token would be set correctly, this is due to how the package merges existing headers I think defp getToken(code) do token = Reddit.get_token!(code: code) newheader = token.client.headers |&gt; Enum.into(%{}) |&gt; Map.delete("Authorization") |&gt; Enum.into([]) put_in(token.client.headers, newheader) end 
Cool, glad you were able to figure it out.
I have tried it along with just about everything else. Is it the most comprehensive resource? No. But it is enough to get you writing code and, at least to me, highly entertaining. I think the entertainment aspect in technical learning might be a little underrated. I enjoy learning new languages, but I'm far more interested in building things. I appreciate the effort Rob put into doing something a little different. If you regularly abandon technical books (I rarely wade through all of the content when starting out), give it a go. For me, getting enough knowledge to write code is my first objective. The gaps can be filled in later or as needed.
This was a big problem for my recent project. I would love to see Elixir solve this even more, so that you could just write `mymap.foo.bar.baz = "my value"` **Edit:** I originally argued for the ability to write mymap.foo.bar.baz = "my value" because I don't like `put_in/2`, but I believe my idea is not well liked for a few reasons (see the comments). But I'd argue that mymap = put_in(mymap.foo.bar.baz, "my value") violates a worse rule: `put_in` shouldn't have access to the full mymap, but it oddly (and entirely invisibly!) does by way of using a macro. How is this excusable? Good luck to new developers. Elixir does have `put_in/3` mymap = put_in(mymap, [:foo, :bar, :baz], "my value") But this is apparently ugly enough that we felt the need to develop `put_in/2`. Since I'm apparently not good enough with programming language design to propose a solution, I'd love to hear others' opinions...
Wouldn't be possible. The reason `put_in(mymap.foo.bar.baz, "my value")` works is because `put_in/2` is a macro.
Elixir syntax is very regular, and most the language is implemented as Elixir functions and macros. You cannot implement this with functions and macros, so it would be be a deviation from the normal Elixir style.
I did and I liked it better than the elixir tutorials but I still found it lacking. Testing seemed to take a back seat and honestly, it's so so so so so important to test your code especially when you are just starting out.
&gt; we have the problem of assigning to functions If I write mymap = %{foo: %{bar: %{baz: "my value"}}} mymap.foo.bar.baz = "blah" We get ** (CompileError) iex:4: cannot invoke remote function mymap.foo/0 inside match (elixir) src/elixir_translator.erl:234: :elixir_translator.translate/2 (elixir) src/elixir_translator.erl:218: :elixir_translator.translate/2 (elixir) src/elixir_clauses.erl:26: :elixir_clauses.match/3 (elixir) src/elixir_translator.erl:18: :elixir_translator.translate/2 I don't see why elixir can't have a clause to distinguish a map from a function here using `is_map`. &gt; we would still be introducing an ambiguity In your example, you say that the evaluation order should determine the result, and that it is ambiguous. I disagree that it is ambiguous, as the answer to your example should be `%{bar: 1, baz: 2}`. That's because 1 gets assigned to `foo.bar`, and 2 gets assigned to `foo.baz`. Why would either assignment impact an unmentioned variable?
Excellent write-up. I was gradually coming to the same realizations. PS Minor comment: Ecto models are now deprecated and will be removed in 2.0
I can't wait to see more best practices blog posts, always very informing and help me learn the language better!
&gt; In your example, you say that the evaluation order should determine the result, and that it is ambiguous. I disagree that it is ambiguous, as the answer to your example should be %{bar: 1, baz: 2}. That's because 1 gets assigned to foo.bar, and 2 gets assigned to foo.baz. Why would either assignment impact an unmentioned variable? Don't know what unmentioned variable you are referring to. Currently Elixir only has the concept of assigning to simple variables, so when you add the concept of assigning to nested maps you have to define the semantics for it. For example what would with this code do: foo = nil {foo, foo.bar, foo.baz} = {%{}, 1, 2} Or: foo = %{} {foo, foo.bar, foo.baz} = {:atom, 1, 2} Do you see how evaluation order inside expressions starts to matter and we would have to introduce it into the language? You may know that `{a, a} = {1, 2}` raises a MatchError. It would be impossible to keep the same match error semantics when introducing nested maps. How would you generate code to make the following raise with the correct MatchError? foo = %{} {foo.bar, foo.baz, foo.bar} = {0, 1, 2} Additionally we cant generate code for function heads so this type of assignment wouldn't work there. We would be introducing an inconsistency in the language where nested map assignment wouldn't work everywhere where pattern matching works. EDIT: As I hope you understand the reason Elixir doesn't have this functionality isn't because the language designers ignores it or don't care. The reason boils down to Elixir being an immutable language and that assignment in Elixir doesn't work like in other languages. In fact assignment is much more powerful in Elixir than most other languages (because of pattern matching), but that does limit what we can do with assignments in other aspects.
Are there any rails/sinatra helpers for that?
Not that I'm aware of. You can use dig in MRI 2.3, otherwise you have to write a chain of `if x.present?` statements.
Btw, for benchmarking, `:timer.tc` and friends is a bit easier to deal with.
I knew there were other things lol 
Good stuff. I would point out that adding methods get, all, etc to the model is an anti-pattern for elixir/erlang. Yes it's comfortable if you come from rails but it's very OO based thinking. In elixir world your models should not define behavior. Behavior and data should be kept separate if possible. 
This seems like a fun library to play with, but I'm not sure I like the codification of convention (i.e. the naming convention) because it creates a coupling between your application layer and the data persistence layer, which is at its core the same issue that causes so many headaches with the ActiveRecord pattern.
+1 to this. Chris McCord (author of Phoenix) actually wrote a similar ActiveRecord like ORM called [atlas](https://github.com/chrismccord/atlas/commits/master) but it has since been abandoned ever since Ecto came on the scene for these very reasons. Your models (or now Ecto calls them Schemas) should simply produce the queries. Your controller is where all your side effects belong (which include interactions with your Repo).
Add manager: :make to the deps definition in mix.exs.
Well, you can pass the schema to overrule the default schema assumptions. Also, I will be working on writing a module which interacts with Ecto models in order to be able to make composable queries. SqlDust will use the Ecto models to get the schema information.
Seems like it should have worked, but it didn't. I ended running make in the erlydtl dir, then copying the .app file in the ebin dir into build/dev/lib/erlydtl/ebin/ That seems to have worked, though it's inelegant. 
I made a mix "compiler" for erlydtl files. http://www.cogini.com/share/elixir/erlydtl.ex Put it in lib/mix/tasks/erlydtl.ex It takes files in the "templates" directory like foo.dtl and compiles them to ./_build/dev/lib/xxx/ebin/foo_dtl.beam In mix.exs, add it to the list of compilers in the project section. def project do [app: :xxx, version: "0.1.0", compilers: [:erlydtl] ++ Mix.compilers, erlydtl_options: [source: "templates", compiler_options: [:debug_info]] deps: deps] end Add :erlydtl to the list of applications and {:erlydtl, github: "erlydtl/erlydtl"} to the list of deps. Then in your code you can call :foo_dtl.render(...) with a property list of parameters. 
Author here: I agree with both of you. I'm an hardcore fan of the declarative nature of the SQL language, AR has never really grown on me, but I'm all in for giving people choices. Having said that, the point wasn't to encourage people to use AR, but to show how easy meta programming is in Elixir and not to be scared by it: you're not going to lose performance, you're not going to create a mess, the compiler will help you to get it right. AR is probably the most famous pattern around, practically every developer knows it or has been exposed to it, it seemed natural to show how to do something in the way many already find familiar. Besides, rewriting AR (or more realistically, a small part of it) could be a good exercise for those coming to Elixir/Phoenix from other languages/frameworks, especially Ruby/Rails. Thanks for pointing me to Atlas, I didn't know about it. 
Just so we're clear, Atlas was basically a project that served two purposes for me: 1) what not to do with metaprogramming. Lots of abuses 2) that Ecto's Repo pattern is leaps and bounds better than AR Atlas starting looking more and more like Ecto as I studied Ecto's design, to the point that I knew the correct way to build the lib would end up recreating Ecto, but doing it poorly :) 
Why does elixir have these 2 ? what are they used for, if they are different?
interesting stuff... despite my reservations, it'll be cool to see where your project goes! I have a (poorly maintained, yet functional) gem called Tabloid that lets me put an activemodel interface around a parameterized straight-SQL query which I use for custom reporting in a lot of projects, which I've considered porting to elixir if only to make my job converting my old projects to elixir easier. This felt like a similar project at first, although it looks more like you're creating a less verbose or less explicit version of ecto.
Why can you not read the link he gave you which already answered all your questions?
is_binary only returns true in a guard if it's a double-quoted string. throughout Elixir, generally speaking you should use double quoted strings. Single quoted strings are more of a syntactic sugar for lists of ASCII values that are interpreted as a stringlike IF they are all printable, which is an Erlang thing. To prove this, open up an iex prompt and enter [65, 66, 67] and hit Return. You will get back 'ABC'. Meanwhile, if you enter [21,22,23], you won't get back a single-quoted string, because those ASCII values are not all printable.
Just thought I'd share an experimental project I've been working on. I understand that it's common to do use tuples like {10, :pence} to prevent accidentally adding numbers together of the wrong type. I thought it might be useful to have a library to help manage this automagically.
&gt; Ecto's Repo pattern is leaps and bounds better than AR Care to elaborate why?
I would second the strong suggestion to have a focus on testing in any tutorial. Remember that testing doesn't just check your work, it actually makes your code better, because code written to be easy to test also happens to automatically be easier to work with from other code.
Well and I know for myself when I am learning a new language, I know I need testing as a sanity check to make sure what I'm doing is 100% correct
What does BOT stand for?
It doesn't stand for anything; it's a shortened version of the word "robot".
lol
I'd actually argue the opposite approach. Startswith Tasks or Agents and then move to GenServer if you need the flexibility. Ideally you want to wrap whichever you use in another module, providing a pass through for start link and some helper functions for access. Then, you can swap out the implementation without breaking any code external to that module.
&gt; actually passes access to the whole map into the put_in method by way of a macro, even though it appears to only pass the value of baz. It's weird things like this that what make new languages hard to learn. I'm unsure what actual confusion this is causing. Would you care to elaborate?
I presume that this is the author posting, if not I apologize. Welcome to Elixir! I hope your adventures are pleasant. You should seriously consider implementing this as an OTP application with a supervisor and a GenServer. This implementation has a lot of reinventing the wheel and this wheel is very well understood and battle-tested in its generic OTP form. It seems that this game has a save/restore feature where the game state is saved as a bitstring. Figuring out how to stash that away in case the bot crashes and then restore to that saved state would be a good lesson for you and your readers. A stylistic concern is that file names in Elixir are generally written in snake_case and modules in CamelCase. Thus the name of your app would be swarm_simulator_bot (including file names) and the corresponding module name would be SwarmSimulatorBOT. I hope this gives you something to chew on. Keep it up!
Elixir eventually parses to the same AST as Erlang and then is compiled to BEAM bytecode. I don't know what difference you think this might make.
Sure. So the output of `put_in(mymap.foo.bar.baz, "new value")` includes all of mymap, where baz is updated. For it to work that way, `put_in` has to receive the entirety of mymap as an input. From the example, you can see that mymap doesn't seem to be passed into the method. But the method actually receives the entirety of mymap using a macro.
Love what you've done! I'm not a big fan of the &lt;~ macro that you've used here, because in my opinion it makes it a bit non-standard to read, bit I like the library otherwise!
thanks very much for the answer. so, i should use the double quoted ones? could you show me how to iterate through double quoted string? let's say i want to reverse it. so for example "reddit" becomes "tidder"... i know i just can use the available API. but i want to learn, how to iterate and manipulate double quoted strings. maybe reversing is trivial. i can't do easy string manipulation, something like adding another string inbetween. so "reddit" becomes "r3e3d3d3i3t". it just adds "3" in between the characters. reading API and docs, i'm just stuck, i'm still very new in functional programming. :(
For clarification, I think what you are saying is that for someone new to Elixir, seeing code like: mymap = %{foo: %{bar: %{baz: "initial value"}}} mymap = put_in(mymap.foo.bar.baz, "new value") Should be equivalent to this: mymap = %{foo: %{bar: %{baz: "initial value"}}} mymap = put_in("initial value", "new value") Because one would assume the usage of `mymap.foo.bar.baz` in the call `put_in/2` is to provide the value `"initial value"`. However, `put_in/2` is using `mymap.foo.bar.baz` as `mymap.foo.bar.baz`. I do agree that without much knowledge of Elixir it is awkward that `mymap.foo.bar.baz` can be used as a value or a literal depending on context. Ignoring the dual usage of `mymap.foo.bar.baz` for now, reading the documentation for [put_in/3](http://elixir-lang.org/docs/stable/elixir/Kernel.html#put_in/3) and [put_in/2](http://elixir-lang.org/docs/stable/elixir/Kernel.html#put_in/2) should be enough to know which context is being used. ^** Note the usage of `path` in `put_in/2`. To address the dual usage requires understanding that Elixir has a feature called macros. What a macro does is code transformation before compiling to bytecode. It is code that writes code. Macros is a really powerful feature and enables a lot of great stuff!!! Macros can look like ordinary functions. ^** Documentation and reading source is the only way to know if a call is a function or macro. `put_in/2` is a macro while `put_in/3` is a function. So using `put_in/2`, `mymap.foo.bar.baz` is used as code to generate code that points to the variable `mymap` and the keys `foo, bar, baz`. Probably a good tip for Elixir beginners is be aware whether the call you are making is a function or a macro. If it is a macro, remember that its treating the inputs/arguments as code.
So this is all my personal opinion. Golang is my favorite language to come out in recent times and I've been using since pre 1.0, however, when it comes to web development I've stopped using it. It's pretty ok at making API's with mgo but if you want to use a Relational DB and template rendering it can get nasty and because of the type safety (which I generally think is a good thing) but no generics you end up writing a bunch of functions which are nearly identical for your different types. You most certainly CAN write a Go web app / API it's less than optimal I would say especially if you want it done fast. Good examples of a Go web app: https://github.com/gogits/gogs Elixir with Phoenix by comparison has been awesome to work in and when it comes to web programming I'm pretty hooked on this whole functional programming thing. That said I tried to use Elixir for a smaller project (a small command line tool) and was really disappointed at how complex it made the task vs. just doing it imperatively, that may be partly because I don't have FP as part of my primary work day so don't think that way all the time but largely it was the lack of good library support for doing some simple things (like sending an email) I had to reach into an Erlang library to accomplish that task which was not what I'd call "fun". I think they're both great languages and ultimately it's which one you like better. Phoenix has better web tooling than anything Go does but Go gives you more control.
Thanks! Yeah, wanted to do some querying with the most minimal setup as possible ;) Just added composed queries (SqlDust v0.1.0). Busy supporting Ecto models. And then, I guess, I am done for now :D
What about websocket support? Does elixir support better websocket than Go? 
Thanks for the further explanation. I understand that this method can ultimately be explained to a new Elixir developer. But I can only see the frustration in his or her eyes at the feeling of distrust that any method call might not do what it appears to do. Macros certainly can be used to do great stuff to build up the language. But at the same time I find them to be a scary mechanism that will lead Elixir into the gutter if used without care. I already had a developer friend check out Elixir and call me nuts for liking it since it looks too complicated and too hard to deal with. This issue is just one more thing in the bucket.
Cowboy will be getting http2 support in their upcoming 2.0 release, then an update to Plug and Phoenix will support it as well.
I think you nailed it with the last sentence. Go will work fine but you're going to have to spend a lot much time hacking things together where Elixir/Phoenix will give you a awesome framework out of the box. Elixir code also looks super clean compared to Go code IMHO. 
Elixir allows you to use the Erlang ecosystem to as long as you're willing.
What do you mean? Phoenix is implicit? Like Rails with magic stuff? 
There is one more approach for gen_server initialization - using *proc_lib:start_link/3* and *gen_server:enter_loop/4*. [Example here](https://github.com/nwalker/flussonic/blob/master/apps/rtmp/src/rtmp_socket.erl#L96-L139). IMO, it is better than timeout/setup info.
I think you might need to be less vague. What is it you want to do?
It will definitely do a lot for you automatically but it's not magic if you know elixir is very easy to understand everything they're doing. You should read the Phoenix Programming book from Pragmatic Bookshelf they walk you through how every piece works.
Awesome - that looks great and is new to me, actually. I'll add a note for that later today. Thank you.
I come from a Java/C background, and I used Programming Elixir by Dave Thomas to learn. I'm working on a list of issues. It's about a page and a half. Where's the best place for sharing? Right here inline?
I know that there is a connection between elixir and ruby, but the language itself it's completely different in almost every way. You will find elixir to be very explicit mainly because it's a functional language without mutability, as oppose to ruby's imperative nature. Elixir does support some metaprogramming which you can consider 'magic' at times and protocols (aka traits) which are kinda similar to mixins (although mixins are more flexible). All this in terms of working with state in a concurrent system leads to a clearer and safer solution (imo) because state is very explicit.
While I would second what /u/midnight_swim said, there is perhaps a bit more. When people say that code is 'explicit' or 'implicit' they are usually making a statement about how easy is it to accidentally do something unintended because you don't really know what's going on. Ruby makes it very easy to create systems which do things behind the scenes which are both amazing and difficult to fix. Elixir makes this a little bit more difficult, but it is still a distinct possibility. It is still possible to write magic macros which write unknowable code. It is still possible to send strange, unexpected messages to key processes which do something fancy, but the developer is going to have difficulty understanding. I think the more important thing is that the leaders in the Elixir community have learned the fear along with the joy of working in Ruby and are going through great pains to provide much of the benefit of metaprogramming and custom DSLs while working to avoid the pitfalls of large implicit systems which break inexplicably and irreparably. As a case example, compare Rails and Phoenix (as many often do). In Phoenix, the control flow of a request is right in front of you in just a couple of files. If you install a new dependency which needs to be in the middle of that control flow, yes, you have to put it in there yourself, but it also means that dependencies are mucking things up without your realizing it as is so common in Rails. The Phoenix devs learned the lesson that if you feel the need to hide complexity, then you are probably better off with a less complex way of doing things. The community and its self-regulation to avoid patterns which produce inscrutable code is its greatest defense against the worst horrors of implicit code. The language developers are trying to provide good examples and we inherit so many great tools from Erlang and OTP that we might be able to pull it off, or at least make strides in the right direction.
No it's not.
Just released SqlDust v0.1.1 :) It supports composable queries using Ecto models https://github.com/archan937/sql_dust#composable-queries-using-ecto-models
I like the enthusiasm (even if it will be divisive) but Phoenix has a long ways to go to get the kind of gem library support that Ruby and Rails have to build a full-featured website. As a trivial example, I still don't think there's a connection-throttling library to prevent, for example, brute-force attacks on a given endpoint. That's one example, here's another- Is there an equivalent to [Paperclip](https://github.com/thoughtbot/paperclip) yet, to help handle the really annoying intricacies of multi-part file uploads and the associated form? But I do somehow feel "more enabled" by coding in Elixir than in Ruby, that's for sure. Even if that means I might have to code some things on my own... which, of course, is the same feeling Ruby gave that got the Ruby gem library to be as burgeoning as it is today...
Ok this is just what I've discovered looking through the source code. Of course I've done some exploring myself: https://github.com/olafura/beam_to_ex_ast So the elixir source code gets turned into quoted form which is Elixirs AST, it's what is used in macros and other tricks. You can test it out with: Code.string_to_quoted This is done in Erlang code: lib/elixir/src/elixir.erl :elixir.string_to_quoted So this form sort of gets turned into directly Erlang AST, and I say sort of is because it's doing some compositing to do with module information I believe. Look at: lib/elixir/src/elixir_translator.erl lib/elixir/src/elixir_compiler.erl So Erlang AST can be turned directly into beam code or Erlang code. See: http://stackoverflow.com/questions/29621196/erlang-beam-lib-chunks-is-broken
Hey Alex, missed your comment... No, I haven't deployed anything with drone yet... I hope to do that soon and write the experience down, but it might be in a couple weeks... Maybe this demo repo helps a bit: https://github.com/drone-demos/drone-with-elixir/blob/master/.drone.yml + one of the avail. plugins: http://addons.drone.io/ Best, Roman
Pinterest built their rate limiter API in Phoenix with a 90 or 95 percentile speed of 800 microseconds (not milliseconds), what makes you think connection throttling is all so necessary or isn't already handled somewhere else you're unaware of? Secondly, no one uses paperclip, carrier wave is far more popular, but yes there is a library called Arc I believe that handles all that same stuff. There's Gaurdian which handles authentication and/or authorization in a decentralized fashion using JWT as well as many other things you'd want in a standard app. I personally am seeing all the new fresh ideas being put into the elixir language more so than Ruby/Rails but that's just a personal observation. Yes you're correct the small time game as far as library support has yet to be mopped up, but there's plenty of good stuff on hex.pm if you search for it. If you need some domain specific stuff you'll have to check if it's available in elixir/ruby and decide if the cost of porting is worth it if it's not available. Other than that there's very little reason to use Rails anymore. 
Always interesting hearing José talk. I do wish the hosts had better questions around the concurrency of Elixir. IMO that is the distinguishing feature from other languages such as Node or Go.
Nice work!
This isn't necessarily true nowadays. Node 0.8+ supports the [cluster](https://nodejs.org/api/cluster.html) module which lets you run a Node.js app across multiple cores. You can use [start-cluster](https://github.com/ericclemmons/start-cluster) or [pm2](http://pm2.keymetrics.io/) (with `-i 0`) to take advantage of this feature.
thankss .. this is great, i don't know you can do this: def reverse(reversed, &lt;&lt;first, rest :: binary&gt;&gt;) do reverse(&lt;&lt;first, reversed :: binary&gt;&gt;, rest) end
i'm happy that i've chosen elixir. never thought that functional thing would be this beautiful. moving from php to elixir, is like breathing a fresh mint air. i hope that elixir will be the next big thing.
This is neither here nor there but you calling my code "beautiful" (even if I stand on the shoulders of giants) just brought tears to my eyes lol I am happy as hell to share it
Big user of Chocolately and Elixir. Much appreciated.
You're welcome. Glad to see it's helping! 
I use it for development, yes. I work on a couple different projects with different Elixir versions.
I've used exenv, but wasn't entirely happy with it. Kiex is my next stop I think.
TDD is definitely awesome! About windows, I haven't done win32 programming in a while but this kind of thing is always a pain, C# or Java have nice wrappers over their APIs but it can certainly be done with c++ and then you can communicate with it via ports or NIFS (Specifically for this I would choose NIFS as its easier and you can just let it crash without the awkwardness of ports communication). Also I would just point out that your solution is Linux only and would also not work with OSX.
Sorry I skimmed too quickly over the readme, I thought you used inotify directly. I'll give it a try tomorrow at work.
Exenv works great for me, in conjunction with elixir-install. I'd recommend it. What was your pain point?
I use kiex. I blog about Elixir (in fact I blogged about kiex recently) and sometimes I want to install Elixir master to try out and write about new features. Kiex has been helpful there.
I haven't had a chance to use it yet, but this looks very promising https://github.com/HashNuke/asdf
I use Kiex. 
Good to know! 
You have already done the hard bit, breaking down the problem into a series of transformations. It's perhaps not the algorithm I would have thought of, but it seems sane. You don't seem to need to access any individual word's current counter randomly, so no need to put this in a map, just use a list of tuples. Here is the basic structure. char = "f" [{"foo", 0}, {"bar", 0}] |&gt; Stream.map(&amp;increment_word(&amp;1, char)) |&gt; Enum.map(&amp;print_and_reset_complete/1) Then we just need to define the actual functions. def increment_word({word, count}, character) do new_count = if String.at(count) == character, do: count + 1, else: 0 {word, new_count} end def print_and_reset_complete({word, count}) do new_count = if String.length(word) == count do IO.puts "Found #{word}" 0 else count end {word, new_count} end Each of these functions is small and simple to reason about. The control flow we started with is expressive. The output is going to be another string of {word, count} tuples with updated counts. Of course, some error detection would be nice (if a count somehow is outside the bounds of possible word lengths, for instance). I hope that helps.
Thanks for your reply, you're right I don't need a dictionary and I tend to abuse them. Could you clarify a bit what do you mean by saying that the control flow we started with is expressive? Thanks for your help. 
I use this every day (and have been for months). Thanks for your contribution. 
This can be read as a natural language sentence fairly easily by someone familiar with a few things in the language. I will translate. Given a character char = "f" take my word list [{"foo", 0}, {"bar", 0}] and for each one, |&gt; Stream.map increment matches giving me a new word list (&amp;increment_word(&amp;1, char)) then for each one, print and reset complete words, giving me a new word list. |&gt; Enum.map(&amp;print_and_reset_complete/1) You have to know what Stream.map and Enum.map do, but these are such common structures in Elixir you pick it up pretty quickly. Other than that, it pretty much reads top-to-bottom left-to-right and says what it does. &gt; you're right I don't need a dictionary and I tend to abuse them. By the way, if you did, for some reason need a map (Elixir form of dictionary), you could do it easily by adding the following to the end of the pipeline: |&gt; Enum.into(%{}) And your tuple list would be used to generate a map.
Not long ago I did a LOC count of Phoenix and Rails and Phoenix was something like 1/10 (or less) the size of Rails in sheer code complexity, so that alone makes them incomparable to me. Phoenix is more like a thin layer on Plug which is more like Rack.
Thanks so much for your explanation, as you said the algorithm is quite evident from the code. That's nice. 
I have to agree. I'm personally not a big fan of the 'rails way' of doing things or a fan in general. The experience I have with Rails (which I admit, is quite limited) is always feeling like I'm carrying along something heavy. I can definitely see the issue some people have while comparing Phoenix with Rails. Communication is indeed the problem here though. Ruby and Phoenix both have their strengths, but most of the similarities stop at the syntax. Personally I feel that Phoenix definitely shouldn't advertise itself as a 'Rails' replacement, although we can definitely hope it gains a similar amount of interest from developers around the world.
Thanks I'll have a look there. I read the whole wiki on their website and they specifically said that it's not possible due to some issues in windows or powershell... Thanks anyway
No, thank you. Really cool to hear :)
Thanks
You're welcome and thanks for the star! ;)
I wonder if the slower start up time for the first request really is due to DNS or is it due to TCP's [slow start](https://en.wikipedia.org/wiki/Slow-start) algorithm - this would be the case if hackney reused TCP connections through the HTTP persistent connection mechanism. Anyways, thanks for writing this piece, it was a good read.
Actually, I've just realised that the request only returns a plain json. So slow start shouldn't be an issue.
The simple way in elixir would be recursion or Enum.reduce(in other scenarios where a accumulator can be used to modify a result within the iteration). In this problem, the modified map can be passed to a recursive method, until it finds the result. To give an example with just one word to be found, I would do like this. defmodule Foo do def find(word) do find(IO.getn(""), word, word) end def find(_char, "", word) do IO.puts "Found #{word}" end def find(char, &lt;&lt; char :: binary-size(1), rest :: binary &gt;&gt;, word) do find(IO.getn(""), rest, word) end def find(_char, part, word) do find(IO.getn(""), part, word) end end Foo.find("foo") 
You're welcome!
5 days...It could be that it is not possible?.. mmm
Yeah, creating an *env tool is basically just running a regex on rbenv, so I'm sure it's a good tool. when I had a few hiccups with it I figured I'd not invested enough into it for it not to be worth checking out the alternatives 
The message that seems to resonate with my rails colleagues is that phoenix gives you the tools to assemble the magic that happens in rails. In rails, you have to fight the magic to do something different. In Phoenix, assemble it the way you like, because the Lego blocks are all right there to see.
Ok, here's my list. * Structs accessed using mystruct[:mykey] causes an error if it doesn’t exist, instead of maps in which this access can be safely used and it returns nil if it doesn’t exist * `[] ++ nil #=&gt; nil`. Is this a bug? * Parenthesis should be required for function calls to enforce code consistency and clarity * There should not be an exception for keyword lists without square enclosing brackets as in `DB.save(record, name: “Dave”, city: “Dallas”)`, same reason as above. * `Alias`, `Require`, `Import`, `Use` - I feel that we don’t need all of these options, and that they should be combined / simplified because it’s too complicated * Functions from Enum should be imported by default. I don’t need “Enum” to be everywhere in my code * Many functions in Kernel belong more to Enum or Dict * Can strings just be converted to binaries automatically when calling Erlang functions? * I need an easy way to define global constants * My code has many instances of this: `message = %Message{message | somekey: “newval”}`. This looks gross, when what I essentially mean is `message.somekey = “newval”`. The syntax doesn’t work for nested values, so `put_in` was added to Kernel. It surprisingly doesn’t work for adding a key, so you have to use Dict.put_new. I don’t know of an easy way to add a nested key. The syntax here is disorganized and unappealing. * The Elixir website scared my very smart friend away * I wish we had real for loops. As impossible as it might be, I’m allowed to still wish for it, right?
Whats your programming background? Can't really suggest much without knowing your current level.
Does it need to be cached in Elixir? If we're talking analogous to Rails, we're talking web services, so there's a good chance you could be putting it in Redis or Memcached instead.
This is fairly easy to implement, would be a fun exercise in learning Elixir/Erlang But also Rails.cache has various configurable backends so if it is talking to one of those you can just interface with the same backend from Elixir code
If you are looking for already built packages then [Quantum](https://github.com/c-rack/quantum-elixir/) should do the job. I think its implemented using GenServer as @Cazrin suggested.
The only glaring one missing is ** I believe I saw indications at some point that it was there. Not sure why Jose removed it, but one possibility is that Erlang doesn't actually include a natively implemented integer power operator, for whatever reason. It does have IEEE floating point power but that has roundoff error for very large and very small values (which means its behavior will differ if you come from, say, Ruby). I ended up implementing my own integer power function here https://github.com/pmarreck/elixir-snippets/blob/master/math_integer_power.exs but I still cannot have it take advantage of the ** operator because the Elixir preparser doesn't recognize that as an infix operator.
Go has no exception model. The designer basically decided they were just a nuisance that could be ignored (but manually checked for). Literally, if anything in your app can break, you have to check it after every line, or Go will just skip the error. This is incredibly stupid IMHO. Elixir, like Erlang, takes a very different tack. Elixir *embraces* failure (which is going to happen at some point no matter what) and focuses on restarting quicker. If something goes wrong, the stack trace is logged and the node is restarted by its supervisor process... In a millionth of a second. So as a programmer you just sift the logs to find states you forgot to account or test for, and fix those and redeploy. If you're going to write a web service that can potentially accept ANY input... Which would you expect to work better?
Setting up massively complex architectures for no reason is dumb, but having small-n dependencies like database, redis, etc. won't hurt you &amp; will probably have a far more reliable and maintainable solution than anything you come up with one-off.
No, it really is. Chocolately isn't nearly as big as Homebrew but it's pretty essential with how I manage software on my Windows machines. Thank you for contributing to a better Windows ecosystem.
Looks promising. Are you the author?
Nope.
&gt; I offer a highly unscientific approach to come up with a gut feeling for that. You know, if we had to wait for "scientific proof" or even just a quantifiable rationale on why we should switch to a whole new development platform, I suspect we would all still be programming Cobol or even Fortran; because it's really hard to be scientific about it, if not impossible. In the end, software is about community and while it's technically true that Rails will work more or less "forever" in the technical sense, it will still likely fall out of use completely at some point simply because the community has moved on. It's a basic tautology that has no real logic to it. The software is viable because the community is viable and the community is viable because the software is viable. Etc. Witness the PHP community for proof that software viability is determined this way without real regard for its superiority. BFDLs like Jose, Guido, and Rasmus have all basically created a community from nothing by simply being the ones to create the foundational technology. How cool is that?! Sorry, OT. Just having some wonder over here. Probably too much caffeine. 8}
Well, what else do you want to use it for? I can tell you that it's not an ideal choice for writing desktop style rich applications, though that may be possible I don't know. We don't know what else you'd want to do with it.
This looks awesome. I was toying with Spacemacs due to the alchemist plugin but even after several attempts couldn't quite get there. All seems to work ok (though I'm not sure I quite get the macro expansion pieces - doesn't quite do what I thought it would).
FWIW - I've gotten a lot closer to what I would like to use with Atom. I'm not really proficient with Emacs either though.
2 days in, it's super close to feature complete already
[this](https://upcase.com/videos/intro-to-elixir) is the only reference I could find about the Constable project, and it states clearly that is an internal tool (I was curious too :P). Quoting: &gt; Recently we've been working on an internal communication tool written in Phoenix, a Rails-like web framework for Elixir.
That new sandbox feature is *fantastic*.
Most things you would think of as keywords in other languages are macros in Elixir, implemented in Elixir. Check my NDC Oslo talk for an introduction to this idea https://vimeo.com/131643017
Yes I was thinking about that too, in JS the code checks for multiple formats passed to the parse function. I will learn more about the File and Stream modules in elixir and make the change.
Good ideas.
Will check your implementation, and if more fitting for the task will use that. There was no particular reason why I chose it, it was the first in the list, and was working. Can't really make suggestions, just started diving into torrents and elixir :)
Thanks I haven't had to do much debugging, because simply manually testing functions in IEX REPL has worked great for me until yesterday. Finally, have a integration test that fails strangely that this will be great for i'm sure.
Should the worker be a GenServer? Or just implements start_link.
I don't know about Elixir-specifics, but in original Erlang-OTP the name of the start function is freely choosable. Since I haven't worked with Elixirs `supervisor` so far, I have to assume, that it is simply wrapping around erlangs supervisor with a nicer API. So it should be enough if the child implements `start_link`. The `worker/3` function does even allow you to specify another start function. As far as I can remember it is important to return `{:ok, PID}` from the called starter. At least it works this way in Erlang. `gen_server`s do this more ore less automatically if directly wrapping to it, while for non `gen_`* you need to manually build that tuple.
[Here's the module in question](https://gist.github.com/nemski/c802202c33d17a54f2fd) The worker starts, the process is still alive but nothing is getting pushed into the Agent. I've tested this with just Task/Agent model and it works and I've got tests around my other components, but this isn't doing anything. Also not receiving any messages on the parent process.
It seems to me that you started learning the language, you learned that recursion is how loops are done and you started implementing recursion all over the place. The first thing to know is that recursion is usually implemented in the same few ways and there are helpers which implement these patterns for you. For example, Enum.map is recursive under the hood, but it implements a very common structure where you just provide the mapping function. GenServer is just a more rich, complicated Enum.map. It handles all of the recursion for you and you provide a set of callback functions which get called either for the lifecycle of the process, when a timeout occurs, or when a message is received. I would highly recommend reading up in the docs and guides on how GenServer works because you seem to have some fundamental misunderstandings. You have tried to implement a one-shot GenServer which doesn't receive any messages during its lifespan. This is a common enough use-case that a helper been provided in the form of [Tasks](http://elixir-lang.org/docs/stable/elixir/Task.html). You can start a Task as an OTP worker just like a GenServer or even do more fancy things with their supervision, but that is beyond my scope here. Further, you seem to want to be transforming an external API call into an enumeration of elements. You should really consider wrapping this up in a Stream. Streams are, in part, designed for wrapping behavior like this to make it work like any other Enumerable. In particular, [Stream.resource/3](http://elixir-lang.org/docs/stable/elixir/Stream.html#resource/3) is a good place to look. Some combination of Task and Stream would better capture what you are trying to do here.
[Spacemacs](https://github.com/syl20bnr/spacemacs/tree/master).
Sublime
Emacs on OSX has sometimes had a few issues requiring patching. The Spacemacs Readme suggests a particular port be installed. https://github.com/syl20bnr/spacemacs#os-x 
Phoenix is in no way a replacement for OTP, but you don't need to know OTP to do interesting things in Elixir, particularly if you are focusing on doing something in a framework like Phoenix. It is also true that without learning OTP, you are missing out on a huge part of the reason to use Elixir. If you are feeling a bit burned out on learning stuff and you can find something interesting to do which doesn't use OTP, then it's totally fine to take a break and go do it, but if you find yourself continuing to use Elixir, you will want to go back and figure out OTP.
I see.. But I made the question because after watching some conferences about Phoenix by Chris and José, I was left with the impression that the idea behind Phoenix is to make all the OTP processes and supervisors stuff for you. Isn't that true? 
Check out elixirsips.com EDIT: Woops, this is not a free site! Didn't read the post title completely. Carry on.
I believe they are subscription based
Apache Thrift is an example of a possible way to share logic between the erlang vm and .net, assuming theres thrift clients written for both.
Thank you! I'm really glad to hear you find it useful :-)
Explicitly, all floats in all languages have this behavior.
http://0.30000000000000004.com/
One way to solve it would be to avoid floating point math, except of the final step. Stream.iterate(1,&amp;(&amp;1+1)) |&gt; Stream.map(&amp;(&amp;1 / 10)) |&gt; Enum.take(10) Anyway, more like StackOverflow question. 
You can also use Stream.unfold/2: Stream.unfold(1, &amp;{&amp;1 / 10, &amp;1 + 1}) 
Ok, I finally got out of surgery, so I had time to play with my computer again, choco worked like a charm, thanks! :)
Hi, thanks for the answer. So you say that more often than not, a Phoenix app will be part of a larger tree. That makes perfect sense. Your book is great resource to learn Elixir and OTP, it really feels like a conversation, rather than a technical reference. 
That last part was just what I needed! I was feeling a bit overwhelmed. Thanks!
V8 only "destroys" Erlang in purely numeric floating-point operations.
Glad to hear you liked it. Regarding code listings, are you talking about the kindle version? In the pdf version, listings are copy-pastable text.
Yes, precisely that! As soon as you move past some basic demo, you'll likely need to use some OTP blocks, so it's worth learning about them :-) Glad you like the book, and wish you a lot of fun working with Elixir and Phoenix!
Related to this there's a package available for elixir for dealing with arbitrary precision decimals: https://github.com/ericmj/decimal
Thanks you! You answered [my question](https://www.reddit.com/r/elixir/comments/46p5un)
Ok, what I said was that having "small-n dependencies" like Redis was actually hurting me in my current situation, and your response is "that won't hurt you". 
1st of all: Take a chill pill. Now, on with my comment: I just finished the server api for an app in Phoenix. I do not need to compile assets for this so i am not using it (it´s optional). Anyway, i don't think you need to know node, just install it if you need asset compilation. Phoenix will use some node.js libraries to compile the assets (again, only if you need to compile assets). Node is actualy quite good at that kind of work (i use ember-cli and the whole thing runs on node, including creating the final build for deployment). Phoenix wasn't created to support your specific needs. It was created to serve a community that will for the most part need that kind of functionality. If you don't really know what static assets are or why you need them, you should either learn before you start complaining and being rude or ask people nicely. Sorry about how poorly written this is, but i am on a rush.
&gt; Why the fuck is "compiling static assets" such a crucial piece of writing your first web application? It's not. You can pass `--no-brunch` to `mix phoenix.new` if you don't want to use Brunch.
I'll ask Manning why are they using images on kindle. Thanks for reporting!
It's for client-side code. A lot of Phoenix users happen to make rich content and some (like me) are using large SPA's which make asset building essential. Phoenix's philosophy is that it should allow for all sorts of use-cases, but be composable so that you can just opt out of things with no overhead. I mean, there's nothing *I* personally need with CSRF protection, but there's a plug for it and it's enabled by default in the browser pipeline. And I'm glad it's there.
The book is about a lot of things, many of them i don't use or need to learn. Other things i use. I don't get pissed just because they have there things i don't need. I am just happy that they are there in case i need them on the future. Web development **often** requires web assets to be processed for deployment. Rather than reinvent the wheel, developers can optionally use Node.js tools for those services. Phoenix will use brunch.io to compile static assets such as JavaScript and CSS by default, and Brunch.io uses npm, the Node.js package manager, to install its dependencies. The book is pretty clear about static assets: It doesn't say anywhere that web development **always** needs static assets. It says **often** and a few words later **optionally**. Edit: typo
Dont even try client side)
You are right. The JS shit fest is creeping into everything. But your point is being dismissed because of your tone. I have looked a few times at what is going on in Phoenix and it feels like they are going the wrong way. It's hard to explain but the features they are building don't seem to be the best way to take advantage of the language and it's built in framework (OTP). It's like Phoenix is trying to be a carbon copy of Rails in the Elixir environment, and if I'm not wrong, Rails 5 now (by default) depends on a JS runtime and Redis. I think the web layer of an Elixir application should be a peripheral part and not the framework. Front end asset handling is an even more peripheral part of a web application server/backend/whatever-you-call-it.
[V8 vs HiPE](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=v8&amp;lang2=hipe)
&gt; Because the JavaScript-native solutions are going to manage JS asset management better than an Erlang/Elixir solution could ever manage. That's a poor excuse. It's not imagemagick or curl you're depending on. It's Node. You don't see MySQL depend on PostgreSQL because it already had such a nice parser, or vi depend on emacs because it already had such great syntax highlighting. &gt; one of the big selling features of Phoenix is using websockets to communicate This isn't some weekend project or some proof-of-concept, right? It's supposed to be something that's intended for production. If client-side stuff is such an essential feature, then you need to carve it out of Node, integrate it into Phoenix and then own and support it. You can't reasonably tell people on page 30 of your book to go and read this whole other pile of books with hundreds of pages each on a tool that you're ultimately trying to replace because for the foreseeable future it'll be better than what you can ever hope to have. And you can't tell them to just type in some magic incantation and not worry about it either, because eventually things will break down and they'll need to figure out how to get them running again. Isn't that like the whole point of bothering with Erlang in the first place? &gt; Phoenix doesn't write the client-side code for you. If that's what you thought was going to happen, I'm legitimately apologetic that the community has misinformed you. That was not what I thought was going to happen. But I also didn't think that the first thing to do in learning Phoenix would be to go an figure out Node. Much like I don't expect step 1 the Windows Installation Guide to be downloading a Linux live CD and using GParted to set up my hard drive, because GParted is already so much better than what Microsoft can ever hope to have, and besides, why bother duplicating the effort. If the community and the ecosystem is set up in such a way that deferring to other non-trivial tools every x. steps is acceptable, then this is a major issue of the language ecosystem. &gt; It seems these comments are largely reacting to your tone and not responding to your issues. My language reflects my disappointment on the matter. Here's this great language that ticks off a lot of boxes and unlike other researchy crap has somewhat sane syntax and actual traction, and then as soon as you actually want to start doing anything \*bam\* you need to first put up with all the shit you were trying to escape from in the first place. Like I said, it feels like a cruel joke.
&gt; You don't see MySQL depend on PostgreSQL because it already had such a nice parser, or vi depend on emacs because it already had such great syntax highlighting. These are not parallel examples; a dynamic web application isn't a monolith. A dynamic web application is composed of a server which handles its logic and a client which handles its. Additionally, the server is usually expected to serve the client code to the server upon request. Managing this client code is not really a function of the server, but it is common enough that Phoenix has the ability to automatically run a toolset to package up this client and put it in a place that it can be served up upon request. As others have pointed out, the coupling here is extremely light and can be disabled or replaced very easily. &gt; If client-side stuff it's such an essential feature, then you need to carve it out of Node, integrate it into Phoenix and then own and support it. It's not at all clear how this is essential. JavaScript clients are often built around JavaScript frameworks and toolchains. The ability to rely on these toolchains is a *benefit*, not a gap in Phoenix. The greatest complaint in this regard isn't that Phoenix doesn't have a built-in option, but that it is using Brunch instead of Webpack by default. There just isn't a compelling reason why Phoenix needs to reinvent the wheel here. The reason for choosing Brunch over Webpack was that Brunch was seen as having a more friendly, less complicated configuration process. It didn't need to do this at all (and you are free to turn it off), but Phoenix is never going to have a native way to compile JS. &gt; I also didn't think that the first thing to do in learning Phoenix would be to go an figure out Node. What does 'figure out' mean? Is this just your personal aversion to Node, or is it that you found installing and configuring Node on your system was particularly onerous? &gt; If the community and the ecosystem is set up in such a way that deferring to other non-trivial tools every x. steps is acceptable, then this is a major issue of the language ecosystem. Why? You say this as if it is self-evident. There is tremendous value in using language-native tools and a great deal of cost and effort in reinventing these tools. If you think these are problems, enumerate the actual costs.
I just wanted to share my side of this as I kind of agree with what your saying, so bear with me here. I really dislike the way the JavaScript ecosystem is creeping into all the current web development frameworks. *However*, a lot of web development tools have been developed or extended by developers that worked with Node. Tools like SASS/SCSS compilers, webpack and Babel.js were incorporated in Node frameworks quite extensively, and have evolved a lot because of the continuous use. Phoenix is relatively young, and instead of reinventing the wheel opted to go for a battle-tested Node solution. But! I don't think anyone will mind you implementing a SCSS compiler or Babel.js equivalent as an Elixir module. In fact, I think such a tool, when properly implemented, will probably be welcomed with open arms in the Elixir community. (I for one would love this) Although matching the quality of Babel.js and a variety of standard NPM packages will probably take a while. I personally chose to not use Brunch in my Phoenix application. As said earlier, with `--no-brunch`it really isn't much of an inconvenience to generate a Phoenix application without Brunch. I haven't missed it although I tend to focus on back-end first. 
Brunch falling out of favour wont break builds. The --no-brunch argument is for the Phoenix application generator which you only use once - to set up the project. If brunch goes out of favour you just replace it with something else and deprecate the argument. It's not a big deal. And Brunch is not integrated into Phoenix in any meaningful way so even if Phoenix does end up replacing it, upgrading wont break your asset compilation, you can continue using Brunch. Really, all Phoenix does is spawn a watcher process, which is configured to Brunch by default. &gt; watchers: [node: ["node_modules/brunch/bin/brunch", "watch"]] That's it. &gt; Yeah? What values exactly? That people will already be familiar with node so we can depend on it for everything we're too lazy ourselves? Developing your own asset pipeline is a huge waste of time and you're never gonna be able to keep up with what the node community is doing on that front. Having worked with Rails for most of my career, the rails asset pipeline has just gotten in the way of frontend developers. We straight out replaced it with webpack in our most recent project.
&gt; I'm sure no one will ever criticize you in any way... Yes, clearly, the major issue here is people's feelings getting hurt, rather than a brand new platform already making asinine design decisions. But since you insist on wanting to compare mental capacity, let me put things in perspective: How many non-node frameworks are out there that depend on node? Is that coincidence? Or were they all perhaps not smart enough to recognize this possibility for reuse, unlike Phoenix?
I really don't think you understand what is going on here. The phoenix app generator (what happens when you call `mix phoenix.new`) will create a project that uses brunch to compile assets. This is done because brunch is a pretty good build tool for client code. However, you *100% do not need to use brunch or any Node whatosever*. If you run the app generator with the `--no-brunch` option then you will have absolutely no Node in your app. Your next complaint seems to be that there haven't been client build tools built in Elixir. What language/framework are you coming from? In all likelihood it doesn't do any more than Elixir/Phoenix does, and if you want to build a serious single page web app you are almost certainly going to end up using some combination of javascript build tools (grunt, gulp, brunch, webpack, browserify, babel, etc.). These all run on Node. The complaints you are leveling at Elixir are true of virtually any language and framework, the only difference is that the Phoenix app generator will very kindly do some work for you, if you so desire. If you disagree with this, please point me to the elements of other languages and frameworks that you feel are lacking in Phoenix/Elixir.
You absolutely don't have to learn a single thing about node to use Phoenix/Elixir. Just don't use brunch. It literally says it's optional in the part you quoted.
&gt; In all likelihood it doesn't do any more than Elixir/Phoenix does No it doesn't. But then again, unlike Programming Phoenix, the literature that's supposed to welcome newcomers also doesn't tell them that it's common practice and encouraged to depend on node. &gt; if you want to build a serious single page web app Well at some point you need to make up your mind. Either this is *the* major selling point for Phoenix and needs to be addressed properly, or it's a fringe use case (because Phoenix is concerned about the server side) and needs to be treated as such like in most other frameworks. Everything else is inconsistent and will lead to pain one way or the other.
If your problem is with the book, then fine. Maybe it should be clearer about the relationship between Brunch and Phoenix. There is no mind-making-up to be done. It is neither the major selling point nor a fringe use case. It is an extremely common use case, but very much a convenience feature, and not a core selling point. The devs felt that most people would use a node-based asset pipeline, so they built the application generator to support that by default. Anyone who doesn't want that simply needs to add a simple 12 characters (` --no-brunch`) to the script that they will run only once per project. Like I said, I haven't read the book, so I can speak to any issues with it, but you are making a mountain out of a molehill with your complaints with Phoenix. I don't think it's an issue at all, but even if it were, the fix would simply be to change the behavior of the app generator to have brunch added as an option and not a default. At worst, your issue is one with the application generator and totally unrelated to issues with the language/framework.
Those benchmarks are not purely floating point operations. Not trying to shit on elixir/erlang but it is not great in terms of raw performance. But again you are not using it for raw performance.
Sublime Text 2
&gt; I need to learn to deal with node first before I can start working with Phoenix You don't need to learn almost anything about Node. The only things you have to do are install Node, which is pretty simple, and learn to save JS packages in your package.json file. But if you don't even want to do that much, then don't. It's pretty simple. You're welcome to use something else (or nothing at all) for managing your static assets. Just create your application with `mix phoenix.new --no-brunch foobar` to create your project `foobar` without Brunch or Node.js.
Good morning! Yes, it is a new day now in good old Europe and a new day always has the chance to see things from a new perspective. So here's my two cents: I always have a programming language that I like the most and that typically changes every five to seven years. I try to do as much in that language as reasonable as that gives me training and joy. Still I have to fight the temptation of doing everything in that language, because it is just one option in my tool belt and there is no golden hammer anyways. So why would people start to reimplement something as boring as the perfect asset compilation in Elixir, when there's a pretty damn good implementation already available? For something that happens only on the development machine and maybe on the CI server, but has no impact on production machines? There will be some implementation in Elixir in the future because someone can not resist and will write one, but I think it was and is the perfect decision to use existing stuff and go for more interesting details in Elixir. And by the way: Elixir is no golden hammer either. It is great for a number of reasons and I love it, but I will never ever use it for everything. Sometimes it is Ruby, because I already have big components written in that language. Let it be Python, because it needs to run on Google AppEngine. It might be Java, because I can easily wrap an enterprise bean with it and can offer it as a REST service. Sometimes it is C++, because I need to interface with some audio conversion library. Sometimes it is a couple of lines in Lua to implement a check in Nginx without the need for a context switch to some other process. I love Elixir, but I still have respect for my ex and I will still have a beer with my friends…
Thanks for sharing this! I should really make it a habit to do it myself, but somehow I always forget it :(
I'm currently working on a hobby project with no Ecto and using rethinkdb instead of Postgres. I can confirm that Phoenix is still very useable and useful without Ecto. That being said, Ecto is really nice. 
&gt; Good morning! This made me laugh, thanks!
Yeah it's one of those handy little ideas that only has limited applicability. Still where it's applicable it's a help.
I use the Google test to determine these things. If I get a specific error and search for it, it's a bit unsettling when I see that I'm apparently the first in the indexed world to have encountered it.
It's okay, I got your back! :)
I would describe Elixir / Phoenix as having the status of "low buzz". It's visible, but not prominent to people who are looking around in the space and is showing up on their lists of 'possible future stuff I might get around to playing with'.
I like the classy Elixir dev in the graphic
Why do people care about this instead of just going with what feels right? When I first encountered Ruby I thought it was awesome but I knew no one doing work in it yet. At some point I just *had* to work with it and finally got a startup job (this was right around Rails 1.0, if that) in it, and then it continued to get attention and this paid off career-wise. (By the way, that was QUITE hard to do without Java experience and coming out of a Microsoft ASP.NET shop!) If you like Elixir, use it and contribute to the community. If you don't, find something you DO like and contribute to that. Who cares if something's popular? That's a poor indicator of quality, utility OR actual value... all of which are subjective things *that only exist inside your head.* So why do you care about what people think *out there*? If you get in now and it *does* end up "mainstreaming," then you'll have a very successful career as the already-expert.
I just wish Google prioritized links to the latest versioned docs lol
&gt; Why do people care about this instead of just going with what feels right? It matters a lot if you're the one hiring, or the one wanting to make a living being hired.
If something has started to trend upward, it is likely it will continue to, barring some major catastrophe; and it's not that hard to find those metrics. also, due to the way language fashions and jobs work, it's best to be a good generalist if immediate employment is a concern
While all of the Elixir books cover the subject at least a bit, the Elixir book that I have enough knowledge of with the best OTP coverage is Elixir in Action. If you can't bring yourself to buy the book for whatever reason, then [Learn You Some Erlang For Great Good](http://learnyousomeerlang.com/) is free online, but it does require translating between Erlang and Elixir (which is actually straightforward once you figure it out). If you don't mind buying a book and reading the Erlang and you want a deeper dive, then [Desiging for Scalability with Erlang and OTP](http://shop.oreilly.com/product/0636920024149.do) is very well done and very near to final release. From there, it becomes the usual wilderness of blogs, conference talks, technical papers, and reading the code of other projects (often in Erlang).
ETS tables are owned by the process which created them. By default, an ETS table is created as :protected, meaning any process can read from the table, but only the owner can write to it. If you were to add the option :public to :ets.new/2 then your spawned process should be able to write to that table. A table with infrequent writes and frequent reads should probably be the default :private. Make a module which defines a process that owns and updates the ETS table which is separate from the process which is requesting and processing those hourly requests. 
Related: I really hate it when I access a link and the domain redirects me to the root of *the mobile version of the site* (completely losing the context) instead of the original URL *with the mobile bit added* (usually via a "m." subdomain)
&gt; Where should I call "Cache.init" to create the table only once? In the config of your app, I believe, which is loaded once. For example, if you open any test_helper.exs, you see a call to "ExUnit.start", which inits the ExUnit process and is only called once. As a safeguard you could have it check to see if it already exists before creating it. I would suggest wrapping your ets-accessing code into an Elixir module wrapper that sticks to basic cache semantics like get, fetch, put... so that you can swap it out with another store at will in the future... Actually, that appears to be what you're already doing... I bet someone else has already done this for you somewhere online, unless you're doing this as an academic exercise :)
Excellent!
It's interesting to see people draw comparisons between Phoenix and Ecto to Rails. I firmly feel that the similarities in implementation are superficial while the similarities in ideology are deep. It's fun to watch people try to figure out how they feel about this and to articulate how these new tools do something very different in a strangely familiar way.
I love node packages. I use them everyday. But you're damn right it's one big shitshow of mixed languages &amp; bad choices by devs. I understand everything that is out there, but it's so bad. E.g. Golang packages, Elixir http servers, PHP Apache, etc... Every language currently existing is shit for webdevelopment. Please.. someone out there.. Create a language that does concurrency &amp; webservers like golang, packaging like npm/composer and performance like rust &amp; go. Then we can all use that language,, have all our tools there. And FU if u say that's not possible. It facking is.
The intended message was merely "It's ok to not use pipes". Many newcomers somehow get it into their heads that they should be using pipes for everything, because that's idiomatic. One point I didn't make (to keep the post somewhat short) is that there are APIs designed for pipes. I maintain the RethinkDB driver and the entire query language is designed around using the pipe operator. Plug.Conn is designed for pipes. Ecto.Query is designed for pipes. Enum and Stream are designed for pipes. This leads into your point, that if we want to use pipes we need to make sure our functions are designed for pipes. Our own API should be pipe compatible. Newcomers hit problems when they try to change the nature of pipe rather than their API.
Well, ideally pipe could be extended to handle the idiomatic error case instead of discarded entirely (i.e. implement the Error monad instead of just function application/Identity monad) and having LINQ for the list monad and possibly even do-notation would be even better!
&gt; The intended message was merely "It's ok to not use pipes". I should have been more clear, thus is a major problem with writing to fully convey a message. The sense I have from the post is that it is intended to try and temper a sort of over-enthusiasm people tend to have about pipes, but I think it just missed the mark a bit. A worthy effort, but I don't think that code branching is the biggest issue and I think more should have gone to showing different ways to code around things.
I am contemplating a follow up post "Adapting your code to work with pipe". I think it will hit those points properly.
The first thing that comes to mind is that you don't actually need to build on a similar host if you're not using platform-specific drivers or ports. You'll have to dig into it yourself, but exrm uses relx, and relx lets you point at any erts to include, and you can point it at an erts for another platform that will be copied in. This lets you do cross-platform releases pretty easily. It'd probably be nice to have these erts in some easily-grabbable place to build a tool on top of exrm/relx that can just go grab these when you want to build for Raspberry Pi (where building on-host can take a while) or for Linux from Mac, or vice-versa.
Haven't used it, but there is Maru. 
I think the winner is... an Erlang framework lol. https://github.com/knutin/elli It has an Elixir wrapper... https://github.com/pigmej/exelli
That's a step in the right direction! Still a little heavy for my tastes...
Plug with Plug Router. Though, Phoenix is lightweight and doesn't have the footprint you'd commonly associate with full featured frameworks. Since it's a framework in a functional programming language, everything just a series of function calls rather than a heavy runtime with lots of objects in memory.
So the interesting thing I found was that Elli (linked to below) is ~twice as fast as plug (according to some random dude on github). Speed is another thing I'm looking for (the whole reason I'm doing this in the first place is to move my API off Flask/Python -&gt; Elixir). I'll play around with Plug as well and maybe put some benchmarks up on reddit :)
Ironically, it's probably conceptually more heavy-weight than plug because it's a bit lower-level. There has been work for an elli backend to plug (plug, in principle, can support more than just cowboy for http). But Elli gets its speed from disregarding all the niceties that you get from OTP. Processes spawned by Elli will be harder to get visibility on. Flask on Werkzeug is actually easier to debug. In that sense, I think of Plug as the most lightweight abstraction...it's reasonably close to http, and it's reasonably fast.
Collectable is a protocol as well. It defines rules on how to add elements to a collection (like a list or a map). For instance, if you have a list list = [:a, :b] You could go: Enum.into([:c, :d], list) #=&gt; [:a, :b, :c, :d] Since Collectable is a protocol, you can define it for your own structs.
For most of you, this is either old news or too far in the future to be terribly useful. For me, the sooner I get a lock on a time and place, the easier it is for me to get things scheduled with my employer. If you're in the same boat then maybe this information will be helpful. Regardless, hope to see you all there in August.
I didn't know! Thanks for sharing. Is it important that :myapp is an atom in this case?
Yes, it should be the name of the application from mix.exs, or the name of a dependency as seen in the deps list. And no worries, this is an easy one to miss if you haven't used releases, and I blame Mix for it. This post just reminded me to open an issue for it!
Camelcase stuff like `myVar` is not idiomatic FYI, you should change your very first example to be `my_far`
what do you mean? elli acceptors/handlers are fully compliant otp processes and have better tools for introspection monitoring than cowboy. with `handle_event` in an elli handler you can monitor the entire http lifecycle. with cowboy/plug you have zero way to tell anything other than what is exposed in the http req term
You seem to have a chip on your shoulder about Node. Use the best tool for the job, I say. Since Elixir/Phoenix are so young, there's a lot of reliance on external stuff. For example, the last time someone recommended a deployment tool to me, it was Capistrano, which is written in Ruby. It is best to leave your religion at the door when you do dev. You seem to have a "belief" that Node is bad, period. A little overzealous a conclusion, I think. Also, you seem to have never heard of the --no-brunch option, or the fact that Phoenix ONLY uses node for npm. Please don't give up on Elixir just because Phoenix decided to rely on Node for a pretty specific task. I'm pretty sure everyone in this community is tired of OO spaghetti dependency hell.
https://excasts.com -&gt; Has a few.
I wish it were in Austin again. :(
thanks so much guys
Largely a good piece, although I question using [first] ++ rem_dupes(t, first) when [ first | rem_dupes(t, first) ] is ideomatic. Maybe because the former takes less explaining to some? My feeling is that part of the magic of pattern matching is using the same structures to both create and match.
So I considered that, but didn't want to spend time talking about reversing the list in the empty case. Also, that's not tail-recursive either, so the best approach would be to have a result list, and make 3-arity functions, but again, I didn't really want to over-complicate things. If it's any consolation, the C code isn't optimal either ;-)
Those two pieces of code are almost entirely equivalent and don't require reversing anything.
ah, right you are. sorry, yes, that would would be better actually. UPDATE: fixed.
&gt; Phoenix ONLY uses node for npm. That does not change the fact that I need to get Node on my system. &gt; the --no-brunch option That only makes things worse. That is one option right there that'll be likely outdated in 1 or 2 years time. And this isn't some decades old framework that has gained some cruft over the years. It's a brand new one. Why such carelessness? Those are pretty major flaws in the community. The right thing to do would have been to leave these irrelevant details out and leave it up to those that want to do flashy JS stuff to figure out for themselves. Not burden everyone else with their problems. &gt; Elixir/Phoenix are so young, there's a lot of reliance on external stuff. Fine then admit that and simply leave it out. Most other server-side frameworks don't care about client-side JS stuff. So why should Elixir? Especially considering how apparently nobody has the resources for it. &gt; Phoenix decided to rely on Node for a pretty specific task. Phoenix got its priorities entirely wrong. It's more than just "a pretty specific task". It's a lot like C deciding to initialize everything to 0 that can be statically allocated and leave everything else uninitialized. And C++ caring on with that tradition, except in a myriad of more fucked up ways. Or C-Strings being null-terminated because that's what happened to be the fastest implementation on Dennis Ritchie's PDP back them. I didn't provide all those links in my other posts for fun. They each do highlight one brain-dead decision, that nobody spent much thought on at the time, to solve one utterly irrelevant problem in the grand scheme of things, in a supposedly clever fashion. And now the entire world suffers them for the rest of eternity. &gt; It is best to leave your religion at the door when you do dev. This is not about religion. It's about deciding how much time you want to spend on things. I want to spend zero time on debugging node and I want to spend zero time learning a language that has a community with such a casual attitude towards dependencies on 3rd-party code in foreign languages. When I hit some problem in Elixir and look for help I don't want to read "npm this" as a solution. If I liked node, I would've stuck with it in the first place. Not looked towards Elixir.
To most people, Magic is any code I didn't explicitly write to do X. It's very subjective so it's not very useful to tell someone that X isn't magic because of Y. They're just going to say Y is magic too and you're blind not to see it. 
I think right now alchemist for emacs is the best option. However, there is an [atom-elixir] (https://github.com/msaraiva/atom-elixir) package in the works that uses alchemist as a backend to provide all the nice features in atom. 
&gt; I'm not not seeing the difficulty here. Did you have people trying to run the code on Windows x years later?
We keep our systems up to date, and support only one OS----Linux. To add to that the entire application is run in-house with users only seeing the client-side interface via desktop or web clients. If you have to support installs on grand variety of client environments then yes, perhaps C/C++ is not the way to go.
I use IntelliJ with the elixir plugin.The developer behind the plugin has been doing a lot of work on it recently and it's going to be a huge improvement when it's released.
So this situation you're describing here won't and can't happen, even if Phoenix decides to completely change to some other JS build tool. The reason is because the brunch code / files are only added when the project is first generated (if you don't use the --no-brunch option as mentioned previously). Phoenix itself has no further dependencies on brunch or node - all it just has a single line in the dev.exs file that tells Phoenix what command to run to build JS files - the framework has chosen Brunch (which yes, requires node) as a starting default for this for convenience - but replacing that choice is as easy as changing that line in dev.exs. You can easily tell Phoenix to shell out to whatever you want - could be some other tool, like make, or just nothing at all. For example, I've replaced brunch with gulp in my own project, and I only had to change that one line in the dev.exs file, and add a Gulpfile.js file to my project. If a new tool should come down later, then I could choose to either change that line again - or just keep using what I'm using (because the framework updates won't change my project files, which includes dev.exs) If this is still unclear, then I highly recommend you generate a new project and give it a try. It may be easier to understand once you see how all the parts tie together.
Imagine you're at one end of a tunnel with a train coming through. The only way to count the number of cars is to count them in succession as they exit the tunnel. With a linked list you can only access the head or tail of the list and you can only see one node at a time. In order to count the number of nodes in the linked list, you must count them one by one. [This is a linear complexity](https://en.wikipedia.org/wiki/Time_complexity#Linear_time);if the length of the linked list is N, then the time-function to perform this would be T(N) = kN + c, with k and c being some constants.
Is there a reason you don't mention in your article that you can just use Elixir's `Enum.uniq` function? 
In addition to the other answers here, you can read more here: https://rob-bell.net/2009/06/a-beginners-guide-to-big-o-notation/ As the link says, an O(N) operation is called a linear one. For most languages, accessing a length property will usually be a constant time operation ( which is O(1) ), so a linear operation for length is somewhat costlier than you might expect. As a result, if you are going to be needing the length of an extremely large list very often, it might make sense to track the length separately as you add/remove elements and pass it around as a separate value with the list. For lists that aren't extremely large, or in cases where you don't need the length very often, it isn't something you need to worry about, however.
I isn't see anyone mention why getting the length for a list takes O(n). As I haven't looked at the Erlang source for quite some time, but I vaguely remember it being implemented as a linked list. This has some benefits such as allowing us to efficiently obtain the head element and then tail list from a list, elements can be added to the head of the list efficiently, etc. But one of the downsides is counting the elements in the list will take O(n). A solution to this would be to store the length somewhere but this might be difficult to do depending on how they're manipulating it internally (but this is some you could definitely do). Now ways you can deal with this are design your algorithms not to need to obtain the length, or if you must need the length maybe you could use a different type (such as a tuple, which accessing the size of a tuple is O(1)) or if it has to be a list just get the length once and reuse it. 
I think the way to go about it is to pick developers that are open and motivated enough to pick up elixir (or any other new/less common language). This is what I'm doing with a startup I'm working on. I picked elixir because it was the (or one of) most appropriate language for the task. Now because elixir isn't very common in my area (neither is erlang), and since it's a startup being worked on by students so hoping to get some additional students onboard and it's unlikely many (if any) other students in the area are going to know it. This is why I'm just looking for individuals that are willing to learn it, rather than holding out for some that are already experienced with it. And I think the same should apply to other businesses. 
Thanks. That looks very interesting.
It does look like it was abandoned a year ago so. :/ Probably better off using other tools, creating an api, and having your elixir apps interface with them. 
I am not an expert on this but I am skeptical. The reason is that effective parallelism in Elixir relies on separate processes sharing no state. So, if you have a large in-memory data set, you would probably have to copy parts of it around to get decent parallelism, which wouldn't really be high performance. So, it's possible, but I am skeptical that it is the right tool for the job.
I've thought of this in the past too. Sometimes I've seen OTP referred to as "poor man's Hadoop". One of Julia's founding promises was [distributed computing](http://docs.julialang.org/en/stable/manual/parallel-computing/) data science; though I've lost track of their progress. I feel like the concurrent / distributed / supervised features or Elixir/Erlang/OTP would work well for Data Science and Machine Learning projects. One of the difficult challenges is writing a new library using OTP which uses distributed algorithms. One could try to interoperate or bridge with existing libraries (fortran, C/C++, python), however, that also adds to the complexity and challenge. In any case, I feel like this would make a terrific SaaS concept. Especially if it were setup to run on docker/AWS and take advantage of [GPUs](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cluster_computing.html) etc.
&gt; high performance of Elixir There is no such thing. BEAM is slow as hell in number crunching. 
The IntelliJ Elixir plugin is being developed but is not necessarily the best possible choice right now. I use it mostly to have a consistent environment with my Java and Ruby projects. PS Next plugin release brings hope for lots of improvements.
It's an interesting point. The nearest competitor to Elixir/Erlang in terms of support for the Actor oriented model is Scala and clearly one of the things Scale is known for is data science in the form of Spark. Is Elixir simply too slow to compete on a level playing ground in that arena? It should scale better, right? But is that enough? 
I haven't looked at the code, but typically the first entrant into Techempowers benchmarks is riddled with errors or even fails to compile under their conditions. It usually takes 2 or 3 rounds of people going over the entry before it becomes production worthy.
Good to hear, thank you! At this stage I only have my testbed at home, but would love to hear about any experiences with hosting providers.
JVM is relatively secure due to its maturity. You probably meant Java applets that indeed have a bad fame but are almost irrelevant nowadays. BEAM VM is probably much more vulnerable due to its very low popularity and exposure to the public Internet thus far.
It's amazing how many people confuse applet security with general classloader isolation and how it relates to the security manager of the JVM. While there were some security manager bugs in the past, exploiting them is usually pretty hard, fragile or related to a combination of some particular libraries (like e.g. the recent RCE via deserialization). BEAM doesn't even have proper multiversioning or visibility isolation ala OSGi. :-( 
We don't know what caused the errors and unfortunately we didn't have a chance to collaborate with them on a true run. A few months ago they added Phoenix in a preview, but it was a very poor implementation. They were testing JSON benchmarks through the `:browser` pipeline, complete with crsf token generation. They had a dev DB pool size of 10, where other frameworks were given of pool size of 100. And they also had heavy IO logging, where other frameworks did no logging. We sent a PR to address these issues, and I was hoping to see true results in the latest runs, but no preview was provided this time and we weren't able to work with them on the errors. tldr; these results are not representative of the framework.
It depends what people are looking for. Elixir mode for Emacs (which Alchemist uses/enables) has been annoying me lately because it actually requires more keystrokes to get the job done because I have to manually fix annoying smart indentation. At least when I use Vim it's not hard to disable smart indentation. With Emacs in general and especially Elixir mode, sometimes you have to either accept a mode's quirks entirely or turn the mode off (and sometimes disabling something doesn't fully work either). Sometimes hacking around in Elisp is more trouble than it's worth. I've tried a lot of workarounds and hooks but to no avail (e.g. messing with electric mode settings, etc.). The worst offender tends to be whenever using cond, but smart indentation and new syntax created by macros tend not to play well either in some cases. I've never been big on auto-completion and other bells and whistles of IDEs that actually slow me down, so lately I simply switched to using Gedit with the gtksourceview syntax highlighting for Elixir. KISS is working better for me than fighting environments that are trying to be too helpful. The best choice varies by language, since something like Emacs/SLIME really is the best choice for something like Common Lisp, etc.
**Any** sufficiently complex piece of software is going to be vulnerable in some way. The JVM is a huge target, so there is a great deal more discussion around its security problems, both by those seeking to exploit and fix them. BEAM is a much smaller target, so there are fewer people trying to crack it and fewer security analysts trying to shore it up. All of that said, the greatest security risks in any project are the code written by the least experienced developer in a particular domain, which is usually you. We still live in a world where SQL injection attacks work because developers aren't sanitizing their inputs. Your security is going to be best in an environment which encourages you to write safer code, and many would say that BEAMster languages provide this. It ultimately comes down to which security story you and your team are happiest with. Just be wary of marketing which tries to sell you a false story.
TIL about Ur. WTF is Ur you ask? From http://www.impredicative.com/ur/ &gt; Ur is a programming language in the tradition of ML and Haskell, but featuring a significantly richer type system. Ur is functional, pure, statically typed, and strict. Ur supports a powerful kind of metaprogramming based on row types. &gt; &gt;Ur/Web is Ur plus a special standard library and associated rules for parsing and optimization. Ur/Web supports construction of dynamic web applications backed by SQL databases. The signature of the standard library is such that well-typed Ur/Web programs "don't go wrong" in a very broad sense... https://en.wikipedia.org/wiki/Ur_(programming_language) https://dspace.mit.edu/handle/1721.1/92321 Anyway, they hold the top performance result right now, so I thought it would be worth looking up.
This may surprise you but banking web applications are a total crap security-wise. So it doesn't matter which VM is used because there will always be easier-to-exploit app level vulnerabilities. Bank security relies mainly on limiting loses, not on avoiding them. Source: at Kontomatik we reverse engineer bank web apps across the world.
BEAM had orders of magnitude less exposure to the wilderness than JVM so if I'm asked to guess which VM is more hardened security-wise, I guess JVM is.
So part of this depends on what you mean by "vulnerable". Fundementally, the BEAM VM does not try to be secure and in fact has a great many facilities that work against anyone trying to make things more secure. The same features that make debugging so easy, like being able to use a simple cookie to connect directly to a remote node and diagnose problems while the system is running, are also potential security nightmares if you are not careful. The BEAM and the standard libraries that run on top of it (e.g OTP) all assume that one you are on the inside you are trustworthy, so there is no sandboxing or separation of priviledges within a BEAM VM. In Erlang and Elixir you tend to isolate diferent security contexts in different OS processes via ports or in different VMs. In most languages that run on the BEAM VM there is little difference between a local function call and a remote call, so it is trivial to create different microservices within your app that maintain their own priv and data access boundaries.
BTW - call for speakers is still open as well - if you have an idea for a talk go here: http://empex.co/call-for-speakers/
Because it's "fast enough". It's faster than Ruby or Python, which are considered reasonable for most tasks. Erlang/OTP essentially admits that it's not going to be a one size fits all solution. This is obvious if you see how many escape hatches are provided - ports, port drivers, c nodes, nifs, java nodes. Erlang is very interop friendly, and you are gently encouraged to write in another language then integrate with the vm if you need high performance. 
Good to know! Thanks. Just an FYI most cloud-hosted infrastructure-as-a-service providers do not allow packet multicast functionality, but you probably already know that. :) 
It's safe enough for [Klarna](https://en.wikipedia.org/wiki/Klarna).
Thanks for posting that, surprised I haven't heard of it yet.
I've had a chance to meet the creator on a few occasions -- very smart guy, but does not understand non-academic conceptions of maintainable code and hasn't put the effort into documentation. (This makes sense for a professor.) http://www.impredicative.com/ur/ is its home. 
To expand: wasn't BEAM specifically created for telecommunications? The operations performed in those systems aren't necessarily intensive. It simply wasn't a concern for them - everything was constructed for a very specific purpose. In that sense, you could argue, that bringing BEAM to the context of Elixir, and therefore often web, brings to light some of its aspect which the designers thought would keep in the shadows. Might someone happen to know how opinionated BEAM is in its philosophy? Is a forked VM which is geared for a more general purpose a complete pipedream? To try and narrow down the scope: let's assume that interoperability turns out to be an insufficient solution, for example because of deployment and maintainability concerns.
This is awesome and timely since I was trying to this same thing just last week!
This is the right answer ;)
Politics of programming. Benchmarks are always bias and don't take into account a lot of factors. Stability, scalability... all these things come into play in the real world. 
A comparison would show how they contrast more than what they share. That said, a detailed comparison would still be interesting to read. Really, Rust and Elixir synergize. You can write NIFs in Rust while letting the message passing OTP stuff happen in Elixir.
I tried the sublime addon, but that doesn't work for some reason despite multiple attempts to set up. All the other options were too much of headache as well, so I just use a notepad-esque editor until a better option exists. I'm surprised it's this complicated to just get this implemented easily in one of the many other editors that exist. The sublime/other variations weren't exactly "out of the box" and had lots of incomplete dependencies.
Yeah, that would be the maintainer of the Rustler project, which is the NIF in Rust thing.
This seems pretty useful. Thanks.
See also [the full list of 150+ available API docsets](https://kapeli.com/dash#docsets), courtesy of [Dash for OS X](https://kapeli.com/dash).
Dash has a plugin for any package on hex.PM and the Erlang docs. Awesome work here too, I would have gone for this had dash not added the hex.pm functionality last year.
I don't think there have been any, but why should I pay to get into a conference in the first place? Hardly reinforces the FOSS spirit. Elixir specifically is still rather new, so I guess I'm not shocked that these guys are trying for the quick buck. Just a bit tasteless imo
Because the space in which a conference is given is not free, and the burden of paying for it should be shared amongst all the attendees? I mean OSCON will cost ~$1195 for a 3-day pass, and that's the biggest FOSS conference I can think of but a lot of that money gets whittled away to things paying for lighting, sound, space for X number of people, etc. The reality of it is that very few people make 'big money' off conferences, it's mostly a labour of love to put this stuff together and make it fun for all the attendees. I think its a bit premature and maybe even disingenuous to paint these guys as "trying for a quick buck".
Ah, the fact that you guys got your pricing out before even knowing who'll be speaking is a bit backwards. :) My suggestion... get good speakers, then tell us it's $300 to watch them. If you get Jose Valim and Chris McCord to come up and speak for an hour, I'd certainly pay the price. But for you guys... many of whom *I've never even heard of*, I'm not really that inspired. Perhaps someone else can fill me in on who you are?
Modnulenames are atoms, it is this way in erlang and elixir as well. And as long as everything is achievable with function calls everything is fine. But some erlang libs require you to use some erlang defines (similar to c macros), these can't be used from elixir and probably never will. 
Yes, use the erlang module gen_tcp. The Elixir getting started guide has a good writeup on this: http://elixir-lang.org/getting-started/mix-otp/task-and-gen-tcp.html 
You don't have to thread everything through the gen server process. You can dispatch a task, and in that task, send a reply to the original process. This removes the genserver as the bottleneck using `reply/2`. See: http://erlang.org/doc/man/gen_server.html#reply-2
But I need to update the gen_server's state with the processed message
Best practice is to pattern match in the function definition when possible. You should be reserving you use of case for situations where you have to do something that is not possible in the function definition (like first calling some non-guard function). The advantages are clarity and expressiveness. Always be wary of adding another layer of indentation to your function as it increases the cognitive load of understanding what is going on by quite a bit. It also makes things more expressive by separating code paths out into discrete definitions. For example: def sum_list([], acc), do: acc def sum_list([head | tail], acc), do: sum_list(tail, head + acc) can be expressed in language as. * The sum of an empty list and an accumulator is the accumulator. * The sum of a list with a head and a tail with an accumulator is the sum of the tail with the accumulator head plus the old accumulator) Note that there are no conditionals in there, it is just (recursively) describing the definitions of different possible paths. Programming by definition ends up being *much* easier to reason about once you grow accustomed to it.
This isn't a direct answer to your question, but make sure to look at the functions available in `Enum` which remove a lot of the need for common recursive tasks. For this, it has `Enum.sum(list)`.
That exactly what he mentioned as "unnecessarily complicated", though I don't understand. The supervision system is by far the best tool Elixir and Erlang have to offer, so I don't get why you think its unnecessary. If you want to create a new process without linking it to the current process you can simply run `spawn` and it will crash all by itself without bringing anyone else down with it.
Isn't it non-evil optimisation tu put the more frequent case first when possible ?
Have you some sources ? I think I read that function clauses perform much better.
Sure, I'm following the documentation and I'm aware of Enum.map, Enum.sum and Enum.reduce, that was just for example :)
Yes, I read an article that explained how we end up by building mental patterns, it takes time to get used, but eventually something like for(i = 0; i &lt; length(list); i++) feels natural to the programmer. The same thing is supposed to happen with functional programming logic, I think the key is repetition of basic exercises, like in college times. I'm trying to solve some problems from Project Euler (https://projecteuler.net/) using Elixir, that's when I got the question I made
Sorry, just copy/pasted from Elixir site, but I do agree on putting the "easy return cases" first, like constant numbers and checks for null, feels way more logical.
So he did! I should have clicked the link obviously. Personally, I found the approach described in that guide to be incredibly simple, considering all the failure cases it handles. If you don't care about that kind of robustness (maybe it's not a production app, or something), the gen_tcp is dead simple on its own.
I'm unable to measure meaningful differences in my own benchmarks. I did 1M invocations and saw less than 5% difference and it wasn't consistent which was faster. The pattern matching itself should be identical. It undergoes the same optimizations either way. The only difference would be whether it changes how/when the new stack frame is created and I'm not even sure that would affect performance.
There are a couple of issues here. The first is that while case is a fine and useful structure, when you can pattern match in function declarations, it is usually a better idea. def baseurl("na"), do: "https://na.api.pvp.net/" def baseurl("eune"), do: "http://eune.api.pvp.net/" Then there is the issue that you can just go: def baseurl(region), do: "http://#{region}.api.pvp.net/" If you are wanting to make sure it crashes if an invalid region is included: @regions ["na", "euid"] def baseurl(region) when region in @regions do "http://#{region}.api.pvp.net/" end The following code is duplicated and seems to be generalizable (I don't know the LoL API). Velkoz.Region.baseUrl(region) &lt;&gt; "/api/lol/#{region}/v#{get_version} Repetition of this sort generally says that something is going wrong. Also, passing around uri strings is usually not the best way to do an API. If I were doing this, I would be generating a [Struct](http://elixir-lang.org/docs/stable/elixir/Kernel.html#defstruct/1) which holds query information and a module which takes such a query struct and converts it into an API call very close to it actually being sent.
I would use a multi-headed function here: https://github.com/Tim-Machine/velkoz/blob/master/lib/velkoz/region.ex#L5 thus: def baseUrl("na"), do: "https://na.api.pvp.net" def baseUrl("eune"), do: "https://eune.api.pvp.net" 
Great idea thanks!
I am correcting the blog post and have another question for you. Is it valid to something like this: config :my_app key: :value Or do I need to also include the module name? config :myapp, MyModule key: :value Here is my example file: https://github.com/sheldonkreger/sitedown-notifier/blob/master/config/config.exs It may also be relevant to see this file, because it defines the application's callback module. https://github.com/sheldonkreger/sitedown-notifier/blob/master/mix.exs#L20 
The latter is the one you'd want if you were going to specify configuration for a single module. You can use either though in general, the former would be better for things like config settings which are common to multiple modules. Your example file looks good! 
as others have said, gen_tcp and acceptor pool in the form of ranch and have you handler act as a gen_server, much nicer. Also, packet mode, it seems very under appreciated but quite nice.
I also wrote the article how to test with power assert in your elixir projects. Enjoy! http://qiita.com/ma2ge/items/29115d0afbf97a092783
I think I would prefer to have the spawned process send its result back to both the server and the original client, instead of sending to the server which then sends to the client. But the difference would be minimal I guess.
You can definitely start with elixir, there is no need to know erlang before you learn elixir. I would suggest however that you learn to read erlang later when you feel comfortable with elixir because a lot of libraries that are used are written with erlang and there are a lot of great resources on the internet written in erlang.
I started with Erlang because I didn't know of Elixir and it frankly wasn't stable at the time, a couple of years ago. I'm really love programming languages for their abilities so I don't really learn Brainfuck and maybe didn't appreciate Ruby because I knew Python. I would definitely recommend starting off with Elixir but I would recommend using Erlang libraries and reading Erlang code because it's going to make you a better programmer. The problem with starting with Erlang is that it's an old language so the tooling and a lot of the things are all over the place like with any other old enough language. Elixir has really great properties to it which I think make it a language that you don't outgrow. So it's not as much about hey, Erlang is for the real programmers. It's more Erlang has a lot of cool code and you would be silly not to take advantage of it. I also feel like with LFE, the BEAM is inclusive it there are no real first and second class citizens, like I feel with JVM languages. Maybe it's because there is no messing of paradimes, it's all functional.
Also, you'll probably find that once you are comfortable with elixir, you've almost learned Erlang by accident. (to finish the job you can read http://elixir-lang.org/crash-course.html )
thanks so much.
Learn Erlang to the point where you can understand what's going on in other people's code if only at a high level. What I did was that I started out with Simon St. Laurent's [Introducing Erlang](http://shop.oreilly.com/product/0636920025818.do) which is quite short and gives a pretty good summary of what Erlang is about (rather than say Learn You Some Erlang which is very comprehensive). From there, I moved on to Introducing Elixir, which follows the exact same format only with Elixir code instead. It gives you a great comparison between syntax and where the semantic differences are. However, if you feel like the former gave you a good enough idea of what the concept of process orientation is about, you can move on to Elixir in Action or Programming Elixir. Elixir in Action definitely covers more technical aspects of BEAM, where Programming Elixir is just as much an introduction to functional programming and thinking differently from say Ruby.
Remember, data is immutable, so if you just Map.put(socket.assigns, ...), then you will get a new assigns map back and the socket struct will continue to have the map with the old value.
So would this be equivalent? def assign(socket = %Socket{}, key, value) do %Socket{socket | assigns: Map.put(socket.assigns, key, value) } end 
Joe's position here seems to be more confrontational than is really needed and this probably reflects a misalignment of message and audience from Chris's talk. Vertical hardware scalability is important because if you really had one physical server per connection you would have problems. Horizontal hardware scalability is *also* important because you want your application to remain available even through hardware failure. Erlang's concurrency model and OTP can provide **both** vertical and horizontal hardware scaling. Chris's presentation emphasized one without the other because they stress-tested one but not the other. This is a message which is actually better-aimed at people outside of the Erlang community who can use it as a more similar comparison to what they are already doing. A test that said they could handle some large number of connections across a distributed Erlang cluster would require more complicated messaging to communicate. I think Joe should back down just a bit and embrace the buzz which is bothering him then add an amendment that explains that this is due to Erlang's great concurrency model and, guess what, it also makes it much easier to spread out the load to a bunch of hardware and get even greater risk isolation and fault tolerance.
You have the big Elixir-specific packages, are you looking for more general Emacs advice as well? &gt; Any tips on keeping iex up to date with the currently compiled code? If you are running your project in iex (e.g. `iex -S mix`) you can type `recompile` to re-compile your current project (with some caveats, see [the documentation](http://elixir-lang.org/docs/stable/iex/IEx.Helpers.html#recompile/0)).
I didn't see this as confrontational at all. Well, no more than any discussion I've had with Joe. If you watched the moderated discussion from Friday, Joe went on and on about "not breaking the laws of physics" in a similar fashion. That's just how he rants. Personally I think this is a great point being made here. I think it unlocks a lot of good queations.
Adding processes and some form of support for JSX sounds very exciting to me, especially combined with the virtual-dom. A recurring thought I've had while playing with react, is that with the focus on isolated components and usage of a functional programming style, it could benefit from using OTP-like abstractions. 
https://engineering.pinterest.com/blog/introducing-new-open-source-tools-elixir-community I bet there are plenty of folks at this point chomping at the bit to do some Elixir work (myself included!) and leave their Ruby work at least for a little while, although you're still largely looking at remote workers 
https://engineering.pinterest.com/blog/introducing-new-open-source-tools-elixir-community is a good example.
Probably my favorite talk from the conference. Thanks for sharing your experience @bcardrella
Maybe someone is shadowbanned - I see 2 comments in the indicator but I don't see any comments. 
[I did a show HN for a business I'm working on with a live production site](https://news.ycombinator.com/item?id=10864935), if you'd like me to answer anything I can surely help. I think the whole "hire X_LANG developer" thing is kinda bogus. Truly talented developers can learn any language, and only care about using languages for the right task. Also, if you're still worried Python and Ruby are pretty similar in terms of syntactic structure - if that person has even an inkling of functional programming experience, they should be just fine.
It's not about hiring elixir developers, but hiring developers who would be interested in learning elixir. We have tons of quality people in our pipeline, but 50% of the time they end up joining dropbox or google instead, and we had to work pretty hard to get that percentage as low as it is. I don't personally feel like elixir would be a _con_, but alternatively, we could adopt Go or some other language which has a big community and tap into that talent pool. Tech stack is unfortunately a talent attractor and people make assumptions on your company's engineering culture based on it. 
The mix command is to be used from the command line not from inside the iex repl. Try using the mix command from your windows console.
I'm writing a [free web app monitor](https://nonstop.qa) which checks all users' requirements every ten minutes. Maybe there's a better way to architect this? Currently, a cron job runs a rake task every ten minutes: It creates jobs for Resque workers which generate [RSpec using custom matchers](https://github.com/dogweather/rspec-webservice_matchers) on the fly for each project to test. The workers shell out, run the RSpec and receive JSON results which they store in the database. I'm able to run 10 concurrent Sidekiq workers doing this, but I'm working on reducing the memory use by breaking off pieces into microservices.
I think the way I'd do it is just create a genserver which every 10 minutes receives a message to generate exunit tests. Basically it sounds perfectly doable, but it's hard to translate individual tools because tools are a product of their language.
I've seen gen_server on a timer suggested a lot but I'm curious how people handle the distribution problem. For example pretend you need to do some operation for every user in the DB every hour, and you have 3 instances of your app running. How do you ensure that reliably all users get updated, without duplicating the work 3 times? For extra points - what if it's running on some cloud infra and instances can be rebooted/migrated between machines without warning? Do people generally use a separate "master" instance running a different erlang application to schedule the work?
If by cloud infra, you mean containers, the only answer I've gotten from Erlang people is "don't".
Awesome! :)
If you wanted to, you could probably define a sigil that called out to System.cmd: http://elixir-lang.org/getting-started/sigils.html
Because it runs on BEAM you have the full Erlang ecosystem that works for you, but you will need to somewhat understand Erlang to read their docs. I wouldn't say anything is particularly bad, but this isn't a magic pill. You make tradeoffs. Writing idiomatic elixir is going to be weird coming from an OOP background and distributed concurrency isn't easy, its just easiest in elixir. I'm sure as FP continues to gain in popularity many people will start disagreeing with some elixir choices, like not being a static language is a con for some, but I consider it a pro. It's a well designed language though and you aren't going to feel like you're writing magical spells that work for some unknown reason. It's really good about being explicit and avoiding code indirection.
One problem that I have is, it's pretty hard to see the performance gains of Elixir, at least on a small scale right now. For example, [this is a program](https://github.com/amw-zero/qwerty_dvorak.ex/blob/master/lib/qwerty_dvorak.ex) I always write when learning a new language. I can explain it further, but long story short, the program opens up a dictionary file, converts each word to what that key sequence would be when typed on a Dvorak keyboard layout, and checks if the converted word is still in the dictionary. I've tried a few different versions of this in Elixir, and the performance has been disappointing so far. String comparisons and raw computation seem to be a downside of the Elixir/Erlang ecosystem. Just because Elixir encourages concurrent code doesn't mean that it will always result in increased performance. That being said, I'd love if anyone has any suggestions on how to make this faster, I am still very much in the beginning of learning Elixir. And, don't get me wrong, I love it so far! Mix does a great job at wrangling the building/running of Elixir apps, but I don't even know if I'm running a compiled or interpreted version of the program. This could be a downside as well, coming from Ruby where it's always `$ ruby program.rb` to run a program. It's just more complex to build and deploy with Elixir by nature of having to run on the Erlang VM. And that's my main point here, is that the [Ruby version](https://github.com/amw-zero/qwerty-dvorak/blob/master/qwerty-dvorak.rb) of this program is still much faster than the Elixir version right now, while the Elixir version is more complex to build and run. I'd be really happy if I could write a version that beats the Ruby version in Elixir. All in all, the language and tooling/ecosystem are fantastic. Seriously. But being transparent about shortcomings can lead to making it even better.
The main negative that I find is its not built for certain tasks. If you're doing tons of math, list mutation, or CPU heavy loads, it is not an ideal choice. It's designed to be fault tolerant and highly parallel, but that goal is not without its sacrifices. Just make sure your use case isn't "Elixir for everything!"
I can see how it's easy to see that. About half of Elixir users come from Ruby, which is generally a love or hate type of language. Erlang syntax is also pretty messy, so if it's not your cup of tea to marry the two, it can seem pretty awful. For me, it's just different. Different takes getting used to.
I love the enthusiasm haha. The metaprogramming is super Lisp-y. Which I like too. And don't even get me started on pattern matching. It's not like Elixir or Erlang invented that, but I have been LOVING it lately. My functions almost never have `if` in them! And I hate `if`. I really do. I find it really elegant that each clause of a function operates on a specific pattern of arguments and you can only focus on that pattern of arguments inside of that function body. Of course, it's kind of subtle. It's the same logic that's going on with `if`s inside of a function, and there's still a runtime penalty for using function clauses with pattern matching of arguments (no free lunch!). But mostly I love how we're taking back the `=` operator. The `=` operator makes no sense in other language as assignment. We grow up writing equations like `2x + 5 = 13` and that means that both sides are equivalent. Assignment statements (and in many ways statements in general) are just dirty to me. Pattern matching all the way.
Just curious, have you tested the difference between start up speeds and actual run speeds? For example in Java it may seem like a slow language at frist because the JVM takes a bit to start up, but in actuality it's quite fast. Just an idea that popped to my head on why it may run the Ruby version faster.
Yeah that's what I've heard. Although I guess it makes it up with concurrency, eh?
Now that you mention the if statement, I find it a felony if I don't add this picture. This blew my mind https://imgur.com/e8hO6TZ
OK. I don't mind the syntax. Thanks for your opinion. :)
Cool. Thanks! :) Guess I'll have to brush up on Erlang maybe.
Yeah that seems like it'd be a problem, especially if one comes from an OOP background.
Metaprogramming FTW. :)
Nice read. Thank you! :)
Oh boy that's rough. But that example is kind of why `nil` stinks, right? You wouldn't need to check if `x in [false, nil]` if there were no `nil`. You could just match on `false` and the case would be much neater.
I too have found that file and string operations in Elixir/Erlang seem to be very slow. Just opening and reading a file with 600k words into memory using File.read! takes 3-4 minutes(!) on a Macbook Air. EDIT: As pseudothere points out below I must have been doing something wrong. It takes about 7 seconds to read 600k words on a Macbook Air.
I've been using Elixir (and Phoenix) for about four months now on a production application at my company. All in all, it's a wonderful language, and I have very few complaints. That said, here's what I've found to be a problem so far: * OO -&gt; Functional switch. Also Elixir's biggest strength. That said, Elixir and Phoenix look enough like Ruby and Rails, at least on the surface, that it's occasionally frustrating to have to rethink all the design patterns I've learned over the years. * Deployment setup sucks. It's getting better, but there's no capistrano-like fire and forget solution. Be prepared to do a fair bit of DevOps work to get a deploy script that works for you. * Erlang leaks through in quite a few places. You don't need to be fluent in the language, but you'll have to learn enough to at least comfortably read the Erlang standard library documentation. * Dialyzer is a pain. There's optional typing, but it's not built into the compiler or the runtime, and most of the tooling still assumes you're writing erlang instead of elixir.
No, just look at how unless gets transformed at compile time to pattern matching. It's so cool
I think erlang syntax is not messy because there is no case where you can not be sure about what something is. For example you can't doubt if something is a function argument or a list element.