Yes, Nim is garbage-collected. Nim is not memory-safe if you do not use garbage collection; last I looked it is also not memory-safe in multithreaded mode if you do not use the Boehm GC. Rust is the only industry language that supports memory safety without garbage collection (and supports dynamic allocation).
Yeah. Phillips was also patented, he was just more willing to deal with Henry Ford. It is crazy to think what can be patented.
Per the documentation, those memory regions don't look anything like Rust's lifetimes. They look like a simple case of "newtype wrapping" for pointers and do not uphold any of the safety guarantees that Rust's stack references do.
Yeah that seems to be the case. As I understand, Nim doesn't pursue the ideal of "no dangling pointers, no NULLs, etc." - it doesn't indeed try to be memory-safe.
Tl;Dr. "I already understand C and Nim is closer to C."
If he wanted C, why didn't he go with C? Now he has a meta-programming system on top of C and look how well that worked before.
I encountered a similar problem after the most recent rustup. After changing this: .map(|thingy| { Person {email: thingy.email()} }) to this: .map(|thingy| { let c = Person {email: thingy.email()}; c }) the "`thingy` does not live long enough" went away.
 .map(|thingy| { let c = Person {email: thingy.email()}; c }) Looks like a bug to me. What if I delete thingy? Or does `thingy.email()` do some kind of auto-copy?
My understanding is that all commercial implementations of Ada require a garbage collector for memory safety in the presence of allocation (or more specifically, deallocation). I also don't think any implementation of Ada guarantees data race freedom in the presence of multiple cores, like Rust does, but I could be wrong about that.
The main Ada deployments that I know of all statically allocate all memory outside the stack. That can be a form of memory safety, but it's not exactly what people usually think of when they hear the phrase...
&gt; add one line Couldn't cargo have something like "add" so you just do "cargo add hyper" or "cargo add io"?
While you do have a notice about Rust still changing, you might want to paste a `rustc --version` in there, so there's some record of which one it does work on. (Can't wait till this isn't needed anymore.)
I don't know what I said in my comment that contradicts what you said. In Rust, `char` is a Unicode scalar value which is a subset of Unicode codepoints. So what I said seems to be in perfect alignment with what you said. (UTF-8 doesn't seem relevant here, the author has a single byte, and I prefaced my claim by saying, "if it's latin-1...")
Yes, this is something that may get added to the CLI.
You can pattern match in arguments, except in self.
&gt; There are other small things that turned out not to be a problem, but were nevertheless overcomplicated. Look at this line: &gt; &gt; centroids = clusters(points, &amp; centroids).iter().map(|g| avg(g)).collect(); &gt; &gt; Why do I have to convert the vector to iterator and back, instead of being able to map it directly? I guess this is to leave the possibility to map into another container type (say, from a Vector to a List), but adding a map function on Vector would have not prevented this more sophisticated use. I don't quite understand what he complains here about. How would it be possible to map on vector directly if input and output are of different types: `Vec&lt;Vec&lt;Point&gt;&gt;` and `Vec&lt;Point&gt;`. And why would anyone need to write `|g| avg(g)`, isn't it the same as `avg`?
&gt; It seems like he's making this decision on first-impressions instead of taking his time to research the issue To me it seems more like his first impression wasn't so good, and instead of spending more time to research it and understand how it works, he went with something he's already comfy with. That sounds like a pretty reasonable choice to make; why spend time learning how to program well in one language when there's another language that you're already pretty comfortable with which fits your needs as well? Recently, I've been writing some Go code for coursework (because I have to; I'd have preferred Rust otherwise). It's a field where both Go and Rust are suited (concurrent programming), but I keep getting annoyed when Go doesn't give me the tools to do something I could do easily in Rust. For example, I wanted to send typed messages between channels, however Go doesn't give enums (and interfaces get automatically implemented depending on the methods implemented for a type), so I ended up using `interface{}` everywhere -- this is something between `Box&lt;Any&gt;` and a void pointer. But this isn't really an issue with Go; it's an issue with me. I'm approaching the language with a Rust-y style of coding, so of course I'll be programming it in a way that expects stuff like enums and generics to exist. A lot of the annoyances are just because I haven't yet learned the Go way of doing things. Given a choice, would I switch to Rust? Yes; in a heartbeat. Does this make Go less suited for that application? Not automatically. I bet if I had the time to learn the Go way of doing things, I'd find myself able to use the language quite capably. But that's an investment of time that I'll have to consciously make. It seems like the author of rustix decided against doing so. (I'll probably be writing a blog post on my experience as a Rustacean with Go later)
Does that mean that writing Rust is "literally writing LLVM IR"? Or ASM? Or byte code? The author is writing Nim code. You asked why he *didn't* go with C. I explained, with a guess, that perhaps the author is going with Nim because he finds it more exciting and fun than *writing C*. This seems entirely reasonable to me.
So if a type `thingy.email()` returns is `#[deriving(Copy)]` this works, correct? Then why doesn't `.map(|thingy| { Person {email: thingy.email()} })` work? 
For example, when I switched from Perl to Ruby, Moose was just a brand new thing. Many, many things in Ruby were just nicer and cleaner than pre-Modern Perl. Most languages are Turing complete. It's not a matter of 'can do,' it's a matter of 'is nice to do.' That said, Skylight.io's Ruby-gem-in-Rust is a direct example: the Ruby version used significantly more resources, and leaked them. The Rust version is not only incredibly more lightweight but also doens't have any leaks.
C++ also supports memory safety without garbage collection. You just have to allocate memory using exclusively `make_unique` and `make_shared`. Can you do unsafe memory operations in C++? Yes, but in the same way that memory safety in C++ is "opt-in", you can also opt into memory un-safety in Rust. And about Rust being an industry language... that is very arguable. Somehow I feel that people in this subreddit forget that we have been writing large-scale complex systems without memory safety for decades. Memory safety is a good thing, but it isn't everything. And Rust is lacking with respect to other languages in the non-memory side of things.
Oh don't get me started on distributing ruby applications! ;) This is so complex that some projects (eg Vagrant) end up embedding their own Ruby ecosystem to avoid the compatibility issues. Good point, desktop applications is a big one (though the GUI toolkit part is a bit lacking on Rust today). You post inspired me to write a client (something like amazon's CLI client) to an internal app that I have on work. Would be a nice way to introduce Rust to the people at the office, and I wouldn't need to worry about ruby version and bundler and rubygems and whatnot. Thanks :)
`unique_ptr` and `shared_ptr` are unfortunately not memory safe (e.g. dangling references, use-after-move), and, anyway, it is possible to get memory unsafety without any allocations at all (e.g. a dangling reference caused by returning a pointer into stack data). Also, it is hard to avoid data structures like `std::vector` (which allocate memory), and these bring in additional insidious memory safety problems, like iterator invalidation. Modern C++ has definitely made improvements with respect to memory safety, but there is not any reasonable memory safe subset: even just plain (signed) addition isn't, since overflow is undefined behaviour.
Memory unsafety is not opt in in C++. It is not even opt out. So I think it is different :) &gt; Somehow I feel that people in this subreddit forget that we have been writing large-scale complex systems without memory safety for decades. Memory safety is a good thing, but it isn't everything. And Rust is lacking with respect to other languages in the non-memory side of things. There are certainly many areas where Rust could improve, but overall I think it's already pretty good (and most of its biggest issues are just standard library things that are easy enough to swap out). For me, Rust hits the sweet spot for those times when I don't really want to give up anything--when I don't want to give up speed, or control, or safety. I wouldn't use it to build a website, but most of the usability tradeoffs it makes are made with that in mind (not *all*, but most). As for your other point, I think everyone here is aware that you don't *need* good tools to make good software (look at PostgreSQL!) but it certainly helps. Rust has liberally stolen from many other good languages when it comes to things that don't involve memory safety, and (though I'm biased) I think it has done a pretty good job at selecting their better features. But if you have ideas on how to improve the other aspects, please write up some RFCs!
Had Rust defined signed addition overflow behaviour already?
You're right. I was thinking in terms of production code but his is a hobby project, by what I can understand.
That feels like something for crates.io rather than the standard library.
Sure does; modulo bugs, any `rustc` can generate code for any supported platform ([built-ins](https://github.com/rust-lang/rust/tree/cf636c233dfeef5abf0de8fb35e23c0a161810d2/mk/cfg), but there's also ["flexible target specification"](http://doc.rust-lang.org/nightly/rustc_back/target/)). As an example, // barebones.rs #![feature(no_std, lang_items)] #![crate_type = "staticlib"] #![no_std] #[no_mangle] pub extern fn add(x: i32, y: i32) -&gt; i32 { x + y } #[lang = "sized"] trait Sized: Sized {} #[lang = "copy"] trait Copy {} On my x86-64 Linux computer, running `rustc -O --emit=asm barebones.rs --target=aarch64-unknown-linux-gnu` works fine, emitting this aarch64 assembly: .text .file "barebones.0.rs" .section .text.add,"ax",@progbits .globl add .align 2 .type add,@function add: add w0, w1, w0 ret .Ltmp1: .size add, .Ltmp1-add (I chose that platform because it emitted the shortest asm, but most of the others work.) That said, there's so much we can/should do to improve before we can call the experience *nice*. E.g. a cross-compiled copy of the standard libraries is required to do anything meaningful, and its not ridiculously easy to obtain them: building rust yourself with `./configure --target=platforms,you,want` works, as does using a nightly by extracting libs from the corresponding nightlies for the platforms you wish to target. Once we've made installing the some extra libs easy (and possibly a few other things), running `rustc --target=...` should just work, as should `cargo build --target=...`.
I just saw [this thread here](http://www.reddit.com/r/rust/comments/2vr3kj/dropck_question/) which refers to [#22252](https://github.com/rust-lang/rust/issues/22252). This may be related.
Yup, it's been defined for at least as long as I've been using Rust. :)
Maybe it's that you might have an array with 10^4 elements, but are unlikely to have a struct with 10^4 elements?
`map_in_place` is already a thing, do you mean something else?
`map_in_place` has additional constraints.
NIM has a lot that I like (overloading, do notation), and I definitely like the idea of compiling to C (I think C is still has more widespread support than LLVM), but as far as I know it's oriented toward garbage collection , it doesn't have RAII (are they adding it??) .. so Rust remains more interesting. Superficially I also prefer braces to significant-whitespace.. works well with expression-syntax IMO. I think I might have read they want to retrofit RAII and 'blocks=expressions' to NIM, that could be interesting, and their claim of realtime control over the GC is also intriguing i.e. run it for a controlled timeslice
I think you didn't shorten the Sub implementation (Add seems to not have pattern match anymore, while Sub still does) 
Oh yeah, I just did `Add`, I forgot `Sub`.
I agree with all your points. You'll be happy to know that there are people actively working on addressing them! In particular: variadic generics and inheritance have concrete plans (I don't actually *want* inheritance, but it is in the works), and if and when someone actually comes up with a proper proposal for HKTs they seem very likely to be added to the language as well. CTFEs are a huge sore point and I fully expect Rust to step up in the future here, but I expect they might come last / piecemeal for whatever reason... just a hunch. As for your fourth point, I am hoping to try to add extension methods to Rust to help address some of the boilerplate of writing *non*generic code, but I'm afraid I don't see how to resolve the &lt;T as Trait&gt; thing (well, without relaxing coherence). Maybe you can enlighten us! Like I said--there's lots of room for improvement. But I'm quite optimistic that most of these issues are going to be solved :)
Note that Rust boxes are as expensive as `shared_ptr`s in C++, and that `shared_ptr`s are thread-safe (the reference count is atomic). And IMO it would be good if it were true. If you state this now, and a newbie tries the language, it will probably never come back, because it isn't true. Rust compiler/tooling/language spec/language features/standard library/library ecosystem are not industry level. I don't see how lying about it can be any good.
&gt; And the design seems... hacky? In comparison to Rust, that's at least partly because Rust took a *long* time figuring out what its feature set should be in a remarkably hacky manner, then the developers simplified it a *lot*. Rust of the first half of last year was covered in sigils for things that have since been moved into traits and types that act like every other trait and type, for example.
No, they're not. You're misinformed on this point. `unique_ptr` is if anything marginally more expensive than Rust's `box` since it has to zero out its contents (well, Rust's box does too right now, but not for long, hopefully). As for `shared_ptr` being thread safe, this is only true of the reference count itself. C++ has absolutely no way to enforce safety of any other operations with the data. And in practice, the atomic overhead is high enough that in performance-sensitive applications people generally roll their own unsafe single-threaded version (which Rust can provide safely in the standard library).
Ah, I see. Yeah, it would be nice if Vecs supported more sugar, I have mixed feelings about every Vec method ever being sacrificed at the altar of the Iterator.
It's not necessarily that Ruby (or insert whatever language you want) isn't practical for things, it's just that sometimes another language comes along that you'd rather use for those things for whatever reason. For the things I used to do in C++, I think Rust is an advancement in ways that I care about and I'd rather use it. For some of the things I used to use Ruby for, I now would prefer Elixir. It feels like the right kind of advancement over Ruby for some of the things I care about.
Oh, nice. I feel better about using `interface{}` now :) I did something slightly different, `type Message struct {data: interface{}}` because `Message` was possibly going to have some common fields. Yeah, it reinforces my point, basically :) Btw, is `interface{}` always vtable'd over all types, or can it get an enum-like representation when the compiler detects that its only being used with some types? I still feel rather dirty about using something which is effectively a `Object`/`Box&lt;Any&gt;` with the associated vtable and costs. Then again, I guess the Go way of thinking about this might be that small perf losses are okay for ergonomic gain; after all it's also a GCd language, which makes my life very easy but also reduces performance.
`map_vec` sounds pretty nice
&gt; `std::vector&lt;smart_ptr&lt;T&gt;&gt;` This not equivalent because it has a runtime cost, both in space and time. Rust can guarantee it without a runtime cost. 
I don't know that kind of detail about the compiler's optimizations unfortunately. :-( But I've certainly always thought of an interface having the overhead of vtable lookup. In the Go world, if you need better performance on generic code, then the answer is usually to copy &amp; paste (or better, code generation) for specialized instances. I've had to do it once or twice (but only after a benchmark proved it was worth it).
I wonder if this could be tweaked to work off git tags. So if/when a new tag is pushed, cargo publish is run. This way, you'd avoid the "build failing" status for every commit that was not a release.
Even for production, if you're currently working with C, having the generated C be visible (and sane enough), and working with all your current debug tooling and setups sounds like it can be an advantage. For tricky hardware/software interactions it's probably also nice if you already have the C knowledge. I have to say though that the above are all guesses, since I'm a high-level dev really liking the fact that with Rust the only C I have to think about is FFI :)
I actually have a feature request in for cargo that makes `cargo package` create the tag. Bundler does this in Ruby world, it works great.
It would be nicer if these were functions that operated [on iterable types](https://github.com/rust-lang/rfcs/issues/397) so you didn't have to call `.iter`. If there is UFCS, this would then just be centroids = clusters(points, &amp;centroids).map(avg).collect(); 
We have [IntoIterator](http://doc.rust-lang.org/std/iter/trait.IntoIterator.html), which is close. But I don't think we can do `impl&lt;T: IntoIterator&gt; Iterator for T`, because `IntoIterator` takes `self` by value.
Simple things should be simple, compare that with the following approach (using a D's static if like feature): fn do_a_thing&lt;T: Number&gt;(thing: T) { if (T is i32) { // compile-time branch println!("i32"); } else if (T is i64) { println!("i64"); } } This approach is less extensible than the trait approach. The resulting code is, however, simpler and involves less boiler plate. If you want extensibility, traits are awesome. But if we are talking about an implementation detail of an algorithm, you might not expose those traits anyways, so then you are just adding boilerplate for no gain.
And now try to add a simple for loop...
I'm sure it already exists then.
I used "industry" not to mean "production quality" but to mean "not an academic language".
The biggest problem with that approach is that it doesn't really work with threads—such a thing is inherently racy. Nim gets around it by not having a thread-safe GC (sending pointers between threads segfaults, last I looked), but I don't really consider that a viable solution for large-scale systems. To Nim's credit, they now have the Boehm GC as an option, which is an excellent choice; the Boehm GC, contrary to popular belief, is actually an outstanding implementation given its design limitations.
It did, but 'deref coersions' landed, so this is how you do it now. Yup, you'd allocate two pointers. Not a big allocation, and often on the stack, but still an allocation.
&gt; In order to make the comparison valid, I have to add an &amp; You shouldn't have to: fn main() { let a_str = "Hello, world"; let a_string = a_str.to_string(); if a_str == a_string { println!("YES"); } } 
Quoting myself: &gt; This approach is less extensible than the trait approach. But still, this statement: &gt; Except maintainability and flexibility in large programs. Traits are awesome for specifying generic interfaces and writing/using generic components. But for compile-time branching, they force you to pay the extensibility/maintainability price up-front, even when you don't need it. If you just need to branch based on the type, the traits for doing so will be an implementation detail that you won't expose. That buys you no extensibility/maintainability at all. Anyhow the compiler does know which types are handled, and when you call the function with a type, it knows if that type is handled or not. Worst case you get a compilation error. &gt; how would you prove that you're handling all cases with your design, With an `else` for if-clauses and a match anything `_` for switch statements you can specify what happens for any other type (like a compilation error, or do something different at run-time).
It was also part of 'deref coercions', so it's been a few weeks, but yeah, very recent :)
Why don't `RingBufReader` and `RingBufWriter` actually implement `Reader` and `Writer`, respectively? And why not implement that on `RingBuf`itself? Seems like a whole lot of pointless indirection to me.
Maybe i'm so used to unconstrained generics, that I just try to use constrained generics in the wrong way or with the wrong idioms and that feels frustrating. I haven't found any documentation about how are they typically used in practice or what idioms have emerged (even the documentation on Traits is lacking on, e.g., generic trait examples).
&gt; But this isn't really an issue with Go; it's an issue with me. I'm approaching the language with a Rust-y style of coding, so of course I'll be programming it in a way that expects stuff like enums and generics to exist. A lot of the annoyances are just because I haven't yet learned the Go way of doing things. I'm looking at Nim right now because I've found in Go that *"the Go way"* is ultimately to use hacks to work around language deficiencies and then convince yourself that it's OK because it's *"the Go way"*. That also seems to be the primary response from the community to criticism of the language. Rob Pike made it pretty clear last year that the language is closed, so I don't see things improving too much any time soon.
Great point on RCs. On .iter() though, maybe it's just me, but I really like code to be explicit. Instead of having to remember a litany of arcane copy ctor rules every single time I get near a vector (Hi C++), I rather spell what I want, and especially read what I wanted 3 months ago. I would be very worried if my productivity bottleneck were my typing speed, especially given a half decent IDE.
Yeah. Sounds like my laptop got behind. My fault. :)
I need to write up my "opt-in autoclone" proposal I've discussed on IRC sometime. We could quite easily support copy constructors on an opt-in-at-use-site basis, allowing the ergonomics of a high-level language precisely where you want it.
So should I still wait to completely dive in?
Nope. He said that it generates readable C. The most enjoyable thing about C is that it's a thin layer around assembly. So by saying that he is saying that he has a direct access to the memory layout. It's also easier to follow how things are translating to machine code. Rust is not that transparent.
&gt; Why don't `RingBufReader` and `RingBufWriter` actually implement `Reader` and `Writer`? First they can, the main reason why they don't now is because there has been a large amount of churn in the std around these traits and I have just been waiting for that to slow down. However, this would only be a convenience implementation. The entire point of the `Buf` and `MutBuf` traits is to efficiently work with `Read` / `Write` values **without** double copying. If RingBuf only implemented the `Read` / `Write` there would be no way to move data to / from sockets w/o a double copy. The tl;dr of `Buf` (and there does need to be more docs) is to encapsulate the pattern of passing a slice to read from a socket, getting the # of bytes read, and advancing the cursor. That's what it is for (`MutBuf` is to do the same with `Write` values). Hope that this makes sense. &gt; And why not implement that on `RingBufitself` `RingBuf` has gotten the least amount of love so far. I was mostly trying to get `ByteBuf`, the `ByteStr` (immutable sequence of bytes` abstraction, and the `Rope` implementation done. The original reason that `RingBufReader` and `RingBufWriter` were split out was because `MutBuf` used to extend `Buf`... which was bad and caused problems requiring this indirection. I have since fixed the traits, but I have not gotten around to updating `RingBuf`.
Things should be largely stable from here on, but there's still work to do in e.g. catching up the documentation with all the changes that have been happening. If you want a polished experience with very little breakage, beta might be the best point to "completely dive in".
As always, it depends on your tolerances. If you don't want to have to re-learn anything at all, then wait until May 15. If you don't mind minor things changing, and don't mind some small rough edges in things like error messages, documentation, and other stuff, then any time after next week is a fine time.
One thing about this: I can't fix doc issues I don't know about, so if you care about docs, it might be good to give it a poke, and then open issues about stuff that's missing. But not everyone has time for that, so no worries if you don't. :)
If you compiled the C output from Nim with Clang wouldn't that just essentially put Nim and Rust in the same LLVM boat? :P
It's not just typing speed, it's reading complexity. Ruby is probably the poster child for really simple pipelinable collection APIs. You can type things like User.all.find_all do |uu| uu.friends.map {|ff| ff.name }.include?("Joe") end And get a vector of all users with a friend named Joe. It's not especially efficient, but it sure is readable once you have a feel for the basic sequence methods. Adding in ".iter()" and ".clone()" and a bunch of dereferences because you got an immutable reference instead of an immutable copy (which should be optimized to an immutable reference anyway) is just extra complexity.
If you're opting in at every usage site, that's not going to be better than just typing .clone().
&gt;Rust is the only industry language that supports memory safety without garbage collection (and supports dynamic allocation). How exactly does Rust do this? Is it as simple as unallocating the memory once the lifetime expires?
Thanks for the ping! I'll make sure we make some progress here.
&gt; It was gonna be a GC-by-default, green-threaded thing, unsuitable for actual systems/low level. I don't think there was ever going to be a GC enabled by default - it was supposed to be optional - and green threads were always optional as well. Then they decided to simplify the language a lot and it no longer has the option of either.
&gt; Rust also changed its target a bit mid-course, right? Rust never changed its target. It's just that the way of accomplishing those goals was very, very different.
No; I'm more suggesting changing `IteratorExt` to something like: pub trait IntoIteratorExt: IntoIterator where Self: IntoIterator Forgive me if the syntax is wrong; I'm not used to Rust. I would expect one could then just remove the trait in favour of top-level functions. Currently it is: pub trait IteratorExt: Iterator where Self: Iterator 
I've definitely run into a couple of places where it would have been useful.
Funny, this is also what I said to people when they asked whether /u/steveklabnik going for Rust is a sign of the end of Ruby. Sorry for speaking to myself. Just occured to me while rereading.
Awesome! I wish ptrace wasn't gutted on OSX, so you could use the same APIs rather than having to write a whole 'nother set that does the same stuff over mach's ports and message passing.
Yeah that's fine or things that aren't that straight forward.
Multiple iterators are great, but that doesn't mean that you can't have a vec#map that picks a default iterator. To get the standard behavior for the "map" function as expected by users of other languages, you'd end up doing an implicit allocation. Specifically, the iterator you'd want would be ".clone().into_iter()". This does bring up one disadvantage to how explicit Rust is. With all the lifetime information kicking around, it should be possible to optimize for memory reuse. If the compiler sees that the input to #map is never used again, there's no reason to .clone(). In fact, you should be able to do a pipeline -&gt; loop transformation for a series of sequence method calls - but Rust may have trouble doing that due to how explicit it makes the user be about exactly *how* to do each operation. 
&gt; The new IntoIterator trait is now available and used for for-loops, making it possible to write `for x in &amp;vec` rather than `for x in vec.iter()`. Best new feature ever.
Oh; agreed, Go could quite easily be worse than Rust for even applications which Go was designed for (eg my cocurrency stuff). I'm just saying that most issues as a newbie can be attributed to muscle memory from previous languages. Almost every time I see a "I don't like Rust because foo" post, its almost invariably answerable by "foo isn't how you do it in Rust, try bar". I find the workarounds quite hackish myself. But I also found some workarounds (like using enums when you want single inheritance) quite annoying and hackish when learning Rust. Now I find them okay. I'd like to objectively say that Go is lacking some things and this hurts the language; but I can't be sure if these things are really needed until I am able to code in the "Go way". Because some of these workarounds might disappear when my entire code is written that way. Though my guess is that many don't, which is one reason why I'm not spending valuable time on improving my Go. And since Go doesn't have performance as a hard goal (unlike Rust, which tries to make abstractions zero cost wherever possible), the acceptability of the "hack" depends on what you're using. In Rust I think twice before using Rc/Arc. In Go, I'll use GC'd pointers *everywhere* and not feel bad about it.
&gt; Rust is the only industry language that supports memory safety without garbage collection (and supports dynamic allocation). ATS does too and it is used in at least one production system - maybe not industry enough to count for your criteria though.
&gt; It's way too early to pick a blessed HTTP library. I very much predict there to be one at some point, however, at least a client: Because cargo. Depending on curl feels somewhat... dirty.
I think looking at the other side of the coin is more interesting: how hard is it to write memory *unsafe* code in the two languages. That is, how easily do small mistakes cause huge problems (like reading private keys directly out of memory). In C++, it's very, very easy to have memory safety problems with no indication from the compiler that there is one. In Rust the default code you write will be safe, and you have to explicitly tell the compiler "I want to live life on the edge" by typing `unsafe`. &gt; If you only use smart pointers created with make_shared and make_unique, you cannot get a pointer to stack data in the first place If you heap allocate everything (including e.g. loop counters) and never use the stack for anything other than storing those pointers, and never use references, you're paying a huge runtime cost for memory safety, and it's not even *guaranteed*. You also have to be careful to use `get` or iterators, everywhere with `std::vector`, never `[]`, and much of the `algorithm` header needs very careful thought (functions take multiple iterators but only do any bounds-checks/limiting with one, so the other iterators can run off into unallocated memory if they're not long enough).
Sure, Cargo can switch to a pure Rust HTTP library. That doesn't entail picking it as *the* official Rust HTTP library. Cargo also uses TOML, but including a TOML parser in `libstd` would be a significant change.
&gt; which is one reason why I'm not spending valuable time on improving my Go That's good. I spent 2 years trying really hard to like Go and it certainly has its merits but with so many other great languages popping up like Rust and Nim I've finally broken away. I'm sure I'll still use it for little stuff here and there, but nothing too serious. I'm holding off on Rust until their 1.0 release and learning/using Nim right now. So far so good.
def, am I correct in saying that much GC/heap allocation can be avoided by using `var` parameters? That's the impression I have of how it works but not totally sure.
That doesn't sound right. An immutable parameter should not cause a copy either. Don't cause allocations and the GC won't run.
Very cool work! Is reading from another processes' memory completely memory-safe, as in doesn't need "unsafe"? Especially the string reading. And I guess writing will at least be unsafe?
Piston. [Definitely Piston](http://www.piston.rs/).
I've been working on a high performance CSV toolkit: https://github.com/BurntSushi/xsv --- It's not finished yet, but it has been a fun project and has already come in handy a few times at work, particularly the indexing support. (Performance in this context means it should be fast and use as little memory as possible.) It has caused me to build out a lot of dependencies: [quickcheck](https://github.com/BurntSushi/quickcheck), [csv](https://github.com/BurntSushi/rust-csv), [elastic tabstops](https://github.com/BurntSushi/tabwriter), [basic stats](https://github.com/BurntSushi/rust-stats) (e.g., streaming standard deviation), [argv parsing](https://github.com/docopt/docopt.rs). And for the future, [suffix arrays](https://github.com/BurntSushi/suffix) and [cbor (binary JSON)](https://github.com/BurntSushi/rust-cbor).
Hmmm, ok. I'm still pretty new and I must have misunderstood something. Going to try to find whatever it was that I read. Thanks for the info.
I'm busy revamping [img_dup][1], my biggest software project in Rust to-date. It's a tool for finding similar and duplicate images in a directory tree based on perceptual hashing, and I even built a GUI for it with Conrod. [1]: https://github.com/cybergeek94/img_dup
Each closure expression has unique types so that they can undergo static dispatch and hence be inlined/optimised. One has to opt-in to dynamic dispatch and type-erasure by creating a trait object of the appropriate closure trait. One way to avoid this would be move the `condition` check inside the closure, like let test = |n: usize| n &gt;= 6 &amp;&amp; (n &lt;= 15 || !condition); although this may impose extra cost. That said, the dynamic call that is required to be able to use multiple closure types is likely to be expensive too. In this case, the closures are zero-sized, so the allocations are free, but in general, there is a trick to avoid the allocation for non-escaping things that want a bit of dynamic polymorphism: let (closure_1, closure_2); let test = if condition { closure_1 = |n: usize| n &gt;= 6 &amp;&amp; n &lt;= 16; &amp;closure_1 as &amp;Fn(usize) -&gt; bool } else { closure_2 = |n: usize| n &gt;= 6; &amp;closure_2 as &amp;Fn(usize) -&gt; bool }; The `closure_1` and `closure_2` variables are never used other than inside the `if`, they're just to ensure there's a spot on the stack in the right scope to store the closures. This strategy works for arbitrary trait objects.
The optimizer has no trouble doing this sort of thing as long as it can see the bodies of method calls (which it can for most clones). The lack of magic doesn't make this any harder for LLVM.
I firmly believe LLVM IR was a better choice for Rust than C. Whenever you need to add anything to the IR, be it garbage collection metadata, tail call annotations, precise aliasing information, or--most importantly--*debug information* that goes beyond `#line`--you need to not be constrained by the limitations of the C language.
"It should probably just be fixed at the compiler level. I don't want to do any premature optimization."
It’s definitely worth checking out Maven’s release process as well. It’s nicely automated.
Can't wait for that!
Isn't it safe from the caller's perspective? No matter what you do in the other process you cannot corrupt your own memory. As far as I know unsafe is not supposed to mean "probably dangerous to your application stack".
Yes. I just rechecked "the Book", and basically I went through Generics; then I went through traits. The traits part does not mention (or I didn't see it) that you can make a Traits generic. The syntax within generic traits is also a bit special, like for disambiguating when you implement a generic trait method as a function of other methods from the same trait. I think examples would help. What would have helped me most is a "using generics correctly" section. For example, how to write a "min" function. In C++ there are a lot of tutorials (and two books!) on generic programming about how to do this! See for example [0], which is a 5 part series (the books are Elements of Programming and From Mathematics to Generic Programming). How to write generic algorithms like "find/find_if", or "rotate" using Rust would be also awesome examples. Another thing that would have helped me is a section with common idioms. That is patterns, that have emerged within the community to solve common problems. An anti-idioms section (patterns that newbie use which shouldn't be used). I understand that Rust is a young language, but I bet that if one starts a poll on typical idioms, a lot of people will agree on some of them. A similar poll on how the language gets used wrong by newbies would also yield some results. Since Rust has been used to write some larger applications already like servo, the compiler, the standard library, ... I think such information would be really useful. Mostly because otherwise it takes a lot of time to learn. Basically you have to read lot of code and make lots of mistakes to start recognizing these patterns. People come to Rust from different language backgrounds and some of them can shoehorn another language solution into rust and get it to work, but that is not necessarily the best/easiest/rusty way of doing things. [0] Writing Min Function (5 part series): http://componentsprogramming.com/writing-min-function-part1/ 
By using `for x in vec`, you get the same as `for x in vec.into_iter()`, while `for x in &amp;vec` corresponds to `for x in vec.iter()`. In the former `x` is by value, in the latter it is by reference. That means that the former will move out of values that are not `Copy`. For example: let v = vec![Box::new(1), Box::new(2)]; for i in v {} for i in v {} Fails with: iter.rs:4:14: 4:15 error: use of moved value: `v` iter.rs:4 for i in v { } ^ iter.rs:3:14: 3:15 note: `v` moved here because it has type `collections::vec::Vec&lt;Box&lt;i32&gt;&gt;`, which is non-copyable iter.rs:3 for i in v { } 
Exactly. Ruby and Python both have suffered by baking in terrible stdlib implementations that everyone is now stuck with.
*Jumping at the opportunity for a shameless plug* While its notability is debatable, if you're interested in low level networking it might be of interest to you - [libpnet (https://github.com/libpnet/libpnet)](https://github.com/libpnet/libpnet). libpnet allows manipulation of packets down to the data link layer, as well as the implementation of datalink/transport layer protocols at speeds equivalent to what you'd get with C, whilst also having some lovely safety guarantees, courtesy of Rust. (And, coming soon, the brevity of Python... Check back in a week or two!)
If I do something like: xs.clone().into_iter().filter(...a).clone().into_iter.filter(...b) can the compiler really reliabily transform that to let mut ys = new vec(); for ii in xs { if (...a &amp;&amp; ...b) { ys.push_back(ii); } } Because that's a pretty non-trivial transformation that preserves the *value* but not the memory semantics at all. This is the standard pipeline-&gt;loop transformation that languages like Haskell have no trouble with.
It's a bug. See [rust-lang/rust#20400](https://github.com/rust-lang/rust/issues/20400) for details.
Was Steve Klabnik the king of Ruby or something? On the face of it, that sounds ridiculous for such a popular language.
For 3D visualization, [Kiss3d](http://kiss3d.org/) is definitely worth a mention. I'm not affiliated with it, but I am pretty impressed with it. Its a high-level 3D graphics engine that's awfully easy to use.
I missed the part where you said Steve being in town was what prompted you to organise the meetup, so it read like you just happened to bump into all these Rust developers. Reminded me of [this commercial](https://www.youtube.com/watch?v=7g4Z1OYnlDM) (which coincidentally is for an Australian beer).
I wish! There's so many things I would do...
I doubt Rust would be within an order of magnitude from C++ if they're off.
I think we can make Rust's `unsafe` syntax extensible by libraries to cover things besides memory safety in a reasonable way. I don't have a detailed design, though! For a simple version you could make a default-deny [lint plugin](http://doc.rust-lang.org/book/plugins.html#lint-plugins) and add explicit #[allow(ptrace_calls)]
Pretty much every platform has a C compiler. I started writing a new program and that needs to support a platform without native support for Nim or LLVM. It only took me a few hours of fiddling with Nim to get it to work. I have no idea what it takes to port LLVM but it looks intimidating.
The git repository contains the make file to build the executable and it uses --release. I think the emphasis here is not so much on performance as different algorithms are used for the languages. That makes them not really comparable. If one would do a proper performance comparison between rust and C++ on this kind of code I would still expect C++ to win if compiled with gcc. At least in my experience gcc is still often measurably faster than llvm (which rust is based on).
Top links to github for the last year on /r/rust has a lot cool projects: https://www.reddit.com/r/rust/search?q=site%3Agithub.com&amp;restrict_sr=on&amp;sort=top&amp;t=year Unfortunately, this search also includes RFCs and issues on Rust itself, but I don't think the reddit search language is powerful enough to remove them (at least what I tried didn't work).
This is such a bold project. I've only watched parts of the series but it's a high quality production, and delivered well. Point people looking for video introductions to Rust toward this.
That ruby code is not obvious at all. If it does what you say it does, then it sounds more like a `filter` function. As I understand it, functions that end with `?` return bools, which means that expression in middle is returning a bool. Filter functions usually reduce the result to those that pass the boolean expression; `find_all`... I'm not even sure what that's doing. Is it hitting a database? And `include?` is weird too... it just reads really poorly. It sounds like you want to find all the users friends, but include Joe who's really more of an acquaintance. If `uu.friends.map {|ff| ff.name }` is some kind of iterable, then why not call the method `.contains?` ? `include` just really sounds like you're adding to it, not checking it (if it weren't for the `?`).
`uu.friends` is a collection of friends (could be an array, or something else that includes the Enumerable protocol), `uu.friends.map {|ff| ff.name }` is a new array of names of those friends. `include?("Joe")` returns true if any of the names is "Joe". You can skip the intermediate array by using detect/find (these are aliases) like this `uu.friends.detect {|ff| ff.name == "Joe" }`
Definitely! It's still very early on :D
Oh, I see, you want deforestation. Well, the point of Rust's iterators is that the compiler doesn't *have* to do deforestation.
Rust can compile to C via llvm-cbe (a C back end for LLVM, much like Emscripten is a JavaScript back end). This negates the point of part ability.
Rotations, no. It produces a different hash. Resizing/stretching, yes. Padding, I think so. Cropping, it depends on how much but usually yes. My main concern is edits (things added to or removed from the image, color changes) which show up in the hash quite nicely. img_dup will show the two images' stats when comparing them in the GUI or in the results output from the CLI, though I have yet to add the "file created" date. I don't concern myself with the original so much as the highest-quality copy.
Dan Grossman Coursera class use 'unnecessary wrapping' instead of Lambda Calculus scary (for a newbie) idioms. I agree that this is a very important thing (recognizing the existence of a smaller solution)
According to the blog, new rules to avoid `unsafe_destructor` has already landed, but with the latest nightly (from 2015-02-13 21:15) I still need to use `unsafe_destructor` for simple stuff [like this](http://is.gd/FrfpgJ)?
I think that "highest quality" is a good approximation of "original", but how do you measure quality? If I, for example, add white noise to the image, will it increase or decrease the quality? How the hash represent edits?
That looks great!! I've been working on a side project at work using your csv library and I've enjoyed it, I'll have to give this a try as well.
Equality bounds in where clauses are still being worked on. However, you can use something like https://github.com/darinmorrison/unify.rs in the meantime.
I just choose the image to keep based on highest resolution, since that's a direct factor in visual quality. `img_dup` only hashes and finds the images that are closest; it leaves it up to you to choose which one to delete and which to keep. The hash doesn't represent edits; if you have an unedited and an edited version of an image, the hashes will be only one or two bits off, and `img_dup` looks for that. It collates images based on how close their hashes are together.
`io:Error` is not a trait so you can't use :. What I was looking for is type-level equality constraints for non-associated types, which seems to be a work-in-progress according to the other comment. I believe (I could be wrong) that rust uses = for (type-level) equality constraints, not ==.
I'll join the bandwagon... https://github.com/Kintaro/wtftw Not sure if it would count as notable...but it's my "biggest" rust project so far and at the moment is more a way to distract myself from my thesis from time to time.
&gt; "This is one of many design decisions in Rust that optimize for low-level performance over higher level usability." its' not even that.. its' their idea of *making everything explicit*. In C++ you can have hidden operations, but they're still deterministic. (it's just not immediately obvious when an operation is or isn't performed - but you still have complete control over that, by virtue of what types you use). I agree that hidden operations can definitely make it more ergonomic - its' just it needs better tools to figure out whats' going on. (not all IDEs' will do jump-to-def on operator overloads, and sometimes with hidden operations there's nothing to actually click 'jump to def' on .. the ide would have to tell you the expression results in something that gets converted). But you can still trace where things come from in the debugger, and in the profiler - and profiling is more important anyway - often the actual cost isn't actually related to the operations, but rather cache issues and so on.
This is a full memory fence, emitting CPU fence instructions in addition to informing the compiler, not a compiler-only fence.
[Servo!](https://github.com/servo/servo) A parallel browser engine in Rust. [Here's a recent talk by Jack on Servo](http://www.youtube.com/watch?v=7q9vIMXSTzc). [Hyper](http://github.com/hyperium/hyper) is an HTTP library. [Iron](https://github.com/iron/iron), a web framework. [Html5ever](https://github.com/servo/html5ever), an HTML5 parser.
Could it read its config from the [xdg config](http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html) directory? (either $XDG_CONFIG_HOME or, if it's not set, ~/.config)
About this on the html5ever readme, &gt; Note that the HTML syntax is a language almost, but not quite, entirely unlike XML. For correct parsing of XHTML, use an XML parser. (That said, many XHTML documents in the wild are serialized in an HTML-compatible form.) What does Servo does when it encounters a XHTML document? (or: is there a library that provides a html5ever backend and a XML parser, with a single interface?)
Can I ask why not the following? xs.iter().filter(|&amp;a| ... ).filter(|&amp;b| ... ) or xs.iter().map(|&amp;x| x).filter(|a| ... ).filter(|b| ... ) I don't understand why you're cloning the collection just to consume it straight away. It seems like you're in pursuit of non-optimal behaviour when a better alternative exists.
I think the asm! is the way to go. I think you want asm!("" ::: "memory" : "volatile"), though. 
Apache 2.0 explicitly grants patent rights.
People consider being incompatible with GPLv2 an advantage?
No, people use MIT/Apache-2.0 because: 1. Requiring all code to be under Apache 2.0 means that all contributors have to grant a license to any patents they hold which might cover the code they're contributing. 2. People who are using an Apache-incompatible license like "GPL 2 only" (as opposed to "GPL 2 or later") can still use it under the terms of the MIT license... they just don't get patent protection beyond "the Apache license probably scared away any contributors with malicious intent".
It isn't anymore, but the intial release did. They're basically grandfathered, new releases will have to have one.
There's been multiple visible figures moving to other things during that time, so that wasn't just this in isolation. But yes, he is very active in the Ruby community. OS is like the stock market, people _EXAGGERATE_ such things. He wasn't the king of Ruby, he is.[1] [1]: Just want to make him blush :D.
It landed before the alpha. So there _is_ a huge difference there. It would be very harmful to the messaging of "Rust is committed to backwards compatibility" if - after a long time of using it", it just broke the struct syntax one month before release, for something I don't consider absolutely necessary.
I just created a PR adding intrinsics for such a singlethreaded fence. https://github.com/rust-lang/rust/pull/22358
I chose the word "poor" carefully. I would not rate the state of affairs as fair or better when I cannot distribute the resulting binary according to terms provided by the library's license as intended. I was not trying to describe it as a license violation. It's *fine* but worth noting for LGPL because while you can produce a useful binary under the same or compatible license, there is a caveat that the library must be linked dynamically (and even then you have obligations.)
If there was an API-compatible alternative to libao under a more permissive license? I would love to have that problem. I think it's worth solving, at the very least I don't want to have to double-check every license.
It's weird, being a Mozilla project, to not use MPL..
Ah, found it, I'd asked brson about it and the response was &gt; no plans, yet. if a good candidate and project appears somebody may be interested in mentoring
No, because having C as an intermediate language limits what your host language can do. For example, you can have a language that requires [tail call](http://llvm.org/docs/CodeGenerator.html#tail-call-section) elimination semantics - even for function pointers - but you cannot express that in C (you can only have hope that the C compiler does it for you). Of course, if you never aspire to do certain things C cannot, then it's alright ;-).
I am just compiling with 'cargo build --release', and was hoping it will already optimize it to the max. It is super interesting that Gcc is optimizing virtual method calls away btw !
&gt; Note that translations of the header files probably have to be licensed under the same license as the original header file (as it's directly a derivative work) It doesn't really make sense for an API to be copyrightable (and I hope that the USSC will confirm that in the Oracle vs Google case). And since writing bindings is just mechanical and doesn't involve any creative work it doesn't make much sense for them to be copyrightable either, even more so when they were produced with a tool like rust-bindgen. A 'null' license might make sense in that case.
It's in the [faq](http://doc.rust-lang.org/complement-project-faq.html#why-a-bsd-style-permissive-license-rather-than-mpl-or-tri-license?).
I don't see why you are working with `&amp;T` as the element type everywhere. T is a generic type parameter and if you use it as `T` it could be instantiated as either say a value type like `f32` or a reference type like `&amp;MyObject`. 
In Europe there is no such thing as a null-licence just as there is no public-domain dedication. If software doesn't have an explicit or implicit (e.g. GPL derivative) licence you legally can't use it.
Copyright is for creative works only. If something is not a creative work (e.g. phonebook, and I would argue 'automatically generated bindings') then copyright does not apply. A license in that case would be meaningless (although it may make some people sleep better). I'm not arguing that bindings (especially those that are automatically generated) are public domain, I'm arguing that 'copyright' does not apply to them at all. Is a cow public domain?
What do you mean by generic? Is it a trait object, or should `Foo` be parametric? Besides, you're already `Box`ing the object, so it seems like generics aren't preventing anything. I also don't know what you mean by "It's recommended to use `&amp;T` over `Box&lt;T&gt;`". They're for different things. `Box` owns its contents, `&amp;` doesn't. They aren't interchangeable in these sorts of situations.
&gt; I would love to have that problem. Readline has that very "problem". Basically, people thought it ridiculous that Stallman was trying to enforce license terms by the very act of being able to link to a library: Readline isn't LGPL, but GPL. So someone whipped up a basic (compared to readline), but perfectly functional, line editing library that used the same interface and is BSD licensed. Generally speaking, trying to define "derived work" in a license is ultimately bound to fail, as it's a term dictated by copyright regime and decided on by courts. Readline, as non-essential functionality, is in a much worse position here than say BLAS when it comes it to things being considered derived from it. Libao? Depends. In a game, most definitely, in a bookkeeping app, not so much, especially when that app can also call "aplay" or whatever to notify with sound, and dlopens libao.
No the difference is, that &amp;T is borrowed while Box&lt;T&gt; is owned. If you want both, you need an extra data structure to abstract over it. enum MaybeOwned&lt;'a, T&gt; { Borrowed(&amp;'a T) Owned(Box&lt;T&gt;) } which is basically `std::cow::Cow` without the requirement of `T` implementing `Clone`.
Unfortunately I can't read assembly, but if I could I would definitely want to find out why the llvm program is less efficient. After all, the program is rather simple, and I'd expect it to be at least as fast as C++. Initially I suspected the copying of vectors into their respective functions (i.e. `fn add(self, other)`) to be the problem, but changing the implementation to use references instead just shaved off a millisecond.
&gt; Well yes, but &amp;T can be a pointer to the stack or the heap but using Box&lt;T&gt; restricts you to the heap only. This is true, but you said that you want to allocate it in an initializer, and you can't do that on the stack because you'd be left with a dangling pointer. That leaves `Box`ing. Your code: fn new() -&gt; Foo { let bar = Box::new(...); Foo { bar: &amp;*bar } } is already allocating on the heap, but because `bar` is a stack-allocated variable the `Box` is dropped when `new()` returns, so dangling pointer. That's why the compiler wouldn't accept it. The solution is to just use `Foo { bar: bar }` rather than taking a reference to the Box's contents. Are you sure you need dynamic dispatch? If you don't (and static dispatch is fine), consider using struct Foo&lt;T&gt; { bar: T } instead, which lets you store the value directly in the struct. As a sidenote, thanks to the recent addition of deref coercions you could now use `&amp;bar` in your code rather than `&amp;*bar`.
If they don't actually *work*, why should they be there *at all*?
I don't think the deref copies it to the stack, perhaps I didn't word that well. I meant that because the `Box` is owned by `bar`, and `bar` is dropped at the end of `new`, the `Box` is deallocated leaving the pointer into it dangling.
Take a look at [this](http://is.gd/lnLlrs) play.rust link. We can see that the dereference of the `Box` does not cause the contents to be copied onto the stack (its address is wildly different to that of the stack-allocated value, so it's on the heap). [This section](http://doc.rust-lang.org/reference.html#lvalues,-rvalues-and-temporaries) of the reference clarifies this behaviour.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Sweat of the brow**](https://en.wikipedia.org/wiki/Sweat%20of%20the%20brow): [](#sfw) --- &gt; &gt;__Sweat of the brow__ is an [intellectual property](https://en.wikipedia.org/wiki/Intellectual_property) [law doctrine](https://en.wikipedia.org/wiki/Legal_doctrine), chiefly related to [copyright](https://en.wikipedia.org/wiki/Copyright) law. According to this doctrine, an [author](https://en.wikipedia.org/wiki/Author) gains rights through simple diligence during the creation of a work, such as a database, or a directory. Substantial creativity or "originality" is not required. &gt;Under a "sweat of the brow" doctrine, the creator of a copyrighted work, even if it is completely unoriginal, is entitled to have his effort and expense protected, and no one else may use such a work without permission, but must instead recreate the work by independent research or effort. The classic example is a [telephone directory](https://en.wikipedia.org/wiki/Telephone_directory). In a "sweat of the brow" jurisdiction, such a directory may not be copied, but instead a competitor must independently collect the information to issue a competing directory. The same rule generally applies to databases and lists of facts. &gt;[Civil law](https://en.wikipedia.org/wiki/Civil_law_(legal_system\)) jurisdictions have traditionally used the similar but not identical concept of [droit d'auteur](https://en.wikipedia.org/wiki/Droit_d%27auteur). [European law](https://en.wikipedia.org/wiki/European_law) tend to harmonize the protection of Intellectual Property throughout member states and the doctrine gains more influence. In the Databases Directive 96/9/EC—the [member states of the EU](https://en.wikipedia.org/wiki/Member_State_of_the_European_Union) are obliged to confer protection known as the [database right](https://en.wikipedia.org/wiki/Database_right) on non-original databases, that is on those that embody no creativity, but are a consequence of substantial investment (financial, labour etc.). &gt;==== &gt;[**Image from article**](https://i.imgur.com/Fid9RHR.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:%27The_feast_of_reason,_and_the_flow_of_soul,%27_-_ie_-_the_wits_of_the_age,_setting_the_table_in_a_roar_by_James_Gillray.jpg) --- ^Interesting: [^Threshold ^of ^originality](https://en.wikipedia.org/wiki/Threshold_of_originality) ^| [^Copyright ^law ^of ^the ^United ^States](https://en.wikipedia.org/wiki/Copyright_law_of_the_United_States) ^| [^By ^the ^Sweat ^of ^Your ^Brow](https://en.wikipedia.org/wiki/By_the_Sweat_of_Your_Brow) ^| [^Sweat ^of ^Your ^Brow](https://en.wikipedia.org/wiki/Sweat_of_Your_Brow) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+com43y6) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+com43y6)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I want a Vec -&gt; Vec map function. You'd implement that as xs.clone().into_iter().map(...).collect() Now I'm going to chain them. I think this is a good idea, and am willing to pay the performance cost when I do it. But... there's no need for any performance cost if the library and language are on my side.
Thinking about it more, you wouldn't even need to get into optimizations like stream fusion. All you'd need was a coercion to and from iterators: So ys : Vec = xs.map(...).filter(...) expands to ys: Vec = xs.iter().map(|&amp;x| x).map(...).filter(...) Then we just have a loop-rearrangement problem after inlining, and there's plenty of research on that even though it doesn't really seem to be in LLVM. And yes, I realize that right now I'm talking about a language "just-like-Rust-except...". But the design of Rust doesn't exclude this kind of thing, and I'll hold out hope that the developers decide that this sort of cost hiding isn't really much different from what any language at Rust's abstraction level already does. I mean, "for" loops already can hide the iterator. Edit: Looks like I need to think of .iter() as being like "seq" in Clojure. That's significantly more useful than I thought. Maybe all I really want is auto-dereferencing.
Again though, why the clone? My versions function the same way (except possible some `mut` issues, not sure) but don't involve a clone (and potentially hefty allocations). You could also replace `.map(|&amp;x| x)` in mine with `.cloned()`, which would clone the individual elements one-by-one rather than the whole vector.
Also not in the US. I am neither American nor German.
Yes, it is. I personally thing iterator solution is better though - no magic needed at the library level for efficient chaining, and it works for many different types of collections (even cross-collection mapping). It is a bit noisier syntactically, but I can live with that for the benefits.
The syntax noise isn't actually giving you any of the benefits. There's still no reason why vec#map can't be an alias for .iter().map(|&amp;x| x).map
Do you mean `.collect()` there? If so, then the benefit is efficient chaining.
A dereference on its own does nothing, it just represents a lvalue. What happens with this value depends on how you use it: If you take a reference to it, you end up with a pointer to the original location. If you store it in a local variable, then a memcopy to the stack happens. This works the same way in C and in Rust, as far as I know.
I would really like to see an event-driven HTTP (1.1 or 2) parser in Rust. If a grad student wanted to take this on for GSoC, that would be fantastic. :) 
Some of the projects from [here](https://careers.mozilla.org/en-US/position/oljBZfwY) might work as gsoc projects. Specifically: - rustfmt - l10n/i18n libraries - datetime (maybe? proper date handling is a nightmare.) - Improved benchmark support
how it differs there?
Even if it doesn't, crates.io is free for all to publish :)
Awesome! Thanks a million! I needed to add three lines to `Cargo.toml`: [lib] name = "dynlib" crate-type = ["dylib"]
`lib.rs` should be `basic_usage.rs`, that's a typo &gt;_&lt; 
In addition to what /u/Gankro said, because they may always be updated in the future, and then they'll need to have a license.
How did you compile? Did you use optimizations?
Try "cargo build --release".
&gt; a workaround is to put the glob use on top This does seem to be a general solution to my problem. Thanks!
With boom as load testing tool, I can push now ~2-3k compared to ~5k with Go. When I use "wrk", I can push ~80k compared to ~52k with Go, however, I get the following error with Rust &gt; Socket errors: connect 0, read 0, write 0, timeout 1829
Also the optimized binary is in `target/release/foo`, not `target/foo`. I was tricked by it once.
Would [std::mem::swap](http://doc.rust-lang.org/std/mem/fn.swap.html) possibly be useful here?
Couple of notes: * Instead of unwrapping the line you should return error on utf8 conversion failure * Not sure if using `std::io::Error` is really appropriate here, especially if you add utf8 error handling * `c_char` probably should be used instead of `i8` in casts * [Answer at Stack Overflow](http://stackoverflow.com/questions/24145823/rust-ffi-c-string-handling) kinda recommends `String::from_utf8` instead of a temporary `str`
Instead of `#[link(name = "libclntsh")]` use `#[link(name="clntsh")]`: the `lib` prefix and appropriate suffix is added automatically by the linker.
Globs are believed to only be broken in ways that reject programs, so they are safe to call stable and fix later. It is a high priority so it should be fixed relatively soon, but likely not before 1.0.
I'm not aware of how many bugs globs have open, or how serious they are, off the top of my head.
This sounds sorta like C `volatile`? I think Rust already has volatile intrinsics but I could be wrong (at least, my recollection was that the guarantees `volatile` gives were initially designed for signal handlers).
Nice! I haven't used msgpack much, but it sounded very similar. Thanks!
Maybe, though not for users of a library written in this way.
`volatile` ensures only that the read/write will take place even if it seems unnecessary to the compiler, it doesn't prevent reordering of non-volatile reads/writes across it.
Thanks, dzamlo - I just defined LIBRARY_PATH to be the same as LD_LIBRARY_PATH and then that worked. (Most my C/C++ has been on Windows so still getting settled in with Linux tool chain.) I also removed the 'lib' prefix per qrpth's direction. So between both comment replies to my posting the two together solved my problem. Thanks very much indeed to both of you. :-)
I don't think learning two instead of one language makes that much of a difference. The real learning curve are the libraries, frameworks, paradigms and conventions different platforms have. A real world application written in your hypothetical framework would still have to interact with existing javascript code and doing it the "browsers way" on the client side and probably support different paradigms on the server side. Javascript is also more event oriented that rust, I'm not sure they would match well in that regard. By using a different language than the native one (i.e. rust instead of javascript) you add an additional layer and thus more complexity. It will also be harder for beginners to find relevant information and help online. Additionally, if you have any hard to debug bugs or edge cases, you would still need to know javascript to debug your code on the "native" level. In case of a web development framework I'm not so sure the benefits out weight the drawbacks. There are also some tools like node.js that already do what you proposed and their existents counter my arguments a bit. So don't let my negativity stop you :-) That said, I believe there is a place for compiling some code from rust (or any other language) to javascript. Let's say you have some complex algorithms that you need on the server, as well as on the client side, in this case it would be great to be able to reuse that part of the code. But not for the complete web framework. BTW: there is some work going on compiling rust to javascript via emscripten: https://github.com/tomaka/cargo-emscripten 
It has been done for Scala (http://www.scala-js.org/, http://scalagwt.github.io/) so yeah, it should be possible. It's a very complex and big project, though. And the code would come with a bit of a bloat from having to include parts of the standard library and/or other crates, which for the most web sites is a serious issue. It's mostly a good option for the more complex projects, with lots of code to refactor. For the same reasons why http://www.typescriptlang.org/ might be a good option. Also an easier interoperability and code sharing between the client and server sides might be a nice side-effect.
[I would rather think it's a good idea, some people even got it working.](http://ocsigen.org/) :) My personal opinion is that Rust is not a good language for this kind of work. I know some people disagree (Hi Chris Morgan !) but I think it's just too low level and that its semantic doesn't map to javascript very well, making the communication difficult. edit : And no, you can't completely ignore javascript's semantic, because you will have to manipulate the browser APIs and use some existing libraries, and those are so full of javascript-ism that you need some way to communicate with that.
We shall see if the newer std::net is any faster. I'll be porting hyper over in my next batch of Rust time. 
I found that vim coupled with [rust.vim](https://github.com/wting/rust.vim), [syntastic](https://github.com/scrooloose/syntastic) and [racer](https://github.com/phildawes/racer) works quite well. CTags related plugins can also come in handy: * [TagHighlight](https://github.com/skroll/vim-taghighlight): requires some extra configuration * [TagBar](https://github.com/majutsushi/tagbar) Also for file navigation I usually end up using [ctrlp.vim](https://github.com/kien/ctrlp.vim). It's much more convenient the "Project Views" in most IDEs. You can also get some generic, word-based autocompletion, but there's no real autocompletion plugin for Rust (that I know of).
I'm pretty sure those are apples and oranges. The latter is likely using a persistent connection, and the former does a TCP connect each time. I benched my mudpie server (for the first time just now) and it doesn't support keepalive, and it got (using the go boom tool) ./proj/bin/boom -n 100000 -c 10 -cpus 4 http://localhost:8002/hello 100000 / 100000 Boooooooooooooooooooooooooooooooooooooooooooooooooooo! 100.00 % Summary: Total: 3.7617 secs. Slowest: 0.0243 secs. Fastest: 0.0001 secs. Average: 0.0004 secs. Requests/sec: 26583.6191 Total Data Received: 47100000 bytes. Response Size per Request: 471 bytes. And I know that will be improved when the new IO library lands and accept() doesn't cause a thundering herd on me.
by the way, you should also check the cpu load of your load tools vs the webserver. I'm testing 'go boom' against 'mudpie' and boom is 211% cpu and mudpie is 80% on a quad core. So the test program is slowing me down. Allow some extra cpu for kernel work, but I'm still seeing ~15% idle in vmstat that I can't explain either.
Interesting. Would it be possible and/or desirable to replace [RBML](http://doc.rust-lang.org/nightly/rbml/) used for rustc metadata with CBOR?
[This plugin](https://plugins.jetbrains.com/plugin/7438) for IntelliJ is coming along, but is in its early stages (only syntax highlighting, I believe)
Yes. That's the one they linked, rust.vim. It's just mirrored off from the main repository so vim package managers can use it.
Is std::net landed? Link to RFC?
Detect isn't where that would be select. 
Update: [rustfmt is now on the brainstorming page](https://wiki.mozilla.org/Community:SummerOfCode15:Brainstorming#Rust)! Thanks brson!
No a question about the code: but why the Unlicense instead of CC0, which is usally recommended for such things? (CC0 is longer, but avoids many pitfalls and a fallback for legislations where you cannot just waive copyright)
What colorscheme is that for vim?
brackets isn't too bad weirdly enough 
msgpack does indeed have the problem of not differentiating between text and binary. The authors have been annoyingly stubborn on this point, invoking the string handling of languages like PHP and JavaScript.
Well, one difference is that in the C++ version, you are heap allocating each element of the vector with a `unique_ptr`, while in the Rust version you are not. Either make the Rust version use `Vec&lt;Box&lt;Person&gt;&gt;`, or remove the `unique_ptr` indirection in the C++ version.
I agree with other posters that there's a lot of other contenders for this that use languages that map better to javascript. Where I think there might be value is if you manage to abstract away a lot of the actual API stuff, in the same way that React-Native abstracts away the native APIs for iOS and Android behind a declarative layer.
This is great! A few questions: * Windows/Linux/OS X nightlies are synced to use the same commit - will your FreeBSD nightlies do this too? [https://github.com/rust-lang/rust/issues/14431] * Would it be possible for you to serve these over HTTPS and provide checksums? [Reasons for doing so here: https://github.com/rust-lang/rust/issues/16123] * Do you plan on maintaining historical archives? There have been a few occasions where I've needed to revert to an older nightly for whatever reason. * Would it be possible for you to host a FreeBSD version of `rustup.sh`? Thanks for doing this!
Slightly non-related: I've only dabbled in Linux distro packaging systems. How complicated is it to set this up in FreeBSD?
As pointed out in another comment, the code isn't *exactly* equivalent. Additionally, you should be using [`test::black_box`](http://doc.rust-lang.org/test/fn.black_box.html) to make sure that no optimizations remove the calculated value from the Rust code. Finally, as pointed out, since this example is so heavy on memory allocation this ends up more as a glibc vs. jemalloc benchmark than a C++ vs Rust benchmark.
Yes, but in the C++ version, each element of the `vector` is a `unique_ptr&lt;Person&gt;`, which is itself a pointer to a heap allocation. So you have a heap allocation for the `vector`, full of pointers to other heap allocations. In the Rust version, there is only the one heap allocation of the `Vec` for all `Person` elements.
Addressed that in an edit, difference persists
I'm surprised nobody mentioned [SublimeText](http://www.sublimetext.com/) yet which IMO is the best text editor out there. There is a [syntax highlighting plugin](https://packagecontrol.io/packages/Rust) and also a plugin for [Racer integration](https://packagecontrol.io/packages/RustAutoComplete) (although I couldn't make it work on Windows).
You might want to try without the smart pointers too: vector&lt;Person&gt; vec; vec.push_back(Person {.name = "Mitchell"}); against your original Rust version.
Rust is well-suited for asm.js, actually. What you can do with asm.js is forgo the garbage collector, using an array-based allocator instead. And the Rust borrow checking will come into play then. How this is useful? Well, with asm.js you can program some calculation-intensitive staff, like self-rendering games and video processing. It's possible to make a cache-friendlier version of the calculations that way.
I also agree somewhat about aliases being bad, but I like some names for methods that came from smalltalk, and some that came from lisp(?), so I like the ability to mix and match. collect/select/reject/detect/inject map/find_all/&lt;na&gt;/find/reduce I like the clarity of the name map, the symmetry of select/reject, am undecided about detect/find and always use inject (not sure why)
I'm wondering if rust binaries for freeBSD could use the system malloc, because FreeBSD is using jemalloc 
Here are my results. I removed the infinite loop, and reduced the number of iterations a bit, so I don't have to wait forever for valgrind. Rust: struct Person { name: String } fn main() { let mut vec: Vec&lt;Person&gt; = Vec::new(); for _ in 0..500000 { vec.push(Person {"Mitchell".to_string() }); } for _ in 0..500000 { vec.pop(); } } C++: #include &lt;string&gt; #include &lt;vector&gt; struct Person { std::string name; }; int main() { std::vector&lt;Person&gt; vec; for (int i = 0; i &lt; 500000; i++) { vec.push_back({"Mitchell"}); } for (int i = 0; i &lt; 500000; i++) { vec.pop_back(); } } rustc -C opt-level=3: mem: 500,028 allocs, 500,028 frees, 29,902,288 bytes allocated time: real 0m8.601s user 0m8.513s sys 0m0.077s clang++ -std=c++11 -O3: mem: 500,020 allocs, 500,020 frees, 24,888,600 bytes allocated time: real 0m2.889s user 0m2.790s sys 0m0.093s EDIT: You can ignore the time, it's irrelevant for this benchmark, and the rust version probably ran on a cold cache. EDIT 2: Use braced init list instead of designated initializer syntax for the C++11 version, as the latter is a C99 feature that is not part of C++11. 
Ah, so that's what you meant by "stack allocated" version? Mind you, it isn't stack allocated, the vector allocates the memory on the heap in both languages.
Because it best reflects my philosophy. If someone has a real legal problem, please file an issue and we can fix it together.
And the heap alloc for each of the `String`s inside it. But the C++ version has that too.
The extra allocs are because we used `.to_string()` instead of `.to_owned()` afaict.
Are you measuring real memory usage or virtual memory usage?
So `to_owned` is generally better in memory/performance critical code? What's the difference in terms of what's going on behind the scenes?
The allocation strategy used by vector in C++ probably differs from Rust's. You can't necessarily draw language level conclusions by examining a single data structure run in a micro-benchmark. By allocating more memory the C++ vector will have to resize less often, possibly making it faster.
&gt; since JavaScript is garbage-collected What about asm.js and emscripten? Firefox will [skip garbage collection](http://asmjs.org/faq.html) for asm.js code. &gt; Q. Why not just keep optimizing JavaScript JIT compilers instead? &gt; A. No need to stop! But JIT compilers have less predictable performance based on complicated heuristics. The asm.js model provides a model closer to C/C++ by eliminating dynamic type guards, boxed values, and garbage collection. My understanding is that eliminating the GC could be useful for high performance web apps. I think it would be nice to have a 3D application (for example, a game) written in Rust that could be compiled to native code on multiple desktop platforms (rendering with OpenGL or DirectX), to native code on mobile platforms (with OpenGL ES), and finally to the web on asm.js (with WebGL). Perhaps a framework like Piston could deliver such compatibility in some years. That's something that Unity [can do today](http://blogs.unity3d.com/2014/10/07/benchmarking-unity-performance-in-webgl/), so I suppose it's not literally impossible. edit: by the way, they are [compiling scripts written in C# to C++](http://blogs.unity3d.com/2014/05/20/the-future-of-scripting-in-unity/), enabling the use of emscripten.
base16 mocha. [preview](http://chriskempson.github.io/base16/#mocha). [vimfiles](https://github.com/chriskempson/base16-vim).
Update: either I'm doing something wrong now, or I did something wrong initially, but after running the stats again, I found this number much much lower, at 43. You can find the new summary at the link, along with its generator.
That's really fascinating. I guess for some performance-critical domains Rust would indeed be useful.
I'll kindly re-iterate: &gt; If someone has a real legal problem, please file an issue and we can fix it together. I've been a heavy user of the Unlicense for *years*. I'm well aware of its perception. There are trade offs to every license and I've consciously and deliberately chosen mine.
`to_string` goes through the generic formatting framework, which might do more than just strictly allocating a new buffer and copying the bytes over.
Ok, thanks!
Maybe I'm misunderstanding, but msgpack supports strings and byte arrays as separate types, which should count as disambiguating between text and binary strings. Note: I'm the author of an experimental [implementation](https://github.com/dradtke/mpack) of MessagePack, so I'm a little biased towards it.
fwiw, I don't think equality constraints are supposed to be used like that. Especially since the coherence rules would then rule out any other impl of `FromError&lt;...&gt;` for `MyError`. If you really really think that `io::Error` is too verbose, maybe just use a local type alias instead?
Do Rust and C++ vectors have the same reallocation behavior?
Not sure how updated is, but there's an overview of the method lookup algorithm in the [source code](https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src/librustc_typeck/check/method/README.md).
Great write-up and a fantastic piece of work! Thank you :-)
Ahh thank you! I was growing tired of messing with serialize::json deserialization being too picky with (possibly) missing values. 
Ah, that makes sense. I was operating under the assumption that everything was UTF-8 already, but I can see where that would be confusing if not explicitly specified.
Yup. Benchmarks are hard. I say that even when we win :)
I have same work with ScalaJs and there not about writing everything on Skala but ease using Scala in JS what mean different direction. More possible map Rust with CoffeeScript for easier Ajax and so on. JS is great lang for WEB and there to many libraries like Angular and so on. Without that web is nothing today. JS were written in two week )) So what there hard to learn? There going to be more useful if same write parser SASS, LESS to CSS in Rust and so on. 
I'm fairly sure they both double on full. Edit: reading through other comments this seems to not be the case
Just to clear up any confusion, I called it scientific sarcastically. I only posted because I was very confused about the vast difference in resource use between two programs I thought were identical.
All variables in rust are by default immutable. You make them mutable with the mut keyword.
Yeah I know how it works in rust, that's not really my question. 
&gt; If you what I posted If I what you posted? I'm not exactly sure what that means, but I will reiterate my question: Why doesn't rust have a let mut alias similar to how nim uses two different keywords.
It's been proposed before. One of the main reasons why people don't want that is that `var` is what many non-Rustaceans are used to for declaring *any* type of variable. In most languages, this is fine -- if you don't want to mutate something, just don't. In Rust, mutability interacts with the borrowing/ownership system much more and you don't want users getting even more confused with random borrowck errors just because they made all their variables mutable by accident. Besides, that extra verbosity comes useful. I was pretty surprised that in general one doesn't *need* mutability for most variables; `mut`s in my code are pretty rare and these days I question myself whenever I type it. The most common patterns requiring mutability -- getting data out of a branch, and for loops -- both are solved by the everything-is-an-expression thing (`let y = if foo {.....; a} else {.....; b}`) and iterators respectively.
Can't wait to use it!
How vec![T; N] is better than Vec::from_elem? I always thought that if anything can be implemented as function, it should be a function. And macros should be used to express something that cannot be written as function.
There are other reasons too, like let (x, mut y) = ... Basically, the design is much more straightforward this way, in many ways.
Given that `vec![]` already exists, I find it a much more elegant solution to inuitively extend the existing macro than to add a separate constructor. Kudos to whoever had the idea. But how does the performance compare to the iterator approach? Is that what it expands to? (On mobile at the moment, or I'd check myself.)
It's a good point, and I feel the same way in general, but note that `vec![EXPR; EXPR]` is something we probably want anyway for consistency with `[EXPR; EXPR]`.
&gt; do to #20300). I guess this should be "due to"
It expands to running through the array with a pointer, using an `unsafe` block. It's surely faster than using an iterator, as, at the very least, it uses clone once less. This is the code: macro_rules! vec { ($x:expr; $y:expr) =&gt; ( unsafe { use std::ptr; use std::clone::Clone; let elem = $x; let n: usize = $y; let mut v = Vec::with_capacity(n); let mut ptr = v.as_mut_ptr(); for i in range(1, n) { ptr::write(ptr, Clone::clone(&amp;elem)); ptr = ptr.offset(1); v.set_len(i); } // No needless clones if n &gt; 0 { ptr::write(ptr, elem); v.set_len(n); } v } ); ($($x:expr),*) =&gt; ( &lt;[_] as std::slice::SliceExt&gt;::into_vec( std::boxed::Box::new([$($x),*])) ); ($($x:expr,)*) =&gt; (vec![$($x),*]) }
I think Steve's explanation is compelling. `let` is for introducing one *or more* bindings and with `mut` you can ask for one specific binding to be mutable. How would you do this in Nim? let (x, mut y) = (17, 29); y += 1; The thing to take away here is that `mut` only affects the immediate binding while `let` just lets you introduce one *or more* bindings. So, I would argue that these are orthogonal things.
https://github.com/joyent/http-parser/blob/master/http_parser.c as new data arrives, parser-&gt;execute is called which runs the new buffer-full of data through the parser. The parser goes as far as it can with the data that was received, it stores its state, and then returns. The re-enterable state-machine for the parse is the important bit. This is usually quite different from parsers which expect their source input to block. Those parsers are quite a bit simpler, but not terribly useful for event-driven schemes, unless you have some sort of control inversion (e.g. fibers) 
Yeah that would certainly be tricky to do :) serde does however support deserializing into a generic structure like [json::Value](https://github.com/erickt/rust-serde/blob/master/serde2/src/json/value.rs), so it gets you some of the way there.
Fixed, thanks!
The intention is to have the iterator approach optimise to be equivalent to that, if [it doesn't already](https://github.com/rust-lang/rust/pull/22200).
I just found [a question/answer on Stack Overflow](http://stackoverflow.com/questions/27886474/recursive-function-type) that seems to be exactly what I'm talking about, but I will leave my post up in case anyone wants to add more info!
Think of `let mut x = 5` as grouping like `let (mut x) = 5`, not like `(let mut) x = 5`. The general syntax in Rust is `let &lt;pattern&gt; = &lt;expr&gt;` and one possible pattern is `mut &lt;identifier&gt;`, so `mut` actually groups with the pattern, not `let`! This lets you do things like `let (x, mut y) = &lt;expr&gt;` where `x` will be immutable and `y` will be mutable.
I think that ship has pretty much sailed, in the case of Rust.
Oh jeez, I'll never be able to *un*-notice that...
Does basic functionality like that really need `unsafe`?
Note that `vec![EXPR; EXPR]` literally works today (and for quite a while), it's just restricted to the set of EXPR's that `[EXPR; EXPR]` accepts. This RFC is simply allowing more valid expressions.
I'm replying late, but you can try this the of OS X ld from osxcross: https://github.com/tpoechtrager/osxcross
&gt; The most common patterns requiring mutability -- getting data out of a branch, and for loops -- both are solved by the everything-is-an-expression thing Also the shadowing helps.
Ah, yes, if you need to unload and swap out the library, then you can't let the run-time linker do this automatically, so you do need this sort of control. Cool, that would be a pretty awesome project, and I really like the idea in that blog post. 
While I think macro can be very useful for readability, I believe this is a perfect example of macro overuse that could lead to less readable code. Just to avoid very few keystrokes, it introduce a new syntax. Using macro to avoid complex and redundant code is a good thing, but I don't believe `let mut` is such a pain it deserve a special syntax. If every program do the same his own way, Rust code might become hard to understand at first sight. 
I can't say. Hyper is still experimental. If a faster design is found or suggested, we may adopt it. 
Yes, but it would have to be let (mut a, mut b, mut c) = (1,2,3); This macro lets you do it without `mut`.
At this moment my preferred Rust editor is also Sublime Text: [The Sublime Linter plugin for Rust](https://github.com/oschwald/SublimeLinter-contrib-rustc) is really awesome.
Ah, I see. I thought tuple destructuring allowed something shorter.
What is better? A macro that possibly pollutes the namespace or a built-in literal for it? I prefer the macro.
To actually mutate elements _in_ the vector, you'd have to use `for i in &amp;mut v` (and v has to be mutable). Moving out of some var is something that happens "all the time" with affine types and as demonstrated above, the compiler complains about it if you try to use a variable after it has been moved. Nothing error prone about that. Did you refer to something else?
Interesting! A proofreader comment: &gt; Rust serialize::json JSON 183 Either the number is wrong (should be 83 instead of 183?) or this line is not in the right place in the serialization benchmark list.
The [Rust Bay Area](http://www.meetup.com/Rust-Bay-Area/) group does monthly meet-ups, although there's apparently not a concrete date for one in April yet. (I should be clear that I'm not formally connected with any sort of organisation in SF, so it turn out that e.g. erickt is unable to organise a meetup in April .)
I'm in the meetup group already, and I've checked out the events on the table so far, but I'll only be in town for a weekend (I forget which one), so maybe I can help steer it in that direction.
**TL;DR:** The lesson to be learned here is: Borrowing of `Self` in a trait's function is *always* explicit. You can't sneak it in via associated types. But you may not have to: Think about whether it makes sense to move the “borrowing operation” outside of the trait like it is done with iterators. It might feel weird, but it's also very flexible. The problem here is that according to the trait definition the function fn frequencies(&amp;self) -&gt; BTreeMap&lt;Self::Item, usize&gt;; is not defined to return something that borrows from `Self` because there is no lifetime parameter in `BTreeMap&lt;Self::Item, usize&gt;` that would say so. You're trying to “sneak in” a borrow by type Item = &amp;'a T; But this cannot work for several reasons. One is that `'a` is not the lifetime of `Self` in the `frequencies` method. Rust does not allow you to sneak in this borrowing via associated types because it would not be able to properly type- and borrow-check generic code if it was allowed. One approach of making the explicit would be the use of higher-kinded types for associated types (which is not yet possible): type Item&lt;'a&gt;; // &lt;-- hypothetical Rust, not yet supported fn frequencies&lt;'a&gt;(&amp;'a self) -&gt; BTreeMap&lt;Self::Item&lt;'a&gt;, usize&gt;; But in this case, we can move the reference out of `Item` and write this instead: trait FrequencyAnalysable { type Item where for&lt;'a&gt; &amp;'a Item: Ord; // &lt;-- will work in 1.0-beta fn frequencies(&amp;self) -&gt; BTreeMap&lt;&amp;Self::Item, usize&gt;; } // ^ note this impl FrequencyAnalysable for … { type Item = T; // &lt;-- no reference … } Unfortunately, this kind of constraint of `&amp;Item : Ord` is also not yet supported (but there is an [open issue](https://github.com/rust-lang/rust/issues/20022) for it (**Edit**: It has been fixed!). Resolving it is part of the 1.0-beta milestone). Also, if you want to do it like this, you are limited to `frequencies` *always* returning a “loan” which may or may not be what you want. Here's a crazy idea: Take `Self` by value! trait FrequencyAnalysable { type Item : Ord; fn frequencies(self) -&gt; BTreeMap&lt;Self::Item, usize&gt;; } This is similar to [`IntoIterator`](http://doc.rust-lang.org/std/iter/trait.IntoIterator.html). The trick is: If you want a “borrowing” `frequencies` (or `into_iter`) function, you simply borrow *ahead* of time and implement this trait for references: impl&lt;'a, T: Ord&gt; FrequencyAnalysable for &amp;'a [T] { type Item = &amp;'a T; fn frequencies(self) -&gt; BTreeMap&lt;&amp;'a T, usize&gt; { ... } } Here, the return value is not really a “loan” of `Self`. `Self` already is a *borrowed* slice and this just gets passed on. And just like `IntoIterator` you can also implement it for containers which would consume them.
If I try to use it IE a regex!() macro I get: /home/j/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-0.1.10/src/re.rs:782:42: 782:52 error: obsolete syntax: `:`, `&amp;mut:`, or `&amp;:` /home/j/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-0.1.10/src/re.rs:782 let text = re.replace_all(text, |&amp;mut: refs: &amp;Captures| -&gt; String { ^~~~~~~~~~ note: rely on inference instead error: aborting due to previous error This was fixed in `regex 0.1.14` but `regex_macros` won't work with that version Version: rustc 1.0.0-nightly (b63cee4a1 2015-02-14 17:01:11 +0000) Cargo.toml is the same as your gist with a different package name and author
Based on the crates.io statistics / download statistics for macros like `cfor!` and `fallthrugh_match!`, I suspect the concerns of people here are not going to be issues in practice--that is, I think most of the people who initially ask about whether these constructs can be in Rust are okay with not using them, and these macros will not suddenly take over a large number of Rust programs.
Ok... Downloading my own repository from github and building it works... It even ignores my Cargo.toml and correctly downloads the new versions... And yet my main dev repo doesn't work - is there some cargo cache that needs flushing?
On ocasion, I'll need to run a `cargo clean`. But it's pretty rare and I haven't identified what conditions actually lead to it. More frequently, it's because I forgot a `cargo update`. :-)
I'd already run a clean, but not an update. Looks like this time I needed both. Wierd. Thanks for the help
I don't have April organized yet, but we could try for a dinner. Which weekend?
 let data = Arc::new(vec![1u32, 2, 3]); This should be enough.
Just checked. It's the 3rd to the 5th. I knew it was early in the month.
At first I was looking at Rc, which mentions immutable, but it was not working. Your suggestion works. Here is the new code. Thanks alot. use std::sync::{Arc, Mutex}; use std::thread::Thread; use std::old_io::timer; use std::time::Duration; fn main() { let data = Arc::new(vec![1u32, 2, 3]); let x = 5.0; for i in 0us..3 { let data_clone = data.clone(); Thread::spawn(move || { println!("data[{}]:{}",i,data_clone[i]); println!("x: {}",x); }); } timer::sleep(Duration::milliseconds(50)); } I still see clone though `let data_clone = data.clone();` I'm guessing its only cloning the container, and not the whole content. 
Arc and Rc are the same, except Arc is thread safe. So that's why it didn't work. And yes, for both, clone simply bumps the refcount.
I encourage you to pursue the second option -- carrying around the "initialized" struct. It might *seem* clunky, but really what's happening is that you're allowing the compiler to enforce one of your design invariants for you. It tells the "truth" -- you can't invoke your Tcl stuff without having Tcl be initialized, and you represent that using an initialized TclState struct (or whatever). From that point on, your code that depends on invoking Tcl will, *somewhere*, need a reference to a TclState object. Now imagine you've written a few thousand lines of code this way. When you audit your code, it will be obvious *instantly* which code can possibly invoke Tcl, and which code never does. The presence of a `&amp;TclState` parameter (or whatever) tells you this. This is really, really valuable. It seems clunky because you're paying a cost *up front*, and you're forcing yourself to deal with the potential problem of calling uninitialized Tcl code at design time, rather than much later, at runtime. At runtime, when you discover that some particular code path did not guarantee that Tcl was initialiezd, and mistakenly invoked some Tcl function. If you discover that the burden is just too great, you can always remove the TclState struct and rip out the parameter from all methods that used it. That's easy. But it's *much* harder to go the other way -- if you realize that you need the compiler's help in checking your invariants, now you have to find all the places that need a TclState and rework them to carry one around. That's much harder. So start with the design that prioritizes correctness. It's much easier to start with something that is correct, and then make it fast, than it is to start with something fast, and then make it correct.
Having both `var` and `let` is one of my top nitpicks with Nim. I strongly prefer `let mut` even it takes some additional keystrokes. So maybe it's just the name I have an issue with because it hides the fact that they are mutable. If it was `mut!` for example, I'd probably love it :P
In case you haven't seen this yet, one of the mods created a [`var!` macro which does just this.](http://huonw.github.io/var/var/)
&gt; Am I correct in assuming that it's best to use the smallest unsigned number type (`u8`) unless you need negative or a larger range of numbers? Not necessarily, it kind of depends on the use case. In the general case, most architectures perform best with 32-bit or 64-bit integers. Some architectures are even unable to directly address a single byte, and so must mask and shift bytes to give you the desired value in memory, resulting in performance degradation. On the other hand, if space consumption is a concern, either on memory or in some specialised file format, using smaller-sized integers certainly has its use (and generally doesn't come with a penalty on the most common platforms).
In `Rc` (as opposed to `Arc`), it’s the reference count that is not thread safe.
I'm another Sublime Text 3 + [Racer](https://packagecontrol.io/packages/RustAutoComplete) + [Syntax Highlighting](https://packagecontrol.io/packages/Rust). When combined with things like [Vintageous](https://packagecontrol.io/packages/Vintageous) (vim emulation, far better than the "Vintage Mode" that comes with ST3) and [VintageousOrigami](https://packagecontrol.io/packages/VintageousOrigami) (Split Pane support) I'm quite happy with my set up. I'm about to try out the [Sublime Linter for Rust](https://packagecontrol.io/packages/SublimeLinter-contrib-rustc) as well. For those curious, some other really good plugins are [GitGutter](https://packagecontrol.io/packages/GitGutter) (shows git diffs in the gutter bar) and [AdvancedNewFile](https://packagecontrol.io/packages/AdvancedNewFile) (allows creating and opening files easily with Super+Alt+N). [Screenshot](http://i.imgur.com/8bAbLQL.png) (Yes, I still haven't registered...shame on me)
&gt; As far as I know, it's safe to call multiple times, too. Complementing /u/0xdeadf001 excellent answer, you could use [std::sync::Once](http://doc.rust-lang.org/std/sync/struct.Once.html) on your `TclState` implementation to guarantee that you don't call the initialization function multiple times, even if the user of your library ends up creating multiple `TclState` on the same process.
Yes, that's accurate.
I just read it as a response to http://www.reddit.com/r/rust/comments/2w3t29/so_i_found_out_that_nim_uses_two_keywords_for/
&gt; (I'm not sure if this is worth doing this though - would anyone want to use the low level bindings?) One reason is so that you can make an alternative `tcl` package if you don't like the way the author built that particular high-level API.
Nice summary, thank you!
I didn't realise you could do that, that's brilliant.
&gt; use assertions and panic if you ever see a value that's out of range. If you have a defined range that you always check, what does it matter if the integer is signed or unsigned?
Wow, default Rust support, very cool :) 
It makes more sense to check that a value is less than 0, than check that a value is greater than 2^31.
An immutable vector still isn't thread-safe because its lifetime is unknown. E.g. the thread which owns the vector might suddenly drop it, making all the pointers in the other threads dangle (cf. https://en.wikipedia.org/wiki/Dangling_pointer). That's why you need a shared ownership for the vector, implemented by `Arc`. As for `Rc`, documentation might be confusing there, because the `Rc` itself isn't immutable. It's a reference counter after all, it needs to increment and decrement the counter, it can't be immutable (cf. `inc_strong`, `dec_strong` in https://github.com/rust-lang/rust/blob/master/src/liballoc/rc.rs). The more verbose documentation at http://doc.rust-lang.org/std/rc/ draws a better picture: "The Rc&lt;T&gt; type provides shared ownership of an immutable value". P.S. I've made a pull request - https://github.com/rust-lang/rust/pull/22460, we'll see how it goes.
`mutant!`
Nice! &gt;...inspired by the keyword of the same name in languages like Nim and C#. I believe Swift also has `var` and `let` with similar meaning.
I think that's a fair assessment, yes.
Ah, I was wondering why it kept trying to give the variables I wanted to use static lifetimes.
You could use [lazy-static](https://github.com/Kimundi/lazy-static.rs) as well.
I was experimenting earlier today with `Thread::scoped` to come up with a possible answer and ran into the same problem :)
What if the C lib has a close function as well (e.g., SDL_Init, SDL_Quit)? Can we somehow protect the user so that he does not mess anything by creating a second instance? Probably hide the struct and do a hidden static like here? Generally writing a proper wrapper for a state machine like API (SDL, OpenGL, etc.) is a PITA.
Plus, if for some reason a person wants to run multiple Tcl scripts in separate threads, each with it's own global state separate of the others, this model would allow you to evolve towards that. The first choice doesn't.
Right, totally! Or if you later found out that you needed to carry some other client-related state throughout your design, then you have a natural / obvious place to do that.
&gt;In some languages it's recommended to use signed over unsigned numbers because the compiler can optimize those more efficiently, even if the negative numbers are not used. wat. is this true? what lang (or really, compiler?)
Probably C++, where signed integer overflow is undefined.
No choice really. `derive(thing)` requires special compiler support---AFAIK not even a compiler plugin can implement their own `derive`.
The way deref coercions work is that if `T` implements `Deref&lt;Target=U&gt;` then Rust will automatically coerce `&amp;T` to `&amp;U`. Two common examples are `String: Deref&lt;Target=str&gt;`, and `Vec&lt;T&gt;: Deref&lt;Target=[T]&gt;`, so you can pass `&amp;String` where `&amp;str` is required, and `&amp;Vec&lt;T&gt;` where `&amp;[T]` is required. It can also be chained, so you can pass `&amp;T` for `&amp;V` if `T: Deref&lt;Target=U&gt;` and `U: Deref&lt;Target=V&gt;`, and so on. However, Rust will *not* coerce `String` to `&amp;str` automatically. Requiring you to write the `&amp;` keeps borrows explicit at the call site, so you can tell at a glance whether something is being moved, borrowed immutably, or borrowed mutably. You can see the [deref coercions RFC](https://github.com/rust-lang/rfcs/blob/master/text/0241-deref-conversions.md) for details (particularly, how it deals with `&amp;mut`, which I left out).
Good C APIs follow this design, as well. My favorite example is [udis86](https://github.com/vmt/udis86), which puts all the state inside a struct that the user can allocate anywhere, then initialize with a library call. This makes it simply a joy to write safe wrappers for other languages (*hint hint*, anyone looking for a FFI project...)
Not too difficult. https://www.freebsd.org/doc/en/articles/contributing-ports/article.html and https://www.freebsd.org/doc/en_US.ISO8859-1/books/porters-handbook/quick-porting.html
I do something like that in my [libao bindings](http://www.rust-ci.org/tari/rust-ao/doc/ao/struct.AO.html), where there's a nullary struct which controls user access to library functionality. I use an `AtomicBool` when the library is initialized, and panic if somebody attempts to reinitialize it before the original is dropped (thus deinitializing the library).
Haven't tried it but from the docs on github I think just doing something like this should work use chrono::{UTC, Local, DateTime}; let dt = Local.ymd(2014, 7, 8).and_hms(9, 10, 11); // `2014-07-08T09:10:11Z` // July 8 is 188th day of the year 2014 (`o` for "ordinal") 
You misread, the recommendation is to use signed integers *because* it gives the compiler more room to optimize. Consider this toy code: for (int8_t i = 0; i &gt;= 0; ++i) { // some code with side effects } An optimizing compiler may decide to turn this into an infinite loop because the check before each loop iteration can be removed (since overflowing would be undefined).
This is a [known big issue](https://lifthrasiir.github.io/rustlog/worklog-2015-01-13.html). Sorry about that :( Unlike `UTC`, `Local` is an offset constructor but not an offset *value* itself currently (since it caches the calculated local offset). It greatly limits what is possible with the offset constructor, and for this reason `Local::now()` is actually special-cased. You can convert from `DateTime&lt;UTC&gt;` to `DateTime&lt;Local&gt;`, however.
Cool, that's about what I'd expected. My main use for unsigned values is counters, and my thought process is more "this is *never* going to be negative" than "I need that extra bit". As you say, it conveys more information.
That's the syntax for referring to an associated type. `Deref` is currently defined this way: pub trait Deref { type Target; fn deref(&amp;'a self) -&gt; &amp;'a &lt;Self as Deref&gt;::Target; } If it were `trait Deref&lt;T&gt;`, then you would just say `Deref&lt;str&gt;`. The advantage of using an associated type instead of a normal type parameter is that an implementing type can only deref to a single other type. With a normal parameter I could implement both `Deref&lt;str&gt;` and `Deref&lt;[u8]&gt;` for `String`, for example, and then things can get ambiguous or have more confusing error messages.
How do you do that conversion? (I don't think that would help with what I'm trying to do, but it's still a good thing to know. I tried it and couldn't figure it out.)
&gt; Why "Friends of the Tree?" Just feels out of place to the whole "Rust" motif. It's borrowed from a Mozilla tradition for recognizing contributions, but I believe they actually call it something different now. It does stand out though. What's something more fitting?
&gt; Why "Friends of the Tree?" Just feels out of place to the whole "Rust" motif. It's [a mozilla-ism](https://badges.mozilla.org/en-US/badges/badge/Friend-of-the-Tree); tree == "source tree".
Indeed, [a fungus is often a friend of a tree](http://en.wikipedia.org/wiki/Mycorrhiza), and vice versa.
Good god. [Why haven't I realized this sooner?](http://imgur.com/ITqUUZD)
What happens when you take a mutable reference to a non zero-sized constant - `let a = &amp;mut CONST;`? Is it still copied to the stack or it doesn't compile?
&gt; It does stand out though. What's something more fitting? Hematite, ochre, rouge, maghemite or colcothar. All iron(III) oxides, or containing iron(III) oxides. Ochre is kinda neat, it's painting with rust.
I think it should be prohibited. Now when constants don't behave as rvalues when taken by immutable reference, they would be better not behaving as rvalues at all. Taking a constant by mutable reference is rare anyway and making the created temporaries explicit would benefit both a reader and a writer of the code and prevent some very confusing cases like const A: [u8; 3] = [1, 2, 3]; fn main() { A[0] = 4; } 
That's an interesting point. I expect the result of that program to not have changed due to my patch, but I can't confirm atm. Could you make this suggestion on the internal discuss forums or in a rust-lang/rfcs issue?
Unfortunately the Rust fungus isn't exactly what you'd call friendly to trees... 
As stated by others equality constraints aren't fully implemented for a couple of reasons internal to the compiler. I have an open PR that turns on the partially working equality constraints and adds a feature gate for them. Fully functional equality constraints are mostly likely on hold until either Niko or I have time to implement them, and I've been swamped by things unrelated to Rust as of late.
So in this case the &amp; operator is acting as a borrowing mechanism? As far as I can tell the &amp; operator in Rust is entirely for borrowing, unless you start writing unsafe code in which case it reverts to its more traditional form of being used with pointers. Is this a correct understanding?
Then can it be defined, please? Because I don't know of a better way to discover the details without delving into compiler internals. 
It gets installed by the installer if you're using a nightly. And the book is in src/doc/trpl
You **could** use it with a blocking thread, which calls execute when more input arrives. However, the point is to use it with a polling based system, such as epoll/kqueue (or Mio :)) When new data arrives for a connection, that's when you call execute() with the new buffer of data. It is a push vs pull model. The gain is not in the request availability itself, the gain is that it is the only way to utilize polling driven socket management systems, which is the only way to achieve &gt; 10k concurrent connections. Joyent's http parser is a bit ugly, I've just discovered https://github.com/h2o/picohttpparser which is much more readable, and faster. 
really?
Great series! Rust should be able to reach C level speed but I'm almost sure the golang implementation is hand crafted assembly (see: https://github.com/golang/go/tree/master/src/crypto/sha1)
Not currently, there's some open issues for both .pdf and .epub.
It's still widely used for checksumming though
It depends on the usage. For example, git commits are referred by a SHA-1 hash, but this isn't a security feature -- actual "security" (to detect tampering) is achieved by signing the commit (or a tag) with GPG.
 [dependencies.color] git = "https://github.com/bjz/color-rs.git" rev = "bf739419e2d31050615c1ba1a395b474269a4" No GPG protection from tampering here.
That's mostly correct. In fact borrows are pointers too; Rust doesn't really hide this fact. You can do println!("{:?}", &amp;3 as *const i32); even from safe code. The key difference is that raw pointers have no lifetime / validity checking, so you can't *dereference* them from safe code.
Signatures almost always work by signing a hash of the data to be authenticated. In the case of Git, the signature authenticates the commit / tag object itself, and the rest of the repo (all files, all commit history, etc) are authenticated through the Git object hashes, which act as a [Merkle tree](http://en.wikipedia.org/wiki/Merkle_tree). Unfortunately this means a SHA1 break compromises the whole scheme.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Merkle tree**](https://en.wikipedia.org/wiki/Merkle%20tree): [](#sfw) --- &gt; &gt;In [cryptography](https://en.wikipedia.org/wiki/Cryptography) and [computer science](https://en.wikipedia.org/wiki/Computer_science), a __hash tree__ or __Merkle tree__ is a [tree](https://en.wikipedia.org/wiki/Tree_(data_structure\)) in which every non-leaf node is labelled with the [hash](https://en.wikipedia.org/wiki/Hash_function) of the labels of its children nodes. Hash trees are useful because they allow efficient and secure verification of the contents of large data structures. Hash trees are a generalization of [hash lists](https://en.wikipedia.org/wiki/Hash_list) and [hash chains](https://en.wikipedia.org/wiki/Hash_chain). &gt;Demonstrating that a leaf node is a part of the given hash tree requires processing an amount of data proportional to the [logarithm](https://en.wikipedia.org/wiki/Logarithm) of the number of nodes of the tree; this contrasts with hash lists, where the amount is proportional to the number of nodes. &gt;The concept of hash trees is named after [Ralph Merkle](https://en.wikipedia.org/wiki/Ralph_Merkle) who patented it in 1979. &gt;==== &gt;[**Image**](https://i.imgur.com/MzU6lAc.png) [^(i)](https://commons.wikimedia.org/wiki/File:Hash_Tree.svg) - *An example of a binary hash tree. Hashes 0-0 and 0-1 are the hash values of data blocks 1 and 2, respectively, and hash 0 is the hash of the concatenation of hashes 0-0 and 0-1.* --- ^Interesting: [^MD6](https://en.wikipedia.org/wiki/MD6) ^| [^Libtorrent](https://en.wikipedia.org/wiki/Libtorrent) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+copewdn) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+copewdn)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
It would need to re-hash every commit and every historical version of every file in the repo. SHA-1 is *meant* to be secure, it just hasn't aged well, much like MD5. afaik Git includes no provisions for upgrading to a stronger hash, which is a huge blunder.
Oh, I totally missed that! Now I will have to test the pure go version. Will take your bets ;) ... I think it will be clocking in at about 250MB/s.
I wouldn’t bet on that, everybody else except Amazon supports epub including Apple. Besides, you can always just convert epub to mobi.
Well, actually, I kind of motivated by [this post](https://www.reddit.com/r/rust/comments/2w825v/local_times_in_chrono/). I was working on two different major features that eventually merged into 0.2 for weeks, but my daily job and other distraction factors have prevented me from making a full release. Thank you /u/savage884, I finally got enough time *and* motivation to get that done. :) (Some people from #rust would also recognize that I've done a live streaming of finishing 0.2.)
https://github.com/rust-lang/rust/issues/12859
1. You're moving a Sender into a closure environment. 2. The closure must implement Sync because your closure may be called in parallel on multiple threads (this is what allows hyper to process multiple queries at once ;)) 3. Because the closure must implement Sync, all of its components must as well. Sender does not implement Sync. If you want to avoid this, wrap your type in a Mutex and unlock it when you need to use it. If in the future it (Handler) uses Clone your Sender will simply be cloned. The relevant issue: https://github.com/hyperium/hyper/issues/248
Are you talking about `extern { static mut ... }`? That is not affected by the RFC I want to propose.
For some reason I can't see it if I type "Mozilla" in the search box. The direct link and typing the EIN work fine though.
I had thought that the URL included it, sorry. The EIN is 200097189 for those that need it.
I thought it was a funny article and didn't read it as an attack on Go. But I can see now how others may misinterpret the posting. Deleting... sorry. 
Hematite already means [something different](https://github.com/PistonDevelopers/hematite) though.
The `sys` module currently contains a number of un-exported implementation details for higher-level APIs in `std`. The plan is to eventually export a fair amount of this at a lower level, where it makes sense. However, in the 1.0 timeframe we are very focused on stabilizing the primary, high level APIs in `std` so those are taking priority for now.
is there a work around?...maybe an out of tree package that exports the types?
As far as I know, the Mozilla Foundation doesn't support Mozilla Research -- a division of the Mozilla Corporation -- financially in any way.
TL;DR: OP really likes that Cargo and Rustdoc comes bundled with the language and has opinionated and simple defaults/interfaces. Otherwise finds Rust's cross-compilation support relatively immature.
No idea. I believe it is possible to request Charity Navigator to rate a nonprofit. I believe they also have some set of requirements that need to be met before they will do it.
No, it's part of a for-profit company. That said, if at some point in the future, the Rust core team wanted to make the Rust project exist independently from Mozilla, they could start a nonprofit like the Apache Software Foundation or GNOME to oversee it, which could accept donations. But I don't know if that will ever happen.
How did it clock? Betting on 260 on gccgo
Not sure about thiez, but: I personally have no issue with the post. It's a fun satire on a language. I agree that it is gentle teasing. However, I don't see any point of posting it here. This is the Rust subreddit. Not the new-programming-language subreddit. While Rust and Go have been traditionally compared quite often, that doesn't mean that a post criticizing/satirizing Go is on topic here. But of course, posting a critique about Go is bound to evoke some reaction from the Rust community ("yay! Go sucks!"), and that's what it _seems_ like the post is trying to stimulate. So, it's off topic and flaimbaity. I'd love to read this on programmerhumor or elsewhere, but not here. --- Now if the post explicitly was [a](http://arthurtw.github.io/2015/01/12/quick-comparison-nim-vs-rust.html) [comparison](http://andreaferretti.github.io/on-rust-and-nim/) [between](http://youtu.be/WVZ7yMvxImo) [the](http://www.infoworld.com/article/2877924/application-development/go-rust-road-ahead-young-programming-languages.html) [two](https://medium.com/@adamhjk/rust-and-go-e18d511fbd95) [languages](http://joshitech.blogspot.com/2014/11/fibonacci50-rust-slower-than-go.html), there is some constructive discussion that can be had. But this isn't a comparison. The only constructive comments we can really make (aside from the gophers in the subreddit) on this topic are "Well, Rust doesn't do any of those things" and pat ourselves on the back.
Lockfiles pin down the version unless you run `cargo update`.
`foo#add` takes a mutable reference of self, so you cant take anything from it, the solution is simple, yet more irksome, i admt: #[derive(Debug)] struct Foo { value: u8 } impl Foo { fn add (&amp;mut self, x: u8) { self.value += x } } fn main () { let mut foo = Foo { value: 42 }; let val = foo.value; println!("{:?}", foo); } I think this only works because `value` is Copy, so it might be different with non-`Copy`able code. [playpen](http://is.gd/4u3iio) hope that helps!
Thanks, the files are available via HTTPS already and I updated the URL in the post. I also updated the build script to generate a file containing SHA-256 hashes. I don't plan on maintaining archives, but it's pretty easy to build from source if necessary. I hope the Rust team will distribute FreeBSD binaries of the final 1.0.0, since they have working build bots already, but if not I might investigate creating packages.
"Nick Nethercote fixed memory measurements for jemalloc" I would have never guessed. :P Nice job at removing 1.2 million clone calls too.
I really hope so! In a place where debugging is orders of magnitudes harder, the guarantees that Rust makes would be crucial. Unfortunately, I don't think that rustc can cross-compile to many embedded systems architectures very well. 
There are about a kajillion lines of legacy C code in existence. Also there are many obscure chips with an implementation of C (or some wacky dialect of C) that LLVM will never support. I think Rust will soon be a great choice for consumer-focused embedded systems ("Internet of Things") built around 32-bit ARM microcontrollers, which have become amazingly cheap and powerful. Indeed there's already been some [work to build an RTOS](http://zinc.rs/) for such chips. There are other industries (e.g. automotive, aerospace, nuclear power) that are a lot slower to adopt new technology, and for good reason. There are also many sophisticated static analysis tools for C, which do things far beyond what Rust's built-in checking can do. C is in some ways a nightmare for static analysis, but it has the twin virtues of being relatively simple and massively important. Truly *replacing* C would occur on a scale of O(100 years)... it seems absurd to make technological predictions of any sort on that scale.
Excellent, thanks! 
This is strange when you first meet the problem, but it is a trade-off if you want clear rule for when ownership borrow returns. Clearly, someone will downvote this but myself think my comment is actually constructive this time. Please, leave a comment if you're sure I'm wrong. 
&gt; This is strange when you first meet the problem, but it is a trade-off if you want clear rule for when ownership borrow returns. It is not necessarily a trade-off. It is just a matter in which order the compiler ~~borrows the object~~ evaluates the arguments. If the compiler would ~~borrow~~ evaluate the arguments of the method first, this problem would not occur in all cases not involving the use of a reference. See Sinistersnare’s example as a proof.
What level are you looking for/going to start writing the exokernel stack at? You'd either have to write drivers for actual hardware (bad idea) or piggyback off Xen/KVM as OpenMirage does. Once you have those bindings it's a case of writing all of the other infrastructure, an ssl stack, etc, then you can write your REST server. There's a lot of pieces missing from the jigsaw. It's completely possible, but as far as I know noone has worked on it and it'll probably be years before the pieces are in place.
I don't agree with that. struct Foo { value: u8 } impl Foo { fn add (&amp;mut self, x: u8) { self.value += x } } fn main () { let mut foo = Foo { value: 42 }; let val = &amp;foo.value; foo.add(*val) } I think order doesn't matter here, it's about when borrow returns. 
Of course. That is why I wrote it will work in all cases where references are not involved (or where the value is `Copy`). I must admit that my wording was not precise enough: It matters in which order the compiler evaluates the expression. If it would evaluate the arguments first, your example would compile as well. I reworded my post. My main point is: It is thing which can be fixed in the compiler (relatively) easily.
Would it be desirable to have a factory-trait for Duration? Would be handy to be able to write `UTC::now() + 1.day()`
&gt; I have a kindle myself and I’m exclusively putting epubs on it If you're converting it to kindle format then clearly you're not exclusively putting epubs on it... There's no point in making everyone do the same conversion step. 
Is it only to handle calendar/timezones stuff, not to measure short time intervals, for that purpose I should use `time`, right?
I'm worried that people will call`UTC::now()` several times and then subtract them from each other to measure time (e.g. how long some code was executing). This should be explained and discouraged in documentation.
I think the question was: Why is `foo` borrowed mutably *before* `foo.value` has been evaluated and converted to an rvalue? So, there is an ordering that would make this function call OK.
This is really tricky question! I cannot give you answer myself. The best resource on this (besides asking Rust devs) is probably this section of reference document: http://doc.rust-lang.org/reference.html#unsafety If you do not find the answer there then you should create an issue for that.
Agreed. An ex-Chrono type `Duration` has a [`span` method](http://doc.rust-lang.org/nightly/std/time/duration/struct.Duration.html#method.span) which can be used without requiring Chrono at all, for your information.
Given that most electrical engineers only begrudgingly accepted C sometime late last year, I highly doubt it.
&gt; There are about a kajillion lines of legacy C code in existence. soooo way overrated of a problem
But Mozilla has a larger impact on the world. It is now the lone voice protecting users on the Internet where Apple, Google, and Microsoft would like to monetize them faster.
`self : Box&lt;Self&gt;` is a special case in which the syntax is valid.
I can see the following in the reference: &gt; 6.1.3.2.3 Behavior considered undefined &gt; Mutating an immutable value/reference without UnsafeCell Does this apply to my case?
The Free Software Foundation (FSF) and Electronic Frontier Foundation (EFF) have almost the same (if not more) impact, yet they have far less budget (less than 1% of Mozilla's). What I'm saying is that 80k$ will be more missed by them than Mozilla will miss it. EDIT : you can also have your national digital freedom organisation, who works against the laws that allow the companies you mentionned to do what they do. Simple example, there is only one in France, the "Quadrature du Net" and it survies on 200k€, and all the employees are payed minimum wage. Where do you think this money will have the more impact ?
Apparently this thread is against the rules: https://www.reddit.com/r/redditdonate/wiki/index#wiki_what_is_an_ein.2Ftax_id_and_how_do_i_find_it_for_my_favorite_charity.3F Of course everyone seems to be doing it...
There is one thing about Rust that will seriously hinder the more serious embedded development - it's designed for a system with Virtual Memory where malloc never fails. For simple embedded applications you don't need any dynamic memory allocation, but for serious stuff you don't have enough memory *not* to do any memory allocation. Take a protocol stack (my area) - you can't allocate all the buffers you might need statically, there isn't enough memory. You can't put them on the stack because it's too small. You malloc buffers for received data and pass them up the stack de-allocating as you go. The fundamental mechanism for dynamic memory in Rust is 'Box' and there is no mechanism to gracefully handle Box failing to allocate memory. You can't have an embedded target crash if it can't allocate memory for an incoming packet, it can abort the procedure and drop the connection but it needs to be able to handle all of that programmatically, returning error codes etc.
Definitely not if you do not declare variable as `static mut`. Going back to your original question: On one hand, if you do not want to write to the global variable then declaring it `mut` does not make sense. On the other hand, I would worry about load/store optimizations because compiler expects that the value never change. Even in case of `static mut` it is not clear from reading the reference that it is safe: fn foo() { let a = global_value; // loads value extern_fn(); // modifies value let b = global_value; // loads new value assert!(a != b); } If the extern call is memory barrier for global_value, then the code is correct. I would expect that it is (it should be for all global values) because otherwise I cannot see how the global mutable variables could work in Rust in general. But I cannot say for sure.
I don't actually know the answer, to be honest. I would assume that you need the mut.
Cool
In practice - the fact that you may well not want the default heap allocator. You might have set your heap segment size to 0 and be using a custom allocator. That's not insurmountable though. In practice as @stevelabnik1 has suggested above, you throw away all the standard library dynamic memory stuff and start again.
Embedded is a bit of a nebulous term these days. Very difficult to define. My working definition is "doesn't have a virtual memory controller" which seems to work reasonably well to separate the two worlds.
I doubt that avr-rustc will happen before AVRs become significantly less popular. Arduinos are moving towards ARM like the rest of the world, eg the new ["Zero"](http://arduino.cc/en/Main/ArduinoBoardZero)
Gist SHA1 isn't mean to be secure. There is no point to be secure about that. Collisions in code repository are very unlikely. The main reason to use SHA1 is that it is fast and also has small collision propability.
SHA-1 is used to refer both to the object tree for the commit as well as reference the commit's parent commit. If you can find collisions for the former, the signature is suddenly valid for two different states of the repository content.
No, I wouldn't like to justify it, because this is just a message board and not a congressional investigation. But most projects are greenfield projects anyway. Code reuse, beyond the OS, is mostly a lie. And for embedded systems, if it's not big enough to run Linux, then it's small enough that you can probably keep all the code in your head anyway, so it's not like you couldn't rewrite all that code anyway. People have been using "legacy code" as a cover-all excuse for not doing things for decades. If they had just not made the excuses in the first place, there wouldn't be unmaintainable legacy code.
If this field had more people with degree in computer science or related education/experience (I'm thinking about mathematics here, not engineering), we'd probably see much more new technologies and advancements being used. However, most people working on embedded systems have limited programming experience, or limited language knowledge, or limited theory knowledge, or any combination of these. For instance, if you try to explain why keeping the core code - ~10% of code where the program spends ~90% of it's time - as C/C++ and use a higher level language for safety guarantees in the other non-time critical part, they will ask you: "why use two languages when I can use only one that does everything?". In fact, this could be the core of the argumentation in most cases. Also, some would immediately think of tools like like python (terrible embedability), lua, ruby, or even perl (all with no runtime guarantees) as these "high level" languages, as their lack of knowledge would immediately direct them to the nearest thing they can compare to. Explaining inferred types, algebraic type declarations and parametric polymorphism is almost as hard as it can be. Last, but not least, you'll hear the "this is unfeasible" arguments. "Where are we going to find people to program in these things?" I see the same thing happening with Rust, at least in the short term. It would be a good thing if a language like this gets traction enough to cross that barrier, but I have a little less hope today than I had at my 20s.
You might also like: https://twitter.com/horse_rust
Hmm, there is at least one typical example of this in libc - the `errno` variable. Which the stdlib needs to read. However, [the way it is done in Rust](http://doc.rust-lang.org/src/std/sys/unix/os.rs.html#58) does not give a good answer to your question, I'm afraid.
No.
It's not likely to, as it's backwards compatible to fix, sorry :/. 
Really nice video, I'm actually still in the middle of deciding whether to use Go or Rust for my latest project. Too many things to consider, they both have amazing qualities yet they differ so much... 
As far as i know, errno can be implemented as macro. So I am not sure that this example is correct for this case.
Would be much appreciated!
Will it get fixed at all, then?
As felix says in https://github.com/rust-lang/rust/issues/6268#issuecomment-38216126 , it's certainly nice to fix, but hasn't been known to be a major problem. If it's causing you lots of issues, you should raise that in the ticket so we know about it. It will eventually get fixed, but because we're trying to ship 1.0, anything that's not directly relevant gets put into the "post 1.0" bucket.
Thank you for taking the time to explain this! I have a much clearer mental model of things now.
The [Bitcoin hash rate](https://blockchain.info/charts/hash-rate) is about 2^58 per second. Yes, really. I believe each of those is a double-SHA-256 operation, which is around twice as much work as a SHA-1 operation. There are [attacks to find a SHA-1 collision](http://en.wikipedia.org/wiki/SHA-1#Attacks) in something like 2^60.3 to 2^65.3 operations. Of course the majority of Bitcoin's hashrate is provided by special-purpose hardware that couldn't easily be repurposed for SHA-1 collision finding. It's just a general measurement of the feasibility of the attack. Another measure: "estimated cost of $2.77M to break a single hash value by renting CPU power from cloud servers".
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 6. [**Attacks**](https://en.wikipedia.org/wiki/SHA-1#Attacks) of article [**SHA-1**](https://en.wikipedia.org/wiki/SHA-1): [](#sfw) --- &gt; &gt;In early 2005, [Rijmen](https://en.wikipedia.org/wiki/Vincent_Rijmen) and Oswald published an attack on a reduced version of SHA-1—53 out of 80 rounds—which finds collisions with a computational effort of fewer than 2^80 operations. &gt;In February 2005, an attack by [Xiaoyun Wang](https://en.wikipedia.org/wiki/Xiaoyun_Wang), Yiqun Lisa Yin, and Hongbo Yu was announced. The attacks can find collisions in the full version of SHA-1, requiring fewer than 2^69 operations. (A [brute-force search](https://en.wikipedia.org/wiki/Brute-force_search) would require 2^80 operations.) &gt;The authors write: "In particular, our analysis is built upon the original differential attack on SHA-0 [*[sic](https://en.wikipedia.org/wiki/Sic)*], the near collision attack on SHA-0, the multiblock collision techniques, as well as the message modification techniques used in the collision search attack on MD5. Breaking SHA-1 would not be possible without these powerful analytical techniques." The authors have presented a collision for 58-round SHA-1, found with 2^33 hash operations. The paper with the full attack description was published in August 2005 at the CRYPTO conference. &gt; --- ^Interesting: [^SHA-2](https://en.wikipedia.org/wiki/SHA-2) ^| [^Secure ^Hash ^Algorithm](https://en.wikipedia.org/wiki/Secure_Hash_Algorithm) ^| [^Sha1sum](https://en.wikipedia.org/wiki/Sha1sum) ^| [^RIPEMD](https://en.wikipedia.org/wiki/RIPEMD) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+coqjmrn) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+coqjmrn)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Thanks for showing the calculations. Three millions is a lot of money, but it is not astronomical. That kind of shows how insanely powerful the bitcoin network is too..
I totally thought `rm Cargo.lock` was the official update command until just now. :P
By defining the method as `fn mutate(&amp;'a mut self) { }`, you tell rust that the `&amp;mut` borrow for the method call is supposed to be valid as long as the inner reference of the `Foo&lt;'a&gt;`. That means once you call `mutate()` in `main()`, rustc assumes it will be mutably borrowed as long as the borrow to `val` is valid. That borrow however outlives the loop, so the mutable borrow does as well, and you get the error because a second loop iteration would create a second mutable borrow of the same lifetime. What you want to do is to remove the `'a` form the `mutate` method, to make it get a new lifetime. (It will be equivalent to `fn mutate&lt;'b&gt;(&amp;'b mut self)`). That way you get a new independent borrow only for the duration of the loop body.
&gt; And for embedded systems, if it's not big enough to run Linux, then it's small enough that you can probably keep all the code in your head anyway, so it's not like you couldn't rewrite all that code anyway. For several years I worked on an embedded target running a full Bluetooth protocol stack. It was a 64Mhz processor (probably still is) with something like 300k of RAM and 4-64Mbit of flash for code. As far as I'm concerned that's still at the large end of 'embedded'. The codebase we compiled for it was about 1 million lines of C. It was one of the best maintained and well architected codebases I ever worked on, I understood it well and I couldn't get anywhere near 'keeping it all in my head'. It had, I would conservatively estimate, 100 man years of effort in it. I personally put 2-3 man years in. This is not something that you could just rewrite. This is why good interfacing with the existing world is important. There is an enormous investment of time and money in existing code, and being able to build upon that and work with it rather than throwing it away and starting again is absolutely vital if you want people to use your shiny new language.
Thanks. The concept that was confusing me is that the 'a lifetime refers to the borrower, not to the borrowee.
Awesome! Reading it now :) Glad to see an Intermediate level of Macros being presented.
Unless you've got a C-to-Rust compiler lying about...
Alpha 2 is coming out tomorrow, and there are less and less breaking changes since that. Maybe start learning it this weekend? You might need to change something now and then, but nothing radical's not gonna change anymore.
&gt; The book itself looks about done now Well, I landed a [rewrite of the macros chapter](http://doc.rust-lang.org/book/macros.html) this morning :) /u/steveklabnik1 is hard at work on chapters on closures (currently lacking) and associated types (currently nonexistent). The docs on [static and dynamic dispatch](http://doc.rust-lang.org/book/static-and-dynamic-dispatch.html) are very new as well. Most of the content there is solid, but it's not really "done" even for 1.0 purposes.
Actually I think you're wrong there. It's a common mistake that people make in internet discussion groups - most of the people in the internet discussion groups only represent a small part of the larger software community. I particularly remember a comment on Hacker News that said "Does anyone even write C any more?" An absolutely enormous amount of (particularly) C and C++ is written by enterprises as internal tools and as products to sell. Those codebases get years of effort and are an enormous part of the value of those companies offerings. It's easy to forget because it mostly isn't discussed on the internet (for lots of reasons, commercial confidentiality being a big one). Inevitably a lot of what gets discussed on the Internet is web developers doing web things. This is why C, C++ and Java are stuck at the top of the TIOBE rankings. They're languages used by enterprises and that's where most of the software engineering effort in the world is done. If you want these companies to use your new technology, you need them to be able to use it without throwing away everything they already had. And you really do want them using it, that's the difference between a well designed toy of no particular significance, and a serious competitor.
I am literally re-writing the documentation chapter now, and there's still tons of topics I could add. major standard library features have basically no documentation, or at least, no documentation I approve of (I'm mostly kidding, I just haven't read it at all, they could have amazing docs) Not to mention, the entire first part of the book becomes invalid now that `rand` gets moved out to Crates.io. :/ Sixteen open issues: https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AA-book
The Arduino language is C++ with some headers included by default. I've also used straight-up `avr-g++` to target AVRs with 64 bytes of RAM. Sophisticated static features like templates are really handy when your device is so limited at run-time. Outside of the enthusiast world, inertia and proprietary toolchains are a big obstacle, yeah.
I found the first hygiene example quite clear and obvious what problem hygiene is trying to solve but the second example not so clear. So you pass a string to a `LOG` call whatever that does but you have to pay attention to the name the string is saved as otherwise the example makes no sense. const char *state = "reticulating splines"; LOG(state); I didn't even notice the `state` in the external call until I'd read the example a dozen times trying to make sense of it. So, the next two statements: "watch what happens" and "will likely segfault" aren't clear. They both look fine so the problem isn't clear. Other than that, I find it fairly clear. The formality is odd as it jumps around a lot from "Whoa, that's a lot of new syntax!" to talking about "syntax trees" and "grammars" without pausing. One more thing: I previously did not find the repetition operators magical. I found them [extremely](https://github.com/rust-lang/rust-by-example/pull/193#discussion_r15363505) [confusing](https://github.com/rust-lang/rust-by-example/pull/200) (I was trying to explain their behavior but I had to use a myriad different cases to show how they operated). Their current behavior may be more understandable now than then but calling them magical sets high expectations. I hope it's warranted...
As a little extra, you don't have to even define the second lifetime `'b` you can use make it impl&lt;'a&gt; Foo&lt;'a&gt; { fn mutate(&amp;mut self) { } } You don't need to even define the second lifetime `'b` in mutate.
The language itself seems quite stable in the basic concepts although some of the libraries, especially io will change soon. On the other hand there are just the compiler and cargo, but no real IDEs, no tools for refactoring nor debugging and only few examples. If you used to work with java and the eclipse ecosystem rust will seem primitive and unergonomic to you.
Rust is already on Homebrew Cask (http://caskroom.io/)
The cask formula uses the official Rust installation packages and therefore also comes bundled with Cargo. To upgrade to the latest nightly build you just need to do an manual update with *brew cask install --force rust*. You are right the **brew** formula doesn't contain Cargo, but if you use the **brew cask** formula it works fine.
Oooh nice; I wish I could come to this one!
Can macros be used in the context of creating structs and such? Maybe something like a macro over: struct Point { x: f64, y: f64, z: f64 } where you can pretend the struct is an array with the result? 
Yes, definitely. Rust is converging on its 1.0. There will still be changes, but the core "feel" of the language is quite stable.
Thanks for the feedback. I'm already working on another set of tweaks to the document :) &gt; I previously did not find the repetition operators magical. I found them extremely confusing Yeah, the old version said "magical and unintuitive" which is probably more fair :) I really wanted to express both parts -- the ability to "do what I what" a lot of the time, combined with uncertainty over the exact rules and how they'll behave in another context. I think "magic" has the latter connotation as well for a lot of programmers, but you're right that it could sound like a simple boast. &gt; The formality is odd as it jumps around a lot from "Whoa, that's a lot of new syntax!" to talking about "syntax trees" and "grammars" without pausing. Those are vital concepts in programming languages, especially if you're working with macros. I don't think that a conversational or informal tone is incompatible with using precise terminology. That seems like setting our standards too low :) We could do more to define them within the text, though. There's a glossary for the book in progress. I'll open a ticket for that.
So the Mozilla Foundation and Mozilla Research are independent from each other but both divisions of Mozilla Corporation. It is a bit confusing.
For sure. I have been playing around lately with some more experimental languages and it's kind of shocking how mature Rust feels by comparison. Having easily decipherable error messages is huge, for example.
what do you mean by contents of the commit? I thought you had some idea of how git works :-) This is an example of what the raw data of a commit looks like: tree 0946c58b4844929c8057599d414d51aee3ba8ae2 parent be1027a90d535014df7787ede862c2f8be88494b author Author &lt;Author@localhost&gt; 1423934735 +0100 committer Author &lt;Author@localhost&gt; 1423934735 +0100 Commit message commit message here, etc etc as you can see, the meaningful "content" of the commit is the references it has to the state of the directory -- a tree hash -- and the parent commit -- a commit hash. 
As of 2012, according to [their publicly disclosed tax return](https://static.mozilla.com/moco/en-US/pdf/2012_Mozilla_Form_990-Public_Disclosure.pdf), the Mozilla Foundation (not Corporation) had $24,000,000 in assets. It's certainly up to each person to decide where they can have the most effect with their money and what they care about the most, but the Foundation isn't hurting for money.
Actually, the part that I used to think *might* be magical was how `$($x:expr),*` matches `1, 2` but not `1,` (note the trailing comma) as a regex would. This actually became problematic when I tried to do more complex (determining what was allowed) things with the splitting operator though. I don't inherently disagree with you about the tone and these things are hard to get where everyone agrees anyway. Thanks for working through this section. Seems good. Especially how you describe hygiene using rust syntax. It makes the examples particularly relevant and doesn't require interpreting an unknown syntax to decipher (like when reading wikipedia). By the way, I think the glossary is such a super awesome move. It could make so many of these little issues better.
This is cool. Just the other day I was thinking of implementing the BitTorrent protocol and then maybe a simple client on top of that. 
We've talked about adding an `unlock_unchecked` method, together with ensuring that `mem::forget` works on the guard. Also, depending on what you're doing, `park`/`unpark` might be useful: http://static.rust-lang.org/doc/master/std/thread/index.html#blocking-support:-park-and-unpark
Wow, that's awesome :) I didn't know avr-llvm was so active now.
"This number 4 *is* random. It was selected by rolling a fair die."
&gt; Can I leverage the shape of the struct inside of a macro? Not very well, yet. It's something that a lot of us are thinking about, e.g. for user-defined `derive` traits.
IMO c/c++ will never be replaced: because - as soon as we move away from it, there are many ways in which people disagree on what should be changed and how. C can live on since nothing has attempted to replace its' actual purpose as I see it - the *simplest* language that eliminates the need to write most assembler. C++ and Rust are both too complex to do this (e.g. requiring you decide on how polymorphism should work). And as long as there's C, there will be C++. I like the relationship between C and C++ - splitting the complexity into layers. Yes I know C++ is not a strict superset of C, but near enough .. I wish C++ would patch over a couple of issues there like void*. Personally I would like to see more choice ... I hope Rust is here to stay, and more languages will follow;all with interoperability. (C ABI, LLVM, ... maybe c++ will get an abi and some subset of that makes for better interfacing ). What I think will happen is C/C++ live on through momentum, and attempts to 'replace' it will specialise into niches (rusts' being security obviously, and there will be others, like gamedev's need for a 'fluid'(creative) kind of productivity+C-like low level performance over all else)
I would be more economic with the use of `unwrap`. Especially your long-running background thread may panic but you have no provisions of restarting it automatically. You can simply call `map` on the `Option` and handle the error at the end of the chain.
thanks! I will look into that
&gt; NOTE: This module is very much a work in progress and is under active development. At this time it is still recommended to use the `old_io` module while the details of this module shake out. Most likely a bug that will be fixed in time
My experience with Go was similar to this (though I didn't know Rust at the time). It's certainly a nice language, and goroutines are awesome, but the type system felt too restrictive to me - I expected more powerful tools from a static type system. I'm surprised you didn't mention compile times. That seems to be a big advantage of Go compared to Rust. I know you didn't mean your post as a comparison between the two, but that sounds like something a Rustacean would notice. Overall, I really liked your post. I really appreciated the level-headed tone, which certainly sets an example. This kind of post tends to generate inflamed discussions, but there's no reason it should be this way.
 &gt; I expected more powerful tools from a static type system. Probably obvious from the post, but this irks me a lot. If it's a static type system and a compiled language, I really expect a lot of lifesaving compile time checks. Not necessarily the Rust level of compile time checking madness, C++/Java level is enough for me. But with Go, that's not there and I feel strange about it. &gt; I'm surprised you didn't mention compile times. Simply because I wasn't compiling large things in Go. All my code is small enough that even if written in Rust, compile times would be pretty small. I knew that there was a difference in compile times, but it didn't affect me personally so I didn't write about it :) &gt; Overall, I really liked your post. I really appreciated the level-headed tone, which certainly sets an example. Thanks! &gt; This kind of post tends to generate inflamed discussions, but there's no reason it should be this way. Agreed. I consciously tried to avoid anything flamebaity. As far as /r/rust goes it's much more civil (just see how [this](http://www.reddit.com/r/rust/comments/2wd4y2/you_dont_like_googles_go_because_you_are_small/) was handled), though you still get some flaming in extended discussions like [this one](http://www.reddit.com/r/rust/comments/2vqy81/author_of_unix_in_rust_abandons_rust_in_favor_of/), but it doesn't hurt to be sure. I'm still debating whether or not to share this on the Go subreddit; I'm not sure how prone they are to flamewars :s
Its a balancing act with static languages for me. I'm a java dev by day but the quick iteration and development speed I have in Python keeps me using it for personal projects. Sure I make some mistakes that static would catch but at the same time I move faster and fix the mistakes faster.
&gt; From the outside, it seems that Rust's big weakness might be compile speed for a while. I hope that improves, but understandably it will always be slower than Go. I've always hated compile times. When I used to work with Firefox I'd stick to Desktop code (which is javascript and doesn't need a recompile). I've pushed for various measures that would speed up Firefox compile time, even tried hacking at some of the ideas. When I started working with Servo, I was again irked by the fact that we downloaded Rust, and built it (and llvm!). This gave me enough drive to [fix it by making Servo use a snapshotted Rust](https://github.com/servo/servo/pull/2639). We're pretty fast on incremental builds now, but I still hate the compile times and I keep thinking up wacky schemes that aren't going to work to split up our code to make it faster to compile. (The above was just to give a picture of how much I hate compile times :P ) Despite hating compile times so much I will still write whatever I can in Rust. I know that it will take twice as long to compile. However, I don't mind this because Rust trades off compile time efficiency for something much more valuable: compile time correctness. It tries to be "correct" about so many things at compile time (and gives tools at various levels so that others can add more checks of correctness, whether it be by the type system or by the plugin system) that I rarely have to worry about runtime issues. With Servo code as long as it compiles, however large the PR, I'm usually happy and I don't worry much about the tests crashing. In any other language; I wouldn't do this -- I would run the tests and fully expect some effort to be required to make them work too. I find this quite liberating -- if it compiles, the battle is mostly won. And this is something I'm willing to sacrifice fast compile times for. 
They didn't until Java 5 IIRC.
I like rustdoc especially for the built in example-testing functionality, even if it is a bit more complex.
Yeah, me too. Go also has a way of [writing examples that are checked](http://golang.org/pkg/testing/#hdr-Examples) that is different from `rustdoc`, and the "check" comes when running `go test` as opposed to `godoc`.
As currently implemented on `BufReader` and `Cursor`, `fill_buf` returns the remaining part of the buffer until it is exhausted. I think this avoids excessive reallocations and copying, so it's a good 'default' behavior for the `BufRead` contract.
Subscribing to both /r/baduk and various programming subreddits always winds up with titles that cause little moments of confusion like this.
Maybe nim is actually the right language for you: with a GC, so you don't fight the borrow checker, but still a nice type system with generics, enums, and even meta-programming. I should of course mention OCaml because I'm a fan and it has quite good performances too ;)
&gt; I also heard a lot about how Haskell would be great for static analysis but there's hardly anything out there besides GHC's type checker. This is a language that has been known in academia for 15-20 years. That's because (unfortunately) Haskell isn't that popular in industry. As you point out, a static analysis is hard and a lot of what they do is fairly heuristic. Someone's got to pay for all that development. There's lots of companies to pay for something like Coverity because they all use C.
I don't _want_ a language with a GC, really (and when I do I'll use Python or JS), I just found the presence of a GC liberating. I don't really mind fighting the borrowchecker. I'm happy with Rust for now -- I've looked at Nim and like it but I have languages I'm more comfortable with right now which cover all my use cases.
Is it really “fighting”, though? I'd say, once you grasp the concept it'll become a second nature. I havn't tried Go nor Nim yet, but I'm familiar with multiple “GC languages” and for my kind of applications I don't really miss GC at all. It's hard for me to imagine how the lack of being able to express what I mean (w.r.t. who owns what) can feel liberating. Maybe I just had enough time to adjust to C++/Rust concepts. I dunno…
Yeah, we tried to remove the `'`, but it didn't end up working out either. Languages are hard.
Trait objects do indeed use type erasure.
For me python was already ruined by C++. I always ended with writing 5 lines of code just to check if the parameters are all ok and then I notice, that one Typename in C++ would have spared me all that. Now rust has ruined C++ with it's enums, type inference, the Option-type and built-in tuples.
/r/golang is pretty calm in my experience. If you don't troll about generics, then you will probably get a good discussion from them. /r/programming likes to paint /r/golang as some ravenous mob, but it's unfounded and tells more about /r/programming's anti-Go circlejerk than anything else. --- By the way, I enjoyed your writeup. What course are you using Go in?
It's my understanding that type erasure is a compile time process. i.e., It's orthogonal to whether there's actually a type tag at runtime.
Yes, that's mine as well.
If the primary reason you want a GC is to be able to freely share data between threads, you definitely don't want Nim: its GC is not thread safe.
http://docs.oracle.com/javase/7/docs/api/java/io/BufferedInputStream.html#read%28%29
Sorry, their first sentence about the general contract threw me off.
I'm really happy that this has landed! But there's some magic that I don't understand: When I look at the `scoped`'s signature: pub fn scoped&lt;'a, T, F&gt;(self, f: F) -&gt; io::Result&lt;JoinGuard&lt;'a, T&gt;&gt; where T: Send + 'a, F: FnOnce() -&gt; T, F: Send + 'a I don't get how the returned guard knows about `F` closure's borrows, as the `JoinGuard` has only `PhantomData&lt;&amp;'a T&gt;` and is not parametrised by `F` at all! From what I've tested, it works well – forbidding and allowing what it should – as if it also included `PhantomData&lt;F&gt;`. Is it possible that somehow `'a` is not just a lifetime, but conveys also information about what and how the closure borrows from its environment?
Nuclear reactors, chemical plants, and airplanes also require security. They aren't necessarily doing a great job of it, either. But I'd be terrified to fly on a plane whose software was written in a language with a single existing compiler that hit 1.0 in the past 10 years. The Canadian nuclear industry is going to keep using [PDP-11 assembler until 2050](http://www.theregister.co.uk/2013/06/19/nuke_plants_to_keep_pdp11_until_2050/). It's easy to laugh, but I'll bet they have a pretty good idea how those systems behave by now, and what can go wrong. Also these systems are far simpler than anything they could replace them with today. There is more code running in your hard drive or your motherboard's power regulation chips than in the entire PDP-11. I also read about an airliner that had two redundant computer systems, developed by different teams using different hardware and software designs. Maybe next time *one* of them should be in Rust ;)
I don't miss the GC that much in Rust. Atomic refcounting is safe and easy. Thread-local refcounting is safe, easy, and *really* fast. Cyclic data is a pain, but the really nasty cases don't come up too often. Plus if your data is non-enormous, you can copy it all over the place and your code will still be faster than the Python and Ruby scripts most of the world is using to get stuff done. Rust feels a like a high-level language when I'm not paying close attention to memory / performance. There are only a few extra annoyances. C and C++ give me the control I need 5% of the time and make me pay dearly the other 95%.
Heh, now I kinda want to troll both just to see what will happen :p Thanks! This is a course on cloud computing and distributed systems, by a really awesome professor. We're working with the Raft algorithm, and till now the assignments have been implementations of subsets of the algorithm. Both Rust and Go are suited for this (In fact Hoverbear [has an implementation in Rust being worked on](https://github.com/Hoverbear/raft/)) since they do concurrency pretty well, though for it to be easy to evaluate the code he's asked us all to use Go. (He's one of the few people in the city who _do_ know Rust)
&gt; I find this quite liberating -- if it compiles, the battle is mostly won. And this is something I'm willing to sacrifice fast compile times for. I agree. The funny thing is, Rust's compile-time checking isn't what takes up the time -- it's generating tons of LLVM IR and then optimizing it away. So rustc may get a lot faster in the future, although it'll never be as fast as Go's tools, which sacrifice anything they possibly can for compile speed.
Nobody else seems to be maintaining a DNS library and I had to retrieve TXT records for a program I'm working on. Certainly not production quality but better than nothing.
Point taken. It didn't really hinder things for me, and all that rust upgrading has gotten me used to running `sed` everywhere. But I see how it can be a problem for larger codebases.
&gt; When I started Go it felt like this was the answer, the end of the story That's really disheartening, because Go ignores nearly all developments in programming languages over the past 40 years. They want a language that is simple above all else, which is a valid goal. But it's weird to elevate it as the pinnacle of anything *except* simplicity. You shouldn't trust that someone has the end of the story if they're mostly re-hashing their own ideas from years past. Great artists steal.
True. However, from my point of view it's a blackbox with a tradeoff :) (Besides, using llvm lets Rust work on the good problems!)
Have you used non GC languages in large scale projects? In manual memory management, the problem knowing who owns what doesn't surface in small scale projects, nor when the source code for the whole application is available. However with high attrition in teams or binary only libraries, knowing what piece of code should manually release the memory goes out the window.
Oh cool. That sounds like an interesting class. I'm aware of a few Go implementations of raft: * https://github.com/hashicorp/raft * https://github.com/influxdb/influxdb/tree/master/raft * https://github.com/coreos/etcd/tree/master/raft
Virtually all signature algorithms are only signing hash of the message and hash function is meant to be cryptographicaly secure. I've never seen any digital signature algorithm which works differently.
Well written article. Anyways, comments: &gt; XHRProgress The XHRProgress would be implemented as an interface, e.g. type Progress interface { Headers(Id, *Headers, Status) Loading(Id, []byte) Done(Id) Error(Id, error) } The Shape example is weird, because I'm not sure where I would use such code - although I don't know Rust that well, the enum case seems to be closed to external extension. Although I can imagine several cases where such enum-s would be useful, e.g. specifying the types of XML struct. &gt; Smart Interfaces Yup, agree that such things can cause boilerplate, but I encounter such code very rarely in production code. &gt; Overall it seems like Go doesn't really aim for type safe abstractions, preferring runtime matching over types. Yes and no. There's less type-safety possible at compile-time, but as with any such language you can use/build other tools to support your additional constraints. For example I've used code-generation to ensure that I've the exact same structures in multiple languages, that diff/patch the same way. (More information about solving [similar problems](https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4/pub)) &gt; Visibility/Fmt It's simply something that you get used to after a while... any argument about style can be mostly ignored because after 1 month you get used to it. I write several languages (Go, JS, Delphi, C, Java), each having different conventions, and I hardly notice those minor details... the major gripe for me is not having a standardized formatting style across different libraries in the same language. *Disclaimers: I have more experience with Go. As with any language their use takes time to learn - hence the clarifications how you would do those in Go. By no means I'm saying Go is perfect, and that Rust is bad. When I had to write a browser/kernel I would choose Rust over Go any day... when I had to write command-line tooling, I would choose Go over Rust.*
I used [Postman](https://chrome.google.com/webstore/detail/postman-rest-client/fdmmgilgnpjigdojojpjoooidkmcomcm) during my testing, which is nice if you're already in your browser. I originally used the body of the request, and I may switch back to that, but headers were nice in that they already took care of some of the parsing work. Thanks for the feedback.
People are creating interesting products (Docker, coreOS, etc) in boring Go. But I have yet to see anything interesting from better languages.
The two big ones are OpenDNS https://labs.opendns.com/2013/10/04/zeromq-helping-us-block-malicious-domains/ and Skyligt.io http://blog.skylight.io/rust-means-never-having-to-close-a-socket/ , etc Until we have an actual stable release, I wouldn't expect more than a couple of others.
&gt; But I have yet to see anything interesting from better languages. What?
&gt; The XHRProgress would be implemented as an interface, e.g. No, this doesn't work. I wanted a union type of tuples, basically. A progress message can either be a "Oh look, we just got headers" message, containing the headers and some metadata, a "We just got some data" message, containing some bytes (+metadata), a "Done" message, containing metadata, or an "Error" message contianing metadata. It's not an "and" thing, it's either-or. It's a message; a signal, to be sent across threads, which may contain data. The message itself has multiple variants, each containing their own type of data. The rest of your points are well taken. I'm not so fond of relying on extra static analysis* for stuff I consider basic, like generics. The visibility and style thing I agree with; it's just what I'm used to and what makes it harder for me to transition. *Sort of hypocritical, really, I've authored the bulk of Servo's static analysis (achieved via the plugin/lint system)
When a lifetime is "reused" in more than one place, it becomes basically the intersection of all the actual lifetimes in play. e.g. `(&amp;'a T, &amp;'a U)` is basically implictely saying `'a: 'b + 'c`, where 'b and 'c are the "real" lifetimes of the two references. So the fact that `F: Send + 'a` and `JoinGuard&lt;'a, T&gt;` use the same lifetime variable means that they both "know" about eachother for the purposes of lifetime checking, as 'a has to accommodate both of them at once. Lifetimes also contain mutability information. So given: fn foo(&amp;mut self) -&gt; &amp;T fn bar(&amp;self) -&gt; &amp;T The reference returned from `foo` will behave as if is an `&amp;mut`, because it is tied to the same lifetime as `&amp;mut self`. This means that this code is invalid: let x = baz.foo(); baz.bar(); // oh no, baz is mutably borrowed by x
Sorry, I meant to say interesting products made in better languages
It doesn't run any of the code that it downloads, so currently nothing. All it does is download the code and run Cargo to generate the docs. That said, adding some sandboxing wouldn't be a bad idea, but it's not as critical as it is for play.rust-lang.org.
Time to start fuzzing libsyntax / librustc / rustdoc to find some juicy 0-day! They're written in an safe language, sure, but it's a 0.x version of a safe language, with some unsafe code mixed in and plenty of legacy cruft. I don't think people have put a ton of thought into hardening the compiler against malicious input yet.
Hm, good call with build.rs. It does run as a user who doesn't have permissions to modify much of anything, but I'll definitely look into sandboxing.
Refactored it to use a function instead. It will probably not work but puts down some ground to investigate further. I'll get back to it soonish :-) At my system, looks like its starting dispatch but ignoring the input/output of the command. When I code vim I usually start with some simple commands in my editor, surpised to see it not working :(
&gt; I wanted a union type of tuples, basically... Sure, I've tried that messaging approach in Go as well... it really doesn't work out well. After converting to interfaces/blocking the code got much simpler. &gt; A progress message can either be a "Oh look, we just got headers" message, containing the headers and some metadata, a "We just got some data" message, containing some bytes (+metadata), a "Done" message, containing metadata, or an "Error" message contianing metadata. It's not an "and" thing, it's either-or. I don't understand why the async nature of it is a necessity. There's also possibility of using: req, error := ReadRequest(in) ... data, error := ioutil.ReadAll(req.Body()) [pkg/http](http://golang.org/pkg/net/http/) uses that approach. If the headers didn't contain anything then the headers are empty. Anyways, I'm not saying the enum approach is bad, simply that it's not nice approach in Go and there are probably alternatives, although I cannot be sure because I haven't properly analyzed the decisions/problems that XHR needs to solve.
Nightlies are the unstable branch.
`rustdoc` also requires all upstream crates to be compiled, so presumably `cargo doc` is also building dependencies, and thus running arbitrary code.
Very cool project. Would be nice to have all the official crates' docs up there by default.
You could agree to use the next nightly after each stable release comes out. Or someone could build and upload the exact commit for each stable compiler, as a `-dev` build (the default when building from source) to enable unstable features. I think these conventions can evolve outside the core Rust project.
I was aware that lifetime "remembers" from what it has been borrowed and with which mutability, but I didn't expect that it can remember more than one source of borrow, as in following: fn main() { let mut var = 0; let val = 42; { let guard = std::thread::scoped( || { assert_eq!(val, 42); // added after edit var = 42; }); // println!("{}", var); // error, as expected println!("{}", val); } assert_eq!(val, var); } Note that this `'a` knows to handle `val` and `var` differently! This is what felt like magic to me. ---- Edit: Added immutable usage of `val` to the closure (as I forgot to do before), to show fine-grainness of lifetimes better.
 #[cfg(all(target_os="macos", feature="ffmpeg"))] pub static AUDIO_DECODERS: [RegisteredAudioDecoder; 3] = [ vorbis::AUDIO_DECODER, libavcodec::AUDIO_DECODER, platform::macos::audiounit::AUDIO_DECODER, ]; #[cfg(all(target_os="macos", not(feature="ffmpeg")))] pub static AUDIO_DECODERS: [RegisteredAudioDecoder; 2] = [ vorbis::AUDIO_DECODER, platform::macos::audiounit::AUDIO_DECODER, ]; #[cfg(all(not(target_os="macos"), feature="ffmpeg"))] pub static AUDIO_DECODERS: [RegisteredAudioDecoder; 2] = [ vorbis::AUDIO_DECODER, libavcodec::AUDIO_DECODER, ]; #[cfg(all(not(target_os="macos"), not(feature="ffmpeg")))] pub static AUDIO_DECODERS: [RegisteredAudioDecoder; 1] = [ vorbis::AUDIO_DECODER, ]; Looks like combinatorial explosion. Are/will be there better ways to do it?
[This](https://github.com/servo/servo/blob/master/components/net/http_loader.rs) is the code that generates the stream of messages, and [this](https://github.com/servo/servo/blob/master/components/script/dom/xmlhttprequest.rs#L793) is the handler in the script task. I'm not saying the read method won't work, I'm saying that generally in Rust we try to use channels and types messages as often as possible, and it's quite efficient in this case. As far as my Go assignment goes, [this](https://github.com/Manishearth/cs733/blob/master/assignment1/kvstore.go) is where I first used typed messages. (It's a concurrent key value store)
&gt; As far as my Go assignment goes, this is where I first used typed messages... One possibility there is to put the handling code into the message http://play.golang.org/p/f3SxlXkGgb Then the message handling loop would convert to: for message := range cs { message.Handle(store) This also means that adding new messages wouldn't make the backend message handling code larger. Also it can be externally extended by adding a message parser. Commonality of the ack can be put into an embeddable struct.
On a very minor point, this is the first time I've seen all the module structure defined in the top-level lib.rs. Any thoughts on this vs each directory having a mod.rs?
Codius is using Rust to sandbox executable financial contracts. Wit just got bought by Facebook and uses Rust + Clojure in their voice control applications. Facebook also has various internal projects in Haskell. Eaton built a hydraulic dump truck whose control system is written in a hard realtime DSL within Haskell, that does compile-time thread scheduling. Galois makes cryptographic software for industry and government using Haskell and a variety of other languages. Bluespec makes a hardware design language implemented in / based on Haskell. There's Mirage OS which is an OCaml-based unikernel for Xen deployments. Galois made something similar with Haskell. Scala is used a whole lot in industry as well. Erlang routes billions of phone calls and powers Snapchat (also acquired by Facebook). I could provide links for all of these and 100 more, but your lazy trolling doesn't deserve any more effort on my part. Get some perspective, there is more to programming than deploying a web app on a ton of Linux boxes.
I'm pretty sure that it does. Also, I'm sure that it runs a `build.rs` file.
&gt; How would you describe this without enums? Go uses interface{} for that http://golang.org/pkg/encoding/json/#Unmarshal, and yes, Rust solution is nicer for those. This made me think that this kind of "enum" constraint can be statically checked, although type method tagging can be used for it. *Should add implementing this checker to my todo list :D* &gt; Another known workaround for the absence of enums is visitor pattern. I would prefer implementing that store message as an interface, because I need two pieces of behavior to keep in sync with the message structure -- so they probably should belong together. Of course that is not always the case. Saying it in an other way, to add the functionality in the interface case I would need to introduce 4 new things (1 type, 1 method for handling, 2 method for reading/writing the structure). In the enum case I would need to modify methods instead of adding methods. Of course the JSON structure is pretty much closed, so there won't be any more structures, and probably more methods that handle those structures --&gt; this means that the enum case would be better for it. &gt; It returns both file and error while it should return either file or error, this is exactly where enums would be useful. How much would using enum actually improve code quality in that case. I understand that using enum would be safer; but how often do those problems happen when the errors are being properly checked/vetted? In a similar sense you could add always a second implementation of everything done by another person to cross-validate each other. It would make the code safer. But is it valuable to the end-user to do so? Some cases, yes, some cases, no. I really haven't done proper cost-benefit analysis on enums. Although from the preliminary overview - for constrained number of items it indeed is beneficial. Of course this means that people can accidentally use them in cases where they should be using some other approach instead. Essentially I can see benefits of it, but I haven't worked extensively with them to say what all their cons are; or what kind of code their use leads to.
It's a high priority TODO for me.
Part of the power of lifetimes is how fine-grained they can be. In this case, the fine-grained-ness is that two variables declared in the same scope aren't automatically connected, borrowing one does not automatically borrow the other.
The signature of `scoped` is an interesting case for lifetimes, the bounds `T: 'a` and `F: 'a` look like they're bounds on `T` and `F`, but I personally think it makes much more sense to view them as bounds on `'a`. One can call `scoped` with `T` and `F` essentially arbitrary, and the compiler ensures that the return value can only be used while `T` and `F` are guaranteed to be still valid, since the two bounds restrict `'a` to that period (taking the intersection of any lifetimes in `T` and any in `F`). How a closure borrows things is conveyed through lifetimes; a closure value is really just a struct containing fields for each captured variable: if they are captured by reference, then the lifetimes propagate out to the type of the closure, e.g. your `var` example below implicitly creates a struct: struct AnonClosure&lt;'a&gt; { var: &amp;'a mut i32 }
Isn't that what he's talking about here: &gt;"...this will behave exactly like `interface{}` (implemented on all types) unless I add a dummy method to it, which seems hackish"
It definitely will: `rustdoc` (which `cargo doc` calls) runs the type checker, and hence needs the source to compile, including any macros.
Has any thought been given to making docs like this a requirement for major new features?
What about getting the folks who write the features contributing docs?
I think it *might* just be a consequence of not needing to look at implementation details of functions and structs to figure out type checking around things that use them. Obviously in this case it turns out "obvious" but I think in more complex cases it's not necessarily the case. Like if you have a Foo&lt;'a&gt;, what's the borrow? mutable? immutable?
Is there any way to poll a socket then? 
I mentioned this in my post, and said that it felt hackish. But yes, I can do that.
Maybe not lints, but it must load all expanders :) Half the things on [this page](http://doc.servo.org/script/dom/blob/struct.Blob.html) wouldn't show up otherwise, for example.. (`Reflectable` and `JSTraceable` are generated by our syntax extensions) 
&gt; Personally, I actually find enums (or sum types, or algebraic data types, or whatever you want to call them) the biggest thing I miss in other languages. Agreed. &gt; They are orthogonal to existing features in Go, outside of nil. I both agree and disagree with this. I can tell you that the Go community would vehemently disagree with this point. They consider type switching (a thing done at runtime) to be a completely valid alternative to ADTs. They aren't the same language feature at all, but in Go, ADTs could be used to solve very similar problems that interfaces already solve. In Go, there is a ruthlessly pragmatic view on whether compile time safety is worth it or not. There's a lot of appeal to "these problems don't happen in practice so why should we add to the language to fix them." I've written a lot of Go myself, and I tend to think their observations are mostly correct. (But I'm also in love with Haskell and Rust, so I like my fair share of compile time safety features too.) Another point of confusion is what it means for an ADT to satisfy an interface. I remember thinking through this a few years ago, and I think I came up with a way to make it work, but it still seemed confusing/non-orthogonal to me. The details escape me at this point. Finally, and this is a more subtle feature that people who haven't used Go tend to forget about, but a *central* feature of Go is a notion of a default value. Every single type is initializable with a default value. For many types (pointers, channels, maps, slices, interfaces and functions), that value is simply `nil`. For other types (ints, floats, arrays), that value is `0`. Product types like structs default to the default values of their components. What is the default value of an ADT? Sorry for the terseness/hand-waviness on the technical details. It's late and I'm trying to get quickcheck to build. :-)
Yeah, lifetimes are associated with *loan paths*, which are basically paths starting at a local (or argument) and proceeding through chains of `.` (or indexing).
Rust has a lot of bugs that are [tagged as good for beginners](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy). These don't require deep compilers knowledge. Many of them are about documentation, error messages, that sort of thing. It's a great way to get started with the project! We're always happy to have new contributors. Feel free to stop by `#rust-internals` on [Mozilla IRC](https://wiki.mozilla.org/IRC) if you have questions!
While I welcome docs from anyone, I would rather have the people who love compilers write compiler code, and the people who love docs write docs. I find the best documentation happens when, rather than try to write out docs, the person who writes the feature and I have a chat, and then I write something up after. That said, I totally welcome other people doing my job ;)
It's definitely a good idea, and it does happen, although sometimes behind the scenes, e.g. someone will speak the design/implementer and write the docs while conferring with them (or at least request feedback). In any case, as the language becomes more stable there will be a bigger focus on going back and backfilling places that need polish, and docs are one of the biggest ones. As a concrete example, /u/nikomatsakis, /u/aturon and I are all intending to work on the docs around `Send` and `Sync` and concurrency (my [most recent post](http://huonw.github.io/blog/2015/02/some-notes-on-send-and-sync/) came out of those sort of discussions).
Keep in mind that pretty much all libraries out of the main tree are still using old_io, and that there is no compatibility layer to ease the transition.
It'd be alarming if it didn't!
It only lists those who made commits between alpha 1 and alpha 2.
Making it more flexible and robust so we can just call it vim-cargo, and you can use dispatch if you want :-)
You can also contribute to other rust-related projects, like [rust-rosetta](https://github.com/Hoverbear/rust-rosetta)!
This event occurred a day or two ago, but the video is now ready for streaming.
What *would* be nice is if opening up a Rust project in Vim automatically loaded the 'cargo' compiler plugin (which sets up ':make' to invoke Cargo, and tells Vim how to parse the filename and linenumber out of error messages).
Doesn't vim-rust already take care of this? I've currently set this up with dispatch and I can jump to lines and files from the split it opens.
The plan is to first write Go compiler in Go which is happening now, and then use SSA in new Go compiler. I do not know how slow it will get but I think they will keep current usage of fast compilation during development and optimized albeit little slower compilation for prod once code is ready.
rust.vim takes care of some of that. If you have `compiler cargo` in your `.vim/ftplugin/rust.vim`, you can do `:make &lt;cargo cmd&gt;`. E.g. `:make build` will run `cargo build` and populate the QuickFix list. rust.vim also has a syntax_checker for syntastic that works quite well. Edit: Use https://github.com/rust-lang/rust.vim the wting repo is no longer up to date AFAIK.
This language would be nothing without you.
I don't think that's true, but thanks.
yes thanks for that :) docs are coming along great I think. I hope more depth is written up over time, but I understand the need to get as many parts covered as possible! I was playing around with closures and realized I was able to return a generic, I thought this was awesome :) 
It's not built in, but you can write one. We didn't want to privilege hash maps with syntax as opposed to other data structures.
Running cargo within a docker container seems like a safe way to do sandboxing.
Lack select/poll, no timeouts for UDP sockets? How is this 1.0?
[rust-kr.org](http://rust-kr.org/) is (as far as I know) a prime *small but complete* example of a [website primarily implemented in Rust](https://github.com/rust-kr/rust-kr-rust). (In reality, it works behind a proxy and has some Python interface for live chatting.) EDIT: Added "small and complete"; I think crates.io delegates a frontend templating to JavaScript.
http://arewewebyet.com/
Maybe! I'd be more open to it at least.
&gt; Another point of confusion is what it means for an ADT to satisfy an interface. Rust has ADTs and interfaces and there isn't an issue here. What would be the confusing part? &gt; What is the default value of an ADT? Scala has default values too (inherited from Java) and they chose null for the default value of case classes, so probably Go would follow them.
&gt; Rust has ADTs and interfaces and there isn't an issue here. What would be the confusing part? Because of structural subtyping. &gt; Scala has default values too (inherited from Java) and they chose null for the default value of case classes, so probably Go would follow them. I don't think any of my points are show stoppers. But they are certainly strange. I'm not really on the up-and-up with JVM languages, but this behavior certainly seems strange to me.
Thanks! Here's the [thread](http://www.reddit.com/r/rust/comments/2v1fe3/hows_rust_working_out_as_the_backend_for_cratesio/) for anyone interested. Definitely worth the read, although I'd like to hear more about the challenges /u/acrichto faced developing it.
I use Atom. There's a few nice packages that support Rust development. I have syntax highlighting and autocomplete suggestions.
I was planning on using React. This sort of thing is definitely the future of web dev in my opinion.
Yeah, I just meant some sort of JS client. Experimenting with this is high up on my post-1.0 todo list.
&gt; If you have `compiler cargo` in your `.vim/ftplugin/rust.vim` Could you please expand on this? I can't find either word in `ftplugin/rust.vim`
**Specific Questions** 1) How should one pass an array of strings to a C FFI function? You can see how I *received* one in the `get_tag_multiple_strings` method, but I'm not sure how to do the inverse in `set_tag_multiple_strings`. 2) What should APIs return, `String` or `&amp;str`? I think I grasp the distinction, and I see why it makes sense to *consume* `&amp;str`s, but is it possible to do the same thing with what you return? I ran into problems with lifetimes. 3) Are the stability attributes used in the core language/standard library meant for use by libraries like this as well? Should I be tagging things unstable? Is that worthwhile given the version number? 4) Building through Cargo already informs rustc and rustdoc that this is a `lib` type crate, and that it's called rexiv2. What are the `#![crate_type = lib]` and `crate_name` annotations for? Should they be there? 5) What's the best practice for third-party library dependencies? My Linux package management background strongly protests against bundling the source, but making users go elsewhere to download and install stuff isn't great either. Should `build.rs` look for the libraries and print a message? Attempt to download them? Fetch the source and build them?
vim is nice for small edits. I use Atom for larger changes and navigating a project.
Will be there! What will we be hacking on?
Thanks! (Direct URL, for anyone else annoyed by the web player: http://vid.ly/u1d8s2?content=video&amp;format=Himp4)
Emacs, obviously. :-)
Thanks, didn't expect putting any random command there to work.
One fun extension is to allow x =&gt; y, as sugar for (x, y), Then we can add Perl to the [list of influences](http://doc.rust-lang.org/reference.html#appendix:-influences). A macro for sequence comprehensions would be amazing, too. They would integrate such that e.g. a `HashMap` comprehension is a sequence comprehension of pairs.
Heh, we were just talking about that in [this thread](http://www.reddit.com/r/rust/comments/2wnnv8/pythonlike_dict_syntax_in_rust_thanks_to_macros/cossrvj?context=3). I'm not sure there's a compelling reason to add this before 1.0. After that point, we can add new language features every 6 weeks; we just can't remove them.
I really enjoy reading /u/acrichto's code, such as [this file from git2-rs](https://github.com/alexcrichton/git2-rs/blob/master/src/remote.rs), that uses slightly longer and more descriptive lifetimes.. it's way easier than remembering that, in this file, `'a` is the lifetime of the `repository`, `'b` is the lifetime of the `callback`, `'c` is the lifetime of the `remote`, and in the next file they're something totally different.
This is really cool, will start using ASAP :D
Awesome, thanks! I've made a [tag 0.1.0](https://github.com/ogham/exa/releases/tag/v0.1.0). Right now I'm hesitant to call it *stable* as although it works for me, it might not be bug-free for others - but I can definitely update you once I get a 1.0 release done.
Please do send me a message when that happens then, let's fill AUR with rust projects!
I am currently using Sublime Text 3 with Racer, SublimeLinter and Sublime-Rust. I'm pretty happy with that package — it definitely makes my coding a lot easier and enjoyable. I have to admit that I haven't really spent time investigating other alternatives (Atom, Vim...), but that is mostly because I am lazy and pretty satisfied with my current editor! SublimeLinter warns about type missmatches, unused variables and lifetime issues as I type and racer's autocompletion works surprisingly well! [Racer](https://github.com/phildawes/racer) - [SublimeLinter](https://github.com/SublimeLinter/SublimeLinter3) - [SublimeLinter Rust linter](https://github.com/oschwald/SublimeLinter-contrib-rustc) - [Sublime-Rust](https://github.com/jhasse/sublime-rust)
Nice job shen!! I am using it and love it!
Yay! Thanks!
`cat` is for concatenation, why do Linux users keep on continuing `cat` abuse?
It's also the tool to use if you want to output a file. Similarly, `kill` is not only used to kill processes.
What would you use otherwise? `dd if=filename status=none`? I agree that `cat` is very often abused in scripts (`cat filename | command` instead of `command &lt; filename` or `&lt; filename command), but I don't know of any easier way to output a file to the terminal.
I’m probably just being slow, but where'd the name ‘exa’ come from, if you don't mind me asking?
Extremely off topic: is your nick a reference to The Stormlight Archive?
For the novices like me following along puzzled by the [intrusive](http://stackoverflow.com/questions/5004162/what-does-it-mean-for-a-data-structure-to-be-intrusive) jargon.
Just a note, I think your output examples on the website would look much better if you used a monospace font instead.
I haven't tried this out yet (but want to); one question: are the command/line options compatible with ls? It would be nice if it could be made into a drop/in replacement for ls (i.e. add ~/bin/ls as a symlink to exa and get "enhanced" versions of the default ls behavior automatically.
Yep, the "broken windows effect".
Fantasy novel, has a character called Shen. Well, kind of. It's not his real name. It's a common enough amalgamation of letters to not be indicative, though.
`less`? That's my go-to tool and it doesn't screw up the terminal if there are non-printable characters or the file is too long.
The case for "peta": 15 is leet for ls; 10^15 = peta. Just sayin'
Bikeshedding: I'd rather see semicolons as the separator with a semicolon also needed at the end.
To the point of autocomplete, while I'm not a heavy user of it, I haven't missed it when writing Rust code and don't find i'd ever really use it even if something were to be exceptionally good. I use vim as my editor, just one of many out there. I'd just pick the tool you're comfortable with.
You've got another user. This is pretty cool. The website looks great too.
I tend to go with vim+racer, its slightly painful to setup if you haven't used it before. Also to make typing better I remapped caps to escape on my kb (who needs caps lock anyway?)
Inspired by exa hitting HN today and wanting people to be able to test it without figuring out Rust. Instructions for installing exa and iota included. Looking for other Rust apps to test with.
That "safe" in the title is a bit misleading, it implies that there's no unsafe code at all.
It means it's safe to use. In the context of Rust, a "safe" abstraction is one where all `unsafe` blocks are proven to not be memory unsafe (or cause data races) in context. `unsafe` isn't intended to mean "this code is unsafe", it's intended to be a "Hey, I know you can't prove the safety of this snippet, but trust me, I believe that this is safe" to the compiler.
https://github.com/BurntSushi/xsv --- A fast CSV toolkit. :)
thanks, I'm going to try some of this out. Been using vi for years ineffectively so I think it's time to try something new and still having access to Vi bindings will be nice. 
Love it! You should post this on /r/programming
+1 for using SI prefixes by default.
There are also hard events happening around Mozilla Firefox lately. * they agreed to be compatible with DRM (practically allowing DRM inside FF). * they strangely enabled a feature called "WebRTC", which can make IP resolving requests that are completely invisible in network monitor (including firebug), and these requests also ignore proxy rules. Details on that: https://github.com/diafygi/webrtc-ips it can be turned off with "media.peerconnection.enabled" but it's still enabled by default..
This is to filter out duplicates, no? In the last "Rules" section it is clearly said that you can make a post in a subreddit. Or did I miss something?
&gt; Windows support? &gt; Sorry, not yet — Although Rust is cross-platform, I don't have a Windows machine to develop on. Consider virtualizing windows 10 preview, if you're interested :) Looks geat btw
Sometimes I want to keep seeing the rest of my terminal and it's a short file, or be able to see the contents when I type my next command.
Can you add options for hiding columns? I don't always want the modification date cluttering everything up.
I *believe* LLVM should convert a pass-by-value function into a pass-by-reference one if it will be more efficient. So if you implemented `Mul` for the combinations of `&amp;M` and `M`, you would just write let x = &amp;m * &amp;m * &amp;m * &amp;m * &amp;m * &amp;m * &amp;m * &amp;m * &amp;m * &amp;m; The `&amp;` aren't overly pretty, but I don't feel it's an eyesore. I have my editor set up to show `&amp;` in a darker font, so it's quite unobtrusive.
Lovely project! Installed already and tried it, and will use it a lot for the git integration (man, that thing is simply _AMAZING_), but it wont completely replace `ls` for me at the moment, because it's too slow when confronted (understandably, as it has a lot more features). I tried it in a big gitted folder (my use case for `exa`, as it will prevent me for using two commands for achieving the same result, `ls -lh` and `git status`, that i generally use in sequence) and this was the result: ls --color=tty -l 0,01s user 0,00s system 84% cpu 0,006 total exa -l 0,59s user 0,30s system 98% cpu 0,906 total As you can see, the difference is quite large to be ignored, given that i _abuse_ `ls`. It's just me or it's a normal processing time? I compiled it with the `--release` flag, but maybe i did something wrong! Still, i will use it, and **thank you very much**! PS: if there is any way i can provide you a more scientific output for benchmarking purpose i will gladly help!
Sure, but in the context of the post, I thought it meant "without `unsafe` usage"
Hi. And thanks :) You're the second person to report slowness when in folders with large Git repos. Before release, I tested it with the Rust repo, and that worked ok. But apparently it gets slow when in folders with *very* big repos. I'm going to do some investigation and see if I can get it to go faster, and, in the meantime, add a --no-git flag to disable the column. Could you tell me some things about you repository to help me track down the cause? 1. How many files are there in your repo? (`find . | wc -l`) 2. How many objects do you have? (`git count-objects -v`) Feel free to message or e-mail the results to me if you aren't comfortable posting them here.
Nice! I was working on some code that needed this kind of datastructure. Played around for a while trying to get something I didn't hate. Managed to get as far as something I strongly disliked.
I'm in the same exact position. I work every day in a huge repo and I `ls -l` there all the time. This is the difference for me: ᐅ time ls -l &gt; /dev/null ls --color=tty -l &gt; /dev/null 0.00s user 0.00s system 0% cpu 0.004 total ᐅ time exa -l &gt; /dev/null exa -l &gt; /dev/null 0.70s user 0.27s system 98% cpu 0.979 total And the info you asked for ᐅ find . | wc -l 74123 ᐅ git count-objects -v count: 678 size: 2816 in-pack: 383235 packs: 5 size-pack: 202531 prune-packable: 0 garbage: 0 size-garbage: 0 Feel free to PM me for more info.
I like it!
That's not been updated in a while, it really should be.
Do you have some more info on that? I'm pretty sure I've read on here that that's an LLVM optimization.
Right. This should work like `cargo publish` (or even be part of it), where we already have authentication.
Well, thank you for the quick reply! :) No need for secrecy, here the data you need: &gt; * How many files are there in your repo? (`find . | wc -l`) λ find . | wc -l 21817 &gt; * How many objects do you have? (`git count-objects -v`) λ git count-objects -v count: 3173 size: 39284 in-pack: 66251 packs: 8 size-pack: 71326 prune-packable: 127 garbage: 0 size-garbage: 0 Any other data i can provide? I think that, if you want to strees test the project, you could test against the linux kernel source. If you need, i can do it for you (if you tell me what i should measure, i can measure it).
This is preventing me from using `std::io` too. If you look at the IO reform RFC, there is a plan for them (including a follow up RFC), but I don't think it has been done yet.
&gt; pass by reference optimization should work only if the value type supports copy operation. Not sure about this, but I expect the optimization would still work. &gt; If a type doesn't support copy, then Rust does a Move operation while passing by value. So after the call, the original variable is useless. Isn't it true? That is true. But you're only moving the return values of the intermediate operations, which you aren't using afterwards anyway, so there's no issue there.
I do not like list comprehensions. It looks backwards. Instead of that I prefer "Ruby-way": `(0..3).zip(0...i).map { |i, j| i * j }`
Being able to use them to do edits remotely via a SSH session is a big plus.
Seems like it is scheduled for next week: https://github.com/rust-lang/rust/issues/22500
At least the docs still recommend using `old_io`.
Oops! So the changes to the plugin system have made me wrong. Your code works for me. What's your `Cargo.toml` look like?
I've tried two: [package] name = "test" version = "0.0.1" authors = ["javaisgarbage"] and [package] name = "test" version = "0.0.1" authors = ["javaisgarbage"] [dependencies] regex = "0.1.8" regex_macros = "0.1.8" The latter did not work, there was a problem with too few arguments in some file in regex_macros or something. I updated rust to the latest nightly and now the latter does work. Thanks!
Not an answer but just wondering, can't you just open `/dev/stdin` / `/proc/self/fd/0` and read it? Same goes for stdout / stderr of course.
However, this seems very error-prone for actual uses. It usually means that read() is not safe to call without a loop of some sort. Is there a method that actually guarantees that resulting buffer is filled if at all possible?
I had the later with `*`s as my versions. Both of those have different versions, my lock shows regex at 0.1.15 and regex_macros at 0.1.8, so that's probably the issue, you're using versions that are too old and don't compile with the new compiler.
This kinda works, but obviously horribly unsafe #![feature(fs,io)] use std::io::Read; use std::fs::File; fn main() { let mut stdin: File = unsafe { std::mem::zeroed() }; let mut buf = String::new(); stdin.read_to_string(&amp;mut buf).unwrap(); println!("{}", buf); } 
I don't want to go too deep into defining embedded systems, but if C++ is too much for any part of your system, or if we are talking about specific architectures - or, as I said, specialized processing cores - then you might have a system that is indeed best served by assembly, and maybe C. However, "embedded systems" nowdays are also include what we could call "desktop" a few years ago (or even "mainframe" a few decades ago) - 64mb to 1Gb of RAM, and powerful ARM processors (even multi-core, sometimes) with a well-defined instruction set and a handful of compilers available. In the later scenario, using a higher-level language not only cuts down debugging time, it also makes the product more reliable. Either way, as I said before, the arguments stay the same. In fact, what you replied about C++ is exactly what anyone will hear, even if someone decides to use Linux (!) is used as a base for a product, which makes it much harder to meet realtime guarantees, etc. Last, but not least, I think you missed my point of low+high level: I see Rust as a nice fit for these scenarios where you have a C/assembly base for doing low-level and optimized operations, plus a high-level software with guaranteed memory safety and no unforseen stalls - which are a must for any system that has a minimum soft-realtime requirement.
Sure, but that is completely unrelated to the topic, and one does not prevent the other.
Emacs requires a bit of setup to be really usable. One trouble here is that Emacs doesn't follow conventions of GUI platforms (like Ctrl+c / Cmd+c to copy) because it predates them. Also, people don't generally use vanilla Emacs, everybody customizes it. So if you choose Emacs, I recommend installing [Cua mode](http://www.emacswiki.org/emacs/CuaMode) (to have sane copy/paste), and [undo-tree](http://www.emacswiki.org/emacs/UndoTree) (to have sane undo/redo, plus a nice interface to a "tree" of all states, enabling you to easily navigate to all past states). You do so with Emacs built-in package manager. And, generally speaking, adopt some or all of the suggestions made [by ErgoEmacs](http://ergoemacs.org/emacs/emacs_make_modern.html). Then you need to install other packages like rust-mode (for syntax highlighting). There's also [racer](https://github.com/phildawes/racer), that provides Rust autocompletion for Emacs (and vim, Atom, etc). There is [Aquamacs](http://aquamacs.org/) which seems to be have saner defaults for OS X. I don't know how compatible it is to Emacs, but since [this Aquamacs-specific](https://codedocean.wordpress.com/2014/01/14/enabling-melpa-package-archive-for-aquamacs/) guide to "how to enable MELPA" appears to be identical to what you would do in Emacs, it seems it's highly compatible. (You would install rust-mode and many other packages from MELPA, so you need to enable it in your config). In short, perhaps you will want to give Aquamacs a try.
Yeah, "safe" can be a bit ambiguous. I would call something that uses no unsafe code "written in safe Rust", as opposed to "safe" which just means "exposes a safe interface".
I'm not a Go person but AFAICS io.Reader has "ReadAtLeast" and "ReadFull". Both seem to provide meaningful guarantees. Rust's read() does not seem to. And of course see std::istream - read() vs readsome(). Rust's read looks like readsome() with the name that does not suggest that, and no full-read alternative...
I just released a crate with this functionality yesterday, actually: https://crates.io/crates/tempdir.
It's mostly the old tempdir code with updates for the new IO APIs.
&gt; I'm not a Go person but AFAICS io.Reader has "ReadAtLeast" and "ReadFull". Both seem to provide meaningful guarantees. Rust's read() does not seem to. Nope. See: http://golang.org/pkg/io/#Reader &gt; Read reads up to len(p) bytes into p. It returns the number of bytes read (0 &lt;= n &lt;= len(p)) and any error encountered. Even if Read returns n &lt; len(p), it may use all of p as scratch space during the call. If some data is available but not len(p) bytes, Read conventionally returns what is available instead of waiting for more. With that said, those functions are implemented *on top* of `io.Reader`: e.g., http://golang.org/pkg/io/#ReadFull
Its open source you can file a PR https://github.com/teepee/arewewebyet
I'm one of those `cat file | less` people. Get mad. ;)
Exactly, you can also implement `impl&lt;'a&gt; Add&lt;A&gt; for &amp;'a A` and `impl Add&lt;A&gt; for A` for more flexibility, and then specialise these implementations.
2) API can only return a `&amp;str` if it is somehow holding the memory. For example, https://github.com/vhbit/lmdb-rs would return a `&amp;str` (or a `&amp;[u8]`) because the *LMDB transaction* is holding the CoW memory from being garbage collected by LMDB. It's zero-copy that way. The `&amp;str` and the transaction share a lifetime, so when transaction goes out of scope Rust would know the `&amp;str` is invalid as well. If you're not going to hold to the memory, you should then use String, passing the memory ownership to the user of your API. ( There's also a stackoverflow answer I wrote: http://stackoverflow.com/questions/26913532/the-lifetime-of-str-makes-comparison-hard/ :-p ) So, if you've got the image memory-mapped in a read-only way and you've got a handle of some sort which holds the memory mapping in memory, then you can return a `&amp;str` slice into that memory, making its lifetime equal to that of the handle. Similarly, if you parse the image into some kind of in-memory structure and keep it immutable afterwards, then you can return a `&amp;str` slice into a string on that structure, making the slice lifetime equal to the handler holding the structure. If, on the other hand, you just parse the image and return the results, without holding to them, then you should use String to pass on the ownership. 3) IMHO, yes, you should eventually mark the API or parts of it as stable. That means they won't go away, at least not until a major version change. But yes, given the 0.1 version it makes sense to leave everything unstable for now if you feel it's unstable. 5) openssl-sys might be a good example. I think the `build.rs` links to the system library there on the platforms where it expects to find it.
Oh that's unfortunate. I did not know.
["When guard goes out of scope, it will block execution until the thread is finished."](http://doc.rust-lang.org/book/concurrency.html) In the thread section.
I'm aware, that's why I also suggested a function.
Nice! CSV often used in science, if you can get away with it. It is very readable (if spaces are used to align columns), self-documenting and easy to parse. Sometimes it is even used when a binary format would be a much saner choice.
Great presentations
One can always write a small macro which would result in something like let mut vec = vec![1]; with!(vec, push_all(...), push_all(...), pop_back());` etc.
See also csvkit 
That's fantastic, I'm really looking forward to it! Thanks for all the documentation work you've already done as well!
FWIW, I actually tried to use `csvkit` before I built `xsv`, but it was just too slow. Joining was slow, computing stats was slow, etc. `xsv` can be quite a bit faster because it lets you build an index (`xsv index data.csv`), which can then give you constant time access to any record in the data set. Also, `xsv` uses a simple hash index to make joining faster too. And parallelism for stats (which is only made possible because of the index!), plus streaming computation of things like mean and standard deviation.
&gt; It is very readable (if spaces are used to align columns) `xsv` supports that with [elastic tabstops](https://github.com/BurntSushi/tabwriter): [andrew@Liger suffix] xsv slice -i 500000 /data/csv/play/worldcitiespop.csv | xsv table Country City AccentCity Region Population Latitude Longitude cn jiagu qu Jiagu Qu 14 30.933333 86.916667 You can also "flatten" records: [andrew@Liger suffix] xsv slice -i 500000 /data/csv/play/worldcitiespop.csv | xsv flatten Country cn City jiagu qu AccentCity Jiagu Qu Region 14 Population Latitude 30.933333 Longitude 86.916667
Incorrect. This is why I tell everyone to keep using `box`. LLVM doesn't reorder side-effects, and allocations are side-effects. Some of the copies may be elided, but there is no in-place initialization if the value is not constant.
Huh, could have sworn I read that in the docs somewhere. It must have been about `box`, not `Box::new()`.
One example is for queues with O(1) worst-case performance. Another is recursively flattening a tree using no extra space and no copies. There are others. Those were just the first two off the top of my head.
AFAIK the `box` keyword will do this, at least it will once its stable and fully implemented.
The syntax has actually changed to `in vec.emplace_back() { Sth::new() }`. This is part of [RFC 809](https://github.com/rust-lang/rfcs/blob/master/text/0809-box-and-in-for-stdlib.md). Alternatively `*vec.emplace_back() = Sth::new()` has been proposed. Both should be workable.
you're welcome :)
So it essentially rewrites `a..b()..c()` as `{a.b(); a}.c()`?
Thanks! Looks like an RFC should come this week.
Just curious, will this apply to all vector like containers? I'm particularly interested in emplacement into ring buffers. Thanks!
Yeah. You don’t have to convince me of the tradeoffs—I’m on the Mono performance team at Xamarin, where I have been working mainly on SGen. I’ve also been working on a GC-less language (off and on…ugh) for a while.
I'm particularly interested to see what the Cargo support is like.
&gt; This is why I tell everyone to keep using `box` Yeah, but I don't want to put my elements on the heap. I've allocated a vector. Why should I have to have an extra layer of indirection, higher memory usage, cache misses, etc, to put it on the heap?
Haha, complex macros are their own level of black magic! The macro that I posted was actually one that I had saved from a previous reddit thread about method chaining. I got it to compile again and posted it here.
It will apply if the containers make the effort to implement the interface. A ring buffer can probably do it just as easily as a plain vector, so yes.
I'm not sure. You could try checking if the close method produces an error. [It returns a HttpResult.](https://github.com/hyperium/hyper/blob/master/src/server/mod.rs#L147)
I've had trouble getting this working on Linux (and therefore Travis) with the embedded native components. The latest revision should work on OSX with Rust 1.0alpha2. Hopefully Linux support will come soon!
So far it can perform the basic Cargo operations (clean/build/test), and show the output in the IDE console. Next I'm thinking of improving the integration with NetBeans' test UI, then maybe hooking up the debugger. What would you guys find most useful, Cargowise?
Ah yeah noticed the unwrap is missing, added it back in. No difference.
So, I tried manually dropping req and res in the thread. I can drop req (after making sure the uri match uses a ref), but I can't drop the response as its partially borrowed. Is this the problem?
That's unfortunate, but it looks like you're right.
That is very good to know, I will have to check it out. My csvs are typically about 1 million rows and 50 columns or so, but I never do much more with csvkit than joining and concatenating. Anything more and I just use Julia's DataFrames package.
You may have missed the parent comment: it claimed `Box::new(Foo::new())` will initialize `Foo` in place, which is only correct for `box Foo::new()`. That wasn't meant to encourage heap allocations, just `box` over `Box::new`. There is an RFC open for specifying an in-place allocation mechanism (`box x` for `Box`, `Rc`, `Arc`, etc.) and a more general in-place initialization, e.g. `in(v.back()) x` (using the initially proposed syntax).
Huh? It's for display only. Elastic tabstops have never failed me. Can you say more?
You've got a lot of balls posting a 4chan link to reddit. I wish you the best of luck.
One thing that stuck out to me is the use of Vec for IterGcThing. Allocating a new vector for every visit to an object seems very inefficient. I implemented a mark and sweep collector some time ago for a vm but I took some inspiration from servo's tracer and used the visitor pattern for marking. pub trait Traverseable { fn traverse(&amp;self, gc: &amp;mut Gc); } And each object is then responsible for calling traverse recursively on its fields. Have you given an implementation like this any thought or did you find it good enough for now?
In principle, the sandbox code accept a link to a pastebin website and fetch it from there.
I think this could/should be implemented as a macro.
Ah, yeah, I saw that in the README but didn't make the connection. Travis also does OSX builds, so it would probably be a good idea to set that up, and there's a service called Appveyor that does CI builds for Windows. For the record, it didn't build for me on Windows, though I look forward to trying it out when it does.
Oh that is very exciting! You've been working on that for a very long time. It's great to see it's finally merged. :-) I can't wait to try implementing your pattern api with for `Regex` and `SuffixTable`.
&gt; Most libraries will fail on them and mess up the data on missing entries. I missed this the first time around. Elastic tabstops are not the same as fixed width fields, and they only apply to *contiguous* runs of tab delimited fields. Once there's a missing entry, the "width" of that column gets reset. In fact, if a line appears that has no tabs, the entire buffer can be flushed at that point because the widths are re-computed after that. You can read a little more about it (with some examples): http://burntsushi.net/rustdoc/tabwriter/ So yeah, if you're running across people using elastic tabstops to represent structured data, it's going to give you a bad time. I've only ever seen them useful as a means for displaying aligned data that a human reads.
I have always found HDF5 difficult to work with, it seems that BSON is promising if there is ever a stable schema system for json ever really stabilizes [json-schema](http://json-schema.org/examples.html) has been around for a while but never seemed to be widely adopted [see also](http://en.wikipedia.org/wiki/JSON#JSON_Schema)
Now we have brainfuck in Rust macros, Peano and binary numerals in types, and bct in macros. Turing complete system is Turing complete, as ancient memes recall :-)
Rust By Example currently uses Gitbook. The Book uses `rustbook`, which is a similar, but significantly more primitive, tool that is similar. I'd like to transition RBE to `rustbook` at some point.
Looks good! Have you considered adding some sort of interactive mode?
Specially if one thinks of a function pointer to a function that takes two function pointer as argument and returns a function pointer, something like compose in FP. Quite interesting to read without typedefs.
I haven't actually thought of that honestly. Seems like a major piece of work though. Probably separate from `xsv` altogether.
Yeah, this seems like an oversight. Seems OK because it is unstable though.
&gt; This is an exclusively subjective opinion. Of course! The question is "What do C/C++ [systems] programmers think of Rust?" and I answered what I, as a C programmer, think of Rust... I don't see a way to answer without writing a subjective opinion! 
Every time I tunnel out to look at a 4chan link that seems to be half-decent, I end up agreeing even more with my university's decision to block 4chan. :/
&gt; subjective opinion. Opinions are subjective, that's why they're opinions ;)
FYI, [dark](https://github.com/kvark/dark) also has suffix array construction in linear time &amp; space for its BWT transform. It hasn't been updated for the Rust changes for a while, but otherwise would be interesting to compare in terms of speed. What algorithm are you using? What are the memory requirements?
Oh I think it will be the future. I'm not completely happy about this, as I think that pure functional languages should be the future. Haskell and the like, you know. I'd rather learn Haskell then Rust, but that's my personal decision... But of course, Rust will be a good step towards more reliable, stable and even more secure systems. And I like that!
This is Quora, so at most we can learn is what _one_ most upvoted C++ programmer thinks of Rust.
The details are here: http://burntsushi.net/rustdoc/suffix/struct.SuffixTable.html#construction --- TL;DR linear time &amp; space with about 6 bytes of overhead per character in practice. From looking at your code, it looks like we're using the same algorithm (SAIS). It's not clear to me whether yours handles Unicode efficiently though. It was tricky to get it working without copying (and also supporting 32 bit lexical names): https://github.com/BurntSushi/suffix/blob/master/src/table.rs#L677-L697
add ?share=1 to the end
Interesting that you as a C developer believe more in pure functional programming (of course a C programmer can also program in other languages: but presumably we're talking about C/C++/systems here). Do you mean pure functional programming for application development, or also for systems programming?
Is it really that outlandish to think that there exists code that would like memory safety, but garbage collection is unacceptable? Crypto libraries, browsers, servers with latency constraints, databases, ...
Traditional GC is not an option for situations where you need predictable latency.
&gt; add ?share=1 to the end Thanks, but it didn't help. 
Is there still the issue where Atom can either A) autosave or B) autocomplete, but not both enabled at the same time? I think that's the problem I ran into which made me ditch Atom. Edit: Ooh, looks like it was fixed: https://github.com/atom-community/autocomplete-plus/issues/221
I mean pure functional languages for everything which is supposed to be a big, complex system. This can apply to everything. Of course there is no better choice as C (and maybe rust) for a kernel or embedded system, but for everything else I'd like to see functional languages to succeed. Though, Haskell is a bit hard to learn, at least for me.
I understand this. But I have experience with languages both with GC and without it. Most of the time it is possible to make your data-structures and algorithms more GC friendly to solve this issue.
Please use the `--release` flag! Without it, it's an *unoptimized* debug build.
Check Xerox Cedar, ETHZ Oberon, DEC Olivetti Spin, Genera, Singularity. All OS with GC wide support. You don't need GC for everything, as long as the system languages allow for value types and low level GC control. The problem is that no mainstream OS vendor decided to bet on these systems. 
Here's a summary: * `~T`: Now a library type with no special syntax, `Box&lt;T&gt;`. * `@T`: Gone entirely. * `&amp;T`: same Not to mention a whole ton of other changes. Rust has really, significantly, deeply changed in the last year. It's gained a lot of focus, and thrown a lot of stuff out.
Is there anything I can do to help with that? I'd be happy to draft up some documentation if I could learn it myself first somehow :P
The key word was “exclusively”: Most opinions are based on facts, but this one is solely based on habit. I doubt that rust is even effectively noisier than C. Both are pretty much in the middle between obfuscated Perl and Python. Sorry if that sounds to harsh 😯
What binding a trait with +'a means is basically saying that if the concrete type contains references, all of its references must live at least as long as 'a
No, thank you http://www.cnet.com/news/quora-reveals-your-reading-habits-by-default-with-views/
Yes, the declaration for the C89 `signal` function is the epitome of clarity: `void (*signal(int signum, void (*handler)(int)))(int);` (The semantics are not complex, but the syntax is atrocious.)
What I meant by "inconsistent" is that if all the methods that currently return `()` returned `Self` instead, we would be left with something like this. foo.bar().baz().buz(); // yay chaining! foo.returns_a_value(); // oh crap, can't be chained foo.bar().baz().buz(); // back to chaining again :( Function chaining in rust *isn't* easy, but it isn't necessary either. 
You probably could have `chain!(a..b()..c())`. I'm not convinced that getting rid of the macro invocation by having a compiler extension is worth it. Also, as /u/deficientDelimiter noted, it clashes with the range syntax.
It is probably a better idea to have some kind of token for missing entries.
&gt; You should check out modern Rust, there's only one type (well, two if you count raw pointers) of built-in pointer. Ehh, I honestly think that `&amp;mut T` ought to be considered quite distinctly from `&amp;T`, which would make three types of pointer/reference types in Rust. As I use Rust more I keep inching closer to sympathizing with the `&amp;uniq T` or `&amp;my T` crowd from the mutocalypse. But Rust nevertheless still has no more language pointer/reference types than C++11 now that `@T` and `~T` are gone! :-)
Out of curiosity does geany have any rust support?
Thank you, I corrected my code ! For other people who may have the same problem, you can see here my corrected code : pub fn subdivise_by_default(&amp;mut self, id: OctreeId) { let parent = match self.nodes[id] { Leaf(parent, _) =&gt; parent, Subtree(_, _, _) =&gt; panic!("subdivision d'une zone déjà subdivisée") }; let childs = self.get_free_nodes(); for &amp; child in childs.iter() { self.nodes[child] = Leaf(id, Default::default()) } self.nodes[id] = Subtree(parent, childs, Default::default()); } For your curiosity, this code is part of a octree structure (http://en.wikipedia.org/wiki/Octree), but the nodes of the tree are not allocated with Boxes, but contiguous in a Vec. It's inspired by http://bluss.github.io/ixlist/target/doc/ixlist/struct.List.html . get_free_nodes get 8 nodes previously released, or allocates new nodes by pushing in the Vec. It must have a mutable self, because it pops the 8 nodes indices from the list of released nodes. Sorry for my english, I'm french.
`&amp;T` is not gone...
I meant "is still the same as it was then"
coming from C++, i think rusts' syntax is spot on. Familiar but cleaner.
There's a reason: mutability. It wouldn't make sense that a method wouldn't run after another in some weird fashion. In other words something like: obj.read_only_method().mut_method(); would fail! Unless we let `read_only_method()` sometimes return a `&amp;mut` which means that sometimes it would break it's promise of never mutating stuff. This would be hard for people to understand and something that sometimes works and sometimes doesn't is far more confusing and less trustworthy than something that never works at all. The idea is that if there's a convenience in being able to shape it in some way it can be fixed with a macro that does all the sugar code behind. The nice thing is that as soon as you see a `chain_call!(...)` you know some code transformation is going on behind the scenes.
Which is an amazing read.
Most likely not, but calling free () on such blocksizes is also not something one really wants to do, or triggering cascade drops with RC == 0. EDIT: Some info about where I got the information from, http://www.spacewar.com/reports/Lockheed_Martin_Selects_Aonix_PERC_Virtual_Machine_For_Aegis_Weapon_System_999.html
Eh, it’s not that it’s impractical, it’s just not my impression of what the language is for, insofar as a language can meaningfully have an intent. The standard library constitutes the common vocabulary of a language. Exchanging it for something else is like writing in a different dialect. I *like* having a standard library of generic containers and algorithms in a language that has that expressive power. I don’t miss it in C or Forth.
Pure has very different meanings, even within the same language-community. * Is it that it doesn't alter the parameters it's given? * Is it that it doesn't have any side-effect whatsoever? * Is it that it is a one-way complete mapping, a function of mathematical-like definition? The third is too complicated to be worth it. The second one only mattered at systems level to guarantee it was thread-safe and memory safe, but Rust's lifetime type system already guarantees this while offering more flexibility in what you can do. The first is implied by Rust's variables being immutable by default. The reason why pure, and true immutable (that is declaring something immutable and making sure no one can make it in any way mutable) are very limiting, and most times you'll want to break off them. That is you'll make a function pure, until you realize that you want it to log stuff, so it can't be pure anymore, but you can't change the type without breaking stuff. Or you make something truly immutable, until you realize that you want to do a system check and set it to a value depending on the environment on which the code is ran, which means that your value is altered at one point. In other words, whenever you declared something "pure" you were bound to regret it. If the definition of pure was loosened up, then the lifetime system and immutable by default system covered it perfectly.
I dislike that as well. What I do if I really want to read something there is I copy the title of the question and then go to Google where I search for *quora* followed by the title I copied. Google has some policy that websites must show visitors the same thing spiders see or something so then you get all the answers for that particular page load. I considered getting my browser to always send google as referrer for quora (some use-referrer-x-if-site-is-y addon probably exists) but then i decided to avoid quora as much as possible because i don't like what they are doing so i don't want to give them any meaningful amount of page views.
Bookmarklet: Click to hide the login prompts and unfuzz the screen. &gt; javascript:(function(){function a(c){var e=document.getElementsByTagName('*'),i;for(i in e){if((' '+e[i].className+' ').indexOf(' '+c+' ')&gt;-1){e[i].style.display="none";}}}a("modal_signup_background");a("modal_signup_dialog");a("modal_signup_facepile");})();
I agree that is bad. Let's see if I'm able to read it. Signal is a void pointer to a function returning an int. Signal takes two parameters; integer signum and void pointer to function handler. Handler should ~~take an int as parameter~~ *take no parameters and return an int*. Not sure I got that right and even if I did, I had to stop and read it for way too long.
I like it, a lot. It allows you to solve lots of problems in an easier and cleaner way than C++. Give it type level integer/booleans (there is an RFC for this!), HKTs (RFC for this!), variadics (couldn't find RFC) and I switch. Give it a way easily wrap C libraries that use the C preprocessor (couldn't find RFC), and I will very happily switch. I really use type level integers a lot in C++. I work with binary trees, quadtrees, octrees,... With type level integers I implemented them once, as a function of the integer, and by writing quadtree&lt;N&gt; it generates either a binary tree (1 dimensional quadtree), a quad tree, an octree (3D quadtree), ... I also use HKTs every now an then, and type-safe variadics are just useful. For example, I've used a couple of times a Boost.Fusion map, which is like a tagged tuple, where you can assign to each value in the tuple a tag to get it. It is not very ergonomic to use, but the nice thing is that you can automatically generate them and use them to do compile-time reflection. In Rust, it is hard to work around needs like these without HKTs and variadics. And writing a plugin is imo worse than a macro (shadow worlds). Finally the FFI with C is not idiot proof with respect to macros. Some libraries define macros for magic values, and these change between library implementations (e.g. MPI). It would be nice to have a way to tell cargo: this is the FFI module for MPI, it needs to substitute some values from the MPI library of the user, pass the include path to cargo, and have the C preprocessor replace the macros with the values. It can be done with a separate script, but this is a problem that you don't have in, e.g., D or Nim.
AFAIK, RTGC guarantees only *pause time*. It's unclear when and how many such pauses to be happened since garbage creation. Then it doesn't seem to be fully realtime system. I think there should be a clear explanation on this part because I really cannot trust a claim with only sales pitch regardless of wherever it came from.
[cdecl.org](http://cdecl.org/) might help here: &gt; declare signal as function (int, pointer to function (int) returning void) returning pointer to function (int) returning void &gt; http://cdecl.org/?q=void%20%28*signal%28int,%20void%20%28*%29%28int%29%29%29%28int%29
By the way, [Jane Street](https://en.wikipedia.org/wiki/Jane_Street_Capital) is a high frequency trading company built around OCaml, a high performance GCed language.
Floats can be `NaN` because if they didn't they wouldn't be floats. This is how floats are defined, and how they work all the way down to your CPU. Rust could change it, but that would be incredibly inefficient. Floats are filled with gotchas as they attempt to be a balance between speed, precision and range. Ints are defined in a much simpler manner. So int's can't be `NaN`. You will see that all integer types implements both `Ord` `Eq` and `Hash` unlike the floats. If you want to implement `Hash` for floats answer the next questions: 1. Do you consider different types of `NaN` (it has a bunch of values) to be different? Two functions could give you a `NaN` and have it hashed as separate and different values. 2. Do you separate `signaling NaN` from `non-signaling NaN`? 3. Is there a difference between `-0` and `+0` they are both valid values? 4. How do you handle [denormalized floats](http://en.wikipedia.org/wiki/Denormal_number)? 5. And to that point, is 0.9999999999999999 just 1 or are the separate values? How big of a difference do you want to store? And for implementing `Ord` you'll probably also want to solve: * Is `NaN` bigger or smaller than `0`? than `1`? Than `+/-Infinity`? * Is `signaling NaN` bigger or smaller than `non-signaling NaN`? * How do you handle imprecision were you can't represent `1/10` or `1/3` fully? So the solution to that is to build something like: trait CleanbleFloat { type CleanForm fn standarize(self) -&gt; Self::CleanForm } impl&lt;T: CleanableFloat&gt; Ord/Eq/Hash for T where T::CleanForm: Ord?Eq/Hash { ... } struct CleanF32(f32); impl Ord for CleanF32{...} impl Eq for CleanF32{...} impl StandardFloat for f32 { type CleanForm = CleanF32; fn clean_up(self) -&gt; CleanF32 { ... // here goes the assumptions for your code. } } Then you can repeat the whole `CleanF32` + impls for `CleanF64`. Internally this means that sometimes, when using a float, you'll have to call the function to "clean" it so that you can guarantee that the answers to the above questions are answered correctly. If what you want is a way to represent numbers that are not always whole in a reliable and efficient manner that implement `Ord`, `Eq` and `Hash` look at the `num` crate, specifically [`num::rational`](http://doc.rust-lang.org/num/num/index.html). All the implementations there fullfill that. BigRational can get quite close to describe most numbers. Something like sqrt(2) cannot be fully represented (only approximated) but this was a problem we already had with floats. It won't be as fast as floating points, but you get predictability instead. TL;DR: This is how floating points are defined, and the CPU itself keeps these true. If you don't like it you'll have to implement your own, much slower, not hardware supported, version instead.
Rust uses composition over inheritance, so instead of `Value` inheriting from `MultilistListPointers`, `MultilistListPointers` wraps `Value`. I don't think that makes a difference as to whether the list can properly be called intrusive or not: it's just the Rust idiom. You could write it as a structure with a trait that provides access to the pointers, but there's little benefit that I can see to doing so, other than trying to mirror Boost intrusive more closely; `MultilistListPointers&lt;T&gt;` will dereference to `T`, so it doesn't affect ergonomics. Much of the purpose of writing multilist was to show that comments like the parent comment are not true: you can write intrusive lists in Rust.
Here it is: https://github.com/rust-lang/rfcs/pull/899
In general I've been thinking of `forget` as more or less OK, since you can effectively leak things by putting them into TLS and never releasing that TLS. But I guess that only works for things you could put in TLS in the first place (`'static`). Maybe we need to mark `Value` with a `'static` bound. Or we can just switch to one of the alternative designs suggested here or on IRC, which would avoid this problem.
I get it now, the actual intrusive element is ~~MultilistListPointers&lt;Value&gt;~~ (no, I think it is `MultilistElementHolder&lt;Value&gt;`), and `Value` is just a blob/payload. (I'm further confused, why `MultilistElementHolder` has a [`[MultilistPointers&lt;Value&gt;; 1]`](https://github.com/pcwalton/multilist/blob/master/lib.rs#L161)? What storing an array of size 1 actually means here?)
Yes, that is the correct way to read C declarations, but I don't think you can say it's *easy*, especially compared to a type declaration in something like Rust or Ocaml or Haskell.
Here's one alternative: http://www.reddit.com/r/rust/comments/2wpj70/safe_intrusive_doublylinked_lists_for_rust/cotr9o7 There was also a more radical alternative suggested on IRC which doesn't tie the lifetime of the list to the contained items at all, but rather uses a "destructor bomb" on each item to panic if the item was not removed from the list before the item was destroyed. (This is a clever way to prevent iterator invalidation.) I'm still not totally clear on how this design enforces the mutability restrictions, but if it can be made to work then this seems like an ideal solution.
Instructive. rustc will have a good API yet. One of the greatest things about Rust is that refactoring isn't scary, so I'm confident rustc will eventually clean up. When I update [rust-chamber](https://github.com/brson/rust-chamber) I'll adopt these APIs.
I think the height should be configurable. (Since you mentioned vim: I use Unite, in full screen mode for searching files.) The last frame should be cleaned, that's exactly what I want :)
Good integration of Rust's tests with a GUI would be sweet. It would possibly require some interesting architectural changes to the test crate to give GUIs the type of feedback they want. From Cargo support I want it to have a list of my dependencies, with the versions that Cargo chose to build, and an easy way from switching from the upstream revision to a local development revision of a given dependency, and back. 
Kuchiki(朽木) is a very interesting name indeed. Did you know that it is a well-known metaphor from [The Analects of Confucius](http://www.acmuller.net/con-dao/analects.html)? 5:10 宰予晝寢。子曰。**朽木**不可雕也、糞土之牆不可朽也。於予與何誅。子曰。始吾於人也、聽其言而信其行。今吾於人也、聽其言而觀其行。於予與改是。 5:10 Zai You slept during the daytime. Confucius said, "**Rotten wood** cannot be carved; dirty earth cannot be used for cement: why bother scolding him? At first I used to listen to what people said and expect them to act accordingly. Now I listen to what people say and watch what they do. I learned this from You."
&gt; How can we make memory management and programming as complicated as possible? I don't get this. It seems to me like the author has not spent much time with modern Rust. They think the memory management is prohibitively difficult, which I don't understand at all. Sure it's a bit harder than a GC'd language, but once you get to know the borrow checker it's not bad at all. Also, what does he mean by "make ... programming as complicated as possible"? Rust is not a difficult language to program in, in fact I'd say it's easier than many thanks to things like ADTs and the awesome type system. I'm also don't see why compiling to C is "courageous and brilliant" and "brave". It's hardly the first language to do so, and nor is it always the best technical solution. Rust chose LLVM as it had clear advantages over C (there was a comment here on /r/rust about this about a week ago, I can't remember the author unfortunately). &gt; Once you learn about indenting consistently, curly braces are noise. That does matter. Personal opinion. I like curly braces much more than semantic indentation, and I have experience with both. &gt; Constantly having to declare basic types is noise. Good thing Rust has excellent type inference. As a final point, I think it's time someone clearly defined "low level access". I've heard that Nim has direct access to `malloc`/`free`, but how well does it incorporate into the rest of the language? In Rust you can hide all the scary stuff behind a safe interface and never have to worry again - this fits seamlessly into the rest of the language. Talking to C is also fairly seamless, technically speaking, in that you can call both ways without penalty. AFAIK the GC/runtime prevents this in Nim.
Not everyone is going to like Rust. That's super okay.
There is also a [HyperLogLog-specific implementation](https://github.com/jedisct1/rust-hyperloglog) in Rust.
Neato, love to see more approximate algos in Rust! I started [Quicksilver](https://github.com/polyfractal/quicksilver) (HLL, PCSA, planned to add more) a while back but it has fallen into disrepair over time. Glad to see more modern variants that actually compile :) If Coda or Jedisct1 are reading, I'd encourage you to add an `insert_hashed()` to your APIs. In practice, it's convenient to specify your own hashing algo instead of whatever the library bakes into place. E.g. I might want to use xxhash or murmur instead of Rust's SipHash.
I haven't done a full audit, so I'm not entirely sure. There's an open issue for it!
I mean intrusive collections. It was hard to build something like intrusive list using rust's lifetimes, maybe this is not the case now.
&gt; 4) Stuff like memset_s and some of the constant-time memset cryptographic stuff that can't be optimized out would be great. There are a [variety of `volatile_...` intrinsics](http://doc.rust-lang.org/nightly/std/intrinsics/index.html#types) which won't be optimised out.
They disabled views a long time ago.
Cool! N.B. I had to add '-L /usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib' to get the compiler to the analysis step, but with rustc this happens without the arg. It's not obvious to me where this happens - how does rustc do it?
My Rust functions are all absolutely pure, as in the third definition. The only thing that does actual input/output is the `main` function. Try implementing `STM` with functions that do logging. What are you going to do, undo the logging when you `rollback`?
&gt; Also aren't these versions quiet outdated? The versions are the versions of [the `gcc` crate](https://crates.io/crates/gcc) which is a small Rust lib that manages calling `gcc` (etc.) when building libraries with Cargo. In particular, it's not building the full gcc C compiler, and the versions aren't the versions of that compiler.
You don't rollback logs, they only show what the program was doing at a certain time, which helps you reconstruct the steps that lead it to some (generally illegal) state. So I don't log the transactions as they happened, I log how I set up the transaction, and then log when I cancel it. When I rollback a transaction I don't undo the logging: I log the undo! That is the way you undo log is something like: INF sometime soon Function A: Transaction B: Added two to x ERR sometime then Function A: Transaction B: Unexpected failure, rollback initiated. ROL sometime now Function A: Transaction B: Removed two from x. ROL sometime late Function A: Transaction B: Rollback successful. The important thing is that logging is something parallel to the main action, and good code would have those things separate. If my transactions all implement a trait `Transaction` which implements the `do`, `undo` methods (commit is an external method), I'd have a separate trait `Logged` which uses various hooks enabled on Transactions to log info. The existence of hooks itself already implies side-effects, the logging only makes it clear that this methods cannot really be pure, even though in theory they are.
This does look like a slightly nicer syntax. I'm still struggling to explain in words why my example syntax is right.... I guess the use case is a little odd anyway. A Bar contains a member P, which must have the Neg trait. A Foo contains a reference to a Bar, which contains a member P. The Bar reference must have the same lifetime as the Foo instance, to prevent a dangling pointer scenario. But the bar member of Bar is not a reference, so why does it need a lifetime at all? 
Using a lifetime as a bound like `P: Neg + 'a` just means that `P` is required to outlive `'a`, that is, any references *contained in* `P` have lifetime longer than `'a`. E.g. suppose we have struct Ref&lt;'r&gt; { x: &amp;'r i32 } and we try to have `Foo&lt;'a, Ref&lt;'b&gt;&gt;`, that is, instantiating `Foo` with `P = Ref&lt;'b&gt;`, the `P: 'a` constraint means that `'b` must be longer than `'a`. (Also, with the right trait implementations, it would be possible to have `P = &amp;'x T`, meaning `P` can be a reference itself.)
Would it be possible to name this macro "let_mut!" or "let_muts!" ? I believe that would make the intent immediately visible.
Then why not put all of the logging into a non-pure function that calls the pure function and logs it did this?
&gt; That was me. I thought it was a member of the core team, but I have an awful memory for names. Thanks for the original comment, and this one, it's very interesting stuff.
I cannot be sure they won't enable something else weird tomorrow.
https://github.com/rust-lang/time/issues?q=is%3Aissue+is%3Aclosed+windows See if one of those issues has your solution. Make sure you're using MSYS2 to build. Windows doesn't come with the headers `time` needs by default.
How did the crate happen to become named after `gcc` if it mostly invokes `$CC` or `cc`? ;)
We (Servo) also have a [bloom filter implementation](https://github.com/servo/rust-selectors/blob/03fa4751eb5a2ec0357f95788dbdc9727d92d706/src/bloom.rs) that we were planning on extracting into an independent library, but maybe that’s not that useful if it already exists :)
&gt; There's missing breaking change You can submit a PR to fix it! https://github.com/cmr/this-week-in-rust
[Here](https://github.com/rust-lang/rust/blob/1.0.0-alpha.2/src/librustc/metadata/filesearch.rs#L187-201) is where it happens. Libraries are searched in the path relative to the executable.
If that Anybody programmed in a language with Generics or an otherwise rich type system he might be right at home with this defenition. P.S. I feel what's beneath the whole argument is the earth-bones old Dynamic vs. Typed debate.
I always found it odd that people complained about ~T and @T as 'too many pointer types' ... they could have been thought of as syntax sugar for things you have to reason about anyway
&gt; If there are improvements you'd like to see or things you'd like to be able to do, let me know. I'd like to be able to resolve user-supplied names. For example, -Z print-enum-sizes prints variant sizes for all enums, but it would be better if you can choose the enum you are interested in.
Whenever you see lifetime notation, it's for references. Objects that are not references are moved and don't need lifetime annotations. There's also the static bound, but I won't go into that.
I understand how it's easy to generate it, but I still don't understand why it has to use `as`. I looked up the definition of `Neg` and it has `Self as Neg` and I don't understand why that's necessary or why it's implemented that way.
Because deleting the lock makes cargo recompile everything?
That's a good attitude and is so much nicer to hear than hyperbolic statements like "highly unsafe", "dangerous safety hazards" and "not safe, at all". That rhetoric is getting just a little too old already. I've ported a good bit of my Go code to Nim and I'm looking forward to Rust 1.0 (or at least the beta) before I jump in (I've learned much of the language, but not so much the libraries). I think Nim and Rust will be a good pair of languages to use in the long run.
The `Self as Neg` is used to talk about associated types. As for why it's necessary: trait A { type Output; fn a(&amp;self) -&gt; &lt;Self as A&gt;::Output; } trait B : A { type Output; fn b(&amp;self) -&gt; &lt;Self as B&gt;::Output; fn c(&amp;self) -&gt; &lt;Self as A&gt;::Output; } If we left off the `Self as ...` in `B`, how would we know what return type we want? We could always make Rust assume that `Output` was referring to the associated type of the trait we're currently defining. But: struct Output { o: u8 } trait X { type Output; fn x(&amp;self) -&gt; Output; } Now the associated `Output` shadows the outer one, and we have no way of referring to the `Output` struct. Perhaps we could go partway, and use `X::Output` rather than `Self as X`? Now we can run into problems when implementing the trait. impl&lt;'a, T: X&gt; X for &amp;'a T { type Output = &lt;T as X&gt;::Output; fn x(&amp;self) -&gt; &lt;Self as X&gt;::Output { (*self).x() } } Here we're implementing `X` for all `&amp;T` as long as `T` implements `X`. Note that this particular `impl` is useless, because we're basically re-implementing auto-deref for `X` - this is just a simple example. So let's suppose that instead of `&lt;... as X&gt;` we just had `X`. We wouldn't be able to refer to the `Output` of both `T` and `&amp;T`, which we need to be able to do here. I agree that syntactically the current way is not particularly pretty, but it's unambiguous and there are no special cases. Any methods of elision here (that I can think of) would introduce special cases like the ones above (and fall apart in more complex scenarios), and I feel (and I think the core team generally agrees) that semantic simplicity trumps syntactic simplicity. --- As an amusing sidenote, I ran into an ICE while testing these examples, all thanks to misspelling an associated type. Reported [here](https://github.com/rust-lang/rust/issues/22037#issuecomment-75778775).
I do not find casts ergonomic ever, they basically need parenthesis always (ok, not if they're the whole expression). They don't chain well and they cause you to have to parse them mentally in the opposite order of lots of constructs. I love Rust, this is one of its (relatively small) warts. Scala got this one right...
Still calling them together mixes them and makes them non-pure. There is no real benefit of compiler enforced pureness in Rust. All benefits are already handled by the lifetime/reference system.
&gt; I'm not totally convinced that Rust will ever be good for making website backends Why shouldn't it be, though? Today's stacks are basically plain old HTML+CSS+JS and a REST(-ish) backend interface. So about the only thing the server has got to do is handle those calls. Rust has great meta-facilities and a strong type system going for it. Look at the amazing things the [yesod](http://www.yesodweb.com) folks are doing with such suppport. Given this, it's quite probably only a matter of time before Rust eats their lunch. :-)
"...not safe, at all..." Come on now. Only way we could accept statements like these as dry facts would be to narrow the definition of "safe" as "whatever safety is included in Rust". That doesn't seem reasonable. I think Rust is going to succeed and I think there's no reason for people to get insecure about it. There are going to be half-baked comparisons of languages. I don't see it as a real threat.
I defined "good" in a very specific way here. Many, many, many websites don't need performance, and a slower language is perfectly acceptable. Cranking out sites in Rails is incredibly productive, and being okay with GC is a large part of that. Dealing with ownership is not. I'm aware of the haskell web frameworks, and I think they're doing cool stuff, but for now, the majority of people strongly prefer a dynamically typed language for this use case.
Though `u` and `i` suffixes were removed to stop them appearing like defaults/the standard choice, because they almost never should be.
IMO, "dangerous" makes it seem hyperbolic. It's a safety issue, we get it. Beyond that it sounds like we should be afraid to use anything else. Rust is great and can (and will) stand on its merits alone.
&gt; then couldn't Rust as well since it's technically possible to have memory errors when doing something that you're not supposed to? This is why I qualified with &gt; (at least, if we're disregarding the escape hatches, on all sides.) Anyway, on to the meat of it: &gt; because it doesn't have the same safety features as Rust. It's not about Rust's features. Nim is kind of a special case here, because most languages that have a garbage collector are memory safe. That's why they have a garbage collector in the first place. That safe Nim can segfault is very surprising. I wouldn't expect pure Ruby code to segfault, nor pure Java code, nor pure Python. But pure Nim can. This is why /u/pcwalton talks about this behavior, specifically, because it's the way in which Nim is unique. Pointing that out is not dishonest, in my book.
Jane Street does not do high-frequency trading, as far as I know.
Right, so that describes a specific aspect, which could also be applied to Go. I'm not arguing against that. I'm only arguing against some of the rhetoric that I hear that gets applied far too broadly. And again, the discussion is good. I've not suggested that pointing out specific issues is wrong. Only that overly broad characterizations and overly hyperbolic descriptions don't need to be made, and frankly I don't think they benefit Rust. It's just my opinion and I'd be giving the same opinion if someone tried to do the same to Rust.
Just my opinion: What I wanted in a new programming language: C+Being able to have functions with different namespaces, bind functions to structs (not classes) + generics/interfaces. NO GC For me your (our? although I haven't really contributed) whole extra memory safety system is icing on the cake.
As Rust reaches stability and adoption grows, these comparisons are only going to increase in quantity (and likely reduce in average quality). Maybe rust-lang.org needs to host a simple Rust vs X type page, showing the advantages, explaining the tradeoffs and conceding the places where another language might be better suited. There's some good stuff in this thread, and getting it out there might reduce the incidence of some of the more brain-dead comparisons. [somehow I'm still an optimist]
Type ascription makes much more sense to me as a user than something like using `:` for "has value" in struct literals.
Yes, unfortunately, safe Go can segfault if `GOMAXPROCS` &gt; 1 (i.e. in multithreaded mode).
The borrow checker! It's [the fourth flavor](http://knd.wikia.com/wiki/The_Fourth_Flavor) of memory management. It avoids garbage collecting, refcounting, and manual memory management.
Thanks! Nice suggestion. It really does make Rust pretty state of the art for hard real time applications.
&gt; I don't remember (and I just double-checked some guides) ::Output described in any basic guide. associated types have no documentation other than their RFC yet. Working on it. &gt; The where keyword is also not described - and rarely used - in any of the guides/examples. It is: http://doc.rust-lang.org/book/traits.html#where-clause
&gt; (our? although I haven't really contributed) Contribution is not the only measure of a Rustacean! If you do any Rust programming at all, I'd say 'our.'
&gt; Is it currently feasible to write a modern precise copying GC on top of LLVM? It is now, thanks to some awesome work by Azul: http://llvm.org/docs/Statepoints.html (BTW, I'd love to use this in Servo for JS garbage collection: it would potentially be a major advance in performance of the DOM.) &gt; It's also possible that we'll see an assembly back-end for Nim soon. I'm pretty sure I read about someone working on one in the Nim IRC or forum. That doesn't invalidate your point about the negative aspects of compiling to C, of course. Would the assembly backend do IR-level optimizations?
Seems unnecessary. We know that `P` is `Neg` so `P::Output` should be resolved by the compiler without help, unless there is an ambiguity. IMHO.
Last May we did not think about adding type ascription using `:` as an operator, so there was less incentive to change.
Truth! Who wants to start a project porting the linux kernel to Rust?... haha I just know, not to inflame rivalry, that a couple of really smart devs ran into problems using Go for game development because of garbage collector pauses. And while I know the Go team is working hard on getting their collection times down, I think Rust really shines in that department.
Having data in my enums, and then pulling said data out via a match statement is pretty killer, clean and sugary. To accomplish the same in C, you'd need a struct, with a type and a union of the different data types, and the type would have to be an enum, and you still wouldn't get the exhaustion check that you would with Rust's match. Game Development
Huh, I had never heard of region based memory management. I'll need to look into that a bit more 
Interesting anecdote: I showed some immutable by default code to some Haskellers and they got super excited, then I showed them the `mut` keyword and they got a little huffy. Gotta leave something for the C++ programmers :)
Rust is exactly region-based :)
There have been nightly build failures for a few days.
My absolute, 100%, no-questions-asked killer feature is the fact that *I don't have to worry about aliasing anymore*. Rust gives me the tools I need to have very precise control over aliasing. I would easily give up most of the features mentioned by others just to keep that.
&gt; This document describes a set of experimental extensions to LLVM. Use with caution. Because the intrinsics have experimental status, compatibility across LLVM releases is not guaranteed. We may have different criteria for "currently feasible" :-). When it's used in Servo or somewhere else that will be noteworthy. &gt; Would the assembly backend do IR-level optimizations? I don't know, but I doubt it. I'll ask on the Nim IRC. My recollection is that someone was just starting such a project. My point was that any technical debt incurred by Nim starting with compilation to C can be overcome without superhuman effort. Given Rust's design goals, compilation to C was a nonstarter. I agree that the comparison is not one of the better ones, and that the author's tongue in cheek (I hope!) categorization of Rust's design goals made it useless. I like Nim, and Rust, and I think the competition between them (and D and Go) should be able to benefit each community. 
Ahh, I only skimmed the HLL code...nevermind then :) That definitely complicates things
Do you mean "reoslve" as in running name resolution? If so, you should probably be able to do that at the moment, although I'm not sure exactly how. It might need some minor tweaking to name resolution APIs.
Well, personally I don't feel comfortable in Python or Rails. Not because of performance, simply because everything is a runtime error, so there are likely thousands of bugs dormant in the code, waiting for the unsuspecting user. Now, neither Rust nor Haskell are magic, but the stronger the type system, and the stronger the **invariants** that can be expressed. The software won't be bug free, but my experience has proven that I regularly hit compiler errors when doing changes in the code, which in Python or Ruby would have been runtime errors (if I ever detected them). I think there might be too much emphasis on performance in the communication sometimes; performance matters because replacing C or C++ obviously requires performance, however many, *many*, usecases that do not require this degree of performance could nonetheless benefit from the expressive and strongly-typed type system that Rust brings to the fore.
(Aside from the borrow checker) ADTs, and syntax extensions. The fact that not only does the compiler provide tools (like `PhantomData`) so that I can create my own safe abstractions; it provides a proper plugin system so that I can define even more complex checks if necessary. Also, the entire philosophy of not trusting the programmer leads to some great results.
Bad comparison. I don't know anybody who likes icing and it's rarely used because of that. But then I remember that Americans don't know better with their lack of good sweets:&gt;.
And nothing about the bug that [zeroes out](https://github.com/rust-lang/rust/issues/22536) your structs upon implicit copies in some circumstances... 
Gnarly Bug! Sounds like a perfect use case for [Rust's Clone-on-write (Cow) Strings](http://doc.rust-lang.org/collections/string/type.CowString.html)
&gt; It's the fourth flavor of memory management. It avoids garbage collecting, refcounting, and manual memory management. So, it's the holy grail of memory management? 
If memory safety is indeed binary, how are statements like "highly unsafe" and "not safe, at all" *not* hyperbolic?
Syntax extensions are pretty awesome. I feel like Rust will have some awesome DSL's in the future. (On second thought [zinc.rs](http://zinc.rs/) has a pretty amazing syntax)
Let us remember that Rust 1.0 is a backward compatibility check-point aiming at providing a *minimal* subset of features that are both useful enough to make things and at the same time proven enough to guarantee the backward compatibility. Adding `P::Output` indeed seems like good syntactic sugar, however syntactic sugar is not required for 1.0 and may be harmful as there is a risk the rules to define "unless there is an ambiguity" shift with experience/changes to the language. That being said, I do so wish we had `P::Output` :)
Pervasive move semantics that are way easier to get right and way harder to get wrong than C++'s. Borrow checking is a large part of this.
'borrowing' and 'lifetimes' is Rust's warm fuzzy terminology for regions.
I think it did experiment with various combinations of that and requiring explicit copy, but all ended up being too verbose.
It did experiment with it briefly (I was there) but it was deemed simpler, and nicer ergonomically to go with move-by-default. Basically: it's easier to remember to do things when they are the default.
Is there a winner yet? I really want to use the language which is most popular because it makes sense.
Type ascription in Haskell feels so natural that I had to look up the name when I first saw it mentioned here. :)
I wholeheartedly agree, I was totally blown away by how clean match statements + destructuring make my code
cdecl is helpful sometimes. I have it installed on my computers but rarely use it and when I do, I keep forgetting how picky it is about names so all I usually get from it is "syntax error". This leads to further frustration and less use of cdecl on my part, which again makes it more likely that I'll forget how to use it. Vicious circle, that.
For me there is no single killer feature. I programmed in C++ before and was already searching for a modern close to the metal language. The main disadvantages of C++ were the bad template programming (compiles slowly, needs to be in headers, ugly errors), the header-system wich forces you to write every class or function twice and the iterator-ranges without lazy map- and filter- and fold- operations. Unfortunately all ofthe alternative candidates had a major design flaw that made them useless, for example D has a garbage collector (i know, it's optional but is often required in the standard library). For my daily programming the most useful features are enums and default-move. enums because they are far easier to write than a variant type (even with boost::variant) and less bulky and faster than an inheritence based implementation. move because you can easily skip the copy-constructor and don't have to explicitly write move(...) everytime you explicitely want to move. Also the high-level threading without the need for writing message passing classes around boost::lockfree classes are really useful and make highly multithreaded applications quite easy.
Most of the uses of `isize` in the Rust compiler were just for a default, not for a good reason. "Most" in this case means definitely greater than 90%, and probably more like 99%. So almost never pretty much fits, at least for `isize`.
There was a time where you had to type `move` or `copy` explicitly almost everywhere. It was terrible.
Tell me about it, it took two minutes to get cdecl to parse the declaration (it didn't like the `*handler` part)
A modern type system (enums and Traits etc.) and the Borrow Checker of course.
&gt; I've encountered some giant repetitive and downright weird compiler errors. Then you should probably file a bug.
And this one http://smallcultfollowing.com/babysteps/rust/no-implicit-copies/ :)
&gt; What does Scala do? For number literals, you can use suffixes (`l` for long, `d` for double, ...) or the `: Type` syntax scala&gt; val x = 10: Double x: Double = 10.0 scala&gt; val y = -1l y: Long = -1 There are methods (`toInt`, `toLong`, ...) to convert values between types. That said, I'm not sure why /u/ghexsel said that «Scala got this one right». I think that expressions like `fn((foo.time / 1000l).toInt)` are not better than `fn((foo.time() / 1000) as i32)` 
This is essentially correct. Rust's memory management was definitely derived from regions, but we took it in a very different direction, much closer to C++. That's why Niko was so keen to change the name from "region" to "lifetime". :) (Another reason for changing the name is that regions have had something of a checkered reputation in the programming languages community. This is basically because you can't realistically arena allocate everything, so "classical" regions can't be the single memory management story. Continuing to call them "regions" has made academic folks more familiar with classical regions think that Rust is trying to arena allocate everything, which is not the case.)
There was a huge push recently to remove I size/usize from code that isn't using collections/pointers, so please explain how I'm wrong. Perhaps I was being a bit hyperbolic, but my point is still valid.
That post was perfect: Rust's rationale for initially having explicit move/copy, and it's rationale for dropping that. Thanks. 
Any time. I have a dream of someday writing up all the old history... the RFC process has helped us serialize the more recent stuff.
What brought me to Rust was accessibility. Being a web programmer used to interpreted languages, being able to use a language that is extremely fast and close-to-the-metal is liberating. C always felt way too low-level, and C++ is extremely overwhelming, but Rust I can understand. Knowing Rust enables me to work on projects that I couldn't before. Because it has great performance and lacks of a GC and a runtime, I can use it to build stuff like real-time audio applications, ruby extensions, mysql plugins, fast libraries that can be consumed by virtually any language etc. Also, being exposed to a developing language (I became interested about a year ago) and the discussions that ensue taught me a lot. The fact that almost everything is discussed in the open means that I can follow the conversation and learn a bunch about the trade-offs involved, even if they go way over my head most of the time. I've never seen a language being so open (even though there's no shortage of open source languages today), and to me that has one of the greatest advantages of following Rust this past year.
Honestly, a language like C, that I could write low level stuff in, without any segmentation faults, and with nice name spacing.
ben0x539 also said that Rust's default move semantics were way easier than C++'s opt-in model.
It's not a push to make developers use 32bit, and I don't know how you think it implies developers are too stupid to decide. All this is doing is making the developer *choose*, rather than defaulting to pointer-sized, which can create portability bugs. I don't think it's discouraging pointer-sized when it's needed either - I was in favour of `isz`/`usz`, which is the same length as `i32`, and I also wasn't personally in favour of having integer fallback to `i32`. Besides, I rarely find myself annotating interger types thanks to type inference, so the long name doesn't come up often.
Andreas Gal as a contributor? That sounds like it might be a big deal...?
So, how should the programmer make use concurrency and communication between threads in Rust? I'm still reading the Rust book and learning the language, I have experience with Python (my main language for various years) and Go (second language since few months)
Good unicode support is not at all silly! :) Just ask the rust core team about supporting unicode cross platform (Windows &amp; Posix).
&gt; Being a web programmer used to interpreted languages, being able to use a language that is extremely fast and close-to-the-metal is liberating. C always felt way too low-level, and C++ is extremely overwhelming, but Rust I can understand. So, I'm on the correct boat!
I like icing, but only is reasonable proportion to cake. :-)
This! I totally agree. I'm ready for a statically typed language that's fast and does concurrency safely, and NO NULLS, as opposed to ruby. I'm an experienced rails dev and the things that STILL waste me the most time are having one of strings, symbols, integers, or nil when I thought I had a different one of those. I'm ready for a compiler to catch those for me. Also C scares me but rust makes me feel more confident that my code won't crash or have buffer overflow vulnerabilities, etc. Also, anything that can keep /u/steveklabnik1's attention for more than a year has got to be something good ;) &lt;3
Rust still has channels in the standard library. The point here is that they are no longer language items, meaning that the compiler doesn't have to do any special handling; the standard rust type safety and memory safety checks are sufficient.
http://doc.rust-lang.org/book/concurrency.html is the introduction. As /u/burntsushi says, we have channels, they're just not special. What _exactly_ you should do depends on what you're trying to accomplish. Channels and Arc/Mutex are two common choices.
I'm gonna finish the hypermedia book right after 1.0, I swear...
This is my first ~real Rust codebase, BTW, so comments as to code quality and idioms are much appreciated. (Especially from such a nice community as this!)
I definitely experience runtime errors in ruby, in dev and production, that the rust compiler would have caught, all the time. Of course, I'm in a 3 year old rails app that 30 people of various experience have worked on, soooo yeah.
I think the core team's view is that typing two extra characters occasionally is worth it for reducing portability bugs, and I agree with this view. Besides, I find them about the same to type, since it takes longer to reach up and hit the numbers. And as /u/heinrich5991 says, if you're doing something that requires `usize` or `isize` for the types to work (indexing, memory offsets, etc.) then fallback won't kick in at all - they'll be correctly inferred.
True, but see [`TypedArena`](http://doc.rust-lang.org/arena/struct.TypedArena.html). This is dynamically sized, so it (de)allocates in the heap in big chunks.
I guess I should also qualify in another way: while a compiler _may_ catch these kinds of errors, I don't think most Rubyists _think of it that way_, which is an important distinction. My first reaction to a `NoMethodError` (not that I get as many of those these days) is not 'oh man I wish I had static typing,' it's 'what is up with this test?'.
You might be interested in a similar thread I created a few months ago: [Why are you interested in Rust?](https://www.reddit.com/r/rust/comments/2aawnw/why_are_you_interested_in_rust/). There are lots of great responses there!
There's a [reflection-based multi-type arena](http://doc.rust-lang.org/arena/struct.Arena.html) but I think it has various problems. It does handle destructors intelligently, however: &gt; As an optimization, objects with destructors are stored in different chunks than objects without destructors. This reduces overhead when initializing plain-old-data (`Copy` types) and means we don't need to waste time running their destructors.
It's probably more useful for soft real-time than hard real-time, because for hard real-time it's common to statically allocate everything on startup. Even though hard real-time memory allocators exist (I'm not sure if jemalloc is one of them), if you're allocating memory you're probably doing some additional work with it, and for hard real time you need to know the maximum work you'll do in advance.
Quote from your linked HN code-example/comments: &gt; In debug mode, this program throws an exception; in release mode, this program [has a null pointer bug] Yes.. "training wheels off in release builds for performance (unless explicitly stated otherwise)" is a clearly stated feature of Nim. Nim in debug mode is [mostly] very safe (granted you don't touch inherently unsafe things like ptr.. which you can also do in Rust), and debug builds is how you're suppose to develop and test code in any language. I can't speak to your first two points, but this doesn't seem to be a valid argument against Nim's safety.
Cyclone is worth looking at.
&gt; I think one of the first things I heard about Rust was (Graydons?) writeup on typestate system and how it can statically prove correctness of far wider set of problems. Do you happen to have a link for us?
In short it scores high in almost everything except usability, where it's hard to use, more so than manual memory even. That is with manual memory it's easy to make a program that works 90% of the time (and crashes the other 10%), with lifetimes you get memory management that works 100% of the time, or simply doesn't compile at all. The other memory management systems generally incur either a performance cost, or become unpredictable (you don't know when something is deleted).
Aside from must-haves for a modern language like immutability by default, tagged unions, pattern matching and type inference; and, of course – borrowchck: 1. Freedom to choose dynamic or static dispatch withouth changing anything on the implementation side. 2. Dynamically sized types being first class! 3. Sending borrowed references between threads and modifying each other's stacks without race conditions, 100% safe! – this is currently my favourite (although I discovered them after being already drewn into Rust)
Traits or error handling. I especially love generic constraints. I want variadic generics. 
&gt; Yes.. "training wheels off in release builds for performance (unless explicitly stated otherwise)" is a clearly stated feature of Nim. First, this is a very different philosophy of safety from that of Rust (or of most other languages that are safe). Memory safety is not designed to be "training wheels": it is not designed to make it easier to fix problems before you ship the product (although it does that too). Rather, safety is designed to rule out classes of bugs that occur at runtime. If your program crashes in the field—which it will—you want to have it fail in a predictable way, rather than having it run off the rails with arbitrary behavior (including, in many cases, exploitable security vulnerabilities). In fact, this very issue—null pointer dereferencing—was the cause of [a Linux kernel security vulnerability](http://lwn.net/Articles/342330/). Arguably, you don't need new languages if all you care about is memory safety in debug mode: C and C++ already have Valgrind and ASan which are pretty good. Safety in debug mode is something that essentially all languages have nowadays, and it hasn't stopped the flood of memory safety issues that continue to plague C and C++ programs. Memory safety in *release* mode is what is important. Second, I also think you're underestimating what undefined behavior implies. Undefined behavior does not mean "undefined in release mode". It means "undefined in the language", period—i.e. undefined in release mode, debug mode, and every other mode. If you're relying on the compiler to compile a null pointer dereference in a way that causes a read of address 0 (like you're suggesting Nim does) you are *not* using the compiler in a supported way (because you in fact aren't writing C) and the compiler is free to break you in any release. Now (as Araq pointed out) you can use the "sanitize" options of some compilers to reduce that undefined behavior, but you lose performance doing so, and you will not catch all undefined behavior that way. Finally, Nim is still not safe in debug mode, even if the compiler were fixed to not emit code that exhibits undefined behavior. That is because Nim's GC is not thread-safe and sending garbage-collected pointers to other threads can cause use-after-free. That is not a property that D, Go, Swift, Rust, or any other modern language I know of possess.
One question I still have is why we default to move instead of reference. I find myself using references way more than moves. Can anyone shed some light on this? Is it just because references to POD types are usually unwanted? What about default references for non-Copy data types?
Interesting. It seems like this shouldn't need reflection for the non-destructor case, right?
People who make a big deal about purity usually forget that GHC ships about a dozen mutable variable types in the stdlib. Or they're using "Haskell" to mean "whatever subset of Haskell I need to win this argument". The people who've actually built large systems in Haskell don't obsess over purity; they see the language in a multiparadigm light. True, mutable variables in GHC work differently, and this has some advantages. But the problems of (memory-safe) concurrent shared state are still present. You can easily cause race conditions with `IORef` or `MVar`. And there are [a lot more subtleties](http://mainisusuallyafunction.blogspot.com/2011/10/thunks-and-lazy-blackholes-introduction.html) when you start needing to bend the rules. I ended up down that rabbit hole just because I needed a global lock to wrap a C library. Like many other issues with Haskell it comes down to the fact that laziness is a pervasive, global side effect. While the semantics may be pretty, the details get *very* ugly when you care about performance or low level details. The Haskell world has many interesting alternatives to shared mutable state, such as deterministic pure parallelism, nested data parallelism, or STM. But I always found them lacking in performance predictability and/or ergonomics. You can stick to message channels, but you may end up sharing an object by accident, or purposefully sharing an object without knowing it uses a mutable variable behind your back. The Haskell trait (i.e. typeclass) system can't talk about properties like "is thread-safe". Rust allows *local* mutation with less boilerplate, but it's much stricter than Haskell when it comes to shared mutability. Local, non-aliasable mutable variables are fairly harmless. In Haskell you would transform this to use a tail-recursive helper function, whose extra arguments are basically your local variables. Whatever. GHC also has the [`ST` monad](http://hackage.haskell.org/package/base-4.7.0.2/docs/Control-Monad-ST.html) which provides a pure interface to local mutation. I do sometimes wish Rust still had `pure` function checking, but that's for fairly specific uses cases, e.g. STM or model checking, where you really want to know that there are *no* side effects.
&gt; works 100% of the time, or simply doesn't compile at all This is what makes it easier to use than manual memory management, for me at least
BTW C++ modules will come eventually (C++17? Maybe...) and the D people have stated that their goal is to have the standard library completely non dependent on the GC. Not that I don't like Rust, but I think their is more than enough room in the space Rust is aiming at.
It's not at all uncommon for leadership at MoCo to contribute code, when they have time. It's finding the time that's problematic, I'm sure.
Memory safety in the Rust sense: the same safety guarantees as GC'd languages, but also data race safety. Source: I wrote a concurrency framework in Ruby and I am so tired of debugging other people's accidental data races. Beyond that, the separation of the memory safe and unsafe parts of the language through the explicit "unsafe" keyword is very helpful from a security perspective, since it makes it easy to find security-sensitive parts of the code, whereas with a language like C (and to a lesser extent C++) it's more like walking a minefield where things can explode practically anywhere.
Depends on if your goal is 90% working or 100% working.
There used to be a green (M:N) threads implementation in the runtime that was built on top of libuv. As I understand it, it became too difficult to maintain meaningful, comprehensible abstractions over both M:N and 1:1 threads without substantial overhead, so they opted to [remove them altogether](https://github.com/rust-lang/rust/pull/18967). All tasks are now OS threads.
Two killer features for me, and I'm not even coding it yet: - Rust is the only semi-mainstream language that validates my obsession for linear typing. - The Rust community is amazing. It feels a lot like the Haskell community, but without the constant masturbation about purity, and with possibly a more honest approach to the language's caveats. I'm probably doing my end of degree project in Rust starting this September. We'll see how it goes.
You expressed beautifully the issues I have with Haskell. I've always felt like I was the only one who felt this way :c
I just love how Rust continues to try to boil each problem down to its fundamental issue. Memory unsafety? No need for a GC; let's boil it down to an issue about aliasing+mutability! Thread safety? We need language support, but let's boil it down to the `Send` and `Sync` types!
Long story short - rust needs a constexpr system!
In light of this post I scanned crates.io's existing crates and couldn't find anything, so I created one, called `mac`. Here's the github repo: https://github.com/reem/rust-mac. As of this moment, it's empty, but I'm about to stick some of my own favorite little macros in it, plus maybe repackaging some larger macros in one place.
Can I join the webdev train? Woo woo!
* There was `Gc` (`@`), and there was `~` and all of the shit that goes with it: `~str`, `~[]`, `~Trait`. Now its been librarified, so its cool. * First class support for concurrency, but then the core team realized that it did not need to be backed by the compiler, because the type system was able to express the needed invariants to make it safe. * Enums used to be not handled by `match` but by the `alt` keyword! * Like others said, green threading, because to support 1:1 and M:N it made the IO libraries weaker. You can probably find a few others looking through the RFCs repo, I am sure I am forgetting basically everything.
Sorry, I was trying to be sarcastic but I failed. And who is Jason Livesay and why should we care what he thinks?
Wait so `Output` can be a different type for type `A` and `B` when you inherit from type A? It's shadowed? Can't your other example have `&lt;T&gt;::Output` and `&lt;&amp;T&gt;::Output`?
Pattern matching, Lifetime, Traits, immutability by default, great Concurrency support. omg do I love the **Functional record update syntax**, unfortunately I haven't seen it being used in the wild
Thanks a ton folks! Too bad rust cant use LLVM (near as I can tell). I have that all compiling on my machine. Two different versions, I am building a reflection system for C++. 
That would be a great feature for Rust to have. I know of a few places where I'd gladly use a u128 type, e.g. they come in handy for prngs and calculations on population numbers. Btw. the issue is [here](https://github.com/rust-lang/rfcs/pull/138/commits), but is closed without explanation. What gives?
Only if you don't need to chain them. Imagine this pseudo-Scala: val x = foo .someString() .someCoverterToOptionFloat() .getOrElse(1.0) .toInt // or .asInstanceOf[Int] in some cases .toString vs val x = ((foo.someString() .someCoverterToOptionFloat() .getOrElse(1.0)) as i32) .toString The second obviously needs some temporary variables, while the first is fluid. Edit: rewrote the example and got formatting working
&gt; match (then alt) didn't always require exhaustiveness. I'm not sure what it did in the failure case (probably some sort of runtime error). It was a panic, which was then called `fail` (and was a built-in expression, and before that was a statement). &gt; Destructors used to be defined using a specially-named field on the struct. Obviously this didn't work well for enums. And before that, there was the notion of a "resource", which was basically a value with a destructor and nothing else. &gt; There was some sort of purity notion for functions, I don't know much about the details, but I do know that the definition of "pure" was different to what most programmers expected. Yeah, there was `pure`, and there was also an I/O effect notated `io`.
Rust used to have generators a very long time ago. They were notated with `fn*`, `fn+`, and `fn?` for zero or more iterations, one or more iterations, and zero or one iterations respectively. I don't believe they were ever fully implemented, however. The predecessor to the borrow checking system was "alias analysis", which was similar to the "alias burying" paper of Boyland. Unfortunately it fell down in the presence of higher-order functions too easily (which is an issue that alias burying had as well). There was a system of "linked task failure", which was kind of similar to Erlang supervision trees. There was also intended to be an accounting system for limiting task resource usage. Early Rust had neither typeclasses nor `#[derive]` and instead had code that would take the representation of a value of any type at runtime. That runtime code could do various things like print the value's representation, compare two instances of a type, and so forth. All vectors were reference counted at one point and there was no append operation—there was only an optimization that would perform in-place mutation if the reference count was one. (PHP does something similar.) The story on mutation changed several times: at first, individual fields of records were mutable (like OCaml). This caused problems with the borrow checking system.
There was a conditions error thing at one point, which was totally separate from the Result or Option types. It only seemed to appear on IO things for me.
Tempted by the parallel paint feature, I gave it a try on linux: http://i.imgur.com/6pOGLar.png Errr :) Ran with ./mach run -r -Z show-parallel-paint https://www.cnn.com 
&gt; Wait so `Output` can be a different type for type `A` and `B` when you inherit from type A? It's shadowed? Yep. Remember that `A::Output` and `B::Output` are completely separate types. Neither is shadowed by the other, you access them via their traits (the `X as Y` syntax). All the trait inheritance is saying is that a type must implement `A` if it wants to implement `B`, and this lets us use `A`'s methods in the definitions of `B`'s. &gt; Can't your other example have `&lt;T&gt;::Output` and `&lt;&amp;T&gt;::Output`? What if we combined that with the above issue (`B::Output` and `A::Output`)? We still need to be able to disambiguate based on the trait. Theoretical the sugar you describe would be possible, but is there much point when it would break down so easily?
I'd love to see Minix ported, because it's so damned small. A memory safe free/libre microkernel written in Rust would be a security miracle.
And someday soon hopefull Rust will have emscripten baked in, so you can emit asm.js code from your Rust and get near-native performance and efficient memory usage from your webapps, too. :)
The next few years is going to be about concurrency and networking. I feel mutexes are the goto of the 2000s, hide them behind language features, make them safe, take a small time hit. While Im a huge fan of C++ for speed and Scala for language features, Rust feels like it takes the best from both. 
About purity, here's a quote from kibwen who is quoting himself ([original thread](http://www.reddit.com/r/rust/comments/2s7bnt/thoughts_about_rust_from_d_programmer/cnmvw2o)): &gt; With regard to purity, Rust actually did once have a notion of purity! And not only that, purity was the default: you had to explicitly opt out of purity by marking your function with the io keyword. This would have been in 2011 or so. Ultimately it was removed because Rust already provides guarantees that make it impossible to access shared mutable state (both for reading and writing) without using an unsafe block. Once this guarantee was in place (Rust didn't even have global variables for the longest time!), there were long discussions regarding the utility of the remaining guarantees of purity, and also lots of disagreements over precisely what purity should mean (and tangential stuff like whether it should be subvertible by unsafe blocks, whether it should be opt-in or opt-out, and so on). In the end it was removed entirely. So even though modern Rust can't automatically memoize referentially transparent functions (definitely unfortunate), you already get one of the greatest benefits of purity--freedom from shared mutable state--by default. 
Rust used to have classes with constructors and destructors: http://pcwalton.github.io/blog/2012/06/03/maximally-minimal-classes-for-rust/ (granted, todays system is similar, but I found that interesting) In general, /u/pcwalton's blog has quite some content on your question if you go back far enough.
it could be possible a compacting collector in theory could outperform using Rust's allocator
https://github.com/rust-lang/rust/issues/4707 might be interesting too
Well, it's comparable to other region-based methods I think. ParaSail comes to mind, which seems like it's less fussy to use. I don't think it's as low-level however..
[Cargo](http://doc.crates.io/index.html) allows you to [pin your dependencies to specific versions/commits](http://doc.crates.io/manifest.html#the-[dependencies.*]-sections). In fact, it even does it automatically via the [Cargo.lock](http://doc.crates.io/guide.html#cargo.toml-vs-cargo.lock) file: assuming you don't change your compiler version (and/or use [`multirust`](https://github.com/brson/multirust) to manage the compilers), you can come back to a project in the future and it should still compile just fine. E.g. for a project with a git dependency on the `foo` package: [dependencies.foo] git = "https://github.com/username/foo" rev = "abc123def456"
Oh, very cool. I was hoping. Interesting it does so automatically. For some reason Hematite doesnt seem to be doing that. 
Hmm. There is a checked in .lock file. In looking at it, it has version numbers. Perhaps some of the dependencies have made version changing changes without changing the version?
Very cool. I notice that in the ini parser example, the `tag!` macro needs a byte sequence. tag!(semicolon ";".as_bytes()); Wouldn't it be possible to extend the macro to also allow plain string literals?
That seems to be the (very good) reasoning about a lot of stuff in preparation for 1.0.
&gt; There is a checked in .lock file I don't see one in [the github repo](https://github.com/PistonDevelopers/hematite)? &gt; Perhaps some of the dependencies have made version changing changes without changing the version? It's not possible: "editing" a git commit gives it a new SHA (i.e. changes the 'version'), and you cannot overwrite a crate version on crates.io, can only upload new ones. Both git and crates.io are designed to be immutable (for approximately this reason for git, and exactly this reason for crates.io).
Edit: Oh I see. A .lock is made when I build whether it fits or not. There isnt one checked in. [[package]] name = "gfx_gl" version = "0.1.1" So that doesnt mean anything?
Agreed. Not everything must be added right away. If no compiler/language support is needed, I'd be happy to have those types in a crate. As I said, they're useful in some areas, but they're not ubiquitous enough to warrant putting them into std or even into the language.
Who's Jason Livesay?
&gt; That's a good attitude and is so much nicer to hear than hyperbolic statements like "highly unsafe", "dangerous safety hazards" and "not safe, at all". That rhetoric is getting just a little too old already Note, there is a difference between truth and rhetoric. Having to share pointer between threads and it causing failures seems to be squarely under dangerous. This is something *Java* programmers take for granted. And Java is old enough to drive. I do think pcwalton shouldn't respond to each of these Rust vs X post, his work on Rust speaks volumes, and I trust his time is better spent fixing issues, than debating language safety with Jimmy the Programmer.
I suppose you could implement this with a type class that the macro can use to convert the incoming value to what it needs. Not sure if there's a better way, though.
An enum like `enum Either { Left(Foo), Right(Bar) }` will be implemented as a tagged union, e.g. in C++ syntax: enum EitherTag { LeftTag, RightTag }; struct Either { EitherTag tag; union { Foo foo; Bar bar; }; }; Specifically for `Option&lt;T&gt;` this turns into something equivalent to `template&lt;typename T&gt; struct Option { bool present; T value; }`. Thus `Vec&lt;Option&lt;Foo&gt;&gt;` will be the same as `std::vector&lt;Option&lt;Foo&gt;&gt;` with that `struct Option`. Note also that `Option&lt;T&gt;` where `T` is or contains a non-null pointer will be optimized to not include the `bool present` tag (it sets the pointer to null to represent `None`), so, for example, `Option&lt;&amp;T&gt;` and `Option&lt;Box&lt;T&gt;&gt;&gt;` will be all the same size as `T*` in C++.
`Some::&lt;T&gt;(x)` and `None::&lt;T&gt;` have the same size, which is: * the size of `(bool, T)` for most types (the boolean flag indicating which variant it is) * the same size as `T` if a non-nullable pointer is found inside `T`, e.g. `Option&lt;Option&lt;(Box&lt;T&gt;, Box&lt;U&gt;)&gt;&gt;` should be no larger than the two pointers themselves, the first one being used for the inner `Option` and the second one for the outer `Option`
Move by default
&gt; The story on mutation changed several times: at first, individual fields of records were mutable (like OCaml). This caused problems with the borrow checking system. I'm really curious about this one (because intuitively, I prefer OCaml's idea of mutability being a part of the type). Can you give a simple example or explanation of the problems with the borrow checking? Were they only theoretical (i.e. borrow checking would fail) or also practical (it would also result in runtime errors/races)?
You can give it `b";"`
By the way, your usage of `~` in the INI file example looks quite strange. Why do you use it like that?
&gt; * A `try!` version for `Option` instead of `Result` I’m not super happy with it, but https://crates.io/crates/triable As to the initial question, I personally favor publishing many small crates doing one thing each rather than bigger crates full of unrelated things. Putting things together helps discovery, but that’s not necessary to make things discoverable.
Yeah, `Cow` is cool. I just had to test it myself. :) But it wraps a `&amp;B` or a `&lt;B as ToOwned&gt;::Owned`, not a `&amp;mut B`. For example: `Cow&lt;str&gt;` wraps a `&amp;str` or a `String`. A possible example: fn add_txt_suffix_to_cowstr(mut text: Cow&lt;str&gt;) -&gt; Cow&lt;str&gt; { if !text.ends_with(".txt") { text.to_mut().push_str(".txt"); } text } #[inline] fn add_txt_suffix&lt;'a, I: IntoCow&lt;'a, str&gt;&gt;(text: I) -&gt; Cow&lt;'a, str&gt; { add_txt_suffix_to_cowstr(text.into_cow()) } But I'm a bit surprized that lifetime elision did not work for the second function.
Actually, Rust compiles down to machine code using LLVM. This means that Rust ultimately generates LLVM code that LLVM uses to compile down to machine code.
Thank you! Those "as_bytes" were killing me :) I just removed them, it is a lot more readable now.
I needed a separator in the macros. The tilde looked innocent enough to be used there, but I am not sure it is the best one. I am open to suggestions for that part. Maybe I could do completely without the separator (if the macros allow it), that would not change much the [usage](http://rust.unhandledexpression.com/nom/macro.chain!.html).
The `R` is important to tell the compiler that it is a generic type. Consider this example: struct R; struct Foo&lt;A: Add&lt;R&gt;&gt; { a: A, ... } This would cause an ambiguity if we didn't require the generic `R` to be declared.
Do keep in mind that I stopped maintaining this list relatively quickly, and so it only represents deprecated features of the language for a narrow slice of time rather than being an exhaustive list. Though at that point in Rust's life the compiler certainly did have a greater than average number of old features lying around, hence the need for the issue in the first place. :)
Not to be confused with #4707, linked below.
For the struct definition itself, you could just leave off the Add bound: struct Foo&lt;A&gt; { a: A } impl&lt;R, A: Add&lt;R&gt;&gt; Foo&lt;A&gt; { ... }
&gt; hand-written dynamic linking driven from metadata (with hot code reloading) Wait, what?
Wow, I'm amazed that the compiler's smart enough to use inner pointers to collapse the representations of outer Options. Is there any other cool magic related to null pointer optimization that you've been hiding from us? :)
Ada supports [dynamic allocation](http://www.adaic.org/resources/add_content/docs/craft/html/ch11.htm#11.1).
&gt; `Option&lt;Option&lt;(Box&lt;T&gt;, Box&lt;U&gt;)&gt;&gt;` should be no larger than the two pointers themselves Did you mean `(Option&lt;Box&lt;T&gt;&gt;, Option&lt;Box&lt;T&gt;&gt;)`? [Playpen link](http://is.gd/F3uf2B)
That's amazing.
True :)
Like, as someone who really really really likes linear types, my only option is languages like Rust and ATS that have affine types. There's basically no alternative. I'm still waiting for Linear Agda or something.
The Lua model of coroutines (i.e. genuine coroutines running in a single thread, with well-defined switch-points between them) is very efficient and also predictable without requiring locks, i.e. if I know there is no yield between here and there then effectively I have a lock on everything owned by the thread. The language (e.g. borrow checker) could reason about things on that basis. I have no idea how well this could fit into the current concepts of Rust, though. But genuine coroutines give a lot of provable/checkable guarantees to the coder.
&gt; Nim and Rust have different goals and different means of achieving said goals. Comparing them and especially putting one above the other is simply wrong, if not outright disingenuous. Well said.
It's honestly what I dislike most about rust syntax, "mut" just sounds and looks stupid to me. Mut mut mut. 
No *runtime* VM then. 
You can extend it to non-zero integers using [`NonZero`.](http://doc.rust-lang.org/core/nonzero/struct.NonZero.html)
You can serve HTTP in rust simply by using a ~1000 LOC library. https://github.com/kjpgit/mudpie/ If you want more "advanced" stuff, well, people are shaving that yak all the time too.
I [came across a paper by Eric Brewer from 2003](http://www.onebigfluke.com/2015/02/ghost-of-threading-past.html) that basically says coroutines are the solution for writing highly concurrent servers. So I'm saying it's a loss in that respect. Python, ES7, and Go have coroutines of some sort (as do many other languages). I was looking into how Rust would address the points in the paper and I hadn't realized `green` was taken out.
I still pronounce it "mute" not "mutt"
I fully agree, see [this comment](https://www.reddit.com/r/rust/comments/2x2pon/what_significant_languageruntime_features_were/cowucw5) just up the thread. Non-preemptable coroutines/continuations are a great fit for rust, and not terribly hard to implement as far as I can see. Making them convenient and high level like C#'s async/await might need to some compiler help, or it might be possible with a suffiently clever macro... i'm not entire sure.
I think the Cap'n Proto benchmark is unfair, it skips the `new_log`. Instead of measuring the serialization the benchmark measures the speed with which the memory can be copied.
Sorry, I got sick of this in-joke after a couple years in `#haskell`.
Is there a possibility to make the same about strings? (Strings that will never have the size 0)
Because Rust permit impurity by default, I think the use of monads in Rust would be much less. I wonder which name will be chosen for `Monad` in Rust, though. `AppendWithUnit`? It isn't better than `Monad`...
Having the task move the "shared" mutable references out of itself on every yield would give you the safety you'd want. I'm not sure what the ergonomics would look like, but it should be possible to share an environment between a whole bunch of tasks as long as they are never run in parallel...
Can't you do enum matching with a switch statement in C?
I still prefer calling them Monads. :/
This looks great. Rust for serious protocol parsing is my next game. I love the name too! The two values you have to pass to ```::Await``` in a ```Consumer``` are the only things that I don't like the look of at first glance. Is it not possible to automatically work out the ```consumed``` count from what has actually been consumed? Or at least provide a mechanism for automatically getting that value in the basic cases? Seems like there's a lot of scope for screw ups for a more complicated parser. You basically have to re-do the length based logic of the parser. Or make sure that every complex parse outputs a type that includes a consumed value. Everything else is really cleanly separated architecturally, but you need to know the ```needed``` value from the *next* state which feels like a poor separation. You could just let the library call the next state with everything it's got, possibly waiting for the parser to generate Incomplete and then the state to pass that Incomplete length value back out. With the current design you could emulate that behaviour by always returning 0 or 1 in await, but it's uglier. On this point - in your OmNom example, is there any reason you aren't passing the Incomplete() value to ```Await``` and have a hardcoded value instead? 
That is a runtime overhead that would not be necessary if the compiler understood what 'yield' means (and tracked yield-points), and had a concept of sharing a mutable reference between cooperating 'tasks' within a single thread. I guess it's a bit late for 1.0 now, though!!
By the way, nobody replied to the other part of your question, about whether there is a language where moves are explicit: [C++11 does exactly this](http://en.cppreference.com/w/cpp/utility/move) with std::move and move constructors. There are some nuances, as is always the case with C++: * Not a keyword, but a library function. * Necessitated adding an entirely new type of reference, plus an entirely new kind of constructor, to the language. So way less elegant. * The origin variable is not invalidated via the type system as in Rust, but instead as a "gentleman's agreement" of what a move constructor should do. So less efficient and more brittle.
&gt; typestate checking This is the one feature that first got me attracted into Rust, it looked really great. At the time, I did wonder how it could be composed though: that is, if I were to created a new annotation (predicate) then it seemed I would have to go and annotate each and every existing function since by default it was assumed a function would not preserve the predicate. I am afraid the composability issue proved unsolvable...
There may be room for other ameneties, particular for dealing with global data that doesn't need locking because its known to run in a non-smp environment.
While I was reaading the ini example I remembered writing Clojure in the past.
Completely agree.
Followup: How do enums "count" exactly? If you started from 1, could you potentially fit a free option in?
Is it possible to make something like this for intellij? 
I don't think this can be made to work, since you'd have many possible associated items for the same type `()`.
I don't think so. It already uses the pointer in the String for the Option optimization by the way, because it is never zero. To be clear, I think NonZero only works with types that are "all bits zero" in their invalid state. If all bits zero is an invalid state / never possible, then the type can impl Zeroable.
Option&lt;(Box&lt;T&gt;, Box&lt;T&gt;)&gt; works as well, it's just the double-option that doesn't work.
Glad to see a datetime crate with active development. It is referenced somewhat in the linked wikipage, but I was wondering if/how the design has been influenced by joda-time/JSR-310. Not necessarily from a API perspective (not sure if the API is particularly ergonomic in Rust), but in general, as I think those libraries/specs are regarded as good "battle tested" treatments of datetime. There are a few mentions of future work, but is there a general roadmap for this crate?
AFAIK there isn't any inverse version of `io::Chars` or `io::Bytes`, and while you could realise your iterator as a Vec I doubt that's what you have in mind. I don't think there's anything built-in to drain an iterator into a Write. For a one-shot operation you could probably just fold over the iterator (with the Write as accumulator)
That'd be pretty awesome... We should probably just bribe jetbrains
&gt; It already uses the pointer in the String for the Option optimization by the way, because it is never zero. Oh yeah, completely forgot about that! :)
Is the `innerHTML` thing is big as I think? Does it make some DOM manipulations made by jQuery work now or do I give it too much credit?
I've only seen discussions at a conceptual level. It would be great to have a proof-of-concept as a syntax extension or other external tool.
I haven't looked into this, but it's big because: - A lot more tests in our suite work because they had a casual innerHTML dependency - It's a major hurdle in getting normal websites to work (so dogfooding) I know for a fact that jQuery AJAX works. We support the CSSOM but I don't think that portion of jQuery works yet. I should have a look, that was one of the things I and Bruno were interested in fixing up but other things got in the way.
They have fallthrough and are not guaranteed to be exhaustive, though.
I calls it as I sees it. But I should call it mute, as well since that does clear up some confusion.
Its author did a quite good IDE for D. I bet this one is going to be as nice for Rust. Congratulations on the work.
Agreed on all points. :)
Any good date/time library design needs to account for the language semantics, so there is not much direct influence. For the design decisions, though, I occasionally looked at [CL `LOCAL-TIME`](https://common-lisp.net/project/local-time/), [JodaTime](http://www.joda.org/joda-time/), [Python's `datetime` module](https://docs.python.org/3/library/datetime.html) (with its [well-known caveats](http://www.enricozini.org/2009/debian/using-python-datetime/)) and [pytz](http://pytz.sourceforge.net/). To name an example of JodaTime influences, there is no timezone-aware `Time` type (which was there but I then realized the rationale). To name an example of language influences, there *is* timezone-aware `Date` type missing from JodaTime which was deemed necessary for convenient construction of `DateTime` type. The separation between `TimeZone` (constructor) and `Offset` (storage) is somehow observed in JodaTime but nevertheless my original design. Given the explicit goals and limitations, I think external timezone support, TAI support and convenience wrappers would be the next and probably last big things. (There is an [issue tracker](https://github.com/lifthrasiir/rust-chrono/issues) listing them.) I don't think that support for non-Gregorian calendar, for example, should go to Chrono.