The content of the talk seemed to mostly be "you are doing it wrong; here's how you should be doing it". It was presented in a way that made me feel like I was being talked down to.
whats this? mod foo; foo::bar(); with no use foo? but then in a submodule you do need to use foo? When did that become a thing? Thats super inconsistent.
Thank you so much. I feel like quite an idiot now. I guess that's what happens when you're learning a new language :D
Thanks. You have made everything much easier!
Oh, maybe. It was a couple months ago now, but I think I had the impression that some rt starting function needed to wrap my code, so that my function's return value had to pass through it. Like `std::rt::init(myfunction, args)`. If it's a before-and-after thing, like std::rt::init(); result = myfunction(); std::rt::cleanup(); result that should be much easier.
I think you want to build something equivalent to the ExecutorCompletionService in java. [See here.](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorCompletionService.html) Anyways, you want each of your tasks to put something on a result queue when it completes. After you've spawned all your tasks, just wait on the result queue and stop the threads after you've encountered the very first result that evaluates to false.
As one more 'this is how you figure this out' kind of answer... `git log | grep exists` returns 467bea04fa1d5fd894d64b2b2901d94260301631 as a commit: https://github.com/rust-lang/rust/commit/467bea04fa1d5fd894d64b2b2901d94260301631 ---------- Additionally, if you used the I/O path extension methods `stat`, `lstat`, `exists`, `is_file`, or `is_dir`, note that these methods have been moved to the the `std::io::fs::PathExtensions` trait. This breaks code like: fn is_it_there() -&gt; bool { Path::new("/foo/bar/baz").exists() } Change this code to: use std::io::fs::PathExtensions; fn is_it_there() -&gt; bool { Path::new("/foo/bar/baz").exists() }
Wow, that's not how I thought it worked. I thought use and mod were totally orthogonal actions. ie. mod creates a symbol table: foo - bar - foobar &lt;--- use my_func_yy from here via self::yy::my_func_yy(); - yy - my_func_yy &lt;--- Actually symbol, used via full path foo::foobar::yy::my_func_yy - xx - my_func_xx &lt;-- use my_func_yy here via super::yy::my_func_yy(); and use creates local aliases to those symbols: foo - bar - my_local &lt;--- via. use foo::foobar::yy::my_func_yy as my_local - my_foo &lt;-- use here via my_local() - foobar - yy - my_func_yy - xx - my_func_xx I didn't realize that you could call a relative path directly. mod foo { mod bar { pub fn call() { println!("Hi"); } } pub fn call() { // self::bar::call() not required. bar::call(); &lt;--- O_o is very surprising to me. } } No wonder this is surprising to people. On first look it makes it seem like you only need mod, not use.
Thank you! I have figured it all out. Man, this was way easier in C :P
Because you can write `draw(width =&gt; 500, height =&gt; 400)` and omit the default arguments or you can write `draw(None, None, None, None, 0, Some(500), Some(400))`
I am but there wasn't an update for Ubuntu x64 in some time.
&gt; As one more 'this is how you figure this out' kind of answer... `git log | grep exists` returns ... "To keep track of changes, just check out the entire source repository and grep the log. If you're on Windows, also see the following link on installing `grep` since `FIND` is rubbish." This also applies to the "you can grep for breaking-change" comments, too. This *is not* intended as an indictment or criticism, incidentally. Just that grepping the log can be somewhat inconvenient, *especially* if you're relying on nightlies. I tried to find a way to do this on GitHub, but failed to do so. Man, whatever happened to This Week in Rust?
`*T` (in C) doesn't have move or automatic deallocation semantics like `Box&lt;T&gt;` does. I think conflating them is a *terrible* idea. There was (probably still is) a trap in D where some code which is valid in both C and D has different semantics. If you're not cautious, you can end up writing/copying code that doesn't do quite what you think it does. Just to demonstrate how dangerous this is, I honestly *cannot remember* what the behaviour in question is. To be fair, one upside is that the change would disallow things, not change the behaviour of existing things. Nevertheless, I still feel the difference between "pointer to *something (maybe)* in memory with unknown semantics" and "owned pointer" is wide enough to want to avoid conflating them.
I actually quite like Rust's way of handling modules: * `mod` is used to declare the structure of the project. * `use` brings stuff from somewhere else into the current scope.
I'm rather fond of it, myself. Having said that, it's still weird (relative to my experience).
Nice. I didn't know about CFFI in python. Looks very simple and interesting. Thanks.
&gt; For example, there's the libstd library which is a crate containing the std module I think this would be better phrased as "there's the libstd library which is a crate that *is* the std module". The crate root is the start of the module, i.e. `extern crate std;` is basically like writing `mod std { /* contents of src/libstd/lib.rs */ }`. (There is a `mod std` inside `libstd`, but that's just a hack so that macros work internally, it's not exposed publicly.)
Done. I didn't want to add anything about `extern crate std;` being like putting the contents of the crate there, since then I feel I'd have to clarify that having multiple `extern crate std;`s doesn't cause multiple copies to be brought in and then it's getting long for a parenthetical aside to clarify what "crate" means. Maybe an addendum, if it merits further explanation. :) Also, I'd forgotten about the self-import module, which is funny because I've had to use the exact same trick myself. :3
Thanks for that write-up! That's a pretty concise tutorial for modules and what I like the most is that in your *points of mental model* you explain most crucial things the way that there is no place for most common misconceptions that newcommers make. And explanation of paths and how they interact with `use` etc. That had been always confusing me.
&gt; So although multi-file crates are really just a single, giant file in disguise (like with #includes), the scoping rules work as you would expect from a normal "neat little boxes" model. I was going to list the differences between the module systems of Rust and Python... except you can do some hideously evil stuff with dynamically loaded modules, so there's not much point. You can pretty much get whatever semantics you want with enough magic. :P
Oh, also: &gt; Even more unfortunately, the "correct" code that compiles under rustc fails to compile under rustdoc due to, ironically, inability to find names from the child module in the example. This is because `rustdoc` compiles each example as a separate crate, and will automatically [wrap the example bodies in `fn main() { ... }`](https://github.com/rust-lang/rust/blob/5e13d3aa00e8cfdf1a64f58f6c649460400231c0/src/librustdoc/test.rs#L232-L238), which is the normal case when writing docs. You can disable this automatic behaviour by manually providing your own `fn main() {}` (if actually rendering with `rustdoc`, writing it with a prefix `# `, like `# fn main() {}`, will stop it appearing in the output).
Ah, ok. As far as I can tell, there's nothing about the `main`-wrapping behaviour in http://doc.rust-lang.org/rustdoc.html. I *did* miss the bit about `#` HTML commenting, though. I've fixed it by added un-commented `main` functions since: 1. it's probably better to give examples that will compile without additional flags (I was having to add `--crate-type=lib`), and 2. if I'd used `# fn main`, I'd have to explain what it means on the Gist, or manually strip them out before pasting it in and urgh effort.
I still don't get your point. I mean, ok you did get some things wrong at the beginning but this is not weird but normal. &gt; So although multi-file crates are really just a single, giant file in disguise (like with #includes) Of course, every .dll or .exe is a chunky „big“ file. What is weird about that?
Can you use the rustup.sh script? $ curl -LSso rustup.sh https://static.rust-lang.org/rustup.sh $ chmod +x rustup.sh Then whenever you want a new nightly: $ sudo ./rustup.sh As a side note you could also just run the rustup script directly from curl so its a one liner. But I like to look over the script first before `sudo`ing it...juuuust in case ;)
This is very useful. Thanks!
&gt; (i.e. the stdlib will feel clunky) It sure does - a bit. But we should be able to retrofit the existing APIs with default arguments without breaking other code - the default arguments get inserted at the call site, so the ABI should not change. Of course that means we should be extra careful while designing the APIs so that the retrofitting is not unduly complicated.
I've had a look at it, but it didn't build for me with the latest nightly cargo and rust.
&gt;I want to make a full-on guide about the module system Amen to that!
Thanks!
Could you explain how this could be solved by coding a C-style for loop?
True, Builders can be quite verbose. However, they allow more fine-grained control over how the arguments are initialized, e.g. defaults can be arbitrarily retrieved / calculated on `.build()` if they were not set. E.g. a `GraphicsBuilder` could default the viewport geometry to the current window's contents. This is something that default arguments don't allow by themselves (although this can be emulated by defaulting to none and catching this in the method implementation, as is customarily done in python).
Thanks for this, I keep messing up when it comes to other crates. A few days ago I figured out how this works, but this gist puts it in a clearer form ^_^
Many, some of the problems I wrote about a long time ago: http://lucumr.pocoo.org/2009/7/24/singletons-and-their-problems-in-python/
It's not the only difference, /u/Quxxy points out another. I was just clarifying because the original phrasing made it sound like a crate foo *contains* a module called foo (suggesting paths would be `foo::foo::...`), while it's really the case that the top level module is the whole crate itself.
Reading this, I was interested to know what happens to the boxed values when Ruby is finished with them? Is that what the author means by: "I didn't cover freeing memory or exception safety, which will be the subject of future posts (soon!)." ..? Because it seems to me that each "Point" created in Ruby will allocate a new boxed object, which Ruby probably expects Rust to handle, and which Rust probably expects Ruby to handle? *edit*: I ask because I've previously seen work exposing functions to Python, a similar thing, and in those cases it's a single item being allocated (the function), clear memory safety within the function, and usually pass-by-value semantics. This is different, it's exposing objects from Rust to Ruby in boxes, which seems semantically and memory-wise a different game entirely; as given, it actually doesn't look *safe* as it suggests it is in the title?
`extern crate` is kinda in between `mod` and `use` semantically: - Like `mod`, it _adds_ actual new modules into the namespace in the sense that it links to external libraries and exposes them as a module path. - Like `use`, all identical `extern crate`s are module paths that point to the same logical module, and are hence interchangeable. So, neither `use` nor `mod` are entirely correct keywords to use. However, arguably you might be able to drop the `extern` keyword...
It's nice to see one's own thoughts reflected in another's writing. I think Rust's module system is built on a solid and intuitive logical foundation (which happens to be *very similar* to how C++'s classes and nested classes work); it's the two comparatively minor things mentioned in this post which break the analogy and confuse people. Namely, that unlike everywhere else, `use` paths are absolute rather than relative, and unlike everywhere else, items from outer scopes are not visible inside submodule scopes. These are the same things which tripped *me* up for a while. As the article also suggests, I strongly suspect, but have not been able to confirm it with people who were around at the time (none have responded), that the historical reason for this is because experience showed that the alternatives were too confusing... *for modules defined in separate files*. Obviously, having entities from one file (or worse, from a whole subpath in the hierarchy) be implicitly in scope in an entirely separate file would tend to be surprising. ("Where are these names coming from?!") Not that it'll make much difference, but I plan to submit an RFC to resolve this by semantically distinguishing inline (same-file) modules from external (separate file) modules. Instead of the current `mod foo;` you would write something like `extern mod foo;` (not to be confused with `extern crate` which used to have that syntax), but the syntax is not important and the could be something different. Normal `mod { }`s would transitively see items from parent scopes up to the innermost `extern mod` - in other words, would see definitions from the same file but not different ones. `use` would always use relative paths. This means that in an `extern mod` you would have to write `use ::foo::bar;` to import something from the crate root; if this is a bother, we could potentially have an implicit `use ::*;` at the top of each `extern mod`. The main drawback of this approach is that you would no longer be able to move code from an inline submodule into a separate file by just cut-and-paste, but would have to add `use`s for the items used from formerly-in-file parent modules. The advantage is that it would hopefully get rid of the confusion every newcomer initially experiences from the intuition-breaking inconsistencies of the current system. (And it would hopefully be just plain more usable in many cases as well.)
&gt; The main drawback of this approach is that you would no longer be able to move code from an inline submodule into a separate file with just cut-and-paste, but would have to add uses for the items used from in-file parent modules. You know, I actually did that today across several modules, splitting them out as they became too big. I have to admit that I really like being able to do that. :D Once I realised what was going on, I actually started using more modules specifically to narrow the scope for imports needed for the implementation of things. "Oh, this struct impl needs these five types pulled in? I'll just chuck it in an inner module and re-export to keep everything clean." If I had to create a new file for each of those... I probably wouldn't bother. &gt; The advantage is that it would hopefully get rid of the confusion every newcomer initially experiences from the intuition-breaking inconsistencies of the current system. I'm kind of on the fence about this. On the one hand, the current system is inconsistent because modules are the only things to have non-lexical scoping rules. On the other hand, the new system would be inconsistent because a module's scoping would be different depending on whether it's inside its own file or not. :P I can't discount the possibility that the current system isn't bad; it just isn't explained clearly enough to newcomers. Perhaps once the new guide deals with this, we'll see a precipitous drop in the number of people on IRC and Reddit confused by modules and `use` statements and nothing will need changing. That said the distinction between path types is kinda... *wonky*. I don't really understand why you can't just have unprefixed paths try `self::` first, falling back to `::`; both of those would continue to exist if you needed to disambiguate, and I deeply suspect it would solve a significant proportion of the early confusion.
Travis is green, wonder what's wrong?
While the presentation is interesting, I find the split of languages in the beginning to be downright irresponsible. The type system in C is almost entirely useless and it's even memory-unsafe. C++'s is only a minor improvement on both counts. Then, Scala has a pretty good type system, certainly comparable to Haskell's. I think the presentation would've been much better with a different split than interpreter vs VM vs native executables, or none at all.
Ok, I see, neither `extern use`, nor `extern mod` describe the situation precisely, so we have `extern crate`. Now it looks more logical. Thanks!
`=&gt;` seems more confusing to me. It's already used in `match` and `macro_rules!` with entirely different meaning from what you are proposing. I do sometimes wonder if `struct` initialisation should have used `:=` instead :p.
Ah ok now I see your point, although I don't agree. Python does not allow to define inline modules and such they inherently don't have access to any other scope. In that sense I do not see how Rust possibly combines `#include` with a pythonic module system. Visibility-wise it works exactly like python. You just don't have the inline case in python. I also do not see how you see any similarity with `#include`.
It doesn't really use cargo, it just calls the makefile and you don't get any err msg. You need glew glfw3 and premake4 to build it.
according to that wikibot reply: "libfixmath has no external dependencies other than stdint.h and a compiler which supports 64-bit integer arithmetic (such as GCC)." so this would probably be unsuitable for mobile platforms, I would imagine-- just pointing that out; this thread has been informatative
It also says: &gt; Conditional compilation options exist to remove the requirement for a 64-bit capable compiler as many compilers for microcontrollers and DSPs do not support 64-bit arithmetic. 
This is a design I've been working on to make Piston support generic events, where you can pass an event between functions, use traits for events, but without needing any generic constraint except `GenericEvent`.
Same rule in C++ and Python, that's why I've mentioned in the "Questions" section of the RFC. Actually, I don't know what's the best solution for this (that's why I didn't defined strict rules about this in the RFC)
The solution I wrote in the RFC was the following (not really the same as I used with a bare function, but the solution is the same): let incr = |x = 1, y| x + y; incr(y: 2); 
That's why I wrote in the "Motivation" section than this feature should be discussed before 1.0, as the standard library API will be frozen post-1.0 (and leaving some "old-fashioned" functions behind) But maybe I took too much time to write this RFC, and it's too late now :(
Actually, you have to look up documentation because you don't always know what's the function corresponding with arguments you want to supply (e.g. `concat` and `connect` in `std::str::StrSlice`)
[This will be a bit long and rambling.] Since you ask, I was also a bit uncomfortable with your talk. To give you an idea of my background, I've used C++, Scheme, JavaScript and Ruby in serious production systems for a long time, and I have a lot of personal experience with Haskell and Python. I'm _very_ enthusiastic about Rust, but not because I think type systems will solve my clients' most serious problems. In my experience, the commercial reality is that you can build large, successful systems using dynamic languages. Problems can arise in practice: 1. Refactoring is hard in larger, older dynamic codebases, especially when you only _mostly_ trust the tests. 2. Scaling is hard, because most dynamic languages are slow. Bugs are generally a minor issue. A few things slip through that might have been caught by a static checker, but you fix them, write a regression test, and move on. Ruby and Scheme both provide memory safety, so bugs generally don't escalate into catastrophes. The payoff for using these dynamic languages is vastly reduced time to market, and vastly faster responses to users' feature requests. This is worth the occasional minor bug, commercially speaking. And commercially, scaling often only matters once your Heroku bill passes $200K year, that is, the full cost to an employer of hiring a single sysadmin or devops person. All that said, Rust offers a rather unique combination of features: 1. You can get almost as close to the metal as you can in C. 2. You can maintain full memory safety even when dealing with utterly hostile data. 3. The abstraction tools are good enough that I can already reach 25% of the developer productivity I'd have with Ruby or Python, and maybe 50% in the long run. That's a huge, badly-served niche right now, and Rust looks like it will open up entire worlds of awesome possibilities. So, my recommendations for your talk, assuming you want to win people like me over (which may or may not be a goal): 1. Focus on the really cool possibilities that languages like Rust enable. 2. When attacking existing solutions, focus on the things about them that even experienced practitioners tend to dislike. For example, most C programmers hate subtle memory corruption, and most Ruby programmers hate large-scale refactorings when it takes 30 minutes to run the tests. 3. Avoid blanket condemnations that assume people are irresponsible for using technology X, unless you actually understand the technical and commercial tradeoffs they faced. I actually like your vision of the web. I see an awesome world just opening up, and I'm super-enthused about writing fast, safe, parallel applications in Rust. And anyway, I hope this post helps you in some way—if not, feel free to ignore it. :-)
&gt; The `sep` argument is a problem for me. The `split` function I wrote was just for the example, I just wanted to show two default arguments and I choose `split` with `sep` and `count`, but that's not the change I expect in the standard library. In fact, I didn't even specified changes in standard library as I think it's not the point of this RFC, maybe another later. &gt; Although this is not an issue with the feature per se, it can encourage bad API design. And I think that having default/named arguments doesn't encourage bad design, as they can be present even without this feature :)
Looks like they added direct download links to the page recently. The download button expands to options for `WebM (HD), Mpeg4 (HD)`. Nice! Still confused how a Mozilla website fails so badly at web video.
apparently i'm blind! sorry
At least for using Rust from Perl 5, it seems to work to just provide a way to drop the type in the Rust code and pass the pointer to that in the object destructor of the integrating language. The drop function itself would be just something like (from my example code): #[no_mangle] pub extern "C" fn drop_rectangle(_rectangle: Box&lt;Rectangle&gt;) { } Since it takes the pointer as a `Box` it owns instead of a borrow, it'll destroy it at the end of the function. It's no similar to C libraries providing a `free_*` function.
Further Work - "Investigate event transformations" would an event transform be something like going from game-screen to menu-screen as an event which means keyboard arrow-keys would be for button selection on the menu screen instead of moving a player... what is meant by this statement exactly?
could this be implemented in stages:- [1] defaults in the syntax allowing C++ style trailing defaults [2] using the parameter names as keywords to be more specific (dependant on the defaults given in [1]) I do believe either level is a step forward: unlike overloading, it leverages fewer symbols.. does more with 1 definition -hence reduces the amount of navigation through code &amp; documentation. Defaults should be considered orthogonal to 'parameter structs'- its equally useful for functions with small numbers of parameters (2,3..). its not just about 'lots of params'. maybe it would also be nice to have a way of getting a functions' arguments *as* a struct
In order to use Racer you need to have Rust's src (or some such) directory accessible. AFAIK with the rustup script you won't.
Servo using `hyper`? What about `teepee`? Is it too high level.
&gt;A module does not exist alone, it exists in the context of the root module. I'm a bit concerned about this fact. I see why it is needed, but I'm still trying to imagine what problems it can cause. It seems like the partial isolation of names does the good job mitigating the usual "header" dangers. But e.g. a common problem with headers - their "non self-sufficiency" (a header can accidentally use something that it doesn't include) is still applicable to Rust. Though I don't see a practical problem here, since the order of definitions doesn't matter in Rust and the whole crate is a unit of compilation. Another problem is macros, which don't have usual scope rules and are order-dependent, but I hope it will be fixed somehow. Any other potential dangers?
Could you elaborate? If I interpret correctly, you mean to hook the Rust destructor into the dynamic language's GC system? That's a nice way to handle this, if it works universally (Python's GC has a lot of 'magic'), I'll give you that. :) I still think this is mixing up the strengths of the two languages though: Rust would be best used IMO for functional code to extend the native class systems of the dynamic languages.
We're currently using `rust-http`, and are evaluating the various HTTP libraries that are coming up. `hyper` looks promising — Teepee does too, but it's still unfinished and might be a bit too high level for what we need (we need low level byte access much more than we need parsed stuff)
That's correct, you have to download the source separate. Which is another reason I like to download the rustup without running it so I can add that.
&gt; Could you elaborate? If I interpret correctly, you mean to hook the Rust destructor into the dynamic language's GC system? That's a nice way to handle this, if it works universally (Python's GC has a lot of 'magic'), I'll give you that. :) Well, hooking into the GC sounds a bit more dramatic than it is. It is really just using destructors. I made a [gist](https://gist.github.com/phaylon/f4837563f004efca242a) of my Perl 5 experiments in that regard. That all just uses basic `Box&lt;T&gt;`, but I don't see any problems using `Box&lt;Rc&lt;T&gt;&gt;` or `Box&lt;Arc&lt;T&gt;&gt;` and having Rust and the dynamic language share ownership over the resource in more complicated scenarios. &gt; I still think this is mixing up the strengths of the two languages though: Rust would be best used IMO for functional code to extend the native class systems of the dynamic languages. My main focus for these experiments is having Rust function as a glue between Perl 5 and external bindings, and having the ability to optimize parts of the code to be more space or time-efficient than a dynamic language could be. For these cases the kind of bindings described work out nicely enough.
That's where I got it from. I find it a very zen-like demonstration of the elegance of Rust's memory management model :)
Syntax extension perhaps? If somebody comes up with something it would be awesome.
That could be done either by shifting game loop (yes, you can do that in Piston) so you have one function for the menu screen and one for the actual game. Imagine a time line where events happen. The events can be of different types, such as "update", "render", "pressed button" etc. Now, if you want the events to mean something else, you would like to have a function that transforms or delays the events in the time line. This is an event transformation. With AI behavior trees, you can make events mean something else, but if you don't know the exact behavior, then you don't know what exactly the events mean to the AI (because behavior trees are also a language). Since behaviors are declared before they are transformed to an executable state, it is very hard to tell what happens because of 3 reasons: 1) the state structure can be very complicated, and 2) behavior trees in Piston can have parallel semantics, and 3) they are not semantically checked at compile time. So while AI behavior are good at expressing event logic, they are not suitable for hard coded or "safe" logic. If we can wrap an event in a type that implements GenericEvent, it could override some of the events or "fake" new ones. Or perhaps you start up with one event type and end up with another. Perhaps events can come from a different source than the window, such as the network, where you want to build in some type safety. For example, never call a function "login" if the events coming from the user have not gone through the authentication process. You start out with some basic events for connecting with the user, and then you wrap or transform the event type until it got correct type. Just throwing some ideas :) There is an area of event transformation that is called Functional Reactional Programming (FRP). There have been several attempts at making it work with Rust, but due to some compiler bugs and borrowing issues, there have not been much success. Denommus knows a lot about this.
Maybe I'm just a crotchety old fart but I think the module system is more complicated and confusing then it needs to be. I'd much rather have a system similar to C#.
The impl of `GenericEvent` and the impl of the event trait should both agree on the type, even if it is not enforced by the type system. The `fail!` messages are there to tell when the event trait changes the type it casts to `&amp;Any`, or to catch programmer errors. When compiled with "-O2" it should be optimized away. If there are unit tests and the program passes `assert_event_trait` for every event, then it should never fail at runtime.
It's a Rust wrapper around a C library. It does require premake4 to run the C build, and glfw3 headers installed, to compile against. It uses Cargo's "build" feature, to call the makefile that builds the C library, then Cargo builds the Rust library and wraps it all up together. Better error indication from Cargo would be good. And I need to document more clearly I'm sure.
Aaand the interesting question is how is it all related to recompilation and its speed. Since non-isolated modules can't serve as "partial compilation units", doesn't Rust return to the C++ approach - recompiling the whole ~~transaltion unit~~ crate with lots of ~~headers~~ modules on every change?
This is cool! But I do have a few thoughts.. With traits, is it possible to do this? == trait World { fn split(&amp;self, count: uint); } struct MyWorld; impl World for MyWorld { fn split(&amp;self, count: uint = 3) { // Split the world... } } I think we should probably disallow this for explicitness's sake, however should we introduce some syntax to mark a field as default, otherwise how are we going to deal with default values of parametric traits? trait World&lt;T&gt; { fn split(&amp;self, count: T); //count needs to be default but I can't mark it as so! } struct MyWorld; impl&lt;uint&gt; World&lt;uint&gt; for MyWorld { fn split(&amp;self, count: uint = 3) { // Split the world... } } Also, is there a reason why we can't use `=` for specifying default arguments in function call? (Since we're doing that in function definition already) Instead of `split("hello,world", sep: ',');`, can we have `split("hello,world", sep=',')` I think it's more clear that way 
This is great thanks. FRP is big right now, I think Elm takes front seat on that. I also like event sourcing, where events transform state over time, like a play by play with a sequence of events.
You would call it with keyword syntax - `incr(y: 2)`.
I can't think of a way to catch/detect incorrect implementations at compile time with syntax extensions, but I suppose it should be possible to create a syntax extension to try make implementing the event traits correctly in an easy way. Something that can be used like: event! CustomEvent { fn from_arg(arg: ArgType) -&gt; Option&lt;Self&gt; { ... } fn custom(&amp;self, f: |ArgType|) { ... } } This can auto generate: trait CustomEvent { fn from_arg(arg: ArgType) -&gt; Option&lt;Self&gt;; fn custom(&amp;self, f: |ArgType|); } impl&lt;T: GenericEvent&gt; CustomEvent for T { fn from_arg(arg: ArgType) -&gt; Option&lt;T&gt; { let id = TypeId::of::&lt;Box&lt;CustomEvent&gt;&gt;(); GenericEvent::from_event(id, &amp;arg as &amp;Any) } fn custom(&amp;self, f: |ArgType|) { let id = TypeId::of::&lt;Box&lt;CustomEvent&gt;&gt;(); self.with_event(id, |any| { match any.downcast_ref::&lt;ArgType&gt;() { Some(&amp;arg) =&gt; f(arg), None =&gt; fail!("Expected `ArgType`") } }); } } 
Lame not seeing the slides in the video... but great talk Steve! Didn't catch this one.
Some events use two arguments, is it possible to wrap ArgType in a tuple if it does? Gfx generates a type alias for shader parameters. Perhaps we could use the same technique?
Could you give an example of event sourcing?
Yes, it should be possible to put the arguments and argument types in tuples in the generated code.
Just wanted to update and say that Ratio has been working great for me. Thanks!
Do you have an example where you would prefer named parameters instead of a struct sugar?
Even though it should never fail at runtime (if implemented correctly), I don't think this gets optimized away with "-O2", since the compiler wouldn't know at compile time if the downcast will succeed.
I don't like optional/keyword arguments. I'd much rather see exactly what arguments a function takes. Reading code where every function call may be missing several arguments that affect the behaviour of the function irks me. Especially in a systemsy-language like Rust. Considering that only a small minority of functions ever benefit from keyword arguments, and that structs with default values fulfil most of the needs (albeit in a slightly clunky way), I think it'd be a mistake to cater for this at the language level. But using macros to smooth out the struct-passing-method gets a thumbs up from me. 
I hope he updated that talk... Rust .10 with `~`
Looks good to me. What "unnecessary groupings" are you referring to?
When destructuring you can do 'let &amp;P { x, y } = self;'. Using the r-expression with same syntax to refer to a default value is confusing, because it means something entirely different. Personally I would like ', ..' at the end to annotate default values for the rest, to avoid accidentally forgetting it. It tells clearly "here are some default parameters". In case I want to use the default value explicitly, I would not mind writing 'y: Default::default()'. I don't want to look up in the documentation to find out whether there are extra arguments with defaults or not. It would be nice to have an indicator of what is going on. This is something I appreciate with the current syntax (don't need to look up for each function call). The thumb rule for default values is never use them except for obvious cases. If this is up to the library author to decide, then I expect lower quality of Rust libraries, because there is no right answer to what "obvious" is. The reason I find struct sugar appealing is it encourages a good pattern where functions with many argument take structs. It forces programmers to think about it instead of just putting in some default arguments and calling it a day. Later on in development you will benefit from refactoring of structs, while default arguments leave you a mess where you try to match up with the default values of structs. What if you change the default value in a struct member? You then need to update all default arguments. It would be brilliant if you were forced to put a struct there when being lazy. In addition I think there are many benefits with struct sugar, such as enum variants that wraps a struct, implicit return values and initialization of vectors.
Don't worry about "struct allocation". I'm sure it'll optimise to as fast as keyword arguments could be. 
&gt; I don't like optional/keyword arguments. I'd much rather see exactly what arguments a function takes. Reading code where every function call may be missing several arguments that affect the behaviour of the function irks me. Especially in a systemsy-language like Rust. So here you are opposing only optional arguments, keyword arguments don't make anything surprising. And I agree that using default arguments shouldn't be on by default, so that's why I suggested `,..` as a way to opt-in. &gt; I think it'd be a mistake to cater for this at the language level. And once again, I agree with you! If you read discussion thoroughly you'll see that this proposal is about struct initialization sugar. There's nothing new added into language except of rather simple sugar. And keyword arguments are only one of side-effects of adding such.
There's actually like five versions spread across two or three repos... I just gave another version of it on Tuesday. I think I've given... six or eight talks about Rust at conferences so far?
I did read it thoroughly. And I agree with the approach in the link. I never said I was against it. When I said it'd be a mistake to cater at the language level, I was alluding to an RFC that was proposed yesterday (which has since been closed).
&gt; I did read it thoroughly. And I agree with the approach in the link. I never said I was against it. Oh, so sorry then. But you didn't said you aren't against it too! And because of that I had a feeling that you are just hating optional arguments in general without reading this discussion.
I like that you get it as part of the sugar and not by making the language more complex. Not entirely sure if it will be ambigious with keyword arguments, but struct sugar will cover many use cases. At least struct sugar discourages some bad usage of default arguments.
I don't entirely understand the lint they've added for checking that values are rooted, but it sounds like it implies that Rust is not living up to its primary mission of memory safety. Can someone explain what's happening there?
No worries mate :)
Steve, how familiar are you with C++11? There's a couple of parts of this talk I think it would be safe to say are outdated in regard to C++. For example, @16:30 "the good old fashioned C++-style for-loop" is actually what C++ people would call the C-style for loop, heh. C++11 has the same range-based for-loop as everyone else. @20m "the unique_ptr is not truly memory safe". The std::unique_ptr of C++11 feels identical to Box&lt;T&gt; in every way, to me. I'm not sure how it's not memory safe. Granted, here we were talking about boost::unique_ptr which got fleshed out in C++11 as std::unique_ptr. At any rate, two quibbles. Otherwise great talk. 
"When a function calls another function, you need to list all the generic constraints" Why not create a trait like Num, which consists entirely of just trait constraints?
Yes. There's a reason I'm /u/steveklabnik**1** : I deleted my original Reddit account long ago. I like the Rust subreddit, but I really wish I could just never actually go to this site. You might enjoy https://github.com/rust-lang/rust/wiki/Operating-system-development
We could do that, but then you will be forced to implement all events and come up with names for collection of events, which is hard. One of the goals with the new design was allowing custom events defined outside Piston, which tomaka and I knew there was no obvious solution.
I guess I've misunderstood how `&amp;Any` (and trait objects in general) works :p.
My C++11 is pretty poor, to be honest. And yeah, I should have said "C style" :) I don't remember exactly what example I was thinking of with unique_ptr, but even with C++'s smart pointers, the language is overall not memory safe. I maybe shouldn't make specific claims, and keep it more general. For example, I believe that you can still end up invalidating a `unique_ptr` through certain function calls, in a similar way to https://github.com/steveklabnik/rust/blob/5765b5073f182a410a2398dadabce2927bdec559/src/doc/intro.md#ownership , no? Like, if I had a `uniqe_ptr` to that `std::vector`, this would still invalidate the reference? One thing I've really enjoyed about Rust is brushing up on more modern C++, I originally learned it around 1997, and then haven't touched it for years. Lots has changed...
It probably happens at LLVM level, where it looks at the address and not at the type. This makes it possible to optimize out things that seemingly makes no sense at type level (also LLVM might know stuff at lower level Rust does not know). Generics makes it possible to optimize for each type individually.
We've got a type (`JS&lt;T&gt;`) which is only safe as a field in heap-allocated types that are reachable by the GC. If you have a `JS&lt;T&gt;` on the stack somewhere, the GC doesn't know about it and any attempt to use it could trigger a use-after-free error (since the underlying value could have been GCed). The lint checks that any type annotated `must_root` doesn't appear in argument or local bindings unless specially annotated that it's allowed.
&gt; For example, I believe that you can still end up invalidating a unique_ptr through certain function calls, in a similar way to &lt;link&gt; , no? Like, if I had a uniqe_ptr to that std::vector, this would still invalidate the reference? If I'm understanding you correctly, no, you can't really break C++ like this. If you have a unique_ptr to the vector itself, pushing onto the vector won't invalidate the unique_ptr to the vector (it will only invalidate any references to the vector elements). Similarly, you cannot have a unique_ptr&lt;T&gt; to a vector&lt;T&gt; element since the vector owns that memory, not the unique_ptr. My understanding is that C++11 has roughly equal "ownership-safety" features (assuming you stick to the idiomatic bits). The problem is to get proper memory safety all around you need the second piece of access-control (ie lending and all that) to complete the puzzle and not let bad stuff leak out. Also, obviously, C++ can't enforce you only use the idiomatic, safe constructs. That's done only with convention. 
Since it's convenient, I end up reading some other reddits. Rust and Netrunner are the two where the community is really centered here, and I end up reading one or two others because if I'm here... That said, the defaults are absolute trash (so bummed /r/philosophy is a default now), and most of Reddit is a cesspool. I'd certainly never identify as a Redditor in public.
`let trimmed_str: &amp;str = string.as_slice().trim_chars([' ',','].as_slice());` For the record, I figured this out by reading http://doc.rust-lang.org/std/str/trait.StrSlice.html#tymethod.trim_chars and clicking on the `CharEq` link to see the list at the bottom of http://doc.rust-lang.org/std/str/trait.CharEq.html.
This is quite ugly, but it works! Thank you!
I think this should work: let string = "Foo".to_string(); let chars: &amp;[char] = [' ', ',']; let trimmed_str = string.as_slice().trim_chars(chars); Because of DST `[char, ..2]` no longer coerces to `&amp;[char]`, so you need to type annotate the slice, this is done with the `chars` variable.
Ooh, this looks much nicer. Will commit/push now.
Yeah, that wasn't clearly expressed. I meant to ask if there's some alternative approach to what I provided above that I hadn't thought of that would be more appropriate.
&gt; @20m "the unique_ptr is not truly memory safe". The std::unique_ptr of C++11 feels identical to Box&lt;T&gt; in every way, to me. I'm not sure how it's not memory safe. Granted, here we were talking about boost::unique_ptr which got fleshed out in C++11 as std::unique_ptr. unique_ptr&lt;T&gt; foo = ...; take_by_value(std::move(foo)); use_it_again(foo); // use after move! There's also the standard C++ problems of taking a reference into the `unique_ptr` that is not fundamentally linked to it, so the reference can be kept around even after the `unique_ptr` is deallocated.
Well, `&amp;Any` is a trait object. The generics here is used only to generate a typeid to match against the typeid that's gotten from a method call on the `Any`, which I presumed to have been called through a vtable, but it seems like LLVM can optimize away a vtable lookup at least some of the time. I wonder if this might not get optimized away if the event is implemented/used in a different crate.
Here's a `macro_rules!` version of what I suggested (I'm too lazy to hack up a syntax extension :p). It doesn't have the same syntax due to the limitations of `macro_rules!`. I've not tested it with `piston::event::GenericEvent`, but it compiles with a mock version of the trait: macro_rules! maybe_tuple { ($name0:ident,$($name:ident),+) =&gt; {($name0,$($name),+)}; ($name:ident) =&gt; {$name}; } macro_rules! event { ( $trait_name:ident { fn $from:ident($($arg:ident: $arg_type1:ty),+) -&gt; Option&lt;Self&gt; { ... } fn $with:ident(&amp;self, $closure:ident: |$($arg_type2:ty),+|) { ... } } ) =&gt; { trait $trait_name { fn $from($($arg: $arg_type1),+) -&gt; Option&lt;Self&gt;; fn $with(&amp;self, $closure: |$($arg_type2),+|); } impl&lt;T:GenericEvent&gt; $trait_name for T { fn $from($($arg: $arg_type1),+) -&gt; Option&lt;T&gt; { use std::intrinsics::TypeId; let id = TypeId::of::&lt;Box&lt;$trait_name&gt;&gt;(); GenericEvent::from_event(id, &amp;($($arg),+) as &amp;std::any::Any) } fn $with(&amp;self, $closure: |$($arg_type2),+|) { use std::intrinsics::TypeId; let id = TypeId::of::&lt;Box&lt;$trait_name&gt;&gt;(); self.with_event(id, |any| { use std::any::AnyRefExt; match any.downcast_ref::&lt;($($arg_type1),+)&gt;() { Some(&amp;maybe_tuple!($($arg),+)) =&gt; $closure($($arg),+), None =&gt; fail!(concat!("Expected `",stringify!(($($arg_type1),+)),"`")) } }); } } } } event! { CustomEvent { fn from_arg(arg: int) -&gt; Option&lt;Self&gt; { ... } fn custom(&amp;self, f: |int|) { ... } } } event! { CustomEvent2 { fn from_arg(arg: int, arg2: f32) -&gt; Option&lt;Self&gt; { ... } fn custom(&amp;self, f: |int, f32|) { ... } } } 
This is a small change that affects two methods that are rarely used in the extant codebase. Nobody felt that it would be controversial and the implication that we were deliberately attempting to sidestep community consensus is incorrect.
Neither of those are examples of unsafety in the ownership semantics of `unique_ptr` but instead are examples of unsafety in C++ itself. The first case is a dereference of a null pointer (assuming 'use_it_again' actually dereferences it... if it doesn't, this is perfectly safe), and the second case is pulling the value out of the unique_ptr and doing unsafe things with it (this is a form access safety, not ownership). In order to have (enforced, checked) complete memory safety you need: 1. strong ownership semantics w/ lifetimes 2. strong access semantics w/ lifetimes 3. no other (unsafe) semantics w/ compiler enforcement My point is that unique_ptr is exactly as good as Box&lt;T&gt; for #1, but of course C++ fails miserably on #2 and #3 elsewhere in the language. If C++ had the rest of the language support for #2 and #3, unique_ptr would serve it's purpose as #1 just fine. Similarly if the rest of the Rust language didn't have #2 or #3, you could do similarly bad things with a Box&lt;T&gt; (namely pull the value out and do unsafe things with it). C++ has neither #2 or #3 so there are plenty of ways that don't involve ownership to break memory safety. In place of #2 and #3, C++11 programmers use convention instead of compilers with all the usual caveats that apply.
The library stabilization process is intended to clean up the libraries by clarifying naming, enhancing consistency, and removing duplicate functionality. That is the process that was followed here. Minor changes in those categories (including the temoval of duplicate functionality) that result from the process, such as these changes, are not considered RFC material. That ensures a reasonable balance between community input and maintaining a healthy development pace.
I think this was just a miscommunication in the deprecation message. It should suggest replacing `v.unsafe_set(i, x)` with `*v.unsafe_mut(i) = x`. There is no intent or plan to make writing unsafe code less ergonomic. This is purely a matter of cleaning up redundant APIs.
I'm not a fan of open-ended namespacing. I *like* being able to follow a name back to its source easily. If it weren't for that, I'd have probably gone stark raving mad trying to implement procedural macros. Preemptive reply to "but you just organise your source with one file per class in folders" because that *always* gets brought up: yes, until you have to look at code that doesn't, and *then* you want to shoot whoever added open namespaces to the language. :D
We should have docs on this. Care to open an issue? I'll get to it tomorrow 
**Edit**: just realised this wasn't posted by Steve. Oops. On the slide about segfaults, you say that `&amp;str` cannot be dereferenced because if it was, it would cause a segfault. I thought the reason it cannot be dereferenced was that `str` is unsized. But if you fixed that, you couldn't assign to it because *s would be `str` and a string literal is a `&amp;str`... I'm confused now. :S
&gt; For example, creating a fixed-size array of collections is not possible without mem::uninitialized and init_elem. unsafe { let mut array: [T, .. n] = mem::uninitialized(); for place in array.mut_iter() { ptr::write(place, T::new()); } }
The quote was "the unique_ptr is not truly memory safe" (nothing about ownership*), and both of my examples demonstrate how unique_ptr is not memory safe. It doesn't really matter that that's a problem with the rest of C++ (that's definitely not an argument in support of C++ in any case), `unique_ptr` is still not safe. *I haven't watched the talk so I don't know if there was further discussion about ownership in particular. Also, I contest that unique_ptr has strong ownership semantics: you can freely use a moved-from unique_ptr value (after moving it), meaning the ownership of the pointer isn't actually being tracked. If it didn't lead to a null pointer dereference this wouldn't be a memory safety problem, but it does, and dereferencing a null pointer is undefined behaviour.
It's for [managing Rust objects with the SpiderMonkey GC](https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/), which is well outside the warranty on Rust's built-in memory safety :) I would love rustc to generate stack maps for third-party garbage collectors, but it's way off on the horizon.
I suppose stuff like this needs to go into the unsafe guide.
Done.
It actually means that Rust is doing much more than living up to its mission of memory safety :) Here, we're trying to provide compile time safety by objects managed by a C runtime. Not something that I would have expected from Rust. If you look at the [post](https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/) I linked to, we use Spidermonkey's GC for DOM objects. Since this isn't a GC tied with Rust's runtime, we need to hook in to SM and let it know when we are using a DOM object -- it would be bad if a DOM object was deleted by the GC while we were using it in Rust code. So we have a way of rooting DOM pointers, which tells the SM GC to back off for a bit until it's unrooted. This is all accomplished by the miracles of the type system (`JSRef&lt;T&gt;`/`Root&lt;T&gt;`, — there are lifetime checks via `ContravariantLifetime` and custom destructors among other things that keep it safe) However, there is a certain type of pointer -- `JS&lt;T&gt;` which unfortunately has to be exposed publicly to the rest of Servo's code. This pointer is meant only to be used to store references to related JS objects inside a DOM struct* (eg `Node`s in a `NodeIterator` or `Window` in a `Document` or `XMLHttpRequestUpload` in `XMLHttpRequest`), and for constructors. Since we need to be able to use this pointer for DOM struct fields, it has to be public, which means that it can be used elsewhere. Which is bad. The type system doesn't really let us constrain _where_ a type is used, so till that PR we were mostly following a set of rules: "use `JS&lt;T&gt;` for DOM struct fields, `JSRef&lt;T&gt;` for local pointers on the stack, and `Temporary&lt;T&gt;` to return from methods" (`Temporary` is a type that can't be used unless rooted) However, Rust lets us define lints that can make these rules more concrete. Which is what that PR does, it finds out when `JS&lt;T&gt;` (or any other `#[must_root]` value) is used on the stack (via a `let` binding or similar), and throws an error. It's still not watertight (I believe a `Vec&lt;JS&lt;T&gt;&gt;` or perhaps `Option&lt;JS&lt;T&gt;&gt;` would get around it, though it would be hard to instantiate without triggering the lint), but that's something that can be patched up later and isn't too crucial right now — also is a bit of effort in getting all those side cases out without resorting to a full-blown use of `check_ty` :) I found it pretty amazing that Rust not only lets you get pretty strict safety guarantees for your own abstractions if you type things correctly (eg types like `Box` and `Vec` could be easily defined with the same safety guarantees out of the compiler), it also lets you define pretty arbitrary compile time checks in case the type system falls short of providing you the tools to define these safety guarantees. *We tell SM that a DOM object internally contains a reference to another DOM object using trace hooks via`JSTraceable`, which is explained in the blog post, though the implementation [has shifted from using `Encodable` since then](https://github.com/servo/servo/pull/3468) 
So the goal is to replace void func(int arg1 = 0, char arg2 = ' ', char* arg3 = "") { // insert C++ here } with struct FuncArgs { arg1: int = 0; arg2: char = ' '; arg3: &amp;str = ""; // Yes, I know... } fn func(args: FuncArgs) { // insert Rust here } ?
DST landed?
&gt; The value that's been moved isn't available after it's been moved. The ownership of the original object is preserved and its value is in a new location. There is still one and only one owner. It won't be double freed. It hasn't been leaked. You are using a new value, not the old one. Because you can use the new value unsafely has nothing to do unique_ptrs ownership semantics and everything to do with the value itself having unsafe methods of accessing it or using it. I was careful to say "unique_ptr value", I'm *not* refering to the `T` stored inside, i.e. the actual `unique_ptr` thing can be used after it is moved. &gt; This is just you repeating the same argument that C++ has null pointers and therefore everything is unsafe. This isn't relevant for all the same reasons. No, it is relevant. `unique_ptr` could have had an implementation this avoids this memory safety problem (check if it is null and abort/throw an exception, rather than just dereferencing the pointer directly), but this was avoided, prioritising performance over correctness.
large chunks of it have, but it's not totally done yet.
I had more snide comments, but realised that 0.10 was, like, a bazillion years ago, and the talk has probably changed enough that it's not worth it. I did find comments along the lines of "this is the final syntax, *thank god*" entertaining, though. :P
Heh. Yeah, this was so long ago...
&gt; I was careful to say "unique_ptr value", I'm not refering to the T stored inside, i.e. the actual unique_ptr thing can be used after it is moved. There is absolutely nothing unsafe about using the unique_ptr object itself after it's been moved from. It's state is guaranteed by the C++ standard. The old value has been moved and there is a new value. There is still one owner. There will be no leak, nor double free. There is only unsafety is around using the T in an unsafe way (note: this is true regardless of whether it's been moved or not... your 'example' has a bunch of useless dressing around what is a simple creation and dereferencing of a null pointer) &gt; unique_ptr could have had an implementation this avoids this memory safety problem (check if it is null and abort/throw an exception, rather than just dereferencing the pointer directly), but this was avoided, prioritising performance over correctness. unique_ptr's job is ownership semantics. This has nothing to do with ownership semantics. What you wrote here is also 100% true of raw pointers, too. unique_ptr's presence in this situation is incidental and is a red herring.
http://jvmsoup.com/2014/06/18/make-business-logic-simple-using-event-sourcing-and-a-lot-of-ram/ Above states it better and with graphics, also Martin Fowler has a great article on it. It's sort of summed up as a sequence of events that affect state. So instead of setting state based on an event such as going from x=1 to x=2, you would do x+=1. the event is not associated with the current value of x, just what would be applied to it. One benefit is you could essentially rerun or rewind events, as well as snapshot state along the way, like game saves. I've yet to implement it with anything, but I intend to at some point
Speaking of struct initializers, it could be great to do something like the following. #deriving(From2) struct Foo { x: uint, s: string } let x: Foo = from(2,"Bob").unwrap() let y: Foo = from("3","Bob").unwrap() // Calls from::&lt;uint,str&gt;("-3") to work let z: Option&lt;Foo&gt;= from(-3,"Bob"); // is None because from::&lt;uint,int&gt;(-3) is None let a = Foo { x: from("2").unwrap(), s: from(Bob).unwrap() } 
&gt; That said, the defaults are absolute trash (so bummed /r/philosophy is a default now), and most of Reddit is a cesspool. I'd certainly never identify as a Redditor in public. True, but I'm not aware of anywhere like "reddit the ~~good~~ subreddit parts" elsewhere on the internet. Individual forms can be nice but I miss threaded, collapsible comments, and not needing to sign up for tons of disparate forums instead of once. Reddit has a seriously wicked long tail of good subreddits, and a handful of them even have sane communities. 
I think it is sad you're being downvoted. I'm appalled at the Rust community, quite frankly, for being so dismissive of well-thought-out discussion and effectively shitting on anybody that doesn't follow the current "cool-kids" consensus. Even if what you propose isn't accepted why should you be voted into oblivion? You encourage a spirited debate. I can see Rust potentially being a great language that is ignored at large because of the poor community spirit.
Now we could have method *and* struct defaults. And perhaps, there is a way to unify them - in fact, the argument list of a method is but an implicit struct, isn't it?
Unfortunately these instructions didn't work for Cargo. I've been round the loop trying to get it to work several times now, and give up. I may try again when Cargo is integrated into the installer, but it doesn't inspire confidence in a project aiming for mainstream adoption. (I never had this problem installing Go, Dart, or many other languages, except for more esoteric ones such as Self)
what i'm findings the compulsory namespacing feels like overkill; you have functions organised under traits and types aswell. something like inherit-use or resolving the problems with circular glob imports would help. maybe it would be nice if structs could be nested like in C++ (whilst combined with rusts' more open way of adding methods) 
&gt; The std::unique_ptr of C++11 feels identical to Box&lt;T&gt; in every way, to me. Box&lt;T&gt; has both the ownership semantics and is memory safe, accessing a unique_ptr after it's been moved is possible and it's therefore not memory safe. I'm really not seeing what you're getting at. /u/dbaupp 's point was that Box&lt;T&gt; has safe memory semantics but unique_ptr doesn't, you're agreeing with him.
Thanks! I opened up an issue here https://github.com/PistonDevelopers/event/issues/196
&gt; including 'this sucks, re-write it again.' Rule #6!
Do you have a github of the project to check ?
Yes, the relative vs absolute thing needs to go in, thank you.
Haha yes, I would expect 'this sucks' to expand to a real criticism.
&gt; (it will only invalidate any references to the vector elements). Ah yes, duh.
Well, C++ isn't super bad with memory safety. Many implementations support a debug mode which switches to a standard library implementation that includes lots of checking for iterator invalidation and index bounds on things like `vector&lt;T&gt;::operator[]` and `array&lt;T,N&gt;::operator[]`. Catching some of the errors at runtime in testing is better than nothing. But these debug modes are slow and never used in production code. It's still possible to create and hold on to references to temporaries for too long or to have a kind of disagreement between different parts of the code about whether something should be considered "borrowed" or not. It seems most of the memory-safety-related security issues are "use-after-free" errors in which someone expected something to live long enough. But it depends on the kind of program you're writing. In my domain, these kinds of errors come up almost never because I mostly don't need "long-time borrows". And sometimes if you need "long-time borrows" you might opt for shared ownership/reference counting to avoid destroying something too early. In summary, the "only" real advantage of Rust over C++ w.r.t. memory safety is the lifetime system and the borrow checker which prevents you from holding on to a reference to something that does not exist anymore. And how big this advantage is does depend on the application domain and whether you need "long-time borrows" or not. So, if you want to convince a C++ person that Rust has some cool features w.r.t. memory safety, I think it's important to not oversell Rust and to avoid exaggerations about the "badness" of C++. Specifically, "use-after-free" errors are errors not everybody has to deal with depending on the application domain. Also, with a complex language like C++, some C++ zealots are quick to doubt your competence. And if they do, they're probably thinking of bad code written by a C programmer that just uses a C++ compiler instead of a C compiler without leveraging the C++ language "properly". 
I was asking myself the same thing. I was about to complain about the author not dealing with the details about memory management. But then I noticed the line you quoted. Let's wait and see what he comes up with in future posts... &gt; it actually doesn't look safe as it suggests it is in the title? Well, creating memory leaks is probably less bad w.r.t. safety than allowing users to manually destroy things without guaranteeing that use-after-free errors are impossible.
I think that overall, C++ _is_ that bad, but I agree with you that C++ programmers don't think that it's that bad ;) The endless stream of security vulnerabilities from dangling pointers, iterator invalidation, stack overflows, etc _to me_ say that it is truly a problem. And the answer is, as you say, "well, bad programmers write bad code," the issue is that we all are bad programmers at times. One slip up, and you've introduced a vulnerability. Not to mention code written by someone who's well meaning but less experienced. What "proper" leverage of C++ is has changed four or five times over the last five decades, as holes are found in the last "proper" style. I think of the situation as being very similar to Ruby with regards to performance. Rubyists will tell you that Ruby performance doesn't matter. And yeah, in many ways, it doesn't. But then you have a million users, and it turns out that yes, Ruby really _is_ terrible at perforamnce, and it _does_ matter. But everyone still says that it doesn't, except sometimes.
Another aspect that confused me was organizing files. If you use cargo, then things are automatically set up, but it would be really nice if you could show how to set it up using a different tree-layout. 
Why wouldn't you just match on the result instead of unpacking it into a tuple first? I'm not a rust user so I don't know if that's even possible.
The rules are the same, just the name of src/lib.rs and src/main.rs are cargo related. I'll make a note.
argument-structs and keyword/default arguments handle different use cases. keyword/default arguments are useful for functions with few parameters and easy variations, e.g. a function with 2 parameters and one has a clear default, saving you naming another helper function. As such they reduce the number of entities you need to create and name, making navigation &amp; documentation easier. Argument structs are useful for large numbers of parameters, i.e. complex setup. we should have both, IMO.
Not yet, my evil plan is shelved until better (more free time, less active projects) times.
&gt; What "proper" leverage of C++ is has changed four or five times I would regard this as an exaggeration. But hey, I'm not one of those that still need convincing. :)
What is the reasoning behind implementing readln as a macro, instead of a function?
Please don't force your readers to use `cargo new`. Somebody may even think that modules are cargo's, not rust's, feature if you won't note that cargo step is only for convenience! And I guess there are other people like me, which just don't like when simplicity of something is being unnecessarily hidden behind unrelated layers.
Cargo is the official tool, and so all documentation assumes that you're using Cargo by default.
I'm not the author, but `println!` is a macro because then you get compile-time typechecking of the format string. I'm assuming the same motivation is there.
Multiple libraries to do the same thing are healthy! Don't be discouraged.
But there appears to be no such thing as a format string with readln, only scan{,ln}. In fact, it seems to not have arguments at all. 
Oh! Yes, you're right, i'm unsure about readln, I was thinking about scanln.
Please continue to do so, the library here presented has made choices during its implementation: - `{u8}}}` is not viable (parsed as `{`, `u8`, `}}`, `}`) - `{u8}` will be fed `0xffff` without signalling the overflow - ... Depending on one's needs, this might not be suitable, so having alternatives would be good; and then we'll see which is more popular.
Is it possible for `scan! ` to allow conversion from any type that `impl`s `FromString`? (Is that still a trait? Or is it `FromStr`?)
Not as many Rust references as the first talk, but still relevant for the outsider view on the language. You might enjoy watching the direction his project is going, as well.
Hrmm. I'm just seeing the title slide, nothing actually plays :/
It shows that slide while buffering, here. But for a couple of seconds, at most. :/
Added to the calendar: https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com
For instance, if you're not using cargo but a Makefile system. 
I'd like to have `readln()` and `println()` functions in the prelude that don't require allocating a handle to stdin or stdout, respectively. The `print!()` and `println!()` macros already do non-allocating writes to stdout using a private task-local handle. I don't see what the problem is with giving users access to that, and creating an equivalent with stdin.
I like some of his ideas but I can't help but feel like maybe we just need better IDE's to help with refactoring instead of designing a language grammar around the fact that IDE's suck at their job. He doesn't like big idea languages but I can't help but feel like he is creating a big idea language around better code malleability. Not saying that is a bad thing necessarily. An easier to parse language would probably help to make better refactoring options in IDE's. 
There are big ints in `libnum`, but they aren't great in terms of performance. It's probably be better to find some gmp bindings (I'm sure some exist out there).
Here's the references about Rust: at 40:00 he says that Rust lambda functions are weird at 1:14:00 he is complaing about not able to use globals
Really nice. :) The only thing I don't really care about is the example. It has this implicit connotation of "exchangeability" and/or "taxonomy" that might give new programmers the wrong idea about what modules are used for.
@thestinger maintains [rust bindings to gmp](https://github.com/thestinger/rust-gmp).
It's more complicated than that. Libnum does too much allocation for lots of things.
No, they can't be ported to it. It needs to be developed independently. GMP uses algorithms with superior time complexity and the implementations are incredible in terms of constant costs. Competing with it means writing more than one multiplication algorithm so the best one for a given size can be selected, along with a lot of hand-written assembly for different CPU revisions.
Some feedback: * I personally remember learning about Rust's modules as a C++ programmer who had never fully learned the module system of any other language (I still have only a vague idea of how Java's, Python's and D's module systems work). You should assume that your reader is ignorant; even people who are decently experienced systems programmers can have unexpected gaps in their knowledge. * You don't explain what a "module" is, before you start describing how they interact with one another and with the crate system, and how they're defined. This makes the first two subsections a bit disorientating. * Your example modules (`english::greetings`, etc.) don't map onto any real-world usage. This makes it harder for your reader to get a handle on what the module system "should" be used for. * You introduce the syntax for module definition (`mod foo { }`) and the syntax for out-of-line module definition (`mod foo;`) without ever making it obvious that the whole point of modules is to allow you to define items (conceptually, "parts of your program") between the curly braces. I think your early examples should be more "real-world" in this respect. * Your terminology is a little intimidating. By the second subsection, you're already talking about "referring to modules" using `::`, "namespacing" and "name conflicts". These ideas should be introduced explicitly and carefully, if they're to be covered at all. Perhaps a subsection dedicated to "how to unambiguously name items in other modules", shortly followed by "how `use` allows you to make these long clunky pathnames easier to specify"? * You talk about "public and private items" before introducing the `use` statement. I think knowing about the latter would make it much easier to grok the former. * IIRC, the old guide emphasised strongly that `mod x;` is completely functionally identical to `mod x { &lt;contents of x.rs&gt; }`, and I remember finding this to be a memorable and informative description of how out-of-line module definitions work. I'd recommend trying to convey something similar. In general, although I'm sorry to be so critical, I think it's too easy for an ignorant person reading this guide to completely lose the thread of your explanation.
Main points: * Factoring can make stateful code harder to reason about. * Pure functions don’t suffer from that problem, but in games, a lot of code is stateful. * Straight-line code is easier to understand than many functions, even if that means writing monolithic functions. * Local functions and local scopes are a good middle ground. * Lambdas aren’t quite as good as local functions, because they need to allocate space somewhere for their closures. * We want syntactic consistency between local/global &amp; named/unnamed functions so that moving code around is easier. * Simpler, more consistent languages make programmers happier, and that’s a good thing. * An explicit way to capture variables into a lambda is nice; why not also allow that for local blocks? Then the compiler can tell you which variables you need to consider when factoring. * Capture helps track data dependencies, which are important in concurrent code. * Capture on functions at global scope could be used to reason about global state. * Opt-in transitive capture would require that a function specify not only the values it uses, but also the values used by those functions it calls. * Explicating data dependencies encourages making impure functions “more like” pure functions. * Rather than outlawing global data, we should add language features to make it easier to use global data correctly. * Languages should understand that, and how, programs mature over time. * Safety is valuable but excessively safe defaults slow down development unacceptably. At the risk of sounding like an advertisement, the language that I’m working on, [Kitten](https://github.com/evincarofautumn/kitten) is intended to address many of these issues. Ease of factoring is a core principle of the language, static types and side-effect checking help keep the code easy to reason about, I’m working on mechanisms for managing resources and data dependencies, and so on. Some Rustaceans have expressed interest in it, because it has very similar goals to Rust, though with a rather different approach. At this point it’s a spare-time research project with delusions of utility, but my fellow language geeks may like to keep an eye on it. :) 
[Rust isn't context-free](https://github.com/rust-lang/rust/blob/master/src/grammar/raw-string-literal-ambiguity.md)
Sidebar, #5, #6.
Please observe Rule 6.
Critical is good!!! Unlike the main guide, the topic guides assume a much more advanced reader. This doesn't mean that it shouldn't privide the right information. It seems to me like most of this is saying that I assumed _too_ much, rather than the right level. This is really good feedback because that balance is so hard to strike, and you're right that it could have basic information. That's the trick!
I wouldn't mind a better one, it's hard to come up with something that has no functionality other than showing off modules.
Some interesting ideas about refactoring code. In particular, his note about how factoring large blocks of code into distinct functions can cause confusion and safety issues really resonated with me. I ran into some issues with that when implementing BTree, where I refactored a bunch of things out, but then it made it possible for the function to be called elsewhere and I had to add asserts, discussion of invariants, and/or mark it unsafe. It would be interesting to consider providing a #[part_of(foo)] declaration on a function, to assert that it should only be called by the function `foo`. In this way you can split out logic into free-standing functions, while specifying that they aren't intended to be used generally. I realize that you can just declare the function inside the parent function, but I find that noisier than splitting it out as a free-standing function. 
I think with the current design it lazily parses stuff but once parsed you can't go back. It's possible that this can be worked around, but we've had quite a bit of trouble with the strongly typed headers in rust-http. I love the idea, just that I'm not sure if we really want that. We haven't decided against Teepee yet, but some members of the team found it a bit "over engineered" -- too much for our needs, basically.
Is there a reason rust uses `||` for closures as opposed to `()`? It never occurred to me that `()` could be used and still be clear. Like below: let empty = || {}; let empty = () {}; I'm not proposing any change by the way. I'm just curious what the reasoning is.
33:00 "functions/methods.. and there's good reason to think we should never have got on the method train" +1000000000 r.e. refactorability. its one of my biggest gripes in C++. 
The parser doesn't know when it needs to parse a pattern or an expression with `(`.
Because functions and closures are different in Rust. Closures have an environment and are therefore two words (and moreover, come with lifetime bounds); functions do not. The difference is important in systems programming.
You can also use mutable globals with a mutex around them (or at least, if it doesn't work today, it is planned). We don't disallow mutable globals in safe code for philosophical reasons; we disallow mutable globals because it would be totally memory-unsafe if we didn't.
If we only allow a maximum of, say, 5 hashes, could we make the language context free?
`String` does not yet implement `Slice`.
I think so. You could represent raw string literals as S = r"A_0" A_0 = #A_1# | B_1 A_1 = #A_2# | B_2 A_2 = #A_3# | B_3 A_3 = #A_4# | B_4 A_4 = #B_5# B_1 = (regex for anything without "#) B_2 = (regex for anything without "##) B_3 = (regex for anything without "###) B_4 = (regex for anything without "####) B_5 = (regex for anything without "#####) 
Did you ever consider something like Haskell's \\ (which looks a bit like the lambda symbol)?
Pretty sure I figured out what's wrong. 32-bit Rust binaries (like the Cargo you downloaded from crates.io) require libgcc_s_dw2-1.dll, 64-bit Rust binaries require libgcc_s_seh-1.dll. If you install the 64-bit Rust compiler, only libgcc_s_seh-1.dll is available, so (32-bit) Cargo from crates.io fails to run. Fortunately, there are finally 64-bit builds of Cargo available, but they're not up on crates.io yet. Grab them from https://github.com/rust-lang/cargo See issue: https://github.com/rust-lang/cargo/issues/639
Ah okay, that makes sense.
Thanks. I will try tomorrow.
There's also [rust-bignum](https://github.com/jsanders/rust-bignum), which tries to be a drop-in replacement for `libnum`'s bigints, written in terms of `rust-gmp`.
I think it's just that games have their own special set of requirements, which can conflict with other domains - and games haven't traditionally been important enough to drive a language already. The extra syntax for some raw pointer tricks (e.g. double casting) seems to indicate a philosophical difference , no doubt you have a good reason for it from your experiences/domains... but he covers in the other talk how 'game developers aren't afraid of pointers' also see the 'data-oriented' stuff . I ran into this whilst trying to use the common 'blob' techniques for minimising allocations, stuff I've been used to doing since 1995. (you can write games with *no* dynamic allocation, just pooled entities and precompiled assets.) He talks quite a bit about refactorability in this particular talk.. a lot of game coding is exploratory, you're subject to rapidly changing design demands. You can tolerate bugs &amp; suboptimal performance whilst experimenting .. then go back and fix/optimize once the design stabilises. I agree with most of what he's saying but not all; I'm happy with the way rust does globals for example, after the experience of dealing with concurrency. I'm also a big fan of Rusts' lambda syntax, its makes those small single expression closures nice enough (without needing currying or yet another syntax) overall listening to these couple of talks confirms for me why my experience is still a bit ambiguous... I'm not just going mad or suffering 'comfort zone issues'. I'm also pleased to see he thinks C++ is worth replacing, again confirming I wasn't going crazy looking at Rust in the first place. my ideal outcome would be for Rust to get forked or adapted.. unless perhaps 'blow-lang' leads to something with an easier migration path from C++ ... something that can be gradually inserted back into C++ projects, like how Swift interoperates closely with ObjC in the apple-verse. 
~~GPL.~~ Licensing.
This is a bit strong, since that proof just concerns the lexical grammar, which I would say doesn't matter how convoluted it is, and not the parser grammar which is context free. When people complain about C/C++ being non-context free they refer to mixing of type checking and parsing, which Rust avoids doing.
He was mostly talking about lambdas, though. You start with a big function body and, given the necessity, create a few local lambdas-- just to avoid exposing a new separate function, but I guess there'd be no difference in implementation here. It would only be a closure if you specifically close-over variables, but even then it still depends on the variables and closure scope. If you only reference local variables in a local closure, there's no need to allocate a special context.
I was surprised not to have seen links to these videos on this subreddit (...or maybe I just missed them). Due to the lack of exacting specifications on current Rust semantics, sometimes I'm left wondering how to solve a compiler error. These videos have helped me understand the rapidly evolving situation. We should link to them on the Rust site.
&gt; It's not a build system, rustc does that on its own and when it doesn't, the docs helpfully point you towards make `rustc` definitely does not automatically build dependencies, and manual makefiles are not a nice solution (where is this stated? Our docs should be updated). &gt; It's not a package manager, there's no package database Yet. It's a work-in-progress. &gt; What possible use does it have to a newbie, as compared to a two-line shell script they can write from rustc --help? Not having to read `rustc --help`. It also handles e.g. `cargo doc` and `cargo test`, which require more makefile effort. Furthermore, it works on windows without having to have `make` installed. &gt; Sure, once you've used it long enough to see your dependencies break, it's awesome. But before that? Not even break. As soon as you just *have* any dependencies it's awesome. I know I certainly prefer writing `[dependencies.foo] git = ...` and letting `cargo` fetch and build everything, rather than fiddling with git submodules and working out how to build the dep to the right place/link against it. (And then handle optimisation flags etc.)
GMP is actually LGPL, but, in any case, [licensing *is* the main problem with putting it in the main distribution](http://www.reddit.com/r/rust/comments/1xcq1q/c_gcc_vs_rust_wtf/cfa79me).
Yeah, we have different ideas of what big ideas are. Just because a big idea has guaranteed benefits makes it no smaller to me. As in, the restrictions an idea imposes on the general use case is what make it a big idea. I love Rust, but these kinds of statements sound too much like gospel. "You should use immutable data" is philosophical in your eyes-- there are *guaranteed properties* about them, and there are people that really believe a purely functional language have *definite* benefits. It hasn't been proven. Likewise, "guaranteed memory security" might not sound so much as a de facto benefit when using other metrics. As a methodology, it also hasn't been proven. There would be no big ideas given arbitrary metrics.
How about, instead of just `fn` *items*, also having a form for `fn` *literals*? For instance: let f = fn(n) n + 5; println!("nein: {}", f(4)) 
&gt; Theoretically it could be ported, but it would be an absolutely huge investment of energy I meant that it can't be directly ported to Rust's standard libraries due to the license. The result would be `unsafe` LGPL Rust code without an advantage over the original project. Recreating it without the ability to copy the GMP code would be an enormous project and it would be *expensive*, because you would need a diverse set of hardware to benchmark / test the assembly on.
I don't think there are guaranteed properties about immutability on the program as a whole. Even purely functional languages like Haskell have a way to do mutability and interact with the outside world (the IO monad). &gt; Likewise, "guaranteed memory security" might not sound so much as a de facto benefit when using other metrics. As a methodology, it also hasn't been proven. I don't know what that means. Memory safety certainly has been proven with dynamic and managed languages; you don't see use-after-free exploits targeting, say, Ruby nearly as often (and, given an abstract model of Ruby, it's likely you *can't* get these kinds of exploits—as in, provably—and this has been proven for some languages like Standard ML). That's a fact, and it comes out of memory safety.
You can nest an `fn` inside an `fn`. The nested function is scoped inside its enclosing block but is otherwise identical to a function declaration at the top level; in particular, it's not a closure and doesn't capture variables from enclosing scopes. 
&gt; Even purely functional languages like Haskell have a way to do mutability and interact with the outside world (the IO monad) But they are encapsulated, as is `unsafe`. On the second point, I wasn't very clear: of course memory safety is desirable. But you can't really compare Rust's approach to managed (mostly GCed) languages-- what hasn't been "proven" is if Rust's implementation *is always worth it* for non-critical applications. Not that it needs to be proven or always worth it.. But if we're gonna say it's not a big idea *because* of it, it needs to be bullet-proof. Sorry I didn't touch the overhead response in my previous answer: I don't really think the idea is to unify them. Blow seemed to be talking mostly about lambdas, but couldn't the lambda/closure dichotomy be determined statically?
Nobody's proposed it yet, but I wouldn't be opposed.
&gt; Blow seemed to be talking mostly about lambdas, but couldn't the lambda/closure dichotomy be determined statically? It could, but one of the design goals of Rust is to make things that have different machine-level semantics look different.
I come from other languages where you don't have those problems. Because GC is available, etc. I still don't see a really good argument against being consistent with `fn`/closure declaration fn (x: float ) -&gt; float {x*x} |x: float | -&gt; float {x*x} // I'm assuming that slide |x:float|-&gt; float x*x is correct or even omitting the float return type entirely fn (x:float) -&gt; x*x |x: float | -&gt; x*x I'm might be missing some case, but why not allow interfering of return types in simple cases. 
But then expressions declared with `fn` would not have type `fn`. That would be confusing, wouldn't it?
This is not yet implemented, was my impression.
Haven't watched the talk yet, but the past few days I've been basically adding lifetimes to ~4k lines of librustc's code, and I think that having methods on context types would be so much more ergonomic than dealing with free functions. Specifying genrics only once is great, and being able to write `Self` in an impl would help further. The main issue is actually identation, you'd want to maybe do the same thing that C++ headers do for namespaces: don't indent inside them, at least if it spans an entire file.
Oh, I guess it's not a problem for that project, then.
Isn't uniform function call syntax (UFCS) solving the issue? `a.x(b, c)` is just a sugar for `x(a, b, c)`
Quick links to some slides/talks mentioned in the video * http://www.slideshare.net/cellperformance/data-oriented-design-and-c * http://mollyrocket.com/casey/stream_0019.html * http://t.co/K5e0vv4T4w
I don't know to what extent the audience for this guide is people from other languages, but something /u/rime-frost hinted at is that modules are actually pretty weird to people who have mostly lived in C++ and C# land (and I suppose with Go as well). My understanding of this explanation of Rust modules is due to working with Python. And even then, a running joke is that half of my Python code is import statements. This talk about moving from C# to D explains the mindset of the C# programmer well (from 5:10 to about 14:00): https://www.youtube.com/watch?v=6_xdfSVRrKo#t=5m10s Namespaces in C++ are similar if you turn a blind eye toward the weirdness of how header files and translation units work. In Python (and now Rust) I've reconciled that modules are *the* (non-class/struct/what have you) namespacing mechanism and that they can't span multiple files. However, it took me a while to be comfortable with that, so this guide may benefit in addressing this aspect of modules (and maybe referring to some other concept that is more useful in its stead, traits maybe? I don't know enough Rust idioms yet). For the sake of clarifying what C++ and C# programmers will miss, say we wanted each language's `farewells` namespace to have functions for each combination of formal vs informal and daytime vs nighttime. If we assume that each routine is actually horribly long with lots of helper functions and types, and there's nothing really to be done about each being horribly long, then my instinct is to split them up. The split would be made such that someone browsing the source tree can more quickly hone in on sub-concepts since you can physically isolate the helper functions/types/etc. related to one set of routines from the other set of routines. Pretending the natural divide here is formal versus informal, it would look like this: // src/english/farewells-formal.rs pub mod farewells { pub fn formal_goodbye_daytime() -&gt; String { "Good day.".to_string() } pub fn fomal_goodbye_nighttime() -&gt; String { "Goodnight.".to_string() } } // src/english/farewells-informal.rs pub mod farewells { fn informal_goodbye_daytime() -&gt; String { "Later, alligator.".to_string() } fn informal_goodbye_nighttime() -&gt; String { "Nightie night.".to_string() } } It's a small thing, but I can imagine a lot of people balking at having to define update mod.rs with use statements every time they add a source file. Beyond that, nice guide! I agree the example isn't amazing but I'm not sure what would improve it.
~~Because `str` doesn't implement `Sized`.~~
Oh, and then we can get closer to a haskelly style of function declaration! static foo: fn(i32, i32) -&gt; i32 = fn(x, y) { x * y } (joking of course)
Rust's proposed UFCS is not that. Our UFCS is basically allowing a method `a.x(b, c)` to be called as `TypeOfA::x(a, b, c)` (it doesn't allow an arbitrary function to be called as a method).
That doesn't prevent anything. I have a PR adding the appropriate impls here: https://github.com/rust-lang/rust/pull/17585
Click to play!
&gt; Unlike the main guide, the topic guides assume a much more advanced reader. I assume by "more advanced" you mean "having a more advanced knowledge of programming languages in general" (eg, grokking what a "name conflict" is and what a "scope" is), rather than "having a more advanced knowledge of the basics of Rust" (eg, grokking what a "lifetime" is). If so, then why do you assume that the topic guides have a more advanced reader? Aren't the topic guides essentially supposed to be a continuation of the main guide? &gt; It seems to me like most of this is saying that I assumed too much, rather than the right level. It's partly that, but I also think that the guide is hard to follow because of the way it's written, not just because of the level it's written at. You're not allowing ideas to become thoroughly fixed in your reader's mind before you move on to other ideas which depend on them. Even if somebody is already pretty familiar with `idea X`, refreshing their memory about `idea X` before describing `novel-idea Y which-depends-on X` will make things much more readable. Looking at the other guides, throwing your reader in at the deep end has worked quite well in other contexts, but I think the difference here is that your reader is likely to be carrying a lot of half-baked ideas derived from the module systems of other languages ("privacy mostly applies at the object level"; "most imports are glob imports"), so some extra care might be warranted.
If you look at his [previous talk](https://www.youtube.com/watch?v=TH9VCN6UkyQ), I'm not sure Kitten would satisfy him. He doesn't like 'big idea' languages, and would probably lump a concatenative lang amongst those. He also wants to be able to have explicit control over allocation and memory layout - I'm not sure Kitten has that, right? (Btw, I think Kitten is super cool - these comments don't change that)
I just want to go nt out that Jonathan is not the entire gaming industry. There are quite a few that are taking the progress of rust with lots of interest.
I think Johnathan puts a lot of weight on an argument that's just wrong. When i started using rust i was delighted because it was the complete opposite of a big agenda language. Rust was and still is designed with practicality in mind, constantly improved to work better for real world situations abs nobody is afraid of admitting if things are not ideal and they get changed. When however the argument is that rust is a "big agenda language" and as such a problem there is no place you can go. You killed any discussion because it was dismissed on a completely subjective concept.
You're completely right.
That's look great! care to upload screenshots of servo renders some more common site? (e.g wikipedia, reddit..) And one other question: what about a chrome to the browser? will it be possible in the future to attach the firefox chrome to servo's engine or will it have to be a new chrome entirely?
Yeah, I basically agree with everything you say here :) And I certainly appreciate that you are a solo dev here. It will be exciting to see where things go for Kitten. You are definitely exploring some exciting territory! By the way, I am interested to know how you are typing the stack. Do you use row polymorphism like in Cat? I also wonder if it would be possible to make the type syntax the same as the expression syntax (might not have my terminology right), like in languages like Haskell and Idris. Could open up some interesting possibilities.
&gt; For example, unifying closures and functions is not zero-overhead, because of the need to account for storage of the closed-over variables. I don't see the connection between a unified syntax and unwanted overhead. Please explain.
Yes, though I prefer to call it “stack polymorphism”. The stack is typed as a nested tuple with a kind restriction so that it’s always nested in a stacky way, and there’s a minor trick in how you generalise function types. Making the type syntax non-magic has been in the back of my mind for a while. Ideally, I would like to have a stage for compile-time evaluation, where type expressions are ordinary expressions that happen to produce types, which are then used during the typechecking stage. It wouldn’t be hard to implement things like `def` and modules this way, as a sort of compile-time API for talking to the compiler. Seems potentially quite useful, I’ve just been focusing on other things.
Could we also get a macro that deconstructs a `String` supplied to it? Currently `scan!` can be used to parse stdin, but I'd like to be able to parse strings directly, too :) 
Sounds really cool! Yeah I feel at the moment kitten's syntax feels a little ad-hoc - would be nice to tighten it a bit. But that's the process of design, Rust has gone through tons of iterations. &gt; The stack is typed as a nested tuple So in Rust: type Stack&lt;S, T&gt; = (S, T); fn add&lt;S&gt;(((stack, x), y): Stack&lt;Stack&lt;S, i32&gt;, i32&gt;) -&gt; Stack&lt;S, i32&gt; { (stack, x + y) } assert_eq!(add(((((), "hi"), 1), 3)), (((), "hi"), 4)); Obviously no 'kind restriction' here though.
[reddit](http://i.imgur.com/9QeLLVv.png) looks pretty good [too](http://i.imgur.com/wQyfB39.png). (At least, everything is in about the right place, and there's colors etc.) PSA: servo is now easier to build than ever: clone [the repo](https://github.com/servo/servo), install [the deps](https://github.com/servo/servo#prerequisites), and [run `./mach build`](https://github.com/servo/servo#normal-build). The build I tried just now is time I've ever been able to get a working copy. (Although I did have to convince it to use the `gold` linker due to [a new `ld` bug](https://bugs.launchpad.net/ubuntu/+source/binutils/+bug/1371636)!)
I have a fix for the extra borders being displayed over on the right, as well as the double arrow next to "my subreddits", that bors is working on Right Now :)
I think servo would also make a good backend for a "traditional" UI toolkit, one that could be the standard choice for Rust desktop apps. Doesn't need to be XUL, though. (And the last time I mentioned XUL in the presence of servo developers I got snarled at. They don't seem to like it)
I explained over in this thread: http://www.reddit.com/r/rust/comments/2hjrrm/jonathan_blow_declarations_and_factorability/cktp7xf?context=3 The tl;dr is that the types have to be different because they work differently at the machine level (also, for safety reasons), and so if we adopted the `fn` syntax then expressions written with `fn` would not have type `fn`.
&gt; That's look great! care to upload screenshots of servo renders some more common site? (e.g wikipedia, reddit..) [The (whole) Rust wikipedia page](http://i.imgur.com/kUrSAvT.png) (looks *so* good). (NB. high-resolution PNG.) Reddit [posts](http://i.imgur.com/9QeLLVv.png) &amp; [comments](http://i.imgur.com/wQyfB39.png).
Wikipedia: http://i.imgur.com/YgzThNX.jpg Reddit: http://i.imgur.com/0QFviMt.jpg
[video here](https://www.youtube.com/watch?v=_B5yJ8BnZ4g) so.. on Ubuntu it doesn't render Reddit correctly (i'm using the latest github source code). 
Wow. everything actually looks really good, far better than I expected. Makes me wonder, it seems to be almost ready enough for broader testings, something like nightly binary builds for volunteers to test, is anything like that is in the roadmap anytime soon?
Yeah, I haven't dabbled much with closures and it shows. I thought the slides were somewhat correct when it comes to Rust's closure. They weren't as I've imagined.
I think this would be to early. Many pages lead to crashes, have a completely broken layout or do not work at all.
Visual Assist X for Visual C++ actually has a refactoring tool called `Extract Method` which does exactly the thing he talked about regarding moving smaller parts of a function/method. It's surprisingly good at forwarding the necessary parameters to the new function/method.
&gt; Many pages lead to crashes, I thought Rust prevents all crashes.
I just read this thing fully, and I have to wonder, would it be possible to implement some kind of Lazy COW DOM (I love this combination of words) in Servo? Something like what Facebook uses in React.js? Or is that already implemented?
They're task failures (or clean aborts from the JS engine). I can't remember the last time I saw a segfault from Servo. :)
Doesn't make a difference to a user.
Rust is a step forward from C++ because you can add methods 'outside the class' (there are no classes); method call syntax is more readily available. But my favourite idea from any language is D's idea of UFCS. Where I run into some 'friction' in Rust is organising traits and relationships between them. (that could be solved with duck-type traits): I ended up with lots of single function traits and extra names for groupings, and extra boilerplate to implement those combinations, and if you want to reorganise you have to faff around with those. We'll see what stance "blow-lang" will take, from the noises he's making so far, I suspect he's going to be in favour of a system thats as malleable as possible 
It certainly can. One thing that has been suggested is that when layout crashes we can just restart it in a sort of "safe mode", where all advanced CSS features are disabled. We can do that without affecting the state of the DOM (so user input, forms, etc. will be preserved). Another thing we can do is contain crashes to particular subcomponents, so for example if an image decode fails due to an out-of-bounds array access we can just display a red X for that image. This works because we have exceptions and a clean isolated architecture in Servo.
How beefy of a machine do you need to build it? (Or to be really specific, could a 2011 macbook air with 2GB of RAM reasonably handle it?) 
Is there an idea of what part of Técnico the will meetup be at?
Pardon me! I tried to implement a similar trait for `String` and `str` but ran into the following error: error: the trait `core::kinds::Sized` is not implemented for the type `str` &lt;ommitted&gt; note: the trait `core::kinds::Sized` must be implemented because it is required by `TestTrait` This was with Rust version `0.12.0-nightly (c669411af 2014-09-23 22:05:38 +0000)`. I haven't looked into DST yet, so didn't really understand the error and shouldn't have posted so confidently. Good to know this feature is on its way! Cheers! edit: formatting
have you considered referring to it as UMCS (Method Call Syntax) to communicate this better- "its not what D does" 
so would it be more probable being included in a new browser project than being part of Firefox?
&gt; "All we’re going to get out of this is yet another “C” with some incremental improvements on the status quo." C++ with a few incremental improvements like ufcs, no headers, cleaned up syntax would suit me fine. 
D with no GC then?
Wait, now I'm super confused. How are failure/panic implemented with C++ exceptions under the hood? In terms of LLVM?
I'm guessing languages like D make it a little easier for themselves by plonking a `=&gt;` in the middle - but you'd still need to do lookahead.
After spending a little time thinking about it, all of this talk of closures strays a long way from his actual concern - namely the idea of migrating functionality to larger and larger scopes over time. In Rust you can simply nest any item inside a function in order to limit its scope: fn foo() { struct Bar { x: i32 } { fn baz(b: Bar) { /* ... */ } baz(Bar { x: 1}); } // baz is not visible here } // Bar and baz are not visible here There's no need to introduce closures at all.
Many games have a large blob of 'gameplay code' that is single-task, that needs its tendrils to 'go everywhere', so passing state objects around is very high friction. Is there a way to make a global only visible to one task so that it doesn't need `unsafe`?
I think you could make the syntax clearer (and reduce the number of unique sigils) by doing something like fn f(x:float) -&gt; float { return x*x; } // standalone function var f = lam(x:float) -&gt; float { return x*x; } // closure Alternatively, you can do what C++ does and make the closed-over environment explicit, in which case var f = fn(x:float) -&gt; float [] { return x*x; } would have type `closure&lt; empty, float -&gt; float &gt;` (syntax not correct, but you get the idea), and `fn&lt;type&gt;` could be a type alias for `closure&lt;empty, type&gt;`. Functions with no capture section have no captures and thus are equivalent to `fn` types.
The point that type system proponents make is that (1) and (2) aren't conceptually different. If you structure your program from the beginning knowing that the type system can enforce invariants, you can represent invariants with types using simple techniques ("the only way to get this type is by calling this function, and the only way its contents can be modified is like this"). In a language without strong typing, you can still create types that act similarly, but you can't catch the errors ahead of time, so there's extra invariant-checking overhead (runtime overhead, but also development-time overhead and testing overhead). Of course, memory safety and thread safety are a lot harder to get than many invariants :)
I'd define a "big idea" as "anything which this language uses as a tagline". &gt; [Rust is a systems programming language that runs blazingly fast, prevents almost all crashes*, and eliminates data races.](http://www.rust-lang.org/) Those are big ideas. Its an advertisement for what the language is designed to do. In fact, I'd say those are "bigger ideas" than anything Go or D have advertised up to this point. I can't find any [similar advertisement](http://www.cplusplus.com/) on the C++ website. 
Just wrap the arguments in a tuple and let destructuring do its magic: use std::collections::HashMap; fn main(){ let map: HashMap&lt;uint, uint&gt; = vec!((1,2), (3,4), (5,6)).into_iter().collect(); for (k, v) in map.iter() .filter(|&amp;(k, v)| (*k + *v) &gt; 5) .map(|(k, v)| (k+1, v+1)) { println!("{}: {}", k, v); } } [playpen](http://play.rust-lang.org/?code=use%20std%3A%3Acollections%3A%3AHashMap%3B%0Afn%20main%28%29{%0A%20%20%20%20let%20map%3A%20HashMap%3Cuint%2C%20uint%3E%20%3D%20vec!%28%281%2C2%29%2C%20%283%2C4%29%2C%20%285%2C6%29%29.into_iter%28%29.collect%28%29%3B%0A%20%20%20%20%0A%20%20%20%20for%20%28k%2C%20v%29%20in%20map.iter%28%29%0A%20%20%20%20%20%20%20%20%20%20%20%20.filter%28|%26%28k%2C%20v%29|%20%28*k%20%2B%20*v%29%20%3E%205%29%0A%20%20%20%20%20%20%20%20%20%20%20%20.map%28|%28k%2C%20v%29|%20%28k%2B1%2C%20v%2B1%29%29%20{%0A%20%20%20%20%20%20%20%20println!%28%22{}%3A%20{}%22%2C%20k%2C%20v%29%3B%0A%20%20%20%20}%0A}) Edit: oops, code block formatting
What gets me about his attitude toward Rust isn't that he's criticizing it; it's that he doesn't really seem to have a clear idea of what Rust's big idea of safety really costs. In his first talk he correctly labels it a big idea language, but then he goes on to suggest several features that Rust has *because of* (or alongside) its big idea: auto-freed pointers, non-nullable pointers, less RAII boilerplate, no exceptions, automatic serialization, thread safety by tracking variable use (2nd talk), etc, often making it sound like Rust goes the other direction. In his second talk he uses things like data-oriented design, local functions, and block scope as examples of going against "what he learned in programmer school," which are yet again available in Rust and often in a better form than C++. He even gets Rust's fn/closure types wrong, inspiring little confidence that he knows what he's talking about wrt Rust. Maybe I misunderstand him, but to me it sounds like he's lumping the "big idea" of safety-without-GC with the often-bad "big ideas" of "what he learned in programming school." What I do like about his talk is the focus on ergonomics, including syntax. `~T`, while less clear to someone unfamiliar with the language, was much more obviously about the `T` than `Box&lt;T&gt;`. Dropping header files, growing programs from less to more abstraction (YAGNI), named parameters, easy cross-compiling, etc. are all good that would help Rust.
Why not, rather, invert this mess: put the tendrils everywhere (where they have the required scope to perform their function), but aggregated through a common "detail agnostic" core? As examples, consider map-reduce, or the simple functional fold. I have a "modifier" system which allows any point of code to apply modifier functions which may be aggregated from across the codebase, but connected by a typed-key. I've been a professional gamedev for 20 years and many things bothered me about recurring constructs in games. Most of them amounting to brittle, stateful, over-large messes. We can do better -- we're not locked into disorganized cesspools. Though I think higher-order functions, or comparable are a necessary abstraction. A lot of my problems went away when I was able to *flexibly* "invert control": plug custom detail functions into a larger control system... just like a simple fold. To be clear though, I'm not speaking from a Rustacean (is that the right term?) perspective -- I'm awaiting 1.0 before I commit time to learning.
A release build (i.e. all optimisations on) took me about 15 minutes IIRC, on a relatively new, but not super-fast, laptop. (This was running in the background too: I ran `nice ./mach build --release`.)
Not too sure, /u/joshmatthews probably can give a better answer.
cplusplus.com is not *the* C++ website, it's a general reference site (with a bad reputation, AIUI). I don't think C++ has a central website like Rust/D/Go.
Of course it does, if it means their system doesn't get compromised by a heap-spray attack or similar.
It can't prevent stack overflows, for example. (Not that this is unsafe.)
I don't see how replacing `||` with `lam` (which is used in no other mainstream language) is clearer. `||` has precedent from Smalltalk and Ruby. Furthermore, I think that making the closed-over environment explicit *increases* "friction", by making you type more when the compiler could infer it. Finally, closures with no upvars are not the same as `fn`, because of unboxed closures. `fn` has virtual dispatch, while closures do not.
&gt; I don’t think “big idea language” is really a meaningful concept. If this phrase enters the common lexicon as a result of Blow's talks, I'm going to be really disappointed. "It's a Big Idea Language so it won't work" is perhaps the most meaningless, stupid criticism you could make of Rust.
Not just context free, but *probably* regular as well, and you want your lexical grammar to be regular (ideally).
Thats interesting, maybe i should drum up some discussion on the discourse forum. 
`/* */` comments can be nested, so it's not regular (unfortunately).
As a whole, yes. There may be parts we can extract and re-use, such as the HTML parser.
I was working on a full-rust implementation of RSA. I was hoping to one day contribute it to rust-crypto. It required working with big ints. I found the bigint structs in the libnum library that comes with rust. Those work great, and they implement the right traits so that you can use all the normal arithmetic operators like +,-,*,/. but they're immutable and nothing is done in-place. Everything like addition creates a new bigint. That, plus other things like not being able to iterate the bits making up the number, makes it pretty inappropriate for implementing RSA. But I did get RSA working, very inefficiently. I took the bigints from libnum and I was working on making all of the operations in-place and mutable. I got pretty far, trying to keep all of the same unit tests working. But the code is probably full of bugs and I haven't looked at it in a while. I don't know if anyone would be interested in something like that.
Benchmarks from the commit message: bench | treemap | btree -------------------|-----|---- find_rand_100 | 76 | 74 find_rand_10_000 | 163 | 153 find_seq_100 | 77 | 82 find_seq_10_000 | 115 | 108 insert_rand_100 | 111 | 220 insert_rand_10_000 | 996 | 620 insert_seq_100 | 486 | 411 insert_seq_10_000 | 800 | 534 (There's still a pile of memory layout (etc.) optimisations possible, too.)
It is hard to deduce the problem without being able to see the context (e.g. the crate and module imports).
main.rs: http://pastebin.com/qDPs0ifk syscall crate: https://github.com/kmcallister/syscall.rs Cargo.toml: http://pastebin.com/f6UyMPAi
https://isocpp.org/ is probably closest to one, but it's nowhere as central.
&gt; Even get_byte() seems to block until I press enter The problem here is that your *terminal* stdin is (line) buffered, you need to disable buffering in your terminal. You can do this using termios, [this article](http://shtrom.ssji.net/skb/getc.html) has the details. This code will get you unbuffered stdin (i.e. you'll be able to read byte by byte): **Note** I've tested this on Linux + glibc. Termios constants are different in *BSD/OSX, so you may need to change some values if testing in those OSes (you should have a `termios.h` header file somewhere in your system, all the constants you need should be in there). extern crate libc; use libc::{c_int, c_uchar, c_uint}; use std::io::stdio; fn main() { let mut stdin = stdio::stdin(); let mut old_termios = Termios::new(); let stdin_fd = 1; match unsafe { tcgetattr(stdin_fd, &amp;mut old_termios) } { FAILURE =&gt; fail!("Couldn't fetch termios structure"), SUCCESS =&gt; {}, _ =&gt; unreachable!(), } let mut new_termios = old_termios; // Disable ICANON -&gt; disable canonical mode, which disables buffering // Disable ECHO -&gt; Disables local echo new_termios.c_lflag &amp;= (!ICANON &amp; !ECHO); match unsafe { tcsetattr(stdin_fd, TCSANOW, &amp;new_termios) } { FAILURE =&gt; fail!("Couldn't set termios structure"), SUCCESS =&gt; {}, _ =&gt; unreachable!(), } loop { match stdin.read_byte() { Err(e) =&gt; break, Ok(byte) =&gt; println!("Got {}", byte), } } match unsafe { tcsetattr(stdin_fd, TCSANOW, &amp;old_termios) } { FAILURE =&gt; fail!("Couldn't restore termios structure"), SUCCESS =&gt; {}, _ =&gt; unreachable!(), } } #[link(name = "c")] extern { fn tcgetattr(fd: c_int, termios: *mut Termios) -&gt; c_int; fn tcsetattr(fd: c_int, optional_actions: c_int, termios: *const Termios) -&gt; c_int; } static ECHO: tcflag_t = 0x08; static FAILURE: c_int = -1; static ICANON: tcflag_t = 0x02; static NCCS: uint = 32; static SUCCESS: c_int = 0; static TCSANOW: c_int = 0; type cc_t = c_uchar; type speed_t = c_uint; type tcflag_t = c_uint; #[repr(C)] pub struct Termios { c_iflag: tcflag_t, c_oflag: tcflag_t, c_cflag: tcflag_t, c_lflag: tcflag_t, c_line: cc_t, c_cc: [cc_t, ..NCCS], c_ispeed: speed_t, c_ospeed: speed_t, } impl Termios { fn new() -&gt; Termios { Termios { c_iflag: 0, c_oflag: 0, c_cflag: 0, c_lflag: 0, c_line: 0, c_cc: [0, ..NCCS], c_ispeed: 0, c_ospeed: 0, } } } BTW, I've termios binding in my [serial.rs](https://github.com/japaric/serial.rs/blob/master/src/termios.rs) library, although they are not publicly exposed in that library, the source files may help you. Hope that helps!
Do you remember the exact commit of the slides you used for the talk at GWO? I watched twe first 11 and a half minutes of your talk and it was good so far but would like to have the slides before I watch the rest.
That's *extremely* helpful! Thank you so much!
syscalls are working! thank you
Gankro's on fire! &lt;3
Roughly speaking, what were the issues with the old implementation that allowed you to get these performance increases while still focusing on correctness (ie. allowing even more headroom for performance)?
The following is lazy, right? let data_source = map.iter() .filter(|&amp;(k, v)| (*k + *v) &gt; 5) .map(|(k, v)| (k+1, v+1); So nothing will get evaluated until you do for (k, v) in data_source { } And if you wanted to force evaluation you could do let actual_values: SomeCollectionType = data_source.collect(); Is that correct?
&gt; I thought Rust prevents all crashes. It can't prevent all logic errors. if size &gt; max_size { fail!("Impossible! size ({}) &gt; max_size ({})", size, max_size); }
That worked, thanks a lot!
Do you have any specific thoughts about what insights this research might hold for Rust?
cool news, I didn't expect that, is there any official statement about the goals and why are you working on servo apart being really cool? :)
The old implementation was basically... nonsense. You can see it in [the 0.11 docs](http://doc.rust-lang.org/0.11.0/std/collections/btree/struct.BTree.html). Beyond the fact that it doesn't actually implement any of the collection traits or provide any iterators, this is the entirety of its actual API: impl&lt;K: Clone + Ord, V: Clone&gt; BTree&lt;K, V&gt; { fn get&lt;K: Clone + Ord, V: Clone&gt;(self, k: K) -&gt; Option&lt;V&gt;; fn insert&lt;K: Clone + Ord, V: Clone&gt;(self, k: K, v: V) -&gt; BTree&lt;K, V&gt;; } Keys and Values have to be `Clone` to insert or get? And they take the BTree by-value??? Is `get` removing? If it is, how do you non-destructively search? If it's not, how do you remove? Wait... does `get` *destroy* the tree????? This sort of madness was problematic enough that the whole thing was just deprecated a while back. Although serious respect to the guy who managed to write even *this*, since the original BTree issue is a chain of like 5 people "starting" an implementation and then disappearing into the mist... but we can do better. And now we have! :D
&lt;3
He also complains about having to put 'pub' in front of things. That kind of stuff isn't for philosophy, its for code reuse or 3rd party libraries. Even if you don't want to use it yourself, you will want everyone who is writing libraries in your language to do it. Maybe the whole program could have an attribute that sets if it should expose everything or use a rule like Golang's capital letters = public rule.
www.eff-lang.org is a syntax extension for OCaml. To answer your question: No. I just wondered, if those ideas may be useful/implementable in Rust? And the high-level overview on www.eff-lang.org made me think that this might be interesting for making a language even more expressive,- and being a syntax extension, without sacrificing low-level idioms.
That's actually hilarious, and I think a case where TDD would have done a whole lot of good (regarding the dodgy public API). I still need to figure out how by-value `self` works -- does it consume the object on which the method is called because you lose references to it?
Just remember that `collect()` isn't an "evaluate" command. It's meant to collect the results in a collection type. A for-loop is usually what you want otherwise :)
Perhaps Rust could at least keep a set of official GMP bindings, with libnum trait interoperability etc.
Couldn't agree more. Additionally I doubt `...` is very much used, so when it finally does show up in code, it will cause much more confusion than just writing `a..b+1`.
I'm not sure exactly what you mean, isn't that sort of the same thing? It turns an abstract description into a real value by actually performing calculations, isn't that evaluation? What would a "pure evaluate" command that is not "collect" do differently from collect? In any case, C# provides methods such as `.ToList()`, `.ToArray()`, `.ToDictionary()` (I think). I kind of prefer the generic approach of rust where the return type is inferred statically.
Re: BList You have to augment the B-Tree to store subtree sizes, and then provide a way to search based off of those sizes. On paper it's a trivial augmentation, in practice it's a fair amount of work which would basically require duplicating the whole codebase, unless you start doing some hardcore generics. Skiplists and Blocked-Lists (linked list of array deques with B-tree-ish capacity/size semantics) are also candidates for this functionality, with different strengths and weaknesses. Re: Why use TreeMap It provides better worst-case guarantees, at very least. BTree has a lot of degenerate input sequences that still have `O(log n)` perf per operation, but are doing a *lot* of work nonetheless. TreeMap should also beat BTree when using *very large* keys/values, or expensive to compare keys.
So, `collect()` will allocate a list, and then put the results into it. Using a `for` loop never has to actually allocate a collection, it just computes each element on demand.
eff is not a syntax extension for OCaml. It's syntactically similar and implemented in OCaml, but that's all. It would be awesome, though. :)
Unsure. I MIGHT have mentioned it in the commit messages? :/
Thanks, I thought there must be a catch, if everything would be that easy, surely someone must have tried this before. I was already dreaming about IO-equations and expressions replacing printf!-macros etc...
I recommend reading the reddit discussion to get some ideas: http://www.reddit.com/r/rust/comments/2hgspp/struct_sugar_and_using_it_for_keyword_and_default/ Also, I have translated some code a few places to see how it looks like for real: https://gist.github.com/bvssvni/3cdc297616aa37b7526f https://gist.github.com/bvssvni/253fa45305283b71d61e
Another language that models effects with types is PureScript, which uses row types. (I think that Opa does it too). To get closer to having something like this in Rust you would need higher-kinded types, so that Monadic effects can be made convenient.
&gt; Desugar val into Some(val) whenever val is non-Option and Option is expected I think this is a bad idea. Confusing Option&lt;T&gt; with T essentially brings the troubles of nullable pointers into the logic of your program.
What about the field is an Option&lt;Option&lt;T&gt;&gt;, should a Some(1) be desugared into Some(Some(1)) or be a literal Some(1)?
"Desugar val into Some(val) whenever val is non-Option and Option is expected" So no, the value must be known to be non-Option.
Non-static expressions can't be allowed in traits as part of the method signature, because the type of `self` is not known. You can't call stuff like `self.len()`, so I think it should only be in the impl.
I do not like special-casing Option in the language like this. At all. Writing Some() is not worth the cost of inconsistency. I sort of feel that way about this entire proposal, actually, but the rest I can live with. Also, how does this apply to non-concrete types? I.e., what if you have an argument that only has to implement a trait? Would default arguments not apply there? This is starting to sound uncomfortably niche to me.
That might be acceptable, because when you see `Some(x)` in a function argument it usually means the argument is evaluated against some criteria. This might make it easier to reason about performance. The RFC could make that particular sugar optional. However, it will break refactoring of overloaded methods. It can be added later as a backward compatible change.
To me, it's not so much a question of whether it would be useful as whether it is adding magic to the language that normal users can't use. Rust is just finishing up dealing with the fallout of special-casing Box, and there was arguably a lot more incentive for that than there is for Option. So any proposal that imagines treating Option separately should IMO have much more justification than "it usually means x anyway." Personally, I don't think this idea really belongs in Rust as a language.
Why did they deprecate Ratio? Is there a replacement?
Of course. I am working on this idea because I think it's good enough to be discussed thoroughly, but it might be a big step from there and put it into Rust.
Yes, and overloading might be supported as well: http://www.reddit.com/r/rust/comments/2hpu5k/extended_struct_sugar_named_parameters_defaults/
If you wanted to do that, couldn't you implement it yourself? Shouldn't be too difficult.
If you mean that each individual user could implement it for herself, sure, but I think this is general functionality which deserves to be in `std`. (And it's something we can point people to when the compiler complains at them for using `f32`/`f64` in these situations.) If you mean that I could implement and submit the change myself, of course I could, but I have plenty of higher priorities right now (and for the foreseeable future). Plus these sort of seemingly "small changes" always take way more effort to get through the process than it seems like they should.
I think you understand the concept, so my previous comment isn't really necessary, and /u/kingkilr explained what I mean, but I will clarify. It's easy to think that `map` and friends can be used as a replacement for a loop, but then you would have to trigger the evaluation with something and that could be `collect`. The thing is that `collect` creates a collection, which is a waste of time. That's all.
We can drop `Some(val)` desugar and overloading and only have struct sugar. The syntax will be more explicit, all functions got unique names, but still nicer to use structs. This might be a good middle ground solution.
The september video seems to be cut off in mid sentence. (1:04 ~). Is it just me?
I completely changed how the API works. Previously pretty much all redis commands were manually wrapped which was okay, but it was high maintenance burden on the side of the library and created a huge API. It also did not actually work well enough because the error handling was either non existing or too complex. With this version I now went with a pattern that's much closer to `process::Command` from the `std` crate where you add parameters to a command pipeline which you can then execute. It's not ideal yet, primarily because of the lifetime of temporaries in Rust, but for the most part the API feels really nice now. I also implemented two stage types. The first stage is the types as they come from the parser and server, the second stage is a conversion through a `FromRedisValue` trait to whatever the user expects. I think this feels most natural, but I'm not entirely sold yet.
I agree with /u/protestor that `Option` shouldn't be anything special in that sugar. Keep it simple and don't introduce weird special cases! Speaking of `slice` example, while `from` is perfect to be made default argument, `to` really isn't. I think that `slice_to` should be separate function, since `to` really changes semantic of a function (from slicing as much as possible to slicing some given amount of elements) and changes an implementation of function which should be really performant (adds bound check, and changes source for `len` field in returned slice). For other uses (where there is no obvious performance issue), I think that passing `Some(3)` is perfectly ok. Moreover I can easily imagine function taking default `Option` argument, but without `None` being the default. For example (please ignore syntax, it's only to convey the idea), fn give_me_best_movies(limit: Option&lt;uint&gt; = Some(10)); fn create_button(border: Option&lt;BorderArgs&gt; = Some(type: Bevel, width: Px(5))); I'm opposing non-static expressions too, because with them we would hardcode default arguments into the language and disallow users to simply build parameter structs beforehand.
I wanted to say that you forgot to indicate that `{x: 1, y: 2}` (which is neccessary for nested cases and may be helpful for clarifying "it's a struct"), but now I see it would be just parsed as block expression with a single expression (struct sugar) in it.
Yeah, I figured out that too. Trying to compress down the rules to the essential.
Non-static expressions should only be evaluated on Option, because it needs None to know if whether it shoud use the default value. Because it is only evaluated on Option, there is no need to specify the option type, because the precence of an expression implies the argument takes Option. Inside the function the value should be unwrapped, therefore annotating with Option might be misleading. The same code, but now sugared with correct internal type: fn give_me_best_movies(limit: uint = 10); fn create_button(border: BorderArgs = type: Bevel, width: Px(5)); The problem is to make the external type usage appear similar to the internal type usage. Therefore I thought of desugar 'val' into 'Some(val)'. Alternative is to make the type for internal usage magically unwrap. Even you specify 'Option&lt;uint&gt;' the internal type is 'uint'. The approach currently in the summary is the least built-in way I can think of, it is only sugar. *Edit: rustdoc will generate the external type, but I think we should consider the internal type in the source.
We could only permit default values with named syntax, which will not require any special treatment of Option. This will limit default values to static expressions, because the compiler need to insert them at the call side. If we do this then we can extend to allow non-static expressions for Option, but this will result in the confusing type annotation I mentioned.
I'm not terribly familiar with Redis or its API, so this may be uninformed feedback, but... In the X11 world (since XCB), we tackle the problem of "there's a huge API and it's impossible to maintain by hand" with code generation. Namely, there is an XML description of the wire protocol and a code generator reads that description and outputs code in the target language. I wonder if you could leverage a similar solution for Redis? (It'd be great if there was a machine description of API available, but maybe it wouldn't be too hard to write one yourself.) I've found this technique to work reasonably well because it fixes the maintenance burden problem while not sacrificing the benefits that the compiler will give you. In this case, if the Redis API is built into your library, then you can guarantee that a program compiled with your library can *never* run a Redis command that doesn't exist or with an incorrect number of parameters. That seems like a pretty useful guarantee to me. The story is different with `process::Command` because it *must* support a general interface. There isn't any other choice. &gt; The first stage is the types as they come from the parser and server, the second stage is a conversion through a FromRedisValue trait to whatever the user expects. That seems reasonable to me. Another approach might be to utilize the `Encoder` and `Decoder` traits in the `serialize` crate. The main benefit is that clients can utilize it with the `deriving` attribute. For example: #[deriving(Decodable)] struct MyRedisValue { f1: String, f2: int, } And your implementation of the `Decoder` trait would figure out how to handle arbitrary structs. (I'm assuming this is applicable to Redis because you've provided implementations for tuples for `FromRedisValue`.) Another plus is that any standard library types that provide an impl for `Decodable` or `Encodable` will also automatically work with your library.
In order to set a default you need 1. a specified empty value 2. a condition to check for an empty value, or trigger condition somehow 3. a value to replace the empty value The right side of the equal sign describes the value to replace the empty value, but what the empty value is and what condition trigger the check, is implicit. I chose Option because it is the only data type that fulfill all these conditions and makes sense to be assigned to a struct member. Default structs values uses the named syntax to trigger the condition. There is no specified empty value, but we are "faking" it with the '..' in the named syntax. We can merge these two concepts by not allowing default value for Option in structs, because that would be ambiguous if the argument in a function also has a default value, because the semantics of desugaring must be the same as for calling the function.
The quick answer is "no". What seems to be missing are * multiple dispatch or modified binary operator traits (to make different types mix well without much hassle) * integer constants as parameters for generic structs and functions (so you can do compile-time dimension calculations) According to [this official blog post](http://blog.rust-lang.org/2014/09/15/Rust-1.0.html), Rust 1.0 will solve the first bullet point. It does not mention anything about integer parameters for generics. So, I guess ... no, I *hope* this will be a post-1.0 feature.
None's descriptive meaning is the lack of value T which the Option&lt;T&gt; type wraps. Under some circumstances you can interpret it as the extension of T, for example if T is a number, None is infinite. But it could be zero, or NaN, nothing, or many other interpretations. Only because you can interpret something in a context, does not necessarily mean that you "should" always think that way. Instead, you should understand the context. This is why I chose Option (in context of default values): 1. The type must have an empty type 2. The type must be unwrappable to a single value 3. Result does not makes sense, because it contains an error message, which when stores in a struct refers to something wrong happened with an operation somewhere, which is irrelevant to the usage we like, because we can't specify what we want to do with the error Therefore, the only type left is Option. The types here are generic, so this is a mathematical proof that the optimal type, given the context of our problem, is Option. This is what I meant in the text you are referring to.
If you think about it, C was a Big Idea Language at the time. "High Level Assembly".
You know when you are working on analyzing a hard problem that can't be made simpler, and explaining it in full detail and examining all the connections... the reason I am sharing this is because the problem is complicated. There are lot of opinions about null pointers, they must be bad, etc. Rust shows that most problems can be solved without null pointers. What if there is a problem that requires null pointers to be solved? Should we refuse to solve the problem, even if it could bring us great benefit? I look at this problem and try to understand what it takes to solve it, it does not mean I like null pointers, or that I have a special interpretation of None. It is just that this is the only way I see a pure sugar extension to Rust that solves these problems. When I saw the struct sugar, I recognized an area which would be controversial, but fits Rust's syntax reasonable well. I think it is worth exploring!
C had a tagline when it was new. "High Level Assembly". Doesn't that sound like a Big Idea?
What I meant with None as not self documenting is when you call a function 'foo(None)' it does not say what the argument is. It does with named syntax. We should figure out a way to address the syntax. Perhaps use the table in the summary?
I wouldn't expect anything soon. As it currently stands, Servo doesn't highlight or have a way to follow links. Also crashes are super frequent on various sites. 
&gt; You describe two examples, the first where you have 'movies = Some(10)' but in you second example you mention 'limit' I don't know what do you mean by that assignement and I have been always talking about `limit`. &gt; It is only meaningful to speak of 'None' as the empty value in a context where you want a default value. There exists contexts where this is not true, but that does not invalidate the cases where it makes sense. I do agree with that, but problem is that these contexts can both appear in one usecase, and for somebody it may be surprising that `None` doesn't mean "`None` has been passed", but "no argument has been passed". Besides, if you want to forbid default arguments for `Option` types, then you would have to ban default arguments for any generic function too.
Sorry I didn't state that my commend about self-documenting assumed not omitting name. Because I agree that when name ommited it's really not obvious. And that's the reason that I don't really like implicit casting from tuples.
imagine if there was an automatically generated 'struct' for any function argument block. (and a way of calling the function for those args). // you write... fn foo(a:A,b:B) { ...} // automatically generate this... struct foo::Args { a:A, b:B} foo::Args{a:2,b:3}.call(); // same as foo(2,3) maybe this could be done with a 'procedural macro' ? 
Have not thought much of generics yet, but if we go for non-static expressions, there should be no problem: fn foo&lt;T: Default&gt;(bar: T = Default::default()) { ... } let x: uint = 4; foo(Some(x)); foo(x); // Desugar to Some(x) There is a discussion whether you should write Option&lt;T&gt; or T. One is correct externally to the function, the other is correct internally. The current approach is to use internal and desugar to Some, because it allows you to add a default value without breaking code. It is what I thought of as the most refactor friendly approach. Maybe we could have a trait, but it must be similar to what Option does.
Cool charts! What's cow::BtreeMap? Also, I'm surprised iteration is so slow on BTreeMap :/
Good point. The generic thing might make it more trickier. struct Foo&lt;T&gt; { bar: T // don't know if Option or not }
This is interesting. When you refactor out arguments to a struct, the function gets another type signature, but it keeps sugar compability with the old type signature.
I moved away from it because of performance concerns. Another problem is that 'Default' must be implemented for all struct members. There are no required parameters.
Same problem with 'bool'. However, I don't think implicit casting should be banned because of the "trouble types". My major concern is what happens when you refactor code, and starting with tuples is often natural.
I'm somewhat surprised by that, since it doesn't seem to match the numbers from the PR; in particular, the numbers there indicate insertions into a `BTreeMap` should be approximately double the speed of insertions into a `TreeMap` for reasonably large targets, while this doesn't seem to be reflected. What sort of keys are you using?
&gt;Confusing Option&lt;T&gt; with T essentially brings the troubles of nullable pointers into the logic of your program. I might be missing something, but I disagree. If you've got a val eligible for this sugar, you know it's non-null (regardless of whether it gets promoted to Some(T). On top of that, if the callee expects Option, they already take the possibility of null into account. So what potential error could result?
I mean, the compiler can guarantee type safety, but the trouble with nullable pointers is also that programmers *think* in terms of them, and confuse a value with an optional value (in some languages like Java you can't even pass an non-optional value anywhere!). It's a conceptual problem, but I agree there isn't a potential error lurking. ... a more dangerous thing is the pervasive use of .unwrap() (people even suggest sugar for this). It's not memory unsafe like following a pointer without knowing if it's null, but it's still a fatal error that could be lurking. I think that processing the option in a monadic style would be great, but without higher kinded types and a lot of sugar it isn't really convenient. I can see it can have a merit (the Erlang's approach: write clean code without error handling that, during error, fails the task, and have a supervisor handle any error condition) but I suppose that a lot of deployed code won't be very careful to consider the possibilities of unwrap. It's just too tempting to turn Option&lt;T&gt; into T and disregard errors.
I'm guessing it refers to [https://github.com/csherratt/cow-rs](https://github.com/csherratt/cow-rs). Some interesting points about this implementation: - The internal node size is 42 and the leaf node size is 31. It might be worth testing to see if large values of B would help the `collections::BTreeMap` implementation. - The keys and values are stored inline, not behind a `Vec`. - Instead of using unsafety and drop magic to leave this inline vectors partially unfilled, `Default` is used to produce padding values. - Instead of a straight binary search or linear search, it uses two levels of linear search - first though every 8th key, then through the remaining group of 8. - Values are only stored in the leaves.
Keys are uints, payload is a struct of 8 uint64. The benchmarks for the PR was uint for a key and uint for a value. The numbers look correct to me, BTreeMap looks to be inserting twice as many keys as TreeMap.
It's a Copy-on-Write btree like datastructure. It's basically a b+tree without the inter-leaf pointers (which had to be removed to make COW efficient). https://github.com/csherratt/cow-rs It was never at the quality that I felt was needed for the standard library. But has been good enough for my own projects. The benchmark was part of the project. As for the iteration performance, It's bit of a surprise to me too. It could be a complexity problem, to many branches. For the HashMap to peak at 400 Million entries a second it can only be spending a handful of cycles actually fetching the next value. BTreeMap peeks at 70 million and stays stable at that speed until the data structure grows larger then the L3 Cache. So I would guess most of the time is not spent waiting on data, but figuring out where the data is.
&gt; For the HashMap to peak at 400 Million entries a second it can only be spending a handful of cycles actually fetching the next value The HashMap iterator is literally just walking across the backing array yielding entries with non-empty hashes, and I believe HashMap tries to ensure a load factor between 0.25 and 0.91; and, if there are no deletions, it will lie between 0.45 and 0.91, meaning, at *worst*, it has to examine about two `u64`s (adjacent in memory) to find each element. (Although the branches will be fairly unpredictable with a good hash.)
`skip` returns a lazy iterator, the way to actually get information out of them is consumers like `collect`, or, at the lowest level, `next`, which just fetches the first element (which seems like what you want): match args.iter().skip(1).next() { Some(a) =&gt; ... None =&gt; ... } (This doesn't do any allocation, unless the underlying iterators do some (not the case here).)
Or you can use a `for` loop, which calls `next` under the hood and does the matching for you: for arg in args.iter().skip(1) { // do stuff with each arg except the first }
You should just create an enum **Key** containing all of the keys, and then implement PartialEq/Eq on it manually, like: impl PartialEq for Key { fn eq(&amp;self, other: &amp;Key) -&gt; bool { // check if they're both AMinor/CMajor and return true, etc. } } impl Eq for Key {} 
Yes, it internally uses `FromIterator&lt;I&gt;` trait, which is implemented generically. If Rust would allow specialized implementations, then implementation of `FromIterator&lt;MoveItems&lt;T&gt;&gt;` for `Vec&lt;T&gt;` could reuse existing allocation. And `skip(k)` skips k elements, not k-th element.
&gt; Follow up question, does collect() on a moved iterator, actually do allocation? Does collect do what on a moved iterator? What `collect` does depends entirely on the type to which you collect, since it is generic (it is possible to collect to a `Vec`, a `HashMap`, a `String`), but yes, most instances of `collect` will have dynamic allocations etc.
I agree. I think the interface should make it clear that SET takes a key and a value and that KEYS returns a vector of strings. The API could even be taken one step further and not use strings for the commands, like rust-http (teepee) http://chrismorgan.info/blog/teepee-design-header-representation.html
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Canonicalization**](https://en.wikipedia.org/wiki/Canonicalization): [](#sfw) --- &gt; &gt;In [computer science](https://en.wikipedia.org/wiki/Computer_science), __canonicalization__ (sometimes __standardization__ or __normalization__) is a process for converting [data](https://en.wikipedia.org/wiki/Data) that has more than one possible representation into a "standard", "normal", or [canonical form](https://en.wikipedia.org/wiki/Canonical_form). This can be done to compare different representations for equivalence, to count the number of distinct data structures, to improve the efficiency of various [algorithms](https://en.wikipedia.org/wiki/Algorithm) by eliminating repeated calculations, or to make it possible to impose a meaningful [sorting](https://en.wikipedia.org/wiki/Sorting) order. &gt;The term __canonicalization__ is sometimes abbreviated __c14n__, where 14 represents the number of letters between the C and the N. &gt; --- ^Interesting: [^URL ^normalization](https://en.wikipedia.org/wiki/URL_normalization) ^| [^Graph ^canonization](https://en.wikipedia.org/wiki/Graph_canonization) ^| [^Canonical ^form](https://en.wikipedia.org/wiki/Canonical_form) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckvd5ud) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckvd5ud)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
One approach is to simply have the key enums be major by default, and essentially just refer to sets of notes. If you want to name AMinor as a shortcut, just do something like `let AMinor = CMajor;` (not sure of syntax for global vars). Perhaps even name it "KeySignature" rather than "Key", to signify that it refers to the note set/key signature, rather than the whole semantic bundle of the key. Then you would store separately whether the user meant C major or A minor or D dorian. (Don't forget you might need that info in the cases where a key signature can be represented with either flats or sharps.) This is roughly what I did with similar requirements in a C++ app^1. Something you also might consider is making keys be integers with a bit for each note, where the bits are set for every note in the key, instead of a simple increasing series. To some extent you can do the same thing with chords. Another approach would be for a key to consist of a root note and a mode, more or less the intuitive representation. In that case you would want to implement PartialEq on your struct. To compare them, you might be able to do something clever like just adding the reprs of the root note and mode of each key and compare those numbers. Then you would derive the note-set side of things from these enums, ideally with more clever arithmetic. My apologies if my terminology is off, it's been a while since I messed with music theory. Also if I've said anything really boneheaded because I'm tired. ^1 Not a visual editor, just a little utility that would figure out a key given a set of chords. I think my keys were just integers in [0, 11]. 
Have you considered making the `KeySignature` enum based on the number of sharps or flats in the key instead of the name of the key? enum KeySignature { SevenFlats, SixFlats, FiveFlats, FourFlats, ThreeFlats, TwoFlats, OneFlat, Neutral, OneSharp, TwoSharps, ThreeSharps, FourSharps, FiveSharps, SixSharps, SevenSharps, } Then maybe use a separate `Key` struct with a `get_signature` method: enum Note { AFlat, A, ASharp, BFlat, // you'll probably want another way to map // equivalent note names to their chromatic number // ..., GFlat, G, GSharp } struct Key { note: Note, minor: bool, } impl Key { fn get_signature(&amp;self) -&gt; KeySignature { // ... } } You could also provide an inverse method `get_key` on `KeySignature` to convert back and forth between `Key`s and `KeySignature`s.
Why not just use a module with callable_from_foo_only being private? 
I think, ordinary functions should implement Fn trait, too.
&gt; Are the two a's distinct entities or has the first a been overwritten by the second a? You can test this by borrowing a reference: let a = 5i; println!("a = {}", a); let c = &amp;a; let a = 10i; println!("a = {}", a); println!("c = {}", c); This will print: a = 5 a = 10 c = 5 So the original value of `a` remains on the stack, and the second `let` binding is allocating a new spot on the stack and pointing `a` to it. This is safe because it's not mutating the value of `a`, it's changing what `a` points to. The original value of `a` won't be dropped until the end of the block, so the lifetime is valid. If you try to do this with `b`, however: let mut b = 5i; println!("b = {}", b); let d = &amp;b; b = 10i; println!("b = {}", b); &lt;anon&gt;:13:5: 13:12 error: cannot assign to `b` because it is borrowed &lt;anon&gt;:13 b = 10i; ^~~~~~~ &lt;anon&gt;:12:19: 12:20 note: borrow of `b` occurs here &lt;anon&gt;:12 let d = &amp;b; Because you are actually trying to mutate the value in this case. The "immutable by default" rule holds true: let a = 5i; println!("a = {}", a); a = 10i; println!("a = {}", a); &lt;anon&gt;:4:5: 4:12 error: re-assignment of immutable variable `a` &lt;anon&gt;:4 a = 10i; ^~~~~~~ &lt;anon&gt;:2:9: 2:10 note: prior assignment occurs here &lt;anon&gt;:2 let a = 5i; ^ 
That's a good explanation, thanks. I think that it would be apt to say that the first ``a`` is being *over-shadowed* by the second ``a``. Do you know if there's a compiler flag to warn about this? I looked but didn't turn up anything (and rust's linter doesn't warn about this either).
What if the shadowed a has no live references when the new a is declared - can its space be reused? What about the pattern of declaring a variable mutable, mutating it, then declaring the same variable as immutable for the remaining of the scope?
A compiler warning would make me seriously sad. There's a huge argument for readability in overshadowing variables. Look at vec![] for a good example. let mut vec = Vec::new(); vec.push("example"); let vec = vec; // This ensures vec is immutable for the rest of the function
Thanks for all the responses! Lots of clever ideas here... I'll have to think a little more about what I actually want to be able to do. 
That, and the example given by DroidLogician, are both good examples of where overshadowing is nice. But, any situation where a variables name no longer represents what you think it did is a counter-example. Anyways, whatever the Rust developers decide to do it ok with me. But I think it would be nice to be able to have the linter let me know when a variable's been overshadowed so I can have a heads up and check it out.
What would happen here if you intentionally would want to call give_me_best_movies(None); The point is that the limit is still optional; this is the sort of case where the function would take an Option&lt;uint&gt; even if it didn't have a default value.
The objection against Option in this case seem to be against the concept itself. This is very understandable, because you don't want arbitrary concepts in the language. However, we also want to type less, or not being forced to type a lot to make the program run again. let (first_name, last_name) = match (person.first_name, person.last_name) { (Some(first_name), Some(last_name)) =&gt; (first_name, last_name), _ =&gt; return } vs let Person { first_name = return, last_name = return } = person; One advantage with the last version is to be able of returning a different error message for first name and last name. You don't have to change much code to get there. The struct sugar lets you refactor code easier and encourages structs as monadic values, that are meaningful. "The person lacks a first name" instead of some cryptic error message. It is easy to see that if code is expressed close to context of what it means, then improving the code is more likely to improve the meaning. The problem with code in real life is it starts out simple and grow complex over time. The way the syntax works in Rust now, it punishes the programmer a little at every step, and discourages some patterns that are good, or don't cost anything in performance or clarity. Some people are willing to give up safety to avoid this. It is not just a about Option being a good thing or not, but whether we want to give up some of explicitly and agnosticity of the language to make refactoring easier.
An example: foo(Some(x), Some(y), Some(z), None) you save 50% of the time by typing foo(x, y, z, None); Lets say the 3 first arguments turns into a struct. This could be refactored to: foo((x, y, z), None); This is 2 characters. If you change the struct to use non-Option values, the code will still not break.
I would probably store the nodes as ints. Just enumerate the buttons on the keyboard starting from the left. This way you can easily change the tune of a melody by adding one to all the nodes, and you can easily to calculate stuff like "c-sharp + 1 quint" Eventuallly you also want to name the tunes, but as I see it that is a separate issue. You can live with redundancy here. One idea is to use something like the following. enum Key {D,C,E,G,A,H} struct NodeName { key: Key, is_sharp: bool, octave_number: int } 
About ways to manipulate Option nicer than raw matches: it seems like a job to combinators and monadic code (I can only find [this](https://www.reddit.com/r/rust/comments/2dnx7k/exploring_the_option_monad_with_rust/) tutorial about the subject..). Right now, what Rust offers for Option are the methods `map` and `and_then`, that corresponds to Haskell's fmap and &gt;&gt;=. For this example, your example using map from [option](http://doc.rust-lang.org/std/option/) would be something like this (beware, I didn't test): person.first_name.map(|first_name| { person.last_name.map(|last_name| { // inside this block, first_name and last_name are guaranteed to be // values inside "Some" - if any is actually None this block won't run. // You can put here code to handle the "normal path" }) }) Looking that way it is a terrible syntax, but with a macro it would look like this (note that a macro would actually emit `and_then` instead of `map` to be more general) do! { first_name &lt;- person.first_name; last_name &lt;- person.last_name; // in the rest of this block, they are guaranteed to be non-null } (I think that someone put such macro at github, but I can't find it..) Now it's still terrible (and could use the let Person { .. } = .. for further syntax sugar), but it has an interesting property: it doesn't need to return early. Instead of having the structure you propose: Extract variable from option or return early. From this point we are sure it's not None So let's manipulate the variable as if it wasn't an Option until the end of the function We would have Inside this block: `{ ...}` we are sure the variables aren't None (if they actually are, the whole thing is a no-op!) But it's just for this block, after that it's business as usual The second approach is more composable and makes it easier to move code across function boundaries.
In this case, the user was seeming to want just the first element, so a `for` loop isn't quite the right tool (since that will repeatedly call `next` and yield everything, and does not provide any way to explicitly handle the empty case).
Rust's serialization traits need some exercises like this to get in shape. I hope you are reporting issues upstream for bugs and improvements that make sense.
Because everything in that module can still call it.
Did you mean this macro? https://gist.github.com/bvssvni/9674632 I've never used it in a real project, because if it is not part of the language, then I don't bother look it up and use it, because that takes longer time than typing out the code it generates. I think there is a difference between the usage of writing monadic code and retrieving values from a struct. However, the problem this syntax tries to solve is allowing non-static expressions in the function arguments: Assume we have a struct: struct Person&lt;'a&gt; { pub first_name: &amp;'a str, pub last_name: &amp;'a str, } Then we could add a method "print_name", but in a large project, you might not want to add methods, but keep a private function close to where it is used. So, we write a function instead: fn print_name(person: Person) { println!("{} {}", person.first_name.unwrap_or_else("(null)"), person.last_name.unwrap_or_else("(null)") ); } print_name(Person { first_name: Some("Mikey"), last_name: Some("Mouse") }); vs fn print_name(Person { first_name = "(null)", last_name = "(null)" }) { println!("{} {}", first_name, last_name); } print_name("Mikey", "Mouse"); Notice how similar the last call is to: println!("{} {}", "Mikey", "Mouse"); It is easy to see that you would start with a simple case like the last one and then add stuff like default parameters, then factor out the arguments as a struct. While you are working like this, you don't want the code to break, and you want to keep things simple.
Yeah, I did not argument against you, just supplying with an example. :) It would be interesting to see an example where it can lead to error.
The [const vs static RFC](https://github.com/nikomatsakis/rfcs/blob/const-vs-static/active/0000-const-vs-static.md) might be of some relevance too, in relation to future support of CTFE.
You *might* run into trouble by just blindly calling `args.iter().next()` to skip elements, because iterators aren't guaranteed to keep yielding None forever. If the iterator had no elements to start, something wonky might happen. Edit: whoops, misread "If you want the very first value" as "If you want to skip the very first value". Carry on.
&gt; this dependently typed stuff Just a nitpick because people keep getting confused on this point, and I'd like to get out in front of it as much as possible: None of C++, D, Scala, or Haskell are dependently typed. (Though GHC may soon be, if ICFP is to be believed.) The defining characteristic of a dependently typed language is *not* the ability to use values of value-level types at the type level, e.g. to parameterize functions and types over compile-time `int` values as C++ lets you do, and Rust hopefully will. The defining characteristic of a dependently typed language is the ability to actually *instantiate* such parameters with value-level values, and not just with values that are "known at compile time" (a la `constexpr`). In C++ and future Rust you can have value-level `int`s and type-level `int`s, but you can't lift value-level `int`s to the type level. In a dependently typed language the type and value levels are collapsed and you just have `int`s. (In the literature what I'm calling the "value level" is called the "term level".) In Dependent Rust you could write: fn zeroes_and_ones(n: int, m: int) -&gt; [int, ..n + m] { [0, ..n] + [1, ..m] } There is no longer any distinction between "generics" (compile-time, `&lt;&gt;`) and "normal" (runtime) function arguments. You could also write a function which takes types as arguments and/or returns a type. This is quite a bit more radical than just being able to write `fn foo&lt;const N: int&gt;(...)`.
For ordinary users there is rustup. $ curl https://static.rust-lang.org/rustup.sh | sudo bash You can easily change it to save and check git HEAD before build i guess.
If the type and value levels are the same, should not the implementation be simpler? I played around with Idris a few days, I liked the idea that the type system allows whatever you can do in code. Would it be possible for Rust to go directly to dependent types, or is dependent types only possible by gradually adding more and more power to the type system?
It's too early for this kind of tool. There's no reason to install anything but the nightly, and that will be true until 1.0. Point releases are just the nightly on a particular night, they're not any more stable or supported than any other nightly.
&gt; If the type and value levels are the same, should not the implementation be simpler? Why would it be? (Not saying it isn't - I don't know.) [This thread](http://www.reddit.com/r/haskell/comments/2hif58/edwin_brady_on_idris_in_the_type_theory_podcast/) has some discussion of some of the difficulties that come up (such as erasure). Stephanie Weirich and Richard Eisenberg had presentations at ICFP this year about adding dependent types to Haskell, which is definitely the "gradually adding more and more power" case, but I think this might be something of an innovation, and usually a dependently typed language is built as such from the ground up. (Dependently typed languages are also usually built as theorem provers first and foremost, and not as programming languages, to which Idris is an exception.) You might be interested in those, as well in a [demo implemention of a dependently typed language](https://github.com/sweirich/pi-forall), also by S. W. (I haven't watched or read any of these yet! Too caught up in Rust things...) See also [this S.O. answer](http://stackoverflow.com/a/13241158) by Conor McBride which predates the ICFP stuff (I don't know how much they have in common). Anyways, "possible" is an interesting word, but my sense is that moving Rust directly to dependent types is not something that could be done lightly or easily, especially while keeping Rust's original goals in mind. (But ATS is also a dependently typed systems language, so maybe the two aren't inherently contradictory.) But I do have a shred of hope that maybe Rust could *eventually* be extended with dependent types, in a similar manner to Haskell. :)
&gt; If the type and value levels are the same, should not the implementation be simpler? Well, not really, because type inference becomes undecidable. That necessitates something to fill the gap—in Idris' case, tactics-based theorem proving.
There are lots of up-to-date Rust libraries which track the nightly build, but you need to know where to look for them. Once good source is [Rust CI](http://www.rust-ci.org/), which triggers library builds every night and reports on the results. You'll see that there's a large number of libraries which are sometimes broken for a day a two, but which are otherwise quite usable. And you definitely want to run the nightly builds, if at all possible. That's what most Rust developers are doing right now, even if it's a bit adventurous at times.
I know basically nothing about implementing syntax extensions, but you should be able to write your own lint for this, and then use it on your own projects with a simple Cargo dependency.
Yes, I just imported BTreeMap from libcollections that shipped with my compiler. It was compiled with Cargo using --release. I thought rust was actually good at preserving that meta-data? Since it would be needed to do any of the templated datatypes.
I'm amazed by how poor the rust HashMap performs. Does this benchmark include https://github.com/rust-lang/rust/pull/16628 ? I'm assuming yes.
I'm new to Rust, with that in mind I think using a hashmap makes sense here. Create an immutable hashmap where major (key) corresponds to minor (value). The minor key can then be associated in another hashmap which corresponds to the data that both keys represent (ie: a sound byte, midi key). Access to the minor key would be a direct thing, while access to major would be an additional step or two of determining if it's major and then accessing what it represents in minor. 
I mean, in this case, you actually want a value to signify that you want to get all the movies, rather than "limit" movies.
Making an evaluator is simple, since basically evaluation and type checking are the same. Making a surface language that is understandable and usable by someone not familiar with type theory is harder. Making an optimizing compiler for it ... is very hard.
Note that the presentation by S. W. was, in fact, not dependent types. It was only GADT, HKT and some sugar for type level literals. Arguably, GADTs are often called "poor man's dependent types". :)
Oh, okay. As I said I haven't watched - just seen others referring to these two presentations together under this umbrella.
Rather than using `.collect()`, you might use `.fold()`, `.all()`, `.any()`, `.find()`, `.position()`, `.count()` ... etc. These don't store evaluated values in a collection, but "evaluate" the values only as needed.
&gt; What fills the gap is simply that top-level signatures must be provided (like in Rust). I've been wondering whether it might make sense to look into bidirectional type checking for Rust. I know essentially nothing about it, except that the most notable (or at least most frequently noted) drawback is that it requires top-level type signatures - but Rust already does! But what are the benefits?
&gt; match args.iter.skip(0).next() { Some(a) =&gt; ..., None =&gt; ... } More like: match args.iter.skip(1).next() { Some(a) =&gt; ..., None =&gt; ... } or just use `nth()` (as it does the same thing as `.skip().next()`): match args.iter.nth(1) { Some(a) =&gt; ..., None =&gt; ... } 
Because the memory safety issues of mutable borrows actually _aren't_ only relevant in multithreaded circumstances. If you have two mutable borrows of the same memory, and you drop one of the references, the other one is now pointing at freed memory. This is also responsible for errors like iterator invalidation (note that unlike the former, this type of memory error is not handled by a garbage collector). This is why types like RefCell, which dynamically check borrow rules, are useful in single-threaded code.
I've a related (and totally noob) question, what is the easest simplest leanest way to workaround this borrowing limitation when I know it doesn't apply? For example, suppose I want two closures that modify a vector as a way to simplify my code: http://is.gd/wrFP7n - how should I implement them? (Last time I've tried it I ended up using raw pointers with `unsafe`).
This is the "easiest" way to convert from one C-style enum type to another that I can think of (without using `unsafe`): #[deriving(FromPrimitive)] enum MajorKey { CMajor = 0, GMajor = 1, ... } #[deriving(FromPrimitive)] enum MinorKey { AMinor = 0, EMinor = 1, ... } impl MajorKey { fn to_minor(&amp;self) -&gt; MinorKey { std::num::FromPrimitive::from_int(*self as int).unwrap() } } impl MinorKey { fn to_major(&amp;self) -&gt; MajorKey { std::num::FromPrimitive::from_int(*self as int).unwrap() } } You will have to be careful to make sure that the MajorKey and MinorKey primitive values always match correctly (as well as having the exact same number of keys, or you can end up triggering `fail!()` in `.unwrap()`). I'm not sure if performance might be an issue with this method (as `#[deriving(FromPrimitive)]` generates a `match` to convert from `i64` to the enum type). I wonder if a syntax extension to map a C-style enum type to another might be worth writing for something like this.
I may be misunderstanding your reply, but I'm not suggesting that there's no need for mutability checks. My point is that there are special restrictions for mutable borrows, like the fact that you can't have multiple mutable references. Within a single thread, it wouldn't seem to matter how many mutable references there are.
Could you please explain what you mean by *"drop one of the references"*? I'm not understanding why dropping a reference would free the memory. Wouldn't the memory be valid as long as there's a reference, and wouldn't the lifetime semantics ensure that we can't have a reference that outlives the referenced memory?
Thanks, yes that does help. Though looking at that code I would somehow expect `baz` to reference the new `vec` that was assigned via `*bar`, but I guess there's a distinction between references and pointers that makes my expectation misplaced. Is that right?
I guess my expectation would have been that the immutable borrow would have prevented modification of the vec during iteration. But that would seem to be prevented by not allowing mutable references to immutable data, which I understand. But given that the data is mutable, I would have thought that multiple mutable references would be allowed within a single thread. Overall I think I'm catching on though.
If you are on Ubuntu you could use the nightly package from the ppa.
Change size_of&lt;int&gt;() to size_of::&lt;int&gt;(). I have no idea why the syntax is like this actually.
To even greater confusion, C++ does have a term "dependent type" in its vocabulary, but it means [completely different thing](http://en.cppreference.com/w/cpp/language/dependent_name#Dependent_types).
The reason for that syntax is that size_of&lt;int&gt;() is ambiguous. Without having the parsing and type checking in the same step (I think it's those two things), the compiler can't know whether the &lt; symbol is a less than operator or specifying the type. The double colon syntax disambiguates that.
I think that the ability to create and store commands without evaluating them is useful, but I think the API could look a lot better if it didn't focus on that. Maybe something like con.set("foo", 42i); con.get("foo"); Have your current API be possible, but have something way simpler be the default.
Yes, I'm confused. If `baz` is a reference to `foo`, and `foo` is still in scope, why would `*baz` not be valid? How does the inner scope free memory?
So basically (written from my head, just for the idea), fn pure_evaluate(&amp;self) { for _ in self { /* NOP */ } } Allowing you to my_collection.map(|item| { /* side effects */ }).pure_evaluate() Which is really stupid because it's a convoluted way of doing a for-loop. I should knock this up in the playpen for kicks, I have no idea if this will actually work. EDIT: I find the "pure" part of the name really ironic because forcing side-effects is anything but pure.
That however requires wrapping a hundred or more functions, some of which do not map at all to function calls in rust because they are variadic. They also become a ton more complex when you use them in a pipeline. Redis is a lot more than get and set unfortunately. Some functions it might make sense to wrap, but I do not know which ones and which ones not.
Tangential question: is this a shallow or deep "size of" ? If I take the size_of a tree (or something else complex), will it tell me the size of the entire tree? Or just the first node's memory layout?
You can break memory safety in a single thread if mutable references are not exclusive. Consider an enum like this: enum Foo { Pointer(Box&lt;T&gt;), Integer(i32) } Take one reference to the boxed `T` inside a `Foo` of the `Pointer` variant. It doesn't have to be mutable. Then use a mutable reference to the enum object itself to change the variant to `Integer`. Reading from the first reference now is a use-after-free, since the boxed `T` was freed when the variant changed. You could also take a reference to the box, and try to follow a garbage pointer.
It operates on the type rather than the value (unless you use size_of_val, but even then that just operates on the type of the value), and is therefore a static size. The size of pointers (eg: to heap allocations) can't be read, because it's really just pointing to a location in memory. It doesn't actually know anything about the memory it is pointing at. That's what rustc checks at compile time. So it technically only takes up &lt;machine sized int&gt; space.
That's good to know, I presumably haven't yet got to that part of the Rust tutorial. Thanks.
This was actually a somewhat bad example, you're right (this stuff is tricky). Here's a better one, from Niko Matsakis (who designed the borrow checker): struct Foo { f: u8 } let mut x = box Foo { f: 3 }; let y = &amp;mut x; let z = &amp;mut y.f; *y = box Foo { f: 4 }; // frees the memory z points at
Here’s a simpler example that doesn’t require too much thinking about allocations, destructors and such: let mut vec = vec![1i, 2, 3]; let ref_1 = &amp;mut vec; // this mutably borrows the vec the first time... let ref_2 = &amp;mut vec; // ...and this mutably borrows it the second time // Now that we have two mutable references to the same Vec, we can do evil things let foo = &amp;mut ref_1[2]; ref_2.pop(); println!("{}", *foo); // uh-oh, what foo was pointing to is no longer in the vec `Vec`s aren’t the only things where this applies: changing the variant of an enum can invalidate references too, as noted by /u/Veddan below: let mut x = Ok(1i); let ref_1 = &amp;mut x; let ref_2 = &amp;mut x; // Take a mutable reference to the value contained in x let foo: &amp;mut int = match *ref_1 { Ok(ref mut x) =&gt; x, Err(_) =&gt; unreachable!(), }; *ref_2 = Err("foobar"); println!("{}", *foo); // uh-oh, we’re trying to take the value inside x // as if it were an Ok(int), but it’s actually an Err(&amp;str), // so we’ve violated type safety
http://is.gd/7nN9Ue Basically, if you reference a non-Copy value in a closure, the environment captures the value for the duration of the closure's existence. If you pass in a value explicitly, that's no longer the case.
I believe you need to annotate some things (maybe just generics?) as #[inline] for the library to include all the metadata necessary to do real inlining. Or maybe I have it backwards? How to correctly optimize Rust code is something that's very unclear to me.
pczarn has a really slick solution to this in development! http://discuss.rust-lang.org/t/pre-rfc-the-amortized-hashing-strategy/536/
Both references are mutable. You can get an iterator over the collection's contents by mutable reference.
I was considering going down the road of code generation as well but it makes for a crappy API if not done with care. Also it's also quite high maintenance.
&gt; Also it's also quite high maintenance. Why? Does the Redis API change a lot? The point of code generation is to reduce the maintenance.
It changes often enough and people run modified redises with custom commands.
How would you feel about a "`relet`" keyword to make such shadowing explicit? I can totally think of cases in code I've seen where reusing a variable name in this way could lead to confusion.
Thanks for the clarifications. So static dimensional analysis *is* possible without dependent types? I guess the libraries I linked to are proof. So: fn mul&lt;T: Unit, U: Unit&gt;(x: T, y: U) -&gt; UnitMul&lt;T, U&gt;; fn div_lhs&lt;T: Unit, U: Unit&gt;(x: UnitMul&lt;T, U&gt;, y: T) -&gt; U; fn div_rhs&lt;T: Unit, U: Unit&gt;(x: UnitMul&lt;T, U&gt;, y: U) -&gt; T; ?
I'm far from an expert in programming language design, but I feel like the more keywords a language has, the more complex it appears, especially to the uninitiated. That can negatively affect adoption. I'm of the opinion that it's not necessarily the language's job to make it difficult to write bad code. Rust makes it difficult to write *incorrect* code, i.e. mismatched types, dangling pointers, race conditions, etc., but you can still have correct, bad code, such as that containing ambiguous name reuse. Bad code isn't necessarily error-prone; it just adds technical debt, which is the programmer's problem, not the compiler's. The issue here is that "bad" code is subjective. An approach that is clear and intuitive to one programmer might be garbage to another. If you start enforcing subjective rules in the compiler, you're going to piss people off.
I got frustrated with juggling multiple versions of the compiler pretty quickly and hacked together a prototype that installs from source and binary, as well as versioning for things like rustc. I only really had time to work on it over vacation, and it still needs a few days of work. I would be happy to let you know when it's ready.
Sure (although, don't just tell me, tell everyone :) ).
Of course. I intend to post it to Reddit, been spending all my free time on an RFC + implementation. I'll try to get it in a public usable state in the next couple days since the main functionality is all there. I just need to add Cargo support and clean up all my debugging and such. 
&gt; Which is really stupid because it's a convoluted way of doing a for-loop. It provides supplementary semantics information (namely it guarantees the iterator will be exhausted), but that's besides the point since SirOgeon specifically noted: &gt; A for-loop is usually what you want otherwise :) and was mostly pointing out that if you want to run an iterator to its end (for its side-effects) you shouldn't use `collect()` no matter how convenient it looks. As a side note, a `run` or `exhaust` command would be as convenient as `collect` and would alleviate the risk of people using `collect` to exhaust the iterator. &gt; I find the "pure" part of the name really ironic because forcing side-effects is anything but pure. You're the one who introduced "pure evaluate", SirOgeon only talked about &gt; an "evaluate" command
They still perform unneeded work which I'm not sure is optimised away, though.
No, not really. Iterators should be used rather as views than as universal high-level collection modifiers. Although it's a really cool idea! But still unfortunately totally hides what's going on under the hood as each collection is totally different in implementation and you won't know if operation is O(1) or O(n²). If you want to use `Vec`, then prefer using it's own methods. And probably you will notice that you don't need `colect` too often.
That defeats much of the purpose of using DSL closures to simplify code, unfortunately. If I pass a reference to the vector via the argument I might as well use a non-closure function, but passing a reference will make it too verbose.
Thanks! Looks good enough. http://is.gd/2VPkfC
The main reason i have not done it yet is that i have not found a way to reuse code between connection and pipeline objects.
Iterator invalidation is a bad reason for having borrowing restrictions. It's not a problem related to memory issues, rather it's a problem of mutating some collections while iterating over them (Java collections have the same problem for example). This problem is easiest to solve by not using iterators (instead use HoF's and views). Also, the following code results in a compiler error in Rust, but it's perfectly safe and often useful: fn main() { let mut i = 1u32; let r1 = &amp;i; let r2 = &amp;mut i; *r2 = 2; println!("{}", *r1); } A slightly more complex example that is perfectly safe as well: struct Foo { x: u32 } fn main() { let mut f = Foo { x: 1 }; let r1 = &amp;f.x; let r2 = &amp;mut f; r2.x = 2; println!("{}", r1); } So, I think the Rust borrowing checker is way to restrictive (and thus not very user friendly).
&gt; Iterator invalidation is a bad reason for having borrowing restrictions. It's not a problem related to memory issues, rather it's a problem of mutating some collections while iterating over them Mutating a collection while iterating over it is *exactly* what causes iterator invalidation. &gt; but it's perfectly safe and often useful This gets in the way of concurrent code, where data races are not safe (e.g. one thread writing to an `&amp;mut`, and another reading the same memory via an `&amp;`). It is also difficult/impossible for the compiler to deduce that a mutation of borrowed will not cause unsafety in general (likely equivalent to the halting problem, which is unsolvable). The compiler has to be conservative or else there will be memory unsafety, and avoiding the problems of memory unsafety is the whole reason for Rust to exist. Hence, I don't think there is much that can be done to make the `&amp;`/`&amp;mut` part of the borrow checker less restrictive without introducing memory-unsafe holes.
&gt; Yes, what I'm saying is that iterator invalidation is a problem in the collection/iterator implementation (and possibly API as well), it's not a general memory safety issue. There's no way to have high performance collections with high performance iterators that can never be invalidated. E.g. without the strict borrowing Rust has, a collection like `TreeMap` (which is a uniquely owned AA tree) would have to point to the root and retraverse the whole tree to get the next element: a whole subtree can be deleted via a modification, and if the iterator was pointing there, it is now left dangling. And, even then, it's not possible to just avoid invalidating the whole tree entirely. E.g. let mut value: Box&lt;uint&gt; = box 1u; let ref_into_heap: &amp;uint = &amp;*value; let mutable = &amp;mut value; *mutable = box 2u; // whoops! The last line is a new allocation, and the old allocation is destroyed; but `ref_into_heap` points to that old allocation! It's now a dangling pointer (same problem as when the `uint` is a collection and `ref_into_heap` is an iterator). This sort of behaviour can happen internally to a collection type too (e.g. `TreeMap` as described above). &gt; This thread is about single threaded execution Changes to the type system do not happen in isolation, the rules have to work for all situations, including multithreaded code. Furthermore, the language (hence the borrow checker) does not/*should* not need to understand threads, all it sees are function calls and `&amp;foo`s and `&amp;mut bar`s etc. I say "should" because there is more than one threading model and each is appropriate in different situations. Baking a fixed set of them into the language makes it likely that any others are handled less well; it is better to provide enough type system features for each threading model to be able to expose a good and safe interface. The [built-in traits](http://doc.rust-lang.org/nightly/std/kinds/index.html) are part of this (specifically, [`Send`](http://doc.rust-lang.org/nightly/std/kinds/trait.Send.html) and [`Sync`](http://doc.rust-lang.org/nightly/std/kinds/trait.Sync.html) are for multithreaded code). In particular, there are models where &gt; my examples are using references to thread local stack data which obviously shouldn't be allowed to be shared between threads is false. All that is needed is for the subthread with the references to be guaranteed to finish before the references die (that is, before the parent thread leaves the stack frame the references point to). Rust's lifetimes, borrowing and the `Sync` trait enable people to write libraries that expose 100% safe interfaces for this. &gt; IMHO there is much room for improvement in the Rust borrower/lifetime checker. Yes, there are improvements, the major one is [making borrow scopes non-lexical](https://github.com/rust-lang/rust/issues/6393), but keep in mind that any "improvements" must be [*provably*](https://github.com/nikomatsakis/rust-redex) memory safe; I find it unlikely that there is much that can be done to make the interaction between `&amp;` and `&amp;mut` borrows less restrictive because it is just *so* easy to invalidate references via `&amp;mut` (and allowing `&amp;mut` to alias loses useful guarantees Rust has for certain optimisations).
&gt; There's no way to have high performance collections with high performance iterators that can never be invalidated. I think it's bad to use iterators in the common case (they should rather be a special case when nothing else can be used). For the vast majority of the collection operations, HoF's and views should be used instead of iterators. To hinder the developer with borrowing rules that makes the rare iterator case safe is not a good design decision IMHO. &gt; Changes to the type system do not happen in isolation, the rules have to work for all situations, including multithreaded code. Again, to make writing single threaded code harder just because you sometimes need to use multiple threads in a special way is another bad design decision. You should not disallow perfectly safe and valid single threaded code just because the borrowing checker inference is limited in the multi threaded case.
&gt; For the vast majority of the collection operations, HoF's and views should be used instead of iterators HoF's are not nearly as composible as iterators, iteration/collections in Rust used to be based around HoF's but this just didn't work out (e.g. try mapping over two collections in lock-step with a HoF `map`... and, before you define a `map2`, the collections can be arbitrary). Maybe you're thinking of Haskell with it's HoF's like `map` and `fold`... but that's exactly what Rust has: `[a]` is actually exactly an `Iterator` due to Haskell's laziness! (Functions like `fmap` and `&gt;&gt;=` serve a different purpose: structure preserving "mutations", nothing for interfacing between types and connecting/collecting values.) In any case, an iterator *is* a view. &gt; To hinder the developer with borrowing rules that makes the rare iterator case safe is not a good design decision IMHO. The borrowing rules are not just for iterator invalidation, e.g. the example in my parent comment just there didn't have any iterators in it. (I said it could apply to iterators, but the actual code there has no iterators and is currently broken.) &gt; Again, to make writing single threaded code harder just because you sometimes need to use multiple threads in a special way is another bad design decision. You should not disallow perfectly safe and valid single threaded code just because the borrowing checker inference is limited in the multi threaded case. It's not perfectly safe just because it is single threaded; look at my previous comment, look at the rest of the thread, there's several examples of single-threaded code that is broken, and is caught by the strict borrowing rules. The examples you gave before were special cases with very restricted behaviours that allowed a human to easily verify that it is OK, but as soon as you have function calls and pointers it becomes much harder (meaning that any relaxations can only apply to a few very special cases).
&gt; In any case, an iterator is a view. No, an iterator is not a view, it's more like an element pointer with an increment operation. I'm talking about Haskell stream fusion and similar libraries, i.e. immutable data types to iterate over collections. And all batch operations should be lazy until forced into a new collection. I realize that it's a hard problem to implement a "perfect" aliasing/reference checker, but I fear the restrictions in the current implementation may be a big annoyance, and turn off, for C++ programmers (like me) that are starting to use Rust. And it might also make people use reference counting more than necessary, which really isn't a good thing.
Not sure whether this is still valid or not, but here is a guide from July: https://github.com/npryce/rusty-pi/blob/master/doc/compile-the-compiler.asciidoc EDIT: and another one: http://metaverse.fr/blog/compiling-rust-for-the-raspberry-pi/ YET ANOTHER EDIT: *facepalm* should have pointed you towards Zinc as well: https://github.com/hackndev/zinc
Work on form controls has started, though IIRC we're using text-based widgets for now (eg `(*)` for radio buttons.) Once we integrate html5ever we'll probably make document.write work which might fix part of acid3
Yeah, we're probably passing quite a bit more than 0/100 in reality, because a fair bit of Acid3 is just JavaScript stuff that SpiderMonkey passes. Notice that Acid3 just crashes before executing any tests because `document.write()` doesn't work. In any case Acid3 isn't a focus at present, since it covers a lot of esoteric stuff that normal Web sites don't use nearly as much as other things we have yet to implement (like forms). The focus is on getting to browse real Web sites.
Looks like your accelerated layers is messed up for Acid2 (graphics driver or HiDPI issue perhaps?) The parts that are missing are precisely those that got a separate GPU texture.
i don;t even... know where to start debugging (i;m using Nvidia's proprietary graphic driver + servo git cloned yesterday.. some changes landed between then and now. i'll see what i can make of it and open some bug reports (i'm not very familiar with rust)) 
thanks :&gt; i bet you are using Arch. 
Speaking of html5ever, I've read it claims it is pretty fast, but haven't seen any benchmarks. I actually downloaded/built the code but there were no benchmarks I could run (Makefile benchmarks failed, while cargo didn't run any).
Hectic, that example makes a lot of sense. Thinking of corner cases is making my brain hurt. That's actually really interesting - smart pointers can save you when everyone is pointing at the same memory address, but not if you point into something else. Does C++ allow you to create smart pointer dependencies, where the owning object creates a smart pointer to lend out data safely? I somehow doubt it..
Should somehow automate the production of this video, and then record it every month.
Every proposed solution I've seen to this problem short of garbage collection ends up looking exactly like Rust's borrow checker. I think the Rust team was toying with being able to identify lifetimes more precisely like this but gave it up as being too complex (and not obviously safe) for too little benefit.
The Rust team doesn't officially provide nightlies nor stage-0 snapshots for ARM, so you'll have to cross compile an ARM compiler yourself. [This article](http://github.jfet.org/Rust_cross_bootstrapping.html) has the details on how to do that. I've been recently working on getting Rust and Cargo to work on the two ARM boards I have (Odroid XU and Beaglebone), so far I got Rust working on both and I've yet to check if Cargo builds and works. I've put my build scripts in [this repository](https://github.com/japaric/ruststrap), and I'm thinking if I should host unofficial nightlies for Rust and Cargo, but I've some doubts: - Is there any people (apart from myself) interested in such thing. - Will my nightlies work OK in environments that I can't test? (a.k.a. I need testers) Anyway, if you would like to test the unofficial nigthlies I'm making, you can PM me. P.S. I only have nightlies for hard float armv7a, so they won't work on the Pi, but they should work on the A20.
&gt; should have pointed you towards Zinc as well: https://github.com/hackndev/zinc The zinc stack is for bare metal environments, I think the OP wants to run the rust compiler within some linux distribution. (Also doing bare metal programming on a ARM processor (with MMU) is more complicated than using zinc on an ARM microcontroller, plus IIRC zinc only officially supports two microcontrollers at the moment: LPCxxxx and STM32F4xxx)
My point is simply that iterators (in Rust, Java etc.) are by definition mutable, while streams (and views) can be immutable (even if the underlying collection is mutable). &gt; Shared ownership interacts horribly with mutability, so reference counting is not a fix. I don't claim it is. I just meant that it can be abused as a work around for the unnecessarily strict borrowing rules, i.e.: use std::rc::Rc; use std::cell::RefCell; fn main() { let f = Rc::new(RefCell::new(1u32)); let r1 = f.clone(); let r2 = f.clone(); *r2.borrow_mut() = 2; println!("{}", r1.borrow()); } 
Ah, I was wondering if there was a way to change a mutable variable to an immutable one or vice versa. It would be nice if there were an explicit way to do it without shadowing though.
actually not :) i'm using mac os. but... term is term :)
On my MBP i7 nightly build compiles about 2,5 hours. And, yes, runs properly. But still in development, so changing every day. btw, you don't need to buy it, it's free. instead you can donate to mozilla. ;P 
Wrong subreddit. You want /r/playrust
I've never worked with different processor architectures, so forgive my ignorance: Why would you need to install rust on the ARM board? Wouldn't it be enough to cross-compile the program using "regular" rust, and then put *that* on the board?
"do! { first_name &lt;- person.first_name; last_name &lt;- person.last_name; // in the rest of this block, they are guaranteed to be non-null }" This is clean looking! I really like Clojure for its cleanliness, perhaps a different take on this: do! [first_name person.first_name, last_name person.last_name] //bindings { // in the rest of this block, they are guaranteed to be non-null } just a thought
I'd say `advance(|_| true)` is probably the most likely to be the most performant way of consuming an iterator: fn main() { range(0i, 10000).map(f).all(|_| true); } See http://is.gd/C47Gho.
I'd love to see a new sub accompanying it! I can't always get on IRC but I am definitely interested in Rust API design.
Just wanted to say it's awesome to have a channel like this. Rust's biggest promise is the ability to create safe, efficient, concurrency-friendly abstractions, and I think it's pretty great at that! But I think many people struggle when they come to Rust to understand how to apply patterns from other languages. In addition, a lot of Rust's newer (e.g. explicit bounds on lifetimes, unboxed closures), more complex (procedural macros), and upcoming (like multiple dispatch and associated types) features are mostly of interest for library designers, but are poorly documented or don't have many real-world examples yet. It's practically a full-time job keeping up with the language enough to even know what's possible! So the more people we have sharing ideas and solutions, the better :)
For the lazy: [Direct link.](irc://irc.mozilla.org/#rust-apidesign) ;)
Unneeded work? Depends on what is needed I guess. `.all(|_| true)`, `.any(|_| false)` and `.fold((),|_,_| ())`(for the type of iterators we are talking about) are internally just for loops that calls a closure in each iteration . The closure and any related unnecessary branching gets optimized away when compiled with optimizations turned on. Having said that, it's true that using a for loop is often easier to read/debug than having a bunch of closures chained together with `.map()` and ending with an `.all(|_| true)`.
What kind of performance concern are there with `Default`?
My link is also a direct link! And it works for people who don't have an IRC client installed! :)
Well, FF has mibbit built-in as a protocol handler. ;)
http://discuss.rust-lang.org/t/struct-sugar/551/14
Correct me if I'm wrong, but the average desktop user is more or less unaffected by this bug. I can't see any super-evil attack vector. That said: Of course one should install the update but it's not more urgent than the myriads of past updates fixing remote code execution bugs caused by the usage of unsafe languages. ;)
About crate concatenability: I didn't even know about this. Wouldn't `use` statements and explicitly fully qualified paths already throw a wrench in that set of gears? For me, the big win is that my code won't break on new trait implementations when I'm not using the trait. For the given example: Code that doesn't deal with `Image` at all (by not importing it) won't break by implementing it for `Player`. But as far as I can see, this would not change in this implementation. And given what advantages it would bring it could be very well worth having to be more explicit sometimes.
&gt; My point is simply that iterators (in Rust, Java etc.) are by definition mutable, while streams (and views) can be immutable (even if the underlying collection is mutable). I don't see your point. Iterators are not mutable by definition and you can also have an arbitrary amount of immutable views (aka iterators) into a mutable object.
Generally it'll delete a word backwards, like ctrl-backspace in other applications. I'm happy `^W` works like I expect in pentadactyl, that's saved me a lot of accidentally closed tabs.
Yeah, but coming from C++ I'm irked that I can't use an Allocator to put a temporary Vec or a HashMap or a String into a piece of stack, that makes the overhead of RefCell somewhat of a moot point because the Vec itself is already an overhead. Maybe the task-local memory makes for a superfast allocation which I shouldn't worry about. In C/C++ the allocation eats a lot of cycles, though.
&gt; However, if we consider beyond a single crate, then it is possible that some other crate comes along and adds more impls. For example, perhaps another crate adds the conversion to the MyInt type that we saw before: &gt; &gt; struct MyInt { i: int } &gt; impl Convert&lt;MyInt&gt; for int { ... } // int -&gt; MyInt Is this really possible? How can "some other crate" add an implementation of a trait it doesn't own for a type it doesn't own?
Honest/ignorant question: why does it take so long to render compared to firefox? (I know it's in early-stage development etc...)
IIRC some DHCP clients are vulnerable, but not the ones on OSX
Is there a reason *not* to reserve keywords "just in case"? This comes up here in the case of newtype, but I was also wondering about, e.g. "become" for guaranteed-TCO. It just seems like it's a pretty low cost thing to do, and it's a lot easier to release words back into use than claim new ones.
Small nitpick: Either I'm missing something elementary, or there's a typo. &gt; impl Convert&lt;uint&gt; for int { ... } // int -&gt; uint &gt; impl Convert&lt;int&gt; for uint { ... } // uint -&gt; uint Shouldn't that second comment say `uint -&gt; int` (not `-&gt; uint`)? 
Yes, looks like a typo, it should say `uint -&gt; int`
Under multi-dispatch, you can also get by with owning a parameter of the trait being implemented, since these are used for dispatch just as the Self type is.
Make T a concrete type owned by the second crate and it works, since Vec&lt;[T]&gt; would then be owned by the second crate. 
Specifically, AIUI, as long as your crate is the creator of *any* of the types used in the implementation, that proves to the compiler that no other crate is going to provide a differing implementation for the same type, which heads off the problem that the coherence rule was designed to address.
I feel it important to specify that it's any type in the *signature* of the implementation, since types used in the body have no effect on coherence.
I don't know if "crate concatenation" was meant to be taken literally, AFAICT it just referred to adding new impls without causing existing code to become ambiguous.
FWIW, I have very similar effects with both Intel and ATI drivers. Scarily enough the ATI drivers occasional even show things drawn by other applications. While this clearly seems like a driver problem I've only ever seen it occur in servo…
A readline is a readline http://www.bigsmoke.us/readline/shortcuts
It is definitely more complicated to get a usable language. It is relatively easy to implement a type checker for something like the Calculus of Constructions because the typing rules are "simple" and fit on a page or two. Like this [paper](https://personal.cis.strath.ac.uk/adam.gundry/pattern-unify/pattern-unification-2012-07-10.pdf) by Adam Gundry and Connor McBride says in the introduction if you have simple kernel theory you don't need much to check it. As you move towards a full language you need more complexity like higher order unification to perform elaboration and implicit argument synthesis (like it is done in Agda). This is also a good paper on implementing a very simple dependently typed language: http://www.andres-loeh.de/LambdaPi/LambdaPi.pdf.
&gt; My point is simply that iterators (in Rust, Java etc.) are by definition mutable, while streams (and views) can be immutable (even if the underlying collection is mutable). It is easy to build immutable lazy streams on top of iterators (a shared linked list of thunks that call `next` to generate each successive value); but it is much much harder to build equally powerful "mutable" iterators on top of lazy streams when there are affine types and value types (that is, languages like Haskell and Java that have global GC have it easy). That is, the mutable versions are the more fundamental types. In any case, a stream/view has to be mutating some part of memory, at some point, or else no computation will ever happen; a language like Rust is just exposing precise control over this to the programmer. &gt; I don't claim it is. I just meant that it can be abused as a work around for the unnecessarily strict borrowing rules, i.e.: The heap-allocated reference counting is not at all necessary, it's the `RefCell` that's fixing the "problem" here. use std::cell::RefCell; fn main() { let f = RefCell::new(1u32); let r1 = f.clone(); let r2 = f.clone(); *r2.borrow_mut() = 2; println!("{}", r1.borrow()); } Anyway, I encourage you to try to formalise (or at least write down) some less strict borrowing rules and see if they're memory safe.
[A PR](https://github.com/servo/servo/pull/3535) landed earlier today that appears to fix Acid2 rendering.
Thanks for the update! [Link to the Nickel.rs website](http://nickel.rs/)
That's quite possible :)
In your example: &gt; extern create redis; Ha! I'm glad to see I'm not the only one who (in my case, *constantly*) does that. Have you ever considered a special syntax error for that one? :3
I'm using A Rust nightly. For me it's: rustc 0.12.0-nightly (d64b4103d 2014-09-26 21:47:47 +0000) Makefile failure is: task '&lt;main&gt;' failed at 'can't open file', /home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libcore/option.rs:314 As for the benchmark it is a great start :D, on the other hand libxml2/lxml is from some benchmarks[1], approximately 100-180 times faster than html5lib, which would make html5ever 20-30 times slower than that ;) (it's not by that *exact* amount, but it still is an order of magnitude slower). [1] https://github.com/seriyps/html-parsers-benchmark
Doesn't even have to be special, there's only a few things valid after `extern`, just levenstein distance against them and suggest the one with the least distance.
Look at the `by_ref` method. It will let you pass your original reader into the buffered reader and get it back when you are done. 
I was thinking more along the lines of: &gt; `error: rustc cannot create externs for you; that's your job.`
Thank you, I'm sure I'm on the right track and I'm trying to use this but the "when done" part is where I'm stuck. If I simply store the TcpStream in the struct and create a BufferedReader when read_line is called, then at the end of the function any unprocessed data gets destroyed along with the BufferedReader. So I need a BufferedReader to exist the entire time. However, I can't do this either: struct Server&lt;'a&gt; { conn: TcpStream, read: BufferedReader&lt;RefReader&lt;'a, TcpStream&gt;&gt; } Because I cannot call by_ref without a weird hack around UFCS, which may or may not be causing complaints that the connection does not live long enough: fn new() -&gt; Server&lt;'a&gt; { let mut conn = TcpStream::connect("127.0.0.1", 4847).unwrap(); conn.set_timeout(Some(500)); // Needed because both Reader/Writer::by_ref are in scope for TcpStream, and no UFCS // so can't Reader::by_ref(..) fn get_reader&lt;'r, T: Reader&gt;(r: &amp;'r mut T) -&gt; RefReader&lt;'r, T&gt; { r.by_ref() } /* Error, &amp;mut conn does not live long enough */ Server { conn: conn, read: BufferedReader::new(get_reader(&amp;mut conn)) } } 
Sorry for the late reply. The keyword version (don't really care what the keyword is) makes it easier to move code from a lambda to a function and vice versa. There's extra needless syntax changing between fn(whatever) and |whatever| that seems like it would feel worse than replacing a word (which you have to do with the function name anyways) I'm a bit confused as to what you mean by virtual dispatch. I guess you are saying that a trait function is still a `fn` type even before a typeclass dictionary has been supplied to it?
I think the .all() call [here](https://gist.github.com/Thiez/a139bfaefbd44865872a#file-constraints-rs-L48) would still wait for the threads sequentially, so it wouldn't short-circuit when the fastest thread returns false and isn't at the beginning of the vector. 
It's not insanity in Haskell, e.g. there is [a "variadic" `printf` function](http://stackoverflow.com/q/7828072/1256624), which works by overloading its return value to either be a function or the result of a printing. (Also, if you're talking about type system power, Rust isn't that strong; dependently typed languages like Idris, Agda and GHC Haskell* can express much more in the types than Rust.) ^*Yes ^I ^know ^it's ^not ^really ^dependently ^typed, ^but ^the ^rest ^of ^the ^statement ^still ^holds ^for ^Haskell.
&gt; The heap-allocated reference counting is not at all necessary, it's the RefCell that's fixing the "problem" here. Doesn't work, your version prints 1 instead of 2. I believe it's cloning the actual value, not the reference.
This is brilliant! thanks for this and all your other work japaric 
That was a really nice read, interesting perspective. Not sure if op is author, but if you are reading this: Yes, for your question towards the end.. I would be interested in reading about the development process for redis-rs 
OP is not the author, but /u/mitsuhiko is active in this subreddit, too.
[Link to the RFC](https://github.com/rust-lang/rfcs/pull/160), just in case someone is wondering what that construct is supposed to do.
Crikey 8 year club? Must've been one of the first people on reddit.
If, like me, you have attempted to parse some complex JSON documents, you have probably encountered various issues with libserialize: - https://github.com/rust-lang/rust/issues/17658 - https://github.com/rust-lang/rust/issues/17377 - https://github.com/rust-lang/rust/issues/15659 - https://github.com/rust-lang/rust/pull/15795 They can't easily be fixed because of API-related issues. Since I want to parse some complex JSON documents right now, I've created my own crate. Here is a real-life example of what you can do with it: https://github.com/tomaka/spine-rs/blob/master/src/format.rs 
Maybe instead of this: match optVal { Some(x) =&gt; { doSomethingWith(x); } _ =&gt; {} } Rust could allow this: match optVal { Some(x) =&gt; doSomethingWith(x); } As long as match returns nothing, `_=&gt; {}` could just be implicit. It will solve the verbosity problem without introducing new syntax. EDIT: OK, now I understand that the new syntax is needed to save the purity of `match`.
Rust types are cool, but this wouldn't really be hard to implement in most languages. Chained function calls and multiple returns have been around for a long time.
&gt;It's practically a full-time job keeping up with the language enough to even know what's possible! So true. Without digests like "This week in Rust" and proper documentation you pretty much have to read through all the merged pull requests to be aware of new features and read #[test]s for examples of their usage x_x
Isn't the idea with match being that you are forced to handle all cases? If it implicitly did nothing on "no match" then it loses a lot of its power
As a Rust newbie who is familiar with Haskell, I too would've liked to see an example of it being "not perfect". It follows a pretty clear set of rules; the only "false positives" I've seen are when you're doing something you probably shouldn't be doing anyway, even if it's technically possible to compile.
It could be a compiler warning, in case of missing enum variants.
But if you have an implicit default, you may miss a case. Especialy if you add latter a new variant to the type, the compiler will warn you when it is not handled. Add `_ =&gt; {} ` when needed don't seem so cumbersome to me.
Warnings are easy to ignore. 
The requested URL /tomaka/from_json/doc/from_json/ was not found on this server.
I noticed this. It's probably because the travis build fails because it doesn't download the latest rustc. This will fix itself in a few days at most.
Compiler won't warn you if you have `_ =&gt; {}` and add new variant.
Can confirm
That's exactly why I advocate you should define manualy a default value, only when you have to. When you define a default, there it is no more unhandled case, so if the default value is always defined, you always loose this check.
Why throw an error only on the match and not on all partial function definitions? And if explicitly covering all cases is an important problem why allow 'if' to have an implicit empty 'else' ? Just curious...
Mitsuhiko is a really big name in the python world. He's the creator of projects like flask, jinja, and werkzeug.
Match is designed to do cover the variants of a data structure, and if some variant is missing, you probably made some mistake (more often than not, that's correct. Haskell does what you suggest, but with the - Wall flag, and it has shot me in the foot lots of times). If, when used as a statement, just performs some action in the case of a bool expression being true. But, when used as a expression, else is required. 
`bool` has exactly two variants. This is widely known and unlikely to change. (I.e. an omitted `else` is much more likely to be intentional rather than a mistake, and is unlikely to get broken by a refactor changing the definition of `bool`.) Neither are necessarily true of user-defined `enum` types.
Shouldn't the UFCS example be `Cowboy::draw(&amp;player)`or `Image::draw(&amp;player)`? The call to`Player::draw(&amp;player)` makes no sense to me.
Meh, 8 years ago Reddit was a bit of a different place, but I think that's the least of his achievements...
I feared it would be similar to Swift's (solely dedicated to `Option`) but as a construct for "lightweight" refutable pattern match it looks nice.
Here's an example I've run into a couple times: let mut t = std::collections::treemap::TreeMap::new(); ... match t.find(&amp;key) { ... None =&gt; {t.insert(other_key, other_value);} } Playpen example [here](http://is.gd/yzR1td). This fails to compile due to the borrow checker. If it were `Some(&amp;val) =&gt; t.insert(other_key, other_val)`, that would be unsafe: the insertion might invalidate the reference to `&amp;val`. But because its a `None`, it should be safe to insert. However, this subtlety is lost on the borrow checker, and the borrow checker won't allow it.
I'm looking over the website and came to the section of [routes](http://nickel.rs/#routing). So you can specify rather fancy routes as strings: server.get("/bar", simple_handler); server.get("/user/:userid", handler_with_param); server.get("/a/*/d", simple_wildcard); server.get("/a/**/d", double_wildcard); Would it be possible to verify these statically with a macro, similar to how `println` checks the format string? **EDIT:** I haven't actually used Nickel.rs, so it's quite possible that this is already the behavior, but I did not see mention of it looking over the website so far.
Do you want the _ case to evaluate to () by default?
Why not just break them up by using generic parameters instead? Then you save an allocation.
A simple example of a shortcoming of the borrow checker: AFAIK it is not possible to mutably borrow non-overlapping parts of an array and modify them in different threads (without using unsafe code). (There is `chunks_mut`, but I did not manage to use it in different threads.)
Isn't Idris basically an extension to GHC that introduces dependent types (and changes syntax slightly)?
I'm glad to see my suggestion to unify the return type and struct initializer got picked up, unless it made the rounds before I brought it up.
&gt; Rust isn't that strong Rust's type system *is* more extensive than the mainstream languages most programmers are used to. One day we'll end up shifting the window of perception ("lol *rust* has a strong type system? what are you even smoking") but for now I don't think we need to be especially modest in this area, unless speaking specifically to an audience versed in Idris et al.
The thing is that Borrowck is purely lexical right now. This cause these two classic examples of borrowck sucking: foo.set(foo.get() + 1); // error, cannot borrow foo immutably, because it is already borrowed mutably and match foo.find(key) { None =&gt; foo.insert(bar), // error, cannot borrow foo mutably, it is already borrowed immutably Some(x) =&gt; {}, } These two methods (in std::collections::TreeMap!) should logically have identical code, but borrowck gets angry in the mutable case, so you have to introduce a temporary variable that doesn't clearly accomplish anything. fn tree_find_with&lt;'r, K, V&gt;(node: &amp;'r Option&lt;Box&lt;TreeNode&lt;K, V&gt;&gt;&gt;, f: |&amp;K| -&gt; Ordering) -&gt; Option&lt;&amp;'r V&gt; { let mut current: &amp;'r Option&lt;Box&lt;TreeNode&lt;K, V&gt;&gt;&gt; = node; loop { match *current { Some(ref r) =&gt; { match f(&amp;r.key) { Less =&gt; current = &amp;r.left, Greater =&gt; current = &amp;r.right, Equal =&gt; return Some(&amp;r.value) } } None =&gt; return None } } } // See comments above tree_find_with fn tree_find_with_mut&lt;'r, K, V&gt;(node: &amp;'r mut Option&lt;Box&lt;TreeNode&lt;K, V&gt;&gt;&gt;, f: |&amp;K| -&gt; Ordering) -&gt; Option&lt;&amp;'r mut V&gt; { let mut current = node; loop { let temp = current; // hack to appease borrowck match *temp { Some(ref mut r) =&gt; { match f(&amp;r.key) { Less =&gt; current = &amp;mut r.left, Greater =&gt; current = &amp;mut r.right, Equal =&gt; return Some(&amp;mut r.value) } } None =&gt; return None } } } 
since you can define the `_` case, i don't see where is the problem. 
Apparently libxml2 [implements](http://xmlsoft.org/html/libxml-HTMLparser.html) a "HTML 4.0 non-verifying parser", which I suspect is much simpler than a HTML5 parser with all the precisely-specified handling of bad markup. Still, I hope and expect that html5ever can do a lot better than 20x slower. Thank you for the link to the benchmarks; I will look into integrating html5ever so we can get some more numbers!
Another factor is that I haven't optimized the DOM representation used in that benchmark at all, because Servo has its own DOM. It's definitely doing some silly things like linear search for attribute names.
Good point, in the 70's C was a high level language. Easy to use, massive standard library, competitive performance. Today its considered microscope bare bones, and a barely a low level step above assembly.
I noticed this: `children = [].as_slice(),` you can now do this: `children = [][],` it's valid syntax, just try let v: &amp;[u8] = [][]; *I still favor the [..] syntax myself*
Thanks for quick answer. I usually SO silly questions, but I couldn't remember if it was like Python or like C. +1 to both.
No, it is a completely separate language http://www.idris-lang.org/. Although it is currently written in haskell.
&gt; Thank you for the link to the benchmarks; I will look into integrating html5ever so we can get some more numbers! My pleasure really, I've been reading and puzzling html5ever library. It's quite huge - I like the macros you used, I might crib them :) for my own parsing needs. As for the implementation, it's not that hard, I'm probably almost done with integration. 
The dicussion on the RFC also brought up the possibility of a `while let`, but it was decided to defer discussion until after `if let` was implemented. It could be useful in code like: while let Some(n) = stack.pop() { /* ... */ } So I'm crossing my fingers that `while let` will follow soon, as well.
I wonder if messagepack is better for such an example.. https://github.com/mneumann/rust-msgpack
Yeah, I thought `[].as_slice()` made it clearer.
I think the error should go away :) But I don't program in rust so I don't have any skin in the game :). I've just come to appreciate a language that gives me a guarantee about something (i.e., memory safety), and one that is opinionated (which can also be OK, if it is uniformly applied). No big deal, just different strokes for different folks.
Yeah, and making it in C++ so it has static type safety wouldn't be all that difficult unless I'm totally missing what people are talking about (which is extremely possible).
It's looking pretty favorably. EDIT: and accepted https://github.com/rust-lang/rust/issues/17687
I've been warned of this in the past. &lt;small&gt;okay that was terrible&lt;/small&gt;
Yeah, `while let` would be nice for this case, though currently, it's possible to do it this way I think? loop { for Ok(v) in rx.try_recv().into_iter() { /* Process incoming messages. */ } /* Do some handling while waiting for more messages. */ timer::sleep(); }
This would only recv one message from the channel.
Would it be possible to implement `into_iter()` for any `Fn() -&gt; Result&lt;X,E&gt;`? And then `rx.try_recv.into_iter()`?
I've had a look at one of the Idris papers, and the syntax looked almost identical to Haskell (it uses a lot of the same keywords, `:` instead of `::`, etc.). I know it is a separate language, but superficially it feels like a Haskell dialect. The author of Idris states that it asks the question: "What if Haskell had full dependent types?" [1] [1] http://eb.host.cs.st-andrews.ac.uk/drafts/impldtp.pdf
Oops. Yeah. I wish there was a way to generate an iterator from a closure returning `Option&lt;T&gt;` or something, but I suppose even that might not work in this case as the closure ends up moving `rx`.
Yes, the 'borrow checker' is very similar to region analysis. The first language that I'm aware to have done something like this is Cyclone: http://www.cs.umd.edu/projects/cyclone/papers/cyclone-regions.pdf &gt; Does this mean one can have a ML-like language without GC? I'm not good enough with ML to tell you.
Maybe something like this (untested)? struct IterateOk&lt;'a, O, E&gt; { f: ||:'a -&gt; Result&lt;O, E&gt; } impl&lt;'a, O, E&gt; Iterator&lt;O&gt; for IterateOk&lt;'a, O, E&gt; { fn next(&amp;mut self) -&gt; Option&lt;O&gt; { (self.f)().ok() } } fn iterate_ok&lt;'a, O, E&gt;(f: ||:'a -&gt; Result&lt;O, E&gt;) -&gt; IterateOk&lt;'a, O, E&gt; { IterateOk { f: f } } Then use it like: for v in iterate_ok(|| rx.try_recv()) { /* Process incoming messages. */ }
EDIT: this comment describes closure types in Rust historically, but be aware that both the semantics and the syntax of closures are (and have been) in the process of changing and this comment does not address that. For a start, see [Uniq&lt;strncat&gt;'s comment here](http://www.reddit.com/r/rust/comments/2i10b8/how_does_rust_support_algebraic_data_type_with/cky5v6n) and the [relevant RFC](https://github.com/rust-lang/rfcs/pull/77/files). Closures in Rust aren't as general as closures in other languages. Some closures cannot be returned from functions, only passed to other functions (which means that the memory they reference can live on the stack, as there's no way for them to outlive the stack frame where they were created.) Other closures can only be called a single time, so that the memory they reference can be freed as soon as they have been invoked. That means that you can't naïvely write the classic `counter` example from ML: let mkCounter () = let n = ref 0 in fn () =&gt; (n := !n + 1; !n) because one kind of closure cannot be returned: fn mkCounter -&gt; (|| -&gt; int) { let n = Cell::new(0); || { n.set(n.get() + 1); n.get() } // not okay---the closure leaves its stack frame } and the other can only be called once: fn mkCounter -&gt; (proc() -&gt; int) { let n = Cell::new(0); proc() { n.set(n.get() + 1); n.get() } // this is okay } fn main() { let c = mkCounter(); let x0 = c(); // okay let x1 = c(); // not okay---c already called } Still: these closure types are general enough to do _most of_ what you'd do with them in other languages, e.g. `map` takes the former, and `spawn` (for creating new threads) takes the latter.
std::num::Signed is *likely* going to disappear in a few weeks. aturon's working on a proposal for this. We don't want to have to support a pseudo-mathematical hierarchy that's probably broken. That's a job better served by individual math libraries. Instead everything will be compressed into simple extension traits for "(u)int" and "float".
&gt; "We need to start reasoning a lot more about collections of things and what transformations we actually want to do." This sort of thing is exactly what Clojure aspires for, and does well I think. 
Those are the legacy closure types. Those restrictions don't apply to new implementation of closures.
That's not really a shortcoming of the borrow checker, just missing library support for fork-join parallelism: Its safe to create non overlapping mutable slices from an array (see the `mut_split_at` method), and it is safe to modify those concurrently in different threads (no library written yet, but possible to define due to the `Sync` trait).
Comes from emacs I think, doesn't it?
Wouldn't C++ require a lot of extra annotations which Rust here is inferring? (But yeah, Rust-like inference isn't too hard)
Everything in that module should be able to call the function or should not be in that module. Basically, putting thing in module foo is saying #[part_of(foo)] for that thing.
Is there any reason to use `pub:` instead of only `pub`? The colon seem unnatural to me. 
Can Win 10 be run as VM?
I guess people are doing it with success
I don't see what you think is the problem with algebraic data types. They don't require dynamic allocation. Their data is just "inlined" where the size of an `enum` is the size of the largest variant plus a discriminator (or possibly smaller in case of things like `Option&lt;&amp;T&gt;` which can be optimized into a single nullable pointer). As for closures, Rust currently supports 5 different kinds of closures that are suited for different kinds of tasks: boxed closures (`||` and `proc`) and unboxed closures. Boxed closures carry a pointer to the closed-over data with themselves. A `||` boxed closure possibly points into some stack frame which limits its lifetime. Unboxed closures carry their state with them (inline), so no indirection and no heap allocation is necessary. However, for boxed `proc` closures the variables are moved into a heap-alocated block. But this does not require a garbage collector because the heap block is considered "owned" by the function. As soon as the function is consumed/falls out of scope, the block is released automatically just like how it works for `Box&lt;T&gt;`.
I installed and booted it in VMware without issue. I have not experimented much yet though.
I kinda wish I had the time to get my COM prototype working with WinRT as well. Then again, I decided to wait for the inheritance stuff to shake out first, before re-implementing it all with mountains of macros and unsafe. :P
It is to make all members of the struct public. You start defining a struct in local scope: fn foo() { struct Bar { ... // lots of members } } And then refactor it to: mod bar { pub: struct Bar { ... // lots of members } } fn foo() { use bar::Bar; } The current syntax requires putting `pub` in front of every member. In many applications a struct only represent data, so it would be nice to make every member public instead. This RFC addresses concerns around refactoring, building upon an idea of unifying name syntax for function arguments and struct initialization.
Wait, Windows 10? Why are you doing this? :)
There's no way in such a system to express "here is a function with three sub-functions, which can only be called by the parent function".
I see some [sinon](http://sinonjs.org/) is leaking...
I can't think of any semantic reason why this would be better than an `Answer` wrapped in an `Option`. Since you want to signal "no input at all" there was no answer, so the type should be `None` or otherwise `Some(Answer)`.
Why not? :) It's a technical preview, intended for testing stuff that should work when it's released "to the public". (Scare quotes because anyone can sign up and download it now, so in a way, I suppose it *is* released to the public, in a alpha-ish state.)
Dude I think syntax extensions and compiler plugins are some of my favorite features in Rust. So many powerful programming features that you can plug into the compiler to make your life easier without having to ship everything with the compiler itself. So good. This looks really nice.
Is this going to be improved by the 1.0 release?
might be useful as an option.
While semantically they are equivalent, it is not always convenient as it adds nesting in pattern matching and makes writing methods on `Answer` which need to take three states into account harder. Though, I think, using `None` as a variant for custom enum is probably not a good idea.
I really like this! Apart from Servo, my Rust code is mostly physicsy and not needing unit tests (too fluid), but I'll be sure to mess around with this for a while :D
Me too! Recently I've defined an auto deriving syntax extension for Servo (having the ability to define these is amazing), and defined my own compile time safety guarantees via a lint. It's really amazing! 
For what it's worth, you can perform a match that's two layers deep: match get_answer() { Some(Value(x)) =&gt; x, Some(NaN) =&gt; ..., None =&gt; ... }
Another way to do it would be to just make `UrlSource,GZipDecoder,OpusReader,LemmaFrequencyCounter,TsvWriter` all enums and member fields of the `Computation` object. Implement helper methods on each enum that do common tasks with them (the same methods which you would have made trait methods in the previous system). As long as you control these enums, you can define interface boundaries wherever you want. (If you want others to be able to extend interfaces in crates which use this, then you have to use traits)
Also haven't used either, but looking at the examples it appears this has support for an after_each, and nesting. Didn't see that in shiny.
Yes, but that's exactly what I said is inconvenient nesting.
This is the same reason I was waiting on doing some COM work in rust. I didn't want to have to write a boat load of macros to get rid of all the boilerplate, especially with inherited interfaces.
Very [rspec](https://www.relishapp.com/rspec)-y. I like it! :)
It might also be fun to have Rust man pages that are generated by rustdoc. Might not be too hard.
I never got to implementing nesting, so stainless is better in this regard. On after_each, although trivial, I could hardly find a valid use case for it in rust. 
If I need or want to use my own `None` variant, I usually just name it `No&lt;typename&gt;`, which in this case would be `NoAnswer`. That works for me in keeping stuff separated while still having an easy convention.
There's also a bit of a semantic issue here. The `Option&lt;Answer&gt;` variant has `Answer` always being an answer. So you can have code that requires that a valid `Answer` is present. If the semantic `None` (whatever it is called) is part of `Answer`, all code will have to deal with the `None` case.
I thought about parsing MIDL, but realised that was probably a *lot* of work. Then, I remembered type library TLB files from my VB days; if you pointed VB at one, it could bind to a COM library. I figured there had to be enough RTTI in one of those, and they might be easier to parse. Turns out that the loader for type libraries is in a COM library itself. I decided that the best way forward would be to just leverage the existing loader and generate the Rust bindings from that. &gt; I know of one project that actively parses MIDL and that's SharpDX, which is a DirectX wrapper for .NET. Ooh, nice. I'll have to remember that one. That said, I'm a little confused when it comes to DX. I was under the impression that DX was "not really COM"; it doesn't inherit from IUnknown or something. My understanding was that DX10+ doesn't even use COM-style interfaces at all. Anyway, I never got around to pushing my WIP up to a repository; if you're interested, let me know and I'll get it up somewhere.
DirectX 10 and 11 actually still expose a good chunk of their main interfaces through COM interfaces, that eventually do inherit IUnknown, looking at the [documentation](http://msdn.microsoft.com/en-us/library/windows/desktop/bb174541\(v=vs.85\).aspx) for IDXGIObject it is even mentioned that there's COM interfaces. ~~As far as a I know, behind the scenes it really isn't true COM, but the public interface is a COM wrapper around it. I believe the primary motivation for keeping this compatibility at this point in time is because of WinRT.~~ **EDIT:** I was wrong, see below for explanation!
Call it "NoAnswer" instead of None or put it in a module so it's answer::None. Or possibly just use Option&lt;f64&gt;. 
Ah, I thought you were referring to nesting `match` expressions. e.g. match get_optional_answer() { Some(Answer) =&gt; { match Answer { Value(x) =&gt; ..., NaN =&gt; ... } }, None =&gt; ... }
Yes, please. I've hacked up my rustup script to do this, but it's ugly and I'm using a bunch of hardcoded paths, so it's probably not a great candidate for a PR. It would be great to throw mine away for something cleaner. 
https://github.com/rust-lang/rust/issues/14916
COM is a technology for interfacing between components. It's kind of meaningless to say "DX is not really COM" or "DX is really COM". DX uses *some* bits of COM to expose its public interfaces. Mainly it just uses IUnknown. However, the interface technology (COM) is distinct from the implementation technology. I know for a fact that DX is implemented in C++, having worked on the runtime and a few related pieces. IUnknown is just a tiny part of COM. It's the most universal part, of course. But DX does not use most of the rest of COM / OLE -- it doesn't use COM-based marshalling to communicate between threads running in different apartments. The main reason that DX uses COM / IUnknown for its public interfaces, is that it provides a consistent way to deal with object lifetime (using reference counting), and a fairly easy way to extend interfaces (QueryInterface). This has nothing at all to do with WinRT. 
&gt; Cameron used Rust’s new lifetime bounds feature to improve safety checks on Root Did he happened to find any issue that the old system had let slip ?
Tangent: What has always annoyed me about Haskell is that tagged union constructors are top level (and that nobody seems to care). I was sad to see Rust did this too. Like record fields, I think it would be better if constructors were nested under the type. This is what some languages do and with something like Swift's ".constructor" syntax, this can be almost as concise. 
Thanks for the feedback! I will make a notice.
Since types in Rust is declared with 'member': 'type' it might be ambiguous with a new member declaration. I don't mind typing pub in front of every member, but don't like it when refactoring. That should be done afterwards.
&lt;3
Rust already has man pages, do you mean as Rustdoc rather than as the usual man page format?
I understood it as generating man output from rustdoc, for people used to man or so that the doc is easily accessible from the console or from third-party software (I regularly use `pydoc` for a quick check rather than open a browser tab to the full documentation)
I had heard of shiny before I made this, but I wanted support for nesting and `after_each`, plus I wanted to get some experience writing a syntax extension, which I'd never done before. Shiny also didn't expand to modules, which was a deal-breaker for me. I wanted to be able to better automate tests like: - Open a connection pool - Add a dummy user to the database - Do the test - Remove the dummy user from the database This could be done with a DummyData struct which deletes itself from the database in its Drop implementation, but sometimes you want something simpler or more complicated and `after_each` is useful.
The first Toronto Rust meetup is [happening tonight](http://www.meetup.com/Rust-Toronto/events/206244382/) in the Toronto office. We're going to be broadcasting the three scheduled talks, and they'll be recorded for posterity as well (should be available at the same link after the meetup, I believe).
I understand what COM is, but I guess I did not understand why they continued to use COM interfaces to expose the implementation of DX. Having seen examples of DirectX with C++/CX, I figured perhaps that was a strong motivator, but again... since it is C++/CX it could just access the C++ interfaces directly if it desired. Exposing it as COM via IUnknown for a way to do resource management makes since. My phrasing "behind the scenes it really isn't true COM" to me meant essentially what you're saying, in that DX uses some parts of COM to expose its public interface. That was entirely ambiguous wording on my part. You are correct in saying that the phrasing I used doesn't make sense. In any case, their continued use of IUnknown as their basis for exposing the DirectX API makes it easier to write bindings to DirectX in other languages. Not as easy as other ways of exposing the interface, but easier than trying to directly consume C++. Thanks for making it clear as to why they continue to use IUnknown to expose the interfaces. It makes a lot of sense to me.
Thanks for posting this! Just got back into cell reception. Should be in town in an hour or two.
The compiler did not catch anything new. We're aware of some soundness holes with the current system though.
The are 2 legacy closure types and 3 new closure *traits* that are replacing them. Trait objects (`Box&lt;FnOnce&gt;` for `proc`, etc.) will be used instead of the old closure types.
But then you could put that code into a library and give it back to the community!
I thought this was cool. It's featured 4th in their programming languages showcase, after Ruby, D, and Julia, and it has a lot of stars.
"I don't see what you think is the problem with algebraic data types. They don't require dynamic allocation." Are you saying something like a cons list does not require dynamic allocation? I would like to know how that can be done.
A cons list's requiring dynamic allocation is orthogonal to the fact that it's canonically constructed from an enum. If it were constructed from a struct, it'd still require dynamic allocation: struct Cons&lt;T&gt;(T, Option&lt;Box&lt;Cons&lt;T&gt;&gt;&gt;); But no one is arguing that structs require dynamic allocation. /u/sellibitze was simply saying that enums don't always require dynamic allocation. E.g., there is no dynamic allocation in `Option`: enum Option&lt;T&gt; { Some(T), None, }
Note, we're planning to start streaming talks around 7:30pm EST.
'a lot of stars' is a bit of an understatement. :3
I raised question about ADTs while both of you answered about Enum. Well Enum is not what I am asking about because it does not allow for recursive type definition.
I was planning to go since the Meetup event creation, but unfortunately I had a last minute setback.. thanks for the live streaming!
I don't think it is guaranteed to be improved for 1.0; AIUI, it is nontrivial to implement nonlexical borrow scopes.
Also cargo is listed on Githubs package managers.. needs more stars people! https://github.com/showcases/package-managers?s=stars 
&gt; extern fn alone is probably wrong, you probably want extern "C" fn `extern fn` is an abbreviation for `extern "C" fn`. &gt; A first step towards being more Rusty might be to build an &amp;[u8] from function and/or output, using the things in std::slice::raw ; [`CString`](http://doc.rust-lang.org/nightly/std/c_str/struct.CString.html) and [`CVec`](http://doc.rust-lang.org/nightly/std/c_vec/struct.CVec.html) will be helpful.
I like Rust and all, but how did it get more stars than ruby??
I am usually explicit with `extern "C" fn` anyway. Seems clearer about the intent.
I see. Thanks. So the reason I don't need automatic GC for recursive ADTs is that I need to manage them myself (though with some assistance from the compiler). This isn't what one gets in ML, but it is a difficult problem to solve. The arena idea is particularly interesting.
Yep, that's Rust's part of the design space- memory safety without requiring garbage collection. However, there also used to be (and may be again in the future) plans for a `Gc&lt;T&gt;` to optionally use a tracing garbage collector per-task for particular objects, and Servo uses `Js&lt;T&gt;` for memory managed by JavaScript's heap.
Box would be pretty useless for List, as that would disallow the tail from being shared by two lists. But I got the following to parse ``` enum List&lt;'a, T:'a&gt; { Cell(T, &amp;'a List&lt;'a, T&gt;), Nil, } ``` but I had to make T:'a instead of just T.
If "extern fn ...." is shorthand for extern "C" - would it make sense to make extern "C" automatically apply [no_mangle], whilst `extern fn` does mangle
You asked about ADTs *in Rust*, which by your definition, means we have to talk about `enum` with explicit boxing for recursive types. There's no other ADTs in Rust.
Maybe, but, using `extern fn` is definitely not *wrong*.
I'm glad I finally looked into rust. So promising to have a memory-safe alternative to C without a GC.
Do you actually *like* cargo? (I do) Do you visit the repository often? (I don't) Do you think libcargo is in a state where other people will find it useful? (I *definitely* don't) I appreciate the sentiment, but just randomly staring projects is weird. Does staring the rust repo achieve something? I'd say so, more people see it, it's *tangibly useful* to dig through the implementations and see how things are done. I'm not so sure about the cargo repo. I've literally only ever dug through the cargo repo to try to figure out why it was doing obscure things with OUT_DIR, or why the build was failing. 
I was surprised and delighted when I got to the part where that feature was revealed. Great idea.
Thanks for answers. The main goal was to solve situation with identical values for different enums. E.g. we have two different libs with different enums that have some of the same values. enum Foobar { Foo, Bar, Less, // Less defined also in core::cmp::Ordering } fn main() { let k = 2i; match k.cmp(&amp;3i) { Less =&gt; println!("&lt;"), // booooooom! Greater =&gt; println!("&gt;"), Equal =&gt; println!("=="), } } 
Agreed - it's not the problem in the OP's code.
You could do something like: macro_rules! new( ($typ:ident { $($field:ident : $value:expr),+ }) =&gt; ( { new::&lt;$typ&gt;(|obj : &amp;mut $typ|{ *obj = $type { $( $field : $value ) } }) } ) That is, write the whole struct at once. However, this (and the original code) has some problems, the overwriting will cause the destructor to run on uninitialised memory which can lead to undefined behaviour. You should use [`std::ptr::write`](http://doc.rust-lang.org/nightly/std/ptr/fn.write.html). Also, I recommend you wrap the `*mut T` into a smart pointer type like `struct Boehm&lt;T&gt; { _data: *mut T }`.
question: I know there are no plans to use servo in Firefox but does that mean it's impossible or even just unlikely? Its a very exciting project but it would be sad if chrome adopted it easily and Firefox struggled for years to swap out gecko. (like the difficulty of e10s) Or will servo be offered in a standalone browser? Two browsers from mozilla? ...sorry for the OT
This looks nice and fun. I am looking forward to seeing more strategy games in rust. Nitpicking: As far as I can see the game calls a method named "take_turn" on the player, so some of the "communication" doesn't happen through channels. Would it be possible (and useful) to use a channel to tell a player that it is his turn? * The game uses a channel to send a message that the player that he should take his turn * The player receives the message * The player uses a channel to send a message containing his action. * The game receives the message. 
Unlikely, I guess. Either someone needs to put the effort into having a clearer boundary between Gecko and fx (hopefully with XUL/XPCOM/XBL/etc on the fx side), or Servo needs to support everything that Gecko does (all the X* stuff I listed above) and be shoehorned in somehow. Both tasks look pretty hard to me. We do have ongoing work embedding Servo in Chrome, though we're not working with Google on this AFAIK. I personally don't think Google would switch to Servo though. To me the picture looks like we'll have a new browser for mobile, and something for desktop -- not yet sure what that something is. We're a research project, most of our discussions on practical usage stop at the dogfooding level :)
I'm really looking forward to watching it! I heard you did a great job.
The new tracking issue is here: https://github.com/rust-lang/rfcs/issues/349
You could star it because you'd like to contribute to it at some point. :P (Contributions &amp; their contributors are awesome!)
Just so I am clear, you are talking about the data im copying over calling its destructor? Why would writing to a raw pointer cause it to run its destructor? I thought about creating a smart pointer but couldn't figure out a use case as I don't need to define methods on it for my purposes. Am I missing something there as well?
Interesting...I kind of get why it happens for borrowed pointers because they should be initialized already so copying over the old values could leak if their destructor isn't run (please correct me if i got that wrong)...but for raw pointers isn't that a bit presumptuous?...I just had a lightbulb on the smart pointer though...For it to really feel like a smart pointer I need to fulfill the Deref trait right? Are there any others that I should include?
Yes, it's a bit presumptious, but then not running destructors is also a little bad; I don't really know or care so much, especially because `unsafe` code should be as restricted as possible anyway. &gt; I just had a lightbulb on the smart pointer though...For it to really feel like a smart pointer I need to fulfill the Deref trait right? Are there any others that I should include? Implementing `Deref` is enough, although you may also like to implement traits like `Eq`, `Ord`, `Hash` (which all just call the corresponding functionality on their contents) and `Clone` (which just copies the pointer, since this is presumably meant to be a GC with shared ownership).
This was exactly the kind of help I was looking for :D How big a performance hit would I expect from translation of types? Would the safety of rust still apply for all the internal functions after type translation and mean I only need to be extra careful of the boundary function between C and rust? I'm pretty much coming from Python and didn't realise that the border between C Ffi and rust required manual translation. From the blog post I read it seemed that rust handled the data just by knowing what ABI to apply. 
Actually, last question...is there a benefit to using a macro vs just having a function that takes the value and then uses ptr::write?...ie fn new2&lt;T&gt;(obj : T) -&gt; Boehm&lt;T&gt; { let mem_sz = mem::size_of::&lt;T&gt;(); let alignment = mem::min_align_of::&lt;T&gt;(); let ptr = unsafe { heap::allocate(mem_sz, alignment) as *mut T }; //this will never hapen for heap::allocate but it might be possible for boehm::allocate // if ptr.is_null() { // fail!("Allocation Failure: new&lt;T&gt;() could not allocate enough memory") // } unsafe { ptr::write(ptr, obj) }; Boehm::new(ptr) }
I played around with this for a while, and then looked around on github for other generic code, and this is what I gathered: Whatever you have in your angle brackets after the impl has to be used in the named thing you're implementing, or in the named thing you're implementing a trait for. So: impl&lt;A, B, C&gt; Something&lt;A, B&gt; for SomethingElse&lt;C&gt; { //good impl&lt;A, B, C&gt; Something&lt;A&gt; for SomethingElse&lt;C&gt; { //not good So in your second example you have impl&lt;T, R&gt;. You use the T in TypedReader&lt;T&gt; and you use R in BufferedReader&lt;R&gt;. In your failing example, you try to impl&lt;B, T&gt;, but you only use B in TypedReader&lt;B&gt;. T isn't used in the impl header, it's only used later in read, so in this case, read is the thing that should have the &lt;T&gt;, not the impl itself -- which is what you do in the version that works. I don't actually know if this is correct though... I'm just mentally pattern matching on other code that I've seen. It would probably good to get clarification from someone who actually knows how this is supposed to work. 
Here's a couple of resources you may find helpful: [Rust FFI Guide](http://doc.rust-lang.org/guide-ffi.html) and [Writing Unsafe and Low-Level Code in Rust](http://doc.rust-lang.org/guide-unsafe.html). You can also use [rust-bindgen](https://github.com/crabtw/rust-bindgen) to have the (direct unsafe) bindings generated automatically. Since these operate on the C types and are unsafe, one usually builds safer and cleaner abstractions on top of them. The manual translation requirement is because Rust's types are different from C types. E.g. `&amp;str` is not null-terminated and may contain zeros. So we need to use [to_c_str or with_c_str](http://doc.rust-lang.org/std/c_str/trait.ToCStr.html). If you only used the C type equivalents (`libc::c_int`, `libc::c_float`, `*const libc::c_char`, etc.) you wouldn't have to do type conversions in your code. In fact, if you look at the [libc docs](http://doc.rust-lang.org/libc/index.html) you'll find that they're defined in terms of Rust types (e.g. `libc::size_t` is `u64`). These are platform-specific, though, so the size may differ on different architectures. What do you mean by internal functions? Your non-C and non-unsafe code? In that case, yes. Rust doesn't allow you to convert types that would result in memory safety. You can still get number overflows, etc. if you're not careful, though.
Probably not; I would recommend you use a function.
Rust is great, in the last few days I started experimenting with it. I mainly rely on Java and so far I am not sure about why would I use Rust, but as a systems programming language it looks promising. What I would maybe use Rust for is game development. I wanted to try that for a while, learn OpenGL and everything, so maybe in the future I would use Rust for that.
Will adding inheritance make it harder to add HKT? Apparently its [really hard to do HKT with variance](http://youtu.be/6COvD8oynmI?t=1h11m28s) - will a more far reaching concept of variance also be needed when adding inheritance to Rust? (we already have it for lifetimes) Maybe I am confusing subtyping with inheritance though... could somebody clear me up?
I'd really like to hear more about how these inheritance proposals will interact with future additions to the language and type system. We don't want to add something right before 1.0 that will hurt us when implementing features like HKT later.
Yeah, I'm not so much worried about folks "overusing" inheritance, more about how adding it might constrain or complicate the addition of more advanced type system features in the future.
Yes, this is basically the entire reason why I would rather try to remove subtyping and variances, if it's at all possible, rather than add even more of it. Not because I don't think it's useful: it's definitely good for ergonomics if `Option&lt;&amp;T&gt;` with compatible lifetimes is automatically accepted just like `&amp;T` itself is. But because it has a reputation of interacting badly with other features, and in particular of screwing up type inference. (Allegedly Scala's comparatively-awful inference is attributable to two things: subtyping and type lambdas.) It seems like a bad way to spend the complexity budget. And this is why I would favor a solution based on a `trait Transmute`. It's minimal, does what's needed, does many other useful things - which means that we will likely want to have it no matter what, can be implemented *almost* entirely as a library, works through the existing trait resolution mechanism, and has prior art in GHC which *has* many of those more advanced type system features, showing that they don't conflict with each other too much. (Big flashing red disclaimer: I haven't read most of the other proposals. There's just too many. If they've been narrowed down to only two, then maybe that can change.)
check out /r/rust_gamedev, https://github.com/PistonDevelopers/piston, and join #rust-gamedev on mozalla IRC!
Thanks for that!
The way I do it is by looking at commits. You shouldn't need to be familiar with the compiler because commits that break things are tagged with `[breaking-change]`. These commit messages almost always contain advice on how to migrate: git clone git://github.com/rust-lang/rust cd rust git log --grep '\[breaking-change]' | less If you scroll down a bit, you'll find a commit from last Friday that details the breaking change you ran into (and how to fix it): https://github.com/rust-lang/rust/commit/416144b8
Thank you.
I know it doesn't really help, but the notetaking for this meeting was not as thorough as others. What is written down as "this looks complicated" was actually given greater consideration and elaboration.
closure traits ... are you saying some closures will be sugar for creating trait objects; trait objects are ptr to data &amp; ptr to vtable? will a single-function trait optimise to a (ptr to data,ptr to function)?
ruby/ruby isn't the official Ruby repository, just a mirror. While the core team takes a refreshingly pragmatic approach there (they accept patches through any channel, pull requests get served just as normal redmine tickets), the main discussion and repo is at ruby-lang.org.
The use of `take_turn()` comes from the original design of my Dominion simulator (whose code I'm looking to improve and is the main driver for exploring different approaches). There are a couple reasons for it: 1. All users have to do is define the code that they care about, without any looping and blocking on channel boilerplate. 2. A lot of cards in Dominion have effects on other players; for example, when forcing another player to discard a card, it's important to let that player choose which card they want to discard but offer a reasonable default (e.g. check in order for Estate, Duchy, etc.), and my solution to that was to create those as default methods on a trait. Naturally it makes sense to extend that to require one method to be implemented, which is `take_turn()`.
Does rust have a concept of volatile and xdata? I imagine most everything else can be encapsulated in unsafe code. 
For a long time, they didn't even really accept pulls, even though it was a mirror too.
The first problem I can see is that (assuming `next_line` was renamed to `read_line` recently; I can't find "`next_line`" in the docs) `next_line` returns a String. This means that whatever the lifetime of your reader, *the `String` you just read* won't live past the end of the function. Insofar as I know, there's no way to move a value (like a `String`) out of a function along with some references into it. If I'm wrong, someone please do tell me! The way I handled zero-copy parsing was to read all the input into a single string *first*. Then, the lifetimes should be relatively easy to deal with; you keep a `&amp;'a str` in your structure, and all the slices you return are also of type `&amp;'a str`. Alternately, you could return an intermediate structure which owns the read-in `String` and has methods to extract the slices from it. That way, the lifetime of the slices becomes the lifetime of the intermediate structure value (i.e. `&amp;'a self`). Hope that helps. **Edit**: as an aside, to clarify on my unsureness above; there's no way to express "`X: 'x` where `'x` is a lifetime which lives as long as the non-copyable value `X` does, even if it is returned or moved around", is there?
Let me know / link me if you end up kicking off the ANN project! I was planning on starting a small lib for both practise an using in a personal project (automatically categorising instrumentation for a generative music engine) but I'd be more keen on collaborating than doing the whole thing solo :)
The sugar already exists, although it isn't exactly what you're stating. The new closure syntax results in a unique, anonymous type implementing closure traits. It is possible to capture either by-value (including references) or by-reference. A call to the closure is *static*, because it's based on the type. There's no function pointer involved at all. Since it implements those traits, it can be boxed as a trait object like `&amp;mut FnMut` (like the old boxed closures) or `Box&lt;FnOnce&gt;` (like `proc`). The old closures being fully replaced with this new system.
&gt; The first problem I can see is that (assuming `next_line` was renamed to `read_line` recently; I can't find "`next_line`" in the docs) `next_line` returns a String. My apologies for the confusing names: I'm running against a custom `BufferedReader`, not the real one. See the first part of the file. Here, `next_line` is a stand-in for the real `Buffer::fill_buf`, but with all the `consume` and `from_utf8` details stripped out, because they just complicate the basic idea. This code all compiles and runs. &gt; The way I handled zero-copy parsing was to read all the input into a single string first. This won't work in my case. Some of my individual files are in the gigabytes[1], and I'm processing one file per core at any given time. The output of my parser is being fed into a parallel map/reduce implementation. If I try to do this all in memory, my machine will swap itself to death. My real question here is whether `Iterator` can be used for streaming, zero-copy iteration. I can make the code work trivially by getting rid of `Iterator`, but that seems rather unfortunate.
&gt; This won't work in my case. Some of my individual files are in the gigabytes, and I'm processing one file per core at any given time. The output of my parser is being fed into a parallel map/reduce implementation. Memory mapping the entire file will work as long as it only needs to run on 64-bit. On 32-bit I don't see a good way of avoiding copies in safe code if it can't all fit in virtual memory.
Thanks for the update! It's just natural for me to hope that such an exciting project can be eventually shipped to users. Especially through Mozilla since they are really the only browser company that I trust. Firefox has taken a beating lately and any advantage would help. But keep up the great work!
This is a really clever idea, and it took me 30 minutes to figure out why I can't make it work in the real program. In my code, `BufferedReader::next_line` is only a placeholder for the real `Buffer::fill_buf`, which has the following type signature: pub trait Buffer: Reader { fn fill_buf&lt;'a&gt;(&amp;'a mut self) -&gt; IoResult&lt;&amp;'a [u8]&gt;; This is necessary because `Buffer` implementations have temporary internal storage, and I can't find any way to implement that without `fill_buf&lt;'a&gt;`. I've updated my example to have a `Buffer` trait, and an actual internal buffer, just like the real APIs. And as far as I can tell, this completely blocks your approach. :-/ The more I study this, the more I'm convinced that the only feasible solution is to define a `ZeroCopyIterator` type with the necessary lifetime bounds. Well, maybe somebody will figure out a clever version of `Iterator` that works for everybody, but I don't see it yet.
Thanks :) Eventually obviously we want it to be used, just that the specifics are far from being under consideration right now AFAICT
And there's a PR out for it: https://github.com/rust-lang/rust/pull/17733
Rust already has subtyping (including function variance) due to lifetimes. It would be possible to remove subtyping and replace it with coercions inserted by inference, but it means that you wouldn't be able to define a type constructor that behaves like &amp; yourself. Also, none of the inheritance proposals being considered have included type constructor or function variance. It will hopefully be possible to implement the DOM in Servo without it.
Yeah, you're right, sorry for depending on your implementation details! I think the key insight here is that the `Iterator` trait requires that the returned objects must live for at least as long as the iterator itself (so that you can do chaining) - but you can't do that while being backed by a `Buffer`, because the duration of the borrow is smaller. Or maybe I'm completely wrong :)
I notice that `arg()` causes runtime failure if `cmd()` hasn't been called at least once. What would be the downsides of using a state machine to make this a compile-time type error?
Maybe we could have a `ZeroCopyIterator` in the stdlib, with weaker requirements, and then make `trait Iterator: ZeroCopyIterator`? But I'm pretty sure this would need a RFC, and extensive discussion
Type constructor variance for non-lifetime parameters is already part of the language. It is computed (and relied upon) as part of lifetime parameter variance, but a user program can't rely on it directly. I was referring to exposing any sort of inheritance subtyping in a way that works with parameter variance. I don't think it's necessary for the DOM, but it might be necessary for other use cases.
&gt; Are there any plans to stabilize the compiler API, or define a plugin-specific API with stability promises? Not as far as I know. Honestly, the libsyntax internals need a *lot* of work, which will probably happen post-1.0. It's my hope that members of the community will develop improved metaprogramming interfaces as ordinary Cargo libraries — for example, a better quasiquote or a less messy version of [`AstBuilder`](http://doc.rust-lang.org/syntax/ext/build/trait.AstBuilder.html). I believe most of the infrastructure needed in rustc itself is already in place. If the community converges on one or a few metaprogramming libraries, then there is less code that needs to change with the actual compiler APIs, and we can iterate much quicker on a slick interface with an eye towards eventual standardization.
Stabilizing syntax extensions is not a 1.0 blocker, yes.
This is awesome! I just wrote my first syntax extension a few days ago and it was pretty intimidating; this goes a long way towards cleaning it up.
Even for non-performance-critical projects, I'd prefer Rust over Java because its type system is more expressive. But, I also program in Java for work, so it's nice to use other languages in my spare time.
Thank you to everyone who has proposed ideas and offered advice! The Rust community is awesome. I've been speaking with burntsushi and a few other people who are interested in streaming, zero-copy parsers in Rust, and we're going to be exchanging dubious experimental hacks using the [rust-streaming](https://github.com/emk/rust-streaming) repository. Our goal is to come up with the best solutions we can within the constraints of Rust. Pull requests are welcome, including dodgy proofs-of-concept! **UPDATE:** Our current technical obstacle blocking `StreamingIterator` is this [very mysterious difference between lifetime handling in structs and traits](http://stackoverflow.com/questions/26192564/rust-struct-can-borrow-a-mut-self-twice-so-why-cant-a-trait).
Awesome. I should have more confidence that you guys are thinking about these things! It would be cool to see this addressed somewhere when speaking about the inheritance proposals.
Really hoping HKT will eventually become part of the language. 
Wait, where did you give credit? You say it's a guide that you did not author, but did not say who did, nor does the guide itself.
I think you just need to update your local rust
Have you tried `use std::slice::ImmutableSlice;` ? I'm guessing something broke somewhere. Is there currently a way to get previous nightly builds?
I ran into the same thing last night and fixed it by pulling the latest down from the repo. I'm not using the nightlies though so maybe you have to wait for that
Yes, I tried adding that to cargo's cache of the code, but it didn't help.
This is a temporary regression that was fixed [yesterday](https://github.com/rust-lang/rust/pull/17715). The fix should show up in the nightlies soon.
`std::slice::ImmutableSlice` is in the prelude so you get it for free
I've also run into this problem (for CSV parsing) and it is rather frustrating. The best I've been able to come up with so far is this: pub trait Viewer&lt;A&gt; { fn next_view&lt;'a&gt;(&amp;'a mut self) -&gt; Option&lt;&amp;'a A&gt;; } It seems like having the lifetime in the return type is necessary. But this trait definition fixes the return type to `&amp;'a A`, which makes it rather difficult to compose with other things. (For example, try writing an `enumerate` method. I don't think you can.) It is very possible to eschew iterators here completely and write a `for`-like macro. But this makes it impossible to write generic functions over these "streaming" iterators, which is painful. It seems to me that a streaming iterator *ought* to be generalization of the `Iterator` that we have now, but I'm not sure that notion is expressible in today's Rust. Another option I've stumbled across is to create an iterator and make it wildly unsafe. If the caller calls `collect`, they're doomed. This approach isn't only bad because it's unsafe, but it's *silently* unsafe. Which means it's absolutely inappropriate. My eyes are pretty narrow right now. Is there another way of looking at this problem with the tools currently available in Rust?
I think constexpr is CTFE, so no, you can only construct AST nodes, you can not run functions at compile time.
You can run functions... but only your own functions, meaning if you wish to run user-defined "functions" you have to a lot of legwork. *Theoretically* there could be a plugin with a crate attribute* `#![enable_ctfe]` and a macro `ctfe!(...)` where each something like the following: - `#![enable_ctfe]` just stores a copy of the whole crate's AST to be accessible to `ctfe!` (theoretically it should actually run macro expansion on it, with `ctfe` carefully disabled). - any calls to `ctfe!(...)` are run through an AST interpreter using the original copy of the AST for "calling" other functions etc. However, I don't think this is very reasonable, and it would be a rather large hack. Might be fun to play with, though. ^*[#15778](https://github.com/rust-lang/rust/issues/15778) ^gets ^in ^the ^way ^at ^the ^moment.
You aren't very observant, are you.
In this case, because that I'm linking to is closed source, I would be unable to use rust-bindgen. however, that doesn't mean that it is not a great tool for later on when I'm hopefully doing more integration with C code. I'm currently reading through the rest of your resources :)
rust-bindgen doesn't need C source code to generate bindings. It needs C header files that defines the API for the library. Even for a "closed source" library, as long as a header file is provided for it, rust-bindgen might be useful (depending on how well rust-bindgen can generate bindings from the header file).
I've started poking at this issue with a pair of proposals: * [Unsafe Impls](http://discuss.rust-lang.org/t/pre-rfc-unsafe-trait-impls/569) * [Raw Slices](http://discuss.rust-lang.org/t/pre-rfc-rawslices/573) The second one is much more promising, and I expect will be accepted in some form (generally positive feedback). The first one is a moonshot idea that I haven't really fully considered the implications of.
That's better, thanks! Also, I'm wondering if maybe the guides should include authorship information and a date. When I'm reading stuff online, I frequently look for that information on an article; if the article is good, I like to seek out others by the same author, and the date helps me tell if it is likely to be up to date or may be outdated. I understand that perhaps authorship information isn't included as the documentation is all supposed to be part of the project and belong to the project as a whole, but given that most of the guides are authored primarily by one person, it might be nice to give credit. Or another option would be to just link from each page to its [source on GitHub](https://github.com/rust-lang/rust/blob/master/src/doc/guide-plugin.md); that solves the problem entirely, giving full credit to all contributors, a history of the document and recent changes, and lets people know where to send patches without having to dig around and find it.
How about Vec::iter()? That gives you all the things like filter, map, etc.
You know what, I'm a dumbass. Totally didn't see that. Still, would be nice to have as many methods as Scala does.
This would let one use unsafe code in a safe context with objects like `Box&lt;Index&lt;..&gt;&gt;`, where the compiler just knows that the trait `Index` has a safe fn `index()` even if the impl for `Pointer` is unsafe, so if box contained a `Pointer` it would still allow you to run `unsafe` code in a safe context. If you control the trait you can mark the `index` method as unsafe, this gives you the _option_ to put `unsafe` on the impls
It not about what you use [] for, but whether if it is worth increasing the complexity of the language just to make some very rare unsafe edge cases more convenient. I guess it would be totally the C++ philosophy to enable unsafe traits. I doubt that for Rust's philosophy.
That’s a good point, but there may be some other way. /u/Gankro has proposed two, for example, and the Raw Slices one actually seems pretty feasible.
As the author of this guide, I strongly agree with not putting authorship labels on official docs :) One thing that bothered me about the Haskell community is that a lot of documentation (e.g. the [infamous monad tutorials](http://byorgey.wordpress.com/2009/01/12/abstraction-intuition-and-the-monad-tutorial-fallacy/)) is only available as 20 separate personal blog posts, each with its own tone and dodgy analogies, each targeting a different version of the language, and none of them ever receiving more than a handful of updates. I don't want Rust documentation to be like that. I want a cohesive set of guides that are continually updated as we refine our teaching methods. And I want it to be something the whole community feels ownership of. As for linking to Git history, that seems okay but not really necessary enough to justify the UX clutter. It's enough of a niche case that people can find the history themselves or ask around, I think.
This is very impressive, thank you for building this and sharing! Do you intend to support programmatic usage as well? I assume something like this could turn into (or be used to build) a full-fledged parser library. &gt; This might be overkill, though. :P I think it meshes very well with the flexibility we have with `format!` and friends.
This is already sophisticated enough that you should go all the way and make it a parser generator :)
Let me see if I am understanding this correctly: * The variances of type parameters of generic types are computed, but this is *only* used in turn to compute the variances of lifetime parameters of other types which contain these. For instance, the variance of the type parameter of `Option` is used to determine the variance of the lifetime parameter in `struct OptionalInt&lt;'a&gt; { i: Option&lt;&amp;'a int&gt; }`. * This variance information is *not* otherwise taken into consideration by the typechecker. Sublifetimes are considered for instances of `OptionalInt`, but the lifetimes in instances of `Option&lt;&amp;'a int&gt;` must match exactly. * However, changing this and taking variance and sublifetimes into account for `Option&lt;&amp;'a int&gt;` as well is what is proposed in the above RFC from /u/nikomatsakis. * But it is *not* planned for this to be done for inheritance, so `Option&lt;&amp;SuperStruct&gt;` and `Option&lt;&amp;SubStruct&gt;` would not be compatible. (Which is notably weaker than "planned not to be".)
Real macros! Real module system! (No header files!) Nicely scoped attributes for lints etc. Nestable multi-line comments. Cargo instead of Autotools. (To add to ehsanul's list.)
Using the macro name `describe!` is a bit unfortunate, given that there's no namespacing for macros or even a way to control which macros are imported from a crate. Also I wouldn't count on `IdentTT` sticking around, because the only built-in syntax extension of that form is `macro_rules!` itself, and that isn't even using actual `IdentTT` anymore.
Can we get a barebones Rust server?
I think there is something wrong with your MinGW... I have also had a problem like this. I had been using rustc on Windows 8.1 without any problem, until I installed Haskell. The problem is that Haskell comes with its own version of MinGW, which for some obscure reason causes errors when being used by rustc. What I currently do is renaming the directory of Haskell's MinGW when I want to compile Rust stuff (this way Windows only finds Rust's MinGW, which is the good one). Maybe you also have more than one MinGW installation. Could that be the problem?
Rust (the game) is written in Unity 3D, and uses the Unity multiplayer system. While not impossible, it would be very difficult and annoying to do.
Maybe? I have only installed (to my knowledge) one version of MinGW. Maybe, like in your situation, something else I installed had it's own version of MinGW, but I can't think of anything. 
Is "monkey patching" `TcpStream` like that an idiomatic thing in Rust? I'd go with `struct PacketStream { stream: TcpStream }` and use explicit `PacketStream` type in `process_stream` function, but my brain may still be too deep in "old" programming languages. Which way seems better to you?
see the debate around the recent jonathan blow talks https://www.youtube.com/watch?v=TH9VCN6UkyQ http://www.reddit.com/r/rust/comments/2gwi11/jonathan_blow_ideas_about_a_new_programming/ In my view the best solution for games would be a build option that disables safety. (borrow check errors become warnings, array index checks are omitted, etc.) That might need to be a sliding scale.. e.g. .. debug // least performant, most diagnostics release // DEFAULT employing the full Rust philosophy unsafe_debug // like unsafe_release but extra debug info unsafe_release // most performant, most unstable. bugs are crashes, no bounds checks, matches C/C++ they could be compiler settings to "avoid polluting rust source bases", and standard rust code would work fine in unsafe projects. Another solution might be an std::unsafe::Vec ? but you'd need the index operator to be unsafe
Thanks to pythonesque for this Pull Request!
Creating a new trait and then implementing it for types which already are in the std is a pretty standard thing to do.
&gt; Is "monkey patching" TcpStream like that an idiomatic thing in Rust? It's not actually monkey patching. Monkey patching, as commonly used in Ruby, add new members to objects or classes globally, potentially causing all kinds of nasty side-effects far from where it's done. Traits exist locally. This means that implementing traits on existing structs doesn't risk creepy action at a distance.
This is yet another argument for ad-hoc operator overloading (in my twisted mind). In my perfect world, you'd just make an `unsafe` method that is used for operator overloading. I.e. something akin to: impl&lt;T&gt; Pointer&lt;T&gt; { #[index_method] unsafe fn index(&amp;self) -&gt; ... }
That's why I used quotation marks. Is there a proper term for this technique? I can't really compare it to anything I know from other languages.
Yeah, his talks are very insightful. Unsafe build looks like an option too, it certainly would increase the language’s versatility (gamedev and stuff), although I’m not entirely sure if it would pay off performance-wise to make the whole codebase unsafe. I’m personally leaning more towards 80/20 approaches. An unsafe vector type sounds like an overkill to me too—why implement the whole vector functionality again when you only need to avoid bounds checking? I believe something like a raw slice would be sufficient.
Yes, that seems like a good summary of the situation. On the last point, inheritance is somewhat orthogonal to the question of whether Option&lt;&amp;SuperStruct&gt; and Option&lt;&amp;SubStruct&gt; are compatible. Even with existing trait objects, Rust's type sysem could be extended to make Option&lt;&amp;SuperTrait&gt; and Option&lt;&amp;SubTrait&gt; compatible, but the implementation of this feature would require a change to vtable representation. With efficient single inheritance, the vtable layouts are guaranteed to be compatible, so there is no drawback from the implementation side.
In Haskell it's declaring type to be an instance of a type class, in Clojure it's implementing a protocol. When applicable, it's an extraordinarily good solution. It's a zero cost abstraction, it's very safe, and it's very convenient for a programmer to do. It's the one thing I'd like most mainstream languages to steal from Haskell -- honestly, in my experience it replicates 90% of the gains of OO in practical software with none of the drawbacks.
is rust going to get pointer-arithmetic operators eventually - do any enhancements to traits allow '+' to be used with pointer + int , etc
You will need this hack to get it working: https://github.com/klutzy/rust/commit/cf04327c93ab5f62db990e6849cba7a71ef284a5 afaik
I'm pretty sure that this is due to you running a 64-bit MinGW install, but a 32-bit Rust install. I was getting similar errors with the 32-bit Rust nightly, and a 64-bit TDM-GCC install, but when I downloaded the 64-bit nightly, they went away.
It's probably possible, provided you install the right flavor of mingw toolchain. But why not compile directly on your Windows machine? I think this is going to be the least painful option.
This adhoc overloading has the unfortunate downside of not working in generic code, AFAICT?
It has volatile load and store intrinsics along with volatile versions of memset/memcpy/memmove as an optimization.
Beyond basic control over tokenisation, whitespace control, and an easy way to write scanners with a macro, it feels powerful enough for basic uses. I have a nasty habit of aiming for simple and accidentally hitting "turing complete". I'm trying to avoid that this time. :)
I'm not sure what you mean by "programmatic usage". As I've mentioned elsewhere, there's only a few things left on my wish list for it: * Ability to define scanners with a macro. This is largely just a question of allowing the generator to do a prefix match, and some glue to hold it all together. * Ability to select tokenisation policy. Off the top of my head, I'm thinking "words and numbers" (current default), "identifiers and numbers", "space delimited" and "exact". I'd love to support arbitrary tokenisers, but the *macro* needs to be able to call them to tokenise the patterns, so they have to be known to the plugin crate. * Ability to select whitespace policy. This will be "ignore" (current), "explicit eol" and "exact". Again, these have to be known to the plugin crate.
Hope that Rust can do this in the near future just as Go can, right now.
Memory safety is hugely important to rust, but lack of unsafe indexing is likely to cause *less* safe code than if we allow it. An unsafe index operator could only be used inside a block of unsafe code, but what the current workaround does is allow you to run legitimately unsafe code in safe code blocks without knowing.
&gt; But why not compile directly on your Windows machine? Because I don't have one :) I could use my fiancee's computer, but I would rather not install compilers there if it isn't necessary
Thanks! Relevant issue: https://github.com/rust-lang/rust/issues/12859
&gt;Because I don't have one But then what are you going to do with Windows binaries? &lt;shrug&gt;
I'm not the OP, but he probably wants to distribute binaries to Windows users that don't know or don't want to compile the source themselves. We have a similar setup at work with a Linux based build server creating packages for both Linux and Windows. Setting up cross-compilation was actually easier than setting up another build server on a Windows machine. Although that is for C++, not Rust.
Nope. Transmute your pointer to an int, do the operations there, and then transmute back. Since Transmute is a no-op, it's just more work on the developer to explain what they are doing than adding a runtime cost. This is one of the ways Rust encourages you to write safe code over unsafe code.
Yes, precisely :)
Doing arithmetic on int when you're really trying to handle pointers isn't safer, you lose type safety (i.e. you can accidentally convert an actual integer to a pointer, rather than converting the pointer-in-`int`-form that you're trying to) and it's just generally harder to make sense of the code when you've lost the pointerness. Writing safe code in this circumstance means writing higher-level APIs, that do all the raw pointers manipulations in a correct way, meaning external code does not have to touch the `*const`/`*mut` at all.
Only when Rust's compiler tells you to. So almost never. A breakdown of the most common times you'll need to annotate your variables: * Top level static variables always require annotated types. * Numbers will often require explicit types, but it's not a big deal in practice because you can just add i32 or . or something to the number, and you usually only need to do it in one place. * Sometimes you have to annotate variables in lambdas, because (I guess) Rust's type inference scheme can't quite figure it out on its own. * By far the most common other case where I have to do it is when using ```.collect()``` on an Iterator, and in that case it's necessary because you can .collect into any type implementing FromIter.
When it adds clarity. This is almost always just a style choice, but sometimes it is nice to future readers of your program to let them know what the type of a value might be. 
Use it whereever it makes your code better. Code is better if (not exhaustive): - it compiles (put types in places where the compiler cannot infer) - it is clear (occasionally it is hard to keep track of what's going on without having the type information, so an annotation helps with that) - it is safe (when using unsafe code getting the types correct is not guaranteed due to functions like `std::mem::transmute`, so explicit annotations are good) - the people who will be reading/writing it (you) like it
Was just reading this http://aturon.github.io/features/let.html#use-type-annotations-for-clarification;-prefer-explicit-generics-when-inference-fails.-[rfc]
I tried to build a minecraft server about 3 years ago (Admittedly it may have gotten better now) but that was a nightmare in itself. I doubt stuff could be much worse. Notch is not the best programmer.
Hmm, I actually like the other way better.
That's true. In any case, if we are to take variances into account in typechecking because of lifetimes (per that RFC), we'd already be paying whatever costs that entails, so it's not clear what we'd gain by leaving inheritance (of any form) out of it. Might as well, at that point.
I agree about locks, but many of the other points I agree with. Then again, explicit is often better than implicit, even with language guarantees (so new programmers don't get as confused).
coming from C we got used to this idea that (*T) + (int) advances the address in units of sizeof(T). C's syntax is optimised for this kind of code.. it makes it easy to write code for concatenated allocations. advance a pointer past one block, recast into another type, etc. in this type of code the compiler can't really help you much. Wrap unsafe{} is as much as it can do. I linked the jonathan blow talk because he explains how important these tricks are to him Asking around some more it seems the sticking point is that operator + has to be safe, but *T ofseting/recast is inherently unsafe. they'd need a way of making + unsafe for *T
Oh hey, thanks for posting! This was my first rust project so any feedback is appreciated.
I never understood bashing Notch for his programming skill. He literally just walked away with a few billion dollars. It would be easy to write that off as him getting lucky but I think there is a bit more to it than that.
I'm going to type this from memory, but aturon.github.io has the in-progress stuff. Eventually it'll be in the rust-lang organization.
Being a good game designer doesn't imply much about your programming skills one way or the other.
Just did it myself, was pretty easy. Now to write some tests...
When you *must* is not the same as when you *should*. Annotations are noise when they are obvious and documentation when they aren't. You should try to put yourself in the shoes of someone who is learning the code for the first time. Looking at your code *locally*, how much can you deduce about the code block you're in. If you assign a literal or invoke a constructor, type annotations are just duplicating what the right hand side tells you. If you're calling out to a standard library function or 'well-known' function in your codebase, then an annotation shouldn't be necessary. Similarly, if you're calling a "helper" function, defined perhaps just above or below the call site, an annotation is probably not too important. On the other hand, if you're calling an obscure function, especially one defined in another module, then an annotation might save you a trip to `grep -R "fn &lt;funcname&gt;`. Or perhaps in a function which allocates several local variables with some tricky logic, it might be nice to be explicit about what the types of everything is so that you can spend your attention in the function, not definition-chasing.
The most concise you can get is the `match`. You can disregard the content with `..`: enum Foo { Bar(int, int, String), Quux(String) } let a = Bar(1, 2, "3".to_string()); let is_a = match a { Bar(..) =&gt; true, _ =&gt; false }; This is especially useful if the variant `Bar` gets additional fields later.
Note that this is on my branch and I will be upstreaming the changes over the next week as I write tests for them. Much of the work here consisted of adding support for tables, tweaking forms, and adding and/or fixing a bunch of HTML4 stuff (`&lt;td align&gt;`, `&lt;td width="25%"&gt;`, `&lt;input size&gt;`).
[see also](https://github.com/rust-lang/rfcs/pull/163)
Bill Gates is the richest man of the world (again). He is a bad programmer, too. 
Thanks. I think the macro would be closer to what I want, though a short syntax would be nice. I guess I don't know how often it would be used though. The `if let` syntax is maybe a little better, but for actually storing the result, it ends up being about the same as `match`.
The hint about the `..` is helpful. Thank you.
Thanks for the link. I'll keep my eye on that.
Less hackers. How is this even avoidable? 
`Bar(_)` says "`Bar` should have a single field, which we ignore". `Bar(...)` says "`Bar` can have any number of fields, all of which we ignore".
What makes you say that it will never perform well enough? I've been examining the big number libraries in OpenSSL and PGP. They really aren't ultra complicated, and I don't see how rust would prevent me from reaching similar performance. But either way, the goal of the rust-crypto project is to have pure rust implementations of cryptographic algorithms. So that project would still find it useful.
Do you render the form fields yourself or are you utilizing the platform's native toolkit?
Marking it as unsafe would make ensuring safety more convenient (since calling it in safe code would be an error, instead of silently accepted).
Isn't the borrow checker used to know when it's appropriate to free a variable? Rust doesn't have C++'s `delete`..
If you just want this for `std::option::Option`, it has a `is_none()` method: http://doc.rust-lang.org/std/option/enum.Option.html#method.is_none You could also implement this kind of method for your own enum.
There is solution for exactly that. If someone finds it noisy, one can make small modules. IMO, there is no need to introduce 3rd solution to this problem.
At least in Chrome's case, we looked into using native widgets for web content and decided it'd be too much effort for something that ultimately would just make things perform worse. (And there's lots of ways it can go wrong: for example, many web pages will do stuff like style only the foreground color of button text, assuming that the button background color is as it is on Windows. Or assume more basic stuff like the size of buttons.) https://code.google.com/p/chromium/issues/detail?id=10949 Also from that bug, here's an age-old comment on the subject (second to last comment) from Shaver of Mozilla! https://news.ycombinator.com/item?id=2126244
Rust doesn't have a complete answer to C++'s template metaprogramming, yet.
True, but given that many companies, sadly, forbid use of metaprogramming, this isn't a big handicap.
&gt; rust has a habit of making unsafe code painful to write This is similar to how Ada, Modula-3, Oberon, Sing#, C# do it. And I like it, even though I am also a big C++ fan. When safety is important, it is good to have explicity when dirty things are being done.
I think the OP's question was about the languages themselves, not their libraries/frameworks.
We style the form controls ourselves: http://mxr.mozilla.org/servo/source/components/style/user-agent.css#120
There's a difference between unsafe code being *painful* to write and unsafe code being explicitly segregated. In many ways, having unsafe code *not* painful is better: if code is easier to read and write, it's easier to verify and easier to write correctly.
Seems like an oversight. I'd expect `b"Hello"` to be the same as `[b'H',b'e',b'l',b'l',b'o']`. File an issue?
* Talk to C++ libraries* * Be used in Windows ~~Metro~~ ~~Toybox~~ Modern* * Catch failure without creating threads* * Get you a job*? :D &amp;nbsp; \* Well, sort of.
Its possible to catch without threads, there is just no safe mechanism for it, just a unsafe intrinsic.
Rust has been known to get some people here jobs. Exhibits include /u/steveklabnik1 and others with a *mozilla* flair.
Well, `b"Hello"` works the same way as `"hello"`, and the same way as `&amp;[b'H',b'e',b'l',b'l',b'o']` at least used to behave.
&gt; \* Well, sort of. Let's face it; there are few enough counter examples that they're basically sampling errors. :)
The question was not if it *will* get you a job, but if it *can* give you a job; therefore the exhibits are proof by construction. Now, for the question if it *will* give *you* a job, I fully acknowledge your statistics-based objection. The probability is non-zero, but close.
Alright, I'll give you that one.
Oh yeh, C++'s templates are a nightmare, I was just saying that they technically allow you to express things at compile time that we can't express yet.
Yeah, that is factually correct. I was more responding to the 'yet' :)
This could at later point be merged with [hematite](https://github.com/PistonDevelopers/hematite)?
I'm not a C++ dev so I find this curious...why is it forbidden? Too easy to dangerous things? Or too advanced, and so they are worried with getting code that is unmaintainable by future employees?
I hope the answer will be "no". C++’s template metaprogramming is an ugly fail in the eyes of many of us.
Just attach that method to a trait, then: trait MyUnsafeIndex&lt;T&gt; { #[index_method] unsafe fn index(&amp;self, idx: uint) -&gt; T; } impl&lt;T&gt; MyUnsafeIndex&lt;T&gt; for Pointer&lt;T&gt; { ... } The real downside is that there's so much compiler magic associated with operator overloads that deviating for the method signatures it expects is nearly impossible (e.g. the compiler auto-refs operator overload arguments which precludes by-value overloads for binary operators).
From the [Google C++ Styleguide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.html#Template_metaprogramming): &gt; The techniques used in template metaprogramming are often obscure to anyone but language experts. Code that uses templates in complicated ways is often unreadable, and is hard to debug or maintain. 
Great answer. Not sure the fact that no language can really talk to C++ is Rust's fault though. (But yes, in practice it's an unfair advantage of C++.)
Yup. Everything beyond the level of LLVM-IR is superficial.
There are definitely better metaprogramming facilities out there. I would love the power of C++'s templates in a sane package.
&gt; want invoking unsafe code to involve elaborate ritual sacrifice Compiler error: goat not found.
They have very low usefulness to complexity ratio.
Exactly this. Anything else we can do with hygienic macros. 
Well, this is not a purely language property, but C++ has huge amount of libs in all possible fields, while rust has almost none.
D has some ability to "talk to C++".
If you thought we got a lot of confused posts about the game Rust before...
That *would* be nice. On a completely unrelated matter, if anyone's hiring, let me know. ;)
On my Windows Vista setup, I get link errors: &gt; undefined reference to `_gmtime32' I think this is somewhat known - I should use an older MinGW, but I don't want to downgrade it. Any info on if/when this will be fixed?
Actually, in this case the Web page is styling the form fields manually.
Ruby is turing complete, can you write a kernel in Ruby? No- turing complete only has to do with what you can compute, not with what machine-level semantics you can express.
It requires expert knowledge and companies rather hire novice programmers, hence they shun away anything that can make it harder to do so. This is not only related to C++. Many other languages suffer from similar limitations, e.g. not using list comprehensions or iteratable in Python. 
It's not everyone's cup of tea (nor is Rust), but D is a fine language if you are looking for metaprogramming with semantics closer to C++.
Oh yeh, I've played around with D, I love it's metaprogramming facilities, it's what I was thinking of when I said there were better ones out there :)
the borrow checker prevents some crashes at compile time, but it's an over-estimate of what you can't do, and requires a little extra up-front work with lifetimes. as someone else mentions, when things are freed is down to scope blocks, similar to RAII in C++
Unsafe code in rust just use the unsafe keyword: unsafe fn kaboom(ptr: *const int) -&gt; int { *ptr } Here is some documentation: * http://doc.rust-lang.org/guide.html#unsafe * http://doc.rust-lang.org/guide-unsafe.html * http://doc.rust-lang.org/guide-ffi.html#unsafe-blocks 
Another reason you want raw pointer tricks: rust ADT's are great , but you can have something like an immutable ADT where only the actual size of the variant required is used. Without raw pointer tricks, if we want this in rust we have to wait till this is built into the compiler and semantics
I would be very interested in seeing someone come up with a model of how (overhead-free) intrusive data structures could be safely supported in a hypothetical version of Rust. I think they're an important enough usecase that it's worth spending some time figuring out whether it's possible, even if it doesn't end up being practical.
Let me guess, the person doing weird things because "performance" had absolutely no evidence to support it. I agree about keeping `unsafe` as simple as possible. Languages where the designers think they're smarter than the users are never pleasant to use. I want a language that assumes I'm brilliant but distracted, so it'll catch mistakes but won't stand in my way when I really need to do something weird. Large programs may have entire subsystems where `unsafe` shouldn't be allowed, which you can enforce today with `#![forbid(unsafe_block)]`. And lint plugins can enforce additional project-specific rules. Servo has `deny(unsafe_block)` on most of the layout code; we also have a custom lint for auditing uses of `transmute`.
My very preliminary idea was that we could just have non-moveable types (how to declare them as such is another question) and a trait like: trait Relocate { fn relocate(from: &amp;move Self, to: &amp;out Self); } which of course would require having `&amp;move` and `&amp;out` references (because it would obviously be paradoxical to pass and return values of nonmoveable types by value!). Then the `impl`s for `Drop`, `Relocate`, and/or `Clone` would have the `unsafe` code for dynamically patching up e.g. the doubly linked list threaded through the value. (I don't think it would be possible to avoid `unsafe` code in the implementation, but at least you could present a safe interface, which you currently cannot.) Calls to `relocate()` would have to be explicit, unlike C++'s implicit move constructors, but this is consistent with Rust's existing philosophy of e.g. requiring explicit `clone()` calls instead of an implicit copy constructor. The annoying thing as usual is how to make this play nice with generic code (which currently is allowed to assume that every type is moveable). (This is notably even an issue for the `Relocate` trait itself!)
Crash.
I'm assuming that by "intrusive data structures" you mean "data structures that hand out 'partially-borrowed' mutable pointers to elements", not "data structures that put theirselves into your structure" (keeping in mind that a structure can be both). The latter can be done with associated fields: trait LinkedList { next : Option&lt;Box&lt;Self&gt;&gt;, fn find_cond&lt;F: Fn&lt;(Self,),bool&gt;&gt;(&amp;self, f: F) -&gt; Option&lt;&amp;Self&gt; { if f(self) { Some(&amp;self) } else match self.next { None =&gt; None, Some(ref t) =&gt; (&amp;*t).find_cond(f) } } fn delete_after(&amp;mut self) -&gt; Self { let succ = self.next.unwrap().next.take(); mem::replace(&amp;mut self.next, succ) } } Relocation isn't particularly interesting - the more interesting part is non-memcpy-movability, which could be done via a variant of `Sized?` (`Move?` in the style of `Copy`?).
You certainly can, just not with the data structures in `libcollections`. rustc, for example, uses this for Ty.
My experience is that a good static type system is tremendously helpful for rapid iteration and refactoring. In the year I've been working on Servo's 100+ kLoC , we've managed a number of tricky architectural changes as well as a year of Rust language drift, and we did this with a level of speed and confidence I would find hard to achieve in C++. There's just too much implicit complexity — type conversions, inheritance, overloaded copies and assignment, implicit reference-taking with no lifetimes, template duck-typing and SFINAE, template specialization interacting with header file order, etc. etc. Sure, there are tools and best practices for mitigating these problems, and I'd love to see Rust get more tooling of this form. But nothing takes the place of starting with a solid foundation. Your list is missing option [3]: stick with C++ for now, and wait for the Rust ecosystem to mature (or contribute the missing stuff yourself!). Why would a fork be better than contributing these improvements upstream?
both have their uses; I can easily see domains where forbid(unsafe) would be desirable - probably the majority of code people write, and even subsets of gamedev. But when unsafe code is genuinely needed , it would be great if it could be as pleasant as in C/C++
Wow, companies that consider list comprehensions to be an experts-only feature in Python are *seriously* behind the times.
 println!("{}", unsafe { *(0 as *const uint) });
Yup. The case I ran into recently on our client was weak references on common user icons. Our entire icon pack is less than 5mb, was loaded once and stored in an enum. This for client machines that typically has around 4gb of ram available. A single one of our business objects was heavier than the entire icon pack. At best it didn't affect memory. At worst it would trigger several disk reads when GC became heavy (since these icons were literally everywhere) and would potentially use more memory since the reference to the icon would commonly be stored outside of the enum resulting in double loads. That certainly isn't too say weak references aren't useful. You just have to know what you are doing with them.
Also some things that rust doesn't intend to provide that C++ does. Implicit type conversions. Null pointers/values.
Also note that multiple inheritance in C++ is mostly used for classes that act like interfaces. In Rust, the same thing can be accomplished with traits, so multiple inheritance isn't really needed.
&gt; I think knowing Rust will already help you get a job, but probably not a job programming in Rust :) I am definitely getting lots of interest when applying for jobs and internships recently, when they see that Rust is one of my most used languages. It definitely makes you stand out from the crowd when applying for 'cool' places. But as you say, none of those jobs are for actually programming in Rust. :)
Regarding [1] through [4], those all seem like pretty minor syntactic issues. I think in each case you could write a small macro to recover the more implicit syntax. But also, C++ has a *huge* number of syntactic annoyances that go away in Rust. Syntax is something where there's always room for improvement and you can never make everyone happy. At some point it's worth taking the bad with the good, when it gives you access to powerful semantics. &gt; It was definitely encouraging to see that the Rust team considers an unsafe build a possibility. I'm not really sure about an "unsafe build" of the language. The goal is for standard Rust to have first-class support for unsafe code. It may not have exactly the syntax you prefer but it will be powerful, concise, and correct. &gt; feels awkward needing to 'use' basics Considering `sizeof` one of the "basics" is historical baggage from C. It doesn't even make that much sense in idiomatic C++. Sure you need it sometimes but I don't see why it should be more fundamental than, say, `mem::transmute`. If you are really really picky, you can substitute your own version of the [prelude](http://doc.rust-lang.org/std/prelude/index.html) with one line of code in each module. &gt; My preference would be traits are optional. When C++ finally gets' concepts it'll be like that. There's even a proposal for 'auto' arguments as sugar for templated functions That's very interesting. I'll think more about how that might look in Rust.
I would vote for "always" because it makes it easier to read
Yep, this is a well-known phenomenon in the Haskell community as well. Even if a company says you'll be doing "some Java and some Haskell" you have to think twice about what the proportions will really be ;) I think Rust won't have as much of a problem there because it's much easier to sneak some Rust into an existing C/C++/Python/Ruby/… project.
Do you have a degree? I want so badly to get into systems programming but I don't have the time or money to get a degree.
I submitted [a small RFC](https://github.com/rust-lang/rfcs/pull/339) on this issue last week, but it got no attention so far.
I would definitely like for Rust to glean what it can from D's metaprogramming. Some form of compile-time functions would be very nice.
What blocks it from being used in Windows Modern?
I even implemented the part about byte string literals as an exercise (it's a very small change), but immediately run into an issue very similar to [this one](https://github.com/rust-lang/rust/issues/17233), which I could do nothing about.
It's called a joke.
Feed a family of four [:D](http://goto.ucsd.edu/~mstepp/math_jokes.html)
So, with an allocator, can you allocate the data structures from libcollections on the stack in Rust? Secondly, is it possible for a Rust allocator to allocate to the stack in any situation?
&gt; I want a language that assumes I'm brilliant but distracted Exactly. That's the perfect nutshell: precise and accurate. 
I think there was a Rust project in GSoC last year but it didn't push through. (I did GSoC with Servo last year, amazing experience)
If you can't get a degree, pour your free time into open source and learning fundamental CS and such - there are great courses online. It won't help you getting overseas jobs, but depending on the workplace, actual OSS experience can be extremely valuable.
There is no added complexity if `str` is moved to the library (and I hope it will be moved), see the last section.
Allocators aren't implemented in Rust AFAIK (cf. https://github.com/rust-lang/rust/issues/12038). As for allocating byte buffers on the stack, you can allocate the buffer if you know the size at compile time, I haven't seen a working allocation with a size known at runtime so far. Maybe it's possible somehow with `unsafe`?
CTFE is definitely planned. ETA unknown though - probably post 1.0.
He means using the scan* macros as functions so you can provide parameters at runtime.
If let can also be used as an expression. So let is_none = if let Some(_) = some_value {true} else {false}; should also work.
It would help greatly if we had a command line tools and libraries for the same kind of functionality that golang "oracle" has: it's a tool that you can send queries about the code to – for example "what's the type of this thing", "where is this variable mentioned in the code", "who calls this function", "what does this macro expand to", "what are the members of this struct" etc. Would help writing plugins to for existing IDEs.
A formal specification is badly needed, no doubt.
Agreed. I've been a Mozilla contributor for more than 5 years now in various capacities, and spent significant amounts of time finding ways to ensure that volunteers do not receive second-class treatment. Part of that is not calling out the employment status, because it becomes too easy to discriminate based upon it. I feel weird seeing the flair beside my name.
With regards to number 3, what about friends of the tree? It's still a bit arbitrary, but it stems from excellent contributions recognized in a core team meeting.
You could do what we did over at /r/rust_gamedev which is encourage community members to list rust projects that they work on in their flair. For example, I've worked on and am knowledgeable about Piston, so I list that on my flair. Hopefully that makes it easier for other people to ask me questions. In /r/rust our compiler hackers could add `rustc` and the standard library authors could add `stdlib` or something. It does require a system of trust, but I think it would work out just fine.
For #1, why does there need to be any restriction beyond "link to a pull request to rust-lang/rust or rust-lang/rust-rfcs?"
No, it was a great success. /u/-mw- implemented debug symbol support under me in 2013.
In fact, FotT is *the only* non-arbitrary criteria for awarding that flair. But, to use the same example as in the post, dbaupp has never been recognized as such, and he's definitely a contributor worth distinguishing.
Let me turn the question around. What sort of contributions are you anticipating that don't fall under this umbrella? Particularly well-written blog posts? Meetup organizers?
I'm not picky, I'd accept anything that positively contributes to the community. But I'm looking for concrete ways to inspire folks as to how they can begin actively contributing, rather than "just" rewarding people who have already decided to contribute. I'd like to be able to say, "hey, if you'd like to get a shiny thing next to your name, try any of the following! [list]".
I thought supercontributor was for Friends of the Tree? I think that is a good indication for a supercontributor. If there is a contribution to rust-lang/rust I think that is deserving of contributor flair. I think it is good to have a lot of `contributor` flair :D I think there should be another flair for `core team`, which would include /u/dbaupp, even though hes not part of mozilla so in the end i would say `contributor` &lt; `supercontributor` / `mozilla` &lt; `core team`
Seems like the [core team](https://github.com/rust-lang/rust/wiki/Note-core-team) and committers (or r+ers, I guess) should each get their own thing. Also FotT. 
 I had tried it using an `if let` expression as well, but ultimately it's about the same length as `match`. Was hoping there was something much more concise. I think a macro is going to be the best bet for now. Thanks though.
We could also have a list of projects to choose from (perhaps limit the number of projects you can choose)
As someone who is just a "second-class volunteer", I think it is valuable to be able to see who are the people who work full-time on Rust versus those who are "just" volunteers (even serious volunteers). I would hate to lose something like that. I can understand if you want to rename it to something like `rust-team`, and open it to the possibility that non-Mozilla-employees might be included, but there's value to knowing whether the thing you're reading is coming from someone who has helped microscopically (like me) versus someone who has helped majorly (like supercontributors, or whatever) versus those who are active in steering the way the language goes. Maybe, for example, make a `rust-team` flair for those who regularly attend the rust weekly meetings?
Agreed. For quite a long time after getting involved with Mozilla, I was unable to really identify who was an employee and who wasn't, which is something that Mozilla encourages and should continue to do so. It might be prudent to have that distinction for "official" statements, but this is Reddit, so that doesn't matter much :)
For (2), what about "core team" or something (related to commit access or something similar)? What we really want there is "this guy knows what he's talking about", which extends beyond the employees to people who have been trusted by the community to do &lt;something&gt;.
When I said "last year" I meant "this year", oops :P Interesting though, I'll have to have a look at the project :)
I agree, primarily for this reason. Secondarily, it's misleading. I *am* on the Mozilla payroll, and since I work on Servo I do have the unique advantage of getting paid to code in Rust full-time. But I'm not actually a member of the Rust team, and lots of non-staff contributors know way more about the language than I do. When I've contributed to Rust itself, it's been on my own time, as a volunteer. So I'd rather wear the "contributor" badge (but I also don't want to confuse people into thinking I've left MoCo or something).
I was trying to make a distinction (however vague) between "syntactic niceties" and things which have a major impact on expressiveness. Bitfields fall under the former. There's nothing you can do with a bitfield that you couldn't do manually with the various bitwise operators with a bit more typing. &gt; Overloading on mutability and lvalueness/rvalueness. This one is interesting. Is there a profitable use for this in generic code, i.e. where you're not operating on a particular type which has a given mutability and l/rvalueness, but on a type variable, and it does a different thing depending on what mutability/*valueness the type it's instantiated with has, in some appropriate way? More concretely, whether this gains you anything beyond just being able to elide the `_mut` or `_move` or whatever suffix on the function you're calling. &gt; Something like inferred return types This one is somewhere on the border. For the most part there's nothing you couldn't write explicitly, perhaps using a dedicated newtype, with just some more typing. But sometimes a lot of it.
That [doesn't necessarily crash](http://play.rust-lang.org/?run=1&amp;code=fn%20main%28%29%20{%0A%20%20%20%20println!%28%22{}%22%2C%20unsafe%20{%20*%280%20as%20*const%20uint%29%20}%29%3B%0A}). (Null-dereference is undefined behaviour, and so is legal to optimise out entirely.)
I am starting college in January, maybe I should try to be a help to Rust? That sounds fun! I will keep reading the dragon book and see if I can help :)
&gt; Allocators aren't implemented in Rust AFAIK Allocators are implemented in Rust. The standard library types aren't parametrized by them, but that doesn't mean they aren't implemented. There are implementations of collection types with support for allocators.
It's completely possible without any hacks. It is a trivial safe abstraction built on `unsafe` code.
&gt; Rust currently has very bad support for intrusive data structures. This seems like a big omission. I was reading some articles on performance best practices for game programming, and this kind of structure is almost always recommended.
That's a good point!
This looks like a violation of the prime directive of software engineering - "Use the right tool for the job". If you want D-like semantics and syntax, shouldn't you be, well, using D instead of trying to change a language with well defined goals and domain of problems that it tries to solve? You're trying to use a "Memory safe, concurrent language" to write memory unsafe code, that's like trying to use hit a nail with a screwdriver. I do agree with some of the *implementation* points you make but there must be an initial axiom that we all agree on the goals of the language and aim to improve the language in according with said goals. As others also commented, unsafe code should be possible and simple but also segregated and *explicit*. This is clearly a stated design goal of Rust. 
I'm in favor of a list. It could be automatically generated by looking for all github rust projects with over 10 or 20 stars, as a sanity check. That way users can say what they are working on outside of the core libraries, which is likely to be the vast majority of users in the very near future. We should also have a form that users can submit if they want to list a project with less than 10 or 20 stars, so nobody's project is unintentionally excluded.
It's currently possible to dynamically allocate on the stack?
I agree, but I think the problem is the lack of macro namespacing, not necessarily the name of the macro. I would be pretty bummed if `IdentTT` went away unless it was replaced with a more general way to expand syntax extensions that allows users to specify things like `IdentTT` in their own code.
Rust has a lot of advantages over D that don't have anything to do with safety. D has advantages too, of course.
&gt; E.g., untagged unions can be emulated even easier than bit fields. Can they? Presumably you're thinking of just storing `[u8, ..??]` and transmuting to and fro as required. But can you get the right size and alignment? (I can't remember if that was the only issue... I know this possibility has come up before and that it was not good enough for whatever reasons, but the details are hazy.)
Intrusive data structures can be done, but they lead to `unsafe` code everywhere and working with them is arguably less pleasant than in C.
For those of us not familiar with Ocaml or who don't want to read 10,000 lines of code, anyone have any details on what this magical algorithm that removes high level constructs is? It sounds like a fancy way to say "inliner".
&gt;Presumably you're thinking of just storing [u8, ..??] Exactly. &gt;But can you get the right size and alignment? Not in generic way. I wish we had non-type generic parameters and compile time `sizeof`/`alignof`. But the similar situation is with bit fields sizes. (Although, frankly speaking, I haven't tried to emulate any of them.)
&gt; Not in a generic way. A portable way? :)
I think that the changes in the RFC are unnecessary and will mostly just get in the way. Right now the error messages are already good enough that I read it once, understood it and worked around it. No need to ban them altogether.
Rust has perfectly good null pointers: "typed" ones in the form of `Option&lt;&amp;T&gt;`, and "implicit" ones in the form of `*const`.
Nope- that's a translation of the Linux kernel's *computation*, including its effect on hardware, translated to JavaScript running on *emulated* hardware. The difference between JavaScript/Ruby and Rust/C/assembly/machine language is the tools to directly manipulate hardware. JavaScript/Ruby simply don't have the same level of control, so the best they can do is control emulated hardware and/or control real hardware through a lower level language. After that it's just performance, yes, but there is a significant technical and practical gap beyond just being turing complete.
That's not really the same, especially when the language spec explicitly states 'no concept of null' But I guess it's a way to emulate it.
In what way are they not the same?
Well you could give out silly/novelty flairs...
Maybe I'm mixing up how a null pointer can be expressed.
Ah. Well, I don't know how well the design would translate. Originally, the patterns were going to be string literals, in part so that you *could* translate them more or less directly to a runtime call. But that proved unpalatable. At this stage, there's no plans for a runtime version.
I installed the Win 10 TP specifically to look into this. Compiling even a simple WinRT program produces a veritable *mountain* of stuff. Two .xbf files, AppxManifest.xml, .build.appx.recipie the .exe, .exp, .ilk, .lib, .pdb, .winmd and a .pri. It's hard finding any accurate information as to what all these bits are for, or the format they're in. Pretty much all the documentation I've found so far about the "internals" of WinRT are either vague overviews or "just use Visual Studio!". You can't run the executable, either. It doesn't have a main function. Well, it does, apparently. But it doesn't. Instead, it gets loaded like a DLL... maybe. I have no idea how VS even launches this stupid thing, let alone attaches a debugger. When it gets run for debugging, it shows up as a child of svchost.exe, *not* Visual Studio itself. That's not even getting into WinRT itself, which is COM, except they don't use the COM interfaces *or* the standard COM types. You *can* do COM in Rust, but it's hideous. And there's the new metadata format (.tlb -&gt; .winmd). And even if all that gets solved (which is all at least theoretically tractible)... WinRT still forbids a number of important APIs to everything *except* the VC runtime. I know that VirtualAlloc is verboten, plus all the *replaced* APIs... large parts of the Rust standard library would probably have to be ported across or simplified. I don't see any reason Rust couldn't be made to run on WinRT in some form. I suspect it'll be a huge amount of work and it may not ever work 100% properly or efficiently. The more time I spend with Windows 10, the more it feels like an appliance that only grudgingly has an API rather than an OS for PCs. `&lt;/rant&gt;`
The unsafe version: let ptr: *const uint = std::ptr::null(); // or let ptr: *const uint = 0 as *const uint; The safe version: let ptr: Option&lt;&amp;uint&gt; = None; This is compiled to a single nullable pointer (i.e. it is pointer sized).
It should be fine; the accesses are in-bounds in the chunk of memory that was allocated. (BTW, you should use markdown's \`'s for delimiting code, to avoid problems like your accidental italicization due to `*`s, something like ```Foo*`s are only accessed ...``.)
Huon is on the core team, so I think he qualifies for supercontributor with the current rules :)
You have the right idea. Unfortunately, the way Rust currently invokes static methods on traits, there's no way to call the methods you have defined. This is getting fixed: see https://github.com/rust-lang/rfcs/blob/master/active/0046-ufcs.md.
Unfortunately the C++ doesn't translate directly, although you would expect it to. This will work in the meantime: https://gist.github.com/amw-zero/5d0d8b3d9c2ed48e235d
Here's a brief tutorial: https://code.google.com/p/intuitionistic/source/browse/examples/tutorial.ipl
FotT?
A certain moderator on /r/rust already already hands out novelty flairs, in a way (case study: you and me)
Friend of the tree.
 &amp;int is 8 bytes Option&lt;&amp;int&gt; is 8 bytes Option&lt;Box&lt;int&gt;&gt; is 8 bytes That's cool. Last time I tried `size_of::Option&lt;~int&gt;()` it was 16 bytes. Good to know I can make a Vec&lt;Option&lt;Box&lt;T&gt;&gt; without wasting half the memory. (Or wrapping Vec&lt;*(mut|const) T&gt;) 
&gt; size_of::Option&lt;~int&gt;() it was 16 bytes That must've been quite a while ago, IIRC, the null pointer optimisation was added in Rust 0.6.
Sorry but no, that's simply incorrect. JavaScript can manipulate hardware "directly" (efforts such as asm.js) and Rust on the other hand sits atop llvm which manipulates the hardware for it (and llvm is implemented in c++!). Your definition is simply non tractable as I already said in my previous response. Again, on intel machines, no software language actually manipulates the hardware "directly" since there is a translation layer embedded in the cpu itself. All of this is just implementation details and not an important meaningful distinction for any purpose except performance. 
A slice is only a "view" into an array/vector. You will need to return the `Vec`. Alternatively, you could try using iterators.
I don't understand how this proposal is to lead to better API design, maybe a better example would be nice. The _forced_ splitting up of one Trait into multiple Traits to satisfy some new rule, why would that be better? I must admit i don't fully understand the whole RFC but for me, the example looks worse after the change..
[LLVM uses `i&lt;n&gt;` for its integer types](http://llvm.org/docs/LangRef.html#integer-type).
&gt; There are implementations of collection types with support for allocators. Would you kindly point us to them? Also, is it possible to implement an allocator that will use a portion of memory allocated on the stack?
asm.js is not actually manipulating hardware, it is just a low-level subset of javascript that is designed to be easier to optimise. (That is, it's an "asm for JS engines", not "javascript manipulating asm".) LLVM is also not manipulating hardware in the manner you imply: it is not a virtual machine, despite what the name suggests (previously it was an initialism for low-level virtual machine, but this is no longer the case). LLVM is an optimiser and code-generator that outputs native machine code, just like a normal C/C++ compiler (in fact LLVM is the backend used in the clang C/C++ compiler).
I haven't read the dragon book myself, but from what I heard, isn't it a bit... from a different age, not to say "outdated". Maybe the parser and the AST it produces, or the CFG (control-flow graph) fit some traditional design, but many parts of the compiler weren't designed after a model, but rather evolved into that shape.
&gt; It's non-standard in C++ Stack allocation is used all the time in C++, it is entirely standard. `int len = 123; char buf[len];` does a stack allocation of 123 bytes. `std::string small ("string");` might use the small strings optimization, keeping the "string" on the stack. Allocators (http://en.cppreference.com/w/cpp/concept/Allocator) are a part of the C++ standard. &gt; and often results in very brittle code That's not a problem with stack allocation or Allocators per se, that's a problem with the "trust the programmer" language design and it is present everywhere in the C++ language, not just in the stack allocation or Allocators. &gt; that can be really hard to debug when something goes wrong and wipes out the stack Why something would wipe your stack in the first place? And if something does overflow over your stack, then having some data on the stack will only increase the chance that the call stack will remain intact, giving you a meaningful stack trace. &gt; I don't like this idea though, since this seem to be just porting a buggy feature from C++ Instead of "just porting" a feature Rust should/would attach a lifetime to the allocator.
Well, I have not finished the context free grammars section (chapter 1... I just got the book), and I hope that it teaches good ideas for how compilers work, even if not too modern. If it does not, I wish I would have heard of another compiler book (preferably that does not cost $130...) I just want to get my feet wet with really low level stuff like compiler writing, and books appeal to me. Maybe if I do GSoC I can get really into rustc :D
Well then, I hope I can follow in Tesla's [footsteps](http://en.wikipedia.org/wiki/Nikola_Tesla#Relationships) then.
Cheers! Forever helpful is the /u/dbaupp
Fixed sized buffers I assume?
If there's an open project for Rust, I'd love to participate in GSoC! 
&gt; the example looks worse after the change.. Do you mean the one listed under "Drawbacks"? That's illustrating a particular issue that won't affect most traits. This change can significantly improve performance (see my other comment in this thread) so it's worthwhile even if some code gets uglier, IMO.
&gt; I would wish for more syntactic sugar in the language, akin to say python, where i can do array[2:] or array[::-1] or whatever. Also, currently my rust code uses a log "as_slice" The [slice notation RFC](https://github.com/rust-lang/rfcs/blob/master/active/0058-slice-notation.md) (accepted and partly implemented) helps a lot. Spelling out `to_string` is good because it's an allocation + copy (as with most `to_*` methods, unlike `as_*`)
Yes, but that also requires us to store and manage an index when all we want is to index in the array by nibble.
I do not understand where are you coming from with that assumption. Checking for owerflows is easily encapsulated in the Allocator. The only real problems are to pin the Allocator to the stack frame (e.g. prevent it from being *moved*) and to prevent collections from being used outside of the Allocator lifetime (enter Rust' lifetime checking). There is no reason to keep the stack allocation itself fixed in size.
Can you explain "We hope that this will lead to better design.", please? What would be improved? From my very basic understanding, it will not be allowed to put methods in the same trait if one of them uses generics and the other doesn't, right? I just think that will be hard to explain and as i said, i am wondering how this helps in better API design..
What I mean is, there's currently no way to allocate a dynamically sized buffer on the stack in Rust without digging through unexposed LLVM API right?
AFAIK, yes! And even if you get the buffer, encapsulating it inside the allocator struct might be a problem (for all I know, the allocator can't use the `alloca` from its constructor because it'll go away immediately; and template metaprogramming in Rust is limited to types so far).
Oh, yes, of course. So it's just a common inspiration then.
I _think_ I understand what you're trying to do here: Split a large number of generic traits into two separate traits, one of which can be used by reference, and one of which can't. The major payoff, as I understand it, is better error messages (thought I don't yet understand why that can't be accomplished within the current system, by flagging the calls which can't be made by reference). There's also a supposed to be a performance benefit, which I haven't wrapped my head around yet. My thoughts on this matter have little to do with the exact question under discussion. Rather, they're an appeal to consider certain general principles, which could actually cut either way in this case. Honestly, as things are now, I'm pretty unhappy with the ergonomics of Rust traits. My intuition is that if something works as a struct, I ought to be able to extract a trait from it, and write generic code. But given a struct, it's often impossible to extract a corresponding `trait` with the same API. For example: impl ZeroCopyParser { // Inspired by—and calling—Buffer::fill_buf. fn next&lt;'a&gt;(&amp;'a mut self) -&gt; Option&lt;Datum&lt;'a&gt;&gt; { ... } } …works fine, but it has no corresponding trait: trait StreamingIterator&lt;T&gt; { fn next&lt;'a&gt;(&amp;'a mut self) -&gt; Option&lt;T&gt;; // Can't put 'a on T. } …which means that `Buffer`-style streaming I/O in Rust can only be generic if I'm willing to accept a 25x to 50x performance hit. (Which in turn makes it hard to build APIs that do generic streaming computations like [Spark](http://spark.apache.org/docs/latest/quick-start.html), an otherwise potentially awesome use-case for Rust.) Which brings me back to the RFC under discussion: 1. Will splitting traits like `Iterator` into two traits make it more or less intuitive to extract traits from structs? 2. Will this change increase or decrease the number of cases where traits can be extracted? 3. How does this change affect generic parameters to the trait itself, such as the `T` in `Iterator&lt;T&gt;`? Will every method that touches `T` be forbidden under this scheme? Or only methods like `fold`, that have their own type parameters? I would certainly be very sad if we could no longer have `fold`, but I don't think that's under discussion here, right? The only thing that would change is that we would need to put `fold` into a separate trait, correct? All other things being equal, I do like the idea of `Box&lt;Trait&gt;` being usable as `Trait`. But I really want to convince myself that all other things are equal, and that Rust trait-from-struct-extraction ergonomics will be neutral or improved by this change.
&gt; really low level stuff like compiler writing It's also really high level stuff at the same time :) it's an interesting area.
This sounds amazing... and way over my head. I am naturally sceptical of the claims, since it seems like magic to me. This would seem to be the programming language "holy grail".
My first thought was creating a wrapper around slices and implementing Index for it, but that's not possible because .index(foo) returns a reference. Creating an iterator and implementing RandomAccessIterator would work because .idx(foo) returns by move. This would require keeping an extra piece of state (current index into the slice), but it would be doable. "no way to map one element to two elements with Rust iterators" wouldn't be a problem, since you're creating the iterator from scratch anyway, and you wouldn't actually ever need to use the non-indexing parts if you don't want to iterate over all the nibbles. The third alternative would be to create a nibble indexing trait, and implement it for the types that you want (slices in this case). This might actually be the best alternative, if you don't need iteration.
Someone asked last week how to install rust on an ARM device running linux. The answer was that there was no easy way to do it since there aren't official nightlies, so you have to cross compile the rust compiler. At that point in time, I already had rust cross compiled for ARM, so I figured I could share the compiler I built to make it easier for others. Fast forward to this week, I got rust and [cargo working on ARM](https://github.com/japaric/ruststrap/issues/4). I've setup build automation, and I'm hosting the nightly builds! I hope these nightlies make it easier for people to develop applications [1] on ARM devices. [1] Hopefully something cooler than [blinking LEDs](https://github.com/japaric/bb.rs)
I think that flair should be based on things that can be factually verified, and aren't based on some kind of arbitrary distinction. As far as contributor badges go, there are really two things I can see being important; which projects people contribute to, and whether they are a maintainer (reviewer, committer, whatever that particular project calls it). Beyond that you could have some kind of arbitrary threshold for commits to determine who is more active or not, but I don't think that's worth it. So what I'd like to see is badges like `(servo)`, `(servo reviewer)`, `(teepee)`, `(cargo maintainer)`, and so on (I don't know what the various projects call their various roles, I'm just using examples here). For the rust repository itself, being one of the largest and most central projects, you might break it down a little bit into subcomponents, such as `(rustc core)` for someone a member of the core team who hacks on the compiler, `(rust-docs)` for someone who primarily contributes docs, `(libstd reviewer)` for someone who does mostly library work and has reviewer privileges, or something of the sort. If people have contributed to multiple projects, let them pick whichever they feel is the most important. Which projects we allow is a bit of an open question; I'd say just allow people to list any projects they want (that are verifiable, such as published publicly), and let people evaluate the reputation of the project itself based on their own judgement. Now, this does only cover actual code contributions. We may want to have some flair for other people who contribute to the community in other important ways, but I don't have any good suggestion for how to do that other than on a case-by-case basis. I think that listing people's primary project, and role if they have some kind of special privilege on that project, is the best systematic way to assign flair, and anything else can be done based on the judgement of the mods.
Oh but you *can* return a reference for `Index`. It just won't truly reference the original `&amp;[u8]`, but since u8 has no internal mutability, it doesn't really matter. static NIBBLES : [u8, ..16] = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]; struct NibbleWrapper&lt;'lt&gt; { bytes: &amp;'lt [u8] } impl&lt;'lt&gt; Index&lt;uint, u8&gt; for NibbleWrapper&lt;'lt&gt; { fn index&lt;'a&gt;(&amp;'a self, idx: &amp;uint) -&gt; &amp;'a u8 { if *idx &amp; 1 == 0 { &amp;NIBBLES[(self.bytes[*idx &gt;&gt; 2] &amp; 0x0f) as uint] } else { &amp;NIBBLES[(self.bytes[*idx &gt;&gt; 2] &gt;&gt; 4) as uint] } } } It works because we can always shorten the lifetime of `'static` to `'a`.
Alternatively, you could use a `Nibbles` newtype that doesn't allocates memory, but instead gives you a "view" into the nibbles of a slice. #![feature(tuple_indexing)] use std::fmt; struct Nibbles&lt;'a&gt;(&amp;'a [u8]); impl&lt;'a&gt; Nibbles&lt;'a&gt; { // Can't implement ops::Index (`[]`), implement `at()` instead fn at(&amp;self, index: uint) -&gt; u8 { if index % 2 == 0 { self.0[index / 2] &amp; 0b1111 } else { self.0[index / 2] &gt;&gt; 4 } } fn iter(&amp;self) -&gt; NibbleIterator&lt;'a&gt; { NibbleIterator { nibbles: *self, state: 0, } } } impl&lt;'a&gt; Collection for Nibbles&lt;'a&gt; { fn len(&amp;self) -&gt; uint { self.0.len() * 2 } } impl&lt;'a&gt; fmt::Show for Nibbles&lt;'a&gt; { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { try!(write!(f, "[")); let mut is_first = true; for x in self.iter() { if is_first { is_first = false; } else { try!(write!(f, ", ")); } try!(write!(f, "{}", x)) } try!(write!(f, "]")); Ok(()) } } struct NibbleIterator&lt;'a&gt; { nibbles: Nibbles&lt;'a&gt;, state: uint, } impl&lt;'a&gt; Iterator&lt;u8&gt; for NibbleIterator&lt;'a&gt; { fn next(&amp;mut self) -&gt; Option&lt;u8&gt; { if self.state == self.nibbles.len() { None } else { let nibble = self.nibbles.at(self.state); self.state += 1; Some(nibble) } } } fn main() { println!("{}", Nibbles([8, 8, 8, 8])); }
&gt; From my very basic understanding, it will not be allowed to put methods in the same trait if one of them uses generics and the other doesn't, right? Only if you want to use the trait as a [trait object](http://doc.rust-lang.org/reference.html#object-types).
I implemented byte literals. To answer the question **why**: I just made it like (Unicode) string literals and didn’t consider making it fixed-sized. I did not *decide against* fixed-size. Now that you mention it, I agree it might be better to make them fixed-size, just because the conversion is easier one way than the other.
Asyncrhonous IO
https://github.com/rust-lang/rust/wiki/Note-guide-for-new-contributors
I agree that we should be careful to temper our rhetoric about the capability of Rust's type system. Although it's more capable than the type system of most mainstream languages, let's not fall into the trap of selling it as a magic bullet with no downsides. That way lies only disappointment for end users and embarrassment for people who are trying to sell the realistic benefits of Rust.
Could you elaborate on why the set of changes in the RFC are the only changes that can allow us to do that? I had assumed we were going to use a system like this, which seems like it'd be far less painful: `&amp;Trait`, `&amp;mut Trait`, `Box&lt;Trait&gt;`, etc implement `Trait` *when possible*. A trait object is always instantiable and usable as before, but if it's not possible for that object to implement its trait, the compiler will generate an error telling you why. For example: trait ByValue { fn bar(self); } fn blah&lt;T: Foo&gt;(t: T) {} fn ref(t: &amp;mut Foo) { blah(t); // ~ ERROR `&amp;Foo` cannot implement `Foo` because the `bar` method takes `self` by value } fn val(t: Box&lt;Foo&gt;) { blah(t); // fine } fn e&lt;T: PartialEq&gt;(t: T) {} fn self_escape(t: &amp;PartialEq) { e(t); // ~ ERROR `&amp;PartialEq` cannot implement `PartialEq` because the `eq` method references the erased `Self` type } 
Thanks for doing this.
True. Though when coupled with the custom lint system, I do find that authors can set up pretty powerful/arbitrary safety guarantees.
Best title.
Thank you very much! I totally missed your answer, but I'll research what will fit best ASAP!
http://www.cs.princeton.edu/~appel/modern/ is the book I learned from. You can find PDF copies online....
Can I throw this on my r-pi? 
Ok, this article has inspired me to start learning about Rust. Where should I begin? Is there a good book on Rust yet?
http://static.rust-lang.org/doc/master/guide.html
From what I've heard, expansive abstractions like that are usually looked down upon because they have to pick the lowest common denominator of database support. Any type or operation which isn't present in the database has to be implemented somehow. This is one of the reason popular projects like Discourse only support Postgres - not all of its features are unique to Postgres, but all of the available abstraction layers do not support its feature-set. As for NoSQL, they are not relational, so they would not fit cleanly into an abstraction which cleanly matches relational databases. Or perhaps they would, as a database with a single table which relates strings with arbitrary data (or one table for each type, relating strings with that type).
&gt; But is anybody out there thinking about the future possibilities for abstraction? Yes. Most exciting to me are proposals to use Rust's macro system to create expression languages and ORMs in the same vein as Python's SQLAlchemy (see [this issue](https://github.com/rust-lang/rust/issues/14658)). Another proposal was to use Rust's macro system to allow writing SQL directly into Rust code (taking advantage of the type system) and have it suitably converted and sanitised for various DBMSs (see this [blog post](http://kimhyunkang.github.io/blog/2014/06/15/rust-rfc-libsql/)). &gt; Is it too early (ie. language too immature) to be committing to heavy/deep abstractions over a wide variety of databases? Perhaps too early for any abstraction that's very reliant on the Rust macro system, since it's behind a feature gate and won't be appropriately finalised until well after 1.0.
Ah, I didn't think of "precalculating" the nibble values rather than calculating them on the go. It's possible to put the static into the index method in order to make it self-contained.
Also look at http://rustbyexample.com/