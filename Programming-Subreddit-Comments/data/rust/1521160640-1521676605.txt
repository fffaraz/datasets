That works too. :)
Or be explicit in both cases — i.e. have `..&lt;` and `..=`. The idea of _either_ inclusive or exclusive being mapped to a `..` operator is kinda scary, given how much of a precedent there is for `..` and `...` meaning "any old thing" depending on what language you happen to be looking at today. I feel this is a step in the right direction, though...
I am writing a macro and get an `ident`. The `ident` can either be a concrete value or an Option. I want to always handle it as an option, wrapping any concrete value with `Some()`. Is this possible?
I once had the misfortune of porting a Coffeescript library to Rust. This library made frequent use of both inclusive and exclusive ranges. Except in Coffeescript, .. is the *inclusive* range operator and ... is exclusive. You can just imagine how many hard to find bugs came as a result.
I think it's to early to criticize a language that I don't understand yet. The answer to my initial question was always in `request.get_ref::&lt;UrlEncodedBody&gt;()`, I can't approach Rust as if it were C++. I was thinking about having an inmutable and calling `get_ref`, but I suppose that's not allowed, or is it? I'll advance a little more with the book and see where that leads me before creating an opinion. 
There are some [conventions on naming](https://rust-lang-nursery.github.io/api-guidelines/naming.html#ad-hoc-conversions-follow-as_-to_-into_-conventions-c-conv), if that's something you mean.
The signature from the docs is actually pub trait AsRef&lt;T&gt; where T: ?Sized, { fn as_ref(&amp;self) -&gt; &amp;T; } But I know you were referring to the argument and not the return type. Thanks for the clarification.
This is an amazing write up! :) One small typo: "It's a testament to his genius that **the** his creation has been able to scale" It would also be very handy if each chapter had a link to the next chapter – but it's no big deal. Thank you for sharing this!
PROTIP: just write it is as in rust, and then at the end flip them all.
Something like this might work: macro_rules! blah { ($x:ident) =&gt; { { let val: Option&lt;_&gt; = $x.into(); val } } }
Finally I understand the choice for this syntax! Your explanation should be in the docs :D
Looks like you've got the makings of a neat series here. Is hardening the code on the agenda?
I mean, it beats not following any rules at all and having an utterly unmanageable mess. At least with this, when I do something truly stupid my co-workers can point out my error easier.
Seems like a decent approach (at least for some domains) but there seems to me that there's still the tremendous problem of somehow wrapping or implementing any library you ever want to use (including much of std) in a way that lends itself to this paradigm in an idiot-resistant way.
Let's say that you're dealing with something weird but credible, like `&amp;&amp;Arc&lt;String&gt;` The search order for the `self` type of a method call is plain first, then the deref chain, then automatic reference, then autoref of the deref chain. - `&amp;&amp;Arc&lt;String&gt;` - `&amp;Arc&lt;String&gt;` - `Arc&lt;String&gt;` - `String` - `str` - `&amp;'auto &amp;&amp;Arc&lt;String&gt;` - ~~&amp;'auto &amp;Arc&lt;String&gt;~~ (duplicate) - ~~&amp;'auto Arc&lt;String&gt;~~ (duplicate) - `&amp;'auto String` - `&amp;'auto str` *However* because `AsRef::as_ref` is a self-by-reference method, those `self` types are *not* the `impl for` type. So the actual search order becomes: - `&amp;&amp;Arc&lt;String&gt;` `impl AsRef for &amp;Arc&lt;String&gt;` - `&amp;Arc&lt;String&gt;` `impl AsRef for Arc&lt;String&gt;` - ~~Arc&lt;String&gt;~~ - ~~String~~ - ~~str~~ - `&amp;'auto &amp;&amp;Arc&lt;String&gt;` `impl AsRef for &amp;&amp;Arc&lt;String&gt;` - ~~&amp;'auto &amp;Arc&lt;String&gt;~~ (duplicate) - ~~&amp;'auto Arc&lt;String&gt;~~ (duplicate) - `&amp;'auto String` `impl AsRef for String` - `&amp;'auto str` `impl AsRef for str` Your case is much simpler of course. The search order is AsRef for `str` (`self: &amp;str`) then `&amp;str` (`self: &amp;&amp;str`).
Agreed... though I might be biased since I actually made a similar "`..` is to `&lt;` as `..=` is to `&lt;=`" comparison during the RFC discussion.
The compiler error in plain English is &gt; You say this function returns an error that's specific to IO, but you then try to return a `ParseIntError`. That doesn't make sense! The error handling architecture of the standard library has fallen out of favor. Crate `failure` is *much* more friendly: - Any type that's `Display + Debug + Send + Sync + 'static` can be used as an error message. All you need is to add the `Fail` trait (no required methods) or use the `failure::err_msg` function. - The standard library `Error` plus `Send + Sync + 'static` is automatically `Fail`. Those additional traits are nearly always present. - The type `failure::Error` can contain *any* error that implements `Fail` So make your function return `failure::Error` and it'll Just Work.
Oh, and about an IDE, I think Visual Studio Code has the best support, but I haven't used it myself.
It's definitely possible to learn from the book, but you're right, there's a lot of terminology. I feel like it's aimed at a "beginner-ish" audience - people who don't know rust and don't need to know anything of _systems_ programming, but do know general programming and programming terminology. It does granted words like `keyword` (a word reserved for a specific meaning), variables, binding (setting a variable to a value), showing, etc. If you haven't done any programming at all, I would suggest starting with a different language, my favorite to suggest is Python. I don't mean this as an insult to either you or to Rust - Python is just a nicer language to get the general concepts in, since you aren't forced into the deep end from day 1. There are resources for beginners available for Python which aren't yet written for Rust, and it's a much more forgiving environment. I programmed a lot in Python before I learned Rust, and I felt like that was a good transition. It's possible to learn rust as a second language, but I'm not sure the resources to learn it as a first language exist yet. Words like "keywords", "variables", "binding", "showing", etc. are currently assumed knowledge, because someone coming from another programming language will likely have exposure to these concepts. Even in the ideal world, where Rust has all of the resources, I would still probably suggest learning Python first. Just to get the feel for logic, and to learn some terminology in a place where you can experiment more freely, before learning all the rules. Knowledge of many languages is good in general, so it won't be harmful to learn Python as well as Rust. With that said, if you do want to keep going with rust first, I'd check out https://rustbyexample.com/. It's nice, has lots of examples (thus the name).
I think I'd be really interested in using this. I see the list doesn't support modification at indexes. Would this be impossible?
The rust book is written for people who already know at least 1 programming language, and I'm guessing that for you, rust is your first language? In this case, I can understand how the book might be difficult, since it doesn't really introduce core concepts that found in most every other programming language (things like variables, values, immutability, keywords, etc.). I'm afraid I'm familiar with any really basic "what is programming" resources (but I bet they're out there!) I can't explain everything you had a question about, but I wanted to at least offer a few answers for you: &gt; like we dont know what keywords are (like nobody knows what that is, i mean are there 'keywords' in regular langugae?) The concept of a keyword is common in other programming languages, it's not from spoken languages. It means a word that has special meaning in the programming language. &gt; why it called 'foo' - like that seems like a random arrangement/set/sequence/[enter some other billion of related words] of letters, and it's extra confusion The name [`foo`](https://en.wikipedia.org/wiki/Foobar) is a common placeholder name in programming examples. Normally the name of a variable would reflect its purpose, or the data it stores. But in simple examples, there isn't necessary a purpose, and so the name `foo` is used. I have no idea where this name came from, though. &gt; again it just seems a whole lot clearer and better if they just said if immutable or mutable was better? One is not necessarily better than the other. It depends on the context. Chapter 3.1 tries to show some of the trade-offs. And finally, my personal favorite IDE for rust is IntelliJ with the [rust](https://intellij-rust.github.io) plugin (configured to run cargo check -- there is a setting to enable this in the IntelliJ settings panel) Good luck!
that's unfortunate, hopefully someone knows as that would be the first &amp; most important &amp; primary thing to find maybe even last thing, cos that's helpful would be able to give you a basis to continue learning 
Most programming material is not aimed at non-programmers. You learn to program just once, and then you learn new languages over and over. General language learning material usually targets the second case. If you want a book that's aimed at non-programmers you might have to look for beginners stuff using Python, Godot, RPG Maker, Scratch, or something else along those lines.
likely not, im sure (guessing) experienced ppl are specialsied and focused elsewhere in other things just have to wait for someone to know, do you or anyone know the most basic resource for python or anything to learn basics?
it's unclear which options are actually relevant to teaching the basics in a way that would actually enable you to learn and progress on a given topic, in this case programming i guess..., but hopefully someone knows 
I haven't tried the rust plugin for intellij but I have used rust in vscode and quite liked it.
I was really iffy on `...`, but would have never thought of `..=`. I like it.
`pub` on a field means: - you can take any possible valid `struct`, replace that field with any possible valid value (limited only by the rules of that type), and get another valid `struct`. "Valid" means whatever you choose it should mean, but if your implementation contains `unsafe`, watch out! 
Sorta apropos to your design decision: `pub` on a field means: - you can take any possible valid `struct`, replace that field with any possible valid value (limited only by the rules of that type), and get another valid `struct`. "Valid" means whatever you choose it should mean, but if your implementation contains `unsafe`, watch out! 
The appeal and advantages of Rust are not going to be easily understood by someone with no programming experience. As stated by other responses, I'd advice using a different language to learn the basics, as they'll have more resources available for complete beginners.
`RefCell` to the rescue: catching reentrancy bugs and preventing data races, stable since 1.0. Create a struct which contains `RefCell&lt;VeqDeque&lt;T&gt;&gt;` and implement `Iter` for it. If it panics or fails to compile you did it wrong. Note (if you do this) that you *cannot* return `item` as borrowed, only as cloned. This is correct and catches some nasty iterator invalidation bugs that lesser languages would make you suffer through silently. Also note when I say cloned, the cheap cloning of `Rc` is sufficient. 
Depends on what you want to do. Python lets you do general programming in a lot of fields. RPG Maker and Godot are much more specifically for making video games.
Unfortunately ``` (1, ..b) ``` is currently a valid syntax, it means a pair of `1`, and a range to `b`. So it cannot be (easily) used for tuple unfold.
The most important use of `..` is not iteration (which could be done with something like `range` function as in Python), but slice indexing: ``` &amp;vec[3..6] ``` Two dots here are the same as dots in for loop. This syntax you propose would look a little unusual here: ``` &amp;vec[3..&lt;6] ```
as also priorly asked and mentioned, just have to wait for someone to know, do you or anyone know the most basic learning resource for python or anything to learn basics? do you know?
It's *probably* possible to implement something like C# expression trees in rust using procedural macros. You'd have to transform some subset of rust into a bunch of calls building up a runtime ast, and then have an interpreter for that ast. This would have some of the advantages of c# style expressions, in that you could manipulate them at runtime and with some effort and restrictions even convert them to sql or something, but actually compiling them would be somewhere between horribly impractical and impossible. (If you've ever used react, this would be roughly analogous to how the react compiler turns your inline html into a bunch of react library calls)
I just want to point this out, since it may save you some time. It looks like you parsed the type `&amp;&lt;P as Key&gt;::Value` incorrectly: it's not `(&amp;&lt;P as Key&gt;)::Value` (`&amp;&lt;P as Key&gt;` doesn't actually make sense as a type). Rather, it is `&amp;(&lt;P as Key&gt;::Value)`, which, described in plain English, is an immutable reference to `P::Value`, where `P` is the type parameter which implements `Key`, and `P::Value` is the value type that `P` implements `Key` with. It looks like you're just running into some of the differences between Rust and the language that you're used to, C++. You'll get used to it... and while you're learning, I really recommend you sign into #rust-beginners on IRC, the people there are super nice and helpful and I was just lamenting the other day that there don't seem to be as many beginner questions as there used to be
I'm not sure if there's anything in [imageproc](http://docs.piston.rs/imageproc/imageproc/) specifically useful for this application, but it seems worth mentioning for computer vision in general.
I've always thought (not for Rust in particular) that `[0..5)` would be a good syntax for half-open ranges, borrowing the notation from math. Then `[0..5]` would be the inclusive range syntax.
I'll agree with everyone else here that Rust is not a good language to start with. A lot of the guarantees it provides, though they make the code easier to work with, makes it harder to write. This is why the book is more aimed towards learning Rust as a second language when you already understand the basic ideas behind programming, though some terminology you still have to just learn by seeing how it's used. If you have a bit of money to invest, [Learn Python the Hard Way](https://learnpythonthehardway.org) is a great learning tool (though, please, use the Python3 course, not Python2). "The hard way" refers to that the author gives you exercises to work through, encourages you to try it yourself, then guides you through the process of solving it, including the process of fixing the initial incorrect attempts. I haven't actually used it myself but I have some friends who have and strongly recommend it. If you don't want to invest any money (and that's fine; I didn't), [codecademy](https://www.codecademy.com) is what I used to initially learn the basics. It goes (sometimes excruciatingly) slow, and is therefore a good resource when you just start out. Learning to write computer programs is just as difficult and time consuming as learning a foreign conversational language, if not harder. You won't understand some terminology immediately, and will have to guess-and-check muddle your way through the beginning. You'll figure things out as you go. If you're a student, see if your school offers any classes or resources aimed at beginning programming, as that will be your best bet, with the availability of direct feedback. If you're a working adult, see if your employer would be willing to invest in you learning a new skill; learning programming is great for your logical thinking skills. See also r/learnprogramming for the resources they provide. PS: I'll let you in on a little secret: most of the industry still makes little mistakes when coding every single day. It's impossible to be perfect all the time. That's why we have our tools that tell us when we do something bad; we can iterate and fix things quickly and move on to the next thing. The truly fluent coder that can write correct code on the first try is a rarity of its own class. We may have good days, but we also have bad days. Don't despair if it's hard; it's hard for everyone. It's a whole new way of thinking.
There is multipart example https://github.com/actix/actix-web/tree/master/examples/multipart Here is section for streaming upload https://actix.github.io/actix-web/guide/qs_7.html#streaming-request
are you saying the basics are different in the diff options? im not sure if this is actually getting any closer to the answer of the question of the OP tho
&gt; with everyone else here could you look over what everyone else that commented said? it does not seem they actually said that, so could you check that out? 
The basics of how you build a program are different in each option i suggested, yes.
&gt;easier to work with, makes it harder to write i dont understand this, or what's the significant, it's very unclear to me and causes confusion 
that 'py hard way' source has been said by others, including on reddit to be very flawed also the py reddit itself has said that as well in addition to the flaws that others have said, im concern about if there's any clarifications i could make in regards to the main post? i dont feel that the importance or msg was relayed given that you recommended a source like that which overall ppl have said to be better than other sources that are 'below average' so that is to say it's better than other (most) sources i guess im not really sure but i feel/think there's a disconnect to the understanding of what an actually good learning for beginners actually is do you think that when you see the main post? or again, is there any clarifications i could make? 
Things like borrowing rules in Rust. In a language like Python, there's a concept called a Garbage Collector that handles lower-level details like tracking memory that your program uses. When you're done with it, the GC cleans up after you. You can have your thing used in multiple places without any worries because the runtime keeps everything working. In Rust, a name bound to some value has two ways of reaching that value: it can _own_ that value or it can be _borrow_ing that value from whomever owns it. When nobody owns a value anymore, it dies and no longer exists. Rust has a complicated system that runs at compile time to make sure that everything that you borrow lives at least as long as it is borrowed for. Additionally, Rust makes sure that only one person can be changing a value at one time.
sorry im sure you would understand that i dont understand anything you're saying since you're using technical terms and words i dont understand im sure you understand and realise that after reading the main post
Well in my hypothetical language, `0..5` by itself would be invalid syntax, you'd need some brackets to specify what kind of range you want. Matched brackets are much nicer for current editors I agree, but if you push boundaries you're always going to break something
im also sure you're aware that any kind of good communication would show things in a way that is familiar to the listener tho im not sure what your experiences are, tho im guessing you're aware of that 
I'll defer to others' opinions on Py the hard way then. As I said, I haven't used it, but rather recommended it on a friend's experience. Everyone learns differently, so what works for one person won't help someone else. Teaching programming is _a hard problem_. It's best done in an interactive fashion, which _cannot_ be achieved in any currently existing medium other than face-to-face contact. Adding to that, most people in the position to try were largely self-taught, so tend towards providing information and expecting people to look up and/or figure out what they don't understand on their own effort.
im also guessing that you're aware that when something is introduced we always introduce them in a way that is familiar and understandable first to the listener and then we could elaborate more none of which ever needs or requires terminology, not even once this is a very basic lesson of good communication/teaching and if i hadn't gotten this understanding across to you in this comment and all previous comments, then i haven't done a good job
&gt; bound to some value but maybe im mistaken from the viewpoint of someone experienced on this topic, maybe it's very hard to see or understand how nobody would understand what you mean by &gt;bound to some value
I've been using IntelliJ with the Rust plugin which is officially supported by JetBrains. It gets regular updates and I hope it eventually evolves into a separate IDE.
I'm paraphrasing, but it seems that every top-level comment does indeed have some form of "Rust isn't the easiest place to start"?
the question in the OP is about the basics of what you need to know to understand the basics things that was needed to know in the context of the OP not sure if that's any significant diff than what you are relaying it would seem based on what others said that the basics of programming are the same across programming 
Oh, yes, sorry. The basics of programming in general are largely the same across the major languages.
There is room for some kind of Learn Rust The Hard Way book that just goes through with repetitive simple examples and problems for new programmers, but I don't think it exists yet.
Yes. /u/nixos_learner, as https://doc.rust-lang.org/book/second-edition/ says: &gt; This book is written for a reader who already knows how to program in at least one programming language. After reading this book, you should be comfortable writing Rust programs. We’ll be learning Rust through small, focused examples that build on each other to demonstrate how to use various features of Rust as well as how they work behind the scenes. It's not really intended to teach you programming. There aren't any great "learn programming via Rust" resources out there right now, to be honest.
Something I only thought about just now... is a range literal even necessary? I rarely use ranges, but I'm guessing there are domains where they show up a lot more frequently.
Docs for language features land after the feature, that is, the PRs get opened, then the feature lands as stable, then the docs PR is merged. So they won't appear for another day. That said, this feature is very simple: https://play.rust-lang.org/?gist=d23ff83a40929f737f03ad1b178e07b0&amp;version=nightly
Having looked at your Reddit history, I can see that you've been bouncing around between languages like Rust, Kotlin, and Typescript, and I think it's really worth saying: don't worry about picking the "wrong language". Once you've learnt one language it will be far, far easier to learn another. You'll also gain tons of experience, leaving you far more informed and better able to make the decision of which language you prefer to use. I would echo what other people have said, that Rust is quite complex as languages go and so one I'd recommend as a first language. Myself I started with Python and it taught me a lot without throwing so many concepts on me right from the start like Rust. Don't worry about it being 'dynamically typed', people have a lot to say about static type systems being better, but just know that lots of people and companies use Python and get a lot done with it, so flawed or not it wouldn't be a mistake to learn. It's worth noting that there isn't a perfect language out there; a good quote by the creator of C++ is "There are only two kinds of languages: the ones people complain about and the ones nobody uses."
The book is aimed at people who already know how to program, period. You don’t, that is fine. What you need to do is learn how to program first. /u/steveklabnik there are now a days excellent online resources to learn how to program, for example, these are great resources for people with no programming experience * MIT OCW introduction to computer science * Stanford CS101: Introduction to CS One is Python based and the other JavaScript based but the language is pretty much irrelevant because they focus on teaching people how to solve problems using a computer and programming in general. Maybe there is a good SO question about these courses that we could link to. There are many others like MIT structure and interpretation of computer programs but those two courses above do a really Great job.
As an Integrated Development Environment for learning, I just remembered about [PyCharm Edu](https://www.jetbrains.com/pycharm-edu/)! This is an "Easy and Professional Tool to Learn &amp; Teach Programming with Python". &gt; Enjoy an easy interactive way of learning Python while programming. &gt; &gt; Get instant feedback and quick results using an intelligent development tool. Keep it up! &gt; PyCharm Edu detects code problems and errors on the fly, as you go, and makes valuable suggestions based on its deep understanding of Python code. Thanks to this instant feedback, you can save time and effort both with learning and teaching. This seems to be what you're looking for. Once you're familiar with how to write code and the concepts involved it will be easier to pick up the terminology used to talk about code than before. ---- I am not affiliated with JetBrains, though I have contributed to some of their open-source libraries, and use their products. I hold a free student license to their paid offerings, but PyCharm Edu is and always be free to use.
Personally, I just can't get used to this alien syntax. I don't believe that mistyping is such an important problem that you have to mess up readability. The more I think about it, I think the next best thing to do would have been to do nothing about it. * You nearly never use `a..b` in pattern and it always can be replaced by `a...b-1`. * For the range syntax there can be a lot of alternative s like `(a..b).inclusive()` or RangeArgument
I've always liked the notation with reversed brackets more (so `[0..5[`), probably because that's what we used in school.
Thanks for the feedback! Will take care of it. :)
As with many other projects, the initial idea included dwelving into many different areas. Somehow it felt natural to stop after explaining recursive resolve, though. I did do various types of stressing on the Hermes DNS server on which I based the guide, and it will probably stand up to many obvious means of attack. It’s no djbdns, though, and it’s definitely open to cache poisoning attacks. There are some heuristics that can be used to defend against poisoning, and there’s DNSSEC. Next time I work on it, that’s where I’m likely to pick it up. If there’s enough interest I might also write about it.
Slice indexing is literally just a range of valid indices you want to be transfer like a copy without the copying. Doing &amp;vec[3..6] would also bring it more inline with popular HDLs like System Verilog, VHDL Clash. 
I don't like seeing = used this way since it's a pretty distinct symbol and makes it easy to separate assignments out from the rest of the code. However, maybe this will get better with time.
Better copy the source file (if needed) and swap it there before porting to Rust. Then you can validate your code when you are only partially done and also use ranges that were not used in the original source file.
I still like the idea of a const marker akin to send and sync
I've heared good things about [learn python the hard way] (https://learnpythonthehardway.org/book/preface.html). 
nope can confirm that that link is definitely not for beginners * a beginner by 1) definiation and 2) common understanding of the word is a person that knows nothing about a given topic * i also googled it right now: *a person just starting to learn a skill or take part in an activity* - &gt;Rust is a modern **systems programming** language focusing on **safety, speed,** and **concurrency**. It accomplishes these goals by being **memory safe** without using **garbage collection.** the link already threw all these unneeded &amp; bad for learning terminology at you that you (likely?) didnt need to know to actually do programming on https://rustbyexample.com/hello.html &gt; 'source code' * nobody would know what that is, and there's not everyday life examples that most would be familiar with on https://rustbyexample.com/primitives.html * it doesn't show or explain what it does, it doesn't show the big picture or anything, it doesnt introduce the idea/concept * it just introduces the term/word and that equates to zero understanding, it's not actually teaching anything (at least for beginners) 
&gt; likely not I've found experienced people always learn at least 3-4 programming languages, even if it gives nothing but the experience. Knowing one programming language is a good start, but in order to _be experienced_, you need to experience a variety. Most rust programmers know at least one of C, Java, Python, Ruby, JavaScript, or another language. You can definitely specialize in one language, but it won't be effective unless you know _what makes that language special_. Context from knowing other languages is how you get that perspective, and how you usually choose what to focus in on in the first place! -- As for learning: - https://learnpythonthehardway.org/python3/intro.html. - https://www.khanacademy.org/computing/computer-programming These two are my two best suggestions. They're very different - the second one is even in a different programming language, but they're both very good. I would recommend trying both, and going as far as you can with whichever one sticks better. P.S. it's called "learn python the hard way", but that's more branding than anything else. Both Khan videos and it are nice ways to start, and even if it's "hard", it's built for beginners.
&gt; Rust is a modern systems programming language focusing on safety, speed, and concurrency. It accomplishes these goals by being memory safe without using garbage collection. &gt; &gt; the link already threw all these unneeded &amp; bad for learning terminology at you that you (likely?) didnt need to know to actually do programming Really? Speed is too technical?
Fantastic!
If you're wanting to benchmark on cloud instances, I think SSDNodes and Vultr had pretty good disk I/O last I checked. Vultr also has a comparison against Amazon and other providers where it also shows how well it fairs, not sure if that is still the case these days or if Amazon is offering better/faster disk options. The perf of DataFusion looks really impressive. You mentioned that Spark performs best on larger datasets than you were benchmarking? Will you be comparing DataFusion with a larger dataset in future?
As you are a newcomer to programming it is essential that you come in with an attitude to learn, not an attitude of ‘this is outside of my scope so I shall complain’. You are learning; you are necessarily going to be immersed in things you don’t know. All your issues would have been solved if you spent a few hours searching and gaining intuition for the terms. That’s right, learning takes time. IMO, graphics programming is the best introduction to programming there is. I think this because I did this. I’d recommend LazyFoo’s SDL tutorials, and the sites open.gl and learnopengl.com. Those are in C++ because Rust is not so widespread as of yet; this will change in due time.
not a single person had a direct response/answer to the question in the main post besides this one person: https://www.reddit.com/r/rust/comments/84sa9l/is_there_currently_a_main_ide_for_rust_went_over/dvs235q/ it's unclear how the random reddit users are voting tho, probably based on bias
There's a line in the first tutorial that tries to test for whether the top two bits of the length byte are both 1s (as I understand it). if (len &amp; 0xC0) &gt; 0 { Shouldn't this be if (len &amp; 0xC0) == 0xC0 { I wasn't at at all clear what happens if one but not both of those bits are set…
i think edit2 is a good answer for this subquestion that came up 
hmm yea ill look for a good learning source, it's not the kind/type of question that appears to be sufficiently good to ask on reddit at least not sure if the knowledge that 'py hard way' is discouraged even by the reddit sub and that's openly said on their sub page as well it's said to be better than most learning resources for py, and it being better than most says a whole lot about everything else but the top 10% or 5% not relatively near the top 1% of quality out there (for learning resources or anything else across the topics in this universe)
you also appear to be replying to the OP in a way that completley ignore the points of the OP that others and other replies did not do 
well this was a positively upvoted comment (so im not allow to speak or something on reddit?) then all of the sudden randomly a few reddit users out of 800+ views downvotes it, interesting
I use it a lot in small programs quickly hacked together. Usually it's to power an iterator. 
ok thx for input however still need the recommended learning source for beginners, which the main question of the OP are you able to provide the resource so i may leave?
no need for this, i already had went to look for a good py learning source ill look back on this in the future i guess
I just found something: http://craftinginterpreters.com/representing-code.html ``` String className = type.split(":")[0].trim(); String fields = type.split(":")[1].trim(); ``` Why split it twice? I think it would be better to cache the split result as "splitted" and then access with index.
now that is a good comment you see and yet why didn't you get lots of upvotes (obviosly cos of the biases of others and ppl, at least those that knows rust, arent actually reading the commments)
thx
I don't know about this article's version of it, but the C++ core guidelines has a [section about the semantics of all of the different kind of pointers (owning, non-owning, etc)](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#S-resource), and an automated checked that goes alongside it. Herb Sutter did [a talk about it at CppCon 2016](https://www.youtube.com/watch?v=JfmTagWcqoE) and there were several other videos about the core guidelines as well that I can't seem to find. Although, I would say that the linked talk actually is beneficial for Rust developers because it addresses a lot of the kind of problems that people might encounter dealing with ownership in Rust as well. Although Rust lifetimes make some of the things a bit easier than what you have to do in c++.
/r/learnpython is the place to go, and their sidebar has [some good resources](https://www.reddit.com/r/learnpython/wiki/index), going by that, [this looks like a good tutorial](http://introtopython.org/) :)
What parts do you want to run on a gpu? https://arrayfire.com/ and https://github.com/spearow/coaster are just two options. But do give it some thought before you start. There are no const generics. But this shouldn't be a hard stopper. Computer vision is still a relatively new field for rust. But i think rust is mature enough. If had to build this, i might just pick rust and build bindings to the C++ libraries. At the end of the day the question depends less on rust and more on * scope of the project * available time * your skills and experience * skills and experience of collaborates 
your reply was better than others ones: * you actually answered the question * your comment was actually relevant to one of the topic of the OP -- the book tho honestly i dont think you understand what a good learning source is, and that was pretty much cleared up in the OP 
Maybe it messes up aesthetics, but I don't see how `..=` would mess up readability.
this is a trivial subtopic/talk and i could go through all the top level comemnts at the point/time of the comment you &amp; I made, but here's one of many examples of how that is a clearly wrong and incorrect statement (and for that reasons is why i had pointed it out): https://www.reddit.com/r/rust/comments/84sa9l/is_there_currently_a_main_ide_for_rust_went_over/dvs0x7i/
Okay, so when site 1 adds a new head element to the list and it receives the op from site 2 which removes the head element, the structure tracks that the op from site 2 is *actually* removing the element at index 1 now, because that's the old head but just moved to a new index?
you know there's been more than one 'good recommendation' on this post (and im sure many others) of things ppl never even personally used, or used recently within the last 1 year timeframe it's reddit, but im quite annoyed at how ppl would randomly do that i personally would never recommend anything i didnt know for sure abosutley was good based on what the OP said and i have done so once in my life thus far but some ppl value quality more than others, so what more is there to say
The new syntax is usable in more places than the old: `...` was only stable in patterns, while there was no way to express e.g. the full range of `u8` in a for loop (which is now `for i in 0..=255`).
&gt; only so many ways to express an idea yea im well aware of the fundamental problem &amp; limits of lang
&gt; You nearly never use a..b in pattern and it always can be replaced by a...b-1. This isn't true. For example, if you want a range that goes up to the maximum number of a type, say, u8, you can't say "u8 max + 1" and have it typecheck. You have to use a larger size and then cast, which is not great.
the main post already said some of the many ways that are actually good none of the responses had directly replied to the OP in the way that was asked
&gt;ask for clarification on what exactly you don't understand? well i guess that's why you had responsed a few of the confusing things mentioend in the OP after it was realised i had done the things you are mentinoing after-the-fact and yet somehow this false part of your comment gets 8 upvotes, interesting? i'd say so 
&gt; explain the disconnect i believe the disconnect clearly shown at this point with various evidence i've given: &gt;the main post already said some of the many ways that are actually good https://www.reddit.com/r/rust/comments/84sa9l/is_there_currently_a_main_ide_for_rust_went_over/dvsdw7c/ &gt;ask for clarification on what exactly you don't understand? well i guess that's why you had responsed to a few of the various confusing things mentioend in the OP after it was realised i had long already done the things you are mentinoing currently after-the-fact https://www.reddit.com/r/rust/comments/84sa9l/is_there_currently_a_main_ide_for_rust_went_over/dvsdxrr/ 
&gt; /u/steveklabnik there are now a days excellent online resources to learn how to program, Oh there certainly are. I've even worked on some of them. What there aren't are those *in Rust*.
&gt;basic building blocks that you understand? i had stated that it was everyday life, things that most everyone would already be familiar with so for example you use 'box' and 'x' why not use 'bag' and 'milk' ? the vast majority actually would understand 'bag' and 'milk' analogy instead of some abstract word (not even, it's a letter) like 'x' 
These two cases describe different types of labels, one is undefined and the other de facto unused. Either should result in an error. Annoyingly, parsing domain names is still more tricky. For one, using a simple string conversion will produce the wrong result if a label contains a dot – which may for instance happen in the way e-mail addresses are encoded in SOA records. Worse, the code doesn’t protect against infinite recursion. A name akin to `b"\x03www\xC0\x00"` will eat up all available memory. Since the RFC limits domain names to 255 octets, you could protect against that by checking the length of the produced name and bailing out. But, and I only realized that when building test cases for my own code the other day, `b"\xC0\x00"` or something a little more subtle like `b"\xC0\x02\xC0\x00"` will still loop indefinitely. The simplest way to protect against all of this is to count the number of jumps and stop at some point. 128 seems to be a good choice since that is the maximum number of labels in an uncompressed name. After several rewrites, I ended up with [this code](https://github.com/partim/domain/blob/bytes-for-slices/src/bits/name/parsed.rs#L190) – and hope this really is robust now.
&gt; where needed. yea 'where needed.' and you dont need the terms to understand any of those things if the learning source is done properly and well **example:** you dont need to know surgery terms to see if a leg is missing from someone **and there's a billion other examples across the topics** on this basic lesson that you dont need technical terms 
'Do you understand what problems it solves? Do you have those problems? Or would learning programming be sufficent for you?' its well know and apparent from the context of the OP that no beginners would know this and it's when there's a good answer that the basics like that are mentioned if the answer was attempting (and achieving in this case) to be helpful
Is using nightly "bad"? I wanted to make use of attribute procedural macros and seems that its not stable yet, is nightly an unstable broken piece of stuff, or are the nightly features not quite there yet?
or if you just dont ask reddit you're saying basiclaly
as for 'graphics programming' if there's good relaible sources with a 4.8+/5 ratings from 1k reviews minimum that vouches for this claim/idea, i'd be happy to look into tit
have you not taken physics ever? or some engineering? humanities major perhaps?
basically there should be significnt evidence to support any claims or opinions part of scientific method yea? but everyone knows basic things like that by now it's 2018 after all
Good catch. I have an habit of doing it like that because it works for checking whether a single bit is set. Apparently I never considered how it can fail when checking for two bits...
Oh shoot. Never thought about cycles... In practice, do servers actually encode multiple jumps? The spec seems to allow for it, but in practice I haven’t seen anything other than a jump to an earlier occurance of a common tail. Anyway. Thanks for pointing it out!
i like that answer, first person and comment to make it thx &amp; enjoy =)
Another option to counting jumps is to track the earliest start of a (plain) label sequence. Just to emphasis the importance of what you've said: if names aren't limited and pointers aren't tracked, it's pretty trivial to get a 10x or more amplification in response to a query.
[Same docs in a more navigable form](https://google.github.io/xi-editor/docs/rope_science_00.html).
Adopting the Arrow and Parquet formats is 100% the correct approach here, IMO.
Depending on the algorithm used for determining compression, multiple jumps might happen in complex responses. Perhaps something with CNAMEs. But more realistically, a malicious client could use recursion in the question and blow up an unexpecting server.
There is #rust-machine-learning on mozilla's IRC server. Not very active, but a few regulars in there.
I’m probably just slow this morning, but could you elaborate on the "track earliest start" suggestion?
&gt; You nearly never use a..b in pattern and it always can be replaced by a...b-1. Not *always*. You can't replace `0..size` with `0...size-1`; that would overflow when `size` is 0.
Hello! My name is Ilya, I'm Rust developer from ruRust community and I'm working mostly on gamedev libraries in Rust. Your plans are great! I can't wait to try to use your project in my student work :wink: But I have a few remarks. First of all, didn't you look at `three-rs` project? It's small but quite powerful 3d game engine written entirely in Rust with `gfx` and `cgmath`. As one of the maintainers, I promise to help you with your project-specific issues, like cloud rendering. Second remark is about `nalgebra` as math library. I'm afraid `nalgebra` is too abstract tool, I think `cgmath` would be more practical choice for you.
I've been working on building agent-based simulations using reinforcement learning. The only libraries I use are nalgebra, rand, xorshift, and rayon. I'm not doing deep learning or using GPUs, so I haven't really missed dedicated ML libraries like tensorflow. nalgebra (and ndarray) are sufficient for all of my linear algebra needs, but neither are very ergonomic. So for me, the biggest missing piece is an interface that makes commonly used numerical operations more easy to use (e.g., sorting of f64, argmax, nicer scalar and component-wise operations, using structs with named fields as arrays). Type level integers would also be nice.
Hi Ilya, `three-rs` does look very interesting for the visualization part! I didn't know about it, very new here. Regarding `nalgebra` being abstract, it's actually not that much of a problem. I do need few generic linear algebra concepts. In particular SVD and Choleski decompositions of matrices at least. How good is the interop story between `cgmath` and others like `nalgebra` and `rust-ndarray`?
I'm excited to hear about something like this! Caching, partitioning, and query optimization are going to be very interesting - and tough - problems to build out here.
The Core Guidelines are awesome, but they don't cover all of Rust's guarantees; data race prevention was a non-goal last I checked, for example.
I read "thunk lifetime elision" as lifetime elision for closures and was confused for a moment.
/r/playrust
I know this is very unrelated to the post, but since I saw this reply I have been wondering. What is the best way to find the fraction with the smallest denominator that rounds to a specific decimal number? Ie in you axample 15/19 is the fraction with the lowest denominator that rounds to 0.789. I was able to solve it with a brute-force approach, but it is a very slow approach especially with very small numbers (ie. 0.00000000000000001). I though about using a continued fraction approach but I don't know if that would solve it. Does any one have an example?
Who posts to a sub without reading it? Besides boots, I mean.
Yea, but you don't need special syntax for that. If `Range` and friends were tuple structs, you could just write `for i in Range(0, 10)` instead of `for i in 0..10`. Technically you can do that with the way they are now, but it's much more cumbersome to write `for i in (Range { start: 0, end: 10 })`, and in this case the clarity of named fields is unnecessary.
Oh well, I don't know much about using `nalgebra` along with `cgmath`, but interop process might be not the easiest one. Fortunately, `three-rs` uses `mint` library for math abstractions, so you can use any math library as long as its types are convertable into `mint` types.
Thanks for the suggestion! Sadly, the compiler can't infer the type.
You could also do that with +, -, × and /. Just like there is an Add, Sub, Mul and Div trait, there is a Range structure. Those who prefer to type it out completely can. 
Also - doesn't look like there are arrow or parquet crates? That's interesting. Definitely a big (data) hole.
&gt;trying to solve the problem by carefully following a bunch of rules is not interesting to me... But that's exactly Rust. The only differences I see is that the rules are automatically checked and a bit less restrictive. (Rust allows you to return naked pointers for one.)
I'm currently planning on using this Rust implementation of Arrow. It isn't published as a crate yet. https://github.com/jihoonson/iron-arrow
That's awesome. This might be the most efficient way of storing chess games possible.
How come ops need to be executed in order? I thought the C in CRDT stands for "commutative", if implemented via operations?
In VHDL the ranges are inclusive as in `v(5 downto 3)`; for the lowest eight bits that would be `v(7 downto 0)`, and with generic sizes the code will be littered with “`- 1`”s, as in `v(width - 1 downto 0)`.
If i do a nightly crate do everything depending on it need to be nightly?
If anyone ever wants to see a *legendary* amount of bikeshedding, yak-shaving, and all the other bits that go into the sausage of language design, check out the discussion threads for this syntax. :-P
I'm surprised at how small that crate is. I would have expected arrow's implementation to be similar in scope to parquet, which looks somewhat hefty. Perhaps I misunderstood that.
Yeah, that would be a little more efficient. This code is just in an offline script that's only run periodically, so I figured I'd keep the code as simple as possible.
I’m not a downvoter, but it’s possible that others have noticed that you’re putting a lot of effort into judging the quality of the responses you get. Even the praise you give in this comment seems like a back-handed way of casting aspersions on other replies. A little genuine gratitude — even for replies that don’t hit the nail on the head — can go a long way. 
Neither my Debian workstation nor my Ubuntu laptop work currently, but hey I have high hopes both of them will update to Mesa 18 in not too long. Thanks anyway, can't wait to play with it.
This is a really catchy way to entice potential Rust programmers into getting into Rust. The way you edit the video gives a pace that viewers can still follow (it's fast but manageable) yet not boring enough (like most 30min tuts). And it hooks people who... uhhh... speaks in *meme*. I'm eager for another one of your videos. Nice.
I upvoted your post for providing feedback on our documentation and learning resources. Thanks for that! However, you seem to be pretty new to both Reddit and programming in general, so here's some things to think about: 1. There's no requirement for writing your posts with correct spelling, grammar, and punctuation, **but it helps**. Your initial post is difficult to read because there are almost no proper sentences except for questions. The entire post and most of your replies as well seem to be almost "stream of thought" style writing which is quite difficult for readers to understand. Consider spending more time formulating your posts. Higher quality posts tend to attract higher quality answers and vice versa. 1. Meta-commentary on your own posts tends to get downvoted. This is a general rule of thumb across Reddit. Nobody wants to read about how you think you shouldn't be getting downvoted or your posts are being "censored". It's off topic and it doesn't add anything to the original conversation, so without fail it's going to get downvoted. 3. You seem to have a pretty strong reaction to new vocabulary. If you've ever learned a foreign language before, you'll know that the very first thing they teach you is a bunch of vocabulary. Most of the terminology you list in your initial post is easily googleable and will take you to learning resources geared toward new programmers. You will not find one single book that answers every single one of your questions exactly the way you want. You need to be willing to find the answers to your questions by doing some research. Being able to find the answers to questions on Google is perhaps the most important skill to being a successful programmer. 4. As a beginner, you actually have the least experience in knowing what is or isn't important to learn about programming. Simply because you think "much of the info (and wordings) is not actually needed" doesn't make that true! Find a resource that is designed to teach programming basics and follow that. As /u/OptimisticLockExcept said, https://automatetheboringstuff.com/ might be a good fit for you. CodeAcademy's Javascript course might also be work better for you https://www.codecademy.com/learn/learn-javascript
Parquet has compression and many other features, to make more efficient use of disk space &amp; bandwidth. Arrow is an in-memory format, and so is kept purposefully simple, so vectorized code that operates on Arrow memory buffers can be written. So given that, not too surprising.
As someone who writes a lot of SLAM code and is a really big fan of rust, I would probably suggest sticking with C++ for now. As you've observed, some of the low level primitives for image processing are there but there really isn't any of the higher level infrastructure or libraries that make life a lot easier. Long term that's something that I'm interested in changing, but right now you'll be stuck re-implementing a lot of basic functionality on your own, which can be fun but also very frustrating.
Arrow is basically just a set of arrays. Parquet has lots of advanced encoding schemes. Source: I've effectively worked on both, and implemented part of arrow for a project at work.
a couple of things. `use entity::*;` is looking for either `src/entity.rs` or `src/entity/mod.rs`. Neither of these exist. Paths are "absolute", relative to the crate root, not relative to the current file. I believe that the `self::` notation you're using elsewhere makes it relative to the current file, but I've never actually noticed anyone using that syntax before, so I'm not sure. Most people just use absolute paths. Then if you move files around and restructure your code, it's less hassle. Inside several of your files, you're redeclaring modules, which isn't right. For example, in `src/game/mod.rs`, you declare `pub mod map;`. Then in `src/game/map/mod.rs`, you declare `mod map;`. Is there really a `map.rs` file in the `src/game/` directory and the `/src/game/map/` directory? I doubt it. You just need say `use game::map;` to import it from `src/game/mod.rs` where it was `pub mod`-ed. I recommend reading [this chapter.](https://doc.rust-lang.org/book/second-edition/ch07-00-modules.html) There might be some other stuff going on, but that's a starting place.
Is there somewhere a comparison of http frameworks that also describe their threading and blocking model? I'm interested in trying out an http service that's using non-blocking I/O with multiple worker threads for the handlers code, where handler workers are the same as I/O workers, i.e. my service would spawn say 4 threads in total, and they will both process I/O and the business-level request handling code.
I renamed a few things to making what I'm doing a bit clearer.
I find lot of CppCon talks interesting from a C programmer perspective (in C land there seems not much going on these days - like everything was already said) and wannabe Rust programmer. They often touch low level things, e.g. performance - and many of us live in the world of CPU caches, this is not C++ specific.
`&gt;.&lt;`, lol
I've always thought that syntax is ugly, but more importantly, it's basically impossible to parse. Say you want a range from `a[0]` to `a[1]`: `[a[0]..a[1][`. Which ones are closing brackets? At least with `[0..5)` you can always match the brackets easily.
Range syntax is necessary for pattern matching, and without something like active patterns it's pretty much the only option.
Paths are resolved from the root of the crate by default, not relatively. So, `use game::entity` should work or you can explicitly make it relative with `use self::entity`.
Wait, that's backwards. GP is a bit confusing but seems like they are suggesting removing *exclusive* range syntax and having only inclusive? I suppose that would work (stability and iteration performance issues aside). Indeed, it's true you "nearly never" use exclusive ranges in patterns because there's no stable syntax for that! 
Have you taken a look at http://www.arewewebyet.org/? Might be a good place to start.
It's not rustup itself that's the problem. It's available freely in the repository. It's the curl dependency of bootimage and xargo that's annoying since they require that I specify the SSL library manually since pkgconfig isn't included in the search path by default. It can be dealt with, but it's still more annoying than I'd like.
This is fair! I tried to address it, but I don't know everything about Rust. If there's anything I didn't address that also wasn't addressed my anyone else, I can try and fix that. My main focus in writing the reply I had was in letting you know Rust isn't necessarily the best first language - but I may have misinterpreted things you've said.
That's good to know about py the hard way! I haven't been a large part of the community, and I guess I'm running on outdated knowledge. If there are better tutorials you've found, I'd go for that. Py the hard way is just the only resource I've had someone recommend to me, so I was forwarding that.
I believe you are looking for Rust’s macro system: https://doc.rust-lang.org/book/first-edition/macros.html
At a first glance that seems possible but I don't know of a library that does it yet. You can certainly create a grammar of expressions by overloading the arithmetic operations. You might need a procedural macro to handle some of the type conversion because overloading is not as flexible as in C.
Likely just pointing out that they are about to start development of their fork.
Macros would give you similar compile time functionality. As for runtime, you could do similar constructs from scratch in Rust very easily (as with any language), but I think .NET can also compile expression trees into efficient machine code, whereas with Rust you would have to just walk the tree and interpret it which is much slower. (unless you built a runtime compiler from scratch but that is a big job!) 
I couldn't find the blog post I was thinking of, but here's a similar one where the idea of using macros to transform an expression at compile-time is discussed in enough detail to (I think) get you started: https://danielkeep.github.io/quick-intro-to-macros.html
That's still unambiguous (but admittedly not that readable). I think neither of the two syntaxes is well suited for programming languages (for example with your syntax you can get some confusing situations when you use an array of literal ranges as the first or last parameter)
Awesome, thanks!
I had never heard of Vultr but just checked out their offerings and was impressed. Do you have any experience using them? 
Where should i look? I do not expect to make something significant since i have never worked on a compiler, but i would like to poke around during the weekend.
Could you post your code? It's really hard to help you with what essentially boils down to debugging without your source...
For writing shaders in Rust you may be interested in [rlsl](https://maikklein.github.io/rlsl-milestone-1/)
sounds like a fundamental problem with humans then
sounds like biases with humans
why dont i have that problem (i dont downvote ever for example unless im a hater) guess there's a those few that are haters
some isnt 'few' btw it's only the few doing it
there was very little to be grateful for in this thread very very very very very few actually had anything good to say very very very very very few very very very very very few actually had answers to the questions asked
ppl need to face the facts and i stated the facts and a few ppl are very biased so that's how it is, it's their problem
If the operation changes based on optimization level, you're probably hitting undefined behavior somewhere. Take a look at anywhere you're dealing with raw pointers. It's possible that the compiler is optimizing out setting the register that controls the LED, since there's no visible side effect.
have you not taken physics ever? or some engineering? humanities major perhaps? theatre? quite the comedy yea?
&gt;My main focus in writing the reply I had was in letting you know Rust isn't necessarily the best first language ok well i can let you know that this would've been a very helpful response, and that's one of the few helpful that would've helpful to be said as you could see first-hand, there was not much if any indication of the helpful thing of what you were trying to say, &gt; It's definitely possible to learn from the book, but you're right, there's a lot of terminology. 
Is there some way to tag a line as "Don't fuck with this. It has side effects, I promise!"?
&gt; wasn't addressed my anyone else, only like a few (2 or so) comments out of ppl that like to make random comments had actually said anything that actually showed they read or had a basic understanding of the main post in the OP you had made that indication 'there's a lot of terminology' tho the OP had talked about more than just this
yep you're likely accurate in what is said lots of outdated and near-valueless comments on this thread, and very few parts of comments that were good **basic takeaway: do things yourself, cant relay on ppl (but in the general case you still have to ask cos you never know if you'll get luckily)** in this case, no luck the very very few ppl that actually knew the answers didnt said it basically or simply didnt see the question
(Down vote on Reddit has a very specific meaning: this content does not contribute to discussion. If a post gets downvoted, that means people believe that it does not as anything.)
like i never once provided outdated info to anyone and if it was on the basis of outdated info, i'd would've made a responsible indication of the outdatedness clearly the vast majority of ppl in society including this site are pretty careless and i already know that from experience 
no need for this, i already had went to look for a good py learning source ill look back on this in the future i guess
if this response of was made earlier on (since it was one of the few that actually directly responded to the post of the OP then i would've been much more receptive at this point im far past being very upset &amp; annoyed at the insane amount of inaccurate statements and random comments thrown around
as for 'graphics programming' if there's good relaible sources with a 4.8+/5 ratings from 1k reviews minimum that vouches for this claim/idea, i'd be happy to look into it
or if you just dont ask reddit you're saying basiclaly cos all they seem to do is complain with non-answers =)
basically there should be significnt evidence to support any claims or opinions * part of scientific method yea? * but everyone knows basic things like that by now * it's 2018 after all
Amazon has the [I3 instances](https://aws.amazon.com/blogs/aws/now-available-i3-instances-for-demanding-io-intensive-applications/) which are running NVMe ssds. Not sure if they're more cost effective though.
Ops *from a given site* must be executed in order. If site 1 generates ops `a` and `b`, and site 2 generates ops `c` and `d`, then you can execute in any order so long as `a`is executed before `b` and `c` is executed before `d`. Ops from a given site must be executed in order to avoid remove-before-insert errors. For example, take a `List` CRDT. If op `a` inserts an element and op `b` deletes that same element, executing in-order results in a noop but executing out-of-order results in an insertion. In practice, in-order execution of ops from a given site is a fairly easy constraint to satisfy. If you send ops as they are generated, you can guarantee in-order delivery by using any protocol that sits atop TCP (HTTP, WebSockets, SMTP, XMPP, etc.). If a site is temporarily offline, simply append ops to a vec as they're generated, and then send the vec once you come back online. State-based replication (which Ditto CRDTs also support via the `merge` function) does not have any ordering constraints, but it is also less efficient in most cases.
Knocking out [blockers to the stabilization of proc macros](https://github.com/rust-lang/rust/issues/38356). I'm willing to mentor anyone that's interested in working on this part of the compiler. Hit me up here or mention me (@abonander) on an issue you'd like to tackle.
All Ditto ops are idempotent. Once an op has been executed, re-executing that op has no additional effect. If you experience otherwise, it's a bug.
It's bound functions to create it for you (combined the two blocks): https://github.com/FreeMasen/wiringpi-rs/blob/fe810d482de34e1b85ba924ba926c7e601901660/src/bindings.rs#L207-L215 extern "C" { pub fn wiringPiFindNode(pin: ::std::os::raw::c_int) -&gt; *mut wiringPiNodeStruct; pub fn wiringPiNewNode(pinBase: ::std::os::raw::c_int, numPins: ::std::os::raw::c_int) -&gt; *mut wiringPiNodeStruct; } There's also this: extern "C" { #[link_name = "wiringPiNodes"] pub static mut wiringPiNodes: *mut wiringPiNodeStruct; } Which it looks like you can iterate if you need to: https://github.com/hamishcunningham/wiringpi/blob/master/gpio/readall.c#L56
Was it mine? http://words.steveklabnik.com/an-overview-of-macros-in-rust
read_volatile/write_volitile, possibly?
issue has been resolved! https://github.com/servo/servo/issues/20239#issuecomment-373800913
SSDNodes says their prices are going to "expire" in a few hours. That's a pushy (almost scammy-feeling) kind of marketing that makes me uncomfortable. Do they actually change on a daily basis?
"block" is kind of a vague term here. What it means is that it should not sleep while waiting for something to happen or spend a significant amount of time performing computation. Creating a short random string is likely not going to block for any significant timescale unless you're reading directly from `/dev/random` which can block if it needs to collect more entropy. If you're using `ThreadRng` or `OsRng` from the `rand` crate, that uses `/dev/urandom` which never blocks by design.
What is the best way to store a list of functions / closures? I have to store a list of predicates with signarture `&amp;T -&gt; bool`. Currently I use struct Foo&lt;'a, T&gt; { predicates: Vec&lt;Box&lt;Fn(&amp;T) -&gt; bool + 'a&gt;&gt; } By 'best' i mean the way that is most flexible, e.g. allows user to pass functions, closures etc. For example without adding lifetime `'a`, everything inside passed function/closure has to be `'static` (if I understand it correctly). And without box... well, I was not able to create example without box, but I would love to see one. Playground: https://play.rust-lang.org/?gist=f85e2b751fea0901b9ddba380ab1b318&amp;version=stable
&gt; Amazon, Google and Azure all have offers to try their services I think if you're new to any of them. Amazon has free 1 year tier for a small instance, Azure and Google I think offer a certain amount of $/credit to try services for a period of time. Most of the instances available in the free tiers are not suited for benchmark use since they are virtual instances, and in most cases also have a "CPU credit" system where the CPU performance drastically drops after you burnt them in a short burst.
It might be a server auction system (Hetzner has that too). From the companies side, it's a very effective system if they want to ensure a steady stream of demand.
I don't think so! The one I'm thinking of, if I'm remembering correctly, walked you through the construction of a simple parsing macro (much like the one I ultimately linked).
You've pretty much reached the optimum, besides finding some datastructure that's specialized for storing DSTs/trait objects (I can't find one on crates.io with some cursory searches so don't worry about it). You need `Box` because each actual closure type is unique and cannot be named directly, so type-erasing them to trait objects is really the only thing you can do when you have to stick them somewhere. When a closure is required to be `'static` it means, practically, that it cannot have any by-reference captures (which is the default mode for `Fn`); adding the lifetime lets the closures capture their environment without moving, though the captures still have to outlive the inferred lifetime. Functions are always `'static`. 
The mangled name is probably a closure inside the relevant function body. 
Why this comment is downvoted? This is just an opinion, you might disagree with it, but it's correct, polite and reasonable.
Ah, beautiful, thanks!
You need to annotate your functions with ```rust #[no_mangle]```
Are you required to recurse at all? The spec seemed unclear to me: I was assuming that you couldn't jump back to something that itself contained a jump. In any case, I think it would be fine to limit jumps to be only back into previous records, which should limit the recursion.
&gt; well this was a positively upvoted comment (so im not allow to speak or say anything or something on reddit?) It's just that you have a very weird way of writing, and your posts are WAY too long and not concise at all.
&gt; But with other rows I click into functions that aren't closures and can see the actual code. Really? Did you have to do anything for that? It never worked for me, but I didn't really question that, as I figured I couldn't use XCode for Rust development anyway. As for the mangled name: that would be normal, no? A closure is --- by design --- an anonymous function. Even if you happen to bind it to a variable `closure` in the example, that doesn't change the (lack of) name of the function. You could rebind it to `another_variable`; I don't see how a debugging tool built on top of DWARF debuginfo and macos' C ABI could keep track of that. Especially since Instruments doesn't know about Rust. But I'd love to be positively surprised.
I had to read the part about 'move' several times but it sounds pretty clear now! Thank you.
Even if it's not possible to get it to work with a closure, if you can see lines of like a struct method or a free function you could just refactor the code to use those instead, and have a custom struct. That might be a lot of work, but if it lets you use your favorite profiling tool then it might be worth it?
Oh yeah, I also vaguely think I remember this...
This is the subreddit for the Rust programming language. You're looking for /r/playrust.
Thanks, can you please include this in the README?
&gt; (Original developer of Leaf here) Did the maintainer change? What happened?
Wish I had the time to help – I have three proc-macro-attribute crates that I'd love to see on stable (well, to be fair, two also rely on specialization).
[Here](https://imgur.com/a/mHKLw) is a gif of what I'm seeing. I feel like my other comment didn't explain how I'm seeing the Rust code in Instruments very well. To be honest, I'm not even sure how this profiling is working at all (in terms of getting the symbols and pulling up the source code) but this is the workflow that I do to access that code. As you can see, the `...$closure$...` that I select is surrounded by different closures in that same module::function that are all taking quite a bit of time to run and I'm not able to differentiate these closures. I am writing a transpiler that converts Python3 code to Rust, so I'm doing some funky things, we can probably leave it at that. The point is, I just can't differentiate between these closures. 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/miR7COT.gifv** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dvtkmfa) 
See https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb
I don't think so. I didn't like how their plans were also quite inflexible. They're OpenVZ based, also with Docker option for about half a year. I've not tried them personally but they've had multiple reports of the fastest disk I/O iirc. I much prefer Vultr or trying Hetzner in future.
Ah that's cool. They've not had that great disk I/O perf in the past, are the NVMe SSDs locally connected or network block storage? Depending how it's provided locally can also affect perf, quite a few ways to manage it for virtual machines.
&gt; Do you have any experience using them? I do, but nothing fancy or intensive. I used to go with DigitalOcean but discovered Vultr a few years ago. I quite like their aesthetics/UX as well as offerings. They're quite fast and nice to work with and have some nice customization like the ability to provide your own install ISO allowing for any OS of your choice, whereas other providers have limited choices that can be a bit old with their kernels or packages. Hetzner has cloud offerings now and they look quite impressive, I have no idea how they compare beyond bang for buck.
Ahh. I stand corrected.
Sounds like an interesting bug report for /u/japaric...
&gt; EDIT: btw, imagine how fast a website re-render/layout could be if the function was specialized based on the actual DOM for a page (i.e. figure out what parts of the DOM are unlikely to change over time and hard code them into the layout and rendering functions) As fast as a JIT?
http://danielkeep.github.io/tlborm/book/ maybe?
gl::clear with 0 in alpha maybe?
Thanks for the info, I never considered if Rust had a runtime or not.
Thanks, I was thinking the other day about the potential to dynamically load in a library at runtime after I found `rust_libloading`. But like you said, uber unsafe and unstable; I would lose every guarantee that Rust gives me.
The SSD drives on the I family instances are local drives.
I'm currently working to implement the treewalker interpreter in rust, but I get stuck with the borrow checker and I don't know where to ask
Yeah, I like the idea of expression trees in Rust. But clearly that capability is not within the language design. I could build an interpreter, but I don't think it'd be worth it. Thanks for your reply!
I want to try to implement AWK-like language in Rust. I am writing AWK-like due to fact that there can be some differences due to fact of missing specs and/or performance/usability changes, but I try to be as compatible as possible. In future I want to add JIT via LLVM to check out how it will work out. 
Thanks, that's understandable but odd. I remember a months or two ago how Leaf was announced to conquer it all. Seriously hoping the new developers will push it forward. It doesn't matter if there are existing, popular frameworks. We have Cassandra and Hadoop but still other actively developed alternatives. I still believe that Rust can shine here if we consider that the other solutions are C++ paired with Java and Python.
I hate to say this, but the "practical intro" chapter you're thinking of doesn't work in current Rust any more, and it hasn't been rewritten. At this point, it'd probably be better to just delete it.
NVMEs are M2 drives connected over the PCIe bus. They are not network attached nor are they SSDs in the traditional sense although like SSDs they have no mechanical parts. Compared to SSD drives, they have better throughput, better latency, more expensive and smaller volumes. 
But at [what](https://www.youtube.com/watch?v=x9Ag_aTTuK8) [cost](https://www.usenix.org/conference/hotos15/workshop-program/presentation/mcsherry)!
And correct not because they are good or bad, but good because these are the formats people are already using. You need to go where the data it is, [it pulls you in](https://datagravity.org/).
Yes, I'm well aware of what an NVMe SSD is, NVMe is the protocol(can use x4 PCIe lanes), M.2 is the form factor, you can also get M.2 drives that are SATA based and thus not as good in perf compared to NVMe. My response was about if the drives were made available to the cloud instances(typically VMs) locally or over a network protocol layer(See Vultr's block storage, DigitalOcean has something similar, Amazon has Elastic Block Storage I think). Network attached storage is flexible but will not perform as well at disk I/O. Locally, you have other ways of providing that storage to the cloud instance, depending how you go about it you can have higher overhead. Sometimes the VM is using a disk image which layers a filesystem on the guest on top of a filesystem on the host. You can also assign a partition as raw block storage device or LUN, If the host is using LVM to manage the filesystems it's pretty flexible at this too, as is ZFS with zvols I hear. You then have the virtualized disk controller, this can also be SATA or SCSI for example which incurs some overhead vs giving the VM access to it's own disk controller. Likewise you can also passthrough the hardware directly to the VM guest along with disk controller, however this is less flexible which tends to be something cloud instances pride themselves in. Some storage might also be backed by RAID configuration which can improve on disk I/O, I believe this is what SSDNodes does, Hetzner offers it too(at least on dedicated servers). You can also serve storage locally over an internal network to the VM guests running on the same system, I've been able to do network communications from one VM to another local instance at speeds that are very fast, the disk I/O perf on the host would be the main limit then, alternative you could use RAM as a small volatile storage option which would perform far better than NVMe afaik. Beyond that, the OS itself can be configured to prioritize thoroughput by configuring the kernel, using the appropriate I/O schedulers, filesystems, etc. The host OS that may run multiple guest VMs providing cloud instances may also be configured in different ways affecting perf based on what the other guests are doing. If they share resources like disk I/O, CPU time, etc then their activity can impact on the others, some providers will try to prevent/reduce that from happening while others may not. You can for example isolate CPU cores to individual guests, when you see vCPUs offered, it usually means that other guests can share the same CPU cores being offered. In your guests you can also in some cases have control of how your cores are utilized, assigning two to only be used for a particular process for example while everything else uses the other two cores on a quad core system(though the host will need some too). So uhh as you can see, there is a variety of options/configurations that providers can give with cloud instances. For those less in the know they may only notice the specs in relation to price. But the above is largely why you can get varying perf beyond actual hardware components and the generic resources being offered.
Yeah, depends what you're benchmarking really :) Perhaps people want to know how the two compare on such instances or from certain providers(perhaps not this kind of workload). I suggested Hetzner for good price for what you get if you want a proper dedicated server where you don't have any of those issues, they've also got some fairly nice priced cloud instances now from the looks of it. Vultr also has offerings that while virtual I believe avoid the issues you mentioned, they're of course not free. I don't personally have experience with Amazon, Google or Azure services, I just know they tend to get a lot of business regardless of perf/price. I touched on different ways storage can be provided in another response [here](https://www.reddit.com/r/rust/comments/84t3jj/first_benchmark_for_datafusion_rust_vs_apache/dvtwd6l/). And briefly on CPU. Is there info on which Amazons instances use the CPU credit system that affect consistency? I assume they're clear about what ones do/do not use that system? Vultr has their own comparison page [here](https://www.vultr.com/benchmarks/) but that's likely dated and I generally assume bias when a provider shows such on their on page. It compares m3 and c3 large instances which I don't think are in the free tier? There was some website I recall with user/community benchmark contributions that verified Vultr was doing well, of course spinning up your own instances to run such tests yourself would always be the best option :P
Just checking, did you see [`futures::executor::ThreadPool`](https://docs.rs/futures/0.2.0-alpha/futures/executor/struct.ThreadPool.html)? That's probably the easiest way to create a future from a long-running computation. Also, even if you fix the ownership issue you're having, I think you're still not scheduling a wake-up call in your implementation of poll(). Without that, the executor will never know when your future is complete. It doesn't busy-wait on futures' completions. Even if you don't want to use `ThreadPool`, you might benefit from reading its [source code](https://docs.rs/futures-executor/0.2.0-alpha/src/futures_executor/thread_pool.rs.html). (By the way, I I found the post title insensitive. It's not a big deal, but you might be turning away others who would usually help with questions like this.)
Nah, I'm pretty sure I saw a similar thing a year ago while looking at providers, and when I see such a marketing tactic I'm generally skeptical. Timer expired and just reset itself iirc. Not something I'm fond of, but I guess it lets them have flexibility in price and less legal concerns. If the inflexible hardware configurations(they have a linear offering last I checked that you could upgrade to the next plan any time) they seemed to be quite good. I think a part of their advantage was that they provided containerized OS guests rather than full VMs which should be less overhead. OpenVZ however I think had some issues and things I wasn't too fond of, especially with isolation/consistency of hardware resources due to sharing with other customers, if I'm not mistaken overcomitting resources might have been more common. I prefer VMs running on KVM hypervisor. Both DigitalOcean and Vultr use KVM.
I think I know where "Foo" comes from. In the Vietnam War, when someone was blown to bits, they would be considered FUBAR (f*cked up beyond repair). So that's why programming examples normally use Foo and Bar in close proximity. I could be wrong though!
Yeah I'll just say trivializing the idea of violation doesn't seem like a great way to ask for help.
It was a figure of speech, I'm sure OP didn't mean anything in particular by it. 
I suspect the OP does not speak English as their first language, so this mistake is understandable. But to say that a person has been "violated" is very serious - most often it is a euphemism for rape or sexual assault. It's not a figure of speech which is appropriate to use in this context.
I'm not a native speaker of English either, so I might be missing some language nuances. But AFAIK "violate" has other meanings apart from the one you mentioned. We can't really know what OP meant, but to me, it looked like nothing more than a harmless joke.
You can violate a law, or a rule, or an order, and that just means to disobey it. But to violate a person means to rape them ([citation](https://en.wiktionary.org/wiki/violate#Verb)). Jokes about rape are not acceptable in the Rust community. I don't think the OP understood this, but now that we all do understand I hope we can move forward with the shared agreement that this isn't an appropriate expression.
the SSDNodes Pricing pages goes on and on about their KVM platform, and compares it to competing OpenVZ systems, so I don't think it's OpenVZ based.
I understand that the expression is in bad taste. I was just a little surprised at such a hostile comment towards the OP when there was obviously no ill intent on their part.
Do you have any references for dtrace that I can check out? Can I install it with Homebrew? Thanks so much for the comment!
Jokes about rape are not in bad taste, they are an offensive and egregious violation of our community standards. I don't think this user realized they were making a joke about rape, but the comment you originally replied to is an acceptable, even mild way to chastise someone who makes a joke about rape.
I spent most of the day today working directly with glutin and it was the same deal. Clearing with 0 alpha just gave me a black screen, I'm guessing because it's running in proper fullscreen mode so there's nothing behind the window to show. Same thing happened if I called clear directly through gl and the same thing happens if I do a no-decorations no-fullscreen window at the native resolution. I tried turning off fullscreen at the end but then I learned that it's not implemented in winit. I'm not manually cleaning up my shaders manually, but it still happens if I just open a window and clear it to some color without creating a single vertex. And it only happens on this one machine (which is the only one that matters). It works perfectly everywhere else. I am using opengl as a backend and I think it's my only option because I'm running on one of [these magnificent things](https://ark.intel.com/products/78867/Intel-Celeron-Processor-J1900-2M-Cache-up-to-2_42-GHz). I don't think it can do dx12 and it definitely can't do Vulkan. The weirdest thing to me is that it works fine if I run it by itself, but if I run it through FFI it has this problem until I kill the parent process. I'm testing with a parameterless void function so I'm not sure what could be lingering.
Hi there. I'm the OP. Here is the meaning of the word `violate` plucked from the [oxford](https://en.oxforddictionaries.com/definition/violate) dictionary. 1. Break or fail to comply with (a rule or formal agreement) ‘they violated the terms of a ceasefire’ 1.1 Fail to respect (someone's peace, privacy, or rights) ‘they denied that human rights were being violated’ 2. Treat (something sacred) with irreverence or disrespect. ‘he was accused of violating a tomb’ 3. literary Rape or sexually assault (someone). Out of the 3 possible contexts and meanings associated with the word, may I ask why you chose to conflate my usage of the term with the 3rd one? Because I meant, 1.1 or 2. 
In case anyone is interested, I’m currently maintaining a native Rust implementation for Parquet, with the intention to contribute it to Apache soon: github.com/sunchao/parquet-rs. Contributions are welcomed :)
&gt; I am using opengl as a backend and I think it's my only option because I'm running on one of these magnificent things. I don't think it can do dx12 and it definitely can't do Vulkan. The branch of gfx I assume piston is using supports dx11 so it is possible. Anyway not sure what to suggest, go on glutins gitter chat and talk to tomaka and see if he can help you.
Well I ended up fixing it with a somewhat "awful hack." The general advice was to set up both windows on the main thread, but I was unable to see how to do that since both windows run function blocks until the window is closed. So I moved the GTK window to the main thread and the rendering window off of it, and I added a two second delay for the rendering window after the GTK window. This works for now, but it kind of scares me. I also switched to mpsc like someone suggested. The changes can be seen in [this commit](https://github.com/IntrepidPig/vgraph/commit/e76877ce188e8bf81ddec52c456af0d943588e44) if you're more curious. Thanks for all the help!
As I said, to violate a person means to sexually assault them. The dictionary confirms this - in the first two definitions, the object of "violate" is an abstract concept ("human rights," "the terms of a ceasefire," "a rule or formal agreement," "someone's peace, privacy, or rights"). The third definition, in contrast, takes a person as an object. It's fine that you made a mistake, but I'd encourage you not to dig yourself in further by trying to deny the error, because what you wrote was (unintentionally) very offensive.
I am going through [500 lines or less](https://github.com/aosabook/500lines) and will be implementing them in Rust 😁
Oh... terribly sorry if that's the case then. I was certain they were the one offering OpenVZ and Docker options. It seems I've mixed them up with another provider. Ah it seems like they are the correct one I had in mind, they've replaced the OpenVZ and Docker offerings with KVM for a while now: https://blog.ssdnodes.com/blog/the-road-to-kvm/ They make a good point about kernel issue with the previous offerings, I think that was one of the reasons I preferred VM providers. I don't know what this means for their disk I/O perf now then, as their previous approach may have been the reason they were in the lead. You'd need fresh benchmarks to confirm now. Sidenote, looking at the pricing it says the sale expired for me. Clicking on an option though indicates the crossed out value is what they ask for monthly, you can get the discounted monthly rate still if you agree to a yearly contact which is about 2 months of their monthly contract rate. Looks like a nice offering if you don't need the types of cloud instances other providers offer with hourly rates no contracts(Amazon I know has discounted rates if you do opt for longer terms).
In case you return `Async::Ready`, the poll method will never be called again. That is something you know, but the compiler does not know, so it's being overly cautious. Therefore we have to work around it. The easiest way is probably by using an `Option`, like this: struct RndStringFuture(Arc&lt;AtomicUsize&gt;, Option&lt;thread::JoinHandle&lt;RndString&gt;&gt;); Now you can return `Ok(Async::Ready(self.take().unwrap().get_val()))` from the `poll` method.
Thanks for feedback. There are 3 aspects that most probably would be painful. (1) All Gauss-Newton optimizations in DSO seems to be done by hand (not sure, code is a bit obscure). Adaptating it without a higher level library will be extremely painful (2) Writing an extension with pose graph optimization will also be painful without an equivalent of g2o. (3) Writing an extension with loop closure detection without an equivalent of openFABMAP will be kind of annoying but manageable. So the main difficulty for first having an equivalent to DSO is the Gauss-Newton optimization. The rest of the difficulties concern extension work I'd like to test. Maybe the first thing to do is to try having some GN working. If I can't, whether I try pure Rust or C++ binding, there is no point continuing.
Yeah the closure is anonymous and has a mangled name, but the DWARF still includes line number information for both the function (in .debug_info) and for the instruction addresses (in .debug_line). I don't know how Instruments works, but there should be enough debug info for it to determine the corresponding code for closures.
If it's only failing for code in the current crate, then maybe it's missing a path to tell it where to find that code? If all else fails you should be able to use the address of the instructions to lookup the line number information using a tool like addr2line or llvm-symbolizer. That'll at least let you identify which closure it is.
I'm sorry but I do not agree with you. I have no time for a rebuttal. I'd rather spend that time rusting. None the less, you won't find me using that word here on r/ rust. 
I'm glad that you will not use the word again. I wish that you had the maturity - not to mention the empathy for survivors of sexual assault - to apologize for your error instead of suggesting that being sensitive to rape is a distraction from being a Rust programmer.
That's fair. I did try to phase it without being too hostile, but I could have done a better job.
Choosing "Edit Target", and setting the working directory (box below arguments) to the root of the project _might_ help. Although, when it does work for me, it looks like your library source, and often is an unrelated file in the same project. Pretty useless. The ASM view works great.
I understand it's a conversation you don't want to have and that's fair, so no response needed. I'll just say that I disagree. From the title and you're description of "My keyboard is wet with tears." it seems like the general intention was "futures has cause me real pain and anguish". Given that, I have a hard time seeing any of those points except #3 being applicable. #1 and #2 are really "rules were broken" and that isn't generally something I'd expect to cause tears. Anyway, I'll call it there. My original comment was overly hostile, so that's my bad. My intention with this post was simply to say that words to matter and whether your intention or not, words do have implications that others may read into. If you want help from the broadest possible set of people, an alternative title might make that more likely.
There's ndarray that other people have mentioned for arrays. If I ever get time and motivation, I'd like to try to fork [Utah](https://github.com/kernelmachine/utah), which is a data frames library for rust. Something needs to happen for sparse matrices. I want to help, but it seems like it's tough for folks to get any traction in this space
https://docs.rs/futures/0.1.14/futures/future/fn.lazy.html is the "go to" way to make a future calculating some task. Since creating a random string doesn't block threads, I would go with just using this. If you do need to offload it onto another thread, maybe use `tokio::executor::spawn`? It's relying on another crate - but `tokio` is currently the core of asynchronous rust, and by using its threadpool, you won't be duplicating work by spawning extra threads only you use.
I once modified the build to RUSTFLAGS=" --emit asm" cargo build --release and then was able to search for the lambda with grep in the resulting .s files in the target directory. Then asm file near the lambda definition had the file and line tag, like .file 76 "/Users/something/something/mod.rs" which had the source for the lambda. Would be interested in easier way though!
The main problem here is that strings don't have a runtime `fmt` method for string formatting. Rust supported string formatting is always (and only) done at compile time via the `format_args!()` macro, and other macros (`format!()`, `println!()`, etc.) which call it. This has the advantage of performance and compile-time validation of formatting args, but the disadvantage that you have to write the formatting string "inline" with the call. If you change each of the lines using `.fmt()` to something like the following, it should work better: format!( "{value} bottles of beer on the wall, {value_prime} bottles of beer\n\ {command}", value="No more", value_prime="no more", command=buy, possible_value=99 ) Documentation for string formatting: https://doc.rust-lang.org/std/fmt/#usage --- Sidenote: there is _technically_ a method called `.fmt`, which you found, under the 'Display' trait. Unfortunately this method is not what you were looking for, as it writes the contents of some string _to another string_. Like, `let mut a = ""; "asdf".fmt(a);` leaves `a` as `"asdf"`, and does not return any meaningful string from `.fmt()`. This is also why it's in the `Display`, not a method on string. ([more info on `Display` and related traits here](https://doc.rust-lang.org/std/fmt/#formatting-traits))
If you expect to defer some arbitrary work into another thread and wait in the parent thread for it to resolve and return a value use `thread::spawn`; that's literally what it does. In C# a Task is a unit of work (blocking or not, no one cares) that is sent to the thread pool, and will be executed arbitrarily, on some worker thread; at some point the task may be suspended (by calling await) and eventually some other thread will resume execution (caveats apply to do with thread affinity, but lets ignore that for now). From a programmer perspective you simply take a blocking operation and go `Task.Run(() =&gt; { ... })` and you have a task. Nice and simple. That's not how Futures work. Futures push the implementation of that non-blocking operation *on to you*, the implementer of the future. A future, logically, must start its operation in a non-blocking manner, and then check and return the value when poll() is called. Your future will only be polled when the state machine updates; that is, if no futures have changed, your poll won't get re-called. You, *the implementer of the future* must trigger a new poll explicitly if the state of the future resolves itself. If you want to turn `thread::spawn` into a Future, use `OneShot`; if you have an arbitrary closure you want to turn into a future, use `lazy`. Just realize, in general, using `run(my_future)` will *always block the current thread*; that's what it is intended to do. This all makes it difficult to implement `Future` because the work of doing it right is pushed onto the person implementing Future; At a super high level, I would say, these are the low level building blocks that you probably don't want to be using. &gt; Trying to learn futures... I really wouldn't do it this way. You should probably try to do something practical using tokio; trying to understand and use `Future` without an executor context is, in my opinion, largely meaningless.
&gt; Is it possible to fix the problem without significant structural changes? (Notably on the way I'm trying to string interpolation) No. Rust doesn't *have* runtime string interpolation, it doesn't have named arguments, and it doesn't have variadic functions. So you're basically zero for three. If you're doing interpolation, it *must* be with a string literal (not a variable, not a constant, a literal) as the format string. You're probably better off just building the pieces up one at a time. use std::fmt; pub fn verse(n: u32) -&gt; Result&lt;String, fmt::Error&gt; { use std::fmt::Write; let mut s = String::new(); match n { 0 =&gt; write!(s, "No more")?, n =&gt; write!(s, "{}", n)?, } write!(s, " bottles of beer on the wall, ")?; match n { 0 =&gt; write!(s, "no more")?, n =&gt; write!(s, "{}", n)?, } writeln!(s, " bottles of beer.")?; match n { 0 =&gt; write!(s, "Go to the store and buy some more, 99 bottles")?, n =&gt; { let obj = if n == 1 { "it" } else { "one" }; write!(s, "Take {} down and pass it around, ", obj)?; match n { 1 =&gt; write!(s, "no more bottles")?, 2 =&gt; write!(s, "1 more bottle")?, n =&gt; write!(s, "{} bottles", n - 1)?, } }, } writeln!(s, " of beer on the wall.")?; Ok(s) } fn main() { println!("2: {}", verse(2).unwrap()); println!("1: {}", verse(1).unwrap()); println!("0: {}", verse(0).unwrap()); } 
I think only the [T2 instance type is affected](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-credits-baseline-concepts.html), though I guess the T2 Unlimited instances just cost more once you've burnt your credits instead of throttling down.
Thanks for the support. Sometimes you have to pick your battles. And this is one battle I chose not to fight. I really get nothing by engaging them other than to stroke my own ego. I'd rather let them believe they are better than me. Better than everyone else. I'll Just follow the rules. Stay out of their way. I'm here for rust. All the other pointy whining and senseless babble is not for me. 
Great, thanks for the well written explanation. Actually you could copy and paste this as is into the README :)
&gt; The general advice was to set up both windows on the main thread, but I was unable to see how to do that since both windows run function blocks until the window is closed The way to do that is to either split those function blocks into callbacks, or run them blocks each in its separate thread. If the blocks need something done by the GUI, they tell the GUI to do that, typically by calling [`idle_add`](http://gtk-rs.org/docs/glib/source/fn.idle_add.html) with a closure they provided.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/gamedev] [kryen from Chucklefish doing AMA about using Rust for their new game Spellbound (x-post r\/rust)](https://www.reddit.com/r/gamedev/comments/78ckci/kryen_from_chucklefish_doing_ama_about_using_rust/) - [/r/programming] [Chucklefish (maker of Starbound) is writing a new game in Rust, and kyren is doing an AMA!](https://www.reddit.com/r/programming/comments/78c8r4/chucklefish_maker_of_starbound_is_writing_a_new/) - [/r/programming] [Chucklefish (maker of Starbound) is writing a new game in Rust, and kyren is doing an AMA!](https://www.reddit.com/r/programming/comments/78ca3o/chucklefish_maker_of_starbound_is_writing_a_new/) - [/r/rust_gamedev] [Kyren from Chucklefish is doing an AMA in r\/rust on using Rust for their new game, Spellbound](https://www.reddit.com/r/rust_gamedev/comments/78d30h/kyren_from_chucklefish_is_doing_an_ama_in_rrust/) - [/r/spellbound] [Kyren from Chucklefish Discusses Spellbound and Using Rust](https://www.reddit.com/r/spellbound/comments/78hci2/kyren_from_chucklefish_discusses_spellbound_and/) - [/r/witchbrook] [Kyren from Chucklefish discusses Witchbrook and using Rust](https://www.reddit.com/r/Witchbrook/comments/852lbb/kyren_from_chucklefish_discusses_witchbrook_and/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
This works: pub fn square_of_sum(n: usize) -&gt; usize { let s: usize = (1..n+1).sum(); s.pow(2) } sum is defined as fn sum&lt;S&gt;(self) -&gt; S where S: Sum&lt;Self::Item&gt; I assume, that for some reason the compiler can not automatically determine, that S is usize. `as` does not add a type hint, but performs a cast, so that the original is still unknown. EDIT: [relevant SO thread](https://stackoverflow.com/questions/41017140/why-cant-rust-infer-the-resulting-type-of-iteratorsum)
You're doing gods work here by explaining why this is a problem in the most polite, nice &amp; deescalating way possible! Thanks, there are way too few people like you!! :) ... , *especially* in anyonymous online communities ;)
LBAs don't all halt, they can infinite loop as well. But the time needed to know whether something halts or loops is finite and a function of input size.
Sorry, yes. I mixed it with the approach of just limiting the amount of steps provided above, which halts in all cases.
 let owned = mut&amp; owner.field[0]; This is very confusing, did you mean let owned = &amp;mut owner.field[0]; ? &gt; What's the best way to handle this? Would need to see more code, it's not clear to me.
&gt; Are there any downsides to using them both together? Of course, your app would acquire twice as many threads, each with its own stack, both competing for scheduling by the operating system. &gt; If yes, is there any way by which they can share a thread pool? You can check if these libraries allow you to initialize them with a thread pool. If not, you can fill issues to nicely ask them if they could parametrize their thread pool with a trait to allow you to provide your own. Once that is done, you can choose whichever thread pool you want, implement the traits for tokio and r2d2, and initialize both libraries to use your thread pool. C++ has a family of Executor traits with different guarantees that libraries can be parametrized upon. Maybe some day Rust will have something similar.
whoops, didn't notice that, yes, I meant the second one. I'm not sure what else would be helpful, the only other thing I can say is that they are both in the same function/scope.
As a side note, there is a crate called strfmt that provide runtime string interpolation.
I think you misunderstood the definition, it makes a difference which object you use. 1. and 2. are used for something and 3. is used for someone. I think you can't use 1. for someone.
Actually, what you just said was super helpful. I think it might be best just shift the value out then unshift it back in after I'm done with it. I'm honestly un-used to working with a language where a value can exist in one place and that you can only have one writable reference and many readable. Also, all of them show ways to solve this that I'm unaware of, so still helpful. EDIT: Ok, so the solution is as follows (doing the first thing that you suggested): let mut owned = owner.field.remove(0); //some code... owned.some_method( arg, arg, owner); owner.field.insert(0,owned); So I move owned out, used it and then move it back in. One of the things I'm having trouble with is knowing when to reference, when to move, errors that can happen and when to use borrowing vs moving to fix them. 
I really shouldn't response to this, but, I just can't stand by and watch this sort of nonsense. Please stop.
Just to clarify, are you thinking this could be done without linking the whole compiler (or at least the backend parts) into the exe?
[You can find the slides here](http://babelmonkeys.de/%7Eflorob/talks/RC-2018-03-12-caches-and-you.pdf) and of course [follow RustCologne on Twitter](https://twitter.com/RustCologne) or [join us on meetup](https://www.meetup.com/RustCologne/) :)
Fun exercise! If you wish to go beyond Peano numbers, I invite you to check out the [typenum](https://github.com/paholg/typenum) crate. It has a more efficient representation that you may want to look into.
/u/MrMarthog is right about how to fix it; here's another way if you want to keep it as one expression: (1..n+1).sum::&lt;usize&gt;().pow(2) So, why doesn't it work without the type annotation? The first `square_of_sum` works because you are explicitly doing `sum + x`. By `fold`'s definition, `x` must have type `usize`, therefore `sum` must too. `sum_of_squares` works because you are directly returning the result of `.sum()`, and your function is declared as returning `usize`, so it knows to look for the implementation of `Sum&lt;usize&gt;` for `usize`. The second `square_of_sum` doesn't work because you're passing the result of `.sum()` to `.pow()`. Nothing says what the type of this intermediary value returned by `.sum()` should be: as /u/MrMarthog says, there can be multiple types which implement `Sum&lt;usize&gt;`, and the type inference cannot guess which one you want. For example if I write this: struct Foo(); impl Foo { fn pow(&amp;self, _x: u32) -&gt; usize { 0 } } impl Sum&lt;usize&gt; for Foo { fn sum&lt;I&gt;(_iter: I) -&gt; Self { Foo() } } then the following would work too: (1..n+1).sum::&lt;Foo&gt;().pow(2)
&gt; We are using Rust today at Galois to build cooperative control algorithms for autonomous systems targeting embedded Linux and desktop Windows systems. As with Boeing’s Ivory work, we are converting an existing, sophisticated C++ control architecture into Rust, one module at a time. The lack of runtime systems and the native C ABI compatibility of both Ivory and Rust makes this style of incremental program hardening very practical, and allows us to prioritize resources on the parts of programs that are most vulnerable to attack: external data parsers and network interfaces. Did I read that right: is Galois really using Rust in production on embedded systems today? In any case, it's extremely good news that a company involved in embedded software is taking interest (and apparently using) Rust.
It does happen. As an example, do a `dig net. NS` and look at the raw response. The result will be something like this: ;; QUESTION SECTION: ;net. IN NS ;; ANSWER SECTION: net. 84706 IN NS b.gtld-servers.net. net. 84706 IN NS i.gtld-servers.net. (Followed by more NS records). Your mileage may vary, of course, but my resolver returns the record data in the first record as `b.gtld-servers` followed by a reference to the `net.` in the question. The second NS record is `i` followed by a reference to the `gtld-servers` in the first record. Only expecting backwards jumps seems like a reasonable assumption, but given that forward jumps aren’t forbidden, I am almost certain something somewhere will do them resulting in strange and annoying errors in name resolution. Given that name resolution is so important, I’d rather not risk that. Or, as the second level support department in a previous job had written in large letters on the wall: ‘Assumptions are the mother of all screw ups.’ (Only it wasn’t ‘screw’ they used.)
I did take a look at `typenum` whilat writing this. To explore the basics of number theory and Peano numbers would have been overkill to use `typenum`. As well as that most of the code from the exercise was actually ported from Haskell that I wrote a while back, hence the mention of currying and GADT. 
I think you should just return failure::Error. Then `?` will just auto-convert any other Error to it (by boxing them).
As far as i understand, I shouldn't use `failure::Error`in library. I should probably add `.context` or `.map_err` but I don't know how should `MyError` type looks like.
Really great ! Is a Kodi plugin in the cards ?
This is one of those things where Rust requires a bit of a shift in the way you approach the layout of your code. These 'two-way references' are very common on object-oriented code but they don't play well with Rust's borrowing system. Instead, you will have to break up your code into those bits that operate on `owned` and those that operate on `owner` and then tie those two together. In your case, `some_method` likely doesn't need full access to `owner` -- you are passing in an immutable reference, so you probably only need some information from it. You might get away with fetching that information separately and pass it into `some_method`. Alternatively, you can perhaps move `some_method` to `owner`'s type, passing in the field index as an argument and have it call simpler, more dedicated methods on `owner`. In general, Rust favours ownership to be laid out in a tree and access to follow ownership.
Yup. I believe they’re on the friends page! I’ve known some Galois people for a long time, they’re great. I stopped by their office in Portland and gave a talk about Rust a few years back.
You cannot pass two references to the same memory if one or both are `&amp;mut`. Aliasing law. You must reconsider the purpose of the method and might use shared references only. 
That looks exactly what I'm after, thanks!
Oh wow, thank you so much for writing this software!
(This code is untested) With a library, I think the best approach is to use it to scaffold your errors and design them as usual in Rust. Your type could look like this: use std::io; #[derive(Debug, Fail)] pub enum MyError { #[fail(display = "an IO failure occurred")] Io(#[cause] io::Error), } To make it work with `?` you could either use `map_err` like this let file = fs::File::open("/some/file") .map_err(MyError::Io)?; (use a closure instead of `MyError::Io` if you need to put extra things in the error) or you could `impl From&lt;io::Error&gt; for MyError`, which will allow you to just use `?`.
YESSSSS!!! This changes everything! 
ahhhhahaha. Gotcha.
Ah, yeah, you can't. You can only refer to fields, as far as I know. It might be possible to make an API that takes expressions in strings, but I'm not sure that's in the works. In more complicated projects I tend to end up with my own wrapper types around paths, and implement `Display` for those. So, maybe a `ErrorPathBuf` wrapper type that implements `Display` and maybe `Deref` and `DerefMut`?
How can I receive and remove the first element of a `Vec`(like `Array.prototype.shift()` in JS)? Or what's a simple FIFO data structure?
The pedant in me doesn’t like that embedded system also means embedded Linux computer. It’s easy to get rust installed and running on different flavors of Linux. We have a control system at work that connects linear motor controllers, fiber optic gyroscopes, GPS, and IMUs to a 40 core Dell Precision server rack. Some of it is written in Rust. In someways people consider that an embedded system because we talk to embedded hardware, but I think the luxury of Linux and the fun of programming resource constrained embedded systems don’t always coexist. Where I hope Rust improves over the next year is native support for actual embedded processors like PIC32s, Leons, RAD750s, where the LLVM backend does natively target them (MIPS, SparcV8, and PowerPC respectively) but we need seven different tools made by /u/Japaric to get them working. To my understanding embedded Rust will be somewhat difficult for some architectures like the PIC16 because their llvm background was abandoned (llvm 2.9 removal), so even if rustc wanted to try to compile for it, there wouldn’t be anything the backend could do. I’ve wanted to revive that backend, but I think having to fork llvm and rustc might be too big of a task for one person.
&gt; I think you've taken a shortcut here, fold's definition only asserts that f: FnMut(B, Self::Item) -&gt; B and init: B, there's no intrinsic relation between x and sum. &gt; &gt; However the callback is a simple addition and thus adds that B: Add&lt;Self::Item, Output=B&gt;. Yes, that's why I talked about `sum + x` just before, but I guess that wasn't quite clear so thanks for spelling it out. &gt; I don't understand why the sum() version doesn't work though, there's also only one implementation of Sum&lt;usize&gt; in the stdlib, and it's for usize. Because the type inference engine doesn't really works on a "I only found one option that matches so I guess that's what you want" basis; it's more conservative than that. If the context doesn't force the impl to be a specific type, the compiler would rather ask you to be more explicit, than implicitly use an impl that might not be what you wanted.
Would this Executor/Thread Pool trait live in the stdlib or could it be in its own package? Cross package interop is really important for composability. 
`Vec::remove` will remove the element at the given index and shift all subsequent element to the left, so `vector.remove(0)` will do what you want. If you don't care about retaining element order you can use `Vec::swap_remove`, which instead of shifting will put the last element in that space, and thus will be more efficient. If you want a proper and efficient queue, you should use `VecDeque` instead.
Right, indeed. I don't know either :/
Marvelous! Right now I'm running a "daemonized" graphical Spotify client in a fake X server session on my HTPC. Needless to say it uses way much resources than necessary. Need to try Spotifyd instead. :)
One way is to make `visit_x` not return anything, and thus not be generic, thus object safe. E.g. struct StringVisitor { out: String } impl Visitor for StringVisitor { fn visit_a(&amp;mut self, _a: &amp;DataA) { self.out = "got an A".to_string() } fn visit_b(&amp;mut self, _a: &amp;DataB) { self.out = "got an B".to_string() } } 
The problem is that `Error` borrows the parser, and that's why it is still considered to be borrowed after parsing the subexpression. And this happens because you are not actually using non-lexical lifetimes - if you want to enable them, you need to put `#![feature(nll)]` in `lib.rs` - features can only be enabled per-crate, not per-module. Although it is a bit weird that the compiler does not warn you about the useless `#![feature(nll)]` in `parse_expr.rs`. `Expr`s do not borrow anything (as they don't have any lifetime parameters), and parser returns owned values instead of references, so cloning them immediately is completely pointless. You can safely remove `.clone()` from `self.unary()?.clone()`.
Yeah, you're right. I guess it wouldn't be *that* hard to do the loop detection properly. Keep a bitset marking records as used, and stop whenever a given record is used a second time.
You want a VecDeque.
Yeah that might be cool but also it's your work and it'd be nice to have you get the credit :) If that's what you want to do I'm more than happy too.
&gt;Spotifyd streams music just like the official client Is this something accepted by Spotify? I'm *very* interested in an open source client for Spotify, but it worries me that there is something against their licence.
I've changed the path a few times, no luck on that. Do you mind explaining a little more as to how I'd use addr2line? I've been messing around all morning trying to get it to work but haven't been able to. Here's what I'm doing: * Profile my program with "Instruments" * The closure I'm interested in looks like this `sandbox::cannoli_mods::cast::import_module::_$u7b$$u7b$closure$u7d$$u7d$::hcf5e7392232839e8+0x165d` * I then run GNUs `objdump` to get an address, as so: `objdump -d target/release/sandbox | grep 'hcf5e7392232839e8E+0x165d'` This returns: `100024954: 0f 84 73 05 00 00 je 100024ecd &lt;__ZN7sandbox12cannoli_mods4cast13import_module28_$u7b$$u7b$closure$u7d$$u7d$17hcf5e7392232839e8E+0x165d&gt;` * So I take that first number (which I believe is the address?) and use `addr2line` as so: `addr2line -e target/release/sandbox 0x100024954` But get `??:0` which is unfortunately not what I want. What am I doing wrong here?
Works perfectly! Great job!
Is there any up-to-date tutorial on how to use Rust with iOS? Anything I find seems to be at least one year old, and I would suspect thing may have improved. I would like to create my UI with Swift, and call Rust for some specific functions that don't need to interact with Cocoa Touch.
I don't think it's particularly sarcastic. We chose "curly braces and semicolons" as a basis for Rust's syntax for exactly this reason. It doesn't mean that we don't deviate in ways, of course, because we have some features not present in those languages.
Last time I checked, spotifyd was just a small shim around an outdated version of librespot. I simply use the latter.
I would even say that separate thread pools for separate tasks is good practice, as it makes the pools have more predictable behaviour. Previous discussion here: https://www.reddit.com/r/rust/comments/834d55/new_tokio_release_the_tokio_runtime/dvgexwm/ 
Not an exhaustive list, but probably safe to say: * Threads * Anything to do with IO operations (net, fs, stdin/stdout?) **Edit**: Here is the wasm stdlib, which has most stuff around threads and IO stubbed out: https://github.com/rust-lang/rust/blob/6741e416feb54b18de41c348ecc70ba5cbc961ce/src/libstd/sys/wasm/mod.rs **Edi again**: This lib is also useful for filling out the features missing in terms of inter-operating with JS, DOM APIs, and Web APIs: https://github.com/koute/stdweb
I mostly agree with Quxxy, but I thought his answer was unnecessarily convoluted. If you can live with your arguments being formatted before your final string (instead of being "injected" into the formatting string), you can write your code very close to your original code: pub fn verse(n: u32) -&gt; String { let value = match n { 0 =&gt; "No more".to_string(), _ =&gt; n.to_string(), }; let value_prime = match n { 0 =&gt; "no more".to_string(), _ =&gt; n.to_string() }; let command = match n { 0 =&gt; "buy".to_string(), _ =&gt; format!("Take {} down and pass it around", match n { 1 =&gt; "it", _ =&gt; "one" }), }; let possible_value = match n { 0 =&gt; 99.to_string(), 1 =&gt; "no more".to_string(), _ =&gt; (n - 1).to_string(), }; format!("{value} bottles of beer on the wall, \ {value_prime} bottles of beer.\n\ {command}, {possible_value} bottles of beer \ on the wall", value = value, value_prime = value_prime, command = command, possible_value = possible_value, ) } The .to_string() calls are sadly necessary (to tell that we want a dynamic-length string), otherwise it would look much cleaner. But I thought, this might look a bit cleaner than Quxxys answer.
&gt; The standard library has a number of unstable features. I had a feeling that some of them have been there for a long time without really being blocked on anything. To find out, I went through all of them and checked.
I have much respect for Rust developers for making cryptographically secure PRNG the default. If it's identified as a bottleneck during profiling, it can be easily changed to something faster provided that it's safe.
From your description it seems that you don't need `futures`, since PRNG doesn't block and file can't be made async.
Shot in the dark: you are compiling in Release mode, right?
&gt; I know the Galois folks. I'm pretty sure that comment was tongue-in-cheek. I guess we know different Galois folks :)
Huh. Well I guess I have a question for Adam now. :-)
I could always be wrong!
I feel like I was clear about why I don't see it as nonsense. You're free to feel otherwise of course, but words do in fact have meaning and since English isn't a programming language, it can be read in multiple ways. Alternatively, if what you're saying is that it doesn't matter if you use words that trivialize sexual assault, I think you're pretty terrible and I'm not sure what you're hoping to get out of this discussion to begin with other than making other people feel bad.
I think it's slightly different in each of the OP's cases: For this: pub fn square_of_sum(n: usize) -&gt; usize { return (1..n+1).fold(0, |sum, x| sum + x).pow(2); } The compiler assumes both '0' and '1' are "{integer numeric}". `Add::add` is not ambiguous because both 'sum' and 'x' can only be the std-defined integer types, and _no one outside of 'std' can define an Add implementation concerning two integers which results in an outside type_. This is because for `impl Add&lt;B&gt; for A`, the "input" types are both operands, and the output is an associated type, a type system "output". In this, it's fairly similar: pub fn sum_of_squares(n: usize) -&gt; usize { return (1..n+1).map(|x| x.pow(2)).sum(); } `1` is _some_ compiler-defined integer. `(1..n+1)` is undeniably a range of `usize`. usize's `pow` method is unambiguous, so then you just have `Iterator::&lt;usize&gt;::sum()`. Here's the thing about `sum`: it's defined on a trait where the _output is a type-state input_. pub trait Sum&lt;A&gt; { fn sum&lt;I&gt;(iter: I) -&gt; Self where I: Iterator&lt;Item = A&gt;; } The 'self' type here is _the output_. It's defined in a way such that the output type determines the implementation, not the iterator. the `-&gt; usize` here then clarifies that it's `usize`'s implementation of `Sum`. Then in this case, inference fails: pub fn square_of_sum(n: usize) -&gt; usize { return (1..n+1).sum().pow(2); } Just like before, `(1..n+1)` is undeniably a range of `usize`. But now, there's an intermediate type! The result of `sum` is unknown, because _any type can implement `Sum`_ and then be the result of this. The key is that `Iterator::sum` is approximately `sum&lt;R&gt;(self) -&gt; R { &lt;R as Sum&gt;::sum(self) }`. "R" here defines the implementation, not the iterator, and thus any "R" could be the result of the Sum. [As /u/dioafpire pointed out](https://www.reddit.com/r/rust/comments/852oft/type_inference_for_sum_vs_fold/dvun0k7/), you can create your own type and then have it be the intermediate type here, rather than `usize`. There's no way to do this with the `Add` implementation in the first example because _the inputs to the expressions are the type system inputs_. In `Sum`, the output of the expression is the type system input. Hopefully that wasn't too much over-elaboration. I have an idea of what the difference is for the unknown type (type system input vs. output), but it's hard to put it into words.
I don't know of much that's both lightweight *and* simple at the moment. [hyper](https://crates.io/crates/hyper) is going to be the most lightweight. It's can support a capable async http server, but it is not simple to use directly. Many other frameworks are built on top of hyper. [rocket](https://rocket.rs/) is the most simple to use in my opinion. It's very fast, but also supports a lot of behavior - not very minimal. It currently requires nightly rust, but besides that I would recommend it. The best bet is probably [gotham](https://gotham.rs/)? I've heard a lot of good things about, but have not used it myself. It's very fast and will have a lightweight runtime, but it's not really minimal. I don't know how easy it would be to implement the server you described, and it isn't as _simple_ as hyper, but it looks like a good choice.
I'm trying to run it locally - running into some issues with my `vlc` setup though. This is my log running the server - it's not taking much CPU, though that's probably because vlc isn't actually pulling anything. It's running on my fairly under-powered laptop with a stream of my local screen from OBS. https://gist.github.com/daboross/02d1466e1e913a27b1c7e3a87e07362b Here's what `vlc` logs: https://gist.github.com/daboross/7b9c901ff6af98b759b5e642ee2d82e5 I'm not that much of an expert with this protocol, though - mostly just installed OBS and tried to stream my local screen through the server to see if I could see any performance issues. Is there a better way to launch `vlc` than `vlc rtmp://localhost/live/test` that might get it to attach to the right stream?
Can't const functions be used for that?
if a rust 'const function' is basically the same thing as a 'pure function' then I will thank you for informing me that this support already exists
Rust used to have pure functions for doing exactly what you want (indeed, pure is still a keyword, a leftover from that past). This was removed for.. uh, reasons. This new incarnation, const functions, are meant to be functions that can be run at compile time, so they have another focus. But they can still be called at runtime AFAIK. And they must be pure anyway. The trouble is that the const functions are still very limited; you can't write a loop inside of them, and indeed it looks like you can't even branch https://github.com/rust-lang/rfcs/blob/master/text/0911-const-fn.md &gt; The intention of this RFC is to introduce a minimal change that enables safe abstraction resembling the kind of code that one writes outside of a constant. Compile-time pure constants (the existing const items) with added parametrization over types and values (arguments) should suffice. &gt; This RFC explicitly does not introduce a general CTFE mechanism. In particular, conditional branching and virtual dispatch are still not supported in constant expressions, which imposes a severe limitation on what one can express.
Well, I think that conceptually `const` implies `pure`, and practically it will probably remain so^1 if `const` functions are to be used with `const` generics (getting a different result would be troublesome). However, this does not mean that `const` equals `pure`, off the top of my head I can think of: - `const` only representing a subset `pure`, though the subset could grow up, - no specific compiler optimization being applied to `const` functions. On the latter point, optimizers have to avoid changing the order in which observable effects occur. One nifty property of `pure` functions is that they have no observable effect, which leads to multiple optimization possibilities: - sinking a call into a branch, if the result is only used there, - hoisting a call out of a loop, if the arguments do not depend on the loop variables. That is, in general a call to a `pure` function can be elided when unnecessary or only executed once instead of many times. As far as I know, no such optimization is, today, applied to `const` functions. ^1 *One caveat I can think of is that in theory one could used `Option&lt;SideEffectOnDrop&gt;` as an argument to a `const` function, with the understanding that the value can only be `None` at compile-time, and therefore an otherwise `const` function could have an observable effect when called with a non-const argument... I am not sure this will ever happen in Rust, though.*
There exists no functionality for marking functions pure in rust. While there's some need, most of it is already covered by Rust's type system and mutability rules. I mean, Rust prevents _shared mutability_. This allows it to have both safe parallelizing and efficient mutations when cloning/copying data would be inefficient. There isn't a way to prevent access to thread_local variables, but all access is constrained behind interfaces which ensure safe access. Rust provide a guarantee that no variable can be accessed mutably twice at the same time, and still lets people use thread locals and globals for caching, logging, or other appropriate tasks. If you're concerned with parallelism, do we really need pure functions in order to be safe? We have `Send` and `Sync` traits to guarantee only synchronized or immutable data is shared between threads, and globals are only ever accessible behind appropriate locks. I guess I'm trying to say: Rust provides a lot of the benefits of pure functions without introducing purity, and while we don't have purity, we do have safe concurrency.
You could do most of this with the code at the end of the main Rust book...
Huh wierd, on the rtmp server side the logs look right although the timings seem small, making me wonder if OBS is actually sending real video through (I would expect your laptop isn't getting that much higher CPU performance than my ryzen 5 1600X). I have my OBS setup with the defaults except for a key frame interval set at 2 and bitrate of 3500kbps. I also have it playing 1080p 60fps standard big buck bunny in a loop as the video.
I doubt there's much demand for it. It's not like it's difficult to pay attention and not mutate things, especially in Rust.
clippy isn’t technically stdlib, but it is unfortunately undtable and I don’t see a more prominent Rust linter around as an alternative
I too could always be wrong. In fact, I have heard it argued that I always am. So there's that.
I had not thought about that. Just gave it a shot. The good news is the performance timings are much much better (~90ms of work every 10 seconds), but the issue still persists.
https://github.com/withoutboats/failure_derive/issues/3 is the open for this.
Hm, wonder how you missed it: https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html#method.remove
The danger isn't that nightly is broken; we test every single PR before it lands. The danger is that the features may completely change, so upgrading nightly may break your code. If that's a problem is only something you can answer for yourself.
Can you give an example of where you would want to use this specifier?
I'll be cutting a new release of https://crates.io/crates/simple-server in the next few days.
In my experience, anyone who uses the phrases, "God's Work" or "God Fearing" isn't.
I think I have OBS set up to output a lower stream quality and at 30fps, might explain the lower timings. If I can figure out how to get vlc to read the stream to experience the bug, I might be able to help debug networking. I have next to no video streaming knowledge, but I do have some experience with tokio and mio networking.
There is work going on to get it to stable, but unfortunately our approach has revealed organizational and technical problems that we first must address before we can start riding the trains to stable. That said, from clippy side we're very ready to no longer having to chase nightly... :-)
I want to format a floating-point number as follows: (a) scientific notation is never used, (b) I specify a maximum number of digits after the decimal point, and (c) there are no insignificant trailing zeros after the decimal point. For example * 1.0/3.0 formatted to 3 fractional digits = "0.333" * 1.0/3.0e10 formatted to 3 fractional digits = "0.000" * 1.0/2.0 formatted to 3 fractional digits = "0.5" Any way to do this with the standard formatting descriptions?
It works on linux, macos and windows.
Hmm, this seems like the best one. Thanks! Why it doesn't support closure as a handler?
No problem! If you give it a shot, please file bugs if anything is weird! There's some important PRs I need to get in this next release.
I just realized I"m on VLC 3.0. Maybe that's the reason it doesn't poo poo the metadata for me but does for you (looks like you are on 2.2.6).
Librespot is really cool, thanks. Any idea is there, or is anybody working on, a CLI/TUI client, so I wouldn't have to use open.spotify.com?
Maybe faster. You'd have a AOT compiled function in some low level IL with some "holes" for known specialization points. So at bare minimum you'd just have to fill those in. But you'd probably want to run a few optimization passes afterwards too (but probably not all of them.. all the IL you're dealing with has already been optimized to some extent at this point). Oh, and of course the first time you call it you'd just run the generic AOT compiled version (build the specialized one in the background and swap in when done). 
I'm the author of Spotifyd. Spotifyd is, as you say, a shim around librespot. The version of librespot is generally not outdated, though. Librespot has, at least historically, focused on building a library based on reverse engineering of the Spotify protocols. Plietar encouraged users to build more featureful applications using the librespot library. This is what spotifyd does. It provides the features I expect from a Spotify client in the spirit of MPD: * Has a config file * Daemonizes * Writes to system log * PID-file * D-Bus MPRIS All features that were out of scope for the librespot project, otherwise I would have contributed them back.
The closure you want is `sandbox::cannoli_mods::cast::import_module::_$u7b$$u7b$closure$u7d$$u7d$::hcf5e7392232839e8`. The `+0x165d` is an offset within that closure. The instruction at `100024954` is a jump (je) to offset `0x165d`. The target address of that jump is `100024ecd`, so that's the address you should be running addr2line on. A more natural way to find the address is to use nm to find the start address of the closure and then add the offset, since that doesn't rely on there being a jump to the offset you want. However, both those addresses are within the same closure so if `100024954` didn't work then I'm doubtful that `100024ecd` will. The way you ran addr2line should have given some information, but you will also want the `-f` and `-i` options to display inline function information. If you run `objdump -S` on the executable, does it display any source information for the closure? 
a parallel high order function with the implication that the invocations will be order independent, so they may be re-ordered. requiring a truly pure lambda makes enforces this constraint, rather than having it as a note in the documentation 
You can build a client using the [Spotify Connect API](https://developer.spotify.com/web-api/web-api-connect-endpoint-reference/) quite easily. There is the excellent [rspotify](https://github.com/samrayleung/rspotify) library for talking to it from Rust. There are also cli clients that can talk to the official spotify client over D-Bus MPRIS such as [sp](https://gist.github.com/wandernauta/6800547) that should work with spotifyd as well with minimal modifications (probably just s/Spotify/Spotifyd/ for the destination).
The official Spotify app forLinux supports MPRIS media controls, and there's probably a way to control media apps that support MPRIS using command line tools.
Additionally, [wasm-bindgen](https://github.com/alexcrichton/wasm-bindgen) appears convenient for JS interop, and there's a [repository](https://github.com/rust-lang-nursery/rust-wasm) dedicated to coordinating rust-wasm efforts, which includes the beginnings of a [book](https://rust-lang-nursery.github.io/rust-wasm/).
Thanks that sounds awesome 
How well does GTK work on Windows and can I use the Adapta GTK theme on Windows?
This seems promising, although unmaintained as of recently: https://github.com/budkin/jam
Then a `Data&lt;String&gt;` would only be usable with visitors that produce strings, which defeats the point of the pattern, which is to separate the data from the visitors that could be applied to it.
That works, but it smells a bit because then `StringVisitor` would have to be constructed with a dummy `out` before being applied, and there's no static guarantee that `self.out` will be assigned by the `visit_*` methods.
Hm- I might have to try using it again! I do like using hyper as a client, but I found myself writing a lot of boilerplate when using the server side (at least compared to rocket).
Definitely, but it's the best I currently know of. You could have `out` be a `Option&lt;String&gt;` and use `None` as a dummy value (and `.take().unwrap()` to remove it) which lets you use types that don't have such natural dummy values as "", and gives you the runtime guarantee that you only use any one return value once, but not the guarantee that everything returns a return value unless you use them all. 
I’m addressing issues on [luminance](https://github.com/phaazon/luminance-rs/issues/54) and bringing examples into [luminance-samples](https://github.com/phaazon/luminance-samples-rs) so that I can blog about it and have a solid set of “start your applications quickly”. Also, I’m working on a new demoscene production that I’ll release in weeks or months – it’ll be my third release with [spectra](https://github.com/phaazon/spectra). Containing things like *volumetric raymarching* (participation media), *raycasting*, *pbr*, *text overlays* and maybe some crazy things I’ve been wanting to do for a while. :)
In my graphics program, I have a large buffer that is made and filled once every frame. This buffer usually stays the same size between frames. Should I drop the buffer between frames and start a new Vec::with_capacity() every time, or should the same buffer be used for several frames and just overwritten? I don't know about the performance impact when using Rust. Also, I have a large ImageBuffer from the image crate, and I don't know about it either.
Does the script at the beginning use some feature of ripgrep unavailable in standard grep? It strikes my eyes as a big assumption that everyone knows that rg is an alias for ripgrep, and what the syntax is. It's just a nitpick, but if the point was to inform the audience how this list was compiled, it may have been better to avoid "external dependencies" in the lingo.
It seems there are at least two: it says method is `GET`, while I'm pretty sure, it's `POST` and the body is all zeroes. I'll file proper issue tomorrow.
Try [actix-web](https://github.com/actix/actix-web) It is build on top of actix actor library, so it is easy to handle messages from uds and manage http server. Also it is easy to combine sync and async code. Actix web is fast.
Out of the whole compiler stack, how can I force just `libsyntax` to build in debug mode? Not just turning on debuginfo, the inlining in release mode is too aggressive to effectively step through in a debugger.
Not sure if it will help, but on my machine: cargo-profiler (cargo profiler callgrind --release) outputs: 155,305,216 (62.7%) ???:rml_rtmp::chunk_io::deserializer::ChunkDeserializer 41,591,175 (16.8%) ???:__memcpy_avx_unaligned_erms 24,568,679 (9.9%) ???:__memset_avx2_erms 1,511,886 (0.6%) ???:mio_rtmp_server VLC 3.0.1-0-gec0f700fcc outputs: [mov,mp4,m4a,3gp,3g2,mj2 @ 0x7fd500001940] could not find corresponding trex [mov,mp4,m4a,3gp,3g2,mj2 @ 0x7fd500001940] error reading header [00007fd538034b30] avio stream error: Failed to open rtmp://localhost/live/test: Input/output error
You should typically retain the allocation, not necessarily for the allocator's sake because it's usually pretty good about repeated frees and allocs of the same size, but to avoid reinitializing the buffer every time.
Basically a bot which takes a bunch of things from twitter, wordpress and so on and posts them to a subreddit. It seems like the pre-existing packages for interfacing with REST APIs are sort of broken by design in the sense that they usually embed Hyper as a dependency (which in turn depends on openssl-sys) - as soon as they stop being updated they become incompatible with everything else because you can't transitively depend on different versions of bindings to the same binary which is, for this kind of integration problem, an issue to say the least. It's frustrating because on their own, these kinds of libraries are actually very convenient to use but not being able to integrate them easily vastly diminishes their usefulness. I was considering solving this problem by splitting the project into different service applications with those mutually exclusive libraries in them and having them communicate over TCP or HTTP but that has far too much overhead for a part-time project like this - both in terms of run-time and development overhead. So currently I'm in the process of ripping out the models and auth logic of some of these libraries so that they can be used together in the same project in such a way that Hyper is always the direct dependency of my application. Wish me luck!
I have an enum using the [plain_enum](https://docs.rs/plain_enum/0.4.0/plain_enum/) crate which I want to be able to use as an index into arrays of the proper size. What's most strange to me is the interaction with E0210 (must involve local type) impl ops::Index&lt;Player&gt; for [u32;MAX_SIDES]{ is allowed, but impl &lt;T&gt; ops::Index&lt;Player&gt; for [T;MAX_SIDES]{ Is not. Why is this?
&gt;So make your function return failure::Error and it'll Just Work. You mean `Result&lt;T, failure::Error&gt;` right?
This might help a bit with understanding how imports/modules work: https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/
Appreciate the run. I did not know about the cargo-profiler package, that's neat and good to know thanks! I'm confused on why vlc is having trouble for everyone else. If you get a minute would you mind pulling the latest and running `cargo run --release -- --log-io`, and then send me the files produced in the logs folder? I have an app (my old elixir debugging tools) that can analyze the i/o traffic and and may help show me whats going on.
Hey, good article :) reminds me of when we did Lambda Calculus in my compiler class The CSS looks good in my mobile chrome, but it's not resizing well in the Relay for Reddit browser. I'm not sure why, but I figured you would like to know.
* [**rlsl**](https://github.com/MaikKlein/rlsl) * [**rspirv**](https://github.com/google/rspirv) * [**inspirv-rust**](https://github.com/msiglreith/inspirv-rust) (archived)
There is no CSS... I just wrote it in markdown and rendered it with Pandoc. It'll probably render better [here](https://github.com/shingtaklam1324/number-theory-rust/blob/master/index.md)
Fun to see my crates being used to build stuff :-) If I may ask, is this something you do on your spare time or is it something you do for a living (i e, to integrate into some commercial product)? Also, what is the reason MPRIS requires nightly?
Instead of using `self.out` you could have the method return a `Box&lt;Any&gt;`, and then downcasting it to a string, i e: trait Data { fn accept(&amp;mut self, visitor: &amp;mut Visitor) -&gt; Box&lt;Any&gt;; } That smells too because of the overhead for the extra allocation and the downcasting, as well as that you have to uphold the guarantee that `visit_a` never returns something else than a `Box&lt;String&gt;`, but it might or might not be a problem in your case. But yeah, it's a bit annoying that Rust does not support this in a better way. 
Considering the context of the post, it would be more surprising if many didn’t know the rg alias or syntax.
Hmm, unfortunately `objdumb -S` isn't showing me any more information. I noticed on Instruments that it showed my filename and said it couldn't find the file. So I believe that it _can_ bring up the code but I just need to figure out how to tell it where the source code directory is. I'm going to look into that a bit more. I'm just not having any luck with `objdump` and `addr2line` for some reason. 
Sweet. So wasm-bindgen and stdweb does more or less the same thing, right?
Looking forward to a very long FCP section in TWIR this week! 
Sounds like https://github.com/steveklabnik/simple-server/issues/83, gah! that has an associated PR. If I have wifi on this train, I'll be doing it today, but if I don't, it's gonna be till tomorrow.
stdweb does more than wasm-bindgen, and even the parts they do the same, they currently do very differently. This is all super cutting edge, so everyone's kinda figuring it all out!
Thank you so much for your help. I wasn't able to get this to work out but I really appreciate your comments! I was able to access the source code in XCode's Instruments though! There was a small red icon that asked to manually locate the source file, it then let me select the file I needed and brought up the proper code!
It's simple, not necessarily brief.
When found in a pattern, `&amp;_` matches a reference to a value. So when you bind to its right-hand side, you bind to the value itself. This is how destructuring matches work.
THANK YOU VERY MUCH! Apparently I added the [feature(nll)] attribute at the wrong file, and now it is running fine. I almost stopped learning rust because of this problem. Again, thanks!
Want to elaborate?
Glad you got it working. Do you know where it was trying to look for the file? Maybe there's something we need to fix in the DWARF paths so that this just works.
 for &lt;pattern&gt; in list { ... } is equivalent to for elem in list { match elem { &lt;pattern&gt; =&gt; ... } } Also, suppose `&amp;x` as `x` wrapped within a "struct" `&amp;`: let y :i32 = 1; struct Foo(i32); match Foo(y) { Foo(x) =&gt; x, // x: i32 } match &amp;y { &amp;x =&gt; x, // x: i32 }
I'm not completely sure, when I hovered over the icon it said something like "File 'my_file.rs' could not be found", it gave no path so I assumed it was relative to the "working directory" that I specified in Instruments. Although, I changed the working directory to point to the same directory as the source file and it was still unable to locate the file. Maybe absolute paths would work better (if that's not how it's done already)?
I didn’t consider that, but the details of this code are not really important. I might as well have not included it and just kept the following sentence that describes it. There’s also a lie in this code: GitHub’s API only allows 60 unauthenticated requests per hour per IP address. So I’ve had to cut `rg`’s output in ~half and run the rest of the network requests from a server that has a different public IP address. But all of this is besides the point of that already-long post, so I didn’t include it.
Virtual memory hacks (mmap, VirtualAlloc, etc).
Rust HashMaps may have fast iteration compared to noncontinuous hashmap implementation (like e.g. Java's), but still have to iterate over holes in the values array. Use [indexmap](https://crates.io/crates/indexmap) if you iterate a lot, it stores the values compactly, and so iterates as fast as `Vec`, which is *very* hard to beat.
So, by the start of the 1.27 cycle (end of this month), we should have a lot of merged stabilization proposals. If people send lots of stabilization PRs next month, 1.27 is going to be an awesome release! The things I'm most excited of (or rather, feeling the dire need for) are `TryFrom`, `flatten` and `transpose`, though; still not ripe for stabilization. Maybe for 1.28 or 1.29?
That looks like some debugging or profiling feature of the game. I can't find anything about that on Google, probably because of the confusion that you also made. So.. see /r/playrust for the Rust game. This subreddit is about the Rust programming language, which can also be used in games :D.
Cool! Is the heuristic complicated? I think the efficiency of Huffman depends a lot on it. I mean, in games where every move would be picked at random Huffman compression the data would look like noise, and it wouldn't compress well. So I guess you need a heuristic were most likely moves would have a low index. This would already compress well without Huffman compression if you have an efficient encoding for integers of variable size, so most of the magic would be in the heuristic. Heuristics were likely moves have low index in the ordering have some cool information. If the index of the move is high, that means that the move is unexpected (which can mean either a very good move or a very bad move). Can you give some more information about the heuristic? Did you come up with it yourself? :)
I've removed your post, as it doesn't relate to the Rust programming language at all. Please repost at /r/playrust, the official Rust game subreddit.
&gt; [...] isn't. isn't what?
I'd still like to know why the [u32;] array was allowed, but if anyone's wondering I solved my problem by making a local copy of plain_enum and implementing the things I wanted into the EnumMap struct that it generates, since that uses a [T;ENUM::SIZE] backing anyway.
This is actually endianness-dependent, so you'll end up with differing behavior between x86 and, e.g, ARM. x86 is little-endian, so the least-significant byte gets the lowest memory address. That's why your `higher word` is apparently coming second. If you want your code to be portable you need to convert to a specific endianness before you do your manipulations or write two versions of your conversion covering both endiannesses and switch them with `#[cfg]`. You can do this without external code as the stdlib provides conversions, but it requires a detour through `u64` since `f64` doesn't have them: let (lower_word, higher_word) = unsafe { let temp = transmute::&lt;f64, u64&gt;(0.2); // we use little-endian here for best perf on x86 // as the conversion is a no-op; // on big-endian platforms the bytes are swapped let (lo, hi) = transmute::&lt;u64, (u32, i32)&gt;(temp.to_le()); // convert back to platform endianness for correctness // again a no-op if it's the same (u32::from_le(lo), i32::from_le(hi)) }; The code is arguably more readable with the [byteorder](https://crates.io/crates/byteorder) crate: use byteorder::{LittleEndian, ByteOrder}; let mut buf = [0u8; 8]; LittleEndian::write_f64(&amp;mut buf, 2.0); let lower_word = LittleEndian::read_u32(&amp;buf[..4]); let higher_word = LittleEndian::read_i32(&amp;buf[..4]);
I never use sum because of this issue I always just write the fold. I've seen this asked before and explained but regardless of the reason its just unergonomic and a pain in the backside.
Actually, why doesn't putting the `T` behind a `Box` work? trait Data { fn accept&lt;T: ?Sized&gt;(&amp;mut self, visitor: &amp;mut Visitor&lt;T&gt;) -&gt; Box&lt;T&gt;; } trait Visitor&lt;T: ?Sized&gt; { fn visit_a(&amp;mut self, a: &amp;DataA) -&gt; Box&lt;T&gt;; fn visit_b(&amp;mut self, b: &amp;DataB) -&gt; Box&lt;T&gt;; } Rust should only need to generate one copy of the `accept` method here, because an unwrapped `T` can't participate in the stack layout (since it is `?Sized`). The `T` would effectively be erased. Or maybe it needs to generate two copies, one where `T` is a struct (`Box` is a normal pointer) and another where `T` is a slice or trait object (`Box` is a fat pointer). Still, why can't Rust generate two versions of this function and stick them in the vtable?
Try IRC at channel #rust-beginners or the Discord. I got some great advice on how to deal with the borrowchecker there!
I published a write-up this week: https://lichess.org/blog/Wqa7GiAAAOIpBLoY/developer-update-275-improved-game-compression tl;dr: We use (1) promotions (2) captures (3) negative piece value if target square defended by pawn (4) piece-square table. We tuned a linear combination of these and some other candidates with gradient descent (SPSA), but for now settled for these four in a strict order of precedence. Experiments and tuning were mostly [done in Rust](https://github.com/niklasf/rust-pgn-reader/blob/a7448ade512888946eb3ce39bdc4a29e80b4d697/examples/compression.rs#L91-L97), the [implementation for production](https://github.com/lichess-org/compression) is in Java. It's ~5x slower, but runs on the JVM like the rest of the site (which is written in Scala).
Would it be possible to have a [custom attribute](https://github.com/rust-lang/rfcs/blob/master/text/1566-proc-macros.md) that marked a function as pure and 🤞 if that attribute makes it down to LLVM for a [custom optimizer pass](http://llvm.org/docs/WritingAnLLVMPass.html). Maybe your custom attribute macro could just mangle the name with `__dobkerapure_` ?
Ok. So my guess was correct that it is endian-ness dependent. I ended up writing a small macro and using cfg to hide the implementation details.
Hmm sorry, I was off by one. Beta **1.26** is cut in ~12 days. So yes, most of these FCPs will hopefully make it into 1.27.
The next beta will be 1.26, doesn't it? Since the current nightly is 1.26. So the 1.27 beta will be cut in the middle of May, and there's the 12 days plus a full cycle's worth of time for that.
Should we know any thing about ssh to follow the tutorial?
Yep, 100% agreed. The point was to get it working first then optimize later, as making that not allocate memory will require some complex lifetime management. That being said just because it allocates memory doesn't immediately mean performance is bad and my measurements show that performance is way more than acceptable as is, which is why I was confused.
Intro section: &gt; When I built Finda, I wanted it to be fast — specifically, to respond to all user input within 16 milliseconds. &gt; Given this goal, you might be surprised to learn that Finda is built with Electron, a framework that’s often decried for being the opposite of fast. &gt; In this article, I’ll explain how Finda uses Rust to leverage Electron’s strengths (easy packaging, access to complex OS-specific APIs, the visual capabilities of the browser) while minimizing its downsides of unpredictable latency and memory usage. Kevin, if you see this post and are in the mood to answer questions, I'm really curious about the memory usage of this app. I have full confidence in Rust to keep memory usage down, but I'm curious about Electron's usage in this kind of setup.
Why is `T` on your visitor trait a generic parameter instead of an associated type?
How could we help? :)
Still waiting for an idiomatic Qt bindings...
It could be either. It doesn't make a difference to the problem.
In the side-bar: &gt; The Rust Programming Language &gt; &gt; A place for all things related to [the Rust programming language](https://www.rust-lang.org/), an open-source systems programming language that emphasizes zero-overhead memory safety, fearless concurrency, and blazing speed.
Is there any Windows IDE that supports debugging?
 &gt; Still, why can't Rust generate one or two versions of this function and stick them in the vtable? The function is still going to be monomorphized based on `T` because that's what the function declaration says. I'm not going to defend Rust here because I think we could do better w r t trait objects. It's just the way things work today.
Nice write up. Lots of platform-specific problems. I've also noticed that platform-specific code for foreign platforms doesn't get much compile-checking, making it hard to check this code *actually works* on the intended platforms (yes, this is what CI is for, no, setting up checks for all intended targets isn't easy, especially when some of those targets aren't even stable or easy to set-up).
Nope, that shouldn't be necessary I think. But it's also not really a tutorial. More of a "let's build this thing together", so we get pretty deep into the weeds of async implementation :) Happy to answer questions you come across while watching though!
I am a bit confused cause the authors own analysis shows that by far the most time is spent in rendering the results, so i am not sure why effort was spent on (re)-writing the part that takes one ms into rust. That is unless using rust was literally a 10x speed-up over JS. It seems to me like work should rather be spent on optimizing the rendering, maybe by not utilizing a full blown react stack with a virtual dom and diffing on top of a fully generic browser engine containing another dom, an xml-parser and cascading style sheets.
Thanks! I'm using xmonad as my window manager, but it's virtually indistinguishable from other tiling wms given that I've turned off all window decorations. The bar at the bottom is polybar, which I've been super happy with! I'm also using the fish shell. My configuration files are probably the place to start if you want to reproduce: https://github.com/jonhoo/configs. They're not super well organized, but if you run into issues let me know. As for editor, it's actually neovim with fzf, lightline, and the neovim-completion-manager + rls :) Font is Noto if I remember correctly (on my phone, so check the configs) and the atelier dune color scheme everywhere.
Thanks so much, I'm totally gonna try all of that out! Your autocompletion actually seems to work way better than mine, I'm currently on vim 8.0 with vim-lsp, but it has a few problems. As for fish, all of my colleagues are using it, but I don't like how it has its own bash flavor, I like a lot of the features it offers but they are relatively easy to get in zsh with plugins. One last question though, is the font on polybar also Noto? It looks a little different to me, but I might be wrong. Thanks again though, I'll let you know how it goes! I'm running Arch so it shouldn't be too difficult to try out your setup =)
This sub is about the programming language for FEARLESS CONCURRENCY. You probably want the game sub, /r/rust-game
Also I feel like the key criticism of electron apps is generally that they're resource intensive, no that they're slow
Presumably the part that takes 1ms would have taken far more than 1ms if it were written in Javascript instead. I also got the impression that that part was never written in anything *but* Rust, and the Electron part was added later.
This is a really helpful article - I was thinking about prototyping a reboot of one of my old apps in a similar Rust + Electron setup, and seeing how the interop works makes me really want to give it a shot!
The data can implement `Data&lt;T&gt;` for all `T`. The code which actually calls `accept` *must* know the concrete type of `T` anyway, because it gets that back as its result.
Ah, I was missing the separate formatting syntax for pattern matching. I guess that also explains why you also can't specify the types of them either then. e.g. `for x:u32 in list`.
Quite blind suggestion: try to print the packet timestamp, when it is actually sent and possibly when it is received. From what you are saying it looks like you are either pausing before sending the next packet. vlc provides quite a bit of verbose information if you run it with -vvv that might give you some more hints if the pause does not exist and there is an issue in how you compute the timestamps.
You still want to be able to create order-independent non-pure functions (eg. cached functions). This is currently possible, and I think this is sufficiently noisy (eg. you need mutexes, arc, etc.) that it seems fairly unlikely to do so by mistake.
Also, Electron package size size means your app size is 50+Mb even if the actual app is tiny.
Thanks for letting me know! Will make a new attempt now.
Are the problems explained somewhere? 
I'm sure you'll be able to use servo as a library eventually.
You can collect an iterator of `char` directly to a string: let string = "hello".chars().collect::&lt;String&gt;(); If you already have a string that you want to add characters to, you can use `.extend()`: let mut string = String::new(); string.extend("hello".chars());
Best moment starts at 3:19:20
&gt;Error message doesn't accurately reflect the mistake made. This is very true, and all the "inferred type" errors with numbers could seriously be improved, but i think that they are notoriously bad and also a terrible example to pick if you want to suggest a *general* improvement to rust error messages. They aren't ones you run into a lot of the time, but they should definitely on the individual case be fixed. &gt;I'm an old C++ coder, and the only thing I care about now in my C++ errors is the file and line number. Once you have full rust knowledge I would also assume you get to that level. But that information is still obscurely hidden in the middle. I can say that I do not agree with this much at all. Most of rust's compile time errors when you are used to rust are usually trait/generic related or lifetime related. In both of those cases the detailed error messages and expansive information are very helpful. A line number and file doesn't help the fact that a trait isn't in scope or that you are referring to a value that doesn't live long enough because you are borrowing from a temporary value.
You can install the same visualizers for the Visual Studio debugger, but they go in `&lt;Visual Studio install dir&gt;\Common7\Packages\Debugger\Visualizers`.
It reminds me of a few guys who wanted to make hydrogen a more popular energy source by building a hydrogen powered shotgun. 
Thanks, for the idea. I added a section on Elm to the front page.
Just a quick note to say that the videos are great and that it's fantastic to see people in the community creating more material on "intermediate" rust. Looking forward to seeing what else 2018 will bring on this front in the Rust community. I'm a self-taught / hobbiest programmer. YouTube videos (and of course great material like the Rust book) have been nearly 100% of my education (no books, no course, no one to really ask questions of); so these types of efforts are extremely helpful!
All of the rust error messages seem to be whatever the first thought was of the person writing the error. So some of them are better than others. Take the two errors mentioned on this page: https://doc.rust-lang.org/book/second-edition/ch10-01-syntax.html The first one: error[E0369]: binary operation `&gt;` cannot be applied to type `T` | 5 | if item &gt; largest { | ^^^^ | note: an implementation of `std::cmp::PartialOrd` might be missing for `T` This is a readable and simple error message, with the 'hint' portion being the inferred knowledge part. This is a much better error. error[E0308]: mismatched types --&gt; | 7 | let wont_work = Point { x: 5, y: 4.0 }; | ^^^ expected integral variable, found floating-point variable | = note: expected type `{integer}` = note: found type `{float}` This is a type error mixing integer and floats, and it is almost ideal to what I would want for the operator error in OP. I'm not opposed to more verbosity when the error message requires it. E.g. borrowing issues where you need to points of reference to see where conflicts occurred do require two lines. There are some errors you get in C++, like template issues, where a multi-line breakdown is helpful as well. But I'm more referring to the simple mistakes, missed ; etc, where everybody makes those, you should be able to identify that very fast to fix your typos so you can move on with life.
Ask and you shall receive: https://github.com/marcelveldt/plugin.audio.spotify
Haha, yeah, that was pretty great! I'm *so* happy I realized that I needed `-la`, otherwise I would probably have spent forever trying to figure out why I wasn't getting any output ^_^
"wait, kernel roulette, like... russian roulette? \*clicks\*"
I'm glad to hear you enjoy them! If there are particular things you'd like to see covered, please do let me know :D I'd also encourage supporting the people who do these kinds of things in whatever way you can, whether it's retweeting their announcements or supporting them on Patreon. Hearing that people are excited about what you're doing, and willing to help share it, is part of what makes it fun to do these :)
BTW, if you're using rustc 1.20.0 or later, you don't even need unsafe code: let hi_lo = 0.2f64.to_bits(); let hi = (hi_lo &gt;&gt; 32) as i32; let lo = hi_lo as u32;
Sure, but then *everything* that produces or passes around a `Data` has to be parameterized on `T`.
&gt; Or just a headless Electron runtime that servers the web pages to be viewed IN MY REGULAR DAMN BROWSER. This is LITERALLY what Electron is designed to avoid. People don't like webapps. People like native apps and normal webpages. If you have a webpage that needs a lot of non-browser-like functionality then users prefer it to be a native app. 
You could read the other replies.
&gt; IMO rustc needs a single-line error message format out of the box. On nightly there's `--error-format=short -Zunstable-options`. The [original issue](https://github.com/rust-lang/rust/issues/42653) was closed though and it doesn't look like there's a tracking/stabilization issue for it yet.
Use an enum type that implements From&lt;&gt; for all error types that you want to handle. Afaik, ? and try! automatically try to convert when they ‘throw’
This is a poor example, a straw man argument. The first, easiest thing would be to guess that you can't multiply int with float, which is easy to verify and fix. &gt; you might think that the fix to the problem is that you need to implement std::ops::Mul&lt;float&gt; for integer * float You might think a lot of things, but you're assuming they only think of that one thing, which makes this pretty contrived.
Why are you commiting binaries to github? Wtf?
&gt; or that ? is a very niche operator Well, yes, it doesn't magically do everything you want it to do.
50MB is tiny on modern systems: it’s half a percent of the RAM of the average laptop (8GB) It’s not even much greater than the size of the UHD artwork you need to bundle with modern apps. I agree that it’s a slightly hacks way to go about creating apps, and that it’s frustrating that apps sometimes differ slightly from standard behaviours. But there are plenty of Electron apps out there (Simplenote, Slack) that are far superior to natively implement alternatives. And Electron gives much more aesthetically pleasing results on Windows and Mac than GTK variants. 
0 P p0pp Pp p0 P0pppppppppppppppppppppppppppppp
50MB is the disk usage; RAM usage is in the 100s of MBs. That adds up _quick_ when I need memory free for LTO...
You should definitely try [failure](https://crates.io/crates/failure). It is pretty well described [here)(https://boats.gitlab.io/failure/custom-fail.html)
http://carol-nichols.com/2017/04/20/rust-profiling-with-dtrace-on-osx/ The above is a starting point
Rusky is correct --- I did an initial prototype with ClojureScript that actually had far more functionality (details here: https://kevinlynagh.com/datatron/). After showing a few folks, they were most excited about the fast search and window switching stuff, so I decided to cut the half-baked exploratory research features and just focus on that. The rewrite in Rust was partly for speed, but mostly because I'd never really done a proper project in Rust and wanted to see what it'd be like. = )
&gt; Well, yes, it doesn't magically do everything you want it to do. Was this sentence meant to be condescending? I don't expect the `?` operator to magically do everything. The purpose of this question is to figure out either how to set things up so `?` can be used more robustly or what other patterns exist for error handling.
Thanks. I've heard this crate mentioned a few times, but I've avoided looking into it. I think I better give it a look.
&gt; I'm an old C++ coder, and the only thing I care about now in my C++ errors is the file and line number. Once you have full rust knowledge I would also assume you get to that level. I agree that in many cases all the information I need from an error is *where* and I agree that the compiler should have a (stable) option to provide this, but I think it's generally the editor's job to filter this down for me. Even the most basic editors can highlight erroneous lines. e.g. Emacs can read rustc's output and highlight error lines without any plugins because it can recognize `path/to/file.rs:line`. With basic rust support editors can have an error list that gives you the one line explanation and summary. Because of those factors, I think it's right to have verbose errors by default.
The best way to answer this question (if you have a Mac) is to try out Finda for yourself: https://keminglabs.com/finda/ For me, on OS X 10.9.5 Finda is using about 140MB of RAM according to Activity Monitor. I have no idea how to break this down between Electron's rendering stuff vs. Finda's own threads and heap allocations. I keep everything besides icons in memory for performance reasons. For me, that's probably about 20k browser history results and perhaps 100k indexed files? I haven't implemented much in the way of live benchmarking/introspection capabilities (one downside of Rust, compared do doing things in JS where I'd be able to open up a terminal and query the data structures myself). Right now my focus is on the business side --- writing blog posts like this one and perhaps implementing some features that make the difference between people buying Finda and not (e.g., I'm looking into integrations with Sublime Text and IntelliJ). As fun as it'd be on a technical level to work on compressing the in-memory index or moving the rendering to the GPU or a non-Electron toolkit, I don't think that's going to move any more copies of Finda itself. =)
A single 12mp JPEG image off an iPhone, uncompressed into RAM for display/processing, occupies almost 50MB on its own. Have a couple open (eg a Slack Channel full of images) and you’re easily in the 100s of MB. I think people spend too much time looking at the Activity Monitors instead of just considering how their system’s are working. There are lots of things that might be wrong with Electron, but on modern PCs, it is not hindering system performance through excessive RAM use. In comparison to the size of the data (uncompressed in RAM) that modern apps work with, Electron’s use is insignificant. 
You misinterpreted. The 50mb is the min binary download size for an electron app.
Looking at GNU ld's man page, that's not correct: &gt;On systems which support shared libraries, ld may also search for files other than libnamespec.a. Specifically, on ELF and SunOS systems, ld will search a directory for a library called libnamespec.so before searching for one called libnamespec.a. (By convention, a ".so" extension indicates a shared library.) Note that this behavior does not apply to :filename, which always specifies a file called filename. I do vaguely remember a situation where there were versioned versions of a .so but not a bare version so I had to symlink it to the bare .so. You could also try `#[link(name=":libv4l2.so.2", kind="dylib")]` - I wonder if rustc would mangle that.
&gt; That said, there is no fundamental reason why rust couldn't generate code for this even in the original case, the swift compiler is (I think) capable of it. The trick is to just pass in type information with the arguments that tells the code how to handle the T (size, align, pointers to every function that might be called). That makes sense to me. Is this something the language team is intent on fixing? I haven't seen it in any roadmap or anything like that, but it seems like a pretty severe limitation. I imagine this would block a lot of other OOP and FP patterns too. The code I was planning on writing in Rust will involve a lot of generics and dynamic dispatch. Some of it might be able to be replaced with ADTs but I don't really want to go down that path just to find a situation that can't and wish I had chosen Haskell or Ocaml instead.
Yeah I ripped out the `#[link]` directive and in my `build.rs` I did some ``` println!("cargo:rustc-link-lib=dylib=v4l2"); ``` which didn't work when I symlinked `libv4l2.so.0` to `libv4l2.so`
Did you mean to cherrypick what I said? &gt; I don't expect the ? operator to magically do everything. Then why are you claiming that a single operator is niche when it's no more niche than most/all other operators?
[The first edition of the rust book has a chapter on error handling](https://doc.rust-lang.org/book/first-edition/error-handling.html) which describes this the topic in detail. It is a bit older, so it uses the `try!` macro, which has the same effect as today's `?` operator.
If you don't care about what the original error is, you probably want to return `Box&lt;std::error::Error&gt;` - it implements `From` for any type implementing the `std::error::Error` trait, so most if not all errors can be returned using it. `failure::Error` is similar but provides some extra methods as well, and the ability to attack a stack trace.
If you want to append a `&amp;str` you'd be better off using `.push_str()`: let mut string = String::new(); string.push_str("hello");
I thought LLVM was able to compile IR to C, not exactly readable but C that performs the exact same thing as the rust version but able to compile to C. If llvm doesnt support it isn't there any decompiler good enough to allow cross-compilation?
Presumably the originating string was a strawman, but yes this is the more optimal approach in this specific case. I looked to see if `impl Extend&lt;char&gt; for String` was internally specialized for `str::Chars` but it doesn't appear to be, which is unfortunate.
&gt; Is this something the language team is intent on fixing? Not that I'm aware of. I'd probably have heard about it if it was on the short-medium term roadmap but I'm not an authority here.
Y'all really should look into [Sciter](http://www.sciter.com/). It's like Electron but the runtime weighs like 4-8mb and it uses a C API instead of Nodejs (and ofc there's [a rust crate](https://sciter-sdk.github.io/rust-sciter/doc/sciter/index.html)) I haven't tried it with Rust yet, but I've been having a blast using it for a C# program I'm writing. 
/u/ekuber has been collecting feedback for diagnostics at https://internals.rust-lang.org/t/compiler-diagnostics-improvement-wishlist/6886. I'm not sure if he regularly reads reddit.
I should add that given the amount of tasks and associated trust we give machine learning, it's not understandable how C++ with Python is accepted as good enough. Software in cars and traffic control must at the very least be safe against easy to defend attacks and best require formally verified implementations. I know innovation and iteration is valued a lot, but I'm scared to think how little one can trust the Tesla control code or centrally automated traffic control systems. Once we throw in machine learning, you don't even have a way to predict/verify. It's like an organism you know little about but just that it somehow produces acceptable output given certain input.
If `Tile::flood()` didn't take a &amp;Tile then this would be much easier. Something like this could work: https://play.rust-lang.org/?gist=aa6b1a51befa03a7c89427f3e8f888ea&amp;version=stable 
&gt; I don't know how much of a recognized problem it is See /u/ehuss post: &gt; /u/ekuber has been collecting feedback for diagnostics at https://internals.rust-lang.org/t/compiler-diagnostics-improvement-wishlist/6886. I'm not sure if he regularly reads reddit. So yes this is a recognized problem, and it is actively being worked on! Please give a copy of your valuable feedback there where the people who are working on the problem will be sure to see it.
How does it work?
cool. you could also add relm :). also i get 503 when i tried to access your website
Well, there is https://github.com/zserge/webview and we even have 2 crates with binding for it, native calls are supported, but the problem is the MSHTML engine. I hope they will add an option to just bundle gtk with Windows builds.
just curious, whats wrong with spotlight?
I think it has its own layout engine. There's a high level overview here. https://sciter.com/developers/engine-architecture/
Might be my computer, but to me vscode and atom are unusable due to terrible performance. I think an i5 ought to be enough to run those editors.
SIMD instructions.
It doesn't even rely on `hyper::Chunk`. I like to use `reffers::ARefs&lt;[u8]&gt;` instead, which lets you directly use mmaped regions.
Yes, his mistake was thinking 8GB is the average. It's a personal pet peeve of mine and I'm glad others feel the same.
I'm doing this right now with my project, [Turtl](https://turtlapp.com). Before it was a pure-js Desktop app (NWJS), but I recently split out the UI from the core logic and built [turtl/core-rs](https://github.com/turtl/core-rs) which embeds as a shared lib. Working really well so far. I've only really tested on Windows (gnu toolchain) but for my next trick I'm going to be automating builds for linux/windows/osx/android. Exciting stuff!
I use i3 laptop from 6 years ago for my daily laptop usage. No problem running vscode. Atom on the other hand is a huge mess.
this is very much intentional and by design. All ops in rust are implemented only on themselves. You can't multiply an f32 with an f64 either.
It's not even possible to implement it, is it? It would be an orphaned implementation (unless, of course, you implemented `integer`, `float` or `std::ops::Mul`, but that would make you the compiler or standard library author, so hardly a typical consumer of rustc).
If that's the case, I can't imagine what purpose it is supposed to serve.
Yeah, it's always that same argument that I'm supposed to accept even though everyone obviously edits text documents in web browsers all the time.
If what you are looking for is a pure text editor, then by all means don't use it. That's not what either of these tools is for.
Empirical evidence seems to suggest that developers benefit from having more than just line numbers and files. https://www.barik.net/archive/2017/03/01/170922/
Knowing nothing about rust, but something about imperative OO programming, I second number 2. An item probably shouldn’t know anything about it’s container. 
Fair enough. Thanks for the note.
Savage! :D
Take a look at error-chain: http://brson.github.io/2016/11/30/starting-with-error-chain It builds an error type for your crate and automatically implements conversions from other error types you use (you just need to list them) Failure is like another iteration on error handling in Rust. It seems cleaner, but I don't like that it defines another trait (even though I see that stdlib's Error trait unfortunately sucks). Anyway, if you don't want to bother with any of this, simply use Box&lt;Error&gt; as your error type everywhere. That's because all error types are automatically convertible to Box&lt;Error&gt; when you use the ? operator.
It's basically an extension of the enum/From thing the above guy mentioned. It's pretty smooth, but not always the most intuitive.
I agree, in that sense the error message could be smarter and check if the user actually can implement the trait or not.
OP, check out Github’s [releases](https://help.github.com/articles/creating-releases/) feature instead. Generally it’s best to avoid committing compiled binaries (although there are [extensions to avoid the negatives of large binary files](https://git-lfs.github.com/)).
Receiving specs from a friend and writing a program sounds like a fun way to experiment with rust, especially when it provides utility for musicians 🙏
You could also write format!("{}", 99) directly, but this would be probably way slower than just calling .to_string, because it has to go through the whole fmt::Arguments system. You could also say String::from() or .into(), which do the same.
For those that don't know what Permit A38 is: https://www.youtube.com/watch?v=GI5kwSap9Ug
So it's similar in that it has: - A scripting language that's not exactly JS?(seems it might have some features specific to it and isn't in sync with what you'd get in the browser or on Node) - CSS which is similar to the script language situation I think? Ditto for HTML markup So what you write for it, how portable is that outside of Sciter? Are you able to utilize much of the existing JS ecosystem? A quick google search it doesn't seem like React works, only Sciter's implementation of components to provide a similar offering. So they have their own engine to do all this rather than benefiting from large dev teams with current browser tech like Googles CEF that Electron uses. I guess it depends if you're ok with the trade off that involves. Personally I'm not sure what makes it better than Qt/QML then? Which has a similar JS inspired language and CSS styling support. [This](https://sciter.com/developers/for-web-programmers/) seems to touch on differences/compatibiliy, with JS(at the time of writing I guess ES5 compared to SciterScript) covered [here](https://sciter.com/docs/js-dart-tis.html). Hard to say how well modern web stacks can work on Sciter as they would Electron. I think React-Native probably works better when available? AFAIK Windows and macOS have support, that code also works on iOS and Android, Ubuntu had tried something in the past and iirc there have been efforts at working on GTK/Qt support in the past year too. That does assume you'll use React though. Curious how Sciter compares to GTK/Qt/QML, does it really work well with third party libs? Some of the language differences didn't seem like they would.
Honestly, I use a five year old Apple laptop for daily development, and it has 8GB of RAM. The Steam survey puts just 85% of machines at 8GB or more. All the IDEs I’ve worked with (IntelliJ, Xcode, occasionally Eclipse) use 100s of MB. There have been decent affordable machines with &gt;= 8GB on the market for the last four years, especially the second hand market. Anyone who bought a machine with less for development purposes made a mistake. And despite the downvotes I’ll stand by my comment: Electron is a perfectly adequate way of creating apps on modern machines. It’s not efficient and it’s not native, but it’s a great way of getting to market quickly. 
I'm doing (yet another) static site generator. So far it can take a directory with a config file, some markdown files and some templates and composite them into a site that works nicely with GitHub pages. There's also an embedded rocket server to allow sites to be tested locally. Next steps are to implement some form of Jinja-style templating. Thanks to the developers of the excellent pulldown-cmark and rocket crates.
Still working on knocking out [blockers to the stabilization of proc macros](https://github.com/rust-lang/rust/issues/38356). [One PR](https://github.com/rust-lang/rust/pull/48524) merged, [two](https://github.com/rust-lang/rust/pull/48465) [in-flight](https://github.com/rust-lang/rust/pull/49124). Having worked on this bit of the frontend for a little while now, I think I'm starting to enjoy it. It's not the most navigable (the macro expansion code in libsyntax is *really* dense and not that well documented... yet) but I like to think I'm starting to find my way around pretty well. In fact, I'm actually willing to mentor on any issues on this bit of the compiler. I've actually [found one](https://github.com/rust-lang/rust/issues/43988) that would serve as a pretty good introduction to some of the architectural concepts in the frontend but should be pretty easy to knock out with a little bit of guidance. Hit me up here or on the issue if you'd like to tackle it. 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/rust-lang/rust/pull/48465) - Previous text "two" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Yeah I tried to do the thing where you link each word to a different URL.
It would be cool to get something like syn and quote for the HIR off the ground.
If you just want to iterate over the result, you don't need to collect the result into a vector first. [Example](https://play.rust-lang.org/?gist=da058095037e14658b446688b93307cb&amp;version=stable) I'm curious though, if generally there is a nicer way to do simple parsing.
Sure, I won't disagree with you that machines with 8GB or more are accessible and "affordable" by certain metrics but I would caution you not to overestimate the average user's machine. The steam survey is what, 18.5 million users? Hardly representative of the entire population. That would still leave something like 2.75m machines at under 4 GB of RAM and that's for a segment of the population who by virtue of their interest (playing games) spend more time on the computer and are more exposed to technical concepts. The average user couldn't care less about RAM or anything like that. For example, just the other day someone was complaining to me that their 10 year old mac book air with 2GB (!) was starting to run slow and he was especially upset that the machine "only" lasted 10 years without major repairs. That same user recently bought a crappy all-in-one desktop/monitor for $200 new that has 4GB of RAM and is quite satisfied with it. I know of another user that has a 6 year old laptop with 4GB of RAM that they use every single day that only is recently considering replacing their laptop because everytime they plug it in to charge it literally short circuits everything. How about the office of about 50 people running 5 year old desktops with 4GB of RAM because they literally only use a browser and outlook. So yes electron is "fine" for "development purposes" or "modern machines" where the user is savvy but is an absolute disaster for the average user on a basic machine. I will happily discuss the technical merits and advantages of electron all day and I am a happy user of many electron apps but it is my pet peeve when electron proponents choose to ignore reality and dismiss the "average" user.
I tried this - servo is way too big, mostly due to the JS interaction, which can't be seperated from the core. Nevermind that the memory usage of servo is worse than with Electron. I recently tried to make a GUI framework [azul](https://github.com/maps4print/azul) for desktop development using webrender, but it'll take quite a while until it is production-ready. Meanwhile, you can use webview-rs [like this](https://github.com/fschutt/wtaskman), simply sending JSON back and forth between the system-native engine (MSIE / Safari / webkit2gtk) and Rust. This eliminates the binary bloat (50MB down to 800KB with webview) of Electron, but the memory usage is still around 90MB for a simple app. Azul takes ~25MB of RAM and 10MB of disk space, which is sort-of acceptable, with redraw times of 1 - 4 ms (fast enough for desktop apps, but too slow for games).
This is not a problem with Rust, but with your OS. If you want to build or develop with shared libraries, the libname.so symlink MUST be present. Using `-lv4l2` is the right way to set this up, as it will be portable across systems with and without shared libraries. The static library (`.a`) will only be used if the shared one (`.so`) is not present.
Good bot.
[Trying](https://i.imgur.com/LGAzRyY.png) to draw better - but still minimalistic - vector sprites for [Zemeroth](https://github.com/ozkriff/zemeroth) game.
This is what I (a relative Rust n00b) use and have had no problems with. I usually create an alias for my project like `type LaResult&lt;T&gt; = Result&lt;T, Box&lt;Error&gt;&gt;` (Name LaResult something in-line with your crate or even don't import the original Result type and name it Result. Then return LaResult&lt;SomeDesiredType&gt; from functions and use ? operator to automatically deal with errors inside.
I think a combination of hyper and tokio can do what you want (the one tokio_core couldn't).
[Automatization](github.com/omni-viral/chains) of execution synchronization for [gfx-hal](https://github.com/gfx-rs/gfx).
Handmade hero in rust off and on. Up to day 80.
I would just like to point out that what you're trying to do isn't possible in C++ either. ``` class Base { public: template &lt;typename R&gt; virtual T visit(Visitor&lt;R&gt;&amp; v); // error: template cannot be virtual }; ``` The reason is the way templates/generics work in C++ and Rust, through monomorphization at compile time. Java's type-erased generics work (to a point; because `void` isn't first-class, you need to have a dummy return, and of course you can't use any non-boxed primitives) because, in the end, the `visit` method compiles down to just returning `Object`. C#'s JIT-generics work because the necessary instantiations are generated at runtime, and virtual dispatch of generic methods is handled differently from non-generic methods. (Excellent description here: https://stackoverflow.com/questions/24350763/how-can-c-sharp-allow-virtual-generic-methods-where-c-cant-allow-virtual-temp ). And obviously dynamic languages like Python don't care what the return type is anyway.
I struggle to find a good description of the internals that's more then the quoted paragraph without going ahead and reading the source. There's something with tag bits in a presentation... From a glance, I don't see anything that isn't possible in Rust (note that, for example, `Option` compiles to "Null pointer or pointer" in many cases, so Vec&lt;Option&lt;T&gt;&gt; would be a feasible structure as a basis).
Here's a [slightly more in-depth summary](https://lwn.net/Articles/745073/) on LWN.
There was a backend, but it was removed years ago. 
🤔🤔🤔 so you are saying there's a chance It's a bummer tho. It would help alot while some platforms stay unsupported or unstable.
I'd say it's just an edge case that is not covered. Try and open an issue and see if someone will tackle it
The plural of anecdote isn't data. The [Steam survey](http://store.steampowered.com/hwsurvey) has 85% of users with &gt;= 8GB of RAM. The [Firefox survey](https://hardware.metrics.mozilla.com/) has 30% of users with &gt;= 8GB of RAM Even at &gt;= 4GB (&gt;= 60% according to Firefox), an Electron app like Visual Studio Code [uses &lt;250MB of RAM](https://blog.xinhong.me/post/sublime-text-vs-vscode-vs-atom-performance-dec-2016/) with many files open, accounting for less than 7% of total system memory. A half-dozen Electron apps would still leave 50% of RAM available for other tasks. There are bad Electron apps that use too much memory: however this does not mean that Electron is primarily to blame; neither does it mean that Electron apps are unsuitable for average machines. On that [same test I linked to earlier](https://blog.xinhong.me/post/sublime-text-vs-vscode-vs-atom-performance-dec-2016/), Atom -- also an Electron app -- used *twice* as much RAM for the same task. Clearly Electron isn't the reason for Atom's poor performance. 
There is nothing conceptually forbidding `const fn foo(x: &amp;mut i32) { *x += 5; }`, which definitely cannot be deduplicated or moved around arbitrarily. wrt the `SideEffectOnDrop` type, essentially this exact issue is being discussed in https://github.com/rust-lang/rfcs/pull/2238 (pointers to const fn)
What is the benefit of XArrays over `Vec&lt;Box&lt;T&gt;&gt;`, that is a heap-allocated array of pointers to (owned) objects of type T?
`Vec&lt;Box&lt;T&gt;&gt;` might reallocate when adding to it. A better base for comparison would be `Vec&lt;Option&lt;Box&lt;T&gt;&gt;&gt;` with a rather large initial set of items.
In that case it's actually better to have Vec&lt;Box&lt;T&gt;&gt; and create it with_capacity(), you will get the same result.
Interesting! If it’s open-source, is there a repo link?
&gt; Unlike a hash, it allows you to sensibly go to the next or previous entry in a cache-efficient manner. Ordermap/indexmap also lets you do that, you store the data in a dense buffer (possibly column-major) and hash into a sparse indexes array. Keying adds a small indirection, but you're saving memory (especially as your indexes array can be adaptive) so the end result in "hashmap" mode is generally a wash and iteration uses the dense buffer.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/iliekturtles/uom) - Previous text "uom" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
I like the tool:) I also looked into the implementation and found rpassword.I am looking for such a crate to work with ssh2👍
Why isn't shared Cargo `target-dir` the default? It's annoying that for each project the same gigabytes of dependencies have to be rebuilt from scratch.
Nice! This really seems to have some good potential. I didn't realize that the Rust compiler was so-well documented at this level.
The guide is a very recent, but very desired effort! It's been really awesome to see it take shape.
Username checks out
Everyone in comments (especially on HN) is shitting on your decision to take electron but I think it's of little consequence, they're just bikeshedding. Sure it takes more memory/disk but for a solo dev project, not having to learn multiple langauges/frameworks/quirks for each system is a huge time saver, you also get a unified look and feel across all the platforms, which IMO is nicer than a "native" look on each. Good on you! Looking forward to see how this project goes.
Over the past two months, I've been working on a side-project that I'm thrilled to publish now: **Hello Rust! - A show about the Rust programming language.** Would be very happy for constructive feedback. It is directed at people, that finished the Book and want to learn some intermediate Rust concepts. Not sure what I will cover next, but you can find the show notes here: https://github.com/hello-rust/show Also, I've created this fancy website (mostly because of the domain name): http://hello-rust.show/ If you like the show, here's how to stay in touch: Retweet: https://twitter.com/matthiasendler/status/975450790998487040. Follow: https://twitter.com/hellorustshow Subscribe: https://www.youtube.com/channel/UCZ_EWaQZCZuGGfnuqUoHujw And if you want to be super awesome, become a patron at https://www.patreon.com/hellorust. I will donate 50% of the money to the people behind Open Source. The first batch will go to the family of the creator of the Nunito font. Read his tragic story [here](http://sansoxygen.com/). The other 50% will go to getting better video equipment. Namely, a proper video cutting tool like Adobe Premiere. (Right now I shoot with iMovie, which is... inconvenient).
Thanks, I'll check that out. I'm new to github as well. Just wanted these to be easily available and usable for average users. I think only a minority of the population even knows what the compiler is.
Indeed, it was very motivational :)
I suspect this is because having the `map` closure return `()` is perfectly valid. That error, from what I recall, only triggers in contexts where returning `()` cannot possibly be right. Or, to put it another way: is the problem that the closure is returning the wrong type, or is it that it's returning the correct type that's missing a trait implementation? The compiler has no way of knowing in general.
I don't think there is any compelling reason beyond a vague sense of "this might not work properly" I've seen in the past, and no one having gone in and implemented it. Wasting space is (rarely) a priority when there are larger concerns in play. There are actually a few ways in which Cargo is... *less than frugal* with your disk space. Like how the index cache contains the entire history of every crate's publication (for a messy reason to do with git), or how various crates bundle the entire source code of other C libraries in their entirety for every version, even minor updates. Or how there's no command to clean up old, unused crate archives. Or how it extracts all those nicely compressed crate archives to uncompressed folders because the compiler can't read said archives... :P
I don't, since (other than mrustc, which I've never used) this doesn't actually exist yet. It should be reliable, as that's the point. It'd be a bug if it wasn't.
&gt; The steam survey is what, 18.5 million users? Hardly representative of the entire population. Actually, that amount of participation in a survey is huge, highly representative and orders of magnitude better than medical studies considered the gold standard of their respective fields. Considering 18,500,000 not a high enough number in a survey for _anything_ is, frankly, hilarious. However, you are dead on that the survey is not representative because it’s heavily biased towards gamers and techie types who are much more likely to have more RAM. 
I'm still working on a Rust PGP packet dumping library [pgpdump-rs](https://github.com/srct/pgpdump-rs) for my Rust PGP keyserver [sks-rs](https://github.com/srct/sks-rs).
Good bot
Note that `Vec&lt;Box&lt;T&gt;&gt;` is not cache-friendly - actual elements of type `T` can be allocated in very different places in memory (only pointers to them are stored contiguously), so you can't prefetch and process bigger slices of data at once - at every iteration you have to make a jump to a remote, possibly different each time, location to read the data.
Niiice, will try back home, thanks !
Don't put words in my mouth, please – I'm not looking for anything, and never said I was. Nor am I complaining, per se. All I said is that 100s of MBs of RAM **is** noticeable in my normal development cycle, which is an objective truth and not for someone else to correct. People pretending memory usage doesn't matter simply need to get out a little more – great, it doesn't matter for you, congratulations; it still matters for many people.
Still working on 2,3-trees. I did enough insertion exercises last week to write the actual code over the weekend, this week I'll probably add a bunch of tests to be sure the patterns I've found are correct. 
I'm mainly bothering that it wastes time. I've given up on saving space anyway. &gt; "this might not work properly" Do you mean that Cargo build system is maybe unsound? Shouldn't Rust developers focus on making it sound instead of recommending an inefficient setup that masks this problem? Is the soundness of Cargo is an explicit goal, wouldn't it be better to put it to test by making `target-dir` shared at least in the "use at your own risk" setups like nightly?
Right, so an array interface to a radix tree
I believe the concern was that Cargo/rustc might get confused if build artefacts from different compiler versions with different compile options are all jammed together in one place, given that it was never explicitly designed to cope with that. And it *would* probably go through nightly first... but someone would have to step up and implement it for that to happen. Which so far as I know, no one has.
https://play.rust-lang.org/?gist=289161c4c2318c9768ee6d5ba5921d4c&amp;version=undefined You were taking a shared reference to `subtree` instead of a unique one
I'm glad it is working :) May I volunteer you to provide the rtsp support for rust-av? :)
Making http://GitHub.com/anglegrinder faster and support more complex pipelines
Say I have a C program that calls a rust function. Is there any way I can pass a C-style higher-dimension array to the Rust function, e.g., in C I can write the following: void foo(int* bar, int rows, int cols) { int (*baz)[cols] = (int (*)[cols]) bar; //snip } or better still, void foo(int bar[cols], int rows, int cols) { //snip }
makes way more sense in rust than in C though... the C syntax is just yucky
Getting rust up and running on a nrf52840pdk board. So far I can get an led to turn on... but on the plus side I know the cortex-m and svd2rust stuff is working now.
Really nice! Great work! Looking forward to upcoming episodes!
&gt; multiple instances of cargo and rustc trying to mutate the same files in the same place at the same time Why the same couldn't happen with a per-project `target-dir`? I understand that it's possible to have doubts that shared artifact cache works. I don't understand how one could have such doubts and at the same time be confident that per-project artifact cache works correctly. 
There isn't a built-in solution for trait object downcasting, but there are crates that attempt to solve the problem. I personally used [downcast-rs](https://crates.io/crates/downcast-rs) in the past for my downcasting needs, and it worked well.
Going to try to come up with a way for users to set render target format options in ggez, so we can provide a work-around for [The Great Mesa sRGB Bug](https://github.com/ggez/ggez/issues/194). Straightforward in principle, but so far ggez has assumed that render targets and such are hardwired to `Srgba8`, so it's going to take a little bit of re-architecting.
I'm using the (mopa)[https://crates.io/crates/mopa] crate, or simplified custom versions of that approach, whenever I need something like that.
Very cool! I'd love to make a little virtual-console-like thingy someday. Or perhaps a virtual-console-chipset, which can have different emulated CPU's dropped into it...
I like the guy with the axe. He looks appealingly grumpy.
There doesn't seem to be any code in any of those repos...
Whoops that's what I get for not copy and pasting
Whoops fixed. Should have pasted
Subscribed
Another interesting crate (maybe not the best for this situation) is typemap which stores one item per type and allows lookup by type.
I wrote a little command line tool to search for processes. pgrep does this too but I want to add some more features such as search across multiple fields as well as dump the output in multiple formats https://github.com/abhijat/pfinder At this time the program does nothing that a mix of ps + grep won't do but I hope as I add more features it will turn out to be more useful.
Mostly finished with my Lisp evaluator. All of the core functionality works, but I have some work to do to make it easy to integrate and use. https://github.com/treyzania/mglisp
I wonder how far we are from releasing webrender to beta.
Thanks! This is what I'm trying to do, but double mut. So let mut refer = &amp;mut A; refer = &amp;mut B; refer.insert(...); So I'm trying to dive into the HashMap so let mut refer = &amp;mut A; if let Some(ref hash) = A.get("key") { refer = &amp;mut hash; } refer.insert(...); And I can't get it to work .. I am trying to edit a complex hashmap in place. So I want to insert values inside the internal HashMaps without copying, duplicating, or cloning the HashMaps. So I want to edit the HashMap while I'm working inside of it. [Here is a working example in lua](https://paste.ofcode.org/7a5b9SPn5Hh4mUZyiCJJdM) (since I know how to do it here, and might make sense what I'm trying to do.) 
You might want `Vec&lt;Option&lt;&amp;T&gt;&gt;` or `Vec&lt;Option&lt;Box&lt;T&gt;&gt;&gt;` to ensure the "pointeryness".
It should work the same way as in C. Except that C function signature is technically wrong, yeah? It should be `int** bar` or `int* bar[]`. use std::{slice, ptr}; use std::os::raw::c_int; unsafe extern "C" fn foo(bar: *const *const c_int, rows: c_int, cols: c_int) { /* null checking elided for brevity */ let bar: &amp;[*const c_int] = slice::from_raw_parts(bar, cols as usize); let baz: Vec&lt;&amp;[c_int]&gt; = bar.iter().map(|&amp;c| slice::from_raw_parts(c, rows as usize)).collect(); println!("{}", baz[1][2]); } 
The trouble is that the algorithm only works if all steps are done in order. Therefore, this method is inherently not paralisable.
This was surprisingly very enjoyable! Tone, pace and editing are very good! Great job! I’m looking forward for the next episode :)
Maybe you could create a vector containing all the j (from i*i to max) and [par_iter](https://docs.rs/rayon/1.0.0/rayon/iter/trait.IntoParallelRefIterator.html#tymethod.par_iter) on it?
Oh, sorry. That's a typo. Thanks for catching!
From my dogfooding, things seem to be getting pretty good. 
The cast is from a pointer to `int` into a pointer to `int[cols]`, which works in C. For what it's worth, `gcc -std=c90 -pedantic` does give a `warning: ISO C90 forbids variable length array`, but `gcc -std=c99 -pedantic` gives no warning as variable length arrays are now supported. I don't think this can be done in Rust, as you can't use a type `[c_int; cols]` where `cols` is a runtime variable. What you can do is simply use `bar[y * cols + x]` instead of `baz[y][x]`. After all, this code: void func(int i); void foo(int* bar, int cols, int y, int x) { int (*baz)[cols] = (int (*)[cols]) bar; func(baz[y][x]); } is compiled to perform a multiplication in assembly: foo: movsx rdx, edx movsx rsi, esi movsx rcx, ecx sal rdx, 2 lea rax, [rdi+rcx*4] imul rdx, rsi mov edi, DWORD PTR [rax+rdx] jmp func
I am loving all the video content people are creating in addition to the large amounts of blog posts and articles. Really cool to see the content expanding in scope and diversifying. I like that you put your show notes and things on github.
The official c++ project is in pre-order right now, and so since this is based very directly on that, it can't be released as open source. The C++ version will be released as public domain 2 years once the whole project finishes up. Until then, there is a rust-version repo link here: https://github.com/Lokathor/handmade-rust but it's restricted to people who pre-ordered the game and joined the official Handmade Hero github group with the email link you get and all. The current code follows the C++ super closely. Once there's enough that I've gone over to make it worth doing from scratch in a rusty way, I'll do a more rust style thing I can release. However, expect a lot of unsafe code :P
That isn't the case for the inner loop. 
First of all, thank you for the help; that answers my question completely, with the possible exception that the nuance below might offer another solution, but I think I'm now equipped to figure that out for myself if it ends up being important. &gt; Except that C function signature is technically wrong, yeah? It should be int** bar or int* bar[] The second one is incorrect. It should be `int* bar[cols]`, but the first one is correct as written. C has no native way of passing a multi-dimensional array as a function argument unless its dimensions are known at compile-time. When passed as a function argument, an array of any dimension is usually (see the alternative below) implicitly cast to a pointer to its first element. That's why, in the first example, I explicitly make the pointer conversion. The second example, if I had written it properly, is just a short-hand for the same conversion. There is a third way around this that I alluded to above, which is to have all of the dimensions (optionally excluding the most significant dimension) known at compile time, e.g., #define COLS ... //snip void foo(int *bar[COLS], int rows) { //snip } The `int**` notation only works for passing pseudo-arrays created by explicitly constructing a pointer to pointers, e.g., int **array = malloc(rows * sizeof(int*)); for (int i = 0; i &lt; rows; ++i) { array[i] = malloc(cols * sizeof(int*)); } //snip for (int i = 0; i &lt; rows; ++i) { free(array[i]); } Note that while a "true" array is guaranteed to be contiguous in memory, only the lowest-dimension subarrays of these structures are guaranteed contiguous. Although, one could convert a true multi-dimensional array into one of these pseudo arrays trivially, i.e., #define ROWS 16 #define COLS 32 int foo[ROWS][COLS]; // has built-in pointer arithmetic int* bar[ROWS]; // indistinguishable from `int**` for (int i = 0; i &lt; ROWS; ++i) { bar[i] = &amp;foo[i][0]; } This is because in C, `a[i]` is just syntactic sugar for `*(a + i)`, which is in turn equivlant to `*(([[TYPE OF A's ELEMENTS]]*)(((void)a) + i*sizeof(a[0])))`. It's starting to get hard to read, but the point is that you need information about `sizeof(a[0])` that isn't preserved by casting to a pointer to that first `int`.
Is it realistic? Electron uses JavaScript, so its gets all the "natural" integration of JS within the HTML/CSS system. I see two paths forward for a WebRender/Servo alternative: - use JavaScript, requires a JavaScript JIT, possibly programming JS via webassembly, - ditch JavaScript, and capture events "manually", but then you only have coordinates and need to find on which element the user clicked. It seems that using JavaScript would be "easier", but integrating SpiderMonkey (or equivalent) makes it Rust/C++, with a rather large C++ surface.
WebAssembly might be the key here. Of course you need a VM for it, but Rust can already compile to it, and it's created to supplant JavaScript. Maybe there will be a way of compiling WebAssembly in an AOT fashion that doesn't require a VM. Also, I think JavaScript APIs like the DOM could be written in Rust, and higher level frameworks like Angular or React can be created on top of it by third parties. The DOM doesn't have to be JavaScript.
I would love to eventually. rtsp is definitely on my list as I want to make a media server that can pull in my camera feeds and push them out to youtube via rtmp. I don't care if it's in my own repository or in rust-av, I don't know if you would want my rtmp stuff to be moved under rust-av as well (though depending on your goals that may not be appropriate). Right now my personal roadmap is * Write an I/O buffer to reduce allocations in the RTMP code * Build up client RTMP logic (so the rtmp library can be used to act as a video publisher or video player) * Build a proof of concept websocket &lt;-&gt; RTMP proxy. * Start building the framework to turn it into a basic wowza/evostream style media distribution server. Then I have to learn RTSP to read/write the protocol. So it might be some time before I can get to working on rtsp :).
Hmm. The main reason that I want to use Rust is to reap the benefits of Rayon, so I'm beginning to think the best idea would be to explicitly convert to a pointer-to-pointers, e.g., unsafe extern "C" fn foo(bar: *const *const c_int, rows: c_int, cols: c_int) { let baz: Vec&lt;&amp;[c_int]&gt; = (0..rows).iter().map(|x| { slice::from_raw_parts(bar + (x*cols), cols); }).collect(); //snip }
Continuing work on [tarpaulin](https://github.com/xd009642/tarpaulin), last week I improved coverage results removing some false negatives and removed some lines that were misreported as coverable. This week I'm doing more of the same but I'll be improving coverage of chained calls and macros.
Couldn't one manipulate the Servo DOM and react to events using pure Rust code?
I think that not only javascript but also 50% of DOM are unneeded and only make things slower
One issue I see is that the loop you want to parallelize modifies a mutable variable. Trying to parallelize it could introduce a data race.
If I may make a suggestion for the benchmark at the end: raw numbers are nice, percentages relative to a normal are easier to read. Also, some commas to help read big numbers, please. Here is a sneak preview: +--------+----------------------------+-----------------+ | name | normalized compressed size | compressed size | +--------+----------------------------+-----------------+ | gzip | 1.0 | 36,518,322 | +--------+----------------------------+-----------------+ | orz-l0 | 0.8 | 31,155,905 | +--------+----------------------------+-----------------+ See how easier it is to quickly compare the relative improvement? And how easier to read the big numbers are? (I immediately know it's a 5MB improvement!)
I'm hoping replacing most of the JS logic with Rust will clear up a lot of problems and limitations the app has currently (so far in my testing everything is working better). I'm probably a few weeks out from releasing the new version (v0.7) so it shouldn't be too much longer =].
It's the inherent trade-off of avoiding the error-prone implicit casting that C does when dealing with numbers.
The canonical resource concerning Rust releases is maintained right at the root of the repository: [RELEASES.md](https://github.com/rust-lang/rust/blob/master/RELEASES.md) It goes *all* the way back, to even pre-1.0. As for keeping up, I recommend subscribing to [This Week In Rust](https://this-week-in-rust.org/). Even if you don't care about anything else going on in the ecosystem/community, it tracks important PRs merged and highlights new releases. It usually makes the front page here every week the new edition is posted.
Great videos, keep on going
Perfect, just as I was gonna start learning rust! Now there's a nice structured and scheduled thing to follow
Servo already has code to do that. You'd have to implement code that registers and dispatches events to rust functions instead of JS ones. Or is the event registering/dispatching stuff implemented in JS under the hood?
I strongly suspect that when the compiler optimizes properly, parallelizing that inner loop will *not* help you. There are no real calculations happening there, so that inner loop should be limited only by the speed at which your processor can read/write from RAM. Adding more threads will only add communication overhead.
I think it would be much better to have a way to make a cross platform GUI without needing 45MB of dependencies to get a window on the screen.
No idea :D
Subscribed! Keep up the high quality content!
https://github.com/servo/servo/pull/19950 was created by somebody experimenting with this idea recently.
The plan for rust-av is to provide loosely coupled building blocks that can be used for multimedia purposes. The I/O protocols part is currently underspecified since right now the assumption is to have to deal with simple buffered I/O and until we have to deal with rtp-based protocols the approximation works fine. Having more people bouncing ideas hopefully will lead to better API and code :)
I really enjoyed the builder syntax. I am going to look at implementing that in my usual programming practices
Ok, I know I am being a fool here. I have a function that is written out like so: impl Thing&lt;u8&gt; { pub fn new() -&gt; Thing&lt;u8&gt; { // Logic } } impl Thing&lt;u16&gt; { pub fn new() -&gt; Thing&lt;u16&gt; { // Other Logic } } And I call that function like so: `Thing::new()` Rightfully, `rustc` complains telling me that it finds two implementations of the function. So, I give it a little more information: `Thing::&lt;u8&gt;::new()` At this point `rustc` says it cannot find the function. What am I doing wrong here?
Unrelated to your question, but I think you have an off-by-one error, if I run your code with `max` is `50`, it will declare `49` (a.k.a. `7*7`) a prime number. See [here](https://play.rust-lang.org/?gist=0bec7399fece8b34c7ce1d1beace6027&amp;version=stable), sorry about the silly prime number iterator.
As Mark Twain said about the weather... everyone talks about it, nobody does anything about it. :-/
I really enjoyed it, can't wait for the next episode! 😊
Everyone else is telling you this is a bad idea (it is) and maybe why, but that's not what you asked. You asked how to do this, so... Here I am to deliver. I hope you're ready. **I do not endorse what follows as an example of how to use rayon well**. You'll need a little Cargo.toml file to go along with this as a `main.rs` for `bencher` and `rayon`, but then you can switch from `.par_iter()` and `.iter()` to see the performance difference. I think I've made a good-faith attempt to do this in a way that doesn't hamper performance, but if any reader has an improvement please do share. https://gist.github.com/saethlin/b92fe08be85674d9884701bf593a1fc2 On my machine, the rayon-less implementation is 12,565 ns/iter, and the rayon-ful is 209,000 ns/iter. _But... how..._ This is exactly what some other commenters are trying to point out: This is a bad candidate for parallelization and for rayon especially. First off, the easy source of overhead here is creation of the thread pool. You have tiny tiny jobs being launched by a very short-lived thread pool, and spawning those threads is not free. Looking at the `perf` output (release mode, debug=true) suggests that this program spends 90% of its running time spawning threads. Ouch. Even accounting for that 90%, we have a performance degradation. I suspect that the other problem is cache contention. I'm a bit fuzzy on what's going on here, but as far as I know this results from synchronization across CPU cores. We know that no synchronization is required in the parallel part (that's what the unsafe is all about) but the hardware has no idea. Ideally, each of the rayon threads will end up in an independent core. Except that each core has its own L1 cache, and therefore each write to the vector invalidates the caches of all other cores and forces a synchronization. So much for attempting to make this parallel...
Are you sure? This works for me: struct Thing&lt;T&gt;(T); impl Thing&lt;u8&gt; { pub fn new() -&gt; Thing&lt;u8&gt; { Thing(8) } } impl Thing&lt;u16&gt; { pub fn new() -&gt; Thing&lt;u16&gt; { Thing(16) } } fn main() { println!("{}", Thing::&lt;u8&gt;::new().0); // prints 8 println!("{}", Thing::&lt;u16&gt;::new().0); // prints 16 }
It's alright if you read it backwards (and write e.g. `int const *const x;`, which you can read backwards as "x is a const pointer to a const int", but obviously no one writes this way. Why it's designed such that it's only readable backwards is I guess one of life's great mysteries. 
Not sure that would be any better than Chromium, other than faster layout and paint. They're both complete implementations of the Web Platform, so they're both going to gobble memory. Servo also has an utterly *incestuous* relationship with SpiderMonkey.
Hi there, this got caught in reddit's spam filter somehow (not sure how, it's been very aggressive recently). It's too late by now for me to approve it and have it get seen by anybody, would you mind resubmitting it? If reddit doesn't like one of your links then it will probably get filtered again, but I'll keep on eye on the spam queue.
u/jackmott2, while you didn't get the answers you were hoping for, I think it's rather rude to just delete your question. People invested their time in trying to help you, and even if the answers weren't what you were hoping for, the topic could potentially have been useful for others. Now it is useful for no-one. I can't speak for the other posters, but I personally would not have tried to answer your question had I known you were just going to delete it. Perhaps next time you could ask on IRC instead, which is inherently more ephemeral and does not create the wrong expectations in those who might answer.
I'm working on [adding some functions to Rust's atomic number types](https://github.com/rust-lang/rust/pull/48658), also of course [mutagen](https://github.com/llogiq/mutagen) (expect yet another blog post as I go along) and TWiR.
What's a PIP?
I apologize to u/dbaupp and u/ealhad 
Maintainer of LeoTindall/libui-rs here. I'm a college student at the moment which makes it hard to allocate time to that work, so any contributions of code or [money](https://patreon.com/leotindall) are appreciated! A 0.3 release should be coming up in the next few months which will put `iui`, the safe bindings crate I'm building on top of `libui`, in an eminently usable state. As things stand, simple apps can already be written with it and run well across all platforms. I'm waiting on better memory management from the `libui` project itself, which has just recently been revived.
Thank you, the par_chunks feature looks promising! And yes, the proper way to do this is to do a segmented sieve and parallelize on the segments. That is the next step! 
If there's spare capacity, I wonder if bors can dodge serialization and merge several PRs at a time? Let's say PR's 1, 2 and 3 are r+, and the current master state is m. Than, bors can create commits `m + 1`, `m + 1 + 2`, `m + 1 + 2 + 3`, test then in parallel, and, by the time `m + 1` is completed, `m + 1 + 2` should be near completion as well, so it could be merged as well, and `m + 1 + 2 + 3` after that as well. Of course, if `m + 1` fails, `m + 1 + 2` and `m + 1 + 2 + 3` have to be canceled.
&gt; Would be very happy for constructive feedback. Well, okay then! This is from a long time programmer, but almost complete Rust newbie (I'm going through the manual, though). I know some of the answers to my criticisms here, but I am writing from the point of view of a Rust newbie. The presentation is great. Not a lot of time wasting, I'm seeing you code, good environment, good pronunciation, good audio, etc. All that makes for a video that is pleasant to watch. Good job there. Episode 0: * You should introduce Rust. Tell people why they would want to watch this. No need to make it long, but say something like: "It's compiled and fast like C, but solves a whole lot of sources of bugs and annoyances". Draw people in. * You should note that this series is not for the novice programmer. You clearly expect people to know things like what an Enum is and why it's useful, and are only going to teach people how to use one in Rust. Episode 1: * What is cargo? * What is all this weird code that appeared? Why is there a #[cfg(test)] there? This is a pet peeve of mine: when a tutorial throws a bunch of arcane looking stuff at you and doesn't bother to explain what that actually does. This IMO sucks because if something goes wrong I have no clue what am I doing at this point or why, so I have no clue how to even start fixing it. * Why "println!"? Why the "!"? * Ooh. I get it. It's a test harness. But why are you writing code in a test function? How do I write main()? How do I just run a program normally? * --no-capture? Again, why are you writing code in a test function when you're not actually testing anything? The only thing being tested is that the code compiles and runs. * Now use super::* comes in, and is randomly papered over. So far this seems like an odd way of coding and unnecessarily complex. * You use "match", but don't explain how it works, mention what happens if you add an extra variant to the enum, and then don't include it in the match, or how to make a default case. * Editor seems to indicate a warning. This is ignored. * Semicolon is mentioned but not really explained * What looks like warnings scroll by and instantly disappear when you execute the code * Structs are confusing. A mention of classes and how Rust structs work would be very helpful here. * self and mut introduced, but not explained. * returning values without a "return" keyword isn't explained * Now there's a &amp;mut. Also not explained. * At the assert, we finally have a test that actually tests something. * What is #[derive]? Why does it start with a #? * Why do you need two of them? * The "nice debug output" disappears too quickly to read it There, that should be it. Overall still not bad though, but I would say my ability to actually understand it was there only because I read a good deal of the manual first. 
True, but in my Playground I created a enum to get around this. Enum Subsetting{ Simple(String), Complex(Hash&lt;string,Substring&gt;) } And it works on the reading front (immutable) but as soon as I try to borrow something as mutable it gets upset.
Sadly, there's nowhere near that level of capacity. Given how many builds we produce, it would be very expensive to allow for this kind of full speculative parallelism.
Is it possible to re-use (some of) the artifacts generated by the travis builds? I remember builds for the different architectures taking a different amount of time. If this difference is significant (like &gt;50% longer): Is there an effort to keep all build agents 100% busy? E.g. by preemptively starting the next build on otherwise idling/waiting machines assuming the current build fails? (Could give faster feedback on failure.)
Well that explains why I suddenly couldn't find it anymore as well. I resubmitted it now at https://www.reddit.com/r/rust/comments/85nok1/derive_more_090_released_now_supports_deriving/
Running that code out of my existing project works, but in my existing project it fails. I'm going to have to dig deeper...
How expensive though? I'm absolutely not telling Mozilla how to spend its money, but it seems like "throw more money at Travis" could be on the table. 
&gt; better than medical studies considered the gold standard of their respective fields But medical studies go to great length to cover as many different populations as may be. The Steam studies only cover, well, active Steam users, so gamers, who will probably have over average computers.
Yep, it got blocked, I've just approved it. :)
How about splitting up the rustc repo into parts that can be separately tested and built? The obvious candidate would be having separate repos for rustc and libstd, although we'd need to define some kind of "liblangitems" that contains all the lang items and that libstd would then depend upon (and all this would just be an implementation detail masked by the facade). Even if you still wanted to include libstd as a git submodule in the rustc repo (which I'm not sure is even necessary?), that would drastically reduce the queue time for anyone doing work on the stdlib.
But `const int` and `int const` are the same thing, so it's not a matter of order. The problem here is one of precedence. C designed its types to be a stack of decomposable modifiers so that `int * a` means `*a` is an `int`. So `int * const a` means `*const a` is an `int` and `int const * a` means `*a` is a `const int`.
A little off topic: what was your motivation for using jekyll for this site rather than continuing with cobalt, like your blog does? I'm just looking for an opportunity for feedback and am not offended nor wanting to convince you to change.
I use sublime, and the multi-line syntax is beyond the regex decoder support it has. So I get a mangled error appearing in my editor. This is with the "official" sublime package. 
I do want that to happen, and a shorter error message that is easier to parse will allow it to appear in editors like Sublime, which uses regex to find errors in log files for highlighting. 
Very good feedback from both of you. Thanks for that! Yes, I've added a few more notes to the description, Github and the homepage that the target audience is more like intermediate Rust programmers. Will also add a link to the Rust book in the first video. As for TDD, you've got a point there. I don't mention it explicitly, but yes, it's not pure TDD. Guess it's just my stile of quickly getting some output on the screen. I guess this will be less of a problem in the future, when the focus is on actually testing the code or running it from the commandline.
Hey /u/epage! Still a huge fan of cobalt. The only reason I picked jekyll was, that I found a nice theme, which was built on top of jekyll and I needed to get something up and running asap. That said, I plan to move it to cobalt if I find the time. Wanna help me with that? I could make you an admin if you like. :-) Also still have your PRs open for my blog (thanks!), which I also want to merge when I find some time.
In general, this is a limitation of the borrow checker. The mutable borrow doesn't end in the `None` arm. In hyper's case: this is why maps have ` Entry` APIs, and hyper will be shifting it's header type to that of the `http` crate, which does have an `Entry` API.
Sounds like what you'll need are: - [jekyll import](https://github.com/cobalt-org/cobalt.rs/issues/276): Started but needs more love. Looks like your site would be a good test case. - [theme support](https://github.com/cobalt-org/cobalt.rs/issues/301): not started I have some CLI WG stuff I need to work on first. Maybe I can make implementing the features needed for it a priority after that.
Or, depending on how much engineering they're willing to commit to this, AWS EC2 spot instances for extra throughput when the price is right.
Our goals are pretty well aligned then. I (tried to at least) designed the amf0 deserialization crate and rtmp crate to mostly be building blocks allowing anyone to add rtmp handling to their application, which is why right now the only mio code is in a separate `mio_test_server` crate in the examples folder. The only thing that get slightly muddled from a building block perspective is the `ServerSession` struct (and soon to be `ClientSession` struct) which handles some of the higher level logic of how to handle the core RTMP workflows so it's easier to get up and running quickly with a client or server without having to have heavy knowledge of what responses are expected by peers. it's all built on the lower level building blocks though so anyone can technically ignore those if desired. In regards to the I/O buffers (assuming you are talking in the same vein as I am thinking), unfortunately even with the proof of concept it's become clear that a pretty robust byte buffer system is going to be needed and I am struggling to see a good way to implement the serialization and deserialization without it being directly referenced. The problem really comes in that a slice of a packet needs to be held in a queue for an unknown period of time because I can't predict exactly when the socket will be ready to send that data out (or file operations or anything). At the moment I am thinking to create a growable byte buffer that can have slices copied into it, and each slice I add generates an `Rc&lt;usize&gt;`, with the usize referencing an identifier for the slice. If I run out of space I can count any slices with a strong count of 1 (meaning the buffer has the only reference to the slice) as consumed and re-use that space. This will probably require some defrag like capabilities as well when space becomes low. I guess the other option is a growable circular buffer but you'd need two per connection (one for input data and one for output data) in order to manage the lifetime of each of the slices put into it. In my head that seems to have its own complications, especially in lifetime management. I dunno, I'm going to have to play around a lot. I'm not sure how easy it's going to be to have a general purpose buffer. I've been thinking about memory allocation management a lot lately but I'm not used to having to worry about it much (I mostly work on C# LOB apps and haven't worked on c++ in a decade, and managing pooled resources in C# is pretty easy since when you don't have to worry about lifetimes).
https://www.reddit.com/r/rust/comments/73w227/limn_gui_library_an_early_stage_cross_platform/ there are few projects like this already
An approach relatively common (e.g. used in crtmpd) was to use as much vectorized I/O so you would avoid tiny memcpy all over. But it is more or less a late optimization IMHO. Normally what happens is that a rtmp A/V stream is unwrapped as a flv stream and fed to a normal flv demuxer. 
I try to come at least every couple of days. Thank you for the ping! For what is worth, [the output in nightly is](https://play.rust-lang.org/?gist=0773a2c9f6e61d448c73338b26c8ca7b&amp;version=nightly): ``` error[E0277]: cannot multiply `{float}` to `{integer}` --&gt; src/main.rs:5:27 | 5 | println!("Test {}", x * y) | ^ no implementation for `{integer} * {float}` | = help: the trait `std::ops::Mul&lt;{float}&gt;` is not implemented for `{integer}` ``` Once [#47613](https://github.com/rust-lang/rust/pull/47613) lands on beta, a note could be added: ``` error[E0277]: cannot multiply `{float}` to `{integer}` --&gt; src/main.rs:5:27 | 5 | println!("Test {}", x * y) | ^ no implementation for `{integer} * {float}` | = note: cast `{float}` to an integer value using `as` = help: the trait `std::ops::Mul&lt;{float}&gt;` is not implemented for `{integer}` ```
This was a wealth of information, excellent writeup! &gt; One thing that surprised me while working on this support in TRust-DNS was that I ended up being the person who had the pleasure of adding the IPv6 multicast socket option bindings to libc and socket2, which is surprisingly easy! If you notice things missing while you’re working on similarly low-level features, you should definitely not be put off by process or working with the maintainers to get those changes in. This is really good to know. A year ago I ran into some missing socket APIs and kind of just said "oh well". I probably should have dug further and I definitely will next time.
&gt; IMO rustc needs a single-line error message format out of the box. [There's one](https://github.com/rust-lang/rust/pull/44636), but it's not the default as out of the box compiler diagnostics must be _understandable_ over _concise_. I'm even [working towards _increasing_ the amount of help the compiler gives](https://github.com/rust-lang/rust/pull/47652) (on an opt-in manner, very much a work in progress). If you dislike the diagnostics in the terminal (which try to give you as much context as possible for an error), you might find the IDE integrations more to your liking, as the same information is shown inline with your code.
Glad you enjoyed. And yes, It was straightforward adding the bindings. Definitely just do it next time ;)
If you could provide an example, I've been trying to nail down these lately. So far its come down to the suggestion machinery not paying attention to the visibility chain. I thought I had fixed (if not minimized it).
It is not an unreasonable chain of thought. It's part of why the current message in nightly [is already closer](https://github.com/rust-lang/rust/pull/47613) to what OP was suggesting.
&gt; Namely, a proper video cutting tool like Adobe Premiere. Give [DaVinci Resolve](https://www.blackmagicdesign.com/products/davinciresolve) a shot. It's free and it's super professional. We've been using it to work on some Rust videos ourselves (Rust Belt Rust and a series for Manning) and it's been great. It's *way* better than iMovie, I'll say for sure!
I looked at crtmpserver a bit and it seemed to use an approach similar to what I described, unless I misread the input buffer class. That being said my concern is less surrounding the demux process and more about what happens after demuxing. For example a video packet comes in, I need to unwrap the flv information to get the raw h264/aac bytes (which are usually not contigious due to RTMP's chunking protocol). I then need to pass those bytes to all distribution points that I want to send the A/V bytes to (RTMP viewers, HLS muxer, RTMP pushers, etc...), where they will need to be muxed into packets for the outbound protocol and placed in a queue until the outbound file handler or socket is ready to send the packet out. All and all it sounds like a pretty complex scenario when taking Rusts' lifetimes into account, and it seems to me that how the buffer functions can have ramifications of how the building block APIs function to some extent. Maybe I'm just heavily overthinking things though or looking at things from the wrong angle (or my APIs are designed poorly just for this reason).
As someone else said, Performance Improvement Plan. Usually the 'intent' is to say "Hey, you're not performing at the level we expect, so we're going to work with you for &lt;some amount of time, often a 1-3 months&gt; to get you where you need to be" but the reality is it's more of a "Hey, here's a short period of time to try to find a new job because things aren't working out here."
It's the process a big company goes through to cover their ass legally before firing you, euphemistically called a "performance improvement plan".
&gt; It is not an unreasonable chain of thought. No one said it was. &gt; but you're assuming they only think of that one thing, which makes this pretty contrived.
As first approximation you can do a copy wrap it in a Arc and see how far it goes (a lot), then you can do additional refinements over it.
Actually, the sublime plugin SHOULD be using the json format, not the textual format. It provides extensive formatting info, including what lines to highlight for what parts of the message, etc. The json output is designed to be read by plugins. IIRC, it's just 1 line per error, so Sublime should be able to read it.
You're in the wrong subreddit, head over to /r/playrust!
Didn't know this existed, and sounds awesome!
Nice to see an example of futures in use. I keep seeing them mentioned all the time in the Rust world, but so far I haven't had a real need for it in anything I've played around with. After seeing this, I feel quite happy about that, because that looks like a bit of a mess to deal with :P It was way more difficult to follow along this time (not your fault!). Though if I understood correctly, maybe it just seems more daunting because of how you're abstracting over something else and having to massage things in place. Still have some hours of this left to watch for later.
Set up a hierarchy of area-specific forks run by lieutenants, like the Linux kernel, and only merge them upstream periodically. e.g. have somebody be the std lieutenant, take all std patches into their own tree, run them through their own (free) travis / appveyor testing, then submit the whole thing upstream once a week.
[removed]
Unfortunately, testing in this "modular" fashion is a bit risky in terms of keeping the tree green overall. Our experience has been that *any* divergence in what is built for testing versus for artifacts will eventually lead to divergence, and the inability to produce artifacts. That's the reason that, long ago, we'd frequently stop getting nightlies for some period: even though PRs were "passing tests" to land, those tests were different enough from what was needed to build artifacts that one was green and one wasn't. Since then, we've gotten a ton of mileage from having a single, unified build process, such that *every* PR that passes tests has also produced a candidate nightly. I'd be pretty wary of backing away from that; we'd likely be trading one set of problems for another.
The total infrastructure spend is in the ballpark of $60k/year right now. I'd *much* rather get another $60k for contracting work in the Rust ecosystem than to double our capacity to do speculative builds.
Is there any prerequisite knowledge you need to work on that? Besides knowing how to write code heh 
Which works especially well with the working groups. :)
Or just download the .exe and run it.
Sounds pretty cool, just read over the last comment. I might have time to try it out. 
Sounds pretty cool, just read over the last comment. I might have time to try it out. 
https://en.wikipedia.org/wiki/List_of_Asterix_films &lt; yes? Save a couple of nights, they are classic. If you speak German, the older 6 saw a DVD rerelease that features voiceover in one German dialect each, which is a nice oddity for the film nerd.
omg is bors fired!? first homu, then bors, whos next? bot's rights!
&gt; Our experience has been that any divergence in what is built for testing versus for artifacts will eventually lead to divergence, and the inability to produce artifacts. I'm a bit unclear on what the projected dilemma is. If the interface between rustc and libstd ("librustclangitems") is well-defined (and I don't see why it couldn't be), then I don't see how any divergence is possible, or why we would even need separate artifacts for testing and distribution; the interface between them would be just as reliable as the interface between any two libraries in any other Rust project, and the fact that we can guarantee they're all built with the same compiler eliminates any concerns about ABI. This *would* imply that we would have to take care about any changes that relate to lang items, but AFAICT such changes are relatively rare. This would also imply that we would want to be conservative about using new bits of the standard library in rustc itself, but AFAIK we are already forced to do this by our policy that rustc must bootstrap via the prior point release. &gt; every PR that passes tests has also produced a candidate nightly I'm not proposing getting rid of this property, only that the final step for a candidate nightly is to scp whatever the most recently-produced libstd artifact to the build directory (and it shouldn't need to be picky about *which* libstd artifact it gets--that's the whole point of defining the interface between them, which we can bump with every release). We already successfully distribute libstd as its own archive, so what's stopping it from being developed separately as well?
Guilty as charged. :(
My experience with `stdsimd` is that we can push dozens (and we probably could push hundreds) pull-requests there, and every couple of weeks update the rust-lang/rust subtree. In the mean time, we probably push 0-5 rust-lang/rust PRs for new features we need to use in stdsimd, 0 being the most common number. That's one to two orders of magnitude less. The same applies to libc, and could probably apply to jemalloc, liballoc, and libstd as well. The secret is: testing all those components with something really close to rust-lang/rust full CI, or something even more extensive. We currently replicate libc's CI system across these components, but japaric abstracted 80% that away into a cargo command called cross (github.com/japaric/cross). Finishing cross, moving libc and stdsimd to use it, and moving jemalloc, liballoc, and libstd out of rust-lang, could improve velocity a lot. The only downside is that when you need to change rustc to land a new feature, you need to wait for the rustc PR to be merged and the next nightly to be released. For libc this rarely happens (it happened today with the repr(packed(N)) PR though). For stdsimd, it happens very rarerely as well.
Ah, i thought they meant https://pypi.python.org/pypi/pip
Using the fact that if, a/b &lt; d/c, then a/b &lt; (a+d)/(b+c) &lt; d/c You generate (a+d)/(b+c) and replace the upper or lower limit with it. Let's approximate Pi: 0/1 &lt; Pi &lt; 1/0 -&gt; a fraction between is (0+1)/(1+0) 1/1 &lt; Pi &lt; 1/0 -&gt; a fraction between is (1+1)/(1+0) 2/1 &lt; Pi &lt; 1/0 etc... 3/1 &lt; Pi &lt; 1/0 3/1 &lt; Pi &lt; 4/1 3/1 &lt; Pi &lt; 7/2 3/1 &lt; Pi &lt; 10/3 3/1 &lt; Pi &lt; 13/4 3/1 &lt; Pi &lt; 16/5 3/1 &lt; Pi &lt; 19/6 3/1 &lt; Pi &lt; 22/7 25/8 &lt; Pi &lt; 22/7 47/15 &lt; Pi &lt; 22/7 ... 
Being inclusive has always been something important in the Rust community. Making the Rust compiler and tools more accessible to blind programmers is a good idea. Not being blind myself, I don't know the reality of the difficulty mentionned in this blog post. But I think that it is something that coule be explored by the Rust community. 
Ah well, at least you know of it now, in case it becomes useful to you :-)
Nice! Some ideas for future improvement: * `Deref&lt;Target=T&gt;` on enums that contain type implementing `Deref&lt;Target=T&gt;` in each variant. * `AsRef&lt;T: ?Sized&gt;` on enums like above * `Borrow&lt;T: ?Sized&gt;` like above * Either: derive any trait for enum dispatching calls to variants (like what `futures::Either` does, but more general and working on &gt;2 variants.)
Good that librespot has been updated since then. At the time, I tried to fix bugs in librespot, but was unable to do so within spotifyd, since using latest librespot involved much more than just cargo update. I switched to plain librespot because 1) I don't need a config file when I simply use discovery, 2) using it with systemd means that I don't need it to daemonize, write a PID file or log to the system log, 3) I didn't even realize it had MPRIS support (which was also unnecessary in my context, but is an awesome feature). So maybe I wasn't fair to spotifyd in my comment 
AFIK, this depends on which loggers you are using. Do you use `env_logger`?
Wrt rollups, have you considered being *less* strategic but doing more rollups à la bors-ng?
First of all, enums are quite a pain to derive stuff for, so I'm not sure if I will feel like implementing these. For your top 3 suggestions, what usecase do you have for this? When do all of the variants implement the same deref/asref/borrow? For all of them, could you make an issue on Github with an example struct and a desired implementation that could be generated?
 #[macro_use] extern crate log; extern crate simplelog; and then I initialise my logger with: let term_config = Config { time: Some(LogLevel::Debug), level: Some(LogLevel::Error), target: Some(LogLevel::Debug), location: Some(LogLevel::Trace), }; fn init_with_verbosity(verbosity: u8) -&gt; LogLevelFilter { match verbosity { 0 =&gt; LogLevelFilter::Warn, // default 1 =&gt; LogLevelFilter::Info, // -v 2 =&gt; LogLevelFilter::Debug, // -vv _ =&gt; LogLevelFilter::Trace, // -vvv and above } } CombinedLogger::init(vec![ TermLogger::new( init_with_verbosity(opt.verbosity), term_config ).unwrap(), ])?;
That's an interesting tidbit, thanks. Not the most human-friendly bit of syntax out there, but it does make sense.
I distinctly recall once thinking to myself that I should really learn function pointer syntax, only to look it up in a textbook to find [this example](https://i.imgur.com/Ge9szSX.jpg). I really tend to avoid function pointers these days.
Great to see this here! I hacked out the little [proof of concept](https://github.com/scalacenter/advisoryboard/pull/37) in the original proposal. If anyone knows Scala, we need help with [input / expected output](https://github.com/MaxwellBo/scala-verbal-descriptions/issues/3) tests. I did a [similar thing for Python](https://github.com/MaxwellBo/neoreader) a while ago, that actually turned out pretty well!
Why did Rust 1.15 use to complain about the following code while 1.21 compiles it well? What's wrong with it? ``` let it = [1, 2, 3].iter(); ``` And I could not find the exact version which has started to accept it.
That list comprehension example seems a bit off though, at least to me as a sighted developer. I would never read that as it's given, I'd say something more like "x equals the list comprehension i for i in range from 1 to 100 if i is between 10 and 20". I interpret that in my head, but I'm reading (and if I were talking to another Python developer I'd be saying) essentially the things I can see on the screen. I'm also intrigued - is this not something that already exists? I know there's a good number of developers who use screen readers for accessibility, and there's a brilliant video of a developer at a Microsoft conference writing a text-to-speech hello world application entirely using the built-in Windows screen reader. He seemed very comfortable writing and reading code from his editor, and I don't think he was using anything particular to make the code more "readable". I may be completely off-base here, and, like I say, I'm sighted and so I don't have to deal with the issues that crop up around this every day, but is this really the best sort of system for screen reading? At least for professional developers who need speed and efficiency in their screen-reading software.
This is amazing! Thank you! I have one concern, though. [In `failure` `1.0`, they are planning to make `#[derive(Display)]` explicit, rather than implicitly deriving `Display` along with `Fail`.](https://boats.gitlab.io/blog/post/2018-02-22-failure-1.0/) How would that interact with this crate? Would it be possible to use both at the same time, considering that each provide a way to derive the Display trait? I am not sure how conflicts like are handled. Since `failure` is such a common crate used by many projects, I am concerned that their change would cause problems with this crate / could make this crate unusable. Ideally, I would like to be able to use both libraries. The two `#[derive(Display)]` implementations are for different use cases. I'd like to be able to use `failure`'s for my custom error types and yours for newtype wrapper structs. They are both useful usecases. I hope this conflict can be resolved.
That is a very good question. I think it will indeed break stuff to have two crates implementing `#[derive(Display)]`. I think I will discuss with withoutboats on how to solve this. Looking at the examples it might be possible to merge them. In any case I can probably add a feature to Cargo.toml so you can disable the Display derive from this crate. That way you can at least use the rest of the derives from this crate.
[Announcement for Rust 1.21](https://blog.rust-lang.org/2017/10/12/Rust-1.21.html) seems to answer your question quite nicely.
Oh. My. God. This looks amazing. YouCodeThings also [mentioned it](https://www.youtube.com/channel/UC0yCXVwW6FdDQGYA-3OWXxw), but I didn't look at it right away. Definitely gonna try that for the next episode. Thanks!
At least one Rust RFC was decided on the matter of accessibility, in particular to blind programmers. See https://github.com/rust-lang/rfcs/pull/1373#issuecomment-205864317
Yeah, I can understand the issue using the AST directly - I guess most humans don't read the AST, but have some sort of basic additional parsing on top of that, or maybe instead of that? I really have no idea, but I reckon this would be a great place for some actual testing. Maybe that would be the best first start if Rust wanted to go down this path - understanding how users actually read Rust code, and what they 'say' when they write it? The stuff that already exists seems to be stuff like [this](https://www.youtube.com/watch?v=iWXebEeGwn0&amp;vl=en), which is the presentation I was talking about. What's interesting here is that the screen reader literally reads out every single character, which is what Batista seems to want to solve. That's irritating if you're trying to get a high-level overview of the code, but it seems to be useful if you have syntax errors, or whilst you're typing. In the video link, Saqib Shaikh accidentally leaves a hanging quote mark at the end of a line, causing the build to break. He's able to debug it because the screen reader reads out all the characters and he can work out which character shouldn't be there. I guess the ideal would be being able to switch between the two? Like Vim, having an 'editing' mode and a 'writing' mode. I'd be interested in seeing this sort of stuff tested with people who are blind. Have you done much testing of the neoreader system, or is it more of a personal project-type thing?
It's a personal-type thing. Neoreader has three modes, standard, detail and explain. Standard pipes the text straight into the text-to-speech backend, detail does syntax substitutions so that you can hear things like hanging quote marks and stray symbols, and explain pipes it into the AST analysis backend. I would trigger each mode with hotkeys. Each time I hit space, it would also read the last word I wrote in detail mode. Each line would also be read automatically when navigating. In terms of not using the AST directly? I'd probably warn against it. I think another layer step in the AST -&gt; Text chain can be a little redundant. I think you can get the results you want by trying to figure out what a nodes children actually are and tweaking the grammar a little, rather than just blindly deferring to the visit method and hoping the answer makes grammatical sense. Actual testing is super important, particularly with a language like Rust. Scala has proven significantly more difficult to interpret than Python, so I think driving development by tests is pretty wise given that you're just checking strings. 
This idea has merit exploring. Channeling some DevOps (systems thinking/lean) thinking here, can we move quality closer to the source (fail faster), can we increase quality (solve the timeout, other problems), can we reduce the batch sizes (release more often, smaller changes are easier to integrate; more agile than waterfall - also, is there something that we can automate to make the gates less of a constraint/delayed handoff point), can we somehow do single piece flow (can we critically review the places/reasons we stop/wait instead of releasing). Of course technical solutions are good too, but maybe the process needs some lateral thinking?
You said allocating hundreds of megs for you **text editor** is excessive. It is, but that's not what these apps are.
From what I can see in the documentation and the code of `simplelog`, filtering with more than the level of the log is not possible. There are others logger implementation that allow that. See the log crate [readme](https://github.com/rust-lang-nursery/log) for a list. For example, `env_logger` should allow that, using the `RUST_LOG` environment variable.
This is what happens with all of the books too. Sometimes we break links, and then have to update them before updating them in the main repo, but it generally lets us stay decoupled and not have to put all sorts of trivial things through bors.
Thanks for the info 
The Scala proposals are certainly, uh, opinionated. I'm not sure I agree with the use of `context` to describe the `Bar` in the proposal (I'm not sure what I'd propose as an alternative). Unfortunately, I can't speak to wether they're looking to define a higher-level spoken language - I've worked off only a few examples so far, and the rest I've had to wing it. No problem! I'd love to see one in Rust one day - I'd love to try my hand at one as a learning exercise but I don't think I'd finish it any time soon.
Eh, me too. Gotta choose your battles.
Let's be real here, rust is a systems programming language mainly. The majority of people who like it are going to absolutely hate it. Its a mess generally, with some very good ideas.
Why does putting curly braces around match branches make it so commas are unnecessary? Here's a [playground](https://play.rust-lang.org/?gist=a9f2f9ae7878fe23aa9ffe880dd86908&amp;version=stable) link to an example. Based on the book, not separating match branches with a comma is invalid syntax, but the code compiles and runs correctly.
Its a big help when they are things I personally need anyways (the other is collections).
Given that one tends to learn programing from reading the source: if you learn via def foo type a context bar from s string to int then would you not try to type the same way? which means you'd either be showing them the wrong way to code OR we'd be introducing a whole new syntax... There is nothing really wrong with a whole new syntax I suppose, but the fact is rustfmt was made because people thought the idea that two people formatting if statements slightly differently was terrible; so I doubt a whole second syntax would fly.
Doesn't that illustrate an issue with the way procedural macros are called? What *should* happen when both define similar derives? Or in general, shouldn't there be some kind of namespacing for everything defined in a crate, macros included?
I think you did a great job with Hello Rust 1. Thank you for putting your time into these and I cannot wait for more!
lol, yeah that isn't a very useful example... mostly function pointers are just for interop, and they are like take params usually a void pointer and maybe dimensions and return a void pointer... `typedef void * (*callback_f)( void * buffer, int w, int h);` which is still bad... but not as bad as that example. 
Why can't rust insert in the middle of linked lists?
Check out my EDIT to the OP. I understood how my mental model was wrong and why I was feeling frustrated with `failure`. I gave a suggestion for how the documentation could be improved, which would have avoided my confusion and frustration.
The `fern` logger is very flexible on changing log levels of sub-packages. A bit more code to setup, but works well for me.
Working through all sorts of awesome material I found around the web. The first is [the Rust Book second Edition](https://doc.rust-lang.org/book/). Great high level of many Rust concepts. The next is Jim Blandy's Programming Rust. This is awesome when read along with the Rust Book because it fills in many of the gaps. I also listen to [The New Rustacean](https://newrustacean.com/) on my commute. And I coded up a [simple CLI game](https://github.com/robertDurst/rust-cli-game) to practice what I have learned!
If I was going gradually blind, I think I'd be looking at mapping symbols to very short syllables, and using pitch to indicate comments, strings or nesting levels. (Like when we read a story, quoted spoken text has a different intonation to the surrounding text, and the listener intuitively understands that.) It's not necessary to limit yourself to speech either, little sound effects could work too, if the audio backend supports that.
Gratz on the release! Related question: is any of these parser libraries (nom, combine, etc..) suitable for binary formats?
Nope. Check out the assembly on https://play.rust-lang.org/?gist=bd4d734b16e482e5063170a976c9dd28&amp;version=stable : it generates two identical `push_thingie` functions in both Debug and Release. In fact, even if you make the two functions take types which are aliases for each other (e.g. usize and u64 on a 64-bit system), the compiler isn't smart enough to unwind the aliases and deduplicate the function.
`nom` was originally created specifically for binary formats. There are some binary format projects [on the readme page](https://github.com/Geal/nom#binary-format-parsers)
I managed to get it working, but my doing something else. Since I couldn't figure out how to get a mutable internal HashMap (assuming because I had my own enum in the mix, and that got me confused because everything was wrapped in 2 enums) I instead remove the hashes, edit them, and them insert them back again. [Playground link if anyone is interested](https://play.rust-lang.org/?gist=c9b695eec1f3387321619394392b7818&amp;version=stable). Not ideal since it requires a lot more actions, and reshuffling data a lot, but it works. I'll probably come back to it after I understand Rust a lot more. 
I find that surprising on LLVM part. There are specific LLVM optimizations for merging functions or blocks of code, and therefore I'd expect even if the symbols survive that they both point to the same code. I wonder if there's something in the IR emitted by rustc that prevents such optimization... such as Debug info maybe?
Both nom and combine handles binary formats without any problems (see https://docs.rs/combine/3.*/combine/parser/byte/index.html for parsers specialized on bytes and https://docs.rs/combine/3.*/combine/parser/range/index.html for zero-copy parsers). On top of parsing plain `&amp;str` or `&amp;[u8]` it is also possible to parse iterators, `Read` instances or even creating your own custom tokenizer.
Given that this has to respond as someone types and edits, I think a very close mapping to/from the textual form would be necessary, as you say. There is some 'noise' in Rust that could be skipped for both sighted and blind users, such as lifetime annotations which make no difference to the compiled output, but are just there to help the compiler prove things to itself. So unless you are debugging lifetimes, they could be safely hidden or skipped.
There are ongoing work to (partly) implement this! https://github.com/rust-lang/rust/pull/48779
&gt; The stdlib of Rust does not yet have all of the multicast options needed, so we need to turn to another library. Can we unpack "yet" a bit? I've run into [problems doing multicast with std](https://github.com/rust-lang/rfcs/issues/861) myself, and haven't put any effort towards solving them, in part because i don't know what should really happen. is it reasonable to expect std to support this stuff, or should std just provide simple support for common use cases, leaving those of us with more complicated use cases reach for external crates? If std shouid cover more ground, what is the right way to make it do so?
That implements a related, but orthogonal feature: The ability to reuse instantiations of generics that are also used by `extern crate`s.
Yes, for a subset of this: https://github.com/rust-lang/rust/issues/46477
I've had the same questions. `net2` seemed to originally be billed as a future replacement for `std::net`, but there were some issues with that crate. Alex pointed me at `socket2` when I was adding some of the multicast options to `net2` and it is a nicer library, but it's not clear right now that it's going to move into `std`. Does anyone have anymore info here?
Yeah, this video is definitely hairer than the previous ones, and as you observe it's in part because we're trying to abstract over a library written by someone else without this use-case in mind. Implementing futures is often an involved affair, though I don't think it's quite this bad if you do it from scratch (i.e., not on top of something else). I'm still debating what to do for the next video (see the latest Patreon backer post), though I suspect the next one will be a bit higher-level. Probably something more like what the third video was *supposed* to be, namely turning tsunami async. That would showcase how you *use* futures (as opposed to how you implement them), which I think is more widely useful and easier to follow. There will likely also be a video where we finish up `async-ssh` (e.g., `STDERR`, `AsyncWrite`, etc.), but that's currently a little blocked on [changes to `thrussh`](https://twitter.com/pe_meunier/status/975792041375490049).
According to the latest project meeting notes I could find (which are almost 7 weeks old) their hope is/was for a subset of the Beta population to get WebRender in Firefox 64: https://groups.google.com/forum/#!topic/mozilla.dev.tech.gfx/916NeNdjg3U It looks like that initial release would be limited to Windows 10 users with a discrete nVidia GPU. Firefox 64 is expected to hit the Beta channel in mid-October.
This is clear! Thanks 
Seems like the kind of thing that'll be useful to run over Rust programs once LLVM 7.0 bring it to release. If I'm understanding the article correctly, it'll be Valgrind-like, in that it won't require any special affordances from the compiler that might block it on Rust being ported to LLVM 7.0.
I have alot of repeated code like this: if let (Value::Number(n1), Value::Number(n2)) = (left, right) { return Ok(Value::Number(n1 - n2)); } else { Err(throw(operator, TypeError)) } where left and right are of type: pub enum Value&lt;'c&gt; { Nil, Bool(bool), Number(f64), String(&amp;'c str), } And I wonder, how to reduce this into a macro or a function. I tried writing my own macro, but didn't succeed because it would be ambiguous.
&gt; That's still unambiguous (but admittedly not that readable). It's certainly not parsable with one token of lookahead. I'm not sure whether there is an unambiguous grammar for it that also includes things like array access and list literals. &gt; for example with your syntax you can get some confusing situations when you use an array of literal ranges as the first or last parameter What do you mean?
I found the json output when looking for simplifed error formats. However it is quite complicated to try and add full support for that in sublime. You may be able to parse json to make error highlighting appear, but you'll still have an error log that is mostly a blob of unreadable json. I want a readable build log I can click on errors to go to them, and optionally have error highlighting appear in-line in the editor.
I'll try and get that working for me later, I suspected there might be something I just didn't find it in the docs. Also it's prefectly fine to not make this default, building from console should have build-from-console defaults. 
Ah, it was about `'static`. Thank you.
I am fine with things being an error, it makes you think about your type casting, so you can minimize them to reduce numeric errors. It's also a common optional warning to turn on in C/C++ compilers.
I've seen parser combinators talked about before, but Haskell conversations about them and the wiki page are kinda confusing. Do you have a post or description of them that's lower level?
This seems like a very good reason to prefer block comments in the default style, but it seems like rustfmt goes [the other way](https://github.com/rust-lang-nursery/rustfmt/blob/master/Configurations.md#normalize_comments), and so does the [style guide.](https://github.com/rust-lang-nursery/fmt-rfcs/blob/master/guide/guide.md#comments) :(
I just made a quick test to see what happens when you use both the `derive_more` and the `display_derive` crate. It turns out it depends import order. The first `extern crate ...` wins. So by importing `display_derive` first, you can make sure that that one is used.
Well, I'd assume it depends heavily on the machine running the code. The performance number isn't really useful in itself, but only makes sense when you are comparing it to another framework, or running it on your production servers. The author of the article performs the 1st deadly sin of performance numbers: Not stating what hardware he's running the code on. Given his screenshots he's running something Apple, but that leaves a lot of machines to be explored. But without knowing, his numbers are only useful in comparison to each other :)
The simplest solution to your problem is to store a `std::ops::Range&lt;usize&gt;` instead of a `&amp;str`. Then when you need to look at the actual string, provide a method on your AST that takes a `Range&lt;usize&gt;` and returns a `&amp;str`. Another approach is to not own the original `String` and instead tie your AST to the lifetime of the string it was parsed from, e.g., #[derive(Debug)] struct Tree&lt;'source&gt; { source: &amp;'source str, nodes : Vec&lt;Node&lt;'source&gt;&gt;, } You can't do it the way you have it setup because Rust doesn't know how to check sibling borrows. If you google around for the sibling borrow problem, you'll get more context.
Interestingly, I had already arrived at the `Range&lt;usize&gt;` solution independantly of you. Considering the quality of the crates that you have written, this has given me a nice confidence boost! I might look into the second solution however, as it seems cleaner to me and more in line with my original vision for the program's architecture. Thanks for giving this problem's general name - I assumed that it had been encountered by other Rust programmers but struggled to describe it in search queries. Do you know if any upcoming RFCs (NLL etc.) will resolve this 'sibling borrow' problem, or if it's effectively baked into the language at this point?
By the way - I took the liberty of posting this comment as a solution to the stackoverflow post I created in parallel to this post [here](https://stackoverflow.com/a/49394167/9524961) - if this is not OK then please tell me and I'll take the answer down.
Neoreader (my prototype Neovim screen reader / Python AST analysis plugin) supports quite a bit of what you mentioned there! It reads quoted text differently, so variable and function names stand out intonation wise. Speech gets slightly faster, and higher pitch wise, the deeper you indent. I tried making getting the MacOS speech backend to make small bloops on Vim mode transition, but it didn't want to output for some reason. 
This is actually a question about the `#[macro_use]` attribute. Both of the derives are considered "macros" named `Display`, so they get resolved the same way a macro like `println!` would be. And the way that works with `#[macro_use]` is that we go through your `extern crate`s in the order they appear in your `lib.rs`, and the last one to define `Display` is the one that we use. At least, I believe this is how it works! The macro import system is kinda hacky, and I could be wrong. In the future, we want macros to be imported just like everything else. With that system, you could `#[derive(derive_more::Display)]` and `#[derive(failure::Display)]`. But it isn't stable yet.
I'm pretty sure NLL's don't address this. I honestly don't know what the current thinking is on this, and I'm pretty sure that not all uses of this pattern are actually valid, so there's some non-trivial checking that needs to happen. Another thing to consider is whether allocating `String`s for each node is actually an issue or not. :-) I've generally found that it isn't, or more typically, that subsequent work tends to dwarf AST construction by a considerable amount. But of course, use cases differ!
How about defining `fn unwrap_number(self) -&gt; Result&lt;f64, SomeError&gt;` Given that, you can write `Ok(Number(n1.unwrap_number()? - n2.unwrap_number?))`
I should have mentioned that we were trying to reproduce this on fairly beefly linux machines: ``` 8 core + hyperthreading 64gig ram model name : Intel(R) Xeon(R) CPU E5-1660 v3 @ 3.00GHz cache size : 20480 KB ``` https://ark.intel.com/products/92985/Intel-Xeon-Processor-E5-1660-v4-20M-Cache-3_20-GHz
You could well be right that allocating `String`s wouldn't make too much of a difference - but I am a little bit infatuated with the idea of a program that constructs entire datastructures out of slices into the input. I seem to remember reading about a parser for JSON or YAML or something that used this technique and I thought it was such a neat idea that it's been bouncing around in the back of my head ever since. So that's the main reason why I'm doing it - because I think it's cool :)
Probably not actually finite; a parser for a harder language will have an implicit stack or summat in the state machine. The author does kind of drop the "finite" qualifier when they get down to details. On the other hand, a parser for a regular language should hopefully turn into an actual FSM.
That's a great point... let me see if I we can get the mysql db on an SSD drive.
Thanks. I didn't pick up that it did all that from the Neoreader page.
Haha yeah that's totally valid. Guilty of such things myself too!
Yes, there's the `MergeFunctions` pass. It doesn't seem to be run by default, though (according to `rustc +nightly -Zprint-llvm-passes -O &lt;source file&gt;`). From my tests, current LLVM trunk's mergefunc is only able to remove the function in the example above when it's run twice. The first pass removes two other duplicated functions.
Agreed. Allowing blind people to write comments that are pleasant for blind people is something, I guess. But much better if the default style for everyone is pleasant for blind people, either by using a style that is pleasant with current screenreader engines (`/**!`) or by the screenreader engine executing the sort of language-specific transformations described in this post.
I love the improvements in Combine 3, `range::recognize` and automatically encoding parsers as state machines for efficient partial parsing, are awesome. For intermediate rust content (2018 roadmap), it'd be great to explore writing parsers in `combine`, `nom` and `pest`. Currently, it requires a lot of knowledge and experimentation to know which parsing library is best for a particular use case. And prior knowledge of parsing techniques to understand comment threads on the subject. Even though I've done a fair amount of reading on the subject, I would still be an avid consumer. I'd produce it myself if I had more bandwidth. :)
I could use some help with https://crates.io/crates/wikibase if anyone is interested in rust and getting information in and out of Wikidata.
And it looks like this PR implements the full thing: https://github.com/rust-lang/rust/pull/48139
WOO! Exciting to see features like this merged into more mainline compilers. Most of what `Intel VTune` does is already codified by various 3rd parties.
fwiw `#![feature(nll)]` enhances the borrow checker to realize these sorts of cases. https://play.rust-lang.org/?gist=19bde7cd0f55ceb05be2dcc2fb6db021&amp;version=nightly #![feature(nll)] extern crate hyper; extern crate unicase; use unicase::Ascii; use hyper::{header, Response, Body}; fn main() { let mut res = Response::new(); println!("res: {:?}", res); append_header_vary(&amp;mut res, Ascii::new("Origin".to_string())); println!("res: {:?}", res); append_header_vary(&amp;mut res, Ascii::new("Accept-Encoding".to_string())); println!("res: {:?}", res); } // Append an item to the response's Vary header. fn append_header_vary(res: &amp;mut Response&lt;Body&gt;, item: Ascii&lt;String&gt;) { use header::Vary; match res.headers_mut().get_mut::&lt;Vary&gt;() { Some(&amp;mut Vary::Any) =&gt; // Vary already includes our item, so do nothing. {}, Some(&amp;mut Vary::Items(ref mut xs)) =&gt; { // Vary array exists, so append our item. xs.push(item) }, None =&gt; res.headers_mut().set(Vary::Items(vec![item])), } }
This is just me not using the correct terminology, sorry (my computer science knowledge can be a bit spotty in places, I studied primarily physics in college)! The parsers does actually encode to a pushdown-automaton (though except in simple cases where they will indeed be a finite-state machine). https://en.wikipedia.org/wiki/Pushdown_automaton https://en.wikipedia.org/wiki/Finite-state_machine
Improving USB support in https://github.com/ah-/anne-key. The happy path works well enough that it enumerates nicely and works as a HID keyboard. But there are a lot of corner cases that need to be handled, and I just figured out how to run the [USB Command Verifier](http://www.usb.org/developers/tools/), so I'll be tweaking it until all the tests pass.
The link in your blog post to the “Standard library API for immovable types” RFC is incorrect. It points to the RFCs repo rather than the actual RFC. 
I saw that the author had some licencing restrictions, so sciter was cool until I saw that. https://sciter.com/prices/
You can use the 'unsafe' keyword. Some people will bend over backwards to avoid it, but it does exist for a reason. Just be cautious about thread safety and make sure the unsafe stuff is tested. Alternatively store the actual memory in some other structure and then store an index into that in the tree.
Head on over to /r/playrust for better luck.
This is the wrong subreddit, you are looking for /r/playrust.
Isn't this subject to a possible race condition without a transaction? pub fn create(hero: Hero, connection: &amp;MysqlConnection) -&gt; Hero { diesel::insert_into(heroes::table) .values(&amp;hero) .execute(connection) .expect("Error creating new hero"); heroes::table.order(heroes::id.desc()).first(connection).unwrap() }
For some background, this is for my ongoing project to build an os that runs WebAssembly SIPs (Software-Isolated Processes) instead of a hardware-enforced usermode. This is a huge step forward and things from this point on are looking shiny!
Cool. I have some hope for wasm as a cross-platform IR for native code. Personally, I'd like to see it usable for things like reasonably high-performance plugins without losing portability.
Please refresh my memory in helping understand: Why are self-referential structs pivotal for async?
Eventually, everything aside from a minimal microkernel will be compiled into wasm on nebulet! I'd love to see compatability layers that allow the same wasm to run on web pages and in the nebulet kernel! 
This is a pretty neat article. I'm new to Rust (and really to programming in general) can someone explain why point 5D &gt; Restrictions on Values. Procedures, functions, types, labels, exception situations, and statements shall not be assignable to variables, be computable as values of expressions, or be usable as nongeneric parameters to procedures or functions. (i.e., not having first-class functions) would be considered a virtue of a programming language? The author seemed rather opinionated about Rust's design: &gt; The central failure of the language [Rust] is the myopic focus on the affine typing solution to heap allocation and thread safety. The creators do not seem to realise that other solutions already exist, and that dynamic memory allocation is not the only safety issue a programmer has to cope with.
I remember you! Nice work getting it to not only boot, but JIT WASM without leaving kernelspace. Do you know how well cretonne optimises its input? If it's good enough, then after the initial compilation, the lack of context switches could give it potential to be as fast as traditional OSes. 2 questions I have are how much do you sanitize the WASM to prevent it from crashing the whole OS, and whether or not you plan to cache the compiled assembly for future invocations or not. I think a JIT in this case could be very interesting, but I have a big problem with JITs like Java recompiling the code over and over every time I launch it.
Consider what you might do to convert an async function into multiple functions. You might represent it as a state machine using an enum of structs were the structs represent what state is passed between calls. What happens if part of that state is a reference? It'd be turned into a self-referential struct.
That's impossible. The whole point of trait objects is to access the methods through a consistent vtable, but there's no way to build a consistent vtable if each instance has different types. You'd have to put the result of `get` behind something else like `Box&lt;Any&gt;` or a closed enum.
Can you show me an example? Someone else also suggested this.
There's not much to show. Just replace the result of `get` with `Box&lt;Any&gt;`, or with an enum that lists every concrete type it can return, whichever is more appropriate. Or `Box&lt;SomeTrait&gt;` where `SomeTrait` defines the interface you need the returned values to have. I can't be more specific because there's zero context on what you're trying to do.
They also characterized rust's syntax as "terse and difficult to read". Not sure rust was getting a fair shake.
I'm working on a web program written in Rust, it is a simple API, the user interface is simple, but it does the job, I'm happy to be using Rust, and hope to continue to use it even more.
&gt; (i.e., not having first-class functions) would be considered a virtue of a programming language? Because the Steelman document was formulated in the 1970s, at which point in time people were still arguing whether C compilers ought to forbid recursion. Part of both that and the aversion to first-class functions could have been borne out of the fact that blowing your stack due to nested function calls was more of a problem back then (both because memory was more scarce, and because inbuilt protections against memory errors were less prevalent). Another part of your quoted paragraph might be an oblique reference to a feature from older languages called "computed goto", which the authors may have desired to avoid due to concerns about correctness and maintainability. &gt; The author seemed rather opinionated about Rust's design The OP appears to be a fan of Ada, and in my experience people well-versed in Ada are frustrated that Rust appears to have successfully appropriated the terminology of "safety" that Ada has been unsuccessfully trying to use as a marketing tool for several decades.
Is this inspired on things like Jekill, how does it differentiate itself from tools like that?
You're asking it to downcast to `i32`. *Of course* it doesn't work on a string. Like I said, you can only downcast to the original type. You need to try downcasting to all possible types. If all you need to do is print the values, try returning `Box&lt;std::fmt::Display&gt;` instead.
As usual with these articles there's all sorts of little quibbles with Rust (and probably with other languages too, but I don't know enough about them): - 1B Reliability: D gets a "yes?" but Rust a "Mostly?", with no justification. - 1C Maintainability: focuses entirely on syntax, but ignores the maintainability benefits of things like `enum`s. - 2B Grammar: Rust was relatively carefully designed to be simple to parse, and seems worth a 'mostly'. - 2C. Syntactic Extensions: Rust's macros are marked and delimited, meaning places with "new syntax" are contained, so maybe a 'partial'. - 4C. Side Effects: Rust's `&amp;mut` has much stronger guarantees about mutation than (I think) D and Pascal, but has the same rating. - 5E. Initial Values. Rust doesn't provide default initial-values for variables and yet only gets a 'mostly'. - 6G. Explicit Control Transfer. This is a ... very weird requirement. (Also, D's `goto` seems to be able to go into control structures.) - 7A. Function and Procedure Definitions. Rust can define functions and procedures, but not overload them, so this seems like a 'partial' or 'mostly', based on how other criteria have been rated. - 7D. Function Declarations. Why are these all mostly? - 7F. Formal Parameter Classes. input-output is `&amp;mut`. Also, output seems like a return value (especially with multiple/tuple returns), but quibbling with the Steelman itself isn't the point of this exercise. - 7H. Formal Array Parameters. I think this is actually a 'yes', as arrays, slices and `Vec`s include their `len()`, and is likely meant to be in contrast to C-style "arrays" (i.e. plain pointers) where the length needs to be carried separately. - 8A. Low Level Input-Output. This is also a yes or mostly. - 8E. Resource Control. D gets point for custom garbage collection, but I think Rust has even more control over resources. 'partial' or 'mostly'. - 10D. Exception Handling. Ignoring the bit where Rust doesn't literally use something called "exceptions", it seems like it satisfies all the requirements. 'yes'. - 13G. Software Tools and Application Packages. My general impression is Rust's tooling is at least as good as D's at the moment, so 'mostly'. Also, there's a rather major quibble in the intro: &gt; The central failure of the language [Rust] is the myopic focus on the affine typing solution to heap allocation and thread safety. The creators do not seem to realise that other solutions already exist, and that dynamic memory allocation is not the only safety issue a programmer has to cope with. I don't know of any (fundamentally) different solution that gives memory safety in the presence of dynamic allocation, without GC, and also, affine typing does more than solve dynamic memory allocation (e.g. session types, and general control over aliasing).
I find these results very interesting. Async IO is supposed to perform significantly better that synchronous IO, yet Rocket (which is synchronous) still largely outperforms Node and Restify. Rust and Node obviously are very different technologies, so maybe it doesn't make sense to push the comparison further than that. Still, there's [an issue](https://github.com/SergioBenitez/Rocket/issues/140) in the Rocket repo regarding performance, and it doesn't seem like the Tokio stack makes a huge difference either. So what's the takeaway from this ? Maybe your average web application shouldn't worry too much about the sync vs async IO situation ...
If the framework is no longer being maintained, you need to either maintain it yourself or switch to a different framework. The ones I've heard the most good things about are Rocket and Gotham.
is there any explanation why iron was abandoned?
I'm a little naive about this kind of stuff. But is there any point in making a new os other than as a hobby?
It's mostly about challenging oneself and gaining an appreciation for the monumental task of making an OS viable that Linux, Microsoft, and Apple have achieved. It's a lot of hard work, but it's easier to appreciate said work if you've been through it yourself. That said, hobby OSDeving can also be about trying new ideas that no established OS would try simply due to being too well established. For example, this project seems like one of the most viable attempts at an OS that handles protection through an intermediate representation rather than hardware circuitry, while my own project is an attempt to make a kernel inspired by Pony and the actor model to the point where (ideally) tasks would be distributed across the network as transparently as across cores.
here's on note on the last commit: https://github.com/iron/iron/commit/9e5bccb407b1ec8daef51b0d7494627e5c5fc307
I need to get a copy of the value of type T.
More of a mix between Hugo (single binary) and Pelican. I have a comparison table here: https://github.com/Keats/gutenberg#comparisons-with-other-static-site-generators I have never used Jekyll myself because it requires a ruby env so it's not in the comparison table - I'd take a PR from someone that knows about it though.
&gt; The OP appears to be a fan of Ada, and in my experience people well-versed in Ada are frustrated that Rust appears to have successfully appropriated the terminology of "safety" that Ada has been unsuccessfully trying to use as a marketing tool for several decades. It's also a point that Andrei Alexandrescu (creator of D) frequently voices, without looking further. It's a bit frustrating, as he clearly hasn't every had a look at how affine typing is _further_ used in the language. 
check the first posts in this series. they explain it and are awesome. 
That's awesome. A lack of self-referential structs has been a recurring annoyance for me
For an example of the second solution, that's how I use lalrpop: https://github.com/dagit/rust-prolog/blob/master/src/parser.lalrpop#L13 Notice that the `grammar` directive introduces the lifetime parameter `input`. Then the token for string: Token::STRING(&lt;&amp;'input str&gt;) The `token` type itself is defined here: https://github.com/dagit/rust-prolog/blob/master/src/token.rs#L15 I hope that helps. I don't remember where I learned to do this, but I think I figured it out from reading lalrpop's own sources.
So I guess Gary Bernhardt was right, only it's WASM instead of javascript ... https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript
I've heard this before, stated as "Rust skipped leg day". Things like lack of self-referential structs in the regular syntax, that practically every other mainstream language supports, alongside a really sophisticated build system. The most frustrating parts about Rust are often places where the solution is technically possible, but requires so much more effort or is so obscure that most people would give up and go back to python or go. Look at the string situation. There's cstring cstr String str OsString OsStr PathBuf Path. That's 8 types and if you're doing interop with legacy C code you likely have to use all 8 of them in some way. But only String has the full set of formatting functions, but it's the most specific of any of them. It definitely feels like there could be a more elegant solution on par with python, but that's not the case.
This is a really great idea. Good work!
`noisy_float` is a very nice suggestion. I like that its behaviour can change in debug builds where you might wish to test edge cases
It is, and it's also a performance issue, since it needs two round-trips to the server. You'd need something like a `SERIALIZABLE` transaction, or `REPEATABLE READ` in Postgres. I think Diesel prefers (and supports) using `INSERT INTO ... RETURNING`, but MySQL and SQLite don't have that. The alternative in the case of MySQL is to do a `SELECT LAST_INSERT_ID()`, which brings back the performance issue, because the `INSERT` and `SELECT` statements can't be submitted together. I'm also not sure about how it interacts with triggers, since it seems to be per-connection instead of per-scope.
The simplest solution i can think of is changing your tree to #[derive(Debug)] struct Tree&lt;'source&gt; { source: &amp;'source str, nodes : Vec&lt;Node&lt;'source&gt;&gt;, } https://play.rust-lang.org/?gist=4dfd2d013eeb7f7f52e0eb03d503f0b8&amp;version=stable
Also shout out to [actix-web](http://github.com/actix/actix-web), which I've been using with great success.
Note that the video description is wrong, instead of Jeffrey Seyfried on Procedural Macros we have Patrick Walton showing off Pathfinder.
Ahh, yes. Rocket is quite wordy on stdout. You could try running it with `env ROCKET_ENV=prod ...` as that should eliminate the default logging completely and see if that pushes it even higher :)
WebAssembly is designed to run in a sandboxed environment because it was originally designed to be used in web browsers to execute potentially untrusted code from websites. It is also machine-independent, meaning that you can run the same WASM module on an x86_64 machine and, for example, an ARM-based smartphone (this, again, is obviously something you want for the web application usecase). Compiling a WASM application to native machine code gives it near-native performance if done right (the code generator used here, [Cretonne](https://github.com/Cretonne/cretonne), doesn't reach that kind performance yet). Doing this in the kernel (ring 0) allows you to run untrusted WebAssembly modules in the highest privilege level without having to worry about the program crashing your system or accessing the memory of other applications. In theory, the WebAssembly sandbox replaces the hardware security features that are usually used for this purpose (distinct address spaces, privilege rings and privileged instructions, paging with `rwx` permissions per page).
Thank you, it makes things clearer. When you mention WASM compiles into native machine code. How is that achieved?
My [`Cargo.toml`](https://github.com/iliekturtles/uom/blob/da87b7f270e873dbb089c12bb3b8a141b637777f/Cargo.toml) depends on `num-traits` and optionally on `num-rational` with `default-features = false` for both. I also have a `std` feature that adds the `num-traits/std` feature. I would also like my `std` feature to include `num-rational/std`, but only if `num-rational` is already included by the `rational-support` feature. I could add `num-rational/std` to the `std` feature, but this would cause the dependency to be compiled, even if it wasn't going to be used. Is there any way to include `num-rational/std` only if `num-rational` itself is also included?
As I mentioned above, this kernel uses Cretonne for code generation, which happens to include a [WASM frontend](https://github.com/Cretonne/cretonne/tree/master/lib/wasm) already. This translates the WASM module to Cretonne's intermediate language (IL), which is analogous to LLVM IR produced by rustc. Just like LLVM, Cretonne contains [code generation backends](https://github.com/Cretonne/cretonne/tree/master/lib/cretonne/meta/isa) that translate Cretonne IL to native machine code that can then be run. Of course, the details of this whole process are much more intricate, but you can check out the code I linked above if you're interested. Cretonne also has pretty amazing documentation: https://cretonne.readthedocs.io/en/latest/
Hi, the posting is from February, but the position for an experienced developer is still open. This is my company. Please note a couple of things, as there have been frequent questions: * Because of the training part involved, the position is mainly on-site in Berlin. * The position isn't 100% Rust. We're a consultancy for backend development, and projects we're consulting on aren't always written using it. We have a growing Rust implementation business, though. * We have a sizeable Rust training business, which you would be part of. So being able to train people is a necessity. Best, Florian
&gt; It definitely feels like there could be a more elegant solution on par with python, but that's not the case. It's not that the case that there could be such a solution, or that there is? These types all have clear rationales and represent true complexity of the real world.
Rocket is pretty great in my experience.
&gt; solution to heap allocation and thread safety. The creators do not seem to realise that other solutions already exist So there's GC, which solves heap memory safety, and usually solves stack memory safety by virtue of not allowing stack memory references, or only in very limited circumstances. And GC is not a solution to thread safety at all. The only other system I know of there is strict process separation a la Erlang. Any other systems I should be aware of? The author conveniently forgets to give some examples. &gt; and that dynamic memory allocation is not the only safety issue a programmer has to cope with. Of course, Rust also solves dangling stack references, general resource allocation, and data races. Various Rust libraries have also shown that the Rust type system can solve many other safety issues as well (glium comes to mind).
What is noise_float
The Steelman is sometimes obsolete and sometimes it's just a mirror of different needs and ideas. So I think this language judgement isn't very important for Rust. I think to take the good ideas and ignore the rest: &gt; 3-2A. Enumeration Type Definitions. There shall be types that are definable in programs by enumeration of their elements. The elements of an enumeration type may be identifiers or character literals. Each variable of an enumeration type may be restricted to a contiguous subsequence of the enumeration. Sub-ranges for integral types and enumerations is something that I miss in Rust. They increase code precision, make the code more explicit (stronger typing), help catch some bugs faster. &gt; 3-2B. Operations on Enumeration Types. Equality, inequality, and the ordering operations shall be automatically defined between elements of each enumeration type. Sufficient additional operations shall be automatically defined so that the successor, predecessor, the position of any element, and the first and last element of the type may be computed. I miss a more flexible handling of enumerated values in Rust: it lacks successor, predecessor, the first and last element of an enum, the compile-time counting of enum variants, and few other handy things. &gt; 3-3D. Array Specifications. Arrays that differ in number of dimensions or in component type shall be of different types. The range of subscript values for each dimension must be specified in programs and may be determinable at the time of array allocation. The range of each subscript value must be restricted to a contiguous sequence of integers or to a contiguous sequence from an enumeration type. In Rust I miss a simple built-in optional way to require an array type to be indexed only by a specific type, ranged type, or enumeration. &gt; 3-3E. Operations on Subarrays. There shall be built-in operations for value access, assignment, and catenation of contiguous sections of one-dimensional arrays of the same component type. The results of such access and catenation operations may be used as actual input parameter. Currently the Rust handling of fixed size array is still lacking. The constant generics will help, but more things are useful, like better safe slice &lt;=&gt; fixed array conversions, smarter and stricter compile-time handling of array lengths, and more.
Fantastic. Thank you. 
Lots, exploring new ideas, new architectures, new systems programming languages. I would be quite sad for computers to be stuck with UNIX clones.
P-Code, TIMI, Lisp, Xerox systems, M-Code, ... and many others were there first.
https://crates.io/crates/noisy_float
Congratulations, this looks like an exciting step toward using wasm everywhere!
&gt; Things like lack of self-referential structs in the regular syntax, that practically every other mainstream language supports, alongside a really sophisticated build system. Arguably no other programming language supports this. Some allow garbage collected or raw pointers, but that has different semantics compared to self-referential structs and can be done in Rust in a similar way.
Can confirm: Gotham is awesome. No Form support yet, though. I hope it lands soon! I have zero experience with web dev but got some nice things working after 11hrs with Gotham.
&gt; Sub-ranges for integral types and enumerations is something that I miss in Rust. They increase code precision, make the code more explicit (stronger typing), help catch some bugs closer to their origin point. Sub-ranges for integers with run-time checks can be implemented in a library, why would you need language support for that?
I'll be the dissenting voice here. I think there are multiple reasons to prefer line comments and it's not worth switching for the very small minority of blind programmers.
&gt; I miss a more flexible handling of enumerated values in Rust: it lacks successor, predecessor, the first and last element of an enum, the compile-time counting of enum variants, and few other handy things. It's a bit tricky because Rusts enums are more powerful than those intended by the document. What is the successor of `Option::&lt;&amp;'static str&gt;::None`? I suppose it could be done for `[repr(C)]` enums.
Cretonne doesn't have super fast output just yet, but it'll get better over time. Right now, the wasm is just compiled and run. There's actually no way to make sure it does the right thing, other than trust the compiler.
I hope so!
It would be nice to use the [floating-point environment](http://en.cppreference.com/w/cpp/numeric/fenv) for this, but it seems like LLVM does not support it.
[actix-web](https://github.com/actix/actix-web) is feature rich framework (sessions, multipart, websockets, even protobuf), it is not as high level as rocket, but it compiles on stable and much faster. 
How much of the work would be proprietary and how much open source (roughly: are you a fully proprietary shop, fully open source, 80/20)?
Do you have a webpage for your OS? Distributed Pony sounds interesting. It seems to me that this would have applications in kilocore chips with local memory too.
I wish rust had a presence at gdc this year:)
&gt; There's cstring cstr String str OsString OsStr PathBuf Path. That's 8 types and if you're doing interop with legacy C code you likely have to use all 8 of them in some way. But only String has the full set of formatting functions, but it's the most specific of any of them. It definitely feels like there could be a more elegant solution on par with python, but that's not the case. `PathBuf` and `Path` are not strings, they are paths. I realize that paths can be created from strings and converted to strings but so can numbers (which are definitely not strings). Many high level languages also draw a distinction between immutable strings and mutable strings. Java &amp; C#, for example, both have `String` and `StringBuilder`. Haskell, arguably even higher level than either Java or C#, has no less than [**5** string types](https://mmhaskell.com/blog/2017/5/15/untangling-haskells-strings). Strings in Rust aren't as simple as they are in Python or Ruby, but there are valid reasons for this. Making Strings efficient cross-platform is not easy especially when Windows is UTF-16 and most *nix's are UTF-8. Rust is a systems programming language and when there is complexity that can't be abstracted away in a zero-cost way, the responsible thing to do is to expose this to the programmer and let him or her make the decision. When I code, I my general rule of thumb is "make it work right, then make it work fast". If string processing isn't a hotspot in your application, then by all means use `.to_string()` and `.clone()` liberally and just use `String`. You can always come back later and borrowing to make the code more efficient. 
Back in the nineties it was PBNF which was a form of ast you'd ship then it would compile down to machine code on the host computer. 
Here's how type-aware keys can work: https://play.rust-lang.org/?gist=e7e015a404f5dbf464d2cdeab66bb058&amp;version=nightly Note, however, that this will probably not help you with the internals of your library, as you need to be aware of the definite type of your values to process them, i.e. your library cannot process the vector of anys without knowing exactly what is stored in them.
I think this is a great idea! What's your confidence level in SIP? I note a few things in the WebAssembly security doc: http://webassembly.org/docs/security/ (are these required to fully trust code in ring 0?) * module defined trap handlers - aren't there yet * support for multiple linear memory sections and finer-grained memory operations - aren't there yet. Thanks! 
I think the idea is that if you can have compile time checks. So you can define values like only positive, only odd, only even values and have that checked at compile time. 
Is it necessary to come to Berlin for the interview or are you able to do interviews via Hangouts / Skype? Is there a phone interview to prepare for / how many interview rounds do you have? 
Most of the work is client side internals, so it's mostly proprietary. What we produce on our own is often open, for example our teaching material for courses is fully open under permissive licenses.
I thought the position is for teaching. 
Interview over phone/skype is perfectly fine. Expect 1-2 interviews, both 1 hour tops. We have a pretty lean application process and generally don't do coding exercises (we found them to be bad representations of a) the work we want and b) use of applicants time). Spend that time on an honest and representative CV instead :).
It's probably "[...] just a hobby, won't be big and professional like gnu [...]".
I'm tentatively confident in the security of SIPs. To be more confident, I think that the codegen (cretonne) needs a *lot* of fuzzing and correctness reviews. None of those are required to trust code in ring 0. Actually, as the wasm api surface expands, security could possibly get worse.
I'm working on ingesting a large number of logs (~350GB zipped, ~2TB (or more) unzipped), into Postgres so I can generate some nice reports from them. I had this process going in Python, but my computer was running out of memory when I started hitting the larger log files. Switched to postgres-rust and now it's going great (lots of memory left, and it's faster to boot!) Side note: Postgres can only handle ~65000 bind parameters, so for massive inserts, it's much more effective to sanitize the data yourself and just send huge 100K batch inserts, instead of using prepared statements with binds and doing only 5K batches.
Watching that talk actually got me into osdev...
This feature should be studies. Both library-defined and built-in solutions have both advantages and disadvantages. The advantages of a built-in feature are a faster compilation if your program defines hundreds or more different ranges, you can perform reliable compile-time checks, the type system is able to perform a smarter handling of them, you can use a nicer syntax, people are often more willing to use features if they are built-in, etc. The disadvantages are more compiler and type system complexity, we don't know how much Rust programmers will use this feature, ecc.
Defining things like an only-odd-values integral type is sometimes useful but this requires more than sub-ranges, it needs to associate compile-time predicates to a type (see Liquid Haskell and Ada 2012 Static_Predicate). For a first stage of this feature for Rust I think it's enough to allow sub-intervals (0.., 0..50, 1..=5, etc) only: type Positive = u8[0 ..= 99];
I mean, a fundamental part of the appeal of rust is that you can catch problems *at compile time*.
Thanks! I've sent you my resume :)
Because the `!` type is now stable does this mean that `TryFrom` can be stabilized?
Just to note that applying a range to a string has to check bounds and UTF-8 character boundaries each time, so has a slight cost over &amp;str, so using &amp;str would be cleaner.
It's both, I think it's a good split to work on what you teach. For me, it's currently roughly 50/50, I rarely do full projects but help out at places. I would call it "consulting", if the word weren't so misused.
&gt;Matrix client for GNOME written in Rust. What makes this "for GNOME?" Can I only run this app with a particular desktop environment?
It uses GTK+ and is maintained by one of the GNOME developers.
&gt; I miss a more flexible handling of enumerated values in Rust: it lacks successor, predecessor, the first and last element of an enum, the compile-time counting of enum variants, and few other handy things. What would they be useful for? I can't say I've ever desired such operations, because to me enum variants don't have an "ordering" (unlike struct fields, multiple variants never exist within a single enum simultaneously).
:[ I got caught up and couldn't make it.
yes but there's some small complications, it's not immediate. https://github.com/rust-lang/rust/pull/49038 it is the last huge blocker, as far as i know!
Don't use Hyper directly. I personally really like actix-web; it's got a quite ergonomic API and works on stable Rust. Gotham is also available on stable, and some others. Relevant to this thread: http://www.arewewebyet.org/ still exists, and I have been working on improving it. If anyone has any changes they would like to make, please submit PRs and I will review them.
If I understand correctly, 5D was created at a time when Fortran and C had not only function pointers but freaking *goto* pointers, non-reentrant subprograms were the norm, and function pointers weren't strongly typed. It was quite right to say "oh hell no" to that mess. (Reentrancy is the ability to enter a subprogram while it is already running. This means local variables must be allocated on the stack. Old FORTRAN kept local variables in the equivalent of `static mut` locations, so if you tried to do anything recursive it would fail badly. Safe Rust `fn` functions must be minimally reentrant (they can panic or be wrong but not undefined). Safe Rust does understand non-reentrant calls: the FnMut and FnOnce traits enforce the only one call at a time rule.)
Yes, I'm well aware. The times in which bounds checks have mattered in my experience are exceedingly few. It happens, but not often. If you're at that level where the performance of bounds checks matters, then use `unsafe`.
You can also implement a method on the tuple `(Value, Value)` directly. However, you have to define a trait for that first. The advantage is that you can then use the result to chain further operations. [Example](https://play.rust-lang.org/?gist=78d7f85fb7c10f977e1e2aff036073bb&amp;version=stable)
Note that the big event that is missing is the Rust project all-hands next week in the Berlin office. There's even a special edition of the Rust Hack &amp; Learn for that: https://www.meetup.com/Rust-Berlin/events/248733123/ So, if you see us all very active planning on our bug trackers: this is the reason.
Later I'll try to give you a better answer, for now I answer part of your message: &gt; I can't say I've ever desired such operations, Sometimes it's not easy to imagine where to use a feature you have not used yet. &gt; because to me enum variants don't have an "ordering" I think in Rust you can order enums: #[derive(PartialOrd, Ord)] enum Foo { A, B, C } use Foo::*; fn main() { println!("{} {}", A &lt; B, C &gt; B); }
The problem with even that strategy is that only &amp;str constants can be created, different string classes have different members, and string is the only one with a complete set of members but is also the most specific subset of all of them so converting to string requires managing the errors. At the very least having a string trait with consistent semantics for all of them would mean that regardless of which string-based type you're working with, you don't have to keep a different set of rules in mind.
Isn't that really just what `str` is? Most of `String`'s functions come from the fact it derefs to `&amp;str`.
The only thing stopping rust from doing the same thing as python are exceptions, but liberal use of? would work for everything but operators. There's benefits to Rust's approach, but every time I do work with paths it just feels like a part of the language that hasn't been addressed very well because it will suddenly require five lines of non-functional code to generate a filename (because osstr has almost no members) and trial and error to move between the types because each one uses new() and from() to convert. You end up being forced to focus a lot on the mechanics of what you're doing rather than what you're doing, and the fact you're dealing with paths suggests that the string operations are not the bottleneck of your code.
I expect this tool to be great for CPU bottlenecks, but does anyone know how it'll perform if the bottleneck is at the cache level? (for example, fetching data from L2 because L1 is trashing)
`!Unpin`? I am excited by the progress here, except for this trait name. I always have trouble wrapping my head around double-negatives :(
Sure, but that goes back to my point about cross-platform APIs. On *nix `OsStr` is probably UTF-8 and on Windows it's UTF-16. You've got to get your strings in the same encoding before `starts_with()` even makes sense. A trait for strings is an interesting idea but I suspect that it has the same issue as the various other collection traits that have been requested: lack of HKTs/ATCs. Without either of those features, you won't be able to have functions which need to return instances of the implementing type. Which basically just leaves you with `contains()`, `starts_with`, `ends_with`, `index_of`. 
In general if enums could implement Iterator this would be solved?
I notice that it specifically uses `std::any::Any`. Can I still use it with `core`?
Congratulations! What are your plans regarding controlling access to resources: - address space, - files, - sockets, - ... and what are your thoughts on Meltdown (whose mitigation required a TLB flush when exiting kernel mode)?
 enum TrafficLight { Red, Green, Yellow } One issue with this is that the representation here isn't guaranteed to be in source order; the default way that ParitalOrd's derive works uses it, but we'd have to decide that these features would also rely on it. Not impossible, but an important question.
Awesome! This is directed at everyone interested in this kinda stuff, take a look at [Exokernels](https://en.wikipedia.org/wiki/Exokernel) and [Spin](http://www-spin.cs.washington.edu/) an OS written in Modula3 that uses runtime safety properties of the Modula3 language to dynamically extend the OS.
Two solutions is to give a standard ordering to the tags of all enums, or introduce some kind of enum annotation, like #[tags_only], that assures that...
This pattern is also commonly referred as a "self-referential struct." [this](https://internals.rust-lang.org/t/improving-self-referential-structs/4808) thread on the internals board has a lengthy discussion of the implications and current thinking surrounding this topic. If you want your tree to be able to own both the string and the nodes, the [rental](https://crates.io/crates/rental) crate will allow you to do this, at a slight ergonomic cost. As with anything, there are trade-offs.
Useful when you use enums as in C (eg, a collection of constants); pointless when you use enums as sum types.
&gt; Guess it's just my stile of quickly getting some output on the screen. The "proper" way to do that while developing a library might be to add this to `Cargo.toml`: [lib] name = "mylibrary" path = "src/lib.rs" [[bin]] name = "sample" path = "src/bin/sample.rs" Then run the `sample` binary with `cargo run --bin sample`. The `src/bin/sample.rs` should simply contain a `main` function like usual.
I am *glad* that Rust fails on a number of the requirements! Specifically: - 3B/3D: The Steelman requires subtyping (which the OP interprets as inheritance); I find type classes better, as they do not mix inheriting both interface &amp; behavior. - 5B: The Steelman mandates type annotations (at least, that's the OP interpretation: it may actually mandate typed variables); I find type inference leads to much clearer programs. - 6G: The Steelman apparently requires `goto` (at least, that's the OP interpretation) but forbids computed `goto`; in that case, I find labelled breaks/continue much easier to follow. - 7A: The Steelman requires Ad-Hoc Overloading; I find Rust's principled overload (via traits) much more explicit in practice. - 7F: The Steelman requires in/out parameters; I much prefer the ability to return multiple values (tuples!). - 10A-G: The Steelman seems to equate error-handling to exceptions; I much prefer sum types. So, according to the above, I'd add 10 points to Rust for doing **better**. Then if you tally dbaupp's points for 1B, 1C, 2B, 2C, 4C, 5E, 6G, ~~7A~~, 7D, ~~7F~~, 7H, 8A, 8E, ~~10D~~ and 13G (avoiding double-counting), you also need to add 12 points that the author forgot (probably from unfamiliarity). With that, the revised scores: - Rust fair matching (just from dbaupp): 86% (1st place), - Rust vs revisited: 95%. In the remaining areas are notably the lack of standard and the lack of const generics.
I think he fears that web developers will take the code and modify it in a way that goes against his vision.
&gt; Your strings are already in the same encoding by dint of being the same underlying type. Sure, that's true. I assumed you wanted to do something like `myPath.starts_with("example-")` which would (potentially) require a conversion. My apologies. I don't think there's anyway to formulate that type signature either which is probably why there is no string trait. &gt; Whatever the reason, the end result is still the same, for the end developer it's often a pain in the ass to work with strings if it involves a filesystem. I agree with you 150%. I just wanted to point out that this isn't unnecessary complexity. I tried looking for a crate which exposes "simple" path semantics but couldn't find one easily. Perhaps a crate which simplifies some of these things at the expense of runtime performance would be useful? 
Something like that would be ideal, but practically anything would be better than the way it is now. That conversion should be able to be done at compile-time, but of course there are no osstr literals and you'd need a const fn to do it without them... I was working on one myself but never seem to have the time to finish such things. More for paths (basically porting pathlib with ergonomics first). But it sounded like the intention had been to add such functions to the other string types and nobody had gotten around to it 
yep, those silly web devs... bypassing GitHub security and Pull Request checks and instead committing directly to other people's `master` branch while the repo's owners are asleep. If only repo owners could... I dunno... reject pull requests that didn't align with their vision of the repo. I've heard that same statement as what you made other places regarding Jai, and it's such a ridiculous thing to me. A part of me really just thinks it would be fun to release the world's first public Jai compiler *before* Jonathon Blow *just because*, but I don't have time to mess with anything like that.
As a Rust programmer, I'm not surprised you have trouble allocating. :P
pcwalton as well as trishume, both Rust coders I highly admire! It's people like them who make this community so great.
I bet he won't be publishing on github, because he hates git.
&gt; I think in Rust you can order enums: Heh, I didn't realize this was possible. :P &gt; With it you can implement the cycle in a less bug-prone way compared to the current Rust solution of using a match. Can you give an example? Because doing this in Rust is one trivial non-bug-prone line of code: let mut light = [Red, Green, Yellow].iter().cycle(); And frankly, given that nearly all state machines are far more complicated than a cycle, eventually you're going to need something like a match anyway (which in Ada I presume is a switch). And even calling the match statement "bug-prone" is a huge stretch, as it's also trivial to write and read.
But what about just take `app_dirs` name (without `2`) if nobody mantains `app_dirs`?
I find it a bit strange that your business number is a cell-phone number. Doesn’t seem very professional to me.
Cause the guy that owns it isn't responding to questions/giving it up. Crates team won't revoke crate ownership either, for good reason.
&gt; the compiler verifies at compile-time that INPUT contains only the allowed chars. This is nifty, but looks less like an issue with enums and more like desiring overloadable string literals. &gt; Other usages of handy enums is to index arrays (strongly typed array indexing) this is both reliable than converting things yourself, and more efficient than using an associative array. Can you give an example of what you mean here? It sounds like the intent is "create a fixed-size array and give a name to each field" (e.g. the command-line arguments array for your custom-built grep program might be represented by 0 = PROGRAM_NAME, 1 = PATTERN, 2 = FILE, and used like `argv[PATTERN]`), but I'm confused because that isn't usually what people mean by "strong typing", and in most cases would be better served by a struct anyway, since those already have named fields.
Sorry, I didn't mean to imply that Hyper was bad or anything, I just wouldn't want to use it directly without abstraction. I didn't have problems that I would say were "hard", per se, just very boilerplatey. I had several different endpoints (which made me want a router), CORS stuff to deal with (which made me want a middleware system), request-body reading, asynchronous long-polling endpoints, varying output encodings, etc. Once I switched to a higher-level framework, my code got a lot simpler and more directly readable. When I started my project, and it had two endpoints (one POST and one GET, no long-polling, hardcoded CORS), Hyper was fairly easy to get going with.
To do that in general you need dependent types and a way to help the compiler with the proofs.
Is this similar in spirit to [telegraf](https://www.influxdata.com/time-series-platform/telegraf/)?
I am actually rather interested in this. Any chance you could throw up a roadmap/couple issues you are looking to address? 
I'm not sure what your point is. Yes, Rust is more explicit and lets you choose. I would still say that for instance using `Rc` in Rust is similar to how Python deals with the problem.
It's not just about efficiency, but also correctness: There are valid file names that cannot be represented as a `String`.
Ah OK, that does sound like exactly what a framework does: have an opinion on how a user you should setup these extra things. I do think that soon, there will be a collection of middlewares in tower that easily plug into hyper, but it's probably going to be a little more manual than a framework that plugs things together for you.
[I made a very simple binary search tree!](https://gist.github.com/Wesleysaur/bcc5c1f0fd6a3109f1663a63687d504d) I'm still very much a noob and this was my first bite sized project after FizzBuzz so I was excited to get it working without too much fighting with the borrow checker. Any tips appreciated!
you can check [TechEmpower benchmarks](https://www.techempower.com/benchmarks/#section=data-r15&amp;hw=ph&amp;test=plaintext) just compare async frameworks performance tokio-minihttp,actix,hyper with iron which is sync framework. rocket should performance very similar to iron. if you need to get maximum performance, async is the only option otherwise it doesnt matter.
&lt;div class="reddit-embed" data-embed-media="www.redditmedia.com" data-embed-parent="false" data-embed-live="true" data-embed-uuid="ed09c065-44fd-408c-8fad-a2d8b98b9ccb" data-embed-created="2018-03-21T19:29:02.048Z"&gt;&lt;a href="https://www.reddit.com/r/ada/comments/84oo49/anyone_here_that_has_experience_in_ada_and_rust/dvxmq0w/"&gt;Comment&lt;/a&gt; from discussion &lt;a href="https://www.reddit.com/r/ada/comments/84oo49/anyone_here_that_has_experience_in_ada_and_rust/"&gt;Anyone here that has experience in Ada and Rust or not, and can compare? It seems to me the languages are similar in their safety and overall features. :)&lt;/a&gt;.&lt;/div&gt;&lt;script async src="https://www.redditstatic.com/comment-embed.js"&gt;&lt;/script&gt; 
oli-obk5 points2 days ago There are some fundamental differences between how Ada and Rust solve (or don't solve) safety concerns Variables of integral types often should only contain a certain subset of numbers that the backing memory can represent Ada solves this very well with ranged types Rust has no builtin solution for this, but there are crates for it You should keep global mutable variables to a minimum Ada does not address this Rust treats mutable global state as unsafe, but allows it (for now) as an escape hatch for when you can't implement something otherwise You should not access the same memory from multiple tasks without synchronization Ada has language builtin synchronization primitives, but you are not forced to use them Rust has synchronization primitives in its standard library and you are forced to use either them or other from external crates. Otherwise you cannot access the same memory concurrently. You should handle all errors Ada raises exceptions that you can catch and forward, or are implicitly forwarded if not handled Rust has Result types that you need to forward or handle, but are not implicitly forwarded Instantiation of Generics Ada requires you to explicitly instantiate a generic under a new name and then use it through that name Rust allows you to implicitly use a generic Type aliases and subtyping Ada can create an exact duplicate of a type under a new name that is incompatible with the original Rust can only create alternative names for types or requires you to create wrapper types to emulate the behaviour from Ada Low level representations Ada allows you to specify the exact representation a type should have Rust has no such feature. You can choose the order of struct fields implicitly in the type with a #[repr(C)] attribute Aliasing Ada allows you to have multiple names for the same object and modify it through all of them. You can't do anything dangerous this way, because you'll get a runtime exception if you do Rust forbids this at compile-time, but you can use an explicit all-infecting escape hatch to change it into runtime-checks there's probably more... 
Crosspost for /r/ada/. ;) https://www.reddit.com/r/ada/comments/84oo49/anyone_here_that_has_experience_in_ada_and_rust/dvxmq0w/
Does this have something to do with Rust? 
Beside Ada, the succ/pred functions are present in Haskell too, deriving the Enum typeclass: data Weekday = Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | Sunday deriving (Show, Enum) main = do print $ succ Monday Output: Tuesday I agree that in general state machines aren't just a cycle, but having sub-cycles or some partial ordering of states is sufficiently common. A problem here is that I am not an Ada language expert. To show good examples of those Ada features we need a medium-expert Ada programmer willing to show and explain why those Ada features are nice to have, and how they could be added to Rust.
The logo and the title makes me think [Spanish Inquisition](https://history.howstuffworks.com/historical-figures/spanish-inquisition3.htm) 
Video linked by /u/loik_1: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Ideas about a new programming language for games.](https://youtu.be/TH9VCN6UkyQ)|Jonathan Blow|2014-09-19|1:55:24|3,109+ (96%)|217,817 $quote My first talk on designing a programming language for... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/loik_1 ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=$comment_id\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
Note: I personally prefer `Range&lt;u32&gt;`, for space reasons, unless you plan to support files larger than 4GB (which for code is... unlikely?).
My personal approach to ASTs is to store offsets, for compactness. A token is represented as a `Range&lt;u32&gt;` *to start with*, however it can be compressed further in the AST: all keywords/operators have a fixed length, after all, so just having their position (`u32`) is sufficient. In the space it takes to store one `&amp;str` on a 64-bits architecture, you can store 4 `u32`.
I realize he has mentioned Rust in the past, but I'm not sure why any random Jai article is relevant to /r/rust.
See the other discussion: https://www.reddit.com/r/rust/comments/85yj1b/d_parasail_pascal_and_rust_vs_the_steelman/
As I understand it, it just models the instruction scheduling pipeline and so is no help for find cache problems. I don't know if it's really practical to find cache problems statically. You're better off using 'perf' or some other profiler to find those problems.
When I read that the author introduced Rust as `odd`, I already knew what to expect.
There is an RFC for it: https://github.com/rust-lang/rfcs/pull/2295
this looks fucking good for gtk, how come my gtk apps looks like dogshit?
You've buried the lede a bit here by being so coy with the title, I'm sure a whpole lot of people didn't realize that this contains video demos of Pathfinder. :P
&gt; It was based on Ruma code, but uses Matrix REST API directly. Doesn't look like it.
Can you specify where? I can't find it.
My personal experience (as a RustFest Berlin speaker) of /u/fgilcher's professionalism left absolutely nothing to be desired, and I would vouch for it without a moment's hesitation. I should add that while I am both a quasi-anonymous account on Reddit, I am also a real, actual person whose name and professional details you could easily ascertain using a search engine. It is on that basis that I unhesitatingly recommend Florian, and point out that what you said seems quite rude.
First up: Great article, simple, straight to the point and with good educational value! When doing benchmarks you'll typically want to include all the information one might need to reproduce the results, so: * The versions of libraries/software you're comparing * The code using the libraries of course :) * The hardware you're running it on, and * How you're running it, e.g. what commands and so on. Hope that helps :) Keep up the good work!
&gt; Look at the string situation. There's cstring cstr String str OsString OsStr PathBuf Path. That's 8 types Yes, it's very silly but all these types have different specific requirements of the bytes they own. Not all CStrings are valid Strings, and blindly converting a String to a CString could produce... surprising behavior. The same goes for OsString; Windows strings are composed of 16-bit values, not 8-bit values, so you'll have issues there blindly converting. I personally wouldn't consider a Path/PathBuf a special kind of string, even Python has a separate type for Paths. I don't think Rust is introducing any new silliness here, rather it's almost required to expose all the crazy behavior of other systems in the name of having **both** performance and correctness. You could sacrifice either one to make the situation look simpler.
And what are those reasons? Because indulging in what's commonly known as the tyranny of the majority clearly goes against the CoC, and that would be a shame for something that seems to be mostly cosmetic for abled people.
I'm going to question some of a increase post too began a discussion: &gt;So my counter-balance for Rust lies in the "write-only language" qualities that Rust takes from the C-like syntax. 
When you look at a line, it's immediately obvious if it's a comment, because you just have to look at the very start of the line. This is especially true of diffs where you might not have a lot of context. They're trivially easy to add and remove, since it's just two characters at the start.
delete? yes/no?
So basically "metal" from that Gary Bernhardt talk about javascript? That's pretty awesome!
no
There's a roadmap at the end of the readme. I plan to expand on it this week. If you're interested in contributing there's loads of features to be added so pm me and I can go into details. If you wish to use it I'd love to know what features you'd need and I can try adding them in. Currently it's made to suit my need, so I'd love to learn how other people would think about using it.
Actually that's one of the monitoring agents I never look at. I plan on doing a comparison section, I'll make sure to include that. Atm I made it to suit needs that nagios(+forks), munin, zabbix and Prometheus weren't well suited to meet.
If by `core` you mean `no_std`, then I don't think so. The whole thing seems to be built around `Any`.
That doesn't surprise me at all.
GTK looks much better than QT imo. Just use a nice theme. Like this: https://github.com/adapta-project/adapta-gtk-theme
Greatly appreciated the feedback! I've update the post to include hardware specs and will certainly add more details around versioning. The code for each test already exist in the links to GitHub (which contains startup info). I was fearful that by including more it would pollute the - already difficult to read - article further; but, you're right finding a way to make that info more visible certainly would have been better 
Fixed, thanks!
It changes what happens when NaN is encountered (which tends to occur when dealing with 0, infinite values and complex numbers) Sometimes NaN values will propagate through multiple calls before triggering an error in an running application. This library enables that error to occur earlier, which should make debugging easier
I guess not everyone is like me - I automatically watch each Bay Area meetup regardless of who's presenting, always something good in there =)
A couple people have asked, no response, so this seems the easiest way.
Note this thread was from a month ago; we should be careful to not go over there and make a ton of posts. It can be considered brigading.
I'm trying to understand the semantics you're presenting. In the code example, what value is `x1` supposed to have? I'm assuming that it's intended to demonstrate that doing e.g. `a1['c']` would be a static error, but given the typical value of the char `'C'` in ASCII/Unicode, isn't this asking for `a1[67]`? Does the compiler also catch this, since you've defined `a1` to be length 10? Unsure if that's something that you were intending to demonstrate. And it seems a bit weird to define an array type where the first 64 slots are statically unreachable... As for the second example, anyone can do that via the Index trait: impl std::ops::Index&lt;Some&gt; for Arr2 { type Output = u32; fn index(&amp;self, idx: Some) -&gt; &amp;u32 { &amp;self.0[idx as usize] } } ...and now `a2[Some::C]` works just fine. Is there an advantage to building it into the language?
Very interesting. For a long time I've wanted to do something similar by creating a strongly-typed Rust implementation of the addition chain code I wrote in Haskell that's used in https://briansmith.org/ecc-inversion-addition-chains-01, especially since I actually developed all that Haskell code as a translation of real-world Rust code. Any thoughts as to how to go about that?
I'm a little unclear on how new this book is (Amazon says February 27, but the author's [tweet](https://twitter.com/rony358/status/976580985411252225) seems to imply it was released today), and I'm wondering whether anyone out there has managed to get their hands on the book and could give a review.
The stock Adwaita theme is very good as well :P
Similar? CPython basically wraps every variable in an `Rc&lt;T&gt;` and then straps on a minimal garbage collector to break cycles.
&gt; isn't this asking for a1[67]? Does the compiler also catch this, since you've defined a1 to be length 10? Going for a simpler example, you can do type Upper = char[1 ..= 10]; and then you have a 1-based array, there is no 0th position in the array. So in the first case, no there's not 64 unused slots.
The real question is what're you going to do about Specter, which isn't going to be fixed any time soon.
That requires precise timing, right? I can just have nanosecond timing need privileges. 
Supposedly pcwalton is somewhere nearby GDC... https://twitter.com/pcwalton/status/975412852818243585
Seconded, I as well would like to know more about this, especially since the TWiR author appears to be excited about it. :P
Okay, I expected a literal guide.