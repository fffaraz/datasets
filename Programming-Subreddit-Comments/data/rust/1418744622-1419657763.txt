Why do you want to avoid Mutex? It's one of the primitives that's made for this use case, while RefCell is explicitly not.
You need to indent everything four spaces to get it to render properly.
&gt; I have a connection pool object which implements get() and put() methods which both are internally thread safe. Then it should be marked `Send`, and you can just use it.
Personally, I've only used the builder pattern to configure properties that already have sane defaults (see my [plotting library](http://japaric.github.io/simplot.rs/simplot/#examples) as an example), and I wouldn't use that pattern for constructors because as you have said you may forget to initialize some fields. In your particular example I would use struct variants as some form of templates: #![feature(globs)] use Template::*; struct Person { name: Option&lt;&amp;'static str&gt;, initials: Option&lt;&amp;'static str&gt;, age: uint, height: uint, } impl Person { fn new(t: Template) -&gt; Person { match t { Named { name, initials, age, height } =&gt; Person { name: Some(name), initials: Some(initials), age: age, height: height, }, Anon { age, height } =&gt; Person { name: None, initials: None, age: age, height: height, } } } } enum Template { Named { name: &amp;'static str, initials: &amp;'static str, age: uint, height: uint }, Anon { age: uint, height: uint }, } fn main() { let p = Person::new(Named { age: 30, height: 69, initials: "JN", name: "Jack", }); } This way you won't forget to initialize fields nor input incomplete information. I also find this form readable, because the name of field (`name`) acts like a keyword argument (like `name="Jack"` in Python), and is ergonomic because you can shuffle around the fields of the struct variant. HTH
`*` means "dereference this pointer", but only in expression syntax. In pattern it would mean "matched value is dereference of this pointer". In expressions we have *actions* and in patterns we have, well, *patterns*. So `ref` would be good as an action, but as a pattern it seems backwards. See the discussion [on github](https://github.com/rust-lang/rfcs/pull/462#issuecomment-62764540) and [discuss](http://discuss.rust-lang.org/t/change-ref-to-in-patterns/1027).
If it can be safely shared between threads, it should be marked `Sync` as well. Otherwise it cannot be put directly in, e.g., an `Arc`.
Abstraction and crypto honestly don't go well together. For crypto you want shorthand, not abstraction (which I'd argue is all this macro is doing, except for register allocation I suppose [but I assume it constrains that as well since a spill out of registers would lead to non-constant behavior]).
Thanks Steve. I am new and not sure how to implement/mark "Send". I tried as below. #[deriving( Send)] pub struct ConnectionPool { } but still getting Send related error. error: the trait `core::kinds::Send` is not implemented for the type `core::kinds::marker::NoSend`
You can use `String.into_bytes()` and then convert back with `String::from_utf8()` to do it in place and without `unsafe`. From what I know about UTF-8, it should always succeed. Please correct me if I'm wrong.
You can't derive Send at the moment (unless Niko or /u/pcwalton implemented that sneakily!). It is automatically derived based on the contents of the struct. If you tell me what is in your structure, I will tell you why it is not thread safe. Rust is nearly always right about this. Where it is wrong, you need to use `UnsafeCell` instead of the offending structure (and strongly justify why it is threadsafe, since you'll need unsafe code to access the value). (There is an exception in that there are types that are threadsafe but contain non-`'static` references, so normally they can't be shared between threads. There is an RFC for relaxing that restriction. But it only applies to "bounded lifetime" threads--regular threads cannot contain non-`'static` references, since otherwise they would be left dangling if the stack in which they were rooted died. So if the problem is that you have such a reference, for the time being use an `Arc` instead).
The ConnectionPool already is Send. Proof: You said you can put it inside an Arc or a Mutex successfully.
Yup.
 #[deriving( Send, Sync)] pub struct ConnectionPool { idle_conns: Mutex&lt;RingBuf&lt;conn::Connection&gt;&gt;, min_conns: uint, max_conns: uint, tmp_conn_allowed: bool, config: config::Config, conns_inuse: uint, } Here conns_inuse and idle_conns are modified in get() and put() function but uses MutexGaurd from idle_conns. e.g. let conns = self.idle_conns.lock(); { self.conns_inuse -= 1; }
Mutex lock is expensive and want to avoid the locking scope at connection pool object level which will reduce thread contention.
If you can't tolerate the register allocator making spill / fill decisions (that you can't control), then you're basically working in assembly. You're going to need to know a great deal about the target ISA. I would much prefer simply writing in assembly at this point, which I find to be comfortable and familiar, because ISAs are well-known, stable specifications, especially compared to any new macro toolkit. If you need "constant" behavior, you're also going to need to understand quite a lot of the micro-architectural details, i.e. not just the ISA spec but the implementation spec, too. Many things will make it difficult to make a given sequence of operations take the same time / power. Among them: cache states (L1, L2, L3, TLB), hardware interrupts, inter-processor interrupts, SMI interrupts, hypervisors, translation from ISA instructions to micro-ops, data-flow dependencies between micro-ops, branch-predictor state (for your inevitable loop branch), etc. Hell, you even need to worry about DRAM access patterns; see this paper for an interesting cause of information leakage / attack: http://research.microsoft.com/pubs/79603/DRAM-Unfairness.pdf . Point is, if you're already working at this level of abstraction, then a new language is really the least of your concerns, and you had better already be very comfortable working in assembler.
your simplot library is really awesome. I've found a plotting library for rust for many days!
&gt;Also certain fields are only mandatory based on other fields set...if that makes sense Think about the relationships between the fields and try to cluster the fields up into related chunks. It might be appropriate for each of those related chunks to be a type.
min_conns, max_conns and Config are initialized in New() method and used as readonly. How do I inform compiler that these are readonly and safe? I did convert conns_inuse to AtmoicUint. With Rc, getting below error while invoking acquire() let pool_shared = Rc::new(pool); error: the trait `core::kinds::Send` is not implemented for the type `core::kinds::marker::NoSend` With Arc, getting below error while invoking acquire() let pool_shared = Arc::new(pool); error: cannot borrow immutable dereference of `&amp;`-pointer as mutable
This is a great example, nice solution using Complete/Incomplete - it is certainly one of those things I wished were available in languages like C# or Java :).
I modified acquire() and release() to take &amp;self rather than &amp;mut self and it works fine. pub fn acquire(&amp; self) -&gt; IoResult&lt;conn::Connection&gt;{} pub fn release(&amp; self, conn: conn::Connection ) { } Thanks a lot for your help. One thing I am not clear is without passing &amp;mut self to acquire() and release() methods, why compiler allows to modify member variables like idle_conns and conns_inuse? 
Great to hear someone picked this up! Perhaps you can implement command completion via integration with racer?
Nice!!!!
This is awesome, thanks! :)
`.type` is my new favorite thing.
Great!!. Regarding .block for block of statements, can't you use { let a = 1i; let b = a * 2; let c = b * 3; }
Generally, yes. But the result must be able to escape the block. For example, this only works with `.block`: let a = "x".to_string(); a.as_slice() It works because, with inline input, if the final statement is an expression, it is rewritten as `println!("{}" { &lt;expr&gt; });` before being compiled and executed.
I'm not familiar with racer, but completion is one of the many things I plan to implement.
Awesome work. Statically typed languages tend to be lacking a lot of the infrastructure that makes this easy, so I really commend you on the effort. In order to get a REPL working tolerably well in a statically typed language I’m working on, I had to rewrite the compiler into a sort of feedback loop, to allow incrementally adding code, executing only the newly added code, then saving the instruction pointer and returning to the user.
It's gone relatively smoothly so far with Rust, using the LLVM `ExecutionEngine` API for in-memory compiling and linking. As the project README indicates, though, it doesn't currently do the usual REPL thing of letting one reuse locally-defined variables. I will probably need to do some hackery to support this.
I may have misunderstood, but could you rewrite it as `{ let tmp = &lt;expr&gt;; println!("{}", tmp); tmp }` so that the result isn't dropped?
It definitely beats doing `let x: int = some_thing_i_dont_know_the_type_of;` and checking the compiler error messages for "expected int, found foo".
Infact block using { } does work with empty () at the end. rusti=&gt; { println!("hello"); let a = "abc"; println!("{}", a); } hello abc () If I add ; at the end of }, it doesn't print empty () rusti=&gt; { println!("hello"); let a = "abc"; println!("{}", a); }; hello abc 
Some commands require that `-` be specified as the filename to read from `stdin`; the issue of course is that this precludes them from acting on files named `-`, and any other name would obviously have the same issue.
I tried that after you suggested it in the irc yesterday, but I couldn't get a mutable slice out of into_bytes(). It returns a immutable byte vec.
I was referring to the automatic rewriting done by rusti. This code: rusti=&gt; let x = "x".to_string(); x.as_slice() Is transformed and compiled into this: let x = "x".to_string(); println!("{}", { x.as_slice() }); While this: rusti=&gt; { let a = "x".to_string(); a.as_slice() } Is transformed and compiled into this: println!("{}", { { let a = "x".to_string(); a.as_slice() } }); Which is, of course, an error. It's perfectly fine to print the expression yourself inside `{}`, but rusti's expression printing doesn't look inside those to insert a `println!`. It needs the escaping value (if there is one) to be valid.
It's probably the compiling that's slow. It isn't yet able to link new compiled code to previously compiled code. So, if you've defined ten functions and then input even something like `1i`, it will compile all of the functions again. This is obviously high on my list of things to fix. Edit: Oh. Even `1i` from a fresh run is noticeably slow. It might just be the nature of the compiler, in that it looks up crate `std` and all its dependencies for each input.
I do not know why it worked before but you should use pool_shared in the assert.
There are some fun tricks you can do with the builder pattern since we've got moves. Here's an example of a builder that has required named positional arguments: struct Person { age: uint, name: String, } struct PersonBuilder; impl PersonBuilder { fn name(name: &amp;str) -&gt; PersonAgeBuilder { PersonAgeBuilder { name: name } } } struct PersonAgeBuilder&lt;'a&gt; { name: &amp;'a str, } impl&lt;'a&gt; PersonAgeBuilder&lt;'a&gt; { fn age(self, age: uint) -&gt; Person { Person { name: self.name.to_string(), age: age, } } } fn main() { let person = PersonBuilder::name("foo").age(12); } 
Oh I found the issue. Earlier I had pool_shared overriding pool so it worked. let pool = super::ConnectionPool::new(2, 2, true, &amp;cfg); let pool = Arc::new(pool);
http://doc.rust-lang.org/nightly/std/io/process/index.html (sorry, these docs are still pretty poor. http://doc.rust-lang.org/nightly/std/io/process/struct.Process.html has an example though)
Very close actually. The ultimate goal (and perhaps the builder pattern isn't best for this?) Is to provide a complex configuration without the user of this lib being intimately familiar with the innards. I.e. they create a "`Person`" and based on which exact properties the consumer sets on the "`Person`" the lib then figures out which concrete struct to use and those are all hidden from the user. 
Since learning Rust, I've understood C++ and its pitfalls much better. Once you've made peace with the borrow checker, you too will be a better C++ programmer. Also, I wonder what a Rust to C++ translator would look like...
Thanks Steve.
Is this mainly for experimenting with individual Rust statements? I imagine it wouldn't be possible to run this inside of a real Rust program and reload its modules at runtime. As a Clojure user, that would be my holy grail!
I really miss algebriac types &amp; pattern matching in C++. (Yes, I'm aware of boost::variant)
Yeah, that's the idea, more or less. Running small pieces of code or inspecting things as you go along. The `.type` command is good for the latter and there should be more useful commands like that as I get more familiar with the Rust compiler library. Reloading modules would be outside the scope of this project, but could be possible, I suppose. It probably wouldn't be as convenient as a library as it would if it were built into a language. It might look more like a plugin system in C using `dlopen`.
`optional&lt;T&gt;` almost made it into C++14 and it'll probably be in C++17, so there's at least that much.
File and line you have with http://doc.rust-lang.org/std/macro.file!.html and http://doc.rust-lang.org/std/macro.line!.html Haven't seen a FUNC.
&gt; well known C++ library You've got me curious. Which one? (I wonder if there's a way to FFI it).
Will/does it run scripts? E.g. `#!/usr/local/bin/rusti`
Awesome, that's exactly what I'm looking for. :) Although, it seems counter-intuitive to have to use `std::mem:replace`. Why can't `into_bytes()` return a mutable string on `orig_line`?
Take a look at the log module.
iNeither C++ nor Rust fully satisfy me now... but I'm still a captive of C++ momentum/experience. I like 90+% of both but strongly dislike a few issues in either, and the other shows me how that 'few%' could be different. So I'm rolling my own language combining what I like from both. https://github.com/dobkeratops/compiler I've got the main features I wanted: 2way Local inference+adhoc overload+UFCS+expression syntax. But obviously a lot of gaps yet to fill. Safety isn't my gripe , it's general clunkiness in C++, and too much restriction in Rust. &gt;Also, I wonder what a Rust to C++ translator would look like... its probably wishful thinking but I'd like to see if its possible to merge some semantics from both. I plan to transpile to &amp; from C++ eventually at least. I'm hoping a reverse C++-to-Rust transpiler appears (what i need for this is 'half a c++ to rust transpiler').. by taking heavy influence from Rust I'm hoping there's bits of support I can take from elsewhere in this community rather than my 'pet language' existing in a complete vacuum. (e.g. at a simple level, using rust syntax I get syntax highlighting in various editors already, and the same grep recipes work) ... but there's a lot of details to iron out like new vs box , references vs borrowed ptrs, module vs member visibility,etc. (it might be that a c++-&gt;rust transpiler is just futile so no one bothers) At the very least one should be able to get something C++like that can interface with Rust enums/traits &amp; C++ classes. &gt; I really miss algebriac types &amp; pattern matching in C++. (Yes, I'm aware of boost::variant) Its looking to me like a C++ style template engine + overloads + better inference can get a little further emulating variants, i.e. a '.match(..)' method doesn't need you to specify the output type manually like in C++. but I still want proper pattern matching eventually... 
At present, it does not. But it is one of the things I'll implement sooner or later.
What I meant is, why is `mem::replace` needed in order to make `into_bytes()` return a mutable collection? Why does `orig_line.into_bytes()` only return a immutable collection? It seems strange to me considering that `into_bytes()` consumes the String, so we should be able to do whatever we want with it.
QT is an example of something in C++ that lots want to build to.
Rust will ruin C++ for me the day they add C++ bindings. Until then, I use them both and am still happy with both.
I did go through an iteration about like that, you're right. The broken version that I posted was actually a suggestion from the compiler to fix something else about mutme (well, the function that eventually became mutme). It turns out that what the compiler actually needed was an explicit lifetime on the &amp;str in the result, but for some reason it said it wanted one on &amp;mut self. I was trying to recreate the version that told me to put the 'a on self, but I haven't been able to do it! 
https://github.com/rust-lang/rfcs/pull/466
This makes sense, thanks. I originally put the 'a in on self from a compiler suggestion, but I haven't been able to recreate that particular error message, so maybe I was misinterpreting something in the stew of other messages.
I do find myself reaching for languages I know better, thinking "Aaah, but it'll be so much easier because I know how to get my ideas past the compiler!" Only to have a sudden pause thinking, "But if my ideas wouldn't pass in Rust...is there an issue I'm not seeing?!" ...and that's scary :|
After learning Haskell I really missed ADTs when working in C++, and I tried a few different ways of reconstructing them. The one at the moment that seems to have the best balance of power/weight looks like this: // roll your own vtbl struct TypeInfo { uint32_t typeId; void (*moveConstruct)(void* dst, void* src); void (*copyConstruct)(void* dst, const void* src); void (*moveAssign)(void* dst, void* src); void (*copyAssign)(void* dst, const void* src); void (*destruct)(void*); }; template &lt;typename T&gt; void CopyConstruct(void* dst, const void* src) { new(dst) T(*static_cast&lt;const T*&gt;(src)); } // etc for other methods in TypeInfo // magic is here. one `info` struct exists per type which // references GetTypeInfo() template &lt;typename T&gt; const TypeInfo* GetTypeInfo() { static const TypeInfo info = { T::kTypeId, CopyConstruct&lt;T&gt;, MoveConstruct&lt;T&gt;, CopyAssign&lt;T&gt;, MoveAssign&lt;T&gt;, Destruct&lt;T&gt; }; return &amp;info; } template &lt;int kSize, int kAlignment = 4&gt; class Variant { public: TypeInfo* mTypeInfo; aligned_buffer&lt;kSize, kAlignment&gt; mData; // we have this in eastl, roll your own if you need. // define standard constructors / assignment operators using mTypeInfo template &lt;typename T&gt; bool Is() { return mTypeInfo &amp;&amp; mTypeInfo-&gt;typeId == GetTypeInfo&lt;T&gt;()-&gt;typeId; } template &lt;typename T&gt; T&amp; As() { assert(Is&lt;T&gt;()); return *static_cast&lt;T*&gt;(mData.data()); } template &lt;typename T&gt; Variant&amp; operator= (const T&amp; rhs) { static_assert(sizeof(T) &lt;= kSize); static_assert(alignof(T) &lt;= kAlignment); if(Is&lt;T&gt;()) { // copy assign and return mTypeInfo-&gt;copyAssign(mData.data(), static_cast&lt;const void *&gt;(&amp;rhs)); return *this; } // otherwise it's a different type. empty first if(mTypeInfo) { MakeEmpty(); } mTypeInfo = GetTypeInfo&lt;T&gt;(); mTypeInfo-&gt;copyConstruct(mData.data(), static_cast&lt;const void*&gt;(&amp;rhs)); return *this; } // etc } class StructThatCanBeInAVariant { public: // FNV1 hash of "StructThatCanBeInAVariant" // only boilerplate required in child structures static const uint32_t kTypeId = 0x928b612f; // methods, data and stuff }; // put whatever the biggest struct you put into the variant here. // if you're wrong, you'll get a compile time assertion failure // and can change to the bigger structure that triggered the // assertion. typedef Variant&lt;sizeof(StructThatCanBeInAVariant)&gt; SampleVariant;
Unfortunately cmr's been having some technical difficulties, so this week's edition is published via rendering-the-damn-thing-in-github.
I noticed unboxed closures are starting to appear in the stdlib. Yay!
His goals are definitely closest, and it was his videos that inspired me to start. maybe its just NIH, but I've been wanting 'a new language' for a long time hence following &amp; trying Rust for 18+months. and I've got some ideas I want to try.. The features I personally want could easily be retrofits to C++ or Rust.. I just think i'd get further rewriting than trying to figure out either existing source base works and forking it. Perhaps in time similar features will appear in either. - pillar[1]: I want to be able to represent a useful subset of C++ directly via transpiling - he is already diverging on pointers.. `^`. - he's indicated he doesn't like C++ having `&amp;,*` ; for me its' acceptable legacy for continuity. - I started out with &amp;/* like Rust, but realised I must stick with &amp;-references like C++, for my transpiling goal. - he's indicated he doesn't like Rust having many pointer types. - I actually preferred Rust when it had ~ &amp; * @. - I hypothesise @ + auto type params can make a subset do the job of Lua/Python. - pillar[2]: 'as close to Rust as possible'(unless it compromises pillar 1), - because Rust is already SO close to what I want, &amp; has so much momentum - I realise the ideas in Rust I like come from elsewhere but its' what demonstrated them in a systems language. - I agree with the vast majority of what he says but I think I like *both* C++ &amp; Rust more than he does. - its just a small % of the features in both that annoy me disproportionately. headers in C++, compulsory deep naming in Rust. - I hypothesise you could make 1 language engine handle both rust/c++, different front ends to the same AST. - but I'm definitely not going to be able to implement ALL that on my own . - I don't think C++'s problem is complexity -it's features that stop short, so you have to stretch them and they interact badly, or do nearly what you want with different compromises ..like all the ways of emulating ADTs - I'd like to try having fully customisable types like C++, but language sugar for 'common defaults' etc~[T] ==Vec&lt;T&gt; ~T,@T desugar as unique_ptr&lt;T&gt;, shared_ptr&lt;T&gt;. I see swift actually did [Key:Value], I'd suggested [Key=&gt;Value] for rust ages ago inline with its old ~[T].. ? for option, its ubiquitous enough.. - I think compact type syntax is nice because you see this in searches &amp; completion. more room for the meaningful names. the sigils melt away (easy to colorcode) - you use a few types most of the time, then refine. - he doesn't like Rusts' lambda syntax. It's one of my favourite bits of Rust. - It was good in conjunction with the old 'do' notation which would have been nice for data-parallel.. making internal iterators look as natural as inbuilt loops, (I think this is ruby inspired?), so that was on my wish list. - my preferences on a starting point are slightly different - e.g. I've not longed for CTFE so much, on the other hand some of rusts 'functional feel' really does inspire me. e.g. thats why I've started with "for-else" completing the idea that "everything is an expression", whereas he's gone for labeled-break. I've hacked in 'break break &lt;expr&gt;' for nested levels.. he says he doesn't want that relative 'because the meaning changes when you cut paste' ..but for me 'break &lt;expr&gt;' is a more inspiring starting point. - but he DOES have a much more practical starting point, I think, it does inspire confidence that his project will gain momentum &amp; continue. - And I think he's already successfully demonstrated that something *much* simpler than C++ can do the job. - I'm just fascinated with certain 'shiny features' that I want to see blended. I'll see how far I get, perhaps I can just converge on whichever mainstream option out there is closest .. but for the minute experimenting directly is so much more satisfying than having to argue with any community consensus... I wish I started this a year ago instead of being off put by the popular wisdom that its' futile to write your own language. Perhaps as his language gains momentum I'll eventually drop the goal of making this 'rust-like', and converge more there, or maybe when he finaly opens it up I'll ditch this. but for the minute, I've wanted to stick as closely to Rust inspiration as possible (insofar as it doesn't conflict with C++ transpiling) since I've already spent time learning it. maybe the goal of "c++ integration" will make Rust get similar features past 1.0 anyway.. I could find the community just mutates rust in this direction from the other end. I realise the economics of this. 'its not about individual productivity, its about the whole..' but lets see if its possible to make languages work in a continuum.
Yeah, we're at a pretty decent place now. The transition story will get a bit easier in the next few days...
What do you mean by "compulsory deep naming in Rust"?
Oh, silly me. I was using a earlier rustc version and it was giving me an error because `into_bytes()` apparently produces a immutable collection. Switching to the newest nightly no longer gives me that error. 
It's more than adequate. What a nice week this was. Edit: Oh by the way, the extend examples are a bit too optimistic (about Rust's current level of DWIM), they need to work on iterators, not vectors.
I’m lazier and only typing `something.a;` to get an error of "attempted access of field `a` on type `foo`".
[1] the whole heirachical path in the directory structure is backed into the name [2] to make something polymorphic you *must* have a trait, and that is also part of its' qualified name. so you basically have directory::filename::type::trait::functionname. and the trait is *also* namespaced .. and then it's harder to change your mind and move things around. In particular if you have many interrelated traits you're back to the hierarchical idea. Back in C++ I'm cursed with headers but at least I can move a function from one place to another. I'd at least prefer it if you could implement traitless methods impl Foo { ... } and then those satisfy the trait - it precludes having 2 traits with the same method name implemented for the same type - as in the 'cowboy::draw' 'renderable::draw' example -but there' I'd say just pick better names .. and the types would disambiguate it e.g. one is immutable, takes a renderer ptr, the other is a state change. with adhoc overloading, I see it being like non-hierarchical 'tagging' . a function is associated with all of its types , not one position in a tree. Most interesting functions relate 2 types. the 'space of functions' divides up into the intersections of all the types. With '2way inference' there is the interesting possibility of making the Return Type significant aswell. things might end up in a neat heirarchical position but the process of getting there isn't always obvious and demands can change I realise overloading has problems but I've never *hated* it; and I'd probably like to go the other way and add named parameters too, which takes a 'non-hierarchical tag' further.. disambiguate by annotating parameters I'd prefer to add tools to "work around any problems of overloading" rather than remove it. I really do just want to think in terms of functions &amp; structs first and foremost, and anything else comes later, optionally
&gt; Patrick implemented word-spacing, overflow-wrap/word-wrap, outline, letter-spacing, and text-indent. Don't forget `box-shadow` ([commit 1]) and `bgcolor` et al ([commit 2])! [commit 1]: https://github.com/servo/servo/commit/7805fe19edf5353711f49a8ef1c988dc9f932bb7 [commit 2]: https://github.com/servo/servo/commit/8e31e5f98747e4b42dafcc4b076fac46aeb09310
I believe `-O` == `-O2` for Rust, but it goes up to `-O3`. The optimizations at that level are unreliable, but sometimes fruitful. Did you try that?
Yup, --opt-level=3 made no difference for me.
Something that seems really strange: fn reverse_words_bytes(line: &amp;mut [u8]) { let len = line.len(); line.reverse(); // NOTICE THIS LINE let mut word_start = 0; for i in range(0, len) { if line[i] == b' ' { line.slice_mut(word_start, i).reverse(); word_start = i + 1; } } line.slice_from_mut(word_start).reverse(); } If I move the line `line.reverse()` to either the very beginning or the end of the function, the execution time is increased by about 0.8s, or 1/4 of the total execution time. Does anyone know what's going on in LLVM in this case?
This is a great comment first of all, and I feel the same with how this seems to be used as the one tool for the job. I don't know if that is necessarily the case, but seems it. There is an empty project under piston called *scene* which seems to want to cover both scene graph as well as maybe an ecs, but it's basically an empty project. I am personally working on an ecs for a possible game, which also will include a scene graph (the original reason why I started it). I noticed in rust, making an ecs as a library feels complex so it may end up as template code for now, but more importantly making it both interconnected and threaded is definitely a challenge. For instance what owns what in terms of rust ownership in an ecs? As well, how could systems communicate component data efficiently especially in a threaded environment, eg: spinning up channels probably wouldn't be a great choice. On the bright side, dropping components and entities in general are basically a non issue. Obviously shoehorning everything in to ecs is wrong, but that can be said of any approach. What are your thoughts? 
I think you may be able to use a StringBuilder in java to do in-place manipulation.
The way your variant does information hiding, it’s worth noting that it’s unlike a typical algebraic data type which variants are closed and statically known, so you can e.g. generically fold over them. It’s closer to an existentially-qualified type or a generalized algebraic data type, although the set of operations that you retain is too limited since you only expose construction, destruction and casting which are more about bookkeeping than anything else. In the end it looks a lot like dynamic typing.
Looks like you'll need to specify using [this](https://github.com/rust-lang/rust/pull/19467) syntax that it's a closure that can be called multiple times.
that makes sense. Thanks.
Like this? fn func1(foo:&amp;mut |&amp;str|-&gt;Option&lt;String&gt;) { println!("func1: {}",(*foo)("hello")); } fn func2(foo:&amp;mut |&amp;str|-&gt;Option&lt;String&gt;) { println!("func2: {}",(*foo)("world")); } fn func3(foo:&amp;mut |&amp;str|-&gt;Option&lt;String&gt;)-&gt;Option&lt;String&gt; { (*foo)("fizz") } fn test() { let mut f = |arg:&amp;str| { Some(arg.to_string()) }; func1(&amp;mut f); func2(&amp;mut f); println!("func3: {}",func3(&amp;mut f)); }
Willow Garage's Point Cloud Library. A shame, cause their OpenCV project has nice C bindings which would probably work well with rust...but I'm SOL on this. 
I think you might have the wrong subreddit. The [Rust game subreddit is elsewhere](https://www.reddit.com/r/playrust).
I didn't have to make the closure mut, just mark it as an Fn closure with |&amp;:| [previous comment](http://www.reddit.com/r/rust/comments/2pjek9/is_it_possible_to_reuse_closures/cmx9h3p)
No, in that case, I think you're a wizard.
I think I'll only reach the rank of "EVIL CODE WITCH" once I figure out monads.
The last commit being 7 months ago, I think it's fair to say that wxRust isn't a new project. I guess it was posted here in case someone wanted to pick it up. But this could indeed be a nice section for "this week in Rust": some projects that are in demand, including those that were abandoned, so people wanting a new project would see what's needed right now.
Oops. I just go off of what shows up in Reddit mostly :P Definitely an interesting idea, although honestly with Rust's current pace of development it's usually more fruitful to do stuff from scratch.
As a passive onlooker to rust (eagerly awaiting 1.0) this rfc is scary: https://github.com/rust-lang/rfcs/pull/519 As far as I can tell from the docs, spawn creates a task that ignores panics in the child. Whereas try is spawn but catches the panic and gives you the result, but is synchronous - only useful because it catches a panic. Then there is the experimental try_future which is like try but gives you a future instead of synchronously waiting. As far as I can tell there is no way to wait for multiple futures and return the first completed as a result. That means that try_future is effectively synchronous but you can do something before calling get. If I am wrong above please point it out. Given this, it seems like the only decent way to catch panics in a long running daemon is with all panics causing abort. Since you can't catch panics in child tasks (only child task) all spawned child tasks should be wrapped in a hypothetical AbortOnPanic which has a drop that aborts on panic but not on ordinary return. Which is basically what the RFC is proposing, maybe making the default spawn do that instead of ignoring panics, and opting into a spawn_forget or something to ignore panics. Am I just missing something?
Yes, absolutely, it's up to you to enforce the discipline that *this* Variant type contains these substructures, and this *other* Variant type contains these other substructures. That said, I didn't find that discipline hard to keep; in practice I defined N structures then typedef a variant that is supposed to contain one of those N options. It did not feel like dynamic typing at all, although I do see the connection you are getting at. You are right that the type checker doesn't/can't enforce that `switch(variant.TypeId())` checked all the possible options for that variant. I had an older version where the type specified exactly the types that could be placed in the variant and the template metaprogramming just got too ugly. `typedef Union&lt;StructX, StructY, StructZ&gt; MyVariant` was a nice interface, but the implementation was way less clean, and it didn't seem worth it for the minor additional safety. This is C++, after all, a language designed around carrying a shotgun aimed at your foot at all times.
&gt; optional&lt;T&gt; almost made it into C++14 and it'll probably be in C++17, so there's at least that much Will we get pattern matching, exhaustiveness checks and tuple destructuring, though? Without those sum types are pretty useless. Though despite their lack I use ``boost.optional`` wherever I can already.
With some contortions, you can translate that code into Rust: #![feature(unboxed_closures)] fn get_counter() -&gt; Box&lt;FnMut() -&gt; i32 + 'static&gt; { let mut x = 0; box move || { x += 1; x } } fn main() { let mut c = get_counter(); println!("{}", c.call_mut(())); println!("{}", c.call_mut(())); println!("{}", c.call_mut(())); println!("{}", c.call_mut(())); } The key here is the `move` keyword given to the closure. This makes the closure capture `x` by value, meaning that its lifetime isn’t restricted by `x`’s. This syntax is only available with *unboxed closures*, which (if you don’t know) are a new kind of closures in Rust that will replace the old ones. I would recommend reading [Niko Matsakis’s blog post](http://smallcultfollowing.com/babysteps/blog/2014/11/26/purging-proc/) to learn more about unboxed closures. However, there are a few issues/bugs that we have to work around to get this to work: - It’s not possible to return unboxed closures by value. This is a feature that has been wanted for quite a while, but unfortunately will not be available before 1.0. See [RFC #105](https://github.com/rust-lang/rfcs/pull/105) for more information about what this could look like. - The normal call syntax (`foo()`) cannot be used with unboxed closure trait objects. For now, we have to use the explicit `call_mut` syntax instead.
`x` is allocated on the stack, in `get_counter`'s frame, so it can't just extend the its lifetime automatically. You need the closure to capture its environment by value, at which point `x` will be moved into `c` and have its lifetime. This works: #![feature(unboxed_closures)] fn get_counter() -&gt; Box&lt;FnMut() -&gt; i32 + Send&gt; { let mut x = 0; box move || { x += 1; x } } fn main() { let mut c = get_counter(); println!( "{} {} {} {} {}", c.call_mut(()), c.call_mut(()), c.call_mut(()), c.call_mut(()), c.call_mut(()) ); } The `c.call_mut(())` should just be `c()` but [that's not working yet](https://github.com/rust-lang/rust/issues/16929) for trait objects.
I've fantasized in bed at night about the possibility of an OCaml/SML-ish dialect that compiles to (or at least interops perfectly with) Rust, complete with HKT and fully Rust-powered message-passing concurrency. Oh, to be young and have lots of free time. 
Can you briefly describe your inference approach? I'm curious as to how it works with overloading - I'm only familiar with HM (that does not work with overloading) and C++ auto-like inference where it only works in one direction.
How did the D do it? And won't a standard ABI (std::abi proposal for C++17) help alleviate the issues too (Unless I fail to understand the entire proposal)? I'm aware it won't come until 2017+ if it's accepted into the standard at all.
D tries but if you read http://dlang.org/cpp_interface.html the limitations make it impossible to use anything but a library built with them in mind. As for the std::abi that's not happening.
I can't reproduce this locally, moving the line does nothing for me. It's possible it was just a fluke of that run being a bit slower than normal.
What does one become once they figure out lenses?
Why's std::abi not happening?
Loving RFC #195!!! Somehow I did not notice it up to now, but this is a really nice change, that will make it much more convenient to write generic code!
Indeed! I would prefer `:type`/`:t` as per `ghci` though. An `:info` command would also be great.
Because the proposal suggests spiting the std lib into two branches which isn't going to go over too well with the people in the standards committee.
Typically if you have a spawned task you're communicating with it somehow. At the moment you try to receive on a channel in which the other end is dead you will panic yourself unless you took precautions to handle that case. In my experience that leads to panics propagating around quite nicely (often too nicely in fact unless you take appropriate precautions; we have very common bugs whereby Servo task failures take down the entire world with them). I don't think I've ever seen the case in which errors in panicked tasks vanish in practice because of the message passing style in which most concurrent Rust programs are written (although I am willing to believe it can happen).
It's not really name mangling that makes it hard—that has a de facto [spec] on Mac/Linux even—it's the fact that templates mean that the entire C++ language leaks into your interface. [spec]: https://mentorembedded.github.io/cxx-abi/abi.html
Trick question, nobody figures out lenses. 
Rust isn't any better in that regard, no. Arguably, it's currently worse given the difficulty of creating a standalone library exposing a C interface. That's not a language issue, just a technology one. Trying to bind directly to Rust code? Probably not feasible in the general case.
I doubt my inference is as solid as rust, I must check my 'advertising claims' here but it can definitely handle some situations C++ can't. And its definitely no where near 2way *whole program* inference like haskell. (forward only between functions). What looks like 'whole program fwd inference' is of course just a shortcut for writing templated functions... miss the types and it gives them type-params, (I like that for trivial helpers that one would have done as macros in C years ago) It works one callsite at a time, and through the operators, ; it tries to do everything forwards only first(like C++), for overloaded operators; then sweeps within function bodies forwards &amp; backwards until its resolved* This is sufficient to get the obvious cases like 'creating an accumulator', initialising and returning a struct using the info in the signature e.g. ...{ _{...}} and it is a work in progress. it was successfully able to handle something like this (I do show it in the example) auto foo=MyVariant&lt;A,B&gt;(); template&lt;class R,class A,class B&gt; R match_with(MyVariant&lt;A,B&gt;&amp;, function&lt;R(A&amp;)&gt;&amp;, function&lt;R(B&amp;)&gt;&amp;); auto ret=match_with(foo, [](A&amp; a){return ...}, [](B&amp; b){return ...}) // C++ fails, it needs you to specify the output parameter passed as a template parameter. // i.e. foo.match_with&lt;int&gt;(...) .. you'd have to use decltype if it was generic thats the kind of use case I was noticing when going back to C++ after using Rust. my system, at an unmatched call site, with some know types.. [1] finds candidate functions based on the name &amp; number of parameters and scored on currently known types at a call site (it needs some information to try) [2] for each candidate, try to match the template params based on currently know types; &amp; resolve the argument expressions in a temporary copy for that candidate.. (yikes) [3] if they do all match , instantiate that; otherwise try the next candidate. [4] once instantiated, the newly-known types propagate into variables Am I going to have problems with ambiguity like being able to pick a different overload afterwards?... I don't know, its a WIP. I don't have SFINAE yet. Perhaps if I do actually put in template bounds (I definitely want them) I wont need it. C++ *as I use it* doesn't need SFINAE.. I can do what I want with simple collection classes. I figure my worst case scenario is: - simply restrict the inference to forward only when functions have adhoc overloads or no "trait-bounds" are specified. - it might be the case that the better handling of a call site, and 'working back from the return value to for accumulators' is enough. it could just boil down to being a little like having 'decltype(..function..)' for trivial blanks. I think D has "decltype(return)"? but I'll see how it goes. I was aware from Rust that trait-bounds do improve their ability to infer types. I don't object to the existence of trait bounds - I see what they allow - Rusts ability to error-check before instantiation is great. I'd just prefer them to be optional, &amp; duck-typed.v(if these functions exist, consider the trait implemented, and the functions aren't namespaced under the trait.). That's of course roughly what C++ is going to get with concepts; described like that you might wonder why I bothered I guess. I found another interesting/similar project on github, "sugarcpp" , which as the name suggests is a language compiling straight to C++ with a load of syntactic sugar for loops and so on. That's conceptually simpler but more polished and comprehensive than what I'm trying, probably has a higher chance of being useful (lower risk, greater leverage of the c++ compiler) I had to get this out of my system I guess. I've got a lot of ideas to try and trying to contribute to an established project like rust can seem restrictive for me. C++ semantics are enough for me its just headers frustrate me.. (* and of course that can be done better. most of this is a brute force implementation I've rushed through to get something working .. its only 9kloc at the minute, I think Rust was at 80kloc when I discovered it?,"nimrod" is about that size too?, Rust is 500kloc now?(how much is libraries)... I know there's a lot of refinement to come... "the last 10% takes 90% of the time".)
&gt; The optimizations at that level are unreliable They're not unreliable. The only pass added at `-O3` right now is `argpromotion` along with the increase in the inlining threshold. LLVM doesn't treat `-O3` as a dumping ground for half-baked passes like GCC.
+1 from me. String mangling comes up in &gt;90% of all programs. This is why Perl was so big in the '90s – because they got string mangling right. Of course, a solution that allows further improvements once HKT are implemented would be preferable to a currently better solution that makes it impossible to use HKT later.
By tuple destructuring do you mean `std::tie` and `std::ignore`?
Maybe look at the emmited IR for both and compare with someone on IRC? --emit=ir 
Would the ability to export pre-instanciated generics enable a stable ABI for them? (Only for the exported of course)
Are you aware of this? http://www.stroustrup.com/OpenPatternMatching.pdf http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3449.pdf 
Several weeks ago i had a program failing with -O3 which worked with -O2. Not sure what the problem was though, because a few weeks later it was resolved.
And even then you can still learn coq 
If it’s any help, the unrestricted unions of C++11 do make it relatively easy† (by C++ standards) to write a variant type. The catch is that you unfortunately still can’t write a generic, *variadic* class template in a nice manner. template&lt;int I&gt; struct tag {}; template&lt;typename First, typename Second&gt; struct variant { template&lt;typename... Inits&gt; variant(tag&lt;0&gt;, Inits&amp;&amp;... inits) : first(std::forward&lt;Inits&gt;(inits)...) , active(0) {} // ditto tag&lt;1&gt; and second // move constructor writes itself just as well variant(variant const&amp; other) : dummy {} , active(other.active) { switch(active) { case 0: { ::new (&amp;first) First(other.first); break; } case 1: { ::new (&amp;second) Second(other.second); break; } } } // assignment left as an exercise ~variant() noexcept(/* obvious */) { switch(active) { case 0: { first.~First(); break; } case 1: { second.~Second(); break; } } } private: union { // here is why we can't have a variadic variant First first; Second second; unsigned char dummy; }; int active; }; [Quick coliru demo](http://coliru.stacked-crooked.com/a/36803c8b20d30d55) I suppose someone that does not dislike preprocessor tricks as much as template metaprogramming can 'unroll' binary, ternary, etc. partial specializations of a variadic primary class template, should they so choose. But beware header sizes… †: proper exception-safety guarantees may not be as easy to figure out!
I think that puts me at "EVIL CODE ACOLYTE" I *almost* understand monads. But I occasionally run into a case where my understanding doesn't quite work and I get confused. Though that may be Haskell's lazy evaluation throwing me off. 
&gt; You don't even need to send it to play, the URL is determined from the source, so you could generate it even without an HTTP lib. If you wanted to generate a sane URL, you'd need to send it through a shortener at least ;)
I think we can get a pretty good experience for calling C++ from Rust. The way it's done today involves `extern "C"` functions in a C++ source file, which are imported as C functions in Rust. Using Rust's extensible syntax it should be possible to automate away this layer of indirection. You would write a Rust function with an "inline C++" body that is passed to `clang++`. The syntax extension creates the C shim for you. We can import the resulting LLVM code into rustc, enabling cross-language optimizations.
I always wanted to become a ~~wizard~~ haskeller...
Small crates with remapped paths (e.g. pub use my::long::path::Foo as Foo) in your lib.rs seem to be a near perfect answer to that problem.
There are proposals to make a standard ABI for C++, that should make it possible.
There isn't much to monads in itself, the hard part is grasping various monad instances. Just because you known one monad instance, it may not be obvious how other instances work.
Unfortunately `String + &amp;str` and `Vec&lt;T&gt; + &amp;[T]` now work in some unexpected way. The following code prints "Text: suffixprefix" (playpen link: http://is.gd/5f44Bo): fn main() { let prefix = "prefix"; let suffix = "suffix".to_string(); println!("Text: {}" , prefix + suffix); } I think compiler should display a warning or error in this case.
Ah, missed those, fixed!
I noticed the C++ version was just the C version with the extra overhead of accessing the underlying C string through the std::string interface. I think the following would be a more efficient and idiomatic reverse_words function: #include &lt;algorithm&gt; void reverse_words(std::string &amp;str) { const auto End = str.end(); std::reverse(str.begin(), End); auto remaining_pos = str.begin(); while (remaining_pos &lt; End) { const auto word_end_pos = std::find(remaining_pos, End, ' '); std::reverse(remaining_pos, word_end_pos); remaining_pos = word_end_pos + 1; } }
I've "understood" monads for many years, but only recently have been feeling like I'm starting to *understand* them a little bit, if you can feel the difference between "understand" and *understand*. Does [this](http://www.reddit.com/r/haskell/comments/2lompe/where_do_the_applicative_laws_come_from/clxfblk) help, maybe?
Ah, I wanted to riff on /u/ryani’s &gt; the template metaprogramming just got too ugly. to mean it’s not possible *nicely*. I’ve edited.
Might also be useful to calculate something with the final strings and print that result, or just print the last strings. Otherwise a suitably intelligent compiler could just optimize away your benchmark because the strings are not used for anything and the functions cause no side effects other than changing those locally defined strings.
Something like this? cpp_bind! { #include "foo" extern "C" void f(int i) { // ... } } Which would then pick up on all `extern "C"` definitions in that macro, generate the wrapper code you mentioned, and then expand to something like #[link_generated_cpp_binding(12345)] extern { fn f(c_int) -&gt; c_void } Doesn't really sound that hard to me, and would certainly give results faster than holding out for a more "integrated" solution.
&gt; it's usually more fruitful to do stuff from scratch. Since wxRust is mostly a generator, in this case i think it would make sense to reuse some of that effort.
Ouch
It'd be interesting to see what happens if you had just concatenated strings together. The JIT is pretty good at taking successive string concat operations and converting it into a StringBuilder.
Thanks. Now I see that channels have methods for propagating (or not) panics, so that seems to be the place where you decide to handle linked failure or not. That's reasonable, and makes the behavior of spawn not as problematic as it seems. I'm guessing that internally, task::try just uses recv_opt on a channel it creates to get the result back. And all that is powerful enough to do things like erlang' s supervisors since you can select across many channels.
Good to know! I'll admit I was partially thinking of the GCC way when I wrote that, but I was also just thinking of the fact that going to -O3 is often negligible in my experience. I've seen a few cases where it tipped the optimizer over some critical threshold and really helped though, too.
That's true.
Better yet just use a char[]. And you should at least do some warmup of the JIT before measuring the time.
I don't know if conventions are forming (that's a strong word that requires a good survey of existing code), but the tests in Cargo certainly use a similar scheme to the one you described. Most of it is contained in `tests/support`. The underlying logic to discover paths to write tests to is here: https://github.com/rust-lang/cargo/blob/master/tests/support/paths.rs My understanding of how it works is that it creates a new directory for each test within your `target` directory, and it uses an atomic monotonically increasing integer to name those directories (because tests can run in parallel). It also relies on the ability to fetch the absolute path of the currently running executable. Cargo probably needs a more elaborate infrastructure than what you typically need because most of its operations result in some change in the file system (including directory hierarchies). The more convenient interface in Cargo's tests are the "builders": https://github.com/rust-lang/cargo/blob/master/tests/support/mod.rs --- I think this is akin to your "closures." The only real difference is that the environment is maintained explicitly in a struct. I've adapted a simpler scheme [in xsv](https://github.com/BurntSushi/xsv/blob/master/tests/workdir.rs), which uses the same name trick with an atomic integer to name test directories. But I don't need anything elaborate, I just need to test end-to-end CSV transformations. As a bonus, all of this works well enough inside of QuickCheck too. (Where you need to create a test directory for each invocation that QuickCheck makes on your property!) I don't know of any libraries that will handle all of this for you. (But I haven't looked either.) There probably exists a small but convenient subset that could be factored out into a library.
Yeah, as long as unboxed closures can't be returned properly it's probably simpler to just use a good old struct OOP style, although rust's type inference and nice syntax doesn't make it terribly more verbose that the closure solution: struct Counter(uint); impl Counter { fn new() -&gt; Counter { Counter(0) } fn get(&amp;mut self) -&gt; uint { let &amp;Counter(mut x) = self; x += 1; *self = Counter(x); x } } fn main() { let mut counter = Counter::new(); println!("{}", counter.get()); println!("{}", counter.get()); println!("{}", counter.get()); println!("{}", counter.get()); } Although if you only need get_counter locally it works out of the box right now: fn main() { let mut x = 0u; let get_counter = || { x += 1; x }; println!("{}", get_counter()); println!("{}", get_counter()); println!("{}", get_counter()); println!("{}", get_counter()); } 
I've created [a ticket](https://github.com/rust-lang/rust/issues/19952).
Yup, that would potentially be a nice feature.
 a_vector.get_mut(0) = 5; You forgot to dereference it, which you did in the first case. This should work fn main() { let mut a_vector = vec!(1i, 2i, 3i); *a_vector.get_mut(0) = 5; println!("The first number is {:d}.", a_vector.get(0)) } 
It's just a type mismatch. You'll want `*a_vector.get_mut(0)` and `*a_vector.get(0)` respectively; both `get_mut` and `get` returns a reference for *any* vectors or slices. (Also, they now return an `Option` of references as it can go out of bounds, and `{:d}` formatting syntax is merged to `{}`. Are you using an older version of Rust? [Consider using nightlies instead](http://www.rust-lang.org/install.html).)
&gt; There’s a lot of interest in seeing Firefox.html work in Servo. Actually, I have a much more pressing issue: Does `about:mozilla` work? Gradient and everything?
Should I be worried that the patches are huge and touch lots of files? I hope you mean that you didn't just implement single css properties in each.
This is a fantastic project, and I've found myself scrolling through the source code more than once. How is multi monitor support? You should post that screenshot to /r/unixporn. They'd love someone went so far in desktop customization that they wrote their own window manager!
Still optional features which make things easier for a lot of people are certainly no mistake, at least as long as they are not mutual exclusive. This optional behaviour could be hidden behind a compiler directive and would be great for prototyping or sketching programs. Fortunately rust is not only useful for writing firefox OS but as well games...
Just out of curiosity as to what is best practice, given this code corrected for the Option returns, which of the print lines in this case is the 'right' way given they all return the same thing... fn main() { let mut a_vector = vec!(1i, 2i, 3i); *a_vector.get_mut(0).unwrap() = 5; println!("The first number is {}.", *a_vector.get(0).unwrap()) println!("The first number is {}.", &amp;a_vector.get(0).unwrap()) println!("The first number is {}.", a_vector.get(0).unwrap()) }
Ah okay, I misunderstood. I figured the dereference was because the mutable vector was pointing to the original :)
 rustc 0.10 (46867cc 2014-04-02 16:59:39 -0700) Might need to run an update, but i installed it through homebrew **edit** brew upgrade says rust-0.12.0 is already installed, but command line is resolving to /usr/local/bin, i think i have a link issue :(
I wish tiling window managers worked well on OSX.
Already posted last week :D Multi monitor support is available. Just use xrandr and the WM will detect it by itself. Edit: ah, [here](https://www.reddit.com/r/desktops/comments/2oytfl/selfwritten_window_manager_finally_customized_and/)'s the post.
Wow, you've really been working on this a lot since the last post. The last post coincidentally came out the same day as I forked wtftw to hack on myself, and I ended up forking/copying it to my own repo and rewrite based loosely on your source, in order to really grasp why the datastructures were laid out that way and what information the WM needs to track from X11. I never really planned on pushing upstream, just to play with X11 (sorry :[ ) I'm really suprised how much everything changed, and the transition to library-level WM plugins for configuration is neat! Are there any killer features that xmonad has that you haven't implemented yet?
Excellent, that makes even more sense :)
I use [hyper](https://github.com/hyperium/hyper) for my projects and it seems to do the job pretty well. Its design is in flux, but then again, so is everything else in `rust`.
Hm...well, the layout system is not as neat as xmonad's, but xmonad is cheating by using HKTs. I was running a pretty standard config of xmonad, so I probably wouldn't know about any killer features that I haven't implemented yet. Wtftw is mostly a port of xmonad's core framework. I'd have to look at all the contrib extensions to see what may be missing here.
Rust for Rubyists is really just worse than the official Guide, I haven't worked on R4R since I started it. Just so you know.
Spectacle is OK
Oh, didn't know about that. It's been ages since I had a Mac in my hands.
I'll try that one but I'm not hopeful. Usually what I run into is the key binds for the thing don't work because OS X overrides it or it clashes with another apps key binds.
I use xmonad as my only WM, so I'll have to give this a shot :)
/u/edwardkmett
ShiftIt is a decent substitute. If nothing else, having hotkey control over where and how to move a window to a half or quarter-screen view is kind of nice. Something more nuanced for OSX would be welcome since Expose doesn't do everything.
Yes, I am. Why am I shadowbanned? oO God I sometimes hate HN. Not even a message with an explanation.
There's an old socialist slogan: &gt; I would not lead you into the promised land if I could, because if I led you in, some one else would lead you out. &gt; &gt; - Eugene V. Debbs :wink: Anyway, there's not really enough meat here to really say. You don't say _why_ you want to learn Rust or Go, just that you want to learn a "systems" language. The two use 'systems' in two different ways, so that's not really a good route of comparison. The Go people are using "cloud language" now, or something similar. See http://blog.golang.org/5years
+1 for Machinae Supremacy Your media aware terminal/browser software in the upper-left - is there a port of that for OSX? 
Hm, not sure if it works on OSX. It's this one here http://ranger.nongnu.org/download.html
Screenshot looks awesome! Is it possible to support text config similar to i3 http://i3wm.org/docs/userguide.html#configuring
Just the standard arch-linux set up worked for me (I honestly have no clue what the files in /etc/X11/xinit/xinitrc.d are... I've never even looked at them) if [ -d /etc/X11/xinit/xinitrc.d ]; then for f in /etc/X11/xinit/xinitrc.d/*; do [ -x "$f" ] &amp;&amp; . "$f" done unset f fi exec ~/wtftw/target/release/wtftw 
Write some rust code http://play.rust-lang.org
 exec /home/wollwage/code/rust/wtftw/target/wtftw This is pretty much my .xinitrc Testing wm's is kinda tricky when they run in a real X session. That obviously should *not* happen. I'll try and take a look. 
It's unclear, but every comment you've ever made is dead, soooooooo
For the fonts? Not yet. But as wtftw itself doesn't use any text rendering, most of my font configs go into my *.Xresources*. There will be parts of wtftw that render text as soon as I start working on the tabbed layout. A config for that will then follow.
You're not doing anything with the LD_LIBRARY_PATH there, do you do it in something else? EDIT ha ha! Apparently when I was trying to set that, it didn't work. But now it does! Neat!
Thanks, I don't know what the issue was, but it's working now.
Now it works fine, but I can't get the `gmrun` integration to work, it just types a character in my xterm. EDIT: nor do alt-num to switch workspaces. alt-shift-enter does start an xterm though... It does seem that by setting the sample config (and updating my xmobar settings) it's working well enough for me to use! Is there a guide to the built-in shortcuts anywhere? Here's what I use for xmonad: * alt-j and shift-alt-j to move windows around the workspace * alt-h and alt-l to make the split more to the left or right * alt-shift-number to send a window to workspace number * alt-shift-q to exit. I currently have to reboot my machine to test changes...
Never trolled, never linked to own stuff, don't know which part of the guidelines I broke. Well, can't be helped. But thanks. Wouldn't have noticed.
Welp, this is certainly an alternative to wxRust.
Are you running single- or dual-screen? If it's dual, you have to switch to the workspace that needs to have focus. Focus tracking by mouse does not work across screens yet (the little hassles with xlib). And please don't stop the barrage. Everything helps me to get that thing working everywhere.
Single screen, nothing fancy.
&gt; By tuple destructuring do you mean std::tie and std::ignore? Ha, that’s close! Very close. Now make it work in a ``switch`` statement and function arguments … In any case after you pointed that out to me I regret even more that I’m stuck with antediluvian GCC 4.4 at work. 
I dunno why you would be worried; CSS is complicated.
They implement parsing the CSS declaration, layout changes to propagate necessary information, gfx changes to actually paint the necessary bits, and add a bunch of tests to verify the changes. Some properties are more complicated than others; that is the nature of CSS. The second commit in particular also includes a bunch of re-architecting to support things like colspan, and also implements a number of common legacy HTML presentational attributes.
tests/html/about-mozilla.html
That's not how the game is played. It is played like this: you have some needs and you look for tools. If the Rust is the tool for your needs then you use Rust otherwise you search elsewhere. For me, the Rust is more apealling the more I code in C++ because it solves problems that I have with C++. It has build system with dependency management. It has modules instead of header files which is win for several reasons. It has bounds on generic code. It is more convenient for me to be harrased by borrow checker than to fear what naughty memory and synchronization bugs I have not found in testing. So I see Rust as a replacement for C++. But remember, YMMV. If you are just looking for yet another language you will learn then you can simply flip coin.
Seems you have been unbanned.
Ok, that's odd. Focus on the right window? So the typing in the browser worked, but then stopped completely? Huh...the input masks should be correct. I expected bugs to creep up when I post this, but these ones are intriguing.
Yep, wrote an email. Apparently my first 2 comments were too short and I got sacked by their algorithm.
Cool. Dang is a pretty reasonable guy, as much as we disagree at times... anyway.
Not necessarily, as Patrick Walton mentioned C++ templates would still be a though fight, and today templates pervades C++ entirely.
Hm, only reason I can think of is that it crashed. But in a real X session it should throw you back on your tty. I should add more extensive debug outputs, then it should be possible to narrow it down.
Let me know how I can help. Oh, and how do you quit? Shutting down X would be very useful.
alt+shift+q. alt+q reloads the WM and the config. Pretty handy when you change the config or something in the code.
Done.
&gt; , so I hope the Rust community will sell me the language, Why? Simply google "i like rust" or whatever, and there will be plenty of articles biased towards motivating and praising the language. With the level of understanding that is shown, people would just have to reiterate the usual talking points. What's the point in that (unless someone really wants to do that, of course)? It seems a bit entitled to solicit a community to summon a sales pitch for him. His current contention is basically "what the hell is all this syntax", and "those angular brackets makes it look like C++, ugh". I am personally not of the opinion that syntax doesn't matter, but how can you really make an answer to that? Maybe argue that `[`-brackets would have been better, or some more Haskell-y whitespace-as-application syntax for generics. Beyond that, the function definition differences between Haskell and Rust are basically apples to oranges, since Rust's have to express more granularity (typically). You don't have to care about lifetimes, borrowing and friends in Haskell since it uses automatic memory management and pervasive immutability. 
hey, OP here. I just wanted to clarify this was not a post to critique Rust in any way. On the contrary, it was more to see if I could answer my questions with a bit of provocative thought. Yes, it may seems that my choice of learning a language might be arbitrary, but is not. As an engineer I'm perfectly aware I should reach for the best tool for the job at hand, as /u/pepp_cz pointed out. Haskell is great for 90% of the things I need to build, but for the 10% where I need more speed and a better control of system resources, I feel that I could learn a "system" language to do that, making my skillset more complete. Hope this will clarify a bit my intentions, I come in peace ;)
I'm no rust expert, but in response to the points in the article, I think there are a few language features that you have to think about, that can change the levels of verbosity, zen-ness, and assurances of programs in that language. **Immutability**. I think this is largely why Haskell can achieve its zen abstract beauty and functional purity and laziness. But you have to pay for it. It's amazing what you can do without mutability, but many algorithms require it for performance. Sure, you can model mutability in Haskell, but I think then you'll start losing its abstract beauty that you love so much. **Garbage collection**. Garbage collection gives huge gains in the beauty, productivity, and simplicity of code. It also gives high assurances about memory correctness. But you have to pay for it with a runtime library and pauses. These features are great, but they're not appropriate for all programs, such as high performance programs, or low level libraries. Without them, you're left in the world of ugly, verbose code. This is probably why Rust looks like C++ to you. This category is dominated by C/C++. With C/C++, you're stuck with slow compilation and barely any safety assurances. If you're stuck programming in this category of languages, this is when Rust should really interest you. **Borrow Checker**. Safety! Safe memory management. Safe concurrency. No runtime cost. This is the huge feature of rust. But you have to pay for it, with extra thinking, and sometimes extra verbosity. So sure, Rust will never reach the beauty of Haskell, but that's OK. It's in a different category of programming languages. Imagine high performance programs (browsers, image libraries, encryption libraries) that can freely use concurrency with newly achieved levels of assurances against security bugs. You no longer have to make the choice between high performance and high assurances. With Rust, you can have both. But sorry, your code is not going to look as beautiful as Haskell. You should learn it if you want or need to program at speeds similar to C, especially with concurrency. Otherwise, stick to one of the other simpler garbage collected languages.
Thanks, it was quite a good answer ;)
Speaking of fonts, what font are you using in your terminals? It's gorgeous.
Doesn't really fit the OS X windowing model. But, you can do tiling arrangements via keyboard shortcuts. I use Divvy but there are plenty. I've only *manually* dragged a window around a few times in the last couple years, I think.
Evidently complicated beyond my comprehension!
Hasn't happened for me yet
Hey, thanks for the reply. The "why" is, as I have written in my previous comment, to "fill the hole" Haskell leaves when it comes to really go "to the metal", or where you really want your code to be as fast as it could, and have better control over system resources. But yes, I can see your point about the fact the "system" semantic of Go and Rust is quite different, in that sense ;)
Good idea, these gave a pretty good speed boost.
I did that initialize, and removed it when there was no noticeable difference between printing/not printing the result strings. 
If that's your goal of a systems language, you'd be right back here in a month asking the same question if you choose Go. Go doesn't let you get that close to the metal, in fact its so simplistic and strict it can be maddening (this being said it is nice for some things). The lack of generics and ability to get almost no closer to the metal than Python left me needing something else...hence Rust. 
Why is it surprisingly natural? Because you never borrow from a general iterator, its methods are relatively "atomic" and multiple borrowing never occurs. So the Rc-encapsulated iterator behaves just like a regular iterator, just in multiplayer.
what is the state of servo regarding forms and interactivity? can I go to reddit for example, login to my user and comment on a thread?
Same trouble with rogue HTML entities [as before](http://www.reddit.com/r/rust/comments/2pdxbe/24_days_of_rust_fuse_filesystems_part_1/cmvyrrn). Keep on posting, though!
I guess a lot of functions (like `zip`) don't specify in which order they evauluate the two iterators.
Is there a way to do it with cargo?
Tabbed layout? Oh man, I'd love that. Are you planning on using Xft for text rendering? Xlib text apis are a huge PITA and don't play well with i18n.
I don't know yet. I'll have to look into it. Have to find a way that maps easily to xlib *and* wayland.
I've tried to contain myself, but I just *have* to point out that the code comparison in the blog post is not fair to Rust. We are comparing the type definitions of ideal and highly generic code like the definition of Functor, which I can agree is awesome, to the internal parts of a networking tool which has to deal with all the complexities that arise in implementing the protocol and the cursor representation of a highly-stateful text editor. There is ugly code in every language - we should be comparing languages on an equal footing, where they are solving the same problem, not debating the relative beauty of Functor vs. HTTP.
Doesn't that only apply to X11/XQuartz apps?
Note that `from_fn` on Vec is proposed to be deprecated in favour of iterators and collect: https://github.com/Gankro/rfcs/blob/collections2/text/0000-collections-reform-part-2.md#deprecate In fact we propose simplifying *a lot* of Vec in favour of collect/extend: * `Vec::from_fn(n, f)` use `(0..n).map(f).collect()` * `Vec::from_elem(n, v)` use `repeat(v).take(n).collect()` * `Vec::grow(n, v)` use `extend(repeat(v).take(n))` * `Vec::grow_fn(n, f)` use `extend((0..n).map(f))` This will make code more verbose, but will push more functionality towards one of our core pieces of functionality: iterators. Everyone should understand how to use iterators. As always: we favour composition and flexibility over custom specialization and combinatoric explosions.
I've recently looked at Mjolnir. No opinions yet or even understanding of the full capabilities.
I don't know
also, fwiw there's a few different ways to write the given code in a more idomatic/readable way: Original: let v = range(0, 10u).map(|x| x * 3).collect::&lt;Vec&lt;_&gt;&gt;(); Alternative: let v: Vec&lt;_&gt; = range(0, 10u).map(|x| x * 3).collect(); What I would do: let v: Vec&lt;uint&gt; = range(0, 10).map(|x| x * 3).collect(); What should hopefully work from context: let v = range(0, 10).map(|x| x * 3).collect(); And with the new range syntax in the pipeline: let v = (0..10).map(|x| x * 3).collect(); And for sake of completion, with the current from_fn: let v = Vec::from_fn(10, |x| x * 3); However the iterator code is more flexible because I can easily change it to: let v = (2..10).map(|x| x * 3).collect(); But from_fn gets awkward: let v = Vec::from_fn(8, |x| (x + 2) * 3);
does it play well with desktop environment panels? that's mostly what's keeping me on xmonad
In theory, the AvoidStrutsLayout should detect them. Will give it a shot later.
Can you make it so it works nicely with taskbars from other projects: Don't close/maximize/minimize them? Awesome treats them like regular windows, and it's annoying.
Could you name a few? Then I can test. Up until now I've only tested dzen and xmobar, and both are recognized and *not* treated as regular windows.
Rust switched to opt-in Copy instead of opt-out. Previously you needed a "NoCopy" dummy member of a struct to have it not implement Copy, while now you have to explicitly allow it. Copy is for marking it as thread-safe, not for move semantics iirc. That's Clone.
Mainly KDE's plasma stuff. I don't need all of it, just the taskbar would be enough. I don't understand why tiling window managers have to be annoying while working under a desktop as a replacement to their native window manager. Openbox seems to get this right. Edit: I just checked, and Awesome closes lxqt-panel too.
Thanks for the clarification and the examples in your other comment! Together with the new range syntax these look nice. BTW that explains your custom CSS :after username ;-)
The screenshot looks glorious. Going to try it out later. (I love tiling WMs but haven't found the perfect for me yet.)
Yeah, sadly it only works within the XQuartz app. :( I really wish OS X would let you swap the window manager.
&gt; I don't understand why tiling window managers have to be annoying They don't *have* to be. The issue is that tiling devs are usually have a very minimal setup, and supporting most of the freedesktop.org standards is a *ton* of leg work. There's a pretty big difference between a tiling WM that bucks most standards and just works (i.e., core Xmonad) and a WM that satisfies all or most of the ICCCM and EWMH standards. Hell, there are still things being used from the old MOTIF stuff. Openbox has pretty amazing compliance with standards. It's hard to match. Disclaimer: There is a module in xmonad-contrib (or possibly module**s**, it's been a while) that will add ICCCM and EWMH functionality where pertinent.
&gt; Why am I shadowbanned? Probably too critical of Google or PG. Or one of the mods just didn't like one of your comments. :)
Use `#[allow(missing_copy_implementations)]` on the struct.
Why would you want to go back after they've treated you this way? They get away with this shit because "it's where the content / readers are". That only gets worse when we participate in the community, legitimizing it and providing content for free. We have plenty of venues for talking about Rust, and programming generally, that aren't run by megalomaniacs. [Stop using Hacker News.](http://www.reddit.com/r/rust/comments/2inln9/every_language_should_be_designed_simultaneously/cl44w4r) Above are my own opinions and not necessarily those of my employer, blah blah.
Logging in doesn't work right now because we don't have cookies yet. Form inputs generally work.
This is awesome, thank you for doing this :) I've been wanting to learn me some Qt for a very long time, but I always found C++ too indimidating. Maybe with this project I'll be able to build me some simple GUIs in Rust, with the cross-platform goodness of Qt :)
&gt; Merge pull request #20 from Gankro/grand-theft-collect Branch naming as a form of art
I can't speak for the quality of all the code here but there is a great list of [some Rust projects on github]( https://github.com/kud1ing/awesome-rust)
Dr. Who, Portal, Machinae Supremacy, Arch Linux and Rust. &lt;3
He controls the collections inside the system, and outside..
Sorry, no. `Copy` means copy semantics for a struct, which I believe means you can pass ownership to a function and still use it outside because it copies instead of moves. `Clone` just means you can call `.clone()` to get an owned copy, such as if you want to turn a borrowed reference into an owned one. I believe `Copy` currently implies `Clone` but they're planning to decouple that. `Send` is for objects that can be *sent* across thread boundaries, and `Sync` for objects that can be accessed concurrently (`Arc` requires `Send + Sync`).
Plus one for `:t` - loads of people come to rust from haskell and that's basically muscle memory for me now. 
The vector should recognize that the `size_hint` bounds are exact on a range object and only do a single allocation.
I had some parallel collections/iterators I was toying with. I think I'll issue a PR tonight. 
&gt; Why is this a warning? What if I want objects to be move-by-default? No idea, the change is just odd. You need to explicitly silence it if you're okay with it. However there is a good chance you want them `Copy` anyways.
Solution suggested by krdln on reddit: impl &lt;'a&gt; Bar&lt;'a&gt; { fn reborrow&lt;'b&gt;(&amp;'b mut self) -&gt; Bar&lt;'b&gt; { Bar(&amp;mut *self.0) } } 
Side question - anyone know what IRC client is shown in that screenshot?
I've written tens of thousands of LOC in each of Rust and Go. I even maintain some open source projects that others find useful in both languages. I've written several libraries in both languages. I've written several applications in Go, but I'm still working on my first medium-sized Rust application. I love both. I share your sentiments about simplicity: there is a quiet elegance to Go's simplicity that I just love. I've been *quite* happy writing concurrent code in Go and really haven't experienced the same type of misery that I have in a smattering of other languages (like C or Python). (I'm not saying Go is necessarily unique in this regard! Just giving sharing some experience.) Notably, despite the fact that Go uses a shared memory model, I've found the built in abstractions (channels and goroutines) to be very effective and not horribly prone to error. For Rust... I think my favorite aspect of it is the borrow system and what it lets you do *without a garbage collector*. For example, I have a CSV parser *that doesn't allocate* but is *also safe*. This allows consumers to control their pattern of allocation, which is wicked cool. (e.g., "Just allocate a string for fields 1 and 3 out of this 100 field CSV file.") And there there's the whole generics thing. But I fall firmly into the camp that says There Is No Free Lunch. Some days, I really appreciate the simplicity and compilation speed of Go. Other days, I love me some generic functions. I'm not sure if this will convince you to learn Rust, but that's my two cents on the topic.
Previously, `Copy` was automatically implemented for a type if all the contained values were themselves `Copy`, e.g. struct ThisWasCopy { x: int } struct ThisWasNot { x: Vec&lt;u8&gt; } Now, after [RFCs 19 &amp; 127](https://github.com/rust-lang/rfcs/blob/master/text/0019-opt-in-builtin-traits.md) you have to explicitly implement `Copy` for the first case to be `Copy`. The restriction about fields implementing `Copy` still applies, it is just whether the implementation is added automatically. A type `T` that implementing `Copy` means that a shallow byte copy is a safe way to duplicate values of that type. Every by-value use of a value is (semantically) a shallow byte copy (the copy itself may be optimised away), e.g. `let x = y;` or `foo(y)` are both doing shallow byte copies of `y`. In the case that `y: T` has `T: Copy`, `y` can continue to be used, in the case that `T` is not `Copy` it cannot, or else we would've unsafely duplicated the value. [More info about `Copy`](http://stackoverflow.com/a/24253573/1256624).
&gt; Copy means copy semantics for a struct This is slightly deceptive: what `Copy` really means is a shallow byte copy is a safe way to implement `Clone`. (That's one phrasing anyway, see my comment below for another.) The compiler then understands that by-value uses (i.e. "passing" ownership) are not forced to invalidate the source and so allows continued use of it. Other than that, there's no particular difference between the behaviour of `Copy` types and non-`Copy` types. &gt; I believe Copy currently implies Clone but they're planning to decouple that. It doesn't. There was a plan was to couple them, but there's a hitch: it needs negative bounds. See [Niko's comment on the matter](https://github.com/rust-lang/rust/issues/17884#issuecomment-58582308).
I would expect code gen to be basically identical.
Oh dear! Do you have a repository I could test this out on to see if I can reproduce? It could be the case that the binary itself succeeded in all its tests but failed to exit (e.g. thread local destructors blocking forever). You may want to try running the tests manually and seeing if it actually exits as well.
I find this Ray Tracer to be very well written, (It's not mine). https://github.com/ruud-v-a/robigo-luculenta
sorry, not about fonts. General configuration. In i3 if I change config, I just have to reload, with wtftw I need to rebuild?
That's why they'll allowed for GCed resources at some future. The language allows for it, there just hasn't been enough of a pressing need to implement it.
I wasn't able to run the tests successfully (lots of failures), but running the test binary manually showed that the test binary itself was hanging, so this may not be a cargo issue (you can see where threads are blocked with `thread apply all bt`)
How does the LruCache remove method work? It looks like it removes the key from the underlying map, but doesn't alter the linked list?
Ah okay, thanks steve.
yes, it is caused by my test cases. I was able to reproduce by running a single test case. cargo test test_init I just checked out the latest version and ran without any issues on Mac 10.10.1. yes, there are lot of warning though. What OS are you using? 
It is a limitation of old, "boxed" closures; it always borrows its environments (outer variables referred by closures), so any boxed closure created in the function cannot escape that function. The new, "unboxed" closures can technically solve this problem, but it's using some heavy (I admit!) machinery for maximal flexibility and might be unwieldy to beginners. Without a ~~further~~ detailed (EDIT: I've added some hints) explanation, this is what should work: #![feature(unboxed_closures)] struct State&lt;'a, S, A&gt; { // `Fn(S) -&gt; (A, S)` is a trait for environment-immutable closures. // others include `FnMut` (environment-mutable) and `FnOnce` (can only be called once); // this is very similar (and in fact, equivalent) to `&amp;self`, `&amp;mut self` and `self` methods respectively. // `Box&lt;...&gt;` is required for making it a concrete (sized) type, allowing it to be stored to the struct. // `+ 'a` is required since the trait can contain references (similar to `|...|: 'a -&gt; ...` in the boxed closure). runState: Box&lt;Fn(S) -&gt; (A, S) + 'a&gt; } impl&lt;'a, S, A&gt; State&lt;'a, S, A&gt; { // unlike old closures, new closures are generic, so you need a trait bound. fn and_then&lt;'b, B, F&gt;(&amp;'b self, f: F) -&gt; State&lt;'b, S, B&gt; where F: Fn(A) -&gt; State&lt;'b, S, B&gt; + 'b { State { // `box` is for making `Box&lt;...&gt;`. // `move |...| { ... }` means that the closure moves its environments into itself, // this is required since we lose `f` after the return. // the borrowing counterpart is called `ref |...| { ... }`, and a bare `|...| { ... }` will be inferred to one of both. runState: box move |firstState| { // currently there is a caveat for calling new closures in a box: // you cannot directly use the call syntax. you need to explicitly write the method name out. // also note the "weird" tuple construction, this makes one-element tuple. let (result, nextState) = self.runState.call((firstState,)); f(result).runState.call((nextState,)) } } } } Fortunately, /u/steveklabnik1 is working on the new section for unboxed closures in the [Guide](http://doc.rust-lang.org/guide.html), so stay tuned :) (Also, if you just want to *use* the State monad, you can use [`scan`](http://doc.rust-lang.org/nightly/std/iter/trait.IteratorExt.html#tymethod.scan) iterator adapter which roughly does the same.)
The irc client is weechat. The config can be found at https://gist.github.com/Kintaro/72fa4e256e7c61df7326
Technically, can't HKT be [hacked together](https://github.com/rust-lang/rfcs/blob/master/text/0195-associated-items.md#encoding-higher-kinded-types) using the current type system?
You need to post more information. You should (at minimum) include the complete output of the compiler, and some indication of what library you're using (as in cargo package name or git repository). That said, by using my amazing psychic powers, I can divine that `ImageBuffer` has three generic parameters. You are not specifying them. You need to either hard-code them in the signature, or change `draw` to *take* three generic parameters and pass those on to `ImageBuffer`. If none of that makes any sense, you may wish to read [The Guide's section on Generics](http://doc.rust-lang.org/guide.html#generics).
"Technically can be hacked together" is a far cry from "write your software this way" :)
In discussions I still regularly encounter people who think header files and native code must go hand in hand. "you don't want headers? ... java's that way". Crazy stockholm-syndrome/priestly-cult attitudes.
Mostly being facetious, but "Don't write your software this way" is a far cry from "You can't write your software this way" :P
I found Robinson, a toy web browser engine, to be a good pedagogical example for both web browser engine and Rust. Importantly, there is an explanation of the code, in the form of a blog series. https://github.com/mbrubeck/robinson
If you only change the config, mod+q is enough. That will "restart" (execvp) the vm, recompile the config automatically and reload it. If you change the sources, rebuild it, hit mod+q, same result. It's the same as xmonad in that regard. Or the same as i3, as long as it is with regards to the config. (Sorry for any typos, just came back from celebrating my last exam ever....I know I'm gonna regret this tomorrow...)
This is the only solution I know of (at least, it's what I did in [a library with a similar situation](http://huonw.github.io/strided-rs/strided/#ownership-and-reborrow)).
I might try it out in a nested X env. I can try to learn the best practices from every project. For productive use, I'd advise against using my WM at the moment, as @steveklabnik1 has proven. Although I'd appreciate the incoming bugs/issues. For me at least, the WM as been running stable for at least 2 weeks now. Including on-the-fly updates due to it's on-the-fly reload ability.
I think it specifically *does not* work: http://is.gd/CzZHZb (notice that the table starts freaking out and removing elements that were just inserted) Congratulations, I believe you have found a bug in a std collection! When can I expect a PR? :)
You are missing type parameters there (`fn draw&lt;Container,T,PixelType&gt;(...)`). And, if my reading of the library documentation is correct, you should actually avoid `ImageBuffer&lt;Container,T,PixelType&gt;` in favor of `GenericImage&lt;PixelType&gt;` for the fully generic code. The `draw` function would look like this then: fn draw&lt;Image: GenericImage&lt;P&gt;, P: Pixel&lt;T&gt;, T: Primitive + 'static&gt;(img: &amp;mut Image) { ... } I think you probably have to look more at the library source code. It seems that the generated documentation is out of date.
Then go ahead and have fun. It's an awesome file "manager". Especially the in-terminal image/pdf preview is worth a metric ton of awe.
Thanks, that was super helpful! 
I'd proposed a command line flag to pass in cookiefiles but someone (gw?) mentioned that that counts as a chrome and we should either do it right or have none at all.
Started reading it. It's clean and easy to follow.
This also had a really nice blog series : [Writing a path tracer in Rust, part 1](http://ruudvanasseldonk.com/2014/08/10/writing-a-path-tracer-in-rust-part-1)
`Rc` seems orthogonal to being able to share the same iterator and mutate it, which is what `RefCell` provides. You could just `impl&lt;'a, E, I: Iterator&lt;E&gt;&gt; for &amp;'a RefCell&lt;I&gt;`.
Good to know As a side-remark `ImageBuufer` also has `enumerate_pixels_mut` which returns an iterator and can be used instead of `from_fn`. Probably I should also implement `FromIterator` at some point.
Yes, there is some problem with rust-ci. :/ We are already looking for an alternative.
The rust source code itself is excellently written and (coincidally) always up to date. Plus Github's search is pretty awesome. There is some legacy stuff here and there tho, as I understood it, but so far haven't had a problem with that.
Obviously it's a downstream thing rather than something with the Rust bindings, but I reeeeeally wish this supported Win32 and its weird and incompatible console goings-on. Not necessarily because I like Win32, but because I'd like to be able to support it in any readline-esque CLI code I write =(
Just not the compiler. Ignore the compiler itself. The Rust compiler is not representative of how you'd write a compiler in the Rust we have today. It's weighed down with years of a very special kind of technical debt. The language it is written in has changed dramatically over time and the compiler has only really been updated to a "working" state each time. Some parts of the compiler are quite good, but most is not. 
&gt; The rust source code itself is excellently written Many people on this subreddit recommend strongly against using the `rustc` source to learn, unless you're looking at parts you know were redone recently. A lot of it is not a good example of "modern" Rust.
I currently run [Amethyst](https://github.com/ianyh/Amethyst), and although it's slow compared to most WMs on linux, it does the job alright. The default configuration is really similar to Xmonad. 
It's all good - I'm not bitter about you 'picking' on `hyper` or anything, just trying to point out the relative elegance of the constructs.
Looks awesome! One tiny question/nitpick about the placement of the configuration though: you use `~/.wtftw/src/` as your base directory. Wouldn't it be a better idea to adhere to the [XDG Base Directory spec](http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html)? 
What a perfectly cromulent library!
True, with your code and the compilers I tested it's not optimized away. I saw some similar cases where clang was intelligent enough to optimize code away though And if you implement the benchmark like that in a lazy language, it would run in 0 seconds. Unless you explicitly force evaluation of the strings.
Why is treemap being removed? Thanks for your work!
Ah, right. But my point was about `Rc` being excessive/not necessary.
&gt; Original: &gt; &gt; let v = range(0, 10u).map(|x| x * 3).collect::&lt;Vec&lt;_&gt;&gt;(); &gt; &gt; Alternative: &gt; &gt; let v: Vec&lt;_&gt; = range(0, 10u).map(|x| x * 3).collect(); &gt; &gt; What I would do: &gt; &gt; let v: Vec&lt;uint&gt; = range(0, 10).map(|x| x * 3).collect(); &gt; I've slowly come to agree with aturon's guidelines, which suggest using the former case here. http://aturon.github.io/features/let.html#use-type-annotations-for-clarification;-prefer-explicit-generics-when-inference-fails.-[fixme:-needs-rfc]
As far as I remember the slowness of the compiler is generally atributed to suboptimal bytecode being generated by the frontend and consequently LLVM spending lot of time on optimizations. I would expect that this will improve over time. I do not see compile times that bad for clean builds. What I would love is improvement in incremental builds.
I've never used it, so I don't know how well it works, but maybe it would be possible to create a cross-platform Rust library that abstracts over readline/linenoise/libedit and [WinEditLine](http://mingweditline.sourceforge.net/)?
A related question: Are the nightlies built with optimizations enabled? (Thinking of a compiler building an optimized compiler is very meta)
Its fallen into disrepair, and BTreeMap should have superior performance.
The nightlies are built with optimizations enabled, yes. Believe me, when you run unoptimized Rust code, you feel it. :)
this is the second post I've seen where an unboxed closure gets boxed. do you know if there will there be more work done to closures in general? slightly off this topic: [the first post I saw](http://www.reddit.com/r/rust/comments/2pjsep/limitations_of_not_having_a_gc/cmxctvc) was answered with a good solution by boxing the closure. I realized I could implement the whole thing without a box as long as I referenced it all within that main functions scope; soon as I pulled it out to a function on it's own I had to box it, like the replies had done. Why is this? let mut x = 0u8; let mut count = |&amp;mut:| { x += 1; x }; //no box println!("{}",count()); vs fn count() -&gt; Box&lt;FnMut() -&gt; i32 + 'static&gt; { ... }
… only if you decide that you want the type to **not** be implicitly copyable. Otherwise, use `#[deriving(Copy)]`
Run rustc with `--no-trans` and you will be surprised how fast the rust part of it is.
Simply because you cannot name the anonymous unboxed closure. There is an [RFC](https://github.com/rust-lang/rfcs/pull/105) that can possibly make this redundant (the RFC PR is closed, but the discussion is continued below).
I didn't fully internalize that RefCell is simply sharable by the immut ref. Now I get it :) Both methods of sharing have their uses, I guess this means that `Rc&lt;I&gt;` and `RefCell&lt;I&gt;` are orthogonal components.
When I try to use the restart functionality (alt+q), I get task '&lt;main&gt;' panicked at 'called `Result::unwrap()` on an `Err` value: broken pipe (Broken pipe)', /build/rust-git/src/rust/src/libcore/result.rs:745 I have had it work before, I'm not sure what changed between then and now.
Figured it out. It's because I was running wtftw through a symlink, rather than directly.
(I'm not 100% sure if I understood what you're trying to achieve, but maybe this will help you.) You can build a "polymorphic" index and dispatch on the argument type if you use a trait: struct PolymorphicIndex { str_index: BitmappableIndex&lt;&amp;'static str&gt;, long_index: BitmappableIndex&lt;i64&gt;, double_index: FlatIndex, } impl PolymorphicIndex { fn new() -&gt; PolymorphicIndex { PolymorphicIndex { str_index: BitmappableIndex { bitmap: Bitv::new() }, long_index: BitmappableIndex { bitmap: Bitv::new() }, double_index: FlatIndex { bitmap: Bitv::new() }, } } } trait BitmapIndex&lt;V&gt; { fn get_bitmap(&amp;self, value: V) -&gt; &amp;Bitv; } impl BitmapIndex&lt;&amp;'static str&gt; for PolymorphicIndex { fn get_bitmap(&amp;self, value: &amp;'static str) -&gt; &amp;Bitv { self.str_index.get_bitmap(value) } } impl BitmapIndex&lt;i64&gt; for PolymorphicIndex { fn get_bitmap(&amp;self, value: i64) -&gt; &amp;Bitv { self.long_index.get_bitmap(value) } } impl BitmapIndex&lt;f64&gt; for PolymorphicIndex { fn get_bitmap(&amp;self, value: f64) -&gt; &amp;Bitv { self.double_index.get_bitmap(value) } } And then, you can use it transparently: fn main() { let mut indices: Vec&lt;PolymorphicIndex&gt; = Vec::with_capacity(2); indices.push(PolymorphicIndex::new()); indices.push(PolymorphicIndex::new()); let _bitmap_1: &amp;Bitv = indices[0].get_bitmap("abc"); let _bitmap_2: &amp;Bitv = indices[0].get_bitmap(123); } [Playpen link](http://is.gd/Qq7SGc) Is that what you mean?
I don't think `value:T` can be multiple types at the same time. You might need to use traits in your code.
I'm afraid the current design doesn't make much sense. The problem with get_bitmap is that its type signature is making an invalid promise: get_bitmap is claiming to be able to conjure a meaningful &amp;Bitv for *any type T* (like i16, String, Duration, any type at all). Type T has no restrictions and no connection to FieldIndexType. You can't check the type of T at runtime, so this design will not work. There is probably a way to get what you want by using traits, but first I need to understand what you want. What is the expected behaviour of this piece of code: let str_index: FieldIndexType = ... // get an StrIndex from somewhere let result = str_index.get_bitmap(123.0f64); // What is the result? We have an StrIndex but are calling get_bitmap using a double PS. Are you using Rust 0.12? I strongly recommend using nightlies
I really must have been looking at the wrong parts of the source *feels bad*
Left two issues :)
There's definitely some excellent parts, and it *is* always up to date in the strictest sense of the word. It's just ultimately *very old* code that has effectively been hand-transpiled through several different languages that all happened to be called Rust. Rustdoc and Rustc are perhaps the worst offenders.
&gt; Perhaps Rust just isn't that productive a language? &gt; [Rust 1.0.0-alpha – Friday, Jan 9, 2015](http://blog.rust-lang.org/2014/12/12/1.0-Timeline.html) &gt; RUST 1.0.0-***ALPHA*** - **FRIDAY, JAN 9, 2015** 
Good points. Let me back up a bit and explain the goal...I think I may have convoluted things. I'm building a simple document store. The user indexes documents, where each doc is a list of key:value pairs. Fields have a strict schema. E.g. "title" is defined as a string field, "price" is defined as a long, etc. Each field is indexed: strings and longs use a bitmap-based index, doubles get a FlatIndex (which behaves differently). The goal is that when a user asks for `"title" : "Quick Fox"`, they receive a bitmap representing the docs holding the string "Quick Fox". If they ask for `"price" : "Quick Fox"`, they would receive an error, since price has a numerical schema. At a higher level, there is a `HashMap&lt;&amp;'static string, FieldIndexType&gt;` which basically maps key to the value index for that field. I omitted that from the post for brevity. &gt; There is probably a way to get what you want by using traits, but first I need to understand what you want. What is the expected behaviour of this piece of code: So, to answer your question, this should return an error. I accidentally simplified my code for the post...in my project `get_bitmap()` returns `Result&lt;&amp;Bitv&gt;`, and Err is used to signify when you request the wrong schema type. &gt; PS. Are you using Rust 0.12? I strongly recommend using nightlies Nope, I'm on nightlies...although I'm coming back from a break in Rust coding, so that code is a month or two out of date. :) So yeah, it's entirely possible I am attacking this problem entirely incorrectly. My rust is decent for simple programs, but I'm really struggling with more complicated design. :)
This is very helpful, thank you. I've really struggled with using traits effectively so far. A few questions: - By using traits like this, I'm basically doing virtual dispatch through a vtable, right? - Is there a way to specialize the polymorphic index so that it only contains one type of index? E.g. each field will contain only one schema (String, Long, Double), so it only needs one index. If you request a different value type, you just get an error. I'll play around with this, thanks!
oh hrm, maybe in a day or two.
Some notes: * cooooool * `mem::replace` sounds like a better choice than `mem::swap` for what you're doing (just cleaner code). * ~~`decode` sounds like it should be a static member, not a member function? e.g. `ColumnarVec::decode(&amp;mut Vec&lt;Vec&lt;u8&gt;&gt;) -&gt; Self`. Or do you often have a pre-existing one that you want to reuse?~~ Reading more this seems to be the case. * Also interestingly you could take the VecVec immutably if you want to be able to deserialize multiple times, possibly in parallel. It would also be interesting to consider making this API work based on Iterators? Maybe take an `Iterator&lt;Vec&lt;u8&gt;&gt;`? Or perhaps even `Iterator&lt;IntoIterator&lt;&amp;u8&gt;&gt;` once we have that. Not sure if it would be fruitful since you probably always want Vec. * Your `pop` impl for tuples has curious consequences. In particular it will panic if malformed due to the right Vec being empty before the left one, but will return `None` if the left one is. I would suggest using one of these two depending on the semantics you prefer: match (a.pop(), b.pop()) =&gt; { (Some(x), Some(y)) =&gt; Some((x, y)), (None, None) =&gt; None, _ =&gt; unreachable!() } match (a.pop(), b.pop()) =&gt; { (Some(x), Some(y)) =&gt; Some((x, y)), _ =&gt; None, } * For better or worse, your open-brace-on-new-line style is non-idiomatic in the Rust community (we favour a fairly strict style for that sort of thing). * This code frustrates me a bit because it highlights the utility of being able to "partially" drain a Vector via an iterator. Rust's ownership model is really complicating these subtle "all the options" ownership problems.
I was actually thinking about the `for&lt;'a&gt;` syntax in this context. But it seems — for now at least — to serve a different purpose. Maybe /u/aturon has something to add to that.
http://is.gd/vxXGX6 #[deriving(Copy)] pub enum Field { Str(&amp;'static str), Long(i64), Double(f64) } pub trait AsField { fn as_field(&amp;self) -&gt; Field; } impl AsField for &amp;'static str { fn as_field(&amp;self) -&gt; Field { Field::Str(*self) } } impl AsField for i64 { fn as_field(&amp;self) -&gt; Field { Field::Long(*self) } } impl AsField for f64 { fn as_field(&amp;self) -&gt; Field { Field::Double(*self) } } impl FieldIndex { pub fn get_bitmap&lt;T&gt;(&amp;self, value: T) -&gt; Option&lt;&amp;Bitv&gt; where T: AsField { match (self, value.as_field()) { (&amp;FieldIndex::Str(ref index), Field::Str(value)) =&gt; Some(index.get_bitmap(value)), (&amp;FieldIndex::Long(ref index), Field::Long(value)) =&gt; Some(index.get_bitmap(value)), (&amp;FieldIndex::Double(ref index), Field::Double(value)) =&gt; Some(index.get_bitmap(value)), _ =&gt; None } } } For type safety you must return an Option. There is no way to know at compile time whether the type of the field and index match otherwise. My personal opinion: you are better off without this function since the only way it saves you work is if you immediately `unwrap()` it, which is only the right thing to do if you already know what the type is going to be. But if you know what the type is going to be, why make it polymorphic in the first place?
Also, Rust has a built-in framework for micro-benchmarking: * mark your bench functions as `#[bench]`, they take a `&amp;mut test::Bencher` * call the bencher's `iter` with a function, that function is your actual bench code. The function should be a single bench iteration, the benching framework will do its own testing of run speed and run it multiple times if it wants to * if the benched function is "pure", or at least generates output, feed that output to `test::black_box` to ensure it's not optimised away * if your bench function consumes or generates a specific amount of data during a run, set that amount as the bencher's `bytes` field, the framework will then provide a throughput estimate in its output Put that in your test code, and you can use `cargo bench` with a nice output like test foo ... bench: 5691 ns/iter (+/- 1208) = 386 MB/s And, test code is generally in a conditionally compiled `test` submodule, so it doesn't get compiled when not testing (see the testing guide, it's pretty good IME)
Personally, I am actually unsure of the benchmark worth: as mentioned by John Regher, `-fsanitize` is about *quality diagnostics* first and foremost, and performance is a secondary concern As far as I know, this means the benchmark, while useful to understand the cost of `-fsanitize`, is useless to understand the cost *optimized* integer overflow checking would have. Roughly speaking: 1. `-fsanitize` uses `__ubsan_handle_add_overflow` to report the issue; this function can be overloaded by the user which may decides whether it's worth reporting/aborting/...; in an optimized implementation this would probably be the first thing to go, in case of overflow you would either `abort` or `panic!` (decided at compile-time) which should be much more optimizer friendly. 2. `-fsanitize` cares about precisely reporting which operation is at fault, and therefore instrument *each and every of them*; if just aborting/panicking is the goal, then there is no point checking each and every single operation, just taint the result and check at "boundaries" (see the talk on [`Metadata`](http://millcomputing.com/topic/metadata/) in the Mill CPU for a CPU optimized for this detection, there are lessons to be learned there even for a software implementation). 3. Neither the front-end nor the optimizer have seen much work here; notably, it is possible that *new* optimizations could be brought forth by the knowledge that no overflow can occur. For example, today in C++ `uint64_t a = .., b = ..; uint64_t c = a + b;`: it is unknown whether `c` is greater than `a` or not. In overflow arithmetic either `c` is greater or the operation aborted, which is a boon for range analysis. 4. Finally, with proper CPU support, the cost could probably become negligible.
You can also just return the value from the benchmarking closure to avoid it getting optimized away.
you can define traits on enums too...so take your original enum and the generic trait riccieri gave and implement each one, with the specific type, for the enum...you would match on `*self` to make sure the enum is of the right type and then handle the error case if it is not(that you shouldn't get because you are matching before you call this)...a good example of an enum implementing traits is [`std::option::Option`](http://doc.rust-lang.org/src/core/option.rs.html#742-760)
I didn't know what std::move did so I looked it up and began to get excited while reading about it. Then I saw that it's in C++11 only and, well, let's just say that the compiler I have to use in my current project does not support C++11. (I'm interfacing with a proprietary application and when I attempted to link the libraries needed to do that, it didn't work using GCC so I had to switch to what the developers of the application I'm interfacing with is using. Up until that, I had been using GCC.)
http://www.boost.org/doc/libs/1_57_0/doc/html/move.html c++11 move was based mostly off of Boost.Move, from what I understand. Have fun :D
&gt; I think some people here reasonably won't regard this as "needs to be priority #1" post-1.0 I count myself among them. There are many other important things that have been pushed beyond 1.0. Asynchronous I/O comes to mind.
Rust has many zero-cost abstractions. Instead of paying for security during runtime, we pay for it at compile time. That is the path that rust took, and I think it is brilliant. In general, I would not expect rust to compile as quickly as other languages. That being said, code clean up is always a good thing.
Thank you :)
While I like the construction of the column store and the corresponding API, I can't really follow the arguments the author is making: &gt; "... columnarization, a technique from the database community for laying out structured records in a format that is more convenient for serialization than the records themselves." Column stores in comparison to row stores don't offer any serialization benefit per se. The main benefits are the following, I will be using a record (A,B,C,D,E) as example with all types u32 (4 bytes): * If you only use some fields you have to load less data from memory/disk into cache and your working set is more probable to fit into cache. For example when filtering only the records where A=22 and B=45 you only have to actually load x*(sizeof(A)+sizeof(B)) = x*8 bytes instead of x*record_size=x*20. This can make a very significant difference. * When using compression to reduce the size of data, columns can often be compressed better because they only contain data of the same type and nature and thus probably share similarities. When using such a small record consisting only of integers it probably won't make a difference. But if e.g. some fields are country abbreviations, textual description or others are ids, one could easily imagine that there are gains. Coming back to the point about serialization, using the same technique as described in the blog post, there won't[1] be a performance difference between column storage and row storage (e.g. using a struct). The method described in the blog post just lets the data array of the original vector be wrapped by a Vec&lt;u8&gt; without even moving the memory, so the method is independent of the data type that is stored in the vectors. Of course it will only work for data types that do not contains references, otherwise we could get illegal memory access after deserialization (which should be guaranteed by the rust type system because only Copy types are allowed). The only thing this benchmark is testing is how fast a vector can be initialized. [1] The only case where there will be an improvement if you have structs with a lot of alingment overhead. Column storage would not have any such overheads. 
&gt; Not at all, this is still static dispatch. The difference is that it is multidispatch: it depends on the type of the argument to the function, not only on the type of the object. This became possible in Rust not too long ago. See this blog post[1] for more details. Oh, wow...I entirely missed that capability while I was on my break from Rust. Looks like I have some catching up to do on the new trait reforms while I was away :) For whatever reason, I assumed that traits == virtual dispatch, which clearly was a terrible assumption :) &gt; Sure! You can do this by implementing the multidispatch trait on the enum you had before. Be aware that you would get runtime errors this way though. This makes sense. Thanks so much for handholding me through it :)
This makes sense, thanks for spelling it out. Will have a play at it tonight :D
&gt; I suggest a second independent compiler implementation. This should be done before 1.0 anyway, to make sure that the spec is precise and complete. There was some dude doing GCC front end for Rust... last year I think. I saw article somewhere. No word since. 
Oh god no. We actually want to release 1.0.
See also: [Stalin](http://en.wikipedia.org/wiki/Stalin_(Scheme_implementation\))
Is there a way to modify the Rust benchmark so that it doesn't need to use slice indexing?
But good to know. So I have to either track down why that is or mention that in the readme.
Will look into it. It kinda grew from a quick-and-dirty POC to my default WM :D
It's certainly on my mind for post-1.0 work. I don't know how high priority this will end up being vs new features, but my hope is that for some time post-1.0 the focus (at least on the language/compiler front) will be on a small number of features that we would have liked to be in 1.0, but couldn't, polishing existing features, and improving the quality of the compiler and tooling.
ah, btw, are you going to add a systray? that's another feature out-of-the-box that I miss in SpectrWM
I'd recommend to use trayer. Haven't tested it yet, but it should work.
I'm already using it, but I don't like it :-/ I prefer something integrated with the WM
Humm... well, I should install dunst then. I try to send a message with `notify-send` and nothing is displayed, that's the problem basically. And in some cases, some applications requires a systray, like megasync for example. I would love SpectrWM a little more if they had a systray built with the WM, I use `trayer` but I dislike it being shown only in one workspace...
Hrm, now that I think about it, plain old `type Foo&lt;'a&gt; = ...;` already lets you define parametrized type aliases, that would probably be the most straightforward addition to associated types, although `for &lt;'a&gt;` would still be useful for some cases.
I'm planning to keep it as a pure window managing tool. But I might add a systray as a separate stand-alone solution later.
Do you have a different notification daemon installed already? :P spectrwm is a minimal WM, it doesn't implement it's own. I don't think most other WMs do either, actually. I just checked, and I'm really suprised that spectrwm doesn't have a quirk you can apply that makes the window show on all workspaces. That's a pretty standard one for other WMs :/ EDIT: Make sure you add dunst to either your .xinitrc or spectrwm's autorun commands so that it starts automagically once you reboot!
Alright, that makes sense. :) In that case you can use traits to implement it and restrict the type T to meaningful values. See wrongerontheinternet's excellent answer for a good way to do it.
Thank you for the heads up. 
Breaking news! This works now! I just added support for running files. It turns out, the Rust compiler was already detecting `#!/some/path` on the first line of a source file, which would otherwise be a syntax error. So, that was convenient.
the thing was that notification-daemon didn't have a dbus interface, so it was installed but was doing nothing since that detail. I installed dunst and is pretty cool, I almost have it configured as I want! However, I have problems with the [shortcuts], spectrwm uses the Super_L (or mod4) and I want to use it too for dunst, but it doesn't work (I press mod4+space to close a notification and nothing happens) I guess I should start my own thread to get some help on fixing this! Dunst is awesome, thanks!
Sounds to me like it should just desugar `for expr1 in expr2` to `while let Some(expr1) = expr2.next()`.
The trouble is that that only works when expr2 is an lvalue. You often only want to evaluate it once and store the result. 
Good point, you don't want `for x in vec.iter()` to become `while let Some(x) = vec.iter().next()`.
/r/playrust
...I think you're not where you think you are.
Ahh, my bad. I'm new to Reddit. Just made the account and searched Rust. Look for this same post there, in the /r/playrust subreddit. xD
Just to be clear for those on linux, it says the following in the [linked](http://article.gmane.org/gmane.linux.kernel/1853266) announcement. &gt; affects users on Windows and Mac OS X but not typical UNIX users.
What would be the problem with that?
It'll return the first entry in the vector forever.
it's an issue with case-insensitive file systems, but can be spread by any filesystem so it's best for everybody to update.
Oh yes. But couldn't be something like: let i = vec.iter(); while let Some(x) = i.next() ...
Right, rereading it also says this in the post... not sure how I missed it and had to go read the announcement... oh well.
I'm actually incredibly glad this workaround exists. In my eyes, ```while let``` syntax provides a beautiful general-case way of handling foreach-loops.
Thank you! That was an interesting read.
How does for x in iter { iter.next() // skip one } work in that case?
Because there's a difference between writing a standard library and writing a good standard library. Add in the fact that Rust has had a couple identity crisis(es?) over the past few years.
I think that it's more reasonable to have a full 1.0 spec first. It might not be precise or complete (some details may be off) but we can assume that the language is still young enough that discovering these will not be terrible. A second compiler can be done post-1.0 for the purposes of testing the spec itself, and any issues can be solved for a Rust 1.0.1 which would have a full precise spec (doing mostly what the compiler already did).
Probably was too difficult for a single dude to keep up with all the changes and reimplement them.
It doesn't work with the for loop, with the while loop it works as you suggest in your comment, is that a problem? (At least according to testing against the current rustc) Playpen link: http://is.gd/Fi0nAs
&gt; -fsanitize uses __ubsan_handle_add_overflow to report the issue; this function can be overloaded by the user which may decides whether it's worth reporting/aborting/...; in an optimized implementation this would probably be the first thing to go, in case of overflow you would either abort or panic! (decided at compile-time) which should be much more optimizer friendly. It wouldn't be any more optimizer friendly, beyond `abort` being much smaller (`panic!` is more code). &gt; -fsanitize cares about precisely reporting which operation is at fault, and therefore instrument each and every of them; if just aborting/panicking is the goal, then there is no point checking each and every single operation, just taint the result and check at "boundaries" (see the talk on Metadata in the Mill CPU for a CPU optimized for this detection, there are lessons to be learned there even for a software implementation). Panic also reports the precise location and the various panic branches aren't interchangeable. Only an abort without error reporting can be combined with other aborts, and even then it's still going to need to OR the flags together before branching. &gt; Neither the front-end nor the optimizer have seen much work here; notably, it is possible that new optimizations could be brought forth by the knowledge that no overflow can occur. For example, today in C++ uint64_t a = .., b = ..; uint64_t c = a + b;: it is unknown whether c is greater than a or not. In overflow arithmetic either c is greater or the operation aborted, which is a boon for range analysis. LLVM already learns this from the branches to abort and it doesn't help much. &gt; Finally, with proper CPU support, the cost could probably become negligible. That's not true. Operations with side effects have a big impact on optimizations because code motion isn't possible in general. Rust would only be able to leverage CPU support if it gave up on unwinding for these kinds of errors, because optimizing compilers can't support async unwinding without significant costs (LLVM doesn't support it at all right now).
&gt; Personally, I am actually unsure of the benchmark worth: as mentioned by John Regher, -fsanitize is about quality diagnostics first and foremost, and performance is a secondary concern &gt; As far as I know, this means the benchmark, while useful to understand the cost of -fsanitize, is useless to understand the cost optimized integer overflow checking would have. Here are the numbers the implementations from Regehr's paper on C / C++ integer overflow checking: &gt; For undefined behavior checking using precondition checks, slowdown relative to the baseline ranged from −0.5%–191%. In other words, from a tiny accidental speedup to a 3X increase in runtime. The mean slowdown was 44%. Using flag-based postcondition checks, slowdown ranged from 0.4%–95%, with a mean of 30%. However, the improvement was not uniform: out of the 21 benchmark programs, only 13 became faster due to the IOC implementation using CPU flags. Full integer overflow checking using precondition checks incurred a slowdown of 0.2%–195%, with a mean of 51%. http://www.cs.utah.edu/~regehr/papers/overflow12.pdf
I wonder if anyone would like to collaborate on a language that is like Rust plus a few extra features. I'm working on a pet-language that looks like Rust, but is really just a subset of c/c++ (plus some more sugar); ... but there's nothing I want that couldn't be done as additions to a Rust compiler. (an option to make it more liberal, A different module system which could be slotted in as 'use mod...as..', D UFCS + C++ style overloading, duck type traits) Working on my own I'm not attempting to do that though. Omitting large numbers of features from C++ &amp; Rust makes this a feasible 1man project. perhaps is would be possible to build something that can actually handle C++ &amp; Rust behaviour in one AST, although I realise there are many fiddly details like 'module vs class visibility', aliasing rules,... but perhaps it would be a great way to do transpilers both ways perhaps a straight 'rust-&gt;C++ transpiler' as an 'independent implementation' would be of more interest to more people
This bit me earlier today. I was playing around with custom iterators and kept running into compiler errors. In the end it actually forced me to change some things for the better to work around it, but I'm kind of glad that the troubles I had were due to the compiler and not me being stupid (this time.)
The thing is that the sugared for loop doesn't expose the `it` variable you're using. That variable just stores the saved result of the iterator expression. 
This is very neat (I've used it myself a few times recently), but there's an edge case that makes this slightly more error prone (equivalently, slightly more flexible/powerful): `while let` will accept any pattern, leading to confusion about why you're not iterating if a pattern is mistyped. E.g. enum Foo { Bar, Baz, Qux } while let Some(Bar) = it.next() { ... } is valid, but will only execute `...` while `it` yields `Bar`s, but the "equivalent" `for` will give an error, forcing the programmer to be more explicit about their intentions: for Bar in it { ... } // error: refutable pattern in `for` loop binding ...
Sure it works fine if you write out the variables manually, but in the desugaring case, the user doesn't have access to the `i` variable created inside the compiler.
Go, honestly, hasn't change much since its inception. Rust, on the other hand, has changed its syntax and semantics a number of times, requiring library developers to keep up with it. Once it's stopped changing, developers can add features at a faster pace. There's that and the fact that Rust will probably never have, say, a web server in its standard library. Or crypto tools. It's just another way of looking at what a standard library should contain - Go was developed at least in a large part for web-facing services, meaning it should probably contain things that are useful for web servers, while Rust is aiming to be used in places like web browsers, kernels, your text editor an IRC server - where the main priority is providing suitably speedy algorithms to build on top of.
We did that already! Does anyone else remember rustboot? :)
As I understand it, you’re right—right now, the kind of unboxed closure you want—`FnOnce`, `FnMut`, or `Fn`—can only be inferred if it’s created directly in a context that only accepts anything implementing one of those traits, as you observed. Otherwise, it’s assumed to be an old-fashioned closure (for backwards-compatibility reasons, presumably). [Pull request #19113](https://github.com/rust-lang/rust/pull/19113) enabled this inference. In the future, I believe the plan is to remove the explicit `:`/`&amp;:`/`&amp;mut:` syntax altogether and, instead of inferring from the closure’s context, infer from the closure’s code. So any closure that moves out of its environment would be a `FnOnce`, any closure that mutates its environment would be a `FnMut`, and everything else would be a `Fn`. This is part of [RFC 231](https://github.com/rust-lang/rfcs/blob/master/text/0231-upvar-capture-inference.md). However, this hasn’t been implemented yet, probably because of the fact that it would require removing the old closures first.
&gt; It also catches a lot of irritating runtime errors at compile time I know what you meant, but this statement doesn't make very much sense as it's written.
Oh, good point, but that still isn't a regression from the current behavior (in which it fails to compile).
Could someone explain why the first example doesn't work, but the second does? I've come up against this a number of times and don't fully understand it. In the second example, isn't `input` borrowed mutably for the entirety of the match block, and thus prevented from being borrowed by `parse_parenthese`?
Any chance we can get web socket support?
Do you know if there is an index page with all of the valid dates?
What sort of socket support? [std::net already has tcp and udp.](http://doc.rust-lang.org/std/io/net/)
Cool! It's the real language when you can write scripts. : &gt; I'm sure I'll use it somewhere.
&gt; Repositories hosted on github.com cannot contain any of the malicious trees that trigger the vulnerability because we now verify and block these trees on push. We have also completed an automated scan of all existing content on github.com to look for malicious content that might have been pushed to our site before this vulnerability was discovered.
Rust as a language has changed focus numerous times. Each necessitated a rewrite of the standard library, and very often that rewrite was not done. Rust has to pay for it at some point. As far as the Go *compiler* goes (which is what this thread is talking about), it's still far from done. Like Rust will, Go was missing a lot of stuff at 1.0. It still had segmented stacks, for example, and a bad GC, both of which are changes that Rust has already dealt with. And IIRC Rust Cox is still not done translating it fully to Go anyway. So I'm not sure that the argument that Rust is a less productive language than Go is really being demonstrated here. If anything, what's being demonstrated is that writing a language, and a compiler, is hard, even if you know exactly what you're going for.
Great intro - cheers!
You might be interested in [monad.rs](https://github.com/epsilonz/monad.rs) which implements the State monad in Rust in both [trampoline fashion](https://github.com/epsilonz/monad.rs/blob/master/src/monad/state/trampoline.rs) and as a [free monad](https://github.com/epsilonz/monad.rs/blob/master/src/monad/state/free.rs). You can see an example of using it [here](https://github.com/epsilonz/monad.rs/blob/master/examples/state/free.rs). The reason for implementing in trampolined or free monad style are due to the fact that because Rust lacks tail-call optimization, if you implement State (or almost any other monad) naively, you will easily blow the stack…
That has nothing to do with compilation times. Native compilers were already quite fast in the early 90's. The problem is that nowadays many developers are only used to C and C++ compilation times, which are anything but fast. I surely expect Rust compilers to improve. 
The free monad macro I put together isn't too bad as far as usage goes. You specify a signature functor and the map function for the functor and the macro will build a free monad impl for you: pub enum Sig&lt;'a, S, X&gt; { Get(Box&lt;FnOnce&lt;(S,), X&gt; + 'a&gt;), Put(S, X), } pub fn map&lt;'a, S, X, Y, F:'a&gt;(m: Sig&lt;'a, S, X&gt;, f: F) -&gt; Sig&lt;'a, S, Y&gt; where F: FnOnce(X) -&gt; Y, { match m { Get(g) =&gt; Get(box move |:s| f.call_once((g.call_once((s,)),))), Put(s, a) =&gt; Put(s, f.call_once((a,))), } } monad!(State, Sig, map, [ S, ]) I wouldn't exactly call it a hack but the actual macro is [a bit involved](https://github.com/epsilonz/free.rs/blob/master/macros/src/free/monad.rs)…
*hug*
Don't sweat it too much man.
Cool! Does the "modern HTTP" hyper lib support HTTP2? ;)
Nice. Would it be appropriate to add swap_remove to RingBuf?
No worries! The language is not the prettiest, especially in comparison to Haskell, but the semantics are really quite beautiful. I would highly recommend giving it a closer look. :)
`input.next()` only borrows `input` for the duration of its own call, since the return value is owned (as far as the iterator is concerned [1]). Its lifetime not tied to the lifetime of the iterator. [1] Things like `&amp;[...].iter().next()` can return a reference, but it’s tied to the lifetime of the slice, not of the iterator.
&gt; In contrast, I’ve gotten tired of stringly-typed languages; chief among them is JavaScript. Everything is a string That is not true. Javascript has lots of types: Undefined, Null, Boolean, String (which has the problem that it's based on UCS-2), Number, Object, List, ... One problem is that is weakly typed, which means that there are many ways of automatic conversion from one type to another, which may lead to strange unpredicted results. &gt; document.onlood = onload; The problem you are describing here is that you can add fields to object after declaration. This has not that much to do with strings.
It's alright! We'd be happy to have you. :)
I love it! I've been willing to work/contribute on something like this! I'll give it a try.
Have you seen [docopt.rs](https://github.com/docopt/docopt.rs)?
&gt; It looks increasingly likely that hyper will be available to use on Rust-1.0-day. I’m confused. Is Hyper not available already?
Besides a common functional influence, comparing Haskell and Rust truly is comparing apples and oranges. I prefer to think of Rust as a "prettier, safer C".
Be my guest. Any help is appreciated.
[Git](http://git-scm.com/download/mac) 2.2.1 has been released that [fixes this vulnerability](https://raw.githubusercontent.com/git/git/master/Documentation/RelNotes/2.2.1.txt). Be sure to run brew update brew upgrade if using homebrew
Here's an even type-safer version of http://www.reddit.com/r/rust/comments/2pgrz7/required_parameters_utilizing_the_builder_pattern/cmwlxfl that does not need a "build" method in the end: #![feature(default_type_params)] // phantom types trait Complete {} struct True; struct False; impl Complete for True {} impl Complete for False {} struct Person&lt;Name=False, Age=False&gt; where Name: Complete, Age: Complete { agev: Option&lt;uint&gt;, namev: Option&lt;String&gt; } trait PersonBuilder&lt;N, A&gt; where N: Complete, A: Complete { fn age(self, uint) -&gt; Person&lt;N, True&gt;; fn name(self, &amp;str) -&gt; Person&lt;True, A&gt;; } impl Person { fn new() -&gt; Person { Person { agev: None, namev: None } } } impl&lt;N, A&gt; PersonBuilder&lt;N, A&gt; for Person&lt;N, A&gt; where N: Complete, A: Complete { fn name(self, n: &amp;str) -&gt; Person&lt;True, A&gt; { Person::&lt;True, A&gt;{ namev: Some(n.to_string()), agev: self.agev } } fn age(self, a: uint) -&gt; Person&lt;N, True&gt; { Person::&lt;N, True&gt;{ namev: self.namev, agev: Some(a) } } } // walk is only implemented for a Person with both a name and an age impl Person&lt;True, True&gt; { fn walk(&amp;self) { println!("I'm walking") } } fn main() { let john = Person::new() .name("John") .age(37); john.walk(); let unknown = Person::new() .age(37); // unknown.walk(); now this is a compile-time error unknown.name("Rob").walk(); // but this works }
Just checked, "hello world" in Standard ML (`print "hello world\n";`), compiled in `mlton` on Linux, after symbol stripping, has 165kb. While small, it's still far from C's standards (6kb). OCaml's hello world via `ocamlopt` is 133kb.
Maybe they meant hyper will be 1.0 when rust is 1.0?
Kudos for giving a public apology. To your original question: &gt; I would like to learn something different, and I went back and forth in deciding whether I should learn Go or Rust (I know, potentially I should learn both). The real question is: Which of the two? Have you browsed both https://gobyexample.com/ and http://rustbyexample.com/ ? I came from Haskell (among other languages) and Rust always appealed to me as some sort of a Low-level Haskell. Also many Rust-developers have a ML/Haskell background.
But they are semantically completely different... for/in does something for *every* element in the collection, so it's obvious you shouldn't be modifying the collection in the meantime, or advancing the iterator. I think while/let is better for these examples, and maybe the compiler should warn you if you're missing any other cases than None (I assume that's the most common case for if/let and while/let).
Now, how does "the Rust runtime" compare to "the C++ runtime"?
&gt; it should now be possible to call a Rust function directly as a C function with absolutely no setup Nice.
It is almost too late now, but I think all the libstd collections should be a separate git repository. Contributions and bugfixes would tenfold when it's much easier to change, compile, test and iterate with a small crate -- using cargo.
I take to mean that Hyper would be included in the standard library as the official Ruat http lib?
Vec losing `Vec::from_elem`? Please don't take all my sugar.
Does this mean that we should see a reduction on the size of compiled programs from now?
&gt; It wipes out the ability to hoist most array bounds checks out of loops, etc. Why? If the expression is constant (and can be hoisted), you can also hoist the overflow check, no? (But bounds checks shouldn't cause an overflow anyways.)
About that learning experience.. I wanted to start contributing for some time now. So I'd be up for the task later today. (Although I might have a lot of questions about the process :D)
Probably not. But we should see reduced memory consumption for small programs.
I wasn't aware of Rust by example, thanks! :)
Yes, malloc will fail, and so will mmap. It'll do that if you have overcommit turned off or if your process runs out of *address space*. I strongly disagree with OOM-on-abort.
If I'm reading this right, does this mean that its now feasible to make big giant Rust libraries that could end up in big package managers with people being able to use it with both `#include &lt;whatever&gt;` in C/C++ and `extern crate whatever` in Rust?
No. Binaries were mostly bloated by IO subsystem and it was "cleaned" a long (in Rust terms) time ago.
A question about the change to tasks (now threads) and channels... will this allow a select abstraction that lets a task select between I/O abstractions and channels? In the past this has been deemed impractical because it would add too much overhead to channel messaging. But that has made it difficult to write server tasks that can be controlled by other tasks in the process, and I've had to write my own I/O library with epoll and eventfd.
Doing something a bit like this (although without the same kind of generality) was quite a big win for us in PathEngine. The key was a custom container designed to replace vectors of vectors at runtime, as described [here](http://upcoder.com/2/efficient-vectors-of-vectors/).
Absolutely!
Sorry :( `repeat(x).take(n).collect()` isn't exactly a huge burden, though. And as always you can craft your own fns or extensions traits to recover the old behaviour.
Awesome! I'm Gankro on #rust and #rust-internals on irc if you have any questions.
Is `document.onlood = onload` not just sugar for `document["onlood"] = onload`? e.g. you're literally setting variables with String keys?
I see! Hello world is still 600K+ though, even with LTO, which AFAIU means that much of the stdlib is still included. This doesn't affect me in particular, but I'm curious to understand the differences between Rust and C++ in this regard.
I disagree, the collections need network effects to have any hope of being maintained. If the crate is too bloated for fast iteration, you can just comment out the mod declarations you don't care about. Also this is more of a temporary rustc flaw that we don't have decent incremental compilation. :) It's a *collections* library. Many of the changes are much harder work to implement and verify than a lot of other changes in other projects, in my opinion. I often require patches get *twice* reviewed just because of this. As such I hardly expect to get huge boosts in contributions just because it's easier to iterate. (Also it's already *orders* of magnitude to iterate over std::collections)
It looks like there is no difference. What previously was "deschedule" has been renamed to "park", but it still ends up waiting for a mutex/condvar combo. Or as the function says: "The implementation currently uses the trivial strategy of a Mutex+Condvar with wakeup flag".
I was lazy, so I just went to rust-by-example, took a 3-line program and clicked "llvm ir". I haven't actually checked if clang also generates so many fluff declarations, but boy, that stuff looks scary.
Isn't EnumSet fundamental enough to keep in core? How would one implement the common pattern of keeping a set of flags? (without wasting one byte of memory per flag) 
You just bitshift and bitmask over an integer type like you would in C/C++, and exactly like the impl does? https://github.com/Gankro/collect-rs/blob/master/src/enum_set.rs#L153-L165 Basically we're not happy with these designs (the other being bitflags) and want to explore better options for a while. 
If repeat is in the prelude, I'll accept. I can't mistake the parameter order on this one either..
I doubt that the stdlib would itself include a module for http, but that doesn't stop the language from suggesting hyper as a "blessed" third-party library to fulfill that purpose.
I'm pretty sure almost all of that is due to the inclusion of runtime options. http://mlton.org/RunTimeOptions It's a small amount of overhead and isn't representative of larger programs. 
At this point, now that Cargo is working pretty well, it's probably feasible to prototype collections in an external crate, and take the time to get the API right before proposing them for inclusion in Rust. The alternative is to leave half-baked collections in the std library for 1.0, and live with their warts forever. Sure, it's painful when they remove my pet feature (personally, I'm really going to miss `#[unstable]` for libraries). OTOH, Cargo libraries are dead-simple to use.
I think this is the feeling many of us have when our code finally compiles in Rust (or Haskell, or similarly strict compilers)!
I'm more impressed by the followup :P &gt; Sam Nardoni: @pcwalton "after compiling". But how long did you spend fighting the borrow checker? ;) &gt;Patrick Walton: .@samnardoni I didn't have any borrow check errors.
There's also the third option which I consider worst-of-both-worlds: Leave it in std as `unstable` so no one using stable can use them *at all*.
as a haskell user that you are, I think you'll be thrilled when HKT lands (at some point); at which point you'll probably enjoy rust even more. from what I've seen, those who get to the point of even showing interest in rust end up liking it enough to learn it and enjoy it on some level.
I wonder when the point it reached at which servo implements CSS that not even Firefox has. PS: I still hope to see some microtypography features like protrusion in a browser at some point. ;)
There is no `librustrt` anymore - what mandatory lang items are you talking about, btw?
Epic stuff.
I believe that would be possible, with the caveat that you should be really, really careful about using panic. Aborting your user's program isn't very nice.
It's no big deal. :)
We're not really adding things to the standard library, if anything, we're removing more and more. I read this sentence as "Hyper will not be using any experimental features, and will be reasonably feature-complete at 1.0's release."
Yes, you're still going to get static linking by default.
Panic across boundaries is explicitly undefined behavrior, so it's even worse than 'not nice'.
http://doc.rust-lang.org/guide-unsafe.html#avoiding-the-standard-library
&gt; One important change here is that a Rust program ends when its main thread does, following most threading models. Does this mean that (non-`mut`) references to objects declared in `main` can be shared across threads without an `Arc`? Since the owner (`main`) is guaranteed to live at least as long as the borrow (any other thread), there's no memory safety issue and the overhead of an `Arc` isn't needed. Or is that too much of a special case to be handled?
It is available today. I meant, there's concern that several features of Rust won't be stable for 1.0, and many libs will require nightlies to compile. Hyper should be compatible with Rust 1.0 when it arrives. 
Yes exactly. Perhaps I should clarify.
Apologies, such is the life of rustc changing so much. I should have it fixed in a few.
That *is* the problem. All property getters and setters in JavaScript use strings. In most languages, you can't validate that the String is correct at compile time. Even in JS, the JIT won't notice. It will happily set a `onlood` property. Or equally as bad, crash the program while the user is using it, if doing `document.onlood.apply(...)`. Rust's compiler will notice when you try to compile (ie, before a user is playing with your software), and force you fix it.
Recently(ish) there was some serious discussion on MessagePorts, which Firefox doest have. We tend to implement the hard things first so as to avoid a redesign, but currently focus is shifting to dogfooding so more basic things are rolling in.
I don't want tasks to disappear
so you actually use it chromeless? don’t you at least use some primitive address bar with history buttons? those would even work unpriviledged with an iframe.
I have a PR for `image-rendering: pixelated`, which Firefox does not have the standardized form of. (It only has the nonstandard `image-rendering: -moz-crisp-edges`.)
* `mem::replace` is in place now; I think the irc folks got that to me. You, possibly. Thanks! * Taking the VecVec immutably would prevent casting it to Vec&lt;uint&gt;, or whatever internal type. It's important (for this implementation at least) to repurpose the buffer to avoid an allocation. * I agree about `pop`, but it is a 20-30% perf hit to do both non-emptiness tests. Maybe `pop` and `unsafe_pop` are appropriate? The interface is esoteric enough that you shouldn't be able to show up with data other than what you put in, perhaps. * About curly braces, I know... Some day I will forgive you all. * I agree! Not sure what to do, though. It hurts the most with `String` types because the code to do the draining is byte-wise, and pretty slow.
I have a simple native browser shell that I use. Stay tuned :)
Nope. Been thinking about the problem, but welcome PRs also :D
I wonder if you could maybe get some cleaner code or better perf by passing around a Drain iterator (just added to master last night!) and doing some sort of `drain.by_ref().take(num_bytes_in_this_type)`. You could also do it with an `into_iter` and just call `into_inner` at the end (which spits out the Vec it was removing stuff from).
I'm really looking forward to HKT ;)
Author here, "Column store" is totally the key phrase to find earlier work. "Columnar" is commonly used as the adjectival form to describe a data representation or store. "Columnarize" seems like the best verb form. I'm sticking with it. :) I think one reason you wouldn't expect to see a verb form used is that the DB community doesn't tend to move back and forth between forms very often. A store is usually either a row-store, or a column-store. If you want to issue a query, the DB implements it appropriately against the store it has. You might see "migrating records from the row-store to the column-store", but ... this isn't a store, and I needed a word. On the other hand "modern" big data systems want to switch back and forth between the two, because a user wrote their UDF against some rich row-oriented records, whereas storage and transmission can often be column-oriented (open debate on whether this is helpful). Systems like [Trill](http://research.microsoft.com/trill/) will try to rewrite your UDF to run against column-oriented data (a stream, not a store), whereas this approach lets you just get the data back to rows to avoid reflecting on UDF structure and such.
It it statically linking only the symbols it uses or it statically linking the whole library regardless? In GCC terms, is it statically linking with --whole-archive? 
Keep up the good work buddy.
Totally, but the number of downvotes suggested I could have done better on the communication level ;)
Thanks for the pointer!
IIRC, the whole library, regarless. A crate is Rust's unit of complation, so linking half a crate wouldn't make sense.
What do you mean by 'tasks' here? This is largely a rename. Or are you referring to the libgreen removal?
And maybe they should also yank/deprecate the old crate to reduce confusion? Anyhow, xml was just an example. The same problem applies to other crates.
i think it would be prettier if everything about being “familiar to C++ devs” would have been thrown out of the window. * (mandatory) braces instead of semantic indentation * &lt;&gt; instead of [] for generics
interestingly, both are standardized. while pixelated is for preserving the pixels (duh), crisp-edges preserves sharpness, and might use an alhorithm like EPX, HQX, or [this one](http://research.microsoft.com/en-us/um/people/kopf/pixelart/)
Nah, Rust compiler never bothers pcwalton. Otoh pcwalton does sometimes bug borrow checker about letting things through. We call those times updates to borrow checker ;P https://twitter.com/horse_rust/status/526234668526358528
Is there a reason you went with dots instead of colons for commands like `.type`? Coming from Haskell, I'm very used to using colons for commands, and it seems like a good idea to stick with familiar syntax when possible.
I think implementing a bencode decoder is a great first project to complete in rust as it really shows some of the benefits that algebraic data types and pattern matching give when doing any sort of parsing. Just some things that I noticed though: - The bencode spec is separate from the .torrent spec. In your decode function, you are only checking if the first data type is a dictionary. While that is what makes a .torrent file valid, it does not make a bencoded file invalid. You probably want to have a bencode module and a separate torrent module where it checks if the representation of the bencode is valid as a .torrent file - With the first point in mind, I would refactor the parse_dict() method to remove the match statement and move that match statement up into the decode method so that you can recursively call the decode method when you encounter a dictionary or list value (this is what I have done in my own implementation) You can see my bencode module here https://github.com/GGist/RustBT/blob/master/src/rust-bt/bencode.rs if you wanted any reference implementation. Note that this is not the most recent version of my code and so it may or may not compile (still waiting on a compiler bug fix to get compiled into the next rust release).
Braces are great because then it's agnostic of whitespace and indentation becomes purely a style choice. You could pack an entire Rust program into one line. As for this pattern: if something: doSomething(); else: doSomethingElse(); The noise reduction is minimal and makes it difficult to pack it into a one-liner, which is useful since Rust doesn't have ternary statements (`condition ? true_val : false_val`). Rust's expressive if-statements are much more flexible anyways. Almost *everything* uses &amp;lt;&amp;gt; for generics. The only exception I'm aware of is Scala. I don't see that many complaints. 
If @pcwalton needs to fight borrow checker, that is obviously a bug in borrow checker :)
A valid Rust statement or expression can begin with `::` as part of an absolute path, while no valid construct can begin with `.`. Of course, it would be possible to check for a line beginning with a single colon and not two, but my thinking was that using `.` instead would be less visually confusing. Though it seems that absolute paths are not frequently necessary, anyway. I'm open to changing the syntax if a majority of users would prefer it. I'm not exactly sure how to elicit feedback from any users of rusti. I don't even know how many people are actively using it.
I just mean the concept/word. I liked that it used different wording than other languages. 
&gt; Braces are great because then it's agnostic of whitespace and indentation becomes purely a style choice. indentation isn’t a style choice though: it is intrinsically mapped to the AST. i think a semantic tab character (1 tab = one nesting level) is as ideal as it gets. &gt; You could pack an entire Rust program into one line being able to write one statement after an if/else clause is useful, writing multiple isn’t. fitting many things into one line isn’t some quality worth striving for if you aren’t code golfing. also a braceless rust should of course have trinaries, e.g. (python style) let bar = baz if baz &gt; 5 else 0 or (coffescript style) let bar = if baz &gt; 5 then baz else 0 or anything else along those lines. extra syntax here is basically one small tradeoff for all the lost brace cruft. and yes, i think {} are busy glyphs! then there’s bazillion styles of where to put the braces, and none are perfect. no braces = no problems. &gt; Almost everything uses &lt;&gt; for generics doesn’t make the choice less shitty. &lt;&gt;, like all operators, are raised above the baseline, and end lower than a capital letter. this makes them perfect as operators, but shitty as enclosing character. ⟨chevrons⟩ do this right, but aren’t ASCII. and using a font that compensates for the inadequacies of input devices and resulting conventions makes me puke into my mouth ;) &gt; Rust uses [] for the index operator, also just like almost everything else hah! it uses &lt;&gt; as comparison operators, also &gt; together with = as match operator (while = is also assignment *and* comparison operator). then () as function call operator as well as grouping operator! a mess! call the language police. seriously: overloading happens all the time (except in APL). as long as nothing is ambiguous, that’s fine! and lastly generics *are* related to subscripting: you take a special type out of a generic list of types by using a key!
Having a different word for the same concept isn't really a good thing, especially for a new language that's trying to attract new developers.
https://github.com/rust-lang/rust/issues/18510
&gt; Why does it need a marker and why is that marker still feature-gated? Because drop mechanics are not safe currently and can cause all sorts of nastiness.
Yeah, that's true, I forgot about LTO.
That's why I mentioned LTO, which AFAIU removes provably dead code. So either the infrastructure for Rust's `main` + `println!` amounts (transitively) to 600K, or there's dead code that LLVM (or would that be `ld` in this case?) doesn't see as dead for some reason. From a simple `objdump` it seems like a good part of the 600K are from jemalloc.
Could you elaborate on this? Is it because `unsafe` blocks don't preserve invariants internally, so unwinding can cause destructor calls when the appropriate preconditions aren't fulfilled?
But monomorphic (if that's the right term for non-generic) destructors don't require the `#[unsafe_destructor]` attribute, correct? So what's different with generics if they're monomorphized under the hood?
I am not sure currently what the exact cases are where "unsafe destructor" is necessary. I do know for a fact that Drop can currently cause unsafe memory access and cause segfaults. There are multiple tickets open for it.
Edit: ah, probably a classic example of not really being able to trust the length of the iterator. Have to do pushes. ---- Just ran a benchmark and you're correct. But I can't see a fundamental reason. Is it just the standard "we're bad at optimizing iterators", or something else? test elem_000001 ... bench: 41 ns/iter (+/- 9) test elem_000010 ... bench: 47 ns/iter (+/- 11) test elem_000100 ... bench: 56 ns/iter (+/- 9) test elem_001000 ... bench: 200 ns/iter (+/- 19) test elem_010000 ... bench: 13624 ns/iter (+/- 6404) test elem_100000 ... bench: 124469 ns/iter (+/- 9769) test iter_000001 ... bench: 45 ns/iter (+/- 14) test iter_000010 ... bench: 51 ns/iter (+/- 4) test iter_000100 ... bench: 182 ns/iter (+/- 41) test iter_001000 ... bench: 1233 ns/iter (+/- 190) test iter_010000 ... bench: 22583 ns/iter (+/- 10047) test iter_100000 ... bench: 210314 ns/iter (+/- 26394) code: extern crate test; use test::Bencher; use std::iter::repeat; fn iter_n(b: &amp;mut Bencher, n: uint) { b.iter(||{ let v: Vec&lt;u32&gt; = repeat(7).take(n).collect(); v }); } fn elem_n(b: &amp;mut Bencher, n: uint) { b.iter(||{ let v: Vec&lt;u32&gt; = Vec::from_elem(n, 7); v }); } #[bench] fn iter_000001(b: &amp;mut Bencher) { iter_n(b, 1) } #[bench] fn iter_000010(b: &amp;mut Bencher) { iter_n(b, 10) } #[bench] fn iter_000100(b: &amp;mut Bencher) { iter_n(b, 100) } #[bench] fn iter_001000(b: &amp;mut Bencher) { iter_n(b, 1000) } #[bench] fn iter_010000(b: &amp;mut Bencher) { iter_n(b, 10000) } #[bench] fn iter_100000(b: &amp;mut Bencher) { iter_n(b, 100000) } #[bench] fn elem_000001(b: &amp;mut Bencher) { elem_n(b, 1) } #[bench] fn elem_000010(b: &amp;mut Bencher) { elem_n(b, 10) } #[bench] fn elem_000100(b: &amp;mut Bencher) { elem_n(b, 100) } #[bench] fn elem_001000(b: &amp;mut Bencher) { elem_n(b, 1000) } #[bench] fn elem_010000(b: &amp;mut Bencher) { elem_n(b, 10000) } #[bench] fn elem_100000(b: &amp;mut Bencher) { elem_n(b, 100000) } 
I use* it chromeless. But there's MiniServo and MiniServo-gtk coming up which give us a firefoxish chrome on osx and Linux respectively. *Yes, I actually use it. Mostly for googling things and as a Wikipedia browser. 
I plan on changing my rust-ws library to depend on hyper (it currently requires the deprecated rust-http).
 #[lang = "panic_fmt"] fn panic_fmt() -&gt; ! { loop {} } I don't have experience creating apps without stdlib, but this looks like a very, very bad idea to me. Why not `unsafe { core::intrinsics::abort(); }` instead?
The `from_elem` code is a very clean loop. Ideally, it would optimize to a `memset` but I don't think the `loop-idiom` pass works on it at the moment so it's not a cost-free abstraction itself but it's decent. The slice iterators are a cost-free abstraction relative to an `unsafe` loop but that doesn't apply to everything you can use them for. Some iterator adaptors like `map` and `filter` tend to be free but stuff like `skip`, `skip_while`, `take` and `take_while` is often more expensive than writing the code by hand. It's wrong to assume that all of these abstractions have no cost simply because some of them generally don't. The `collect` method is almost always worse than using `unsafe` code.
How does the interfacing between C and Rust work? What functions are exported and how would one include and call them in C? Is there a writeup about this somewhere? I've seen `c_int` pop up a few times in Rust wrappers of C libraries; how would C handle Rust's data types? 
So we'd like to eventually add some way to unsafely express that an iterator produces a *trustable* exact size. If we can statically branch on that (perhaps by negative trait bounds), and then use full on ptr::write and set_len in the trusted branch, do you expect there to be any cost over from_elem?
I don't know. I haven't compared that specific iterator chain to `from_elem` before.
&gt; "prettier, safer C" *barf*
You can make it happen! Servo is a library that you can use from any language, via the [CEF bindings](https://github.com/servo/servo/tree/master/ports/cef).
[qmlrs](https://github.com/cyndis/qmlrs) is Qt Quick bindings for rust!
- Couldn't agree more... I wrote an encoder later on and then realised that HashMap in Rust randomizes key, which screwed it up. I also agree that I should create a separate torrent module, I also had in mind to get that decoder working :P. However, I do loop HashMap first so it's not completely screwed up. - That sounds like a good idea, I also kinda like how you implemented yours. Appreciate the feedback!
10 push ups and 15 squats and you are good to go
My laptop is producing really inconsistent results right now, but the few trials I made were favourable. test elem_000001 ... bench: 42 ns/iter (+/- 28) test elem_000010 ... bench: 44 ns/iter (+/- 54) test elem_000100 ... bench: 54 ns/iter (+/- 9) test elem_001000 ... bench: 193 ns/iter (+/- 48) test elem_010000 ... bench: 14487 ns/iter (+/- 17706) test elem_100000 ... bench: 152159 ns/iter (+/- 46142) test iter_000001 ... bench: 42 ns/iter (+/- 14) test iter_000010 ... bench: 50 ns/iter (+/- 16) test iter_000100 ... bench: 169 ns/iter (+/- 30) test iter_001000 ... bench: 1255 ns/iter (+/- 274) test iter_010000 ... bench: 23248 ns/iter (+/- 3890) test iter_100000 ... bench: 214065 ns/iter (+/- 23545) test unsafe_000001 ... bench: 47 ns/iter (+/- 21) test unsafe_000010 ... bench: 49 ns/iter (+/- 6) test unsafe_000100 ... bench: 62 ns/iter (+/- 10) test unsafe_001000 ... bench: 200 ns/iter (+/- 43) test unsafe_010000 ... bench: 12971 ns/iter (+/- 4054) test unsafe_100000 ... bench: 121820 ns/iter (+/- 15725) extern crate test; use test::Bencher; use std::iter::repeat; use std::ptr; pub trait UnsafeVec&lt;A&gt; { fn from_unsafe&lt;I: Iterator&lt;A&gt;&gt;(I) -&gt; Self; } impl&lt;A&gt; UnsafeVec&lt;A&gt; for Vec&lt;A&gt; { fn from_unsafe&lt;I: Iterator&lt;A&gt;&gt;(mut iter: I) -&gt; Vec&lt;A&gt; { let len = iter.size_hint().0; let mut v = Vec::with_capacity(len); let mut ptr = v.as_mut_ptr(); unsafe { for elem in iter { ptr::write(ptr, elem); ptr = ptr.offset(1); } v.set_len(len); } v } } fn iter_n(b: &amp;mut Bencher, n: uint) { b.iter(||{ let v: Vec&lt;u32&gt; = repeat(7).take(n).collect(); v }); } fn elem_n(b: &amp;mut Bencher, n: uint) { b.iter(||{ let v: Vec&lt;u32&gt; = Vec::from_elem(n, 7); v }); } fn unsafe_n(b: &amp;mut Bencher, n: uint) { b.iter(||{ let v: Vec&lt;u32&gt; = UnsafeVec::from_unsafe(repeat(7).take(n)); v }); } #[bench] fn iter_000001(b: &amp;mut Bencher) { iter_n(b, 1) } #[bench] fn iter_000010(b: &amp;mut Bencher) { iter_n(b, 10) } #[bench] fn iter_000100(b: &amp;mut Bencher) { iter_n(b, 100) } #[bench] fn iter_001000(b: &amp;mut Bencher) { iter_n(b, 1000) } #[bench] fn iter_010000(b: &amp;mut Bencher) { iter_n(b, 10000) } #[bench] fn iter_100000(b: &amp;mut Bencher) { iter_n(b, 100000) } #[bench] fn elem_000001(b: &amp;mut Bencher) { elem_n(b, 1) } #[bench] fn elem_000010(b: &amp;mut Bencher) { elem_n(b, 10) } #[bench] fn elem_000100(b: &amp;mut Bencher) { elem_n(b, 100) } #[bench] fn elem_001000(b: &amp;mut Bencher) { elem_n(b, 1000) } #[bench] fn elem_010000(b: &amp;mut Bencher) { elem_n(b, 10000) } #[bench] fn elem_100000(b: &amp;mut Bencher) { elem_n(b, 100000) } #[bench] fn unsafe_000001(b: &amp;mut Bencher) { unsafe_n(b, 1) } #[bench] fn unsafe_000010(b: &amp;mut Bencher) { unsafe_n(b, 10) } #[bench] fn unsafe_000100(b: &amp;mut Bencher) { unsafe_n(b, 100) } #[bench] fn unsafe_001000(b: &amp;mut Bencher) { unsafe_n(b, 1000) } #[bench] fn unsafe_010000(b: &amp;mut Bencher) { unsafe_n(b, 10000) } #[bench] fn unsafe_100000(b: &amp;mut Bencher) { unsafe_n(b, 100000) }
I know, Rust is included in "any language" isn't it :)
What's that supposed to mean? If Rust is to be a suitable substitute for C then it makes sense to invite comparisons between them.
&gt; then there’s bazillion styles of where to put the braces You mean two, not counting the amount of whitespace before/after? Same-line vs next-line. Same line with whitespace before is the official Rust style: struct MyStruct { // ... } fn my_function() { // ... } Rust's syntax is pretty well cemented at this point and most people have zero complaints, so any major changes would be unnecessary churn. If you want a systems language that looks like Python, I might recommend [Nim (formerly Nimrod)][1]. Alternately, you could fork `rustc` and change its syntax to look exactly the way you want. You seem knowledgeable enough. [1]: http://nim-lang.org/
That comparing it to C is less viscerally appealing than comparing it to an ML (say). Prettier than C? Hardly a feat. Safer than C... it's actually harder to make it *less* safe (making it roughly as safe seems simple though). EDIT: Oh, sorry to have offended some C zealots that think that C is the penultimate simple, low-level language.
Actually, there's same line, next line unindented and next line indented (with the closing brace also indented) and *yes*, I've seen people who use that last one. Also, there's the question of whether to indent the contents of the braces or not in the last one.
I think the biggest source of unsafety was GC cycles, which are no longer an issue. But I'm pretty sure there is still other stuff that is unsafe and I just can't remember what it is right now.
just read the ffi guide: http://doc.rust-lang.org/guide-ffi.html
I'm sure the name will be back in a third party library.
Basic Rust abstractions like `Box`, `Mutex` and `Rc` also all require `#[unsafe_destructor]`. It's kind of silly in its current state.
I think you're right regarding syntax, a Haskell-like syntax would be better in some sense (namely, shorter and clearer code). I'm specially averted to the angle bracket syntax. But the language wants to attract C++ programmers. So it may be right to not appeal the Haskell crowd when following C++ conventions is an option.
You shouldn't have to apologize for writing an article asking why you should adopt a new language. Even if you could have displayed more tact, it's nowhere near as bad as a lot of tech blogs and you certainly didn't deserve to receive as much negative attention as you did. The onus should be on the language to prove its worth to you. You seem like a nice guy.
What if that function is noreturn?
Thanks ;) nice nickname, btw!
Polling is implemented now :)
It only makes sense using a different nomenclature if it is a different thing. We've already seen rockets crashing because people don't agree on how to call units of measurement…
Yes, but you can hit 'stop' and it will hit the brakes in the infinite loop.
I really wish non ascii identifiers were a syntax error. Having to deal with i18n in addition to programming is a very frustrating thing. I had to deal with french source code as a non french person and I found the experience more than frustrating. Crate names need to be without dots. If you want to use a different filename then you need to instruct Rust to pick a different crate name. By default it's fetched from the filename.
As far as I know, `task` was meant to be a generic interface for all the different concurrency runtimes that would then map it to their respective primitives. This is not the case anymore, so renaming it from `Task` frees up the vocabulary.
but do we need CEF if we have rust UI code? i gather that with qmlrs, we could create a `Servo` Qt Quick component [like this](https://qt-project.org/doc/qt-5-snapshot/qtquick-scenegraph-openglunderqml-example.html) and simply write the GUI as QML. but maybe the key mapping and all this are only handled by CEF already and using that makes it easier :)
* same line * next line * same line only for one-statement clauses / only for … * next line indented: fn foo() { bar() } * next line half-indented: fn foo() { bar() } * lisp-style: fn foo() { bar() } * … sure, only your two styles are widely used :)
If you set the crate name with `#![crate_name = "hello"]` the resulting executable is named hello and your filename does not matter.
That works both way. I always have to deal with English source code as a non-English person and it is constantly frustrating.
My point is that the debugger won't tell the difference between some random loop and this infinite one. And what about an unsuspecting user? That reminds me of unfun times on Windows...
Absolutely agree to this one. I am non-english but programmers should stick to english and to standard ASCII as much as possible. Typically a programmer nowadays is somewhat capable of basic english, so please try to stick to english comments as well. I find it only acceptable if someone cannot write english and only then in comments. 
You have your point of view on project management, which you are free to apply to your project. Other people's projects are different matters. You proposed making non-ASCII identifiers syntax error. If you think that will discourage non-English source code, you are being delusional. What you are causing is German source code written with ae instead of ä. If you think non-English source code should be discouraged, fine, but making non-ASCII identifiers syntax error does not achieve that.
&gt; I find it little disconcerting that a "modern" language has such an arcane restriction about Unicode filenames. It's not the filename that's the issue, it's that crate names are identifiers, and by default: http://doc.rust-lang.org/reference.html#identifiers &gt; The ident production is any nonempty Unicode string of the following form: &gt; &gt; * The first character has property XID_start &gt; * The remaining characters have property XID_continue &gt; &gt; that does not occur in the set of keywords. &gt; &gt;&gt; Note: XID_start and XID_continue as character properties cover the character ranges used to form the more familiar C and Java language-family identifiers. If you check out http://doc.rust-lang.org/reference.html#compiler-features, you'll find &gt; non_ascii_idents - The compiler supports the use of non-ascii identifiers, but the implementation is a little rough around the edges, so this can be seen as an experimental feature for now until the specification of identifiers is fully fleshed out. If you were to open a random file with a unicode name, Rust should have no problem with it.
&gt; You proposed making non-ASCII identifiers syntax error. If you think that will discourage non-English source code, you are being delusional. No, but it's better than having to use another keyboard layout because the original source code uses umlauts or is written in cyrillic.
I'm up at 7:30am on a saturday, but that section seems to be referring to segmented stacks, which Rust has not had for a while. I opened https://github.com/rust-lang/rust/issues/20071 to track this. Thanks!
&gt; I'm up at 7:30am on a saturday So you have children, too? ;)
This one? https://github.com/pcwalton/miniservo-mac
Dear God I hope not. ;) Just a little bit of insomnia. I actually have a Netrunner tournament at 10:30, so I was going to wake up at 9 anyway, so it's not that big a deal...
The "newtype" idiom is exactly for that. #[deriving(Copy, PartialOrd, Ord, PartialEq, Eq, Show)] pub struct Meters(pub int); impl Neg&lt;Meters&gt; for Meters { fn neg(&amp;self) -&gt; Meters { Meters(-self.0) } } impl Add&lt;Meters, Meters&gt; for Meters { fn add(self, rhs: Meters) -&gt; Meters { Meters(self.0 + rhs.0) } } impl Sub&lt;Meters, Meters&gt; for Meters { fn sub(self, rhs: Meters) -&gt; Meters { Meters(self.0 - rhs.0) } } impl Mul&lt;int, Meters&gt; for Meters { fn mul(self, rhs: int) -&gt; Meters { Meters(self.0 * rhs) } } impl Mul&lt;Meters, Meters&gt; for int { fn mul(self, rhs: Meters) -&gt; Meters { Meters(self * rhs.0) } } impl Div&lt;int, Meters&gt; for Meters { fn div(self, rhs: int) -&gt; Meters { Meters(self.0 / rhs) } } // same for Feet This is pretty much equivalent to the bare `int` type, but `Meters(2) + Feet(3)` wouldn't work.
It can still have side effects depending on global state. Rust would be using a `panic!` here so it would have side effects depending on *both* global state and parameters.
+1, this is a job for phantom types `Length&lt;Unit, Numeric&gt;` is much more flexible. You can introduce units on the fly without writing any more code than `struct MyUnit` and then `Length&lt;MyUnit, i32&gt;` will just magically work because it doesn't actually matter what the unit is, just that it is not a `YourUnit`. With sufficiently well-designed numeric traits, one could also introduce new number types to. Then `Length&lt;Cm, MyBigInt&gt;` also magically works. Yay composition!
I think `alias` would be a better name than `type`. (Note that using `int` in your case is probably not what you want, a fixed size integer would be a better choice.)
&gt; I'm a non English person So what? You obviously know English to such a degree that being a native speaker or not does not really make a difference to you; you are able to communicate just as well as a native speaker in contexts such as this. I see this argument all the time on topics like this: non-native speakers bring up the fact that they are non-native speakers, presumably as an argument that they are not biased in the matter. Well you are; if you are able to communicate so well that you even have to mention that you are *not* a native speaker, you benefit just as much as a native speaker from everyone being forced to write code and comments in English (or just force them to write their code in their own language in ASCII: see sibling comment). Well I guess the fact that you're a non-native speaker suggests that your opinion isn't about suppressing other cultures in favour of American/British/etc. cultures, at least. Well many programmers seem to want to believe in a world where we all speak the same language, since it's more *practical*... but that might be another topic. &gt; It sounds absolutely forced and it's a nightmare from a project management point of view to have to deal with a non English source code. What's the problem with just enforcing things by convention? Not every single piece of code will ever reach its way into any kind of commercial, or internationally distributed context. I've helped assist on a beginner programming course in Java, and though we could write stuff in our own native language, encoding problems between OSs was a nuisance. I've also help taught young kids (12 or younger, I guess) learn programming, in their own language of course. Now, why should these people have to bother about using English, if they're more comfortable writing it in their own language? Are you afraid that some kid's flappy bird copycat implementation is going to find itself into some international open source code base, or a corporate one? Or some introductory student's pretend "salary processing application"? Demanding ASCII-only identifiers, when we already have Unicode identifiers, is just insisting on erecting an unnecessary boundary. If little kids are able to get into programming in their own language (if they prefer that, or because they didn't know English coming out of the womb), and there are resources for them to do that, I think that's great. Even if some adult from a non-English speaking country is able to learn some programming without having to start learning English *first*, I think that's great, too. Demanding ASCII-only identifiers, or whatever else to enforce that code is only written in English, can be enforced within each individual organization and code base. A pull request which contains comments in Portuguese? Reject it, if you want: we have the technology. Language is a cultural and to some people a personal topic, not strictly a technical one. So it can not be "solved" on a purely technical level. Consider that we, as a culture (the English-speaking programming culture, at least), can't even agree on simple stylistic issues like how to indent code (spaces? tabs? 2, 4, 8? are you fucking serious?), how to lay it out, etc.. So many languages simply leave it flexible, because even if there are some "correct" choices, they might not work in all circumstances. But for natural languages, we are confident enough to demand and put down a law that says that ASCII is all everyone will or should ever need? Amazing.
&gt; So what? You obviously know English to such a degree that being a native speaker or not does not really make a difference to you; you are able to communicate just as well as a native speaker in contexts such as this. So not to go into too much here, but learning English is not even a competitive advantage at this point, it's a *requirement*. This has been understood by pretty much everyone in the west at this point and schools are teaching it at a very early age. In fact, most countries in Europe teach English a few years before the first programming courses start. Many countries have English in kindergarden at this point. &gt; What's the problem with just enforcing things by convention? Not every single piece of code will ever reach its way into any kind of commercial, or internationally distributed context. I've helped assist on a beginner programming course in Java, and though we could write stuff in our own native language, encoding problems between OSs was a nuisance. I've also help taught young kids (12 or younger, I guess) learn programming, in their own language of course. Rust is not a language for kids. Try to make a kid program in Russian identifiers in Rust and then read the English borrow checker's error messages … There are already programming languages for kids, we do not need to go to that level. If you are going to argue that some people do not need to learn English, then you're very wrong. In fact, teaching some people that English is not needed will be terrible advise because you are directly suggesting a terrible career move. &gt; Demanding ASCII-only identifiers, or whatever else to enforce that code is only written in English, can be enforced within each individual organization and code base. I had to interface with a Spanish API provided by a publisher from a different continent. I am very glad that everything was ASCII identifiers because otherwise it would have been even more ridiculous than the whole process already was. Also say as much as you want. &gt; Consider that we, as a culture (the English-speaking programming culture, at least), can't even agree on simple stylistic issues like how to indent code (spaces? tabs? 2, 4, 8? are you fucking serious?). That's why languages should have prevented these ridiculous bikesheds a long time ago and enforce a standard. Go does that, people live with it, everybody moves on to more important problems. &gt; But for natural languages, we are confident enough to demand and put down a law that says that ASCII is all everyone will or should ever need? Amazing. ASCII for programming code is all we will ever need. There were times when people wrote APL and that has universally been accepted as a terrible and stupid idea. Rust even went to a stricter subset than ASCII symbols because "~" was hard to reach on some keyboard layouts. Not everything that is possible is a good idea.
Nice, great job!
&gt; So not to go into too much here, but learning English is not even a competitive advantage at this point, it's a requirement. This has been understood by pretty much everyone in the west at this point and schools are teaching it at a very early age. In fact, most countries in Europe teach English a few years before the first programming courses start. Many countries have English in kindergarden at this point. I'm not really confident in Europe's, as a whole, English proficiency. I think it is overstated. I think The World's English proficiency is overstated, too. But many people who travel to other countries will of course go to places where there are more people who speak English, because the places are somewhat touristy. And people that outgoing with foreigners are probably also more likely to speak English, because why else would they bother? Maybe they're really good at gesturing? I don't know. I once met a Japanese guy in a, let's say a relatively non-English speaking country. He didn't speak English, nor did he speak the local language. Are you serious? Well apparently that's possible. This is just a mildly funny anecdote. &gt; Rust is not a language for kids. Try to make a kid program in Russian identifiers in Rust and then read the English borrow checker's error messages … There are already programming languages for kids, we do not need to go to that level. But it's a language for adults who need to be hand-held into doing 'the right thing'? Actually, let me hand you a freebie on this point: another argument is that other languages might be more suited for certain domains. If I'm implementing an application or library that has to do with some language or some domain in a specific area of the world, then it might make sense to use whatever language is under question. But, this argument might be less relevant for Rust, since it might be biased towards more systems/low-level applications. And in those domains, the domain is dominated and expressed through English terms and concepts, anyway. &gt; If you are going to argue that some people do not need to learn English, then you're very wrong. In fact, teaching some people that English is not needed will be terrible advise because you are directly suggesting a terrible career move. Oh, because that's what I said? Here are two separate things; getting a career in programming, and learning programming. If people just want to get their feet with programming and computer science, and they have the necessary material and resources, I think they should be able to learn it in their own language. As far as getting a career in programming, and going deep into specific subjects? English is absolutely a plus, and it might even be a necessity. I'm not here to *discourage* anyone from learning English, for Christ's sake. &gt; I had to interface with a Spanish API provided by a publisher from a different continent. I am very glad that everything was ASCII identifiers because otherwise it would have been even more ridiculous than the whole process already was. Cool, so they had the good sense to foresee that their API would or could be used by non-Spanish speakers. I have no protests, here. &gt; Also say as much as you want. What? OK, I will... &gt; That's why languages should have prevented these ridiculous bikesheds a long time ago and enforce a standard. Go does that, people live with it, everybody moves on to more important problems. Yes, I kind of set my self up with that one. &gt; ASCII for programming code is all we will ever need. There were times when people wrote APL and that has universally been accepted as a terrible and stupid idea. Rust even went to a stricter subset than ASCII symbols because "~" was hard to reach on some keyboard layouts. Not everything that is possible is a good idea. I dunno. I've seen a few people who seem to like APL more than J or whatever that other language is called, namely because they find J's syntax to be somewhat unsightly. Pervasive use of Unicode was important for the people who made Agda, apparently. As far as being able to use "weird" operators and such, I might personally be more on the side of ASCII operators, with perhaps some rendering magic to prettify it: Unicode operators can get quite small and unreadable with mono spaced fonts. 
Create names need to be ASCII only. You can provide a crate name explicitly.
It would be nice to have something generate the C headers as well, rather than having to write them by hand.
One caveat there is that the programmer may not have as much control over which type is chosen as the intermediate representation. (Or at least, it would be much more "implicit" based on order of operations, and harder to infer just from looking at the code.) That is to say, if you add Feet + (Feet + Meters), after the parenthesis operator are you going to get two operations, Feet + Feet, or Feet + Meters? While this may make no difference for reals, for integers it may change the truncation behaviour for intermediate values.
Because I have spent a a big chunk of my last five years travelling to different countries and giving talks and presentations to programmers. Feedback from almost everywhere (ignoring Japan) has been that English is the language of choice for internal development as far as source is concerned. Using any other language than English for internal sourcecode has been universally mentioned as being a problem.
Sounds solid.
&gt; How could I get more neutral than simply asking "how do you know?" ? Well you had an aggressive sub-tone in this whole thread. Maybe somebody got just annoyed. Just take a breath it's christmas. &gt; The goal was to express anger. Angry comments tend to come off as rude. Or have I been failing to express myself for all these years? I should have written excessively rude.
Not exactly. Just as /u/steveklabnik1 mentioned, crate names are identifiers and identifiers can be Unicode strings as he mentioned. For example, the following code compiles fine: #![feature(non_ascii_idents)] #![crate_name = "ನಮ"] fn main() { } where the crate name is `ನಮ` (=U+0CA8 U+0CAE). It is when I include the character `್` (=U+0CCD), as in `ನಮ್ಮ`, the compilation fails, even though that codepoint has XID_continue property.
Where does one obtain such a majestic shirt?
I believe that this was a limited tee-spring run that some of our community members set up.
Lucky you! Mine will ship in early January.
Nobody works on that to my knowledge. Zinc, is cool, but very close to the arduino IDE, which can be a good thing, but isn't appropriate for alll application. /u/saosebastiao, if you are interested in this, I am too, we could look at it ;) It may be a good time because Rust has had far too few testcase in embedded systems and thus may lack some feature, working on them before 1.0 would be very useful :)
Damn, so there are none left?
There's an example [here](http://rustbyexample.com/generics/phantom/units.html) about units in phantom types.
I made a library in C++ to do this, but I couldn't port it to rust because it relied on integer template parameters. I don't know how to do it in rust Linky https://github.com/MarkJr94/units
Here's the campaign: http://teespring.com/rustacean. Not sure if there will be additional runs.
Unfortunately Rust does not have generics over values yet.
Once 18 more are ordered on teespring, another print run happens.
backed. Those shirts are kinda fun :P
I think they removed them some time ago, at least in Libre Office.
Neat! I like that it's similar to the already-existing [`Vec::from_fn`](http://doc.rust-lang.org/collections/vec/struct.Vec.html#method.from_fn), which does basically the same thing. I'd really love to see a syntax extension like `from_fn![|i| i as uint, ..100]`.
This is memory-unsafe for structs that need destructors: If the user-supplied function panics, the array is not completely initialized, but all array members are dropped!
Here's one way to do it. It's a very, very similar approach, in terms of semantics, and basically identical representation. trait Elem { fn eval(&amp;mut self); } let arr: Vec&lt;Box&lt;Elem&gt;&gt; = vec![box SomeType::new(), box OtherType::new()]; for e in elem.iter_mut() { e.eval() } Trait objects are a pair, `(*vtbl, *data)` (that is, exactly equivalent to your `elem` struct). 
Bah. I thought I handled the destructor problem with mem::write, but that's a good point. Any ideas how that could be handled properly?
Wrap the array in a newtype that handles the destruction properly (at least until all members are initialized). Your macro can generate that newtype.
That was simpler than I thought it would be. Thank you very much, I will try this out.
[*cough*wrongsubreddit*cough*](https://www.reddit.com/r/playrust) But in all seriousness and out of curiosity: did you not see the "RUST PROGRAMMING LANGUAGE" header, or how there's absolutely nothing in the subreddit style, content, or any of the other posts that suggests a connection to the game? I am *genuinely* curious as to how people keep making this mistake. **Edit**: I'm not being facetious or sarcastic; I genuinely *do not understand* how this keeps happening. That it *does* keep happening would indicate there's a *reason*, which I what I'd like to know.
I apologise if I came across like that. I meant it when I said I'm interested in how this keep happening. From my experience with Reddit, I don't understand how you make this mistake, but people *do* keep making it, so there must be something behind it.
Can I actually create that type in the macro, when it's not executed at the top level? It doesn't seem to work: http://is.gd/wmIdez
Unfortunately this isn't quite possible until we have something along the lines of [RFC 197](https://github.com/rust-lang/rfcs/pull/197), since the fields of structs have their normal drop glue called, no matter what you do. (Although not stated there, initialising fixed-length arrays was one of the motivations for that RFC.)
Did they remove the H.P. Lovecraft quotes?
Converting C++ source to Rust would probably yield rather gruesome code, as C++'s class inheritance doesn't map well to Rust's trait inheritance, and Rust made the correct decision not to have inheritance of data types. I could see bits of Rust source converted to C++ with many abstract base classes and `std::move` calls, but I don't know of any tool that does this. 
"Writing to the array twice" is interpreting the Rust code a bit too literally. What does it do in the compiled (optimized) version?
&gt;&gt; Converting C++ source to Rust would probably yield rather gruesome code certainly attempting to map every last concept from C++ is going to be completely Gruesome as you put it - however some subset might go across more easily; not all C++ code uses every feature. (for example in performance oriented gamedev vtables are avoided) and I agree, transpiling rust to c++ sounds more feasible. but imagine if you could go through c++ code and.. - identify if-ladders/switch that could be expressed more elegantly as enum/match, - maybe even identify potentially null pointers (trace back ones that are checked) and turn them into options. - maybe figure out trait bounds for templates by 'reverse duck typing' ("these functions were used, so this T must have been of this trait") - rolling internal vtables where they were used, as function-pointer-tables? - decompse #ifdefs into #[...] expressions, find any macros that can map onto rust macros - report where the original C++ source can't be translated - maybe even overloading can be done now because of multi parameter traits - or an assist tool to identify &amp; rename overloads And of course imagine a straight *C* to rust (purely unsafe, raw pointers) translator
&gt; I think alias would be a better name than type. RFC time!
The [Clang bindings](https://github.com/crabtw/rust-bindgen/) make the parsing of C++ pretty straightforward.
&gt; Am I overcomplicating things or? [std::io::BufferedReader](http://doc.rust-lang.org/std/io/struct.BufferedReader.html) is a wrapper, it takes a `Reader` as parameter and implements buffering outside the wrapped Reader. If you want a Reader or a Buffer from a `Vec&lt;u8&gt;`, either use a `MemReader` as Florob0x2a notes, or slice it. Both `&amp;[u8]` and `MemReader` implement Reader and Buffer, so they're buffered readers OOTB. The `MemReader` approach will remove access to the vec (its ownership is transferred to the reader, though you can get it back out), not so for the slice.
Ah, thanks. Exactly what I was looking for.
I'm not sure how much this would be of any practical help. It would not be any better than C++ with static analysis. Improving the existing rust-bindgen seems much more desirable.
perhaps some templated or inlined code in interfaces could be translated. templates are one of the big hurdles for c++ interoperability. It's certainly it's not low hanging fruit, but there are billions of lines of c++ and millions of c++ programmers C++ programs sometimes have a lot of trivial inlineable acessor functions in the class declarations. this kind of code could easily hide its own unsafe blocks .. thats often the intent. Often it is pure anyway
Interesting finding that copying the `Writer`-imp for `Vec` helped…
I was wondering if there is any particular reason for the focus on JSON. I know that it is widely available, however a text format is unlikely to ever yield faster (de)serialization than a binary format.
Woo, I always feel special when I get mentioned on someone's blog :D. I'm happy to help, hopefully the PRs land soon. 
Yeah I agree that if performance is the concern it's probably premature optimisation, however it would be nice to be able to do the "real" initialization only because if you take OP's code and decide that you need to grow the array you might end up with: let mut my_array = [0u, ..200]; for i in range(0, 100) { my_array[i] = i as uint; } And then your code is probably not what you want. Of course in that case it's a good argument for the use of iterators over literal ranges but it would be nice to get an error there. I guess one solution would be to make the unitilialized value checker a bit more clever and make it understand that you can fully initialize an array if you initialize all its elements, but it might be complicated to implement.
Wow, I can't believe that just some enum work will really be able to speed serde up by three or four times!
Original comments: https://www.reddit.com/r/cpp/comments/2pytzr/armv7_vs_x8664_pathfinding_benchmark_of_c_d_go/
yeah what's going on here; does this indicate a bug/inefficacy in rustc; does this happen in user land or is it a nuance with stdlib; is this anything to do with LLVM LTO? Nice work erickt &amp; aatch!
I guess serialization has multiple use-cases. I think primary use case for serialization is in web API's thus the focus on JSON.
So... it's like Haxe, but with Python syntax and focused on speed?
I could have been a bit more clear. That enum benchmark at the end was a different benchmark from the serde one. It is a test measuring an adaptor type that converts a reader into a buffered iterator. I wanted to see if I could get a deserializer using a reader that was as fast as one using an iterator and I couldn't because of this issue. In serde the improvement is much more modest, it adds around 20MB/s. Which is nice, but it's still slower than rapidjson. 
I started with json because it is an important library and I found a [real world benchmark](https://github.com/cloudflare/goser) to stress test my framework. My plan is once I firm up an approach, the same techniques should apply to other formats. Earlier in the series I talk about some of the other formats we have in our [ecosystem](http://erickt.github.io/blog/2014/11/13/benchmarks-2/) if you want to see some comparisons.
Shucks, the one thing I didn't try is to see if link time optimization helped. I wonder if that would be enough to get llvm to optimize the code...
Its like using the proposed standards tracked "typed python annotations" to create an AST that compiles to a statically typed language. It started with Go but has gradually started to encompass Rust and very very recently C++.
 int main() { auto a = new A(100, 200,_kwargs_type_{z:9999,__use__z:true}); std::cout &lt;&lt; a-&gt;x &lt;&lt; std::endl; std::cout &lt;&lt; a-&gt;y &lt;&lt; std::endl; std::cout &lt;&lt; a-&gt;z &lt;&lt; std::endl; auto b = a-&gt;mymethod(3); std::cout &lt;&lt; b &lt;&lt; std::endl; auto c = call_method([&amp;](int W){ return a-&gt;mymethod(W); }, 4); std::cout &lt;&lt; c &lt;&lt; std::endl; return 0; } The C++11 version leaks the `A` object that's allocated on the first line of `main`. Also, in several places you create a complete local copy of the `A` object on the stack, like here: int A::mymethod(int m) { A self = *this; return (self.x * m); } Why? 
yeah, thats right. I copied the title mostly as-is, and didn't change that. Seems like I can't change it anymore, so it will stay that way.
Finally a rust with sane syntax :). I hope this achieves lift off. But I really think that languages like rust should have a custom syntax. As long as it is the same AST, it should not matter how is it written. You should also be able to add more type inference if you want. I hope that this implementation gets all the features of rust, such as macros and better type inference so it still feels a bit like python.
Not the author of the lib but feel free to post the issue fork and fix if/when you can. The C++ extension is like too new for public consumption and will probably be forked into its own project given this projects history of progression from python -&gt; js -&gt; go -&gt; rust &amp; c++
So many good news in a single post! Awesome!
Also, any non-scientific use case will use IEEE754 floating point math behind the scenes, where operations aren't commutative, which I think is a good reason to avoid implicit conversion.
Yeah! Thanks for working on fixing all of this. You are the hero in this story. 
I don't see how it should be generally possible to turn C++ code into a more constrained Rust without using a *lot* of unsafe code. The other direction seems more viable. This isn't really compilation problem. It's more of a design problem. Rust enforces safer designs. I don't see a “transpiler” automatically redesigning stuff.
Maybe you should check out the Nim (formerly Nimrod) language, which is a statically typed language with macros and a syntax that resembles Python. It's really an impressive piece of work. nim-lang.org I prefer Rust's algebraic data types and pattern matching, but Nim has overloading, which IMO is a big plus. It's good to see some different systems programming languages appear. Rust, Nim, and D (and even C++11/14) are showing that there's a lot of life in this ignored space of PL design. Nim compiles to C (and others) so maybe a Rust backend for Nim could be done when both languages stabilize. 
Problem with Nim is that there is almost no momentum behind it. Programming language is no good with no community to create code and debug. Unfortunately everyone is in love with curly braces which is totally bizarre to me. Nim is cool but I am not jumping on it until a bandwagon forms.
I think it's broken.
The thing is, parsing really should be separate from type checking. And syntax should be skinable. But I am afraid that curly braces of doom have too many acolytes these days.
could whole program analysis infer lifetimes obviously a lot of C++ code out there will be unsafe.. but the 'modern C++' style is basically safe, and some unsafe code will be encapsulated (e.g. private - in the past i've been told to consider unsafe basically working at the module level, because functions in the same module can change data used by unsafe code* ( *... maybe rust now has unsafe fields, that was a suggested workaround)) what about things like maths code in c++ which might be basically pure functions. what about embedded software that avoids allocations and there's also reasons to use Rust besides safety .. e.g. sane macro system
Because closures are more complicated than functions: it's basically a regular function pointer + the closure environment. So for instance: fn square(p: int) -&gt; int { p * p } fn main() { let f = square; let c = |p: int| -&gt; int { p * p }; println!("{} {}", std::mem::size_of_val(&amp;f), std::mem::size_of_val(&amp;c)); } Prints "8 16" on my system. Treating all function pointers like closures would have a performance cost. So basically function pointers are regular C-style function pointers while closure are fat pointers carrying the environment (even if in this case he environment is empty). I'm not sure I understand your 2nd point but I think your problem is that one cannot write the type of a closure in rust at the moment. The compiler knows it but the programmer does not, basically. It's part of the problem that makes returning closure by value impossible at the moment, if I understood correctly. However when you directly affect a closure to a variable the compiler can infer the type for you and it works around the problem.
Ah, I obiously read the post too early this morning :/
No; you can think of the type `()` as the 'type of no computation', or the 'halt' type. It returns a null-operation, and signifies that computation there has stopped. This is exactly what has happened to your program, once `main` has exited. In a type-theoretic sense, it seems really weird that the type that programs *finish* with is a type that could possibly continue computation (and that is what a `Result` type is - two possible branches in the computation). It makes the most sense to stop once a type has been reached in which it is impossible to continue working. There is nothing to do on the empty type, so we must be done. On a more practical note, it only makes some sense to return integer types as exit codes from `main`, as the operating system handles these by convention. Returning a `Result`, however that's laid out in memory, is generally unintelligible. (This is by convention, of course - someone could write an operating system that accepts an exit status of `Result&lt;S, T&gt;`, but this hasn't happened yet).
There are also lifetime concerns. A function always has a 'static lifetime, so you don't really need to concern yourself with lifetimes when passing functions around. However, a closure's environment does have a lifetime. If you tried to call a closure after it's environment had gone out of scope, that would be unsafe. So Rust needs you to use explicit lifetimes any time you store a closure that wasn't declared in the same scope. If you use the same type for both, then the type system can't validate that you're not using a closure in an unsafe way. Unless it applies the lifetime restrictions to functions as well. That said, using unboxed closures you actually CAN use the same type for both. I haven't yet tried storing an unboxed closure, so I'm not sure how it handles the lifetime problem, but I'd guess you have to use explicit lifetimes at all times. The syntax for that is: fn takes_an_unboxed_closure&lt;F&gt;(func: F) where F: Fn(int) -&gt; int;
If it all compiles to one identical AST, I don't see how will there be any difference in quality at all. I am talking about multiple syntaxes that all generate single AST output. Every syntax just need to implement all features of the language, that's all. Nermerle has both C++ like syntax and Pythonic one and there is no difference in result at all. Of course, expecting something like this to be done in Rust is a pipe dream but still...
Yup. And to translate the "apply" function mentioned above, you could just write: fn apply&lt;F: Fn(int) -&gt; int&gt;(f: F, x: int) -&gt; int { f(x) } And then both of the following would work: fn identity(x: int) -&gt; int { x } fn main() { apply(identity, 5i); apply(|x: int| x, 5i); } 
&gt; In a type-theoretic sense, it seems really weird that the type that programs finish with is a type that could possibly continue computation (and that is what a Result type is - two possible branches in the computation). I'd say conceptually, you need to think of the entire O.S. as one "program" for this to make sense. The branch is between "parent process receives success" and "parent process receives failure".
Ah, `Fn` does the trick with generics. Thanks everyone for their insight!
I didn't take a closer look at your code, but there's something else I wanted to point out. &gt; I am using 0.12.0 version of Rust compiler. You should not do that. Version 1.0 will come out soon-ish(first quarter 2015 probably), but until then you should use the _nightly_ builds. There are a lot of changes and additions from 0.12 to the current nightlies, so 0.12 is very outdated at this point. No worries though, your code should easily work with a recent version of rust :)
So, your rust process gets launched and then returns what? Some chunk of memory? What would that mean? How would that work? I'm not sure I agree about returning `()` rather than `int`, but `Result&lt;T,U&gt;` simply makes no sense. Maybe you could explain what you were thinking more than "Just wondering". What would it do and more importantly, why? What would spawn return? Spawn returns quickly...
Thanks for your answer. I am going to update my rust compiler.
Oh! Sorry I am going to fix the miss count. Also, I like your `for (idx, letter)`. So much better. About utf-8 I really did not know that. I am going to read more info so I can get it working with utf-8. Thank you for your kind answer!
Just nitpicking the code, since that's what I do best. * I don't think you need all the "_u64" suffixes [here](https://github.com/Jurily/rust-allocator/blob/80c5a45e4f2d66efb8fd8959a937c44a66b45997/src/allocator.rs#L58-L115). The compiler should be able to infer them based on the type of the array, or if not (since I haven't actually tested it and don't really know what I'm talking about) then it should only be necessary on the first item, and the rest will be inferred. * [That](https://github.com/Jurily/rust-allocator/blob/80c5a45e4f2d66efb8fd8959a937c44a66b45997/src/allocator.rs#L47)'s an interesting way of declaring a function inline. Are you sure you don't want to follow the normal way by moving it to the line above the function and removing the `!`? Some of the Rustaceans that aren't as smart as us might get confused. * Naturally there's no documentation and not a lot of comments to explain to the rest of us what's going on. That said, it looks like a pretty cool project. I guess. Maybe somebody will like it.
Note that there is an ongoing transition from boxed closures to unboxed closures. There will be `FnMut` and `FnOnce` as well.
&gt; The C++11 version leaks the A object that's allocated on the first line of main. &gt; Not necessarily. When the process terminates all allocated memory and file descriptors get freed/closed by the OS anyway. So freeing a isn't really necessary unless you do something nontrivial in its destructor. 
&gt; Yeah that's the basic problem with new languages. Everybody waits for everyone else to jump on the bandwagon. &gt; I hope we get the Rust bandwagon rolling in time. 
But two different syntaxes don't have same AST. That statement is just plain wrong.
Well if you just replace curly braces with white space, it would be easy to get the same result. Now if you want something completely different, getting the same result is obviously more difficult. Your new synax would have to describe the same things (blocks, types, control structures) as the old one, but it doesn't matter what are you using to describe it - curly braces, xml, s-expressions, whitespace.
Yeah you are right about type inference part. That is harder to add on.
I've found this post from the Hacker News and /r/programming (both posted by the author, /u/arthurw). To me this sounds like a fairly objective assessment of Rust.
I looked at nim over a year ago, and it looked nice. The only thing people have to say about it is python like syntax (which only means whitespace instead of brackets) and compile to C. Nim uses a GC for memory safety, and has the same problems as D in that regard. It also seems to follow Perl in the "There is more than one way to do it" mentality, with hygienic and unhygenic macros, non case sensitive syntax, and lack of documentation on what the right way should be. Nim is basically controlled by a single dude, so whatever he says goes. There's very little else going on in that regard. This is observations from when I tried Nim, called Nimrod back when I tried it &gt; 1 year ago, so things might have changed, but that's how I observe it. To answer your actual comment, I'm not a fan of it. I came in wanting systems python, and I left not knowing what I just saw. (Sorry for the rant, in bed sick on mobile trying to waste time)
Missing the forest for a single tree that you could cut down. Even if that's true for this one trivial example in main(), it doesn't address the fact that the codegen is wrong, and this will cause memory leaks and thus crashes in basically any other place that might involve, say, a loop.
&gt;Can't tell you any real numbers, but it seems pretty damn small. Wikipedia page got deleted because language is seen as too marginal. Which is a fucking shame. IRC channel is relatively active, though. That's ridiculous. Nim is already more seminal and important than some other languages that have a Wikipedia page :/
&gt;Well if you just replace curly braces with white space, it would be easy to get the same result. Um, no.
They are not available in `std::os` nor in `libc`, though it is not that hard to make your own binding: extern crate libc; use libc::{c_char, c_int, c_void, size_t, ssize_t}; pub const XATTR_CREATE: c_int = 0x1; pub const XATTR_REPLACE: c_int = 0x2; extern { pub fn getxattr(path: *const c_char, name: *const c_char, value: *mut c_void, size: size_t) -&gt; ssize_t; pub fn setxattr(path: *const c_char, name: *const c_char, value: *const c_void, size: size_t, flags: c_int) -&gt; c_int; }
&gt; The video from the Thursday's SF Meetup about crypto has several interesting presentations. You may want to link to https://speakerdeck.com/tarcieri/thoughts-on-rust-cryptography.
That's a hack and it only works until you start adding Doctype replacements and namespaces.
Thanks. will try this.
Thanks for the update - just wanted to let you know, the link to the servo blog is broken.
&gt; In games, for instance, we need not only ports/wrappers of open source libraryes but also for things like Havok, Scaleform, Enlighten, Umbra, Morpheme, WWise, and dozens and dozens of other libraries. C++ libraries that cannot be easily imported with Rust's macro-unfriendly C-only FFI interfaces. This is the same problem faced by Go, D, and all the other C++ killers: C++ went unchallenged long enough that it's now almost at the same level as C in terms of being a core glue language I agree with this, C++ has such huge momentum - its hard to stray from. add console SDKs to that list. Hence my own experiment (similar goals to Jonathan Blow, but its possible I want to stay closer to C++ than he does), which just starts with C++ adhoc function overloading (which I prefer anyway), and adds features/flavour copied from Rust. But personally I think I remain a captive to C++ IDEs. It's probably wishful thinking that I can ever escape that... I'm going to have exactly the same problem with my pet language as anything else. IDE/debugger integration etc. Then again maybe Rust is all round friendlier to people who don't have C++ backgrounds; I guess I can't directly perceive that. There's probably enough people tortured by C++ that want an escape. I am tortured by headers and a few other things but grudgingly accept the C++ IDE's autocomplete (looking up available functions on the fly) &amp; accurate jump-to-definition &amp; interactive debugging counts for more 
perhaps safety would be a game changer for collaborative projects (i.e. open source on the web as opposed to people in the same office working on a proprietary codebase, with access to shared in-house knowledge), as you'd have much more confidence in contributions from disparate sources.
something else trying to bridge C++/rust (by having both as back-ends), .. interesting
&gt; I prefer Rust's algebraic data types and pattern matching, but Nim has overloading, which IMO is a big plus. I'll take this opportunity to spam my pet project here, which now has Rust style ADTs and pattern matching, and C++ style overloadng. https://github.com/dobkeratops/compiler there's still a lot it doesn't have yet though. I'm firmly in the curly brace camp, and captive to C++ hence my motivations. (I suspect the curly braces and semicolons give c++ opportunity to disambiguate &lt; &gt;?.. ) There's nothing here that couldn't be done as a fork of C++ or Rust (so this is basically an elaborate reskining/remix exercise), but I don't feel confident making such invasive changes to an established compiler and its highly unlikely it would get mainstream acceptance anyway
What's wrong with the attitude?
If you change box to ref it works :)
I am C++ programmer and I want an escape. I want modules, I want checked generics, I want clear ownership rules that are checked at compile-time, I want build system that handles dependencies, I don't want to hunt memory corructions on production machines. I watched first two video from Jonathan Blow and realized that gamedev is very different to how OSes, databases, crypto libraries and software that consumes arbitrary inputs are written. So there is definitely a lot of room for another language for that domain.
http://arewewebyet.com/
And of course, let's not forget the rightward drift of using `with` blocks. It quickly becomes annoying...
Not yet, but we're working on it. For the past few weeks I've been researching what we need to get done to have a full web stack based on scalable constructs like `mio` or another concurrent event loop (though `mio` feels like it solves mosts problems pretty well), such as thinking about a low level HTTP implementation and I've been talking to carllerche (one of the authors of `mio`) about the required and intermediate steps, such as building fast Futures and asynchronous Streams, then figuring out how to efficiently integrate them with mio etc. We've been making progress mostly thanks to carllerche's awesome work, and I'd like to speed things up as soon as I have time to really focus on integrating with mio.
You can still use green threads if you like them, they're just not part of `std` anymore. They've been moved to an external library: https://github.com/alexcrichton/green-rs mio really seems like the way forward for any sort of "C100k" use case. I wouldn't worry about convenience in mio's case, it's a "fast, low-level IO library". A higher level library could be built on top of mio in order to make it more convenient for specific use cases, such as an evented web server. Avoiding callback hell will be harder though. We'd need something like async/await for that, and that has its own set of costs and tradeoffs.
Thanks, I am aware of the site, but it mostly focuses on web frameworks, servers, etc., while I am asking particularly about concurrency methods (and not necessarily tied to web development).
&gt; You can still use green threads if you like them, they're just not part of std anymore. They've been moved to an external library: https://github.com/alexcrichton/green-rs Unfortunately this implementation of green threads is not maintained. It broke recently when the Rust runtime was removed, and fixing it is significant work that nobody has bother to do yet.
You can fix it and submit a PR! :) https://github.com/cmr/this-week-in-rust
If you want some inspiration, you can take a look at netty from the java space. It is one of the highest performing network librariers and they already have the experience of several rewrites which resulted in their current architecture. I guess most of the basic mechanisms could be similarily implemented in rust. For an introduction, take a look at these slides: * http://normanmaurer.me/presentations/2014-http-netty/slides.html * https://speakerdeck.com/daschl/state-of-the-art-jvm-networking-with-netty-4 
&gt; The in-tree getopts, log, `regex`, and `regex_macros` crates are deprecated in favor of the ones from crates.io. `regex_macro` [is implemented with a procedural macro](https://github.com/rust-lang/regex/blob/15f252847817d53e999918cefa810e2bf8e4613a/regex_macros/src/lib.rs) which won't be stablilized by `1.0`. This is unfortunate because moving `regex_macro` to crates.io will make it unusable for non nightly users.
I've been meaning to give something like Rust a try, if not for a career, at least for learning new things. Whenever I look at big boy languages, I feel like I'm a little kid banging sticks together with my C# and webdev career while the talented people are composing with various fancy instruments. But I'll be damned if I'll allow myself to get tuck in a rut!
I don't think anything is wrong with it really. It is a reality based statement that has a caveat that the library hasn't been vetted.
https://github.com/rust-lang/rfcs/pull/469
Same. Rust's my first actually compiled language, so it's been an interesting experience. In fact, learning Rust has made me understand a ton of the bits of C I couldn't understand before. Rust is like the biggest "Best Practices" guide in the world.
Ffmpeg/libavcodec can extract keyframes. There is a [rust interface](https://github.com/mewlips/rust-ffmpeg) that seems well maintained. edit: [example stack overflow question](https://stackoverflow.com/questions/14110149/how-to-find-and-decode-efficiently-nth-frame-with-libavcodec).
&gt; Rust is a classic example of what happens when you try to anticipate everything that could ever go wrong, and then build a language feature that tries to make that less dangerous. &gt; "There are two ways of constructing a software design: One way is to make it so simple that there are obviously no deficiencies, and the other way is to make it so complicated that there are no obvious deficiencies." - CAR Hoare. I hate this line of thought. I hate the defeatist attitude towards security and bugs, as if it's impossible to make any progress and it's just pointless to try. Like completely solving entire classes of bugs doesn't improve security, stability, and productivity. Maybe as rust gets more popular, it'll reach some kind of tipping point as these people realize that something *can* be better than C++.
I think that's a large part of why safety is really important for a Web browser engine. Safety has been done many times in unsafe languages with very careful auditing; for example, avionics systems, the Mars rover, etc. But Web browser engines just move too fast and teams too large for that to be practical. Nobody can hold the entire codebase in their head…except a compiler :)
Nim isn't in quite as bad a position as D vis-a-vis GC. D's current GC is a rather simple conservative one which is not very performant. Andrei Alexandrescu claimed he'd rewrite it after some reddit threads by a D afficionado on its problems, but the story hasn't changed yet. I don't see how Araq's control is a problem yet, any more than Guido's control over Python. A group, not an individual controls Go, and still no generics. There were some additions to Nim that were not from Araq, like type-classes. Etc., etc. It would be nice if Nim were backed by a forward thinking organization like Mozilla that could pay lots of smart engineers to work on it after its original creator left it, but that's just not how it is. Your comment about lack of a "Nimrod way" yet, the lack of docs, and the lack of polish compared to, say Rust, is more on the mark. The comparison to Perl is a bit much though. Probably the sickness talking. Get better soon.
socket may be clone-able, have you checked in to this? as in: let socket2 = socket.clone(); let mut endpoint = socket2.bind("...").unwrap(); socket.write(b"foobar"); edit: similar to this: [where I clone a tcpstream](https://github.com/viperscape/rust-irc/blob/master/src/main.rs#L37-L38)
Thank you. There doesn't seem to be any documentation or examples for the rust bindings, is that right?
We really don't want socket to be cloneable since it would allow for wrong multithreaded scenarios.
from my POV where rust is an unambiguous win is where it both makes something easier to write, and safer/less error prone. i.e. match/enum, vs unions &amp; switch in C. the move semantics &amp; ownership is great too. (I'm perfectly happy with multiple pointer types); and the expression syntax, makes it easier to create everything initialised, which is also clearer. where IMO it becomes ambiguous is where you're likely to do another piece of work to get something working correctly, and going through compiler safety is extraneous: the best example I can give is indexed meshes; you know your indices will be correct because you are going to write something that visualises it (both debug, and the end result) e.g. in an asset conditioning pipeline; if the indices are wrong (in many other ways than just 'out of bounds'), you simply don't get the correct result, and you have to do other work to track that down anyway. even if its read in, the index can be checked once on loading, then it's immutable data. (even there I've been in situations where we've fretted about the processing going on in loading/setup code). There of course a type system or new language might be able to help in other ways, e.g. if you parameterised the *index* you can better communicate 'this is a vertex array, this is a vertex index, for indexing in vertex arrays',(instead of just ints). you can set that up in C++ but it can be verbose; and inbuilt support for tests can be nice. (does D have something like invariant checks you can specify?) Then of course NANs: a simulation that can generate NAN's is incorrect since reality only has NANs in black holes where we never go ... so having to specify more around that is again extraneous (e.g. adding verbosity on operations to check), because you're going to write tests that verify numerical stability (you'll never invert a zero, you'll saturate anything that might overflow, and you'll have other problems like time step accuracy).. you'd use a debug build to empirically track down any mistakes, and rework your design until it never generates NANs in the first place. the debug build can have way more checks, inserted universally (e.g. `#ifdef debug ... this type checks its' not a nan after every operation` So here the C++ 'empirical safety' idea is superior. in the end there is probably significant overlap between "making something work correctly" and "making it safe", one should help the other, but it seems they're not precisely the same thing. I think Rust does give a lot of interesting tools, and it's just a case of letting people choose how far to restrict things ... then these tools would be universally useful
&gt; I also agree that the biggest challenge will be figuring out how to make safety practical for domains such as games in which it isn't as critical as in network-facing software. I don't think it's an insurmountable problem, though :) Many games have network-facing code, too. Maybe multiplayer backends will be Rust's trojan horse into the gaming world?
the difference with a browser engine as far as I can see is its' practically a complete OS, with the ability to run completely general code, capable of running any type of application. Whilst some game engines do have all sorts of scripting/plugin extensions going on, that's not essential; its' possible to simplify what is exposed and how much control is possible across the network. there are curated channels and you can get everything baked in. &gt; Maybe multiplayer backends will be Rust's trojan horse into the gaming world? ... an interesting way of putting it, but I don't think you need a trojan horse .. since gamedev has many other problems created by C++ and a solution would be actively sought. Rusts macros are interesting for data driven code - anything where you want to create a schema that describes how a file format works, and keep serialisation in sync.. that's all really annoying in C++. passing shader parameters is another use case.. again, manually keeping that sort of thing in sync is annoying/verbose. It's made harder by *language omissions* and header files. then people complain 'C++ is too big' and resist adding new features that would fix it! (how ironic) Infact for me it was the reverse... all these other practicalities are the 'Trojan Horse' that got me to look at rusts' safety approaches
No, it doesn't; you can't pattern match on stuff that follows "ref". Try rewriting [this](http://play.rust-lang.org/?code=use%20std%3A%3Arc%3A%3ARc%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20x%20%3D%20box%20Some%283i%29%3B%0A%20%20%20%20match%20x%20{%0A%20%20%20%20%20%20%20%20box%20None%20%3D%3E%20println!%28%22Nothing!%22%29%2C%0A%20%20%20%20%20%20%20%20box%20Some%28ref%20v%29%20%3D%3E%20println!%28%22Something%3A%20{}%22%2C%20v%29%0A%20%20%20%20}%0A}) to use Rc.
We don't want two threads to perform a read on the same underlying nanosg socket, since it would result in each reader receiving only a part of the message.
An interesting read. Thanks for sharing!
I suppose possible reasons why this might happen legitimately are because `inc` is either a trait implementation (fairly easy to special-case), or is being passed to a higher-order function that expects a function of type `&amp;mut int -&gt; ()` (probably much more difficult).
neat :-) - done.
Oh no, this calls into rememberance the 'mutocalypse.' In a certain sense, `&amp;mut` isn't even about mutation...
The problem here is that Netty builds around a lof ot concepts that currently don't work in Rust. E.g. all those handlers are modeled as interfaces which are shared between several other objects in the processing chain. The same is true for all objects which are passed up and down the processing pipeline. They are `Object`s which are typechecked and casted to mutable concrete objects or interfaces at different stages of the pipeline. 
Yes, but perhaps you could pester the author? Like, create an issue on Github for documentation. Or ask it in Stack Overflow (not a duplicate - asking how to do it *in Rust* is legit and different than that C++ question). Also, a starter could be to search for functions like [av_seek_frame](https://github.com/mewlips/rust-ffmpeg/search?utf8=%E2%9C%93&amp;q=av_seek_frame).
First of all, nice article :) But I would like to discuss one of the points made: &gt; On the other hand, the entry barrier is a filter. Rust code quality may be of higher quality partly due to this. I'm not sure if that was the intention, but this sounded elitist to me. Maybe s/he meant that the entry barrier was higher for code (in the sense that it will be harder to make the compiler accept badly-written code), but the impression I got is that the author was talking about programmers instead. Reminded me of Linus Torvalds' comments on C++. I'm not a native english speaker though, so this can be me misinterpreting the phrase. I would love to be corrected.
You've been very helpful, thank you.
Be warned. Learning Rust is like learning from a Shaolin master. At first it will whoop your ass and make you scrub the courtyard for weeks. And then you will attain enlightenment, and you will be jumping over rooftops and chopping through stone blocks, soon enough. 
The article says: &gt; Expressiveness is not a goal &gt; &gt; Expressiveness or elegance is not a goal of Rust. It’s certainly not bad in this regard, just not as wonderful as you may wish if you care it a lot. I've been doing a *lot* of Rust programming in the last few weeks (it's my current obsession), and I have to say that Rust is *extremely* elegant. Rust hits this incredible sweet spot between functional and imperative languages. Once you learn to stop fighting the lifetime system and start using it naturally and even exploiting it, everything becomes so much more clear. It becomes really easy to write natural, concise, powerful code. Especially once you learn the basic toolkit of .map(), closures, and iterators. I've been porting a lot of code to Rust, mainly as an experiment, and the resulting code is usually half the size of the original code, sometimes even smaller. And more important than size, the resulting Rust code is usually more expressive, more obvious / readable, and more obviously correct than the input code. 
I've been I've been having the opposite experience (but I'm still in the courtyard scrubbing phase I think, based on your post above). I would love to see some ways that you've made the lifetime system work for you. Can you point me to some examples of how it changed your design for the better? I keep running into things that I think the abstractions should support, but that get thwarted by the borrow cherker mostly. I think seeing some examples of "before and after" the enlightment would be *extremely* useful. *edit* just realized that "opposite experience" is way too strong - rust is awesome almost all of the time but I find myself spending an unreasonable amount of time fighting it for that last 5% of expressiveness.
Also, it's interesting that you point out map and closures. That's where I have spent the most time in contest with the borrow checker. The problem seems to usually arise as a result of trying to access self or non-copy types (i.e. leading to a move from captured variable) from inside the closure. In the HN discussion on this post, someone mentioned that non-lexical borrows will probably fix this and it seems true, but I'd be very interested to know how you're working it out currently.
Here's the main thing, so far, for me. When the borrow checker complains about something, now I force myself to really think about the *meaning* behind the error, rather than just thinking "How do I beat this code into submission, so it compiles?" Consider one of the big no-nos: borrowing the same data as both `&amp;mut` and `&amp;imm` (i.e. just plain `&amp;`). The compiler rejects this kind of conflict. Why? Well, think about what happens when you do this. Let's say you call some function `f(r: &amp;T, w: &amp;mut T)`, and you pass it two borrowed pointers to the same data, let's say like so: `f(&amp;data, &amp;mut data)`. Deep within the definition of `f()`, you read the value of `r` somewhere, then you write the value of `w`, then you read the value of `r`. What happens? Well, if the caller passed the same pointer for both `r` and `w`, then the second time you used `r` the code in `f()` would return the value of `w`, not the original value of `r`. This would most likely lead to hilarity. This is the classic "aliasing" problem. In some cases, like references to `uint` variables, maybe the problem doesn't seem so bad. What's the big deal, it's just integers, right? Well, maybe. But consider something worse, like passing a `&amp;mut` to a `Vec&lt;uint&gt;` and *also* passing `&amp;[uint]` to the same function. Something like this: fn f(r: &amp;[uint], w: &amp;mut Vec&lt;uint&gt;) -&gt; uint { w.clear(); return r[4]; } Now consider this call to it, which would be illegal: let mut v: Vec&lt;uint&gt; = vec![1, 2, 3, 4, 5]; let x = f(v.as_slice(), &amp;mut v); println!("x = {}", x); The compiler rejects this, but rather than just focus on that, let's focus on why. In some languages, this code would be *accepted*, assuming we expressed it in the syntax that is appropriate to that language. (Rewrite `Vec&lt;uint&gt;` to `std::vector&lt;int&gt;` in C++, for example.) This code contains a bug -- the `r[4]` expression in `f()` is going to read undefined memory, because the `w.clear();` statement freed the memory behind the vector, and this caused `r` to point into undefined memory. In C++, this would lead to undefined behavior, but the compiler would *not* detect/reject this problem. Instead, your code would run, and *something* would happen. We don't know what, because it's undefined behavior, so pretty much anything is allowed to happen, including reading invalid data, causing a segfault, or launching all missiles. Rust rejects this, which is super-helpful, and it forces you to consider *why* it is being rejected. You've asked for a situation where the behavior is not provably safe / well-defined. In this situation, we need to declare a second `Vec&lt;uint&gt;` for the output of calling `f()`. We can do that in two ways: let v: Vec&lt;uint&gt; = vec![1, 2, 3, 4, 5]; // input data let mut output: Vec&lt;uint&gt; = Vec::new(); // for output data let x = f(v.as_slice, &amp;mut output); Or by having f() allocate the vector and return it: fn f(r: &amp;[uint], w: &amp;mut Vec&lt;uint&gt;) -&gt; (uint, Vec&lt;uint&gt;) { let mut w = Vec::new(); // add some data to w, out of scope for this example return (r[4], w); // &lt;-- ownership transfer of w } let v: Vec&lt;uint&gt; = vec![1, 2, 3, 4, 5]; // input data let (x, output) = f(v.as_slice()); // output data I don't know about you, but I find this really helpful. Rust points out where I didn't think through my designs properly -- where I didn't consider the possible implications of my code -- and it forces me to clarify and sometimes think more deeply about a design. I find that to be very rewarding. It makes me solve problems at design time, rather than at runtime (runtime failures, test failures, etc.). I'm working on a few large Rust projects, one of which I'm nearly ready to show the world. It's a port of a common open-source tool to Rust, which will enable before-and-after comparisons. When that's ready, I'll post it to /r/rust, and maybe that will help show some examples. 
You might enjoy reading through the pull requests on the RFC repo, as well as meeting minutes. A full, finished book on the topic would be pretty great, however.
I would be really interested in hearing from you about what your pain points are moving from interpreted languages to Rust. If you've got a moment to give me a braindump, please do!
http://www.reddit.com/r/rust/comments/2q1uew/thoughts_on_rust/cn2f12j applies to you too, if you find yourself having some time :)
Thanks, this is a great reply. I look forward to seeing your ported tool. I agree with you regarding the examples you gave, rust is great for protecting me from that kind of stuff. 
The same is true of the in-tree version.
I think it's kind of both actually. How strict the compiler is will affect which people code for it. In particular, the kind of people who don't like having the compiler tell them they may be doing something stupid will be inclined to use some other language instead. PS: That doesn't necessarily make them bad programmers; they may just have different priorities.
Out of curiosity, what languages have you been translating from?
C++ and C#. 
I did C++ in college (early 2000s), got out and have avoided it like the plague in my career. There was simply too much syntax, and an overwhelming number of ways to accomplish the same thing. I have been wanting to goof around with making games since, but the hurdle of C++ seemed too much (and python too slow). Rust's features, to me, seem nice and concise. I can read through their guide in a single sitting vs. the C++ tomes that are thousands of pages in length.
Oh? I missed that conversation completely.
&gt; Closures certainly have some serious constraints on them. One frustration I have with them is that the "borrows" inside a closure live as long as the closure itself, rather than living only for the lifetime of a call to a closure. I think this is probably the root of my current set of issues (combined with my obsessive desire for pretty code). I like using .and_then and .map to flow Result and Option types through my program, but I'm always having issues with the stuff I want to do in the closures. Your comment above about the shaolin master situation got me thinking though - I've learned somewhere in the neighborhood of 30 languages to some degree of proficiency over my career, and I think I've gotten lazy because most of them are pretty much just a new syntax on top a bunch of standard ideas. Once you've tackled the basic imperative, functional, and logic/constraint styles, there's typically not a lot of really new stuff to climb over while learning a language. I think Rust's lifetimes are actually something new in that sense, and I probably shouldn't expect to pick it up as quickly as something like OCaml for example.
You can always clone it locally and run `cargo doc` in its root, then open the doc pages in `rust-ffmpeg/target/doc/...` in your browser to view the documentation.
If this was true, then the `print!` macro and its friends could not be part of Rust 1.0.
I ran into [something similar](http://www.reddit.com/r/rust/comments/2p4qdd/handing_out_subresources_and_mut_vs_cell/) when working on my D-Bus bindings. What seems to work so far is to use Cell/RefCell and give up the thought that everything that mutates the interior needs a mut ref. Trying to translate that to your scenario, you would end up with: struct Socket { socket: Cell&lt;c_int&gt;, } struct SocketWriter&lt;'a&gt; { socket: &amp;'a Socket, } // and impl Writer for SocketWriter struct Endpoint&lt;'a&gt; { socket: &amp;'a Socket, } fn pipeline1() { let socket = // create a socket let mut endpoint = socket.bind("...").unwrap(); socket.writer().write(b"foobar"); With a socket.writer() returning a SocketWriter struct, you could have a mutable SocketWriter while keeping the Socket struct non-mutable (so you could have several references to the Socket). Not saying this is the perfect or most rusty solution, it's just what I came up with.
Awesome, thanks. That's quite helpful. With regards to 1), have you seen http://doc.rust-lang.org/guide-ownership.html ? I have a patch in the queue to improve it a bit, but it should be helpful. As for two, returning an iterator is indeed very complicated. We actually have a plan to tackle this shortly after 1.0 (tracking issue: https://github.com/rust-lang/rfcs/issues/518 ) and, so, I've been hesitatant to write stuff on it until that gets sorted. I eventually plan to have a whole big thing on iterators, but haven't found the time yet. So it makes perfect sense you'd struggle there. &gt; traits don't seem as powerful or as useful as interfaces are in C#, with IEnumerable&lt;T&gt; being the prime example. That example is indeed helpful, thanks. :) My C# isn't great, but I do know that one of the reasons Rust's traits can be intese at times is because we don't box everything. In those cases, traits provide _static_ dispatch, rather than dynamic, which is a huge advantage, but does come at the cost of some complexity. Thanks again for elaborating. This kind of thing is very, very helpful for me.
Ok, additional stuff on lifetimes (from an example I just got aatch and Gliptic (sp?) to help me with on the IRC!): C#: http://www.reddit.com/r/dailyprogrammer/comments/2ptrmp/20141219_challenge_193_easy_acronym_expander/cn2hhm7 Rust: http://www.reddit.com/r/dailyprogrammer/comments/2ptrmp/20141219_challenge_193_easy_acronym_expander/cn2kvx9 If you replace the .get() call that I use in the Rust version, and therefore replace the match expression with an if contains_key() { thing } else { thing} such that it matches the C# version, the compiler blows up quite spectacularly and then informs you that 'line' doesn't live long enough for ... Well, it has to be valid for a code block that's actually *above* it. :) Now, the guys explained that this is because the [] operator wants its input to match the type for the key (right down to its lifetime!), whereas .get() doesn't care so much, but the error message was useless. The guys also mentioned that the error message should be improved somewhat at some point in the future.
also, there's no clue when the website was last updated. It really does feel like it may not be relevant just from that fact.
Oh yeah, we have a thread to collect lifetime error stuff, too: http://discuss.rust-lang.org/t/confused-by-lifetime-error-messages-tell-me-about-it/358
print! is defined in the compiler itself, while regex! is an externally defined syntax extension. Externally loaded extensions will not be stable for 1.0, and that includes the regex_macros crate, whether it's located in the rust repo or its own.
I personally consider the goals of Rust to be: * Safe * Fast * Usable If not of the project as a whole, at least for the parts *I* touch. :) These goals are in eternal contention, *especially* for internal APIs, but I think this is generally doable for external APIs, with some small compromises like bounds-checking.
Frankly, not all that much. I've already been dabbling in functional languages like Haskell (thank you Learn You a Haskell!) so I was already right at home with `match` and traits, I just had to figure out the syntax and I already had a great environment for playing around with. I've yet to touch any actual projects, though, so I imagine I'll run into issues with borrowing and other things once I do that. Working with mutable-by-default duck-typed programming languages and then working with Haskell really started to make me hate them, so Rust would still be interesting to me even if it wasn't as blazingly fast as it is. In my opinion, it feels closer to Haskell than any bits of C I've ever tried, and that's very much a good thing. Really, trying to learn C is so fucking difficult as the documentation is ancient (nobody makes good tutorials), and the language itself is flat-out *scary*. I HATE the fact that I could break everything with a single mistake. It's the worst learning environment in existence.
It looks the be an automatically generated binding to ffmpeg. Best bet is to read the ffmpeg docs.
&gt; and I think I've gotten lazy because most of them are pretty much just a new syntax on top a bunch of standard ideas. [...] I think Rust's lifetimes are actually something new in that sense, and I probably shouldn't expect to pick it up as quickly as something like OCaml for example. That was exactly my experience, too. Lifetimes really are a new axis to think about. Since I've gotten obsessed with Rust, I've tried porting a few medium-sized components to Rust. What I've found is that it's fairly difficult to "port" things to Rust, in the sense of just converting to Rust's syntax, because the constraints in Rust that make it valuable are not easily applied to existing code *without* also refactoring that code. In every case, I've had to make significant changes to code. For example, instead of having nodes in a tree that all point to each other, you might have a node table and the nodes contain integers that identify each other in the table. That might create other problems! such as managing the lifetime of those integers -- they're basically pointers all over again, so what has the exercise bought you. I'm not sure -- I'm still learning that. But in some other cases, the borrow-checker has pushed me to remove needless pointers between objects, or to move my code closer to a functional-programming idiom. I won't claim that Rust is perfect, in its current form. The lifetime analysis is the heart and soul of Rust, and I think it still needs some polishing before it is approachable. But I like what I see so far.
I actually think the Hoare quote is pretty much spot on. It's the notion that Rust is adding complexity to solve problems that I find offputing. IMHO move semantics and borrowing actually take lots of complexity away. (E.g. managing multiple mutable aliases)
There is also another good quote: "if you do not define formal structure, the informal structure will emerge. But, most likely, it will be a mess". I find it fitting: you love leaving memory management rules undefined? Well, then, the developers will have to invent rules as they go along, and they will STILL have to think about them! But they won't have an automated mechanism that can formally validate their invention.
Cool, thanks :)
I found that right now Rust feels very similar to node.js - in fact, it could easily replace node.js if it had a little bit more completed libraries. Both have similar package managers: in fact, many node libraries have C/C++ code that is compiled when you run "npm install". So, both are actually compiled - for your target machine. The workflow is strikingly similar: you write code, then you look at the console for errors - except for rust, the errors are in compiler, and for javascript the errors are runtime errors. The different "feel" for novice programer might not even be so noticeable: there are a lot of gotchas in asynchronous javascript (promises, rx, events, etc), and time solving them seems to be equivalent to time solving similar cases in rust. Again, for rust that would be compile-time. Both have "&lt;package manager&gt; test", "&lt;package manager&gt; update", etc. Another language I use is PHP, which can not be easily compared, because PHP memory management is done when PHP process dies. Completely different approach. Therefore there is completely different mental model when working with PHP: do what needs to be done ASAP before memory fills up. EDIT: reduce statements to facts to avoid #4.
These threads are notoriously bad...
If I read the RFC correctly, they wanted to avoid compiler flags _as much as possible_, which is why they proposed their block/attribute solution in the first place. I'm not saying I don't expect any performance hit. What I would like though, would be that the inserted `debug_assert!` is not _completely_ unoptimized, because "it is only needed during debug, thus does not need any optimization". It would be interesting to know the exact variant of the proposal which will be implemented.
Awesome, thanks. Seems like Cargo workflow simularities are very important.
Use a mutable reference (`file: &amp;mut T`). This signals the compiler that the function only temporarily *borrows* the file and gives it back afterwards.
The first way to solve this that comes to my mind is to make the `file` argument of `write_header` a `&amp;mut T` instead of `T`. This error is happening because your function requires ownership of the file. So once you pass the file to your function, you can't use it anymore (because that function has taken ownership of it). `&amp;mut` means that you aren't taking ownership, you're just borrowing a mutable reference to the file. It seems to work after changing to `&amp;mut`: http://is.gd/Enours
`file.lines()` is an `Iterator` over a (`Result` of) `String`. The compiler points out that the underlying `String` is short-lived, as its lifetime ends immediately after `let contents = ...;`. Therefore it suggests: let line = line.unwrap(); // extend the lifetime to the loop body let contents = line.as_slice().trim_right(); // ... Your code, still, wouldn't work. :) (The compiler knows what is wrong, but it doesn't know what is correct!) This is because you actually want the `String` to live throughout the `main` function, not only inside the loop body. `trim_right` returns a slice (view) of the owned string, but you can create new owned string with `.to_string()`; consider storing this.
Since this talk that I gave at Open Source Bridge is a year and a half old, I'm sure that almost nothing in it is accurate anymore ;) Posting this mostly as a blast from the past.
I see. I had tried this before, but this time chasing down the compiler errors lead me to the required syntax `&amp;*stringer` which I hadn't come across before. One hurdle passed; I'm now seeing another compiler error that I'm confused about. Despite the [docs](http://doc.rust-lang.org/std/vec/struct.Vec.html) for std::vec::VEC stating that it implements the io::Writer trait for Vec&lt;u8&gt;, the compiler disagrees: fn write_header&lt;T: io::Writer&gt;(aggregation_type: u32, max_retention: u32, xff: f32, archive_count: u32, mut file: &amp;mut T) -&gt; io::IoResult&lt;()&gt; { [...] let mut stringer: vec::Vec&lt;u8&gt; = vec::Vec::new(); /vagrant/projects/whisper/src/lib.rs:35:11: 35:23 error: the trait `core::kinds::Sized` is not implemented for the type `[u8]` /vagrant/projects/whisper/src/lib.rs:35 match write_header(1, 360, 0.0, 3, &amp;*stringer) { ^~~~~~~~~~~~ /vagrant/projects/whisper/src/lib.rs:35:11: 35:23 note: required by `write_header` /vagrant/projects/whisper/src/lib.rs:35 match write_header(1, 360, 0.0, 3, &amp;*stringer) { ^~~~~~~~~~~~ /vagrant/projects/whisper/src/lib.rs:35:11: 35:23 error: the trait `std::io::Writer` is not implemented for the type `[u8]` /vagrant/projects/whisper/src/lib.rs:35 match write_header(1, 360, 0.0, 3, &amp;*stringer) { ^~~~~~~~~~~~ /vagrant/projects/whisper/src/lib.rs:35:11: 35:23 note: required by `write_header` /vagrant/projects/whisper/src/lib.rs:35 match write_header(1, 360, 0.0, 3, &amp;*stringer) { ^~~~~~~~~~~~ EDIT: I think what's happening is that dereferencing the Vec&lt;u8&gt; is giving me the underlying array, but I can't just pass a reference to the Vec&lt;u8&gt; itself without getting a `cannot borrow immutable dereference of '&amp;'-pointer as mutable` error.
And thanks for putting the disclaimer: if you need strong security at this point NSS, GnuTLS, or OpenSSL (or one if its forks) is probably what you should be using. Hopefully one day Rust-Crypto will be on that list, but, its not there yet.
I *love* the change to integer overflow. I think it's important, before reaching 1.0, that you force programmers to write code that explicitly shows when they want integer overflow. Not only is it self-documenting, but now all of the options are left open, and it's possible to really solve the problem of integer overflow in the future. Maybe one day in the future, we'll have hardware integer overflow checking?
Here is a solution use std::io::{BufferedReader, File}; fn main() { let mut max_length = 0; let mut longest_line : Option&lt;String&gt; = None; let path = Path::new("test.txt"); let mut file = BufferedReader::new(File::open(&amp;path)); for line in file.lines().take_while(|l|l.is_ok()) { drop(line.map(|s| { if s.len() &gt; max_length { max_length = s.len(); longest_line = Some(s.to_string()); } })); } println!("{}: {}", max_length, longest_line); }
 &gt; For the past few weeks I've been researching what we need to get done to have a full web stack based on scalable constructs like `mio` or another concurrent event loop Are the results of your research available somewhere? I'm very interested on the issue. My main doubt is how it will integrate different libraries into a single loop. For instance, if a HTTP request has to send a query to a Redis database, the Redis client should not block the current thread. 
Technically speaking, this might work: let mut line = line; // or `for mut line in ...` line.truncate(line.trim_right().len()); Normally `String` cannot be shrunken into its slice without reallocation, but the slice is a prefix of the string so you can use `truncate`.
Seems like a good way to proceed. I'd also like to say, "A Tale of Two's Complement" is a great title.
From what *I've* read, a lot of people are wildly overoptimistic regarding the potential of fast checked arithmetic on modern hardware and compilers. Here's a more cynical viewpoint from Daniel Micay (strcat), the Rust community's resident performance grouch: &gt; The two choices here aren't 'fast' and 'super-fast'. We're not talking about the "last few percent of speed" here. Using checked overflow will reduce the performance of most code with non-trivial usage of integer arithmetic by 30-70%. The only saving grace is that many applications use floating point arithmetic, and this would still be unchecked. Even if the program is bounded by memory bandwidth, the stalls from all of the extra icache churn are going to have an impact. http://article.gmane.org/gmane.comp.lang.rust.devel/10449 In general it's true that we won't know the extent of the impact until we put some work into optimizing it. I'm confident that with the changes proposed here in the OP, Rust will begin the process of determining the exact performance hit that this represents. If it truly turns out to be minimal, then we're in a very good position for making arithmetic checked by default for all Rust code for the mythical Rust 2.0. In the meantime, I can easily live with this compromise. (I'm also obligated to give the usual disclaimer that checked arithmetic is not really a silver bullet by any stretch of the imagination, and will likely only rarely save you from a missed sanity check, and only then after your program has *already* been in an invalid state for a *very very long time*. So not only does it not lead to memory unsafety, it doesn't save you from the need for a good test suite. Any cost it imposes needs to be weighed against this diminished utility.)
I didn't even notice it was an old video until you started talking about @box pointers... heh.
I'm not sure that the following are both possible at the same time: * An endpoint should not outlive the socket that created it. * Send and write operations are mutating the socket. In particular, I think the first is usually achieved by borrowing the socket in the creation of the endpoint, and once a borrow is active, I don't think you'll be able to call a function that mutates the socket. Here's an attempt, but note there is some cruft - `bind` is now `bind` + `get_endpoint`, and `send` is now `get_endpoint` + `send`. This is compiled with 0.12.0, so it's at least a little out of date, in that I think NoCopy is the default now. use std::kinds::marker::NoCopy; struct Socket { n: NoCopy } struct Endpoint { n: NoCopy } struct BoundSocket { e: Endpoint , n: NoCopy } impl Socket { fn new() -&gt; Socket { Socket {n: NoCopy}} fn bind(self) -&gt; BoundSocket {BoundSocket {e: Endpoint {n: NoCopy}, n: NoCopy}} } struct Message; impl BoundSocket { fn get_endpoint(&amp;mut self) -&gt; &amp;mut Endpoint { &amp;mut self.e } } impl Endpoint { fn send(&amp;mut self, _: Message) {} } fn main() { let s = Socket::new(); let mut bs = s.bind(); { let e = bs.get_endpoint(); e.send(Message); //drop(bs); // This is a compile error, because e is still visible } drop(bs); // This is OK because e is no longer visible }
The main problem with pure Rust code is: the high-level code can look perfectly constant time (no branches on secrets etc.) but the optimiser may introduce branches. And there's no guarantee that it does it "reliably" e.g. it may only appear on some architectures/versions/configurations (this seems to be the largest missing piece that experimentation can't cover). It would be interesting for the core pieces of rust-crypto to be compatible with [nadeko](https://github.com/klutzy/nadeko/) to get (closer to) guaranteed constant-time with pure Rust + syntax-extension code. (That readme also includes [an example](https://github.com/klutzy/nadeko/#why) of the optimiser reintroducing bad branches.)
same with a lot of that list for me (which is why I looked into rust) - but for me checked generics aren't worth giving up overloading, and memory crashes are just one part of 'getting things working' ; and rusts module system is interesting, but I don't like having to commit to baking in the directory/filename into the namespace all the time (i find moving a function from one place to another in Rust can easily be as painful as it is in C++, because everything is dependant on location .. in c++ a graph-like workflow is possible where headers manage eachother)
Can you elaborate more please? I remember bits and pieces from the mutocalypse but most of it was too verbose and high (low?) level for me to grok the full implications of. Thank you Steve!
The expiriment that I describe would need to run on all the configurations that Rust-Crypto is used in to be useful. It can't do that with my proof of concept code yet, but, I think it could get there. The expiriment that I describe certainly doesn't mean that rust-crypto couldn't use other mechanisms to ensure that the algorithms that are designed to be constant time actually are. Those two things are (hopefully) fully orthoganal - even if something like nadeko is used, it would be nice to have a tool to help check that its doing what its supposed to. I haven't look extensively into nadeko yet - my initial reaction is that I don't see what nadeko is doing that couldn't be done by new-typing integer types and re-implementing all of their operations in assembly to make sure that the optimizer won't mess with them. If someone can further my understanding of what nadeko provides, that would certainly be appreciated.
one thing to bear in mind is C++ vs its standard libraries (which I do despise).. and gamedev usually uses a subset. you don't need multiple inheritance, (even vtables are avoided), and you don't need exceptions. and its practical to use simplified collections (you don't need complex pointer chasing behaviour at runtime). you can write a replacement for 'std::vector' that does what you need in tens of lines (which to my mind is more pleasant than committing to dependancies on huge std libs and having multiple abstractions to navigate to see what is going on, you want it to compile to something simple, so complex abstractions are stupid .. if you have more source code than machine instructions that seems wrong to me ). For me C++ was just a natural progression from C, itself a natural progression from programming in assembler. eg it has operator ++ because many CPUs have something like that, because it's useful. Where C++ gets annoying for me is "the way classes and headers interact". You want classes to take advantage of the IDE (autocomplete is worth its weight in gold), but you want free functions for decoupling. Once something is in a class, it complicates dependancies. It is an unnecessary paradox created by class syntax, since there is no fundamental reason these 2 benefits should be exclusive. http://isocpp.org/files/papers/N4165.pdf this proposal - UFCS - is a solution, if C++ actually gets this it will be unambiguously superior to Rust for me. At presents rusts' Traits/Impls help, because you can 'extend a class' - this (NOT safety) was actually the single biggest draw to Rust for me ... but that still comes with restrictions and having to bake in decisions about organisation 'up-front'. You have to make a trait. If you want to move a function from one trait or module to another you have to micromanage, just like with header files.. And of course Rust doesn't have an IDE yet so you don't get the 'dot-autocomplete' anyway. I know thats' not Rusts fault itself (and the cleaner syntax should allow superior IDEs in future, thats a win) .. but we are where we are and momentum matters. Gamedev needs code in a fluid form, IMO. (jonathan blow goes on about this a lot in his videos, he cares a lot about the ease of moving a piece of code from one place to another, which is music to my ears). for 2 reasons:- - (a) it is a *creative* process. design(as in game-design) changes - (b) it cares a lot about performance.. - which means routinely reorganising code &amp; data based on profiler feedback, empirical, can't be predicted upfront. - (i) it might be slow because you divided into too many parts, pointer chasing(D cache thrashing), you need to merge, for locality (but see hazard (ii)). - (ii) or it might be slow because your objects are too large(D-cache overflow), you need to divide them up - (iii) or it might be slow because your I-cache overflows, again you need to divide up into several simpler passes... but see hazard (i) - Some people might write code in vtables (because its easier), and you'll have to butcher that - moving from one platform to another might introduce different issues So basically baking in organisational structures upfront is itself a big hazard. You need to be able to move things around easily. "intersection types"(?) would be a godsend (auto-delegation of components) because then you could move pieces between representations without having to reorganise all the access... keep code logically the same but reorganise its' representation in memory. In my perfect world there would be no special concept of a method - just free-functions &amp; UFCS, and optional gather of functions into an interface (duck-typed like go)
Can't that be done with trait objects instead?
Being able to write constant time `if`/`match` is pretty cool, but not necessary for constant time crypto. A new-typed integer type that didn't implement `Eq` would make sure that `if` wouldn't work and require you to do something like `fixed_time_select()` to accomplish the same goal. It seems like nadeko has a pretty big task ahead of it. Looking at something like Rust-Crypto's (hopefully) fixed time software AES implementation (https://github.com/DaGenix/rust-crypto/blob/master/src/rust-crypto/aessafe.rs), its going to be pretty hard (I think) to re-write that in a mannor that will fit into a restricted Rust subset without turning it into something that looks more like a giant assembly blob than Rust code. My other concern is that I want the optimizer to be involved most of the time - I just want it to step out of the way when handling secret data. But if the optimizer is fully removed, I'm concerned that performance might take a significant hit. The performance of that code is already on the lower end of useable, so, it doesn't have much room for any additional performance impacts. All that being said, I'll definitally be following the nadeko project with interest and if its able to help Rust-Crypto prevent timing attacks that would be super cool. 
Maybe there should be a warning when people compile without optimization?
It appears to be more nuanced than that. Previous discussion: http://www.reddit.com/r/rust/comments/2pp9lh/the_performance_cost_of_integer_overflow_checking/
Regarding green threads: https://mail.mozilla.org/pipermail/rust-dev/2013-December/007565.html (&amp; [hn discussion](https://news.ycombinator.com/item?id=6977177))
I was under the impression that the `Deref` impl for `Vec` is more a convenience thing. When combined with auto-deref, it makes many operations far cleaner to write and read. For instance: vec.as_slice().chunks(16) vec.chunks(16) I personally find the second to be much easier to write and read. I've never been bitten by the `Deref` for `String` or `Vec`.
[29 days ago](https://github.com/teepee/arewewebyet/commits/master)
Regehr's paper has an unbiased analysis. He's a strong proponent of integer overflow checking. &gt; For undefined behavior checking using precondition checks, slowdown relative to the baseline ranged from −0.5%–191%. In other words, from a tiny accidental speedup to a 3X increase in runtime. The mean slowdown was 44%. Using flag-based postcondition checks, slowdown ranged from 0.4%–95%, with a mean of 30%. However, the improvement was not uniform: out of the 21 benchmark programs, only 13 became faster due to the IOC implementation using CPU flags. Full integer overflow checking using precondition checks incurred a slowdown of 0.2%–195%, with a mean of 51%. &gt; http://www.cs.utah.edu/~regehr/papers/overflow12.pdf He states this on his blog: &gt; A highly tuned software integer undefined behavior checker for C/C++ could probably have overhead in the 5% range. This would be from *only* using `abort` and using special optimizations to OR the flags together and report errors as lazily as possible. So if `x + y` overflows, it may or may not report an error - but it *will* report one (without an error message - just a crash + core dump if enabled) if the result is used for an operation with a side effect. I think a 5% hit for those semantics is still quite bad. If it was done with `panic!` or even abort + precise error reporting, it wouldn't be able to optimize well. If there was hardware support, the cost could be reasonable for those lazy semantics - but the impurity it adds to the code will still hurt. It wipes out the ability to hoist most array bounds checks out of loops, etc. These checks hurt much more when you combine them, because you break the optimizations that the other checks rely on to be lean.
&gt; trying to learn C is so fucking difficult That'd actually the opposite to what I experienced. While C is definitely an inferior language to Rust, D, C++ and most other languages, its simplicity allowed to pico it up very easily with only a background in Python, far easier than Rust (which I am still working at after sidestepping into C++ and Java). Keep in mind though that at that point Rust was 0.6, it's far easier to use now IMO.
Shortest solution would be match file.lines().filter_map(Result::ok).max_by(|x| x.len()) { Some(line) =&gt; println!("{}: {}", line.len(), line), _ =&gt; println!("No such line") } 
It's a bit unclear to me. In C, unsigned types never overflow, they just wrap around. Not sure exactly what they mean by overflow here, if it applies to unsigned types.
That's not true, in C signed overflow in undefined behaviour while unsigned overflow is defined as wrapping. Any integer type with a finite range can overflow and that's true for all elementary integer types in both rust and C. Until now rust has had defined overflow for both signed and unsigned integer types defined as wrapping. This article says that it's no longer true and rust will switch to undefined *value* for both and a crash in debug builds.
If file does not exist then `lines()` will forever return `IOError`.
But others have been :) `Vec&lt;T&gt;` implements `Clone` when `T: Clone`. But `&amp;[T]` always implements clone, and simply returns a copy of the slice (using the same underlying buffer). So calling `.clone()` on `Vec` will either return a Vec *or* a slice, depending on the type inside Vec.
Given the low complexity of this program, I think exiting on the first error is acceptable, especially if it improves readability.
I think that this option must be mandatory and even standardized, otherwise you''ll probably have another "gcc's -ftrapv" mess: an option which doesn't even work..
Just work, just work, for a very limited value of "just work".. Try putting some multiplication in your expression and see if you still find wrapping arithmetic so nice..
&gt; while vacuum is, indeed, cold, it's less effective at cooling down engine nozzles than air Is this supposed to be surprising? Vacuum is obviously a very bad conductor of heat owing to its lack of mass. (It's why things keeping liquids hot or cold are called vacuum flasks!)
If you don't mind having `Option&lt;String&gt;` as longest_line and dealing with `.as_slice()` later, the following should work: use std::io::BufferedReader; use std::io::File; use std::result::Result; fn main() { let mut max_length = 0u; let mut longest_line : Option&lt;String&gt; = None; let path = Path::new("test.txt"); let mut file = BufferedReader::new(File::open(&amp;path)); for mut line in file.lines().map(Result::unwrap) { let ts = line.as_slice().trim_right().len(); if ts &gt; max_length { line.truncate(ts); max_length = ts; longest_line = Some(line); } } println!("{}: {}", max_length, longest_line); } Depending on what happens later and your platform it may be worth using `file.read_until('\n' as u8)` to gain a significant performance improvement, converting to valid utf8 later if necessary.
Bit late to the party here, but I really like this idea. We are still quite a ways from building any sort of plugin system or the likes, however I've been thinking about how we could do it. I like the idea of using rust-lua, however I'd *much* rather if we could do it in Rust. Deep Rust integration is something I'd love to achieve for iota, too. So this would be great for that!
I'm the author of Iota (#3 in the list). The emacs keybindings are somewhat temporary. Right now im working on Vim-like modes and keybindings. I hope to have it finished in a week or so, at which time you can ditch the emacs bindings :). The plan is to have a configuration option which will allow you to start the editor with either "vi-mode" or "emacs-mode" enabled, which will allow you to chose your editing experience. Pretty cool that you wrote one of the examples with it! Thanks for checking it out! Really enjoying the series of posts, keep up the great work!
Looks like I've run into https://github.com/DaGenix/rust-crypto/pull/182, update to 0.2.3 fixed the problem. I'll update the article later.
Thanks, that's an interesting option, since Socket already has the Reader and Writer traits, it could have functions returning &amp;Writer and &amp;Reader and that would separate the message related features from the connection related ones.
Nah, compiling without optimization is the common case. The problem only arises when people who are accustomed to dynamic languages (or Java, or any other language where the concept of "optimization levels" does not exist) crank out a blog post where they wonder aloud why Rust is so doggone slow for a systems language. Our only saving grace at the moment is that unoptimized Rust is slower than Ruby, which should be enough to raise eyebrows among anyone who is actually familiar with Rust.
For my own part, I've never used checked arithmetic for my daily coding, so I don't know if wrapping or checked is better. But I want to understand the differences, and what I now need to think about, so I can avoid bugs in my Rust code. So, with wrapped arithmetic it is always true that `a - b + c = a + c - b`, whereas with checked arithmetic one of them could panic where the other one does not. Correct? What more arithmetic properties are broken with checked arithmetic? 
I think that you're right about "a - b + c = a + c - b" but try "(a+b)/2" it doesn't work with wrapped arithmetic even if "a/2 + b/2" fit inside an integer.. So instead of having some cases working "by luck" and garbage in other cases, I prefer having checked arithmetic and having the computer yell at me when I made a mistake.
You're certainly right, there are a lot of reasons to use Rust over C++, and I didn't mean to imply that Rust's advantages are restricted to backend code. Still, I think the safety advantages of Rust are stronger arguments in cases where a buffer overrun can do real damage and an obscure bug might affect a lot of players at the same time, i.e. multiplayer backends. Maybe game developers that are reasonably happy with C/C++ and won't even consider Rust at this point will take a closer look once they see their backend-writing colleagues using it. That said, I don't know anything about the future, so I'm just saying I can imagine it happening this way, not that it actually will :)
Here's another use case for you:- What if you've researched Rust, you want to use it, but you're still uncertain; you could write code in a C++ subset that *does* translate to rust (avoid overloads, have some way of mapping methods to traits..maybe write dummy classes to test instantiating your templates, with a naming convention) - and just transpile to convert over. you could gradually refactor an existing C++ sourcebase until its' friendlier to rust transpiling that way you still get the benefit of the mature C++ environment. it might be that later Rust gets more support for c++ libraries , or once tools appear its' more compelling to use.. eliminate risk of adoption
With deref coercions (`&amp;Box&lt;T&gt;` → `&amp;T`, etc...) and `ref` generalized as a pattern modifier instead of just a binding modifier, I can *almost* see it working. The problem, of course, is that you're relying on the compiler to figure out when you want to do the coercion, and it's not altogether difficult to imagine scenarios where this would be inadequate.
Why both? Pick one and do it well.
If there aren't any Rust bindings for libopencv already, you might look at what can be done to bind the functions you need.
The absolute elegance of this code, compared to the others presented here, is amazing, and it really shows how rust supports just the right amount of functional programming. What performance implications are there in using some of these built-in functions? How would this compare, performance-wise (algorithm speed and memory allocations), to the other solutions presented below?
My concern is what effect is this going to have on the already slow unoptimized builds. At what point is it going to become impractical to build an interactive application with rust because your debug build is too slow to be usable?
I remember reading that blog post. I got the impression that Rust got two orthogonal concepts mixed into the mut feature. Maybe it doesn't matter, maybe it does. It can become awfully a lot to type and consider making API's if you have to consider both.
Here's another short one adapted from rootnod3's, using if let (which I just learned about): use std::io::BufferedReader; use std::io::File; use std::result::Result; fn main(){ let path = Path::new("test.txt"); let mut file = BufferedReader::new(File::open(&amp;path)); if let Some(ln) = file.lines().filter_map(Result::ok).max_by(|x| x.len()) { println!("{}: {}", ln.len(), ln); } else { println!("No such line"); } }
why not?
The fact that it's going to be reporting a unique error for each overflow check greatly limits potential optimization anyway. The branches can't be merged by combining the flags together and then doing a single check.
Does somebody know, what opportunities unspecified values provide for optimizers? Also, two’s complement isn't mentioned anywhere in the post except for the title :D Is it still guaranteed? It can be observed not only through overflows.
Yes, the call to `server_channel` blocks (and now that I think about it, the name of that method is a little outdated. It used to return a pair of channels too, and wasn't renamed when I changed the API to be event-based). That's actually a surprisingly good point that I hadn't thought about, since during testing I just close the server's connection with Ctrl-C, but that wouldn't work in all possible scenarios. I'll have to add some programmatic method of shutting the server down to the API. I don't believe that there is a supertrait that covers both. If I understand it correctly, that would fall under the domain of HKT (higher-kinded types), which is on the roadmap, but more likely to land in Rust 2.0 than 1.0. As for `server_channel` being callback-based, that's not necessarily the API's final design. It does make the code very simple, but at the cost of a little bit of flexibility, which I may rework to add back in.
if let is really only worth it when you ignore the other case. If you _need_ to handle the None case, then match is more readable imho.
Do one thing good instead of 2 things not-so-good. At least that was my thought.
[Comments inline in gist](https://gist.github.com/tupshin/6ec681125e98444684ef)
And how exactly do I de-reference? This: let curr_min = *(pq.top().unwrap()); fails with the error: cannot move out of dereference of `&amp;`-pointer 
No you did not misinterpret. I think it cast negative connotation and was a bad example of civil Rustaceans, so I’ve removed that part. Thanks for bringing it up!
It's not so much that Rust got the two concepts mixed, it's just that they are two sides of one coin. Is it "it's only safe to mutate if this is the only reference" or "This is the only reference, so it's safe to mutate"?
Basically, the blog post below caused a huge argument, it was pretty split down the middle. If it's still confusing, I can try to summarize :)
Clone is one way to escape the ownership issue in this case. There are other ways, and probably preferable ones, but clone should be simple to understand. Also you can reverse your iterator using for item in pq.into_sorted_vec().iter().rev() { Might help you simplify your logic.
If you need more examples of overflows leading to critical bugs you should peruse the previous discussions on the subject both on this subreddit (linked elsewhere in the comments) and in the rust RFCs. It's not a theoretical concerns, it's an actual cause of bugs and security vulnerabilities, for instance: http://www.net-security.org/vuln.php?id=3446 An other thing is the potential for more aggressive optimizations by the compiler. If overflow yields an undefined value then the compiler is free to assume that "a + 1 &gt; a" is always true for any 'a' for instance. If you tell the compiler to assume wrapping arithmetics (as is still currently the case in rust) then the compiler can't make that assumption and has to generate an actual check. 
When in doubt, profile, measure, and then decide. :wink:
Ah, that's a good point. I've never run into that situation myself.
I assumed that the destructor was called as soon as the `Box` went out of scope, like they usually do, but I checked with `valgrind` anyway. When running `cargo test`, and the `perl` script, I got no leaks. The `julia` script leaked like crazy, but I am tempted to blame that more on the fact that `julia` is still in development.
Funny thing about that, is that there is a way of finding averages that is overflow safe: `(a / 2) + (b / 2) + (a &amp; b &amp; 1)` [But this is patented by Samsung](http://www.google.com/patents/US6007232?hl=da&amp;dq=6007232).
It has to leak. The ownership is transferred to the caller (Julia/Perl), so the caller is responsible for disposing it, which it doesn't to.
Good point
Wow, nice timing! I've just published [24 days of Rust - calling Rust from other languages](https://siciarz.net/24-days-of-rust-calling-rust-from-other-languages/), fortunately there's no Julia or Perl there ;-) Anyway the more the merrier!
I agree in general, however I also thought that seeing if let would be useful in its own right. Also, in this case it's not clear to me that the 'else' is useful (I almost left it out, but decided that putting it in would make the relationship to your solution clearer). Depending on the use case, it might make more sense to not print anything in the case of an empty file so as to avoid putting spurious data into a command pipeline. Anyhow, it's just another way to approach the problem that shows a nice feature of Rust that I only learned about myself as of yesterday.
Listen to vhbit, please. He has answered your dilemma and this would be the best solution.
Algorithms can be patented. This is just a particularly simple algorithm.
Hi, this if my first project in rust. It's not yet production ready obviously, but i think it's kinda cool to be able to write a plugin for glibc in rust. I'd be glad to see a review / comments.
These posts are great and this one is my favorite. Thanks for writing and sharing!
&gt; Also, cargo appends a fingerprint to the lib name, so let’s use a Makefile that will fix it so we have an unchanging lib name: Could this be a cargo option? It's useful for anyone that wants to ship a name.so; it would be better to have cargo build handle all of this, instead of having a separate Makefile. Also, the `*` in this code in the Makefile makes me uneasy, ln -fs $(PWD)/target/libpoints-*.so $(PWD)/target/libpoints.so (but fortunately it will error if there's more than one libpoints-*.so, so in practice it's okay)
So, this only works if you're exposing a C interface. Rust doesn't have a stable ABI, so putting out a stable lib name doesn't make sense: you can only be sure it will work with a compiler of the same hash.
I sent you a formatting pull request. :)
Thank you! Anything else that caught your eye?
Especially when they found names imem&amp;umem which are good IMHO.
 let mut lines = file.lines().filter_map(Result::ok).collect::&lt;Vec&lt;_&gt;&gt;(); let mut lines = lines.as_mut_slice(); lines.sort_by(|x, y| y.len().cmp(&amp;x.len())); for ln in lines.iter().rev().take(n) { println!("{}: {}", ln.len(), ln); } Why does only slice have a sort method?
What's the latest on rust-fmt?
I don't care that much about the name as long it is not `int`. IMO, `iptr/uptr` are the best names, but even `potatoe` would be a better name than `int`
I'm the one who implemented all this stuff, and imem/umem look *absolutely awful* in type signatures and when reading code. They don't indicate at all that they are numeric, and the obvious connection "unsigned memory? int memory?" is wrong, it's an integer wide enough to hold a pointer to the entire *virtual* address space, not just the entire memory.
Would love for someone to implement it. 
Another aspect I didn't mention above relates to the COM/DirectX code I've been developing. I may consider contributing code via Cargo, but as I'm using experimental parts of the language, it makes me feel this is premature.
Please don't forget that "inheritance" is backwards compatible, and we have a six-week release schedule. Just because it's not in 1.0 doesn't mean that you're going to have to wait forever. Also, build.rs can serve as a temporary, if not exactly ideal, replacement for procedural macros. Also, macros will be stable, syntax extensions / procedural macros will not. Also I quoted "inheritance" because Rust may not get the kind of inheritance you're thinking of.
(The names correspond to Reddit URLs)
Well, 1.0 for Rust will _not_ mean feature complete, but, from then on, _backwards compatible_. That is, the dev team feels that the language is good enough to be released "into the open". And I believe there are a lot of backwards compatible features which will be added later on, for example Higher Kinded Types or maybe negative trait bounds. You have to understand that "Rust 1.0" might not mean what you think it does. Compare it with C++: Are they at "1.0" yet? Shouldn't things like Concepts be implemented before that? Filesystem access in the stdlib? Modules? Rust 1.0 is simply a point after which things will stay backwards compatible, so people can actually start using rust without compiler updates breaking their code. 1.0 does not mean "no more features after this point". So what has to change is your understanding of "V1", not the release of 1.0.
What experimental features are you using? As steve said, macro\_rules will be stable, but procedural macros(or syntax extensions) will not. Also note that if you use experimental parts of rust, people using stable rust 1.0 will _not_ be able to use your code.
I'd add "concurrent" to that list.
I'd also been playing around with syntax extensions, but realised that those were experimental. That's fine, but the macro seemed to indicate that the feature was unstable to me (the wording right at the start). It's good to know that macros will be stable. Hopefully that will suffice for my purposes. I'll need to get a later Rust download then, and see how I progress with that, trying to limit myself to non-experimental features.
This is a really essential improvement to the language. It's not perfect, but it's definitely a step in the right direction. Some times you really, really want to rely on modular arithmetic -- intentionally "overflowing" and depending on the fact that your machine represents integers using 2's complement. There needs to be a way to safely express this. I propose adding a % (for "modular") to the end of an operator, to indicate that you want modular behavior. For example: let x = 4u32; let y = x -% 5u32; // y is now 0xffffffff Also, can we ***please*** index vectors and slices with `u8`, `u16`, and `u32`, without casting them to uint? I've been working on lots of numeric code lately in Rust, and needing to constantly add `as uint` is fatiguing, and adds no value to the code.
As an aside: I've had some experimental, prototype code for COM bindings for a while now. Do you have anything up I could look at? Depending on where you are, I might be able to contribute something/you might be able to steal something. :P
That's what `WrappedInt` is for, and the usual operator traits would be implemented for it. I think the `%`-suffixed operators would be backwards compatible to add. As for indexing with other types, I know I've seen it discussed.
Servo wants [something for implementing the DOM](http://discuss.rust-lang.org/t/summary-of-efficient-inheritance-rfcs/494). This is currently delayed until next year IIRC.
I don't really see where the idea of 1.0 being feature complete comes from. Are there *any* languages in common use that were considered feature complete at 1.0? Java 1.0 wasn't, Python 1.0 wasn't, C89/C++89 weren't, Go 1.0 wasn't, Ruby 1.0 wasn't, ....
Ack! I got plans for syntax extensions in 1.0! I'm writing them up real-soon-now!
IMO its great for maths , collision code which games have a lot of - to me many interesting functions seem to involve a pair of types - see also the julia language which goes for multi methods as its means of organisation as a good solution for it's domain; I would prefer to start with adhoc overloads and then look for more ways of working *with* that, e.g. add keyword arguments. Also imagine using it in conjunction with Rusts' type annotation syntax e.g. do_something(x,y:Foo,z:Bar,w) // I can still be specific. do_something_foo_bar(x,y,z,w) // which parameters do '_foo_bar' postfixes refer to? you get to intersperse meaning with parameters. Another more direct way of doing that is to use constructors wrapping individual parameters , further encoding meaning.. create_window("title", Rect(topleft,size)) thats' quite similar to the kind of code you can write with enums. What I like about adhoc overloading: you're leveraging names that you've already given to the compiler - you're increasing their meaning .. "say it with types". Wheras with traits you're having to name something that doesn't exist. Naming is hard, but this way the machine helps. r.e. the downside of not seeing what call is being made, again imagine just giving the compiler a tool to pretty-print calls with types annotated ... with so much inference in Rust you'll want your tools to be able to do that anyway. Decent C++ IDE's have proven the ability to give accurate jump-to-definition - which is worth more, imo Rust can still do overloading, before with double-dispatch, and now with multi-parameter traits.. its just more verbose. and of course there's nothing about having adhoc overloads that *prevents* you from naming specific functions. combined with UFCS/extention methods you could make more use of positional significance too ('the receiver'). Lastly, what I most want to escape from C++ is this idea of making one parameter 'significant'. And sadly Rust actually made it *more* significant, because its the one parameter you *can* overload on... so the upfront choice matters more. Thats why I want UFCS, to move away from methods/receiver being special. ... write overloaded free functions - then gather them into duck-typed interfaces or switch dispatch (sort by type or sort by function, without any up-front choice baked into the syntax). And given the amount of code in the world that *uses* overloading already, isn't it more productive to add ways of using it instead of removing it (thereby asking people to throw existing work away)
Hm... so, what's going to happen with 1.0 and experimental features anyway? Is there going to be a rustc flag for --stable that prevents compiles linking to experiemental things? Or does it just mean that you can continue as is using feature gates, which the caveat that any experimental / unstable things you use will not be backwards compatible? ie. If there's no compile error to using them, there's nothing to stop you using the features which are experimental when 1.0 ships (eg. syntax extensions), as long as you realize you'll hit some code churn every 6 weeks.
A comment in wycats post. "This is just a taste of how to use Rust from Ruby. I didn't cover freeing memory or exception safety, which will be the subject of future posts (soon!)."
&gt; Maybe game developers that are reasonably happy with C/C++ I don't think people are 'reasonably happy with C/C++' .. I curse aspects of it all the time. its just 'the least bad option' and we're stuck with it because of momentum that's so hard to break (see above). The buffer overruns etc aren't really a serious problem IMO - you could make a C++ subset that avoids these (add in-house lints, clang really opens this up). Its' everything else, the headers, the clunky syntax, the lack of reflection. There's lambdas now, which allows doing things with an internal iterator style thats' less error prone IMO. Anyone sane craves an alternative - then when presented one we see omissions and think "ah, actually I really needed that..". But everyone needs a different subset of C++, which is why we all hate something about it.
I'm on mobile, so I'll just point you to http://blog.rust-lang.org/2014/10/30/Stability.html
r.e. making a macro-driven object model ... is there any possibility of generalizing the concept of a vtable between internal and external rather than baking in these ideas .. then moving 'trait objects' themselves into library code. I recall it was possible to fake 'internal vtables' by some unsafe tricks starting with trait objects, (creating a trait objet at the call site), perhaps Rust could gain mechanisms to just express that safely ('this vtable contains functions compatible with this struct layout',...) Is there a way this could be done backward compatible ... are there any changes to the syntax for trait object that might enable this, or could the existing X as Y mechanism be overloaded..
I'm not a fan of it either, looks like a hack, but beats my first version which went like this: v.next().and_then(|name| v.next().and_then(|passwd| v.next().and_then(|s_uid| from_str::&lt;libc::uid_t&gt;(*s_uid).and_then(|uid| v.next().and_then(|s_gid| from_str::&lt;libc::gid_t&gt;(*s_gid).and_then(|gid| v.next().and_then(|gecos| v.next().and_then(|dir| v.next().and_then(|shell| Some(Passwd { name: name.to_string(), passwd: passwd.to_string(), uid: uid, gid: gid, gecos: gecos.to_string(), dir: dir.to_string(), shell: shell.trim_right().to_string() }))))))))))
I can see where you're coming from. From my perspective: - I don't use a decent C++ IDE because there are no good C++ code navigators for vim. This is something of a self-imposed handicap (I would use such a navigator if it existed), but I don't use a Rust IDE because none exist, and anyway - - I don't think you should need tool support just to be able to tell what some code does. This is just sloppy design, as it pushes things under the surface, and you won't get the support anywhere other than the IDE, e.g. GitHub. This is exacerbated by C++'s implicit conversions, which have on at least one occasion made me spend several minutes trying to figure out a single overloaded call. Rust isn't quite as tricky in that regard, but recently it's been getting a lot of implicit conversions in the form of FromX and Deref traits... - If the operation of different overloads for a given method is different, not having separate names is both confusing and makes the available functionality harder to remember. For example, with the STL, I have to remember that `vector::insert` takes either a count and a value, or a start and end iterator. This is *probably* not going to be ambiguous if seen in existing code, but it is definitely harder to remember than, say, `with_repeated` and `with_iterator` methods. Java is much worse: `List::remove` will either remove the element at a given index, throwing if invalid, and return that element - or search the list for a given object, returning whether it was found as a boolean rather than throwing. I don't generally use Java, but I'm sure this can cause confusion when skimming code as to which semantics a given `remove` call is using. Outside of standard libraries, where there's less stringent design, there are much worse artifacts. I've seen quite a few methods, usually in generally poorly written code, whose operation really fundamentally differs depending on the type or number of arguments, in very confusing ways. I guess you can't stop people from writing poor code, but easy overloading is an unnecessary way to blow your foot off, as they say. (If you use multi-parameter traits to fake ad-hoc overloading, at least you know you're doing something weird. But I don't like the existence of that functionality in the first place.) - If the operation is the same, but a given argument can merely come in multiple forms, then using a trait for those forms works fine in Rust and reduces boilerplate, as it's quite likely that other functions will also want to be able to take that set of forms. - If the operation is the same, and overloading is used to add flexibility to what arguments need to be passed, things just get ugly. Then there are things like this: http://qt-project.org/doc/qt-4.8/qpainter.html#fillRect I guess it's easy to use? At least all versions of `fillRect` have the same semantics and return type, but the overloads certainly enable confusion as to what a particular set of arguments to `fillRect` are meant to be. More importantly, they require a completely pointless tract of boilerplate to implement, the type of code that indicates a missing language feature rather than that the features it does use should be emulated! Namely - - Keyword and default arguments are nice; I think Rust probably should have them. But I see them as more of a replacement for overloading than a companion. After all, if you could say `fillRect(rect, brush=..., color=...)` then you wouldn't need more than one overload. (You wouldn't be able to pass bare x/y/width/height under this scheme, but who cares - adding the `QRect()` around that is not much extra verbosity.) This also applies to your `create_window` example. Not that it really matters, but - in Python, my experience is that this functionality is generally sound and useful, but has warts. For example, if you have a function that wraps another function, unless you do straight argument forwarding, you need to reprint all the second function's defaults and, for that matter, all its arguments, which can start to become cumbersome with the large numbers of arguments that keyword support encourages. I think there is a really elegant design for keyword arguments for someone to invent, but it's not exactly the way any existing language does it. - Regarding the amount of code that uses overloading: there is also a lot of code that uses traditional subclassing-based polymorphism. None of it is written in Rust, though, so there's a good opportunity to look for better options.
&gt; I don't think you should need tool support just to be able to tell what some code does. This is just sloppy design, as it pushes things under the surface, and you won't get the support anywhere other than the IDE, e.g. GitHub. this could be built into the compiler. ( well, I have a theory that committees keep C++ unecaserily awkward to sell tools - because its visualstudio/xcode that keep me going back to a proprietary OS, but thats' not the fault of overloading*). Imagine something like a query operator or a `--info filename:pos:line` option. Then it would be trivial for anyone to stick info into any editor, just as easily as you can make emacs automatically grep for a rust definition (thing-at-point) **Rust wants this IMO for its type inference anyway** .. its currently quite hard to divide rust functions up, because you don't know the types inside a function body. But I don't declare "type inference" a misfeature, I just want more tools to work *with* it. (and in my pet-language, I've added template sugar, just miss out the types for writing trivial helpers, or imagine if you had full inference within a module) You need way more beyond what you see on screen , even in rust - where there is deep namespacing - you still have to navigate ambiguity to see what a function is. Programs involve information from many sources, and the purpose of computers is to help humans deal with more information :) it makes perfect sense that our programming tools have good searches built into them. "find me all the functions that use a certain type.." I would agree that clearly marking inputs &amp; outputs would be helpful- I see why the google style guide says "pass a pointer for output parameters". Rusts tuples make multiple return values easier. UFCS would make it easier to "make the receiver be the thing that is modified". If an output is clearly marked, it would be easier to guess whats' going on. &gt; For example, with the STL, I have to remember that vector::insert takes either a count and a value, or a start and end iterator. i've never been a fan of c++'s std libs, but thats not the fault of the language engine; that could be fixed with Ranges, and overloading would make that very clear. I've never really liked STL iterators. I'd prefer interfaces with internal iterators taking lambdas, and C++ had a language omission for so long so we don't have that. Also no UFCS /extention methods stops us bolting nicer interfaces onto the std lib types ourselves. i'd agree 'the same name function should have the same semantics' - but that again is not the fault of the language. In rust land they have functions namespaced under traits, isn't that just allowing the same ambiguity - now you have to look at two names to figure out what one function does... might it just be better to encourage consistent method names. And the lack of overloading makes the traits compulsory, so you extra micromanagement involved. my complaint with conversion operators is that they must be class methods. UFCS is the feature i'm craving. I think i could live without conversions, but overall i would like to build as much on the basic function call mechanism as possible (keywords/defaults, overloading, variadic) - in Rust I think it's slightly messy that you have to mix two mechanisms (macros &amp; functions), reminds me of the mixing of templates &amp; functions in C++ a little. What about ADTs, and the expression-problem. imagine if the enums were composed (join types?) and the individual variants were accessible as types themselves; then you could write overloads for functions that access them, and build up something like pattern matching at the function level to handle enum dispatch. you could write functions one way, and they'd be gatherable both into 'switch' like dispatch or a 'vtable interface' ... I think that would be very versatile - not forcing one architecture or the other upfront. an of course instead of the verbosity of the visitor pattern, a language could gain dedicated support for multi methods &gt; which can start to become cumbersome with the large numbers of arguments that keyword support encourages. .. again not the fault of the language. Defaults&amp; keywords are extremely useful for *small* numbers of parameters, IMO, e.g. 2-3 args and you frequently want to omit 1 eg `fn slice(&amp;self, from=0, to=self.end)` now you have `.slice()` `.slice(from=)` `.slice(to=..` `.slice(,)`) etc expressing 4 helper functions from 1 definition - 1 definition showing up in autocomplete or documentation, and 1 definition to navigate to. I guess i'd quite happily accept a lint saying "too many arguments, use a parameter struct instead.." anyway .. for low level code on consoles i've dealt with a plethora of datatypes (needed for optimisation) and it just gets crazy having to manually name a gazillion variations. a multitude of types which are semantically the same but using different packed formats. row major, column major.. various compressed formats sometimes one is faster than the other. Sometimes you want aligned, sometimes you don't. In these instances you are indeed making something semantically the same, but with many low level variations. Overloading helps because its' doing the job of searching for the programmer. (I want to do this to these objects, compiler, please find me the right function..) 
What's wrong with that, other than having a lot of parentheses?
Nothing other than that and the fact that when formatted "properly" it would shift towards right super quickly. I wonder if some kind of do notation would be possible with rust macro system.
Map.as_bytes() does exist -- that would be serialization.
:o :o :o Is it the freeze-AST-sans-wildcard solution discussed in the workweek? I thought we didn't like that solution :p
&gt; I don't think people are 'reasonably happy with C/C++' That's just not true. Even with all the problems, quite a few people like C or C++. I've seen them :) They might still be better off with Rust, but they'll need convincing to even look at it: - Quite a few languages have come along and claimed they can replace C++ (Go being the most recent one I can think of) while not being able to do what C++ can do (in the case of Go because of the garbage collector, for example). Rust is different, but how would you know unless you look at it? - Even if someone were convinced that Rust is theoretically better, a really experienced C++ developer will lose a lot of productivity when switching to another language and will take a lot of time to regain it. That's why I think that some developers who otherwise wouldn't even try Rust (for good reasons!) might be swayed by exposure to it from related fields.
There are do notation macros, like [this](https://github.com/TeXitoi/rust-mdo).
To expand on your last point: if you're going to rely on checked overflow and can live with the performance cost, you most likely want bigints instead.
I think that a court would rule that this is a math formula instead, [see this ruling](http://arstechnica.com/tech-policy/2011/08/appeals-court-says-only-complicated-math-is-patentable/).
An experiment I conducted on rustc itself (and its libraries) detected remarkably few places that had int overflows, so I think that special operators are not warranted. We'd be fine with just the intrinsics for wrapping ops; but if people want Wrapping&lt;T&gt; for convenience, it can be implemented as a library.
I don't think people are expecting 100% feature completeness, but I do think the idea of having features (that some would consider fairly major) planning to be implemented within months of 1.0 takes some people by surprise. 1.0 tends to be a point of some stability (as in no added features, not just backwards compatibility), but Rust can give off the vibe of powering on forward, feature-wise. Which isn't an issue at all - the backwards compatibility is there, but it's not really what people are used to.
Dude, you're cool. 2 super-intelligent persons, whom I highly respect, Eliezer Yudkowsky and Ron Maimon, both think that one of the most important traits of an honest and virtuous person is an ability to say “oops, sorry, I goofed” and move on. - [The Importance of Saying “Oops”](http://lesswrong.com/lw/i9/the_importance_of_saying_oops/) - [Internet as a platform for discussing ideas](http://www.quora.com/What-are-the-advantages-and-disadvantages-of-the-Internet-as-a-platform-for-discussing-ideas/answer/Ron-Maimon)
Why is there a need for a separate '#[no_mangle]' ? When does someone want to export a mangled C function?
Thanks, I'll make sure to check out those 2 links ;)
&gt; If there were write_Map_to_disk() and read_Map_from_disk() functions that would be great, however, there is not. That would assume there exists a single representation of on-disk maps which is unlikely. Though there is built-in support for JSON encoding and decoding. &gt; Do you guys/girls have any advice? Am I missing something? Am I thinking about this the wrong way? There's a `serialize` crate which defines encoding and decoding protocols (currently used by JSON). You can use that system for your own serialization format. &gt; #3 seems very expensive and coming up with/parsing a binary format seems hard/annoying. My first thoughts on the binary format are: Why not reuse existing serialization formats (binary or not)? There's a whole cottage industry of those.
Maybe cargo could have a clib section, or a clib crate type, checking that a C API is exposed and not mangling the library name?
Note that most of its mechanisms are probably UB now, the old runtime had deoptimized TLS access to prevent certain issues, and that is no longer the case AFAICT. Rust doesn't, and likely never will, support such a model in its standard library, you need to pretty much have custom versions of it with the runtime still in.
Are you saying that the "functional programming" one was also faster?
C callbacks don't need to be mangled. IIRC the reason for the explicit 'no_mangle' is because there are cases where you don't need to call C functions by name from another language, and it would be possible to accidentally create symbol collisions. Writing 'no_mangle' forces you to acknowledge that you might be duplicating a name that exists somewhere else.
About point #1 - is it possible to bootstrap the current Rust version from the OCaml version? Actually, I mean, is there a script to do so?
I actually have a pr in the world queue that adds support for [this](https://github.com/rust-lang/rust/pull/19927), as well as download resumption and hash verification. Great minds think alike :)
&gt; I'm the one who implemented all this stuff, and imem/umem look absolutely awful in type signatures and when reading code. They don't indicate at all that they are numeric, and the obvious connection "unsigned memory? int memory?" is wrong, it's an integer wide enough to hold a pointer to the entire virtual address space, not just the entire memory. How does `imem` indicate less that it is numeric than `i64`? And the obvious connection suggested by `int` is arguably more wrong. Any 4-letter name will not be completely self-documenting. I don't care much about the name (all names that short will suck in some way). Choosing `int` just means that we will have to work a lot harder to teach people which types to use. At the moment, almost every use of `int` I see on github is wrong.
Never, because it's still going to be faster than Python that people actually ship as production software.
I mean, there's an enormous stream of fairly major features that should/will be implemented for Rust - off the top of my head: externally loaded syntax extensions, fully hygienic macros, full support for associated items, higher kinded types, Gabor's error handling syntactic sugar stuff, and generic specialization/negative bounds. That list is a subset of the things that we're *already* pretty sure we want to do. That list will also take at least 1-2 years to implement. At a certain point, you have to say "this is good enough" and cut a release, or Rust will turn into Yet Another Obscure Research Language instead of a thing that people actually use to solve problems. I have plans to stabilize the syntax extension API pretty quickly after 1.0, but I would much rather have a real 1.0 now than block on syntax extensions.
Having to use `man rustc` to find out what the options for `rustc` are seems pretty reasonable, and simpler than searching through a guide (for non-Windows users, anyway).
Putting too much information in a guide leads to a bloated/noisy guide. One might as well leave a link to how command line programs tend to be structured/built up, for those who are not used to that.
&gt; Why not reuse existing serialization formats (binary or not)? There's a whole cottage industry of those. Because they all have one thing in common: they are meant for data transmission, not for storage. Storage has different needs: * Data should stay at the same location on change * It plays well with caches (disk buffers, etc.) * It doesn't need to be fully loaded or fully written * It provides a fast path to any piece of data (or, alternatively, this is solved by an index) Have a look at https://github.com/couchbaselabs/couchstore/wiki/Format for an example of an on-disk format. Alternatively, have a look at leveldb.
In the release builds, you will not be able to use experimental features. They will be available in the nightly builds, feature gated and with no stability guarantees, similar to how nightly builds currently work. So if you're using experimental features, you'll need to use the nightlies, keep up with changes and fix things as they break. If you use just the release builds, you should be able to depend on stability.
Latest binaries are available at www.rust-lang.org. They're also providing rustup.sh for downloading and installing Rust and Cargo.
I have no real contribution other than to say thank you for the effort you put in! Jumping between topics like that must be quite tricky. You are a machine :)
Would it webscale properly without MongoDB?
If you're set up for homebrew, I believe you can leave off the sudo. At least, I don't run it with sudo and it works fine but I might have tweaked a permission somewhere a couple months ago.
Thanks again for this series.
I personally like to use homebrew for managing installed tools, so I created myself a small script that downloads the current nightly Rust and Cargo and links it to the system using homebrew. This way I can easily update, uninstall or switch to a different version. https://github.com/zargony/dotfiles/blob/master/bin/update-rust-nightly
I've been working on my own set of DirectX bindings and have been using a few macros here and there to simplify the process, but the majority of what I've been doing has been going into a code generator that parses the DirectX headers and spits out generated code, similar to how SharpDX is doing it for C#.
1.0 is not the end. The plan is to release a new 1.x every six weeks.
Great series - thanks, dude! Merry Christmas! :)
It's not fully complete, but actually there is a big part of the original package (I think). If you have some advices on the API design, tell me, as the actually API isn't as nice as I wanted to. :(
brson has also been working on an rvm/virtualenv-like tool, https://github.com/brson/multirust
How will this interact with casting between integer types, such as `int::MIN as uint` or `257u16 as u8` ?
That sucks. But I assume that was fundamentally an issue with the specifics of libgreen's implementation/requirements? Or are there issues with the new runtime that preclude the possibility of building any sort of efficient green threading on top of it?
You already create a Vector on line 80, why not just index into it instead of iterating? You can even define static named indices i.e.: static NAME_IDX: uint = 0u; // .... Some(Passwd { name: xs[NAME_IDX].to_string(), //... 
I'd recommend against this, honestly. Rust works just fine installed locally, so if you only need it from one account you should use the `--prefix=` argument when you run the script to install it to a local directory, then add said directory to your path. This way you don't need to run it with `su` privileges.
Because very few OS's will put nightly software in their repos. Ubuntu has ppas, but even then it's more reliable to just update it yourself.
Out of bounds on malformed input
Because a ppa relies on someone updating it every day when the nightly comes out. Personally, I install rust locally so I'm not running a foreign shell script as a privileged user.
Ah, I didn't know about that ppa. But what if someone's OS doesn't have some mechanism like that? I agree that it's not a secure distribution method, and I'm hoping it'll change after 1.0.
:) If there's no alternative, then yeah, rustup.sh or building yourself from instructions on the repo makes total sense. I just like to aggressively push package management solutions so people get in the habit of trying to do that first. I mean, why not! PPA is a vastly superior end user experience (granted that it's like this PPA or thestinger's Arch repo), in my opinion. &gt;I agree that it's not a secure distribution method, and I'm hoping it'll change after 1.0. I'll be curious. For those wanting the latest and greatest, presumably it will still be encouraged.
&gt; I just like to aggressively push package management solutions so people get in the habit of trying to do that first. I mean, why not! PPA is a vastly superior end user experience (granted that it's like this PPA or thestinger's Arch repo), in my opinion. Agreed. &gt; I'll be curious. For those wanting the latest and greatest, presumably it will still be encouraged. My hope is that a single script will suffice for a while - no being "required" to download the script again every time. That means you can manually check in the first time, then never re-download it - no risk of running a malicious script.
Hehe, I want that too, but think about the implications. If the build process ever changes (outside of things below the Makefile) then what do you do when the pre-installed rustup.sh becomes out of date? (You'll wind up wishing that you had encouraged users to update it regularly. Now maybe they're missing incremental updates). Not a fun problem to solve. Fortunately my projects compile fast enough that providing docker container defintions to host the build process provides for all of the isolation and fast clone-to-dev time that I need. Clearly Rust is a different beast, and much as I might like, I can't think of a vastly superior option to the status quo - other than versioned, trustable binary artifacts (Which of course I don't expect rust to be providing for nightlies. I mean... maybe I kind of do, given where Rust sets the bar, but I'm not complaining).
Yeah, that was a stupid excuse :) You're probably right and I'm just tired of writing C(-style) code.
24 days in a row! You the man!
Nice. BTW, if your structures are `Copy` (and they are), there is no reason to provide both `fn to_something(&amp;self)` and `fn into_something(self)`, you can just as well leave only the latter one and rename it to `to_something(self)`, because `Copy` types are not moved, they are, well, copied.
This can be done automatically. There are is a repository with daily Emacs packeges for Debian (and thus Ubuntu etc) for example. But this is the exception. Despite Debian good with Python packages, occassionally you need to use "pip" to get the newest stuff. 
Neither does C++ force you to use objects, and nor is C++ a low-level language.
Can someone ELI5 what are the responsibilities of a browser engine? I saw that Servo implemented XHR themselves, a thing I thought to be a part of the JS engine like spidermonkey. I thought that Servo, as a browser engine should only handle rendering the web page, parsing HTML and CSS and that's it. I'm obviously wrong, can someone explain?
Due to (performant) interopt with C, I cannot see a reason why Rust would not use twos-complement.
Why are those new types rather than using the one from `std::io::net::ip`?
The browser engine is supposed to parse the webpage source, fetch resources, render the page, and handle interactions. It's a JS engine's job to implement types like `Array` and `Number` and `String` in JS. The web-specific types (XHR, `Node`, `Document`, `Window`, `Storage`) are part of the DOM. Handling javascript is the job of the browser engine too, however usually there's a JS engine that we can subcontract the task out to, with hooks for the DOM. IIRC the JS engine is part of the browser engine, and it need not be a standalone component like Spidermonkey. But afaict all modern implementations have a clear boundary between browser engine and JS engine, however it is always the browser engine that implements the DOM.
Oh thanks, I didn't know exactly when implement into_/to_ functions, so I've implemented both, just in case. :)
At the start, I've wrote this library using standard types with an extending trait `IpAddrExt` with implementation on `IpAddr`. But with this API, it wasn't possible to implement `Add`, `Sub` and others traits to my trait `IpAddrExt`. More, using one struct for each IP version is useful to do more specific operations (like returning a `[u8, ..4]` for IPv4 instead of one `Vec&lt;u8&gt;`). Well, actually it's not really used, but I think having the possibility to do specific operations could be useful :)
Thank you, you will help the generations of rust developers to come
 trait Set&lt;T&gt; { fn set(&amp;mut self, T); } struct MyStruct&lt;A, B&gt; { a: Option&lt;A&gt;, b: Option&lt;B&gt;, } impl&lt;A, B&gt; MyStruct&lt;A, B&gt; { fn new() -&gt; MyStruct&lt;A, B&gt; { MyStruct { a: None, b: None, } } } impl&lt;B&gt; Set&lt;i32&gt; for MyStruct&lt;i32, B&gt; { fn set(&amp;mut self, a: i32) { self.a = Some(a); } } impl&lt;A&gt; Set&lt;String&gt; for MyStruct&lt;A, String&gt; { fn set(&amp;mut self, b: String) { self.b = Some(b); } } fn main() { let mut my_struct = MyStruct::&lt;i32, String&gt;::new(); my_struct.set(0); my_struct.set(String::new()); } this would be ok
Think about what happens when someone tries to instantiate something like `MyStruct&lt;int, int&gt;`.
I pretty much assumed there would be simple, straight-forward answer that would leave me feeling kind of stupid. :) Thank you!
if you have a good way to distribute "installer", why not distribute rustc and cargo along with it? 
hansjorg did a great job setting it up (and it supports multiple versions with update-alternatives), but I think it would be good to transfer ownership to the Rust team to make it the "official" PPA for Rust in the future. Does anyone know of a similar PPA for Cargo? The cmrx64 PPA does not seem to do nightlies.
[DOM objects](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model) are usually native code data structures — C++ traditionally, Rust in the case of Servo. These objects represent the structure of the document; as such, they are the input to layout, which needs to be fast and is also implemented in native code. A JS engine like SpiderMonkey or V8 is not necessarily tied to the Web platform — see [Node](http://nodejs.org/) for an example. SpiderMonkey provides hooks that Gecko and Servo use to create JS objects and bind their methods to native-code procedures. When you use a `HTMLBodyElement` object from JS in Servo, you're actually calling [Rust trait methods](https://github.com/servo/servo/blob/0e6304dcf7fd6712f4455151b55a361de857359d/components/script/dom/htmlbodyelement.rs#L56-L66) through these wrappers. A lot of the glue code is auto-generated from [WebIDL specifications](http://www.w3.org/TR/WebIDL/) by an [enormous Python script](https://github.com/servo/servo/blob/master/components/script/dom/bindings/codegen/CodegenRust.py). Servo inherited this script from Gecko and in fact some unused parts of it still print C++! `XMLHttpRequest` is handled much the same way as a document node. XHR doesn't participate in layout [1] but it still has some special powers — it can make network requests that JS code isn't otherwise allowed to do. So it's natural to have a native code XHR object in the browser engine that talks to the native code network stack. If XHR was implemented in SpiderMonkey then it wouldn't integrate properly with the browser's implementation of DNS caching, HTTP optimizations, SSL/TLS, same-origin policy, [CORS](http://en.wikipedia.org/wiki/Cross-origin_resource_sharing), proxy and privacy settings, etc. Of course the interfaces provided by a browser don't *all* have to be native code. One example occurs when you load a [JS polyfill](https://remysharp.com/2010/10/08/what-is-a-polyfill) for a missing browser feature. It is possible to implement [much of the DOM in JS](https://github.com/andreasgal/dom.js/), using features like [ES6 proxies](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy). In fact, this was the plan for Servo initially. Instead we ended up with a native code DOM, but we have some [cool new ways of managing memory for it](https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/). In the future we plan to merge the JS wrapper and native-object allocations. We'll have a single contiguous object in memory with some fields that are used by SpiderMonkey and some that are used by layout and other Web algorithms. I hope that actually works because it'd be neat and should perform really well! For more info on what a browser engine does, check out mbrubeck's [excellent series of articles](http://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html) and the [Servo talks from the November SF Rust meetup](https://air.mozilla.org/bay-area-rust-meetup-november-2014/). [1] I'm like 95% sure of that, but after a year and a half spent implementing the Web platform, nothing would really surprise me at this point.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Cross-origin resource sharing**](https://en.wikipedia.org/wiki/Cross-origin%20resource%20sharing): [](#sfw) --- &gt;__Cross-origin resource sharing__ (__CORS__) is a mechanism that allows many resources (e.g., fonts, JavaScript, etc.) on a [web page](https://en.wikipedia.org/wiki/Web_page) to be requested from another [domain](https://en.wikipedia.org/wiki/Domain_name) outside the domain from which the resource originated. In particular, JavaScript's [AJAX](https://en.wikipedia.org/wiki/AJAX) calls can use the [XMLHttpRequest](https://en.wikipedia.org/wiki/XMLHttpRequest) mechanism. Such "cross-domain" requests would otherwise be forbidden by [web browsers](https://en.wikipedia.org/wiki/Web_browsers), per the [same-origin security policy](https://en.wikipedia.org/wiki/Same-origin_policy). CORS defines a way in which the browser and the server can interact to determine whether or not to allow the cross-origin request. It is more useful than only allowing same-origin requests, and is more secure than simply allowing all cross-origin requests. &gt; --- ^Interesting: [^Same-origin ^policy](https://en.wikipedia.org/wiki/Same-origin_policy) ^| [^XMLHttpRequest](https://en.wikipedia.org/wiki/XMLHttpRequest) ^| [^Internet ^Explorer ^10](https://en.wikipedia.org/wiki/Internet_Explorer_10) ^| [^Web ^Messaging](https://en.wikipedia.org/wiki/Web_Messaging) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cn57bdk) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cn57bdk)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I think you better ask in #rust-gamedev, you'll get an answer faster. Piston is frequently broken.
Returning a fixed-sized array is nice because it doesn't require a heap allocation.
It looks like Cargo doesn't like you having a space in `/Users/xxx/Google Drive/Projects/Rust/...`. See [this issue](https://github.com/rust-lang/cargo/issues/1015). 
Tip: running `cargo doc --open` builds the doc and opens it in your browser for you.
Are you sure? I was thinking that the compiler could check only once the overflow flag and if there was an overflow, do again the computations to identify where the overflow happened.. This slow down the slow path (there was an overflow) but I don't think that this is an issue..
That's terrible.
Just thank you! My personal bests are docopt and Fuse!
Agreed. I kind of alluded to that in the TODO list in the lib.rs docs. 
One way to make this work would be through wrapper structs: trait Set&lt;T&gt; { fn set(&amp;mut self, T); } struct MyStruct&lt;A, B&gt; { a: Option&lt;A&gt;, b: Option&lt;B&gt;, } impl&lt;A, B&gt; MyStruct&lt;A, B&gt; { fn new() -&gt; MyStruct&lt;A, B&gt; { MyStruct { a: None, b: None, } } } struct MyFst&lt;'a, A: 'a&gt;(&amp;'a mut A); struct MySnd&lt;'a, A: 'a&gt;(&amp;'a mut A); impl&lt;'a, A, B&gt; Set&lt;A&gt; for MyFst&lt;'a, MyStruct&lt;A, B&gt;&gt; { fn set(&amp;mut self, a: A) { let &amp;MyFst(ref mut ms) = self; ms.a = Some(a) } } impl&lt;'a, A, B&gt; Set&lt;B&gt; for MySnd&lt;'a, MyStruct&lt;A, B&gt;&gt; { fn set(&amp;mut self, b: B) { let &amp;MySnd(ref mut ms) = self; ms.b = Some(b) } } fn main() { let mut my_struct = MyStruct::&lt;i32, String&gt;::new(); MyFst(&amp;mut my_struct).set(0); MySnd(&amp;mut my_struct).set(String::new()); } Edit: updated with a working example.
How about Rust's Auto Compiler Compiler?
There's a Ruby project called racc, FYI: https://github.com/tenderlove/racc Probably won't be an issue, but you could improve your Googlability by calling it something else, like "rucc" perhaps? Then it's just "Rust Compiler Compiler"
What do you mean by ancient glibc ABI? Also, the rustup.sh script seems to download this exact package, by calling on download_package() this, &gt; /usr/bin/curl -f -o ./rustup-tmp-install/rust-nightly-x86_64-unknown-linux-gnu.tar.gz https://static.rust-lang.org/dist/rust-nightly-x86_64-unknown-linux-gnu.tar.gz
Can you make that table less scroll-y?
Awww, that's unfortunate. I'll think about a better name... Someone suggested "raccoon". =) 
&gt; What do you mean by ancient glibc ABI? It's built against glibc from CentOS 5 or 6. This means it calls into legacy versions of some functions. &gt; Also, the rustup.sh script seems to download this exact package, by calling on download_package() this, Yes, I'm aware that it downloads that package - it's not the same nightly as in the one on Arch's official build server (pkgbuild.com). It doesn't eliminate the redundant files with symlinks/hardlinks and the downloads are much larger since it's not using xz compression + deltas.
Is there a reason why there cannot be a .to_x method for all types x?
Merry christmas ol' chap! Nice work on the image finder and thanks a ton for the contributions to Conrod! It's definitely still early days but she's getting there :) Looking forward to getting back to work on it soon to get ready for 1.0!
Not all values can be converted so either to_x would have to secretly panic if it found something wrong (bad) or it would have to return junk. Also a lot of conversions are ambiguous so you have to explicitly state what you want.
The GUI has to be enabled with a specific command-line flag, so by default it will operate purely in terminal. If you try to run it in GUI mode in a CLI-only environment it will just panic and exit (OpenGL functions will fail to load). It can be set to print JSON that can be piped into another script to manage the images. I have yet to get around to documenting the JSON structure. I was working on a `gui` feature branch which I then merged back into master which was, up to that point, CLI-only. I probably should have kept it that way. Perhaps I might keep another branch or fork that is CLI-only and doesn't require Freetype or SDL2 to build and doesn't have the GUI flag. Or just add build configuration attributes that disable the GUI at build time. The latter would be preferable if Cargo supported build config flags.
And once again this proves that `int` and `uint` should have been renamed because they appear among the primitives while types such as `i32` and `u32` do not. They are being used as default arithmetic types *everywhere*.
You should most likely not be using `int` unless you know what you're doing. Use `i32` instead.
https://i.imgur.com/xPZRD4c.png Joke aside, nice work!
This may be a bit out of place, but I've always sort of been curious what YACC's use case is. I've never properly looked into it. Since you wrote this, maybe you could tell me from your perspective. What would be a good project where you'd consider building an LALR parser?
Or YARCC, for that piratey vibe? When I design a language, it will start with a letter no popular language starts with, so there will be no acronym collisions.
Hello, That's quite cool indeed, I had thought of doing this for a long timeto work with my RustLex (https://github.com/LeoTestard/RustLex/), but had no time to do it. Out of uriosity: I notice you have the code of the original YACC on your repository, which thus contains mostly C. Did you actually reimplemented automata construction and code generation in Rust, or do you just have a wrapper syntax-extension that uses the old YACC under the hood ?
And why not?
I really love it. The more we have in Rust, the better.
I'm pretty sure the Rust bandwagon is rolling; having one of the larger FOSS companies behind something helps gain a lot of momentum. Rust is in most system programmers' headspaces. If you go to, say, r/cpp, Rust is mentioned quite often, for example.
Aww, I kind of like the scrolling ;) It lets you pick exactly what you want to see and hide the rest! I originally had the table be less wide which made some of the code lines wrap, it was a little weird but maybe not as weird as the scrolling. Let me try putting that back, that would be better for printing too.
See also libpnet: https://github.com/libpnet/libpnet
Mesa's glsl parser uses bison ("GNU yacc", essentially). You could browse https://github.com/search?utf8=%E2%9C%93&amp;q=extension%3Ay+%22%25token%22&amp;type=Code&amp;ref=searchresults for inspiration, but generated parsers are quite popular to use whenever text needs to be parsed.
Ah, yep, I *don't* know what I'm doing. Should I be using f32 also? Can you point me to some documentation explaining this? [The rust guide just uses `i` in its examples](http://doc.rust-lang.org/guide.html#variable-bindings), so I don't know any better :-/
Thank you!!! &lt;3
Yeah I've definitely made some assumptions with these conversions, like String to char assumes that either your String is length 1 or you want the first char of the String, which might not be what you want at all!
No, rustc only generates code, it won't execute it. There are no performance improvements to be had just by sticking a JIT in the compiler. https://github.com/murarth/rusti/blob/master/src/rusti/exec.rs does this with librustc and linking to llvm.
Yeah I have no idea what I'm doing. Should I be using f32 also? Do you know of documentation about this that I could read, either definitive explanations of what we should currently be doing or discussion about the potential rename? I did find these RFCs and their associated comments that look relevant: https://github.com/rust-lang/rfcs/blob/da7d52ec07d3683b23532e6ff0f18e639d7c7957/text/0212-restore-int-fallback.md https://github.com/rust-lang/rfcs/blob/180cda6a41ce6320f3f6668651872bac0bd882ac/active/0000-int-name.md And this discussion about what to use in the guide: https://github.com/rust-lang/rust/issues/15526 Thank you for your help!!
If you're looking for a use for this - a userspace TCP/IP implementation is a really useful thing to have, look at [VDE](http://wiki.v2.cs.unibo.it/wiki/index.php/VDE)/[LWIPV6]( http://wiki.v2.cs.unibo.it/wiki/index.php/LWIPV6) for examples: I've been using them for virtual machine testing infrastructure. But this is really the perfect thing to be using Rust for.. might have to try and find some time to hack on it. Would be helpful to have nonblocking IO/epoll in std though, anyone know the status of that?
Ok, after reading through some of those, I've switched the types in the headers of the table to be i32 and u32 (kept f64). It looks like this decision is still very much in flux though! A few of the examples, like the ones using `std::char::from_digit`, are a bit weirder now since they expect a uint. 
How is `char` worthless as a datatype? When you want to pass a character for insertion in a text editor, what else are you supposed to use?
Yeah, I noticed that as well, but I figured there's basically zero chance people actually get confused by this.
Anywhere you want to parse a mostly context free grammar. Programming languages, protocols, etc.
&gt; When you want to pass a character for insertion in a text editor, what else are you supposed to use? You'll have to be more specific, because "character" is an ill-defined concept. Because Unicode grapheme clusters can be composed of an arbitrary number of Unicode codepoints, you'll need to pass a `String`, or better yet some custom datatype that enforces that only a single grapheme cluster is present in the string. Note that you do *not* want a vector of `char`, because `char` doesn't represent Unicode codepoints, it represents Unicode scalar values, which represent a range that is a subset of all codepoints (and also a vector of `char` is four times bigger in memory than you need). Or perhaps you don't care about Unicode, you're fine with only supporting English. In that case, you want `std::ascii::Ascii`, which will happily give you the `u8`s that you truly desire. Note that you do *not* want `char` here either, because `char` represents a superset of all legal ASCII characters (and not only that, is four times bigger in memory than you need).
Thanks, very interesting. Maybe this will help. I need to think a bit more about this, API design is hard :)
I believe the guide is going is going to be re-done to use i32 mainly soon.
There's always `&amp;*some_string`. It seemed like that was the way to go for a little bit, but now I've seen people say it isn't, so I don't really know.
Just out of curiosity what are the costs and and tradeoffs of async/await?
Yes (AFAIK). Here's a related RFC issue: https://github.com/rust-lang/rfcs/issues/442.
So far, I am really adoring Rust. I really like how much simpler the build environment is, especially with unit testing baked right in. The fact the compiler is so strict had been both a bit frustrating and a blessing. There are certainly points where I have missed C++... But I am finding that feeling starting to passs time goes on.
I haven't done much of anything in rust, but I imagine you could extract the logic of finding duplicates into a library of sorts, and then make two frontends: GUI and text interface. Both the frontends would then contain very little logic, and they'd both use the same things to do the actual searching for duplicates. 
I was also thinking along the lines of this version. It may suck having to implement trait implementations directly off each data type... But I think with things right now that the compiler does not think it has enough type information to differentiate between the two. I recommend opening a ticket describing your situation and state exactly your intentions. You may also want to include the possible workarounds mentioned in these comments and describe why they don't quite work or for what you are trying to do.
I've considered this... But it seems like keeping debug and release using the same code to be more important. This is why I am using the debug assert. Though I could very likely be using more of them. It seems like debug asserts are ones best tool for adding some assurance with raw pointers.
Boxes have a size implementation... But it may be because of of the way you are using the static lifetime. I'd consider moving the statics in your PublisherBuilder to a where clause. Ex: where A: 'static, B: 'static I'd test, but am sitting in the car ATM on a long drive hehe.
I'd certainly use the specific types (u32, i64, etc, etc) over int unless you need the variable to be based around the pointer size. (Ex, occasionally with indexing?)
Modern use of C++ (C++14 &lt;3) is pretty safe and similar to Rust in many ways. Unique smart pointers are very much like Box. Shared smart pointers are like Rc. Stack allocation is preferred with copy and move schematics for moving data around. You shouldn't be using delete and friends unless you have a very specific reason (and the object in heap is encapsulated into a stack object for RAII). If you are afraid of C++, but find yourself needing it for a project you might consider spending some time learning about how modern C++ use works. It's actually pretty nice these days! Having said that... I certainly don't blame you for preferring Rust where you can! 
Each component type is stored in its own vector, with Any just being used to get the different vectors past the typesystem - still seems pretty data driven to me, the indirection is only relevant during initialization. Maybe you are saying that all different component types should be allocated in the same slab of memory as well, rather than each in their own?
They do, for the most part. The CLI is somewhat strongly coupled to the processing infrastructure whereas the GUI is pretty self-contained. The CLI wouldn't be too hard to decouple. The hard part is getting Cargo to conditionally compile the GUI, since you can't have it pass `--cfg` directives to the compiler. It looks like the features section is something I want to look at. Edit: Done.
Oh, I assumed that the Any was for each component individually. That's still an awful lot of indirection though, hashmap -&gt; box -&gt; vector -&gt; actual value.
What do you use debug builds for? Only debug symbols? 
Data oriented, as in... data and code are highly separated. Entities are represented by an id. The associated data represented by simple structs which can be composed together rather than fat classes with inheritance. The design is based around the approach outlined at http://entity-systems-wiki.t-machine.org/rdbms-with-code-in-systems In regards to being contiguous, I've mentioned in my other comment that things may be refactored along those lines for cache coherency. Having said that, this article outlines some of the tribulations in such an approach. http://t-machine.org/index.php/2014/03/08/data-structures-for-entity-systems-contiguous-memory/
Looks amazing!
Some of the implementation is an unfortunate side effect of various parts of the type system. The Box itself is required because Any doesn't implement the Sized trait, which is required by HashMap. (Weird because Any is basically a Box with type casting built in. The size would then be of the pointer itself, not what it's pointing to). Building an ECS to work with a single contiguous vector is not an easy proposition. I'd consider it to be ideal, as one could gather up all of the associated data in a single request... but check out the article I linked in my other comment. In regards to HashMap -&gt; Vector -&gt; Value. It makes it easy to do things like "Give me all of the Position components". (A very simple table lookup for the type to get the list of related components).
Generally, for anything more complicated than you can easily do with regexes. Programming languages (and similarly-complex grammars) are a prime example. **Warning:** Controversial opinion inbound. I always assumed that Parsing Was Hard™. I mean, I had no idea how to do it, and surely parsing something as complex as a programming language must be nightmarishly difficult. Why else would all of these automated parser generators like YACC and Antler exist? Especially when these tools are extremely finicky to use unless you understand parsing very well and often produce very difficult-to-understand error messages; parsing certainly must be some deep magic that is not given to mere mortals to understand. One day, after getting tired of struggling with Antlr, I finally broke down and read up on building my own parser. Learned about recursive descent parsers and started implementing my programming language's grammar And... holy shit, that was straightforward. Six hours later, I was done. Not only had I implemented a parser for a complex programming language in one day, but I finally *got it*. I understood what all of those stupid error messages had been about, I finally really *got* why certain constructs were problematic, and I realized that using tools like Bison and Antlr hadn't actually been saving me any time. They had just been preventing me from really understanding exactly what was going on and making it needlessly difficult for me to design my grammar. If you, like me, had assumed that parsing something like a programming language was hard, you might want to actually try it. Recursive descent parsers are surprisingly easy to write, extremely powerful, and a hand-written parser can generate far better error messages than an automatically-generated parser. Plus, for me at least, I don't find them any harder to write than an equivalent tool-generated parser.
`Any` is a trait, it is not inherently boxed. The only way to handle traits is behind a pointer because a value of type `Any` represents any value that implements that trait, and these values are arbitrary and can be any size at all. That is, the pointer (and pointer-sized-ness) is entirely introduced by the `Box` in the `Box&lt;Any&gt;`.
Given that boxed closures are slated to be removed entirely, my standard line is that any guidance related to closures will soon be obsolete. Here's praying for the 1.0-alpha to end the churn!
The `&amp;:` bit of `|&amp;: _: &amp;mut Request|` should be going away once boxed closures are finally removed, yes? Also, I'm surprised that Rust can't infer the `&amp;mut Request` type in the argument list, given that it's being passed directly into a function with a concrete signature... Think how much nicer the code would look without either of those!
I wish I could be less unhelpful, but I've been punting on everything closure-related since October. There's simply no way to keep track of what things are broken, what things are transitional, what things are intended...
So far I hear that people have had a hard time making ECS-esque things for Rust, I'm excited to see progress in this space. :)
Tell me about it. My window manager's config system is entirely based on a closure for each key command in the config. I am at the same time looking forward to 1.0 and dreading 1.0.
Wow, I didn't think of using `as` as a hint. I simplified a bit to this: Some((box |f| println!("{}", f)) as Box&lt;Fn(&amp;_)&gt;) Thanks!
&gt; Gabor's error handling syntactic sugar stuff Is there a RFC? Why this and not Gabor's other stuff (like existentials)?