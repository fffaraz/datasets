I'm working on an AoC challenge and got this error from Rust: &gt;\[Running cargo run\] Compiling aoc\_2015\_3 v0.1.0 (/Users/andrewbanchich/Documents/Projects/aoc\_2015\_3) error\[E0308\]: mismatched types --&gt; src/main.rs:37:33 | 37 | if !visited\_coords.contains(coords) { | ^(\^) expected &amp;Coords, found struct `Coords` | = note: expected type `&amp;&amp;Coords` found type `&amp;Coords` &gt; &gt;error: aborting due to previous error &gt; &gt;For more information about this error, try `rustc --explain E0308`. error: Could not compile `aoc_2015_3`. &gt; &gt;To learn more, run the command again with --verbose. &amp;#x200B; Why does it first say `expected &amp;Coords, found struct Coords` but then immediately say `expected type &amp;&amp;Coords found type &amp;Coords` ? Shouldn't those warnings have been the same number of ampersands?
Pinging u/phaazon_: this feels to me like a better motivation than the one you presented in the RFC. Abstracting over slices of different types felt somewhat arbitrary, whereas SIMD run-time detection is bread and butter SIMD portability-wise. --- &gt; I'd say that this is pretty bad, and is a problem that C++ does not have (C++ has had generic lambdas since C++ 14). While I do appreciate prior art, I would note that there's many things that C++ has that we may not be keen to get in Rust. It doesn't mean that anything C++ has Rust should reject, just that simply "having it because C++ has it" is a poor argument. &gt; So we need both, generic closures, and higher-ranked trait bounds (for function types at least). I feel much more convinced about the usefulness of this RFC now. I'd still like to know how difficult it is, implementation-wise, but at least there's a clear benefit. Specifically for the case of SIMD, though, it seems to me like a macro could handle this: simd_lambda!(|(a, b)| a * b) could perfectly instantiate an impl of a trait which copies/pastes the given implementation for each method: `trait BinarySimd { fn apply((a, b): (_m128, _m128)) -&gt; _m128 { a * b } ... }`. 
&gt; Should it though ? It's a library API, it can do whatever it wants. &gt; would force me to make it fail silently You could just unconditionally abort the process. That's how run-time `#[no_panic]` would work anyways.
The sophisticated type system helps to enforce certain constraints and compile time, and improve the correctness of your program. I suppose this might not mean much to people who haven't used a programming language with similar capabilities (while Haskell programmers will say that their type system is better). But programmers in languages like Rust and Haskell are used to feeling that their code works just as soon as it compiles. And this also benefits refactoring (less likely to break things, since the compiler points out potential issues). To people using dynamic interpreted languages like Python, you can boast that Rust is faster, without being the dreaded C or C++. It's a simplification to say that writing code in Rust will just magically make it faster, but switching to Rust is often a good way to get a performance boost. Rust is one of the few new languages that's a "systems programming language". This is not that well defined. But if you want to write an OS kernel or program a micro-controller your main options today are basically C, C++, and Rust (and older languages like Ada). You just can't use something like Go, at least in it's current form. To a slightly lesser extent the same is true for things like game engines and browser engines. These last two points can be combined: Rust is an option for things where there's little competition other than C or C++. For those who aren't fans of C or C++ (or even people who are, but are interested in what a newer language might offer in that area), that seems like reason enough to look into Rust. And personally, just the fact the language is expression based (match statements, if statements evaluate to expressions, etc.) is pretty great. If I try going back to Python, it can seem quite awkward being able to `match` over an `enum` like I would in Rust. 
Ah, that's reasonable then. I think it was one of the design proposals for this as well (or still is?), but I'd have to go through and reread the threads to remember exactly why the rfc ended up using `existestial type;`.
No memory-unsafety related segfaults is a big sell.
&gt; Yes. The Write trait is for things that can be written to, i.e. sinks, I see. Makes much more sense. I knew something was wrong, when I had to pass the buffer the implementor supposedly writes to. I have removed the Write impl for now. I have used two simple fn serialize and deserialize to serialize the struct. However, my little project has goit a fn capture, that captures keystrokes from the console and I would like to add a new word to the dictionary whenever the user hits space. I guess that would be a a correct/better use for Write? 
The second error is the complete one - somewhere in your program you tried to give `&amp;Coords` when the compiler needed it to have type `&amp;&amp;Coords`. The first error is the short one that tries to narrow it down for the user, and it's generated something like this: 1. the compiler tries to match `&amp;Coords` with `&amp;&amp;Coords` 2. both types are references, so extract and match their inner types 3. the compiler tries to match `Coords` with `&amp;Coords` 4. one type is `Coords` and the other is a reference - so you get "expected `&amp;Coords`, found `Coords` For example, if you tried to assign `Vec&lt;(i32, String)&gt;` to `Vec&lt;(bool, String)&gt;`, the compiler would also try to find what part of the type is different and report that in the short error, and the complete error message would look something like: expected bool, found i32 note: expected type `Vec&lt;(bool, String)&gt;` found type `Vec&lt;(i32, String)&gt;`
&gt; However, my little project has goit a fn capture, that captures keystrokes from the console and I would like to add a new word to the dictionary whenever the user hits space. I guess that would be a a correct/better use for Write? No, not if I understand correctly. `Write` is for when you're writing a struct that acts like, or wraps, something similar to a file. You can implement it for a compressor (you write data to it, it does its stuff, then outputs to another thing that implements `Write`), for something that computes a checksum, counts, bytes, and so on.
i've never seen or worked with once, but it might be like an extension of the principle behind tracking 'unsafe' eg "only an unsafe block can call an unsafe function.."... you'd split the concept of unsafe into multiple effects ('changes globals..' 'uses raw pointers' .. 'performs IO' .. and more beyond that (types of IO,.) ).. but the current strategy is 'pass a mutable pointer to the thing that could be affected.. you can only change X by having a pointer passed to it')
&gt; If someone is writing From::from implementations that panic! their code is already broken I don't think this is entirely true. If `from()` allocates, it could panic due to running out of memory. This could happen with `String::from()`, for instance.
Then String should use `TryFrom` instead.
I mostly agree. Though it's also consistent, in that Rust mandates function specify their types. So things at the global level have to have types specified, while those that are local do not (except when it can't be inferred).
Any way to avoid writing out the type `u8` in the line `impl Foo&lt;u8&gt;`? I'm doing something similar except with an extremely long and complicated type, and I don't want to have to write it out. struct Foo&lt;T&gt;(T); impl Foo&lt;u8&gt; { fn new() -&gt; Self { Foo(0u8) } } 
Since allocation panics, there wouldn't be anything to put as the error in the Result. And I don't see anything in the docs saying `From` shouldn't panic, per se: &gt; Note: this trait must not fail. If the conversion can fail, use TryFrom or a dedicated method which returns an Option&lt;T&gt; or a Result&lt;T, E&gt;. "Fail" is kind of vague. But I think the point is that it should work for any input, but may panic for things like allocation.
[removed]
This is a really good blog post on the subject, from the single-threaded safety perspective: https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/
That's probably not too bad. I get that in the grand scheme of things really big numbers aren't different from really small ones, but pragmatically getting an undefined computation that results in something tiny is usually alright for whatever you're computing. 
Quote of the week.
Exactly. Some problems are not easily parallelized, but nearly every non-trivial application has *something* you can stick in another thread and gain at least a small advantage from that. In many languages the complexity and dangers of multithreading preclude taking the risk and effort for that, unless the problem is heavily parallel. But it's nearly free with Rust.
No memory leaks, or leaking file handles. No undefined behaviour, ex uninitialized variable causing your code to "work" in debug, but crash in release build. Excellent error handling, which makes it easy to visually inspect idiomatic code, and verify that all error conditions have been accounted for. (To mention some advantages )
I'd panic too, if one asked me to represent the square root of a negative number using only real numbers. :D
Algorithms are never obsolete, just implementations. ;-) I mean, I know of at least one person right now writing Rust for Gameboy Adanced hardware, so you never know where these things might be handy.
I mean, you'd hope so.
That's an even more ornate way of saying, "I'm a shitty person." Doesn't help the case.
The fact that it only panics in debug mode is a bit icky though, but yes, and simple enough to fix.
Oh, nice.
Rust has functioning iterators, ADTs, and pattern matching.
Only 3x? On my laptop the Rust version was 6-12x better, though with lots of warnings about statistical outliers.
I think where it's most helpful in learning is giving you a reference point when learning how a rasterizing engine works. The details for basic raytracing are pretty mathy but that aside they're not super complex to understand. Once you've understood how a bit of the math and how it maps to your implementation then learning about how a rasterizing simulates those results becomes easier.
Sorry, I'm new. Could you give a simple example of how you use this?
Yeah, I've been saved from enough bugs by having overflow checks everywhere that it really is something that should always be the default. Unfortunately, overflow checks will probably always be a big performance impact until CPU makers start adding more ability to handle them more nicely. Maybe Rust will create more demand for this ability?
A simple example is included in the repo. It formats the code before commit (error handling, blocking and readding the formatted file is not yet ready). Another dummy example of posthook is also included which echos "Posthook". 
To my experience actually compiling JS/JSX with Babel do not take a lot of time, but packing an assets may be painfully slow. I do understand that it may be far away from scope of this project, but if it will be faster and better then Webpack it surly will get popularity it deserve. In any case, that is really nice project. Good work.
The type system is a huge perk over most non-academic languages, but for me the big win is in dependency management. If I want to use a tool that was written in C or C++ I look for a precompiled package, and if I fail to find one, I seriously reevaluate how badly I need the tool, because sorting out the dependencies and build environment will take all afternoon on a good day, and somewhere between a full week and "lol, yeah right" if there's a problem. Rust is different. If I want to use a rust based tool I cargo install it and switch workspaces for a few minutes while it compiles everything. I just assume it's going to work.
Since if is an expression, you can do this: let mut app = App::new(); if verbose { app.middleware(...) } else { app }.resource(...) or let mut app = App:new(); let mut app = if verbose { ... } else { ... }; app.resource(...)
Hah, true! I'm trying to remember if that cpu even has floating point hardware. It's an arm7tdmi but I'm not sure if Nintendo sprung for the option. [This article mentions putting an fpga on a cartridge](http://www.drdobbs.com/gameboy-advance-for-non-gaming-applicati/184405662) because of course somebody did. The graphics hardware is a fixed point fixed function sprite/tile engine with affine transformations and a scanline interrupt, all *very* similar to SNES. I don't remember if it had bilinear filtering or was nearest-neighbor only. 
If they're in the C++ world I show them enums and match *drool*
Yes, that’s fine! Only transpiling seems to fit the project’s goals best. I have a special interest in that extra feature. For something like the deno project, not having any reliance on node would be great.
Can you not do something like this? fn foo(f: impl Trait) -&gt; String; trait Trait { fn call&lt;T: Display&gt;(x: T) -&gt; String; } If the above is possible, then I don't see why it shouldn't be possible to use universal quantification in function arguments too.
strong disagree. i was so astounded by how slow the process of javascript ecosystem builds was i decided to just avoid that universe entirely. it is a talent leak and time waster. javascript has taken one of the advantages of dynamic languages and made it a disadvantage.
he got a couple tips on twitter and wrung some more speed out of it since posting
Any particular tips or notes making a JSON API with Rocket and Diesel? :) Are there examples of doing this correctly or nicely already?
Thanks for the help! Interestingly, this produced errors. ```rust error\[E0382\]: use of moved value: \`app\` \--&gt; src\\main.rs:161:9 | 159 | app.middleware(middleware::Logger::default()); | --- value moved here 160 | } 161 | app.resource("/suggestions", move |r| { | \^\^\^ value used here after move | = note: move occurs because \`app\` has type \`actix\_web::App\`, which does not implement the \`Copy\` trait ```
I feel like people very often focus on the performance of rust. The main reason I love rust is the correctness. I write something and argue a lil bit with the compiler, although I must say the arguing part is continuously getting shorter, and when it compiles, it works. And on top of this we have cargo project management and the best docs ever. The only grievance I have With rust is it's compile times, which is sort of fixed by cargo check.
You definitely don't want that semicolon on 159. `.middleware` takes ownership of self, and then returns it, so you need to use the return value after calling middleware. You can't just call .middleware for its side effects, like you might a Java builder.
Hmm. I guess I have to look at that more thoroughly :) 
Here is an example of a struct implementing the `Write` trait: https://docs.rs/deflate/0.7.19/deflate/write/struct.DeflateEncoder.html
Believe what you will. It's just one more reason that I'll send people to the old version of the site because I feel it gives a more professional impression of Rust.
r/woooosh
(Tbh I just didn't think it was that funny, and decided to answer the implicit question instead.)
Advantage compared to what? Compared to dynamic languages, you will often see thriftier resource utilization and incredible performance gains at the cost of a steep learning curve and increased turnaround due to compile times. This is however countered by great correctness guarantees, often the compiler will have you fix a load of errors up front that you would need time and either discipline or luck to even find in a dynamic language. Compared to other high-level compiled languages (think go or java), Rust still has the benefit of better compile time checks and possibly better performance (though decidedly less pronounced than compared to dynamic languages), at the cost of a less mature ecosystem. This situation is improving. Compared to other low-level languages, there's decidedly less UB, and, well, I personally cannot fathom how one can even write web services in such languages without wearing a huge 'HACK ME' sign.
I have to write both C++ and Rust atm and indeed, match and enums with associated values are really *addictive*, if I can say so.
This has previously been submitted as https://www.reddit.com/r/rust/comments/an2uf6/learning_rust_via_advent_of_code/
It really should not. Borrow checks do not magically get ignored because you use unsafe, you only have a very limited set of extra powers. I could imagine the exact effect depends on the codebase. If you're really curious just try it out for yourself :)
Use `for_each`, not `map`. `map` is lazily evaluated.
The main things that `unsafe` does is allow you to dereference raw pointers, and call other unsafe functions. In that sense, it actually *adds* to what you can do. It is actually not possible to disable the borrow checker. However, the borrow checker does not, and has never governed raw pointers.
&gt; I am just basing this off of the fact that the borrow checks will be ignored This is a misconception. The following code is internally inconsistent; it tells the compiler to make two exclusive references at the same time. let mut s = String::from("hello"); let r1 = &amp;mut s; let r2 = &amp;mut s; println!("{}, {}", r1, r2); Taking the same code and putting it in an `unsafe` block does not change the fact that it's internally inconsistent. unsafe { let mut s = String::from("hello"); let r1 = &amp;mut s; let r2 = &amp;mut s; println!("{}, {}", r1, r2); } Unsafe lets you: - Dereference raw pointers - Call unsafe functions (including C functions, compiler intrinsics, and the raw allocator) - Implement unsafe traits - Mutate statics - Access fields of unions Other than that, it's the same as safe Rust.
Probably not 
Is there a reason you can't use a type alias, like type ShortName = MyType&lt;Extremely&lt;Long, Complicated&gt;&gt;;
Misread this as 'Guy ports PHP ~~script~~ interpreter to Rust and gets 3x speedup' Skimming + IWANTTOBELIEVE is heady stuff.
Rust still allows you to disable the safety for sections of code, so I don't think that would be an issue. When doing kernel developement, you are forced to do many crazy things.
No there's no reason. Even the type alias is a pretty serious wart on the code though.
Your code looks really neat! I had never before properly looked at the code of a simple ray tracer, and I'm surprised by how little code you need for such a result. Well done! I have some minor feedback (though many of these are quite subjective): * You have a bunch of `new` methods that directly initialize the struct. It makes your code slightly more concise, but at the cost of no longer requiring the field names, and therefore I think it makes your code slightly less readable. * You write `Option::Some` and `Option::None` which isn't very idiomatic Rust given that they're part of the prelude. But I'm sure this was a conscious decision :) * I personally wouldn't have made `Color` a type alias for `Vector3`, because it keeps you from adding methods such as `Color::black()`, and the `from_rgb` and `to_rgb` methods don't really make sense for other `Vector3`s. * Several times you have something like `diff_light = diff_light + light.color * light.intensity` which could be shortened to `diff_light += light.color * light.intensity` if you implement the `AddAssign` trait. * You no longer need `extern crate` in the 2018 edition anymore. * Several of your types could be `Copy` but aren't, such as `Ray` and `Vector3`. By making them `Copy` you no longer have to pass them by reference, which makes your code less noisy. * In some files you have more nesting than required. e.g. in the `cast_ray` method you can replace the `match` with `let intersection = Ray::intersect(ray, objects)?;`, and in the `render` method you can replace the `match` with a call to `.unwrap_or(self.bg_color)`. * `Shapes` should probably be singular since an instance of it represents a single shape. * The `render` method's `filename` parameter can be a `&amp;str` since `ImageBuffer::save` accepts `String` as well as `&amp;str`, so this saves you an allocation (and some typing). That's about it. Thanks for sharing!
If x and y are both unsigned integers, is the best way to find the absolute difference between them to cast them both to signed integers first? It seems like there might be a way to avoid the extra casts since the abs will obviously be unsigned, but I'm not finding one. fn main() { let (x, y) = (12_u16, 10_u16); dbg!((x as i32 - y as i32).abs()); }
I've never looked into compiling Rust, but in the C compiler, having free access to memory actually reduces performance, because the compiler is limited in what optimizations it can perform, since variables might be changed outside of the regular access patterns (e.g. `volatile`). For example, due to pointer arithmetics, all array access always has to hit memory. This is the one reason why Fortran is faster than C and so still used in high performance computing.
I tried everything. There are two things I discovered. The variable under ngram.0[0], which is the first two max, doesn't update in the loop. It's always the same, and it*s randomly a different one. I guess because it's a Vec without natural ordering. That's ok, but still it doesn't iterate correctly. The second thing is that Duration is sometimes (). Don't know why: This is the latest attempt: // for each ngram in profile.ngrams() for ngram in &amp;ngrams.iter().next() { // if the first value of the ngram and the current character and the second value of the ngram and the upcoming character are the same if ngram.0[0] == (chars[i] as u8) &amp;&amp; ngram.0[1] == (chars[i + 1] as u8) { // then sleep as long as Duration for that ngram stored in the second field of "ngrams" std::thread::sleep( *ngram.1 ); } else { // else sleep within random range std::thread::sleep( Duration::from_millis( utils::rng(103, 425) as u64 ) ); } } The entire project is located here: https://github.com/aspera-non-spernit/chattr The issue is in src/lib.rs
Awesome feedback, thank you very much. 
In general, there's no way to omit types in top-level signatures like this. However, depending on what you need from the type you could do `impl&lt;T: MyTrait&gt; Foo&lt;T&gt;`. With more information on what you're actually using this for we may be able to find a better way, but other than a trait bound or type alias there's probably nothing else.
Hey, you're looking for r/playrust. This one is for Rust the programming language.
Okay, here's what's happening in your code in that attempt. `ngrams.iter()` gives an `Iterator&lt;Item = (Vec&lt;u8&gt;, Duration)&gt;`. Then when you call `.next()` on that, it gives you the first item in this iterator, wrapped in an `Option`. (This is a different one each time because the iterator order for a `HashMap` is unspecified.) So now what you're trying to do is run a `for` loop over an `Option&lt;(Vec&lt;u8&gt;, Duration)&gt;`, which is the same as saying `if let Some(item) = my_option { use(item) }` In this case you can just do `for ngram in ngrams` (or `for ngram in &amp;ngrams` if you don't want to consume `ngrams`) and I believe it will work how you expect it to.
&gt; Since allocation panics, You can use the `try_` APIs for allocation like `Vec::try_push` which don't necessarily panic. Although on OOM you are not guaranteed to get a panic or proper error anyways.
 impl Drop for Acid
Lol my bad! 
I considered it, and maybe I will sometime down the line, but busy at the moment. Plus I can't think of a name beyond "cargo-outdated**2**", which is kind of lame.
/r/playrust
Compile times go down as you cut down on Generics, not as you add more unsafe.
Fortunately I was just hoping to get a solid understanding about how they work abstractly, not necc. create a viable product. :)
LMAO
What math are we talking about? calculus? linear algebra? I'm in calc 1 right now.
I'm struggling to understand the use case. As I understand it, to use this I'd need to alias every relevant command to `shell-hooks &lt;COMMAND&gt;`. But if I'm doing that, why not just alias it to a shell script that runs my prehook and then runs the command? Is it just liking the TOML config better than writing shell script? 
I'm not sure she the connection. The fast x^-1/2 algorithm requires bitcasting floats to ints, but that operation is reasonably typesafe. It's in the standard library, in fact. Likewise, invoking `rsqrtss` or whatever is also perfectly type-safe. (Numerical stability or sufficient precision are not guaranteed by safety.) No need for `unsafe`.
The best I can think of is to use `wrapping_*` twice: let d = x.wrapping_sub(y); let abs_difference = d.min(d.wrapping_neg()); 
The borrow checker is very much instant. It's the amount of generated LLVM which is the problem.
No more modafinil for you
Even with NLL?
Here is my c# code using xunit.
No artificial flavoring, preservatives, or stabilizers. 
NLL just changes the set of programs that are permitted by the borrow checker. It doesn't have anything to do with codegen as far as i'm aware
I have a question here: [https://www.reddit.com/r/learnrust/comments/apag3q/raw\_pointer\_value\_loses\_lifetime/](https://www.reddit.com/r/learnrust/comments/apag3q/raw_pointer_value_loses_lifetime/) I appreciated if you Rustaceans could check it out :) &amp;#x200B; Love ya'll &lt;3 HOWZ1T 
To put what some of the other commenters said in the simplest, most concise form I can: `unsafe` doesn't doesn't turn anything off... it just turns *on* extra features which the compiler can't verify.
Let me know if this is a stupid question but one wish I have when writing rust is using the javascript `=&gt;` operator for writing closures. Do you think it would be a good idea to push this idea as a alternative to how closures are written. Small eg: ``` let closure = |x| { num }; ``` can also be rewritten as ``` let closure = x =&gt; num; ``` 
You could create a vector or character with chars().collect() and index into that. 
Lack of null ptr. Novel error handling without exceptions or c style error codes. Pattern matching. Zero overhead memory management. High level type system with little to no performance impact. Bound checked arrays with iterator support providing zero cost use in 95% of cases.
If you know it’s ASCII treat them as u8s instead of Unicode.
If this is only ASCII you can use bytes directly.
So, I'm looking to build a newsletter system with Lettre, looks promising. Just, what would be the best way to implement a dynamic email template? (For names and stuff) Any insights or tips would be greatly appreciated. :)
If you \*really\* care about constant time lookup and maximal efficiency, and you can guarantee that you only have ASCII: \`into\_bytes\` [https://doc.rust-lang.org/std/string/struct.String.html#method.into\_bytes](https://doc.rust-lang.org/std/string/struct.String.html#method.into_bytes) &amp;#x200B; "This consumes the \`String\`, so we do not need to copy its contents." &amp;#x200B; That it, it converts the owned \`String\` to the owned \`Vec&lt;u8&gt;\` that's the \`String\`s backing storage. &amp;#x200B; Based on reading the Python reference, I believe Python indexes for strings index into code points, so the \`char\` family of iterators and indexing is probably closest to Python. &amp;#x200B;
If the string is actually just a sequence of ASCII bytes, then using a `&amp;[u8]` sounds like a better idea. You can make a literal of this type using `b"7GATTACA"` (with the leading b meaning "byte"). The only downside is that byte slices don't print as strings, but that can be worked around with a helper type that implements Display by converting the `&amp;[u8]` to a `&amp;str`
`s.as_bytes()[2] as char` is O(1), so in terms of performance it's the best approach if you can guarantee that `s` contains symbols from `U+0000` to `U+007F`.
A lot of game dev uses C++, rust offers a lot of the same control and performance with the added bonus of safety and ergonomics, so I can see the appeal. I've been playing around with rust a lot lately and would jump at the opportunity to use it at work. I have a background in C++ but have mostly been using JS, Java, and Python at work.
`impl Trait` is tricky because it’s not a real type, only a shorthand for (in this case) adding a generic type parameter to the function it’s written in. fn foo(f: impl Trait) -&gt; String is equivalent to fn foo&lt;T&gt;(f: T) -&gt; String where T: Trait Under this proposal, it should indeed be possible to write `impl for&lt;T&gt; GenericTrait&lt;T&gt;`, but that’s still a higher-ranked trait bound, not a higher-ranked type. If it were a real type, you could have something like a `Vec&lt;impl Trait&gt;`, but you can’t. (Actually, that syntax may work in the future, but if so it would be sugar for a `Vec` of a single unspecified type that impls `Trait` – all the elements have the same type – where the actual type involved would be inferred from the rest of the code.) By comparison, `dyn Trait` *is* a real type: you can have, say, a `Vec&lt;&amp;dyn Trait&gt;`, and fill it with instances of multiple different types implementing the trait. It’s dispatched at runtime. But `dyn Trait` doesn’t work with traits that contain methods with generic parameters, precisely because that’s incompatible with monomorphization.
You can already write as below, so changing to use \`=&gt;\` wouldn't add much worth. let closure = |x| num; &amp;#x200B;
Why does your use case prevent the use of crates?
good
if compile times can be sped up significantly you will get a big chunk more gamedev mind share. and gfx-rs contribution and easy wrappers for it will help as well. 
I was going to make a joke that only a shitty language like JavaScript would need such a thing... Then I went and found this: [https://github.com/libav/c99-to-c89](https://github.com/libav/c99-to-c89) Sigh. &amp;#x200B;
Wrong Reddit r/playrust
I feel like this is the real validation for Rust. Carmack, and others like Tim Sweeney, have looked at alternatives to C++ for years. That is just as a part of them looking at future ideas and technologies on the horizon. That however has included looking at languages like Haskell, which is a great language, but has things that prevent it being a C++ alternative. Tim Sweeney even did a whole talk years ago on how the vast majority of the bugs in the Unreal Engine are caused by out of bounds and null pointers. If Carmack ends up recommending Rust as a real alternative to C++ then it really drives home how viable the language is.
Pragmatic? Use D if you are familiar with C++. The amount of useful metaprogramming you can do with it, plus constexpr, etc. is unbeatable IMHO to date. Nim looks good also but it is less mature. I see Rust and like it (except that the borrow checker gets on my way, but I understand this design decision). But in Rust, for example (and help me here, I might be wrong) I do not know how to conditionally add or remove a field from the layout of a struct or do some constexpr or introspection-based decisions (again, I might be wrong and this could be possible). As for async programming (primary use case for me together with tight control on layout), there is nothing right now that I could call usable.
Yep, he's approaching a 4x speedup now: https://twitter.com/DanielLockyer/status/1094786049086152704
Heck, worth it at the same speed to not have to maintain php. 
This *should* be possible in exactly the manner you're describing, IMO. It's literally just what are typically called *IFDEFS* in other languages. Simpler to implement than the attribute-based stuff like `#[cfg()]` and blatantly more powerful, if you ask me. The apparent widespread opinion that being able to control the compiler in that way from source is somehow horrific and unthinkable is one of my bigger gripes with Rust so far, which I otherwise really like.
Hi! Though the Gba doesn't have floating point, so the algorithm isn't useful there, since it relies on the floating point representation : [sign | exponent | 0.xxx]. 
I remember he liked Haskell a while ago, so I'm not surprised he likes rust too.
This is pretty cool. Python definitely seems to be lagging in terms of this this kind of tooling. But have you seen Anaconda (http://conda.io). It does some of the things you listed (like managing interpreter versions) much better than anything else I've aeen in the python world...
Would that be done using bytes()/as_bytes() on the string? Just so I understand this right, this is creating a new allocation of bytes (the iterator will when collected) right?
it's a good job!! would U can tran golang to rust? Because I know ,most project write in golang can trans inot rust (haha,maybe). So the golang programer it's more simple than python.
It doesn’t create any new allocation, it just reinterprets the memory you already have. Completely zero cost, it’ll just let you index it as bytes instead of as Unicode points. By comparison, making an iterator and collecting it will iterate over the string and allocate a new set of memory. 
Thank you. This is a great suggestion.
Thank you, this is excellent info.
Okay, that makes sense. So we have: `bytes()` -&gt; new allocation `as_bytes()` -&gt; reference into existing bytes. 
Thanks. 
bytes I think is shorthand for .as_bytes().iter() But as_bytes you’ve got right 
Thanks. Would your suggestion only work with literals or can I prepend a value stored in a variable with a leading `b` somehow? 
It's a constraint imposed by a remote service that I'm running my code on. It's a bit contrived. I would love to hear your suggestions if this was not a restriction.
Thanks for the suggestion, wouldn't that be expensive.
Thank you! Actually there is already a Python to Go transpiler and it seems to be in much better state than pyrs. https://github.com/google/grumpy
Thanks. That helps! 
Yes. Other commenters have made better suggestions. 
as_bytes() convert string slices into byte slices which is immutable. into_bytes() convert a Sting into a Vec&lt;u8&gt; which can be mutable. They both do zero allocation 
&gt; as_bytes() convert string slices into byte slices which is immutable. &gt; &gt; into_bytes() convert a Sting into a Vec&lt;u8&gt; which can be mutable. &gt; &gt; They both do zero allocation I understand. I was referring to collecting the iterator returned by `fn bytes()` [https://doc.rust-lang.org/std/string/struct.String.html#method.bytes]
The language and standard library have been delivering stability for three and a half years and counting. Rust 1.0.0 source code still compiles and works today. (As long as it was stable channel.) https://blog.rust-lang.org/2014/10/30/Stability.html Whether or not any other library makes or keeps similar promises is up to that library; however, semantic versioning is strongly encouraged. 
Right. For your example as_bytes or into_bytes are probably your best bet depending on if you need mutablity 
Actually, I couldn't find a way to hook scripts to shell so I had to create it. Had it been there, this tool wouldn't be born. Yes, in a way, it's just replacement to your shell script. But since we are making configuration files which are declarative, now it would be as easy as adding new files w/o changing the script. You could as add as many script files as you can which can be run parallel (not yet implemented), and so many other things. Also generic optimizations on the shell-hooks will now benefit all hooks. Main problem it solves are: - hooks (obviously) - Hooks management at one place - Configuration - Easier update - Easier to replace the tool Some use cases on top off my head: - Hooks to monitor execution of some commands like a long running process and provide notification w/o knowledge of the script (pre and post hooks) - Finer tracking of invocation of individual commands to generate better usage statistics (pre or post hook) - Prevent running of some commands based on some conditions (prehooks) 
Indeed, thanks!
he actually liked it so much he basically, according to the talk he gave, ported entire parts of Wolfenstein to haskell. He also built a lot of VR stuff for Facebook in racket. Carmack is a beast. I still remember laughing at one of the youtube comments under the Haskell video saying "oh god, John's hell world is wolfenstein!"
In theory, if you're doing lots of random-access reads from spinning platters, the drivers/firmware have more opportunities to optimize the access patterns if the requests are all sent-in to the kernel quickly before they start resolving, rather than waiting for each request to complete before moving onto the next one. Or, if you're doing a lot of independent HTTP requests in a loop, then it doesn't make sense to have to wait for a request to come back before being able to send out the next one. In short: non-blocking I/O. It doesn't require multiple threads.
The test fails whenever it `panic`s; `assert` and `assert_eq` are calling `panic` conditionally. If a pass for this test means that `get_trade(&amp;db_conn, 1)` returned a `Result::Err(ErrorKind::DieselResult(e))` where `e.kind() == &amp;ErrorKind::DieselResult(diesel::result::Error::NotFound)`, then the code you wrote above is correct.
Like this: [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1b817fdd4c76f2ae0c412c3155f18087)
Oh man, I'm a huge Rust fan and I just appreciate this on so many levels... Have some Gold.
&gt; It keeps coming up every now and then and I wonder whether there is some confused teaching material somewhere It's probably that it gets repeated often that Rust is safe, unlike C. So people assume that when you go to unsafe mode Rust becomes like C.
Thanks for sharing! Fun read. 
&gt; By the way, where did you get the notion that the borrow checker is disabled by unsafe? It keeps coming up every now and then and I wonder whether there is some confused teaching material somewhere I think it's just a natural assumption, I thought the same initially. It's counter intuitive that "unsafe" mode give you *more* abilities. Perhaps if it was named "sudo" it might get the idea across better ;)
I’m using it to run some Monte Carlo simulations of bingo. I have found it to take a lot longer to write, but I also don’t spend that time debugging Python type errors. For performant simulations, I like it. 
What are best practices around method naming? I've been looking around and it seems like if two traits define a method with the same name, they'll collide with each other. Is that right? For example, if I have a library that has trait Foo with method `draw()` and another library with trait Bar with method `draw()`, and they're both implemented for e.g. String, and they're both imported into my module, then which implementation will `"hello".to_string().draw()` pick? Is there some way to namespace methods so that e.g. I could do `"hello".to_string().Foo::draw()` or something? If not, do people tend to avoid using methods with common names, or prefix them like `mylibrary_draw()` or something? This isn't an actual problem I'm facing in real life, I'd just like to understand more about how this system works, and see if I'm understanding it right, and learn about best practices if so. Thank you!
FWIW, build --release is often incredibly fast compared to regular old build. You pay a lot for debug info.
[This page](https://doc.rust-lang.org/book/ch19-03-advanced-traits.html) from the rust book has more info about your question. Long story short, you'd write `&lt;String as Foo&gt;::draw("hello")`. This is called the Fully Qualified Syntax for function calls.
This is awesome! One of the first projects I tried to build when I started learning Rust was to write a simple load balancer. Didn’t go far since I didn’t know a lot about the topic, and reading this now tells me how much more I can learn. It’ll be fun going through the code to see how everything works. As an aside, have you considered actix? It’s an actor framework written on top of tokio IIRC, so you might be able to model the workers architecture to different actors. And actix is known to be super fast as well.
&gt; Perhaps if it was named "sudo" it might give a more accurate idea on first impression ;) Then I'd expect a sandwich.
Thank you! I'm on 17.2 in the book right now (was reading the section about trait objects when this question came to me), haven't quite made it to chapter 19, should have known that it'd be covered. I appreciate the response!
I have rewritten a computational-heavy Python script (generation of a heatmap based on a 3D voxel space) in Rust and achieved a 200x speedup. This didn't really surprise me as Python is quite slow if you can't leverage optimized libraries such as numpy. What did surprise me is how easy it was to convert the Python code to Rust. The initial 1:1 port looked nearly identical and parallelizing execution with ryon was a blast. I'm looking forward to using Rust more for this kind of application if I don't necessarily need all the data science goodies that come with Python.
&gt; overwhelming feeling of completeness pouring out of your being through your brainwaves and into the global human consciousness [Yeah yeah, the Time Knife, we've all seen it. Let's get back on track, bud.](https://youtu.be/mhII8J_4Y1g?t=88)
Yeah, the Rust book is actually fantastic. When I read it, I kinda jumped around though. I didn't really have the patience to read it all linearly, though I did try. I don't think it covers which trait it chooses by default, or if it just errors out, though. They had an example where the compiler did choose one function over another, though, but not all the details. That's probably just a thing you have to test yourself, I suppose.
Glad you like it! I don't know much about actix so thanks for the suggestion, I'll look into it. 
Well - don't optimise - don't optimise yet - profile first
This could be amazing depending on exactly how well it works. I imagine that there are some places where optimizations will be needed after the initial translation, but on the other hand, starting a new project is easier.
The only time I tried dabbling in Rust I wanted to make a game, but I was disappointed to find that I would basically have to write an engine first and wasn't interested in that. It's been a few years so I don't know if it's gotten better.
&gt; Find what RNG is used for crypto and security purposes? `rand::thread_rng` should be fine most of the time, but may fall back to a weak RNG is the OS’ fails. It is currently considered to make the weak fall back a non-default compile-time option.
This is pretty cool! Good job. Python -&gt; Rust seems like no easy task, so you've got a big challenge ahead! What is your take on dependencies in python? Do they get transpiled too?
Yes, I'm using it to read a bunch of [HDF5](https://www.hdfgroup.org/downloads/hdf5/) files, extracting just a few of the datasets. The data are post-processed and then aggregated into bins over which various statistics are performed (mean, variance, count). At the end, the statistics are plotted using [gnuplot](https://crates.io/crates/gnuplot). The binned statistics work is basically a custom implementation from [what's in scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binned_statistic_dd.html), although it computes everything in a [single pass](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_Online_algorithm) since the data to analyze is larger than can fit in memory. I was able to use SIMD to speed up the binning computation.
I have implemented all of my simulation code during my PhD in rust. It is numerical solution of a Fokker-Planck equation coupled to a Stokes-flow (hydrodynamics), describing interacting self-propelled particles. It is a hybrid particle based sampling and spectral scheme (calling to FFTW). Although it was somewhat risky to go for rust four years ago, I have never looked back. Bluss's ndarray is the single most useful crate to me &lt;3! But apart from that, cargo is freaking awesome as well is the community. Reuse of work done in the community could not be easier. Need a nice CLI? Clap. Want to quickly slap a progressbar onto it? Pbr. Parrallelise trivial schemes? Rayon. But still some operations that are easily implemented using numpy or Julia in a few lines need a bit more effort. Mostly economical issues in my case. Would do it again. I was suprised to how many problems there already existed a useful library.
&gt;Because Rust must have been influenced by Python: tuples, conditions, loops, ranges and general approach looks a bit similar too. Wikipedia doesn’t state Python as direct influence, but it should have been a common ancestor of some sort. It's the latter. [http://rigaux.org/language-study/syntax-across-languages.html#VrsDatTpsTplType](http://rigaux.org/language-study/syntax-across-languages.html#VrsDatTpsTplType) [http://rigaux.org/language-study/syntax-across-languages.html#VrsDatTpsRng](http://rigaux.org/language-study/syntax-across-languages.html#VrsDatTpsRng) As John Carmack has put it and what drew me to Rust is that sometimes it feels like a blend of Haskell and C++.
&gt;It is actually not possible to disable the borrow checker. Well technically it is possible by using [https://github.com/thepowersgang/mrustc](https://github.com/thepowersgang/mrustc)
I am writing a small program to convert some HTML files using Servo's html5ever crate. My question however is about a section I've written with options and results interwined. This code works. But is there a much nicer way to write it? ```fn walk_content_header(node: &amp;Handle, post: &amp;mut Post) -&gt; Result&lt;(), Error&gt; { node.children.borrow().iter() .find(is_h1) .map(|title| title.children.borrow() .first() .map(|title| title.children.borrow() .first() .map(|title_str_node| match title_str_node.data { NodeData::Text { ref contents, } =&gt; { post.title = Some(contents.borrow().to_string()); Ok(()) }, _ =&gt; Err(format_err!("Post was expected to be '&lt;h1&gt;&lt;span&gt;text here&lt;/span&gt;&lt;/h1&gt;'. The 'text here' bit is missing.")) }) .ok_or_else(|| format_err!("Post h1 &gt; span is missing")) ) .ok_or_else(|| format_err!("Post h1 is missing")) ) .ok_or_else(|| format_err!("Post header is missing"))??? }``` Namely is there a way to write this which is much flatter? I did try this previously which is much flatter and so nicer. However the `borrow()` values are being dropped and lost. So I don't get to borrow each node for long enough. ``` fn walk_content_header(node: &amp;Handle, post: &amp;mut Post) -&gt; Result&lt;(), Error&gt; { node.children.borrow().iter() .find(is_h1) .and_then(|title| title.children.borrow().first()) .and_then(|title| title.children.borrow().first()) .map(|title_str_node| match title_str_node.data { NodeData::Text { ref contents, } =&gt; { post.title = Some(contents.borrow().to_string()); Ok(()) }, _ =&gt; Err(format_err!("Post was expected to be '&lt;h1&gt;&lt;span&gt;text here&lt;/span&gt;&lt;/h1&gt;'. The 'text here' bit is missing.")) }) .ok_or_else(|| format_err!("Post header is missing"))?; Ok(()) }```
What you're describing is very much how the different traits in Diesel are structured. I'm on mobile so I can't really go into too much specifics until some time tonight but the short answer to your question is yes Rust is the sort of language to do this, but the number of trait bounds you will write to do this in a type safe way may be more effort than the duplicated code you're trying to abstract. 
I wrote a parser and analysis framework for the OpenData the ALICE CERN experiment: \[alice-rs\]([https://github.com/cbourjau/alice-rs](https://github.com/cbourjau/alice-rs)). The C++ code in which the original framework is written is a total mess and reveres engineering took the majority of the time. Using Rust for this kind of project is a great choice. The speedups compared to the original framework were almost fantastic: Somewhere between 70% faster on the conservative side (doing exactly the same work in a realistic scenario without any of the experiment's specific code) to several orders of magnitude (using the experiment's analysis tools which do an absurd amount of unnecessary IO). I actually hope to have a paper publish which uses this framework sometimes soon.
Anaconda has one great problem going for it: it's the walled garden of a for-profit company. It also itself needs to be bootstrapped. Miniconda is the recommended way to do that, but even that has bootstrap issues, especially when you want to build and test against multiple versions of it. On 'nix that **pyenv** bash script OP is trying to replace is the overall best way to install and manage multiple versions of both standard cPython and pypy and Anaconda and Miniconda... it's incredibly useful, but definitely suffers from the issues that OP describes. So no **conda** _really_ isn't an alternative to what's being described here.
\&gt; Note that actual performance gap is larger because swc works on worker thread while babel works on event loop thread. I suck at understanding async/mp programming. But I though creating a thread generates overhead. Could you explain why — or link a post — why this is faster? 
Very interested in this, will take a look. That said: 1. Name is _terrible_... would assume it's a Python library somehow related to Cross-Origin Resource Sharing, and it comes very close to **pycor** (an existing pypi package for Korean-language NLP). Inventing acronyms can be a real issue. Sadly **pyup** is a thing... 2. Would need to equal **pyenv** to be able to achieve critical mass on platforms that do have bash ... the bash itself isn't a significant problem, but the difficult on Windows is. You'd need to be able to use this to compile/install Anaconda, Miniconda, pipi, Jython... 3. Suggest pulling back the opinionated install of **pip**, **black**, **yapf**, etc ... a configurable list, sure, but defaults that include items that are themselves problematically opinionated -- I'm looking at you, **black** and 88 bloody characters -- are just going annoy. Love me some Rust and completely agree on Python needing a single-file toolchain boostrapper ala **rustup**, but it's gonna need to be battle tested and it will have a major uphill battle without almost-parity with **pyenv**.
Oh. That is nice. We are also working with HDF5 files and doing mostly binning and mean calculation of unstructured data in climate research. It would be interesting to see how you guys solved this. Is it proprietary/closed source software? 
How does this compare to the other Rust crypto projects?
I have a Pro's/Con's list [here](https://brycx.github.io/2018/09/25/orion-pure-rust-crypto-lib.html). Performance-wise, I haven't seen major drawbacks when comparing to crates from RustCrypto. For example, when I benchmarked it, RustCrypto's portable SHA512 implementation was a little slower than orion's. I've submitted a PR to have it included in Brian Smith's [crypto-bench](https://github.com/briansmith/crypto-bench/pull/46), so that people may easily compare it to other libraries themselves. I hope that answers your question! 
There is [RFC 2515](https://github.com/rust-lang/rfcs/pull/2515), which proposes `type Foo = impl Bar` as the syntax for declaring existential type. 
Not only are they at the item level, they can be part of your crate's public API. This can be a problem if you have: `const MSG_SIZE = 32;` And change it to: `const MSG_SIZE = size_of::&lt;Message&gt;();` Now the type of `MSG_SIZE` silently changed from i32 to usize. That's a breaking change and could make a downstream crate quite unhappy.
But his is a downstream effect from the decision that allocation failure panics and _not_ one of `From` and certainly _not_ what the OP was getting at.
The fact that collecting into a `Vec&lt;u8&gt;` allocates heap memory has everything to do with `Vec` and nothing to do with `u8` bytes v.s. `str` Unicode. `Vec` always allocates if it is not empty.
I'm not saying that you should cave into this fella's demands, but you can learn go in a matter of hours if you ever feel like it. https://gobyexample.com
No, the `b` prefix is only on string literals (which makes them byte string literals). Where does your `&amp;str` variable come from, though? For example if you’re reading a file, try `std::fs::read` instead of `std::fs::read_to_string`.
I’m using it for Monte Carlo research
I did my bachelor thesis about computing Casimir forces in Rust. The source code can be found [here](https://github.com/ThomasdenH/casimir-fdfd). Cargo is really great for dependencies and testing. I used mainly `rayon` and `nalgebra` for the core. There are probably a lot of improvements to do, but Rust's ownership rules made it easy to reuse memory explicitly to reduce allocations.
For single-pass calculation of statistics, you can use my `average` crate. It does not yet use explicit SIMD though.
Is there a way to check if a position in the `.as_bytes()` is a valid position to slice the string? so as to use a O(1) indexing without breaking on unexpected unicode
I have been working on my new main loop library (cross platform, and for GUI applications among other things), [thin_main_loop](https://github.com/diwic/thin_main_loop). I've added Futures 0.3 support for that library recently. Even newer is [dbus-futures](https://github.com/diwic/dbus-rs/tree/master/dbus-futures), a crate so WIP that it isn't on crates.io yet. It is a D-Bus connection for Futures 0.3. Because of the way libdbus and Futures work, I have to write code for every event loop I want to support. So far, I've written support for thin_main_loop (Tokio support will come, at some point). There is a lot of work to do on both libraries, so if you want to collaborate, just let me know here or on github!
I'm using Rust to do some scientific computation. I switch to Rust from C++ and find that Rust can be a little faster than C++.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Rendy is released](https://www.reddit.com/r/rust_gamedev/comments/apeqdy/rendy_is_released/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
A part time project, code named ATEN, to provide a quantum secure document and message exchange platform that assumes SSL can be broken, and which leaves minimal bread crumbs. It also handles secure key management. 
Huge milestone for the Amethyst project! Hopefully we will see plenty of other engines picking this up as well.
How are you making sure that your APIs are constant-time ?
Linear algebra for sure. Affine transformations if you want to understand why we use 4 dimensional matrices/vectors to represent 3 dimensional space (but you can also just take that for what it is and move on). Some background with implicit surfaces is good if you want to add shapes to you raytracer, but you can almost always find a write up where someone else has the done the math. Geometry and trigonometry are useful to understand reflections and some of the other computations. Understanding derivates and integrals is helpful if you start looking at physically based models of raytracing. Physically based raytracing is really computing solutions to the lighting equation and that means computing an integral. But it's not an integral that you can solve analytically so we solve it numerically instead.
This looks great! If I understood the benchmarks correctly, this is quite a bit faster than allocating, which makes sense because it's already allocated. Have you used this in apps, or seen it improve performance in real code? I think this + lazy static could work quite nicely together
Constant-time comparisons are provided through the [subtle](https://crates.io/crates/subtle). So even though unsafe usage is being minimised, this is one of the cases where I simply didn't see using safe-Rust only as a better alternative. The only other implementation that requires constant-time execution is Poly1305, which in case of orion esentially is a port of Andrew Moons [poly1305-donna](https://github.com/floodyberry/poly1305-donna).
I am using Rust to write a [molecular simulation engine](https://github.com/lumol-org/lumol). This is my third attempt, afterr a try using Julia and another one using C++. I find Rust to be in the sweet spot in between, with a
Not to undermine your work, but to balance things a bit. ;) &gt; In terms of unsafe code, there's considerably less compared to what I've observed in other Rust crypto projects (mostly RustCrypto crates). Almost all of `unsafe`s in RustCrypto/hashes [fall](https://github.com/RustCrypto/hashes/search?p=1&amp;q=unsafe&amp;type=&amp;utf8=%E2%9C%93) into two categories: - Conversions from `GenericArray` into arrays. (will automatically go away with introduction of const generics) - Handling SIMD/assembly in `blake2`. (unfortunately we will have to live with with it until something like [this](https://internals.rust-lang.org/t/pre-pre-rfc-target-restriction-contexts/7163) is introduced) The only exception is `sha3` crate, but in your case you have the same amount of `unsafe` indirectly via [`tiny-keccak`](https://github.com/debris/tiny-keccak/search?utf8=%E2%9C%93&amp;q=unsafe&amp;type=). So I can't say I support such rejection of `unsafe`. Also if we'll take blake2b, `blake2` (without enabled features) shows up to 766 MB/s, while `orion` implementation shows up to 683 MB/s. (cheers to [cesarb](https://github.com/cesarb) for an efficient implementation which is currently borrowed by RustCrypto!) &gt;RustCrypto's portable SHA512 implementation was a little slower than orion's Note that RustCrypto benchmarks use buffers with lengths which are not power of 2 and measure performance of `input` function without finalization. Was this comparison done as part of `crypto-bench` or by running built-in benchmarks?
&gt; Not to undermine your work, but to balance things a bit. ;) Of course! &gt; The only exception is sha3 crate, but in your case you have the same amount of unsafe indirectly via tiny-keccak. So I can't say I support such rejection of unsafe. I see why you won't support the rejection in case of eg. the `block-buffer` crate (that uses unsafe IIRC). Though, in terms of `tiny-keccak`, most of its unsafe code is unneeded. For example, I have opened a PR to replace 10 of the 13 lines of unsafe with safe Rust. &gt; Note that RustCrypto benchmarks use buffers with lengths which are not power of 2 and measure performance of input function without finalization. Was this comparison done as part of crypto-bench or by running built-in benchmarks? I ran custom benchmarks locally, using the same operations (new, input, result), but with input lengths as power of 2. These most likely aren't that reliable, so I won't say that orion is definitely faster there. It wasn't done as part of crypto-bench, IIRC RustCrypto isn't a part of `crypto-bench` yet. Only the old `rust-crypto`? 
/u/Hywan (?) rewrote the WordPress block editor parsing system from PHP to a Rust library and the thing is around 5000 times faster. :D
You mean quantum mechanics?
No. I mean quantum computing. Most key exchange mechanisms rely on some form of public key encryption (SSL, PGP, etc) all of which use a trap door function that is computationaly hard to revers, such a factoring the product of very large prime numbers. That is not true if a quantum computer (QC) can be built. A QC can factor very large prime numbers is linear time, not exponential time. So adding more bits to the key doesn't buy you much. A QC secure algorithm uses a scheme that doesn't allow a QC to crack the key programatically. The attacker is then back to using brute force and cryptoanalysis to break the code. &amp;#x200B;
Very interesting. And also non-trivial. I will watch this with interest to see how you crack all the borrow/life time issues. Good work. 
Ah, I meant that too. I'm not sure you're using the word as in quantum computing or as in Firefox Quantum. I'm looking forward to seeing your work!
From my companies web page: &amp;#x200B; ## This is a work in progress ATEN is about security. About the ability to exchange a document with a counterpart in the knowledge that the document will remain absolutely secure. Also, the mere fact that you have exchanged a document is also held securely. This is a zero leak system. ATEN consists of a number of different components which combine together to provide security at a provable level. There is a secure key management system that is maintained in a secure encrypted repository. You need your key to be able to communicate with this, so we provide a hardware key management tool that keeps copies of your keys. This stores your private key, your public key and the ATEN servers public key. You use the cloud component to request the public key for your document recipient. Each document is encrypted at source using the highest grade of AES encryption. The keys are random. The keys themselves are then encrypted with the recipients public key and signed with your private key. This way, only the true recipient can read the document and they can be absolutely sure that it was sent by you. All the metadata about the document is also encrypted. This means that anyone trying to do traffic analysis based on who sent a document to whom, even if they can't read the document, will be frustrated. The transfer of the documents and the meta data is further encrypted using the ATEN server keys. This way an eavesdropper, even one who has broken the SSL encryption used by HTTPS, can tell nothing of what is going on. The ATEN server supports only one public endpoint with all the usual command and control that is normally sent as part of the URL being encrypted as well. In the ATEN storage platform, all documents are encrypted with keys, that as was stated, are encrypted. ATEN has no access to these keys, and hence is unable to read the documents or the metadata. It is clear that ATEN can be abused. Hence it is not offered for sale at this time. Each implementation will be accompanied with consultancy. Clients will be required to go through rigorous compliance checks. This is not a case of simply downloading the code and getting started. At the very least, clients need to understand that using ATEN is very different indeed to using Outlook and GMail. Billing for ATEN has yet to be finalised, but the billing also will not leave a bread crumb trail to follow. For further information, please make contact with Osiris for a confidential chat about your requirements. &amp;#x200B; *The Hardware Key Management is a challenge, but Rust on a single board computer, secured in a resin block is where my ideas are headed. As I don't know the answer at present, I have kicked this can down the road!* 
How is this an advantage over Python, Ruby, C# or Java, just to name a few?
A language can have both a GC and RAII.
Thank you! So your local `from x import y` just transpile to `use x::y;`. But nothing actually happens to dependencies. And there is really not much sense right now, since most likely nothing will compile at all. 
sure: fn valid_utf8_char(data: &amp;[u8]) -&gt; bool { match std::str::from_utf8(&amp;data[0..std::cmp::min(data.len(), 4)]) { Ok(s) =&gt; s.chars().next().is_some(), Err(e) =&gt; e.valid_up_to() &gt; 0, } } 
Ohhhhh I see. Thanks!
&gt; It's a constraint imposed by a remote service that I'm running my code on. It's a bit contrived. I don't think I understand this. Can you say more? The only way I can perceive this is if you have to hand your code to the service, and it owns the responsibility of compiling and running it, but doesn't provide any way to add external crate dependencies. My guess is that this will be a very annoying way to use Rust, since we rely quite a bit on the ecosystem to provide important functionality. &gt; I would love to hear your suggestions if this was not a restriction. I don't have one yet. But I will soon. The crate is under development. In any case, it's not all that much different than the suggestions given to you. Instead of working with `Vec&lt;u8&gt;`/`&amp;[u8]`, you'd get proper byte string types. In any case, I was asking because I wanted to hear about constraints that would prevent the use of said crate.
Any suggestions on how someone with zero knowledge of graphics programming might learn how to use something like this?
Thank you, there were many answers about assuming ASCII without saying how to manage possible problems
I never said it couldn't... but it's not common among popular languages and, unless the language is carefully architected to specifically address this, accidentally picking the GC to deal with stuff that should be cleaned up promptly is still a risk.
I'm in the process of adding enums to [tox](https://github.com/Lapz/tox). So far can parse enums correctly and i'm currently working on typechecking and implementing them within the VM. I hope to have it done by friday but I have two assignments due this week.
I think getting the fundamentals is easier by starting with some `OpenGL 3` tutorials. This seems to be a Vulkan like API, which means that it is a very low level API. Normally you wouldn't use this kind of API directly in an application. These kind of APIs are more appropriate to write graphics engines, which are then used by applications. 
I tried several times to write graph algorithms that take mathematical expressions as input. It’s much too inconvenient so I went back to C++.
For it to work reasonably well, some powerful static analysis should be implemented. Since Python doesn't have tools to fight borrow checker you will be better off starting new project directly in Rust. But I was imagining a workflow when you quickly write and debug some rust-style Python code using theirs wondrous tooling, then transpile and copy it to your Rust project and then add some `&amp;` and `.clone()` to calm down the borrow checker. Such use case is already available as of now.
Still working on [Eko](https://github.com/ravernkoh/eko), a simple scripting language written in Rust. I’m in the middle of a rewrite tho :(
I am very new to coding and am trying to learn functions, I do not understand how to use arguments that aren't integers, I tried String but that doesn't work. Also I dont know how to print a line with multiple arguments, in this case I want to print the name all in one println! statement. Any help would be greatly appreciated, many thanks. Here is the code: fn main() { another\_function(Joe, Bloggs); } fn another\_function(x: String , y: String) { println!("My first name is: {}", x); println!("My last name is: {}", y); }
That's a nice comparison you got! Thank you. Since when Carmack started bringing people into Rust? &amp;#x200B;
Thank you! Actually I once finished some Go tutorial just like yours, but I don't feel like I can confidently say that "I know golang"
Thanks. Is `collect` not relevant in this scenario?
Understood.
Awesome work! Very excited to see Rendy replacing the built-in renderer in Amethyst.
That's already pretty correct, good shot. The problem is you calling your function: `another_function(Joe, Bloggs);`. You're not actually passing `Strings`, but identifiers. It would work if those identifiers would designate variables that are `String`s like so: fn main() { let name_joe: String = "Joe".to_string(); let name_bloggs: String = "Bloggs".to_string(); another_function(name_joe, name_bloggs); } fn another_function(x: String , y: String){ println!("My first name is: {}", x); println!("My last name is: {}", y); } But you don't always need variables, you can pass the values directly: fn main() { another_function("Joe".to_string(), "Bloggs".to_string()); } fn another_function(x: String , y: String){ println!("My first name is: {}", x); println!("My last name is: {}", y); } Now, as to why we're making `String`s like `"Bloggs".to_string()`, that's a pretty rust-specific thing. If you're just starting out, I'd suggested taking it at face value and moving on, it will be important later, but too much right now, I suppose.
You're missing two things: first, \`Joe\` and \`Bloggs\` are not strings here, they're identifiers. They'd need to be wrapped in \`"\`s to be strings. Second, Rust has two kinds of strings; \`"Joe"\` would be a \`&amp;str\`, not a \`String\`. You have two options: `another_function(String::from("Joe"), String::from("Bloggs"));` or `fn another_function(x: &amp;str, y: &amp;str) {` Either will make this work. The latter is what's more idiomatic in this case. &amp;#x200B;
&gt;Since when Carmack started bringing people into Rust? He tweeted about it a day or two ago.
There's a bunch of engines now.
Beyond this, it's about the ecosystem. Normally, I can't just expect others' code to be threadsafe. But in Rust, I can. That's huge.
Creating a thread does create a little bit of overhead (but we're talking milliseconds), but once you have 2 threads, then in theory you can process things twice as fast (in practice it won't be quite twice as fast, because there is some overhead in terms of coordinating the work between the threads, but for some workloads you can get quite close to this). This works for N threads, up to the number of CPU cores in your machine.
Nice to know people can be drawn to Rust that quickly
The type argument for `collect` is the type of the collection to return; `u8` is the item type, not the collection. You would there want `Vec&lt;u8&gt;` instead. (Remember, vectors aren’t the only thing you can collect to: you can collect to a `HashSet`, for example, or if you have an iterator of `char`s you can collect to `String`.)
It seems to me that the main reason it's so hard is that we don't have a commonly supported shared ABI that offers more than the C ABI. And every language uses its own memory representations for complex objects (Strings, HashMaps, etc).
 let hello = "hello"; println!("{:#?}", hello.bytes().collect::&lt;Vec&lt;u8&gt;&gt;()) Thanks, that works like a charm.
As a fellow, uh, _experimented_ Rustafarian - thanks!
Ok thanks! It’s really other order of magnitude.
I don't like to argue about naming, but I'd like to share the fact that I first read it _YHitler_ which made me a little confused to say the least…
Many thanks for the help!
Many thanks for the help!
Any time!
Seems a bit of a solution in search of a problem, for me. Unless this load balancer is actually reimplementing a significant chunk of functionality of actix, it doesn’t make sense to pull in such a huge dependency for something that should that should be lean and mean. I guess actix is modular, though, so maybe there’s something smaller than actix-web that fits this use case?
/r/rustjerk more likely
Nice! I have thought about doing this some many times :) It always seemed like a sub-set of Python could be a nice prototyping language for Rust.
Thanks for the reply! I have been tinkering around with it for a few hours now and, unfortunately, I am now seeing exactly what you mean... Thanks for the comment, do you know in your experience any good ideas for generalization of the process?
I can highly recommend https://learnopengl.com/ for anyone looking to learn modern OpenGL. It's C++, but using [gl](https://crates.io/crates/gl) and [glutin](https://crates.io/crates/glutin) one can get pretty much the same result using Rust, though with a lot of `unsafe`.
It will work, but it's a silly option to choose, because you're doing the conversion twice! (and the extra one allocates!) Internally, `bytes()` is defined as: pub fn bytes(&amp;self) -&gt; Bytes { Bytes(self.as_bytes().iter().cloned()) } So by doing `hello.bytes().collect::&lt;u8&gt;()` you are actually doing: Bytes(hello.as_bytes().iter().cloned()).collect::&lt;u8&gt;() But you already have a byte slice by the time you have done `hello.as_bytes()`, so you should just do that.
He did not bring me into Rust, i had similar feelings about it when it was pre 1.0.
&gt; this does not apply for the setresuid syscall, which is applied on a per-thread basis. OK, you're right I had missed that you were using the syscall directly but as the other person said, mixing two different privilege levels in the same address space really doesn't work in general. You run a lot of risk of "leakage", and it's also not portable for what it's worth. &gt; rather than requiring the user to start a system service in the background This can and should be transparent to the user if done via DBus activation. A good example here is how e.g. GNOME Control Center's date/time UI [calls out to systemd's timedated service](https://gitlab.gnome.org/GNOME/gnome-control-center/blob/7f905e789c04b3d99155361dc531fa93bf36aa12/panels/datetime/cc-datetime-panel.c#L406). You can even have the "mechanism" in Polkit terms be the same binary. Also, while the whole thing is oriented around DBus, you can pass a file descriptor over to your mechanism and use e.g. Servo's [ipc channel](https://github.com/servo/ipc-channel). I am aware this requires more "installation" to use your software; it can't just be `sudo myprog`. But Polkit was designed the way it is today for a reason. (I am a former upstream maintainer of DBus, on and off contributor to Polkit including having written the patch for a recent [polkit security issue](https://gitlab.freedesktop.org/polkit/polkit/issues/75) and the general ecosystem here for quite a long time) Or if all you care about is running your program from the CLI via `sudo/pkexec`, then I'd agree with the other poster who suggested using fork/exec instead. A trick here if you want to share the same binary is to "re-exec" yourself. I have a [WIP multiprocessing PR](https://github.com/projectatomic/rpm-ostree/pull/1680) for rpmostree; see [this bit of code using /proc/self/exec](https://github.com/projectatomic/rpm-ostree/pull/1680/commits/630878b80797095141e9c0b76da323b27fb01b6b#diff-be1fdae9bc20c15ea20e99c9a2166619R55) to do the "re-exec self" trick. 
Now I'm wondering if one could make a version of it that works on a fixed point representation... Probably not, but it's a neat thought.
In my case it's a misunderstanding. Typestate drew me to Rust.
This is super cool. I was just having this issue in one of my projects. Note that you do not need to use \`extern crate\`, you can write as well \`use crate as foo\` or \`use foo\_renamed as foo\`.
Macros are the easiest way to do this without writing a lot of type information. (Sorry for again not being able to go into more detail, you caught me on a travel day)
This might be a good place to start: https://github.com/Lokathor/learn-gfx-hal It is a series of tutorials in the same vein as learnopengl.com Rendy will be making things a little more simple than that, but until there are Rendy tutorials, the tutorial on the layer Rendy is built on would be next best! 
Well... there's two hard things in computer science. Cache invalidation, naming things and off-by-one errors. Pycors was easy to remember, short but google-able. Since I did not want to pass too much time finding a name, I picked one so I could work on what I wanted. I'm open to a rename, [I've opened an issue for that](https://github.com/nbigaouette/pycors/issues/40). Regarding features, I prefer to release early, release often. That allows getting feedback, re-aligning priorities and failing fast. In no way I can compete with pyenv's features from day one. And not from day two either. But scratching my itch I can achieve a lot still. That's a good Rust experience. It solves a real issue I have. It seems easily extendible. I'm not expecting to dislodge pyenv anytime soon. But that shouldn't prevent me from exploration and scratching my own itch! As for the installs, I too am uncomfortable with the opinionated way of doing it. Another issue is the reproducibility. We suffered a lot with pipenv breaking with upgrades so some people/groups try to pin its version. Another issue is what to do when such an installation fails. Continue? Stop Python installation? How is the error reported? How is the setup tested? Some options are providing flags arguments, a config file or an interactive session with the user with questions. Any of those required some work which I did not want to do first. So since I'm the only one using it for now, I've decided to add those until a better solution is found. Opened [issue 41 for that](https://github.com/nbigaouette/pycors/issues/41). Except from pip being upgraded, you don't have to use what's installed. And even pip will complain if it's outdated itself. I don't have a preference for either blakc or yapf or any other linters. But having them installed will prevent VSCode from complaining every time I open a Python file. Except from that, don't use it if you don't like it.
Thanks! In terms of theoretical performance, pulling from the object pool is constant regardless of the size of the contents in the pool. If you plan to pool "cheap" allocations the benefit is negligible, example being 4k or 8k buffers. This pattern really shines with "costly" allocations because they are always guaranteed to be the speed at which you can pull from the pool. My original use case was in a logging agent (sends logs for your machine to a centralized point). I was making an insane amount of allocations (40k/sec), most of which were costly. This was the project I used to reduce that to a manageable amount. 
I would have written: *sum types are additive*.
For those looking to try out stuff in this space- also see `asdf`. 
Yeah that is correct, but not a nice workflow for the user in my opinion :) 
I've previously used `serde_json::Deserializer::from_str(input).into_iter::&lt;Type&gt;()`
A quick&amp;dirty example that might help you: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1b72542f7c604393b12d82d0d07c08aa
Didn't know that serde_json deserialization supports iterators. Sweet!
I just read the answer of /u/killercup which suggests that iterators work for deserialization as well. I'll leave it up to you to change my code as an exercise :-)
Could you add a section to the README that compares &amp; contrasts this with other crates that solved similar problems? For example, [`thread_local`](https://docs.rs/thread_local).
There's some rust work going on in [TVM](https://github.com/dmlc/tvm) that I've chipped into a bit. TVM is really cool, it's a compiler framework for deep learning. Basically you give it a graph of array operations and it optimizes and compiles them to a fast executable, targeting CPU, GPU, FPGA, webgl -- there's like 12 different backends at this point. I'm hoping to eventually use it to implement a rust HPC / deep learning library, so I can stop writing that stuff in Python and C++. That's a ways off though.
I don't see how what you're saying is relevant to the post. From my understanding the "cooperation" the title refers to is cross-language tooling, not FFI or ABIs needed for that.
Owh, sorry for misunderstanding, but now I get it :) &gt;traits are like classes, enums are like data I remember reading [this](https://science.raphael.poss.name/rust-for-functional-programmers.html) article with comparison of Rust, OCaml and Haskell and similarities are striking.
The table of contents links are currently broken since they're missing .html at the end :)
&gt; The first is the injection interface by which Meson tells Cargo where and how it built liba. The second is the extraction interface by which Meson gets information from Cargo about what it built and how. Neither of these exist in a form that would be actually useful. You can't tell cargo where and how Meson built liba because cargo does not care. Some library in the dependency graph of the Rust project that links liba cares about this, and what you have to do is to tell this library where liba is. Most libraries read an environment variable where they expect the path to liba to be specified. If that exist, they use that, and if not, they compile liba from source themselves. Also, to get information about what cargo built and how what everybody does is invoking `cargo build --build-plan` (or `cargo metadata`) and just extract whatever you need from the json file. Anybody on IRC, Discord, or Zulip would have told the author this if it would have bothered to actually ask the question. 
I wrote an 8-puzzle solver as a part of a course in grad school in rust, and decided to publish it on [crates.io](https://crates.io/crates/project_1_itcs_6156), and for some reason crates.io tells me 26 people have downloaded it. No idea why anyone would be interested in my lame project lol. The reason I published it was that I expected the `cargo doc` documentation of my package would end up on [docs.rs](https://docs.rs/), but it only showed the README.md for some reason. What's up with that? It would be so amazing to automatically have documentation published every time you publish something on `cargo`.
Is it because my project is not a library?
Turns out it is indeed because of how Git does its output. Git will write to stderr even if successful for some of its commands. Silly me to not think to look into Git's implementations and thinking it was an issue with `std::process::Command` . Thank you for pointing me in the right direction!
Oh shoot, will get that updated ASAP.
I don't know, I use almost nothing Rust provides as solution for multithreading problems as I rarely use it myself. In any language you write `par_iter` or analogue and don't worry about anything, and it works just fine in 99% cases. For me, rust is much more robust and easy-to-use than my primary language - C#. For example, let's take a look on this code: ```cs interface IFoo { int X { get; } } int x = Foo().X; ``` It compiles just fine. Does it work? Not really. Because `Foo` may fail, and even if it doesn't it could return `null`. Now let's check how it could look in Rust: ``` let x: u32 = foo()??.X; ``` You actually have to places where it could to wrong, since `foo()` signature is actually `Result&lt;Option&lt;IFoo&gt;, SomeError&gt;`. You don't see it in C# but you do it in Rust. So you have two problems in C#: 1. you check values that cannot be null/cannot fail - bad, but ok 2. you don't check values in possibly invalid state/don't preserve state and do a proper rollback when error occurs - absolutely terrible situation. I'm happy rust gives me confidence in these situations. Not to mention macro system. I don't need hacky compiler extensions with possible problems, I just use builtin tool and it just works. P.S. Borrowchecker also makes it much easier to use resources such as sockets/files/... It's just several bullets, but they have immensive implications on the whole ecosystem. And I didn't mention anything related to multithreading :) 
Thanks, does the Type from into\_iter have to be a Rust primitive, and what happens if the type per key isn't the same? I'll try this out for myself, but I'm in the interim curious.
Can someone please point me towards an explanation or documentation of the `default fn` syntax used here: [https://doc.rust-lang.org/src/alloc/string.rs.html#2157](https://doc.rust-lang.org/src/alloc/string.rs.html#2157).
I'm working on a runtime for the [Ink](https://github.com/inkle/ink) language, which is made for writing Interactive Fiction games. I can currently load the JSON "bytecode" into useful data structures and have started writing the runtime engine.
Thanks /u/silwol, the map solution would work when the type is the same per value in the JSON object, but would that not work if they're not the same? &amp;#x200B; I expect each line to be a JSON object, so I'm iterating through the values and checking their type (match value { Value::String(s) =&gt; {}}), and then using the value. I hadn't thought of this when I posted my question. I'll post a gist once I have my code working. &amp;#x200B;
A bit off-topic and completely naive, but, are there reasons not to use Amethyst to build a desktop application with a GUI ?
&gt; I don't think it covers which trait it chooses by default, or if it just errors out, though. [It errors out.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=cfeb6ccf5c497382888e642c45fe8219)
My question was rather about how it is being verified, e.g., on CI, that the machine code being generated is indeed constant time. Just because Rust code does look constant time does not mean that LLVM might not be generating non-constant-time code behind your back.
You might consider using an [untagged enum](https://serde.rs/enum-representations.html#untagged) if there's a fixed number of formats that you can identify.
Why is it better practice to pass a slice to a function instead of a String?
I'd probably use `hyper` here.
Passing a String means that you want this string to be destroyed at the end of the function call. That’s rarely what you want. Sometimes it is though!
Agreed. 
When you implement the trait, you don’t have to implement that method. If you don’t, this is the implementation you get. A great example is Iterator, only next() doesn’t have a default implementation. Implement next, get the rest for free.
I'm not an expert in this domain, but isn't `thread_local` something of an apple to this crate's orange? `object-pool` seems oriented towards providing a region-based memory management strategy to both sync and async contexts. Meanwhile, `thread_local` might use a pool under the hood but seems oriented towards avoiding data races and locking out iterations over all threads' copies of a value. If you or anybody else can explain to me something I'm (probably) not understanding, I'd love to learn more about this domain. :)
But passing a String has the function take ownership and yes, destroy it. But can’t you just pass an &amp;String and that doesn’t happen?
This is great. Been planning to mess around with Rendy for a bit and it's nice to have it on crates.io 
You might be right! I was intentionally vague in my request because I didn't do the compare/contrast myself. READMEs are a good place to set the context of your crate in the ecosystem.
Ah, that's a different question. The reason there is, a \`&amp;str\` is a pointer to some string data, as well as a length. A \`String\` is a pointer to some data, a length, and a capacity. A \`&amp;T\` is a pointer. This means that a \`&amp;String\` is a pointer to a pointer to some data, a length, and a capacity. This means you have to follow two pointers, not one, to get at the data. The only useful thing a \`String\` has that a \`&amp;str\` doesn't is a capacity, and you rarely need to read that value, so the overhead of \`&amp;String\` is almost never worth it. Make sense?
I'm planning on porting my gameboy emulator to wasm. I designed it from day one to work on both native platforms and non-emscripten wasm, so we'll see whether I achieved my design goal.
I've been improving game compatibility for my [MegaZeux runtime](https://github.com/jdm/mzxplay), including [adding music playback](https://github.com/jdm/mzxplay/commit/8f12063fad2e9e865795f67aa3715e702396fcf0). Next step is to add sound effect playback and mix that with the game audio, along with adding volume fade effects and support for pausing Robotic program execution until fades are complete.
If for "GUI" your mean for a game, sure. But normal apps are **far better** with native toolkits. So, far, is not even a contest. &amp;#x200B; P.D: Tip if not get why: Check the history in how any cross-platform UI library failed, fail and will fail forever and ever, including html...
The `new_algo` branch of [pulldown-cmark](https://github.com/raphlinus/pulldown-cmark). We working to get it to pass the commonmark 0.28 test suite. We've gotten pretty close, with approximately 95% of tests passing!
Makes perfect sense, thanks! One question, I know that capacity is the amount of memory that it received from the operating system, so when is this ever important?
I personally have never written code that's needed to query the capacity. The only time I've ever cared was to use \`String::with\_capacity\` to make a new string with a given one to reduce some overall allocations. It existing is \*extremely\* important to the \*internals\* of \`String\`, but as a user, I don't care much.
Okay beautiful. Thanks a lot 
I would be more than happy too. Thanks for taking interest.
Indeed. From your original comment, I believe you may be thinking of server situations where the overhead from the "thread per request" model can become the limiting factor. The difference here is that servers hitting this limit are ones serving 10k-100k+ requests per second. At this scale, the thread startup overhead can become the limiting factor - because you are starting 10k-100k threads (and those milliseconds start to add up). And this can be mitigated by using "async I/O", which allows multiple requests to be processed efficiently by fewer (or even one) threads. But if you are just running a few threads, or your number of threads is fixed, then the overhead is negligible.
Thanks!
Qt doesn’t seem to have failed. Quite the opposite, TBH.
&gt; Need a nice CLI? Clap. You should also check out [`structopt`](https://crates.io/crates/structopt) which makes writing CLI apps even nicer (it actually uses `clap` underneath).
I'm working in the brain tractography (google it in images) field for 5 years now, and porting code from Python to Rust in 2018. What started as a test/poc of Rust is now a major part of our codebase. We've seen various ranges of speedup, from 2x to 25x. It could have been better but large parts of our Python code was in Cython. &amp;#x200B; ndarray and rayon have been essential to our success. ndarray is not a drop-in replacement for numpy but it's really nice and it discourages waste, like masked arrays, it forces you to think more about what you're doing. As for rayon, it's simply wonderful. In makes parallelism in Rust a **pleasure**!
If you're brave you can try out this: &amp;#x200B; [https://github.com/willi-kappler/gronn](https://github.com/willi-kappler/gronn) &amp;#x200B; I need to add documentation and more examples, but it works already with simple stuff. &amp;#x200B;
Looks cool, maybe you should look at doryens rust library: [https://github.com/jice-nospam/doryen-rs](https://github.com/jice-nospam/doryen-rs)
I think the question was more about the default keyword instead of just default implementations as you can already do that in stable Rust. The default thing has to do with some tricky situations with specialization (which isn't stable yet). I don't know the exact issue that the default keyword solves for specialization.
I completely missed this isn’t in a trait. You’re 100% right, this is related to specialization. I know less about that and already made a mistake so I’ll bow out!
Yep. And it's even even worse when it can be inferred later on in the program. When you use `let msg_size = 32;`, the compiler won't automatically make it a particular type. You can actually pass it to a function that takes a `usize`, or an `i8`, etc. and at that moment it will be inferred to have that type. So if this happened with global `statics`s and `const`s it would be particularly confusing. A language certainly can do that. In Haskell you don't need to specify the types of anything (except the occasional case where it can't be inferred). But it would be considered good style to do so here anyway. I think I saw a proposal at some point for some limited form of inference for global variables? Or maybe I'm imagining this. It would be nice to have some compromise here if possible (but it may not be).
More important, when passing a `&amp;String` you are demanding that the caller provide you a borrow to an _allocated String_. This prevents the caller from passing string literals or strings sourced from somewhere other than the default allocated String. There are _very few_ reasons to actually want to pass a `&amp;String` (or `&amp;Vec&lt;T&gt;` for that matter), the only additional capability that they have over `&amp;str` or `&amp;[T]` is access to the allocation's underlying capacity. If you need a shared borrow, just pass `&amp;str` or `&amp;[T]`, your callers will thank you for the added flexibility.
Ah, apologies for the misunderstanding. There are currently no tests to verify actual constant-time execution. The subtle crate, when using the nightly feature, uses inline assembly to attempt to "fool" the compiler. Using assembly is the best method available, to my knowledge, to make code run in constant time. I have been meaning to look into setting up [dudect-bencher](https://github.com/rozbb/dudect-bencher), but haven't come around to it yet. If you have any tips or useful resources please do share!
Yeah, PHP is notorious for being very slow. This is not a problem on the web usually because compute power is not the bottleneck (IO is, eg loading files, reading database, etc.). I consider a speedup of 3x to be pretty minor when going from an interpreted dynamic language (php) to a static compiled language (rust).
What would you pass instead of &amp;Vec?
Don't disagree with the sentiment, but what would it mean for a language to advertise 'tool compatibility with c/c++'? I think tooling in general is one of the biggest problems in both of those languages, so it is incredibly fractured. Here is a short list: - cmake - autotools - Conan - Meson - second - gnu make based - vs projects I know this list is a combination of (meta-)build tools and dependency systems, and I've omitted the fact that a majority of c/c++ projects are probably have a huge dose of flavor/roll-your-own/custom tooling attached. I doubt any of the existing tooling has enough market share and/or stability to make it a worthwhile goal or compatibility target. Tooling is actually a big reason I think a language like rust has a chance of supplanting existing options
Putting this here since it's relevant to Cargo; as part of this work, we'll be gaining some new matchers, for example.
It doesn't need **pyenv**-parity even day ten, I just think that _if_ you want it to go big it'll need to move in that direction, to give it a wider appeal and marketing wedge argument. So I suppose I'd say try not to introduce anything that conflicts with that goal along the way. The reality is that a single-file Windows / Mac / 'Nix interpreter bootstrapper is sorely lacking and could get serious traction, but in doing so it will naturally overlap a significant amount of **pyenv**'s bailiwick (installing Python interpreters, but truly cross platform), and is making transitioning off of **pyenv** to **pycors** would increase its natural draw and expand its uptake. Ideally it would do that while also not getting drawn off into distractions like installing personal-preference dev tools that come and go like the seasons. Bootstrapping the interprets is enough of a job to handle well.
As /u/ErichDonGubler mentioned, you can use an untagged enum. You can do so either at top level (e.g. if you have a limited number of struct variants), or at any deeper level (e.g. have a BTreeMap&lt;String, YourUntaggedEnum&gt;, where you can iterate over each entry).
&gt; I think there are opportunities for low level networking packages in Rust which focus on throughput for these types of workloads. Pnet is very handy for handling and manipulating packets in user space, but there is no Async and at the IP/TCP layers much of the packet manipulation is copying bytes around in the background. This is why I personally prefer the Sans I/O paradigm: a library strictly manipulating the packet (raw bytes) in place would allow zero-copy, and let the caller decide how to receive/send.
Depends on what is supposed to happen. Usually, you want a function to just "look at" that string and not take ownership. Like this: fn show(text: &amp;str) { println!("{}", text); } That's where `&amp;str` comes it. The function would borrow that string for the duration it executes. And `&amp;str` is preferable to `&amp;String` in that `&amp;str` is a little more flexible: it could refer to a part of a `String` or to something that's not even heap-allocated (string literal). If you want the function to take ownership of a `String` (for example, because it would send it off to another thread or move it somwhere else like here struct Person { name: String, } impl Person { fn new(name: String) -&gt; Self { Person { name } } } then passing a `String` by value is probably a good idea.
Not all heroes wear capes...
&lt;3
Woot! This is part of my plan for the week too, shepherding this through. The other major goal I have is to get [druid](https://github.com/xi-editor/druid) running on mac, and as a stretch goal, making it run as a VST plugin. I'm actively chatting with the rust-vst folks about cooperating there.
I'm not super deep into proc macros but i think it's possible. I will probably add this feature in the future.
Thanks for the tips. I will take a look at your suggested solution. I don't know if proc macro crates allows re-exporting or not.
I published a crate over the weekend, [ability](https://docs.rs/ability/0.1.0/ability/). It provides a procedural macro for generating vtables for FFI, with a focus on providing ABI compatibility for traits across compiler versions. The goal is to allow apps to specify plugin/extension APIs using traits. I don't have a ton of time to work on it, so contributions are very welcome. It's not functioning perfectly at the moment. 
Thanks. The whole thing with &amp;str gets confusing because you still need to pass a reference for a literal and because it can be heap or stack data. Thanks for your reply
The PHP interpreter generally starts fairly quickly, and the article notes that they sometimes hit maximum exec time on large stacks.
Working some more on (metered-rs)[https://github.com/magnet/metered-rs] for metrics using proc_macros :)
On the one hand 3x even seems slow, on the other hand I'd guess it's mostly alloc-heavy string munging and hashmap manipulations, so Rust isn't going to gain *that* much, what you'll gain in raw computation you might even lose in slower allocations. Could be worth benching inferno with jemalloc now that Rust's been on the "system allocator" train for 4 releases or so.
If you want to turn your byte array back into a `&amp;str`, your best bet is probably `std::str::from_utf8_unchecked()` (or `std::str::from_utf8()` if you're willing to incur the overhead of checking that all the bytes are ASCII to avoid `unsafe`). Again, no copying/allocation happens: the bytes are just cast into a str. An ASCII crate is a thing, but you said you didn't want one?
It's possible to use Valgrind to check to some extent constant-time properties. (we essentially mark key data as uninitialized and track if there any branches dependent on it) Take a look at [`ctrgrind`](https://github.com/RustCrypto/utils/tree/master/ctgrind) which is a descendant of [agl/ctgrind](https://github.com/agl/ctgrind).
Desktop applications usually don't update the window every display refresh, and when they do is often a section of the window. This allows application focused GUI toolkits to save on processing time (and by extension battery life) by skipping unnecessary redraws. By comparison games put more emphasis on having a similar level of processing time frame to frame because it's more important that everything gets consistently updated between display refreshes. It's better to just redraw everything in most games then to try to figure out what changed.
As a bit of a follow up. I couldn't find a meaningful way to compare \`thread \_local\` and \`object-pool\`. I think it [/u/ErichDonGubler](https://www.reddit.com/u/warlizard) hit the nail on the head. I did test a \`SyncPool\` implementation and there was a massive improvement. Down to 3.78ns compared to the 10.02ns of the \`Pool\` implementation. I' can't think of a real apples to apples test I can do, but I am open to ideas. I think the only real comparable crate out there is [LifeGuard](https://github.com/zslayton/lifeguard). The crate isn't thread-safe and pulling takes 9.52ns. That's originally why I wrote this crate, I needed a thread-safe alternative. If a \`SyncPool\` is something of value, I am more than happy to add that as part of this crate. At 3.78ns per pull, I would be hard pressed to think a global allocator could beat that. 
This is related to a feature called "specialization" which allows "overlapping trait implementations". This is usually not allowed. We have two trait implementations. The very generic impl&lt;T: fmt::Display + ?Sized&gt; ToString for T { default fn to_string(&amp;self) -&gt; String { use core::fmt::Write; let mut buf = String::new(); buf.write_fmt(format_args!("{}", self)) .expect("a Display implementation return an error unexpectedly"); buf.shrink_to_fit(); buf } } for all types that also implement `Display`. But for some types this generic implementation might not be the best one (w.r.t. performance or other properties). For example, for `str` we can avoid the complete std::fmd machinery and go straight to a `String` like this: impl ToString for str { fn to_string(&amp;self) -&gt; String { String::from(self) } } So now, we have two trait implementations which are *both* applicable for `str` because `str` also implements `Display`. Before we had this specialization feature, the compiler would complain about overlapping trait implementations. But being able to do so has benefits. Clearly, the second implementation is preferable for `str`. This is where my understanding of the topic ends. I think the tricky part is in deciding which implementation is "better". This may get pretty complicated. I think that requiring the more general implementation (and therefore less favorable) to be defined as `default` is about making this decision easier for the compiler.
I wasn't previously aware of this crate, but it looks really interesting. Thanks for the heads-up!
Why can't a Stream take a resumption argument?
Good to see people interested. Next I'm going to work on integrating rendy into amethyst and polishing rough edges in the process.
Something like that would be perfect for this project
The post mentions but doesn't detail the problems with semver. What issues need fixing? I've sort of thought of SemVer as "good enough" and my bias is normally to lean towards "if it ain't broke..." 
My goal with this crate was to have a mechanism to reuse buffers. I'm sure this community can find other use cases but that was mine. I had looked at some other `region-based memory management strategies` before writing this crate. I looked at a few in particular. [slab](https://github.com/carllerche/slab) [rust-typed-arena](https://github.com/SimonSapin/rust-typed-arena) [generational-arena](https://github.com/fitzgen/generational-arena) [pool](https://github.com/carllerche/pool) [lifeguard](https://github.com/zslayton/lifeguard) All of these are awesome projects but they just didn't align with my exact use case. * slab, rust-typed-arena and generational-arena were optimised for fast deallocation but not avoiding it all together. * pool used a bunch of unsafe and also didn't have deattach and attach semantics * lifeguard as I stated above had a tad too much overhead and wasn't thread-safe Hopefully, that gave you some background on what my thinking was behind this and what is floating around the rust eco-system similar to this.
Here's my biggest one: “Matchers” or “ranges” (even the terminology is split up thanks to the lack of a spec!) are not defined in semver. It only defines how to version a particular software artifact, it cannot answer the question “does version 1.2.3 fit the constraint &gt; 1.0.0?” Does that make sense? The “&gt; 1.0.0” part is undefined. That includes things like “is that space required there?”, and so is an interoperabilty issue.
https://touch-point-tehnology.com
very cool, I will be following this closely! I use poetry and pyenv where available, but like you said pyenv doesn't exist on windows so this would be a perfect cross-platform complement to poetry!
I have a few structs and enums that are each within their own file, so they are each within their own mod. I keep it this way for code organization. But for API exporting, I want them all exported at crate-root level. &amp;#x200B; As of now, I do \`pub mod A; pub mod B; pub use A::StructA; pub use A::StructB; pub use B::EnumC; pub use B::EnumD;\` &amp;#x200B; But (at least as far as docs are concerned), StructA is still under mod A. Is there a way to either break up a mod into multiple files, or fully merge the mod at api level?
You will probably have to do more work to write your own components that you would typically expect in a "native" gui kit, like menus, text boxes, OS integrations, themeing/styling, etc. &gt; where native widget are not a requirement, regarding CPU usage, Memory usage and developer time If you remote developer time from that list you've described [electron](https://electronjs.org/) :)
Would it be better to use String or CoW in that case?
Pretty long article saying mostly 2 things: - there are _some_ issues with semver (repeated at least 3 times) - the semver team has been formed that will do _something_ I'm dissatisfied by the lack of details.
For those who care, I updated the readme of the project to have some raw benchmarks.
I left a few details in another thread here, but really, this isn't so much about the details. It's an announcement about maintainership of the specification changing hands.
As parameter to `new` or also as `Person` member type? As a function parameter type `Cow&lt;str&gt;` or even `T: Cow&lt;str&gt;` makes sense if it's not known in advance if you need your own copy or wether a `&amp;str` is good enough.
This is excellent information, and you should definitely included in your README. :)
I have, but thanks for bringing it up :-). I want something more -- multiple fonts and different sizes at the same time (like the square font for the map vs. a non-square one for text), shapes, etc. Basically, treating the map glyphs as a just another graphical tileset. For anyone reading this, these are the main differences (afaik, hope I'm not misrepresenting either): Quicksilver is a generic 2D API that the guide above uses to produce a grid of ASCII characters. The Doryen (and earlier, libtod) API is console-based. It presents you with a grid of characters and you draw stuff in there. It's very easy to get going, but you have to fit everything in the grid. Whether that's good or bad depends on what you need. Both support desktop as well as webassembly.
Python, C# and Java will throw exception when dereferencing null object, which will crash your program if not handled. Ruby will do it on undefined method. All of them have garbage collection and are slower than Rust.
I see that each \`Reusable\` has a lifetime. Is that scoped to the lifetime of the pool? I've made/used a handful of object-pool implementations, and auto-release (especially refcounted) is the holy grail, but without unsafe, it gets very difficult to manage lifetimes. Or you can use unsafe and refcount under the hood to get rid of lifetimes.. which is a bit UnRust. The other option is to make the Pool 'static, but sort of cancels out the point of a region based pool. So then the next option is to make an allocator that creates and refcounts regions that hands out buffers.. but at that point you've almost made your own allocator. &amp;#x200B;
Custom firmware for the teensy 3.2! Partially to learn about MCUs / firmware development, partially to learn Rust, and partially for writing custom keyboard firmware. We'll see where it goes :)
So if I have an AMD GPU- I can run code on gpu using rust -&gt; llvm path? What are the steps for this? ANd what drivers does one need?
Unfortunately, due to the nature of the work, I cannot share the code at this time. But I'd be happy to answer any questions. To give a little more details: To read HDF5 data, I made a library crate that is a low-level interface to wrap the calls to `libhdf5` (and `libhdf5_hl`). (I'd really like a more high-level Rustic interface but nothing like that exists yet. But I'm keeping my eye on [https://github.com/aldanor/hdf5-rs](https://github.com/aldanor/hdf5-rs).) HDF5 has a fairly large and complex API, so only the few functions that I require (`H5Fopen`, `H5Dread`, ...) are actually wrapped. I use [`ndarray`](https://crates.io/crates/ndarray) extensively since all of the data is represented by multi-dimensional arrays. For the parameters of interest, I define arrays for the mean, variance, and number of hits. For example, if the data were binned by latitude and longitude, then I'd have a `ndarray::Array2&lt;f64&gt;` or `ndarray::Array2&lt;u32&gt;` for the accumulated statistics. Then loop over each input datum, determine its n-dimensional index in the statistics arrays, and update the arrays accordingly. The finished arrays are serialized to CSV for later and plotted with gnuplot. Oh, and I have a pipeline of threads set up so each stage (reading, post-processing, accumulating) can hand off its results to the next and then continue on. In practice, this means that the disk-reading maxes out since this takes the most time (it's a combination of disk I/O bandwidth and `zlib` used internally by `libhdf5` to decompress each dataset). I've done this all as a learning exercise: normally, this would have been done in Python. But I've really enjoyed using Rust for this! It's probably not *significantly* faster than the equivalent Python version since the bottleneck is reading the HDF5 data. But it's been very nice having everything statically typed: adding another parameter to analyze means adding another field to an `enum`. As soon as that happens, Rust errors out on all the `match` statements since they're no longer exhaustive. Then it's very easy to go to each error and add the handling for the new case. With Python, I'd probably forget to handle a case and wouldn't notice the missing case until it's too late. Also, it's very nice making use of multiple threads. With Python, I have to reach for [`multiprocessing`](https://docs.python.org/3.7/library/multiprocessing.html), which is okay in a pinch, but sub-optimal.
Thanks for your answer ! Unfortunately, Electron is exactly what I dont want my application to be built with ;) Even if I respect what the project achieves, just on Slack app already consumes way too much disk space and memory ! Ps: An alternative, [Revery](https://github.com/revery-ui/revery) look more appealing to me :)
What’s the best way to pass the coordinates of a triangle? Should I accept 3 different `Point`s, a triple of `(Point, Point, Point)`, a fixed-length owned array of `[Point; 3]`, an array slice `&amp;[Point]` and check at runtime the length, what?
Thank you for you detailed answer !
Good idea! Thanks!
Came here to ask this. async/await is currently stuck as `std`-only because it uses thread-local storage to hack around the lack resumption arguments in generators. Every call to `poll` takes a `Waker`, which *might* be different every time. The `Future` implementation is always supposed to use the most recent one. The current `Generator` -&gt; `Future` wrapper simply stuffs the `Waker` into TLS and `await!` pulls it out for polling child futures. I would imagine that `Stream` would run into the same problem when using `Generator`s under the hood. It's technically possible to make a `Generator` -&gt; `Future` wrapper that is `no_std` compatible and it's only *slightly* hacky, but I haven't seen any movement toward moving to anything other than TLS. Proof of concept courtesy of /u/Nemo157 [here](https://github.com/Nemo157/embrio-rs/tree/master/embrio-async)
Looks like `Reusable` is just a `RwLockWriteGuard` with `unsafe impl Send`. The lifetime is the lifetime of the reference to the pool that was used to call `pull`.
I want to take input from stdin. I need no error handling since I am sure about the input. input from stdin is = "1 6 2" &lt;without quotes&gt; and also assign this individual numbers into some variables TLDR; equivalent of the following python one-liner &amp;#x200B; \`\`\`python x, y, z = \[int(x) for x in input().split()\] \`\`\` &amp;#x200B;
Echoing what you said about `rayon`, I tried parallelizing an embarrassingly parallel Fortran algorithm using OpenMP. It was better than nothing, but no matter how much I fiddled with the OpenMP arguments, I couldn't seem to get them right. The CPU utilization over time wouldn't quite max out, and after reaching a peak, it would decay a bit. There was a lot of variance but the CPU cores seemed underutilized. So I rewrote the algorithm in Rust and slapped `rayon` onto it. Bam, first try, and it completely maxed out the CPUs until it was finished. For `N` CPUs, it was nearly a `N`x speed-up. Far easier than OpenMP and it actually worked as expected.
Also people here that `unsafe` lets you "bypass the borrow checker" and similar statements. Which is is entirely true. But although it sounds similar, it doesn't mean "disable the borrow checker" (although that would be one way to achieve it); it's achieved by separate mechanisms only available to unsafe code.
Thanks! Basically, I look at your crate and thought---without reading too carefully---that it looked similar to what `thread_local` does. That's all, and that's was all that spawned my question. :-)
Something like: ``` let mut content = ```
Correct. In general, I recommend you use lazy static and wrap the pool in an arc.
...but why? m68k is not even a core Debian architecture.
Did you take a look at Elm and its enforced SemVer repository?
I know that it exists, yes.
It's pretty cool. You can ask it how your current changes would break SemVer if you didn't bump and get a list of breaking changes between two versions. 
They all have different trade-offs, so it depends on your use case. - Tuples are nicer to destructure than arrays. - Arrays are a bit cleaner IMO, because all elements have the same type. You also get the initialization sugar. - Slices allow for more generic code, but you lose compile time checks and optimizations.
Yep! [https://github.com/rust-dev-tools/rust-semverver](https://github.com/rust-dev-tools/rust-semverver) is our version.
Something like: ``` use std::io; let mut content = String::new(); io::stdin().read_line(&amp;mut content).unwrap(); let nums = content.split(' ').map(str::parse::&lt;u32&gt;); let x = nums.next().unwrap(); let y = nums.next().unwrap(); let z = nums.next().unwrap(); ```
Is it possible to deserialize json array into a struct using serde? As: "\[1,2.3\]" -&gt; struct S { x: i32, y: i32, z: i32, } 
I thought the whole point of adding the waker argument to `poll` was that it avoided relying on TLS. Did that change?
If you had a security-related bug, please file it in [RustSec advisory database](https://github.com/RustSec/advisory-db) so that people can audit their projects for vulnerable dependencies, including transitive ones.
Any news on possible upstream LLVM support for the 68k?
&amp;[T], a slice of type T.
I think it's not that Stream *can't* take a resumption argument, but just that it doesn't need to, so we can put off their design. The same reasoning applied to async/await.
No worries, I'd rather you ask than not. Unrelated, but I'm a big fan of ripgrep and your regex crate.
I'd prefer a port to the original MIPS (because of the psp).
This is an internal implementation detail, though- it could be fixed by tweaking the unstable generator feature. The actual design of generators doesn't need to be finalized until later.
&gt; I have opened a PR to replace 10 of the 13 lines of unsafe with safe Rust which have had no negative impact on performance &lt;3 We need more people like you.
This week I'm going to be working on [tarpaulin](https://github.com/xd009642/tarpaulin) closing some issues and hopefully improving CI support with coveralls. 
There was [some](https://github.com/rust-lang/rust/pull/51548) [work](https://github.com/rust-lang/rust/pull/52514) on enabling that in rustc, but rustc probably needs more work still.
Oh, so a resumption argument is an argument in order to *facilitate* resumption, not an argument to be used *alongside* resumption?
Awesome. What kind of post-quantum cryptography are you using?
That's a surprisingly small speedup. Is he benchmarking in release mode? `cargo build --release`
Please do it! I want to program for the genesis?
The Sega Genesis
For the `Future` trait itself, yes. For the `Generator`-backed implementation of a `Future`, no, it's still a problem. There needs to be *some* way to get the unique `Waker` passed to each `poll` call into the body of the generator that's driven by currently argument-less `resume` calls.
Completely fair. For a smaller slack app there is https://volt.ws/.
But why? That thing is from 1988, it's easier to make a cross-platform Rust framework that does all the same things than to port Rust to m68k.
Why not? It’s fun and I get to learn something. Not everything we do has to have a commercial background or goal.
Ahh memories. I started my programming journey in TI-BASIC on the TI-89, when I was 13. Later, I learned C and would write C programs for the calculator. My biggest project was a 3D polygon rasterization library for the calculator, for real-time 3D graphics. The compiler-generated code was often pretty inefficient, and I needed to fight for every cycle, so I hand-coded most of my drawing routines in.. yup! Motorola 68000 assembly.
The underlying generator implementation is just as much an implementation detail of the `Stream` discussed here as it is of `Future`, and it has the same shortcoming in both situations. &gt; Iterators and Streams cannot take resumption arguments, so this is not necessary to solve yet. This is the part that I'm saying isn't entirely true. It may be the case for `Iterator`, but `Stream` is definitely going to need to be passed a `Waker` every time it's polled, which sounds an awful lot like a resumption argument to me.
That work is still in progress. Upstreaming the backend was rejected for the time being as LLVM feared the code would bitrot as long it’s not yet mature.
That should be possible as well, yes.
&gt; Not everything we do has to have a commercial background or goal. Wait… That can't be right?!? I mean open source was never about having fun and learning; it was always about synergizing monetization opportunities in an application-driven affordance space. You're doing open source wrong. (Do I need &amp;lt;s&amp;gt; here? Really?)
I guess the reason is more emotional than rational. Anyway, I have been always fascinated by how pas programmers pushed their hardware and managed to make successful games with 8-10 people. Today, you need a team of hundreds of thousands, and I don’t doubt any single engineer knows less than 1% of their hardware.
Please read the linked thingy.
The spec does define precedence, comparing versions numerically by major, then minor, then patch, which indicates that 1.0.0 &lt; 1.2.3. Does that calculation differ between npm and cargo? Now, it doesn't provide a language for "compatible matching" like cargo's `^` and `~` (and how Cargo interprets a version without an operator, which is as `^`), nor does it specify a syntax for specifying dependencies. And Cargo's "compatible matching" semantics infer some additional semantic structure on 0.x versions that are not included in the original spec (which says that "Anything MAY change at any time" for 0.x versions). But I think that the rules in the spec for the interpretation of ordering of versions is fairly unambiguous and am wondering what difference there would be between Cargo and npm's interpretation of whether 1.0.0 &lt; 1.2.3, or even whether 0.1.3 &lt; 1.0.0. Anyhow, besides specifying "compatible matching" semantics and syntax (and possibly with a couple of different variations allowed in order to not break current ecosystems), a few other potential improvements that I could see: * The ability to have some kind of component which is relevant to order of versions, and is considered higher precedence than those without it, beyond the third component. Right now, there are pre-releases, which always compare earlier than the underlying release (1.2.0-alpha1 &lt; 1.2.0, for example), and there are build identifiers which are not compared (1.2.0+20190211 has equivalent precedence as 1.2.0 or 1.2.0+19700101), but there is no suffix which compares as greater than the 3 component version. This can sometimes be useful in certain circumstances; identifying locally patched versions that fix bugs, where you don't want to increment the patch number yourself as that could provide confusion with newer versions of the upstream package. Or you might want to have some kind of dated build where you do want to compare on date, rather than having to increment the patch number every time. Or there may be libraries where semver is not really relevant, but because you're using a package manager that adheres to it, you want to just leave the semver version the same but have some string that is compared using your versioning system; for instance, your library wraps some underlying data source, and you are providing the same interface but to data that changes with each release, which may be daily. Instead of having version 1.0.567 after a couple of years, you might want to have 1.0.0@2019-02-02 (picking an arbitrary character without going into the bikeshed), because that is semantically more meaningful than 1.0.567 * Some more recommendations on how to apply semantic versioning in practice; some non-normative text that describes a little bit about what should be considered each type of change, how to deal with practical issues. I see a lot of tickets in the SemVer ticket tracker are asking clarifications of this sort of thing, so I feel like some non-normative text on best practices and techniques for applying semantic versioning to common use cases would be helpful. * Changing a few "MUSTs" to "SHOULDs", for instance, "Patch version MUST be reset to 0 when minor version is incremented;" I don't really see any reason that should be stronger than a SHOULD, as sometimes you might, say, produce a version that was marked 1.2.0, then realize there's some fatal flaw before release, but already have internal systems with the 1.2.0 version, so you need to bump to 1.2.1 before you actually publicly release it. * Clarifications (either normative or non-normative) on how SemVer should be affected by changes to dependencies or build tools required. This has been a topic of debate in the Rust community, and I'm sure other communities as well. Do we have to update SemVer if we require a newer compiler? Do we have to update SemVer if we depend on a SemVer-incompatible dependency? Does it make a difference if that dependency is purely internal or if some aspect of that dependency is reflected in the API provided by our package? * Clarifications about how to deal with packages for which SemVer doesn't make sense or doesn't have an obvious mapping, but in toolchains which do some kind of SemVer enforcement or rely on SemVer guarantees; binaries rather than libraries, things that might provide multiple APIs (like a web service that provides different APIs at different endpoints, or a library that uses symbol versioning to provide different ABIs). * Relations and mapping between SemVer and other versioning systems that are widely used; for example, mapping between SemVer and package manager versions for major systems, how to use SemVer for C libraries on different systems using the system's convention for naming and linking libraries, etc. Policies on mapping SemVer to different package managers might be more appropriate for the package managers themselves to specify, but it also might make sense to have some non-normative text like a FAQ that mentions this on the SemVer side, to make the information easier to find. Anyhow, I suppose I should file these on the semver ticket tracker (or update existing tickets as appropriate). I'd gotten the impression that SemVer was in maintenance mode and there wasn't much use in proposing changes and clarifications like these, but now that ownership has been handed off and there will be an RFC process and new maintainers, it sounds like it's possible to start making some minor tweaks to help it fit in better. Overall, I don't think that SemVer needs any major changes, but there are a lot of little edge cases like this that could use clarification, interactions with other tools, and specifying how SemVer version matching should work for dependencies. Thanks for being part of getting this moving!
I had come up with a similar solution you presented in code block 1. Code block 2 seems interesting. I tried but i am getting an error on it. ``` error[E0608]: cannot index into a value of type `std::iter::Map&lt;std::str::Split&lt;'_, char&gt;, [closure@happy.rs:7:39: 7:68]&gt;` --&gt; happy.rs:8:26 | 8 | if let &amp;[x, y, z] = &amp;nums[..] { | ^^^^^^^^ error: aborting due to previous error ```
&gt;The spec does define precedence, comparing versions numerically by major, then minor, then patch, which indicates that 1.0.0 &lt; 1.2.3. Does that calculation differ between npm and cargo? It describes an ordering, but it does not describe how to use a matcher to select a particular set of versions out of that ordering. Does that make sense? &gt; But I think that the rules in the spec for the interpretation of ordering of versions is fairly unambiguous and am wondering what difference there would be between Cargo and npm's interpretation of whether 1.0.0 &lt; 1.2.3, or even whether 0.1.3 &lt; 1.0.0. One major difference, "1.2.3", without a matcher, is defined as "=1.2.3" in npm and "\^1.2.3" in Cargo. That's the biggest example off the top of my head, but the point is to drive out these edge cases and be able to know for sure which implementation does what. &gt; I suppose I should file these on the semver ticket tracker (or update existing tickets as appropriate). Personally, I think that most of this would be non-normative, and while that would be useful, I'd rather focus first on the things that are actually normative. That said, filing issues is better than random reddit comments, sure :) &gt;Overall, I don't think that SemVer needs any major changes, but there are a lot of little edge cases like this that could use clarification, interactions with other tools, and specifying how SemVer version matching should work for dependencies. Glad you agree! That's exactly what we're going for. &gt;Thanks for being part of getting this moving! You're welcome!
&gt; The spec does define precedence, comparing versions numerically by major, then minor, then patch, which indicates that 1.0.0 &lt; 1.2.3. Does that calculation differ between npm and cargo? It defines *precedence*, which isn't quite the same as an *ordering*. In particular, consider `&gt;=1.2.0 &lt;1.2.3`. SemVer says that `1.2.3-dev` has lower precedence than `1.2.3`. If you treat that to mean ordering, it implies that the range contains that version. But that's very unlikely to be what users want. `1.2.3-dev` is an unstable pre-release version and the range the user wrote in no way indicates they want any instability. For pub (Dart's package manager) we thus make a distinction between precedence (which version is best given a set of allowed versions) and ordering (which set of versions are considered within a range. The two concepts mostly overlap, but pre-release versions have different behavior.
So if I’m understanding this correctly: A Vec or String is a pointer to a collection of data. Passing a reference to either of these is slow because you have to follow two pointers to access the data inside. By passing a slice, you’re passing a reference to that collection of data meaning the function doesn’t take ownership and you only have to follow one pointer?
I believe last snippet in the "The whole world" part is a duplicate of a previous one, and does not demonstrate what it's supposed to (static + interior mutability).
Contrary to other suggestions I would just learn the Vulkan api. There's tons of resources and with a little cost up front you'll have a much deeper understanding of how modern graphics (cards) works.
And Amiga. Which makes even more sense when you look at projects like [Apollo core based Vampire accelerators/standalone boards](http://www.apollo-accelerators.com/) which create **new** classic Amiga hardware, m68k-compatible, in FPGA, running at clock speeds orders of magnitude faster than the original ones (which nonetheless is sluggishly slow compared to modern PCs) and having new sets of vectorized instructions, better branch predicting capabilities, faster ram, etc. For people playing with that hardware, that tries to modernize the classic architecture, it makes sense to also bring modern software there. Of course one could ask ‘but why?’ about the hardware itself… And apparently the answer would be nostalgia, so strong that people pay pretty good money for it.
It is a bit weird, considering that there are much more practically applicable or philosophically interesting Rust ports that could use some attention, such as POWER9 or RISC-V.
You'd first need to `collect` the numbers into a `Vec` for that to work.
Wow, this is surprisingly detailed. And I've leaned about some corner cases I haven't even considered! Thank you for writing this!
&gt; It describes an ordering, but it does not describe how to use a matcher to select a particular set of versions out of that ordering. Does that make sense? Yes. That's what I meat when mentioning that it does't define "compatible matching" semantics. I had just thought that you were implying that ordering wasn't defined or implemented the same way between the two versions. I guess that that's one thing that's missing is a standard word for this. &gt; One major difference, "1.2.3", without a matcher, is defined as "=1.2.3" in npm and "^1.2.3" in Cargo. That's the biggest example off the top of my head, but the point is to drive out these edge cases and be able to know for sure which implementation does what. Yep, that was the kind of difference I was expecting. &gt; Personally, I think that most of this would be non-normative, and while that would be useful, I'd rather focus first on the things that are actually normative. That said, filing issues is better than random reddit comments, sure :) True, some is normative (adding a way to add an extra component that compares higher, changing "must" to "should"), but most is non-normative that could go in a FAQ or something of the sort. The biggest issue is definitely defining the "compatible matching" semantics (and possibly syntax) better.
Is [T] or &amp;[T] a slice? I keep getting conflicting info &amp;[T] https://doc.rust-lang.org/stable/rust-by-example/primitives/array.html [T] https://doc.rust-lang.org/std/slice/index.html The popular books also seem to have this conflict. 
 fn main() { let mut v = vec!["one".to_string()]; let x = v[0]; } I get "cannot move out of borrowed content" page 85 of the oreilly book tell me I should get the error "cannot move out of indexed content" Did the error messages change, or something else? I think the index content error has a deeper meaning that the other, which makes sense to me assuming that indexing is just a method call on a &amp;self, but its just another of rustc's typical nags. 
I'm porting some code from c which has lots of implicit numeric type conversions. The rust code ends up looking something like this: for ev in (0..6000).step_by(2) { let test_a = 2_f64.powf(-ev as f64/1000.0); let test_b = dmed as f64 - bmed as f64 * test_a; // .... more code } The resulting code seems to be half "as" statements which makes it harder to read. Is there a better way to be going about this?
I am using the NTRU crate as the basis. Bulk documents with AES and the keys wrapped in the NTRU lattice encryption. I also have a hardware random number generator, so I may repace the NTRU random generator. What I will be doing is packaging HTTP calls so that the payload, including the true end points, are wrapped in NTRU encryption: thus anyone intercepting the HTTP packet can only see that one common endpoint is called, so that offers nothing in the way of determining what is going on. I did look at blockchain, but decided against it. 
How many years until that game gets ported to this language?
Both? 
Would `rendy` be a good library to build a GUI toolkit off of? Just trying to understand `rendy`'s place within the toolchain
TI calculators might not be supported…Rust assumes IEEE floats, but TI-68k uses BCD instead. Rust code without `f32` or `f64` would probably be OK though.
Hey /u/steveklabnik1, the link to the github team is a 404 -- you may need to mark the team as public.
I'm continuing my work on a password filter to be installed in our domain controllers to prevents users from selecting passwords known to be exposed in data breaches. The core logic is done, now I need to get the bits written so that I can compile a DLL that exposes the correct function. No links to code since this is technically a proprietary project, but if I can get permission I'll be sharing on Github.
The link to the "Github team" is dead.
Has anybody found a good equivalent for pandas?
The team is, apparently github makes it private and there's nothing I can do, see the footnote.
Apparently github makes it private and there's nothing I can do, see the footnote.
I figured there'd definitely be some limitations. I recall that `sizeof(float)` returned 10 for some reason I never figured out. There's no FPU on the chip, obviously, and the BCD instructions were unusably slow for my purposes, so I just had to resort to bitshifting integers to maintain precision. It was a lot of fun, actually.
"[Because it's there.](https://en.wikiquote.org/wiki/George_Mallory)" 
Just remove the link
Cool, I remember looking at programmatic output of tests but ran into some problems. - Mind contributing the test parsing logic to [`escargot`](https://github.com/crate-ci/escargot/) for reuse by others? - Mind splitting out your junit logic for reuse by others?
I would recommend to increase the font size then :)
&gt; I recall that sizeof(float) returned 10 for some reason I never figured out. Because `float` encoded the full-range: http://tigcc.ticalc.org/doc/keywords.html#float
It's not a resumption argument in the same way as a full design for generators would be- that would be "something returned from `yield` into the user's program;" while `Waker` is invisible, always the same type, and pretty straightforward to hack in temporarily.
things like wxWidgets have pretty much failed, yeah, but HTML? sounds like a stretch. 
Yes, it's something the resumer passes in that becomes the value of the `yield` expression. (I can't see this comment thread in the main view for some reason, only my inbox...)
I was trying to track down where you found the link to that page, so I could submit a PR to fix it, but was unable to find it. Where are you seeing a "sidebar" under the the ["Learn"](https://www.rust-lang.org/learn) page? I also tried small responsive screen sizes, but I can't manage to make a sidebar appear.
I had no idea that generators were in “a very sketchy, experimental form”. I thought the syntax and traits were pretty much done. The Generator trait was even changed in nightly recently to take Pin&lt;Self&gt; instead of being unsafe. Interested to see what the future brings.
Yeah. I don't know what's going on with /r/rust the last few days. There have been a number of threads where I can't see everything.
The sidebar here on reddit, the first link under "Learn" being to the nonexistent [FAQ](https://www.rust-lang.org/faq.html)
&gt; something returned from yield into the user's Are we talking about the same thing? This seems to mean making the `Yield` associated type of the generator something besides `()`, while resumption arguments would be changing the `resume` signature to something like fn resume(self: Pin&lt;&amp;mut Self&gt;, resume: Self::Resume) -&gt; GeneratorState&lt;Self::Yield, Self::Return&gt;; Unless generalized resumption argument support would entail *another* thing returned during a yield as well as the actual argument?
Ah, that makes sense. Thanks!
Well, the "make Cargo spit out Meson commands" sounds quite doable and doesn't even require modifications to Cargo itself, it can be implemented as a plugin - of which there are already [dozens](https://crates.io/categories/development-tools::cargo-plugins).
What is the size difference between Box&lt;[T]&gt; and Vec&lt;T&gt;?
I think nothing stops you from using this as a library...other than complete lack of documentation... https://github.com/andoriyu/cargo-suity/blob/master/src/results.rs handles parsing of json output. Just defines structures and the rest is handled by serde. https://github.com/andoriyu/cargo-suity/blob/master/src/junit.rs#L45-L102 Handles conversion between formats and `write_as_xml` handles formatting. I wouldn't mind extracting logic into `escargot` and depending on `escargot` instead. Time is a blocker though. I started this because I've switched to azure for my other project and wanted to have a normal way of viewing test results. &gt; EDIT: This reminds me that I need to set aside some time to dabble in Azure Pipelines for my rust projects. I love it. libzfs build times went from 40-50 minutes to 10-15 minutes _without_ using cache for cargo.
Here's my implementation: [https://github.com/nevi-me/rust-dataframe/blob/io/json/src/io/json.rs](https://github.com/nevi-me/rust-dataframe/blob/io/json/src/io/json.rs)
Here's my implementation: [https://github.com/nevi-me/rust-dataframe/blob/io/json/src/io/json.rs](https://github.com/nevi-me/rust-dataframe/blob/io/json/src/io/json.rs)
I've started a gambling framework built on top of Amethyst. It's my day job but I see a lot of potential in Rust so I'm kicking the tyres and seeing what comes out of it.
`Vec&lt;T&gt;` includes the buffer capacity (an additional `usize` field) in addition to the length and the data pointer. So on 64-bit `Vec&lt;T&gt;` should be 8 bytes larger than a boxed slice.
A slice is two numbers: a pointer to some data, and the length of the data. `[T]` is a slice, but `&amp;[T]` (a "shared" slice) is also often called with the same name. `[T]` is an owned slice; and it can only really exist as a heap allocation behind a pointer. For more information, see the Rust reference: https://doc.rust-lang.org/reference/types/slice.html.
Probably they are using old reddit like me, which shows: https://i.imgur.com/ktIUvb1.png indeed the first link goes to 'https://www.rust-lang.org/faq.html' which 404s now
Basically no blockchains use post-quantum encryption (with the sole exception of Iota, which isn't really a blockchain anyways). Do you feel that NTRU is solid / vetted enough to use as the basis for "real world" cryptography? I know some variants (NTRU-HRSS-KEM, NTRU Prime, and NTS-KEM) are on the list for the NIST post-quantum standard, but I don't have a sense of how "solid" they are in relation to other alternatives. 
There's more than a couple bots that crawl crates.io, 26 downloads a day is not surprising.
No idea if I'll get to it, but I really need to give ggez some love, and finish my PR for `TryFrom`.
I'm working on adding Holidays and Torah portions (which will make it feature-compatible with [hebcal](https://linux.die.net/man/1/hebcal)), And I plan on adding a Halachic times calculator in the future.
Calendars are fascinating, looking forward to reading the code!
This is a valid interim solution, but I would also recommend looking at the \`ascii\` crate for long-term usage. It's nice to still be able to do string operations and otherwise accurately model your data. :)
Very interested to see how this pans out. I hope one of the things that gets clarified is binary compatibility. Some people consider it part of their API, some don't, and as a result you can easily end up with a minor version that is source-compatible but binary-incompatible. This easily leads to linkage errors, e.g. \`AbstractMethodError\` in the JVM world.
Depends on the goal of your application. I'm working on a pcap visualization tool with amethyst, and it's working pretty well. If it's something graphic heavy I'd recommend it.
Looking at the code in `metered-rs`, I think `synattra` expects keys that are known at compile time using custom keywords, while `darling` expects the value side of the meta item to be completely blind to the field name so that `FromMeta` impls can be shared by different fields. Going the other direction, I looked at making `darling`'s traits implement `syn::Parse`, but that's going to cause an unfortunate degradation of error messages since `syn` is expecting only one error to come back from `parse_macro_input`.
[There appears to be an open issue about this](https://github.com/rust-lang/www.rust-lang.org/issues/291).
Not sure I'm following - the \`Once\` example in the \`const\` section is interior immutable, leading to being run twice. In the \`static\` section, the \`Once\` is attempted twice, but because of interior mutability is only actually run once.
Thanks again, the links are now remedied and tested properly. I swear, my next project is going to be a website crawler that just makes sure I get a \`200\` status from everything on a domain...
Yeah. I hung out in the #tigcc IRC channel lots (Kevin Kofler is the one who actually got me into FOSS back in ~2005 or so with Fedora Core 5 and KDE). https://www.ticalc.org/archives/files/authors/73/7381.html Wow nostalgia. And bad code practices…single-file C sources, hard-coded integers rather than enums, 50-line `if` conditionals. All kinds of crap :) .
Ahh, cue obligatory conspiracy theory: The people doing the certification are the very people who want to break encryption. Just because it's not certified does not make it a bad scheme! But you have a point. There is a weakness in NTRU if you use the signing algorithm. But as far as I am aware the encryption has been peer reviewed and there are no known weaknesses. 
Ah, that's a good point. Definitely something that should be fleshed out in a new version of SemVer. Actually, if you think about it, it's a little odd for SemVer to specify precedence and not what you're calling ordering (I might call it something different, like "compatibility"), given that SemVer is about using the version number to communicate semantics about API compatibility. From the perspective of API compatibility, I would expect a pre-release of a version that has a new API to be API compatible with that new version, but the precedence rules give no good way to indicate such constraints. Pre-release versions also bring up the question of whether they should ever be automatically picked if not explicitly opted into. For instance, if you use a cargo `^1.2.3` spec, which means `&gt;=1.2.3 &lt;2.0.0`, and a `1.3-pre1` is released, should someone doing `cargo update` actually use that `1.3-pre1`? In distro package managers, pre-releases like this can make sense, because you usually only put them in some kind of testing or unstable repository. However in language package manager which generally just have one big free-for-all pool of package versions, I wouldn't expect you to want to automatically opt-in to pre-releases even if they theoretically match your compatibility specification.
I was going to suggest `dudect` and `ctrgrind`, but since those have already been suggested, maybe also consider using [`ctverif`](https://github.com/michael-emmi/ctverif) which works at the LLVM-IR level.
I think this has to do with [how nom 4 handles Complete now](https://github.com/Geal/nom/issues/718). &amp;#x200B; If you instead do #[macro_use] extern crate nom; use nom::types::CompleteStr as Input; named!(alt_tags&lt;Input, Input&gt;, ws!(alt!(tag!("abcd") | tag!("efgh")))); fn main() { let input = Input("\nabcd\n"); let result = alt_tags(input); println!("{:?}", result.unwrap()); } you'll see that you get the right output. &amp;#x200B; As for *why* using CompleteStr (or CompleteByteSlice) fixes it, I still don't understand, and I just wrote a tokenizer for Rich Text Format (RTF) from scratch in nom.
No, I think we are talking about the same thing and I was just unclear. By "the user's program" I probably should have said "the generator"- I'm talking about `Generator::Resume`, not `Generator::Yield`.
Is there any reason `-&gt; impl Trait` couldn't just desugar to GAT+existential types?
Thanks, that works. "Don't know why this works but it does" solutions are not ideal, but it'll do for now! BTW, did you finish your RTF parser? How did you find the experience of using nom, overall?
Well, technically it's not a valid JSON. What you really need is read lines and parse each line as JSON. You have to do it because any valid JSON starts either with `{` or `[` and nothing else. You got that part covered. Since you work with dataframes I assume getting schema is nearly impossible. Getting `serde_json::Value` from string though is easy: let v: serde_json::Value = serde_json::from_str(data)?; 
I have my tokenizer written, and it tears through rtf files making tokens, but I'm still working on constructing meaning from the tokens I generate. So yeah, the nom parsing part is done. It had a steep learning curve. You can see what I've got [here](https://github.com/compenguy/rtf-grimoire). I have the parsing broken into two modules - "raw" which handles all the details of the parsing, but returns primitive types, and "tokenizer" which builds on the raw parsers, converting the primitive types into Tokens.
Is there any reason to use it at all then? My understanding is that AES is fine for post-quantum symmetrical encryption as long as you double your regular keysize to protect against Grover's algorithm. 
This is pretty cool. Question: Why do you need permission from legal at you $dayjob to release a personal project? Do you have some kind of non-compete what prohibits this? 
&gt;"Don't know why this works but it does" solutions are not ideal, but it'll do for now! If it helps, nom's migrating guide explains it, it just doesn't make a lot of sense to me.
You are correct. AES is good enough for post quantum. However, it still has the problem of key distribution. So you use a some form of public/private key encryption to manage the distribution of the keys. Thats where NTRU comes in. 
&gt; I would expect a pre-release of a version that has a new API to be API compatible with that new version, but the precedence rules give no good way to indicate such constraints. I think that expectation works some times and doesn't other times. Sometimes, API authors want to ship an experimental version where they're still figuring things out and the next prereleases or stable release won't be compatible with it. Other times a pre-release means "we've got the API solid but we're still shaking out bugs", so it probably is compatible with the next stable version. SemVer doesn't have any real way to express either of these. &gt; Pre-release versions also bring up the question of whether they should ever be automatically picked if not explicitly opted into. Right. The way this works in pub is that if there are *any* stable versions in your version range, any of those are preferred, even a lower version. Otherwise, if there are only pre-releases, then it will pick one.
The attribute `#[doc(inline)]` solves that. [Read more here](https://doc.rust-lang.org/rustdoc/the-doc-attribute.html#docno_inlinedocinline).
Gotcha. Makes sense!
I'm not OP, but I found non-macro based parsers to work better at this point. This probably has more to do with IDE support for macros than anything to do with nom. But pom is a non-macro-based alternative if you are looking at other options. I'm not sure how the performance compares. https://github.com/J-F-Liu/pom
Of course, your passwords are not sent to any web site. A hash is computed, the 5 character prefix is sent to the have-I-been-pwned web site, and the list of suffixes (hashed starting with the same prefix) of compromised passwords are retrieved and compared against the passwords in your KeePass database. Parallelization is done using Rayon, so it is easy to check a few thousands passwords under ten seconds.
The main disadvantage is that if we allow that, then there will be return values from traits that no one using the trait can name. With GAT, someone using the trait can always name the return type, whether or not the implementor uses existential types. I think that's the logic in any case? I haven't followed the latest RFCs, only the ones that were around a year ago before and during `impl Trait`'s initial implementation.
interesting. the only problem i have with this is the article makes it sound like c and c++ were the culprits, and not the people who write poor code. 
People who write poor code are unavoidable. C and C++ are not.
Thanks everyone for this!
I mean, they are really. They are the languages in which these kind of bugs are possible. They are tools that make it very easy to write incorrect code. I believe that this is true even compared to many of C's contemporaries which had things like proper arrays.
This is in general the debate when it comes to memory safety. The way I look at it is that I can train myself all I want in using a gun that can very easily go off properly so that when I have it it never shoots without me explicitly shooting it. All it will take is for one of my colleagues who isn't as careful for me to get shot in the foot. As such I would prefer if we made safer guns instead.
It's interesting seeing the diffs on a large project converting to Rust 2018. I'm surprised to see a net gain in lines. https://github.com/tikv/tikv/pull/4138/files
There is plenty of blame to go around, but unfortunately, getting people to write better code is a dramatically more difficult feat to accomplish than designing languages that enforce better code. Consider the issue of car accidents. Drivers are certainly responsible for the accidents they cause, but the most effective thing we can do to reduce accidents isn't necessarily driver education. Traffic engineers can build [better highway junctions](https://en.wikipedia.org/wiki/Diverging_diamond_interchange), better public transportation can reduce the cars on the road, allowing people to take late-night Uber/Lyfts instead of driving home drunk, etc, etc. People *will* slip up, even the best of us. The only things we have that are (more) consistent than humans are the systems we build. When safe coding in a language consists of humans following conventions and rules (i.e. CERT-C, yoda syntax, pointer malloc/free pairings, code reviews), rather than programs following conventions and rules (linters, static analyzers, compiler warnings, lifetimes), I think the systems are just as much to blame as the humans using them.
Even good coders have accidentally allowed security flaws to creep into their code because of a lapse.
You can use `dmed.into()` in cases where the type is obvious to the compiler, but I'm not sure whether or not that would work in the examples you gave above. 
Great to see this kind of progress in Rust graphics! Congratulations on the release? When will this become used by Amethyst itself?
Looks interesting, will try it out. 
That's because fallibility is an expected attribute in humans. We can throw our hands up and say "Well, that's humans' fault for being fallible" or we can use tools and practices to guard against errors.
Human are human after all. Making mistakes is unavoidable. That's why we create tools to auto-check our work.
It depends on the GUI system. If it uses the direct-rendering paradigm - currently Wayland is the only one that is 100% committed - then yes. Direct-rendering GUI means that your application is responsible for drawing a framebuffer that exists in some (system-dependent) place which can be shared with the screen compositor. Wayland is itself pretty simple: it sends you GUI events, you draw (using some technique outside Wayland), you use Wayland to tell the compositor when to display to the screen. I think the last time I checked, Wayland supported either using the CPU to draw to a segment of shared memory or an OpenGL ES context. But I think there is now support for OpenGL and Vulkan. OpenGL can in principle - and even practice - run on the CPU or GPU. Vulkan is, at least currently, GPU-only. Anyway, a library like `rendy` might be used under that kind of system to draw things when they need to be drawn. Cairo and Skia are examples of established (but not-Rust) libraries for 2D vector drawing. They're a little bit higher level than OpenGL ES - Cairo and Skia can understand commands like "fill this curve defined by a piecewise cubic polynomial with this color", OpenGL (for the most part) needs a mesh of triangles. Depending on the application, it might do some or all of its rendering directly. But things like dialog boxes - if they look and feel like a "native application" are probably using the indirect-rendering paradigm. Your program tells the GUI system what to draw - and the GUI system decides where and even *whether* to draw it. This can be much more efficient, possibly have lower latency, look more consistent, and even do useful tricks like opening a GUI window across a network connection. So indirect rendering is still very important for backwards compatibility, native look and feel, and (possibly) low-latency. If a GUI toolkit supports multiple platforms, you'd make indirect rendering API calls on operating systems where that is the best platform, and your own direct rendering when necessary. `rendy` (as far as I understand it) aims to help you with that rendering layer. That said, I haven't looked into whether it tries to work well with partial, asynchronous updates (which is what GUI apps typically do), or if it's more oriented towards the clear-everything-draw-everything model of action games.
Yeah but writing code for time zones... The stuff of nightmares
If you are consistently casting a variable to \`f64\` over and over, you could try aliasing it to the desired type instead: fn blah(x: f32) { let x: f64 = x as f32; // do stuff with x } &amp;#x200B;
Out of curiosity, what are C#’s options for gc-less programming? Would Microsoft prefer that we use F#, Rust, or Go to reduce memory safety errors?
Although they're much less common in Rust, vulnerabilities are still possible in Rust. Here's an interesting article I found: [https://medium.com/@shnatsel/how-rusts-standard-library-was-vulnerable-for-years-and-nobody-noticed-aebf0503c3d6](https://medium.com/@shnatsel/how-rusts-standard-library-was-vulnerable-for-years-and-nobody-noticed-aebf0503c3d6)
That's a tempting idea. If only the coders made no mistakes, we could write safe C/C++. But this is a defender situation, where you must get everything right, so it's very likely to screw up even for experienced coders. Exploring languages (like Rust or Ada) that allow the same coders to write fewer defects should be a total no-brainer, but sadly, as per your argument, the coders often bear the blame. Suppose you have a tool A that you can use to build cars. It lets you build very fast cars, but some of them explode in certain situations, unless the builder is very careful. There are other, safer tools that build slower, but safer cars. Now a tool B appears, that lets you build equally fast cars, that don't explode that way. Now your argument is that Tool B should be unnecessary because builders just need to be more careful. Sounds about right?
&gt;caliber It's because they are the culprits, yes.
That question doesn't really make sense. The whole point of C# and .NET is that it's a managed runtime. For GC-less programming you use something else. Beyond Modern C++, Microsoft uses or at the very least sponsors: - Project Everest, which develops verified-safe (including memory safety) software using e.g. the F* dependently-typed language: https://www.microsoft.com/en-us/research/blog/project-everest-reaching-greater-heights-in-internet-communication-security/ - Rust: https://twitter.com/maxgortman/status/1012011425353461760
Do you know if there are performance penalties associated with using `into()` vs `as`
Please stop downvoting parent comment. I don't think it was asked in bad faith, and it looks petty.
Great to have folks like Shnatsel working on this, so we can have less defects in unsafe code. And yes, of course unsafe Rust, though still more restricted than C, can allow undefined behavior to creep in. The difference is that the attack surface for memory bugs is greatly reduced by building safe abstractions on top of unsafe code. This still means we need to be careful when writing said unsafe code.
html widgets are ok, but much less than native widgets. Considering how much effort is to build a cross-UI that will never match what is given in the host is enough reason to consider, AT BEST, a cross-ui a chase for the low-common denominator. 
Hopefully. within a month there will be an initial implementation in Amethyst and in another few months it will be fully integrated with the new rendering glue that's being written. It is actually as far as we know a first of its kind implementation of combining ECS composition patterns with a render graph implementation such that there should be zero (or very few) lines of code needed to implement new graphics pipelines (and combinations of those pipelines as passes) outside of writing the shaders themselves and attaching the proper components to entities which should be run through those pipelines.
Contracts often mention that you need to contribute full time to your job. In traditional fields people are not doing "the same work" on their leisure time. Talk to a lawyer, a psychologist, a nurse, a police{man,woman}, etc. about what they do with their free time. In tech it's different; we are passionate and creative (or at least, many are). As such we tend to explore similar fields as our job on our free time. Since this is muddy waters, our legal department wants to have in writing these kind of things for the protection of all parties. The delay was actually in getting the green light that everything was fine. And since I'm probably the first one to push for it, the process had a couple of bumps and unknowns. All in all, everybody was willing and of good faith.
Getting there would be great, yes! I think python.org provides pre-compiled versions which could simplify things, but I don't have a windows machine to develop/test this for now... help welcome!
 There is already a mechanism which does this, even if it isn't ideal: macro_rules! num {() =&gt; {30}} fn main() { let _a: u32 = num!(); let _b: i64 = num!(); }
[asdf](https://asdf-vm.github.io/asdf) is cool too. It's in bash though; as mentioned in the post I think a statically (pre)compiled, single-binary can be a lot more ergonomic to use. But getting there will take some time and effort.
Totally with you on this!
There should be no performance penalties on release builds.
https://news.ycombinator.com/item?id=17161168 First comment specifically addresses this ------ &gt; For those wondering why luajit is faster than C/C++/Rust, that's probably because it does direct calls to the function, while C/C++/Rust go through the PLT (procedure linkage table).
It might be worth pointing out that Microsoft is also a big advocate for modern C++, which they have claimed to be safer and less cary to write than C++98ish type code. If these statistics are true for all Microsoft products, then it seems C++14/17 haven't really solved the problems that Rust solves, and there really is good reason to switch to Rust just for the added safety (of course, the better abstractions, tooling, and standard library are good reasons too).
A safety mistake like this almost always has at least two parts. There's some code that makes a security assumption, and then there's some other code that violates it. Now if both parts were written by the same person, or if the violating code was written by someone who was expected to know the assumptions, that's arguably "their fault". It might be reasonable to expect better training or something to make those mistakes less common. But there are other ways the two parts of a safety mistake can come about: - Code might make some security assumptions that were reasonable or clear at the time it was written, but which become unclear or inconsistent as the codebase changes over time. - Code in library A might be calling libraries B and C, such that A is relying on some specific behavior of B to uphold the security assumptions of C. Even if B's documentation explicitly guarantees that behavior at the time, a future incompatible version of B might change its guarantees. - Someone might add a new security assumption to an existing API, which most callers appear to uphold, but which some obscure callers violate. The common themes in these scenarios are that 1) it can be very unclear which particular person is "at fault" for a mistake, and 2) large and complicated codebases maintained by rotating teams of programmers can make these mistakes arbitrarily difficult to prevent.
Lazy static sounds like exactly what you need. Depending on the interface provided by your database, you might also need to wrap the connection object in a `Mutex` or some other synchronization primitive.
It is nice to see rust used in such a large scale project as ALICE.
To allow myself to easily convert C++ code which used dynamic allocations to C# - and ensure that the new C# code couldn't suffer from GC spikes and other annoying nonsense - I once implemented a mempool within C#... and so I basically managed the memory within the managed memory. This was back in the Xbox Live Arcade XNA days.. I think that's what it was called.. and I resented having to work with managed anything. I don't know if it was a good idea or not, but it did the job.
C++14/17 is really much safe language on compare with older C++ versions and it solves almost all memory issues if is used with modern tooling like sanitizers and GSL. Almost all issues highlighted in the article are happening because of C and old C++ codebase. They couldn't be magically solved without re-implementing already existed Microsoft codebase and this codebase is really HUGE. I would say any modern language like C++17/Rust/Go will solve these issues but only after complete code rewriting, which is too expensive.
So I have a serious question. What, if any, downsides would there be to rewriting legacy code in Rust? Besides the time and effort involved, of course. 
That's certainly true for the artifacts produced by the compiler. I'm not so sure about compile time itself - maybe aliasing analysis takes a noticeable amount of time but I doubt it. 
Sanatizers only solve some memory issues. For example, Rust can detect an uninitialized read. ASan wouldn't. It's also done at runtime, which is expensive and doesn't provide you with the proof like guarantee Rust is giving you. I write C++17 at work, and we still have plenty of bugs due to memory corruption, sometimes due to sharing data across threads, sometimes because implementers of safer interfaces make mistakes. C++17 does not solve nearly all memory issues, it's still a security whole, and this article doesn't really clarify which parts of the MS code base these CVEs where found it, so it's hard to say that it's just old C++ code.
Or look at aviation. When there's a plane crash, people don't say "that pilot sucked; everything's fine and we just need more conscientious pilots who can handle the responsibility." No. They find the reasons why the pilots failed, and come up with mitigation strategies so the same pilots wouldn't mske the same mistake again. For example, they introduced checklists, to make sure simple things aren't overlooked. They introduce new guidelines for communication in the cockpit so the co-pilot doesn't think he communicated a problem while the captain was paying attention to a different issue. It's sometimes said that a poor craftsman blames his tools. But if a large percentage of craftsmen can't safely use a tool, sometimes the tool itself is bad.
Why do you want to use `setjmp` and `longjmp`? Interop with C code that uses them? Just for fun/learning? If instead of either of these, this is just to achieve something in Rust that you can't think of a better way to do, you should ask about what you're trying to do, and there's probably a safer and more idiomatic way to do it.
I remember xna and the horrible GC spikes. Especially on the Xbox, the C# CLR was horribly slow at collecting garbage. You pretty much _had_ to pool your objects.
The benchmark does not use `-C cross-lang-lto`.
Unity is making a subset of C# that is gc-less. http://lucasmeijer.com/posts/cpp_unity/
I love that youre looking into this. Don't forget to check out spark, dask, and vaex as well. They are other good sets of apis with parallelism. 
Wow, exciting stuff! Thanks for the update!
Time and effort is mainly it - you need to put in time to have your team learn rust, you need to put in time to redesign your application to use rust idioms (translating C++ to unsafe rust just decreases usability...), and you need to commit to hiring rust employees in the future and/or training all future employees in rust. Above all that, though, you also need to trust that Rust will be here long enough for the effort to be worth it. If Rust stops being maintained in the next few years, or even the next 10-20 years, it could be a net loss. I have no doubt that rust will continue to live that long and longer personally, but established companies are usually more cautious.
Nah, this guy is a piece of work if you look at his comment history. Honestly, just delete the whole chain and ban him from the sub. And if you can flag his account for the admins to ban him, here's an example of him probably violating site rules: https://www.reddit.com/r/onions/comments/8lbwmg/searching_for_onion_sites_with_painless_suicide/dzeki7e/
Oh, there can be a boxed slice, that's the first time I've seen a slice without a reference, you have to admit, its really rare, and that probably contributes to &amp;[T] and [T] being used interchangeably so often. 
Looks like it's soon to be stabilised as [`linker-plugin-lto`](https://github.com/rust-lang/rust/pull/58057).
[Weld](https://www.weld.rs/) is also a interesting Pandas-like library written in Rust. It also got a Python binding.
[Weld](https://www.weld.rs/) is a interesting Pandas-like library written in Rust. It also got a Python binding.
This is crazy I was just thinking about possibly implementing dataframes and rust. I'll make sure to check out those links. Thanks. 
C# includes such a type by default now, `Memory&lt;T&gt;`. 
We use lots of Go at work. I know for a fact it's not memory safe - e.g. you can have many threads writing to a data structure, and randomly resulting in a runtime crash.
This brings back memories. ZZT is what gave me my first dose of programming experience.
*Massive* time, economic, growth dump if we start rewriting basically the entire industry! Look at fuschia os as a new example now.. Google knows that Rust exists but they went to write their entire system in C.. in C.. let that sink in in a hacking guy's perspective. Good for bug hunters, they'll have to pay 100% or more over the costs for fixing those bugs later. As their systems grow, C/C++ will *always* have some memory management issues.
This is usually handled with off-heap collections. Most languages have libraries that implement them. But as a fallback, you can implement an array of structs by using an ArrayList&lt;T&gt; where T is primitive. Petgraph uses this approach in Rust. But it can be used in Java or C# to reduce GC pressure. 
I updated the post to make this clearer.
Thanks for your feedback :)
The absence of the capacity in 'Box&lt;[T]&gt;' means that no length modifying operations are possible: No push/pop/drain/...
At what point do we admit C is too hard for humans to master?
I learned rust as my “first language” (I knew some c# but nothing more than conditionals.), and it was verrrryyy hard as I didn’t know half the concepts and spend most my time googling, however I persevered and did it, and it worked. I am super happy with my choice and am now competent in several other languages because of it. Since you already know some Java you’re better off than I was. I would suggest this book: https://stevedonovan.github.io/rust-gentle-intro/readme.html as well as the official rust book. It’s gonna be a pain to learn but you’ll be glad you did, trust me when i say that.
Other than what I usually do, I've been recently dabbling in a live audio coding environment. It's inspired by Overtone and therefore uses a Lisp dialect for scripting. It has a primitive (i.e. non-future) server/client architecture and theoretically supports multiple users over the internet, although I haven't tested that out yet.
Make sure to make a post once you've programmed your own keyboard. I'd love to do that myself.
`v[0]` translates to `*v.index(0)`, so without a reference, the indexing operator tries to move or copy something out of `v`. Since you can't move out of a reference, you get the "cannot move out of borrowed content" error, which I think is more appropriate.
Thanks a lot, man.
You can write your own serializer/deserializer: https://serde.rs/custom-serialization.html
The hard part is reading and understanding the 1300+ pages of documentation for the MCU. And it could be done a lot quicker and easier with an existing library for interacting with the hardware, so then all you have to worry about is programming the keyboard functionality.
Beware: this tutorial kind of assumes you don't know how to code and spends a lot of time talking about API design. I wish it would just get to the point...
Depends on what you need, but there was static analysis tool developed by NASA that is proved to never miss memory bug. Although is geared more towards C, so it give lots of false positives in C++. Also i would argue that C++17 rules, even though they are more complex than Rust, are more comprehensible because there is standard that you can always rely on. Rust has "only" documentation.
I think Rust is great, but your conclusion isn't supported here-- Windows is obviously not written in C++14/17, being ancient C &amp; C++ code mostly-
MS making a move towards Rust?
It looks like Weld is a runtime, which integrates with dataframe libraries like pandas. I'm looking to build a frontend for dataframe; perhaps it would be able to use Weld, but that's a consideration for the future.
Cool! Let me know if you have any further thoughts.
I yanked the vulnerable versions as soon as I fixed it. Good idea, opened a [PR](https://github.com/RustSec/advisory-db/pull/87) for the bug.
Thanks! This might be a bit easier to get started with than `dudect-bencher`.
I haven't heard of vaex before! Thanks for the tip.
I hadn't heard of this tool before, thank you. I'll keep this in mind.
Isn't it already true that `impl Trait` return types are unnamable? I don't see how that's different if it happens at the trait level rather than on a concrete type, e.g. struct or enum (or whatever the term is). Perhaps I'm misunderstanding what you're saying.
That's definitely true (and nil doesn't help), but it does at least prevent the developer from doing pointer arithmetic (without explicitly using `unsafe`) and abstracts away memory allocation along with escape analysis (no chance of getting a pointer to a stack that no longer exists). Certainly not to the same level as Rust in terms of safety.
&gt; it solves almost all memory issues if is used with modern tooling like sanitizers and GSL Sanitizers only solve issues at runtime, if you're lucky enough to actually run into them at runtime while running with the sanitizer.
["'No way to prevent this', say programmers of only language where this regularly happens"](https://mobile.twitter.com/mjg59/status/1095086114287710208)
I would love to have a macro for Einstein notation. http://ajcr.net/Basic-guide-to-einsum/
&gt;Today, you need a team of hundreds of thousands That's not really true. I've seen numerous cases of indie developers with presumably fairly small teams and limited budgets being able to put out games of much greater quality than AAA developers with huge teams and budgets in the millions. &amp;#x200B; &gt; I don’t doubt any single engineer knows less than 1% of their hardware Probably true, since most people don't develop directly against a particular hardware architecture these days. When developing in a higher level language (anything that isn't assembly), you don't really need to know the details of how any particular hardware architecture works, unless you're developing a compiler for it.
probably similar issue when it comes to emulating old systems - there is occasionally userspace software reliant on quirks of the old codebase that get lost in translation, and which originated e.g. from older compiler being used.
I've been going through something similar as of late. Can't help you too much, but note that clippy has a lint that's not activated per default to warn you about possible loss of information. I've been using ``` cargo clippy -- -A clippy::cast_lossless -A clippy::cast_sign_loss -A clippy::cast_possible_truncation -A clippy::cast_possible_wrap -A clippy::unnecessary_cast ``` One principle I've followed and that helped me is "casts only when things come in and things go out, the internal format is fixed". I've created a wrapper type to handle things internally, and would cast on the boundaries (where I don't have control over the types, of course). That way, you have dedicated places to do your conversions and check them, while the formulas stay free of all the notation. So in your case, I'd run with ``` for ev in (0..6000).step_by(2).map(f64::from) { ... ``` Not sure how feasible that is for you, especially since you're porting an existing code base.
They're writing more and more new pieces in Rust though, from what I've seen. It looks like the native components in Fuschia are likely to be authored in Rust, or that Rust will be supported at least. Funny though, I made a remark about wishing more of Fuschia was written in Rust when it was first announced and I got annihilated for the supposedly stupid suggestion. (I was not pushy or dismissive about it either.)
I agree, it's inferior and has some things that are clearly mentioned as pycors reason for being.
&gt; it solves almost all memory issues if is used with modern tooling like sanitizers and GSL how do you know this?
C# performance is much, much better now, and XNA lives on as Monogame. As well as the JIT/runtime just being better, the language has a lot of added tools for working with memory better - Span&lt;T&gt;, ref returns, and SIMD intrinsics now. 
People who downvoted, what's wrong here?
I swear this is the best written blog in existence. It is so incredibly delightful to time and time again get advanced, complicated matters broken down into digestible pieces, presented honestly and clearly. Excellent introduction, clear scoping, obvious reasoning. I love it!
pom's main parser type looks like this, after expanding a type alias: struct Parser&lt;'a, I, O&gt; { method: Box&lt;Fn(&amp;'a [I], usize) -&gt; Result&lt;(O, usize)&gt; + 'a&gt;, } This allocation can be avoided by using traits, like [combine](https://github.com/Marwes/combine) does. I haven't seen any recent benchmarks but I wouldn't expect pom to do very well.
A company at the scale of Microsoft could maintain Rust *themselves*, if necessary. Not to say that isn't still a huge cost, but it's a lot less detrimental than completely unmaintained dependencies.
Isn’t that C is hard to master IMHO is quite easy, what is hard is to write proper code without error, and that’s where C doesn’t help you, because is a low level language you need to cover up too many fronts and Rust is trying to solve one of the hardest problems (memory management). Just take a look how many bugs and errors are just because those memory issues, even if you master C and memory management you will have bugs in that regard (more if you work in a huge project with other devs).
Perhaps that saying should be amended to "A poor craftsman blames his tools; a great craftsman builds better ones."
The thing I want is type-safety. I want my joins and maps to fails at compile-time if they are invalid. This is hard to do - at the moment Rust's type-system makes this possible but not very ergonomic. I have a [WIP library](https://github.com/jesskfullwood/frames/blob/master/examples/demo.rs) for this but it's on hold until a few more advanced features land in Rust (const-generics, GATs).
I'm sure it's much better, those were the Xbox 360 days, but now Rust has stolen my attention.
Yep - this would just avoid traits getting caught up in the unnamability as well. Looking back at the RFC, there is one specific problem with unnamable trait returns that isn't a problem with return types. When some type a trait returns differs depending on the implementation, it's often useful to apply bounds to that type, or restrict it specifically. For instance, see the example from [this comment in the rfc](https://github.com/rust-lang/rfcs/pull/2071#issuecomment-421104099): trait Polygon { ... } trait Rectangle: Polygon { ... } struct Square { ... } impl Rectangle for Square { ... } trait IntoPolygon { fn into_polygon(self) -&gt; impl Polygon; } fn do_something_with_rectangleable&lt;T: IntoPolygon&gt;(x: T) where T::???: Rectangle { let rectangle: impl Rectangle = x.into_polygon(); ... } If `IntoPolygon` had a `Result` associated type, we could use `T::Result: Rectangle`, but there is no equivalent syntax with `-&gt; impl Trait`. A syntax could definitely be designed, but no one has done that design work and created an RFC for it. --- I re-read through the comments again though, and I couldn't find any other objections besides unnamability. It seems like this might be a feature which was proposed, had some drawbacks, and then was just dropped. There are comments like [this one laying out the different features `-&gt; impl Trait` in trait definitions could involve](https://github.com/rust-lang/rfcs/pull/2071#issuecomment-421091268) and there's a [draft RFC for this cramertj wrote but abandoned due to bad tradeoffs](https://github.com/rust-lang/rfcs/pull/2071#issuecomment-420722580). It seems to me now like this could definitely be added. The original `existential type` RFC didn't include it, but that just means it wasn't finalized then. The main problem now might be that no one's taken up the torch? 
I did not downvote, but I'm pretty convinced that this sentence in itself deserve a downvote : &gt; Depends on what you need, but there was static analysis tool developed by NASA that is proved to never miss memory bug It doesn't give a link to the said tool (which I couldn't find with a quick google search), uses _NASA_ as an argument from authority and uses an exaggeration to describe it (“is proved to never miss memory bug”).
This is very exciting! I've been looking forward to this. Do you plan do the integration in Amethyst or what will be your focus going forward?
&gt; That's not really true. I've seen numerous cases of indie developers with presumably fairly small teams and limited budgets being able to put out games of much greater quality than AAA developers with huge teams and budgets in the millions. Only if you disregard the huge team of engineers that programmed the game engine they put their games on. &gt; Probably true, since most people don't develop directly against a particular hardware architecture these days. When developing in a higher level language (anything that isn't assembly), you don't really need to know the details of how any particular hardware architecture works, unless you're developing a compiler for it. If you want to leverage the full speed of the hardware (which seems to be rare today), you ought to know it.
If you master something you don't make errors.
GTK crate is tricky to work with, Jetbrains IntelliJ/CLion has [problems with it](https://imgur.com/a/N8YoqQX) too (tested in December). You may want to try replacing RLS with [rust-analyzer](https://github.com/rust-analyzer/rust-analyzer) or don't use language server at all and instead use e.g. [TabNine](https://tabnine.com/)
Can confirm this - also get a 404 on using old reddit.
There is a std function for that purpose: [https://doc.rust-lang.org/std/primitive.str.html#method.is\_char\_boundary](https://doc.rust-lang.org/std/primitive.str.html#method.is_char_boundary)
[Here you go](https://www.reddit.com/r/cpp/comments/a5a22b/ikos_21_an_open_source_static_analyzer_for_c_and_c/) Mathematically proven to never miss a bug. So no, i didnt exaggerate. Also i didnt use NASA as argument, but as mere pointer at where to look for it.
Humans make errors. This can't be fixed. But languages like rust can help make less mistakes.
Can you learn Rust? Yes. Is it good for you? Overall, yes, but in the short-term you will likely find it more practical to learn other, more popular languages first. Do you need C/C++ experience? No. It would help you learn faster, or more importantly, appreciate why Rust has rules which seem arbitrary at first. But it's not necessary. Is the official book a good starting place? Maybe. You can try it. It's supposed to be accessible to anybody who has imperative programming experience (and Java counts), but if you're really still a beginner it might be a bit tough.
Then you don't master c if you cannot manage memory correctly. I agree c is quite easy when doing trivial unix style command line programs with very limited scope. But any more than that and the mind cannot contain the whole program and at that point you are not mastering your code any longer.
Requiring TLS make Futures a non-zero-cost abstraction, and really weird to use on targets without TLS.
"The Book" is very good at explaining every bit of rust. If you know Java, you'll quickly see and understand the differences. Rust is more difficult to understand imo due to its ownership and borrowing approach. You may have got lots of "Null Pointer Exceptions" while learning Java, in Rust it's something like "x cannot move out of borrowed content." Then you have to understand some other concepts that java doesn't have, but which closer to C. Rust is not a object oriented language with lots of inheritance. Interfaces are traits and work a bit differently, Classes are traits, and work differently. However, "The Book" that comes with every rustinstallation (run "rustc doc" to open), and the compiler help to make progress. I learned Java in various courses in University. It's a big difference, if you learn something on your own, by stepping into every dark corner of the language or if you are taught to do this and that to avoid this and that at school. But it's manageable.. I have written some programs in rust too. 
Are you talking about [https://github.com/Hywan/gutenberg-parser-rs](https://github.com/Hywan/gutenberg-parser-rs)? &amp;#x200B; Yes, Rust is faster than PHP. PHP is not very good for parsers and compilers. I know this topic well because I'm the maintainer of [https://github.com/hoaproject/Compiler](https://github.com/hoaproject/Compiler) too. &amp;#x200B; I agree with /u/_TheDust_, that a speedup of 3 is strangely “low”. Maybe PHP was super good at this excercise. Need to take a look at it.
My next steps will be integration into amethyst and polishing rough edges along the way.
&gt;Only if you disregard the huge team of engineers that programmed the game engine they put their games on. Well, yeah, I guess if you count the developers of every library and tool (and I guess the compiler as well) involved in the production as part of the game development team then you're gonna end up with a pretty huge "team" for even the tiniest hobby project. Personally, I wouldn't. Besides, the big AAA companies also often use third-party developed engines (Unreal Engine, Unity, etc) and tons of third-party libraries and tools as well.
As u/Jataman606 linked, there indeed exist such tools. Usually the downside is that these tools also report a lot of things that aren't bugs, but can't be proven to not be bugs. This is very similar to the borrow checker: It doesn't miss bugs, but it sometimes can't see that things are safe. Indeed, this is the case with all forms of _static analysis_ in general. Fast, useful, but often with false positives. As an example, there is another tool on your computer (if you use some kind of UNIX) that tells you whether your code contains bugs, never missing any: `true`. It just sometimes has false positives :) So the claim of "never missing bugs" really isn't that hard to achieve; the real challenge is "how few false positives do you achieve?", or "how accurate is the tool?". This is exactly why I asked - imo the post contained sensible arguments, but it didn't link to things and thus might have sounded 'exaggerated' or similar. Thanks for responding, that created a chance for things to be cleared up, and to actually talk about content :)
&gt;Another discussion was around using Read::read to initialize memory. The problem here is that with an unknown Read implementation, we cannot just pass in an uninitialized buffer. Uninitialized data is strictly different from any particular bit pattern, and using it in any non-trivial way is UB. The change to zero buffers before passing to `Read::read` in `Read::read_to_end` wasn't just driven by UB, but also a desire for a more general guarantee about freed memory not being (easily) accessed in safe Rust. If freed memory can be re-accessed, applications (with zero `unsafe`!) may be vulnerable to Heartbleed-style attacks, where a password or private key is read from memory. A `freeze`-like change fixes the UB, but seemingly still risks the information leaks. Links (that you may know about): * [An original issue](https://github.com/rust-lang/rust/issues/20314) * [A (closed) RFC about it](https://github.com/rust-lang/rfcs/pull/837) * [A discussion thread about it](https://internals.rust-lang.org/t/uninitialized-memory/1652?u=huon) ([a comment worth highlighting](https://internals.rust-lang.org/t/uninitialized-memory/1652/43?u=huon))
Join a project. Don't try this on your own. Wes, the author of pandas, is very receptive to Rust for data science. Join his circle, if possible.
That's pretty cool
That's just like, your opinion man :P https://www.merriam-webster.com/dictionary/master &gt; master: adjective &gt; : being or relating to a master: such as &gt; a : having chief authority : dominant &gt; b : skilled, proficient &gt; c : principal, predominant Chief authority, skilled, proficient, etc. "Masters" still make mistakes. Chess grand masters make mistakes. Master craftsmen make mistakes. Having a masters degree is not the "highest" level you can achieve when studying. Etc etc.
never new I was born on 21 Teves 5738. I like my Gregorian birthdate more. It's special. The Hebrew birthdate looks like a regular date to me.
how hard is it to convert your code base to C++/17 from C98 ?
Because Mike Pall is a robot sent from the future. 
Even when trivial it's time consuming
 ~~bugs~~ vulnerabilities , bugs are not always vulnerabilities 
Pretty well written, although I’d suggest you that network requests could be performed with an async/tokio API (maybe still unstable in reqwest) instead of rayon.
How does compiler decide which memory is uninitialized? If I allocate memory directly from OS using `mmap` or `VirtualAlloc` can I then access this memory or should I call `freeze` to tell the compiler that this memory is initialized? Compiler doesn't know anything about `mmap/VirtualAlloc` and by itself would have no idea if memory at such pointers is even readable or writable.
I always hated trap representations and indeterminate values in C and am a bit sad that Rust is going the same way. Very few C programmers understand these concepts, and little progress in teaching them has been made over the last 4-5 decades. If anything, the trend is to rely on tools like ASan to tell programmers whether their unit test have UB, and these concepts are so unteachable that nobody even tries anymore. I’m really surprised by the conclusion that applying this model to Rust would help teaching people how to write correct unsafe code. The article does not argument this reasoning, where does it come from?
My company only has hundreds of thousands of lines of Python, and we've been working to switch from Python 2 to Python 3 for years :(
It wasn’t arbitrary as I [do it in luminance](https://github.com/phaazon/luminance-rs/blob/master/luminance/src/deinterleave.rs#L58-L84). But more examples are always welcomed and I’m glad you didn’t fix your opinion based on a single example you thought was arbitrary. :) I’ll integrate that example, it’s indeed great!
I fully agree (I am a big fan of reactive programming). I'm waiting for a usable and stable way to do that, and I'll switch to asynchronous requests.
&gt; OK, but this "how we teach this" makes little sense. I get generics, but I don't know why this rfc is needed. If there were examples with other generic types, that'd be great. Sure, and I’ll add more examples based on what people suggested. &gt; Off the top of my head: say you had a hash map and you generically want to see if it has some key and then convert it to a string. Is that a use case of this? I’m not sure to get why you mean. In your case, you don’t need *rank-2* because your function is bound to the type of the map — and having a *rank-2* function wouldn’t really make sense. If you want to understand more what *rank-n* universal quantification is, I can give you some hints (I might add those to the RFC as well so that it’s easier for people to get why all of this is brain candies). Universal quantification means *for all X, I can do things with X*. This is *rank-1* as it only has one level of quantifying. If you have *for all X and Y, do this with X and that with Y*, it’s still *rank-1* because both type variables are substituted at the same time: ```rust fn foo1&lt;F, A&gt;(f: F, a: A) where F: Fn(A) -&gt; String; ``` In order to monomorphize `foo1` — i.e. get a copy of runnable code without any free type variables left — you obviously need to get a real, concrete type for `F` and for `A`. You cannot just bind `F` to something and generate and implementation that allows different types for `A`. If you want this, you want another layer / level / rank of quantifying. This is *rank-n*. In this case, you only need to add a single layer more, so it’ll become a *rank-2* function: ```rust fn foo2&lt;F&gt;(f: F) where F: for&lt;A&gt; Fn(&amp;A) -&gt; String; ``` Now imagine I have this function: ```rust fn bar&lt;T&gt;(t: &amp;T) -&gt; String; ``` I **can pass it to both** `foo1` and `foo2`, but the quantification won’t happen the exact same way. If I do this: ```rust let x = foo1(bar, "hey"); let y = foo1(bar, 0u32); ``` The first call, `foo1(bar, "hey")`, will be seen by the compiler and it will generate the appropriate monomorphized function with `F` set to `fn (&amp;str) -&gt; Strng` and `A` set to `&amp;str`. The second call will monomorphize **to another function** which will have `F` to the same type and `A` set to `u32`. You can clearly see here that with *rank-1* universal quantification that the caller drives the choice to pick the type variables. Now, have a look at `foo2`. You can see that we don’t pass `A` anymore. We can call it this way: ```rust let z = foo2(bar); ``` And let’s implement it, so that you actually get the point of *rank-2* here: ```rust fn foo2&lt;F&gt;(f: F) where F: for&lt;A&gt; Fn(&amp;A) -&gt; String { println!("I need to render a &amp;str: {}", f("hey")); println!("I need to render a u32: {}", f(0u32)); } ``` You can see here that the `foo2(bar)` function, in order to be monomorphized, has to monomorphize twice its arguments: for `&amp;str` and for `u32` and **it does directly inside its body**. This *rank-2* type function allows you to take a generic function (or closure / lambda), and keep it around polymorphic until you need to use it. That function will get monomorphized inside the `foo2` function when you need it. As opposed to what someone said in this thread, this is not uncommon, especially in functional programming ways of doing things and yields really nice and clean APIs. You could even remove a lot of *dummy* traits in favor of *rank-n* functions. I hope that helped.
I'm still prototyping something [https://github.com/nevi-me/rust-dataframe](https://github.com/nevi-me/rust-dataframe), I could do with help and ideas.
I agree, be mature, check the subreddit before posting
I'm working on a dataframe library [https://github.com/nevi-me/rust-dataframe](https://github.com/nevi-me/rust-dataframe) I'm planning on supporting as much of Spark's functions as possible, and have made good progress so far. The difficult thing for me so far, is how I'd use this library for exploratory analysis. I have some use-cases where I can do ETL on files whose structure doesn't change (e.g. read JSON log files, transform and aggregate, write to other format), but I haven't a clue on how I'd create bindings for other languages. &amp;#x200B;
Part of the issue is that this is the model that LLVM uses (is moving towards) for the UB that allows it to optimize: `poison` and `freeze`. LLVM also currently has `undefined`, but the differences in `undefined` and `poison` are _even more subtle_, such that optimizations respecting both semantics are basically impossible. (There's a paper on this that I can't recall the name of unfortunately.) The LLVM proposal to introduce `freeze` and "soft" remove `uninitialized` is not accepted yet, but has gathered a lot of support including from core devs. The paper's argument is both that `freeze` and `poison` are enough to model optimization-driven UB and that both are required to model it. (I really wish I had a link.) Without `poison` you remove most "this is UB if it happens, so it doesn't happen, thus optimize" optimization paths, and without `freeze` you can't do a lot of other things, which include things like treating a small padded struct as an atomic unit for atomic operations. In any case, the ideal end case is that nobody will use (`poison`) uninitialized bytes outside of unions (`MaybeUninit`) and padding, plus things like `AtomicCell` can be sound. But there's so much code out there written before `MaybeUninit` will become stable and we don't want to just say that every existing usage of `mem::uninitialized` is actually just a weird way of spelling `mem::undefined_behavior`.
rust interests me too!
You're looking for r/playrust. This is sub is for the programming language known as Rust 
1. &amp;#x200B; I would recommend taking a look at R tidyverse for ideas in addition to Python pandas. For instance, R has &amp;#x200B; \* \`dplyr\`: to select/add/modify colume and/or row \* \`tidyr\`: for melting and pivoting with \`gather\` and \`spread\` \* \`purrr\`: for functional features such as \`map\` and \`walk\` &amp;#x200B; Python pandas library was developed based on \`data.frame()\` from R and \`plyr\` package by Hadley Wickham. Now R has updated version of \`plyr\` in \`dplyr\` and \`tidyr\` and much more in \`tidyverse\`. In my biased opinion, R tidyverse has better design and easier to extend than python pandas. &amp;#x200B; 2. One thing that will be hard to translate to Rust directly is non-standard evaluation in R. R uses non-standard evaluation heavily to make interactive analysis easier. For instance, in R &amp;#x200B; library(tidyverse) mtcars %&gt;% select(cyl, disp) &amp;#x200B; will select two variables \`cyl\` and \`disp\` in data.frame \`mtcars\`. In python, it will be something like this &amp;#x200B; import pandas as pd # assuming mtcars is a data.frame mtcars\[:, \['cyl', 'disp'\]\] &amp;#x200B; &amp;#x200B; 3. As jusskfulwood mentioned, it would be great if Rust compiler can check that the variables exist in the data.frame but not quite sure how. &amp;#x200B;
C++17 is mostly compatible with C++98, so technically the old code is already valid C++17. Trying to convert the programming paradigms is similar to rewriting in a new language, though it is simpler as you get rid of the FFI issues. It takes time, and it is bound to introduce new bugs which then have to be found and fixed, so it is not at all trivial for any large code base.
You want r/playrust. This sub is about the programming language known as Rust. 
Okay thank you
:) i am sure not much has changed on python 2 -&gt; 3 as C++ did from 98 to C++17 , plus on python there is a helpful program "2to3 " and manually find and replace could also solve your problem. i dont know why it has been hard to kill python 2
I thought windows was C++ code. The windows platform does not have a C99 compiler, so if it has C code in it, it must be C89 or some pre-C99 hybrid (the MSVC toolchain is a C++ toolchain).
Previously discussed at https://www.reddit.com/r/rust/comments/ao3jqi/opinons_on_fearless_concurrency_understanding/. There are some flaws in that paper's presentation of race conditions.
&gt;I agree c is quite easy when doing trivial unix style command line programs with very limited scope. But any more than that and the mind cannot contain the whole program and at that point you are not mastering your code any longer. That's the True Scotsman Fallacy.
&gt; am particularly happy about the progress I made on Miri during this week. With help from @eddyb and @alexcrichton, I got Miri to run the libcore and liballoc unit test suites. This is so cool! Congrats for achieving this milestone !
Brilliantly written article! Very informative.
How does only allowing uninitialized (or freeze or poison) behind unions prevent any of those optimizations? Basically, I liked that all values are always ok, and that if you want to manipulate incoherent raw bytes then you use an union and pointer writes to that. I think some people complained that unions don’t let you use “their favorite stuff” like atomics or simd but nobody mentions how is that the case. We could just add atomic ptr read/write/cas that operate on the value behind a pointer and that would let you work with garbage-filled unions. Just because LLVM (or Rust generating LLVM IR) has poison freeze and undef does not mean that Rust should expose these to users.
&gt; If I allocate memory directly from OS using mmap or VirtualAlloc can I then access this memory Why wouldn't you be able to do that? When you allocate memory you get a `*mut u8`. If you want to view that memory as an array of bytes, and the memory is initialized, you can map that to a `&amp;mut [u8]`. If the memory is uninitialized you can map that to a `&amp;mut [MaybeUninit&lt;u8&gt;]`. If you want to read or write to the memory just use the ptr read write methods. Copying a `MaybeUninit&lt;u8&gt;` union is always fine independently of whether the memory is initialized or not. And writing through a pointer to it is also fine. &gt; r should I call freeze to tell the compiler that this memory is initialized? Compiler doesn't know anything about mmap/VirtualAlloc and by itself would have no idea if memory at such pointers is even readable or writable. This is not how it works. If creating an uninitialized `u8` is decided to be undefined behavior (which will probably not be the case), and you access it, then the compiler can assume that this memory is properly initialized (because it would be undefined behavior otherwise). 
Looks like there is a [junit-report](https://github.com/bachp/junit-report-rs). So now I only need to steal your test logic into escargot.
Yeah that's the one. I work with both PHP and Rust so your project has been on my watchlist. :)
Windows isn’t the only Microsoft product, nor is Microsoft an OS company anymore. 
2to3 is quite lacking (cargo fix is much better). Furthermore, the Python3 migration often uncovers deeper issues with unicode compliance. The old codebase is often potentially buggy, but works as long as only ASCII strings are used. When migrating to Python 3, you actually have to think about the string type (either \`bytes\` or \`str\`). That's often time-consuming.
Might be helpful for projects running on GitLab, since it can [parse and present JUnit results](https://docs.gitlab.com/ee/ci/junit_test_reports.html). So you don't need to jump to some text terminal output to see what is broken.
I think Rust is a horrible way to start. It'll make you frustrated and question yourself all of the time. I recommend scripting languages for getting basic programming concepts, like python or JavaScript. They actually help you learn and don't slap you with a page of error messages if you do something wrong.
I don’t think you can go wrong with either. You will learn a lot from c. 
Should I go with C then?
The function parameter, node (type dyn TNode), is unsized. Function parameters are pushed onto the stack and must be Sized... So, you could pass a Box&lt;dyn TNode&gt; (which is Sized) instead.
Should I go with C then? Will it help me learn the nitty gritty of systems programming in a fundamental way?
&gt; It is a bit weird, considering that there are much more practically applicable or philosophically interesting Rust ports that could use some attention, such as POWER9 or RISC-V. [But I already put a lot of work into helping to bring Rust on all of Debian’s release architectures](https://lists.debian.org/debian-devel-announce/2018/11/msg00000.html), so I’m not sure why you think I set the priorities wrong. And there already plenty of people working on LLVM and Rust for RISC-V, so there is no shortage there. As for POWER9, that’s already supported by both LLVM and Rust. In case of missing pieces, there are enough paid IBM folks who will take care of the work.
Compile time checking will always be a bit of a tricky area, because for exploratory analysis, I really don't want to bother with manual type annotations. So there absolutely has to be a possibility to leave type checking to run time and support effectively dynamically typed frames. Once you have such dynamically typed dataframes, their interaction with typed dataframes will also be (by definition) checked at run time. Having said that, one can go pretty far with heavy usage of macros and tuples, but I'm not 100% certain that the current type system is powerful enough to go beyond the existing DataFrame implementations and isn't an unmaintainable monstrosity. I agree with other posters that rust will be much better placed for a truly outstanding DataFrame implementation once const generics and GATs are implemented.
It really doesn't matter. There isn't any kind of trend where people who started with the wrong language developed better or worse than others. A lot of the top systems programmers today started with QBasic, a lot of the top systems programmers of tomorrow will have started with Javascript. Learning C or Rust will prepare you will to pick up the other quickly later if you want. 
Couldn’t a generic function work as well?
Well how is the Box supposed to allocate the correct amount of heap memory when the size is not known at compile time (because different implementations might have a different size)? Maybe that is not so obvious, but I don't think Rust even has enough runtime type information to query the size during execution (and even if it does, Box doesn't use it). I think you have to make your caller give you a boxed object.
The Amiga is indeed my main motivation. Being able to produce programs for the Amiga using Rust would be (will be?) awesome ;).
&gt; But that seems like a dodge to me because I cant even imagine what a [T] is, unless its just an abstraction You're right to notice that `[T]` is kind of an "exotic" type. Specifically it's a dynamically sized type, where its size isn't known at compile time. A normal variable can't have a type like that, but there are other places where it's allowed. For example, you can have an `Arc&lt;[T]&gt;` (a slice of some dynamic size owned by a shared pointer). On the inside of a type like that will be a "fat pointer" which holds both a regular pointer and the length of the object being pointed to.
The function name suggests he is trying to store them in some kind of vector, but you can't store different implementations of a trait via generics.
&gt; Well then, I am a master juggler. Dont mind me dropping the ball after 3 throws, hey, humans make errors, right? Even if you're a master juggler I still expect you to make mistakes from time to time. The frequency of mistakes does not invalidate the statement that you still do make mistakes. &gt; When you master C, sure you still make memory errors, but it will be much less than 70% of all errors you make And we're comparing it to a language that 100% eliminates a class of mistakes. No amount of mastering can mitigate that entirely. It's definitely debatable on if eliminating a class of bugs matters, but that's a subtly. I'm merely replying to this meta-debate about: &gt; If you master something you don't make errors. 
There is constantly new Amiga hardware being produced like harddisk controllers, network controllers and even new mainboard designs and accelerator cards. The Amiga and the m68k community in general has always been very popular and active. Again, try to see it from a hobbyist point of view, not a commercial one. One of my motivations is simply learning new things ;).
But the thing stored in the vector would be the Box, which just references the trait.
&gt; Then you don't master c if you cannot manage memory correctly. If that's your position, has anyone, ever mastered C? I'd be curious to find the active C programmer who, after thousands of lines of C code has not made a mistake in memory management. Alas, that's a rhetorical question because I'm not going to scour thousands of lines if you link someone :P
Of course, none of this matters in safe code, only unsafe Nothing is lost by restricting `poison` to `union`s, at least in terms of optimization. What matters is the existing code though. Code exists with `let mut x: [u8; 256] = mem::uninitialized;`, and it's not a great image to say that `mem::uninitialized` is impossible to use correctly, as it violates validity invariants. It's a balancing act. And it's not about the hardware, but the optimization.
I would learn C first simply because it's a nice, compact language, and you'll get some first-hand experience with a very important and impactful language. It also helps when trying to understand things like boxing, garbage collection, dynamic dispatch, iterators, RAII, etc., when you can imagine what the equivalent C code would have to be. I think C is an excellent language for pedagogical background.
Heh, for that reason I once wanted to port LLVM to m68k myself, but without any prior experience with LLVM backends unfortunately I gave up quickly, before I really started doing anything. I hope you have more success and that one day I will be able to run at least Rust hello world on UAE :). I don’t think I’ll be of much help, but I will keep an eye on your progress. :)
The Rust memory model is more complex than garbage-collected languages, and Rust resources are generally geared toward people who already know a bit about programming. But I definitely think it's better to start with Rust than with C, because C has so many things that are irrelevant to beginners (manual memory management, atrocious build tools, lack of modern features).
Despite being a high level language, C is great to learn much about low lever programming. Both C and Rust are system programming languages, but it doesn't limit them in any way. You can do pretty much everything in C, therefor knowing C is generally good idea, because it teaches you to be careful with memory, and other things. Rust, on the other hand, is a joy to write, because it cares about memory safety for you, but I think that you can appreciate it only if you know how actually messy it could be in a language like C. I, myself a C programmer, for SOC, and I think that C is great for it, but as more I dive into Rust, the more I think about better ways of doing the same things. Both languages are great. C is pretty small, but it isn't easy. You can think of it as "Easy to pick up, difficult to master" type of language. I think that you should start with it, as it builds the solid foundation for any kind of programming.
A null reference/object/method isn't a dangling pointer, nor it is uninitialised memory, which are the supposed advantages you mentioned. Had you said "Rust is memory safe without having to use a GC" it would be another matter entirely.
No-one can live up to that standard. But many can live up to a standard of not releasing code before you are ready to stand behind it.
If you are a complete beginner, in my opinion the IDE is more important than the programming language. I would recommend Java in BlueJ for the beginning. The most important thing is to understand the basic concepts, which are almost identical in every programming language.
&gt; the wrong language _wat_ This reeks of gatekeeping.
If your goal is to learn low-level programming, you can do either. C on UNIX based systems will be better documented and more people will have answers to your questions. If your eventual goal is to write system utilities in Rust, then I would suggest learning Rust instead.
How big is each element in the vector? `Box&lt;dyn Trait&gt;` has a uniform size, while `dyn Trait` does not. If you don't need to store different types of data, then yes, you can just use a generic function. But that's only for homogeneous values.
Sidenote, if you start with Rust I would consider not writing perfect idiomatic Rust code from the get-go. For example, Generics, Type Association, Lifetimes, (and more) these features can bog you down in the weeds. Rust is a perfectly friendly language in my opinion, but from personal experience if you lack perspective you may end up trying to use features incorrectly and that is when Rust becomes a terrible, painful language. Rust seems to make it exceptionally difficult to mash a square peg in a round hole. However, writing Rust like it was Go(lang), ie sticking to simple data types, not using Generics, duplicating code and etc can be an easy way to limit the scope of learning while also making something. I don't advise writing production code in this manner, but limiting how much you have to learn is useful. That's literally what languages like Python and Javascript let you do - forget the details. But with Rust, you don't *have* to use all of the features. The only limitation to that is if you're trying to write more complex applications, like a web app, you'll be forced to learn *some* of it - at least enough to use the framework, which assuredly will use many Generic patterns. Rust also has an exceptionally friendly community, so that's a bonus too :)
Are you asking about making code compile in C++17, or making code idiomatic C++17?
Wasn't NASA's codebase like a million or a thousand dollars per line? (I forget the magnitude 😝)
Great read!
As a _first_ programming language? I would say neither. Assuming you've already got some fundamentals down, I would recommend starting with a language that has a managed runtime and is garbage collected. If your interests lean more towards IT or data science, I'd recommend Python because of its popularity in those contexts. If your interests lean more towards focusing on software engineering, I'd recommend Java, because it's staticly typed and has very well-established ecosystem of IDE support and tons of open-source libraries. There are other options too, of course. C#, Kotlin, Go, etc... Which one you'd prefer has a lot more to do with which might be more popular in certain areas of computing and software engineering that you might like to work in eventually. As far as learning a _systems_ language, I think it's better to learn Rust first, rather than C. Rust's ownership and borrowing system is something you need to understand ANYWAY if you're realistically going to write usable C code, it's just that people do it manually (without the guardrails of the compiler) in C. In Rust, you just run up against the compiler guardrails right away, rather than find out you drove off a cliff _somewhere_ in the last week and need to go through analyzing all that code to figure out why. I think it's better to learn Rust first, even though knowing C is going to be far more useful for employment in the short to medium term (i.e., the next decade), if only because C and C++ are still the de-facto languages for systems programming and the inertia of existing code will keep it that way for a long time to come yet. But software engineering isn't something you'll ever master just staying in one language. You'll need to be understand several different languages. The real answer to your question is that you should learn both, and more on top of that.
If it compiles with clang, clang-modernize does a good job.
&gt; Rust can detect an uninitialized read. ASan wouldn't valgrind can detect uninitialised reads. &gt; It's also done at runtime, which is expensive valgrind is expensive, asan isn't. &gt; doesn't provide you with the proof like guarantee Rust is giving you "Proof" is a strong word, but yes, Rust's guarantees are much much stronger. &gt; C++17 does not solve nearly all memory issues, it's still a big black hole of incomprehensible rules Yes. It pains me to see so many people defend C++17 as if all the memory safety issues were solved. It's a lot better now than it used to be, but it's still incredibly easy to write memory safety bugs.
This is why we write tests.
Well, I just tried it out instead of guessing and discovered that `Vec&lt;Box&lt;dyn TNode&gt;&gt;` simply doesn't work in the first place. So the whole basic idea of OP is a dead end. You probably have to store an enum in the array.
Tentative title? Tratt on Traits But seriously, nice work!
This code compiles and shows what I mean: ``` trait TNode { fn blah(&amp;self); } struct Foo(Vec&lt;Box&lt;dyn TNode&gt;&gt;); impl Foo { pub fn new() -&gt; Self { Foo(Vec::new()) } pub fn push_child&lt;T: TNode + 'static&gt;(&amp;mut self, node: T) { let child = Box::new(node); self.0.push(child); } } struct Bar { } impl TNode for Bar { fn blah(&amp;self) { println!("Hello, world!"); } } fn main() { let mut foo = Foo::new(); foo.push_child(Bar {}); } ``` However, I'm not keen about that `'static` lifetime, but I couldn't get it to work without that.
Why does `mut` switch sides? `fn via_ref( v : &amp;mut Vec&lt;i32&gt; )` but then `fn mv( mut v : Vec&lt;i32&gt; )`. I'd expect `fn mv( v : mut Vec&lt;i32&gt; )`, is this just to mirror `let mut v = ...`? Was `let v : mut = ...` ever discussed? (Also, the`const foo&amp; bar` vs `const foo &amp;bar` C++ discussion comes to mind.) 
Thank you, this is great!
C is actually a pretty good first language. The skills you learn are really applicable to a lot of other languages, Rust included, and the learning curve is steep at first but there's an enormous amount of resources out there (WAY more than Rust, it's 40 years older) to help you get started. Then you can move really quickly to C++, which is (imo) a very good introduction to some features of more modern languages that aren't available in C, while still being similar enough that it's an easy jump. Even if you end up not using it as a primary language, I'd say C is a great foundation to get used to lower-level languages.
You can join us in \#llvm-m68k on OFTC IRC if you like.
If you choose C, I highly suggest you to enable all possible warnings (if you use gcc `-Wall` `-Wextra`)
There was an old attempt at making something like arrayfire (which does have a Rust crate) in pure Rust called collenchyma. You could use that to develop a high performance backend.
&gt;Rust also has an exceptionally friendly community, so that's a bonus too :) You're not kidding. Rust is the only language I've found* where 90% of questions aren't answered with "Why are you trying to do it that way? You're stupid, and you should feel bad" *the other exception being Pascal, where the first question is "Why are you using Pascal?"
It depends on the amount of your 'give-a-shit' and patience qualities. Rust will probably frustrate you often, and searching for answers will require study (read the online book). C will blow up 'mysteriously' and you'll probably jigger things into working, but there are still errors passing unnoticed. Your call.
If as part of this work you want examples of bug reports to Cargo or decisions made by Cargo, please feel free to reach out to the team. I know that we have had extensive discussions of some of the issue you mentioned elsewhere in this thread.
I will for sure :)
I agree with other commenters in that you should probably start with something that abstracts more low-level details away from you. Learning C before Rust might be good to get access to what is going on at a low level before you try Rust. Rust will definitely help guide you to program well, but it may get in the way of your initial learning. I will add that I have no experience teaching people Rust as their first programming language and you may wish to seek some statistics (if they even exist) that describe the outcomes of learning different languages first.
Would you suggest any other language?
Oh, OK, yes, that will work. You need `'static` because trait objects implicitly have a `'static` lifetime themselves unless specified otherwise. If you do `struct Foo&lt;'a&gt;(Vec&lt;Box&lt;dyn TNode + 'a&gt;&gt;)`, then you can support arbitrary lifetimes. [Playground.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0a18d4e9774ba4e8bf0d8f636ad1386c) Although, I don't know how well this specific example will work in practice. Note: Please use spaces for code blocks on reddit. Fences only work in new reddit, so your code looks like a jumbled mess to me.
Start with How To Design Programs: [https://htdp.org/2018-01-06/](https://htdp.org/2018-01-06/)
This is an entire operating system. It's going to be time consuming.
Since you've already learned Java, learning C could be a good next step to understanding the low level of things so you know why Rust is doing what it is. It might cause a lot of headaches and frustrations, but there will always be C code out there.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [C or Rust](https://www.reddit.com/r/rustjerk/comments/apuhzs/c_or_rust/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Python. It's a good way to get introduced to interesting concepts like slicing, 'one way to do stuff', co-routines/generators/iterators and the await syntax (languages without await - especially the await that can optionally receive or return a value - need to make iterators into state machines internally, which can be much more complex).
Hah, I have very similar memories. I also extensively used the TIGCC port to ti89 called GTC. That let you code C on the calculator itself, and that is where I learned to program. Of course I also used TIGCC outside the calculator too. It was cool how you could swap the interrupt handlers for your own and basically take over the OS 😆.
I started off learning C \[1\]. &amp;#x200B; C definitely can start you off strong because it's simple to learn, can be used for almost anything, and is widely popular in open source, industry, and hobbyists. &amp;#x200B; However, the down side of C is that it doesn't include very many facilities for doing specific tasks (so you end up building your own thing for nearly anything that's complex), it doesn't have a good module system (so it's harder to leverage 3rd party libraries), it contains a lot of edge cases and pitfalls (and some of them only appear when you start optimizing, so you might learn bad habits that seem to work for years), and has a manual dynamic memory facility that nobody seems to be able to get right no matter how hard they try. &amp;#x200B; Going back and forth between the two and comparing notes isn't a bad idea. Just learning Rust isn't a bad idea. Just learning C isn't a bad idea. However, there are trade offs to everything, so don't be afraid to backtrack if whatever your final decision is seems to lead you to a dead end. &amp;#x200B; /u/mkusanagi mentioned python and honestly that's not a bad idea either. Python is also widely applicable and popular and is a pretty capable language. It also is a bit easier to get started with than something like Rust or C. Six months ago I never would have said this, but I think Javascript might also be a good choice for first language. It's got a lot of powerful concepts that you'll see in other language and the pitfalls are (I think) less problematic than what you'll find in C. &amp;#x200B; Finally, would you mind adding some more information? Depending on what you're trying to accomplish there may be one language that is going to be more useful for you to learn compared to all the ones that people are suggesting. One of the big problems with learning programming is that everything is potentially really hard. It helps if you can find an application that you can make small victories on in between learning how to program. So, if you wanted to do web development then maybe C is a bad idea. And if you wanted to do embedded development, then maybe Javascript is a bad idea. &amp;#x200B; &amp;#x200B; \[1\] - In the following order: C++ (used as C with classes), C, Java, Lua, C#, Perl, Python, Ruby, Ocaml, Lisp, Haskell, Forth, R, Factor, F#, Idris, Rust, Javascript.
Oh, didn't know about the formatting issue. I kinda got used to new reddit. Your lifetime modification looks fine, thanks! I've yet to use Box in any way in my code, so that's a good pattern to know.
Thanks 🙂
&gt;omicr meh, thanks
Some interesting points which would have helped me getting into Rust: &gt; inlining is the mother of all optimizations Especially by the metaphor that *so* much of optimization is descended from inlining. Instruction and memory scheduling, hoisting from a loop, dead-code pruning, etc. etc. &gt; the security world, where fat pointers are used to encode certain security properties (e.g. the second part of a fat pointer might carry around a memory block’s length, so that all array accesses can be checked for safety) That's exactly how `&amp;str` and `&amp;[T]` and work. --- Thoughts on fat-pointer benchmarks: - Benchmarking dead code gives me the willies. I would: - Reveal the address of mutably-borrowed `v` to an external call. (e.g. printing `v.as_mut_ptr()`) This prohibits the optimizer from assuming that the values contained in it are the same ones pushed, which means it can't do anything to de-virtualize the call. - Use the result value. `assert_eq!`is sufficient (with the above step) because panicking is a side-effect, the side effect depends on control-flow, and the value is a guaranteed dependency of the control flow. - `VEC_SIZE` of 1 million with 16-byte fat pointers means just shy of 16MiB. That could conceivably fit into L3 cache, if not now then soon. This is a sequential load. - Since the `Box&lt;SWithRead&gt;` allocations are made sequentially, the read operation should also be nearly sequential. Consequently (pun intended), loading 50% more data took no more than 50% more time. I'd bet it's *much worse* if you were to shuffle `v`, and that's - Even though the virtual call compiles to an indirect call, the branch-target predictor should be perfectly accurate on the `call` instructions after the first few. --- Thoughts on the thin-pointer benchmarks: - It's not transparently clear what the type of `v`is. It seems to be, roughly, `Vec&lt;(Box&lt;Void&gt;, *const VTable)&gt;`. I would like that to be clearer, and would likely use nightly for `std::raw::TraitObject` &gt; However, `bench_innervtable_with_read` is only just (taking into account the confidence intervals) slower than `bench_innervtable_with_read`. Yes though again I'm curious what happens when you shuffle `v`. Fetching the vpointer will also fetch the object, like you say, but I'm expecting far worse (though equal) cache behavior for both. --- I have a little time before work so I'll see if I can try it out. Oh, one last thought: &gt; `&amp;*x` looks like it’s saying “dereference x and get a reference to where x is stored”, but it doesn’t dereference `x`: it just reinterprets a raw pointer as a Rust reference, which has no run-time effect. The precedence is `&amp;(*x)` and it means "borrow the target of `x`". The only thing strange (to me) is that dereferencing is *not* a load. It's address generation. `*$expr` means "interpret the value of expression `$expr` as a location, invoking `Deref` or `DerefMut`". Loads from memory are, in Rust, purely implicit: whenever you use a location expression where a value is required, Rust loads a value from that location. If you imagine a CPU in which the index registers aren't connected directly to the ALUs, then `*` is analogous to transferring a value into an index register and `&amp;` is analogous to taking it out. It's easy to imagine that pair of operations having the side-effect of telling the CPU it's okay to interact with an address identified by number. 
rust docs says, "If you'd like to learn Rust, this is the spot for you! All of these resources assume that you have programmed before, but not in any specific language" Go for it. When it says they assume, they're talking about data structures and algorithms. The books don't try to explain these, they just expect you to, know, or be fine not knowing until you can learn on your own. You've got this. Do the thing: [https://doc.rust-lang.org/](https://doc.rust-lang.org/)
In the first case `mut` is there because it's part of the reference syntax, which look like this: `&amp;T`, `&amp;mut T`. In the second case, it's part of a pattern, which look like this: `x`, `ref x`, `mut x`, `ref mut x`.
How did you like Idris? I haven't looked into it, but I keep hearing about it. &amp;#x200B; Also, after learning so many things, how was your JavaScript journey? I keep having the need to make some dashboard or other frontend, but the whole web world keeps scaring me off. 
You're not wrong. Starting rust with no programming context has got to be rough, but at the same time, telling someone they should learn such and such language because it's easier is awful advice. You should choose your programming language based upon the problem you would like to solve. If that's micro controllers, saying "learn JavaScript first" is distasteful and will likely lead to someone quitting. The best way to learn a language is to have some project or problem you want to work on along the way, and then sticking to it until your project is finished. 
&gt;Rust is not a object oriented language with lots of inheritance. You may wish to revise this sentence. Rust is kinda on the fence about being an OOP language. 
Idris feels like a cleaned up Haskell. There's a lot of things you can just do instead of having to worry about which language extension you need to include. Dependent types also feel like they make a lot of things cleaner than having to worry about kinds, higher order kinds, etc. &amp;#x200B; That being said, I never quite got the hang of the dependent type pattern matching. And most of the things that I wanted to do with the type system ended up feeling a lot easier using Rust's type system (ownership types are easier than dependently typed DSLs built in algebraic data types). &amp;#x200B; Javascript isn't as bad as I expected it to be. I don't like the object system (inheritance even prototype inheritance doesn't feel like the right way to solve very many problems), but it seems a lot of things don't actually make use of it. Destructuring is nice, their objects are okay, having a billion different libraries that already do what you want is nice. It's got lambdas, let, and dictionary like objects, which appears to handle 90% of what I want to do anyway. I would personally like some static types, but there's also some options there like typescript.
If that's gatekeeping, then so is a bike with training wheels. 
I &lt;3 QB
either way would be fine.. But if you wanna be make something a beyond trivial programs quickly.. then go with Rust
I have look at several ndarrays crates for use for my [relational backend/lang](http://tablam.org). I'm in the camp of data manipulation, not science per se. So, I see this alike kdb+... I wanna to cover much more than ndarray but wish to have it as my array/vector. &amp;#x200B; Some stuff: \- Be "just" a data frame library. Put all the other stuff in another crate (not need to be another repo). I see too much effort in try to implement scientific stuff intermixed with the data frame. This make code confusing. \- Being overly focused with scientific calculation make some restricted to operate on numbers. \- Nice to be able to have row-major and column-major \- **Put focus in how manipulate the data**. Filter, select (columns, rows), mapping, ie: the functional interface. In my design, I don't create specific sum, avg, etc implementation, instead I make "binary ops, unary ops" by ref or cloning and just pass functions for the rest. This allow to be more than "make math". For example, I wanna do equally: array |&gt; sum array |&gt; String.Upper Other way to look at it: Be a good foundation like vectors and b-trees. \-If enum based, then put also decimal, dates, some way to emulate structs, and a way to put raw binary data so is kind of possible to build a custom object (ie: Like Json but a bit more) \- Super-nice if allow to pack heterogenous data using ANY or other way that allow to put any data there. Not yet see how can this be possible. \- Loading from data sources as CVS not need to be hardcode. Instead, give a trait or similar so is possible to plug any we want, alike serde. \- I think a nice, ergonomic interface can be done *first* before to be super-concerned with performance. After several attempts trying to build a relational engine on rust I have become more understanding in how hard is to build a heterogenous, 2d structure. Is hard. I'm under the impression that a generic way to solve all is kind of impossible to do with rust now. Need to do specialization, code generation or similar \- Work together. I think a small group of people could do much more than just one. The problem, like always, are the competing ideas and each personal agenda. That is why I think to get focused in just "be a ndarray" is key. Anyone, could extend from there.
I'm just giving advice based on years of experience teaching people new to programming, and it's entirely optional. I'm not stopping anyone from going with Rust first, I'm just very sure that those people won't keep programming for long. &gt;You should choose your programming language based upon the problem you would like to solve. I agree, but if the problem you want to solve is “I want to write programs that are guaranteed to be memory safe” (which is the prime application for Rust), you aren't a beginner, because beginners don't have problems like that. &gt;If that's micro controllers, saying "learn JavaScript first" is distasteful and will likely lead to someone quitting. I'd recommend Micropython for that, which was covered by the first language I mentioned. Besides, once you know some language, switching is always easy anyways. Anyways, starting off with microcontrollers is always rough, because in addition to the software, you also have to cope with the electronics side of things. However, I've seen people start with this and getting things to work, so it's not without hope.
I'm working toward a solution inspired by this (https://github.com/DenisKolodin/rusty/blob/master/src/config.rs) and that integrates clap/dotenv. I'll publish it once it becomes mature enough.
So what you mean is: The code are not quite equivalent (one will panic and one won't) but since you are running them in a Test, it'll then give the same outcome?
Mutability of owned Values in Rust is part of the binding, not of the value, whereas &amp;mut T is a different (reference) type than &amp;T, hence why it's in the type declaration.
I agree that this does not give a great image. The question is whether saving uninitialized is worth significantly complicating Rusts unsafe code model. You go from no uninitialized memory except behind unions, to two subtly different types of “weird” memory behind potentially every type (integers, pointers, references to integers, DSTs, etc).
Should be possible hmm
As much as I like rust, I'd say C is better to learn first tbh. Then once you blow things up a little bit checkout rust, and see how it differed / protects you from things that explode in C. That's how I learned both and I enjoyed the whole ride. 
Which requires you to write tests for all possible code paths at least, while in the case of Rust these specific issues would be categorically prevented by the compiler without you having to write tests for that. So in the end you have more time to write tests for actually interesting parts of your code.
As someone who transitioned from R to Python, I still miss the syntactic sugars that made R just that little bit less friction-y to get things done. Sure it sometimes made you mad because things were unpredictably failing due to overlapping syntax, but that's the correct trade-off for that space. Unfortunately, it's not obvious that's the cultural values that Rust really has.
Thanks!
C. 
&gt;memory safe” (which is the prime application for Rust) A prime. Also multi-threading, removing pitfalls(related to memory safety), and system level programming. &amp;#x200B;
Title: How can I use the implementations of traits done in other modules, in the current module? Content: Hey! So I'm trying to extend a the serde\_json value struct doing the following: src/serde\_extension.rs use serde_json::*; trait SerdeDefaultStr { fn as_str_default(&amp;self, key: &amp;str, default: &amp;str) -&gt; String; } impl SerdeDefaultStr for Value { fn as_str_default(&amp;self, key: &amp;str, default: &amp;str) -&gt; String { match self.get(key) { Some(res) =&gt; match res.as_str() { Some(val) =&gt; val.to_string(), None =&gt; default.to_string() }, None =&gt; default.to_string() } } } in src/handler.rs im trying to use it then `data.as_str_default("name", "");` This does only work if I put above code into the same file, is there a trick I dont know of? cheers! 
C is awesome to learn the fundamentals of how computers work. I’d take CS50 (they start with C and move on to Python halfway through) from Harvard through EDX, it’s free. That’s what I did and it gave me a great foundation to learn further on my own. I was having a hard time getting into programming, but CS50 really grabbed my attention. Learning C first will most likely also give you a better understanding of what Rust is trying to prevent you from doing. Even with the basics of prgramming down, I’d still recommend anyone to do CS50.
I'm probably more unknowledgeable than you but you'll probably need something that makes up a reference (when do you start counting time?) With JavaScript, everything an event is attached. It might not run correctly after xx seconds but the JavaScript engine will try. You'll probably need to define what does time means. Probably run some kind of a clock. A simpler way to do this: 1. Call the function through a separate thread. 2. The function gets time. 3. Run an "infinite loop" where you compare the current time with the time you got at the start of the function call. 4. Break from the loop once the time "times out". 
&gt;multi-threading Not a concern for people who can't tell `if` and `for` apart. &gt;removing pitfalls(related to memory safety) See above, but in addition to that, Rust grants that memory safety by producing pages of error messages that contain words no regular human has ever heard about. Rust doesn't do it for you, it just forces you to do it yourself. &gt;system level programming C can do that just as well.
What are my options if wanna something like streams? &amp;#x200B; My main use case is that I need to have a "cached" version, fill it and yield from it: pub struct Cursor&lt;T&gt; { pub pos:usize, pub cache: Scalar, &lt;-- I need to fill and yield this pub source: T, }
&gt; [C++] solves almost all memory issues if is used with modern tooling like sanitizers and GSL. I guess you mean, this modern tooling (sanitizers, fuzzers, static anylizers) allows you to find almost all memory safety issues with a lot of runtime testing. Right? The GSL, specifically, `span&lt;T&gt;` (C++'s borrowed slice equivalent) helps avoid spatial memory errors by bounds checking, but we're still left with a pretty unsafe abstraction: C++ iterators. They tend to be as stupid as raw pointers for performance reasons. I hope we (as a C++ community which I count myself to be a part of) will see the light and move towards "ranges" and *prefer* to make them "smart" enough to catch spatial memory errors, too. Another issue is lifetime safety: Dangling pointers, references, iterators, `span`s, `string_view`s, range views. The lifetime checker is supposed to improve this area. But it won't give you 100% safety and the current implementations seem to have difficulties with "non-local" bugs. I mean, if the memory safety bug is completely contains within one function I won't be impressed if this can be detected. Spread this out to multiple functions involving a couple of user-defined times which may store non-owning pointer-like things and a bunch of templates and still be able to detect the bug. *Then* I'll be impressed. My gut tells me that this would require a more thorrow integration of lifetimes into the type system. And sure, with a lot of testing of instrumented code (à la memory sanitizer) you'll catch some more bugs. But it would be super nice *not* having to do that to get to a comfortable level of safety.
Note it's very possible that reference validity will be shallow, i.e. not depending on memory state. (Instead, that'd be part of the stacked borrows model.) And to the latter point, my proposal in the UCG repo to make `mem::uninitialized` essentially `freeze(poison)` has landed decently, so it may in fact be possible to disallow `poison` in integers and pointers while keeping `mem::uninitialized` working. The biggest downside I see to this strategy is a potential ambiguity of "uninitialized" in Rust, being `poison` in `MaybeUninit`/unions/padding, and `freeze` in `mem::uninitialized`, but I think that can be handled in the big fat "DO NOT USE" deprecation note on `mem::uninitialized` that'll be there anyway.
Not really? There are a number of people out there who feel very strongly that certain languages are better to learn first and that you'll stunt yourself if you try something else instead of them. I'm not sure how it would be gatekeeping to affirm the opposite of that sentiment.
I will add as an aside to this that I struggled trying to learn C initially because I couldn't wrap my head around the concept of pointers. I took a break from C and learned assembly instead after which C was much easier to understand. YMMV.
[No Real Programmer™](https://en.wikipedia.org/wiki/No_true_Scotsman) would have done such a trivial error.
Great question! I agree that these functions are best used in very special cases, and I think my problem warrants them. I am working on a WebAssembly runtime that I would like to use in Windows. I am using windows structured exception handling to handle errors that occur in the WebAssembly frames. I would like to `jmp` back to a saved context (`setjmp`) when exceptions occur. This is a strategy I have seen in other runtime projects, but I have not been able to wrap my head around how it can work. The problem of jumping between different contexts is common in runtimes, but I am not aware of a nice, well-defined, cross-platform solution.
Rubberduck debugging to the rescue!! So if u do that kind of thing, make sure to put following into your module head: `use serde_extension::SerdeDefaultStr;` That imported the trait for me :&gt;
&gt; It’s not just a question of whether people can catch problems in code that they write. It’s also expecting people to be capable of re-contextualizing every invariant in any code they interact with (even indirectly). It sets the expectation that none of this changes between the time code is proposed and when it is merged. Thank you! Finally a bit of common sense out of this article.
I really like the closing statements from this post: &gt; Let me be clear, I disagree with the assertion that programmers can be expected to be perfect on its own. But the assertion that we just need better C programmers goes way farther than that. It’s not just a question of whether people can catch problems in code that they write. It’s also expecting people to be capable of re-contextualizing every invariant in any code they interact with (even indirectly). It sets the expectation that none of this changes between the time code is proposed and when it is merged. &gt; These are not reasonable expectations of a human being. We need languages with guard rails to protect against these kinds of errors. Nobody is arguing that if we just had better drivers on the road we wouldn’t need seatbelts. We should not be making that argument about software developers and programming languages either. Code can get to a point where it's so complex, that it's unreasonable to assume a person won't make a mistake. Maybe with [NASA's rules](https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code) would be enough to help avoid this, but we always talk about how tools can help us work faster and better. Why not use a programming language that helps us with this too?
All the real programmers are busy trashing the post over at /r/programming (Viewer discretion advised. Yes, it is as bad as it sounds).
Great read! Definitely puts things into context for those who haven’t experienced the compiler catching things like this for them. It shows how the compiler errors aren’t just there to annoy you :p &gt; Let me be clear, I disagree with the assertion that programmers can be expected to be perfect on its own. Just a small point; I think that “its” should be “their”? 
It is. My soon to be former coworkers cannot bother to learn how transactions, identity mapping and ORM (super anti-pattern but the entire industry uses it) work.
this is a really high quality link/share, thank you!
You can't use traits as function parameters. Here are two ways of solving this: pub fn push_child&lt;T: TNode&gt;(&amp;mut self, node: T) { self.children.push(Box::new(node) as Box&lt;dyn TNode&gt;); } pub fn push_child(&amp;mut self, node: Box&lt;dyn TNode&gt;) { self.children.push(node); }
AFAIK no analyzer can catch the dataraces in a multithreaded context.
learning rusts memory model will make you a better c/c++ programmer since it will force you to learn the \*right\* mental model for memory handling. Rust forces you to do it right, while c/c++ trusts that you know what you are doing (it's a bit like a chainsaw without guards, sure it's useful, but I hope you know what you are doing!)
Its is referring to the assertion but that language could definitely be made clearer
Oh, I guess that makes sense; I didn’t read that way to me at first but now you pointed it out I can see it that way! 
I will try to rephrase it when I'm back at a computer anyway, you make a good point that it can be interpreted badly
&gt; freeze being valid in "any-bit-pattern" types like integers is basically required for AtomicCell (freezing padding). Maybe offtopic but can you elaborate on this? AFAIK the problem is that `AtomicCell` uses an `AtomicU32` to store its `(u8, u16)` data, which means that the `AtomicU32` can have a whole in it of uninitialized bits due to padding, which would make using it invalid. But that's because `AtomicCell` chose to use `AtomicU32`. If instead it would choose to use `(u8, u16)` directly, and operate on it using atomic operations on the memory via raw pointer `*(u8, u16) as *mut u32`, then everything would be fine. The issue here is that `AtomicCell` is implemented on top of a type, `AtomicU32`, that does not model reality, because memory places aren't atomic (in the same sense that they aren't volatile either). What's atomic (and volatile) are operations on memory. 
Did you even read the post?
For C, or in general?
I had no idea that dyn doesn't do anything, is it planned to make using it mandatory? I found it pretty confusing that some code used it and some didn't 
Interesting, I can do this fn m( mut v : &amp;mut Vec&lt;i32&gt; ) is this ever useful? Maybe with unsafe?
This is my experience as well. It is "easy" (read: doable) to write completely memory safe code when writing applications from scratch. You know how everything works, you have all invariants in your head, and writing the code is straightforward. Issues arise when you come back to the same code months later, maybe even years later. Maybe others have made changes. The codebase had grown and grown. Suddenly, all these conditions and invariants that you had in your head are gone. There are not "imprinted" into the code itself. This is when issues arise.
I never learned how to diagram a sentence properly, but: &gt;Let me be clear, I disagree with (the assertion that programmers can be expected to be perfect) on its own Does that help?
It must have been 10 years now since I started doing programming (almost entirely C++), and its always struck me that programming seems to be very much in its infancy as a discipline There seems to be a pervasive idea that anything safe that enforces a lack of errors is somehow not very good. You see this mentality absolutely all over the place with cli tools like git - there's a common and very heavily upvoted idea in /r/programming that nobody knows how git works, they just apply the correct incantations to make it do what they want This is an absolutely ludicrous state of affairs because better tools exist. If you use something like tortoisegit you will literally never make a mistake. Learning git is extremely easy, and you need to remember absolutely zilch. Complex merges and queries are trivial, and its extremely rare that you need to dip into the cli to do something. It is hard to screw up a repo using a good gui tool The only explanation I have is that a lot of people want to get a certain feeling when they do development - its not about building a quality end product and using your tools to best achieve that end, its about them themselves and their own ego. We use CLI tools because they're cool, we use C because its what real programmers do, and micro$oft sux. Real programmers don't write bugs, I simply imagine the code in my head and write it out perfectly with no bugs in (despite all the bugs my code has) Javascript I think is a big symptom of this. Types are considered 'intrusive' or restrictive and slow down development - its true that its very easy to write javascript, its just a terrible language to build any kind of large scale software in. Honestly I'm not even sure how there's even still any legitimate debate about strongly typed vs weakly typed vs dynamically typed vs statically typed anymore, programming in a dynamic weakly typed language feels like intentionally programming while wearing a blindfold This mentality seems to be dying off though, and rust is a good sign that the industry is getting its shit together despite protests from everyone that C and C++ and javascript are just great even when they're obviously terrible. But there's still a huge amount of distance to go when it comes to creating effective programs effectively, particularly when it comes to tooling (from a C++ perspective, no rust 4 me yet)
Well, it's undefined behavior when you use non-atomic reads to read an atomic write by the C++ weak memory model, actually (which Rust largely borrows). All of these issues matter at the optimizer (virtual machine) level, not the (physical) machine code. (This is a complex problem way over my pay grade.) The problem comes with CAS. There's no way to CAS with a hole. If padding remains `poison`, it can compare equal to itself or not, whatever is convenient to the compiler. Actually, more specifically, comparison results in `poison`, the use of which in any manner results in `poison`, and the branching on results in UB (a contradiction, so the optimizer can do whatever it wants). CAS looks at the entire value including padding. There's no way around that, it works that way at the hardware level. At the LLVM level, atomic operations work on integer types. Atomicity is in fact a property of pointer access, but it works on the whole value behind the pointer and can't just ignore padding. [[Of course, I speak not from authority, but as an interested observer. These are subtle issues and I could be subtly incorrect.]]
This is the biggest mic-drop (though I don't mean it's mean-spirited in any way) I've seen come out of Rust so far. Programmers of other languages aren't sure whether it's even possible to automatically prevent single-thread aliasing &amp; bounds violations. But rustc is such a bro, it's proofreading thread-pool RPC like, yeah, it's no big deal. The narrative is totally relatable - come up with something reasonable, implement it, miss a detail. And if anyone is going to jump to the conclusion that "oh, just the carelessness of Lesser Programmers" - *boom*.
In my mind, the phrase "There isn't any kind of trend" implies that the author _isn't_ endorsing the idea of "the wrong language". There's nothing wrong with misreading something, but if you misread something _and_ up the criticism/nastiness level at the same time, that makes everyone sad.
&gt; The problem comes with CAS. There's no way to CAS with a hole. If padding remains poison, it can compare equal to itself or not, whatever is convenient to the compiler Are you sure? I think this depends on which semantics you define CAS to have. At the LLVM IR level, a CAS intrinsic could support not only integers but structs with holes where the holes are poison. At machine code level, CAS instructions do not care, so if you expose CAS instructions in `core::arch` for each architecture, then each one has the semantics that CAS has on that particular hardware.
As with many things about Rust, I think it's helpful to imagine asking the same question about C++. Would I recommend someone start with C or C++? That depends a lot on what they want to do, whether they already have another language under their belt, and so on. I'll note that as with C++, Rust has a steep-ish learning curve, and that picking it as a first language is more challenging than other options.
And you don't need the seat bell :)
I got it now, now it’s pointed out it’s obvious :p
Ah, sorry, I didn't see that rabidferret replied before me.
`poison` bytes aren't necessarily consistent though. That's their whole point. If `(u8, u16)` gets passed around as a `u8` and a `u16`, the padding is different depending on where it's used. If you CAS with different padding from different locations, the hardware CAS will see a different four-byte value, and fail. See also the [C++ link from Amanieu](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0528r3.html) I just edited in. I think you're proposing something similar for `AtomicCell`? It can accomplish the task with `freeze` [fairly easily](https://github.com/rust-rfcs/unsafe-code-guidelines/issues/71#issuecomment-460097424). Of course, you don't need to even think about `freeze`, as it's just a way to no-op regular values and turn `poison` into _some_ (nonsensical) consistent bit string. You already have cases in safe Rust where you can end up with [an arbitrary safe value](https://docs.rs/bytecount/0.5.1/bytecount/fn.num_chars.html), which is exactly what `freeze` is to types valid on any bit sequence.
awesome, now we can rewrite Amiga games in rust!
Why does AtomicCell use `(u8, u16)` instead of `(u8, u8, u16)` ?
If you can choose some other, I would recommend starting with Python, as it has very simple syntax &amp; semantics, purely to learn basics of algorithms. After that I would suggest with C for "low-level" programming, to understand basic manual memory management, and mainly all pitfalls which Rust helps to prevent. Cheers. 
Because you asked for an `AtomicCell&lt;(u8, u16)&gt;`. There's that `u8` worth of padding that has to be accounted for somehow. And when you call CAS on `AtomicCell&lt;T&gt;`, you give it a `T`, and `AtomicCell` has to be in charge of handling padding in a deterministic way. The answer that we have currently is to `freeze` the `T` that you store, turning `poison` padding bytes into arbitrary bit padding. (To be clear: `freeze` is an operation, not a bit state like `poison`. The output is a regular but arbitrary bit sequence.)
I'm not sure what you think I meant. I was not suggesting any language is "the wrong language" but that all languages are fine. 
&gt; And when you call CAS on AtomicCell&lt;T&gt;, you give it a T, and AtomicCell has to be in charge of handling padding in a deterministic way. When the user asks for `T: (u8, u16)`, `AtomicCell` could internally use `(u8, MaybeUninit&lt;u8&gt;, u16)` and call CAS on that. As long as it doesn't call `into_inner` on the `MaybeUninit`, no undefined behavior can happen AFAICT.
Have there been Read implementations that accidentally (or intentionally...?) performed reads from the output buffer? I don't know of that being a thing that happens. As a practical tradeoff I think any solution without UB in safe code is sufficient.
CAS still works on a `[u8; 4]` value at the hardware level. If the padding `MaybeUninit` value isn't frozen or initialized to a known value, you'll get invalid non-matches. This can't be changed by saying "I don't care about byte two" that I know of. And any non-freeze behavior will require `AtomicCell` to be a language feature instead of a library type, to actually work with padding bytes in a non-freeze manner.
Is it race condition?
&gt; CAS still works on a [u8; 4] value at the hardware level. If the padding MaybeUninit value isn't frozen or initialized to a known value, you'll get invalid non-matches. This can't be changed by saying "I don't care about byte two" that I know of. Right, so if the value of byte two needs to be fixed and the same in the `AtomicCell` and the value passed to the CAS, why not just use `Atomic&lt;(u8, u8, u16)&gt;` ? What is the advantage of using a `AtomicCell&lt;(u8, u16)&gt;` and having to use freeze? 
&gt; Honestly I'm not even sure how there's even still any legitimate debate about strongly typed vs weakly typed vs dynamically typed vs statically typed anymore, programming in a dynamic weakly typed language feels like intentionally programming while wearing a blindfold If someone argues for weak typing for quality, yeah i don't know what they're thinking. The argument for being able to code faster is a business one. Can you build something solid enough, without needing it, to get to market sooner?
&gt; This is an absolutely ludicrous state of affairs because better tools exist. I compare it to using a table saw without a riving knife. Sure if you can account for every variable every time, you'll probably be okay, and sure it makes some cuts more difficult. But there's a good chance you'll eventually lose a hand of take a board to the chest/face.
The advantage is that no other generic type works that way. Forbidding padding in `AtomicCell` isn't something that can be done without changing the language to support it, and would be very surprising to anyone trying to use `AtomicCell`. It also only applies to structures below the size of the largest atomic operation on the platform (larger atomic cells are simulated with a lock). And what about enums or unions? Are those forbidden in `AtomicCell`? (Well, it does need a `Copy` type, IIRC.) Basically, `AtomicCell` means `AtomicCell&lt;T&gt;` means _any possible `T`_, which means working on padded types. And `ptr::freeze` has a library-only PR right now, as well.
The Win32 API is a pure C API, and the kernel is written in C and comparatively small amounts of assembly. The userland is mostly C++ and, these days, C#.
I like the idea of having a trait for the data loading part. Assuming, it's not something too crazy it shouldn't be too hard for those of us working on these types of crates to implement. For example, I'm currently working on the next version of my data_reader crate that should allow for heterogeneous data files to be read in, and I wouldn't have a problem adding such a trait if it looks like it'll be a standard one among dataframe type libraries.
It's good when you have people to explain to you why your program might be crashing or printing garbage, otherwise it can be a very frustrating experience. The absolutely unforgiving runtime behavior is somewhat mitigated if you turn on *all* of the warnings and lints the compiler has these days. But even then a lot of things like the integer promotion behavior and the builtin ways to deal with strings are just so badly designed that I'm not sure they're worth anyone's time to figure out.
They removed my message from playrust....
So basically `AtomicCell` requires `padding` to have a deterministic value.
With the new `Span&lt;T&gt;` and `Memory&lt;T&gt;` and friends you could write a game using the ECS pattern and make all your components struct only. Write a `MemoryManager&lt;T&gt;` that allocates from unmanaged heap. This would require very little GC pressure. 
Hey guys, anyone knows a simple way to do a regex over a (large) file? I've seen that doing a "grep -e texttosearch file" is much more faster compared to reading the file line by line. The regex crate seems to support only str. Thanks for any help, I'm really stuck on this. 
Oh how many times have I had people deride Rust because real programmers don't make errors, and then I use their code that is 100% clean room C, and it SEGFAULTs repeatedly for months. Seriously, this has happened repeatedly. I'm pretty sure it's hubris, stubbornness and peoples' ability to invent excuses to avoid learning new things.
I think there's another Rust size breakthrough in tackling this problem. I think it's an error to think all programmers will learn and start writing code in either Rust or a language as rigorous as Rust. I think if we fast forward to a day when software as an industry is becoming more mature you will see most "software" built with higher level tools that interact with lower level code written in Rust. However, they will not be written in Rust themselves. &amp;#x200B; Applications don't translate well to imperative languages. They are mostly event based. Critical libraries such as crypto, databases, and in-memory data structures will need to be rigorously written by experts. But I think a strategy of spending more time on them, using more rigorous tools like Rust resulting in a canonical solution that lasts a long time and used by a multitude of higher level applications written in something else will work well.
Exactly. For `AtomicCell` to function, it needs some way to make padding deterministic. For optimizations elsewhere in the compiler, having padding be non-deterministic is advantageous (such as passing `(X, Y)` as a `X` and a `Y` separately). `freeze`ing the entire value while storing it in an `AtomicCell` is almost certainly the simplest way to accomplish this. And it doesn't add any valid states to an integer to allow `freeze(poison)`, as that's just an arbitrary bit sequence, all of which are valid at integer.
I think Rust is the better choice in your case because of several factors. In Rust you have the possibility to learn a language which on the one hand is already stable enough to support big and serious projects and on the other hand is still in development. This gives you the possibility to experience the 'hows and whys' of the language changes while C already has a big history with many interesting background story's and also language hacks. Another thing is that rust also scopes to tackle some mistakes of C as language which brings useful Concepts to have learned before making the same mistakes in C. I mean the whole ownership model is based upon the pain of many programmers crying in agony over their failing code. C and Rust are great languages and its absolutely worth to learn both of them in my opinion. There is probably no wrong choice between C and Rust in your case as you can learn many things from both languages.
Ask /r/playrust
I'm a big fan of C language and while I do belong to the camp that might look down on other's people C code, I don't deny the fact that tooling helps write a better code and I use all tooling I'm aware of to help me write a better code. If Rust provides is such a tool and still preserves the benefits that C offers it seems to be no brainer not to use it. I admit I still planning to find some time to learn Rust, so I don't know how exactly it compares with C. It's possible I might try it and hate it, but I doubt it will be because it has memory safety features.
This paper (https://www.cs.utah.edu/~regehr/papers/undef-pldi17.pdf) states: &gt; All uses of a given freeze return the same value, but different freezes of a value may return different constants. AFAICT, `AtomicCell` needs two freezes: one when storing a value in the Cell, e.g. via `AtomicCell::new(T)`, and one in compare and swap for the value being compared. Those two different freezes won't return the same value for the padding bytes of `(u8, u16)`, so `compare_and_swap` will never compare to true.
[This algorithm works](https://github.com/rust-rfcs/unsafe-code-guidelines/issues/71#issuecomment-460097424). Freeze the stored values, compare with `Eq`. // Assume `T` can be transmuted into `usize`. fn compare_and_swap(&amp;self, current: T, new: T) -&gt; T { // Freeze `current` and `new` and transmute them into `usize`s. let mut current: usize = freeze_and_transmute(current); let new: usize = freeze_and_transmute(new); loop { unsafe { // `previous` is already frozen because we only store frozen values into `inner`. let previous = self.inner.compare_and_swap(current, new, SeqCst); // If `previous` and `current` are byte-equal, then CAS succeeded. if previous == current { return transmute(previous); } // If `previous` and `current` are semantically equal, but differ in uninitialized bits... let previous_t: T = transmute(previous); let current_t: T = transmute(current); if previous_t == current_t { // Then try again, but substitute `current` for `previous`. current = previous; continue; } // Otherwise, CAS failed and we return `previous`. return transmute(previous); } } }
I think it can be easy to understand the building blocks, but their combinations introduce so much potential complexity that it becomes a challenge to "master" (depending on the definition of that word, of course). I'm reminded of Baduk, where the rules are extremely simple but mastery of the game is a lifetime's endeavor.
I'm also very interested in this. I think there's a space for a Rust backend server + frontend framework that allows for "plugins" that provide both a backend service endoint, and a frontend plugin component. The framework can do all of the communication, protocol heavy lifting, etc. You could have DLL Style web plugins, etc.
&gt; Honestly I'm not even sure how there's even still any legitimate debate about strongly typed vs weakly typed vs dynamically typed vs statically typed anymore, programming in a dynamic weakly typed language feels like intentionally programming while wearing a blindfold I agree with you about weakly vs strong typed, but I'm not sure about dynamic vs static. Static is safer and faster, but it it somewhat restricted and more verbose, so there are still benefits of one over the other. I think dynamic languages still offer benefits (unfortunately at the price of safety). I think dynamic languages with type annotations is a good compromise to at least get some of the safety back.
\`nom\`'s need for a \`CompleteStr\` is because \`nom\` is intended to support a \*streaming\* parser -- meaning it will return \`Incomplete\` when it's ambiguous whether or not an error may be because of the end of a file. It's (very) annoying that people who don't use it still have to handle it, but it does come in handy when you're trying to parse whatever has already come over a network!
Thanks, I got the wrong forum
A better and more complete site is [https://weleakinfo.com/](https://weleakinfo.com/) It used to have a public api but ... [https://twitter.com/weleakinfo/status/1006558285678501888](https://twitter.com/weleakinfo/status/1006558285678501888) shit happens botnnets also If you just want the post data post to [https://weleakinfo.com/](https://weleakinfo.com/) Host: weleakinfo.com User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3 Accept-Encoding: gzip, deflate, br Referer: https://weleakinfo.com/ Content-Type: application/x-www-form-urlencoded Content-Length: 82 Connection: keep-alive Cookie: __cfduid=d01f45ece58b31e2c66e83d573e81c2dd1549997550; cf_clearance=43562bca4cd59ca1343ba0e4461904210e645c8f-1549997554-3600-150; PHP_SESSION=qigct9srncoho1phbsgbtrra0n Upgrade-Insecure-Requests: 1 TE: Trailers query=(your email urlcoded)&amp;type=email&amp;search=&amp;CSRF=(get the token from view-source:https://weleakinfo.com/) To bypass cloudflare well I use the python module [https://github.com/Anorov/cloudflare-scrape](https://github.com/Anorov/cloudflare-scrape) I Will port this to rust in my free time.
One popular way is to start with Python, JavaScript, Racket, C# or something. They allow you to get started solving problems without having to learn pointer manipulation or lifetime stuff. Another popular way is to start with assembly and work your way up, or to start with lambda calculus or something similarly math-y, and then work your way up the abstraction layers by essentially going through the history of software engineering on fast-forward. In no case do I recommend C or Rust. They both occupy a weird no-man's-land, where they simultaneously have too much abstraction to teach you how computers work, but also don't have enough abstraction to allow total beginners to recreate Pong.
C is quite great but each time I write char *mystring = "wanadie"; I die inside so.
have just fight vs reqwest for 2 hours to just make a post, something that I do in 15 seconds with curl or python so atm rust need more docs and I need to redead https://doc.rust-lang.org/book/foreword.html since I still doesnt get the ? keyword 
&gt; Although is geared more towards C, so it give lots of false positives in C++. Unfortunately, that's a big downside. If the single real issue is drowned into a thousand warnings; it's unlikely to be seen and caught :(
Solid post. Strongly agree. 
If you start with C, make sure to use all the linters you can get. It will teach you a lot (and sometimes, warn about the issues rustc would also complain about). I would recommend starting with C. Make sure to internalise the concepts of pointers, stack vs. heap, dynamic memory allocation. When you look at rust later, I'd recommend trying to make small C programs that do bad things (like freeing a buffer twice) and then trying to write an equivalent rust program.
Bugs. I've rarely seen a rewrite (even partial) which did not introduce bugs. The existing tests never cover everything; and Murphy kicks in.
It could be, but also depend what you wanna build (from an os, to a game or just a simple app), but that doesn’t have too much with the language, but with your knowledge of the subject, also as was pointed in other post, C is a very „simple“ or small language compared to others, so is much more easy to learn the entire language, what could be hard is master the concepts (memory handling) and embrace good practices.
&gt; With a normal mutex we would be fine, since you only one lock can exist and it doesn’t matter if we unlock it on a thread other than the one we locked it from. Doesn't that violate the usual assumptions of a mutex? It's fine to do that for a semaphore, not a mutex.
[removed]
Oh, I didn't see that. I might switch to that instead myself.
Yup, that's why I made it.
Posted as a [tweet](https://twitter.com/dpc_pw/status/1095402375597064192): Blaming "programmers not good enough to write correct C/C++" is like blaming "construction workers not strong enough to lift concrete blocks". To reliably and quickly build, modern physical infrastructure, you need heavy duty construction equipment. To reliably build modern software infrastructure, you need heavy duty programming language like #Rust. 
Re verbosity I tend to disagree. Type inference allows you to omit the type annotations in many places, and for all other places, you'd need a unit test to ensure the correct type (or at least an assertion in the code), so this should actually be a win for statically typed languages here. The reason it's not is that static type systems let you encode facts about your program that you cannot identify at all in dynamic languages.
It's OK, I removed your post to spare you further embarrassment.
&gt;Maybe with NASA's rules would be enough to help avoid this I don't know if a set of rules are sufficient. Are there any set of software engineering practices that have enabled a (large, changing) team to use a memory unsafe language safely? Let's say that a new project starts and the company allocates its strongest developers for the new project. Standards are high and the quality is very good. Yet, a large software project that lasts over a decade will encounter problems with maintenance. The original code might be great, but the people who wrote it will leave. The project needs to on-board people who will make not-quite-mistakes, because they're learning. But when those almost-mistakes are detected later on, there's no time to improve them. And so the project quality decays over time. &amp;#x200B;
Don't learn Rust as your first language. It has a lot of nuances that won't make sense or become apparent until you understand more fundamental concepts of programming. Learn C first.
Great article. Good to see trait objects being brought up. It's interesting to see some of their performance implications. TBH more people should probably be reaching for trait objects in the rust community. The vast majority of applications I see posted can afford the small (in many cases) performance impact from using them. A lot of the time it makes sense to use the thing that is more convenient than go after imperceptible performance gains.
? the thread sanitizer can catch some dataraces
&gt;I like my Gregorian birthdate more. 30th - 31st of December?
How do you `try` through a closure? Example (pseudocode): fn lines(r: BufReader) -&gt; Result&lt;Vec&lt;String&gt;&gt; { Ok(reader.map( |e| e?).collect()) } 
The top comment trees are all pretty sane now. Apparently the Real Programmers™ left to write more memory bugs.
You can't, but there are some nice trait implementations in the standard library, such that: let result_iter: impl Iterator&lt;Item=Result&lt;T, E&gt;&gt; = ... let result: Result&lt;Vec&lt;T&gt;, E&gt; = result_iter.collect() I.e. you can collect a sequence of results into a single Result that is Ok if all Results in the sequence were Ok and Err if at least one Result was an Err. 
&gt;It is hard to screw up a repo using a good gui tool Honestly, it's really hard with the CLI too. Because things in s repo are immutable, as long as you have committed something at some point, the only command you can't recover from is push, and even then you can if you're quick. I think it's just a matter of people not bothering to build a mental model and stopping short after they learn a few basic commands. Which, mind you, is rather silly for a tool you might end up using daily. The git UI is all over the place, but it doesn't matter because its fundamental model is so damn simple you can fuck up all you want and still figure out how to get to a state which makes sense.
Generally you'd want test to ensure the business logic is correct (and stays correct) either way, so I don't see the need for tests being reduced that much. 
Sentence needed a static analyzer. "Perhaps you meant 'Let me be clear: I disagree with the assertion that programmers can be expected to be perfect." It's especially funny, now that I look at it, that the sentence starts with "Let me be clear…" :-) It was a great article, partly because it was exceptionally well-written. I couldn't have written it better, as I'm not a Real Writer™.
I would `mmap` the file (you'll need a crate for that and it's unsafe) and then use `regex`'s [https://docs.rs/regex/1.1.0/regex/bytes](bytes) submodule.
The `regex` crate has a `bytes` submodule, which you can use to match on arbitrary data you're getting from a file. If you're dealing with files that are too large to read entirely into memory, you could consider using the `memmap` crate to get a virtual `&amp;[u8]` over the entire file without actually consuming that much memory. I understand that `ripgrep` uses a slightly complicated hybrid strategy of memmap'ing large files and directly reading small ones, and it also handles tricky edge case around how to deal with matches that span more than one read. It looks like the `grep` crate provides some of `ripgrep`'s functionality as a library, though it looks a bit sparsely documented, and it might be tricky to figure out how to use it correctly. Any chance the previous approaches work for your use cases?
What do we all the `&lt;_&gt;`? How about grumpyfish?
I agree with a lot of the points that /u/SCO_1 is making but really disagree on their choices. I found that python is terrible for beginners, the strange syntax, the whitespace issues (beginners can't see what is causing the program to break so it's hard to debug), the disconnect between python 2.7 and 3+ etc. Here are my recommendations: Dynamic typed scripting language: Ruby Strongly typed production language: Kotlin (you will learn java just by working with kotlin) Systems language: well, good luck... they're all gonna be difficult, Rust is probably the most difficult but you'll also learn the most. While Go is the least difficult and also the worst. I won't recommend Go. 
`[u8; 4]` will store the elements directly in the variable. It is just a type which is 4 bytes large. `&amp;[u8; 4]‘ is a reference to the element above. ‘&amp;[u8]‘ is a so-called slice. It is a special type of reference which consists of two parts: a pointer to the first element of the array and size of the slice. Note that &amp;[u8] itself that consists of two parts. Converting an element of type &amp;[u8; 4] to &amp;[u8] is a process know as unsizing. It take the original memory adress and adds to size of the slice to it.
No, a [u8; 4] is exactly 4 u8 values, which can be stored on the stack because their size is obviously known at compile time. A &amp;[u8; 4] is simply a reference to those 4 u8 values. On the other hand, [u8] is a variable amount of u8 values, so its size is n\*size_of::&lt;u8&gt;() where n is the amount of u8 values. This can't be stored on the stack, because it will have different sizes at run time. &gt; It doesn’t make sense why it wouldn’t heap allocate the data then return a pointer. Because that's not how it works in Rust ¯\\\_(ツ)_/¯ If you want to heap allocate, you have to do it "manually" via a Box. &gt; Because &amp;[u8] is allowed, where is the slice being stored then? Well that depends on where you stored it! Maybe this is a slice of a Vec&lt;u8&gt; - in that case the underlying data would be stored by the Vec. Maybe it's static data embedded in the binary (think constants), then the slice would point into the data section of the binary.
I don't understand your question.
Thanks for answering! Have you entertained the idea of any of the following compile-to-js languages?: \- elm (much simpler than Haskell) \- purescript (all the HKT etc. goodness) \- reasonml/bucklescript (a little more like Rust because it's just OCaml)
To be fair, something like 2to3 is much, much easier to implement in a statically typed language.
I'm building a relational engine/lang. I need dynamic behavior, but I wonder how much possible is to encode joins in type safe way? &amp;#x200B; I think is not possible. I ask here: &amp;#x200B; [http://lambda-the-ultimate.org/node/5353](http://lambda-the-ultimate.org/node/5353) &amp;#x200B; The problem is that JOINs create (or remove!) new columns depending in several factors. For my lang I think I need to create a typing syntax like: fun queryOrders(...) = Customers LEFTJ Orders but do the same on rust? I think is possible to encode "I will do a CROSS JOIN" but not "and this fields will be produced"
I agree with your general thrust, but the following stuck out to me: &gt; We use CLI tools because they're cool Are you arguing for visual programming here? I think compositor style interfaces have a place in some areas, but in general, I haven't met a GUI that's better in general for programming. The real reason people have an affinity for CLI tools is that they can be automated very easily. &gt; I'm not even sure how there's even still any legitimate debate about strongly typed vs weakly typed vs dynamically typed vs statically typed anymore Because in the *research* phase of a problem (such as in a REPL or Notebook style interface), you have the types in your brain and are iterating rapidly over them. And when you figure out what you did, you just want to quickly encode the work and not have to go back and carefully annotate the expected types to prove that the work was correct. Presumably interactive theorem prover style systems could help with this sort of thing, but there doesn't seem to have been much movement.
Well, dynamically typed languages are a bit quicker to shift around. And while it is more volatile, javascript for the most part was constrained by small self contained widgets or scripts you would use to enhance certain areas of your webpage, so it wasn't all that difficult to control or manage. Currently, obviously, the front end applications are becoming bigger and more complex. And even with latest tools these are not exactly easy to manage. Hence .. TypeScript is growing fast. While I can agree that programmers tend to be very .. well, ritualistic and people of habit, like well, who would have known, almost all people are. I wouldn't shift this so much on "mentality" and more to big things moving with huge inertia which is slowly shifting. &amp;#x200B;
&gt; Are you arguing for visual programming here? I think compositor style interfaces have a place in some areas, but in general, I haven't met a GUI that's better in general for programming. The real reason people have an affinity for CLI tools is that they can be automated very easily. &gt; &gt; Personally I think visual programming is an interesting idea that's extremely hard to do well in practice - but I'm talking mostly about tooling here like git, build systems, and debuggers. CLI tools are good for automation (and composition), but that's about it in my opinion. Visual tools are able to provide the whole context of what that tool can do which cli tools simply cannot do, and present it in a way where you can't make a whole class of mistakes that are possible with cli tools
Am teaching a systems programming course in C right now. Can confirm.
I've been working on full wrapper for HDF5, it's grown quite a bit lately: https://github.com/aldanor/hdf5-rs (it has been kind of on pause for a year or so when I didn't have much time for it, but now I've resumed hacking on it with full force). The end goal - fully-threadsafe wrapper with Rust-like ergonomic API that covers the entirety (or almost entirety) of the low level libhdf5 (including the more obscure stuff, e.g. we've currently added support for MPI-IO and direct VFD drivers, things like that). It's currently already quite usable on Linux/OSX/Windows with any HDF5 version from 1.8.4 to the latest; uses `ndarray` as a backend for in-memory n-dimensional arrays, e.g. you can read/write `ndarray` arrays and slices. Ofc I'd very much appreciate any participation (it's a pretty tough task for one person tbh), if not in the form of code contributions, but at least in the form of comments/issues from crate's users viewpoint :)
Thank you for the breakdown!
Don't forget `-Werror`. The temptation is real.
I've left a comment re: hdf5-rs above, but just noticed you've mentioned it here as well, thanks! &gt; a more high-level Rustic interface but nothing like that exists yet That's our goal exactly :) [Here's](https://github.com/aldanor/hdf5-rs/pull/31) a recent example - wrapping the entirety of H5P FAPL API, where almost every single usable function is wrapped and every single type has a "Rustic" counterpart, so the high-level interface is (a) threadsafe, (b) memory-safe, (c) complete, so the user doesn't have to dig into libhdf5 routines. Would certainly appreciate any comments, of course! Comments/opinions help a lot in driving the user-side of the interface into being more "Rustic". &gt; so only the few functions that I require (H5Fopen, H5Dread, ...) are actually wrapped. If you mentioned the functionality that you need and is not currently wrapped, we could certainly try to prioritize it :)
Haven't read the book, but this sentence in the v2 changelog is enough to put me off it: "This edition of the book drops the design of imperative programs." Wha? I mean, I'm a reasonably fluent functional programmer, but at some point you have to learn to design imperative programs, I think? Sounds like a Racket™ to me.
Also, if you do choose to learn Rust and Python, rust-cpython and setuptools-rust work together very nicely to allow you to easily and comfortably write Python programs with Rust components.
&gt; Visual tools are able to provide the whole context of what that tool can do which cli tools simply cannot do, and present it in a way where you can't make a whole class of mistakes that are possible with cli tools Is this really true? It seems like if the visual tool really *prevents* you from making an error, then it has a better semantic encoding of the problem than the CLI tool, but it doesn't seem intrinsic that the CLI tool couldn't be enhanced to forbid a clearly incorrect operation. I think you're saying that it makes it more *obvious* when the information is presented in a visually cohesive way, right?
Allow yourself some room to unlearn old habits. Just like writing good C required unlearning popular `goto` and type-punning tricks from the assembly languages of the period, writing Rust without fighting the borrow checker rules or out makes difficult certain designs which the compiler can't verify. Also, don't expect writing a linked list to be a trivial task, suitable for a quick learning project. They're actually deceptively difficult to implement *correctly* without a garbage collector and Rust will call you out on that. There's a [free book](http://cglab.ca/~abeinges/blah/too-many-lists/book/) I recommend on that topic. I haven't had a lot of trouble so far, but that's mostly because I never really built an especially strong habit of using certain Object-Oriented Programming idioms which Rust doesn't like.
Working on [`rust-bitcoin`](https://github.com/rust-bitcoin/rust-bitcoin), a bitcoin library that aims to have minimal dependencies.
&gt; A recent blog article discussed the fact that 70% of all security bugs in Microsoft products are due to memory safety vulnerabilities. Speaking about Microsoft, problem is not in programmers, problem is in managers. People are happy working in MS they earn money, they dont give shit about good coding. Windows is unable to shut down itself nicely since windows 98. How rust will ever solve this?
Yeah, that PR looks gorgeous. Makes it looks like upgrading to Rust 2018 "just works". &amp;#x200B; What you don't see there is the several PRs that led up to the final changeover. &amp;#x200B; \[Here's attempt #1\]([https://github.com/tikv/tikv/pull/3952](https://github.com/tikv/tikv/pull/3952)), which was just going for the whole upgrade all at once. Not a success. &amp;#x200B; That was a learning experience, pointing out all the problems we'd encounter, and toward a better way to approach the upgrade. &amp;#x200B; Here are the \[one\]([https://github.com/tikv/tikv/pull/3962](https://github.com/tikv/tikv/pull/3962)), \[two\]([https://github.com/tikv/tikv/pull/4064](https://github.com/tikv/tikv/pull/4064)) fixes for jemalloc that landed next. jemalloc was removed by default between the toolchain TiKV was on and the toolchain in upgraded to for 2018), and the codebase made assumptions that depended on it, and also used the outdated allocator API. &amp;#x200B; Then \[here is the toolchain upgrade\]([https://github.com/tikv/tikv/pull/4000](https://github.com/tikv/tikv/pull/4000)), without attempting to turn on 2018. That mostly involved, running rustfix, and catching up to clippy and rustfmt's current opinions. Running rustfix did not result in a working codebase - it was confused about paths that were non-ambiguous in 2015 that became ambiguous in 2018. &amp;#x200B; Then finally the PR to turn on 2018 that you linked, which is from a branch tellingly called \`rust-2018-try3\`. &amp;#x200B; Altogether it wasn't \_hard\_, but it did take a lot of time and experimentation to find the proper fixes and upgrade sequence. &amp;#x200B; Admittedly, some of the problems we hit were due to being on nightly.
I could have sworn it was send but I will make sure to correct this when I'm back at a computer
[removed]
My experience with 'visual programing' didn't make me respect the concept (which to be fair was only on the shadowrun returns game editor). It was a very simple, very obvious attempt to avoid bundling a script language interpreter in C#, which backfired immensely on their (obviously lie) stated purpose of 'making it easy for amateurs'. Turns out that making scripts take 20 times the time to write and not being even able to create your own functions to factorize common code make people not want to use your editor to make mods unless they're unhealthily obsessed and willing to waste thousands of their free hours chaining OR conditons.... what a waste.
It's not just about unlearning old habits, though. This probably won't be popular given the sub we're on, but... Rust is not necessarily the final stop in program safety. It's quite possible that some or many of the things that are discouraged in "contemporary rust code" because it uses "unsafe" can be completely verified by a compiler (with or without other kinds of annotations) in the future. When I say "other annotations", I obviously don't just mean an "unsafe" annotation, but something more like lifetime annotations, which don't throw away any of the other guarantees you otherwise have. The problem with "unsafe" is that even though we can build (some) completely safe APIs on top of "unsafe" code, that safety is not guaranteed by anything except a formal proof using a proof assistant, which is pretty tedious. My point is just that even if something is considered bad today *because the compiler can't verify its safety* doesn't mean that it is intrinsically bad or that the language/compiler won't know how to deal with it safely at some point in the future.
I like the demonstration; sometimes a simple example is very effective at conveying a point. It'd be nice if you could expand on what you perceive as fundamental limitations for IDE features inside macros, and notably, whether those limitations apply equally (or not) to all kinds of macros. It seems to me that macros by example could perhaps be more amenable to IDE work, as the transformations are more restrained.
I love the joke, but I don't give one flip about RLS support inside of a macro's definition or use. As you say yourself, RLS supporting the output effect of a macro expansion is "relatively" easy. That's all that most people care about.
I have no problem with that. The problem is when people try to force through the design patterns they know, rather than considering whether there might be a way that the Rust compiler can do more to verify. I personally avoid `unsafe` if at all possible, but that's just because I don't trust my own ability and want to push responsibility for getting that stuff right off on other crate authors, so my only justifiable responsibility in that sphere is making sure I pick crates that seem competently written.
In any case, it doesn't invalidate your point. Cross-thread usage of mutexes is something that other languages may try to validate, but can't deny it outright.
Thank you!
Beautiful explanation. One more question: if the array is stored directly in the variable then that means it doesn’t need to follow a pointer to access the data? I don’t get how it actually could be stored inside of it without needing to do that. Thanks again
Thanks. :) I am excited, too.
kebab-case is best-case.
I like to think that after some level of basic "safety" has been met in a codebase, the only bugs a half-decent programmer will make are logic bugs that are easily caught by good test coverage. It's as though after safety has been established, correctness of a codebase practically follows from correctness on a suitably good (but far from exhaustive) test set. A consequence is that when changes are needed, then as long as they're safe, they can be practically *verified* as correct, automatically, and crucially without burdening the programmer. Safety however is notoriously subtle and requires extensive context. As such, when the compiler basically solves the safety part, correct programming is **simplified** tremendously.
&gt; It doesn’t make sense why it wouldn’t heap allocate the data then return a pointer. You can do that, it’s spelled `Box&lt;[u8]&gt;`. An easy way to obtain a value of that type is to start with a `Vec&lt;u8&gt;` and call the `.into_boxed_slice()` method. `Box&lt;[u8]&gt;`, like `&amp;[u8]`, is a "fat" pointer that stores the length as metadata next to the pointer. (Unlike `&amp;[u8]` which borrows from something, `Box&lt;[u8]&gt;` owns a heap allocation. Just like `Box&lt;SomeStruct&gt;` v.s. `&amp;SomeStruct`.)
I did not know about these links, thanks a lot! Indeed there is an information leak problem with `freeze`. But also notice that the RFC got closed and that we also have a decision that unsafety is strictly about memory safety. Ideally there would be some way to incorporate "information leakage" into the definition of memory safety, in a language that also has "freeze". I am not sure how to do that, though.
The reasoning goes the other way around: After a `malloc`, the compiler knows for sure that the memory is *not* initialized, and hence it can optimize accordingly. If the compiler cannot know where the memory comes from, it has to assume that it got properly initialized.
Indeed, the key idea is to determine if the failed comparison was spurious, and if it was then use the *value that was read instead* as the new "baseline". This way the comparison "converges" towards the bit pattern that's actually in memory (in max. 2 iterations), as long as things don't get re-frozen. Also see [this description](https://github.com/crossbeam-rs/crossbeam/issues/315#issuecomment-462409245).
Local variables are stored on the stack. When you create an [u8;4], the compiler generates the code that adds 4 u8’s onto the stack. Reading the i-th element is simply reading the element from the stack. In principle the compiler still “follows a pointer”, it is just a poonter to the stack instead. An alternative way fo look at this is that ‘[u8; 4]‘ is equivalent to some type magical anonymous ‘struct ArrayU8Size4 { zero: u8, one: u8, two: u8, three: u8 }‘. Reading ‘array[3]‘ for example is then equivalent to accessing ‘array.three‘.
If you do allocate it using an array then pass the array to a function as a slice that is stored on the stack though, correct?
Ty!
Yes. I have this experience, and is common, with Delphi. Despite pascal being verbose exist a lot to say in how you mix your stuff so the tooling become very productive.
"100 warnings? Well... it gave me a binary so it's probably fine..." *Segmentation Fault* &lt;Insert Pikachu Meme&gt;
This is a great explanation. So now if I understand it: every local variable is on the stack since it’s size is known, and since a Box points to heap data, the pointer is still on the stack. An &amp;[T] points to some list of stack data, and since [T] doesn’t have a known size, it’s data can be stored on the stack but has to be accessed through some form of indirection.
FWIW, there is some discussion+wire-frames [here and below](https://github.com/rustwasm/team/issues/162#issuecomment-458225002) about what I think would make a good rust+wasm web components library.
\&gt; I think dynamic languages with type annotations is a good compromise to at least get some of the safety back. Instead, I think is better the opposite. Think seriously WHEN you need dynamic. &amp;#x200B; Not when doing "sum(1, 2)", "for I in .." and a lot of stuff. Even function and method calls could be solved at compile time. &amp;#x200B; Instead, you need dynamic types when building on the fly complex structs/tree, and operating in DATA. But CODE, a lot of it, is very static in nature.
There should be a macro that panics if the Goldbach Conjecture is false.
Start with Python or Go. Really. As a first language, both are wonderful to learn programming. They are friction-free, and you will quickly get code that runs without much frustration. &amp;#x200B; With C, you are going to spend more time fighting bugs than writing actual code. With Rust, you will be constantly fighting the borrow checker. &amp;#x200B; These are fantastic languages, but not good languages to get started with. Learning should be fun.
Code blocks on your site extend super far off the screen to the right when on mobile.
Awesome work! I'm excited to see the FAPL/FCPL support, since that's required in order to write netCDF4-compatible HDF5 files. For my use cases, the biggest piece missing is [attributes](https://portal.hdfgroup.org/display/HDF5/Attributes). Followed by support for [dimension scales](https://portal.hdfgroup.org/display/HDF5/Dimension+Scales). Are these things on the near-term roadmap or are you open to outside contributions for these?
Why in the world would you want programmers unable to prove to others that their code is safe?
&gt; Javascript I think is a big symptom of this. Types are considered 'intrusive' or restrictive and slow down development Thankfully that seems to be changing, Typescript is pretty popular nowadays. Javascript with types.
&gt; We use CLI tools because they're coo We use cli tools because we want to have a uniform interface between your work computer and a remote server. GUI tools for git are super useful, but cannot run on a server without a windowing service, and are often too slow to run accurately on sshfs or ftp.
Attributes - definitely yes and definitely soon (in fact, the abstractions for reading/writing ndarrays are already done for both datasets/attributes, we just need to properly wrap the rest of attribute-specific H5A API, write tests etc). Dimension scales - never encountered that part of HDF5 in my own use cases, but can see that being useful. The problem is, it’s part of libhdf5_hl? Which is, technically, a different optional library, sitting on top of libhdf5, and as such it would probably require separate bindings, separate build scripts etc. I have it written down somewhere in future plans (e.g. H5DO API, packet tables and a few other useful things are also in hl), so when the time comes I’ll make sure to prioritise H5DS as well :)
Good points. I've been programming since the early 80s and it wasn't so long ago that programming was seen by its practitioners as an arcane art. Only certain trained people knew the incantations needed to make things work, and for those practitioners it was maybe in their best interest to keep things cryptic (job security). I understand the draw of arcane tools. There is something exhilarating about knowing just the right regex or awk command or makefile feature, to do exactly what you want. These tools are like little puzzles and they take time and work to figure out, and there is something appealing about using that hard-won knowledge to solve a problem. Making tools \*easy\* kind of spoils the whole game. A big thing shifting this culture is the move online, as the stakes have become so much higher for a screwup. Now a security hole that leaks customer data can erase billions of dollars of market value. We also have systems like vehicle controllers (airplanes, self-driving cars) where a bug can literally kill people. So people are starting to take security and testing seriously, and the discipline is starting to mature into an actual engineering discipline. Also I'm not sure I agree about dynamically typed languages being all bad. Empirically Python is the most productive language when I'm trying to solve something quickly, or work out the logic of an algorithm. I don't know how much of that productivity is dynamic typing vs. conveniences like list comprehensions and the lack of compilation. That said, I agree wholeheartedly that at a certain scale (or when quality is critical), compile-time checks will save your life.
It's called the turbo fish
`::&lt;&gt;` is the turbofish
31st
Yeah but C is what you use to make a public API that like that... It doesn't mean it's made in C, it can just be a wrapper.
I was mistaken actually. In your code, if `get_trade` returns `Ok(something)`, then the call to `unwrap_err` will panic. The other code uses an if-let expression, so if `get_trade` returns an `Ok`, nothing will happen. So, if the test should _always_ be giving you a Not Found error, your version does what you want. If the test should be giving you _either_ a valid value _or_ a Not Found error, you want to use an if-let expression instead of calling `unwrap_err`.
Did you even read the last sentence? Programmers don't want to use good tools well. They want to finish their workdays and bet on football.
I choose to learn how to use my seat belts. The problem is people don't give shit.
This is quite interesting. I love the proof by contradiction, btw. I do think that this generally points out that a major weakness of proc macros is that, well, they're procedural. My first though after looking at this is "I wonder if there's a way to define proc macro *input formats* in a way that allows for code completion". I'd say closest to that right now would be using darling build a proc macro, but even then you can have custom implementations for from_macro, etc. in the things darling can derive... hmm.... you'd almost want to be able to define a grammar for the proc macro. That wouldn't be very easy though, considering what you'd want to support - things like println (string interpolation), general syntax modifications tied to types (a la [rubber duck](https://crates.io/crates/rubber_duck))), etc. And yet for code completion to work I *think* you'd want to limit the input format definition to a non-turing-complete / maybe rule based specification. To be honest, although I love proc macros, I try to limit their use because my quality of life takes a hit in two big ways: * They slow down compilation (iirc they aren't cached / break incremental compilation) * They break code completion I hope we find a good clean layer to put on top of proc macros to make it easier to reason about code completion for them (and incremental compilation).
Then maybe add an feature flag to opt out of dbg? 
ALE ftw. Just discovered it and it makes life so much better :)
Sorry I'm new to vim and have a vague idea of how awesome that might be, but I'm still lost. Can you please describe how you set that up and/or what libraries to go to in order to do the same?
I was not aware that's already taken care of, so it kinda makes sense now. I guess you've already done all the high-impact work :D Thanks a lot, by the way. Portability is a bit of a sore sport for Rust and it's very nice to see it being moved forward, especially in Debian where that work lands to actual users. I guess I've got so many ideas for practical and high-impact projects that are also rather fun that it's hard for me to comprehend doing something just for the fun. 
The NASA example is really hard to apply to anything not-NASA, because their procedures predate those 10 rules and basically make it really hard to have a single person make an error. Change is managed and guarded to an absurd degree, one that would probably never fly (hehe) in a commercial setting.
It was discussed, and there’s an idiom lint for it you can turn on. It may be turned on by default in the future, we’ll see!
It's a bit silly, but forgive my javascript afflicted brain. So I've been getting used to borrow checker doing simple things. Currently re-doing my first job application / training exercise which counts commission in different currencies. And I've noticed, a lot of problems disappear when I use more functional approach and don't mutate any data, but just return new based on old structures. It just felt somewhat like cheating? I don't know. Is this accepted way of doing things or somehow it gonna come back to bite my ass in terms of performance, some later stuff I'm not yet aware of?
https://github.com/rust-lang/rust.vim
There is a cost to using "safe" languages. In many cases that cost is well worth paying. I'm firmly on the "static typing is better" side as I think the cost of paying for static types (in terms of slower development time, etc). is *swamped* by the benefits (to code safety and clarity). OTOH, I'm fairly sure I'm not interested in moving to a dependently typed language like Agda or ATS because I'm not sure the incremental benefits the languages provide over other languages is worth the cost of getting a second brain stapled to my current one so that I'm smart enough to use it. There are plenty of things in rust that it's just a plain pain-in-the-ass to do. I'm sure we've all read ["Too Many Linked Lists"](https://cglab.ca/~abeinges/blah/too-many-lists/book/) by now, but if you haven't, give it a read. There are some things that are very easy to do in other languages (both high and low level) that Rust makes painful. There's a reason for the pain, but the pain is there. The trick is finding a language that provides goodies that you think are important (and not everyone agrees on what these are) with pain that you find manageable (and we all have different pain thresholds). Rust, with my noodling around so far, seems to hit the sweet spot. It does all the Awesome Stuff that I think a language should do, and getting it to work is only Mildly Annoying.
The [issue](https://github.com/SergioBenitez/Rocket/issues/19) that tracks compiling Rocket with stable Rust is not associated with the `0.5` milestone yet. I am not sure if it is going to happen soon. I looked at the dependent issues with the Rust language, it looks like they are actively being worked on but still will not be closed soon enough. In the worst case this may not come in 2019 IMO.
Neat. As others have said, my primary issue is the "easy" path - I rarely write lots of code in blocks, but when I do, I'm likely also referencing the labels later, and that being broken can be really painful.
Thanks :)
Especially not [Mel](http://www.catb.org/jargon/html/story-of-mel.html)
I believe I've seen an implementation of a "builder" do this sort of thing, although I think it took "self" by move and produced a different type. Which my gut says would be more Rust-y. Also see: "session types." There's also the "passkey" pattern. The descriptions I haven't seen aren't concise/aren't Rust so I won't link them. ``` mod options { pub struct NumCoresWrite(()); pub fn request_set_num_cores() -&gt; SetNumCores { // Obviously, there's no point if you allow people to freely construct SetNumCores; this is just an example. SetNumCores(()) } #[derive(Default)] pub struct Options { num_cores: u32, } impl Options { pub fn set_num_cores(&amp;mut self, num_cores: u32, _: SetNumCores) { self.num_cores = num_cores; } } } fn test() { let mut opt = options::Options::default(); opt.set_num_cores(32, options::request_set_num_cores()); } ``` Essentially, you choose when/how to produce a SetNumCores object that will control if/when someone can call set_num_cores (note that SetNumCores isn't constructible outside the options module). And they can only call it once (if that's useful, you could make SetNumCores Copy if not).
Thanks, this worked.
It really annoys me when people bash C or call for “better C programmers” both of these arguments are dumb. You can code in C with the correct tools to help ensure safety. Valgrind, clang-sanitize, static analysis and a good coding standard means you essentially have the safety of any of the C alternatives. Just use the tools that are available. You don’t need to be “better”. That said, rust as a language essentially packages all this up for you. It’s really convenient in that way.
I was thinking about the passkey pattern too, actually! That would be easier to create using a procedural macro as well, but I think it's somewhat limiting as you'd have to somehow keep a construct of these 0 sized objects around if you want to be able to set/get multiple without going through every iteration (`SetNumCoresReadMaxLoad`, `ReadNumCoresReadMaxLoad`, etc.). I think variadic types would come in handy there.
Cloning data to defeat the borrow checker *is* considered an anti-pattern since it can be detrimental to performance; however, it'd be helpful to see some examples of what you're talking about. Perhaps we can help you learn to work *with* the borrow checker instead of around it.
C is weakly typed, and thus won't complain about passing invalid pointers to functions. Type signatures really don't matter all that much to a C compiler. You really have to know exactly what you're doing if you want to succeed, and how to do it in a way that's correct. If the program crashes, which it will, it will simply exit without telling you why, unless you know how to set up and get stack traces. When a Rust program panics, it at least gives you a nice stack trace that points out which line caused the panic. Also, unless you plan on having a miserable time figuring out basic primitives, you should use the glib family of libraries for all your C type needs. It makes working with C a lot easier than without it, and provides primitives which will actually work in a cross-platform way.
For your use-case, it sounds like you could just use the [`[T]::windows()`](https://doc.rust-lang.org/stable/std/primitive.slice.html#method.windows) iterator. As for your implementation, just glancing at it I see `Box&lt;Iterator&lt;...&gt;&gt;` in your `Buffer` type which is probably leaving some performance on the table due to the dynamic dispatch. Your `Index` implementation is probably getting bounds-checked every time as well, and you're copying elements one-by-one into the buffer which is probably preventing vectorization.
Yeah, in contrast, as someone who's still little scared to to write C or C++ (I've never learnt them), my first production Rust program had 5 bugs that were found during the initial couple of weeks of testing (4 of which were logic errors in the same if-statement), and has run flawlessly without downtime for 6 months since.
Btw, I was your GSoC mentor, remember? :)
I'm considering using `euc` for a project, and I have an opinionated suggestion: Simplify `Pipeline` by removing `Uniform` as a separate type, and tell the user to store uniform data in fields of `Self`. This would eliminate the need for the `PhantomData` in your example pipelines where the uniforms include a reference to a vertex slice. You could also then modify methods of `Pipeline` to take `&amp;self`, though that wouldn't be so user-visible. As a separate suggestion, `Pipeline` could have additional methods (perhaps with default implementations) defining how depth tests and fragment blending are performed.
Rust is great, and you should totally try it, but you may want to look at Zig. If Rust is like a modern C++, then Zig trying to be a modern C.
&gt;'m sure as fuck not going to recommend C++ why?
Have a look at the itertools crate as well as the windows method on slices. Both could help with what you’re doing. 
 I dislike how there are apparently dozens of 'blessed' dialects for it and how it combines the power of shooting yourself in the foot of OO with C. To be fair, i heavily avoided since i could comprehend what it was 2 decades ago; the pervalence of C++ in the industry is more or less what convinced me not to be in the industry.
&gt; char *mystring = "wanadie"; This keeps me alive.
yeah, tsan actually catches virtually all data races as long as you can provoke them in tests or whatever. the worst real world threading bug I had starting out was a mutex deadlock... which rust doesn't really help with
Yeah, we have a number of unicode related things that need to be fixed. We also have a couple of very sensitive string outputs that use formatting specific to the old print and are using a number of deprecated APIs that were not carried over to Python 3. We've tried some automated solutions, but they didn't really work well. 14ish years of Python is slow to migrate.
That's a good point, but are there languages like that? I suppose Cython (not to be confused with CPython) would fit it, but I don't think anyone uses it as a primary language.
It [actually _is_ hosted](https://docs.rs/crate/project_1_itcs_6156/0.1.3) on docs.rs but apparently the documentation of binaries is located under a different route, namely `docs.rs/crate/` rather than just `docs.rs/`. Got there from the crates.io page following the link `Documentation`.
 &gt;The git UI is all over the place, but it doesn't matter because its fundamental model is so damn simple you can fuck up all you want and still figure out how to get to a state which makes sense. rm -rf $REPO; git clone git@github.com:.... 
You're taking that sentence out of context: &amp;#x200B; &gt;This edition of the book drops the design of imperative programs. The old chapters remain available on-line. An adaptation of this material will appear in the second volume of this series, *How to Design Components.* &amp;#x200B; If you get through all of the 2nd edition and want more, the chapters on mutable state are still available: &amp;#x200B; [https://htdp.org/2003-09-26/Book/curriculum-Z-H-1.html#node\_toc\_node\_part\_VII](https://htdp.org/2003-09-26/Book/curriculum-Z-H-1.html#node_toc_node_part_VII) &amp;#x200B; Both editions are better at teaching how to actually solve problems using programming than anything else I've seen in 30 years. This has nothing to do with functional vs imperative or static vs dynamic religious wars, and more to do with how long Matthias &amp; co have been working on it.
This proves that no solution is able to provide completion inside all macros, but I'm not convinced that means code completion is a fool's errand in _any_ macro. For example, the meta-items in `serde` attributes are well-defined enough that I think it'd be possible to generate some sort of completions for them.
If you want to build something visual like an application, or a game, then I'd recommend JavaScript. You'll get things done quickly and the ecosystem is huge. If you want to build something numerical then I'd recommend Python. There are niche languages which are popular in specific instances, but Python is a good catch all for numerical problems. If you want to get into systems type stuff, triple-A games programming, and similar, then you should consider C, C++, or Rust. That said Rust is a lovely language. There are many places people don't use C or C++, but do use Rust. Like web servers.
Thank you!. That's what I wanted to know! Now I'll investigate about dynamic dispatch and vectorization. I think that I can't use `[T]::windows()` because it's only available on slices/Vec but not on Iterators. I want to chain `buf_map()`s: let result: Vec&lt;f32&gt; = (1..) .map(|x| x as f32) .buf_map(1, |buf| { buf[0] * 2. }) .buf_map(3, |buf| { (buf[0] + buf[1] + buf[2]) / 3. }) .buf_map(3, |buf| { (buf[-1] + buf[-2] + buf[-3]) / 3. }) .take(100).collect(); I don't know if there is a way of using `windows()` on Iterators. 
Sure. But the kernel \*is\* basically entirely C. 
This is actually work.i'd really love to see. What happens if we rebuild a UI from scratch in a Rusty fashion. I think there's a lot of momentum in that area and I'm hoping we'll start to have something usable that's allrust and crossplatform by the EOY. Working with GNOME has been interesting and effective, but it's both painful to code with and also painful to distribute because it requires dynamic linking. 
Thank you! Looks useful. I want something like [`tuple_windows()`](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.tuple_windows) but looks like it only works with tuples up to length 4. I need really large lengths (about 1000). If there is a way to use `windows()` on Iterators I'd be really happy.
The reason Windows is only offered on slices is because it just gives you pointers straight into existing memory (cheaper than building a bunch of buffers in a row). I think you’d be better off collecting into a temporary vector and calling windows than trying to do magical buffering. 
I mean, that's just speculation, but sure.
The WinNT kernel may not be open source but it’s not like the programming language used is some kind of a military secret. It’s pretty well known.
Against popular opinion but I do not recommend python as a starter language. It is great once you have one language down though as you can kind of force the paradigm you are familiar with onto the language. My gripes: * It lacks visual cues for variables (It is easier to understand the type of a variable when type information is associated with it) * You can pick up bad habits from its scoping (variable initialised in branch can be used outside) * stackoverflow posts about this matter can look like incantations (list-comprehensions is a good example) * Certain functionality you need to unearth quite a bit to figure out what it is implicitly calling (iter call in for loops, str() calling \_\_str\_\_, \_\_exit\_\_ with context handlers using with). * I personally find idiomatic python to be against "Zen of Python" (Simple is better than complex, Beautiful is better than ugly) It's a great language, don't get me wrong but I am very hesitant to recommend it to beginners. But I definitely agree that the C# and Java route are good choices. C is also good choice to learn as well as it is a fairly simple language in comparison to most that are out there, it just requires you to do most of the work but hey that can give insight into what is going on behind the scenes with a lot of things. I'd say go with C, most of what you learn from C can transfer to Rust imo.
Yes but all it shows is the README.md. I was expecting the entire documentation generated by `cargo doc`.
Wrong sub bud. /r/rustgame This sub is for the Rust Programming Language!
Oh shit lol
One thing I'd like to really stress is that the Rust compiler does *not* teach you best practices. You can write plenty of bad code in Rust which passes the compiler. The Rust compiler points out bugs and potential bugs. That's all. It does not teach how to write well written software. I'd also recommend *don't* worry about writing good software. Just worry about writing stuff and learning. That's it. You can care about good software later. Out of C vs Rust I'd recommend C. As a compromise you could also use C for a month or two and then switch to Rust. C has a lot of basics which overlap with Rust. Like if statements, while loops, functions, how to use numbers and do maths, the different types of numbers, variables, structs, and so on. C is a very simple language and most of this overlaps with Rust. As a result you'll have less problems getting your programs to compile, and you'll still be learning things that are relevant. Your programs will have bugs. If you are only writing stuff for yourself then that's fine. That said Rust is a fucking awesome language.
The problem is that if I `collect()` the process will not be "on-line". The program will decode images line by line from samples received from an antenna, I want to decode the images at the same time the samples arrive at my computer. Right now `buf_map()` looks like 3X slower than looping Vecs. The image transmission speed is quite slow, so I don't really need to optimize my program to keep up, but I want to do it anyway to learn a bit.
Even if the rewrite goes perfectly you'll suffer functionality getting lost and missed.
Hence mypy.
GC-less programming in C# is doable. It has stack only structs, APIs for pointers and heap allocation, and unsafe code for making that easier. Outside of specific instances however it's still going to be painful. In the past Microsoft has done *a lot* of research on getting managed languages to near native performance. In regards to C# Microsoft built a language called Sing#, an extension to C# (via a different language Spec#), which in turn they used to build an OS called Singularity. It was a very interesting project. Microsoft went on to try to build a production ready OS using the ideas called Midori.
You have it right. The thing is that when you start dynamic, add types help a lot, but you can live fine with just a static types. I fell the pain more, because my life is around RDBMS and build on the fly stuff. If I could have just a fixed schema my code base on static langs will be fine enough. &amp;#x200B; I think this validate the idea: Very few langs (the only mainstream I know is C# with this expando object) add dynamic types as something explicit, yet the opposite happens much more.
You want tests anyway, but if you can skip half of all tests because the compiler is already proving you're using the right types... Imo it's a clear win
This look this could help me in solve a similar problem (how make a streaming iterator) for my relational engine. I will take a look later to see if it help. &amp;#x200B; I'm triying to emulate this, that could interest you: &amp;#x200B; [https://www.cs.purdue.edu/homes/rompf/papers/tahboub-sigmod18.pdf](https://www.cs.purdue.edu/homes/rompf/papers/tahboub-sigmod18.pdf) &amp;#x200B; In special the promise of easy implementation of query operations and still be performance. &amp;#x200B; \--- &amp;#x200B; From your code, I change the VecDeque with a vector instead. Probably try to uncool a little and apply the map alike: for chunck in chuncks: map(chunck, fn) this probably could mix well with windows and similar stuff.
Are you accessing this "Bradley" through an `Rc` pointer or similar? If so, you might have accidentally introduced a cycle of strong pointers, in which case "Bradley" will live forever.
What if you did something like `take_map` instead? Where `buf_map`'s callback is handed a wrapped VecDequeue, `take_map`'s callback gets an Iterator, which iterates over the first n elements of the source iterator, then stops. You'd save copying all those elements into a new buffer, and you can still sum things. If you end up needing to buffer anyway, you just .collect the iterator in your callback, which shouldn't cost you anything extra. And like map, the callback's return value is the value that the TakeMap.next method returns.
I've got a few silly questions - I'll ask them one at a time.. if I have a struct struct Foo { x : u32, y : u32, ... a few more members of u32 z : String, } Is it possible to derive PartialEq such that it checks all the elements except the z (String)? If I have to manually implement the trait, what's the idiomatic way of doing this?
Ah, I see! Sorry, I was on my mobile which obscured my vision. After reading through The Cargo Book and a rust-nursery page, I could not find any clue on how to solve that. However, there is [this GitHub issue](https://github.com/rust-lang/cargo/issues/1865) and on it a comment that suggests the flag `--document-private-items` but not sure if this helps at all because how'd you tell `cargo publish` to use that flag for generating the docs for crates.io? There is [a reddit comment](https://www.reddit.com/r/rust/comments/7wb3uo/should_you_publish_clis_to_cratesio/dtzvvoh) proposing splitting your crate into a lib and a bin. Maybe this way (plus document private items) you'd be able to get to see the definitions of your now-hybrid-library-binary crate.
It's obvious that the input token stream of a macro doesn't have to be rust. Also imagine non deterministic output or non-halting macros. Knowing that, I would argue that it is possible to estimate the input tokens relationship to the output tokens by executing the macro in a limited sandbox, by using preset patterns or by using statistical analysis to "guess" possible meanings.
Why does the sub trait define fn sub which doesn't take &amp;self but when implementing PartialEq, it takes a borrow? 
It's kind of the same situation as auto completion of code that appears within strings.
Writing my first Rust program. It finds all solutions to a geometric puzzle and displays solutions using gtk-rs. That part was easy. Now I'm exploring ways to assign colors to the pieces such that interesting patterns can be created in addition to just fitting the pieces together. This also significantly reduces the number of "correct" solutions. The whole thing is a nice introduction to a few important Rust concepts. I intended to just put up a window showing results, but now I'm thinking about adding GUI features. Adding scroll bars to the cairo drawing area would help (I can't show all solutions at once) and so would a panel with a list of selectable items. Those are also things I'll want to have in some future programs that will probably be written in Rust. &amp;#x200B; This is a throw-away app but it's allowing me to see what I'm going to need to figure out before doing something more significant with it. Rust is going to force me to use a more well defined data model than in previous GUI apps I've written, and that may be a good thing.
There are also the [sanitizers](https://github.com/google/sanitizers), which are super helpful for catching runtime errors!
I have found address sanitiser (ASAN) to be very helpful for students as it forces them to debug issues with their code and starts exposing them to a passive debugger. Output can be intimidating but compile with debug symbols and you get line numbers that point to where your problem is.
You could also start with Rust, let it deal with memory safety for you, and then as one learns more, "take the roof off" and teach how to write unsafe code. Maybe re-implement things libstd gives you yourself like Vec. Unsafe Rust should teach you almost everything that C teaches.
You can enable some compiler lints to ensure that `dyn` appears everywhere it should.
For Copy types (primitive integers and #[derive(Copy)] structs composed of copy types), taking a borrow or not is roughly equivalent. The difference is prominent for non-Copy types, though. A method that doesn't take a borrow consumes the argument, so it cannot be used separately anymore. It's rarely useful to compare two things for equality and then never be able to use either of them again, but that _can_ be useful for subtraction. The main use case I know of is heap allocated numbers, like the `num-bigint` crate. By consuming `a` in `a - b`, a's heap allocation can be reused for the result and the subtraction can modify in place. Since the original argument is consumed, `a` is then no longer usable and there's no risk of anyone observing that it's changed. This allows working with big numbers to be much faster than if we had to always create new allocations on every operation, while still retaining safety. But even for big numbers, borrowing when comparing equality is fine. PartialEq has no result other than a boolean, so the reasoning is that it will never be useful to consume either side. Since its never useful, it just takes borrowed arguments for the sake of ergonomics.
It's useful even without unsafe, when you want to both: - A) change what v points to within the method AND - B) change the value at the location v points to Here's a silly example using this: /// transforms [1, 2, 3, 4, 5] into [1, 3, 6, 10, 15] in place. fn sum(mut v: &amp;mut [u32]) { let mut sum_so_far = 0; while !v.is_empty() { sum_so_far += v[0]; // modify value at v (uses the mut in &amp;mut) v[0] = sum_so_far; // modify what v points to (uses the mut in mut v) v = &amp;mut v[1..]; } } ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=dee65ddaa893eff592727c96aea2e121)) This is silly because it could be done more easily using a `for` loop, but it should demonstrate what `mut v: &amp;mut` allows you to do?
The basic way that languages provide things like memory safety or thread safety out of the box is by effectively telling the developer that they're not allowed to do the thing that is not safe. Sometimes though, you want, or need to go the thing that's unsafe. 
It would, but it's only worth it if you expect borrowed strings to be used often. Otherwise it just adds overhead of having "is this a borrowed string" stored at runtime. It's a common pattern to see this kind of thing in configuration with values that could be known at compile time: struct Config { value: Cow&lt;'static, str&gt;, } impl Config { fn new&lt;T: Into&lt;Cow&lt;'static, str&gt;&gt;&gt;(value: T) -&gt; Self { Config { value: value.into() } } }
Thanks for the explanation. Seems like extra complications for beginner rusters.
If I might ask, how so? I've never had need to call the methods manually, and `-` and `==` operators automatically do the right thing. Is there a particular case you're thinking of where knowing the internals of this is necessary? It does make implementing `Sub` significantly more complicated, but it shouldn't have much affect for anyone just using the subtraction or equality operators.
I meant I'd have thought that in most places borrow would have been better. For eg, if I have huge structs, (representing some metric aggregates), and I need to compare after - before, IIUC, sounds like I need to make the struct Copyable which might be unnecessary when instead I could have just done the subtraction with already existing borrows in a function. (maybe I'm not expressing myself correctly - it's all still very new to me). Ultimately what I'm trying to do is have two huge JSON files (one representing metrics after and one before) - and I'm using Serde to deserialize to structs and ultimately in one method I'd like to subtract and print some representation of the diff.
Unlike leaks, it seems approximately coherent/defensible for Rust to define reading freed bytes as undefined behaviour/memory unsafety, meaning `unsafe` covers this. But I'm also unsure of how to formalize it (bulk read operations would need to know about struct padding?).
To be fair it's usually just the same four or five trolls, hardly representative of the entire sub.
Are you saying that you are new to programming and have decided to learn either C or Rust as your first language? I think that would be a mistake. Do you need this language to land you a job, or is the main point of this exercise to learn how to program? TL;DR: Don't think about job opportunities when choosing your first language. Assuming that you are new to programming and are interested in learning to program well, and can worry later about which language will get you a job, then a simple but powerful language with no static type system would be a good first choice. Something that is very straightforward syntactically but supports functional programming constructs like closures and persistent data structures very naturally. Clojure (and its browser equivalent clojurescript) would be a good choice. Yes, you could use something like python, which is very popular, but by comparison clojure is much cleaner and encourages you to code better. Yes, you can do functional programming in python, but it's not as natural, and you will constantly be tempted to hack out some iterative thing, because that is very natural in python. IMHO learning to code using clojure will make you a better developer, even if you don't end up coding in clojure later. Once you have gotten the hang of coding and developed skills for decomposing a problem, testing your code, debugging, and so on, then you can think about what kind of job you want and what language would be best for it. And when you get to that point, don't make the mistake of choosing the language that is most "popular" by some metric, or for which there are the most job openings. If having the most openings were really what makes for a fantastic job, then you should wait tables or be a truck driver. In truth what you are looking for is a language for which you expect the supply of developers to be low relative to demand. That's why, for example, Scala programmers get paid more than Javascript developers. For various reasons I think it is likely that Rust will gain traction during 2019 and begin (!) to displace C and C++ for greenfield projects. I think it is likely that Rust developers will be well positioned in 2020. But don't choose Rust as your first language -- choose a language that will help you learn, and save Rust for later.
I think you can make a `[docs.rs]` section in your `Cargo.toml`. I'll check it out later, thanks.
Good thing I'm a Complex programmer.
No, there's no way to do that without some external macro library. If you wanted to do it manually, you could take all the fields you want to auto-derive and put it in a smaller structure and implement PartialEq by checking that one. The slightly dodgier way is to take the one you want to ignore, wrap it in a newtype and implement PartialEq for it where it just returns true.
So, I've been developing rust-pushrod for about the past month or so, and I've heard people who like and dislike Piston. I've looked around, found glfw, and glutin for Rust, but I'm not sure which would be the better, more rounded library to use. Piston is a bit CPU-intensive, and I don't need anything that requires active screen refresh 60 times a second. I only need something that refreshes when a screen becomes invalidated, so more on a polling basis than anything else. Can someone recommend a better library to use, or one that is more mature, or perhaps, more oriented toward GUI design rather than gaming?
I've talked with Matthias about this stuff (long long ago) and have a pretty good idea of what they're doing. I have a great respect for him as both a computer scientist and a CS educator. I've used DrScheme and DrRacket a tiny bit, and followed the progress of the work casually. That said, I find that I just can't make the leap of putting off dealing with mutable state to optional chapters or a second volume of an introductory program text. Mutable state is an important part of the current computing environment for students to learn about, and I prefer the old DrScheme approach where teaching seems to have been more integrated into their curriculum. (I'm afraid I'm not a big believer in special "teaching languages" either: one of the attractions of DrScheme for me was that it walked the line between being a teaching tool and a semi-real-world programming language. The move away from Scheme by both the Felleisen Gang and MIT was not too surprising — I've tried intro teaching using Scheme — but I assumed it was for a more conventional approach rather than a less conventional one.) Anyhow…I agree that the general student problem-solving tools and techniques I've seen from these people are very good. I know they have lots of real-world data and experience to back their approach up. All I was trying to say with my admittedly over-snarky comment above is that I was about to read the new edition of this book, but that sentence caught me by surprise. It seems to indicate a new direction that I wasn't expecting and am not really understanding. Thanks much for your detailed comments. I've sat on both sides in the religious wars you mention, and like you I don't want to bring them into new-student-land. I just want my students to be exposed early to the full range of computing techniques, even if unevenly. Oh heck, I'm probably just cranky because I'm teaching the second 10-week programming course in our curriculum right now: systems programming in C. I wish I was joking (and so do the students).
*precise* completion is impossible in general, because you can’t distinguish good macros from bad macros. Heuristics based completion which almost always works should be doable.
The fundamental problem is that each macro is its own language, which *compiles* to rust. To provide IDE features you need to understand the source language, and this breaks almost any imaginable feature in the worst case. The common case with Rust is not too bad, but the tricky bit is distinguishing the common case from the bad case. Normally, macros set up spans correctly, and that should allow goto defenition and highlighting to work reliably. But you could imagine a variation of caesar which mangled spans! Another good bit is macro by example with $expr matchers: there, you could be sure at least about the syntax! Note that it’s not enough to guarantee that code completion works: caesar could have accepted $expr. Off the top of my head, two possible restrictions come to mind which could allow for 100 correct IDE inside macro: * an $expr matcher for lambdas which returns a closure resolved at the call site. This guarantees that semantics matches as well as the syntax. It is also quite close to how Kotlin’s inline functions work, which can be thought of as a restricted form of macros. * A strictly decorator based form of attribute macros, which can’t change the source item, but can produce other items. 
limiting *input* grammar is not sufficient unfortunately. Consider a slight modification of caesar which accepts $expr:expr and does not transform keywords. For it, the input format is very well defined, but the transformation semantics is still arbitrary enough to break anything.
Are you decoding NOAA APT or SSTV by any chance? :)
Ah - that makes sense! Sorry, I'd forgotten to say this part - the other advantage of using `self` arguments in a generic trait like this is that it completely leaves open the possibility of using borrows. You'd just need to implement `Sub` for `&amp;Type` rather than `Type`, like so: Sorry, I missed that part of it. It's definitely still possible to use borrows with `Sub`, you just need to implement the operations for `&amp;YourType` rather than `YourType`. Like this code from `bigint`: impl&lt;'a, 'b&gt; Sub&lt;&amp;'b BigInt&gt; for &amp;'a BigInt { type Output = BigInt; #[inline] fn sub(self, other: &amp;BigInt) -&gt; BigInt { bigint_sub!( self, self.clone(), &amp;self.data, other, other.clone(), &amp;other.data ) } } There's a disadvantage using it in that you need to explicitly say `&amp;a - &amp;b`, but besides that it works fine. This way it's explicit whether the subtraction borrows or moves its arguments. ----- If you're using subtraction to create a difference of non-integer data, I'd probably recommend just using a method anyways for clarity. It's pretty standard in rust to only use the binary operations for things that operate on numbers. But that's just for clarity - it should be possible to use `-` and sub if you want to.
Interesting, thanks so much for the summary!
No need to make your `HugeStruct`s `Copy`able, just implement `Sub` for (shared) references to `HugeStruct`. _They_ are copyable. impl Sub for &amp;'_ HugeStruct { type Output = HugeStruct; fn sub(self, other: Self) -&gt; Self::Output { HugeStruct { field: operation(self.field, other.field) } } } Then, you can use it on references: &amp;HugeStruct { … } - &amp;HugeStruct { … }
Can you use a `Vec` instead of a `VecDeque` and store a position inside it? Like in a ring buffer.
I don't think hiding the issues is a good approach. You in essence fight a borrow checker with C too, it just never tells you that you've failed until your program breaks at runtime. The borrow checker complaining at you is a reason to go and understand what is going wrong, not to go and code the same errors in a language that doesn't complain. Of course, sometimes the borrow checker is wrong, but when you can tell the difference, you will have mastered those fundamentals you mention.
Thanks
To my parents i always say programming right now is at a stage that we know that a minimal house has a foundation, four walls and a roof. Something construction sector has known for millenniums. Just too emphasized how young our trade is.
&gt;Valgrind, clang-sanitize, static analysis and a good coding standard means you essentially have the safety of any of the C alternatives. If this is the case, how come there are security holes, such as buffer overflows being found in widely used software such as OpenSSL years after they were introduced? Do they just omit using analysis tools or not practice good coding standards?
Yes actually. Almost every C project I’ve worked in professionally (some pretty big ones), has had terrible “best practices”.
Someone who goes straight into Rust without an understanding of programmatic memory won't understand *why* what the borrow checker says is wrong is wrong. His program won't compile, so he'll tweak it till it does, and not gain any particular understanding from the process. If you learn C first, where memory isn't abstracted by higher level concepts like borrowing and references, the underlying problem is naked to the eye.
Runtime lockdep analysis can find those issues fairly quickly.
Thank you. I'll try the \`grep\` crate and if it's not working then maybe I'll try a more manual approach with \`regex-bytes\` and \`memmap\` :)
Thank you. I'll make some tries ;)
Yes, this works out of the box with `derive(Deserialize)`.
Do you honestly believe Microsoft doesn't follow these standard practices?
Yes. I worked there for 5 years.
For some reason I thought I saw the turbo fish 
I'm not familiar with this, can you elaborate? is there some advantage for rust over c++ here? tsan finds lock order inversions easily in c++
 let font = unsafe { core::ptr::read(FONT.as_ptr() as *const PSFFont) }; Not outstandingly complex, but it gives you this icky feeling of using the unsafe block in rust, and more than that, it’s very syntactically noisy. Here’s how to do it in zig: const font = @ptrCast(*const PSFFont, &amp;fontEmbed); Much less noisy, and it produces the exact same, correctly parsed, PSF font. I don't know about his code, but casting pointer like that seems quite unsafe though.