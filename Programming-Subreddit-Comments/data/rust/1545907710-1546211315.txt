This `at` method is identical to `std::ops::Index::index`, so it could be replaced: trait Diffable: Index { fn len(&amp;self) -&gt; usize; }
Someone's gonna have a lot of fun with all these "Updated cargo.toml" commits one day
Thank you for asking this question. I am in a very similar situation. This is a big gap right now in documentation and the community, and probably because a best practice has not been fully settled upon.
I use it for my experimental page cache in my webapp. It is then made safe by using mutexes (spinlocks) in some places
&gt; For an algorithm to tell you where the unsafety "ends" it has to actually understand its effects Isn't that in itself impossible? If I'm allowed to jump all restrictions in unsafe code then I'd be allowed to write loops and conditionals. Properly understanding the effect that any arbitrary code has and what paths it takes over any arbitrary input is impossible as proved by the halting problem.
This a great response and I would highly recommend not letting internal dependencies' types leak into your API, especially if you are building a library. 
I do not agree about putting any limits on any particular direction. That won't solve anything. After all, how many possibilities do you have remaining when you put a limit on an infinite possibility space? But the main point looks solid: we want to keep the language itself consistent and agreed upon. That's where the brakes should be: "locked" by a mutably shared language state. This naturally means that not all the things can be done at once.
I've also taken this approach. The main downside is that sometimes you need to be able to have \`PartialEq\` and \`Eq\` on your \`Error\` due to \`assert\_eq\` comparison in unit tests, and often it is the case the libraries don't derive \`Eq\` and \`PartialEq\` on their \`Error\` types.
I'm curious about your code. This should not be needed. Code examples? I'm pretty sure the same functionality can be achieved by restructuring your code.
Great job, but I probably continue to use perl for this kind of tasks: perl -nle '/foo (\w+) bar/ &amp;&amp; print "this is $1"' # find, modify and print (only if there's match) perl -ple 's/foo (\w+) bar/this is $1/g' # replace and print (even if there's no match) perl -pe 's/\n$/,/' # replace end line with comma perl -pi -we 's/foo/bar/g' * # replace in files inpalce and so on
Any time we see an API that does something magical, it is usually backed by a hidden and shared internal container. Take a `std::mpsc::channel`: it has transmission and receiving ends, that "somehow" know how to send things to each other. Internally though, they share a pointer to the same memory location to communicate. The advantage of that is that we don't need to think about this shared container when we use the `channel`. But let's consider what it would look like if we did! When creating the channel, we would also have this previously hidden `Channel` container as an explicit thing in our code: let mut channel = std::mpsc::Channel::new(); let (tx, rx) = (channel.take_tx(), channel.take_rx().unwrap()); // only one rx The `tx` and `rx` are simply the handles that identify transmission or receiving ends. We can use them to send the data as before, however we now always need a mutable reference to the `Channel` container: tx.send(&amp;mut channel, 42).unwrap(); let value = rx.receive(&amp;mut channel).unwrap(); This lets us do everything that was possible before, but is less convenient, potentially less performant and more error-prone. It is less convenient because it requires us to keep the `channel` object around and take care of making it visible at every place where we want to send or receive the data. It is potentially slower, because we would need to make `channel` visible to multiple threads ourselves, while internally shared structure can be optimized for this use case. It is more error prone because type system does not prevent using a wrong `tx` end with a wrong `channel`. Interior mutability makes this way more ergonomic at the cost of more implementation boilerplate, and possibly unsafe implementation if the utmost performance is desired. However, the channel with interior mutability can also be done with no unsafe code, with the help of `Arc` and `Mutex`. Now that we know this, we can reverse the process and make our own magical APIs :)
async/await is waiting on Pin to be stabilized first AFAIK, so great news \^\^
So, they won't have an interest in Rust nor Tantivvy, so why not go even deeper and speak about internals! :) This gave me a laugh. Good luck. 
I think 1 and 2 have been answer very well already, so let me reply to 3. I think the most reasonable approach would be just using `std`'s `Error` type and creating error enums. However, that brings some boilerplate with it. For that, I recommend [`err-derive`](https://www.reddit.com/r/rust/comments/a9z3m7/announcing_errderive_yet_another_error_handling/) (disclaimer: I'm the author ;))
I find that a rather vague hand-wavy argument. 'Not go outside' is a significant limitation when deciding what to do tomorrow, even if technically infinite options remain. I don't think the design space is infinite, when restricting it to options that make sense. Rust usually isn't intended to do new things that nobody has tried before, so the design space is actually limited to language features that have been tried before in other languages, which is finite.
Grats on the new crate :). Personally, I've moved away from using error derive styled crates. Especially now that the Error trait has become a bit more sane to work with. I do use the Display macro from `derive_more` though. Especially since it can be used for other things beside just errors and is super useful. Funny side note, I am also an author of an error handling crate (yade). ;) These days I don't use my error crate anymore and instead handle things more like this: ``` #[derive(Debug, Display)] #[display(fmt = "{}", kind)] pub struct MyError { pub kind: MyErrorKind, source: Option&lt;Box&lt;dyn Error + Send + Sync + 'static&gt;&gt;, } #[derive(Debug, Display)] pub enum MyErrorKind { #[display(fmt = "I couldn't do the thing")] Thing, #[display(fmt = "Failed to start server")] Startup, } // Granted, this and the next impl would be handy if wrapped up in a derive macro. impl Error for MyError { fn source(&amp;self) -&gt; Option&lt;&amp;(dyn Error + 'static)&gt; { self._source .as_ref() .map(|boxed| boxed.as_ref() as &amp;(dyn Error + 'static)) } } impl From&lt;MyErrorKind&gt; for MyError { fn from(kind: MyErrorKind) -&gt; Self { MyError { kind, _source: None, } } } // I'll often add these helpers to simplify map_err impl MyError { fn thing(err: impl StdError + Send + Sync + 'static) -&gt; Self { Error { kind: MyErrorKind::Thing, _source: Some(Box::new(err)), } } } ``` So now I can do something like... ``` return Err(MyErrorKind::Startup); ``` Or ``` // I like using .map_err over relying on an impl From&lt;T&gt; as I can provide context. This also gives me a point to match on if it's something I can recover from. a_result .map_err(MyError::thing)?; ``` The causing error will get wrapped up in a Box. Since by that point, there is very little point in trying to recover from that error... there isn't really a lot of value in keeping the type. Then for things like say... Diesel, when converting to my error type the error gets automatically taken apart and split into one of multiple error kinds. For example... NotFound, Database, etc. Global context can be included in the error struct itself, and specific context can be provided in the kinds. And then of course... you can still do your standard "spit out all of the causes as a kind of 'backtrace' of my error during error logging". ``` error!("Encountered an error: {}", err.to_string()); { let mut err: &amp;Error = &amp;err; while let Some(source) = err.source() { error!(" - Source: {}", source); err = source; } } ``` You might ask, "But what if you actually do need to downcast the cause?" Really, I think it's best to destructure the cause into your own error kinds or what have you in the first place. Remove the reliance on internal implementations for the calling code. Interesting side note... I've found that those big Error enums that wrap up all the causes cause a notable increase in compile time vs sticking the cause on the heap like above. 
I just added [20 tags](https://www.rs-pbrt.org/tags/) to the [rs-pbrt.org](https://www.rs-pbrt.org/about/) web page to make it easier (for the future) to find blog posts for a certain topic (or **tag**). Right now there are only 5 blog post entries and I might reduce the tags while I write more posts and re-organize things, but I wanted to provide tags and had to learn how to do so using [Zola](https://www.getzola.org). I also started working on [Subsurface Scattering](https://en.wikipedia.org/wiki/Subsurface_scattering) (SSS), but that's pretty early in the game and I don't expect any exciting images anytime soon. Anyway the intermediate (between releases) [documentation](https://www.janwalter.org/doc/rust/pbrt/index.html) has already some information about e.g. the [SubsurfaceMaterial](https://www.janwalter.org/doc/rust/pbrt/materials/subsurface/struct.SubsurfaceMaterial.html) and this will continue to grow ...
I’ve made a proposal along these lines in the past. More of the high concept discussion could be sorted out in Discourse before moving on to a more rigid, formalized process with a much higher bar to entry. https://internals.rust-lang.org/t/blog-post-proposal-for-a-staged-rfc-process/7766/16?u=erlend_sh
&gt; The primary benefit is shutting up people who want whatever is in the negative RFC, and the primary downside is making the people who want those things feel explicitly unwelcome. So at least in my mind, they seem more like a tool for blowing raspberries at people you disagree with than a tool for building a language. I imagine the purpose of a negative RFC wouldn't be for "blowing raspberries" and more for summarizing the arguments for and against a specific feature, as well as the decision not to implement it at a given time. Such an RFC would serve to inform the community as to why a feature won't be considered, presenting a historical perspective on the feature. As the industry and language evolves, the rationale presented by the RFC could be re-evaluated. This is particularly useful for novel functional programming features, such as effect systems and dependent types, that are interesting in their own right, but that interoperate poorly with Rust's imperative/procedural features. On the other hand, a negative RFC could summarize the arguments for and against a feature, and document the decision to 
&gt; You'd either need to play whack-a-mole with a correspondingly endless array of negative RFCs or they aren't going to make a dent This already happens with "Pre-RFC" ideas on the internals forum.
I very, very, very much agree with this. In fact I jumped a little out of joy when I read this. My initial list for negative RFCs would be: * Exceptions, or things that behave or look like exceptions. * (More) invisible type hanges and wrappings. * Non-local type inference. These are some of the things I'd rather never see in Rust. I also very much agree with the need to pause things and slow down. Especially since it's become clearer that Rust doesn't seem to have a guiding vision. And at this point noone really has the authority to come up with one. So, basically everyone can pull it in every direction if they have enough time and energy. This kind of uncertainty isn't good for long-term projects, which I hope Rust wants to become. It can be quite hard to be in the minority against some RFC. I believe it would be really helpful for all sides if things could progress a bit more careful and slowly.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [I wrote a Tetris Clone in Rust](https://www.reddit.com/r/rust_gamedev/comments/a9zgu4/i_wrote_a_tetris_clone_in_rust/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Oh, I did not know about `yade`. I personally do prefer error enums, but I do agree that big error enums with many causes are not very nice to work with. The pattern I like to work with is: * create all your "unit" error types, i.e., all errors that can be expressed using a newtype * create composed errors that only use your unit error types, so the hierarchy stays flat It is more work than using heap-allocated error causes / chaining, but I prefer it when I do want to handle specific errors. When creating an application (which just ends up printing the error), the type information is not useful and I don't bother to have a nice error API. So I think it depends on what you're creating.
Going to re-post most the content from a previous comment of mine. I tend to handle errors such as this (using the Display macro from `derive_more`) ``` #[derive(Debug, Display)] #[display(fmt = "{}", kind)] pub struct MyError { pub kind: MyErrorKind, source: Option&lt;Box&lt;dyn Error + Send + Sync + 'static&gt;&gt;, } #[derive(Debug, Display)] pub enum MyErrorKind { #[display(fmt = "I couldn't do the thing")] Thing, #[display(fmt = "Failed to start server")] Startup, } // Granted, this and the next impl would be handy if wrapped up in a // derive macro. impl Error for MyError { fn source(&amp;self) -&gt; Option&lt;&amp;(dyn Error + 'static)&gt; { self._source .as_ref() .map(|boxed| boxed.as_ref() as &amp;(dyn Error + 'static)) } } impl From&lt;MyErrorKind&gt; for MyError { fn from(kind: MyErrorKind) -&gt; Self { MyError { kind, _source: None, } } } // I'll often add these helpers to simplify map_err impl MyError { fn thing(err: impl StdError + Send + Sync + 'static) -&gt; Self { Error { kind: MyErrorKind::Thing, _source: Some(Box::new(err)), } } } ``` So now I can do something like... ``` return Err(MyErrorKind::Startup.into()); ``` Or ``` // I like using .map_err over relying on an impl From&lt;T&gt; as I can // provide context. This also gives me a point to match on if it's // something I can recover from. a_result .map_err(MyError::thing)?; ``` And then of course... you can still do your standard "spit out all of the causes as a kind of 'backtrace' of my error during error logging". ``` error!("Encountered an error: {}", err.to_string()); { let mut err: &amp;Error = &amp;err; while let Some(source) = err.source() { error!(" - Source: {}", source); err = source; } } ``` You might ask, "But what if you actually do need to downcast the cause?" Really, I think it's best to destructure the cause into your own error kinds or what have you in the first place. Remove the reliance on internal implementations for the calling code. The causing error will get wrapped up in a Box. Since by that point, there is very little point in trying to recover from that specific error... there isn't really a lot of value (imho) in keeping the type. Then for things like say... Diesel, when converting to my error type I have the error automatically get taken apart and split into a relevent kinds. For example... to differentiate between a `NotFound` and a generic unrecoverable `Database` error. Global context can be included in the error struct itself, and specific context can be provided in the kinds. Interesting side note... I've found that those big Error enums that wrap up all the causes cause a notable increase in compile time vs sticking the cause on the heap like above. 
I realized that but chose to keep the `at` method in the trait. This is because if someone wants to make some std type Diffable, they'd need to implement Index on that type which just has a bunch of unrelated consequences. If we keep the `at` method, someone could implement Diffable on String by indexing into as_bytes() and they don't need to go around adding Index to String, for example. Thoughts?
&gt; Haskell has simpler operational semantics and does not have subtyping; it seems to me simpler from a purely technical POV. I love Haskell but it's hard to bring myself to assume that the rest of your comment is given in good faith in light of that opening. Is this some rhetorical flourish about how simplicity is hard to pin down or do you really think this is a meaningful measure of complexity when initially confronted with the language?
C++ is absolutely so complex to parse because its so old. Its because C syntax was inflexible enough to require jumping through a lot of hoops (remember how you couldn't write &lt;&lt; in a C++ template spec until 2011?) to add *anything* to it, and because none of this was fundamentally designed for extensibility its always a hack. 
TBH, that looks like an AWS error to me. That sometimes happens.
I think this post makes sense in the context of "simple vs easy." Simple things can be very difficult. I think most people are arguing that Rust should be *easier*, and so the issue here is that "haskell is simple" does not mean "haskell is easy". So while this post makes sense, I think it's arguing with a strawman.
Nice! It looks like our diff algorithms are pretty different under the hood; if you combine LIS and the algorithm I implemented, you get patience diff. :)
Have you tried [`assert_matches`](https://crates.io/crates/assert_matches)? It works great.
Prefix each line of your code with 4 spaces instead of using triple-backticks if you want people on mobile or old.reddit to be able to read it sanely.
What does this mean for us out of the loop? 
Rust is now capable of writing a graphics program that says "I can't let you do that, Dave" (Jk) From the readme it states that it's an abstraction layer over gfx-rs, but still low enough level that it's mostly designed to be used by libraries. Which makes sense, graphics is really tricky and usually you want a fairly wide spectrum of abstraction so you can iterate quickly when necessary and drop down into lower and uglier libraries in the tight loops or when you need more fine-grained control.
There are a bunch of projects that want to build on top of gfx-hal and having the latter on crates.io simplifies things and also enables these projects to be on crates.io themselves. For context, gfx-hal is a vulkan-like low level graphics API which is implemented on top of several backends including metal, dx12 and vulkan. So the news mostly affects you if you want to interact (directly or indirectly) with cross-platform low-evel graphics programming in rust.
Rust is now capable of writing a graphics program that says "I can't let you do that, Dave". (jk) Messed my first comment up. The readme on GitHub is much more enlightening; this is the lowest layer in the stack of libraries and is essentially the raw wrapper code around the hardware. To my understanding, you can think of it almost as a generic graphics driver exposed as a library. [More info](https://github.com/gfx-rs/gfx/blob/master/README.md)
That is so, so much boilerplate code to accomplish something so basic as handling errors, and it will confuse/intimidate any beginner who sees it suggested as the way of doing things. Not criticizing your library by any means; you're making the best API you can with the Rust you have now. But if this is Rust's error handling story, we need to do better.
If you want error handling to be basic, then use trait objects and forget about enums, `Error` impls and `From` conversions. You can wash your hands of it if you _want_ error handling to be basic. If you are building a library and specifically want to expose the different possible error conditions to a user, then it's _not_ boiler plate to define each of those conditions and the data they carry. It seems likely that we're headed towards a world where `derive` impls would shorten these definitions a bit, but you still need to write them down somewhere if you want to expose them.
&gt; The Rust language core is also rather simple: Ownership, Borrowing, Traits, Interior Mutability, Lifetimes. I wrote what has been a stumbling block for me in my first comment - higher-order functions. Rust has three different styles of functions not just one. Another stumbling block has been the lack of inference for function signatures. In Haskell, I can delete a wrong type signature and have the compiler/REPL tell me what the right type signature should be in most cases whereas I can't do that in Rust, I can only write a possibly incorrect signature and hope for a helpful suggestion. Closure types are unlike function types, which adds another layer of complexity. Maybe you already understand all these and feel like they all stem from ownership/borrowing/lifetimes. I feel like I have a pretty good handle on lifetimes but these still seem like barriers that I need to get over. After having written several thousands of lines of Rust code, I still avoid writing my own higher-order functions and iterators if I can. &gt; It's also from the amount of stuff that you need to just know. For language extensions, you do not need to "just know" them because (a) the compiler can suggest them and you can be on your merry way after just adding them without thinking twice (e.g. like a clippy lint) and (b) core libraries, such as containers and text, work with few to no extensions just fine. You might feel that calling a language extension suggestion a lint is a very bizarre rationalization -- but it is true in many cases! For example, as a user, it is quite odd that Haskell by default doesn't support type classes with multiple parameters, so you need an extension to enable it. Hopefully, it will be on by default with Haskell 2020, along with closely related extensions like FlexibleContexts etc. &gt; I've also been trying to get into the Berlin community and found it very off-putting I'm sorry to hear that :(. &gt; In any case, I just don't agree that Haskell is a good example for a simple language I'm not sure what I said gave you that impression (maybe you're going off etareduce's comment?). I'm not claiming that Haskell is a simple language; I have not used the term "simple" and Haskell in the same sentence till now. There is a lot of room between simple and "overcomplexity" (in the blog post). --- I have more experience with Haskell and I feel that it is simpler than Rust. It seems that you have more experience with Rust and you feel that Rust is simpler. Let's agree to disagree.
Sounds cool and super useful. Thanks for the ELI21
Maybe some clarification is in order. Are you looking to see if Azul fits your use case? Are you looking for a library that provides the blueprint UI? For the latter, I can definitely say it's probably too early to find something as specific as an unreal engine blueprint UI written in Rust. As for the former, I can't quite say.
Regarding the point about documentation sustainability, are there tracking issues for this? At the moment it is the only place I can meaningfully contribute to Rust, which I've wanted for a while.
In order to track something, you have to know what to track. I'm not even sure I know what to do here, so it's unclear how to track it. At least, that's where I'm at. What kind of tracking issue would help you help us?
&gt; Oh, I did not know about yade. No worries! I did a very terrible job of promoting it. At this point it needs updating to the new API of the Error trait anyways. (Not that it would be a hard update). I'd imagine our two crates are doing exactly the same thing though for the most part. I've not yet reviewed the source of your crate yet, but I'd be inclined to just redirect people your way from Yade. Worth considering though that with Yade I put some effort into making sure my Derive worked well for both enum and Kind based Error types and etc... &gt; I personally do prefer error enums I used to use them exclusively :). On the surface they can be quite nice to work with... until they aren't :D. These days I use a lot of smaller/contextual Error types (and associated Kinds.)
Oh gosh! I can do that :)
Looks great! And I decided to proof my appreciation to you by creating an issue on GitHub ;-)
It doesn't necessarily have to be a tracking issue, just somewhere that lists what needs the documentation team has, what could need some help/cleaning up/updating etc or just general calls for actions. One of the hardest parts for contributing to a decently sized project is not knowing where to begin, especially as someone who wasn't contributed before. &gt; The cookbook isn’t done. What exactly is missing here? Is there a good way for a new contributor to see what is considered missing/not finished/wrong in the cookbook? &gt; Rust by Example still languishes. Same as above, what exactly is it that needs to be done about it? &gt; The standard library could use a lot of love. Probably the scariest point :) what kind of love? More examples? Better wording? Right now I have no idea where to start with the documentation, simply because as an outsider I have no way to know what parts of it needs some love. However, I realize that this goes both ways, it's hard for me but also hard for the docs team.
Thanks for Checking it out. You are right I checked out the older atetris and it doesn’t allow movement after a drop. Should be an easy fix.
&gt; It doesn't necessarily have to be a tracking issue, ... Gotcha, thanks. I'll try to think on this. &gt; What exactly is missing here? I am not entirely even sure! The libs team was previously owning it, and I haven't had time to check in. I think there's an issue on its repo with details? I should figure this out though. &gt; Same as above, what exactly is it that needs to be done about it? There's a *ton* of open issues with various things. It's also not had someone to really give it a coherent vision in a few years, and mostly has had things added haphazardly. There's small details, but there's also bigger questions, like "are the sections correct and in the right order?" &gt; Probably the scariest point :) what kind of love? More examples? Better wording? These ones do have issues! https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AT-doc we used to do a better job of grooming them, so older issues will tend to be more fleshed out. Thank you so much for elaborating here, it's really helpful. I'm gonna try to think about how to expose this better. Is there any place that you tried to go to figure this out on your own, and didn't find it?
Thanks! :)
I thought so. Do you happen to know the actual name of the UI element? I thought they are named flowchart but that leads me to diagrams. Maybe knowing the name makes it easier to find information related to it (as on how to do it in pure OpenGL for example).
At least in Blender, which has a similar UI for composing materials, this type of interface is referred to as a "node editor" or "node graph."
I am not well versed in UI design, but I would think that control flow diagram, dataflow chart, and relational database visualizations might get you closer.
Good to know, however I'm using [colin-kiegel/rust-pretty-assertions](https://github.com/colin-kiegel/rust-pretty-assertions) because seeing the diff on mismatch is important for me.
`error-chain` and `failure` are both unmaintained right now, it's probably best to avoid both. Rust advanced error handling is in limbo right now.
&gt; Is there any place that you tried to go to figure this out on your own, and didn't find it? I think having a good way to ask questions informally would go a long way, maybe just a room on Discord for beginning contributors to Rust. It's mostly a communication thing, at least for me.
The unrelated consequences you speak of are sometimes bad, but usually good. Typically when an abstraction is shared among the whole ecosystem it provides a benefit. The worst outcome, imo, is that a type has to be wrapped because its Index impl isn't sufficient for your API. I didn't look at exactly what you're doing so I dont know how often that will come up.
This is very great news! This refactoring is a big pivot for the design of gfx and has been in development for quite a while now. Now we just need a safe higher level abstraction over gfx-hal ;).
The documentation team (like most teams) has a room in the Discord. It's `#docs` under the `Documentation Team` category
I can't see neither the room nor the category.
Are you sure you're in the right Discord?
Your code does not compile because of type errors and non-exhaustive matches. Can you provide a playground example of the code that gives the error that you are struggling with? [Here's my attempt on playground.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=40a72fa996dfb4daf766071b10542861)
Oh, wow. No, I was on the `rust-community` server, which isn't the one linked from the homepage. My bad, I see it and a bunch of other useful rooms. Thanks for pointing that out!
Is this a limitation on a non POSIX system like Windows?
Just fixed it and pushed a new release.
It works fine when you fix those 2 issues, so my guess is that it's something to do with the error type keeping the borrow around or something else we can't see, so we need more information.
you can also add debug=0 to Cargo.toml to remove some information 
So it sounds like language design is overcrowded (as people are fatigued from reading all comments to an RFC), whereas documentation needs more people? Is there someone, perhaps in the community team, with a broader vision of how different sections/teams are staffed (overstaffed, understaffed etc) and ideally could set up, say, http://arewestaffedyet.com and track this? 
There are already some cooking. https://github.com/omni-viral/rendy one of them. It features safer API, render-graph and other useful tools without being very opinionated.
&gt; All in all, I would say that Rust the language (as opposed to idioms encoded in common libraries..) is significantly more complex than Haskell. As usual the overloading between "Haskell" as in "Haskell 98/2010" and "Haskell" as in "GHC" makes this discussion more tricky than it should be. I think it's fair to say that Haskell 2010 is a comparatively simple language by industry standards, and substantially simpler than Rust (and also than GHC, somewhat trivially). I also think it's fair to say that both GHC and Rust are, for the moment, substantially simpler than C++. Which is partly thanks to the fact that C++ itself isn't standing still! If the comparison were to *C++03*, I am actually not sure any more. It's not *remotely* evident to me that GHC is simpler than Rust. Without having done any active analysis, just as a gut feeling, they feel roughly comparable to me. I wouldn't discount the complexity and number of corner cases involved in the various Glasgow Haskell extensions. Part of the reason (though not the main one) why they haven't been standardized is precisely because of how much complexity needs to be nailed down and formalized! Even the (seemingly-and-probably-actually-)simplest ones like `MultiParamTypeClasses` or `ScopedTypeVariables` raise nontrivial questions. As far as I'm aware, your own familiarity with Haskell is also significant (e.g. I see you commenting on `ghc-proposals` occasionally), which means I'm low-level confused about why our impressions could be so different. Can you hazard a guess as to why? I don't follow GHC design discussions *as* avidly as I do Rust, but I am subscribed to ghc-proposals and have seen a few trac tickets and mailing list discussions over the years, and "golly, it's lucky all of this is so simple" is not the impression I got from them. The fact that the GHC surface language is elaborated into the much simpler Core is nice, but that just means most of the complexity is in the frontend, not that it doesn't exist. As far as that goes, Rust also gets translated into the much simpler MIR. (Epistemic status: C++, Haskell, and Rust happen to be *the* three languages I know well.)
How might this relate to using Nix? It seems like it could be a very nice complement.
I've started learning Rust on December 1st by working on Advent of Code. And, looking back, I think that's a reasonable place to start. The challenges are simple enough that you can focus on language specific obstacles yet diverse enough that you will be forced to look at many basic aspects of Rust.
Have you read the book yet? I think it's the best starting point, https://doc.rust-lang.org/stable/book/ After that, yeah, in my experience small pet projects are the best way forward. Don't try to write something *good*, but get some things working first. See if and how you can use traits, try to mess around with lifetimes, etc. 
I have to second this. It sounds stupid, but having a good Rust plug-in in IntelliJ allowed me to slowly discover Rust the language and the stdlib. It made it so much easier to start working in the language.
I'm not familiar with nix. From what I gathered, I think that you can install multiple versions of a binary using nix and then you can use alt to switch between them. alt does not support automatically finding different versions of packages installed with nix, but you can manually tell it about those versions using the `alt def ...` command.
Why do you think `failure` is unmaintained? It's in the nursery. It had a release 2 months ago. It mentions that it's in a kind of limbo right now as far as further API work, but I think it's still a good option for people working on stuff right now.
I think that for an *exact* statement, it would be too difficult indeed and only a subset would be provably exact. This leaves us with underestimating and overestimating unsafety. I hope we can all agree that in this case erring on overestimating the unsafe area is better, rather than gaining false confidence. So, how do we give an approximate, possibly overestimated but not underestimated, view of the unsafe parts? Taking the example of `Vec::set_len`: - It's an `unsafe` mutable method, so we conclude that it modifies the `Vec` instance in a way that violates the invariants that make it safe. - By peeking inside, we see that it modifies the `length` field. - Therefore, once `set_len` has been called, any method of `Vec` which reads/writes the `length` field is potentially unsafe to use. That's the gist. Make the "taint" end when exiting a safe method, supposing that the author of the method got its contract right, and you have a conservative analysis of unsafety within a method. The more clever it gets, the more selective, but as a first approximation that may not be too bad.
Using [byteorder](https://github.com/BurntSushi/byteorder) is exactly what I did for an implementation of the [Whisper database](https://graphite.readthedocs.io/en/latest/whisper.html#database-format) (used by Graphite metrics). Reading of files uses Nom and writing uses Byteorder. https://github.com/tshlabs/memento/blob/master/core/src/encoder.rs
withoutboats was working on a new version but was too busy so they stopped working on the project. Since then there's been no driving force behind the project. mitsuhiko got write access to the repo and merged a few fixes but hasn't started leading it and making technical decisions on the project. So it's essentially orphaned at the moment.
You can just do let x = &amp;mut Type::new(); no need to initially bind it.
&gt; One variant will correspond to Tera errors and contain a `tera::Error` But by doing that, won't I be leaking the `tera::Error` to consumers of the `Result`? (See also answers from /r/SimonSapin and /r/Elession ). By making one enum option carry the `tera::Error`, the `tera::Error` is one Enum away, but it's still leaking. No?
Unsure. All the software I write works on POSIX systems, so I personally wouldn't take advantage of async Windows-only filesystem APIs even if they do exist. YMMV.
I agree with this. Start out simple and ask for help from people to learn about the libraries to use from the ecosystem and gradually incorporate them into your Rust vernacular. Each small project you do can teach you about a new tool. I recommend not trying to do machine learning or audio/video processing for the time being as those are weak points in the ecosystem. Almost any other project you can think of does have moderate or good stuff available for it. If you need help getting the tooling setup, I really recommend VS Code with the RLS plugin for the time being. It's not great, but there isn't a true great Rust IDE out there right now and it will be the fastest thing to set up. It is also the most popular option currently.
I've moved on to vscode as my main code editor last year, before that I used IntelliJ idea. While it was very slow, I thought it was better suited for beginners than vscode + extensions. It's mostly a gut feeling now, though, and I'm happy with vscode. I haven't used another editor for rust since I switched. 
I think they are both good, but vscode is pretty fast to set up, which I think is more suitable for beginners.
Around the time I switched, the code completion options were better in idea. I can't really say how much that has changed, though. 
That's fair. I'll mull on it, but my main concern is implementing `Index` for `String` just feels wrong since it's intentionally not implemented in the standard library.
Oh, well that can't be done anyways because of the rules of traits, so you would need a newtype anyways.
Right, but if I don't add an `Index` constraint and just `impl Diffable for String` in my crate, I can make a (fairly sensible) default of diffing the bytes for two strings. I wouldn't find that behavior shocking and it is somewhat convenient. Maybe I'm too focused on the String case and should just make a macro if it's too annoying to do the newtype shuffle.
Oh wow. This is kind of surprising. I just found the maintainership issue on GitHub. Is the work on the failure crate necessary to be absorbed into std?
&gt; As the industry and language evolves, the rationale presented by the RFC could be re-evaluated. This! This is similar to what good comments should be: explain *why*, discuss the *rejected alternatives* and *why* they were rejected. Then the next person to come along and ask "And why not XXX" will either: - find out that XXX was not considered, and could merit investigation. - OR find out that XXX was considered but did not fit because of YYY and ZZZ; and can check whether YYY and ZZZ are still relevant (end of discussion) or not. Those are great time savers! A negative RFC would allow condensing arguments, and therefore allow newcomers in 1/2/5 years to check the state of things around the subject; if nothing has significant has changed, you can avoid spending time trying to convince others... and if something significant has changed, at the very least the negative RFC needs be updated to take it into account, and a new decision must be reached.
You want /r/playrust
True, I hadn't considered that maybe there should be a reasonable default for String. I typically find that wrapping things in newtypes is pretty clean though. Then again, maybe not all Index implementations apply to your API. I definitely wont say one way or the other, but there are benefits to both.
&gt; I will just draw your attention to the fact that, as a reader, I find it very worrying the speed with which this paragraph slides down the slope from the very restricted special case of abstract equalities necessary to support RFC 2000 to the vastly more complex general case of full dependent types. Thank you for this. Whether const generics and const-value dependent types are related or not, I find it important to evaluate each on its own merits, and specifically on their *marginal gains*. If const-value dependent types are a major cost, a major difficulty to learn the language, but have only minor benefits for users who already have const generics... then I'd rather they are left out. &gt; A foolish consistency is the hobgoblin of little minds, [...]. &gt; -- Emerson, 1841
Heh. Was just looking at this last night. I settled on BoringAuth, a fork that uses ring. 
Congratulations on your continued progress! I personally am excited to see where progress is very blog post.
Hi! Is tantivy suitable for log data (I assume every log entry will be its own document then), and if so, is there a crate that interfaces tantivy with e g the `log` or `slog` crate? 
Since you mentioned that gfx- is presenting a Vulkan-like API, where is the project in relation to vulkano?
This is a great moment I've been looking forward to... :)
Thank you for this ! 
First of all, I will admit to loving consistency. I guess being French, I know a lot about consistency, or lack thereof. It always seems like the French language has taken the "Exception that proves the rule" to heart, and every single rule has a list of exceptions. I would pity foreigners trying to learn French if I didn't have exhausted my store of pity for the French trying to learn French :( However, I would advise caution in using the argument of consistency as a blunt argument. Consistency is *one* nice property of a language, and so are orthogonality and composability. Pragmatically speaking, however, sometimes generalizing may *really* complicate the implementation, and therefore while it could be nice *in the abstract*, one still has to weigh the costs and benefits even for changes which would increase consistency, orthogonality and composability. 
"Things that look like exceptions" are already an accepted RFC: https://github.com/rust-lang/rfcs/blob/master/text/0243-trait-based-exception-handling.md I don't agree with the lack of a guiding vision. Perhaps a guiding vision you dislike, but not a lack of one.
Things could look a lot more like actual exceptions. And I think we just disagree about what a guiding vision is in this context.
Please use four spaces in front of the code instead of triple-backtick.
Is getting generator based iterators finished a part of async/await being finished?
They don’t need to be stabilized for it to be stabilized. They do need to work.
The results were surprising and C was faster it took 2min 1 seconds and Rust took 2min 5secs. It was a close battle in terms of speed but resource usage it was completely different
Not necessarily. The inner `tera::Error` enum isn't marked as `pub` so the type itself doesn't form part of the public API
What heavy handed actions have you seen? I've only seen admins being almost overly patient and open, especially on the users forums.
I'm not going to discuss it publicly because that guarantees my post will be deleted. Those who know what I'm talking about will know what I'm talking about.
I’d like to datamine this sub and see if it’s the same people who redirect the r/playrust folks over and over again. You’d have to sort by new, so that already restricts the visibility. 
It's lower level than Vulkano. Our intent is to have Vulkano [using gfx-hal](https://github.com/vulkano-rs/vulkano/issues/525), but we don't currently have resources to engage, especially since Vulkano isn't actively developed.
It helps to think of `&amp;T` vs `&amp;mut T` as "shared" vs "unique" rather than "immutable" vs "mutable." Then "interior mutability" is rather "shared mutability." From this perspective it is useful for parts of graph-like data structures and arenas- for example https://exyr.org/2018/rust-arenas-vs-dropck/.
What opt level are you using?
This is what OP is referring to: https://users.rust-lang.org/t/the-beta-rust-lang-org-pr-debacle/22778
What you mean by opt
RE Documentation: The biggest issue imho is link rot. It pervades the compiler, docs.rust-lang.org, blogs, and google searches. In the last year it has gotten _significantly_ worse, making it quite difficult to find information if you don't know exactly what you're looking for to begin with and where to look for it. 
Optimization level. This can have a big impact on the performance of your program and I didn't see it mentioned anywhere
I would say I’m not really using any optimization level but I would love to know about it like how can I make it faster and make it use less resources 
Getting an error that was just reported by someone else too: [https://github.com/camccar/RustTetris/issues/4](https://github.com/camccar/RustTetris/issues/4)
Surely it can't be - four comments flagged, one off topic (comparing it to go in a thread complaining about the site) and three that got went off into political correctness land / generalizing a couple people's actions as an absolute generalization of the entire community. Plus, said flagged comments are still very readable - highlighted even, standing out from the rest. If that's their idea of heavy handed, then I'm not sure what to make of it.
Full agreement on all points.
If people could accept running a local server to read docs, we could make big strides here.
cargo build --release And in cargo.toml you could add [profile.release] lto = true And another thing is, you don't normally call rustc. You let cargo do the work.
Documentation will always be much less sexy than coming up with or implementing new features. In many projects work on documentation is also seen as an entrypoint into the team before you get to work on the interesting stuff. So this can rarely be avoided without paying people IMO.
Thanks for the tip I’m new to Rust I’m slowly learning 
Here's the basic code for running in dev mode: ```rust #[derive(Clone)] pub struct Renderer { tera: Arc&lt;RwLock&lt;Tera&gt;&gt;, } impl Renderer { pub fn new() -&gt; Renderer { Renderer { tera: Arc::new(RwLock::new(compile_templates!(concat!(env!("CARGO_MANIFEST_DIR"), "/templates/**/*")))), } } pub fn raw&lt;T: Template + serde::Serialize&gt;(&amp;self, value: &amp;T) -&gt; Result&lt;String, crate::errors::Error&gt; { Ok(self.tera.read().unwrap().render(value.template_path(), value).unwrap()) } fn reload(&amp;self) { let mut tera = self.tera.write().unwrap(); tera.full_reload().unwrap(); } pub fn reload_in_background(&amp;self) { use std::thread; use std::time::Duration; let t_renderer = self.clone(); thread::spawn(move || { loop { thread::sleep(Duration::from_millis(500)); t_renderer.reload(); } }); } } ``` Reloading takes mutable state. But I don't need it to be mutable in production, so I just give it interior mutability in development. I also spin off a thread that reloads it every second or two, so it's definitely hacky.
Yeah, the situation with the book is especially bad. It often takes 2-3 clicks to get to the current book, and then, sometimes, the article you were going for doesn't even exist anymore.
And you should post a gist with both codes, so we can compare them.
I made a joke once that anyone is free to create an `/r/altrust` (pun intended) subreddit, but if it's going to turn into a "/r/rust minus the civility", then I would not be using it anyway. Recently I decided to actually register it, and although I don't plan to actively grow it, I'd like to keep it in my possession, in case I was actually wrong, and people would start to get excluded from the community just because of their private (eg. political) opinions. Feel free to join, post if you want. I am a great free speech advocate, but I if anything start to become uncivil, I will be banning people too.
What kind of documentation needs doing? Because I find that language documentation is usually excellent. Is it internal compiler documentation?
Having comparisons with the text indexing of sqlite and postgres can convince developers to use tantivy in addition to their relational database. The performance gain should outweigh the extra development work.
[C Program](https://gist.github.com/mraza007/ee00e54d2f6703544cef74abbd7141a4) [Rust Program](https://gist.github.com/mraza007/149cf08ffd0356021c1574c920b8d511)
How do you mean? 
Here's the gist of program available [C Program](https://gist.github.com/mraza007/ee00e54d2f6703544cef74abbd7141a4) [Rust Program](https://gist.github.com/mraza007/149cf08ffd0356021c1574c920b8d511)
Using actix? 
When you don’t have a server, every single redirect means another file. Ever wondered why the rust-docs component takes so long to install? This is why. And then, you also need JavaScript for a “real” redirect. Things would be much smaller and cleaner without these restrictions.
Both programs appear to be doing different things. I'd wager the C program performs multiple reads into the same buffer, whilst the Rust program reads the data into one big buffer. So the Rust program contains the entire file in memory, whilst the C Program only had the contents of the last buffer. But you'd have to share the source for me to be sure. Furthermore, the system you're running this on appears to have a pretty large background load (probably the capture of the video), so your benchmarking setup is not really optional for such small differences to be significant.
Still getting "This feature is only available in Edition 2018" error when using async block in my code, though formatting seems to work correctly now.
I'd really like to see them land before 2020. I think they're at least as useful as async/await in the general sense.
Those two programs are not doing the same thing. The C program reads a maximum 150 bytes of the file into memory at a time, while the Rust program is reading the entire file into memory.
I should have included them as a “maybe” like specialization; they’re in a weird place. Since they have to work anyway, the work needs to be done, so they are less effort than any other big feature would be.
Ahh i seee now this sounds interesting
So i should do the same thing with C program too Do you think they might perform the same then
See here https://www.reddit.com/r/rust/comments/a9zx7g/comment/ecnvqzf
I posted the code btw you can check it out 
Your c program reads files line by line and a line can't be bigger than 150 chars. While your rust program reads the whole file to memory. If you read a 10gb file to memory, then you gonna need 10 gb of memory to store that. If you want a faster rust program you should use the crate memmap and use a locked std::io::stdout with a bufwriter. And try different chunks of data to speed it up. And only flush when you need to.
In simple words try to read the file line by line
This is more equivalent to the rust version (error handling omitted): https://gist.github.com/jjwest/c59d7d8889f25fcac22a09b7c5a7b4ec
I think we're two ships passing in the night here - I'm not really talking about the issue of links within docs but links _to_ docs from outside sources like blogs, old discord conversations, google, and the compiler itself like [this issue](https://github.com/rust-lang/rust/issues/57104). I sort of get what you're saying about running a local server, but I think fundamentally the issue is that the Book and `std` documentation on docs.rust-lang.org need stability and possibly more going on under the hood than crate documentation (like maybe looking at `std` and `core` documentation could require a server?).
I wouldn't read the file line by line, I would rather read set amount of bytes at a time. If you read it line by line you have to check every char for a linefeed and that's slower. But if you really need to read it line by line you can use the crate memchr to find the linefeed fast.
Let me run your program and see me cpu stats I hope I don’t blow up my laptop I did in Python the same and my cpu crashed I had to restart 
ok. ill pull out my ubuntu laptop and check it out
It would be easier to fix those inbound links, so that they redirect to the right place rather than showing a page saying “click here”. 
How does this compare to Vulkano? I made some Vulkano apps before; seemed fantastic, but its documentation and examples was severely lacking. A few months back, the creator moved on, and a patch was released that made compiling sharers difficult (At least on Windows) due to C++ build dependencies.
Ok I have fixed that error and tested to make sure it works on Ubuntu. I made that file in windows and windows isn't case sensitive. 
Why? Triple-backtick's much easier to work with, and is standard in Markdown, stackoverflow etc. Upgrade, or deal with it.
It’s even lower level than Vulkano (no concept of a gpufuture or any of the safety helpers that Vulkano provides). It’s basically a small rusty wrapper over Ash that can also delegate to Metal and DX12 where Vulkan is not available.
Because this is reddit?
Yeah, it's part of my internal state... it's not very pretty. I've been keeping myself only loosely tied to actix.
Regardless whether or not your assumption is right or wrong w r t the Rust community in particular, having such a web page could also help Mozilla (and potentially other organizations with money) to pay people to do things where it's needed the most.
Why not use an interval actor instead of a thread for hot reloading? 
Thanks. All working now. Great job! My 12 year old approves. &amp;#x200B; I look forward to learning about SDL and lower level graphics work that you needed to get this working. 
Four spaces is a pain to work with, ie writing and editing it without support for auto-indent and tab → 4 fourspaces / shift-tab back four.
this isn't a question, but wouldn't it be nice if there were a keyword `clone` like there is `move` for making closures?
I like writing docs. If there are any work parties, I'd like to know about it somehow so I can contribute
Oh okay Sounds good
Maybe negative RFCs would be to strong, but instead a **list of rejected features** is better? Currently it is almost impossible to know if someone else has already made a certain feature suggestion, because there are simply to many closed pull requests and issues to look through. So I guess that certain feature suggestions will be made again and again. If there were a list or catalog of reasonable features/ideas/syntax that were rejected and a link to the github issue, then redundant requests and discussions could be reduced. And those discussions wouldn't be completely lost and forgotten about after a few months.
That makes a lot of sense, thank you!
Is it imported?
I'm confused, why do you want to do this?
#why #do #you #talk #like #this? #we #are #not #on #Twitter
yes, i have a `mod foo;` inside my main.rs
Honestly this is what I would describe as "awful", at least to me
`impl Diffable for String` is possible, but needs to be in the same crate as `Diffable`.
I'm close to the same boat ([https://www.reddit.com/r/rust/comments/2p46zr/whats\_the\_state\_of\_rust\_for\_ios\_and\_android/](https://www.reddit.com/r/rust/comments/2p46zr/whats_the_state_of_rust_for_ios_and_android/)) for a incoming ERP project. I'm building a mini-relational language to cover the extensive business logic and cross across platforms. &gt;D) Try to Make a Rust DLL that could interact with .NET and therefore Microsoft Excel. This is the core of the solution, I think. You don't need to commit 100% rust and "cheat" with .NET if required. One thing I do that help me to integrate disparate platforms is build a embebed REST server and call with a http library. For my next project, I'm thinking in switch to something like ZeroMQ or similar. For ODBC, a quick google yield: [https://github.com/Koka/odbc-rs](https://github.com/Koka/odbc-rs) Other solution is leverage FreePascal/Delphi, it have a VERY robust ecosystem for database apps that could you leverage with a little of C-call conventions to glue stuff. This could also cover Excel and other stuff, and still manage to be native and without GC. Also, for excel you could use oData ([https://docs.microsoft.com/en-us/sharepoint/administration/create-an-excel-services-dashboard-using-an-odata-data-feed](https://docs.microsoft.com/en-us/sharepoint/administration/create-an-excel-services-dashboard-using-an-odata-data-feed)) and/or PowerPivot and become a pure data provider. Not many solid libraries to read/write office formats outside .NET/Delphi that I know, put you could pipe to a program that solve this small part. &amp;#x200B; \---- I see the JS integration like the most challenging aspect. Rust, as far I know, is strong with webassembly but this requiere a fairly recent browser to work? A transpolar could work better, but taking in consideration how outdated are the browser in certain enterprise environments I will look at that before jump blind. &amp;#x200B; However, if the project already have a internet connection requirement stay with a pure REST server or simply generate just html/js, boringly but much fast that current fads, then you could be ok. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Can't offer much help with regards to the thread aspect, since I'm not familiar with libnfs (but I'd assume it operates on an event loop, not threads). In terms of passing data, keep in mind that you can box up a Rust closure and use that as your data pointer. Diesel uses this for its implementation of custom functions in SQLite (the SQLite API expects a C function taking a `void *` and a `sqlite_value **`). Our implementation is probably more complex than yours would need to be since we have to deal with multiple signatures, and deserialization of arguments/serialization of return values, but the fundamental idea is still the same and should provide a good API for your library. Note that this does not help your users exfiltrate data passed to their function, but that really isn't something you can do here. It's async. We don't know when the function will be called, so you just cannot write code like that. However, it will work great for having them call other async functions inside the callback. e.g. your_lib::async_fn_1(|some_data, some_more_data| { println!("async_fn_1 is done! We got {} {}", some_data, some_more_data); if some_data { your_lib::async_fn_2(some_more_data, |some_other_data| { println!("async_fn_2 finished! We got {}", some_other_data"); }); } }); Note that it's important you don't have fat pointers here (the compiler should warn you if you accidentally end up with one), so you will need to have `fn async_fn&lt;F: FnOnce(Whatever) -&gt; WhateverElse + 'static&gt;(f: F)` and not `fn async_fn(f: Box&lt;dyn FnOnce(Whatever) -&gt; WhateverElse&gt;)`. You'll want to make sure you include that `'static` bound to avoid accidental memory unsafety. Here's the Diesel impl if you want to use it as a reference (from outermost API to inner-most implementation bits) https://github.com/diesel-rs/diesel/blob/59aa49b65713df8d666991b37f5e18011f3671d5/diesel/src/expression/functions/mod.rs#L328-L349 https://github.com/diesel-rs/diesel/blob/59aa49b65713df8d666991b37f5e18011f3671d5/diesel/src/sqlite/connection/mod.rs#L216-L230 https://github.com/diesel-rs/diesel/blob/59aa49b65713df8d666991b37f5e18011f3671d5/diesel/src/sqlite/connection/functions.rs#L12-L54 https://github.com/diesel-rs/diesel/blob/59aa49b65713df8d666991b37f5e18011f3671d5/diesel/src/sqlite/connection/raw.rs#L67-L107 https://github.com/diesel-rs/diesel/blob/59aa49b65713df8d666991b37f5e18011f3671d5/diesel/src/sqlite/connection/raw.rs#L139-L180 Since it looks like libnfs expects you to free the data yourself, rather than calling a cleanup function when its done with it, you'll need a slightly different structure than Diesel has to deal with that, but I think your code would look something like this (Add `+ Send` if you're involving threads or if libnfs expects its callbacks to be called from another thread): fn mount_async&lt;F&gt;(server: &amp;str, export_name: &amp;str, callback: F) -&gt; Result&lt;()&gt; where F: FnOnce(&amp;Data) + 'static, { let callback_ptr = Box::into_raw(Box::new(callback)); nfs_sys::mount_async(context, server, export_name, run_boxed_fn::&lt;F&gt;, callback_ptr); } extern "C" fn call_boxed_fn&lt;F&gt;(callback_ptr: *const F, data: *const nfs_sys::data) where F: FnOnce(&amp;Data) + 'static, { // The callback (and thus any data it captured) will be dropped when this function returns // since we're creating a `Box&lt;F&gt;` here and never calling `Box::into_raw` or `mem::forget` again. let callback = Box::from_raw(callback_ptr); let data = whatever_you_do_to_with_the_c_data_pointer(data); callback(&amp;data); } Yes, this is the only time you will ever explicitly be using the turbofish for a type parameter in argument position (despite all the fuss about it when `impl Trait` was stabilized in argument position). As one last aside, have you double checked that you're OK to free `server` and `exportname` once `nfs_mount_async` returns? It doesn't seem clearly documented, and it is an async function so you may want to make sure you don't need to keep it alive until the callback is called.
https://github.com/vurtun/nuklear has an example of the node graph you're looking for. There is a rust binding here: https://github.com/snuk182/nuklear-rust
Well, you could always have redirects that only work on docs.rust-lang.org and not a copy accessed via file://. In the case of the issue the parent linked, which involved this URL: https://doc.rust-lang.org/book/second-edition/ch19-04-advanced-types.html#dynamically-sized-types-and-the-sized-trait ...it seems like it would mostly solve the problem to just add some JS to automatically redirect if the current domain is doc.rust-lang.org. Of course, it would be better to do the redirect on the server side…
How do I put trait bounds on it (it's a `Thing`)
&gt;I don't remember how often editions are intended to come out Ideally never again, in the sence that we shouldn't plan on making breaking changes. Cessen made a good point in [Rust 2019 - It's the Little Things](https://blog.cessen.com/post/2018_12_12_rust_2019_its_the_little_things), last subheading: &gt;I hope we don't *ever* have another edition of Rust at all. I hope 2018 is the first and last one. &gt; &gt;That may seem harsh, but let me clarify: Rust 2018 was absolutely a good thing, and I'm glad that we did it. But it was *also* a bad thing, in that it makes the world of Rust more **confusing**. &gt; &gt;\[Tutorials become outdated, ...\] &gt; &gt;So what I really meant above is not that we shouldn't ever have another edition, but rather that we should *try* not to. If there are good reasons and things we really want to improve, sure, let's go for it. But let's absolutely *not* take editions as a given thing, and *certainly not* as a regular thing. In the contrary, editions are great to document milestones, I believe this is what most people mean when talking about future editions.
Macros are absolutely allowed in Rust — in fact it provides many useful and powerful macros of several different kinds out of the box! See https://doc.rust-lang.org/book/ch19-06-macros.html for some examples, and details of what they can and can't do. However, as in any language, you should use macros judiciously. Rust does have a hygienic macro system, which makes it a lot less error-prone than using macros in C/C++. But you still need to balance the conciseness and readability _gained_ by using a macro with the readability _lost_ by obscuring what's actually going on under the hood. As for an _auto-run macro_... the closest I can think of right now is the `await!()` macro, which can be used in any asynchronous context to drive another future to completion. Maybe that will meet your needs? ... (I think you're looking for /r/playrust. And I'll hazard a guess that pretty much _any_ use of macros in the Rust game is going to get you banned.)
God, do you ever get tired of typing? Your constant gish galloping is such a drain. I honestly think you’re one of the worst things to happen to this community; the fact that there are others who think you’re one of the best makes it that much worse.
This is why: https://old.reddit.com/r/rust/comments/a9v724/wasm_broken_code_generation/ A lot of people still use the old interface, especially on devices that aren’t high spec gaming PCs. Triple backtick notation doesn’t work in the old interface (despite repeated complaints) but indent notation does.
That has the drawback of not deploying the same thing to both places, adding complexity there. Very possible, just not sure that the drawback is worth it.
It’s more of a pain when it doesn’t render correctly, like in the places your parent mentions.
Thanks Mamcx. Your idea on building a REST server is an interesting one. If nothing else, it could be a fallback option. I have heard of oData. Maybe it is time to try it out.
Curiosity 
Check subreddit before posting. 
I have this sub in an rss feed and r/playrust posts are very annoying. Even moreso when it's ambiguous from the title.
Personally I'm pretty happy with how the Rust community is moderated (I have minor quibbles, but nothing's perfect).
I've edited the post to use four spaces instead :) 
That makes sense, although I do expect the performance characteristics to be somewhat reproducible. Perhaps a collection of benchmarks would be helpful in determining which functions are prone to poor optimization.
Now it was same just like Rust 
Thank you and happy new year.
Congratulations! Can't wait to see what progress this will unlock in 2019!
Wrong subreddit
Yeah it does look bad.
Upgrade bro. 
FWIW, you don't need javascript for a redirect. You can create an html file containing: &lt;meta http-equiv="refresh" content="0;foo.html" /&gt;
Have you tried it on Linux? My experience with RLS on Windows is pretty bad. It's slow, doesn't work as expected or just crashes randomly. On Ubuntu it works fine. Maybe Defender or some other Windows service doesn't really work well with RLS.
Ah right, thanks. The file thing is the bigger thing so it’s what I’ve focused most on.
Not everyone wants to use the new interface or the app.
+1 on the issues with the book. I couldn’t believe when I first clicked the notice that I was reading an old version of the book that it didn’t even redirect me to the same page from the *current* version. This is something I intend to make a PR for sometime this week.
We shipped the cookbook in July. [https://github.com/rust-lang-nursery/rust-cookbook/issues/414](https://github.com/rust-lang-nursery/rust-cookbook/issues/414) &amp;#x200B; There's still tons to do, but we never intended it to be complete. We need recipe ideas mainly.
Hm, why is it not distributed with the rest of the docs then? My understanding was that that was the idea, and so I thought it wasn’t done, because we were never informed of it’s progress? Anyway, congrats! We should do that!
That’s not really a constructive stance. AFAIK there’s has been no suppression of discussions, even if some decisions were made while discussions hadn’t fully settled. But you might very well know something I don’t, so if you’re willing to share...
What does the old interface have to do with gaming?
Kodraus made something along these lines. I think it commits after every single document, so it is more of a proof of concept than a real product. https://github.com/KodrAus/tantivy-log/blob/master/src/index.rs Some people, I don't know how tightly they are related with Kodraus, also use tantivy for their logs in their Elixir app. https://elixirforum.com/t/what-do-you-use-to-monitor-your-elixir-app/18185 
Well yes. I don't know anything about Golang, but I'd like to see a presentation about the internals of bleve for instance. In the case of tantivy, the internals are so close to lucene, that it should actually be helpful for Lucene users.
As someone who hasn't had too much experience building a lot of crates before, looking at main: extern crate rusttetris; fn main() { let game = rusttetris::game::Game {}; game.run_game(); } Why do you call `rusttetris::game::Game {};` instead of just `game::Game {};` ?
I never learned to read 
That's true... Well, I welcome contributions :)
All the code is part of the rusttetris crate. as defined in **lib.rs**. **main.rs** is just a driver file to run the crate. you can change the code to this extern crate rusttetris; use rusttetris::game; fn main() { let game = game::Game {}; game.run_game(); } And it will run fine. If that looks more readable to you. 
I am also in a close situation. For Excel, you can use calamine to read from any file. It is much faster than .Net versions, you can use serde to deserialize etc... On the other hand you cannot write Excel files for the moment. For my use cases it is not a big deal because I can always write CSV if needed. For databases you should be covered. Overall I would definitely go for rust (I do with very satisfying results). For the frontend I tend to prefer react for the moment (no need for very high performance, easy to onboard everyone, lots of resources to import from).
We were talking about a hypothetical situation in which it was `trait Diffable: Index {...}`, but for the one above yeah.
Rendy says it's based on vulkan, but since it uses gfx-hal it should run under dx12 and metal as well right?
Remember hearing about developments on this a year back, glad to hear things are finally finished!
These benchmarks crop up all the time here and the verdict is always that It's actually very hard to write the exact same program in two different languages. You need to focus on a specific aspect to make any conclusion. Benchmarks in general are much trickier to get right than they appear because there's so much going on at any time on modern machines, it's almost impossible to isolate the behaviour of the code from the OS and hardware. It can still be a good exercice if your goal is to learn a new language.
How do you mean "isn't actively developed"? They merged a pull request 13 min ago....
Lack of adaptability: Why we can't have nice things
There was actually a bug[1] recently found in racer (the autocomplete engine that RLS uses) where it doesn't properly handle CRLF line endings, which is default on Windows. The workaround for now is to switch your files to LF line endings (should be on the bottom bar in VSCode). It has since been fixed[2] but it may take a bit to trickle down into stable. [1] (https://github.com/rust-lang/rls/issues/976)[https://github.com/rust-lang/rls/issues/976] [2] (https://github.com/racer-rust/racer/pull/1007)[https://github.com/racer-rust/racer/pull/1007]
Well there are certainly enough simple servers in the ecosystem now; why not embed one into cargo?
I believe this has something to do with CRLF line endings. See my reply here: https://www.reddit.com/r/rust/comments/aa348b/vscode_rls_autocompletion_not_working_outside_of/ecoyzad
Here's a non-expiring link to the [Rust Discord Server](https://discordapp.com/invite/rust-lang) #docs room: https://discord.gg/kEYk9QD
I'm leaning bug. Was able to reproduce. Note that if you have foo return an instance of Test instead of a string, it works. Here's a variant where we both log the Test instance created in foo, and log it when returned: ```rust impl Test { fn foo(byte: u8) -&gt; Self { let t = Self { a: (byte &amp; 1) == 1, // 2. This must come before "b" - It will incorrectly evaluate to "true" b: (byte &amp; 2) == 2, // 3. This must be evaluated inside the initializer }; log(&amp;format!("{:?}", t)); t } } #[wasm_bindgen] pub fn render() { log(&amp;format!("{:?}", Test::foo(2))); } ```
Yup my primary goal for 2019 is to learn Rust 
Looks like a bug. I was able to reproduce. Here's a variant of your code, where foo returns a Test instance instead of string: impl Test { fn foo(byte: u8) -&gt; Self { let t = Self { a: (byte &amp; 1) == 1, // 2. This must come before "b" - It will incorrectly evaluate to "true" b: (byte &amp; 2) == 2, // 3. This must be evaluated inside the initializer }; // log(&amp;format!("{:?}", t)); t } } #[wasm_bindgen] pub fn render() { log(&amp;format!("{:?}", Test::foo(2))); } It works correctly. If you uncomment the log command in foo, it will print the incorrect result twice.
Which makes the work of the docs team so far all the more impressive. Seriously, I don't think I've ever seen better documentation for a software project than this.
She turned me into a newt! ^(it got better...)
We could! People have *really* indicated that they hate the idea though.
How offen do we need cloned closure vars? And how many times can those clones be removed by careful coding?
I spent some time to complete something I've been working on for the past couple weeks over this vacation, just a bit of fun.
I wish there was a more implementation-centric approach to RFCs. Right now, RFCs are reviewed and (some of them) merged, and then there's this black hole of RFC proposals, where each of them lives in isolation, but there is little visible effort to: - Systematize how the RFCs relate to each other. - Prioritize RFCs (at least within the RFC process itself, rather than informal blog posts etc.) - Define a schedule where *each* RFC falls (even if it's "unscheduled", i.e. no comittment to delivery, that should it be it's own bucket). - Define "phases" of delivery, which maps the relative order and tentative schedule of delivered RFCs. Phases don't constitute promises or commitments, but help define a *roadmap*. - Have some kind of *emergent* Rust roadmap based on the RFCs. In other words, set a "North Star" of where you see Rust evolve, how each RFC contributes to the process, and then work backwards from there to define specific milestones. There are plenty of tools that help organize, visualize, and communicate this process. Right now, it feels like the community has a some visibility into what Rust's future *should* be (and even then, only in fragmented RFC pieces rather than a holistic vision), and almost no visiblity into what Rust's future *will* be (which requires prioritization, dependency resolution, and tentative schedule).
Thanks &lt;3
Please see my comments in the thread about some of the constraints here.
Is questioning your curiosity metacuriosity?
I could attend a meeting, and discuss this possibility and expectiation. Whens the next docs team meeting?
We don’t have regular ones any more due to the lack of people + difficulty of scheduling.
I was not aware documentation needed work. My experience with it was great. I would probably contribute to it if I was actually aware that it needs doing and there was a list of stuff to do. For me personally a call to action on this subreddit would suffice.
Whenever you have Rc, Arc, and boxed fns, I guess
Thanks!
It's a 0.1 so it is just mature enough to be released.
I've never partook fully in the RFC process but I have at times lurked to track feature progress and to understand technical considerations/underpinnings of the language's design. While I like some of the phases discussion goes through, I'm also overwhelmed by the amount of tribal knowledge that serves as the foundation of the languages development. What manages to be written is scattered and burried across ill-mapped corners of GitHub, is lucky to find its way to a "canonical" blog posting, and much is nary found in documentation. The legal world employs something known as a restatement. Restatements of law will be drafted to help formalize law that is officially defined over dispersed common law rulings which themselves pull from distant articles and clauses. Having restatements of the justifications, reasonings, real-world pragmatic considerations, opined type theory musings, and philosophies of orthogonal design that all precede the final technical draftings. I suggest this be done to convey what accepted RFCs achieve for the Rust users beyond the mere language semantics. As a way to catch people up to the communal thought that was produced to reach a decision. For anything deemed "stable to the end of time," such a restatement ought to be formed alongside the more technical statements. By which I mean the restatement too should seek to be stable, and not become a burdensome clerical labor that demands any agile curating. Part of cleaning the RFC process and the general OSS atmosphere will be additionally having formalized documentation on language specifications and full up to date grammer definitions. These are must haves if there is ever a changing of the guard for a "bus factor" contributer. Doing the following will reduce the reliance on playing historian with GitHub comments as a prerequisite to grok the deeper arcana of Rust internals. In addition to these must haves, I think use/need/criteria/reason/etc. restatements could be the solution to the decaying legibility of Rust's design record. I'd hate the community to forget an intentional and wise design choice that never had it's elegance conveyed in learning material, to be plastered over with a poorly conceived sugar or uglier redundancy. I'd also hate for our resource limited contributors to spin their wheels because it takes too long for esoteric knowledge to percolate to where it's needed most.
No, thank you.
Give the Jetbrains Rust IDE a try if you haven't yet. It's really good. RLS is definitely the way forward, but to me it feels not as comprehensive as the intellij Rust extension yet.
Not sure if you can check at compile time, but you can at runtime https://docs.rs/cpuid/0.1.1/cpuid/
That could work. I could do that check in a build.rs, but that seems kinda sketchy (not that target_vendor="intel" or the like would be much better). I definitely can't "actually" do it at runtime. Critical path and all.
`--target-cpu=native` does not work?
Interested in trying it out as a semi-pro player. Have you integrated SRS? Or is it a clone of NES Tetris?
You could still do it once during the initialization of your system and set which function to call based on what parameters you want. Wouldn't require any branching during the actual event loop.
It does work. BMI2 is supported on both AMD Ryzen and most Intel chips. As a result, when using `#cfg[(target_feature="bmi2")]`, it uses BMI2 on both chips. It's just so slow on AMD Ryzen that I can't actually use it.
What looks bad about it? Seems like they let the conversation run a reasonable constructive course and only flagged a couple off topic issues or am I missing something?
No it’s just meant to be nes clone for now. Changing just rotations would be super easy though because I just draw them in 2d arrays.
Why is making the decision at build time correct? Is this library specialized enough that you expect your users won't end up distributing binaries, or using heterogeneous build servers, etc?
Jumping to function pointer in a critical path will still impact performance. A better approach will be to introduce marker types (`FallbackBody`, `Bmi2Body`, etc.) which will implement "loop body" trait (say `LoopBody`), and make loop generic over this trait (Loop&lt;B: LoopBody&gt;). Now you create several instances of loops which use different bodies (using trait objects or function pointers, does not matter) and select one them in runtime. This way thanks to monomorphization body implementation will get inlined into the loop and you will get maximum performance and cost of dynamic dispatch will be negligible (you even can do a benchmark during app initialization to select the most efficient implementation). Using this approach you can move dynamic dispatch/function pointer as high as you want.
Honestly- if you already know c# and F# and don't already know rust, or even if you do know rust- stick to .net. The integration with windows is just unparalleled (no offense to the amazing creator of win32 crate). .net is one of the best choices obviously for ole and ASP .net is one of the best server platform all around. 
Yep
Yeah, vulkano definitely felt unfinished and poorly documented last time I tried it. Gfx-hal is a lot lower level and portable.
I like this approach, and I'm gonna experiment with it tonight. The hard part is that the `LoopBody` is actually going to be written by the user of the library, so it may require them to be aware of those traits and initialization code, which I'm trying to avoid. There may be some macro magic I can pull, though, I'm not quite sure yet. Function pointers are out as a general solution, as I need inlining. I agree with the idea of the approach in principle, though, similar to /u/ben0x539's comment.
Indeed, there seem to be a once-per-week PR merged, so at least one person appears to be working on it. Last time I heard, the creator of the project declared them unable to maintain it, and the actual maintainer was trying to port their own client/game code to gfx-hal...
A lot of the best parts of Rust (aside from uncompromising speed) are a part of F#. Given the opportunity, I would swing with F# due to the maturity of the tooling/IDE, integration (and documentation with) Microsoft Excel, and the language's features. I'm eagerly watching the progress of .Net Core, while I continue to write most of my personal projects with Rust.
It may not be correct. I'm going to explore that. I can say, a popular chess engine stockfish \*does\* distribute separate binaries, which is why I was planning to do the same. That doesn't mean it's the perfect solution, and it's written in C++, so it may be right for them, but not for me.
Ah I see. I thought LLVM would be smart enough to not use this instruction even if it is available when it is not optimal.
But you can use \`borrow\_mut\` to get a (runtime-checked) mutable reference to the wrapped T through your Rc; you just can never get a mutable reference to the RefCell itself, which is why you use RefCell to begin with; if you could, the RefCell would be unnecessary.
Ugh, yes. Every top google result about a language feature is from the old book, which just contains a generic link to the new book. Where the information you're looking for is often under a different headline.
You can to some extent stick your Vim setup in IntelliJ.
So I’m new to rust building. Is there a forum or anything that has blueprints or solid base builds for starters? YouTube is okay but, I wanted to ask others. Thanks. 
I have minor quibbles with the language too. Nothing's perfect.
Highlighting blocks where the developer is actually responsible for avoiding undefined behavior is the practical aspect here, and all but the most trivial code will depend on unsafe code *somewhere*, so any sort of analysis like this would highlight pretty much everything. 
Apologies it's taken a bit to reply - busy with holidays. [here](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=38a7f56b13274deae87e9599eea1ea25) is a playground with an error - seems like a slightly different error than what I remember as I played with it for maybe 30 minutes trying to get it to work. [here's](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=b25ef8e96e043060b8471b49cc2840f8) the same playground with code that's pretty similar, but works. the key distinction is it's for `T` instead of `Option&lt;T&gt;`. The code that breaks has just been commented out. Further details: - this is using the `#[serde(with = "mod::path")]` approach, as I needed to override the normal `Serialize`/`Deserialize` impls for the type - I can get this to work for `T`, just not for `Option&lt;T&gt;` - One problem I encountered while writing the working version (i.e. for `T`) is I need to implement `visit_u64`, not just `visit_u8` in the `Visitor`-implementing type to get `serde_json` to work with these, because of `serde_json`-specific implementation details. That was difficult to track down. - A problem I have previously encountered using `bincode` is that custom `Serialize` and `Deserialize` impls can break it, and it can't handle "untagged" enums (iirc).
BTW future redditors, this is a link to GitHub's trending page, filtered to Rust and the past month. This is *not* a permalink to the top Rust projects of December 2018.
It really depends on what you want. If you want to develop quickly then .net is very nice. If you want to have speed and stability (like in no unexpected exception, much lower resources consumption) then go for rust.
I apologize if this could be misleading in the future, I sincerely haven't thought of this, mods can change the title if they want to
I would take a look at something like web-view https://crates.io/crates/web-view Also if you're looking for a webserver Rocket and Actix-web are very popular options (personally I prefer Rocket but it depends on what features you need).
What about doing it like docs.rs? Versioning on links and still showing the old documentation but with a nice bold “latest version” warning button that redirects. I think it’s a good compromise and (I think?) not that difficult to change
Can someone explain the relationship between this and gfx-hal?
Hi, not OP but you got me curious and would love for you to help me understand you here. Is this what you meant? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=10480cb5a0993d7055e97b99e8ec3b10 I feel like this wouldn't be inlined? 
Building on top of this, once you have the ability to include a closure as a callback function, you can turn this into a Rust-y futures-based API if you so desire by sending the callback argument over a channel. In nightly land (to allow `await!`ing the function) that might look something like this: fn mount(server: &amp;str, export_name: &amp;str) -&gt; impl Future&lt;Result&lt;Data&gt;&gt; { let (sender, receiver) = futures::channel::oneshot::channel(); let callback = move |data| { sender.send(data); }; if let Err(e) = mount_callback_impl(server, export_name, callback) { return futures::future::err(e); } receiver } fn main() { async { // Wow, so Rust-y! println!("result: {:?}", await!(mount("127.0.0.1", "foo"))); } } Using futures 0.1 will be similar.
slightly (majorly) off topic.. 
I'll make the rough list of recent moderator action for you then: This thread was closed after 98 posts. It was let fly even with baseless accusations being mentioned in the thread. https://users.rust-lang.org/t/the-beta-rust-lang-org-pr-debacle/22778/98 People are free to open new threads. A couple of PRs on the Rust website repository were closed and subsequently locked for discussion as people wouldn't want to stop beating a dead horse (that's not what an issue tracker is there for). You are free to open new issues for bugs. This is not moderator, but maintainer discretion. Please note that the website contribution guidelines request issues before PRs. https://github.com/rust-lang/www.rust-lang.org/blob/master/CONTRIBUTING.md We deleted a malicious post on this subreddit framing a person who was not involved in the website as being responsible for the website. For any additional questions, please feel free to mail the mods team. rust-mods@rust-lang.org. 
Seriously? That's, like, basic stuff. Is RLS not tested at ALL on Windows? It's supposedly a Tier 1 platform, and RLS is now part of the official distribution...
Why is TIM6 base address hardcoded here (src/main.rs:25)? let old = ptr::read_volatile(0x40001010 as *mut u32); 
I think you can always using `build.rs` to detect and do stuffs...
Not only part of the official distribution, but they lauded it for it's stability and stuff in the 2018 edition announcement, despite the fact it doesn't work very well *anywhere* for pretty much *anything*. RLS really isnt anywhere near ready for.. pretty much anything, tbh. It's a really sad state of affairs, really, and stuff like this has been happening *a lot* lately. I use Windows, and i use VSCode and RLS over Jetbrains, but it isnt pleasant, and i don't dare try "stable", i only use the nightly tools and i'd recommend others do the same.(Theres a setting in the RLS VScode plugin for this) Oftentimes RLS is somehow able to give me hover info on a type i defined, but still unable to `go to definition`? How do you know the doc comments without knowing where it is, RLS?! What sorcery are you using?! This was the one feature the release announcement said works well and it.. really doesn't. I also use the nightly rustfmt because stable doesnt supporting formatting options i want.
I just stepped off of wor maintaining the reference (though I was away for the latter half of the year) for a lot of the reasons discussed in this thread. Fundamentally, there needs to be a shift in the approach taken, and documentation needs to stop being a nice to have if things are going to change. This year was marked by an a attempt to do just that getting abandoned to meet the edition schedule. That shows that the core team is not willing to prioritize it to the same degree as the rest of the language, and the results are as you might expect.
My name is xfix, not xafi. Nice read either way :).
That's all it was? I was having loads of problem with auto-complete not working during advent-of-code... This would have been very useful to know :(
I feel remarkably stupid (or perhaps of unremarkable intelligence?) when I read reports like these, especially from "new" Rust programmers.
When logging, I believe you do need to commit often because you want to make sure your data is safe even if the application crashes. Although if the application is pure Rust (and very little unsafe) I guess you could commit in a panic handler and make that less of a problem. The second question is about log cleanup; you typically want to erase logs after x days or so (in order to not fill up disk space), how would that be handled? Would you need a separate store for each day or can you run queries like "delete from store where timestamp &lt; x" ?
\&gt; When logging, I believe you do need to commit often because you want to make sure your data is safe even if the application crashes. Although if the application is pure Rust (and very little unsafe) I guess you could commit in a panic handler and make that less of a problem. Commit does not mean what you think it does in tantivy. It cuts a new segment. You probably want a journal log on top of tantivy, and trigger a commit in tantivy periodically. &amp;#x200B; \&gt; The second question is about log cleanup; you typically want to erase logs after x days or so (in order to not fill up disk space), how would that be handled? Would you need a separate store for each day or can you run queries like "delete from store where timestamp &lt; x" ? I would write a merge policy that avoid merging segments that go across a day, and have something that pulls obsolete segments periodically from the index. (this is not super difficult)
Yep - this is why I'd highlight that fact rather than the fact that "`Rc` does not implement `DerefMut`". I'm not objecting to the message, just the way it was put.
This is awesome! Thank you so much!
No worries, you are not the only one feeling it :). To be honest, it is without exception difficult to grasp all the details to anything that takes several hours to think about. This is one reason why crates.io is so amazing, full of libraries with distinct knowledge shared to all. I just begin to wonder what we could be able to do with "Advent of Code for Real Problems", solving unimaginary problems of the day. There could be a prize too for the winner. The winner would be the solution selected for "production". Safe Rust would have an upper hand here in most cases, I think.
I haven't seen your answer! Thank you and sorry for my late reply. &amp;#x200B; The documentation says: &gt;Note that this also means that my-awesome-source is not allowed to have crates which are not present in the crates-io source. &gt; &gt;As a consequence, source replacement is not appropriate for situations such as patching a dependency or a private registry. \[...\] private registry support is planned for a future version of Cargo. &amp;#x200B; Can I still use private crates and have cargo assume these are on [crates.io](https://crates.io)? What happens when I try to publish to a replacement source?
There's something missing from the documentations: when exactly does the ZCA principle really apply. There are many cases where I would like to use a different construct, with more closures for examples, and I think it could in theory have the same cost but I have to do expensive benchmarks to check. Do you guys just check the LLVM IR or what ?
Did you set `edition = "2018"` in `Cargo.toml`?
&gt; This might jump the gun a bit, but let’s jump straight to the final code example Thank you - I really like when the final picture is shown before all of the tiny pieces. It really helps frame things for me.
You can’t detect target-cpu at Compile time, but you can detect sse4a and tbm using cfg(target feature) which are features that intel cpus do not have .
You can't tell at compile-time which arch the binary is going to run on, can you? Of course it's possible to *optimize for* a specific CPU at compile-time, but the resulting binary could still be run on both Intel and AMD CPUs. So either you could detect it at runtime and somehow switch the code, or configure at compile-time which CPU the code is optimized for (and just use that cfg to choose the code to be used).
Not quite, I've meant something like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7af56d9d3fe4838f6e345d50b3b5f32c). The code can be improved (e.g. you don't need marker types here, you can be generic over function), but I think you get the idea.
[removed]
Nice article. Hmm. So there's a memoization crate https://crates.io/crates/cached I'm sure I looked for one when I was working through the Euler problems but couldn't find one. Nice to know!
This sub isn't about the Game...
It is tho... or am I not aloud to Find people to play with in this reddit sorry I’m new asf to reddit.
/r/playrust
"For everything related to the rust programming language..." Nah, it's not. It's about Rust, the open source systems development language from mozilla. I mean you might still find someone to play Here but yeah
That actually works! Thank you. This even explains why the [main.rs](https://main.rs) file works, because cargo generates the file with a LF line ending and VSCode creates all new files with a CRLF line ending.
I tried it to test if this was only a VSCode issue but couldn't figure out if Jetbrains was using the RLS or something else. But I would have definetly switched to that one if the problem haven't been resolved
Thanks for the explanation. It is not clear to me exactly what a segment is, but if a segment means a new file, and there is no way to insert a new document into an existing segment and flush that to disk, it sounds like tantivy is not what I'm looking for w r t logging. 
Yea, weird. It went ok for half a day, and then went broken again. Seeing it on both my phone and mac if connected to home network so def nothing to do with my system. Cargo commands work now, Safari/Chrome on mac works, FF says bad domain, Safari on the phone says bad domain (only from home network), Chrome on the phone works. Mysterious stuff... 
Yes that's what it means. Committing creates several files. You need an extra layer to make things decent for log search.
Well done and thanks for sharing. Lots of interesting bits in there :) I'll definitely have to look more into Z3. I also love the use of SIMD and rayon.. It makes me want to go back and try to optimise some of mine! I'll have to look at pathfinding and cached as well; I wrote my own pathfinding each time and it would have been great having something take care of that (and I used an Rc&lt;RefCell&gt; to memoize my cave erosions behind an immutable interface)! Day 23 part 2 was perhaps my favourite puzzle. My first solution was quite trivial actually, and worked by finding what the largest group of overlapping spheres was and then drawing a sphere out from origin (with a radius starting at the edge of the furthest sphere away in that group as an optimisation) and expanding one at a time until it touched the entire group. I got it down to about 300ms. I then spent a couple of days after the 25th trying to make a much faster partitioning based solution but decided that using cuboid bounding boxes to approximate overlaps (I used these since it was easy to chop them in half each time) was too rough, and my thing failed to converge in any reasonable time.
Thank you for your work on the cookbook. I was using it just a few hours ago to figure out date parsing :)
I think without seeing more code it may be hard to help. One thing I'd try doing is adding constraints to the future impl you return at the top ie: Box&lt;Future&lt;Item = TcpStream, Error = ()&gt; + Send + 'static&gt; To signal that the future returned can be sent between threads and contains only static references. You might then see errors regarding references that are making it into closures that go into the code that builds this future. Normally this requires using "move" on closures so that they take ownership of things rather than borrow them, or if things need sharing between more than one closure, Arc + Mutex (if you need sendability). Async/await makes some of this stuff way nicer, so I'd also encourage looking into that a bit more and having a play with it on nightly rust :) 
I don't think you're being completely fair to yourself. It's very important to note that a huge amount of what I did here was the direct result of other peoples' work: the many crates I used, the other people in the Discord server who shared ideas and helped out, the innumerable blog posts and tutorials I've read about Rust-related things, etc. Besides that, I've been using Rust actively for well over 2 years now. Even so, I ended up spending many dozens of hours on Advent of Code. I will agree that looking back it feels like I accomplished a lot, but there are many more pieces to the puzzle than just me!
Not sure exactly what you mean, but gfx-rs the group of developers working on various graphics-related development efforts in Rust, of which `gfx-hal` is one (currently it is the primary focus along with gfx-portability which uses gfx-hal to implement the Vulkan portability initiative)
&gt; and worked by finding what the largest group of overlapping spheres was and then drawing a sphere out from origin That's a very clever idea! Although I imagine that it would be very difficult to create, I think a visualization of that (perhaps of a toned-down version with far fewer nanobots) would be really neat. Seeing as Z3 took over 20 seconds to run on my desktop and the official guidance was that puzzles were designed to run in "in at most 15 seconds on ten-year-old hardware," I think that the creator meant for people to do something like what you came up with instead of relying on Z3's powers to do it for us.
`Vulkano` checks some invariants and automate some operations (like synchronization) but adds an overhead which may be significant in complex scenarious. `gfx-hal` doesn't anything of this. With vulkan backend it just converts input types and calls matching `Ash` methods. This means that you must be careful to not violate valid usage (you can find extensive documentation on vulkan spec pages). If you interested in working on slightly higher level you can cinsider to use crates like `rendy` (soon on crates.io) that will provide you with tools like command buffer wrappers, resource manager, rendering graph etc to make it harder to violate valid usage and aid you in other ways.
Thanks! Inspired by your usage of Rayon, I gave it a go on my day23 part 2 solution and got the time down from \~300ms t o\~110ms on my machine; very satisfying, and so easy to use!
This exact use case is demonstrated in Azulejo here: https://github.com/maps4print/azul/issues/75
This is a very smart idea.
Yes, I did
There is another option, with slightly different syntax, [here](https://github.com/tylerreisinger/cache-macro).
I don't know much about ffi, but what I understood to be the biggest pain points where: - allocations are made by the rust allocator instead of the host application allocator - `panic`s across ffi boundaries And both are handled here! Well, I fell that the way postgresql has defined c extensions and ffi helps a lot (exposing an allocator and asking for a setup function). But still, it feels really smooth! 
Not that, the fact the criticism was ignored and the rust-lang.org website tries to explode your head with the colours.
Async/await has nothing to do with threading per se, it's basically a compiler extension that automatically converts functions written in familiar async/await syntax into state machines (which is how it implements the whole "yield until X is resolved" thing - it simply returns early from the function, and reenters later with a different starting point). There's nothing you can do with async/await that you can't do with futures, it's just a lot more manual and fiddly. &amp;#x200B; So the answer to all of your questions is yes. For 1, you can just look at plain tokio with a single event loop, for 2 there's tokio\_threadpool and other threadpool crates for scheduling futures. For 3 I don't know of a crate that does this off the top of my head but I don't see why the language would limit you here. For 4, of course! &amp;#x200B; It's worth noting that async/await and just the ecosystem around futures in general is still quite young and there's a lot of rough edges; I expect this will largely work itself out over the course of the next two years or so.
You probably just need to do \`for\_each(move |sock| { ... })\` to move your myFuncsRef into the closure, otherwise it will be dropped at some point and your listener future chain will probably outlive it (remember that futures are deferred, you're just setting up the chain here, all the work is done by whatever executor you're using, e.g. a tokio reactor).
Yes, you can do `mycrate = { "git" = "`[`https://github.com/whatever`](https://github.com/whatever)`", "tag" = "v1.2.3" }`, I do it often for internal private dependencies. You can also use commit hashes using "rev" instead, or branches of course. It accepts ssh URLs as well, e.g. `ssh://git@github.com/user/repo`
I think he want fill "version" in Cargo.toml from git tag.
Oh, that makes more sense after re-reading. In that case I have no idea, doubt it's possible in Cargo directly.
Extremely clear! Thanks! :)
This repository has sent me down a lambda calculus rabbit hole. Extremely fascinating stuff. Thanks for sharing!!
Even if i move it in i still get an error with lifetime :(
Yes, that is what I meant. Since I tag each release it is a bit redundant to have the same information twice. Having cargo build use something like git describe for the version would simplify things.
Perhaps experiment the idea out of tree and if it becomes popular propose it to be merged in.
I googled up some intensive nerding of the issue. It sounds most likely that the AMD processors have more difficulty with latency than throughput, and mostly with the scatter-gather instructions PDEP/PEXT. https://lemire.me/blog/2018/01/08/how-fast-can-you-bit-interleave-32-bit-integers/ "More difficulty with throughput than latency" means that you'll not see this problem as much if the algorithm allows multiple scatter-gather instructions to execute in parallel. The follow-up post shows how bit interleave can be implemented using SSE instructions, which is likely faster on both manufacturers' chips when possible.
I'm still looking into async/await myself, but from what I know so far I can say this: 1. Yes, that's basically the entire point of (Rust) async/await 2. I'm not sure if the "standard implementation" can do it out of the box, but there are definitely crates for threadpools. 3. I don't think that exists yet. Way back in the day Rust had green threads, but that was later changed to OS threads, due to wanting to minimize the runtime. But there's even a GC for Rust, so I'm sure someone somewhere is hacking around with green threads. :-) 4. Similarly to #1: Yes, that's one of the key Rust concurrency features. Also you can check this out: https://rust-lang.github.io/async-book/getting_started/chapter.html It's still a WIP, but it really helped me understand the basics!
I agree. Postgres definitely is setup correctly for preparing all of this. Another option would have been to use a global atomic reference to some of the initial setup, but given that this magic function is called, I felt like it was as good a place as any.
This is very interesting. There is a lot of functionality for ETL here as well as analytics and possibly AI. I was just wondering how hard would it be to implement something like this for MySQL?
agree. This really seems like a sweet spot for F#. All the windows integration goodies of dotnet and the succint encoding of business rules with F#
Didn't read about the internals yet, but the TL;DR looks freaking amazing. &amp;#x200B; Can it fuzz Rust binaries yet?
*Disclaimer: as I am the LibreAuth main developer, my opinion about BoringAuth might be biased, however I'll try to stick with the facts.* It is misleading to say BoringAuth is a fork that uses ring because it suggest the two projects are close and that BoringAuth has something more, which is not the case. Before going any further, please not that the main reason for the BoringAuth fork was the use of the [rust-crypto](https://crates.io/crates/rust-crypto) crate, which was not maintained. I solved this point a year ago with LibreAuth 0.6.0 by using crates from the [RustCrypto project](https://github.com/RustCrypto) (although the name is very similar, those are two different projects and RustCrypto is maintained). That said, let me explain why BoringAuth has nothing in common with LibreAuth anymore. When the fork occurred, LibreAuth only had an early-stage prototype of the password authentication. To be clear, this prototype did not handled very important aspects of password authentication and wasn't even released because I thought it was too dangerous to be used in production. As I moved away from this prototype to something more usable, BoringAuth did not: even if this projects seems to be maintained because there is a few commits, the pitfalls of the dangerous early stage password authentication has not been addressed. Here is short list of things that have been implemented in LibreAuth that BoringAuth does not support: * Argon2 and Sha 3 * The ability to softly upgrade the password storage method (yes, technology evolves, including password storage). * The ability to control many aspects of the password storage method. * Support of [unicode equivalence](https://en.wikipedia.org/wiki/Unicode_equivalence). * The ability to check the min/max password length either by the number of characters or the number of bytes (yes, those two may be different). * NIST Special Publication 800-63B compatibility mode (although BoringAuth might be compatible, it does not implement some strongly recommended parts and does not explain why). For all those reasons, I think BoringAuth should not be used: using ring did not add anything and the author failed to keep-up with essentials features.
Unicode equivalence is the specification by the Unicode character encoding standard that some sequences of code points represent essentially the same character. This feature was introduced in the standard to allow compatibility with preexisting standard character sets, which often included similar or identical characters.
That is a good idea, but it's hard to justify time on something that may not even make it in.
Thank you for all your work, seriously, it was a bright spot of the year for me.
We accepted an RFC to do this over a year ago, but nobody has stepped up to implement it, including me. https://github.com/rust-lang/rust/issues/44687 
Just a quick glance, but it looks like a similar amount of boilerplate: https://dev.mysql.com/doc/refman/5.7/en/plugin-types.html The daemon plugin section looks to have a good bit of information there, so it would probably be very similar to the work done to support Postgres. 
I think we, as a community, will need to distinguish between missing features and new features. &amp;#x200B; There were a number of features that were proposed before Rust 1.0 was announced, but have not been completed: Associated Type Constructors, placement new, and const generics are ones at the top of my mind. (I'm sure there are a bunch more) &amp;#x200B; We're in the middle of re-facoring the entire trait system (the Chalk project), and are still working on improving MIR. Getting RLS and rustc to use a common abstraction of the 'front-end' of a compiler looks like it will be another large re-factoring. These refactorings are blockers for some of those features that didn't make the Rust 1.0 cut. I personally think it's too soon to say 'Rust can't add anything new, it has too many users.' yet. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; there's something I can't seem to find amongst all documentation, libraries, etc: No worries, this makes sense. All of this is new and changing rapidly. Your other replies are good mostly, but have some inconsistencies/incorrect things, thanks to this! Here's my answers. &gt; Can I use async/await for single-threaded IO concurrency? Yes. `async`/`await` produces a value, a `Future`. How that future executes depends on the *executor* you put the future on. Different executors can implement this however they'd like. Tokio originally implemented a single-threaded executor. &gt; Can I use async/await for multi-threaded parallelism over OS threads? Yes! Newer tokios have a work-stealing threadqueue exectuor, so your futures are automatically executed over multiple threads. &gt; Does Rust (maybe with tokio?) support green M:N threads like Go? "green threads" mean different things, so the answer to this is both "yes" and "no". "Tasks" are, strictly speaking, green threads, but they work very differently than Go's. Thanks to the way Futures work, a task knows *exactly* how big its stack will be at compile time, and so it does it 100% correctly, every time, in one single stroke. goroutines have an initial size, and re-size as needed as they execute. &gt; Can channels be used in all the previous situations, where applicable? Yes.
Just a quick tip: You can white Excel files with this Crate: [Simple Excel Writer](https://github.com/outersky/simple_excel_writer) I made a pr that was merged to get it working in windows so you should probably pull it from master to get it to work on Windows.
How should fuzzing and automatically generated test cases be seen in relation to each other?
If you're not sure, that's the best way. Over time, you also develop some amount of intuition for how optimizations work, and so can guess pretty closely.
you want /r/playrust
Super cool :D. I will have to check it out this weekend. 
Great writeup! I stopped after eight days as I'd other time constraints but looking forward to going through the rest at some point and using some of the crates you mentioned. I also learnt a lot just looking through /u/burntsushi's solutions here [https://github.com/BurntSushi/advent-of-code](https://github.com/BurntSushi/advent-of-code).
Woops, I overdid it trying to make it a minimal example! Thought I was missing something very trivial. &amp;#x200B; Thanks for still trying to decipher it! Didn't realise I could put code up there. [Here's an example of a program that creates the error.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=932824b105c2be64ce1cfcb841752a6f) Again, once you replace the \`?\` with \`.unwrap()\`s, it compiles perfectly. &amp;#x200B; Turns out it also works if you get rid of the lifetime parameters for MyError (by first removing the reference-dependent variant in Token)? I'm assuming now it has something to do with reading the error breaking things?
[Here's a proper "working" example of a program that creates the error.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=932824b105c2be64ce1cfcb841752a6f) What exactly do you mean by the error type keeping the borrow around? I think it's definitely a problem with the error now mixed in with lifetime parameters somehow. Since \`?\` returns the error immediately if it is seen, aren't all code paths down the function then independent of the error, though?
That ties cargo to `git`, which not everyone uses.
Thank you!
You can check in build.rs and add appropriate rustc-cfg and then use `#[cfg(intel)]` in your code.
Of all the rust new years posts I've read, no one has mentioned my pet peeve, let's call it dependency sprawl. The fragmentation of the rust crates into smaller basic units has somewhat started, and I wonder where it will end. I come from Nodejs and that ecosystem is pretty much ruined from ideas like splitting lodash into one function per library. reqwest is a great project from a standards and async io perspective, but the depdency tree is ludicrous not to mention to added compile time. it's tokio underpinnings are likewise super, and I am truly excited about the rust async story, but any project based on it comes with a hefty dependency tree and compile time. nodejs just recently showed us the dangers of small widely used libraries changing owners. rust hasn't got anything inherently protecting from that same mechanism to happen. I'm not sure what the solution is. maybe it's more a mental model of not isolating single functions in separate crates. say. what if percent-encoding, http, h2, httparse weren't loosely related crates but instead part of one single library?
It doesn't have to be if you allow other crates to implement some api and if none is installed the Cargo.toml must specify a package.version
Not everyone disagrees that this is a bad thing, which is probably why it wasn't mentioned. If you want something mentioned you should write a post!
Sure, my point is that there's a lot of design work here, and nobody has done that work.
I see that some implementors of the `Add` trait modify the `self` parameter. For instance, `String` does this: impl&lt;'a&gt; Add&lt;&amp;'a str&gt; for String { type Output = String; #[inline] fn add(mut self, other: &amp;str) -&gt; String { self.push_str(other); self } } Whereas the `Add` trait does not specify `mut` for the `self` parameter of the `add` function: pub trait Add&lt;RHS=Self&gt; { type Output; fn add(self, rhs: RHS) -&gt; Self::Output; } Why is `mut self` allowed where `self` is specified?
Although I enjoyed the read, this is exactly the kind of answer I wanted to go for. Due to Rust's strict stabilization, a lot of these missing features got quite a bit of polish before they came out and, coming from a world or C/Java libraries, Rust's crate-wide documentation is far above average. I'm quite certain that getting those last few core missing features in will result in the kind of adoption that we'd expect from a language as exciting as this!
I'm not disagreeing that there's something to be concerned about here but I don't quite follow what's wrong with the lodash example you mentioned. If all I want are a few functions out of lodash, how is it bad to cherry pick just those so the rest of the library stays out of my final compilation?
I would like to see a separation between problem statement and proposed solution (RFC). For example, GAC and HKT are, mostly, two sides of the same coin: they have different semantics, may fit different usecases, but they mostly attempt to solve *the same problem*. I think that the RFC process should be split: 1. A **problem statement** should be submitted, and refined with the help of the community. From then, a consensus should be agreed on how much *effort* the community is ready to expend to solve this particular problem; there is no point spending time on a problem nobody deems worth solving. 2. Then, once the problem is acknowledged and well defined, users should be encouraged to submit one (or several) **solution drafts**; exploring the design space. It is expected that drafts be merged, subsumed, etc... and from these drafts should emerge a **RFC**. This is somewhat similar to the idea of **Tiered RFCs** and I think such a direction is necessary. Specifically, I think we should be deliberate about: - which problems we agree need solving, - how much effort we are willing to spend on solving them -- especially from critical resources such as the team in charge, - and whether any draft solution is likely to fit within the effort expenditure *and* be good enough. That is, be ready to say "No" (doesn't need solving) and be ready to say "Not Now" (other priorities), and design a process that wastes as little time as possible from the community before an early decision point (No/Not Now/Worth Exploring) is reached. --- For a counterpoint, the *Graphics Proposal* is an infamous proposal in the C++ community. A whole group of enthusiasts toiled and toiled for a couple years on a 2D graphics proposal, with mild statements from the Committee ("needs work") to finally be denied inclusion ("not a good fit"). Saying "No" is difficult, and it becomes more and more difficult as more effort has been invested (Sunk Cost Fallacy and empathy), so it was very brave of the Committee to say "No" after so many years... but it would have been better to say it earlier! The process should be deliberate in making saying "No" easier to avoid such waste of effort and good will.
The way I look at it is this: * Rust itself provides (non-green) OS threads. * Libraries like `threadpool`, `crossbeam` and `tokio_threadpool` provide a way to have green M:N threads. Depending on the library it might not QUITE pretend that you're getting real green threads, but in all of them you give it M things to do and it schedules and runs them on N OS threads. * Channels can be used basically anywhere. * async/await, and futures in general, is an orthogonal programming tool for writing async code, basically by defining tasks that can be paused and re-entered. You can execute those tasks on either a single-threaded runner or a multi-threaded thread pool.
&gt; ...so the rest of the library stays out of my final compilation It sounds like the motivation here is some sort of thrift: savings of compilation time? If the end result is an ecosystem full of single function crates, would you actually end up with faster builds? I have no intuition here, but I wouldn’t be surprised if the answer is no.
I don't think you are, but just to be clear: are you still hoping to use `crates.io` infrastructure? At the point you're defining a Git tag, you should only be worried how people are consuming your package -- you've chosen Git as your method of distribution. Cargo supports repo/tag combinations fine like this: depend_package = { git = "https://some-repo", tag = "v0.1.0" }
That's a way of looking at features that I hadn't thought of before, and I quite like it. It also mesh well with the idea of *additive* features. For example, I remember learning Java in school, and then discovering `Stream` when touching Java again for the first time after 10 years; this is less a language feature than a library feature, but it is *additive*, so I'll roll with it. The main thing about *additive* feature is that they do not obsolete existing features or APIs; you can still return `List` in Java, and it is meaningful to do so, not everything *has* to be a `Stream`. The same applies, I think, to async/await, ATC, placement new or const generics. They are additive. Of course, they may require some extra learning, however they are localized to APIs within certain domains: you are not required to learn them to write Rust code, and many APIs will indeed not use them, so that even if you do not know them you can still be proficient in Rust. There are limits, certainly, and writing servers without knowing async/await is likely to become difficult as all frameworks adopt it... but even then, just like `.clone()` solves many lifetime issues for beginners, a few `await!` will make the code work, if not optimally. ATC and const generics will be even more localized, and placement new even more so.
In a dynamic environment like JS it makes sense to only import code that is used, since it is hard to strip that code out at compile time. In a language like Rust, “dead code elimination” will strip out any unused code in optimised builds, so there’s no need to split up packages to reduce final binary size.
Does anyone happen to know how they are using rust? Or what is involved in using this for a rust project?
`mut` there isn't part of the type (written out fully the function type would be `fn add(mut self: Self, ...)`); it's just preventing the lint against modifying `self`. Think of it like the difference between `let` and `let mut`.
It’s common to have git re-write the line endings, so it’s sort of an edge case. I use the RLS on Windows daily and never ran into this bug for this reason.
I'm trying to avoid all the update version commits just to change the version in the Cargo.toml.
Thanks. I was thinking `mut` was part of the type. Also that it could lead to unexpected behavior; but now I see it can't because `self` is consumed by `add`.
My solution was to do an octree search, with a priority queue to always explore the nodes that are in range of the most bots (this guarantees correctness even with local maxima). While some inputs could cause performance issues, it ran in a few milliseconds on my input. It was fairly easy to code, but I got stuck on calculating the intersection of a cube with a bots range until I realized it was easy to find the point in the cube closest to the bot by “clamping” each of the bots x, y, and z values to be within the cube, and comparing the distance from the bot to that point to the bots strength. I could have optimized further (at the cost of more space) by storing the bots that were in range for any given cube to avoid unnecessary work when subdividing, but it ran fast enough so I didn’t bother. I think this was a fairly common solution based on some comments in the solution thread, and I suspect it was the intended solution since it didn’t involve any advanced techniques, just 3-d binary search and a little geometry. 
I suspected as much. Maybe I'll take a stab at it.
"Constructive" is a euphemism for "popular opinion". I'm not saying it's a deceitful euphemism - the promotion of unpopular opinions tends to disrupt groups so they can't go on *constructing* whatever they were working toward - but it's an important one to understand.
Why would anybody object to this?
I suspect you might be right. The challenging part of selecting the technology is that it hits on many of rust's strengths yet also hits on its achilles heel which is windows integration.
Git does rewrite line endings, but I think the most common configuration on Windows is to have it rewrite to CRLF line endings, since it's the default on the platform. So I don't agree that it's an edge case. Line endings is almost the first thing you'd think about when making something cross-platform, and I shudder to think what more subtle cross-platform bugs are hiding in RLS.
I haven't had dead code elimination work out very well for me in other languages so I wasn't considering it in this example. Looks like I need to spend time getting to know how DCE works in rust. 
Thanks. I'll take a look.
“Simplicity” in various forms. By the responses in this thread, maybe sentiment has changed enough to make it viable.
Cross posted to Twitter from reddit. That's why.
I believe they built the fuzzer in Rust?
Well, [here's a very reduced example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d95af692d2dc020a10a227ed43557fc5) that still shows the same error. However, I have absolutely no clue why this isn't allowed - this seems to me exactly like one of the popular examples of what NLL were supposed to allow. However, in your case there's a workaround - you can change the function signature for the error to have `'a` lifetime instead of borrowing `self`: impl&lt;'a&gt; Lexer&lt;'a&gt; { fn peek(&amp;self) -&gt; Option&lt;Token&lt;'a&gt;&gt; { ... } ^^ you probably missed this one, Lexer::next has correct lifetime } impl&lt;'a&gt; Parser&lt;'a&gt; { fn parse_item(&amp;mut self) -&gt; Result&lt;AstNode, MyError&lt;'a&gt;&gt; { ... } ^^ fn parse_subitem(&amp;mut self) -&gt; Result&lt;AstNode, MyError&lt;'a&gt;&gt; { ... } ^^ } This way your signatures make a bit more sense - the lifetime of the error is indeed tied to the lifetime of the parsed source, not the parser itself. And this change also makes your code compile.
Thanks. An electron alternative is a consideration. One thing that gives me pause is that it uses MSHTML (IE10/11) . I just heard a rumor that Microsoft will adopt chromium for its next browser core. Do you think this might affect this particular approach? I'm using my crystal ball and trying to predict what Microsoft may deprecate.
Hm, I have that set up that way, yet didn’t run into this bug. Odd.
One problem with doing this is that git's tags are mutable, where as cargo's versions are completely immutable. 
That does seem odd. Maybe you're using the nightly version where this is already fixed?
Yeah, I’m not totally sure. I guess at this point it’s not really worth investigating...
The idea that documentation is an “entrypoint” is very odd, IMO. Often good technical documentation requires that the writer really understand the system being documented, how it’ll be used, etc.
Aren’t functions that aren’t used removed by LTO on release builds anyways? This sort of thing shouldn’t dictate how our crates are put together - that should be based on ergonomics and it’s a pain to have to add a bunch of crates, and increase compilation overhead
Contrast this issue with the C/C++ alternative: dependency management sucks so much no one uses it, so we either reinvent the wheel or bloat the standard library. If you have a great dependency story, it's going to be abused. When that happens to packages you like, make a PR to replace the dependencies internally or use a different package. This is something we can all complain about or actually do something to fix. Custom registries and clones of crates.io with more stringent upload guidelines may also help. 
I just want the version in the package to be autogenerated from the tag during cargo package. The version in the package would be exactly as a version in a package is today after that. It's just something that simplify things when building releases in a build system such as Jenkins.
FWIW, most bundlers for JS are designed to also perform DCE where possible - enabling that is a not-insignificant reason for the design of the new module system in ES6. The lodash micro-packages are a bit of an anti-pattern even in the JS world now, although still necessary for historical reasons.
Cargo isn't a complete build system so each "project" contained by a crate has to be either a library (static or shared) or an executable. That said you've got two options: either use separate crates for each lib/bin target _or_ add multiple `[lib]` or `[[bin]]` sections to your Cargo.toml and manually add the correct source files. [Here are details](https://doc.rust-lang.org/cargo/reference/manifest.html#the-package-section), but that can get a little unwieldy if the additional targets are more complicated. If you have non-trivial build artifacts (that require post build steps) you may want to roll your own build script in Python/Bash/whatever or use Cargo plugins like `cargo-make` or `cargo-just`. 
Opinion warning. There are 2 interesting questions in testing design. They are on the tester or project architect if using example based testing and more built in if using generated testing. 1. What inputs are worth testing? Do you mostly want to test the happy path, wear your users are mostly going to be, or do you want to test corner cases, where the bugs are mostly going to be. Not enough happy path, and CI is green but Bug reports of broken users. Not enough corner cases, and CI is green but you just introduced a nasty (security) bug. To much of both, and CI take to long to run. 2. What outputs are interesting? To strict and you have a britl test; a test that starts to fail even though the functionality has not changed. To lose and your just wasting your time, the test will pass even though you broke the code. Property based testing like proptest or quickcheck, allow you to specify a distribution of interesting inputs and pare it with specific assertions. This is intended to be used to make fairly targeted pares. (A number parser should always succeed if the input is a string that matches the reg "\d{1:10}") This gives a lot of control. Thus fairly naive sampling over a small number of samples is adequate. So it can be run in your normal test/CI setup. If you make your distribution broad and your assertions general, then you are going to have to increase the runtime, but you will be exploring more corner cases. You may also start to wonder if you could come up with a more complicated sampling strategy, one that does not run functionally identical inputs so often. Fuzzers are exploring that end of the design space. They are testing programs that take arbitrary bytes as arguments and panic if something goes wrong. They use a copy of that program that can output info on what parts of the code were used. Running it thousands of times the fuzzer tries to learn its own distribution of what inputs are "interesting". Computers are fast and surprisingly smart, they have been know to overtime find out that "all the interesting inputs have a correct hash value" for example. So they tend to do a good job at finding unknown unknowns, bugs in corner cases so corner that you wouldn't have thought to write a (property) test. Of course just like you can use a property testing library in a brod fashion, you can make more targeted test programs to hand to the fuzzer. You could take the arbitrary bytes and return if they don't match the regex, and assert that a number parser success otherwize. A Lot of the interesting work is on the border, run a set of operations somehow parsed from the arbitrary bytes on these two different hashmap libraries, and panic if the results are not the same.
I am curious if someone knows this. Related. If I have async/await that works with Futures, and I have a thread pool that can handle Futures running on a bunch of different threads whose lifetime is static, what advantage would "green" threads have? I mean, I've got my async IO, I've got my processing being shared amongst a small number of dedicated processing threads - what more efficiency can I squeeze out?
I've used [cargo workspaces](https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html) to treat several related crates as a single project.
A Cargo.toml defines a package, that contains one or more crates. Cargo has a workspace feature that lets you create groups of more than one package.
Thanks! That's roughly what I gathered. Nix partially advertises itself as a useful development tool, where you can use setup different profiles for different projects to have all dependencies, etc. in place without conflicts. My impression is that alt provides a more agile interface for this- you don't have to wade through the Nix syntax to set up and play with a simple environment. Depending on how you feel about Nix, it might be worth looking into integrating alt (or a clone of it) with Nix such that alt acts like a prototyping tool for Nix. I think this could be valuable.
Ok this makes sense, its basically a function pointer to a whole loop instead of just the expensive function. You say you can be generic without a concrete type here? How would that work? Appreciate your help btw!
I recently refactored my project into multiple lib and bin projects using a cargo workspace and so far it's worked out pretty well. One of my projects even uses another as a build-dependency and not just a regular dependency. The whole workspace is in a single repository and I use IntelliJ IDE which doesn't have any issues with the multiple project workspace setup.
Can you [create issue](https://github.com/intellij-rust/intellij-rust/issues/new) for this on github or provide sample code to reproduce the problem?
There’s more in depth discussion here: https://www.reddit.com/r/rust/comments/7z5z6h/dead_code_elimination_in_rust/?st=JQ8CPYHN&amp;sh=66a7d6cb
Well, I spent the last week looking into that, and my conclusion is that the most important part is missing; full sourcemap support. Without that, you can't debug Rust code in its runtime environment, meaning that you're not going to have a great time with real projects (rather than Hello World demos, which already run fine). Before that's working properly (including variable inspection, which doesn't work with wasm at all right now), everything else is just toying around. I talked to the author of [wasm-dwarf](https://github.com/yurydelendik/wasm-dwarf), which seems to be the most promising start, but he also said that sourcemaps don't work at all right now, and that he was busy with the holidays and stuff. I'll follow up in around a week.
Oh damn that’s awesome. I’m actually doing research with Kensler now! Had no idea that he made this. I’m really looking forward to seeing the graphics ecosystem evolve for Rust. One thing worth looking at: Ray Tracing in One Weekend by Shirley if you want to get more into it. He’s got three books in the series, and after that you can probably graduate to PBRT
&gt; Web Assembly front end should be built ENTIRELY with a Rust toolchain. NPM should have no place in the future development of Web Assembly based front end. Rust programmers should not even have to know what Javascript is. I think the inverse is true: Javascript programmers should not have to know what Rust is. I don't think that "WebAssembly-based frontends" (presumably meaning a web page with zero Javascript?) are the 99% use case. Going into the future, there will certainly be more heavyweight applications ported into the browser that predominantly use WASM (and hopefully Rust), e.g. games, creative tools, and so on. Absolutely, Rust's toolchain should be perfect for these apps. But most people don't need serious systems machinery to make their website. I would bet it's far more likely that Rust's niche is in accelerating key parts of a Javascript application, either by accelerating popular libraries (React, jQuery, etc.) or by replacing small hot-spots in the user code base. The most promising future for Rust is as C is to Python, emulating the success of libraries like numpy.
cc discussion of the pape: https://www.reddit.com/r/rust/comments/84ipuf/angora_efficient_fuzzing_by_principled_search/.
The 3rd party tool called cargo-release can automate some things like this for you. Maybe not in exactly the way you describe, see if it works.
Didn't see an answer so I opened an issue https://github.com/AngoraFuzzer/Angora/issues/10
Yeah, when I looked at it last night I realized it had fallen behind quite a bit. Thanks for actively developing such an important project!
I agree in spirit but disagree in magnitude. I find `reqwest`'s dependency tree perfectly reasonable: it has some you-really-don't-need-to-write-this-more-than-once things like `base64` and `mime`, and some absolutely indispensable things that do the actual useful work like `serde` and `tokio`. Having 20 direct dependencies is not unreasonable, especially when most of those dependencies are in one of the two above categories. Perhaps more importantly but less visibly, `reqwest`'s dependency tree is *shallow* and *narrow*: It seldom is more than 3 levels deep, and where it it it's usually because of crates doing their own internal fragmentation (you can assume that when `tokio` depends on `tokio-core`, `tokio-fs` and `tokio-reactor` they'll all work nicely together) or because it's using a quite foundational crate that's using a lot of other foundational stuff and puts a fair amount of work into its own robustness (such as `regex` or `hyper`). Looking at [the output of `cargo-tree`](https://gist.github.com/icefoxen/67bc22d79c4db8bad6bf903d9c919005), you see the same stuff again and again: `log`, `bytes`, `futures`, `rand`, `libc`, `memchr`, etc. I entirely agree that subdividing crates too far is silly, and have ranted about it in the past. See the `imag` crate for an example. But going too far the other way is just as unhelpful. Javascript is what you get when you go too far on the fragmented side, but C/C++ are what you get when you go too far the other way: you have large bulky libraries like Boost that try to do everything, or you get people constantly rewriting their own code, badly (where's the standard hashtable in C?), or you end up with people using kinda awful hacks just 'cause they're easy (single-header libraries). Neither of these extremes are good. Relying on basically-untrusted and un-warranty'd third-party code for everything is risky, yes, and having a larger surface area of dependencies increases that risk. But the solution is not to try to put the genie back into the bottle, it is to try to build better tools, processes and cultures to reduce the risk. Having one project write and maintain its own internal regex code benefits the security of that project. Making the `regex` crate more robust and trusted, in code and in the people maintaining the code, benefits the security of *all* projects that use it. I think that part of the goal of Rust's stdlib, and one it does *fairly* well, is to strike some sort of balance. Again, you try to throw too much into stdlib and it gets messy, a la Python where you have `urllib`, `urllib2`, and `urllib3`, and you try to be too minimal you have Javascript where you don't even have a standard string formatting function (and I nearly had a seizure from rage when I realized that was the case). The goal of Rust's setup is to have the best of both worlds: you have the necessary stuff in `std`, you have a number of foundational-but-external stuff such as `regex` and `rand` that everyone needs but which don't really need to be part of std in the eyes of the Rust team (because they don't need unsafe code, compiler support, or system-specific support), but you also have people making these foundational-but-external stuff from the start along with a good package system, so that these things get established (I can't imagine anyone seriously writing, or using, a different regex crate unless they have a *real good* reason to). So, you have to strike a balance. `tokei` lists `percent-encoding` as 22k lines of Rust code, `h2` as 22k, and `httparse` as 5k, so I'm not sure I would call any of these things even close to libraries that could be replaced by a single function. Everyone's opinion will differ, but to me the balance so far looks *mostly* okay.
It's not even Achilles heel. .net and windows/office are like glove and hand. Nothing else stands a chance no matter how good. 
&gt; especially from programmers new to Rust At least in this respect, a lot of what you need to know to write bleeding-edge, crazy-high-performance Rust code, is the same as what you need to know to do the same in C or C++. And it's no coincidence, because all of those languages are designed for zero-overhead abstractions over the hardware. So a lot of these intimidating performance experts were experts long before Rust existed, and we don't have to feel bad :)
Many things have/will help JavaScript develop further as a language. However, the likelihood of having to write actual JS is becoming less and less.
Great point
I dunno about that. I use a number of high-function web apps at work. Things like the Atlassian suite, Gmail, etc. If I open a dozen tabs with these things, my browser memory usage can climb north of 2GB. These apps start up slowly, and I often find myself waiting for the browser to catch up after a click. Don't get me wrong - JavaScript is not slow. But standard data structures in JavaScript have a lot of overhead (Node has added some stuff to address that, somewhat), and GC is convenient - but there are trade-offs. So rewriting these in something that has a smaller download package, a smaller in-memory runtime footprint, and runs at near assembler speeds (and has power consumption similar to C - good for phones) might be a very good thing. Yeah, you still have to deal with the DOM, so I don't know how far this goes. The DOM may dominate the performance and power usage. But for these big honkin' apps, it seems like something like Rust may be just the thing we need to get to the kind of experience we'd expect from a native app. I could be totally off on that, but it sounds like a solid argument on paper. :) 
&gt; But most people don't need serious systems machinery to make their website. If you're talking about the use of JavaScript to add blinky animations to web pages you're right, but there's a large environment for serious JavaScript development out there these days. Everything that uses React, Vue, Ember, Angular etc these days is ripe for a transition to Rust.
This is excellent! Thank you. I'll try to get it working
It seems to be a known issue that will be fixed with NLL 2.0 (Polonius). https://github.com/rust-lang/rust/issues/54663
Here's a nitpicky distinction that might not be exactly what you're asking about, but I'm not sure: &gt; Does Rust (maybe with tokio?) support green M:N threads like Go? To be fair to Go, the answer here could be "mostly no". Async IO and the async/await syntax are intended to solve many of the same problems that green threads solve, so there's definitely some overlap here. But what is it that really distinguishes green threads per se? I think the main distinguishing feature of green threads is that you can write code that "looks serial" but that doesn't actually block an OS thread. And Rust doesn't have that property. For example, if I have a serial-looking (or just "regular looking") function in Rust like `fn curl_google_dot_com() -&gt; String`, that code is _definitely_ going to block an OS thread until the request to Google is finished. To avoid that overhead, once the async/await stuff is stabilized, I'd need to mark the function `async` and call it in the context of some async executor like Tokio. Which is exciting and efficient and reasonably ergonomic, but still a visible difference in how the code gets written. In Go on the other hand, if I have `func curl_google_dot_com() string`, that function doesn't block a thread. Instead, the goroutine machinery under the covers (and lots of low-level, goroutine-aware networking code in the standard library) will magically free the current OS thread to go do other work, while my function waits for google.com bytes to come over the wire. The difference between synchronous and asynchronous code is completely hidden, or maybe it's more accurate to say that all Go code is asynchronous. That's a huge simplification for someone learning the language, and I think it's contributed a lot to Go's rapid growth. Rust will probably never have an async story as seamless as that, because (as far as I know) it's not possible to do it in a zero-overhead way.
To be honest, I am not sure that Rust is well-positioned to replace JavaScript here. There's a lot of sense in leveraging Rust/WASM to handle heavy-weight tasks, or for correctness, but there's a lot of other languages that are *easier* to use (garbage collected) and also compile to JavaScript or WASM: Dart? Typescript? C#? If you plan on making a 3D game, or some such application, I see Rust making sense. I have serious doubts that 90% of the web's JavaScript is complicated enough to warrant jumping ship, though, when other languages with GC are so much more familiar and have a bigger ecosystem.
At work we maintain a set of functions acting on an AST that is used both on the golang backend and the typescript frontend. Having to replicate all new functionality in a consistent way on both sides is a recurring pain point. If Rust allowed us to write the data structure manipulation code once and use it from JS in a straight-forward manner, that alone would warrant a rewrite.
Exactly
But does it fit on postcard?
A cargo workspace maps pretty well to a Visual Studio solution in my opinion. A crate would map quite well to a .vcxproj and a Rust module would be a C++ namespace, kind of. The big difference is that crates can contain crates, while vcxproj projects can't contain other vcxproj projects, as far as I know.
I think there are two potential benefits to a green thread approach. One is that there's less syntax and fewer concepts for a beginner to learn, because async code doesn't "look different". Another is that -- since interruption points get inserted automatically by the compiler -- there's less chance that a programmer might accidentally block an important thread with some sort of long-running computation like `find_giant_prime_number()`.
Maybe you should try this on a slightly larger example. I think you'll find it falls into a mess of either nested promises or using `async`/`await` and just catching exceptions anyway. It's not a pattern that's unique to Rust either. Haskell's `Maybe` does the same thing. For both of those languages though, they do it so that the type checker helps catch errors at compile time. Here, you're just handling runtime exceptions differently while mimicking the simplest case of pattern matching.
Anonymous function type will be a concrete type here (so you don't need additional marker types), i.e. loop will be generic not over custom trait `LoopBody`, but over `Fn(..)`.
I just started learning Rust a few days ago and I'm going through Rust-101 [https://www.ralfj.de/projects/rust-101/part03.html](https://www.ralfj.de/projects/rust-101/part03.html) at the moment. At the end of that section, it asks: &amp;#x200B; Building on exercise 02.2, implement all the things you need on f32 to make your program work with floating-point numbers. &amp;#x200B; I'm wondering, is there a way to generically write a \`read\_vec\` method that can handle both \`i32\` and \`f32\` input from the user and store that into a \`Vec\`? &amp;#x200B;
I know but still by simply wrapping the nulllable or undefinable things helped reduce my front end teams simple type check mistakes 100% I believe that's something and about it being not to be unique to rust, rust is my first language with this way of pattern matching and I just wanted to tell that I learned it from rust I think as my rust experience goes deeper I'll find myself better and better at the other languages I use in production, rust and golang thanks for your comment I really appreciate any feedback from the rust community 
I think your best bet would be to use TypeScript and turn on the strict null checks.
Lots of good stuff in here! One point: &gt; There should just be a single side w/ a single interface. It’s important that they remain separate so that a malicious crate’s docs can’t steal your crates.io login token.
Oh, good to know, thanks. But that only requires 2 domains, not 2 interfaces, indices, styles, entry points, etc. 
Shipping a whole garbage collector with your web page is quite a bit of overhead, which most web developers try to avoid.
It all depends on your printer’s dpi and the font size...
More importantly, does it fit on a crab?
&gt; Ray Tracing in One Weekend by Shirley &gt; He’s got three books in the series Dang, that's some weekend! Thanks for the recommendation, though. 
&gt; Shipping a whole garbage collector with your web page is quite a bit of overhead, which most web developers try to avoid. I thought the goal was to, ultimately, to be able to make use of the JavaScript/DOM GC from within WASM? At this point, it'd probably be less overhead for using the browser's GC than for shipping a good allocator.
Yes, but that doesn’t exist yet and will probably take a long time to be implemented.
isn't the one of the ideas of rust avoiding null so you may not accidentally forget one null check and blow things up?
I'm not super experienced with Rust, but I think they avoid it everywhere, including the standard APIs. And if one does show up, the compiler catches it when you try to use it. In Javascript, you have to deal with null coming from the environment/browser APIs and third-party libraries. I think TypeScript's strict null checks should be able to catch anything at compile time that could possibly null and force you to add a check to ensure that it isn't.
&gt;making a copy of some data by mistake because I forgot to use a reference That's really not easy to do. Most objects in the standard library that implement Copy fit into a standard register. Types that allow the developer to copy them, that do not fit into a register usually implement Clone. 
I'm just scratching the surface with learning rust (background in php, javascript and python mostly) but I love these little demos. I've written a bunch in other languages over the last 20 years but haven't tackled it in rust yet. I'd love to try to take this demo and try to speed it up with some multithreading. I guess what i'm trying to say is: Thanks for doing this and giving me a couple of busy nights with a new toy to play with.
Right you can define the generic function: fn run_loop&lt;B: Fn(u32) -&gt; u32&gt;(..) But you can't extract the monomorphized function from that like you did before with: run_loop::&lt;Bmi2Body&gt;; You would need a concrete type to replace ?: run_loop::&lt;?&gt;; Maybe i'm thinking about this the wrong way. 
In the mean time, though, compiling to JavaScript (or a restricted subset, with type hints), already allows much of the benefits of WASM, though: - writing in another language: Dart, Typescript, ... - and benefiting from the host browser's GC. I guess the elephant in the room, there, is that debugging points at generated JavaScript; unless source-maps also work for JavaScript, not only WASM?
As an aside, I'd still like to see crates.io and docs.rs hardened a little more against HTML injection from the crate docs.
Flagged comments on discourse are no moderator action. Everyone can flag.
The use statement and the module system changed a bit in the Rust 2018 edition. It looks like you are using that. In the 2018 edition, you need to start imports to your current crate with `crate::`. See the edition guide for more details. 
Or just remove the line about the 2018 edition from Cargo.toml :-)
I get the general idea of inexpensive copy of registers vs. clone of larger objects (likely heap allocated) being cheaper to reference, this is the same in C++. But let's take the example of Vec3 in the code, which is 4 floats / 12 bytes : it does not fit in a register (let's ignore SIMD for the purpose of that discussion) yet is fairly inexpensive to copy (probably 2 MOV on x64). In that case it's not always clear already when is best to copy or not, even in C++, to maximize performance. Now looking at some code like: let pos : Vec3; let dir : Vec3; let len : f32; [...] let v : Vec3 = pos + dir * len; Depending on whether std::ops traits are implemented on &amp;Vec3 (ref) and/or Vec3 (value) it seems that this code might not compile because (dir \* len) generates a temporary intermediate Vec3 (value) which requires an std::ops::Add&lt;Vec3&gt; impl. But even assuming that this trait is implemented, is it better to take a reference to that temporary to get the compiler to call std::ops::Add&lt;Vec3&amp;&gt;? let v = pos + &amp;(dir * len); Or will the compiler avoid any extra copy when chaining std::ops::Mul&lt;f32&gt; -&gt; Vec3 and std::ops::Add&lt;Vec3&gt;? In short, is there a way to shoot yourself in the foot? I found myself writing some quite verbose code to presumably avoid any extra copy, without being sure if that was really needed or I was doing the compiler's job: let v = &amp;pos + &amp;(&amp;dir * len); Incidentally I find all those operator overloading quite verbose; isn't there a better way that several lines of code to implement an std::ops trait for each argument type pair (LHS and RHS) and their ref variants?
Thank you both, I simply removed the line in Cargo.toml 
Joke aside it almost surely doesn't currently. That was not really my goal, though that can be another interesting exercise. In C++, aside from standard minifying tricks like single-letter function and variable names, one would use the preprocessor (#define) and type aliases (typedef / using) to shorten the code. But I don't know any trick like this in Rust. And those std::ops traits are massively more verbose than operator overloading in C++, so I don't know how I would approach that problem. Any suggestion?
It will be a slightly different initialization, you will have something like this: `fn get_loop(body: impl Fn(u32) -&gt; u32) -&gt; impl Fn(u32) -&gt; u32 { .. }`. I *think* monomorphization and inlining should kick-in here without any problems, but it may be worth to check.
This is outside of cargo's capabilities. You could have some buildscript or `Makefile` to update the manifest from `git describe`. There is also [`built`](https://crates.io/crates/built), which allows you to record the current git tag / commit id. It does not change the crate's "official" version, though.
I am also curious about trying to multi-thread that code. Though if you're not familiar with Rust I'd strongly suggest starting with something single-threaded; there are already many traps to fall into coming from another language without adding extra ones :) I spent over half of the time on that project on Rust-specific issues.
[https://youtu.be/HpuZDLBCykM](https://youtu.be/HpuZDLBCykM) XDXDXD &amp;#x200B;
Getting in over my head has been my learning style. Get completely confused, figure out some small issues, see the bigger picture. Rinse and repeat. Worst case scenario, I don't make any progress over my long weekend and try again some other time :)
My dream: Rust backend, HTML&amp;CSS frontend with minimal JS/WASM :)
Sourcemaps also work for JavaScript. TypeScript in particular maps almost 1:1 to JavaScript and is easy to debug.
Honestly there's a lot of web applications that I'd rather not use Rust for; things like plain old data websites, news pages, etc. I'm not sure if it is just the field, but sometimes I'm more interested in speedy development than performance. I think if we can get C# to have a great WebAssembly story then it would be better positioned for general web development. I'd still like the ability to write front ends in Rust though, but I would not be surprised if it would stay a niche language for that use-case. The great thing about WebAssembly is, "why not both?"
Atlassian and the new gmail are just poorly engineered. There's absolutely no technical reason for their poor performance (as demonstrated by the old gmail!). Also, the DOM is absolutely the bottleneck for web performance for anything that isn't really computationally heavy. JavaScript will happily chunk through 10k records in a couple of ms. Updating that in the DOM is another matter entirely.
This raises a good question: what makes existing webapps slow? Rather than speculate, let's look at empirical evidence: http://mp.binaervarianz.de/JS_perf_study_TR_Oct2015.pdf &gt; This paper presents an empirical study of 98 fixed performance issues from 16 popular client-side and server-side JavaScript projects. We identify eight root causes of issues and show that t inefficient usage of APIs is the most prevalent root cause. Furthermore, we find that most issues are addressed by optimizations that modify only a few lines of code, without significantly affecting the complexity of the source code. What do they find is slowing down apps? &gt; The most common root cause (52% of all issues), is that an API provides multiple functionally equivalent ways to achieve the same goal, but the API client does not use the most efficient way to achieve its goal. ... The most commonly misused APIs are reflection APIs, such as runtime type checks, invocations of function objects, and checks whether an object has a particular property. The second most common root cause is inefficient use of string operations, such as the above example. This raises the question, given these are the most common performance issues, what is the right way to address them? The authors claim the fixes are relatively small, and the fixes _work_, so perhaps we need easier performance profiling instead of a new language. Or even if you want a new language, both of these seem either universal (API misuse) or solvable with a statically-typed, garbage-collected language (eliminating reflection). If anything, that suggests switching to ReasonML/Elm/etc., not to Rust. Don't get me wrong, I'm a big fan of Rust and think it has a lot of value to bring to the web, but I think we should be careful as a community in understanding what roles Rust actually ought to fill.
The recommended way is the [sealed trait pattern](https://rust-lang-nursery.github.io/api-guidelines/future-proofing.html#c-sealed). As seen in serde_json for example: [`trait Index`](https://docs.serde.rs/serde_json/value/trait.Index.html).
Or one could just use \`find\`: \`\`\` find -type f -exec sd 'from "react"' 'from "preact"' -i {} \`\`\`
Yeah returning a closure does work. It does need to be boxed I think because impl in return position can't return two different types, so it needs to be a trait object. Thanks!
Perfect! Thank you!
Not quite sure how far along you are in learning Rust overall, but I'm thinking that an `enum` would work here. ```rust enum IntOrFloat { Int(i32), Float(f32), } ``` Then you would have a `Vec&lt;IntOrFloat&gt;` in which you store either an `Int(num)` or a `Float(num)` depending on which `parse` is successful. If you don't know about enums yet, then this might be jumping ahead a tad.
This is not a post about Rust, but I'm posting it for two reasons: - There are two Rust mentions that portray Rust as a potential C++ alternative in the Gamedev space (and this is by a Unity developer!) - There were a lot of Rust 2019 comments about "avoiding too much cognitive load". This blogpost is a great example of where we probably never want to be.
&gt;The fragmentation of the rust crates into smaller basic units has somewhat started, and I wonder where it will end. Indeed. As a piece of anecdotal evidence, I recently began trying to contribute to a non-rust project. As I was building said project, I noticed it actually uses a single(!) Rust project, for which it invoked Cargo to build it. Well, turns out said project had 3-4 dependencies, which had dependencies, which had dependencies, which had.. So, I ended up waiting 30 minutes for all the required packages to get build for the 1 included package in the non-Rust project itself. Rust compilation took 85% of the time compared to everything else, simply due to a shitload of packages depending on other packages and forcing me to build them. That's not cool, really. I understand the reasoning behind it (less code duplication, have vertain packages hold the 'best' version of x feature implementation), but it just leads to every package on the earth depending on another.
I'm familiar with Unions in C++ so this sounds like exactly what I need. Thanks!
I wouldn't like to assume that my habits are universal. But I almost always use docs.rs or other online resources unless I'm actually without internet connection. So usability improvements to those would trump making the offline experience simpler for me so long as there was still a decent offline option (especially as cargo doc could presumably be made to run the server automatically anyway). On a side note: with `cargo doc`, is there any way to generate/view docs of dependencies while the current crate is in a broken state? That's often when I need to look something up, but IIRC the command will fail if the current crate can't be built.
Rustdoc needs to compile a crate to generate docs, so no :(
At this point it's implicit C++ is at a place no language ever wants to be.
That is not a good idea. Edition 2018 will be the standard going forward. Just do what /u/sunjayv told you and add `crate::`
Hugely successfull and running on billions of devices all over the world? 
It‘s not the base adress but a register (offset 0x10) containing the flag which indicates whether enough time has passed. It doesn‘t work on my device yet therefore i have neither made the code pretty nor written about timers, i am sorry for this mess 😅
\*sigh\* I knew someone would bring that up and contemplated adding a disclaimer.
good point. there are some good counter arguments here, and I haven't really pin pointed exactly what my problem is. having taken part of nodejs journey from "yay it's lightweight - nothing like java" to the utter bullshit of babel and webpack, I only have a gut feeling. today I tried out "acme-client" and the project seems semi abandoned. one the one hand, this crap pulls in an ancient reqwest lib which doubles up pretty much the entire tokio tree of something like 40 deps. on the other hand fuck yeah!!! rust that handles multiple versions of the same code in the same project. rock and hard place. why is this reqwest + tokio stack so big? I wouldn't have cared much if it was like 4 deps. I'll go back under my bridge until I articulated my problems. 
It’s cool! There certainly are downsides. I personally believe the upsides outweigh them, but I think both are reasonable.
[This](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=df0a2e8b6c22040a63c85518269887a2) compiles, and I think does what you want.
Interesting; i think the issue that I ran into is that I approximated the intersections by drawing a bounding cube around a bot and seeing whether that cube overlapped the given bounding box. I think that this was my issue as it was not accurate enough, and it looked like areas would appear to bee promising and then turned out not to be. Perhaps I'll try and work out "proper" overlap like you say and it'll suddenly work :) 
I was under the impression that old editions would remain supported forever and would also get new additions as long as these cause no breaking changes. Did I misunderstand? Sure, there won't be `async` in the original Rust edition, but if you don't need that, then why bother with 2018 and its confusing new module system? Most documentation that you'll find on SO and such will also use the 2015 syntax.
gfx-hal is the standard interface for the various gfx engines. In theory, it will allow you to make your own like Opengl API and have that translated into Vulkan, Metal, DX12, or even OpenGL, all depending on which engine you select. The benefit of this is that you can get cross platform support
So I've gotten further thanks to everyone's help here and while it compiles it doesn't actually do anything at runtime: [https://github.com/cholcombe973/libnfs/pull/12/files](https://github.com/cholcombe973/libnfs/pull/12/files). I suspect this is because there needs to be a thread to run the async portion of libnfs. 
Wow, that range code is ooogly!
I'm trying to write a parallelized word count script for practice, but I'm struggling a little wrapping my head around how threads and lifetimes are supposed to work. &amp;#x200B; Essentially, I have the following bit of code: &amp;#x200B; \`\`\`rust pub fn count\_words\_parallel(string: &amp;str, threads: usize) \-&gt; HashMap&lt;&amp;str,usize&gt; { let result = HashMap::new(); let chunks = get\_chunks(&amp;string, threads); let mut handles = Vec::with\_capacity(chunks.len()); &amp;#x200B; for chunk in chunks { handles.push(thread::spawn(|| { count\_words(&amp;chunk) })); } &amp;#x200B; for handle in handles { if let Ok(counts) = handle.join() { // I am aware this isn't optimal, keeping it simple for now. for (word, count) in counts { match result.get(word) { Some(original) =&gt; result.insert(word, original + count), None =&gt; result.insert(word, count) }; } } } &amp;#x200B; return result; } \`\`\` &amp;#x200B; In essence, I'd like slices of the input string to be keys in a HashMap that is built up across separate threads - where each thread covers different sections of the string. Ideally, this would be possible without using additional space and without invalidating the original string (so that the function can be re-used easily without compromises). To me this means that the HashMap keys must have the same lifetime as the original string - since otherwise the parent thread could drop a string that is still in use. However, no matter how I arrange my lifetimes, Rust keeps me from doing this. &amp;#x200B; I take it that I don't quite understand how lifetimes work. For reference, the exact complaints: [https://hastebin.com/felibuwohu.txt](https://hastebin.com/felibuwohu.txt) (hastebin for brevity). &amp;#x200B; Would someone mind explaining to me why this doesn't "just work", and what I should do to accomplish this (assuming it's possible)?
&gt;Web Assembly front end should be built ENTIRELY with a Rust toolchain. NPM should have no place in the future development of Web Assembly based front end. Rust programmers should not even have to know what Javascript is. &amp;#x200B; I agree with this wholeheartedly!! As above, so below. &amp;#x200B; To be honest, I've never encountered a systems language community (C, Go, Python) sort of "handoff" an entire problem area to another language (JS), specially when there's nothing inherent in the systems language (rust) that prevents a developer from tackling that specific problem space (WASM frontend) in an elegant, performant and secure manner. &amp;#x200B; Sure, the prowess of JS on the web is undeniable. However, it doesn't mean that things need to be or continue to be this way or for that matter, for the rust team should make roadmap decisions based on the current state of JS or its commercial viability. &amp;#x200B; Let's think about what this is saying for a second? To new developers the message is clear: If you want performance, reliability and productivity use Rust as long as it's not WASM frontend, for which you'll need to learn Javascript. Seriously? &amp;#x200B; Last but not least, WASM is not just for the web. A nomenclature issue, I know, but it's not just about the web. &amp;#x200B; Bottom line, let Rust devs write code in Rust. No NPM, no JS... just rust. &amp;#x200B;
I have to wonder how much of that code is "demonstration" code of other C++20 features. I certainly don't understand what is going on with the preamble, but reading the comments there was a few "This uses one syntax for constrained lambdas in C++20." in there that make me think this wasn't a demonstration of what you should do, but rather what you could do. Sort of similar to some rust tutorials I've read that dive into making macros right off the bat. Yes, you can make macros in rust that do some interesting things, no you shouldn't do that needlessly.
Yeah, this is often called [tree shaking](https://webpack.js.org/guides/tree-shaking/) in the JavaScript world.
I don't think there is a cross platform solution. There is, however a windows specific solution. That is, https://crates.io/crates/winapi WinAPI can do all the mouse/keyboard interactions. I'd suggest you google things like "Win32 move mouse" and "Win32 send key". From there, you can get cozy with all the win32isms. It generally ends up not being too hard to do, just not super portable.
Not ideal but I'll take it. Thank you!
That was Java's tagline! :D (did they count Java Card in there? probably…)
[#[serde(skip)]](https://serde.rs/field-attrs.html#skip) is what you’re after I think.
With this being basically the only thing trees do better than hashmaps, I was surprised that implementations of these structures are so rare - at least in other languages. It's very nice to see a solution in Rust.
I don't think it's directly possible, but you could try making a helper struct that is the same as the first except with the "ignored" fields removed. You derive the desired traits for that helper and then would manually implement the trait for the "real" struct that just immediately delegates the call to the helper. &amp;#x200B; As for your second question I think it would probably clone the entire backing \`NDArray\`.
Keep in mind that lambda and serverless, while fashionable, are really [not that great](https://arxiv.org/pdf/1812.03651.pdf) right now.
I don't see how separate in 2 structs help. In some moment I need to put :Box&lt;Rows&gt; and get to square one. &gt;As for your second question I think it would probably clone the entire backing \`NDArray\`. The NDArray is a local cache. The questions was about how clone Box&lt;Rows&gt; (meaning a restarting of the iteration?)
I appreciate being able to use Rust over JS; Cargo over NPM; avoid Webpack/transpiling/config; use Rust's tests over configuring Jest. Etc.
The proper intersection method is definitely important. I first tried the bounding cube approach, switching to the exact calculation for singular points, but it didn't work because the input was constructed in such a way to be antagonistic to that algorithm and the search space was way too large with false positives. &amp;#x200B; I spent a bunch of time trying to come up with an exact intersection algorithm and explored some overly complicated approaches (some of which worked) before thinking of the simple approach. The idea that eventually led me to this solution was the following mess of logic: * First check if the bot is inside the cube (easy) * If it's not, check to see if any of the corners of the bot are in the cube (also easy) * Otherwise, if there is an intersection, it must be the case that one of the planes of the cube intersect the bot's range. I still wasn't sure how to do a plane-octahedron intersection, but given the orientations, I figured that it was probably true that one of the edges must also intersect. * To test an edge, either one of the endpoints would be in range, or the edge extends beyond the range of the bot in both directions, in which case I can project the bots position onto the edge and test that point. I coded this up, and sadly it didn't work (which I later discovered was due to a bug in my subdivision logic), but the projection idea led me to the simplified approach where I project the bot's position onto the surface of the cube.
Does anyone think it would be possible to link a Rust frontend and backend in a way that streamlines passing data? Let's say you're using a backend (Django, Flask, Rocket etc) to host a database... to get the data to the frontend, you have to create a data struct (eg Django model) serialize, pass as a string, deserialize, and pass into a separate, but equiv JS data struct. It would be lovely to have some abstraction that eliminates this step, provided you use rust for both server and client.
&gt;I was under the impression that old editions would remain supported forever and would also get new additions as long as these cause no breaking changes. Yes, that is correct. &gt;then why bother with 2018 and its confusing new module system? But this isn't. The new module system is actually less confusing now. Try looking into it again. I think this is definitely an improvement.
Check out the [derivative](https://github.com/mcarton/rust-derivative) crate and see if that enables you to do what you want. You can also just implement \`clone\` yourself manually. Still, this might be a hint of a potential code smell, and maybe we should revisit the design - I don't think I'd expect a struct like \`Generator\` to support cloning as it is currently designed. I also wouldn't expect to call \`clone\` and have it not clone everything. If a struct was large and complex enough, I probably wouldn't even expect to \`clone\` it at all. I'm not as familiar with your code, but I might propose a \`struct GeneratorHandle\` which points at a Generator somehow, and then have \`Iter(GeneratorHandle)\` in your enum. Or maybe a \`GeneratorIter\` struct, and then add a field to \`Generator\` like: \`\`\` As u/otherwun was suggesting, you probably want create an inner struct, maybe exposing it directly, something like: \`\`\` pub enum RScalar { Rows(NDArray), BTree(BTree), Range(Range), Iter(Generator), } &amp;#x200B; &amp;#x200B; Alternately, you can create a wrapper inner-struct around \`Box&lt;rows&gt;\`
Haskell is already doing this. It would def be cool
Hopefully I won't be gone forever! :)
C++ ranges are a great example of why the Rust community shouldn't worry too much about turning into C++ - its almost all *just* a library. Thanks to the comprehensive metaprogramming capabilities of macros (particularly proc ones) you can already write something exactly like this, with syntax almost identical to how the C++ looks. There is a lot more pressure in the C++ space to move paradigm-style functionality into the STL and standard because it lacks a module system and integrated package solution like Cargo - having to specify third party dependencies in your build system (a la CMake) or include them as git submodules to statically compile them in is a much greater pain in the ass. Considering how much debate there was over whether async should have been promoted into the language core at all (there were a lot of arguments to include the generator semantics but leave the convenience impls to macros) I wouldn't worry about the Rust core developers just haphazardly adopting something like a functional range library into the language proper either. Its just too easy to make it a crate. That being said, this isn't just a "hah, look how smart we are mortals" situation. A lot of the fear about complexity in Rust in part might be attributed to how many crates there are, how useful and pervasive they are, and how the number of them keeps growing. With C++ libraries are often *just* C++ and there is active resistance to using Boost or Qt because of how huge they are as a dependency, but those are the only real major "core" libraries you depend on writing C++. In contrast you trivially reach for chrono, or serde, or failure in almost every project you make in Rust. The language itself isn't made more complex for it, but if everyone is using the same set of crates as a baseline because the core language is kept lean new users still have to learn all those third party crates to get anywhere. Which comes back to the fear of core language complexity - because its multiplicative. If Rust syntax gets more complicated it makes every one of those crates you need to keep familiar with all the more hard to keep your mind wrapped around. In C++ you are going to add in a library using ranges in 2022 and have no idea what this syntax is for. In Rust you are going to start running into the Python problem soon™ where some of your dependencies are async and some aren't, and how you mix them will dramatically impact your performance and just general sanity. 
Been out of the loop for a while, seem to have forgotten the basics, would appreciate any help! How can I best resolve 'does not live long enough' error for the following simple function to read a file line by line and store each line in a vector as tokens. use std::io::prelude; use std::fs::File; use std::io::{BufReader,BufRead}; fn read_file_line_by_line(filename: String) -&gt; std::io::Result&lt;()&gt; { let file = File::open(filename)?; for line in BufReader::new(file).lines() { let tokens : Vec&lt;&amp;str&gt; = line?.split(',').collect(); println!("{:?}", tokens); } Ok(()) } It errors out at `line?` with 'temporary does not live long enough.' I tried adding a declaration and tried using a temporary variable outside the loop to store line per iteration. Error persists. Help!
Ah thanks. I thought gfx-rs was another library.
Writing beautiful SCSS and Rust to create web sites would be my absolute dream. Even if I had to do a little html or css I would be okay with that.
Cross-posting my comment from Hacker News. Here's an implementation that is equivalent to the modern C++ example (playground link: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018): use std::time::SystemTime; fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { let t0 = SystemTime::now(); let triples = (1..).flat_map(|z| (1..=z).flat_map(move |x| (x..=z).filter_map(move |y| if x * x + y * y == z * z { Some((x, y, z)) } else { None } ) ) ); for triple in triples.take(100) { println!("{:?}", triple); } let elapsed = t0.elapsed()?; println!( "{}", elapsed.as_secs() as f64 + elapsed.subsec_nanos() as f64 * 1e-9 ); Ok(()) } It takes about .376s to compile in debug mode, about 0.491s in release mode. This was after warming caches; the first run took about 2.071s, of which a large portion was probably loading the compiler and standard library. In debug mode, it runs in 0.047586s, in release mode, 0.002304. I was pleasantly surprised to see this is actually better on the build times and debug build performance, given that those are two often cited sore points in Rust. I would also say that while this is a little bit noisy, it is more readable than the proposed C++20 version. "1.." looks more like a range starting at 1 than "iota(1)" does. There's an actual "if" statement in there. In fact, while Rust doesn't officially have generator/coroutine support yet, it is available in nightly builds for the implementation of async/await. If you use the nightly compiler, enable the unstable features, and wrap an adapter type around Generator that implements Iterator, you can write: let triples = IterGen(|| for z in 1.. { for x in 1..=z { for y in x..=z { if x*x + y*y == z*z { yield (x, y, z) } } } } ); It's expected that at some point in the coming year or so async/await, and probably the underlying Generator feature, will be stabilized, and I presume the standard library will implement the Iterator trait for appropriate types of Generators (though there is some bikeshedding about the details of that). Rust doesn't have generators yet, so this is only really fair to compare to the generator/co_yield example in C++ (which is also proposed but not yet standardized). I'd say Rust's syntax compares favorably to that example; the ranges are more clear than the traditional C-style "for" loops, there's native tuple syntax, and it's just be "yield" instead of "co_yield".
This greatly confounded me until I used the `let _: () =` trick to get the compiler to say the type that comes from `.lines()`. I used the following: fn read_file_line_by_line(filename: String) -&gt; std::io::Result&lt;()&gt; { let file = File::open(filename)?; let mut lines = BufReader::new(file).lines(); let _: () = lines.next(); //expected (), found enum std::option::Option let _: () = lines.next().unwrap(); //expected (), found enum std::result::Result let _: () = lines.next().unwrap().unwrap(); //expected (), found struct std::string::String With knowledge that it is a `Option&lt;Result&lt;String&gt;&gt;`, I found a solution: fn read_file_line_by_line(filename: String) -&gt; std::io::Result&lt;()&gt; { let file = File::open(filename)?; let mut lines = BufReader::new(file).lines(); while let Some(result) = lines.next() { if let Ok(string) = result { let tokens : Vec&lt;&amp;str&gt; = string.split(',').collect(); println!("{:?}", tokens); } else { //handle this if you want to } } Ok(()) } &amp;#x200B;
Hi y'all, I hope someone finds a use for this! If you do, please let me know what you want it for, or if you have any suggestion for the API.
Impressive work! :) 🤩😍🤙
Hey u/dreamer-engineer, thanks and sorry for editing my post while you were responding. I modified it because I realized I had run into this before and the way I got around it was with the `let temp = line?;` line. But that seems far from idiomatic, so my question then becomes what is the best way to do this? Thanks for your solution. I'm trying to write this as a part of component that will be further used for parsing out really large csv files. It's a learning exercise so I don't want to use csv parsing crates.
&gt; where progress is very blog post Wow. Such graphics. Much pixels.
It works fine because if some type `F` implements ```Fn() -&gt; u32``` then `&amp;F` also does
Hacker's profile: [https://steamcommunity.com/profiles/76561198353942802](https://steamcommunity.com/profiles/76561198353942802)
It sounds kind of reasonable but it's still confused of me how this passes type checking.
wrong subreddit
Agreed!
So, a multi-page app? Seems good to me
your playground link is broken btw. and I also really hope generators land at some point.
Head over to [https://www.reddit.com/r/playrust/](https://www.reddit.com/r/playrust/), this subreddit is for the Rust programming language.
`Fn() -&gt; u32` is not a type, but a trait, so it's no more surprising than e.g. `fn call&lt;T: Debug&gt;(t: T)` being callable with both a `u32` and a `&amp;u32`.
Honestly I completely agree with the IDE support part of this post. I was pretty excited at the start of 2018 for rust IDE support but ended up extremely disappointed.
I was... not aware these files actually had anything in them?
`Fn` is a trait meaning that calling the function requires no external environment other than parameters. This means it's pure (has no side effects) this means that calling an `Fn` type behind a reference is still safe. Your function takes a value of type `F` which implements `Fn` and you give it a reference to a `Fn` closure which still implements `Fn` as in my first paragraph. 
[removed]
Thanks, you cleared it up perfectly!
&gt; rust &gt; cargo &gt; crates Would this have fooled a filter AI?
Maybe this could have an “enhanced mode” where it deletes the file. Or changes your desktop icon layout so rapidly you can play Pong with the TPS reports sitting on your desktop.
Were you surprised it has beaten range-v3?
I was looking at the Guessing Game example of [chapter 2 of The Book](https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html), and when the dandom number generator is added they ommited the line `extern crate rand;` but get a compilation error with rust 1.31.1. Is this a bug on the book? I'm new to Rust (trying to learn after getting annoyed with Fortran)
Maybe it would be good to have an intro to what they are on the README? `.DS_Store` (Short for Desktop Services Store) files describe the contents of the folder they are in. They do more than list file names as my example shows. They can fully describe the layout of the finder window that renders them. They describe the background of the window, and the placement of each record (file/dir) in the window. When you install an application on a mac, and you drag the app to the Applications directory, that UI is based off of a `.DS_Store` file configred to look like that! Hopefully that made sense :P. Anyways, they are good for analyzing what is in a directory. There are some security implications. For example, if you can find a `.DS_Store` file on a web-server, you may learn about other files in that folder, which could be a security risk. I noticed that Rust did not have a library for this, so I spent my holiday week off (well, when I wasn't gaming) to write this. Thank you for your interest :)
Maybe it would be good to have an intro to what they are on the README? .DS_Store (Short for Desktop Services Store) files describe the contents of the folder they are in. They do more than list file names as my example shows. They can fully describe the layout of the finder window that renders them. They describe the background of the window, and the placement of each record (file/dir) in the window. When you install an application on a mac, and you drag the app to the Applications directory, that UI is based off of a .DS_Store file configred to look like that! Hopefully that made sense :P. Anyways, they are good for analyzing what is in a directory. There are some security implications. For example, if you can find a .DS_Store file on a web-server, you may learn about other files in that folder, which could be a security risk. I noticed that Rust did not have a library for this, so I spent my holiday week off (well, when I wasn't gaming) to write this. Thank you for your interest :) 
Wow, I just watched office space 2 hours ago, so reading this comment made me think TPS reports were a real thing that people did haha.
r/lostredditors
The `while let` and `if let` version seems the most idiomatic to me because it clearly shows the types involved and lets you handle the error
Whoops, you're right, fixed.
(I think you're thinking of the non-trait type `fn`: `Fn` is a trait for closures that take their environment by `&amp;`, that is, closures that only need shared access to any captures.)
Closures passed to `thread::spawn` (and therefore, any closed-over variables like `&amp;chunk`) must be `'static`. Your code can't guarantee that (since you allow arbitrary `&amp;str` and not just `&amp;'static str`, so it's not allowed - Rust isn't really able to figure out that you `join` all the threads before the end of the function, and if any threads outlived your function their references would potentially become invalidated, so it prevents this. You may be able to use something like `rayon`'s `par_iter` for this; if you want to keep the `thread::spawn`ing, you'll need to find a way to pass that data to the threads, probably by using something like `Arc`.
Lmao youre right
😂😂😂
[They are.](https://en.m.wikipedia.org/wiki/TPS_report)
Desktop link: https://en.wikipedia.org/wiki/TPS_report *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^227879
As a Linux dev who works with Mac devs, those files are infuriating.
Maybe https://github.com/autopilot-rs/autopilot-rs
Huh. I never realized that's where that information was stored. Neat.
Having used TypeScript and Rust, I often feel the inverse is actually true. I get it that TypeScript has types. But it's not like compiling say Python to JS. It really is JavaScript through and through, and in the early days TypeScript was even based on various proposals to add types to JS (just in case it happened)! When I go to use Rust I often miss a lot of the advanced type stuff that you can do in TypeScript. These are all interconnected, but the main points ... * No null pointer exceptions. I know in Rust we use Option instead of null. In my mind this shifts the potential for an error rather than fixing it. Instead of dereferencing a null pointer, you can now unwrap `Option::None`. In TypeScript `null` is a distinct type, and the compiler will force you to prove a value is not null before you dereference it. * Value based types. Why can't I do `fn increment( n : -1 | 1 ) {`? * Flow based programming. Why does the Rust compiler allow this? `if option_value.is_none() { option_value.unwrap(); }` * Finally in Rust there are a few caveats and pain points around complicated type declarations in functions, and around the use of the `type` keyword. Like there are times a declaration will work in a `where` clause, but not if you inlined it. In TypeScript these pain points don't exist. It's grammar for the type system is much more uniform than Rust's. There is a lot more that TypeScript can do with it's type system which Rust doesn't come close to. However a lot of it only makes sense because TypeScript compiles to a dynamic language, and doesn't have to care about how it's going to lay it out in memory. For example I can say *'object x is a subset of y'*, which is fucking invaluable for mocking data for tests.
Thanks for a more clear explanation. Let me introduce a new scenario below which never pass compiling: ```rust fn main() { let hello = || 32; // error here call(hello); } // take a reference here fn call&lt;F&gt;(f: &amp;F ) where F: Fn() -&gt;u32{ another_call(f); } fn another_call&lt;F&gt;(f: F ) where F: Fn() -&gt;u32{ println!("{}", f()); } ``` So it's pretty clear that `F` is something like @DiscombobulatedYou5 said &gt; It should be read as "can be called and returns a u32" And of course I cannot use a closure directly since the parameter `f` should be the reference. But what confuse me is that both a `value` (is that called so in Rust?) and a `reference` satisfy type checking when the signature is `fn call&lt;F&gt;(f: F ) where F: Fn() -&gt;u32`. Is there any documents memtioned this rule? 
&gt; I if anything start to become uncivil, I will be banning people too. why do you want to create more subchannels for Rust?
So the reason this example doesn't compile is because `call` takes "a reference to something which implements `Fn`" but `hello` is a closure. A closure is a value. References are also a value which is why the first example worked. But you've specified that `call` takes a reference to a value so that level of indirection *must* be made. To make this example work you'd either: * Change `call` to take `F` not `&amp;F`. * Pass `&amp;hello` to call to give that level of indirection. Here's the documentation for `Fn` that we should've linked earlier: https://doc.rust-lang.org/stable/std/ops/trait.Fn.html
I think that the (now deprecated?) crossbeam scoped pool docs give a good explanation for what I think is the issue. https://docs.rs/crossbeam/0.3.0/crossbeam/struct.Scope.html If this is in fact the problem, you can also check out [scoped-pool](https://github.com/reem/rust-scoped-pool) or other scoped threadpools.
I become enlightened at once by your explanation below: &gt; A closure is a value. References are also a value which is why the first example worked. the documentation also gives me : &gt; Additionally, for any type `F` that implements `Fn`, `&amp;F` implements `Fn`, too. And I found a similar discussion https://users.rust-lang.org/t/why-use-type-parameters-as-the-standard-closure-passing-idiom/7824 Thank you anyway :)
You're very welcome
Reminds me of the ScotT Meyers talk at DConf: “the last thing D needs”. It’s all about how the last thing D needs is to be so complex, that they need people like him to go on speeding tours explaining it. I feel the same way about rust. I constantly worry it’s getting too complex 😂
There is a [Rust implementation](https://github.com/libp2p/rust-libp2p) of the [libp2p](https://libp2p.io/) network stack. It's still in development though. It's used by projects like [IPFS](https://ipfs.io/).
why not raft? 
Doesn't go have some wasm support you can use, or will be able to in the future?
Oh god, this syntax… I could have nightmare reading it at night. Please, Rust team, keep the syntax as simple as possible!
Step 1: We use some Rust machine learning to classify posts in r/rust based on whether they were intended for r/rust or r/playrust. Step 2: We invent a new game. We try to come up with a post that acts both as a r/rust post *and* and a r/playrust post. Whoever fools the AI best wins. 
There is a golang library that does this so maybe you can use that to implement a rust version if that interests you
yes, we were working on the [Issue](https://github.com/libp2p/rust-libp2p/issues/648) which posted more than one month ago, but didn't fix there, so he started his own library, which I addressed. It is not a standard implementation yet, and we are working on it. wondering if anyone else also has interests in it, need more input.
A couple things to start you off: https://hacks.mozilla.org/category/dweb/ https://www.reddit.com/r/DWeb/
Did you think that those were just created to annoy you?
Another two points are an issue for rust: &gt; […] compile times are important, &gt;Non-optimized build performance is important, Rust has an issue with both. 
Oh I must've misunderstood, I thought you were asking if we knew of other p2p projects than the one you linked. But you were rather calling for contributors/collaborators, right?
You can extract one of the architectures from a fat library using the `lipo` command: lipo libfoo.a -thin arm64 -output libfoo-arm64.a (Make sure to use `-thin` and not `-extract`; the latter, confusingly, still outputs a fat file, one which happens to only contain a single architecture.) If you want the final result to be a fat binary, you'll have to start by having Cargo build the Rust code separately for each architecture; you can then use `lipo` to combine the outputs into a fat binary: lipo -create foo-arm64 foo-armv7 -output foo This is really something that rustc ought to support natively, though.
Yes, we need some feedback, but its difficult to get it around, because of rather fewer rust as well as distributed system developers here. sorry for letting you misunderstand. 
thanks as well &amp;#x200B;
I hear the Rust community is shit. Is it true that you get offended over everything? 
That C# syntax is pretty, LINQ is really cool
But that's a mutable reference.
Yeah, that SQL—like style really has its merits for certain problems. Those are pretty rare at my work though, so we use the method syntax for LINQ way more often. Pretty cool that you can choose.
This crate could help https://crates.io/crates/enigo
If you know the old system right now, then the new module system *is* more confusing. Perhaps you can learn the new way in a few hours or a few days, but if you don't need anything from the 2018 edition, why would you? Currently the incentive to switch mostly takes the shape of receiving downvotes on reddit when talking about using the original edition. If you use the original edition you can also be compatible with older versions of `rustc`. I actually *like* having to declare `extern crate`. I did *not* find the old module system confusing. I think the new paths are weird. It seems that OP (like me) is more familiar with the original edition. Why shouldn't they keep using it? What difference does it make to anyone else?
Rust has type aliases and `macro_rules!`, so the same tricks work, more or less. You could probably use the latter to simplify the arithmetic ops for `Vec3`.
&gt; and share their Proof Repositories and feedback with us Is there already a [centralized] list of Proof Repositories? How proof repositories are supposed to be discovered?
It sounds like I went through some of the same process - I also did bounding cube and the nswitched to exact position, but like you found that it was no good. Last night (and fixing it this morning) inspired by your earlier comment I reworked my solution to use a bounding box that splits into 8 each time, and measured exact overlap (using what sounds like the same approach you took to find the square in the bounding cube nearest to the Bot and then count distance from that), and it works great! Takes about 35ms now, down from 110 with the growing-sphere solution. I'm sure I could get it faster but I think I'll move on now :D
i like the rust subreddit because they are indifferent to my opinions on the impending mayocide for this i believe they are not offended by everything, if that answers your question
&gt; A big chunk of this effort was achieved through great tooling like rustfmt and clippy. I think actually a big part of the reason for the common style is because syntactically Rust is similar to C, Java, etc. and there are well developed style conventions in those languages — and for documentation, because *finally* we can use Markdown everywhere, instead of having to revert to some crude HTML for code doc. Standing on the shoulders of giants and all that.
Same code on stable with a bit of macro. A more comprehension list syntax is also feasible. https://github.com/TeXitoi/rust-mdo/blob/master/examples/iter_mdo.rs
That isn't really true — there are a bunch of tree structures that are more useful than segment trees. Some examples would be [priority queues](https://doc.rust-lang.org/std/collections/struct.BinaryHeap.html), [ordered sets](https://doc.rust-lang.org/std/collections/struct.BTreeSet.html) and [union find](https://en.wikipedia.org/wiki/Disjoint-set_data_structure), all of which I've used more commonly than a segment tree. (Although I guess union find is more of a forest than a tree) And I mean, sometimes your input data is already a tree, in which case trees clearly are useful.
My wish is a tinier executable. Compile speed or installation speed is not so interesting.
&gt; Step 1: We use some Rust machine learning library to classify posts in r/rust based on whether they were intended for r/rust or r/playrust. Then someone could make another program that's trying to fool this filter, à la [GANs](https://en.wikipedia.org/wiki/Generative_adversarial_network).
I smell trolls trying to test the water. Let it be known that though we strive to be a welcoming community, trolls aren't any more welcome here than elsewhere.
Is there bias in this paper — that it only looks at performance issues which have been *fixed*? Easily fixable problems are more likely to get fixed, hence by looking at only solved performance issues they are more likely to be looking at easily fixable ones.
From another perspective: scripting languages like JS are good for solving problems with, but don't necessarily encourage efficient algorithms or data management. Rust is quite a lot better at encouraging efficient solutions, with its lifetime restrictions and blend of imperative and functional code. Of course that doesn't itself mean we should encourage use of Rust on the web, though perhaps learning the language should be encouraged.
Well you can of course use whatever you want. It's just seems a bit silly to give up on so many cool new features (proc macro, async/await/, etc) just because you want to write `node::Node` instead of `crate::node`. It's not that drastically different :-) But to each their own of course. Glad your problem was solved.
&gt;welcoming community You see that is the stuff I am concerned about because what often is meant by that is community hostile to opposing viewpoints which imo is not welcoming at all. And that is kinda the vibe I am getting from Rust. Getting rid of things like Master/Slave terminology thereby interpreting something sinister into that standard terminology. I am left leaning I want freedom and I am concerned with issues of censorship as well as unjust and oppressive authority. Does that make me a troll?
&gt; No null pointer exceptions. I know in Rust we use Option instead of null... We simply don't use `Option` where we know a value is non-null. &gt; Value based types. This is a complex topic — as I understand it, contract-based programming has not progressed (far) beyond research languages, and involves a significant amount of annotation and compile time while still being unable to prove correctness in much other than trivial functions. &gt; Flow based programming. Rust doesn't auto-unwrap (like IIRC Kotlin does) — though you *can* use type deconstruction to do this: `if let Some(value) = option_value { ... }`. Personally I don't see much additional value in the case you mention — it's obvious to the programmer and would probably be picked up by Clippy, and it's not undefined behaviour, so no reason the compiler *should* complain. 
This is essentially a deliberation process for crates. I love the idea but do not underestimate the effort required to reach even a reasonable level of quality. Need some clarity on the review process. Why would every review be weighted the same, considering Rust expertise is so varied? Tyranny of the majority can rank low quality projects very highly (think Django). The most popular often doesn't imply the "best". Rubrics defining "best" will also be required. 
Priority queue is a heap, not a tree, and in my experience ordered sets are much better served by linked hash maps instead of trees.
This is essentially a deliberation process for crates. I love the idea but do not underestimate the effort required to reach even a reasonable level of quality. Need some clarity on the review process. crev seems to follow a "wisdom of crowds" convention where the aggregate reveals a useful score. Why would every review be weighted the same, considering Rust expertise is so varied? Tyranny of the majority can rank low quality projects very highly (think Django /s). Rubrics guiding a review process will be very helpful. Note that wisdom of crowds has been improved on by "wisdom of aggregate deliberations". This knowledge ought to be considered for crev: https://arxiv.org/abs/1703.00045##
I really like that the review system doesn't rely on a web interface, but is accessible via git. Though i'd like the review and status to be more granular. There are at least a dozen ways a program can be viewed (in)correct or inadequate: * unsafe code * malicious, but safe code (e.g upload env variables and files) * errors in application logic * unconvential use of target platform (e.g. shipping own foreign libraries instead of system libraries on linux) * build.rs scripts which connect to the internet * lasagne/spaghetti code, weak abstractions * xss in docs It strongly depends on what is acceptable or even anticipated by the end user. A verfified status alone doesn't reflect these properties. There should be at least guide lines for reviews. E.g. there was a thread recently on [red flags in rust code reviews](https://www.reddit.com/r/rust/comments/a7xswn/what_are_various_red_flags_for_you_in_rust_code/). Also decentralization: There should be support to define a list of trusted review repositories. Imagine QA in a corporate setting. They would want to have their own review repository, or at least a shared one with contractors.
Do I understand it right? You want to implement a cargo "addon" which verifies your project's dependencies. If you have "whitelisted" the author or if already trusted authors "whitelisted" the crate, the status changes to "verified". &amp;#x200B;
Hm. I'd like to stick to stdlib stuff for now, so I'll have to dig into Arc. A little annoying that there is no simple way to do this, but oh well.
I think you gave a few people chest pain with that title :-)
I use iCloud drive for my desktop and on my desktop I have loads of documents and images. I also have two Macs, one iMac and one MBP. On the MBP the files are more or less scrambled/stacked since there isn't screen space enough to show it like on the iMac. How is this stored/handled in those files?
That certainly explains it. Some kind of scoped threadpool is on my stdlib wishlist now.
“cargo new” should have set a key in your Cargo.toml, “edition = “2018””. Is it there?
There is no immediate relationship to Rust, so I have removed this post. If you think it is relevant, by all means reply to this comment explaining why it is so.
I found this post interesting, despite the "rant" aspect, because it wonderfully balances out: - Stroustrup's "Remember the Vasa". - Graydon's Rust 2019 "Limits to Growth". Both Stroustrup and Graydon are keen to remind us that growing the *language* too much causes a maintenability issue: each newly added feature has to be checked for interactions with every single pre-existing feature, after all. This post, however, demonstrates that externalizing functionalities also has a cost: inscrutable code, horrendous compile times, sluggish Debug performance, and I would add "Good luck stepping through in your debugger". My conclusion is that growing the language is a balancing art... and that the language team will probably need to become increasingly more selective as time passes.
Can somebody explain in layman's term the benefit of using this vs a fault tolerant database?
Prefacing your question with "I hear the Rust community is shit" is just being obnoxious, not "an opposing viewpoint". &gt; I want freedom Sure, but others want the freedom to participate in this community without being bothered by trolls, too. That's why we have moderators.
I changed it to better fit your language preferences but thank you for confirming my suspicion. And could you please define troll.
I am also worried about gaming. The problem with wisdom of the crowds coupled with anonymity is that a single user can create multiple (interlinked) accounts and drown out any negative review with a slew of positive ones. For someone who already trusts one of the negative opinion, this may not be a problem, but for a newcomer... well, in aggregate, the opinions look positive, so why not trust the majority? --- This is the reason why I'd favor an alternative approach where the trustworthiness of the users is integrated in the system rather than leaving it up to each user to vet reviewers one by one. I actually drafted an idea of creating "pre-existing" webs of trust where each participant accounts for a fraction of the total trust, and prevented gaming by having each "new" participant take the fraction they represent from their parent (so that the sum of all fractions is always 1). It's still a draft: [Weighted Web of Trust](https://github.com/matthieu-m/matthieu-m.github.io/blob/master/wwot.md), and there is no implementation so there may be glaring issues. Just reading the first few parts (Goal, Concept &amp; Implementation) should be enough to give a taste; the subsequent sections just go into details. *Note: dpc_pw already helpfully mentioned that an early example of what the common interactions (leaving a review, checking reviews, etc...) would be like could be useful; I haven't had time to design a command-line API on top, so it's still not there :/*
I like **Confidence** as the guiding theme for the next 3 years, though I am not sure it really captures the IDE work.
I think it does: confidence in the tools you use. I can't have confidence in what the RLS is telling me because I know it's incomplete, for instance :) 
thought provoking work
My plan is to use Nim for chily stuff like that, and for game dev C++ or Rust 
A heap is a type of tree, but fair enough with the linked hash map – I haven't really used those.
That's true. It's definitely easier to write efficient algorithms in Rust than JS. I guess my point was that I don't think efficient algorithms or poor data management are where (most) frontend code is struggling: frontend code doesn't often deal with large amounts of data anyway. Performance wise, most frontend code struggles with slow rendering. Or slow network calls (often due to a poor architecture or backend code). And sometimes, overuse of inefficient libraries (but that's not too hard to avoid). Rust isn't going to help with any of those.
You shouldn't change the version that much anyways
Not too familiar with tokio but I think that you can create a new thread and use the [single threaded runtime](https://docs.rs/tokio/0.1.13/tokio/runtime/current_thread/index.html#examples) to handle the future.
I agree with all of that apart from your mention of Jest. Every time I use Jest I thoroughly enjoy it, I actually wish testing in Rust could be that nice. 
I'm silently hoping all that will be used in the future is webasm + some sort of canvas + API for sound/accessability/etc. If you want to use SVG, include it in your webasm as a regular piece of code along with your application code. Same applies if you want a layout system like the latest CSS. I see no future in the web if only billion-dollar companies can make a decent browser. Not amount of features in fancy programming language can make implementing a compliant modern browser within the reach of normal groups of people.
I'm not an expert, but as I understand it, they're implemented at different levels of abstraction. Fault tolerant databases typically some kind of distributed consensus algorithm like Paxos or Raft under the hood to achieve fault tolerance (e.g. [tikv][1]), and their consistency and availability guarantees vary depending on the underlying protocol. You'd use this library if you needed access to the underlying protocol itself--for example, if your state machine is small and you can't afford the overhead of an entire database--but for most applications it's probably too low-level to be of any practical use, and you'd be better off using a more battle-tested database. [1]: https://github.com/tikv/tikv
Thanks!
Been porting my serial port webserver to actix-web. Basically plugging in a new library and ripping out old code. Once all the compiler errors we're resolved in the editor it simply just ran. Lack of null return types ( rust extensively result ) meant I didn't encounter a single NPE and all tests continued to pass. The experience is even better than Java a GCd language.
I learned Paxos first from our distributed systems course, so I'll have to read up on how Raft works!
Oh, I thought they were just there to delete :p
/u/dpc_pw I read through (both) READMEs and even watched the asciicinema video, but I still don't feel like I have a clear mental picture of how this all works in practice. For example, if I publish a review for a crate at version `x.y.z` and a new version of that crate is published, say, `x.y.(z+1)`, then what happens to my review? Is `x.y.(z+1)` now unverified? Your blog post here hints that reviews only apply to a specific version, but I can't say for sure. IMO, this question is really the crux of the matter, because its answer lies right on the line for what _trust_ actually means and whether the system of trust you've setup is something that folks will actually participate in.
My experience with Hest was never being able to get it working :(
I just think that it's great to see somebody furthering forensic when with Rust. You rock!
Strongly agree. Although this is offset by panic hooks that will output the 'expect` message in console, and compile-time checks.
Reference counting is lightweight and, if done well, not that much slower than generational GC. Kotlin Native and Swift use reference counting and would be a better fit for front end development. 
For others who wonder, it's apparently a [Mac OS](https://en.wikipedia.org/wiki/.DS_Store) thing.
The authors seem not to understand the general use-case for serverless. Or they project their own expectations onto what is offered (easy HPC) leading to disappointment. You don't use cloud functions for high performance or high efficiency. They are the best choice when it doesn't pay off and is not required for technical reason to maintain instances or containers. So the reason for using them is their ease of use and low cost for simple infrequent loads. Rust is a perfect fit for serverless.
Sure, but the question is how to handle communication between the runtimes.
A running example will help
"hostname: hackerman" Me too... Me too.
Next is a tool that will delete .DS\_Store recursively and unmount a drive, so that they don't show up in other OSes.
There was a talk about libp2p at rust rush a few weeks ago, not sure when video comes out.
I'm not sure everyone 100% agrees on this, but my impression is that the PGP web of trust model has never succeeded, despite decades of facing essentially no competition as a decentralized identity system. I think the main problem with it is that it requires substantial effort to use. In particular, it requires effort from _every end user_ to curate their list of trusted experts, rather than just from the experts themselves. It's possible that there's an inflection point where new users only need a "list of close friends" rather than a "list of trusted experts", but PGP never reached it. Every successful identity or review system I know of has been pretty centralized. Developing a new system for crate quality, and making that system totally decentralized, sounds like choosing to solve two hard problems at once. Would anyone be willing to write up a "this will succeed where PGP failed" gameplan?
Is there a reason why this should be rejected? trait Foo { fn bar1() -&gt; usize; fn bar2() -&gt; usize; } struct Baz; impl Foo for Baz { fn bar1() -&gt; usize { 4 } } impl Foo for Baz { fn bar2() -&gt; usize { 5 } } 
Note that I could still implement your trait using `fn private() -&gt; Private { unimplemented!() }`. Or if I know one of your types with a sanctioned implementation of the trait, I could just forward to that. The sealed trait pattern works because the "secret" part is something public *from a private module*. This makes it impossible for third-parties to name it at all, so they can't even pretend to implement it.
&gt; If Rust syntax gets more complicated it makes every one of those crates you need to keep familiar with all the more hard to keep your mind wrapped around. I think over the last year, Rust syntax, especially RFC-accepted Rust syntax, has only gotten simpler, not more complex. The reason for this is that I've actively been working to make it so. I think fears over complexity here are unfounded. &gt; In Rust you are going to start running into the Python problem soon™ where some of your dependencies are async and some aren't, and how you mix them will dramatically impact your performance and just general sanity. That's a legitimate concern; I think we should investigate some sort of (a)sync polymorphism, much like we need const-polymorphism, to achieve some code reuse here. &gt; Like.. constant functions. We just got those. Those are pretty fundamental and important and the community was still conservative enough to wait until this month to stabilize a basic form of them. The reason why `const fn`s have been waiting for stabilization for over 3 years was a) needing to do the implementation (control flow is still not fully done wherefore it's still unstable), b) we wanted to stabilize everything in one go but there were open design questions so that was untenable. Then I suggested that we approach things incrementally instead, some key folks agreed, and then we stabilized `min_const_fn`. I fully intend to rapidly extend the powers `const fn` has.
&gt; and probably the underlying Generator feature, will be stabilized `async` and `await` is on the path to stabilization, yes. But I don't know where you heard that generators are... they haven't even been RFC-accepted yet.
The biggest deficiency in frontend development is the poor usability of web workers. The available languages are not a big issue. Understandably, devs coming from proper languages cringe when being confronted with JS. However, I'm writing Typescript every day and it's in no way limiting my productivity or the correctness of the code. Performance and efficiency of single threaded WASM would be a welcome bonus but not that noticeable for small and mid-size applications. However, easy accessible and performant (within WASM and JS bridge) multithreading would be persuasive. As much as I wish WASM to come to mainstream as soon as possible - I've got a feeling that there's not that much momentum behind WASM - or maybe it's only the usually slowness when big players need to agree on a standard. Mozilla seems to be the biggest driver. The MVP is long ago ... 
"Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away." -- Antoine de Saint-Exupery
&gt; Maybe negative RFCs would be to strong, but instead a list of rejected features with links to the discussion is better? You can search the list of closed RFC in the rfcs repository; this should get especially easier over time as the `disposition-closed` label is applied to all closed or to-be-closed RFCs. You can further then narrow that by `T-lang`.
&gt; What's the best way to migrate to exclusively new Futures? You can use the [select](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.11/futures/macro.select.html) macro for that use-case. However I'm not sure whether it works together with tokio async/await. Maybe only if you use the futures-rs 0.3 compatibility layer.
FYI in case it wasn’t clear, all of the examples are things TypeScript supports.
No this is my biggest issue. pgp is meh, and while keybase is helping fix it, it's far from perfect. It's not that I don't see the value of something like cargo-crev, I just think it's gonna have the same issues as pgp and things that are already implicit in society: you just have to trust people won't mess it up for you or you do it all yourself
This looks like exactly what I was looking for. I'll have to go back and replace the Future implementations haha. Thanks for the pointer! 
Did my undergrad thesis partially on raft :) it's simpler and generally has some nicer properties. would recommend 
Well, you can always use channels (https://doc.rust-lang.org/std/sync/mpsc/).
I'd guess you would use a channel (or two if you want bidirectional communication) using futures::sync::mpsc::channel.
In this case you should use futures-channel (or futures-channel-preview) instead of std::mpsc because they are made for async environments
&gt; please define troll You already provided a good example.
&gt; It's not remotely evident to me that GHC is simpler than Rust. I think it's primarily that Haskell has a GC, allows for global type inference, won't distinguish between `unsafe`, `async`, `const fn`, has assorted `repr`s, does not allow for `μ`, makes things that are traits in Rust into types (e.g. `Fn*`, `Iterator`), that makes GHC Haskell an overall easier language. &gt; I wouldn't discount the complexity and number of corner cases involved in the various Glasgow Haskell extensions. This may be a pointless exercise, but if we're going to count all GHC extensions we also need to count all `#![feature(..)]` gates. &gt; Part of the reason (though not the main one) why they haven't been standardized is precisely because of how much complexity needs to be nailed down and formalized! It seems to me that the Haskell committee has in general quite more stringent requirements than Rust does; in particular, we sometimes take the attitude that "que sera sera" and stabilize even tho we know there are known issues. &gt; Even the (seemingly-and-probably-actually-)simplest ones like MultiParamTypeClasses or ScopedTypeVariables raise nontrivial questions. Sure; the type system related pragmas need more careful though, but I see zero reason not to stabilize `GADTSyntax`, `TupleSections`, `LambdaCase`, or similar syntax-only features. It seems to me that the only reason they haven't been stabilized is conservatism. I think there are many extensions in [Stephen Diehl's list](http://dev.stephendiehl.com/hask/#language-extensions) that could be made part of the report. &gt; As far as I'm aware, your own familiarity with Haskell is also significant (e.g. I see you commenting on ghc-proposals occasionally), Yes I was a Haskeller before being a Rustacean and I am still a Haskeller. &gt; which means I'm low-level confused about why our impressions could be so different. Can you hazard a guess as to why? Hopefully my clarification about syntax eases your confusion somewhat. I also don't know how much you read #haskell, but I think there are some quite conservative people who see writing in Haskell98 as a badge of honor. &gt; I don't follow GHC design discussions as avidly as I do Rust, but I am subscribed to ghc-proposals and have seen a few trac tickets and mailing list discussions over the years, and "golly, it's lucky all of this is so simple" is not the impression I got from them. I'm not saying that all extensions, in particular type system related ones, are simple.
Damn that code likes so sharp and readble. It amazes me how much Rust can look like an easy-to-use “scripting language” (ie, Python-like, Ruby-like), while still offering direct bare metal performance.
&gt; I guess being French, I know a lot about consistency, or lack thereof. It always seems like the French language has taken the "Exception that proves the rule" to heart, and every single rule has a list of exceptions. I would pity foreigners trying to learn French if I didn't have exhausted my store of pity for the French trying to learn French :( I tried learning French for 7 years, it never stuck... maybe perhaps because I didn't put in the necessary effort so I wouldn't blame your belle langue. ;) &gt; Consistency is one nice property of a language, and so are orthogonality and composability. These are all strongly related; a lack in consistency usually results in a lack of composability. And you often get consistency by decomposing syntax. For example, consistently applying the `p | q` patterns that we have at the top-level of a `match` arm gets you `pat ::= ... | pat "|" pat ;` and makes the overall language more composable. &gt; Pragmatically speaking, however, sometimes generalizing may really complicate the implementation Sometimes, but this is also an argument in the abstract. Being concrete gets us further in our conversation. Personally I find that more often than not, generalization simplifies implementation because you need to impose checks for the bits you are disallowing. One example of this is that in `const fn`, we need to impose assorted restrictions so that things are not possible on stable, and this requires code. &gt; one still has to weigh the costs and benefits even for changes which would increase consistency, orthogonality and composability. Don't worry, the language team always does this. Even when I could write in the motivation of an RFC that we are doing it purely for consistency and composability, I try to find motivations in real world code.
I screwed up and created a crate with the same name as a protected trademark. I highly doubt I have any users, so my question is: 1. Is there a way to rename a crate on crates.io? If so, how do I do that? 2. If not, what's the correct thing to do here?
I specifically raised the issue of extensions and academic looking libraries as something that makes Haskell feel unwelcome, so no, I didn't miss the word "reputation".
Minor nit: percent_encoding/lib.rs is 447 lines (including empty lines and comments), not 22000.
Thank you for proving every single suspicion I had of this "community". Don't worry about me runing your perfectly good safe space. I think I'll just stay as far away as possible from this.
Really lol
:tada: You are welcome; but also thanks to everyone else who helped! :)
I think the basics of Haskell (2010 report) are both simpler and easier than Rust. It's not surprising given that Rust forces you to think more about layout and memory. I think Haskell is especially easier if you've never programmed before.
&gt; But then add h: (f: A -&gt; B) -&gt; (g: A -&gt; B) and it’s not a new rule, but now it is way more difficult to learn, I just don't agree that higher order functions should make a language *way* more difficult to learn; Rust has them too and I don't consider any language in 2018 to be worthy of my time if they don't. &gt; While nesting/stacking concepts is not adding rules, and mapping is mapping whether you're mapping a value or mapping another function/mapper, that is the kind of thing that looks elegant for maths/theory(/Haskell) but can make things more difficult. It's not just about being beautiful on a mathematical level. Higher order functions are quite useful for getting shit done.
To be 100% clear I don’t think you’re arguing I’m bad faith, I just don’t think you’re correct.
You're right. I just figure that since `Generator` already works well enough for `async`/`await`, and it's a fairly simple interface, it could be proposed and stabilized reasonably quickly. The main thing it needs is integration with `Pin` so it can provide a safe interface, and it looks like the `Pin` work is progressing well. [Self types including `Pin&lt;T&gt;` have been stabilized](https://github.com/rust-lang/rust/issues/55786). I realize that there's going to be a bunch of bikeshedding about the `Generator` interface, but really, other than lack of `Pin`, the current interface is good enough for `async`/`await` and for implementing `Iterator`, I don't really think much more needs to be added.
One advantage cargo-crev has is its audience is rust developers, instead of everyone. 
Do you know why rustc can't (yet) be compiled to WASM? Do you know of any efforts or experiments in that direction?
Multi threading definitely sucks. My personal opinion is that the drive for powerful backends to serve the billions of people on the internet of the future efficiently will drive an incentive to make the front end using similar technology. Writing two language codebases really is just non ideal, I think Rust has the capability of maximizing resource usage and being ergonomic for simple front end web dev. We shall see!
&gt; Then I suggested that we approach things incrementally instead, some key folks agreed, and then we stabilized min_const_fn. I fully intend to rapidly extend the powers const fn has. Thank you so much for all your (and the rest of the teams) hard work!
Add -vvvv to your openssl request to get it to be more detailed. The most important thing is that you connect to the server using what is on the certificate. Easy mistake would be using it's IP address instead.
I'm not sure what you're trying to do, but I noticed this while trying to get py-spy to work with docker: &gt;A multithreaded process may not change user namespace with setns(). &gt; &gt;... &gt; &gt;A process may not be reassociated with a new mount namespace if it is multithreaded. [http://man7.org/linux/man-pages/man2/setns.2.html](http://man7.org/linux/man-pages/man2/setns.2.html) (so it's only pid namespaces that can be traversed using setns() in threaded programs). py-spy and pyflame are both single threaded and wrap their filesystem calls in a pair of calls to setns(). py-spy is also single threaded (I think) but uses `/proc/${PID}/root/${PATH}` and avoids calling setns() entirely.
Also "inlining will fix it up" is basically the motto of Rust abstractions, similarly to C++ metaprogramming. Even the language does this sometimes, e.g. by desugaring `for` loops into function call based iterator machinery.
I'm not sure if I can get any faster in this specific case but slack client app is on the roadmap so we will see soon :-)
&gt; Thank you so much for all your (and the rest of the teams) hard work! &lt;3! &gt; I've been migrating several of my crates and projects to use const everywhere I can, and I managed to completely drop lazy_static about 90% of the time already. Cool! Hopefully we can stabilize `let` bindings, destructuring, and assignments soon as well. :)
I think this is very cool, but I think for widespread adoption this needs to be integrated in a backend supporting a nice website where anyone can browse repositories, and see the reviews, perhaps with reviews still being written trough the cli. Ideally this would be integrated in crates.io.
&gt; and it's a fairly simple interface, it could be proposed and stabilized reasonably quickly. Maybe; but I think this discounts how much time agreeing to a design can take. ;) &gt; I realize that there's going to be a bunch of bikeshedding about the Generator interface Well also `static ||` and such things; I'm on the lang team and I wasn't even aware it existed...
Totally understood, *and assumed*. I equally don't think you're correct... ;)
&lt;3
&gt; You found examples where they do not, which is fine and good (I did say "almost"). Shall I go hunting for the examples where they do, that vastly outnumber them? I neither found nor hunted for these examples; I and others are actively working on improving consistency and reducing complexity in the language. ------------------ &gt; Shall I go hunting for the examples where they do, that vastly outnumber them? No need; here's a list of all merged T-Lang in the last year: + RFC: Unreserve `proc` + RFC: Keyword unreservations (pure, sizeof, alignof, offsetof) -- These are both unreservations; the complexity is negative. + RFC: Reserve `try` for `try { .. }` block expressions -- A keyword reservation; barely any complexity added in and of itself. Furthermore the keyword was intentionally chosen to be familiar and thus make the concept that the keyword is used for take as little complexity as possible. The actual RFC that introduced `do catch { ... }` was accepted much before this. + RFC: Tuple struct construction with `Self(v1, v2, ..)` + RFC: `Self` in type definitions allowing `enum List&lt;T&gt; { Nil, Cons(T, Box&lt;Self&gt;) }` -- These make `Self` work in more places making the language more consistent and overall easier to learn. + Amend RFC 2175 to support for loops and leading vert + RFC: Or patterns, i.e `Foo(Bar(x) | Baz(x))` + update ManuallyDrop RFC to reflect how the implementation now looks + Update RFC 0430 to allow underscores between numbers in CamelCase names -- A documentation RFCs; zero complexity. + Allow panicking in constants + Allow `loop` in constant evaluation + Allow `if` and `match` in constants + Allow locals and destructuring in const fn -- I'd personally say that these take away complexity by making knowledge attained from `fn` directly applicable to `const fn`s and therefore making the language as a whole easier to learn. + Unapprove placement RFCs -- Removes complexity by unapproving placement new. + propose if let guard -- We already have `if` guards on `match` arms, this simply brings `if let` guards to `match` arms; I'd say that this adds to orthogonality, composability, and it most likely simplifies syntax as well. + #[cfg_attr] expanding to multiple attributes -- Some minor complexity added. + Stabilise exhaustive integer pattern matching -- Some minor complexity added but which can be learned from diagnostics easily. + Deny the `overflowing_literals` lint for the 2018 edition -- Not sure; I'd say that this one neither adds nor removes complexity? + Add lint warning for inner function marked as `#[test]` -- Tiny increase in complexity. + eRFC: if- and while-let-chains, take 2 -- Unclear; from a learnability POV it removes a surprise that some users demonstrably have hit; I think it also simplifies syntax and if we extend it in the future it can also overall improve composability. This is also sorely needed to reduce complexity in the compiler itself. + Type alias enum variants -- Also unclear; I think overall it reduces surprises and makes things easier to comprehend. The following RFCs remain that I think are increases in complexity: + Support underscores as constant names + Union initialization and Drop + Allow non-ASCII identifiers A-non-ascii-idents + Re-Rebalancing Coherence + The optimize attribute + Introduce `#[do_not_recommend]` to control errors for trait impls + async/await notation for ergonomic asynchronous IO + RFC: #[used] static variables + Lint Reasons RFC + RFC: `?` repetition in macro rules + RFC: Associated type bounds of form `MyTrait&lt;AssociatedType: Bounds&gt;` It turns out that the RFCs that primarily add complexity do not at all "vastly outnumber" the RFCs that don't add complexity or which removes complexity. My main problem with your reasoning is therefore that you make various assertions about problems that we supposedly have without presenting facts to back them up. ----------------- &gt; Or shall we simply note that even in your own post here, you can't help yourself with pitching very costly proposals. I don't appreciate your "can't help yourself" tone here Graydon. I am not helpless or on autopilot to pitch these and do it fully on purpose. I think dependent types have costs, yes, but they also have notable rewards in particular wrt. reducing the need for `unsafe`. ----------------- &gt; I will just draw your attention to the fact that, as a reader, I find it very worrying the speed with which this paragraph slides down the slope from the very restricted special case of abstract equalities necessary to support RFC 2000 to the vastly more complex general case of full dependent types. It's about sunk cost; once you have introduced the notion of types depending on values, I think much of the cost of learning dependent typing has already been paid. To me, it therefore makes sense to lift the run-time barrier since it brings with it immensely useful capabilities. &gt; Similarly, the casual HKT comments -- they "may also be quite useful" so "we should experiment" -- completely dismisses the costs of learning, understanding, implementing, maintaining, etc. etc. To be clear: I'm suggesting that after we've tried Generic Associated Types (GATs) on nightly, we should come back and see where it faults and where it isn't ergonomic enough to handle the cases that people need. Then we should see if HKTs should be experimented with on *nightly*. &gt; This is exactly the kind of implicit "let's just try everything" approach I'm writing against. No that's emphatically not my approach and that of the language team. HKTs do not suddenly become "everything". Because Rust's generics + traits are more or less the same as Haskell's bounded parametric pol &gt; I think the language is putting itself at risk of colliding with limits by taking that approach, and it would be best to limit that approach consciously. With the current approach the language team is taking, I don't see such risks. I also don't think negative RFCs are useful and I think they will just cause more rifts in the community. It's better to consciously think about in which direction various proposals will take us and keep our current approach.
https://github.com/dpc/crev/wiki/List-of-Proof-Repositories Proofs contains url to Proof Repository, so with each trusted peer, the web grows and `cargo crev fetch all` can fetch more and more recursively.
Basically, `.DS_Store` files contain all of the information needed to render the finder window correctly. &gt; How is this stored/handled Internally, these files have 3 major sections. First, the prelude, which gives pointers to where the main info block of the file is. Second, the info block, which contains pointers into the main data store. Thirdly, the main data store, which is a B-Tree. When you traverse this B-Tree, you get all kinds of metadata about layout of the directory, and file names of course. When there is no .DS_Store file to read in a directory, finder will just arrange the files cleanly in order. Note that `.DS_Store` files are created and Maintained by the finder application. There exists hacks to get Finder to not create these, because people find them annoying.
You can install [this little hack](https://github.com/snielsen/DeathToDSStore) (use at your own risk). This patches the Finder application to never create any `.DS_Store` files.
I don't use macOS but that's cool. Didn't think you could modify a default Apple application.
&gt; How do you plan to support partial trust of reviews, reviews of different versions of packages, reviews of different levels of detail, and conflicting reviews? Several reviews from partially trusted reviewers is probably more useful than a single review from a "trusted" reviewer, after recognising that every human is fallible. There's a lot to unpack here. Trust level in other users can be `none`/`low`/`medium`/`high`, and it is supposed to be simple and generic. Many algorithms can developed based on it, and I leave all of this open-ended. Right now the implementation is a graph flooding algorithm, with different trust level having different edge cost. Conflict resolution could be solved in many different ways, eg. closest (WoT cost wise) wins or forcing user to review and decide themseleves. All could be configurable too. `thoroughness` of a review is explicitily stated in the review too: https://github.com/dpc/crev-proofs/blob/master/8iUv_SPgsAQ4paabLfs1D9tIptMnuSRZ344_M-6m9RE/reviews/2018-12-packages.proof.crev#L14 Before there's a decent sized real-life set to try it, I'm just not going to worry about it too much. All of these are definitely solvable problems, and ultimately, users could pick or even implement their own policies for everything. The big problem right now is to bootstrap ecosystem. :) 
&gt; Don't worry, the language team always does this. Even when I could write in the motivation of an RFC that we are doing it purely for consistency and composability, I try to find motivations in real world code. I do worry; but that's just because I have too much interest in language design. I really appreciate the work of the language team, and the resulting language. I still worry, though, mostly because backward compatibility sometimes feels like a Sword of Damocles hanging over our heads: the slightest lack of foresight doomed to haunt us for eternity. Maybe there could be ways for editions to "take back" features, allowing us to correct past mistakes; however, such would likely complicate the compiler much more than just syntax tweaks. Still I suppose that for a really egregious case it would be an option. The other solution would be to forego backward compatibility, as Swift did with its swift versioning; I still recall the days of Rust 0.x, though, it was already painful then and I can't imagine how painful it would be with a larger ecosystem. I mean, looking at Python... So, yes, I worry ;) &gt; &gt; Pragmatically speaking, however, sometimes generalizing may really complicate the implementation &gt; Sometimes, but this is also an argument in the abstract. Being concrete gets us further in our conversation. I think that's indeed the crux of my argument; let's avoid sweeping rules and just keep examining cases one by one, then decide with a mix of science and guts... it's called "art", I think :)
Each review is per-version and comes with cryptographic digest of content of the package. New version will need new reviews, though the plan is to: * make it pretty easy to discover past reviews, so one can still judge the overall quality of a crate * make it easy to find the most recent, yet still trusted version * make it easy to do differential review (review a diff between previous trusted version and a newer version) Proofs also come with a (advisory) revision, taken from `.carg_vcs_info.json` file, provided by newer `cargo` versions: https://github.com/dpc/crev-proofs/blob/master/8iUv_SPgsAQ4paabLfs1D9tIptMnuSRZ344_M-6m9RE/reviews/2018-12-packages.proof.crev#L409 So it should be possible to fetch the package git history etc. , verify if the released package content is the same as in official github repo, check `git log` between the releases etc.
What plugin do you have for vim to give you that information? 
I think this can work somewhat better than PGP, because the Rust leadership (official or not) has the means to bootstrap the ecosystem. Just on this subreddit, we have one users interested on reviewing/fuzzing unsafe code, who could start something along those lines, and we also have some prominent crate writers/Rust developers who could serve as entry points. Since the system works by graph flooding, you could easily set up a "default" root which would not write any review, but instead would announce its trust into a good set of people (like the libs team members), and those could also announce their trust in the authors of crates they have reviewed. This means a beginner doesn't have to explicitly configure a trusted party, they can just pass an option to be setup with the "default" root, and immediately they get a large network of reviewers (and hopefully reviews). Not fully decentralized, but it abolishes the first hurdle: you get immediate access to scores.
It's also useful to avoid pulling new versions of crates that haven't been vetted yet. This was the crux of many NPMs incidents this year: rogue versions, which one way or another, ended up in the hands of users. The one practical issue is how to set a threshold...
Ideally, such a tool should prevent an insufficiently verified dependency from being pulled in by cargo when running `cargo update`. From memory, it seems that most of the incidents affecting NPM this year were about rogue versions being uploaded either by malicious authors or by hackers using compromised authors' accounts, and then being automatically pulled in on users' machines. --- It is unclear to me how `crev` counters this threat, specifically, how the threshold of "insufficiently verified" is determined. Using the average score seems rather insufficient, for example, if it can be gamed with sock puppet accounts to flood the reviews with "5 stars"... or simply be gamed by having a single "5 stars" review. I'd be interested in hearing how crev solves this issue, or what is your recommendation? --- *It's a problem that I have yet to find a good solution to; especially when setting the bar too high might prevent any update...*
I come from the perspective, that too much granularity is a barrier to entry and makes people more careless about which values exactly do they use. It's better to have few, but carefully filled fields, than too many, sloppily filled ones. It's also more difficult to create a general UX supporting it. Ultimately it's up to the user to pick other users that they trust, and approve their review standards. With time, I hope the community will develop some "best practices" anyway. &gt; Also decentralization: There should be support to define a list of trusted review repositories. Imagine QA in a corporate setting. They would want to have their own review repository, or at least a shared one with contractors. That's kind of how it works. `cargo crev` comes with a generic Web of Trust, that can be potentially used in many different ways, and corporate settings is something I was explicit thinking about it. Proof Repositories are normal git repos, and proofs are just short blocks of text. Proof Repositories can be shared, forked, have PR sends etc. So yeah, there's a of possibilities here. The core is supposed to be generic and flexible, and then more use-case specific workflows and tools can be built on top of it. At least that's the idea.
The [Policies](https://crates.io/policies) page mentions copyright, so I think it may be best to reach out to help@crates.io and see if they can take down or rename your crate. 
Nice to have available. Thanks!
&gt; Non-optimized build performance is importan I'm particularly looking forward to the stabilization of ["Cargo profile dependencies"](https://github.com/rust-lang/rust/issues/48683) which should allow dependencies built for release mode to be used in a debug build. As an (amateur) game developer, actually being able to use debug builds will be very helpful.
&gt; *Compile times are unsurprisingly much longer :( The original C code compiles in a fraction of a second whilst the rust code at best takes 3-4 seconds to recompile in release mode after changing only one file. &gt; * The binary size is much larger - the C binary is 42 KB whilst the Rust release binary is 2.9 MB. &gt; &gt; Am I right in thinking that it's not entirely fair (or at least not entirely straightforward) to compare the compile time and size of the Rust binary vs the C binary? Yes, for the size you are right that it's not exactly fair. The C implementation can depend on the C library, while in Rust the parts of `std` and other crates that you include are included in your binary. Also, if you're currently compiling with the stable compiler, you'll be including `jemalloc`, an allocator that Rust used to use by default. In Rust 1.32, which is currently the beta compiler, the default has been switched to the system allocator, which eliminates a large amount of the extra space used. If you use the beta compiler, you'll probably get a smaller binary size. You can inspect your binary size with `cargo bloat` (`cargo install cargo-bloat`) to see where the remaining size is coming from: $ ls -l target/release/rwmstatus -rwxr-xr-x 2 lambda access_bpf 1925808 Dec 29 14:24 target/release/rwmstatus $ cargo bloat --release --crates Compiling ... Analyzing target/release/rwmstatus File .text Size Name 7.1% 51.1% 132.7KiB std 2.6% 19.0% 49.5KiB chrono_tz 1.8% 13.2% 34.4KiB [Unknown] 1.2% 8.7% 22.6KiB rwmstatus 1.0% 7.5% 19.5KiB chrono 0.0% 0.4% 944B time 0.0% 0.1% 320B regex 13.8% 100.0% 259.9KiB .text section size, the file size is 1.8MiB Note: numbers above are a result of guesswork. They are not 100% correct and never will be. As you can see, `std` and `chrono_tz` take up some of the most space in your binary. Your code itself is only 22.6 KiB. The C program can rely on those being present in libc which is already present on the system, while in Rust it's included in your binary. And actually, a lot more of the data is in the data section, not the text section. I suspect that's probably the timezone data itself. [One of the "todos" listed on the `chrono-tz` crate](https://github.com/chronotope/chrono-tz) is to be able to load the tzdata dynamically; if it could find your system's timezone data and load that, your binary could probably be a lot smaller. On the compile time, while Rust will always be a little slower than C due to the compiler doing more (type inference, borrow checking, monomorphization of generics, etc), the Rust compiler is probably currently slower than it has to be. There are a few well known problems; incremental compilation doesn't work as well as it could, the rust compiler frequently generates a lot of extra code that it relies on LLVM to optimize out, which takes extra time, and a few other issues like that. LLVM itself is a bit slow at code generation. There's ongoing work to improve compiler speeds, and it's better than it used to be, but there's still a lot of improvement that could be made.
I personally dislike PGP, and it's WoT very much. I am a heavy user though, because it's the only game in town for hardware keys (like Yubikey). crev's WoT is nothing like PGP's WoT. In `crev` you're not concerned with "is this ID really belonging to this real-life person", but instead "do reviews of this ID looks OK?". Who is this ID, is secondary at best. Also, everything is supposed to be redundant anyway. To trust a given crate, you want `N` reviews from uncorrelated IDs from within your WoT. Because of that, one compromised person does not ruin WoT of other users.
&gt; "wisdom of crowds" convention where the aggregate reveals a useful score. "wisdom of crowds" metrics are just for information which crates to review first. The primary way of trust is a WoT, with some redundancy: "to trust this crate I need `N` positive reviews from uncorrelated people within my WoT".
&gt; I still worry, though, mostly because backward compatibility sometimes feels like a Sword of Damocles hanging over our heads: the slightest lack of foresight doomed to haunt us for eternity. You're not alone. ;) Sometime after getting the keyword `pure` unreserved I felt like I had made a horrible mistake and that I'd have to loathe myself for a year or two. Happily the sensation faded. &gt; Maybe there could be ways for editions to "take back" features, allowing us to correct past mistakes; however, such would likely complicate the compiler much more than just syntax tweaks. Still I suppose that for a really egregious case it would be an option. We've been considering doing this with UB-happy `static mut`: https://github.com/rust-lang/rust/issues/53639 ... but this would be merely forbidding the feature in 2021 crates by forbidding the syntax; you would still be able to get the feature by composing with a &lt; 2021 crate; that's just a fundamental limitation of editions. For standard library features I had the idea of edition visibilities, for example, you could have `pub(edition &lt;= 2021) fn uninitialized&lt;T&gt;() -&gt; T { ... }`. I'd love to eventually bury that function in a deep hole one day personally. &gt; The other solution would be to forego backward compatibility, as Swift did with its swift versioning; I still recall the days of Rust 0.x, though, it was already painful then and I can't imagine how painful it would be with a larger ecosystem. I mean, looking at Python... I'd rather not end up in Swift's situation and I don't think we'll ever end up needing that. We've been doing really great with Rust 2018 -- the biggest edition breaking changes are in the resolution system and hopefully that will be the last major change to the resolution system ever. &gt; I think that's indeed the crux of my argument; let's avoid sweeping rules and just keep examining cases one by one, then decide with a mix of science and guts... it's called "art", I think :) This is what we've been doing thus far. It's working well. I don't think negative RFCs or artificial constraints are necessary.
&gt; Ideally, such a tool should prevent an insufficiently verified dependency from being pulled in by cargo &gt; how the threshold of "insufficiently verified" is determined. The primary way of trust is a WoT, with some redundancy: "to trust this crate I need N positive reviews from uncorrelated people within my WoT". &gt; It's a problem that I have yet to find a good solution to; especially when setting the bar too high might prevent any update... Don't let the perfect overshadow the good enough. :)
I actually developed a website-based system last year. It was fiasco, and noone used it. :D IMO, for this to work it has to be tightly integrated from `cargo`, easy to run from your terminal, p2p, and potentially be easily integrated with IDEs, like eg. `git` is. So I'm now trying the "git of code review" approach.
Hopefully more will be added to this exciting list. :)
&lt;3
There is a *lot* of blockchain stuff in Rust. Parity, Exonum, MaidSAFE, xcash now requires it to build...
Also, `cargo fix --edition` will convert all of the `use` statements to rs2018 automatically, making the cognitive load to migrating versions negligible.
I believe this is violating the Coherence Rule in Rust, similar to the C++ One Definition Rule, where you have more than one implementations. Unless I'm mistaken, your expectation is for the compiler to consider the union of the two impl blocks, but it actually ends up causing ambiguity. This makes sense if there is conflicting code in both impls. Disclaimer: I don't know what I'm talking about.
Thank you for that.
The biggest gain in that area has already been made I think, now that jemalloc is no longer the default allocator. Aside from that, I don't see what the rust compiler should do more for executable size. You can strip down the debug symbols and such yourself quite easily, it doesn't get much smaller than that. You can use trait objects instead of monomorphization for smaller executable size, but that is not a choice the compiler should make for you. 
C++ imo
I'm basing this 99% on similar posts I've seen the past two years or so that I've been visiting this subreddit: You are locking stdin 1_000_000 times, try locking it once outside the loop with [`io::stdin().lock()`](https://doc.rust-lang.org/std/io/struct.Stdin.html#method.lock)
Try to save a lock to `stdin` since `read_line` takes a lock on every invocation: let mut stdin = std::io::stdin().lock(); ... stdin.read_line(...); &amp;#x200B;
oops just remove the mut then same thing :)
Also could lock `stdout`, but that definitely won't be as significant.
Also, did you compile in release mode? (`cargo build --release`
It won’t be insignificant though; definitely worth it if the goal is to compare best performance. 
Gist says he does, at least. &gt; executables built with &gt; &gt; go build -o count-go count.go &gt; &gt; cargo build --release 
I don't have your dataset, but as others have mentioned your go version constructs a scanner and locks stdin once, while the rust version will lock it once per loop. Try using `lines()` instead, and you can also avoid manually stripping the newline characters: use std::collections::HashMap; use std::io::{self, prelude::*}; struct Counter { items: HashMap&lt;String, usize&gt;, } impl Counter { fn new() -&gt; Counter { return Counter { items: HashMap::with_capacity(1000), }; } fn add(&amp;mut self, st: String) { let x = self.items.entry(st).or_insert(0); *x += 1; } fn render(&amp;self) { for (key, val) in &amp;self.items { println!("{}\t{}", val, key); } } } fn main() -&gt; Result&lt;(), io::Error&gt; { let mut c = Counter::new(); for line in io::stdin().lock().lines() { c.add(line?); } c.render(); Ok(()) } 
And to make it slightly more concrete than "lock `stdout`" pointing the OP towards [`writeln!`](https://doc.rust-lang.org/std/macro.writeln.html) and [`io::stdout().lock()`](https://doc.rust-lang.org/std/io/struct.Stdout.html#method.lock) is how I should do that, correct?
Yes indeed! 
&gt; frontend code doesn't often deal with large amounts of data anyway It doesn't take much to make it slow. :)
Why?
[This](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=08f2ce8dfc30a070a62bab8c22daf577) also compiles without the wrapper struct
I added that and seems to be fixed now! I guess that I first compiled it with an older version of rust. Thank you very much!
Any time! You’re not the only one by a long shot.
Those arithmetic operations will almost certainly be inlined, and the vector values split up to have their individual components stored in separate registers (SRoA: scalar replacement of aggregates), for performance. That is, any copies won't happen. Taking a reference probably actually makes doing optimisations like SRoA harder.
It's an `addon`, yes, but "authors" are only a UX gimmick to help you pick the crates to review first. The actual `verified` status comes from your personal Web of Trust, of people actually looking at the source code and checking if it looks OK.
I don't think the p2p component is essential, and i think that it will be hard to make it as easy to use as a centralized approach. I think a centralized approach with perhaps the rust team hosting the server, would be better, or at least allow the option for multiple review servers with the default one being the one from the rust team. I think the rust team is trustworthy enough that these reviews can be hosted there. But if you're trying to make a more general solution for this, and not just something for crates.io, I do agree with you that a decentralized "git of code review" is the right approach. However, for mainstream adoption, you will need to make choosing a crate, and seeing it's reviews one cohesive experience. This can either be done with integration in crates.io or a website/application that scrapes crates.io and adds the review info on top.
Why are you creating a hash map with a capacity of 1000? In your example you only need a capacity of 2, although in more realistic use cases 1000 might not be a terrible default. You could test the baseline overhead by feeding each an empty file too, that way you know how much of your execution time is spent just setting up and tearing down. 
Something that would be nice for avoiding code bloat from templated functions is an easier syntax for this pattern: pub fn do_a_thing&lt;T: Into&lt;ConcreteType&gt;(param: T) { // Generates a separate version for each type, but this part is small do_a_thing_inner(param.into()); } fn do_a_thing_inner(param: ConcreteType) { // actual work, not duplicated for each type }
Thanks for the tips. I gave it a try, and it's not too bad, ending up just over 3000 bytes. It's still slightly more than the original C++ version, mostly because of those "let" everywhere. `macro_rules!` save the day for implementing traits, but unfortunately the name itself is quite long making that useless even to define a shorter replacement of `f32::min()`, which is used quite a lot, even with a `m!` macro taking &gt; 2 arguments and expanding into a chain of `.min()` calls. [https://github.com/djeedai/rayst-min](https://github.com/djeedai/rayst-min)
If I understand what SRoA is correctly then it's an awesome news to me that Rust is able to split aggregate types into multiple registers when doing a function call. This is a very annoying limitation for C++ of [the x64 MSVC ABI](https://docs.microsoft.com/en-us/cpp/build/x64-calling-convention?view=vs-2017).
FNV is optimized for small inputs and will perform poorly on larger inputs such as strings. [FxHash](https://crates.io/crates/fxhash) seems to be strictly superior to FNV, I suggest using that one for non-cryptographically-secure hashes.
I hope, like python it gets both, after some python experience, it's good to have both. List comprehensions can really flatten indentation. 
Just tried your implementation and the rust version takes about 0.08~ seconds on average which is about 20% faster than the go version now. Thanks!! Most people ITT say the stdin locking was the main culprit - so that lines up. Is the way of reading: while stdin_lock.read_line(&amp;mut line)? != 0 { the 'idiomatic' way of writing this sort of thing in rust code? Reading lines of text from stdin is a common pattern for CLI tools. 
Whoops, I'd left that in there from playing around....just goes to show always do performance tests one change at a time :D
Have you tried `strip`ing your release binary to reduce its size?
Yep from /u/daboross implementation this looks like the culprit. Reading lines of text from stdin is a fairly standard pattern for writing CLI tools (i.e. if you adhere to the 'unix philosophy'), I was looking for it in https://rust-lang-nursery.github.io/cli-wg/ but couldn't see an example. 
I'm using nom to parse a line of text like so: &amp;#x200B; `named!(parse_map&lt;&amp;str, Result&lt;Map&gt;&gt;,` `do_parse!(` `base: map!(take_until!("-"), String::from) &gt;&gt;` `take!(1) &gt;&gt;` `ceiling: map!(take_until!(" "), String::from) &gt;&gt;` `take!(1) &gt;&gt;` `perms: map!(take_until!(" "), String::from) &gt;&gt;` `take!(1) &gt;&gt;` `offset: map!(take_until!(" "), String::from) &gt;&gt;` `take!(1) &gt;&gt;` `dev_major: map!(take_until!(":"), String::from) &gt;&gt;` `take!(1) &gt;&gt;` `dev_minor: map!(take_until!(" "), String::from) &gt;&gt;` `take!(1) &gt;&gt;` `inode: map!(take_until!(" "), String::from) &gt;&gt;` `//take_while!(|ch: char| ch.is_whitespace()) &gt;&gt;` `take!(1) &gt;&gt;` `pathname: opt!(take_until!("\n")) &gt;&gt;` `(Ok(Map {` `base: usize::from_str_radix(&amp;base, 16).unwrap() as *const u8,` `ceiling: usize::from_str_radix(&amp;ceiling, 16).unwrap() as *const u8,` `perms: Permissions::from_str(&amp;perms)?,` `offset: usize::from_str_radix(&amp;offset, 16).unwrap(),` `dev_major: usize::from_str_radix(&amp;dev_major, 10).unwrap(),` `dev_minor: usize::from_str_radix(&amp;dev_minor, 10).unwrap(),` `inode: usize::from_str_radix(&amp;inode, 16).unwrap(),` `pathname: pathname.unwrap().trim().into(),` `}))` `)` `);` &amp;#x200B; I want to eliminate some of these unwraps, but I can't implement From for std library Error types. How do I propagate up errors in this case?
Strongly agree with the sentiment of this post. I’m in favor for **being able** to 100% replace JavaScript on the web with Rust WASM. Of course, it is silly to think that web JS will be completely replaced with Rust, but being able to do so should be the goal, IMHO. The stability that Rust offers to the lifecycle of application development (libraries, frameworks and the like included) is night and day compared to most other languages, especially JavaScript. Not only the stability, but the investment it takes to get to a working product, which you know works as designed, can be achieved so much faster with Rust and with much less code to maintain often times. Let me expound on that last point. With Rust, the language itself guarantees type-safety and memory-safety at compile time, before you ever ship your app. In terms of the basics, the only thing that the language itself does not guarantee is what could be called “algorithmic-safety”. IE, that your algorithms do what they are supposed to do. This is where you write tests. Let’s contrast that with JS. What does JS guarantee? Well actually ... nothing. When you ship your app, you can’t actually be sure that the JS interpreter will be able to successfully run your code without a bunch of additional testing, linting and tooling upfront. Of course, we still get things to work. This is just standard development practice, to be sure. So what is the issue? The issue is the amount of investment it takes to initially build, prove and then evolve your JS projects. You need tests to ensure that you don’t end up with a bunch of `undefined is not a function` errors. Tests to guard against other subtle type issues. And then finally tests to ensure algorithmic correctness. With Rust, you build your applications, and without even writing a lick of test code, things will often just work as expected. This is a phenomenon that is often observed within the Rust community. The compiler already covers so many things that you would have to write tests for in languages like JS, Swift, Go, Java, Python &amp;c (all languages which I have built and maintained large scale apps in). Of course, even in Rust, you still need to test your algorithms. Serialization can go awry in subtle ways. We still need to be responsible developers. To wrap this up (I’ll cut this over to a proper blog post soon), I would argue that it would be a huge win for developers to have Rust as an option for 100% of their web development needs. Greater stability, confidence and quality with less effort. 
There is already crate called custom_error it seems to work similar but with makro. 
That's a good idea, but it still feels more like a workaround, not a solution. &amp;#x200B; In the mean time I have discovered [Niko Matsakis' proposal](http://smallcultfollowing.com/babysteps/blog/2018/06/20/proposal-for-a-staged-rfc-process/) for a more organized RFC process and it sounds to me like this would solve many problems discussed here. One key proposal is a seperate repository for each RFC, which would make seperate FAQ files and discussion threads possible. 
Ethereum TPS problem does not result from the Go language “lack of performance”. Not at all. Ethereum doesn’t scale **by design**: the consensus protocole. Go language is fast. &lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;Ethereum isn&amp;#39;t safe or scalable. It is immature experimental tech. Don&amp;#39;t rely on it for mission critical apps unless absolutely necessary!&lt;/p&gt;&amp;mdash; Vlad Zamfir (@VladZamfir) &lt;a href="https://twitter.com/VladZamfir/status/838006311598030848?ref_src=twsrc%5Etfw"&gt;March 4, 2017&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt; 
One of the worst ideas for portability Apple ever had, and that is saying many things.
While interesting, I think Niko's proposal needs some work; to me it has some notable drawbacks. &gt; One key proposal is a seperate repository for each RFC, which would make seperate FAQ files and discussion threads possible. I think this is one of the less good aspects of Niko's proposal. In particular, I think it spreads the RFC too far away from each other and risks making things unmanageable for the teams. It also seems like it would make RFCs less visible / discoverable thus reducing community involvement in each RFC overall. As the person who manages most of the RFC system (including assigning teams, merging them, etc.) I think that we also need to think about `@rfcbot`. Who will do the work of implementing needed changes to it? The bot barely gets any contributions as is (I and anp work on it sometimes sporadically).
Well put!
Just doing ´:!cargo run´
Just doing ´:!cargo run´
And I've been using `hashbrown` but I don't have *my own* numbers indicating it is faster than fnv.
I would think that [this] might be an even faster hashmap. I tried your best solution, combined with the Hashbrown hashmap, and got from a time of 9.5s to 4.2s (timed with bash command time). This is over a 2.2x speedup and thus also faster than op's go code (assuming a 40% speed difference). Hashbrown can be used as a drop in replacement for the std hashmap, so only the import statements differ. Here is the code: use std::io::{self, prelude::*}; use hashbrown::HashMap; struct Counter { items: HashMap&lt;String, usize&gt;, } impl Counter { fn new() -&gt; Counter { return Counter { items: HashMap::with_capacity(1000), }; } fn add(&amp;mut self, st: &amp;str) { match self.items.get_mut(st) { Some(x) =&gt; { *x += 1; } None =&gt; { self.items.insert(st.to_owned(), 1); } } } fn render(&amp;self) { for (key, val) in &amp;self.items { println!("{}\t{}", val, key); } } } fn main() -&gt; Result&lt;(), io::Error&gt; { let mut c = Counter::new(); let mut line = String::new(); let stdin = io::stdin(); let mut stdin_lock = stdin.lock(); while stdin_lock.read_line(&amp;mut line)? != 0 { c.add(line.trim_end()); line.clear(); } c.render(); Ok(()) } 
After strip-ing the binary, ensuring that he's using the system malloc instead of jemalloc might buy him another good % size reduction.
Short answer: "Sorry, come back in 5 years." Rust is simply too young compared to other languages. Look at the versions on most of our major crates. If you build any moderate or large project with rust you're going to get mostly dependencies that are all 0.x instead of 1.x. Even _very core_ crates like `rand` and `libc` aren't actually set down as 1.0 "stable" yet. Now, that said, it's not _really_ so bad as all that. Sure, crate repos are usually hosting their latest code on `github.com/jrandom/crate`, which you can't necessarily depend on, but when you depend on a specific version of a crate in your Cargo.toml file you're getting a specific blob of code from crates.io, and that specific version can generally be relied upon to exist as long as crates.io keeps existing. Crate versions are generally only yanked if there's some major security flaw discovered. And even the fact that a crate is 0.x instead of 1.0 is basically unimportant because you can just use 0.x if it does what you want and never upgrade. Like, you could use `rand` 0.5 for the rest of your whole life and ignore whatever they do in 0.6 and beyond, if you like how 0.5 works. But basically you're asking for Rust to compete with languages much older and much more popular. We'll get there, just takes time.
I'm really lost with modules and file names. Please tell me where I'm wrong: * Every file has a mod that is the name of the file itself. * When I use 'mod X;' at the top of the file I'm invoking the mod of the file/directory that is in the same path. * Tests don't follow the previous rule (?) (Which ones do they follow?) * One can create arbritary mod/namespaces that need to be accessed by nesting the mod of the filename and the mod of the namespace * Those mod have everything private by default unless made public by opt-in * Cargo automatically manages this properly I feel like one of those assumptions that I have about how Cargo manages the files is wrong because I can't figure out why I can't move some functions from [lib.rs](https://lib.rs) to a file called [parser.rs](https://parser.rs) and from a file called [tests.rs](https://tests.rs) at the same location it can't resolve the parser path. Hell, [parser.rs](https://parser.rs) doesn't even seem to include std or whaeveer (?)
If you only want to load something line by line from stdin, I would use `lines` method from [BufRead](https://doc.rust-lang.org/std/io/trait.BufRead.html): use std::io::{self, BufRead}; fn main() { let stdin = io::stdin(); for line in stdin.lock().lines().filter_map( Result::ok ) { println!( "{}", line ); } }
The implementation would be a big challenge, you are right. Would it be better to have a subfolder for each RFC (or related ones) in the current RFC repo? Splitting up the often gigantic Github issues into several ones with managable size, each focussing on a certain aspect, would make the life of interested newcomers (like me) much easier. (And I guess for everyone else too.) Personal example: I tried to understand the Pin RFC and read through the RFC and related tracking issue for an hour or two. The name \`Unpin\` was confusing, so I made a suggestion to change it. The answer was that my suggestion was redundant with a link to another tracking issue. It took me 5 minutes to even find the discussion I was pointed to, and see there: probably 100 comments discussing alternative names. How could I not stumble over any of those comments in the first place? :'( What I'm trying to say is that it was a bit embarrassing and I just wasted someone elses time, which I don't like. But this will not stop me from trying to understand rustc :) 
Eh I'd use lines() in most code, like the first gist I linked. Using a `String` outside a while loop is _faster_, but you have to remember to clear it, and it's more cumbersome. I would use this while pattern if and only if your bottleneck is reading from stdin - in my case, this happens exclusively in benchmarks. I think all of my real code uses either [`fs::read_to_string`](https://doc.rust-lang.org/std/fs/fn.read_to_string.html) (for file io) or the `lines` function for reading from stdin.
Hashbrown uses FxHash internally
Hey, wrong sub there pal. I think the one you want is r/playrust. This one is about the Rust Programming Language.
And even then, waiting 5 years doesn't help in JS for example, its libs cycle through way faster than that.
&gt; Would it be better to have a subfolder for each RFC (or related ones) in the current RFC repo? Yes, I think that's a better approach. &gt; Splitting up the often gigantic Github issues into several ones with managable size, each focussing on a certain aspect, would make the life of interested newcomers (like me) much easier. (And I guess for everyone else too.) Are you referring to the tracking issues? Some of them are pretty small and then there are huge ones like https://github.com/rust-lang/rust/issues/34511. But I think that one should be split up or closed in favor of more targeted issues. I think #34511 looked small-ish at some point and folks thought it would be manageable; but then we mashed all follow up RFCs into that one and it begat chaos. &gt; Personal example: I tried to understand the Pin RFC and read through the RFC and related tracking issue for an hour or two. The name `Unpin` was confusing, so I made a suggestion to change it. The answer was that my suggestion was redundant with a link to another tracking issue. It took me 5 minutes to even find the discussion I was pointed to, and see there: probably 100 comments discussing alternative names. How could I not stumble over any of those comments in the first place? :'( Honestly pinning is a complicated subject conceptually; you're not alone in finding it confusing. I think behind the extensive bikeshed on `Unpin` there is confusion about the underlying semantics. I'm not too invested in the bikeshed myself, it is far more important to ramp up documentation instead. &gt; What I'm trying to say is that it was a bit embarrassing and I just wasted someone elses time, which I don't like. But this will not stop me from trying to understand rustc :) Don't worry too much about it. As they say: shit happens.
Instead of just mapping to a `String`, you can map to a success value: ``` do_parse!( base: map_res!(take_until!("-"), |b| usize::from_str_radix(b, 16)) &gt;&gt; take!(1) ... ) ``` That way, if `from_str_radix` is a success, you get the unwrapped value, and if it isn't you get the error returned without having to parse anything else.
Have you tried comparing the compile-time and run-time against clang ?
Well, sadly, I don't think we're immune to that sort of churn. Consider: glium died, better all move to vulkano and/or ash. Wait, now we all move to gfx. Wait, now we should all move to gfx-hal. Specs was "the thing" and we were told to totally use it at rustconf2018. Except now it's having work diverted to a totally new crate with an expanded mandate and eventually specs will just be one possible front end over top of the new and better system. Then there's the whole set of error handling crates... If you want to always have the latest and greatest there will always be churn. However, if you want to just pick some version that works for you and keep using that version for as long as possible, you can totally do that (like those companies that _still_ target JVM 1.5). 
Can you give an update on the performance after you made the changes?
1.4x faster, avoiding UTF-8 processing until display time, which is closer to what Go is doing (or rather, not doing): use std::io::{self, prelude::*}; use hashbrown::HashMap; struct Counter { items: HashMap&lt;Vec&lt;u8&gt;, usize&gt;, } impl Counter { fn new() -&gt; Counter { return Counter { items: HashMap::with_capacity(1000), }; } fn add(&amp;mut self, st: &amp;[u8]) { match self.items.get_mut(st) { Some(x) =&gt; { *x += 1; } None =&gt; { self.items.insert(st.to_owned(), 1); } } } fn render(&amp;self) { for (key, val) in &amp;self.items { println!("{}\t{}", val, String::from_utf8_lossy(key)); } } } fn main() -&gt; Result&lt;(), io::Error&gt; { let mut c = Counter::new(); let mut line = vec![]; let stdin = io::stdin(); let mut stdin_lock = stdin.lock(); while stdin_lock.read_until(b'\n', &amp;mut line)? != 0 { c.add(&amp;line[0..line.iter().rposition(|&amp;b| b == b'\n').unwrap_or(line.len())]); line.clear(); } c.render(); Ok(()) }
Cool! Now we're at a 3x performance improvement! And thus probably beating go by 2x!
Another thing you could do to speed things up is to use the Hashbrown crate, which has a much faster hashmap implementation (with an identical API) 
Is there a downside to Hashbrown? If not, why not add it to the stdlib or replace Hashmap with Hashbrown?
How does Go compare?
I’ve been playing with rust and love it, but I’ve only been dabbling. My biggest issue is I don’t trust crates. There doesn’t seem to be any vetting or control of crates. But, I’ve been able to do a ton with the standard library. And I’m learning a lot!
Do you have any information on the specs stuff you mentioned? I tried looking at their GitHub but saw no mention and not sure what else I can search for in regards to that.
&gt; &amp;line[0..line.iter().rposition(|&amp;b| b == b'\n').unwrap_or(line.len())] Can you explain what's going on here? Based on the documentation, `rposition` is looking for the index of a newline from the right, but why would we not just use the `line.len()-1` to begin with? New to rust, so pardon the stupid question :)
You're correct. I'm a little surprised that rust allows a public trait to inherrit from a private trait. What was the original motivation for allowing this?
If the file doesn't end with a newline we don't want to strip off content and produce incorrect results, ala: -% echo -n foo &gt;&gt;file.txt -% target/release/counter &lt;file.txt 500000 bar 500000 foo 1 fo It's not quite right because it doesn't deal with \r, but it's better than nothing.
Cool, I'm learning rust in China. Reading technical books in China is challenging for me but I'm glad to see there are resources for locals though.
By default the hashing algorithm protects against HashDoS attacks, which means it isn’t necessarily the fastest option. &gt; By default, HashMap uses a hashing algorithm selected to provide resistance against HashDoS attacks. &gt; While its performance is very competitive for medium sized keys, other hashing algorithms will outperform it for small keys such as integers as well as large keys such as long strings, though those algorithms will typically not protect against attacks such as HashDoS. It supports swapping out the hasher, which can be useful if SipHasher is proving to be a bottleneck and you don’t need the HashDoS protection. &gt; The hashing algorithm can be replaced on a per-HashMap basis using the default, with_hasher, and with_capacity_and_hasher methods. Many alternative algorithms are available on crates.io, such as the fnv crate. — https://doc.rust-lang.org/std/collections/struct.HashMap.html There is an [open PR to use hashbrown in the standard library](https://github.com/rust-lang/rust/pull/56241).
Is this the talk where he says ideally a language shouldn't need his books? I was thinking about him saying that with all the C++ discussions going on but couldn't remember where I'd heard it.
Because it's new, and there wasn't sufficient time to validate it in time for Rust 2018. That said, I've been using it and it's damn solid.
Ah, ok. I thought you had an intellisense kind of thing xD.
&gt; This was one of the coolest libraries i've seen doing virtual DOM in Rust. I was disappointed though it didn't have any simple examples Sounds like it would be worth integrating your example with the upstream repo and opening a PR to add it. 
 -% hyperfine "./count-go &lt;file.txt" "target/release/counter &lt;file.txt" Benchmark #1: ./count-go &lt;file.txt Time (mean ± σ): 163.4 ms ± 0.4 ms [User: 157.0 ms, System: 5.4 ms] Range (min … max): 162.5 ms … 164.5 ms Benchmark #2: target/release/counter &lt;file.txt Time (mean ± σ): 67.2 ms ± 0.3 ms [User: 64.0 ms, System: 3.6 ms] Range (min … max): 66.7 ms … 67.9 ms Summary 'target/release/counter &lt;file.txt' ran 2.43 ± 0.01 times faster than './count-go &lt;file.txt'
I have created [Gist](https://gist.github.com/goriunov/2e453b4bd93b8198c1216a12b7b95534) this is just an example what i want but can not do it would be really good to remove Boxs at all but i don't know how to go about that.
I was thinking of posting this here, I'm glad someone did. I think there are a lot of C++ users like myself who have fled to rust but have a lingering fear that rust could end up going down the same complexity hole as C++ if it's not careful. I don't think that's currently happening, just that it could. Of course most of this post are about build times and debug performance which are issues that do definitely apply to rust.
Seconded, I'd bet at least a meg of that is debug symbols.
It would be interesting to know more about your efforts, I did something similar and wrote about it here: https://wiki.alopex.li/PortingCToRust . I'd love to hear if your experiences match my own.
&gt; Cargo automatically manages this properly Cargo tells rustc what files to use but does not handle any parsing beyond parsing \`Cargo.toml\` and related as far as I know. Rustc is what is managing those properties. &amp;#x200B; If I had to guess, you are not properly adding `mod parser;` and the like to your [lib.rs](https://lib.rs) or [`main.rs`](https://main.rs), which is what could be causing your problems. [parser.rs](https://parser.rs) should be able to `use std;` unless you have `#[no_std]`. &amp;#x200B; You are going to have to provide a stripped down example for me to help you with anything else, e.g. in [lib.rs](https://lib.rs) fn f() {} mod parser; mod tests { fn g() {} } in [parser.rs](https://parser.rs) etc ...
I think he's talking about [nitric](https://users.rust-lang.org/t/announcing-nitric-the-successor-of-specs/23388). 
I do have I use lsp for rust the source is racer and it gives intellisense and also thanks to tabnine I get machine learning based smart autocompletion 
I think there's a long term hope to do just that! Hashbrown is based on Google's Swiss Table, and is fairly new. When it's cooked long enough as a stand-alone crate, expect an RFC to have it replace the hashtable implementation in std. 
Awesome. Thanks for the link
I'm trying to make an internal clock (for a game, so I might be better off asking on r/rust_gamedev). Most of the time, I want this internal clock to just run forwards at 1 second per real life second. However, sometimes I need to be able to slow it down. Is there any kind of structure in Rust that I could use to efficiently do this, or am I looking at a large amount of engineering for a beginner like myself?
It's an artifact of history I believe.
To paraphrase: the chosen programming language has near-zero bearing on the performance of a blockchain. 
My biggest problems with webdev in Rust are the amount of churn, and the lack of a full-featured web framework similar to Rails. Rocket is coming closer to this goal gradually, but it still lacks some features (a background job runner, for example) that I end up having to roll myself. Having to use nightly on Rocket is only a small issue, because I can just use a `rust-toolchai` file to identify which Rust version to use in my project. But the bigger issue is the churn, which causes issues with compatibility. I recently attempted to start a new project with Rocket and Diesel, and quickly came to a screeching halt as I realized that the latest Rocket and the latest Diesel are incompatible if you are using UUIDs in your database, because Diesel does not work with the latest `uuid` crate. Understandably, Diesel does not want to break backwards compatibility, but they maybe shouldn't have released a 1.0 version while their external interface depends on pre-1.0 libraries. That's really not the core of the problem, though. Yes, if Diesel was on 0.9.0 or whatever, maybe they'd be more willing to release a 0.10.0 to fix uuid compatibility, but the core issue is that there's still frequent compatibility breakage that requires manual upgrading of packages, because there's still so many packages which are pre-1.0 but are critical to the Rust ecosystem. So the answer of "Sorry, come back in 5 years" may just be accurate. You can do webdev in Rust now, but there will be pain points that you just won't encounter with more mature languages.
I wish you would update the title to reflect Rust being faster after a few modifications. It could be misleading to those scrolling by. If that sound to not picky though don’t worry about it.
This is super! At first glance, the problem of how to audit a project with dozens of dependencies seems almost hopeless. A lone dev or small team likely doesn't have the resources to review the code of all the dependencies used by their project. However, if there is some way to reuse code reviews across, like `cargo-crev`does, so that devs can take advantage of code reviews that others have done, then the problem becomes much much more tractable.
Just to clarify: If a version you depends on gets yanked, your code will still build.
&gt; My biggest issue is I don’t trust crates. I'm mostly with ya, but there's a few crates that you might want to look in to because they handle the "cross-platform" element of things for you (winit + graphics lib of choice), or they do provide a very high quality service that has dedicated itself to stability (serde + serializer backend of choice). Don't shut crates out of your heart entirely.
Lol, now I’ve learned the secret to get people to help me with my Rust project...just say the Go version was faster and watch people come out and optimize the hell out of my Rust code! 😋
specs isn't going away. It's in maintenance mode now, but that also means it's effectively "stable".
Like I said, any crate is stable if you never update it ;3c
I think that's false though. The interface is stable, but support for it is not. Everybody is going to assume you're using the latest version and then be unable to help if you use an old version because keeping track of changes is hard. Or you have to go searching to find relevant documentation. Whereas once the project is in maintenance mode, there's no more big changes that trip up support needs.
Well sure, life is complicated if you're not just being glib on the internet.
Yeap. That's the idea. :)
Rust is a perfect language for cryptofin and more and more projects are using it. Join /r/cryptofit , see previous posts.
As another person who uses both TypeScript and Rust, I'll offer these counterpoints: * TypeScript's type system is unsound: * You can coerce an `Array&lt;Dog&gt;` to an `Array&lt;Animal&gt;`, then append a `Cat` to that array. This is because arrays (as well as most other object types) are covariant. * You can assign a readonly type to its non-readonly equivalent, and [the compiler won't say anything](https://github.com/Microsoft/TypeScript/issues/13347)! * Sometimes the compiler will infer a singleton type for a string literal; other times it'll widen it to `string`. Most of the time it does what you want, but when it doesn't, you need to [wrap it in a dummy function call](https://material-ui.com/guides/typescript/#using-createstyles-to-defeat-type-widening) to force it the other way. * Most type definition libraries, as well as the TypeScript compiler itself, don't follow semver. Bumping a minor version can cause code to stop compiling much more often than in Rust. There are good reasons behind all of these issues, largely stemming from its decision to favor practicality and incremental adoption over adherence to theory and soundness. And while I agree that this decision is best for the language, it does occasionally lead to issues like these.
I think it was an accidental gap in the rules -- the hidden item *is* pub, but doesn't have a fully public path. Sometimes that happens naturally if you split code into private modules, which you then `pub use` elsewhere to export the API. But now we've found a useful hack in keeping something unreachable, and some popular crates exploit this, so it would be hard to tighten the rules. Here are more discussions: https://internals.rust-lang.org/t/pre-rfc-warn-about-inaccessible-types-in-public-function-signatures/5156 https://internals.rust-lang.org/t/lang-team-minutes-private-in-public-rules/4504 
If your goal is performance and reading from stdin is a limiting factor, then no, that's not what I would do necessarily. I would use buffered reading by wrapping io::stdin in a BufReader, which is exactly what you're doing in the Go code. If you use buffered reading, then you likely don't need to care about whether stdin is locked or not. Locking the standard I/O objects for performance reasons is often a red herring. For example, everyone in this thread appears to have overlooked the fact that your two programs use completely different buffering strategies. Your Rust program is line buffered, but your Go program is block buffered. Finally, if your are indeed writing serious CLI programs, then it's likely the Go program you've written will fall over pretty quickly on more exotic inputs. In particular, Go's bufio.Scanner bakes a maximum line length into its scanning by default (64K), which will cause your program to quit and give up upon seeing such a line. You instead need to modify the scanner to use a larger limit via the Buffer method before scanning.
No, it's not generally able to do that (not for public functions anyway). It usually only occurs in a single function, which is one reason why the inlining is important.
`FxHash` is really rather poor compared to `FNV` for small inputs. I've tried `SIP`, `FNV` and `FxHash` in a project whose performance depended quite a lot on a single `HashMap` with 64-bit keys, and a simple benchmark showed this result (don't mind the units, the important thing is higher is better): map \ hash | sip | fnv | fx :-------------|-------:|-------:|-------: | std | 49.19 | 52.48 | 7.56 | | hashbrown | 63.00 | 86.67 | 13.75 | | indexmap | 55.21 | 68.60 | 1.30 | It's clear that `FNV` is the best, `SIP` is decent, and at least for my usecase `FxHash` is abysmal (lots of collisions maybe? I dunno.)
Thanks a lot! I was able to make these changes and it also helped my benchmarks by avoiding all those string allocations.
thanks a lot, I will keep an eye on that
`libc` has maintained compatibility for over three years of active maintenance. I don't think any definition of "stable" that excludes this crate is a useful one. 
The idiomatic way to implement your Go Add() function should be: func (c *Counter) Add(item string) { c.uniqueItems[item] += 1 } There is no need to test for a missing key when counting, since any missing keys will start with the zero value. This halves the number of hash lookups, and shaves about 15% off the runtime with your test input. 
Note that the impl blocks are in the same module, so there shouldnt be any coherence issues. And the compiler already complains if one has repeated items in the same impl block; why couldn't it do that in this case?
As a Rustacean, I just wanted to say that I appreciate you giving other languages credit where is due. You da man. :)
Hey /u/TeXitoi. I just found this thread via Google search. I'd found blue-pill-quickstart through other methods and I just want to extend my gratitude. It's definitely just the start of my journey here, but I was worried I was going to spend days figuring out how to get just the most basic code working. You're the bomb.
These suggestions are all well and good, but how can people be guided to the correct implementation in the future so they don’t have to ask for help
Seems like no because you need to be able to build against the rustc LLVM. Looks like it would be pretty easy to do if you used the system rustc (ie not rustup) if only you had a system rustc that let you call -Z to manually add an LLVM pass but I'm not aware of any distros that ship a nightly rustc. All this seems to imply you'd need to rebuild rust nightly against system LLVM or build the LLVM dev tools otherwise. May be worth pushing to stabilize some -Z flags for compiler options like LLVM sanitizers and passes, with the understanding that they may change based on LLVM version.
&gt; I am not sure that Rust is well-positioned to replace JavaScript here; nor that it should even try. Here are some reasons why Rust **should** try: - A lot of people who already know Rust would like to use it for web frontends, rather than some weakly typed language. - Libs for things like like charting, maps, data visualization, cryptography etc. that are written in Rust would also benefit JS apps - Being able to use high-quality Rust crates in the frontend - Fullstack Rust: Being able to share code between backend and frontend will allow for more typesafe API (&amp; overall app) development - When Rust is a good choice for frontends it will also become more used in backends due to the fullstack synergy and having to use less different languages in the stack - A lot of people work in web frontends and would be interested in learning Rust when it becomes a good choice for frontends - Since Rust has no good GUI solution yet, if it becomes a good choice for frontends that would be less of an issue
Thanks, that makes sense...so really I should just compile each architecture separately (not using cargo-lipo) and have each one link against its (non-fat) native counterpart? That does make sense, although it's a bit more setup, obviously.
If you did a study with the same approach on "what makes Java apps slow" you wouldn't find the root cause either.. Yet the same apps would be faster when written in Rust, and thus the apps **could provide more functionality/features** consuming the same resources. (E.g. writing a game in Python vs in Rust. In Rust, you can do a lot more each frame.) Web apps written in Rust could approach desktop apps functionality-wise.
What toolchain are you using, beta or stable?
That's... My whole point?
There are also these: https://crates.io/crates/autoit https://crates.io/crates/inputbot https://crates.io/crates/keystroke
Yep that’s the talk! 
You could use the [time::Duration](https://docs.rs/time/0.1.41/time/struct.Duration.html) type, depending on how your code is structured. If you have some state and a loop that you're running every so often, say, 60 times a second, you could have \`game\_state: Duration\` as part of your state and \`game\_state = game\_state + Duration::microseconds(1\_000\_000/60)\` every time the loop runs. When you need time to slow down you would add a smaller amount to it.
Proc macros work just fine in Rust 2015 too. In fact almost everything does, there's only a very tiny amount of 2018 only changes. (However I'd still recommend the 2018 edition going forward)
Thanks for the response that was very informative! I do actually use stable rust, and additionally I use the one packaged in Ubuntu 18.10 so whilst not terribly old (1.30.0), it will be behind and isn't nightly and most importantly not the 1.32 you mentioned. Hopefully it will make it into 19.04 as I prefer to stick to distribution versions of the rust toolchain.
Interestingly, it only removed 0.1 MB. As was pointed out in another comment most of the binary size might actually just be the time zone data itself brought in by chrono-tz.
Thanks for the response. Your link looks really interesting! I will definitely give it a read before moving forward. And thanks for the review. I find these small pointers very useful so will definitely keep them in mind!
Coming back to this, from v0.3 and on files are written atomically. Thanks for the constructive feedback!
&gt; RFCs that primarily add complexity do not at all "vastly outnumber" the RFCs that don't add complexity In my initial post I mentioned _cost_, not "complexity". I believe that more than 3/4 of the set you enumerate here increase total costs (if we include implementation costs, extra cases to document and teach, and so forth). You may justify this in some "factoring" whereby you claim consistency is not a form of cost, but I've already stated earlier that I believe this is incorrect reasoning. A couple special cases is often much cheaper -- to implement, to learn, to use -- than a consistent general treatment. &gt; I don't appreciate your "can't help yourself" tone here Graydon. I apologize for the snark. I guess the point I was trying to get at is that it seems to me -- reading the way you write so casually about the costs of further extension to the language -- that you underestimate how serious they are. You have a formidable mind and a very optimistic spirit about users' ability to keep up with you (and interest in doing so). I believe Rust is already quite a ways beyond where it ought to be in terms of cognitive load, implementation and maintenance cost, teaching cost, etc. So I think it harms the language and community to increase those costs much further. &gt; It's about sunk cost; once you have introduced the notion of types depending on values, I think much of the cost of learning dependent typing has already been paid. Absolutely disagree. The "value dependence" that exists in the const generics system is on _compile-time constant values_ which are explicitly segregated from general runtime values (both in binding positions and functions) and defined to be concretized at monomorphization time, i.e. _not_ breaking the runtime barrier. Further, even earlier at type-check time they are _almost completely_ concretized, with only _one_ very minor escape hatch that allows judging an equality between two abstract constants if they are literally the same binding. That is nowhere near a fully-paid-for dependent type system -- neither in implementation nor in cognitive costs -- and it is disingenuous to claim that it is (especially since it's been so clearly engineered to _not_ be one).
With pleasure :-)
&gt;Don't worry too much about it. As they say: shit happens. I'm trying \^\^
If you are using msvc toolchain then it won't work. They are incompatible, use gnu instead
We're all subject to implementing non performant and non optimal implementations on any platform or language. The more experienced you are with your language/platform the better to avoid common pitfalls like those above. But bugs will come eventually. So keep studying and keep developing on those. And remember that premature optimizations without analysis and measurements are bad things :) 
There's a PR doing just that [#56241](https://github.com/rust-lang/rust/pull/56241) 
This is excellent advice thanks, will definitely take a look into using a BufReader instead. &gt; Finally, if your are indeed writing serious CLI programs, then it's likely the Go program you've written will fall over pretty quickly on more exotic inputs. In particular, Go's bufio.Scanner bakes a maximum line length into its scanning by default (64K), which will cause your program to quit and give up upon seeing such a line. You instead need to modify the scanner to use a larger limit via the Buffer method before scanning. Shamefully I did not know this was the case (just goes to show edge cases will always catch you out if you're not careful...) so thanks for pointing that out. 
Just tried this, it works and is definitely easier to read code, the downside is the performance still seems to be worse than the Go version by about 10% (in comparison to the solution /u/daboross suggested) Not sure why that is, maybe the reuse of `String` helps? 
As mentioned above, just redid the test with `lines()` and it's still about 10% slower than the Go version. I'm assuming there's some overhead in `lines()` like reallocating strings etc? At the end of the day I'm not looking for blazing fast performance, it's a trivial program, was just curious to see if a Rust version could be quicker or not!
Didn't expect to come to a rust thread to learn something new about Go, thanks! 
Stable (1.31.1)
Can you submit a PR to help try to stop this from happening again, probably within the next month?
I just realised my R and S values change every run, not exactly what you'd expect from a cryptographic signature! &amp;#x200B; The sha256 digest is fixed, so I'm suspecting the problem is how I construct the private/public key from the JWK.
Sure thing. First let's go with something that works: lib.rs: `fn hello() -&gt; String {` `"Hello World".to_string()` `}` `#[cfg(test)]` `mod tests {` `use super::*;` `#[test]` `fn it_works() {` `assert_eq!("Hello World", hello());` `}` `}` This works and passes the test. However if I add: [parser.rs](https://parser.rs): `fn hello2() -&gt; String {` `"Hello World".to_string()` `}` Even though this code is not called, IntelliJ complains to\_string is an unsolved reference (?) however, everything still works fine (haven't changed [lib.rs](https://lib.rs) yet). I change [lib.rs](https://lib.rs) to: `use parser;` `fn hello() -&gt; String {` `hello2()` `}` `#[cfg(test)]` `mod tests {` `use super::*;` `#[test]` `fn it_works() {` `assert_eq!("Hello World", hello());` `}` `}` It tells me hello2 is not found, it tells me parser is an unsued import (??). Adding or removing `pub` from hello2 reports the same problem. Changing `use parser` to `use parser::*` reports the same problem. Adding to parser.rs: `use std;` `use std::string::ToString;` Makes IntelliJ keep complaining that to\_string is an unsolved reference. (And don't even get me started trying to move the test files to their own individual file). There are a few things I'm obiusly doing very wrong: Is the std library only imported by default on [lib.rs](https://lib.rs)? Why I'm failing to resolve the paths?
Yeah, `lines()` allocates a new string per line. It isn't a huge cost, but it makes a difference when compared to reusing the same allocation for every line.
Just tried it with the hashbrown crate, for this particular test it is definitely faster! https://gist.github.com/djhworld/ced7eabca8e0c06d5b65917e87fb8745
Yep just redid the test with the hashbrown crate, it is indeed faster https://gist.github.com/djhworld/ced7eabca8e0c06d5b65917e87fb8745
did you try compiling with the beta compiler?
Edge is not IE. If the users must use IE, they might as well die
It would help if you said what other operations you are looking for specially and which crates you already looked at.
I've added a comment to this issue https://github.com/rust-lang-nursery/cli-wg/issues/29 I'll see if I can discuss this somewhere too!
I am not familiar with .Net so I would just use python for everything except time sensitive operations. For writing API server in rust: rocket.rs - REST juniper - GraphQL I may as well use python pandas for Excel stuff, doing it Unix style (one program do one thing).
Thank you for introducing me to `hyperfine` - that's another tool to put in the box! 
The operations I am looking for is the ones I listed. Basically, I need consistent interface, not extra functionality. There are no creates for that.
Can you perhaps give an example of a "consistent" API?
It's normal, that's how ECDSA signatures work
Oh?! ... So I can't really expect to get the exact same values as in the RFC?
TIL [https://stackoverflow.com/questions/20570625/dsa-generates-different-signatures-with-the-same-data](https://stackoverflow.com/questions/20570625/dsa-generates-different-signatures-with-the-same-data) &amp;#x200B; Thanks!!!
See https://gist.github.com/djhworld/ced7eabca8e0c06d5b65917e87fb8745
`use parser` isn't how you import the module `parser` - to do that you need to put `mod parser` in your `lib.rs`. Once you do that, you'll still get an error about how `hello2` is not in scope, or something like that. The reason is that `hello2` is in the scope of `parser`, so to call it, you need to either call `parser::hello2`, or have a `use` statement such as `use parser::hello2` (`use parser::*` also works, but it's a little scary). After that, you'll probably **still** get an error, complaining that `hello2` is private. This one's simple, just add a `pub` to it.
Link to Rust repository: https://github.com/ixy-languages/ixy.rs
Use [retain](https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.retain). Not sure this is the best way though, since retain requires you to invert the logic.
I like rsfs because it facilitates unit testing.
As you are processing on `char`, you can `Copy` it into a value by dereferencing. That way the borrow will end, solving the problem. ``` let least = set.iter().cloned().anything ...;
`read_all` and `write_to_bytes` do not exist, so maybe you confused the names, but anyhow: if all you need is to read / write entire files (not sections of files), you can get away with: * std::fs::remove_file * std::fs::write * std::fs::read * std::path::Path::new("path").exist() The fourth one is what stands out as being inconsistent (we should probably make a shortcut in `std::fs` for that?) but at least it seems to be slightly more consistent than the above, right?
- fs::open - fs::exists
I mean you could always just make your own, doesn't seem to be too hard. fn exists(path: impl AsRef&lt;Path&gt;) -&gt; bool { path.as_ref().exists() } fn open(path: impl AsRef&lt;Path&gt;) -&gt; Result&lt;File, Error&gt; { File::open(path) }
Yeah it's a bit inconsistent. To open a file you have to call a constructor-method on a `File`. So that's: let file = fs::File::open("some_file.txt")?; However to get a file's metadata as a `Metadata` struct, if it was consistent there would be let metadata = fs::Metadata::stat("some_file.txt")?; but instead there's a freestanding function: let metadata = fs::metadata("some_file.txt")?; But well, you get used to it. The API is not that big. By the way, to see if a file exists, you don't have to use `std::path::Path`, this will do: let file_exists = fs::metadata("some_file.txt").is_ok();
[removed]
jfyi sort | uniq -c
You are fast!
yes, I'm aware it's a trivial application that can be replicated with existing tools. The downside to the `sort | uniq -c` approach is you have to sort the data first, which depending on the size of your input can take a long time. To compare, the updated rust version (which does 1 pass over the data and stores the uniq entries in a hashmap) vs `sort | uniq -c` is about 196x faster (11.8 seconds vs 60.1 milliseconds) $ hyperfine -r 5 "cat file.txt | sort | uniq -c" "cat file.txt | ./target/release/count" Benchmark #1: cat file.txt | sort | uniq -c Time (mean ± σ): 11.831 s ± 0.296 s [User: 11.855 s, System: 0.125 s] Range (min … max): 11.573 s … 12.312 s 5 runs Benchmark #2: cat file.txt | ./target/release/count Time (mean ± σ): 60.1 ms ± 3.5 ms [User: 54.5 ms, System: 10.1 ms] Range (min … max): 56.1 ms … 65.2 ms 5 runs Summary 'cat file.txt | ./target/release/count' ran 196.86 ± 12.52 times faster than 'cat file.txt | sort | uniq -c' Depending on cardinality of your input data, the memory usage between both implementations might differ 
&gt; Here are some reasons why Rust should try: That's a beautiful list of reasons. I particularly subscribe to the idea of making Rust more ergonomic for everyone. It's still not clear to me whether Rust's ergonomics can rival those of GC'ed languages. I do personally value having clear lifetimes (Stockholm Syndrom from 11 years in C++, maybe?), however I've done enough Java to realize that many times it just works with a GC. &gt; Y'all want there to be more Rust jobs. A lot of work is in web frontends. When Rust becomes a good choice for frontends there will be more Rust jobs. I've done some frontend work in the past, didn't enjoy it; I'm really a systems programmer at heart: I want oil up my elbows as I wrangle with network packets and finicky devices, or as I coordinate complex distributed applications spanning multiple datacenters. This means that, personally, I am not just looking for "more Rust jobs", I'm looking for jobs in a particular domain; I'd be happy if they're in Rust, but I've been doing C++ for so long I don't mind too much. I may not be the only one...
**Thank GOD**. That first part makes a lot of sense now. Finally I get the difference between a namespace and module, I thought they were the same thing all along. The std part solved automagically when I added the mod and use parser, I guess if a file is disconnected from the project it doesn't automatically link the std import to that specific file. One last question. I've created a directory file at the same path as src and there is a [tests.rs](https://tests.rs) file in it with this: #[cfg(test)] mod tests { //use testProject::parser::hello2; use testProject::hello; #[test] fn it_works() { assert_eq!("Hello World", hello()); } #[test] fn it_works2() { //assert_eq!("Hello World", hello2()); } } With the uncommented use line it tells me that parser is private. How ccould I then test things from parser? I'm supposed to make it public? I'm supposed too make the tests inside the file that I'm testing on?
To help my understanding, is it the case that the borrowed version is actually a pointer to somewhere within the HashSet structure? So that when you call `set.remove` later the HashSet could do anything it wants, inclusing reallocating and rehashing, so that your reference/pointer is now pointing at invalid data? Hence why the original program is not safe in general. 
Thank you, that worked. As a reward for your assistance, you get another question ;) &amp;#x200B; Consider [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=413e7a61a8a88f031191aab818302365) example. This time, I want to remove all elements satisfying a predicate from the set. This doesn’t compile. I don’t understand why the borrow outlives the invocation of `cloned.`
No, that's not a thing. References are just references, and they have nothing to do with an actual entry in the HashSet. The remove function accepts a reference just because it doesn't have to take a value. The original program isn't considered safe because `least` becomes dangling during the removal of the element in the HashSet. That's it.
I found interesting that the Rust version had seemingly lower throughput but better tail-latency than the C version. If both implemented the same algorithm, I'd expect the tail-latency graph to be roughly similar. 
For that particular case, use `retain`. This outlives because iterators are one-by-one, and they don't fully process the previous combinator before doing the next. Thus, the removal would happen right after the first element matches the filter, where the reference to the `iter()` is still alive.
Wait you say parser itself is private? That's a little strange. Generally, it depends on what you want to test, but if you want to test private functions (like unit testing), then you make a `tests` module inside the file. In this case, your `hello2` is meant to already be public (right?). If you have a tests.rs file, then you probably don't want to write `mod tests` again in that - simply have all your test functions labelled with the right attribute, and in your lib.rs have #[cfg(test)] mod tests; But I still find the part about parser being private strange. What exactly is "testProject"? If you can call `hello2` from whatever module is above the tests module, you should be able to call it from the tests module itself (e.g. like `::parser::hello2`) - public/private visibility is again a separate thing from the others.
What if we accelerate go a little bit by disabling the garbage collector? ;) https://stackoverflow.com/questions/38972003/how-to-stop-the-golang-gc-and-trigger-it-manually
I need an efficient data structure with hash map semantics, but I know it's virtually never going to contain more than 20 or so key-value pairs, so I think I should back it with a vector. Is there a common name for this? I haven't been able to come up with the right search query to find any relevant results so far. I can implement the `HashMap`\-like API on a `Vec` newtype myself, but there might be things I haven't thought of.
I'm not sure why the other guy said no because the answer is yes. I would avoid thinking of them as pointers, but yes `least` is a pointer to the actual value in the set. Because the `remove` function mutates the hash set (takes `&amp;mut self`), the reference must be dropped before this method can be called because the borrow checker is preventing exactly the problem you're describing.
The API is really not inconsistent at all. Here are a few points to consider: * A `File` has a `metadata` method, so you don't actually need to use a freestanding function if you already have a `File`. * Depending on your platform, `fs::metadata` and `File::metadata` may have different implementations. For example, on Linux, the former can be implemented with `stat` while the latter might be implemented with `fstat`. The former, for example, does not require creating an explicit file descriptor. I think once /u/2nd-persona becomes more familiar with Rust library API design, they'll find that the `std::fs` API is perfectly fine. To answer the OP, no, there is no alternative "more consistent" API for file system operations because, as far as I'm aware, there are no substantial criticisms against the current design. There may be crates out there that provide a more platform specific set of file system operations, but the standard library is the thing to use if you want cross platform support.
[Slides](https://github.com/ixy-languages/ixy-languages/blob/master/slides/35C3.pdf)
Thanks again. I thought that if such a method existed on `HashSet`, it would be called `filter`, so I didn’t look at `retain`.
&gt; there wasn't sufficient time to validate it in time for Rust 2018. The standard library has to have the same API across editions. We can change implementation details at any time. This is an implementation detail. 
To be a bit more explicit, a project with a `Cargo.lock` that contains a yanked version will still build, but new projects trying to create one with a yanked version will not.
You can guess what happened next.
Here are a few shortcuts that I usually use instead of matching on `Result`: [https://github.com/Wojtek242/rwmstatus/issues/1](https://github.com/Wojtek242/rwmstatus/issues/1) In general, it is worthwhile to read about `map`, `map_err`, `and`, `and_then`, `or`, ... for [Result](https://doc.rust-lang.org/std/result/enum.Result.html) and [Option](https://doc.rust-lang.org/std/option/enum.Option.html). There is also a great crate [boolinator](https://crates.io/crates/boolinator) which provides nice helpers to get `Option` from `bool`, so then you can use the methods listed above.
&gt;`.filter_map( Result::ok )` this syntax weirds me out. is it equivalent to `|x: Result| x.ok()`?
Just to make it clear, this is what is going on: [https://imgur.com/a/hOFdDya](https://imgur.com/a/hOFdDya) I guess I can add the test on each file individually (which kind of makes sense since I may try to test private stuff) but it just makes my head hurt because there is something I don't understand yet.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/9B7Wdmg.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20ecvgij9) 
Yes to both questions. The name for this syntax is [Universal Function Call Syntax](https://doc.rust-lang.org/book/ufcs.html) and it has the advantage of being completely unambiguous.
Is rustfmt available for the latest rust release (1.31.1)? If I run `rustup component add rustfmt` I get `error: toolchain 'stable-x86_64-unknown-linux-gnu' does not contain component 'rustfmt' for target 'x86_64-unknown-linux-gnu'` Do i have to switch to nightly? &amp;#x200B;
&gt;I fear this approach won’t fly since the references might be invalidated when some children Vec has to be reallocated. Rust will not allow such code at the first place. If you need a tree structure than take a look at `ego-tree` or `rctree`.
This is cool as fuck
I have recently seen [fixed-map](https://github.com/udoprog/fixed-map) but not yet used it
Have you read https://cglab.ca/~abeinges/blah/too-many-lists/book/ ?
Also you should check out other options like \`pub(crate) fn\` if you want something to be seen by your whole library but not outside the library
I believe a similar word count talk was topic of one of the latest hello-rust episodes. Have a look at their repo.
You could also consider using BinaryHeap (instead of a set) since these are designed to always remove the "max" element (by some metric).
The node is supposed to live as long as the double linked list itself, from your declaration But the node object in insert is only valid in the method's scope Also, I see you used Defined in the if, to take ownership of node, why not do the same during connect call Also can you please tell what is that Definable thing supposed to do, didnt find anything from a quick search 
Seriously though, they're quite annoying. &gt;tfw you get a pen drive from some dude and there's a .DS_Store &gt;reeeeeee
Okay that is really cool too. Thank you very much for helping me out here :)
This guy talks really fast and know what he is talking about.
Thank you, but I don’t want a generic tree. I have my own type-safe structure that I have stubbed out at the bottom of the playground link.
Thanks a lot! I've since been thinking about if it makes sense to add a "performance tips for CLI apps" chapter. The main premise of the book in regard to performance has so far been "no need to think about it" (because the assumed audience is people who come from writing bash or python scripts). But now I think having a specific chapter to explicitly state what common bottlenecks are and how to find them yourself would be helpful. Can't promise I'll get around to writing something this year (😉), but I'd certainly like it if someone wanted to help out!
That wrapping in a function call example is not needed. You can add a type declaration on styles to get that to work.
&gt; In my initial post I mentioned cost, not "complexity". I believe that more than 3/4 of the set you enumerate here increase total costs (if we include implementation costs, extra cases to document and teach, and so forth). You may justify this in some "factoring" whereby you claim consistency is not a form of cost, but I've already stated earlier that I believe this is incorrect reasoning. I'm primarily interested in costs for end-users; not implementation or design costs. As for "extra cases to document and teach", I think the changes enumerated above primarily remove extra cases (including in documentation) wherefore they make the language easier to learn. Many of the changes also do have low implementation costs, for example `Self(x, y)`, and it has about 30 minutes of documentation costs in the reference + a mention in the release notes. I and others who care about consistency are willing to pay these costs ourselves. A change like `if let p = q &amp;&amp; r { ... }` is something that would benefit `rustc` a lot and would produce cleaner code in the compiler (sorely needed!) and would thus pay itself many times over implementation complexity wise. &gt; A couple special cases is often much cheaper -- to implement, to learn, to use -- than a consistent general treatment. Perhaps in the abstract. As for the specific cases, which I've enumerated from the past year, I don't think that applies for learning at least. I know that people have tried writing `Self(x, y)` in the past only to get an error. That suggests to me that the language was violating people's mental models. I also cannot fathom why `p | q` only at the top level of `match` expressions should somehow be easier to learn than being able to write `Some(0 | 1) =&gt;`. Likewise, I don't see how oly having or-patterns in `match`, but not in `if/while let` should somehow be more comprehensible. &gt; I apologize for the snark. &lt;3 &gt; I guess the point I was trying to get at is that it seems to me -- reading the way you write so casually about the costs of further extension to the language -- that you underestimate how serious they are. I'm not saying let's casually implement HKTs or dependent types without deep considerations (especially the latter, and especially due to soundness risks). I'm saying that *I'm not willing to rule them out forever*. As for being casual about the costs of extending Rust, I obsess about end-user complexity all the time. I might not always succeed, but I try to make sure that every change we make is maximally easy to learn, consistent, and compositional. Indeed, the huge bikeshed we had about `try { .. }` was purely about trying to limit end-user costs of the feature. &gt; You have a formidable mind and a very optimistic spirit about users' ability to keep up with you (and interest in doing so). I don't try to add features to Rust for the sake of it; I try to see what needs there are and what problems users are facing and then try to solve those problems in a balanced and low-cost high-power way. I also do think that not everyone must necessarily learn every part of the language. For example: I don't need to deeply the theory of machine learning to use tensorflow, I don't need to learn category theory to understand the practical applications of monads in Haskell, and I don't need to understand how `serde_derive` is implemented to make use of most of it. Language features are in my view similar: I don't need to care about `#[repr(C)]` unless I'm doing FFI or have those layout requirements. Realistically, for any language of sufficient complexity (including Golang), not even the language designers and implementers can hold it all in their heads at once. This is certainly true of Rust: I don't know every detail of every corner of Rust, and I don't need to. &gt; I believe Rust is already quite a ways beyond where it ought to be in terms of cognitive load, implementation and maintenance cost, teaching cost, etc. So I think it harms the language and community to increase those costs much further. I think we just disagree here; but if we're talking about cognitive load and complexity, what I worry about is specialization and the loss of parametricity; in particular, the restrictions and the `specialize(...)` modality in recent proposed designs, while necessary to achieve soundness and sufficient flexibility, seem tricky to understand from an end-user POV. Heck, they are even hard to understand for designers without us applying ourselves. &gt; Absolutely disagree. The "value dependence" that exists in the const generics system is on compile-time constant values which are explicitly segregated from general runtime values (both in binding positions and functions) and defined to be concretized at monomorphization time, i.e. not breaking the runtime barrier. Further, even earlier at type-check time they are almost completely concretized, with only one very minor escape hatch that allows judging an equality between two abstract constants if they are literally the same binding. I'm aware of the various limitations in RFC 2000. Even within the compile time barrier, I see the RFC as a stepping stone. Eventually I think people will want to lift some limitations so that they can write more compile time logic. However, while I don't doubt breaking the run-time barrier will have large implementation costs, from a end-user conceptual POV, I think there's not a huge difference -- but we might just disagree here. &gt; That is nowhere near a fully-paid-for dependent type system -- neither in implementation nor in cognitive costs -- and it is disingenuous to claim that it is (especially since it's been so clearly engineered to not be one). I certainly don't think it's fully paid for in terms of implementation nor design, I was purely talking about cognitive costs. As for implementation and design, it seems to me that breaking the run-time barrier might need a PhD thesis or two. It's not a near term project by any stretch of the imagination. Fortunately Conor McBride, and I also believe some people at my university (Chalmers), have been dabbling with linear + dependent typing for a while.
&gt; Shamefully I did not know this was the case No need to be ashamed of not knowing as much about text processing as the _author of ripgrep_ :-D
What's the reason the function parameter of `binary_search_by_key` is required to return `B` and not `&amp;B`? The function is implemented as pub fn binary_search_by_key&lt;'a, B, F&gt;(&amp;'a self, b: &amp;B, mut f: F) -&gt; Result&lt;usize, usize&gt; where F: FnMut(&amp;'a T) -&gt; B, B: Ord, { self.binary_search_by(|k| f(k).cmp(b)) } Since `cmp` doesn't take ownership of `self`, this would still work if `f` returned a reference, right?
Then you can take a look at those libraries to see how they work. The problem with your code is that you can't use references like this. You should use indexes, Rc or unsafe.
I didn't see him comparing latency with C? Only with C#?
Or you could use a `BTreeMap`, if you need both Map functionality *and* max/min-finding.
Ah! Missed the # :(
I have just opened an issue suggesting adding C to the graph: [https://github.com/ixy-languages/ixy-languages/issues/1](https://github.com/ixy-languages/ixy-languages/issues/1)
Deno is a `typescript` runtime with restricted access to the network and the filesystem by default, with the backend (the actual network/filesystem parts) written in `rust` and `tokio`. I'm not affiliated with the projet at all, but it looks really interesting, and these docs explain well how it works under the hood, including the rust parts. 
The problem with transferring ownership by calling 'connect' is that I could possibly have multiple nodes getting connected, so that possibly multiple nodes take ownership of the node I wanted to insert in the first place. &amp;#x200B; Imagine having a LinkedList with two nodes already inside: &amp;#x200B; \[ a \] \[ b \] ---insertion---&gt; \[ a \] \[ c \] \[ b \] &amp;#x200B; When I insert another value ***'c'***, I create a corresponding node and insert that into the list by connecting it to a and b and vice versa. That would mean, that ***'a'*** holds this 'Definable&lt; Node&lt; T &gt; &gt;' as well as ***'b'***. The problem is not 'Definable' since I can unwrap and wrap it again but the node inside is being owned by more that one 'Definable'.
Hello and welcome to Reddit, I see this is your first post and want to help you out, so have an upvote on me :)
Oh, I’m dumb, it totally works when simply using indexes! [https://github.com/flying-sheep/rust-rst/commit/6d995f698f580aba9e67b847432899ce841e6e7d](https://github.com/flying-sheep/rust-rst/commit/6d995f698f580aba9e67b847432899ce841e6e7d)
In my experience, it takes a **very** significant amount of business logic to overshadow the performance of database calls. As a rule of thumb, expect: - `select 1 from foo;`: 0.1 ms. - `commit;`: 5 ms. A 4 GHz CPU will execute 4,000,000 additions in a single millisecond; without any fancy vectorization either. So, in most cases, the database is the bottleneck of anything interacting with the database, and therefore the benchmarks that matter are those involving database calls. Thus, I'd advise to favor "Fortunes". --- Now, most likely you will be disappointed by the performance of Rust on the "Fortunes" benchmark. The issue is blocking I/O: the processing thread being blocked waiting for the result of the database call. Async I/O is still not stabilized, and once it is it may take some time for the ecosystem to adjust... although being so eagerly expected it may adjust quicker than I give it credit for. The difference between Sync and Async I/O is such that on the "Fortunes" benchmark it is likely to see the most performance-oriented Rust framework move above the 95% mark once adjusted; it's just a tremendous game changer.
Just wanted to say, it made me smile seeing a font i made popping up in this game. :)
It’s also notable because it was created by the original author of Node.
I mean, it’s stable in the sense that it can be used on stable. It’s not as nice to use as it will be, but many of these entries already use async.
I think you need smart pointers may be Rc&lt;T&gt; Either way, you cannot have the data on the stack and insert using reference to that, as it wont live long. With Rc&lt;T&gt; two nodes left and right can have reference to the middle one. 
Oh, nice! :) 
@8:30 - did that madman write a driver in *bash*?
@8:30 - did that madman write a driver in bash?
Instead of new syntax the compiler could try to excise the meaty logic of generic functions that accept `Into` parameters and automatically create the `_inner` version. Alas, for now you have to write that code yourself. From the syntactic sugar point of view, the o ky "improvements" I could see are auto-calling `into()` when possible (I'd be cautious about introducing such behavior) and accepting inline traits in arguments, instead of having to specify the generic arg explicitly (Wich again would be an ergonomic when writing code, but slightly worrying when reading code).
Thanks for the response. Is there a native rust library for handling async I/O. I have read articles saying that in 2019 rust language is gonna get native Async/Await capability. 
Turns out I can easily circumvent this problem if I switch to the namespace at the beginning of my program, then open a socket within that namespace, and then switch back to the original namespace. The file descriptor for that socket will remain in the namespace and you don't have to care about namespace switches later in the program.
Thanks. I would love to get involved with getting the infrastructure in place for building audio plugins and GUI/audio apps in Rust, but my time is pretty limited these days. Maybe 10 years ago when I had more free time and less commitments. I follow the rust-vst project's progress and really admire the work those guys are doing. Its weighing up a) going with what I know (JUCE) and know it will fit my needs well, versus b) interesting technical challenge, using a language I prefer over C++, with more freedom in the way I write code. Or to put it another way a) spend time building an application or b) spend time building a framework in order to build an application. 
`B` can be anything, including a reference type! The restriction actually goes in the other direction: if the function returned `&amp;B`, then it wouldn't be possible to use a value type like `i32`.
Rust is a rather harsh language for amateur data structure implementation. The main [problem is this.](https://www.reddit.com/r/rust/comments/7urlxj/how_to_please_the_borrow_checker_when_struct_has/). There are workarounds for it that preserve the borrow checker invariants (rental is one) but most of them just use unsafe (which..., yeah).
Thanks, you are correct. I was looking at all of `rust-url` and being sloppy.
Nice anagram name. The back end was originally implemented in go. https://github.com/denoland/deno/issues/205
Async/await is syntax sugar for futures. Tokio is the standard futures runtime.
In that case it is a cli so nowhere to leak it to. For a library yes it shouldn't leak it like that
Oh hey! Thanks for the fantastic font! I've been using it as my primary programming font for *ages*! For anyone else reading this, the font is mononoki and it's an absolute pleasure to use: https://madmalik.github.io/mononoki/ https://github.com/madmalik/mononoki/tree/master
I like to see embedded Rust in this subs.
What exactly does it mean to be a TypeScript runtime? It just compiles your TypeScript to JS for you instead of needing to manually invoke `tsc`?
From the [`denoMain()`](https://github.com/denoland/deno/blob/master/js/main.ts) function, which is the entry point on the typescript side, it appears that it compiles by himself the code, no need to use `tsc` before. And, I'm not yet sure, but from what I understand of the [`main.rs`](https://github.com/denoland/deno/blob/master/src/main.rs#L100-L101), the `denoMain()` function is loaded from a `V8` snapshot. 
I recently discovered that tokio async channels seems to be fine driving the sending vs receiveing end in different tokio contexts. couldn't see the docs mentioning that, and I don't think it necessarily goes without saying. 
glium "died", and then [the people who liked it picked it up and kept trucking](https://github.com/glium/glium).
The specific thing I needed was the smallest `char` (in the conventional ordering) of a certain subset. So I thought `.filter(…).min()` was quite natural.
Posted a multi-threaded version on a separate branch : [https://github.com/djeedai/rayst/tree/mt](https://github.com/djeedai/rayst/tree/mt) This simply spawns 4 threads and raytrace approximately a quarter of the image rows per thread. Most difficult part was finding how to iterate over the threads and take ownership of the return \`Vec&lt;u8&gt;\` generated; couldn't find a way to iterate forward and take ownership of the vector item, but turns out I needed to iterate backward so \`pop()\` did the trick.
The votes indicate I was unclear or misread you. I understand this to be your main point followed by your supporting argument: &gt; Rust is simply too young compared to other languages. Look at the versions on most of our major crates. Your supporting argument is the antithesis to the point I was trying to make, which was: **don't** use the (major version number) to assess a Rust crate's maturity.
Hmm, they use `rayon`'s `par_iter()`: https://github.com/hello-rust/show/blob/master/episode/9/rust/fixed/src/main.rs. It avoids the whole issue by scoping the data to the iterator, which isn't possible (or at least not simple) with just rust's stdlib.
Have you tried https://github.com/dpc/crev/tree/master/cargo-crev yet?
This is awesome. I've been working on the opposite side of broadly the same problem: data-mining information out of crates and associated data sources (like github). I hope to make this my primary project next year and have a website where the results of this analysis for each crate is presented and can easily be explored. One of the sources of data for a crate is the people involved, and `crev` sounds like an *excellent* tool for gathering and verifying this information. Thank you for attempting to solve such a fundamental problem!
I'd very much like to embed more automatic metrics into `cargo-crev`, to make it easier for people to prioritize which crates are potentially in need of a review in the first place. So if you have a website like that please make sure there are nice APIs to get this information :)
/r/playrust
Why isn't it 1.x yet? I mean the SemVer FAQ says this: &gt;**How do I know when to release 1.0.0?** &gt;If your software is being used in production, it should probably already be 1.0.0. If you have a stable API on which users have come to depend, you should be 1.0.0. If you’re worrying a lot about backwards compatibility, you should probably already be 1.0.0.
macros
maybe make `dry_run` a `enum RunType {Dry, Wet}` so `pub fn run_cargo_update(dry_run: bool)` would be `pub fn run_cargo_update(run_type: RunType)` and you would call it as `run_cargo_update(RunType::Dry)` (or `RunType::Wet`). This is so that people who are reading the code know at a glance what the data means (`true` and `false` don't mean much without context) As for code duplication... I feel like `let success = || -&gt; Result&lt;(), Error&gt; { ... }` should be extracted into a single function (specifically the unnamed closure maybe not the actual `bool` part, since maybe something will *want* the `Result` instead). Maybe you should stick it on `Executor`? Not sure.
Use [`retain`] (https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.retain) for exactly this purpose. 
I would recommend expanding on that more so that OP knows what to macrofy and how to do so (and personally I think they should also know why that might want to prefer macros over anything else)
AFAIK the wakeup mechanism of futures 0.1 (Tokio) and 0.3 are incompatible. Futures 0.3 types expect to get woken by calls to the passed LocalWaker. However the Tokio async await preview doesn’t implement it, but passes a LocalWaker which panics when used. It would then only be compatible with other tokio futures (not the ones in futures-es). That is what you might see. Things might work better if you use the futures 0.3/0.1 compat layer from inside the futures-rs repo instead of tokio async await preview. However I don’t have experience with that one yet. 
It *is* natural, but (depending on use case), it might be even *more* natural to use [`BTreeMap::range`](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html#method.range).
Ahahaha I hadn't even *thought* of producing an API or such. Right now everything's statically-generated pages, and I kind of want it to stay that way for reasons of robustness and security, but I suppose I could always provide JSON database dumps or something similar that could be fetched and queried easily. Saying which crates are in need of review is definitely on my to-do list as well. Shouldn't even be hard to do, to a first approximation, just weight "is this crate used by lots of things?" and "is this crate not reviewed well?". Something else I want to do is having the option to more firmly attach crate ownership to a particular ID, for instance a public key. crates.io doesn't really do ID management all THAT well, partially because github doesn't, because neither of those sites are really THAT interested in being a Super Rigorous ID Provider. So if someone deletes their github username, and a malicious party creates an account with that same username, they still don't have crates.io ownership but they can *look* like they're the same person. I want to be able to enter a user's name and see "their public key is $FOO, they have made crates X Y and Z, their last activity was on $DATE, they've done these reviews ...". So, attaching an actual web of trust to things. I see crev or something like it as one step of that. As you've said elsewhere, PGP is the Right Tool for this but it also really sucks ass. What I *want* is a system that is easier to use and [keys are distributed via a peer-to-peer network](https://github.com/icefoxen/world_id) without needing much centralized authority, but my own efforts with that sort of thing have [succumbed to some yak-shaving](https://github.com/icefoxen/WorldDat)...
`filter` is something you do on an iterator (it wraps the original iterator and returns a filtered one), not a collection. `retain` modifies the collection.
&gt; I thought that if such a method existed on HashSet, it would be called `filter`, so I didn’t look at `retain`. `filter` is usually a pure function creating a new collection, it exists on `Iterator` (and `Option` for convenience). To avoid confusion, the stdlib uses `retain` for "in-place" filtering of collections.
I have nothing to do with the group who made this, except for sharing it :)
A very good questions. There are no code generation magic or unsafe shenanigans as far as I know, just good old Rust traits. It uses somethinf often called "extractor pattern". You can find a high-level overview on the usage [here](https://actix.rs/docs/extractors/) but you have probably already seen that. Let's dig into the docs! (I believe it's helpful to see how I came to understand this by clicking through the API docs. Skip the next 3 paragraphs if you only care about the "magic" way actix-web allows you to extract data from requests.) The example you linked to contains `App::new().resource("/{name}/{id}/index.html", |r| r.with(index))`. Typing `App::resource` into the doc search gives use the [right method](https://docs.rs/actix-web/0.7.17/actix_web/struct.App.html#method.resource) it seems. The interesting part here is the closure type (`FnOnce(&amp;mut Resource&lt;S&gt;) -&gt; R`) because it tells use the `r` is a reference to a `Resource`. Clicking on that, and scrolling down leads us to [`Resource::with`](https://docs.rs/actix-web/0.7.17/actix_web/dev/struct.Resource.html#method.with). Nice. But now it gets complicated. The full signature for `with` is: pub fn with&lt;T, F, R&gt;(&amp;mut self, handler: F) where F: WithFactory&lt;T, S, R&gt;, R: Responder + 'static, T: FromRequest&lt;S&gt; + 'static, Let's unwrap that a bit. The parameter we give to `with` has to be something that implements the `WithFactory` trait. But no it gets weird: This trait is private! So, from the docs, we can only infer that it has three type parameters. The first is something that implements `FromRequest`, the second (`S`) is probably some state (guessing from the name only), and the last one is something that implements `Responder`. So I'd guess we are dealing with something that takes some data from a request, some state, and returns something new that can be used as a response. Sounds useful in the context of a web framework. The part we are interested in is [`FromRequest`](https://docs.rs/actix-web/0.7.17/actix_web/trait.FromRequest.html). This is a trait that abstract over extracting data from a request structure (it's two methods are `from_request` and `extract`!). This is a long docs page. The part you ask about is almost at the bottom in the "Implementors" section. For example, [`impl&lt;T, S&gt; FromRequest&lt;S&gt; for Form&lt;T&gt;`](https://docs.rs/actix-web/0.7.17/actix_web/trait.FromRequest.html#impl-FromRequest%3CS%3E-18), or [`impl&lt;T, S&gt; FromRequest&lt;S&gt; for Path&lt;T&gt;`](https://docs.rs/actix-web/0.7.17/actix_web/trait.FromRequest.html#impl-FromRequest%3CS%3E-20). And this is basically all there is to it! These types allow you to use them in a context where you want to extract data from a request! The concrete usage of that and the way that the obscure `WithFactory` comes into play is also quite interesting. I wrote above that "no code generation magic" was used -- I might have lied a bit. To support *multiple* parameters/extractors in the functions you pass to `with` the `WithFactory` trait must be implemented for functions/closures that have multiple parameters. For that, the actix developers use [a macro](https://github.com/actix/actix-web/blob/0745a1a9f8d43840454c6aae24df5e2c6f781c36/src/with.rs#L291-L306) internally to generate implementations of `WithFactory` for functions with up to 9 parameters that implement `FromRequest`. I couldn't find this documented in the API docs, but the website contains user documentation, too, and as mentioned above has a page on [Extractors](https://actix.rs/docs/extractors/) with [this section](https://actix.rs/docs/extractors/#multiple-extractors) showing an example of using a function with multiple extractors. So, all in all, this means that you can write `.with(index)` and have this functions: fn index((path, query): (Path&lt;(u32, String)&gt;, Query&lt;Info&gt;)) -&gt; String { format!("Welcome {}!", query.username) } I hope this explained the pattern well enough! Let me know if you have any questions. :)
See https://users.rust-lang.org/t/cargo-crev-0-2-notes-from-dogfooding-looking-for-automatic-scanning-tools-and-ideas/23480?u=dpc for ideas on what else can be automatically-scanned. &gt; As you've said elsewhere, PGP is the Right Tool for this but it also really sucks ass. I actually have the same feelings, and while I want to support PGP (https://github.com/dpc/crev/issues/58), I started with my own simple ID-system, and WoT. I use git repos to publish and circulate proofs and information about IDs in `crev`, but in essence everything here is just a text, and therefore transport independent. I was indeed thinking about DHT, but there's only so many days in a year, so I want to get simple, but robust system working first, and improvements can be introduced later, if and after it gains traction. In `crev` (a subset of what current `cargo-crev` does) I even have concept of a project, which would be embedded into VCS repository (as ` .crev/config.yaml` or something). It would basically be a self-generated, self-signed Id (so it can not be recreated), and its authenticity would come from the same source as *review proofs* - users reviewing packages/code would certify that it is indeed the correct one. I think a lot of what you describe is what I've been thinking about too. It's just I've cut the scope drastically, to focus on the most useful bits first, so the ecosystem can start bootstrapping, and hopefully I get some help. I was aiming at `crev` to be simple, but flexible and general enough to serve many different needs, for any language and ecosystem. As you can see: https://github.com/dpc/crev Even a data layer (basically serialization format of proofs and IDs) are in it's own crate, so it can be reused. Please take a look and think if you wouldn't want to share the infrastructure, which would definitely help both of our projects (which I think, are indeed one project). It's still early, so if you have any ideas, there's still room to change some bits here and there if necessary, to accommodate them.
Yes please. I'm aware that macros exist and even wrote some, but without further advice I'll probably misuse them as well.
I see, that makes sense, but when `B` is a reference type the `b` parameter is required to be a reference to a reference? For instance, this is what my code looks like now: struct VecMap&lt;K, V&gt; { vec: Vec&lt;(K, V)&gt;, } impl&lt;K: Ord, V&gt; VecMap&lt;K, V&gt; { fn insert(&amp;mut self, k: K, v: V) { match self.vec.binary_search_by_key(&amp;&amp;k, |(key, _)| key) { _ =&gt; {} } } } The `&amp;&amp;k` makes me feel like I'm doing something wrong here.
I just changed clips-sys' build.rs to use cc. Hopefully it will build on more platforms now. I've also got passing Rust closures as callbacks to clips working nicely now, as well as supporting more of the argument types from CLIPS.
It's kinda general, the default value of an int is 0, so no need to insert a new one
At that size, it might be faster to use an array of key-value pairs, and to just scan the array for lookups. Especially if in practice the map is smaller than its max size.
I appreciate the followup, it seems we have a bunch of subjective-evaluation differences that are irreconcilable, but to focus on one remaining matter: &gt; from a end-user conceptual POV, I think there's not a huge difference The huge differences to an end-user include: - Users lose signifiant clarity about _when_ type-level judgements are made, because they _look_ like they're deferring judgements to runtime based on the dependence on runtime values. This is not true -- the type-level judgements are still all made at compile time -- but they are not _concretized_ until runtime: a distinction that does not exist in the current type system, or in any type system (i.e. "almost all that anyone has familiarity with") where concretization happens entirely at compile time. This is typically a baffling distinction. - To support such judgements, users typically have to begin thinking about the equality of type-level terms that cannot be automatically decided, but must have explicit evidence constructed and supplied. Which entails adding mechanisms for constructing and supplying evidence, which would likely grow into a full equational-rewrites-and-tactics proof system. For most, this will be vastly more baffling, and demands extensive journeys into formal logic and proof theory to understand. Again, I know you're in a position academically where this all seems like old hat, but for the audiences Rust is targeting it is not, and it would be inappropriate. - Similarly, the user's mental model of how and when concretization occurs, and what it means at a machine level, from a language-furnished data-structures-and-code-gen perspective, would be made drastically more opaque. As you allude to in terms of an implementation needing multiple PhD theses. In a language like Rust, it's important for users to have a clear mental model of how their source code turns into machine code. This would be lost. In short: while I like dependent types and think there are plenty of languages where they are profoundly useful and powerful aspects of the design (typically: those that had them from the get-go), they would bring very inappropriate costs to Rust, and those costs are definitely not already paid in the const generics system.
He tried to. He gets a question about it @50:20 something
I also found that bug, but I thought it had something to do with the new 'std' api and therefore, I posted an issue in the language's repo (https://github.com/rust-lang/rust/issues/57036). They told me that it isn't about 'std' and I didn't have the time to repost it yet. Maybe you could do that!
Thanks. This is what I want.
Version 0.3.6 pushed today, incorporating all your suggestions and comments, as well as a fix to a data-race that was discovered. Examples were unified in their functionality. The library API has been stabilized, and should not go any further changes. In the following days we'll focus on writing tests to cover the library. After that a refactor of the Thread/Task waking in sync/async should undergo refactoring. Thanks for all your comments/suggestions/nitpicks, they are appreciated. 
That's a good point, I ruled that out at first because the number of possible keys is large but that doesn't matter if I make it an array of pairs.
No. I didn't have the time yet. 
BurntSushi competed this year's AoC. It's a great benchmark for comparison.
The Option&lt;T&gt; and Result&lt;T, E&gt; types have lots of helper methods on them. You could eliminate many of your \`if let\` expressions with a call to \`map\`, and use \`and\_then\` instead of the question mark operator to short circuit on failure. Beyond that, as other commenters have pointed out, you probably should make a single helper function that replaces all the calls to new, args, spawn, and check which returns a bool of the result. You'd still have a bunch of functions, but they'd each be much shorter.
And `use module::RunType::*` is a nice trick that lets you avoid typing the `RunType::` qualifiers everywhere. (That's what is done for `Option` by default.)
I had the same problem, switching to [mongo\_driver](https://github.com/thijsc/mongo-rust-driver) did the work
Ohh you've actually named that directory "tests", that's what you meant by at the same level as "src". Sorry, I misunderstood what you were saying there. The "tests" folder is special, it's for integration testing, where every file inside that is a test that will run the functions that have been properly labelled inside it, so first of all, remove your `#[cfg(test)]` and `mod tests` from that folder. Now since the tests folder is for integration testing, that means it basically has to treat your library as if it were simply an external crate, so if you don't want the users of your crate to be able to access `parser`, then your integration test won't be able to do so either. So here you have to actually consider what your crate is for - if you want to expose functions in parser to the user, then you make it public (`pub mod parser;`). If you want only want to let the user use certain functions that call functions in parser indirectly, then keep it private and do your testing inside the `parser.rs` to make sure it works internally (you can still have a test of your form, but only using functions a user can call. )
OHHHHH damn! That makes so much sense! Thank you :)
No problem! The [Rust Book](https://doc.rust-lang.org/book/) is very handy for these sorts of things - it's well worth it to occasionally look back through it whenever you're stuck on something.
Looking for features to prioritize, and shortcomings to fix. Highlights since initial release: -High-level fetch (get/post) API -Routing -Element lifecycles (did_mount etc) -Guide moved to own website, which is also an example 
Use cases for blockchains often tend to fall into either "sketchy af" or "hilariously misguided" and either way it'd be cool if the Rust community steered clear of them
Is it possible to toggle features on optional dependencies depending on the features enabled on my own crate? For instance, if I have a feature `std` on my crate, and an optional dependency on `serde`, is there a way to allow the user of my crate to choose between all of the following? * `no_std` without `serde` * `no_std` with `serde` (`serde/std` disabled) * `std` without `serde` * `std` with `serde` (`serde/std` enabled)
Well, I still think that it's inconsistent that to get a File struct you call a constructor on that File struct, but to get a Metadata struct you cannot call a constructor on the Metadata struct. Just an observation.
Virtual-dom-rs is another name for https://github.com/chinedufn/percy
I got this, I don't know if it can be simplified. pub struct Thing&lt;T, U&gt; where U: Unsigned + BitAnd&lt;U1&gt;, &lt;U as BitAnd&lt;U1&gt;&gt;::Output: IsEqual&lt;U1, Output = True&gt;, { /*...*/ }
`rustfmt` should be available. This has been a problem for a few people due to some corruption from previous installs. Make sure you have the latest rustup (`rustup self update`, which I think is 1.16). Also check if it thinks the old `rustfmt-preview` is installed (`rustup component list`) and remove it if it is, or try removing and reinstalling stable. You might find some more information at https://github.com/rust-lang/rustup.rs/issues/1558.
Cool :) I don't have a computer handy to check it but I was thinking along these lines which might work too: type IsEven = Rem&lt;U2, Output = U0&gt;; type IsOdd = Rem&lt;U2, Output = U1&gt;;
Excellent! ```rust use core::{marker::PhantomData, ops::BitAnd}; use typenum::{ consts::{U1, U2, U3}, Unsigned, }; #[derive(Debug)] pub struct Thing&lt;T, U&gt; where U: Unsigned + BitAnd&lt;U1, Output = U1&gt;, { state: T, phantom: PhantomData&lt;U&gt;, } const TEST1: Thing&lt;u8, U1&gt; = Thing { state: 0, phantom: PhantomData, }; const TEST2: Thing&lt;u8, U2&gt; = Thing { state: 0, phantom: PhantomData, }; const TEST3: Thing&lt;u8, U3&gt; = Thing { state: 0, phantom: PhantomData, }; ``` The 2 doesn't compile, but the 1 and 3 do. The only sad side effect is that the error message you get is absolutely crazy and doesn't really guide you to what went wrong: ``` error[E0271]: type mismatch resolving `&lt;typenum::uint::UInt&lt;typenum::uint::UInt&lt;typenum::uint::UTerm, typenum::bit::B1&gt;, typenum::bit::B0&gt; as core::ops::BitAnd&lt;typenum::uint::UInt&lt;typenum::uint::UTerm, typenum::bit::B1&gt;&gt;&gt;::Output == typenum::uint::UInt&lt;typenum::uint::UTerm, typenum::bit::B1&gt;` --&gt; src\lib.rs:330:14 | 330 | const TEST2: Thing&lt;u8, U2&gt; = Thing { | ^^^^^^^^^^^^^ expected struct `typenum::uint::UTerm`, found struct `typenum::uint::UInt` | = note: expected type `typenum::uint::UTerm` found type `typenum::uint::UInt&lt;typenum::uint::UTerm, typenum::bit::B1&gt;` ```