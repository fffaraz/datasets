brb, refactoring all my code
I had a look at the github page, and it has convinced me to try and merge my code into clippy. Manish has already given me submitter rights, too.
First, you want to add it to your Cargo.toml under `[dev.dependencies]`, then you just use it via `#![plugin(extra_lints)]`. Look at the tests folder in the source distribution for example uses.
Glad you liked it :) &gt; (btw: It looks like the chapter is only on the "book nightly" and not on the "book beta") Yeah, I'm going to be doing a batch backport of the book, reference, and grammar to beta right before we release. It's much easier to just do it that way than backport each individual patch. &gt; is there a way to easily show the Deref implementations for a given type? Yes, they're showin in the API docs. For example, scroll up slightly from http://doc.rust-lang.org/nightly/std/string/struct.String.html#method.escape_default , and you'll see `Methods from Deref&lt;Target=str&gt;` This was a pretty serious discovery issue in older versions of the docs. 
Nice article! It was frustrating to read though because on mobile screens there's an obnoxious share sidebar that covers the text.
&gt; It takes extremely long to compile the project from scratch. Even just the rustc-stage1 target, takes ages. This is quite a big inhibitor for further contributions, as one would have to have access to an extremely powerful build machine in order to attain a reasonable amount of productivity developing Rust itself. **If possible, I would like this to change. Perhaps break the project up into several smaller ones, and make it possible just to recompile the ones that changed.**
The problem is that there is no simple rule to decide whether clone is required. I'm not too deep into the semantics (after all I'm just starting with rust), but there may be a number of easily identifiable classes of cases where analysis can find unnecessary clones.
Is there a reason to take a &amp;[T] rather than &amp;Vec&lt;T&gt;? I assume there is since I hardly ever see the latter, but I have no idea what it is. The latter also just borrows ownership, right?
Ah, good point. Yes, there is: basically, taking a `&amp;Vec&lt;T&gt;` means you can _only_ take vectors, and only whole vectors. Taking a `&amp;[T]` means that you can take _anything which can be coereced to a slice_, which includes other types as well. For instance, a slice of part of a vector.
I know it's not the official way to do it, but I code with alignment like that. It just looks so much nicer and feels easier to read...like sections of my code are mini-spreadsheets. I try to undo it and fit it to the "right" way before I push to github or before anyone else sees my code, but it just feels right to write it like that.
Fixed it, thanks for the suggestion!
Nice, thanks!
I've got a script to turn the nightly tarball into a deb (rustc + cargo) and it looks like this. (Not using checkinstall because I don't want to wait minutes on the xz compression..) Usage: ./scriptname tarballname.tar.gz #!/bin/sh SRC="$1" VERS=$(date +"%Y%m%d") set -x set -e SRCDIR=${SRC%.tar.gz} if test "$SRC" != "$SRCDIR"; then rm -rf "./$SRCDIR" tar xf "$SRC" fi DESTDIR=./rustnightly # echo the current path LD_LIBRARY_PATH="$SRCDIR/rustc/lib" "$SRCDIR"/rustc/bin/rustc -V test -e "${DESTDIR}.deb" &amp;&amp; mv -f "${DESTDIR}.deb" "${DESTDIR}-old.deb" "$SRCDIR"/install.sh --destdir=$DESTDIR --disable-verify --prefix=/usr DEBDIR="$DESTDIR/DEBIAN" mkdir -p "$DEBDIR" cat &gt; "$DEBDIR/control" &lt;&lt;EOF Package: rust Priority: extra Maintainer: root Architecture: amd64 Version: ${VERS}-1 Description: Rust Programming Language and Cargo Package Manager EOF touch "$DEBDIR/conffiles" dpkg-deb -Zgzip -z1 -b "$DESTDIR" rm -r "$DESTDIR"
The easiest case is when the object being cloned is not used after being cloned. So code like fn foo(x: Thing) {} ... let x: Thing; foo(x.clone()); // No more use of x
That split has been underway for some time. All of the [librustc_* crates](https://github.com/rust-lang/rust/tree/master/src) used to be a single crate. Naturally, splitting things up can be difficult, because you have to break cyclic dependencies. Using large compilation units buys you a lot of convenience, not to mention helping the optimizer. There's a real tradeoff with build times. If you are building a dev machine specifically for rustc builds, it only needs to be super-powerful on one axis: single-core performance. I went with an i7-4790K overclocked to 4.8 GHz. This was my first overclocked build ever. I used a Corsair H110 closed-loop water cooler, which is no harder to install than an ordinary CPU fan. Otherwise it's just a little mini-ITX box with a decent amount of RAM and an SSD. Total cost was around US$1,000. It handles a full Rust build including LLVM in about 12 minutes (or did some months ago).
I was asking why it was the canonical type for doing that.
That should be possible with a bit of scope analysis. But I'm not yet convinced if this is applicable in the general case, e.g. combined with thread::scoped.
&gt; explain why the struct needs to be wrapped in a Mutex, and then an Arc First, values must normally have a single owner. `Arc` is a reference-counted pointer, which means you can let multiple places "own" it at once and it will be dropped when the last one gives up ownership. The reason for `Arc` rather than `Rc` is that it needs to be shared between threads, so it uses atomic instructions to maintain the reference count. Second, values cannot be mutated by multiple threads at once. `Mutex` is a lock that forces only one thread to access the value at once, by calling `.lock()` which forces it to wait if another thread is already using it. &gt; explain move before the closure params Closures can access their environment in one of two ways- by reference, where they store a pointer to what they use (like `greeting` here), or by value, where they actually move the value into themselves. `move` is what tells the closure to use the second method. One reason to do this is to allow a closure to be called by another thread- if it owns the value (the `Arc` in this case), then it can be moved to another thread without pointing onto the original thread's stack. &gt; explain why * is used here In that location, `greeting` is a pointer (`&amp;mut Greeting`). Assigning directly to `greeting` would mean changing the value it points to. * is the dereference operator, which lets you assign to the actual value being pointed to, rather than just changing that location. &gt; explain why '.unwrap()' is undesirable, what to use instead `unwrap()` panics (crashes the thread) if it fails. I don't know Iron so I can't say which of these (if any) uses of unwrap can fail, but for production code it should only be used when you already know it won't.
Just gave it 3 votes. Intellisense is positively the best thing about working in Visual Studio and even more than VIM it legitimately saves me an hour a day remembering function names and other such details, and handling all sorts of cruft.
Yes, that may be possible (judging after a cursory glance at the borrowck crate), but it would be a) a nightmare to maintain, as the API has unstable written all over it and b) a quite complex lint - I'm not sure I'm that advanced yet.
After 1.0, if no infrastructure changes, beta docs will start to be uploaded to `doc.rust-lang.org/beta`, but stable docs will be under the version number. I don't currently have plans to make changes here before 1.0, but I see how this is problematic.
&gt; but I also am afraid of depending on third-party libraries I sympathize with your concerns, but learning how to work with third party libraries is extremely valuable. Perhaps one of the tutorials could build up a simple library (which you happen to host an pre-baked copy of on crates.io), and then a follow up tutorial for a binary that consumes that library (would nicely demonstrate both library and binary authoring). I'll try to think of some good candidates for those tutorials. I think ideally the project walkthroughs would be at least somewhat non-trivial (my biggest complaint when trying to learn a new language/library is when all of the "getting started" stuff is too simple to be realistic)
Just published! https://crates.io/crates/string_cache Most of that unsafe code is because weâ€™re doing lots of tricks in the memory representation of atoms: 64 bits can contain either a small string inline (up to 7 bytes), or the u32 index of a static atom, or a pointer to a reference-counted string in a specialized hash map that removes entries when the reference count drops to zero. This is hard to do in safe code without sacrificing efficiency.
Pretty much only `JoinGuard` used it. A somewhat-related assumption was made by the not-yet-accepted (at the time) `Vec::drain` API, but that was a lot simpler to fix.
The new Vec::drain is merged now, It's exciting. You can finally remove a range of elements efficiently!
It'd be nice if `/` went to the latest release, for sure. During the period between stabilizing a feature and release, it'll be mistakenly marked as stable in the nightly docs...
It can be confusing to put things in parallel when they are not semantically related in the code. For instance: fn foo&lt;T: This, U: That&gt;( a: Bar, b: Bar) -&gt; Baz { ... } Puts `This`, `That`, `Bar`, `Bar`, and `Baz` all in a line when they are unrelated. This is much clearer, in my opinion: fn foo&lt;T: This, U: That&gt;(a: Bar, b: Bar) -&gt; Baz { ... } It puts all the related items in a "box" delimited by the bracketing delimiters. And even then, for short arguments like that, it is unnecessary. 
I'm not familiar with how getopts is implemented, but if its types implement the proper traits you should be able to do `for f in files {` rather than `for f in files.iter() {`. Also, expect a lot of people to be cross with you for taking the most obvious name for projects that do Rust/C interop. :)
This is the default theme for Octopress, which is a fairly popular blog generator. You could try filing a bug at https://github.com/imathis/octopress/issues
The RAII pattern is used throughout many libraries. Just search for any type with `Guard` in its name. The problem is that in `thread::scoped` is was a misused pattern that lead to heavy consequences. The other parts of the library that got affected by this issue (`drain` only) were able to get fixed easily because they weren't misusing the pattern itself. Everything bellow this line is me rambling about how I think it was misused. I probably should dedicate more time to trimming it further but I can only give so much time to reddit. --- Generally speaking when we access a resource we get a "guard" object that "owns" the resource. The guard is the single owner, and all access to the resource must go through it. A very simple example is `Box&lt;T&gt;` were the `Box` object is the guard for the resource `T`. Another example is `Vec&lt;T&gt;` were the resource is a dynamic array. An even more dangerous example is `Mutex&lt;T&gt;` were mutex no only manages the resource, but also ensures that it's cleaned up. The important thing is that these guards may have to release their resources. Generally you want to do this at the end of the guard's lifetime (exceptions occur, such as `Rc`). The problem is that there's no guarantee that a Guard will be destroyed (it may be leaked) when "forgotten" (when rust assumes it doesn't exist anymore) which leads to unexpected situations. The simplest error that came out was `drain`. Basically `drain` would leave a `vec` that called it in an illegal state, but it would return a guard (in the form of an `Iterator`). As long as the guard/`Iterator` existed you couldn't access the `vec` and realize it was in an illegal state, and when the `Iterator` was destroyed it would "fix" the `vec` and everything would be fine. Except that you could have the `Iterator` forgotten but *not destroyed*, which would expose your (now invalid) `vec`. The solution was to simply not make `drain` leave the `vec` in an invalid state at any point. So basically if you are doing `unsafe` stuff you have to be careful, you can't assume that the destructor will be called, and must assume that someone might accidentally forget something without destroying it. When this happens a resource leak should occur, in the worst case of all you should leave your data in a poisoned state (which might lead to other bugs). `thread::scoped` cannot do this. It's a misuse of the RAII Guard pattern. Normally the pattern is that whoever wants to use a resource (the user) gets a Guard that gives it access from whoever owns the data (the producer). The guard is bound to the producer and can't be given away if the producer isn't going to be available (it's lifetime ends). Since the consumer can only access the resource through the Guard, and the Guard can only exist while the Producer exists, we can guarantee that resources can only be accessed by the consumer while the producer is alive. This allows us to delete the data when the producer is gone, which keeps RAII alive. In the old `thread:scoped` pattern we originally had two threads interacting together: the parent thread (that calls `thread::scoped(...)`) and the child thread. The parent thread has access to the result of the child thread through a `Future` which is a guard for the result of the child thread (but doesn't offer access to resources inside the child thread). OTOH the child thread can borrow elements from the parent thread's . See the problem? The child thread has no Guard for the parents resources! The so called "Guard" is on the Parent thread! So we start setting ourselves up for disaster: our Producer (the parent thread) holds the Guard. Remember that the Guard is guarantee to not exist beyond the producer, this means that the producer is guarantee to not live longer than the producer! OTOH the child thread holds *nothing* which means that it may exist, if it so wishes, beyond the producer (keep going). The only way that the "producer" ensures this doesn't happen is *by waiting for the child*. We can start seeing how problematic that is. All the responsibility is on the producer, when it should be on the user. Moreover there's no way to truly guarantee that the consumer won't misbehave, we only hope that we can enforce it. Basically the guard is guarding that the owner/producer doesn't misbehave (even though it can do whatever it wants) while ignoring what the borrower/consumer is doing! The whole guard pattern is completely backwards! And this is how the new API came to be. It basically decides that if the pattern is backwards, maybe the solution is to implement a backwards solution that fixes it. A closure is used to guarantee that the child-thread cannot exist outside of it, think of `Scope` as a sandbox were you can always just throw away the whole sandbox separate of everything else. The Parent thread defines that at certain point "play time" is over for it's children and they need to leave and clean up the sandbox (this is when the scope closure ends). At the same time the parent thread is given a guard for the resource that the child thread needs to give to a future when its done. The JoinGuard is not really a Guard (it's more of a future and probably could benefit from that naming). If you want to see a language that uses this sandbox-closure pattern extensively, take a look at Go. It's a language with pros and cons, but I've yet to meet anyone that dislikes `defer`.
Would anyone be willing to work on this with me? It shouldn't be too difficult, just take liballoc, rewrite it to return Results, then go up through the layers, returning results as you go. I just did the same thing with libcore.
So, to answer your statements in two parts: &gt; I think the point is this: you've always had to deal with this, we're just remembering that now. It's not that the guarantee isn't valid anymore. It's that it was never valid in the first place. Right. The issue is, people (including myself), *assumed* this guarantee was valid. Now that it has been shown not to be, I think the right answer should be "how do we make it valid", instead of "well, it was never valid, so let's leave things as-is". &gt; In no other RAII language that I know of is there a guarantee of no leaks, because any benefits are far outweighed by the negatives. Also absolutely correct :-) I'm going to be more explicit here: I think the guarantee a lot of people are looking for, myself included, is that an object's destructor will run if code after the end of scope runs. For example: { let guard = MyThing::doit(); // other stuff } println("Guard should have run"); Note that this is a fairly limited guarantee. For example, the following are all currently valid, and should remain so: **Explicitly Storing Something In a `'static`** { let guard = MyThing::doit(); myGlobalHashmap["saved"] = guard; } // The item got moved, and thus should not have been dropped - this is a "leak", but it's also by design. **Not Executing Code** { let guard = MyThing::doit(); loop {} } // This code never executes, so the drop may never run - that's okay. **`panic!()` or aborting** { let guard = MyThing::doit(); panic!("foobar"); } // This code also never runs, so the drop running (or not) is okay. Note that this doesn't somehow magically prevent leaks - the only "guarantee" that I'd like is the following: a destructor is guaranteed to run, if and only if code after the scope of the item continues to execute.
Honestly, for my game, it was easy to just use libcore and create my own libstd. I copied out mutexes, and then just reimplemented the rest. Its not actually all that difficult, if you do static memory allocation (which is what I did).
Don't get me wrong - that's not a bad way of solving the problem! My issue is mainly that I think this: let ff = TemporaryFile::new(); // use ff // ff is dropped and removed automatically when we're done with it Is a lot more ergonomic than the following: with_temporary_file(|ff| { // use ff }) For example, what if I want to return early? In the first case, I can just use `return blah`. In the second, I have to make sure that the closure is generic (e.g. `|&amp;TemporaryFile| -&gt; T`) and `with_temporary_file` passes the return value back, and then make sure to capture the value returned from `with_temporary_file` and return that, etc. etc. Again: it's not *bad*, I just think the standard RAII pattern is more ergonomic.
I think part of the reason that people feel so strongly about trying to fix the problems that can lead to leaks is that the alternative, the scope API, feels a little bit clunky and different than how most resource management works in Rust, which is via RAII. There are a few comments I have on this. One is that RAII isn't particularly good for a lot of types of resource management. As Niko points out, the reason for the failure in this case is that the RAII guard was a proxy, not the actual object that memory was accessed through, and this means that it's a lot easier for it to go out of sync with the real state of the world. But also, dropping via RAII is a very limited interface, that really only works for drop operations that can't possibly fail; you can't return a `Result` from them, and as is one of the central points of the discussion, failing during destruction can cause all kinds of problems, either leaks or whole process aborts. This leaves them mostly useful for very small, simple operations that can never possibly fail, like freeing memory, resetting a pointer, or dropping a mutex. There has been [some discussion of implementing true linear types](https://github.com/rust-lang/rfcs/pull/776) for things that you must actually use exactly once, rather than just dropping as they go out of scope; that would be useful for those types of objects where you want to guarantee destruction, but can't rely on them going out of scope to do so. That would at least help fix the problem with objects that must have some cleanup done, but must also be able to report errors from that cleanup; I wonder if it would also be able to help here? Since linearity of a type affects containing types as well, you wouldn't be able to construct an `Rc` cycle of a linear type and have it leak as you would have to do something to consume the containing `Rc`s before exiting the scope. Another option would be to improve the palatability of the `scope` proposal by making it look a little nicer. Any time you have a large block of code that has to be wrapped in multiple delimiters and a semicolon, it feels a bit janky: thread::scope(|scope| { let future = scope.spawn(|| /* body of the child thread */); ... }); I know that there had been some special syntax in much earlier versions of Rust for Ruby-style blocks at the end of the line that could be written outside of the parentheses, but that idea was dropped at some point. I don't know what the reason was, or if it would be possible to re-introduce backwards compatibly, but it could make this style look more natural: thread::scope() |scope| { let future = scope.spawn(|| /* body of the child thread */); ... } At that point, this reminds me a bit of Python's `with` statement, which is what is used to provide guaranteed cleanup in Python as RAII doesn't work due to everything being RC (with a cycle collector). Some sugar like Python's `with` statement might also make this look more natural (adapted slightly to be a little more Rusty): with scope = thread::scope() { let future = scope.spawn(|| /* body of the child thread */); ... } I feel like with a little bit of better syntactic support, the non-RAII solution might feel more natural and thus lead to less resistance. Finally, on the `Rc`/`RcScoped`/`Arc`/`ArcScoped` proposal, there's the problem of the proliferation of types. I'm wondering if specialization would help here; where you could have `rc::new()` implemented only on `Rc&lt;T&gt; where T: 'static`, but you would have a private constructor that would work for any `Rc&lt;T&gt;` that could be called from `guard::new_rc`. Then anything that needed to vary between generic `Rc&lt;T&gt;` (which is necessarily protected by a guard), and `Rc&lt;T&gt; where T: 'static`, could do so by having two implementations, as `Rc&lt;T&gt; where T: 'static` is a specialization of `Rc&lt;T&gt;`. Of course, this would require specialization, and I know that whether there will ever be some form of specialization is an open question. But it does seem like it could help avoid the `Rc`/`RcScoped` proliferation of types, if I understand correctly. Of course, removing `Rc::new()` from `Rc&lt;T&gt;` would be a backwards incompatible change, and specialization isn't going to land before 1.0, so this is more of a hypothetical, but I figured I'd mention it for the sake of completeness.
Yeah, this is definitely a problem I had as well. Here's [an example where I screwed it up](https://lwn.net/Articles/640017/), using a dummy `_` variable which meant that I joined the thread immediately, when discussing the "Fearless Concurrency with Rust" article; luckily, someone pointed out my error, but it's a very easy mistake to make.
You might want to post this question somewhere more prominent; on a two day old thread, I'm the only one likely to see it due to the notification, and I don't think I have the time to work on this.
&gt; This doesn't result in memory unsafety, but it does mean that a particular guarantee ("if the scope of this variable is exited, and code afterwards continues to run, then the destructor that cleans up state will have already run") isn't valid any more It never was valid. I am starting to fear what the initial issue against Rust is going to be. People are going to claim that Rust prevents all problems and will even straighten your teeth, and then lash back with all the "proofs" that Rust can't "guarantee" what it never promised in the first place! Rust promises you that, as long as you are dealing with safe code: * You cannot access invalid memory (memory that has been freed). * You cannot have multiple threads accessing memory at the same time. (Data races) Rust OTOH does allow you to: * Have resource/memory "leaks" (even GCed languages allow you) * Deadlock * Have threading races (they won't corrupt the data but they can do stupid things). * Have security flaws and exposures. Basically Rust can't protect you from the above because it's a systems language, and like it or not, you need those freedoms to ensure you can work fast enough. Rust's aim is to make programming *simpler* but it can't solve everything. No language, AFAIK, has solved the leak problem. Leaks are always possible in elaborate ways. Today it was this, tomorrow it'll be the next issue. The problem is that most GCed languages don't care too much about "leaks" (you'd be surprised at how common they are) like this. Basically you should never assume that Rust will run the destructor: it never promises that. What you can assume is that if that happens (and the program doesn't crash immediately) the code using your program has a terrible bug. You want to keep things, as much as possible, in a sane state so that the programmer can have the state. I won't even get into the issue with `thread::scoped`, it used the wrong pattern here (see my above huge post to see my opinions) and simply shouldn't be used. But if you are building a destructor: 1. If the destructor is required to make an invalid (but inaccessible) state valid, change it so that the object never enters an invalid state. This should always be possible. 2. If the destructor is needed for a side effect that is needed to avoid other types of bugs (freeing up a mutex, closing a file, etc.) try to avoid having that side effect be necessary. For example if you have a server that opens a lot of files and then closes them so other processes can use them, you might want to use a service that opens files lazily (only when you want to read from them) and if no one has read from them in a long while closes them. That way you ensure that even if a file handle isn't destructed, the file will get closed at some point. When in doubt leave it and let whoever misused it correct it. The program won't become undebuggable gibberish, it'll only crash. 3. If the destructor is needed to release memory, then leave it as is. This is a standard memory leak and will lead to an OOM given enough time. Again the trick here is to leave memory in a debuggable state. Having the above in consideration is enough. All you need to be aware is that there's no guarantee that the destructor will be called when you go out of scope,
My apologies if this is otherwise well known, but what are intellisense pluggables?
Thanks for pointing that out, I have fixed and re-published!
So you're the first to complain about that. I put it in as an experiment, it was cool to see heatmaps and such on my site, but the novelty has worn off now, so I have yanked it - you may now enjoy sidebar free reading!
The convention is to write `let _guard = ...;`: the leading underscore is key.
And if you forget it, you won't know what went wrong and why your computations are slow.
The "unused" lints (unused variables, dead code) will ignore things with leading a underscore.
Uhhh .... Visual Studio Code is based on Atom, I won't touch that piece of crap.
That seems to be the actual issue here - people expect destructors to run, but that's never been a guarantee. This seems typical, but I think the idea of memory not behaving perfectly might sound horrible if you're going to a language for 'memory safety'. Otherwise, this just seems like a bug in a library, and bugs are going to happen. The scope proposal in the linked article seems like a nice way to handle the situation where Rc isn't suitable, and you need a guarantee that the destructor will run given normal execution.
I am personally not fond of considering languages as "entry point" languages. What people usually mean is that they are easy to learn. Rust isn't. It introduces several concepts which are foreign to people both with and without programming experience, and it takes some time to get used to. If you want a low-level language that is easy to pick up, the winner by a wide margin is C. On the other hand, rust teaches more than just a new language. While rusts ownership and borrow system is not enforced in other languages, rust **forces** you to think about ownership and borrowing in a more rigorous manner, which can benefit the quality of the code you write in any language. The flipside is that rust has quite a steep learning curve. If you are interested in the real-world usefulness of the language, with rust it is very much an open question as to how widely it will be adopted (although it is in a strong position for a language which technically hasn't been released yet). If you want a guarantee of usefulness, again C is a clear winner.
I would think that the head of beta and nightly should be under `/beta/` and `/nightly/`, every major stable release should be under `/1.X/`, and `/` should redirect to the most recent stable release. `/` redirected to `/nightly/` seems like a bad call if the goal is to promote people using stable Rust.
&gt;whether that be through `mem::forget` being safe I hope that `mem::forget` stays unsafe. It is one thing if people have to remember that weird things happen when they're using `Rc`/`Arc`, but it is another thing entirely if weird things happen, in safe code, just about anywhere. There is always the possibility that someone at some point will find some way to fix or improve any apparently unsolvable problem, but by marking `mem::forget` safe you're not making anything *easier* but you are guaranteeing that the problem can never be fixed backwards-compatibly. For example `Leak` becomes substantially less onerous if the type system supports HKT, but *that* is a much larger and more dangerous can of worms. 
Unfortunately, a library needs to be rebuilt if any of its dependencies have been updated. This is pretty much unavoidable, because a change in the dependency might have invalidated type checking, code generation, etc. The vast majority of the compiler transitively depends on `libsyntax`, so any changes in that crate are especially painful. One mitigation we've found useful in Servo is to split interface and implementation into separate crates. For example, the `gfx` and `layout` components interact with `script`, but their shared API surface is pretty small. We were able to describe that interface in about 100 lines of type and trait definitions as a new crate `script_traits`. So `gfx` and `layout` depend on the `script_traits` crate. `script` also imports that crate to implement the traits defined within. Changing `script` doesn't force a rebuild of `gfx` and `layout`. (Although you still pay the costs of monomorphization and codegen for any generic functions in `gfx`/`layout` that are used in a crate that also depends on `script`.) Servo's architecture of message passing between threads with disparate responsibilities is very well suited to this kind of split. In other projects it may be harder or impossible to construct the appropriate "header file" traits.
Everybody knows that. 
I would vote 100 times if I could, but for now I'll have to settle with my paltry 3 as well :)
`as_slice()` is deprecated in favor of `as_ref()`.
How does this interact with `abort`? Are all bets off then? What about `panic`?
Calm down Unidan.
&gt; Rust OTOH does allow you to: &gt; * Have resource/memory "leaks" I see this repeated everywhere. Why is it necessary? Why is it worth the tradeoff? Why can't we get rid of it? What causes the disadvantages of fighting this aspect of the language?
Note that the current top suggestion is a general plug-in system: https://visualstudio.uservoice.com/forums/293070-visual-studio-code/suggestions/7752408-plugin-system I would assume any reasonably flexible plug-in system would allow you to implement Intellisense for whatever language you want. Even Sublime's plug-in system is capable of that, and it's one of the more constrained ones out there. Which is why I put my votes on that issue over this one. (And had plenty of other desires to spend my other 7 votes on.)
I'll try to figure out how to do this. For now, [here](https://play.rust-lang.org/?code=use%20std%3A%3Athread%3B%0Ause%20std%3A%3Acmp%3A%3AOrdering%3B%0A%0Afn%20create_and_sort_buckets%3C%27a%2C%20T%3A%20Sync%2BSend%2C%20F%3A%20FnMut%28%26T%2C%20%26T%29%20-%3E%20Ordering%2BSync%2BSend%3E%28vec%3A%20%26%27a%20mut%20[T]%2C%20compare%3A%20F%2C%20sizes%3A%20Vec%3Cusize%3E%29%20{%0A%09let%20mut%20slices%20%3D%20vec![]%3B%0A%09let%20mut%20holder%20%3D%20vec%3B%0A%09for%20size%20in%20sizes%20{%0A%09%09let%20%28v1%2C%20holder%29%20%3D%20holder.split_at_mut%28size%29%3B%0A%09%09slices.push%28v1%29%3B%0A%09}%0A%20%0A%09let%20mut%20guards%20%3D%20vec![]%3B%0A%09for%20i%20in%200..slices.len%28%29%20{%0A%09%09let%20guard%20%3D%20thread%3A%3Aspawn%28move%20||%20{%0A%09%09%09let%20mut%20chunk%20%3D%20slices[i]%3B%0A%09%09%09chunk.sort_by%28compare%29%3B%0A%09%09}%29%3B%0A%09%09guards.push%28guard%29%3B%0A%09}%0A%20%0A%09for%20guard%20in%20guards.drain%28%29%20{%0A%09%09guard.join%28%29%3B%0A%09}%0A}%0A%0Afn%20main%28%29%20{%0A}&amp;version=beta) is a runnable example showing the described error. EDIT1: Let's see...first, by putting explicit type annotations on the first few variables, I move the error down to the thread spawn block. That indicates that the error is really there, and the error message pointing further up is due to type inference failure. See code [here](https://play.rust-lang.org/?code=use%20std%3A%3Athread%3B%0Ause%20std%3A%3Acmp%3A%3AOrdering%3B%0A%0Afn%20create_and_sort_buckets%3C%27a%2C%20T%3A%20Sync%2BSend%2C%20F%3A%20FnMut%28%26T%2C%20%26T%29%20-%3E%20Ordering%2BSync%2BSend%3E%28vec%3A%20%26%27a%20mut%20[T]%2C%20compare%3A%20F%2C%20sizes%3A%20Vec%3Cusize%3E%29%20{%0A%09let%20mut%20slices%3A%20Vec%3C%26%27a%20mut%20[T]%3E%20%3D%20vec![]%3B%0A%09let%20mut%20holder%3A%20%26%27a%20mut%20[T]%20%3D%20vec%3B%0A%09for%20size%20in%20sizes%20{%0A%09%09let%20%28v1%2C%20holder%29%20%3D%20holder.split_at_mut%28size%29%3B%0A%09%09slices.push%28v1%29%3B%0A%09}%0A%20%0A%09let%20mut%20guards%20%3D%20vec![]%3B%0A%09for%20i%20in%200..slices.len%28%29%20{%0A%09%09let%20guard%20%3D%20thread%3A%3Aspawn%28move%20||%20{%0A%09%09%09let%20mut%20chunk%20%3D%20slices[i]%3B%0A%09%09%09chunk.sort_by%28compare%29%3B%0A%09%09}%29%3B%0A%09%09guards.push%28guard%29%3B%0A%09}%0A%20%0A%09for%20guard%20in%20guards.drain%28%29%20{%0A%09%09guard.join%28%29%3B%0A%09}%0A}%0A%0Afn%20main%28%29%20{%0A}&amp;version=beta). EDIT2: Another problem is that the type system isn't granular enough for you to mutably pass each separate index of `slices` into a different thread, since each indexing operation is considered to borrow the entire vector. EDIT3: New version [here](https://play.rust-lang.org/?code=use%20std%3A%3Athread%3B%0Ause%20std%3A%3Acmp%3A%3AOrdering%3B%0A%0Afn%20create_and_sort_buckets%3C%27a%2C%20T%3A%20Sync%2BSend%2C%20F%3A%20Clone%20%2B%20FnMut%28%26T%2C%20%26T%29%20-%3E%20Ordering%2BSync%2BSend%3E%28vec%3A%20%26%27a%20mut%20[T]%2C%20compare%3A%20F%2C%20sizes%3A%20Vec%3Cusize%3E%29%20{%0A%09let%20mut%20slices%3A%20Vec%3C%26%27a%20mut%20[T]%3E%20%3D%20vec![]%3B%0A%09let%20mut%20holder%3A%20%26%27a%20mut%20[T]%20%3D%20vec%3B%0A%09for%20size%20in%20sizes%20{%0A%09%09let%20%28v1%2C%20holder%29%20%3D%20holder.split_at_mut%28size%29%3B%0A%09%09slices.push%28v1%29%3B%0A%09}%0A%20%0A%09let%20mut%20guards%20%3D%20vec![]%3B%0A%09while%20let%20Some%28chunk%29%20%3D%20slices.pop%28%29%20{%0A%09%20%20%20%20let%20compare%20%3D%20compare.clone%28%29%3B%0A%09%09let%20guard%20%3D%20thread%3A%3Ascoped%28move%20||%20{%0A%09%09%09chunk.sort_by%28compare%29%3B%0A%09%09}%29%3B%0A%09%09guards.push%28guard%29%3B%0A%09}%0A}%0A%0Afn%20main%28%29%20{%0A}&amp;version=beta). I'm having trouble expressing "split the slice into a bunch of slices", but I think the rest works out. It requires `thread::scoped`, which isn't available on the beta channel, for the reason that /u/lifthrasiir mentioned. EDIT4: All right, [working version](https://play.rust-lang.org/?code=%23![feature%28scoped%29]%0A%0Ause%20std%3A%3Athread%3B%0Ause%20std%3A%3Acmp%3A%3AOrdering%3B%0A%0Afn%20create_and_sort_buckets%3C%27a%2C%20T%3A%20Sync%2BSend%2C%20F%3A%20Clone%20%2B%20FnMut%28%26T%2C%20%26T%29%20-%3E%20Ordering%2BSync%2BSend%3E%28vec%3A%20%26%27a%20mut%20[T]%2C%20compare%3A%20F%2C%20sizes%3A%20Vec%3Cusize%3E%29%20{%0A%09let%20mut%20slices%3A%20Vec%3C%26%27a%20mut%20[T]%3E%20%3D%20vec![]%3B%0A%09slices.push%28vec%29%3B%0A%09for%20size%20in%20sizes%20{%0A%09%09let%20end%20%3D%20slices.pop%28%29.unwrap%28%29%3B%0A%09%09let%20%28chunk%2C%20rest%29%20%3D%20end.split_at_mut%28size%29%3B%0A%09%09slices.push%28chunk%29%3B%0A%09%09slices.push%28rest%29%3B%0A%09}%0A%20%0A%09let%20mut%20guards%20%3D%20vec![]%3B%0A%09while%20let%20Some%28chunk%29%20%3D%20slices.pop%28%29%20{%0A%09%20%20%20%20let%20compare%20%3D%20compare.clone%28%29%3B%0A%09%09let%20guard%20%3D%20thread%3A%3Ascoped%28move%20||%20{%0A%09%09%09chunk.sort_by%28compare%29%3B%0A%09%09}%29%3B%0A%09%09guards.push%28guard%29%3B%0A%09}%0A}%0A%0Afn%20main%28%29%20{%0A}&amp;version=nightly)! Key changes: 1. Replaced `thread::spawn` with `thread::scoped`. 2. Fixed method of collecting vector of slices. I still get the feeling that there's a better way to do it, but at least this works. 3. Changed handling of `compare` to not move the variable into the closure, since it needs to be available in all of them. 4. Changed the looping method over `slices` to one that satisfies the borrow checker's requirement that no value in the vector be borrowed mutably more than once.
One problem is that `let _ = ...;` behaves differently than `let _guard = ...;`; just the bare `_` means it's dropped immediately, rather than at the end of the scope. I found that fairly surprising the first time I encountered it. The other problem is that if you are creating these in a loop, even `let _guard = ...;` doesn't work, since its scope just lasts until the end of the loop body; so the guards constructed in a loop need to be put in an array somewhere, just to hold onto them for longer than the duration of the loop and drop them all at once afterwards. For instance, you might start with: let a = [0; N]; for chunk in a.chunks_mut(N/NTHREADS) { thread::scoped(move || process(chunk)) } But that doesn't work (and at least you get a warning about the unused return value). You don't care about the join guards though, you just want it to mutate those chunks, so you try: let a = [0; N]; for chunk in a.chunks_mut(N/NTHREADS) { let _ = thread::scoped(move || process(chunk)) } Oops, bare `_` means drop immediately, let's try naming it: let a = [0; N]; for chunk in a.chunks_mut(N/NTHREADS) { let _jg = thread::scoped(move || process(chunk)) } Nope, still doesn't work. Now you need to actually collect up all of those join guards and hold onto them for longer than the loop: let mut a = [0; N]; let mut jgs = Vec::with_capacity(NTHREADS); for chunk in a.chunks_mut(N/NTHREADS) { jgs.push(thread::scoped(move || process(chunk))); } It's actually a bit of work, and experimentation in which you don't do anything in parallel for a while, before you actually manage to get this to work, and the `must_use` warning only catches the first mistake.
Intellisense is the name for Visual Studio's code completion engine.
I second this. Guaranteeing that destructors run makes Rust closer to the mental model that the average user has, and this is a good thing! I am very much in favor of RFC 1094. The proliferation of types discussed in the article could be avoided by `Rc` and `Arc` always requiring a reference-counting scope `s`and providing a default scope with `'static` lifetime.
Great post! Just to add on the issue of non-terminating programs: If the language draws a distinction between data and codata then you can guarantee termination for one and guarantee productivity for the other, ie it won't just busy loop or sleep indefinitely.
Or, maybe the gofmt people aren't the only people who would benefit from rustfmt.
You are asking too much for rapidly evolving language. :) The convention is not yet set in stone and you will need some flexibility. Eventually we can declare a particular configuration as *the* coding convention, but til then, stay tuned.
I'm not sure I understand the new `scoped` API. Has it the same scope (sorry for the pun) as pythons *with* or java's *try-with-resource*?
**ANNOUNCEMENT**: I have just merged extra_lints into rust-clippy.
Let's not pretend that they are authorities on program formatting in general, or that Go invented the concept.
Finally, something I made is useful! I created this crate a long time ago to solve this exact problem. Let me know if it needs to be updated. https://github.com/contain-rs/par-vec It's a bit redundant with `slice::chunks` and `thread::scoped` now but it allows you to separate the subslices from the parent's stack frame, where I think it still retains some utility. It also calculates the slice lengths so they're as even as possible, which is something `slice::chunks` doesn't do. 
And deciding on the-one-true-formatting-way is simple (and perhaps arbitrary) when the biggest concerns are "should opening curly braces go on their own line", various ensugarings, and so on. http://www.reddit.com/r/rust/comments/34cyas/rustfmt_help_wanted/cqtmy2j
Nothing would change from today w.r.t. that. Abort, no chance of course. Panic results in unwinding, so the rules above should be neatly applicable. Just to say that if you haven't forgotten away some value, its destructors will run.
He may have phrased it poorly, but I think that an opinionated approach to formatting is a good one. What is the point of having multiple formatting formats, really? A formatting tool is to maintain uniform style, and one would expect the default style guide to be the one that most people agree on. What would be the use case for having a slightly different style guide? An option such as column max is fine, but separating braces and such is arbitrary. I'd rather have all of the code ever created in rust follow 1 formatting guide.
I wouldn't write C++ off:- So a lot of the mindset will transfer from Rust to C++, and you could argue rust being stricter would make you a better C++ programmer. However C++ has huge momentum behind it, the real value is that there are existing projects in mainstream use, if you learn C++ you can contribute to them. And vica versa, learning C++, Rust will make sense. r.e. employment in some fields you simply wont have a choice.. an established company that might employ you and needs low level code will probably revolve around its' own existing C++ assets, and use of existing C++ libraries. Experience of libraries contributes to your employability. And , a rewrite can be the death of an organization. Some design choices in rust prevent 1:1 mappings of C++ libraries. I'd 100% agree C++ has a lot of undesirable cruft (e.g. headers and clunky syntax) but good tools are available, they count for a lot - 'dot' autocomplete is a godsend working with big APIs - and rock solid 'jump to definition' navigation aware of all the context. C++11,14 have improved things and there are some good potential proposals for 17 I'm praying for (UFCS). If you have a new angle for a new project.. then Rust would be interesting. r.e. new territory, maybe others could comment: perhaps rust has potential for "the internet of things" which requires security and low-level efficiency. 
Just because something is difficult doesn't mean it shouldn't be done. Actually, because deciding such things is difficult, it's more important that this gets done. Having one way of formatting rust code has the benefit of code that is easier to read for new people.
&gt; Basically Rust can't protect you from the above because it's a systems language, and like it or not, you need those freedoms to ensure you can work fast enough. No. Rust doesn't protect you from these problems because you can't practically do so, and in fact no practical language does so.
&gt; I still get the feeling that there's a better way to do it Here is an alternative with a recursive pattern (no more push/pop). http://is.gd/bbguEy Or of course use an evolution of the unsafe methods used in std fn split_at_mut(&amp;mut self, mid: usize) -&gt; (&amp;mut [T], &amp;mut [T]) { unsafe { let self2: &amp;mut [T] = mem::transmute_copy(&amp;self); (ops::IndexMut::index_mut(self, ops::RangeTo { end: mid } ), ops::IndexMut::index_mut(self2, ops::RangeFrom { start: mid } )) } } 
The former. Could anyone write this example in Rust for me?
25x80 terminals are still the standard and default in unix and windows. When doing kernel and embedded work one sometimes ends up programming in these (it doesn't happen all the time, but it doest happen often enough to worry about it). So one important reason to me is that in important fields within "systems programming" we don't have more than 80 characters per line, and we won't have them in the near future. There are other good reasons. For example we have 60 years of 80 characters legacy and that still leaks to new tools (e.g. git). Some of us still need to use some of these tools (source control, diffs, editors, terminals, ssh...) which are designed for an 80 character limit. I think both of these reasons are just realities we have to live with. Every person I've met thinks that a larger number than 80 would be better if we would be able to use it everywhere. I work on some projects with 120 characters and I like it. It is, however, not the way things are. So I prefer to be practical here. For the reasons above I choose 80 characters as limit for my own projects. A nice side-effect i've discovered is that with a modern monitor you can do a 3-way merge without line wrapping. I find this is also nice since manually merging conflicting code is an error prone task and line-wrapping doesn't help. In my opinion, a solid style guide should: - be usable (i.e. work for all of us) - I think this sadly means 80 characters (and probably 2 to 4 space indentation) but I hope someone proves me wrong - improve my productivity: - no more discussions about style, ever. Not in code reviews, not in pull-request, not in meetings, not with your self. Not thinking about formatting is really liberating. Sometimes while brainstorming I write really ugly code really fast and then I hit tab and it looks awesome (been using clang-format for over a year). With such a tool, you just focus on what the program does, and not in putting spaces after commas. - maximize the amount of context I can see on the screen. I don't mean "squeeze everything in a single line", but more like don't waste vertical space. The more context I can see at once on the screen, the more productive I am. There is an article praising this on John Carmack's code which I think is worth a read: http://kotaku.com/5975610/the-exceptional-beauty-of-doom-3s-source-code - I mentioned 3-way merging without line wrapping as a nice to have feature, but as screens get larger this will probably be possible with any style guide we choose.
Sorry for being a bit uninformed about the subject, but my question is if the **only** reason that Rust doesn't provide a guarantee that destructors will always be run is that using the Rc library might cause memory leaks? If so, it seems to me like a big price to pay at the language level to enable a small (but non the less important) library feature and that a solution should rather focus on fixing the Rc problem (possibly by restricting the types that can be used in Rc). Rc is after all just a library, which might even be replaced by a proper GC in the future.
I'm sorry, but I do not believe this to be a place where software is written for you. You should give it a go yourself and ask for help here, on http://users.rust-lang.org/, on IRC, or some other place, if you get stuck.
Rust tends to be pretty indentation happy, so I see the case for 100 characters as reasonable. On the other hand, my viewing setup is for 80 chars. The size of my monitors, the distance I sit from my monitors and the font size of my code all mean that 80 columns is just about right for viewing two files side-by-side on a single monitor. I am not going to give that up. At least, not for the code bases that I am responsible for maintaining. In the Go world at least, there is no line length recommendation (AFAIK). In spite of that, the `gofmt` tool works well with code that is written for 80 columns---it won't take a function definition that was wrapped and unwrap it onto one line. Hopefully `rustfmt` can do the same--and hopefully without any config flags. (I haven't used it yet so I don't know what it does now.) But if it forces 100 columns on me, I just won't be able to use it.
Can't you just put it on one line instead?
I think RefCell might be the answer
See my answer above, the TL;DR is that in important fields within system programming you still end up programming in a 25x80 terminal (kernel/embedded work), and that a lot of legacy tools (and newer ones) that we still use are designed with this limit in mind.
A cycle is essentially a dependency loop. (sorry for formatting, on mobile) Imagine a type called Person that has a field child and a field parent. Now create a person A who has child B. A will hold a reference to B in the child field, and B will hold a reference to A in the parent field. If you draw the relationship out on paper with arrows, you'll see a loop. A - &gt; B - &gt; A - &gt; B... The problem with this is that rc only cleans up its contents when there are no more reference to it. A won't get cleaned up until B gets cleaned up, but B won't get cleaned up until A is. This means that even though A and B may be unreachable in code (ie the rc went out of scope), the memory will live forever 
Suggestion about Rust https://visualstudio.uservoice.com/forums/293070-visual-studio-code?query=rust
That is great to hear! I'll have to pull it down and check it out again.
Yes, you're right. That was part of my point; I should have included that example as well, since there it does work the way you expect. On the other hand, what that really means is that the vector is hidden away inside the API, which means you have hidden extra allocations, and no way of setting the capacity beforehand. I'm not entirely sure that's a bad thing, but it is something to consider based on the general desire to provide zero-cost abstractions.
Thanks for reminding me that computing sucks.
I've been using Atom for rust development over the past two or so weeks. Honestly can't complain about it.
I don't disagree with your analysis, but I come away with a slightly different conclusion. In particular, I think we are working with something of a fundamental tension, and there may not be a "solution" (but see my last paragraph). Object types are designed to *encapsulate* the type that is being used -- that is, they are designed and intended to hide information. This is often a good thing. Hiding information means you can't accidentally rely on it. It means you can have simpler type signatures because you don't have to expose (for example) what kind of types you are holding on to and so forth. On the other hand, hiding types also means that the compiler doesn't know and can't analyze those types for safety. If you look back at papers on parallel programming, there's a repeated observation that parallelism is anti-encapsulation, which is something I'm really coming to appreciate more and more. So what I take from this is probably two things: 1. Writing code generically is, ultimately, more flexible for your clients, but it can be a lot more complicated, and it can be expensive in terms of code blowup. So I imagine there will continue to be a push, particularly in library code, away from objects. 2. Given that we probably can't resolve this tension around objects, we should do our best to minimize the number of fundamental splits people have to work with. In other words, I DO think that adding `Leak` meaningfully changes the situation, because the number of choices continues to grow. All that said, I see some longer-term prospects for finding a middle ground between type parameters and objects as we know them today. Specifically, we might allow you to define "erased" type parameters -- these would act like ordinary generic parameters, except that we would guarantee that the compiler can generate just one copy of the code that is manipulating them (just as we would with an object). This implies virtual dispatch, for example, and it also implies that you must manipulate them indirectly (like a pointer). But you're still not *encapsulating* the type: that is, you're not hiding it, so your clients can still analyze it. Even so, there are certainly scenarios, such as heterogeneous lists, where it's harder still to get away from objects. (And, this is all somewhat speculative.)
Another safety measure to take against memory leaks -- The whole problem occurs only when there are *strong* reference cycles, right? And in most cases, we could find a referrer which can be downgraded (without breaking code logic) to break that cycle, and everything will be fine! Am I correct?
&gt; ...true linearity... Your point about RAII being limited to infallible operations is well-taken. That's another limitation of RAII that I hadn't been thinking about. Regarding true linearity, I think it could potentially help, depending on how it was defined. &gt; ...syntactic sugar for closures... I was actually thinking of something a bit more radical, more like Haskell's `do` notation, but extended beyond the traditional monad to support more kinds of control-flow (probably somewhat similar to the old `for`-loop sugar we used to have). Then you might write: ``` { let scope = do thread::scope(); let future = scope.spawn(|| { ... }); } ``` Here, `let &lt;pattern&gt; = do &lt;expr&gt;(&lt;expr&gt;,*);` would be a kind of statement that transforms all remaining statements in the block into a closure that is passed to the function being called. `&lt;pattern&gt;` would be the arguments to the closure, and the closure would be expected to have some return type indicating control-flow (much like the `for`-loop sugar we used to have). In other words, ``` { ... let &lt;pattern&gt; = do &lt;expr&gt;(&lt;arguments&gt;) &lt;remainder&gt; } ``` would be transformed into something like ``` { ... &lt;expr&gt;(&lt;arguments&gt;, |&lt;pattern&gt;| ControlFlow::PassThrough(&lt;remainder&gt;)) } ``` where `ControlFlow` is part of some enum like: ``` enum ControlFlow&lt;A,B&gt; { PassThrough(A), Break, Continue, Return(B) } ``` Anyway, I'll be honest, I haven't given this a ton of thought. Probably the design I sketched above is full of a bunch of little flaws, and I'm not sure that a feature like this carries its weight. But I think it is definitely plausible that we could do something like this if this kind of closure-pattern becomes very common. 
You're right. Now that I think about it again, I don't think it would. I think the only thing that needs to differ between `Rc&lt;T&gt; where T: 'static` and more general `Rc&lt;T&gt;` is that the constructor of `Rc&lt;T&gt;` would need to be private, but that can be done by just naming it something different in a private trait. I can't actually think of any other operations which would need to differ. I don't have time to work through the whole implementation myself, but I'll go mention the idea on the issue; I think this proposal would be a lot more palatable without the combinatorial explosion of number of types.
If you need to share it between threads, Arc. If not, Rc. Since it is a data structure, not a resource that you want to share, Rc is probably the answer. The leak in Rc only happens under specific conditions, and I hope it is fixed soon (there is a RFC already, IIRC). EDIT: you could also just have the parent own the child, and the child point to the parent with a raw pointer. You'd have to make some unsafe code, but it's not too hard to make a safe API for that. 
Yes, the pointer back to the parent must be a weak pointer. 
Ah, I see that this was already brought up in the [Unresolved Questions](https://github.com/rkjnsn/rfcs/blob/guarantee-non-static-destructors/text/0000-guaranteed-non-static-destructors.md#unresolved-questions) section of the [RFC](https://github.com/rust-lang/rfcs/pull/1094). I definitely think that it would be a preferable alternative.
Yes, and the readability issue of restricting yourself to 80 on a line (when you have space) in a language like Rust (where this restriction will lead to lots of statements being split over way too many lines) is just as bad, or worse, than the readability issue of having to read code written with &gt;80 on a line on a terminal of width 80. 
The gudelines are in-tree now, as `src/doc/style`
After following this for several days, I think I'm now in favor of the status quo with a very strong warning on `Rc` types that can potentially contain cycles that suggests looking into `Arena`s.
I'm also :+1: on the anti-configuration of `rustfmt`.
Awesome, thanks!
I second that, configuration should be a second taught (if any).
&gt; If I give you a library, that clones an `Rc` and keeps it around in a `'static' variable: is that a memory leak? It keeps a copy of the `Rc`? Then it depends - after a terminating library call it should be gone, and it will be, right? I mean, you could do a similar thing with other types by `let`ting it in the function that was called and keeping it around until the call terminates. Does this sufficiently address the question in your opinion? &gt; If my function does something that threatens the OS to the point it decides to completely terminate the program, without allowing your destructors to run: is that a memory leak? Not as far as I can tell - the memory will be freed soon anyway and it's not a guarantee that the program can possibly give without guarantees from the OS, which *can* never be given (heck, the computer could shut down due to a power outage). I'd be more concerned about I/O (I've had programs killed where essential data was still in a buffer and never made it to disk). In my other comment I explicitly made nonterminating programs an exception to my question. For the sake of brevity I didn't do so here. I strongly regret that now. &gt; This last case is critical: the language can't promise you something that your OS won't keep! And that's okay, but I don't see how that justifies the apparent horrors of `Rc`! &gt; In the area of programming languages, the safer your language, the less you can do. Sure, but I haven't heard about what specifically cannot be done without `Rc`. It seems like one of those rickety bamboo ladders being held upright by a person that are convenient when you don't have something better. The problem is that I think we do have something better - other data types. &gt; There's this whole area of programming that can be "proven" to be safe, the catch is that it's not easy (it might even be impossible) to make a program that can loop forever. I'm not suggesting we remove Turing completeness from Rust. I'm wondering out loud if Rust shouldn't be leak safe for terminating programs. I'm working based on the assumption that Rust will end up as the basis of a trillion dollar worth of code. I'd rather have it be as close to perfection as it *can* theoretically be as a TC language. I've read your full comment, but I still don't feel I have the answers I was looking for. I still don't know why it's necessary for `Rc` itself to leak, as I don't see any specific disadvantages. Sure, I realize that to have a powerful programming language you need to be able to do things you may not want to do (e.g. nonterminate), but I haven't heard a single good reason why `Rc` should have these sharp edges. It does sound like throwing out all of `Rc` *entirely* would fix the issue without making anything impossible. Maybe I'm wrong, but at least I'd like to figure out why I would be, and I hope someone can help me with that. Sadly, the arguments in your comment are too generic to address the concerns I have with `Rc`.
Well, usually, you use `Deref` coercions: `&amp;matches.free[0]`, `&amp;s`, etc.
I can give a simple answer you won't like: If it isn't configurable, there's a good chance there's something in there annoying me enough to not use it at all. If it's configurable, I can have everything be like the guidelines propose, except for (for example) indentation. With a per-project configuration file you don't have to think about it when contributing either.
Hmm. So basically a continuation passing style transform? I wonder if `do` is the right keyword for this, this looks a lot like `yield` to me. You're right that this probably doesn't carry its weight for just the scope sugar, but if it could also be used for generators or async programming, then it might be worthwhile. However, I haven't thought it through much either. **edit** Hmm. Not really a `yield` since it's not actually returning control to any parent stack frame. But anyhow, I feel like this is within the design space of the various discussions like `yield`, `async`/`await`, and other forms of providing better sugar for dealing with continuations conveniently.
Woohoo!
Actually, if it's just simple value types being stored (any type that implements `Copy`), `Cell` is probably a better answer.
Thank you! That answers my question pretty thoroughly: the approach might be viable, but making it work with mutability in a precise way is a research problem. Just to clarify (sorry, I'm a newbie to Rust): is it true that the main difficulty is due to RefCell, and e.g. Cell is unproblematic? If yes, then it seems encouraging, because Cell gives us a form of mutation, and RefCell was always kind of unsafe to begin with...
It is not necessary for people to agree on it. It just has to be a reasonable compromise. So long as it is not terrible, you can get used to it.
If you've ever worked in a team, you'll know that other people's idea of good formatting is much worse than the compromise that something like a fixed rustfmt or gofmt style offers.
If we procedded with `thread::scoped` as before we could read free'd memory. With no unsafe code. That's why it's become a large problem.
Yes I do. Still doesn't change the fact that I wouldn't use it. Well, realistically I'd probably just use a forked version. Most of the Rust code I write now and will probably write in the future is for me, even if I publish it as a crate. And so, being able to easily read it myself is my number 1 priority. And there are a couple things in the styleguide that would make scanning code harder for me, especially if there's no syntax highlighting. Edit: Grammar fixup.
No, it doesn't. And it's actually a bit mean to suggest that people who want configurability don't care about consistency, and don't get the point. What you're looking for is consistency across the whole ecosystem. What we (or rather I, since I can't speak for anyone else) want is per-project consistency.
I agree know, on the one hand configuration does seem like it might defeat the purpose, on the second hand I won't use any tool that forces me to write braces on the same line..... So if we have it configurable w/per project setup file I would use it; if not configurable I simply wouldn't use it.
Wait is visual studio itself going to be cross platform? I dislike closed source but it doesn't lag like eclipse on Linux :-{ but hey vim still works
I am someone *firmly* in the "throw features at a system until the requests stop coming because all the users have run screaming" camp. I would *totally* just add `Leak` and call it a day. A major reason I am not-so-quietly cheering on Rust is that it has people in the core team who are very clearly *not* that impatient. I can't not be me, and I appreciate them all the more because of that. :D
So a somewhat related question from someone completely new to Rust: Why is borrowing arguments not the default for methods? [Yehuda Katz wrote](http://blog.skylight.io/rust-means-never-having-to-close-a-socket/): &gt; In practice, the reason this works so well is that most of the time, functions that take values are â€œborrowingâ€ them. They take a value, do some work with the value, and return. Holding on to the value for longer, for example by using threads, is both uncommon and an appropriate time to think a little bit about whatâ€™s happening. &gt;The starting point when writing new functions is to borrow parameters, not try to take ownership. After a little while of programming with Rust, this imposes no cognitive cost; itâ€™s simply the default. So why isn't it the default syntactically, and taking ownership a special operation that requires some notation?
Personally, I like the idea of type erased generics distinct from trait objects... Rust right now claims to give you the choice between erasure and monomorphization but in practice you have to make other tradeoffs at the same time. It feels like this would be useful for other situations as well; for example, could this be used to get polymorphic recursion into Rust (come on, we all want it)?
If point is consistency between collaborators than that is guaranteed by `rustfmt`. Consistency between projects is IMO overrated. Does an embedded project has to look like someone's CRUD application? I think one size doesn't fit all. Configuration should be optional. That way those that want it will add it will. If there are religious debates e.g. over tab vs spaces, then simply remove custom formatting and use the default.
Yup, that's a good way to put it.
&gt; If my function does something that threatens the OS to the point it decides to completely terminate the program, without allowing your destructors to run: is that a memory leak? This last case is critical I think this case is a red herring: mostly what people have been asking for is a guarantee that *if your program keeps running* then destructors will run. 
&gt; There's this whole area of programming that can be "proven" to be safe, the catch is that it's not easy (it might even be impossible) to make a program that can loop forever Man don't let Conor McBride catch you saying that.
Limiting our thinking to terminating programs is not reasonable. Most programs in production are non-terminating, and for such a program it would be impractical to attempt to statically eliminate all resources leaks.
This is a new editor, called "Visual Studio Code." It's based on the guts of GitHub's Atom editor, with a UI written in TypeScript.
This is a proprietary editor. Also from https://code.visualstudio.com/License For this pre-release version, users cannot opt out of data collection. I don't know why people are so hyped on this, seems really stupid compared to existing editors.
&gt; You seem to assume that there is some one-formatting-style-to-rule-them-all which has already been invented. No such assumption is necessary. The only assumption made is that *picking a style* is better than bikeshedding endlessly over it and ending up with differently formatted code in the ecosystem. Maybe you don't buy that assumption. That's fine. But it's entirely different than the assumption that there is some objectively "best" style.
I agree, a lot of work has been done to cover more and more programs, and a good subset of programs could be done with non-turing complete languages that have stronger guarantees. The point is that there'll always be programs that you want to do this "bad things".
What do you mean by the first sentence? I'm not suggesting making Rust non-Turing complete. I'm saying that for terminating programs it may well be possible to make it leak-free or more leak-free and that the resulting leak resistance will translate in part to nonterminating programs. If you don't think it to be practical, what counterexamples did you have in mind against what I suggested?
It's the extra set of delimiters and trailing semicolon that makes it feel clumsy (plus the extra level of rightward drift, though my proposal doesn't deal with that, while Niko's does). You can't get rid of the extra delimiters with a macro.
That's true (about the delimiters), but I kind of think the answer to *that* ergonomic issue should be "it's annoying but deal with it". One of the supposed benefits of a macro system is the ability to write new syntax. Rust's is somewhat second-class since the new syntax really has to conform at its outermost level to a specific pattern, but it's still *there*. Why not use it? (I also thought that "if let" and "while let" should have been macros, though, so feel free to disregard me as a crank.)
&gt; If you've ever worked in a team, Nice rhetorical device.
You make it sound like it happened once in recorded history.
Heh :) Well, with all the rust of the last few months, usually, I'm complaining that I have to roll up 15+ PRs, rather than empty time in the queue.
Yeah, it's a tradeoff, I agree. I use splitscreen a lot so I like 80 too, I was just pointing out that there is a tradeoff here in the first place.
Leak was always about a lifetime bound - types that are `:'static` are trivially Leak. You don't need another thread to lose track of an `Rc&lt;Something+'static&gt;` - any long-lived variable is enough.
That's not the guarantee `Leak` provides - it only says that *if a resource becomes invalid* then that resource was already freed. Most resources people are afraid of leaking (temporary files, memory) never become invalid, so `Leak` doesn't force them to be freed.
Yeah, the way I read it I kind of assumed that he would be mutating the actual structs, rather than just writing a new value into the Cell (or perhaps I'm missing the point?) For instance, if you had a `particle` type that has a method `apply_forces(x, y, z)` or something like that, you would need a mutable particle. You could, however rewrite it so that `apply_forces` returns a new `particle` instead. I've actually never used the Cell types, so please correct me if I'm misunderstanding
Agreed, I don't understand what this brings over a good, FOSS IDE. I'd rather use Vim or EMACS (with a few plugins) any day. And for those that don't like them, there are very good open source IDEs out there, if you just look.
 Yes, it is proprietary but what's wrong with it supporting Rust? Also does that mean other proprietary editors can't support Rust as well? I just puzzled about your thinking? Rust needs to be visible to gain mindshare. :) &gt;For this pre-release version, users cannot opt out of data &gt;collection. If you're worried about your privacy do not use it. :) &gt;I don't know why people are so hyped on this, seems really &gt;stupid compared to existing editors. I am not really sure what you were talking about but I want to see Rust support in all the editors. ;)
Let's see the problem differently: which leaks? Personally, I define: - memory leak: memory that is inaccessible - space leak: memory that is accessible, but will not be accessed (ie, it's unecessary) The distinction might seem arbitrary, but it just derives from `valgrind --tool=memcheck` which only reports "memory leaks" and not "space leaks". You can also see it as the difference between what a GC helps with and what it does not. An example of space leak: struct ServerState { sessions: HashMap&lt;SessionId, SessionState&gt;, } without proper cleanup, you might retain a `SessionId, SessionState` long after the session should have expired (or the client disconnected). At this point it's useless, and will never be accessed any longer, yet it's cluttering your memory, and might even be tying up other resources (open DB connection? open DB cursor? open files? ...). Guaranteeing the absence of space leaks might be solved in some academic language, but I would like to see how restrictive that language is. Certainly, no mainstream language that I know of (not even Haskell), can make such a guarantee. So, if you cannot guarantee the absence of space leaks, how hard should you battle for the absence of memory leaks? In current Rust the risk of space leaks far outweighs the risk of memory leaks, and those are clearly delineated to the `Rc` and `Arc` types. As an engineer, used to trade-off, my opinion is that unless the solution is trivial and "cost-free", it's not worth chasing any further.
Exactly my thoughts! Text editors have been sprouting up faster than new Javascript frameworks lately. If it's not open source, I won't even take a look at it.
That's a good point; I imagine it would be relatively easy to add a `set_capacity` method to `s`.
Have you tried installing a Unix overlay and compiling via gcc or clang? As far as I know, MSVC compiled code can't link with code compiled by anything else because it uses different obfuscation and calling conventions. Clang is probably the best choice, as it uses a LLVM backend just like Rust. Edit: I don't use windows, so there may be compile options to increase compatibility, but I don't know.
I'm really no expert, but if you look closely, you'll see that the library exports '**_**say_hello', while rust looks for a plain 'say_hello' A quick google search reveals, that the problem might be a missing '__declspec(dllexport)' although other posts suggest that this won't work, and others refer to a '.DEF' file, in which you can explicitly configure which internal name should be exported to which external name.
No, I mean that you could use `Cell` for the actual values inside the `particle`. For instance, here's an example where each particle has a velocity and a position, which are stored in cells, so you can have an `&amp;particle` reference but use it to update the values within ([playpen link](http://is.gd/AFD1Ap)): use std::cell::Cell; use std::ops::Add; #[derive(Copy, Clone, Debug)] struct Vec2d { x: u64, y: u64 } impl Add&lt;Vec2d&gt; for Vec2d { type Output = Vec2d; fn add(self, rhs: Vec2d) -&gt; Vec2d { Vec2d { x: self.x + rhs.x, y: self.y + rhs.y } } } #[derive(Copy, Clone, Debug)] struct Position(Vec2d); #[derive(Copy, Clone, Debug)] struct Velocity(Vec2d); #[derive(Debug)] struct Particle(Cell&lt;Position&gt;, Cell&lt;Velocity&gt;); impl Particle { fn new(p: Position, v: Velocity) -&gt; Self { Particle(Cell::new(p), Cell::new(v)) } fn update_position(&amp;self) { let &amp;Particle(ref pos, ref vel) = self; pos.set(Position(pos.get().0 + vel.get().0)) } } fn main() { let p = Particle::new(Position(Vec2d{x: 0, y: 0}), Velocity(Vec2d{x: 1, y: 2})); println!("{:?}", p); p.update_position(); println!("{:?}", p); } The advantage of `Cell` over `RefCell` is that it is basically free, it just exists to provide interior mutability at the type level while imposing no runtime cost; all you are doing at runtime is copying the value in or out of it, just like you would if you were simply setting the field on a struct that you had a mutable reference to. Additionally, there is no possibility for it to panic; since it's only accessible from a single thread, it knows that when it's running it has exclusive access, there can't be anything else accessing the same cell at the same time. `RefCell` has to check this dynamically; when you get a mutable reference out of it, and pass that reference around, it needs to make sure at run time that you haven't gotten another reference out of it somewhere. So that imposes a cost, it needs to set a counter indicating the number of immutable borrows (or the single exclusive mutable borrow), and panic if you try to get a mutable reference to something that's already borrowed, or an immutable reference to something that's already borrowed mutably. They both have their uses, and sometimes you really do need a reference (for things that aren't plain old data, for large structures that are expensive to copy, etc). But for small simple plain old data like points, `Cell` is substantially more efficient, and you can't make a mistake with it that will lead to panic.
&gt; and I hope it is fixed soon I somehow doubt it (see http://smallcultfollowing.com/babysteps/blog/2015/04/29/on-reference-counting-and-leaks/). Leaks are (unfortunately) fundamental. Even GC'ed languages allow leaks, maybe not "unreachable memory" leaks but certainly "uselessly occupied memory" leaks. A simple example is a server keeping a map `SessionID` to `SessionState` and never removing anything from that map; it grows indefinitely.
&gt; Yes, it is proprietary but what's wrong with it supporting Rust? Also does that mean other proprietary editors can't support Rust as well? I just puzzled about your thinking? Rust needs to be visible to gain mindshare. :) There is nothing wrong with it supporting Rust. I just don't like to tone the post sets. it's the perfect time to be /the/ IDE for rust development. An editor that might become proprietary at any point in time doesn't sound like a target for being "/the/" Rust development environment. &gt; If you're worried about your privacy do not use it. :) I won't touch it with a 10 foot pole. &gt; I am not really sure what you were talking about but I want to see Rust support in all the editors. ;) Good luck with that. I am biased towards Micro$oft but I objectively see this editor as bad because they rip off the atom core and build on top of OS software while making it proprietary.
Of course, up to performance and IO API, you can implement a "general-purpose" language on top of any "turing-complete" language, and even some non-turing-complete ones, by e.g. implementing a stringly-typed (i.e. Goedel-numbering-typed) interpreter and running it for 2^128 steps. Of course, this won't help you deal with any bugs. If you are using a language in a "practical, general purpose way", then with the current level of proof systems you can't prove that your program doesn't leak (that resources will be discarded as quickly as you want them to), that your program doesn't have security problems, or that your program lacks race conditions, including deadlocks (if it concurrently interacts with something). This does not have anything to do with run-time performance, in the polynomial sense.
You totally missed my point. When people program in go (and I realize there are other examples of this, but go is the one people bring up in this context) there are no options. You just use go fmt and get on with your life. The bike shed has already been painted, focus on writing code. 
No (usefully general-purpose) programming language provides the guarantee people *want*.
If it's possible to turn it into a configurable file, it's possible to hardcode that configuration. Having all rust code follow the exact same format removes bike-shedding during code reviews which is my favorite part of writing go. I'm a C++ programmer that has been kind of forced into writing go as my day job lately and I dislike many elements of it but the gofmt part (and other tooling) is definitely one of the strongest elements of it. I believe rust should look at successes in other languages and mimic those where possible. Configurable formatter to me is an anti-pattern.
Haskell is actually quite terribly wrt. space leaks. 
&gt; ..? (it's already proprietary) I believe he meant "paid".
I don't know how up-to-date this list is: http://doc.rust-lang.org/grammar.html#keywords Edit: You might also want to have a look at https://github.com/rust-lang/rust/tree/master/src/grammar
We currently unwrap. I certainly hope to support a mode in the future where we wouldn't.
It's very up-to-date.
I think /u/phaylon puts it well below. I care about consistency within a project more than consistency within the ecosystem. I hope that Rust will be used in many existing projects and these will often want Rust code to match their existing code style. We need to accommodate that, if we don't then they'll choose to not use rustfmt, or use a version of the tool that does allow them configurability.
&gt; the 'move' keyword. http://doc.rust-lang.org/nightly/book/closures.html#move-closures &gt; As far as I can tell, (Chrome and FF on OSX) all the links in the reference are broken, Oh my! This sounds like a bug. They work fine in Firefox on Linux.
Almost all types? Not: * `Files` * `Mutexes` * `Arc` * `Rc` * `Vec` * `Box` All of the above will have negative side-effect if they leak. And programmers *will* misuse `Leak`. `Leak` is only for things like `JoinGuard`? In other words, `Leak` is only to support misuse of patterns? `Leak` is only for when you can't think of a better way to do something? So we grab something from crate `A` and then pass it to another crate `B`'s `foo`, and `foo` stores a `Rc` of that object. Then the `A` struct has a new field, that contains a `JoinGuard` (say that it actually contains a `Future` from another library, which itself contains a `JoinGuard`, non-obvious) and suddenly that structure is `!Leak` and `Rc` can't receive it unless it's `'static`. Of course unless having a `!Leak` Member doesn't make you `Leak` in which case you can still cause the leaks by wrapping it on a struct: you'd only be protecting against the trivial case designed to be obvious. You might be surprised, but I assure you that if I look at random pieces of code I'll find implicit futures and thread handles (which is what `JoinGuard` is) than I'll see cyclical reference counting (or reference counting at all!) or any of the strange ways in which you could forget something without destroying it. `Leak` can be done, it's just not worth it. It's easier to having mind that, if you use `Rc` you have to be careful with leaks; than having to consider, whenever you create a struct or a type that, because some library's `Rc` has trouble with it, you need to be careful about not making it `!Leak` accidentally. I think it's fair to make life harder to the few people that use `Rc` to not punish the large amount of Rust devs that will create a `struct` or type. The opposite not so.
Ahh, that sould also explain why `linkchecker` was fine too.... https://github.com/rust-lang/rust/issues/24999 filed. Thanks!
Well that is a tad less exciting unless somehow intellisense is either portable or superior to other autocompletes....
I like Haskell's approach to dealing with temporary values. Instead of finding garbage, of which there is tons of, it just finds what isn't garbage and keeps that. More memory is garbage than not.
Why is this not an issue in go then? (or pep8 for example)
I know many Python projects don't use any formatting tool at all. I'm not sure about Go. Perhaps it is not used so much embedded in other projects? Perhaps Go programmers are particularly accustomed to strict formatting? Clang format chose to be configurable, so there is certainly motivation on the C++ side of things. Perhaps if we'd had rustfmt from the start we could get away with this, but even Rust and Servo use different styles already, I think it is simply too late to enforce a single universal style.
Or you use Atom which is the FOSS editor Visual Studio Code is based on. It doesn't make sense to put any Rust development effort behind VSC.
I get that point, I just disagree and believe per-project configurations are a good middle ground.
Generally the Go workflow involves just running `gofmt` after saving (many editor plugins do this on their own, as well as stuff like `goimports`) Go is pretty simple so the "one true way" of doing things is easy to remember and easy to enforce. With Rust, for stuff like type parameters there's not always a way to format it nicely+uniformly and some wiggle room is nice.
Having read up on Cell and RefCell, they have indeed provided me the answer, and also helped with a few other problems i've been having with Rust. Thanks for the tip.
What is memory safety? That you won't leave chunks of memory allocated without use leading to an OOM error? Then yes all those count. Is it not having access to memory that has been released? Then the problem isn't really `Leak` but misuse of a pattern: the RAII Guard. Again if `Leak` is only meant to solve this specific case then you are only trying to keep a hacky version alive because people liked the idea of scoped threads that were safe, but refuse to understand that the design of the first library was *wrong*, instead trying to say that it's a problem with the language. The RAII Guard pattern is simple: 1. You have a resource that you want to share/lend, but after the resource is freed you need to do some cleanup. 2. The borrower doesn't receive the resource, but a guard that contains the resource. 3. The borrower cannot use the resource unless it keeps the guard around. You can then expect that the guard will do the clean up for you. Here's how scoped thread worked: 1. You (parent thread) have a resource share/lend (the local stack). But you need to do cleanup *after the resource has been left*. 2. The borrower (the scoped thread) borrows the resource straight up. The lender keeps a guard around to verify something. 3. The borrower can use the resource as it pleases, with no guard. OTOH the lender will try to wait for the guard to tell it that it's ok to take back what it owns. See the problem? It goes against the notion that the owner of a resource is the one that decides what can and cannot be done with it. The reason it's called "Guard" is because it protects the resource. Here the `JoinGuard` is staying behind leaving the resource to be used freely by the second thread. It *cannot guard anything*. The problem is simple: `JoinGuard` was not a Guard, it was a misuse of a pattern and was wrong. The wrong assumption wasn't "`JoinGuard`'s destructor will always be called". The wrong assumption was "If we borrow something and need it to have a longer time, we can extend the lifetime as needed". That's not how Rust works, but basically that's what would happen. The new closure system solves this by forcing the scoped thread to have a very defined lifetime that is explicitly smaller than the owner of the stack (parent thread) because it has a defined end in the parent thread.
&gt; That you won't leave chunks of memory allocated without use leading to an OOM error? Then yes all those count. No. That's not what memory safety is. Moreover, it's not what I have *ever* claimed memory safety to be, nor is it the standard definition of memory safety. On the other hand, use after free, data races, etc. *are* memory unsafe. Those are what the `Leak` trait would be designed to help with. Destructors running on stack unwind is a nice property of safe Rust and it would be pleasant to be able to recover that property if necessary. There's no reason to *require* a destructor to run if it won't cause such problems, because your program could be aborted at any time anyway. You can argue that people were just using RAII wrong in some philosophical sense. That's fine. I'm not here to argue philosophy with you. I don't even mind the new `scoped` API. At the end of the day, the fact remains that we know what the problem with using RAII for this was (you don't need to keep explaining it to me :)) and we know a way to fix it (a `Leak` trait) that would allow us to continue using RAII for it and similar types and wouldn't affect most code. Your assertion was that an `Rc` that couldn't accept `Leak` types wouldn't be very useful, and mine was that no, it would be able to accept nearly all types. That's all. Please stop reading more into it.
`become` was/is reserved for guaranteed tail call optimization, and if I recall correctly `do` was sugar for functions that took a closure as their last argument.
Some people might prefer an IDE with proprietary backing. I could imagine that if you are a paying customer, you get better support and can request features without being told "patches welcome". I think it is somewhat rude to dismiss this as "stupid" just because you prefer Open Source IDEs.
I agree that gofmt existing very early was a big help but rust and servo are two projects. If rust gets as big as go (or bigger) then relatively speaking those two projects won't represent a large part of the code base.
So, why is this in the rust subreddit and not in /r/programming? 
&gt; Personally, I like the idea of type erased generics distinct from trait objects... (I do too... but how does this enter into the current discussion?)
There now four steps but soon came more! For now for start with basic it is enough. Also check @brson`s tutorial with Iron [there](https://github.com/brson/httptest)
FWIW, that technique is a fairly standard implementation of garbage collection. :)
The cycle is `Car` -&gt; `Wheel` -&gt; `Car` because `Car` has a reference to a `Wheel` which points back to the `Car`
Note that you don't need `Sync` bounds, only `Send`. `Sync` is actually not that common a bound requirement.
&gt; Could a proper GC solve this? Is reference counting really worth it? Indeed, I think the part that sold me on the idea that really, we should just make `mem::forget` safe is that if we ever want to provide a safe interface that integrates with a GC, then we are going to have to deal with this at that point. A non-conservative GC can solve the "leak forever" case, but it doesn't do anything to solve the "this must be destroyed exactly when all references go out of scope" case, which is exactly the case in which we can have memory unsafety if RAII guards depend on precise drop behavior for memory safety. A GC fundamentally delays collection, and thus destruction of resources. RC is just a kind of GC that happens to deterministically destroy objects that don't contain cycles, and never destroy objects that do, but no GC that I know of guarantees that it destroys objects upon leaving scope. The scoped RC proposal tries to use the lifetime system to fix that problem about RC; and I think that's an interesting approach, and may be worthwhile to provide a type like that for people who need those semantics. But it doesn't mean that we won't ever have to integrate with any other kind of GC, so I don't know if it really solves the problem of having to at some point deal with the problem of "either we allow types to leak, or all code that deals with types that could leak must be marked unsafe". Likewise, the `Leak` trait is also an appealing option; if you ever need to integrate safely with a GC, you just have to add the `Leak` bound to your glue types, so they can't manage those few types of objects that are `!Leak`. But if it's only a few rare types that are `!Leak`, as Niko points out, is that functionality really carrying its weight? And if `!Leak` winds up applying to many types, then that severely restricts what you can store in `Rc`, `Arc` and your GC integration objects. And of course, you could also combine these proposals, such that `Rc` could only contain `Leak` types, but `ScopedRc` could contain `?Leak` types, but that seems like it will just get way too complicated. In the end, the question is what guarantees the core language, the standard library, and any other unsafe libraries are intended to provide. The basic idea behind Rust is to guarantee memory safety and data race freedom, while also providing tools to help mitigate other common problems. There are a lot of problems that can't be prevented without either very large runtime overhead or very large cognitive overhead, like integer overflow (you can add lots of runtime checks, or use dependent types, but the former is impractical for performance and the latter too far in the realm of research and hard to make usable for everyday working programmers), or deadlock freedom (there are ways to statically enforce lock ordering, but will also likely increase complexity, and reduce the set of expressible programs), or lack of ability to panic or diverge (without making the language not Turing complete). So it's important to keep in mind the distinction between guarantees that the language and standard library are expected to provide (memory safety), and those that it encourages and provides support for, but doesn't provide absolute guarantees. Exhaustive matching is a good example; the `match` statement makes it easier to ensure that you cover all possible cases, but you could still ignore it and use and `if/else` tree to check the same and in the process miss many possible cases. I think that, on balance, RAII falls into this category. It's a handy convenience feature, to make it easy to avoid simply forgetting about and leaking a resource, and it does provide guarantees that a protected resource will not have its destructor called *before* it becomes inaccessible, but I don't think that the language needs to guarantee that a destructor is called immediately upon leaving scope. That falls into a similar category as deadlock avoidance, or divergence. It's best to try to provide features that help you avoid it, but we don't need to *guarantee* that you will never be able to leak a type with a destructor outside of unsafe code.
I was thinking of Qt Creator personally.
&gt; That thing is utter trash. This tone invites editor holy wars, which is not something we care about hosting here. Please keep comments constructive.
&gt; `Leak` would have helped `Drain`, too But is it obvious that it was needed? &gt; In any case, you might as well call the former `NoSend` marker `HackToMakeRcThreadSafe` And that's why `NoSend` was removed, it was a hack for something else (negative bounds). That's why we have that issue. And `Copy` had a more nuanced reason to exist, and the separation of `Clone` was heavily discussed. And `Reflect` was not added to allow for TypeArena but to explicitly explain that the results of a function would change based on the type. &gt; The only reason people are singling out `Leak` is because of how close to 1.0 we are, IMO. I agree completely. I agree that more uses for `Leak` might appear and the need might come, but that could be done in a backwards compatible manner if needed. OTOH it might not be the right solution and we'd be stuck with it. The evil of leaks is being greatly exaggerate, and even with `Leak` you could design the old `Rc` and `thread::scoped` which means that you could still cause the error to happen, so it's not like `Leak` is making `unsafe` code trustworthy in any case.
No Rust is not good entrypoint for beginners in low-level (system) programming. Main reasons: Techninal 1. No release version 2. No appropriate for beginner enviroment 3. Lack appropriate documentation Conceptual 1. No stable conception base yet (It is under development) 2. Rust introduces some new conceptions at core level over well -known ones - so a beginner must know and master BEFORE dealing with Rust (pointers, references ... etc) 3. At the point It is not clear what is Rust will be for -it can grow up into just "another DSL" with very steep learning curve (the way of Eiffel)... So for beginners with the ambitions and backgrounds like yours i strictly recommend C. 
&gt; but even Rust and Servo use different styles already Wait, they do? I wasn't aware that there were any differences.
I'm not sure they officially do, but servo seems to have much longer lines (actually uses 100 chars, vs mostly 80). I see more often arguments spread across multiple lines rather than one arg per line. Etc. To be fair there is probably more difference between any two files in the Rust repo than between Rust and Servo on average.
So `do` was for continuation passing style?
Long story short: `fib` is copied (moved, to be precise) and the copy is mutable. More details: - Desugaring of `for` loop: https://doc.rust-lang.org/nightly/std/iter/index.html - trait `IntoIterator` used by `for` loop: https://doc.rust-lang.org/nightly/std/iter/trait.IntoIterator.html - implementation of `IntoIterator` for things implementing `Iterator`: https://doc.rust-lang.org/nightly/src/core/iter.rs.html#1149-1157
That is because it it first consumed by [`IntoIterator`](http://doc.rust-lang.org/std/iter/trait.IntoIterator.html), which has the signature `fn into_iter(self) -&gt; Self::IntoIter;`. Before the loop starts fib cannot be mutated because it is not annotated with `mut`. In/after the loop, `fib` is moved, such that the mutation done by the loop can no longer be observed directly. You cannot access the struct anymore, and thus for all intents and purposes `fib` was never mutated.
I do remember fighting laziness; the idea that `sum` over a list would produce a list of closures (O(N)) AND keep the list alive unless you explicitly opted in to strict evaluation was rather disconcerting.
Mutability is rooted at the owner and it's a property of the variable. let v = vec![1, 2, 3]; // vector we can't change let mut kevin = v; // Give the vector to kevin and we can change it kevin.push(4); The same happens in the loop. Your `fib` is not `mut`, but you pass ownership of `fib` to the for loop, so the new owner can set the mutability as it wants.
From the article, quote: &gt;This is unquestionably a flaw in *something* in the Rust standard library since it should be statically impossible to use-after-free or data-race in safe code, and we've managed to do *both*. How did we manage to do use-after-free? I got the other part, but the data was never freed in the example. We created a reference cycle thereby preventing it to be freed/destructed. But it was definitely not a use-after-free, right? **EDIT**: I got it -- a scenario where thread C was created from thread B (different from main thread), C was given a reference to a stack variable in B, and B exits without waiting for C (by moving the join guard of C into a reference cycle). Now, if C try to dereference the reference it was given; then use-after-free... So, basically, when these 2 things are put together, we'll get a really bad joke: * non-`'static` reference passed to a thread * thread guard moved to a strong reference cycle I really hope the Rust developers don't solve it the hard way, and make things complex (and I trust them in keeping things simple). If it were up to me, I would just rename `thread::scoped` to `thread::youareonyourown_scoped` and move on... Really, that's all needed! And, may be, provide a "strictly safe" alternative named `thread::iwillprotectyou_scoped` which has half the performance/usability but would be really safe even if someone tried to rape it!
I believe a sound tracing GC can be implemented reasonably well as an external library (have some inprogress designs based on spidermonkey's Servo integration minus the craziness -- need to figure out a way to root properly)
I'm pretty sure I'm using nightly, but I'm not sure how to suppress the "weak is unstable" compiler error. 
&gt; I believe a sound tracing GC can be implemented reasonably well as an external library I hope so too, so I'd be very interested in anything you've come up with - do you have anything you can link? But the question was different: assuming you have a `Gc&lt;T&gt;` type or something similar, can you avoid requiring `T: 'static`?
Yeah, I was using nightly. I was using the Hans Jorgenson (sp?) PPA and whatever travis-ci uses for nightly. I think I tried to use the feature in my crate root, but it wasn't having it, nor giving me a useful suggestion. I'll try again later tonight.
Cool. If you upload it to github or something, I can check it out too.
I plan to have a writeup on internals once I clear my backlog of things I want to do. (So, still time.) Note: I haven't really thought any of this through, I'm just working off the SM model: The idea is to use autoderiving to generate trace hooks, and ensure that only structs with trace hooks are used in a Gc. Stack rooting is done by ensuring that no type transitively containing a Gc is used on the stack without rooting (rooting uses the trace hook to root all toplevel Gc&lt;T&gt;s, though there might be a way to do this without traversal at rooting time). This needs a lint, though I'm trying to figure out if there can be a better RAII pattern used here. It's hard to get lints to be perfect. As far as `T: !'static` goes, I haven't really thought this through; but these could be handled by a local GC arena, similar to the thread-local one that handles statics. I don't like this idea though. There might be something better we can do. If you have any ideas, I'd love to hear them.
It is in github, and I'll bring it to #rust IRC if I'm still having issues. I just don't want to out my reddit account. I appreciate it though. 
I was anticipating seeing this thread after noticing it at 9999 this morning.
I know it doesn't mean much but this is my favourite suggestion so far and I hope it's considered. Good luck. Edit: assuming it fixes the problems at least. I don't know enough to say for sure. 
As far as I can think, it should: - a `JoinGuard` could not be stashed directly in a `Rc` because its lifetime would not be `'static` - retaining a reference to the `JoinGuard` in a `Rc` cycle past the `Anchor` would abort, thus avoiding memory unsoundness (at the cost of crashing)
No, IIRC it was just for passing "blocks". The closure passed in wouldn't need to be the continuation of the function.
This seems like it has a very similar issue to the primary one I was concerned about before: requiring different APIs to be exposed for non-`'static` `Rc`s vs. `'static` ones (and possibly splitting the world into four types). Anything that makes it harder for users to support non-`'static` `Rc`s is going to have this issue, I suspect. But otherwise it seems pretty good--the performance impact is there, but it's at least minimal.
What's more, Servo just passed 10,000 commits and the Rust repo is about to break 1,000 contributors. :)
With the old API, each `JoinGuard` and closure could be allocated wherever. If you had a static number of threads, that could just be on the stack. If you had a dynamic number of threads, you had to put them in something like a `Vec` (dynamic allocation). With the new API, you don't have the option of storing things on the stack, because you don't manage the `JoinGuards`. Instead, the API hands you a scope object that has to be prepared to spawn any number of threads, so it basically defaults to the `Vec` solution. With various extensions to the type system (HKT or integer generic parameters), we might be able to parameterize the new `thread::scope` on some kind of container or number of threads, which could get rid of the dynamic allocation.
I really liked the work Adenilson did on this post because it describes the context for many of the feature additions, which the rest of us (myself included!) often forget about because we're so deep in the thick of things.
Of course, that's a CSS trick. In reality there are only single-digit number of subscribers. ;)
I don't really understand what this has to do with Servo. What is the context in which you would make use of this?
I mean, why does `Gc` need a backing arena here? The actual `Rc&lt;T&gt;` object, where `T: 'a`, can't outlive `'a` because of dropck, regardless of whether the `RcBox` it points at is actually freed. Is there something I'm missing about how the collector works that requires it to access dead objects that may have "outlived" their `'a`s, the way a reference cycle does?
Single digits? Lies. There are dozens of us... DOZENS!
Oh hi Karmanaut!
Integrating Servo (and/or a full web browser component) into something like Vim seems more feasible than vice versa. I'f you're building client facing web apps with Rust, there is the advantage of getting immediate feedback. However, I'm not sure if anyone is building client-facing web apps in Rust. 
This looks rather interesting as a starting point!
To be fair, I suggested a very simple fix: just revert the previous PR, which was a purely aesthetic change anyway. A more robust solution could then be worked on in peace. Full disclosure: the low quality of my code is the reason that a "purely aesthetic" change was able to cause this breakage.
Have you seen http://zinc.rs?
&gt; I assume you meant let mut b = a :) Yes I do &gt; (although this example is deceptive since i32 is Copy) True that, forgot about that part (though I tested with a custom struct so the text should be correct anyway)
Recent version of eclipse have had problems especially with speed but overall I like it a lot. Intellij may be even nicer and the community version is open source and has most of the good features. I can't say much about netbeans. Of course in any ide functionality of non core languages tends to vary a lot between language plugins. 
Or from inspecting the HTML. We're all programmers here, right?
I'm also pretty sure eclipse does better autocomple especially if we are comparing vs VS without resharper. I don't think visual studio autocompletes and imports stuff not in current imports, resharper does add this. Also I think even with reshaper it doesn't show inline paragraph documentation for currently selected autocomplete entry which eclipse does.
&gt; this would mean both web dev and web surfing could happen via the same interface which I think could be very useful for some people. You're definitely an Emacser. :)
Hi, I would like to know what you had to struggle with, was it hard to overcome? All in all, do you think it was worthwhile doing this in Rust or would it have been easier in C/C++?
Did you have any difficulty with Rust's current lack of support for `volatile`? pub enum Pin { Pin0 = (1 &lt;&lt; 0), This is really neat, I didn't realize that enums were smart enough to allow anything other than integer literals when providing explicit values.
We have `volatile` intrisics, fwiw (at least `load` and `store`, last I checked. You can write a safe `get`/`set` wrapper on top of them. As for the enums, any constant expression works, but in this case `bitflags` are better suited.
If you'd like to elaborate further on codifying a volatile wrapper: https://github.com/rust-lang/rfcs/issues/1101
I'm happy to see a community leader already following semver on his own crates. All that cargo support means nothing if we don't encourage a culture of responsible breakage! :)
We do have embedding in non-browsers as something we want to support (we kind of already do?). Writing an app that uses Servo inside it like a webview should be easier. Adding vim support to servo itself just sounds strange.
If this is desirable, there should probably just be a new macro called `dignified_acceptance!()`; you may be about to crash, but you can at least crash with a stiff upper lip and a straight back.
Try this: let n: &amp;[i32] = s.borrow(); But if you want an `&amp;[i32]` you can just do this: let n: &amp;[i32] = &amp;s; Or just pass `&amp;s` to anything that takes `&amp;[i32]`. Generally, you don't need to explicitly convert a vector to a slice because coercions will do it for you. :) 
 use std::borrow::Borrow; fn main() { let s: Vec&lt;i32&gt; = vec![1,2,3,4]; let n: &amp;[i32] = s.borrow(); // let n = Borrow::&lt;[i32]&gt;::borrow(&amp;s); // alternative } The problem here is that `Vec&lt;i32&gt;` actually has *multiple* implementations of `Borrow`, each with a different "output" type. Thus, you need to tell the compiler which one you actually want.
&gt; I just don't think panic!() should be the way to send it silently. At least not in debug builds, where you want to grab all information you can get â€“ especially if something breaks. I'd actually be OK with silencing it by default in release builds (but leave it configurable through some option).
Much thanks. Your clarification helped my understanding.
Haha! That I am, young though I may be.
Is this documented somewhere? It sounds like what I'd want. Another question, would it be reasonable to use servo as the GUI/panel engine for a text editor?
For those of you facing the same problem, [beta](http://doc.rust-lang.org/1.0.0-beta.3/std/) still works.
Inevitably relevant XKCD: [xkcd.com/1000](https://xkcd.com/1000)
I would love something more of the style "do your backend in rust, your frontend in html5 within servo"... electron is more "do everything in javascript", AFAIK
I was afraid that lack of volatile would be a problem, but since I do all register access via external C functions, rustc didn't seem to dare to optimize it out. That, or `unsafe` blocks are not optimized, I don't know.
Is bitflags part of core ? I tried building this with them, but I found they were part of rustc internals and I did not really want to use a private API if I could avoid it.
I've explicitly added it to the How To now.
&gt; The biggest advantage of C and C++ for this kind of job in my opinion is that there is already a huge number of libraries, sample code, RTOSes and so on written in those language. That is true. You basically need to re-write parts of `libstd`on top of the desired RTOS. I wonder if CMSIS (aka mbed RTOS) lifts of at some point. Seems to be some reasonable interface for ÂµCs. 
[Done](https://github.com/rust-lang/rust/issues/25053)
&gt; Go and Rust ---
They are on crates.io as well. After all, it's more or less just a macro.
*And he said unto the great congregation 'Go forth, and carry in your claws and on your backs the spores of Rust into the Flooded Lands, that they might take root and spread.* *'And know that you shall be feared and shouted down, but what shall those that oppose you do? Can they catch these spores in their hands? Can they still the air that carries them? No!* *'For they shall multiply and grow strong with deep roots, and the lands that lie barren and cold beneath the harsh salt waters that flooded over them so long ago will bloom anew and a new dawn shall come.'* -- The Book of Rust, 10:52
I don't know what I'm reading. But I like it.
&gt; If we decide to write it in C, I will probably do it again in Rust and write a comparison. Please do! :)
&gt; CMSIS is not really an RTOS I know, but mbed RTOS is afaik the only implementor yetâ€¦? Iâ€™m not even sure how portable CMSIS-RTOS is but from what I saw from flying over it itâ€™s fairly platform agnosticâ€¦
&gt; If this is a stab at the fact that Go and Rust are often compared, despite targeting different use-cases, Yes. &gt; This thesis properly motivates why these languages were chosen for evaluation, while also considering some other languages. Oh sure. There is certainly overlap compared to the other candidates, which look so dead-on-arrival in these domains that they just look like they were included as token "we were thorough and considered many options"-candidates. - Python - not useful in HPC unless all actual work is delegated to other languages. At which point comparing it with another language seems pointless. - Erlang - if Erlang was actually useful for HPC, it would just be by wild coincidence. Like the idea that Prolog would be good for number crunching - I mean, maybe it is. But no one would actually suspect it enough or think it was likely enough to consider it as a candidate for number crunching if they only had time to consider a handful of candidate languages.
/u/MrFloya, do you want feedback on typos/grammar? (Or did you already submit this and don't care anymore, which is what I would do.)
Only a paragraph was spent on it, but if syntax is a major gripe with Erlang, Elixir runs on the same VM with the same semantics. But the raw computing speed deficit in the ErlangVM is enough to want to avoid it in a HPC environment. Though I think that it could be possible for a ErlangVM with FFI into Rust solution to work out well for other environments such as web stuff and game servers.
Even if you don't, the very first entry in the Bibliography, you typo `software` as `sodware`.
It also adds a link to /r/rust in the top bar, so you can quickly get to the sub from anywhere else on Reddit.
Yeah I already submitted it but thanks for the offer!
Is there any place to get a small pbf file to play around with your code? Don't want to grab a six GB file over this wifi...
The one in the repo is about 28 megs but http://download.geofabrik.de/ has a lot of other samples.
Merged thanks!
@mythmon did you make any progress on this? Would love to do pebble programming with rust. 
Great article. I believe iterators to be one of the most important parts of Rust. (They also have that recognition value for developers coming from functional/scripting language.)
What is in a trait is `.into_iter()` in `IntoIterator`, which is implemented for a ton of types since it facilitates the for loop sugar.
Great job. :)
Are you allowed to have random people co wrote your thesis?
I used [the in process style guide](http://aturon.github.io/features/let.html) to guide my choice on the collect invocation. I'm still undecided about it. I agree with you about `usize`, I'll change that!
It's rather logical in Rust, where ownership and move semantics rule. If you've just said `x = y` and moved a value from `y` to `x`, you can't very well return that value too, because that would move it out of `x` (in the general case)!
Another example of this I saw much earlier was a blog post about a string tokenizing API. In C++, `vector&lt;pair&lt;char*, size_t&gt;&gt; tokenize(string&amp; s)` would be very dangerous, since you can't expect pointers into `s` to last as long as they need to, so most designers would fall back on a return value of `vector&lt;string&gt;`. But in Rust, you can express the same pattern safely as `fn tokenize(s: &amp;str) -&gt; Vec&lt;&amp;str&gt;` and the compiler will make sure that the caller doesn't misuse it.
Once we have generic numeric parameters, I'm sure somebody can come up with a C++-template-level abomination for whatever you need. Something like `IntWithRange&lt;0, 15&gt; + IntWithRange&lt;3, 45&gt; -&gt; IntWithRange&lt;3, 60&gt;` to give finer-grained control over the possible values, and occasionally force you to explicitly downcast and check for errors to keep the range from growing too much.
I know C++ the problem would be much worse (possible segfault), but this is an issue on GC languages as well. When I'm designing APIs on ruby, I avoid exposing arrays and hashes on public methods, precisely because I can't know if the caller will end up storing or modifying it (and potentially corrupting my internal state). I end up creating APIs based on internal iterators (which ruby makes very easy), or exposing only immutable [Hamster] (https://github.com/hamstergem/hamster) collections. In Rust that wouldn't be a problem, because I have very strong guarantees on what the caller can and can't do with slices they get from me.
What's more, this sense of security can make one bold enough to do things that would be quite scary in other languages. I'm a rust newbie and I already write compiler plugins ;-).
I've also been working on a kernel in rust. My solution to the statics problem was to wrap my data types in a "LazyStatic" or "LazyMutex" type to handle initialization at use (and avoids dynamic allocations by using Option&lt;T&gt;). The proposed 'const fn' will hopefully reduce the need for this though, allowing that Option to be removed.
&gt; In a language like C++ thereâ€™s only once choice in this situation; that is to clone the vector. In a large C++ codebase if I wished to use a pointer I would need to be sure that the vector isnâ€™t deallocated by the time Iâ€™m done with it, and more importantly, to be sure that no other code pushes to the vector (when a vector overflows its capacity it will be reallocated, invalidating any other pointers to it). Surely, that's not correct? 1. When you have a std::vector or similar, that handle never changes, even when the internal data pointer is reallocated. 2. If you use a std::shared_ptr&lt;&gt; to wrap the vector, you get a reference counted pointer, that will never cause double frees or use-after-frees. There are no issues with pointer invalidation due to reallocation here, either. Just copy it as much as you wish, and it will be automatically freed when zero references to it remain.
&gt; When you have a std::vector or similar, that handle never changes, even when the internal data pointer is reallocated He's referring to handles to the contents of the vector; those might be invalidated after a reallocation. vector&lt;int&gt; v = get_vector(); const int&amp; i = v[0]; foo(&amp;v); // causes `v` to expand and reallocate its contents. cout &lt;&lt; i; // whoops
I'm not (at all) saying C/C++ are great here, in fact I did say this is where I like Rust the most. By "not feeling limited" what I mean is that I rarely if ever need to create references or pointers as in your example, so that particular bug is unlikely to happen for me in any language.
Perhaps you were looking for /r/playrust instead?
I added this in a footnote, but there are a couple of problems: - shared_ptr still has iterator invalidation problems. - even if I'm not using the contents of the vector; this is an API; so the consumer might. A consumer using this API in a callback function shouldn't have to worry that any pointers held would get invalidated. Or something - shared_ptr has a slight runtime overhead, though that's not so important. 
Yes, unfortunately the debugging experience with Rust does not yet come anywhere close to what you get in C# or Java at the moment. In principle, however, there's no reason why debugging things in Rust shouldn't be just as ergonomic as with a good IDE for the above mentioned languages. In practice there is one big open problem though: Debuggers don't know that Rust exists `:)` They just treat it as C or whatever they use as fallback in such a case. You've already linked to my blog post that has some more information on that. That being said, with pretty printers enabled LLDB and GDB can still provide quite usable data inspection and breakpoint facilities. And they both support being driven by an IDE or other frontend through a "machine interface". Eclipse CDT does this with GDB, for example, and RustDT, as already mentioned by llogiq, will do the same *and* will automatically turn on Rust pretty printers. That's already quite nice. You can set breakpoints in your source code and step through it while getting an up-to-date view of variable state. I don't have any experience with XCode but maybe it would be possible to use this as an LLDB frontend for debugging Rust code. Also, from what I've gathered, there are efforts to make LLDB fully support GDB's machine interface protocol (see Microsoft's Visual Studio Code anouncements), so maybe it will soon be possible to use LLDB as a drop-in for GDB in RustDT on Mac OS. In the long run, there's still a lot of work to do, especially regarding Rust support in debuggers and IDE integration. However, since many IDEs are language agnostic and will more or less just forward, what the debugger provides them with, a lot of this should work out-of-the-box once debuggers support Rust natively.
In this situation garbage collection would not protect against iterator invalidation.
It's handed in, so who would care?
This didn't work, unfortunately.
&gt; Also, is it official? Are we declaring war on C at all costs? I meant this in a generic tongue-in-cheek way. C has been getting a lot of flak lately. Also, I disagree with the side-by-side thing. Down the list of posts there's one where someone implemented an OS kernel in rust and apart from memory allocation he had no problems. I'd say Rust can very well take the place of C.
I wonder why they picked a comment from Fiora Aeterna in particular? Loved her work on Dolphin, but that's not exactly linked to Boeing... did she work on something closer to avionics?
Actually, there are a number of segfaults questions on StackOverflow linked to regular expressions precisely because of this issue: the regex is looking into a `std::string const&amp;` so people can pass a temporary there (because of const-ref binding rules) but then when they try to use the iterators inside the string, it's already gone...
This. Idiomatic Rust code is likely to perform better because using slices/references is idiomatic in Rust, while in C or C++ to get an easy-to-use API (idiot-proof?) you need copies or complexity.
Not creating references means you are ok with unnecessary copies.
Unless you create references in safe ways (e.g. on const data), or you send reference-counted copies of the entire thing, instead, yeah.
I would really love to see a version of the ranges calender example using Rust and its Iterators. Here is the original D document: http://wiki.dlang.org/Component_programming_with_ranges And here is the same example using C++ and ranges-v3: https://github.com/ericniebler/range-v3/blob/master/example/calendar.cpp Is anyone up for the challenge? Typo: there is a typo in the article here: &gt; Note how .inpect() only provides its function a &amp;x instead of a &amp;mut or the value itself. This prevents mutation and ensures that your inspection won't disturb the data pipeline. Should be `.inspect()`. &gt; Let's use the two concepts to split up a big slice, group it be evens and odds, then progressively sum them up and make sure that the some of the evens is always less than the sum of the odds. (This is because even starts at 0.) `the some of the evens` should be `the sum of the evens`.
Difference is in debugging time. If checking is on, you get all debug info you need in panic message. Otherwise, you might have a good hour/day/week debugging ahead of you.
Ah, I just remembered another thing I'd like to do: instrument panics automatically so that it would break when they happen. Currently as the default action it just exists.
My [ringbuf](https://github.com/diwic/fdringbuf-rs) might be interesting to you, while targeted for a slightly different use case.
Once we have LLVM-based cross language optimization working, this may not be true anymore :)
Nah, `unsafe` doesn't affect semantics or codegen. It just allows some things that would be errors otherwise.
I'm curious. Is sync_channel faster than regular channel? I know the regular channel is a spsc queue until you clone it. How does that one compare?
Most people who clicked on OP's "typeclasses" link also wanted to click on [this "Functors" link](http://learnyouahaskell.com/functors-applicative-functors-and-monoids) ;)
Unfortunately, no. I may look into it more in a few days, but I don't expect I'll be able to solve it on my own. 
Very nice, the code is very understandable, simple, and clean.
Correct, which of course answer my question. From a design point of view, do you know if there are plans, when HKT lands, to factor out those functions into traits? I guess it would be quite a beastly effort to do so, which then I'm wondering if that was a "shortcut" in the design phase of the language to get things up and running quickly (I reckon not having to worry about HKT simplify things), to then come back and abstract things further if needed? 
Or, if you're using any number that *might* get really big, figure out exactly how big it can get, and size it appropriately. In this case, they could have easily done [this](http://www.wolframalpha.com/input/?i=2^31+*+10+ms) to check that you wouldn't need to have it on for an unreasonable amount of time before it overflowed, as opposed to [this](http://www.wolframalpha.com/input/?i=2^63+*+10+ms).
Fair enough. Thanks for the spot-on answer, Steve!
Any time. :)
What I meant is that this happens, though with less severity, on some GC'd languages too, and thus isn't specific to non-GC'd languages like C++. Note that the post is about optimization - being able to provide a "view" into a collection you own, without having to clone it, avoiding iterator invalidation etc, and retaining the ability to mutate it afterwards. I'm not sure what language you had in mind in your post, but I'm unaware of a Ruby (which is the language I'm most familiar with) library that would allow me to implement something like this without paying the cost of the persistent collection route. You probably don't care that much about performance if you are using Ruby in the first place, so this is probably a moot point ;) I still find it interesting to compare the two languages though.
If I understand correctly (and I might not!), this is how they relate: A regular, non-shared streaming channel is an [unbounded SPSC](https://github.com/rust-lang/rust/blob/master/src/libstd/sync/mpsc/spsc_queue.rs) queue which [uses a linked list of nodes](http://www.1024cores.net/home/lock-free-algorithms/queues/unbounded-spsc-queue). - It maintains an internal list of cached nodes, which means general-case pushing just does a few atomic operations to reuse a node. In the worst-case, it may need to allocate a new node and could stall temporarily during that process. - De-queueing is always wait-free: basically grabs the data, few atomic operations to return the node to the cache A [sync_channel](https://github.com/rust-lang/rust/blob/master/src/libstd/sync/mpsc/sync.rs) is basically a pre-allocated ringbuffer wrapped in a mutex. A queue of "operations" is maintained on the side so that senders can queue up when the buffer is full. I haven't tested it, but I would expect the regular "streaming" channel to outperform `sync_channel`, simply because it never blocks. Once `sync_channel` fills up, the mutex will start blocking the thread, allowing other threads to schedule, etc. It's an unfair test though, since "streaming" is not bounded and can just keep allocating new nodes willy nilly. Also note that `sync_channel` is technically MPSC, since it allows you to clone the Sender and let multiple threads push to the single consumer. **Note:** It was sorta unfair that I compared `sync_channel` against my queue for the same reason. But it was easier to compare two bounded queues than trying to enforce a bound on channel for testing purposes.
Ah, gotcha.
True :) However in that case I would hope the C functions themselves use `volatile` and the LLVM optimizer honors it.
This is super cool, thank you. I've been programming micros in C for years and recently moved to C++ to gain more safety and checks... But the C++ rabbit hole is deep and dark. I'm very interested in Rust for these applications and it's wonderful to see code like yours and zinc to show how Rust is a good fit for micros. Thank you!
I think this is one of those edge cases where the compiler thinks you're trying to coerce it into a trait object (&amp;str impl's From via impl&lt;T&gt; From&lt;T&gt; for T) and there's no pretty way to explicitly select the impl. This works (thanks UFCS!), maybe someone else has another idea: fn test() -&gt; Result&lt;(), Box&lt;std::error::Error&gt;&gt; { Err(Box::from("test")) } 
Another wonderful use of Wolfram Alpha. A ns-resolution 64-bit counter can go up to 292.3 years, or [1.5 x the average time one would have to lie supine before a bird would poop in one's mouth](http://www.wolframalpha.com/input/?i=2%5E63+ns).
[Conrod](https://github.com/PistonDevelopers/conrod/) is a pure Rust GUI toolkit from the Piston game engine project.
I'm also excited for Rust mainly because of its functional ambitions. &gt; so I wanted to ask you on how to approach the language. Coming from a background of garbage collected languages Read the book, but start with [chapter 4, "Effective Rust"](http://doc.rust-lang.org/nightly/book/effective-rust.html). Other resources: http://www.reddit.com/r/rust/comments/31awui/alright_beta_should_be_here_soon_aside_from_the/cpzw7n8 &gt; writing in Atom, compiling in Terminal, getting angry about errors Install https://github.com/AtomLinter/linter-rust and get errors even faster! (But don't get angry, they're there to help.)
I think rust-gnome or conrod are your only options right now. From what I've seen of conrod it looks usable, but if you want the UI to look what you'd normally expect from GUI applications, I don't think they've reached that point yet. If that's alright with you, try conrod, otherwise try Gtk. I've used Gtk in C++ and Rust and it wasn't too bad. The rust-gnome developers are pretty helpful too. Qt bindings are probably far off, you can read about some of the issues [here](http://endl.ch/content/cxx2rust-pains-wrapping-c-rust-example-qt5). qmlrs is another option, but I've never used it. Edit: it looks like the developer of [wxRust](https://github.com/kenz-gelsoft/wxRust) has started updating the project, so that might be ready to use soon.
Ah, I see. Thank you :)
As a fellow rubyist, I was thinking along similar lines when reading this. It's really annoying when a bug turns out to be that something mutated an array/hash when you didn't expect it. And of course just using clone doesn't help, because the nested objects are still shared. But I also agree with /u/f2u that it's not really a GC problem, the problem is rather with the type system.
Great ideas! I will try to implement the exercises from "Functional Programming in Scala" and see how it works out. Seems like I can't get around trial and error :P
&gt;Pick some smallish project / library that I want to work on From my experience this task is more difficult than learning any language :D
Did you try setting `Result&lt;(), Box&lt;Error + Send + Sync&gt;&gt;` as the return type? The compiler is very picky with the bounds.
This looks a bit like Maud (https://github.com/lfairy/maud). Horrorshow being an experiment, am I right to suppose that its approach is somehow different?
Horrorshow [uses plain macros](https://stebalien.github.io/horrorshow-rs/horrorshow/macro.html!.html), while Maud uses a syntax extension.
This is a much better introduction to iterators than [the one in the official book](https://doc.rust-lang.org/book/iterators.html) I would vote to replace the existing one with an adapted version of this article. Here is a [github issue](https://github.com/rust-lang/rust/issues/25084) created just for that.
One difference I see is that it is a GC based language.
For some reason I thought it wasn't handed in.
Can't tell at a glance whether or not it uses a garbage collector, there's no claim against it AFAICT.
The concepts of isolation and isolation boundary seem to be interesting. Though I'm not sure whether they're applicable in the context of Rust.
It's very similar to earlier versions of rust. In terms of actor local GC, language provided scheduling of actors, separated function and async invocation system, mixed structural and nominal types, and an overabundance of language supported reference qualifiers. I think they did a good job at it, certainly much better than I did, but I'd be nervous about the cognitive load of the reference qualifiers (capabilities). See [this page](http://tutorial.ponylang.org/capabilities/combining-capabilities/) for example, or the previous few in the tutorial. We had that sort of cognitive load on variables early on and people basically rejected the language because of it, as well as associated compositionality problems. The many years of design iteration had a lot do to with factoring that space into fewer, more essential and general qualifiers. Slow, tedious, world breaking refactoring work. I hope for pony's sake this doesn't happen to them too -- it looks really nice -- but that's my biggest worry for it.
You're trying to add references together. Is `start` a reference?
From a quick-ish look Pony's capabilities system seems to offer similar guarantees to what Rust's borrow checker does, but in a somewhat different way. I'd have to dig deeper to get a good grasp of what the exact differences are. What I found very interesting is that assignment in Pony returns the old value. I.e. `a = b` is an expression that yields `a`'s old value. It seems like that would've been a good fit for Rust, but that ship has sailed by now.
What did you use to plot the graphs?
The `a = b = a` example took me a moment to work out in my head since I'm so used to the traditional behaviour of returning the new value.
Which is why this is just a bad idea, even if it would make sense in a vacuum.
Seems to work, thanks!
Seems to work for this example, thanks! Unfortunately it doesn't really work via `try!` though as you need a special `from` impl. I e, you can't have: fn func1() -&gt; Result&lt;(), String&gt; { /* ... */ } fn func2() -&gt; Result&lt;(), Box&lt;std::error::Error&gt;&gt; { try!(func1()); } 
&gt; not potentially a equally-named function but with a totally different semantic/signature/aim. For what it's worth, even in Haskell you don't have any actual guarantees that instances of Functor/Applicative/Monad/etc. have the mathematical properties they should. You can write something that has a matching type signature but violates the mathematical properties of these instances and the compiler will happily accept it.
Correct, but I over-generalised in favour of the narrative &amp; to drive the point home ;)
Done, and I've filed a bug for the installers page here: https://github.com/rust-lang/rust/issues/25090 And in the future you can just message the mods directly via the link at the bottom of the sidebar. :)
Aside from being garbage collected, one of the biggest differences from Rust is mentioned on the philosophy page ( https://github.com/CausalityLtd/ponyc/wiki/Philosophy ): &gt; Fully type safe. There is no "trust me, I know what I'm doing" coercion. For the systems domain that Rust is targeting, the existence of an escape hatch like `unsafe` is absolutely necessary (though obviously we should continue discouraging its use where we can). I expect this rule to also complicate a later rule from that page: &gt; The standard library should be implemented in Pony.
HTTPS provides two things: Confidentiality and authenticity. When browsing public content, you usually don't care about confidentiality (even if it is encrypted, from the length of the packets it can be inferred which parts of the website you are visiting). You still care about authenticity, especially if downloading and executing code. 
The "[Is TLS Fast Yet?](https://istlsfastyet.com/)" site should answer that.
HTTPS does no longer provide authenticity. It would provide that if the certification issuers wouldn't have been breached. But they have. Both by government pressure (e.g. in a China and in a NSA case), and also by blantantly wrong procedures where a guy could get a certificate on Microsoft domains.
&gt; When browsing public content, you usually don't care about confidentiality This depends on what is this content and where are you from. Browsing some content may be illegal in some countries. Rust is probably isn't such content but some crates on crates.io or github potentially can be (think about software for encryption, bypassing censorship, breaking DRM schemes, this is what just comes to mind). 
The [paper](http://ponylang.org/papers/fast-cheap.pdf) linked from their front page seems like the best place to look for details. It has a paragraph on Rust in the Related Work section and a big comparison-of-features table with many other languages near the end. Haven't read further yet, but seems interesting - it's not inconceivable that it might have some ideas that Rust could also profit from.
What also helped me alot besides the standard reading was wandering around on github looking at other ppl's code. But reading will only get you so far, theres nothing betting than getting your hands dirty and making mistakes. I use sublimetext without linters and compile in the terminal, might not be ideal when you are used to an IDE but I found it quite pleasant and got used to it.
If it crashes, then don't claim "it doesn't crash" nor "there will never be an uncaught exception". I'm even willing to ignore CPU/Memory faults as a cause for crashes - although they are quite important problems as they can be used as an [attack vector](https://en.wikipedia.org/wiki/Row_hammer). Also, Rust doesn't say it doesn't crash, it says "prevents almost all crashes", which is more accurate.
As is showcased by Java's `ConcurrentModificationException`.
They justify it as to do with field access. Essentially certain fields have move semantics, and can't be null, so if you want to extract the value from them you have to put a new one in at the same time: output = object.field = replacement
OpenGL is a GPU API, and you can't do anything except bind it. But it doesn't do window management. I'd use https://github.com/tomaka/glutin.
Compiling ponyc is amazingly fast. I checked out source from github and compiled in release mode. It took ~34 sec. time make config=release real 0m34.158s user 0m29.358s sys 0m3.128s
`start..` is of type `std::ops::RangeFrom&lt;A&gt;` where `A` is the type of `start`. [`RangeFrom&lt;A&gt;` implements `Iterator`](https://github.com/rust-lang/rust/blob/165a8dec9ce200ede5ad29c8ab7f8e7064c478f3/src/libcore/iter.rs#L2758-L2759) with the following bounds: A: Step + One, for&lt;'a&gt; &amp;'a A: Add&lt;&amp;'a A, Output = A&gt; The `for&lt;'a&gt;` syntax declares a lifetime that is not a parameter of the `impl`, only of this particular bound. There may be a bug in the error message formatting here: `for&lt;'a&gt;` is part of the bound but not of the trait.
Which BTW is why I'm saying this would have been a good fit for Rust. In Rust this requires `mem::replace()`, which has to use unsafe code in its implementation (if I'm not mistaken).
FWIW, Rust doesn't return the new value either. It took me a moment or two to realize what happens if you do `let a = b = a` in Rust (yes, that is not quite the same thing, as it doesn't work without the `let`). I still find returning the old value an interesting idea, though I agree that it might just be too unfamiliar. For Rust that ship has sailed anyway.
Just git clone the rust repo and point it at the src directory in the repo. No building necessary.
i just started learning rust since yesterday... borrowing and lifetimes are bit confusing.. but i may be wrong did not pay much attention while i was reading the official tutorials
Doesn't redirect for me, do you have HTTPSeverywhere or similar enabled?
Nit: "We are returning a reference to a Vec&lt;T&gt;. That is a bit weird; who is going to own that Vec&lt;T&gt;? I said we wouldnâ€™t be allocating anything, and you (usually) donâ€™t get a Vec&lt;T&gt; out of nowhere." Actually, you didn't say we wouldn't be allocating anything! This is the first mention of allocation.
I believe this will break pretty fantastically if data encoded on a little-endian architecture is decoded on a big-endian machine. Cap'n Proto works around this by always [serializing integer types as little endian](https://capnproto.org/encoding.html#primitive-values).
Same goes for 64 vs 32 bit machines.
If you browse the web with unencrypted HTTP then you're actively a hazard to others: https://blog.cloudflare.com/an-introduction-to-javascript-based-ddos/ Not like we can feasibly get rid of it just yet, but it's a worthy goal.
So, one question is whether it will break fantastically, or just panic. It seems like most (don't want to say "all") of the pointer setting is done through first getting a slice, so that if pointers point where they oughtn't, it just crashes rather than violating safety. I'm roughly ok (personally) with data serialized in one architecture not deserializing properly in another. I was about to say "it's your own fault if you serialize `usize` data", but then I realized it was my fault. But, I'm still probably ok with it. It's a very good point though. 
I think it's different, right? I like bincode! :D Rather than giving you an owned `T` back, you get a reference to one (or rather a `&amp;Vec&lt;T&gt;`), which is a horrible mess of fakery. It might have some relation to your `RefBox` though? (just scanning things that seem most similar in the repo).
conrod looks promising, but i think i'll go with Gtk which looks somewhat usable in a way of creating a "traditional" UI.
If you dont even know what OpenGL is, you probably dont want to go creating a GUI library. If you want to have a GUI in an application, you can look to Conrod with Piston though.
I can't say I'm a complete beginner, since I've been following Rust for quite a while now and even made some small contributions to the documentation. This is, however, my first non trivial project. Because I was familiar with lifetimes and the borrow checker, I didn't have much trouble learning how threads worked just by following the module documentation. It was, however, hard to find the best or most idiomatic way to handle errors. Right now, I unwrap many Results, which I doubt is ideal. I heard that try! uses some fancy FromError trait, but I couldn't find out how I could utilize that effectively. I originally chose to look into Rust because I'm hoping to do my masters in distributed systems, and I also have a interest in PL. The zero cost abstractions that Rust provides make me really inexplicably happy while coding. I'm looking forwards to learning the rest of Rust and the many considerations that led to its design.
Hmm, I'm afraid I don't see the warning, but I could link to a different copy?
Ah, it was HTTPS everywhere. Good catch! Now I'll go complain at them instead :)
wow.. great news. I am interested. how to register?
I've actually just started working on a Pastry implementation to learn Rust! Great minds must think alike ;)
I just put the stuff up on github at https://github.com/frankmcsherry/abomonation. There are even some doc comments, though I'm not yet sure how to surface them there. I'm sure I'll learn. :)
Lisp has much more rich "syntax extension" capabilities (you mentioned that you thought Rust was the only one). You should check it out.
With enough horrific abuse of templates, we can have *anything*! Actually, we can do units now, it's just that all the checks would be runtime.
Is there anything in the language to preclude an implementation like F# or Ada?
I don't think you can handle arbitrary combinations of units without variadic and numeric generics. You could handle addition by having `impl Add&lt;Unit&lt;U&gt;&gt; for Unit&lt;U&gt; { type Output=Unit&lt;U&gt; }`, but I don't think there's a way to do `impl Mul&lt;Unit&lt;U1&gt;&gt; for Unit&lt;U2&gt; { type Output=Unit&lt;U1*U2&gt; }`.
Thanks! I'll be looking out for your lints post, I've been wanting to learn for a while but I'm running into the same issue I had with syntax extensions: lack of documentation.
Huh, I've seen this being used for similar things but I've missed some nuances apparently. Could've guessed that that RefCell in the [official docs](https://doc.rust-lang.org/std/mem/fn.drop.html) isn't there for nothing.
See edit, I don't think it is, but I guess I'm not sure exactly what the `&lt;T as One&gt;::one()` is actually returning.
&gt; Try changing the code to build a Vec&lt;(u64, u64)&gt; into a HashMap. I am quite stumped on how to do this. [Here's my code](http://is.gd/1TTL8B), annotated with comments and my approaches so far. It feels like I am lacking some fundamental understanding.
I guess I haven't completely wrapped my head around this. I tried adding `for&lt;'a&gt; &amp;'a T: Add&lt;&amp;'a T, Output = T&gt;` as a bound, but that didn't seem to work. Is there some documentation on this somewhere? It's hard to google for :P
 &gt; The &amp;[u8] data is, in fact, exclusively held. We go and transmute it to &amp;mut [u8] which is very wrong unless we are sure that we have the only reference. It's actually undefined behavior, even if you own it. rustc will add the read-only and no alias attributes from llvm, and mutating data with those attributes is UB.
Ones I know of so far are glium https://github.com/tomaka/glium gfx-rs https://github.com/gfx-rs/gfx-rs 
I think glium is your best bet right now. Check out this example: https://github.com/tomaka/glium/blob/master/examples/deferred.rs. It seems incredibly easy to write safe OpenGL code that's simple to reason about.
If you're just looking for bare-bones OpenGL, there's [gl-rs](https://github.com/bjz/gl-rs), which is exactly the same as normal OpenGL. I'd recommend glium, though - it's a lot safer and easier to use.
It would be great if there were a place to read about potential UB that `unsafe` lets you introduce. It is oft stated (e.g. on HN) that `unsafe` doesn't remove *all* guarantees, it just lets you tell borrowck something it couldn't prove. This was exactly a case where I thought the latter, but (and I'm glad) you are telling me it is the former. I think I can probably work around this particular transmute, because as written the data are initially `&amp;mut` (just really tedious to work with in a loop). However, as it stands I have zero confidence that the rest of the code has any particular properties as long as any `unsafe` exists. This is probably a healthy position, but it isn't particularly workable for a "systems programming language". I went through the llvm docs on `readonly` and `noalias`. It almost seems like things may be fine with `noalias` (the programmer is tasked with ensuring that the same memory is not accessed through different pointers, and I do that). In reading about `readonly` it seems like Rust should just prevent all transmutes from immutable to mutable, because LLVM is technically at liberty to optimize away any writes done through such a reference?
If I'm getting it, the key trick here is that the deserializer never hands over ownership of the deserialized value: it only lets you borrow it immutably from the byte buffer. Since it's an immutable borrow, you can't extend `Vec`s, or drop `String`s, or `swap` or `replace` sub-objects out, or really do anything that would trip over the fact that nothing in the deserialized value actually owns anything at all. The borrow checker interprets the returned reference as a borrow of something out of the serialized byte slice (it's not smart enough to see that's not possible), so it ensures that the serialized byte slice outlives the deserialized values. That is really twisted. I have mixed feelings, but they do include admiration. Obviously, anything that supports interior mutability could never be Abomonable. If I serialize a `Vec` of `String`s, and the `String`s' buffers are arbitrary lengths, doesn't that mean that the next `String` header could be located at a bad alignment? This would be a silent slowdown on x86 and x86_64; it seems that ARM handles this nowadays, too, if you don't generate the wrong type of load instruction. If this is a problem, `entomb` may need to do architecture-specific padding, or go through an intermediate function that takes care of such padding. In addition to byte order and word size, you're sensitive to how Rust chooses to lay out structs and enums. From what the language design FAQ says, I assume this could change from one compiler version to the next. (You never explained why the name is misspelled!) 
Exactly what I wanted - thanks!
There's three steps listed in the linked PR, it'd be nice to get it down to one. And there's the standard cross-compilation story: being able to get support for arbitrary other platforms without having to configure/compile Rust manually.
I think that the easiest solution is to treat the particles as immutable during the force calculation. This requires you to store the forces/accelerations in a separate object. for step in (0..nsteps) { let accelerations = particles.get_accelerations(); particles.perform_time_step(accelerations); } If you are doing computational physics, you may even consider storing velocities and neighborships in separate structures, and do something like the following: for step in (0..nsteps) { let accelerations = system.get_accelerations(positions, neighborships ); velocities += accelerations * step_length; positions += velocities * step_length; // Check if neighborships needs updating } This will make it easy to toy around with different integrators and algorithms for stuff like energy minimization (But I am not sure if the latter approach is also useful for stuff like game programing)
I would add that using &amp;str makes API compatible with many other implementations of strings.
The borrow checker is entirely based on lexical scope, calling drop won't change that. At least for now.
I recently added a `ptr_arg` lint to [rust-clippy](https://github.com/Manishearth/rust-clippy) that will warn on `&amp;Vec` and `&amp;String` in fn argument definitions. Perhaps I should extend it to also match `String`?
Good job! A discussion about what to use (String versus &amp;str) in structs is really not that easy. The "ownerhip" concept is the key. I have some suggestions and nitpicking if you're interested: * "ownership will return to the original owner" sounds like an ownership transfer already happened. But you're talking about borrowing. I'd try to rephrase that to make the distinction between ownership transfer and borrowing clearer. * "Using String for message means the program must copy the value." â€” not necessarily. A move is still an option especially since you don't need `msg` anymore in `main` after invoking `print_me`. But generally, yes, this kind of interface tends to imply unnecessary cloning. * "a String is just a vector of 8-byte chars." â€” I hope not. :) You probably meant to say "8-bit chars". Anyhow, I would avoid the term "char" here since a "char" is 32 bits wide in Rust. You might confuse beginners into believing that a char is only 8 bits wide in Rust. * "In order for us to declare the lifetime, we need to specify the lifetime right after the impl like" â€” I would rephrase that to "In order for us to *use* the lifetime, we need to *declare* the lifetime right after the impl". But I guess it's more of a matter of taste regarding terminology. 
`&amp;r.next` is an `Option`, so it is either `Some(box SlnNode)` or `None`. If you call `.unwrap` on it, the code works. (In production code you should deal with the `None` case explicitly.)
Ah well,.,., https://github.com/CausalityLtd/ponyc/issues/159
With huon's help I (huon, really) fixed up the `&amp;[u8]` -&gt; `&amp;mut [u8]` need (all it needed was another temp variable). So, that source of UB out the window (and as a plus, the `Result` now returns something meaningful, in the form of the remaining `&amp;mut [u8]`).
The optimal data stucture probably depends on whether or not the forces are long ranged, and how often a particle in the system gains a new neighbor. Molecular dynamics simulations often use cell lists or Verlet lists, but they may not be the best option for you. * http://en.wikipedia.org/wiki/Cell_lists (Space is partitioned into regions with fixed size.) * http://en.wikipedia.org/wiki/Verlet_list (Maintain a list of neighbors for each particle. )
It can be done better by using `map`: let b = a.map(|a| a.key); This will be safe in development and production as it won't panic.
Yes. Just replace Pony's 'behaviour' with Erlang's 'process', and you have the same concurrency paradigm.
Their Makefile is also pretty clever. Single only, with lots of gnuisms.
Sounds good. But I still can't print b...
Recently, we generalized all the `From*` traits into the `From` trait. Here's the source of `try!`: http://doc.rust-lang.org/nightly/std/macro.try!.html Basically, on an error, it calls [From.from()](http://doc.rust-lang.org/nightly/std/convert/trait.From.html#tymethod.from) on it. 
Cool blog post! Just one note, sorry for being meta/off-topic: domains with the word "bro" in them might seem benign (and self-ironic?), but I don't think they help with the gender/diversity-related problems that we are currently facing in the tech industry. It might alienate some people, even if the intent is to poke fun at "bro" culture. I'm not asking anyone to change domains, of course. Just something to keep in mind. :)
Hm, I'm not sure about *many*: `&amp;str` requires the string is contiguous in memory. The "interesting" string types (ropes etc.) unfortunately don't satisfy this.
We can say that `String` and `Vec` represent allocation policies and `&amp;[T]` and `&amp;str` represent contiguous data regardless of origin.
To a limited extent: since `&amp;str` is just a pointer to a flat buffer of utf8 data and a length it can be 0-copy created from any utf8 or ascii source, but it still won't support stuff like [ropes](https://en.wikipedia.org/wiki/Rope_\(data_structure\)).
I've finally able to get a working implementation using lifetimes, which I tend to avoid most of the time due to a lack of simplicity in explanation of that part. Thank you for a simple example of the lifetimes, it was really effective.
How long does it take for fib.rs to calculate fibonacci of 50? Other difference I found is GNU vs Clang http://www.reddit.com/r/cpp/comments/34uysi/gnu_vs_clang_c_compiler_performance/ 
Rust: rustc -opt-level=3 fib.rs ./fib 50 LANGUAGE Rust: 12586269025 real 1m27.901s user 1m27.987s sys 0m0.008s Unfortunately my Rust build is a month or so old. It's the last rust version used to build Servo as of a month ago. I can try with a newer build tomorrow.
There is nothing to optimize for. If it's OK to *copy* (as in "shallow copying of raw bits") than a move won't give you additional performance benefits because moving is *also* just a shallow copy of raw bits. The only difference is that a copy allows you to keep using the original while a move makes the original invalid and unusable. And if you're talking about *cloning* (as in "potentially more complicated stuff happening than just shallow copying of raw bits"), Rust does not clone things implicitly. You have to be explicit about it. Since "implicit cloning" never happens, there is no need to optimize "implicit cloning". :)
Sure, sorry. It looks like it is working, I think I just tried using a `+` instead of a `,` before the `for&lt;'a&gt; ...` bound. This is a working bound example: impl&lt;T&gt; IsPrime for T where T: Integer + Step + One + Copy, for&lt;'a&gt; &amp;'a T: Add&lt;&amp;'a T, Output = T&gt; { Thanks, by the way for the help!
Sweet, someone referenced the example I wrote!
It was a pun off the "bro do you even lift" joke that was going on a while ago. I don't think its a problem if you get the reference.
In terms of related work, michaelwu has made a bunch of improvements to bindgen for Servo that we're using for the very C++-centric master SpiderMonkey. In particular, we generate Rust methods that call the mangled non-extern "C" functions. See the branch at https://github.com/michaelwu/rust-bindgen/tree/sm-hacks
Out of curiosity, what's the use case for this encoder/decoder outside of a library like hyper?
Minor correction: gfx does NO hashmap lookups or allocations at run time. We strike for the minimal overhead given the command-buffer based programming model, which is compatible with next-gen APIs.
Yea, I've been waiting for 1.0 to drop, but I plan on digging into gfx-rs pretty seriously in a week or so. I can't wait!
FWIW, [yaglw](https://github.com/bfops/yaglw) still exists. I think as time tends to infinity, it would be similar to [oglplus](https://github.com/matus-chochlik/oglplus) - nothing revolutionary, just cleaned up OpenGL. Edits: Oh whoops, kvarkus already mentioned it in a child thread. Also, I just pushed. It should build with the latest nightly, but it's not exactly a complete API by any standards. gl-rs will be the most like "run of the mill" OpenGL, since it really is just a Rust interface to the same functions. For performance, though, one of the goals of yaglw is to lose no performance when compared to hand-written and hand-optimized OpenGL calls (more accurately: yaglw aims not to make any abstractions that prevent those hand optimizations).
There was a [set of proposals](https://github.com/rust-lang/rfcs/pull/250) that I hope is not forgotten. It has more rough edges than I'd like, but it did feel like we were designing something new, something that can be extended beyond the artificial limits of structural inheritance. Since then I've been thinking about it, from time to time, and I believe it might be possible to expose enough types and traits to allow libraries to work with fields, via indexing operations. One downside is that borrowing `foo[SomeFieldOfFoo]` would borrow `foo` as a whole, unlike direct field access. Although, if the operations were built-in, then I could see `Field: Disjunct&lt;OtherField&gt;` allowing multiple field borrows. That and maybe `Self: StartsWith&lt;Prefix&gt;` could alleviate the need for some of the proposed machinery around associated fields. At the same time, it reminds me of /u/glaebhoerl's coercion(?) proposal, so it may be regarded yet again as intentional complexity. Whatever solution we end up in the end, *please* don't add structural inheritance to Rust.
no clue! but `to_be()` and `from_be()` slow it down similarly. I suspect that something in the toolchain is similarly unsure about which endianness my macbook is. :)
And if we wanted a struct that stored strings that are *either* owned or borrowed, you could use a `Cow&lt;'a, str&gt;`, right?
&gt; Iâ€™m well aware Iâ€™m picking on C++ a bit unfairly. [...] But Iâ€™m really focused here on contrasting the kind of â€œcore abstractionsâ€ that the language offers for handling variants with data. There are _a lot_ of C++ variant implementations. All of the popular C++ ones, e.g., Boost.Variant, Eggs.Variant, **std::**experimental::variant, ..., allow one to "match" on the active variant type: variant&lt;int, error_a, error_b&gt; v{error_b{}}; // size equals to largest type +/- a field identifying active type // does the following look familiar? v.match( // sometimes this is called match, apply_visitor, ... but they all work the same [](int i) { do_something(i); }, // handle int [](error_a ea) { do_something_else(ea); }, // handle error_a [](auto) { do_nothing(); } // handle everything else -&gt; compilation error on non-exhaustive match ); auto ea = v.get&lt;1&gt;(); // gets error_a by location auto ea2 = v.get&lt;error_a&gt;(); // gets error_a by type Some of them (Eggs.Variant, `std::experimental::variant`, ...) are even constexpr! And all of this as a library (which is both a problem and a feature).
&gt; Perhaps I should extend it to also match String? What if the callee wants a `String` to have ownership on? Using `String` means that the caller gets to control the allocation. (Although, I might argue that the callee should take `&lt;S: Into&lt;String&gt;&gt;` instead of `String`.)
This only covers some cases, but if you can implement `Deref` or `DerefMut` then that might help. EDIT: Whoops, /u/wrongerontheinternet beat me to it. :P
BTW, is there a way to keep &amp;str in Person struct in this case http://is.gd/UjUNK5 ? 
&gt; Rust methods that call the mangled non-extern "C" functions How does this work for platforms where C and C++ use a different ABI?
&gt;What if the callee wants a `String` to have ownership on? Using `String` means that the caller gets to control the allocation. You're right, the situation isn't remotely as clear-cut as with &amp;String. Perhaps I could check if the callee does anything with (or to) the String that requires ownership? &gt;(Although, I might argue that the callee should take `&lt;S: Into&lt;String&gt;&gt;` instead of `String`.) Cool, I learn new things every day ;-) But that hardly counts as a mistake. Perhaps clippy could have an `opinionated_style` lint group... 
Yeah, that would be a very useful feature. I am hoping there's some way to generalize it further, since by itself it feels kind of hard to justify to me (but maybe I only feel that way because it isn't in C :P).
&gt; Whatever solution we end up in the end, *please* don't add structural inheritance to Rust. *Please* don't dismiss entire approaches out of hand. If inheritance solves problems, we should consider adding it. It is not practical to dismiss the entire OO paradigm on philosophical grounds if there are real features that are standing in the way of people getting their jobs done that can only be added by adopting object-oriented concepts.
In a nutshell one needs to define data types independently of the layout, and control the layout at the point of use (be it within structs, functions, through wrappers like Vec...). When accessing SoA arrays, the compiler needs do the smart thing reliably. I'm not saying is this simple, but this showcases a lot of problems with such a feature already. struct E { b: B[] as AoS&lt;_&gt;, c: Vec&lt;C&gt; as SoA&lt;_&gt; } struct D { b: B[] as SoA&lt;_&gt;, c: Vec&lt;C&gt; as AoS&lt;_&gt; } struct A { a: i32, b: f64 } let t = A[100] as AoS&lt;_&gt;; let t2 = A[100] as SoA&lt;_&gt;; for i in t2 { i.b = 3.; // creating i here shouldn't load a since is not used and t2 is SoA } If one figures out how to control this externally for Vec, maybe one might figure out how to do it for lists, and hash tables, and from there we can start thinking about generalization. But I guess one has to start somewhere, and arrays/slices and Vec is where it starts.
I was a bit discouraged by a certain use case not being obvious or even possible without a huge chore. I'm talking about a strongly typed node hierarchy. You know, the XML dialect kind. The problem is that multiple inheritance is perfectly suited for it: nodes usually belong to certain classes and have either no children or children of certain classes. Classes can imply properties/fields, and extend each other by adding fields. There are many different nodes that each have different sets of fields and possible children. I can't find a simple way to represent this with a nice API via composition.
I don't understand your question. Can you clarify?
None of the requirements floated in any of the previous proposals were arbitrary. They all came from concrete pain points we were hitting.
Yeah. Also `replace` isn't something you need all the time. I probably use it once per several hundred lines, at most. It doesn't deserve a special operator, let alone a confusing overload for one of the most pervasive operators. (Maybe it's needed more often in Pony, though.)
There are lots of pain points in Rust, but to my mind there are different levels of "pain point." There are pain points which require liberal use of unsafe code, pain points which make it very hard to write robust high-performance abstractions, pain points that lead to excessive compile time, etc. To me, "overridable methods for each step in the inheritance hierarchy" stand out from the rest of the list of "efficient inheritance" requirements in not obviously fitting into any of those categories; maybe lack of them makes some (I suspect rare!) types of code more verbose, but Rust has macros for this and doesn't need to be perfect for *every* use case; at the very least, it would be very far down my list of things that Rust needs syntactic sugar for. For example, I suspect that sugar for native bitsets would be at least as widely used as arbitrarily overridable methods, and I highly doubt that would make it past an RFC. My point isn't that structural inheritance should be rejected outright. Rather, it's that each point in the "efficient inheritance" RFC should be weighed on its own merits; making them a package deal might (I suspect does) leave structural inheritance as the only viable choice, but I think it's wrong to conclude that Rust therefore needs structural inheritance.
Good job,explain two differences,and explain the lifetime.
Yep, `Cow` is what you want.
Oh, so maybe I should implement something like `KademliaError`, then implement `From&lt;Error&gt;` for my new error type? Then I can return a `Result` with that as the `Err` from my functions, and call `try!` on the operations that return their own results? Is there a short guide or tutorial on this, or does that capture the idea
Interesting proposal, but it looks quite complex. I wonder how far we can come with just some sugar for delegation? Here's a brainstorming idea (and probably someone else has brainstormed the same thing, I don't know), which just adds a `#[delegate(Trait)]` to a struct field, which means "implement this Trait, and all method implementations will just call the struct field's method implementations. In case the struct field does not implement `Trait`, this will be a compiler error. To make it possible to override something, the `#[delegate(Trait)]` could be extended with some syntax for excluding (or including) the methods you want to override in the subclass. I'm not totally sure whether to monomorphize or to virtually dispatch in case a parent method needs to call an overridden method. struct Plant { height: u32 } trait Growable { fn grow(&amp;mut self); fn hit_ceiling(&amp;mut self); } impl Growable for Plant { fn grow(&amp;mut self) { self.height += 10; if (self.height &gt; 240) { self.hit_ceiling() } } fn hit_ceiling(&amp;mut self) { unimplemented!() } } struct Tree { #[delegate(Growable)] plant: Plant, } struct Bush { #[delegate(Growable(exclude=hit_ceiling))] plant: Plant, } impl Growable for Bush { fn hit_ceiling(&amp;mut self) { println!("Ouch!") } }
OK, now I'm confused. What's the motivation for using `&amp;'a str` for `Person.name`? To avoid the implicit `memcpy` and `free`? Who owns the `&amp;'a str`? Or is that perhaps just a bad example, since I'd expect the `Person` struct to, indeed, own the string. At the end of the post, it implies that I'd want `&amp;str` in cases where someone else's struct is likely to own the `String`.
Exactly. &gt; short guide or tutorial Not yet. The generalization to `From` landed _right_ before beta, and so has only existed for a fairly short time. It'll get added to http://doc.rust-lang.org/book/error-handling.html at some point. You might want to check out how `io::Result` is made: https://github.com/rust-lang/rust/blob/master/src/libstd/io/error.rs 
The actual requirements aren't 'inheritance', but something that does all this: http://www.reddit.com/r/rust/comments/2j78oh/i_heard_that_rust_will_get_inheritance_soon_but/cl9261m
If I understand correctly, pony does not have a selective `receive` expression. I can imagine that some things could become very awkward that way (but I may be wrong).
&gt; overridable methods for each step in the inheritance hierarchy So maybe it's my failure of imagination, but it doesn't seem that bad to me. Does it make it any better if you have unoverridable methods by default but, like `mut`, you can opt-in to having overridable methods?
If you want to avoid the extra allocation/space in C++, it's not that hard. Ignoring the zillions of libraries that do this, the example translates to: struct Error { enum ErrorCode { FileNotFound, UnexpectedChar } errorCode; union { struct { const char expected; const char found; } unexpectedChar; } errorData; }; Or if you don't like the extra "`.errorData`" in client code, you can even do: union Error { enum ErrorCode { FileNotFound, UnexpectedChar }; struct { ErrorCode errorCode; } code; struct { ErrorCode errorCode; const char expected; const char found; } unexpectedChar; struct { ErrorCode errorCode; } fileNotFound; }; (C and C++ allow you to grab values out of the common initial subsequence, at least for POD types.) It's not quite *as* nice or safe to use in client code as Rust's pattern matching, but it's totally possible to have something equally efficient in C++ with a minimum of fuss.
It's not that overridable methods are so awful in themselves (well, aside from the usual Liskov substitution issues). It's that they're just one of many, many ways of sharing code--and a fairly limited one at that--and aren't obviously required for Servo to meet its performance goals. Insisting on their being critical to Servo to the same extent as, say, cheap upcasting--and like I said, while I may be missing something, I don't understand why they would be--essentially locks you into some form of inheritance (the phrase "overridable methods" doesn't even make sense in any other context) and prevents people from considering other options that otherwise satisfy the team's technical requirements. At the very least, if we removed that requirement and virtual structs still turned out to be the best solution available, I'd feel a lot more confident that it was the right one, not just the only one.
rust is used in servo to build the browser as such. Dart is just little more than a language for making web applications and compile them to javascript for maximal portability.
I think that's [not happening anymore](http://news.dartlang.org/2015/03/dart-for-entire-web.html). It always seemed entirely pointless to me.
Is it expected that cloning a dynamic atom is considerably slower than cloning an `Rc`? From my understanding the performance should be about the same. Is this something I should open an issue about?
If you add `Deref` and `DerefMut` impls for all of those structures, which return the `super` field, you'll get direct access to all the fields without a bunch of accessors (and this can be automated with a macro or custom deriving plugin).
I don't think Rust should be opinionated about paradigms so much as feature orthogonality, since the lack of the latter can result in problems for scalability, maintainability, and interoperability. A lot of what traditional OOP inheritance provides overlaps with features already in the language, particularly around traits with both objects and generics. It's not that Rust shouldn't support OOP code, it's more that the traditional method of supporting it is likely to not be orthogonal to existing features, and so an alternate solution is likely to be needed. However, given Rust's development history, I feel that I can be confident that any inheritance-like feature that is ultimately added to Rust will be reasonably orthogonal.
Awesome, I was assuming that copies were equivalent to clones. Thanks a lot.
I phrased my question badly. I see this idiom sometimes: struct Foo&lt;'a&gt; { bar: &amp;'a str } let my_foo = Foo { bar: "baz" }; To me, this seems wrong: here's a case where nobody else owns that string, so `String` seems to be a better fit. And yet, this is the idiom that's promoted in the post. So either I don't understand some motivation to avoid `String`, or that idiom is wrong.
&gt; Allocations are very explicit. Though note that we still require people to read the docs to understand which stdlib types will allocate as part of their normal operation, such as with `Rc`.
There is a crucial difference between enums as they are right now/discriminated unions/variants (sometimes 'initial encodings') and subtype polymorphism (sometimes 'final encodings'): they are at opposite ends of the expression problem. For the former, you can add clients (e.g. functions that `match` on an enum) incrementally painlessly, but you must rewrite and/or recompile all clients if you change e.g. the number of variants. For the latter, you can add subclasses/subtypes incrementally painlessly, but you must rewrite and/or recompile every subclass if you change e.g. the number of virtual methods in a base. Iâ€™m really not happy that this trade-off is never brought up in discussions. E.g. it happened in the error vs. exception debate: in C++, you can add entire classes of errors and throw them, yet you donâ€™t have to rewrite or even recompile parts of the program that the exceptions will fly through. Whereas all clients that use `Result&lt;T, E&gt;` (for a concrete `E`) will see changes to `E` and need to at least be recompiled. Contrast that with things like `Result&lt;T, Box&lt;Error + Send&gt;&gt;` and manual downcasting. To me that screams this aspect must be present in our discussions. All in all Iâ€™d rather have the Rust `enum` remain more or less as it is, so itâ€™s clear which end of the spectrum it occupies. I find it convenient to tell at a glance what sort of data is being defined. E.g. in OCaml you cannot mistake a closed variant for an open (aka polymorphic) variant or for a subclass.
I tried with the latest Rust version and there was no noticeable difference in the time from the older Rust version.
Nope. The target may not exist; it's legal to create a dangling symlink, and then put something there afterwards.
I saw a git hack a couple years ago that would change one of the time fields on the commit until the 6 digit shorthash resulted in the next higher number so the commits were 000001, 000002, etc. I thought it was pretty clever and promptly forgot about it until this post.
Oh, I had no idea you could do that in python. I don't think anything like that will be added, since syntax extensions are powerful enough to express that (as my extension does) and more.
&gt; If OO solves real problems, we should also include those tools. C++ includes a lot of things that solve real problems but its extremal feature set is not considered a good thing. What you leave out of the language is as important as what you put in.
Interesting. I didn't read too far into the docs (I'm preoccupied with job, kids, wife and learning Rust...), so I didn't catch that.
Cool, I can see why it was made that way then. Thanks!
I'd love for these to be more newbie friendly. Maybe a short explanation for each change note or something. I'd love to know what things like "Implement associated constants", "Add intrinsics for unchecked division and modulo", etc meant.
Sometimes it would be useful. It happens that the borrow check complains about having borrowed a value even though that brrow is no longer used in that scope. Adding a new block helps in trivial cases, but not all. Ideally, the checker would figure this out on its own though.
Oh it's undeniably useful, I'm just explaining the current state of things.
I created a syntax extension that allows for the usage of decorators. https://github.com/Manishearth/rust-adorn Not yet complete, but worth a look. (Also the code sucks; I challenged myself to write it in 10 minutes and this is what came out) cc /u/gsingh93
Count me in :) 
Note: in Niko's example, there are *multiple* expected characters, and thus a `std::vector&lt;char&gt; expected`, which means you must now be careful about encapsulation to make sure that your properly destroy the `vector` when it's instantiated. At this point, reach to `boost::variant` (or similar) is probably less troubles.
Plus, even with overridable methods, there's the question of whether the child's method should have control over the parent's or the parent's method over the child. In C++ (and most any other language), the child controls the parent: struct Base { virtual void doit() { std::cout &lt;&lt; "This is a base implementation\n"; } }; struct Derived: Base { virtual void doit() override { /* should I call Base::doit() here ?*/ } }; This allows to completely replace the `Base` behavior, but at the same time makes it impossible for `Base` to ensure any kind of invariant. There is even a full-blown design pattern to re-assert the parent's authority: *Decorator*. On the other hand, there is another possibility, having the parent control when the child is called: class Base { void doit() overridable { print "Base"; child.doit(); } } class Derived: base { void doit() override { print "Derived"; } } It has another set of advantages/disadvantages of course.
Can somebody dumb down the thread::scoped example with Leak? Im having trouble understanding what is exactly the problem with how things actually work right now :/
I wrote this a few days back, does it help? http://www.reddit.com/r/programming/comments/3406hb/prepooping_your_pants_with_rust/cqq7ham
Enjoyed!! Rust should have used better syntax than &lt;'a&gt;. Can't compile generate lifetime for implementation based on declaration? e.g for below struct, compile knows that variable name has lifetime associated with it. struct Person&lt;'a&gt; { name: &amp;'a str, } For implementation, why can't I use impl Person { } vs impl&lt;'a&gt; Person&lt;'a&gt; ? 
Whenever I try to use `?Sized` in a trait bound I get a syntax error on the `? `, but I see it used in the exact same context in the stdlib. Can anyone tell me why that is?
`?Sized` can, under current rules, be used as a bound in generic definitions, but not in where clauses.
I tried that for a similar problem, and I had issues with pattern matching and mutability. In the end I had to call `deref_mut` manually.
I'm probably stupid, but could UFCS syntax help with self? This is really cool, I was thinking about making a library like Flask, and this may be a good way. Is there a way that we can extend the decorator to accept arbitrary constants like `&amp;'static str`s?
I used to do that but it takes a lot more effort for me to read, understand, and summarize things. I'll try to do more in the future. If anybody wants to write part or all of twir, let me know.
Most of the changes aren't that newbie relevant maybe.. I think a forum such as this one is maybe the best place to have it broken down though, just ask here! Associated constants landed, but there is a lot to fix before it is a usable feature. It allows traits to have constants that each implementor should define. For example something like this to give the numerical types a ZERO constant: trait Zero { const ZERO: Self; } impl Zero for i32 { const ZERO: i32 = 0; } fn main() { let x = i32::ZERO; // x is 0. } I'm a bit surprised that the example actually worked on first try! [(playpen link)](http://is.gd/7OtwMk)
&gt; I'm probably stupid, but could UFCS syntax help with self? Nah, the issue is that I have no way of referring to the `Self` type in a function declaration within an existing function. My code takes #[adorn(bar)] fn foo(arg: u8) { ... } and turns it into fn foo(_arg: u8) { fn _foo(arg: u8) { ... } bar(_foo, _arg) } This is fine when all the types are specified because I can just copy the fn declaration. But when adorned on an impl item, I don't have a way of fetching the type of `self`. I can tell if it's `self`/`&amp;mut self`/`&amp;self` but not the actual type specification (`ast::Ty`). For this I need to go one AST node up, which I don't think I can do until `ast_map::Map` is constructed, and that won't happen for a while. There are workarounds to this (adding an attribute to the impl itself and then stepping down), but they aren't too great. So using closures is the best option I can come up with. &gt; This is really cool, I was thinking about making a library like Flask, and this may be a good way. Is there a way that we can extend the decorator to accept arbitrary constants like `&amp;'static strs`? _scrunches face_ Attributes have [a rather rigid specification](http://doc.rust-lang.org/nightly/syntax/ast/enum.MetaItem_.html). They can be of the type `foo`, `a="foo"`, and `foo(comma separated list of any of these three)`, eg `foo(bar, baz="quux", foo2(bar))`. So I _could_ add param support. Probably will, too. But it will look like `#[adorn(bar(arg="hello", arg="world"))]` or something; and be limited to literal strings^1. It would be awesome if we had kwarg (or anonymous struct) support -- this would work really smoothly then. Varargs can still be achieved by using a slice though. Arbitrary tt support in metaitems is something that people have wanted for a while, but we haven't gotten it yet ( _poke_ /u/eddyb). If we get that we could get closer to python-style decorators. With kwargs we'd be able to do everything python decorators do (assuming I fix the method problem) and have all the magic goodness from `Flask` and `argparse` and the rest :D ^1. Alternatively, we can pass arbitrarily typed arguments by declaring statics and passing them through, but that sounds icky.
I think you're free to be lax until 1.0, at which I'd love to see detailed progress logs on the nightlies every week. (Speaking of, I hope the 1.x versions of Rust all have incredibly detailed changelogs as that'd be *really* amazing to have)
Yes, I know about how attributes work, and was wondering about param support. As you have shown, it might not be as clean as flask, but it is interesting, and it might be possible to get somewhere close. I much prefer flask style to any of the express.js style libraries in Rust. Thanks for the writeup! Hopefully the changes that you need get implemented. Haven't followed rustc Dev closely in a while, but hope it works out :)
740 (551 'working' + 189 'fixed') as of May 3rd: https://internals.rust-lang.org/t/regression-report-beta-2015-05-01-vs-nightly-2015-05-03/1990
Oh, nvmd, I was using an `Rc` instead of an `Arc`, which was must faster. The `Arc`s performance is comparable to the dynamic atom. Now I don't know whether I should be using this library or I should be using an `Rc`, as the performance benefits of static/inline atoms are twice as fast as an `Rc`, but dynamic atoms are 5 times as slow...
You could have named it â€œAdornoâ€!
You could also look through the [awesome-rust](https://github.com/kud1ing/awesome-rust) list and see if anything piques your interest. Obviously the quality and activity will vary, but every little bit helps!
I admittedly only glanced, but wouldn't this be recycling values, not recycling types?
In some sense, the RFC process is a very detailed changelog....
And I even have the [moment on video](https://youtu.be/crPQwotkMHQ?t=13m17s)!!!
FWIW, the file above is also on Github: https://github.com/ericsink/LSM/blob/master/fs/t.rs 
The latter wouldn't work because you can also have lifetimes that are associated with methods rather than the entire impl: impl Foo { fn bar&lt;'a&gt;(&amp;self, x: &amp;'a i32) -&gt; &amp;'a i32 { x } } As for structs, it might be possible to elide the `&lt;'a&gt;` declaration, but since you'd still need to add the parameter list to `Person` everywhere else in the program it would make that less obvious.
Exactly what I was looking for, thanks!
I think the issue is that you have a reference to the `&amp;mut ICursor` rather than an instance of the type. You may need to cross borrow: `compare_func(&amp;**x, &amp;**y)`. Just a guess, can't test it right now. **Edit:** I was close. This is one of three changes that are necessary. The first other one is to explicitly assign x and y as references (the way you have it written, it will try to move them, but `&amp;mut ICursor` types are not `Copy`, so you cannot move out of indexed content). The second, which is really subtle, is to define `res` as being an `Option&lt;usize&gt;` explicitly: let mut res = None::&lt;usize&gt;; The reason for this is that otherwise Rust can't infer from context which instance of the `Index` trait to select for this line: let y = &amp;self.subcursors[winning]; since there are multiple implementations in scope, so it doesn't know what `y`'s type is supposed to be. Normally, this wouldn't matter, because Rust would be able to determine that `res` is an `Option&lt;usize&gt;` from this part: None =&gt; { res = Some(i) } but it seems like it's getting stuck at the function call and not even getting to the other match arm. To test this, I tried just moving that `None` clause above the `Some` clause in the match, and Rust was able to infer the correct type without annotations. This all feels resolvable to me, but it definitely feels like a bug (and may already be filed). [Fully working code is here](https://gist.github.com/pythonesque/416d9d2d72bd0337a9fe). **Edit 2:** The cross borrow actually isn't necessary once the inference is fixed: you just need `compare_func(*x, *y);`
Ohhh that's pretty neat :)
Could you give me an easy example for that? I still don't get it :/.
This is a very clever take on free-lists done in a safe way. It seems like it'd have application in complex event processing, or event computer graphics. Anywhere where you have intermediate data sets used to apply calcs to large ranges of data. It does seem a bit invasive, however. It makes types have to worry some about their (or their neighbors) own implementation. Vectors and other collections of uniformly sized buffers seems like great candidates for utilization of intelligent allocators which can manage this stuff under the hood. 
Assuming b = 0, a = 5: In many languages, the value of `b = a` is 5 - ie. the new value of `b`. In Pony, the value of `b = a` is 0 - ie. the old value of `b`. In many languages, `a = (b = a)` would assign 5 to `a`, so both `a` and `b` would have the value 5. In Pony, `a = (b = a)` would assign 0 to `a`, so `a` and `b` would equal 0 and 5 respectively - ie. the values are now swapped.
It does seem strange to me that we're one month after the 1.0 beta and still no one has tried to [contribute](http://benchmarksgame.alioth.debian.org/play.html#contribute) a working mandelbrot program for Rust. 
The video is apparently not up, but the slides are at http://www.steveklabnik.com/fosdem2015/
In the same sense, so is the commit log itself :p
I'm really excited to see that the [Duration reform RFC](https://github.com/rust-lang/rfcs/blob/master/text/1040-duration-reform.md) was accepted. In particular: &gt; There is no concept of a negative Duration. All of my use cases for that struct have been related to timeouts and I've [never known quite what to do](https://goo.gl/5JA9si) with the negative case. Good stuff! \o/
You can also use `$crate` see [here for details](https://doc.rust-lang.org/book/macros.html#the-variable-$crate). Otherwise you can do like /u/diwic said with a preceding `::`
Years ago, I used to contribute to [Chicken Scheme](http://call-cc.org/), and I got a custom t-shirt from the lead developer for contributing the 256th "egg." I loved that shirt! When Alex Shinn contributed the 512th egg (I think it was 512), I sent him a t-shirt, to try to keep the tradition going. I'd encourage someone who's active in the community to bootstrap the tradition for crates.io, by sending this nice contributor an article of clothing. Or any rusty object. (Or, maybe do it for the 2048'th one, if decimal doesn't appeal to you!)
Happily so ! But considering the crate index is not a power of two, I am afraid it's not so special after all without a chance for massive crate-enclosed tribute.
This branch is broken on current nightly :( Which version of Rust does it need?
But that means I have to read RFCs and I'm *lazy*! Seriously though... had to dig through RFCs on associated constants, still wasn't sure because the RFCs seemed more focused on associated types. So I had to just look at the pull request and read the test cases. Things were pretty clear after that.
I'm very tempted to immortalize your own self-assessment by using CSS to append " is kind of a bastard" to your username. :)
It definitely will work with the rustc from 551a74dddd84cf01440ee84148ebd18bc68bd7c8 .
Thinking about that put a smile on my face! Wouldn't that make a nice 'crate 2000' gift :)?
Sure. But you're not doing anyone a service by refusing to implement things if they're needed.
Yeah casing conventions are great(although c# has screwed upMyJavaCasing ThatCanBeSoAnnoying), naming conventions are cool too. But please don't bother me with brace styling and indentation warnings! Please don't do that please. 
They're also a little hard to understand outside of context, which is something that tends to happen with my slides. They're an aid to the talk, rather than standing alone.
Can't speak for everyone, but in my personal experience I've ever only needed slashes for long conditionals, which at that point makes me start considering a new way to handle that particular conditional.
I've been wanting to watch this since I heard about it. I wasn't around to watch the live stream. Someone youtube it or something. :) (someone with connections at fosdem..)
FOSDEM had huge issues with video this year. Most of the Ruby Room videos are beyond salvaging.
Bad git spelunking on my part, I meant d3c49d2140fc65e8bb7d7cf25bfe74dda6ce5ecf .
I feel as though Adorno would disapprove of decoration.
Thanks for the kind words!
Thank you!
Would you mind filing a bug with your findings? Even if it's already there, adding more information can help resolve things.
Hm, my rustup fails on rustup: downloading toolchain for 'd3c49d2140fc65e8bb7d7cf25bfe74dda6ce5ecf' rustup: command failed: curl -s -f -O https://static.rust-lang.org/dist/rust-d3c49d2140fc65e8bb7d7cf25bfe74dda6ce5ecf-x86_64-unknown-linux-gnu.tar.gz.sha256 rustup: couldn't download checksum file 'https://static.rust-lang.org/dist/rust-d3c49d2140fc65e8bb7d7cf25bfe74dda6ce5ecf-x86_64-unknown-linux-gnu.tar.gz.sha256' Edit: Or, maybe I just don't understand how to rustup.. Stay tuned.. Edit2: I got it to build after `rustup.sh --date=2015-03-10 --channel=nightly`, but I get cryptic assertion failures when I try to run on SDL.h or my own little test library.
Haha good catch, edited :) 
It definitely seems like after some amount of time (6 months? a year? more?), if crates are abandonware and can't compile on nightly (and therefore can't compile on any Rust &gt;= 1.0), they should be removed from crates.io.
Sweet! I'll upgrade right after I finish downloading some more RAM.
Filed https://github.com/rust-lang/rust/issues/25165.
Yeah, it seems that gcc has way better codegen for this example. I'm not sure exactly why, but I suspect it's something more complex than just bad instruction selection on LLVM's part.
Try a smaller font? :P That's what I did. I went from 90 characters to ~110.
Do I have an option to suppress this warning? I like the idea and intention of convention checking itself, but it's totally different story if I am being forced to use specific convention rather than my own in my own code. 
I would, but I can't seem to get monitor scaling to work; for some inexplicable reason, it just makes stuff on the monitor larger, rather than making the whole monitor larger...
Do you record yourself coding often? Or was this recorded just to catch that sneaky 2000 milestone? Because I think I've found a new hobby.
The eternal war of where the brace goes, of tabs vs spaces...
Great to hear! I record everything I do and upload it as a project archive. It's fun and improves overall quality. I call it 'exstream programming'.
That comment doesn't make any sense unless you're programming on an actual Unix mainframe terminal from the 80s, in which case rust would not compile on it anyway. My pet peeve is people complaining about technology and progress violating their outdated no longer relevant standards just because of their habits. It's like the strike of the horse manure cleaners of New York because cars not generating horse shit for them to clean. I'm sorry but I'm not willing to give up my non shit based vehicle.
I mainly don't like having to either muck around with ugly hacks or use temporary variables just to use a long chain of method calls and/or member accesses where I only need to go deep on one single line. Thankfully, that part *does* work properly in rust thanks to the explicit semicolons and closing braces. foo = bar.baz() .quux();
The situation about multithreading is the following: - Cocoa requires you to do everything in regard to your windows from the *main* thread of your application. Welcome back to 1980. - Win32 can create windows from any thread, but some functions such as `GetMessage`/`DispatchMessage` apply on the windows that were created in the thread you're currently in. - Xlib should theoretically allow you to do whatever you want. However some parts of xlib [aren't thread-safe](https://github.com/tomaka/glutin/pull/221) even if you call `XThreadInit`. It has also been reported that you sometimes get a segfault if you destroy a window in a different thread than where you created it. Oh, and don't even think about reimplementing the X protocol in Rust, because GLX/EGL require you to use the native Xlib. 
Reducing your font makes stuff on the monitor larger? That doesn't sound right; you should reformat your computer. Then you can fit everything on your computer on your monitor at once.
Yeah, started with this but those "as usize" are obnoxious .
Yeah, on a laptop in front of my 1440p screen
&gt; That comment doesn't make any sense unless you're programming on an actual Unix mainframe terminal from the 80s, in which case rust would not compile on it anyway. You might want to tone that down a bit. I like having code side-by-side *and* I like being able to use a font big enough so that I can actually read my code. It has nothing to do with "mainframe terminals."
Have you tried `Fn() + Sync`?
Yes, it says `error: expected a path on the left-hand side of `+`, not `&amp;Fn()` [E0178]`.
That's a precedence error, wrap `Fn() + Sync` in parens.
Let's clarify that I'm for a guideline that discouraged *long* lines due to readability, after all that's why newspapers have columns. What I'm opposed is a hard numeric limit based on a hardware limitation that stopped being relevant decades ago. In other words I don't think it makes sense to enforce a specific line length on all rust users. Really, that's why code should be peer reviewed for readability and individuals can always change their local settings such as font or zoom level in their own editor. Our just get a bigger screen. 
Now I run into error: mismatched types: expected `&amp;core::ops::Fn(u32) + Sync`, found `[closure &lt;anon&gt;:5:31: 5:64]` (expected &amp;-ptr, found closure) [E0308]
&gt; based on a hardware limitation that stopped being relevant decades ago As I said, this is false. For me, 80 cols has nothing to do with hardware. It has everything to do with the distance I sit from my monitor and my ability to read the text on my screen. I'm not arguing about what should or shouldn't be enforced. I'm pointing out that your comments on this matter are extremely dismissive. &gt; Our just get a bigger screen. Once again, you're making way too many assumptions. I don't just have "a screen." I have *three* screens. This places limitations on how big they can be (distance from my eyes + physical constraints of living situation).
Thank you! While this looks a bit complicated, it works and even allows capturing (immutable, obviously) variables (however it requires an `Arc`, which would not be needed were the Pre-RFC adopted). Edit: I was wrong; Ker whipped up a solution that just requires a normal &amp;-pointer. However, it still uses thread::scoped, as otherwise our handler would need to be `'static`, which a closure cannot be (apparently due to [#25180](https://github.com/rust-lang/rust/issues/25180)).
That means you're missing `&amp;` before the closure expression.
Yes, thank you. In the meantime, /u/whataloadofwhat already showed a working solution.
La casata is now reserved. 15.5.2015 12:00 ;)
Cant the problem of line cols be resolved by rustfmt? You set the linecols in rustfmt to what you wish and it converts every file you open for you and converts back the original once you save your file.
Sorry, I'll try to get my 420 crates working on linux for the next regression report.
Nickel's (Co-)author here. I'd say nickel and iron share a lot similarity. I think it's fair to say that Nickel focuses more on simplicity whereas iron focusses more on extensibility. That said Nickel is also quite extensible through custom middleware. However, iron allows you to change nearly every part of the system and also moves pretty much every part of the system into separate repositories. Also the way iron pipes requests through the middleware chain is a little different from what Nickel does. Just try both and pick the one you like more ;)
Same. I work on a laptop, and like big fonts. easier on the eyes.
When `rustfmt` will land then compiler will simply force you to use "the one good form" just like `gofmt`. It will put end to the war (at least among rustaceans).
Apparently it's also tightly coupled with EGL, so you'd also need to use the native libwayland.
Honestly, I don't know why Rust doesn't have exceptions. It already has all the required machinery for panics, destructors and stack unwinding. All that's missing is the "catch" construct. It seems like every possible exception safety problem that can happen with "catch" can also happen without "catch", due to multithreading. So I'm not sure why they made that decision.
There is some function which takes closure and works like catch, i.e. it executes this closure and can catch panic, it is in standard library but I don't remember it's name. FAQ says that there is no such function (but there is): http://doc.rust-lang.org/1.0.0-beta.4/complement-lang-faq.html#why-is-panic-unwinding-non-recoverable-within-a-task?-why-not-try-to-%22catch-exceptions%22?
Oh and while you're at it, can you please extend cargo to allow a "platform" field so that it will complain when installing win apis on non-win platforms?
The key is avoiding side effects and using result/option combinators: extern crate rustc_serialize; use rustc_serialize::json::Json; fn parser_test() -&gt; Result&lt;String, String&gt; { let doc = "{ \"name\": \"abcde\", \"num1\": -10.0, \"objItem\": { \"num2\":-10, \"arrayItem2\":[40, 50, 60] } }"; Json::from_str(doc) .map_err(|err| format!("{}", err)) .and_then(|root| root.as_object() .ok_or_else(|| "Root is not an object".to_owned()) .and_then(|obj| obj.get("name").and_then(|x| x.as_string()).ok_or_else(|| "Could not find name".to_owned())) .map(|name| format!("Name is: {}", name)) ).map_err(|err| format!("Error parsing document: {}", err)) } fn main() { let r = parser_test(); println!("{:?}", r); } 
Ah, hm, yes, that's because `our_vec.iter()` gives us borrowed tuples and the `collect` for a HashMap wants owned tuples. I didn't talk about this in the article, perhaps I should have. Try this: http://is.gd/1K3wDL
I know the summary of Iron, but not more. I only work on Hyper. 
The imports can be automatically fixed by a program based on gofmt.
Exceptions are evil. Nice in theory, and when you're writing small piece of code. "I'm just going to throw exception, and my code is so simpler now!", but nasty in a larger systems, using multiple libraries from different sources. "Where, who and how should handle this exception? Where did it even come from, and why? Will this code execute at all, is it safe? I don't know what's going on in this system anymore!" So yeah, no exceptions in Rust and that's great. 
I don't think it spins up a new thread, that was `std::task::try`. There's also `std::thread::catch_panic` now which is sorta like `try` except also without the thread spawning thing.
&gt; glium puts priorities into compatibility and correctness fo all GL versions (which[1] is hard[2] ). Is it feasible for this work to be ported to gfx? Also: is there an ETA for gfx to support other APIs? Looking from the outside, it seems that glium is being favored right now, even though the possibility being compatible with other APIs would be a major selling point for gfx.
Performance and flexibility are the main concerns as far as I'm concerned. Throwing exceptions is really slow when you actually have errors, and Rust (including its libraries) need to be usable without exceptions enabled.
It's actually quite the opposite: Java's checked exceptions are a nuisance, and they provide no good way to handling it. Everytime you call a function that throws something, you are FORCED to write huge boilerplates. In Rust, for cases where you are sure the content is not `Err`/`None` (or heck, you just want to debug / test something), you can use `unwrap`, and for cases where you actually **should** check for errors, you can use beautiful pattern matching / functions created just for exactly these cases (`and_then`, `or_else`, etc.) whereas in Java, in order to have readable error messages or anything really, you'd have to wrap every decoding step within its own try/catch block. It's actually the same in Go - Go forces you to write boilerplate for your errors - for testing / debugging purposes, you are just screwed. I love Rust's approach: It uses Errors as first class citizens (similar to Go - not as "exceptions") while it also provides you beautiful ways to avoiding boilerplate / handling those errors (different to Go/Java - where you are forced into ugly boilerplates)
You can get past the borrow error by using `iter_mut()`. I feel like the for loop should desugar to that when you're using `mut session`, but maybe there's some subtlety there. fn broadcast(&amp;mut self, msg: String) { for mut session in self.sessions.iter_mut() { session.send(&amp;msg); } }
That's what I thought it would do by default, but like you said maybe there's some subtle reason for that not to happen by default. Thanks.
Fair enough. I guess it's a matter of opinion if people would abuse "throw" if "catch" were available. In C++, that doesn't seem to happen very much.
You can initialize an array with Option None for each element, then swap the element out when you wish to; obviously with a runtime maximum. There might be a better way to achieve this, but this is what I did: check [this lib out (cubby)](https://github.com/viperscape/cubby/blob/master/src/lib.rs#L11) for potential inspiration :)
I don't see the difference you are trying to make. `x, _ = ...` in go is annoying boilerplate where "you are just screwed", but `try!` or `unwrap()` in all the same places is somehow superior? That you write `match` instead of `catch` somehow turns the whole thing from a chore to something beautiful? Do you think you'll get a useful error message if you just use `and_then()` and friends everywhere? How will the result of that tell you more than the exception that the Java code would throw? Is there even a way to get a stack trace out of an `Err`?
It is not possible to use a struct like this with purely safe code. The way DST structs are intended to be used is to have a struct like: struct SomeStruct&lt;T&gt; { a: u32, b: T } You can then create a `SomeStruct&lt;[u32; 4]&gt;` (say) and then coerce it (an implicit coercion) to `SomeStruct&lt;[u32]&gt;`. Note that there needs to be a sized version of the unsized struct to initialise. 
I hadn't seen this before, but it looks useful.
Is there a video from the talk somewhere? This looks like just the thing to get me into rust (coming from a year of nothing but node/express)!
"intended" seems a bit strong: it's entirely possible to have unsized initialization behind `&amp;` or `box`, it's just not implemented yet.
Thanks. It's gonna take me a while to figure out exactly what you're doing :) but it looks interesting.
Seems like a mistake in the documentation. read_line() used to return the input as a String, but now it takes a string as a parameter instead, which it writes the input to, and returns the number of bytes written. The input in this example is contained in `guess`, not `input`. EDIT: This mistake seems to have been fixed on the git master branch, but the fixed version is not yet available on the rust website.
Ahh, I see. When you say it's not possible to create one with safe code, does that mean there's a way to allocate one for a runtime determined length with unsafe code? Or can you only coerce a statically known sized type like your example? I saw [this](https://github.com/dotdash/rust-flexarray/blob/master/flexarray.rs) which uses a different approach but it looks a bit hairy. Maybe the cost of separating the header from the buffer like `Vec` is worth it to keep the code simple.
How do you want to catch an exception you don't know of? Put a try-catch around every statement?
Its not noise. Rust is popular because its popular, not because it makes the most sense. There's a difference between popularity and merit. I try to help people avoid wasting their time. They are defensive because they know I'm right.
Thanks, that's something I'll definitely keep in mind. On a similar note, what do you think about (ab)using `panic` / errors in Go for means other than error-handling? For instance, if I wanted `http.Client` to *sometimes* follow redirects, this can only be done via returning an `error` in the `CheckRedirect` fn, or you'd have to use a custom `RoundTripper`, which seems a bit tedious, for a rather simple task. (as described [here](http://stackoverflow.com/questions/23297520/how-can-i-make-the-go-http-client-not-follow-redirects-automatically))
&gt; for cases where you are sure the content is not `Err`/`None`, you can use `unwrap`, Why would you return a `Result` or `Option` if you know you're never going to return `Err` or `None`? Almost every use I've seen of `unwrap` was just the programmer being lazy and saying "let's pretend errors can't happen here even though we know they can". Now, if they ever want to be able to handle errors without `panic`king, they're going to have to break the library's API.
&gt; A match is slightly more beautiful than a catch because it enables pattern matching... That's nonsense. Scala, SML, and OCaml all use pattern matching when catching exceptions. (And I'm sure there are others.) Just because C++ and Java don't have pattern matching doesn't mean you can't use pattern matching on exceptions.
&gt; In C++, that doesn't seem to happen very much. That depends on who gets to determine the coding style.
&gt; no matter what programming language one uses. If you can assume a specific structure to the JSON you're trying to parse (as I see you do in your example), then Piqi can make parsing it really simple, although only for the languages it supports (and Rust is not yet one of them). http://piqi.org/ Just thought I'd point it out in case anyone wanted to add Rust support. I haven't actually used Piqi, but I've heard some people like it.
You need to a `move` closure. Related issue to improve the error message: https://github.com/rust-lang/rust/issues/24909
Um, given that this branch requires an ancient version of Rust, plus some unpublished Clang patches, I am having trouble believing that it's actually being used in Servo. You wouldn't check in generated bindings code without the means to reproduce it, ...would you? :-/
Is there a writeup for the rationale for this somewhere other than IRC? I'm not sure I understand why they decided to make the compiler so conservative in this regard. If it can't find an implementation that actually causes an ambiguity, then there's no problem. If the rationale is the compiler can't guarantee that a conflicting implementation won't exist in the future, then I think that would apply to a lot of use cases, wouldn't it? I imagine that it would ultimately severely limit the usefulness of generic trait implementations.
I made my bid for immortality, but it was cruelly snatched from my hands by an aloof, indifferent diety and a treacherous thief. Oh, woe is me! (Patch fell between the cushions, someone else independently implemented it. :P)
There are times where you can't prove *to Rust* that the error condition can't happen, but it nonetheless shouldn't be able to happen. For example, there are many algorithms that use stacks that will *never* attempt to pop an element off an empty stack if correctly implemented. In such cases, `unwrap()` is entirely appropriate, as if it happens it means all bets are off in terms of code correctness (and thus you can't do any useful recovery).
If I understand rust-bindgen right, it'll generate Rust bindings for C headers, yes? In that case, my project could be reduced to generating C bindings for C++ libraries. Well, that and the remaining work of picking which template instantiations to make bindings for, based on the calls happening in the Rust code. Neither of these parts seem *horribly* infeasible though!
Whoops, my original comment was unclear. This is still a work in progress - one open PR to servo/mozjs, one open PR to servo/rust-mozjs, and a branch under preliminary review to servo/servo that makes use of those two.
The gap is that the beta channel is a snapshot of only what's currently considered stable. note: this feature may not be used in the beta release channel The libraries themselves may be stable, but the Rust *compiler* won't let you use unstable features unless you also use a known-unstable release channel (i.e. the nightlies). Chances are pretty good that the users that would be turned away by the above error aren't yet using Rust, anyway.
OK, that makes sense. I'm kind of used to having a choice between a function that returns an option and one that throws an (unchecked) exception for those cases. The closest you could do in Rust would be to provide an alternate API that panics on error. I'm not sure it would be worth having, but it could provide a more useful error when misused than 'called `Option::unwrap()` on a `None` value'. So far, every use of `.unwrap()` I've seen in rust was someone simply not wanting to deal with error handling.
I agree that people use `unwrap()` too frequently (especially in examples, because `try!` doesn't work in `main()`), but I find it's actually relatively rare in libraries (more common are implicit panics due to array indexing). This is something that we'll have to improve through education. What I would like (and I've mentioned this on a number of occasions) is a way to demarcate a block of code as not allowing exceptions--i.e., it is a compile time error for any function to be called that can perform a stack unwind within that block. That way you don't lose control of your program due to accidental implementation details of third party libraries (especially important in unsafe code). I don't think Rust will have this for a while, though.
&gt; Import libc::size_t and cast to that with as size_t. Thanks a lot, that must have escaped me! I remember attempts at passing ``usize`` (or whatever it was called back then) directly which got me type errors.
I'm suffering imposter syndrome, because my only contribution was to libextra (a channel in which the sender blocks after sending until the message is `.recv()`'d), and it only lasted a few months before being removed. :P
With the `optin_builtin_traits` feature on nightly, you can work around this by doing: trait NotFile {} impl NotFile for .. {} impl !NotFile for File {} impl&lt;P: AsRef&lt;Path&gt; + NotFile&gt; UnixFileType for P { /* ... */ }
Who wants to live forever... ...but seriously, I haven't contributed so far (apart from a bit of RFC discussions, a plea to remove '+' as concatenation operator, that was thankfully heeded by the higher gods, and reporting an ICE â€“ if I fix that, would it still be in time to claim authorship? Edit: PR is now on github). I'm fine with that. You folks have done an extraordinary job. You know who you are.
We don't have a proper HTTP framework yet and you want to write a unikernel?
Why do you need to write drivers? What advantage does Xen provide? I thought it just produced virtual machines and you'd have to write drivers anyway.
Xen and kvm expose real hardware as virtual devices, so you write one set of drivers and they work on anything xen/kvm support.
To put it simply, Go and Rust target very different use-cases. Also, Go is relatively more mature than Rust.
I know this is close to feeding the troll, but for the completeness, I have to assert that *innovation happens everywhere,* not just in Go. Any good enough language and platform can be used for innovation, where the "good enough" criteria include pure language features, standard and 3rd party libraries, communities and dozens of other things. (One can argue that Rust is short of being "good enough" due to its immaturity, which I mostly agree.) If you seem to find innovative software only in Go, that would probably mean your interest is limited in that way. Explore and experiment with other languages and platforms---not just Rust.
Are they exposed as "standard" virtual devices? I mean - you could write a video driver for the virtual device and be done for all devices ever. Where can I read up about this?
http://www.eventbrite.com/e/rust-10-release-party-tickets-16908882924
Damn, without this list Rust would be full of typos and incorrect indents!
Disagree. Rust is popular because it makes most sense in a given context. Sure random popularity is a factor, but without a core quality, you never attract enough attention. In domains of PL at least. Who are you again? And who is defensive? Pcwalton? I don't blame the poor guy, all those people hammering that Nim is better than Rust are annoying as hell.
What typo? I don't see that typo. :P (Thanks for pointing it out!)
There'd also be some poorly ordered header includes!
Now it's clear the Rust can look as ugly as C++ :-)
What I'm doing for [`img-dup`][1] is I'm building the core functionality of the program as an API, and then building my two executables (one command-line-based, and one GUI-based) against that API. This way, the executable becomes both a living example and an ergonomics test for the library API. For simplicity, I've made the executable projects into separate crates that link to the `common` crate via a path dependency. If I wanted to, I could upload `common` crate to crates.io by itself (I'm not sure if I actually want to do this yet). [1]: https://github.com/cybergeek94/img-dup/tree/new_api
Example: I wrote a function that can be used with any input, e.g. a file name coming in from a config file. But in my test code, I specify a file that I just created. So in my test code, I know that the file exists and is valid. And with this domain-specific knowledge I can then call .unpack().
Gotta love your articles. Thanks for the detailed write up!
"This is all due to how Rust implements generics via minimization," is that not supposed to be "monomorphization"? Or, did I miss that term getting retired? :) Also: great read. I didn't *entirely* understand the argument that input type parameters shouldn't be associated types; in the example I don't see the `Transform` wanting to implement the trait for multiple input parameters, which I always understood to be the test for "associated or not". I totally believe there is a good reason, but I don't get it yet. :)
There's a major gotcha waiting for people who want to use OIBITs for specialization/negative bounds - negative impls are "viral" and if you implement `!NotFile` for `File` it will also be implemented for `Option&lt;File&gt;`, `Vec&lt;File&gt;` and anything else containing `File`, i.e. all of them will be classified as `File`s. Remember, OIBITs had very narrow purpose - moving two "viral" traits `Send` and `Sync` to the library, so they are just not designed for other creative uses like emulating specialization.
I realized that the undue complexity is coming from the fact that getting a property value from an object takes two steps: 1. First you call ``get()`` on the object which returns a ``Json`` object. 2. Then you call ``as_string()`` to get the property value. If these two steps are combined into one then things become more managable. fn get_string&lt;'a&gt; (obj : &amp;'a Object, prop: &amp;str) -&gt; Option&lt;&amp;'a str&gt; { obj.get(prop).and_then(|x| x.as_string()) } fn get_obj&lt;'a&gt; (obj : &amp;'a Object, prop: &amp;str) -&gt; Option&lt;&amp;'a Object&gt; { obj.get(prop).and_then(|x| x.as_object()) } fn parser_test() { let doc = r#"{ "name":"Bibhas", "num1": -10.0, "objItem": { "val":"The value", "num2":-10, "arrayItem2":[40, 50, 60] } }"#; Json::from_str(doc).map(|root| { if let Some(obj) = root.as_object() { get_string(obj, "name").map(|name| { println!("Name is: {}", name); }); get_obj(obj, "objItem").map(|o2| { get_string(o2, "val").map(|val| { println!("Value: {}", val); }); }); } else { println!("Root is not an object."); } }).map_err(|err| println!("Error parsing document: {:}", err)); } 
Fantastic writeup! I know that rule 4 and diplomacy and all, but given the previous mentions of the similarity to C++11's closure model, it might be worth pointing explicitly what Rust's trait object capability lets us have in addition: whereas in C++ `std::function` has to be implemented as a separate library type, we get `Box&lt;Fn()&gt;` (and `&amp;Fn()`, ...) for free. In other words, the choices of underlying functionality (the `trait`), static vs. dynamic dispatch, and memory management are all independent and compositional.
Also: &gt; By default, the compiler looks at the closure body to see how captured variables are used, and uses that to infers how variables should be captured: &gt; &gt; * if a captured variable is only ever used through a shared reference, it is captured by `&amp;` reference, &gt; * if it used through a mutable reference also, it is captured by `&amp;mut` reference, &gt; * if it is moved, it is forced to be captured by-value. (NB. using a `Copy` type by-value only needs a `&amp;` reference, so this rule only applies to non-`Copy` ones.) I think it might be clearer to also mention that `&amp;mut` is chosen if the variable is assigned to, even if no further `&amp;mut` borrow occurs inside the closure body. (As written, "if it's used through `&amp;mut`, then it's captured through `&amp;mut`" makes it seem a bit more banal than it is.)
One very easy way to accomplish this would be to use `test::black_box(self)` at the end of your `drop` code. Alternatively, use something like `std::intrinsics::volatile_store`. Edit: I misread your question, but you kinda would need something like what I suggest to make sure that your drop code is executed at all. A move in rust is a memcopy, and the drop glue will *not* run on the thing you moved out of. Nor is it guaranteed that all copies will be optimized away (although LLVM is pretty reliable). It would be better for your key to store its magic bytes on the heap, where they won't get copied around automatically. Having said that, if an attacker has access to your memory you've pretty much lost, so I wouldn't waste too much time on trying to protect your key.
That is sad to hear. :( What were though issues?
Automatic serialization and deserialization (with `#[derive(Serialize, Deserialize)]`, cf. https://github.com/serde-rs/serde) is way simpler than trying to fetch every field manually. Here's a rough draft: fn getname(doc: &amp;str) -&gt; Result&lt;String, String&gt; { #[derive(Deserialize)] struct Item {num2: i32, arrayItem2: Vec&lt;i32&gt;} #[derive(Deserialize)] struct Doc {name: String, num1: i32, objItem: Item} let doc: Doc = try_s! (json::from_str (doc)); Ok (doc.name) } It's even faster (IMO), because instead of maps you deserialize into structs.
:(
I'm not that worried about the actual Drop code, it calls out to a memory scrubbing function implemented in C (until the `volatile_set_memory` intrinsic is marked as stable). What I'm wondering if there's a risk that there will be a copy from the first array that contains the key data into the Key-struct, since the first array doesn't have a Drop implementation. If such a copy would happen, then we would have leaked key data.
What kind of errors did you encounter? Alot of answers you find on google will be obsolete because rust has undergone alot of changes the pas few months. You're better off reading the book http://doc.rust-lang.org/1.0.0-beta.4/book/ The 1.0 release is scheduled for next week and rust has nothing similar to go-routines yet.
I would depend on the if there is any serious video issue. which they were having this year. :(
&gt; A move in rust is a memcopy, and the drop glue will not run on the thing you moved out of. Nor is it guaranteed that all copies will be optimized away (although LLVM is pretty reliable). It would be better for your key to store its magic bytes on the heap, where they won't get copied around automatically. I understand. I see this more as a best effort in trying to keep the stack frames free of old key material. I will probably add secure heap storage as soon as placement-new lands. &gt; Having said that, if an attacker has access to your memory you've pretty much lost, so I wouldn't waste too much time on trying to protect your key. I agree that you have lost when an attacker has access to your memory, but the threat model is that of forward secrecy. e.g. an attacker that has listened to your network traffic for a while and at a later stage manages to compromise your machine. If old keys can be found in your memory the attacker can decrypt your old traffic, if not then the attacker can only access current and future traffic (and of course the resources found on the actual host).
I would like to echo what the previous comments said and also specifically state: Paste your code that didn't work in this topic, and we'll help you debug it and also explain why the errors are the way they are. Any programming language, regardless of whether it is interpreted or compiled, has syntax and semantics, you have to get them both right in order to run correcly. However, in interpreted languages, you only have to get your syntax right in order to run, but the program may not run correctly. Rust is very special in that it can determine flaws in both syntax and semantics, giving you more assurance that your program will run correctly. That means that you do spend more time getting your program right initially, but it usually saves you time in the long run. Rust doesn't do go-routines, but it doesn't preclude someone from building and using their own coroutine library from within Rust (see https://github.com/rustcc/coroutine-rs) In my experience, the most efficient approach is to use event driven programming, and defer to thread pools when you need parallelism. But some folks don't like event driven programming, so to each their own, I guess. 
This is so good, Huon. You are on a roll. By the time I was halfway through (Back to Basics) I was convinced that Rust closures were amazing, and then it kept going deeper. Very thorough and insightful.
It doesn't ever result in an error, because casting means "hey, I realize some data will be lost", but there are a few obscure platforms where sizeof(void *) != sizeof(object) (usize/uintptr_t and size_t, respectively) Edit: although, IMHO, usize should be defined as large enough to hold the size of an object, because that's what we use it for, while we should have a separate iptr/uptr in cases where they are different (only for casting to/from pointers, really).
I bet kud1ing would love help!
Make sure the `LD_LIBRARY_PATH` environmental variable is set to `/usr/local/lib`. You can check with: env | grep LD_LIBRARY_PATH If it's not, either add `export ${LD_LIBRARY_PATH}:/usr/local/lib` to your `~/.bashrc` or, if you want it system wide, make a file under `/etc/profile.d/`
Add *rust-prefix-path* to *LD_LIBRARY_PATH*(env var). export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/lib
For me (on Lubuntu), `sudo ldconfig` did the trick. But yes, the installer should at least detect it and offer suggestions.
It is. Here's the issue for it: https://github.com/rust-lang/rust-installer/issues/30 A first step may be just to detect this scenario and offer suggestions.
It is inconvenient, but it gets you away from global shared mutable state. But for your library, it doesn't seem worthwhile. If I understand my Rust correctly, immutable self is still safe because `Library` lacks the `Sync` marker. Only types that are `Sync` can be shared between threads.
It were errors in the depencies i tried to build. I tried 2 frameworks. At this moment, i've managed to build the "iron framework". But i still get errors while building this one: https://crates.io/crates/nickel Anyway, I have iron working, i can start having some fun now :) Thanks for the info.
One downside to this is that dependencies of the command-line (such as getopts) seem to show up as dependencies for the whole project. I can see this potentially causing problems if your library could be used in contexts where the deps for the command line app aren't appropriate. I'm considering moving from bin to examples for this reason.
This is really cool, looking forward to taking a closer look at it.
Awesome!
Serialization is a different use case and works well when you know the precise structure of the JSON before hand.
In any program: big or small pretending that errors don't happen is a bad idea. Dealing with errors and failures upfront will make Rust software systematically better. I don't think in practice exceptions are faster than handling error codes, but even if there was a difference, it would be negligible and a price worth paying for a code that is correct and reliable.
Well i guesse Go is the way to go then,, maybe rust in the future :) For some reason all the popular web languages aren't compiled ones. eg. php, ruby, python, nodejs. These are really good languages but they lack performance. Except for nodejs. But nodejs has alot of other issues.
Your issues with building probably had to do with backcompat, which is still under churn until 1.0. Once 1.0 comes out libraries compiling with 1.0 should compile fine forever. Rusts build system is also supposed to be the "no need to do anything" kind; you've just caught it at the wrong moment. FWIW go's build system, if anything, is worse on this front. It doesn't do version pinning, so if a dependency doesn't match up right, there's no way to fix it without hacks (recloning in your gopath, etc).
First pull request! :)
The book is better on nightly, because I'm only back porting it next week, BTW.
Go is a very opinionated language, and it doesn't really try to cater to all needs or workflows. Its ecosystem is designed with all the choices already made, to fit the needs and workflow of Google (I presume). Which has its benefits; but it leads to a lot of wtf moments.
Why not giving us the link to the github repository of your library ? I won't help you on this topic, but I, and probably many other people, would be interested in seeing your code.
If the function doesn't capture anything, then its closure-struct is zero-sized, and boxing it does not actually allocate.
A lot of stuff there is very outdated by Rust standards - like, months old.
Thanks, article updated following the feedback, with better motivation and discussion. 
I too am a rust noob, though I'm a polyglot programmer with about two decades of experience. I had a similar set of problems when I first tried rust, but I just gave it a bit of time and read through a few more docs. Then I started writing a lint (because writing static code analysis happens to be one of my hobbies) which I soon merged into /u/Manishearth's [rust-clippy](https://github.com/Manishearth/rust-clippy). Since then I've learned from him and others by asking stupid questions, wrestling with borrowck and writing code. As I said, I still consider myself a newbie (For example I haven't written any rust code that needs to allocate something as of yet), but that's fine. I trust the compiler (whose hints are usually spot on, once one actually takes the time to *read* and understand them). I can ask a lot of clever and nice folks here. So don't give up. Try stuff. Fail. Learn. Tell us about your problems *before* you exhausted your patience.
Really enjoyed this article! I had previously been viewing closures as just another piece of the language. Was fascinating to see them decomposed into their constituent parts, all made out of "plain" Rust. Closures are just sugar! Very cool :) Also enjoyed the last part about trait objects. I hadn't even thought about a vector of functions being a problem, but as soon as it was described it made sense. As did the solution to the problem. Thanks!
Me too. It's my favorite way of dealing with routing. I wrote my own Lua stuff for this a while back: [the router](https://github.com/cmr/leafy) and [the framework](https://github.com/cmr/tweed).
[`Server`](http://ogeon.github.io/docs/rustful/master/rustful/server/struct.Server.html) has a field called `scheme`, where you can choose if it should use HTTP or HTTPS using an enum. HTTPS will require paths to a cert and a key and those will be given to the Hyper backend when the server starts. That's it and the rest happens in Hyper. Edit: I should probably add more docs for this, as you say. There are a lot of things in the library that need more docs... :P
You want /r/playrust.
I fixed something in documentation (https://github.com/rust-lang/rust/pull/24849) and I apparently don't count (I really don't deserve it for ficing one line). So I am assuming that every small fix did not go into this list.
I don't get the licensing of all this stuff tho. As far as I see from the â€œLicensingâ€ page http://maidsafe.net/network-platform-licensing the organization/company tries to follow the GPLv3 license. It states, amongst other: &gt; no person, company or organisation should own the technology At the same time, the organization has a strict CLA http://maidsafe.net/licenses/CONTRIBUTOR.txt which among other says: &gt; you hereby assign to us with full title guarantee all the intellectual property rights (existing and future) in your contributions (the â€œrightsâ€) which seems totally contradictory to the quote above. If all contributions are CLA-ed, the company practically owns the project and all its rights. Am I the only one who sees a contradiction here?...
lol!
Here's what I mean: Often, when you're just trying to write a simple site, you can afford a GC. Dynamic languages let you code up stuff _really_ fast. Rust's strengths don't matter as much in this context. The web is also pretty much inherently dynamically / string-ly typed, so a dynamic language fits really well. This may be just due to the fact that I come from the Rails world. People learned Ruby because Rails was so damn good, but, while people who know Rust already might make backends in Rust, I don't think people will want to learn Rust because they need to write some kind of site backend. Job queue? Database? Some other part of the stack? Absolutely. But basic application logic? I'm skeptical. But we'll see how it goes!
I wouldn't characterize it as worrying.
&gt; If all contributions are CLA-ed, the company practically owns the project and all its rights. You are half-right, I guess? For the current codebase, the CLA doesn't make any difference. It's published under GPLv3, they can't un-publish it (or force you to delete your code). They can, however, dual-license under some other (proprietary?) license and continue delevoping under the new license, making the GPLv3 code old, unsupported &amp; deprecated (note it could still be forked!). While I personally wouldn't contribute to a project that requires such a CLA, I don't think it fundamentally contradicts publishing code under the GPLv3.
Right. Lets move on then.
Thanks, but I can't take the whole credit for that, since all the networking and request parsing is done by Hyper. I don't know how it's usually done in Java, so I can't say anything about differences. In any case, Rust can be very expressive sometimes :)
I had a thought about stringifying identifiers, but I don't think a macro would be able to tell it apart from an expression...
I havent tried nickel but it might be because you are using rust nightly builds instead of the beta release (or the other way around). I tried to use the beta a while ago but alot of crates werent ready for that so I switched back to the nightlies for now, these growing pains will dissapear as rust gets more stable.
All I did was fix two typos, and I'm on there.
Have you taken a look at hyper? That's pretty solid in my view.
Related, [Coroutine-rs](https://github.com/rustcc/coroutine-rs) was mentioned here a little while back. Cool stuff, btw! Coroutines intrigue me, I really want to try using them for a non-toy project.
Small nitpick, the benchmark table says 'speedup' when in fact it's speed *ratio* if you want to calculate the speed*up*, subtract 100% (and yes, this may lead to negative values).
Thanks so much, Brian! They are pretty amazing.
Thank you!
It's nice to hear the concrete points that were particularly enjoyable. Thanks!
Maybe you could add a "dirty" flag instead of clearing and pushing all the time. This way your renderer can own all the panes and you wont have borrowing issues. Something like struct Renderer { panes: Vec&lt;(bool, Pane)&gt; }
Regenerator looks very cool! And yeah, the ownership system is definitely one of the hardest parts of making this working right. I don't think a regenerator-esque approach would work in Rust though, because of all its stringent type system, and the ownership system like you mentioned. Also, welcome to Reddit!
Would that mean that empty structs get 'static lifetime by default?
Apparently there have been a lot of different but closely related things called coroutines over the years, and people do sometimes come up with new terminology to differentiate one sort of coroutine-like thing from another. I think this [paper on coroutines](http://www.inf.puc-rio.br/~roberto/docs/MCC15-04.pdf) as a general control flow abstraction by the Lua folks provides a nice overview of the history of the idea and its various incarnations, as well as providing a helpful taxonomy of the various sorts of things that have been called coroutines over the years.
Feast your eyes! Generated by [cargo-lock-to-dot](https://github.com/brson/cargo-lock-to-dot). [Here's what Cargo is looking like for comparison](http://brson.github.io/images/cargo-deps.svg).
I'm not sure how to task `renderer` for access to `pane`. I'm excited to look into that and `RefCell` tomorrow. Thanks for the tips!
Not sure how this would solve it, since `renderer` would still have to borrow `pane`. Maybe I'm missing something. I did consider adding a `dirty` member to the pane struct, but I didn't love it.
I don't hate it as long as I can opt out when needed - what you did makes the code much safer in most cases. **But**, sometimes, you have to process data coming from somewhere else and *then* it's more convenient to use set_raw.
What do you mean by not very optimized? Also, not everything in Servo is necessarily in a hot path.
I agree that you can afford GC in most cases, but that doesn't mean it's needed. It's not correct to say that the web is inherently dynamic, I think that's just your Rails bias showing. Check out Ur/Web if you want to see an example of how to do static typing in web apps. Ur doesn't have GC, precisely because it's HTTP-only. In a typical stateless webapp (where state is delegated to a database), no references live beyond a single request, so Ur allocates everything in a per-request region that is discarded when the request is finished. This is easy to accomplish in Rust, just pass ownership down the stack as needed until you reach the scope of your handler function, which will take care of deallocating when the request is finished. So if anything, Rust is *more* suited to server side HTTP than other types of applications. Same goes for other type of stateless request/response apps (e.g. thrift, zeromq, grpc etc).
Sure; anyone can write an IPC library for Rust, same as any other language.
We could be immortals, [just not for long](https://www.youtube.com/watch?v=l9PxOanFjxQ).
They do actually: `Bencher::iter` takes a closure that returns a value, and feeds that value into `black_box`. In this case, the benchmarks are returning a `u64` via `.finish()`.
It looks very interesting! One feature I would like to have is to save the server replies offline to be able to use them for future tests. That would simplify a lot testing for me.
I'm on the list too, the only pull request I've made was changing "coerece" into "coerce" in the documentation.
In my particular case, I want to speed up some frequent `HashMap` usage. If you check out the default hasher used by the standard library, [`SipHasher`](http://doc.rust-lang.org/std/hash/struct.SipHasher.html), you can see it says: &gt; Although the SipHash algorithm is considered to be cryptographically strong, this implementation has not been reviewed for such purposes. As such, all cryptographic uses of this implementation are strongly discouraged. `HashMap`s are still susceptible to a DOS attack, which is why [`RandomState`](http://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html) and [`RandomXxHashState`](http://jakegoulding.com/twox-hash/twox_hash/struct.RandomXxHashState.html) exist. These initialize their respective hashers with a randomized seed to help prevent that attack. So I think that anywhere you use a `HashMap` is a good use case for this library. Everything I've said is to the best of my knowledge, so let me know if I'm wrong!
Given the core devs' habit of pushing things *out* of the standard library and into Cargo packages, this seems unlikely.
In addition to what [dbaupp said](http://www.reddit.com/r/rust/comments/35d029/hashing_at_over_9000_mbsec_twoxhash/cr3hmet), it should be said that these are *synthetic* benchmarks. If I just pick a video file I have in my downloads directory and run the included `hash_file` binary, I get more real-world times: $ ls -l movie.mp4 -rw-r-----@ 1 shep staff 153973998 Oct 19 2014 movie.mp4 $ time hash_file movie.mp4 7e6e3d84c121c31f movie.mp4 real 0m0.047s user 0m0.020s sys 0m0.026s Which works out to be ~ 3 GB/sec. Please let me know if there's something I can update in the README to help convey some of this.
There's another port here, https://github.com/Jurily/rust-xxhash
Argh; fixed now! That's one of my pet peeves, and I can't believe I did that. :-) If you look at one of my [commits improving performance](https://github.com/shepmaster/twox-hash/commit/c55a804c86757ace5eb02fffff5037851eaf9f7d), you can see that I **try** to be very explicit about what the ratio means. 
I did not mean to suggest that you consciously mislead people about performance. It was very simple to find the mistake by looking at the actual MB/s numbers in your table. Oh and thank you for being awesome on SO, btw.
&gt;My only excuse is that I was so excited to put the numbers in the README and got caught up in the hype. \^_^ All is forgiven ;-)
Yeah that had the doc back port label, it should have made it into beta...
I'm proposing `let x: &amp;'static Fn(i32) + 'static = &amp;|y| y + y;` to be ok yes.
Quoting myself, cargo has changed to this: &gt; **cargo package (used by cargo publish) will include all non-ignored untracked files in the working directory. Untidy crate authors will have to be careful!**
Static typing on the server side != architectural properties. 
Agreed.
What is the actual use of this example? The closure you return is always the same, so you could simply define it as const and return it from your function. The only way I could see where this is useful is to implement a trait that requires returning a closure.
FWIW, edn has been superseded by [Transit](https://github.com/cognitect/transit-format), which is basically the same model but it's encoded as json/msgpack instead of sexprs.
That version also suffers from the non-wrapping arithmetic issues. If you even instantiate the object in a test, you get panicked at 'arithmetic operation overflowed' That being said, I'd love for other people to use my version, and I plan to maintain it for as long as it is useful to me! When it stops being useful to me, but is useful to anyone else, I can transfer ownership at that point :-) Out of curiosity, what is your use case for faster hashing?
It looks like `regex_macros` is used only for [parsing a custom "hosts" file at startup](https://github.com/servo/servo/blob/49b73c0bfe50366e767525f9f90c5aa348f68f18/components/net/resource_task.rs#L151-L152) if one is passed through the `$HOST_FILE` environment variable. This code is normally used [only when running the W3C web-platform-tests suite](https://github.com/servo/servo/pull/5210). It would be easy to replace with dynamic regexes, and probably worth it to reduce code bloat and save a little time downloading and compiling dependencies. PR, anyone? :)
I see, how does your port fare against the C library?
&gt; That version also suffers from the non-wrapping arithmetic issues. Indeed it does, I have been compiling that crate in release mode to avoid the overflow checking. I was using it for generating locality sensitive hashes from vector projections for the purposes of streaming and batch anomaly detection. It is still more of a toolkit than a functional product, but it can be found here: https://github.com/rrichardson/blars 
Since I don't want to muck about with making bindings for the C library, this is harder for me to automate. To compare, I've just been using `time(1)` to time how long hashing files takes. For a 153973998 byte file... | | C | Rust | |--------------|------|------| | time (ms) | 41 | 46 | | speed (MB/s) | 3581 | 3192 | So the Rust version is about 89% of the C version. This is in line with my timings for a 1GB file of random data. I've optimized all the things obvious to me, and would appreciate anyone else taking a look at it! 
* Not sure why the disclaimer is relevant. * The DoS attack in question relies on the hash table using a non-cryptographic hash function. The default hash function is (hopefully) protected against it, but TwoX isn't.
Yeah, I was glad I (and others) could convince the rust gods to undo this mistake, too. Perhaps I should claim authorship then...
Sorry, I'll try to reword. You asked: &gt; What are non-cryptographic hash functions ever good for anyway? And the standard library says: &gt; cryptographic uses of this implementation are strongly discouraged. So I think for all intents and purposes, `SipHash` should be considered to be **non-cryptographic**. However, it does exist, so "for use in a `HashMap`" seems like an answer to your original question. If we accept that `SipHash` is non-cryptographic, then it is *my understanding* that it is the randomized initial keying of each `HasherState` that prevents DOS attacks or making approximations arbitrarily poor, as you mentioned in a sibling comment.
For what it's worth, there's some good discussion in this territory on the [hash simplification RFC](https://github.com/rust-lang/rfcs/pull/823). 
absolutely, but for authentication you need a MAC, not a simple hash function. There are tools that solve that too. But a quick checksum has its uses. (They are used in all kinds of protocols).
I know. That's why its usually reported as 1.5 (or 1.5x) speedup.
Even then I would rather read it's 50% faster or has 1.5x ops/t relative to old. This 'speedup' definition looks misleading to me. Then again, my day job is high performance java coding in statistical analysis. So you could say I'm (dons sunglasses) ... *biased*.
Of course. set_raw is for the dynamic cases, when you can't possibly know beforehand what header is used. Providing this was required so Servo could implement XHR.setRequestHeader().
Again, anyone can add a library to support whatever IPC protocol they want. Given the proliferation of IPC systems, blessing one particular one into the Rust standard library is unlikely to help very many people. Plus, even if you pick a particular protocol, there are several fundamentally different architectures for a library or framework to implement that protocol, each with different trade-offs, which are appropriate in different situations.
It's not that simple. You don't have the data to be fully defined to deserialize a part of it into a struct. At least that's the plan (https://github.com/serde-rs/serde/issues/44; https://github.com/serde-rs/serde/issues/60). #[derive(Deserialize)] struct Doc {name: String} let doc: Doc = try_s! (json::from_str (doc)); 
Pushing pointers into a list like this is trouble, if pane were to go out of scope you would have a dangling pointer in your list, this is why the compiler is complaining. If you really wanna solve it this way you will probably need `Rc` because you're gonna have shared mutable state. That's why I suggested a container that owns the panes and a flag which will be much easier to work with.
It is very possible that I answered this comment: &gt; But one library like Mojo maybe in the standard library for that developers would have other **standard** option for access to Rust code from outside. And not the original post. Just in case you missed that. Again: There are enough options for interfacing with rust. It is quite likely that the choice will be even greater in the future. However, the **standard** way of interfacing with Rust is and will always be its FFI.
http_replayer currently saves server replies locally. If you create a MockConnector with context "example", it will save replies in a file called ./fixtures/http_replayer/example.json, which you would put in version control.
I share shepmaster's concern that people might inadvertently upload a password file or a key file of some sort...
If rust is too "Hipstery" why are you in /r/rust ? 
Thanks Huon, the contrast/compare with C++11 closures is very useful! It has been interesting to watch Rust's evolution and to see where it ended up following a similar pattern to C++ and where it diverged.
Like I said, technical merit. First time I've seen a language with any kind of substructural typing achieve mainstream recognition.
Is this using "ignored" and "untracked" in the context of git? Or does Cargo have its own mechanisms for doing these things?
Because each function call returns a different Result type, I'd have to .map_err each function call to make the errors uniform with my outer function's return type. Not the end of the world, I reckon. 
&gt;Throwing around big words like substructural typing and paroxysm may seem like a nice defense to take when getting downvoted I don't give a shit about the downvotes, except maybe when it causes replies to get unnaturally snarky because Reddit. &gt;Rust doesn't really use substructural typing. *Mea culpa*. Technically, I meant that Rust was the first mainstream language to disallow [contraction](http://en.wikipedia.org/wiki/Structural_rule), but I didn't feel like looking up the exact terminology so I used what I thought was an umbrella term. (TIL - "nominative" type systems which disallow structural rules are actually not called "substructural".) &gt;Paroxysm is synonymous with "burst," " spasm," or "seizure." You're right, I meant paragon. My bad. &gt;And for the record, Node.js is not and has never been a programming language I don't think that's a useful distinction to make, because before Node.js Javascript was essentially a DSL. The "Javascript revolution" (ubiquitous SPAs, etc.) seems to be tightly related to the rise of Node.js.
Your commentary on Go and Rust sound a lot like a hipster's complaint that their favorite band is gaining popularity, and the new followers *just don't get it*;) edit: removed a paragraph, phrasing
Yes, it's the git terminology.
Interesting. Until just now I didn't even know of the `StructName { key: value, ..oldvalues }` syntax ... Good to know I guess.
I'm honestly confused as to why Cargo is honoring .gitignore files at all. Aren't we supposed to be VCS-agnostic?
Those intrinsics just allow you to divide and modulo by zero without panicking. Its only really useful for kernels.
Pretty similar. The C version reads into a 64KB and ingests that. The Rust version uses a `BufRead` which defaults to the same. I directly read from that buffer. Anything in specific you'd like me to look for?
I mean, *technically*, it could happen. The results would probably plop with a resounding "meh" imo. To take approximate algos as an example, they are almost always used when you need a fast path for performance reasons, and are willing to accept some degree of error. You won't be closing financial deals based on the answer an approximate algo gives you. Take bloom filter as an example. It quickly tells you if a value is inside of a set. It can also give false-positives. So in a hack that induces "false positives", the only thing that happens is degraded performance because the code has to perform extra lookups. In the "false negative" attack, you could make it so values are "invisible", which is potentially a problem. But neither are catastrophic, or leak data, or really mess anything up other than some extra CPU cycles burnt. Another thing to consider is that these algos are typically stochastic in nature. E.g. if you attack my HLL sketch, you need to induce bad hashes in all the registers that get averaged together. And the only thing you can do is increase the cardinality estimate upwards, since HLL can never "go back down". And any incoming input which hashes to a longer run will overwrite your "hack". So basically the only thing you can do is create a ridiculous cardinality, which most people immediately recognize is poor (especially since they are already watchful because approx algos are approximate) These algos are typically used for internal BI, where you need "roughly correct" answers quickly. They are ways to prune the work space so you can focus on certain areas with exact answers. I'm having a hard time imagining a nefarious plot that would somehow mess up an internal BI tool...maybe prevent your competitor from analyzer a certain market segment? I really dunno.
I'm not here to "win", I'm here for insightful discussion. I've already learned that I was misusing "paroxysm".
I am positively happy that concepts I like are gaining traction, but I'm less excited about the crowd it's gaining traction with.
This really feels like the wrong default to me.
You could also write your own `try!`-like macro: macro_rules! try_msg! { ($result:expr, $str:tt) =&gt; { match $result { Ok(x) =&gt; x, Err(e) =&gt; return Err(format!($str, e)), } } };
Well u know... Rust Is Kind Of A Big Deal.
It would be annoying to have to manually specify files in multiple places. There's no reason cargo can't also check for the equivalent files for hg, darcs, whatever.
It's very possible that you're trolling. Or failed to understand my comment. Possibly even both. In any event, feel free to write a mojo binding to rust. Or just hang in there until one crops up.
&gt; Yes, there is no 'unsafe block used in your repo That's exactly what it means. It's saying that the library will not increase the number of `unsafe` blocks, all else being equal. There's just no other reasonable interpretation IMO. We should all be careful to qualify our claims, but it can get tedious after a while. Hopefully a community norm will develop around phrases like "no unsafe code" to mean "no additional uses of `unsafe` from just this library, but maybe there are some dependencies of this library that use it and maybe this library is calling some functions that introduce new paths through `unsafe` blocks." It's valuable to say, "This code has no unsafe" because it's less code to audit. *All* programs pass through some `unsafe` block at some point, so there's really nothing to say about that.
Thank you for the clarification. My first interpretation is "Oh, this project don't have any 'unsafe' path"(BTW, I am still a newbie). And the "100% safe code" create a strong impression! After reading the std code and reference, I realized there are(still)a lot "unsafe" part of rust, and even the "safe" means something different which deserves a good definition in the reference book. So when I discover that it's almost impossible(correct me!) to declare a project is "100% safe code", as you pointed out, &gt;maybe there are some dependencies of this library that use it and maybe this library is calling some functions that introduce new paths through unsafe blocks. and &gt; It's valuable to say, "This code has no unsafe" because it's less code to audit. For me its just the opposite, I had trust the "safe" claim blindly util reach the vec.rs in std. Anyway thanks for all the cool stuff and great effort. I wish I could contribute sometime soon. 
I'm not sure what greater functionality is being extrapolated?
I'm not sure what the author meant but yes you can name a variable declared on the heap `let i = Box::new(5i32)` in C its something like`int *i = (int *)calloc(5, sizeof(int))`. And you should be reading the book found on the rust website, that one seems outdated.
DDoS it with a botnet coded in Rust ;)
What search phrase did you use to find this page, and in which search engine? It would be nice to know how broadly MIT is hosing us by serving ancient mirrors of our docs...
thanks 
 I need to make copies of x and y in the cons function? Or how do I make it so Cons doesn't want ownership?
I think the issue is you take the List by reference. If you take it by value (i.e. you move it) your function will work. http://is.gd/JUhuLf
There is at least one now: https://github.com/rust-lang/rust/issues/25264. I have also seen others in the past that have applied to iron, but I don't have links.
thanks!
I see that you have a few threads here now, if you have many questions then please take them to the IRC channel (https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;channel=%23rust) or Stack Overflow.
&gt; It doesn't seem like we can really do anything about that. We can 1. farm links to the rust book, and 2. petition MIT to update their site.
&gt; , but I'm less excited about the crowd it's gaining traction with. Wait, so *you're* the hipster? :-)
I'm learning rust and i really missed something like this. I'm not versed neither in rust nor in coffeescript, and i thought it would be a fun thing to do. Maybe somebody else can make use of it.
Ok, then: Everyone who has a blog or other site: Add as much (deep and relevant) following (without rel=nofollow) links to the official rust docs, so google will rate them higher. Also looking at the rust book (and having a talk with my friendly neighborhood SEO expert), we could improve our ranking with the following changes (which may require adding code to rustdoc): * Add `rel="next"`/`rel="previous"`/... to all navigation links, effectively making them semantic. * Add `rel="canonical"` to all links to implemented traits in the api docs. * Add more meta tags to the sites, especially the date-attribute (which could either be the build date or the date this particular doc was last updated) * Improve usability on mobile (e.g. viewport meta tag) Basically [#12466](https://github.com/rust-lang/rust/issues/12466), only more so.
Please don't, that's the whole point of the From trait.
Really? I'm subscribed to the rust tag, and by the time I get an email notification, most questions are already answered!
I guess the other way around it much harder? 
I'd be interested in contributing. I've been checking out Iron for doing some web stuff in Rust, and it would be awesome to have some long form documentation for it.
At the first, you should read rule #2, after of trying to understand all text in rule #1. 
Wow, that's... a really snobby sentiment. Thanks for implying that small contributions aren't worthwhile.
Except you cannot implement the `From` trait if the error you are returning isn't defined by you. In this case it would seem that you're returning a `Result&lt;_, String&gt;`, and you won't be able to implement `From` for `String`. I also disagree that this is "the whole point of the From trait" - `From` is designed for general conversion of types, not specifically the conversion of error types. EDIT: Also in some instances you want different error messages returned for the same error type in different situations. Again, `From` doesn't quite cut it.
It's good library design to have an own error type instead of using String, and therefore it's also good application design to have an own error type. If you want to show different error messages for the same error, then you have all the flexibilty with an own error type instead of using a String, just create different outputs of the same error.
Use the official docs, not that url: http://doc.rust-lang.org/1.0.0-beta.4/book/
It does say that it was previously moved here, implying the same place, but it might be nice if it said that was due to a looping construct.
&gt; I'm not sure what the author meant I wrote it, and re-reading it, I have no idea what I meant. This entire thing is gone now, so it's not a current issue, or I'd fix it.
This kind of library is _super_ useful to have. Awesome!
Why not? Rails is often plagued by poor performance (and that can be said about many Web frameworks). High performance should be a good reason to use Rust for making sites.
It's just that `for` loops leverage `IntoIterator` implementations if there are any. For example, `&amp;Vec` implements `IntoIterator`, so you take your vec and create a reference to it like this: `for x in &amp;vec { .. }`. It's not really a conversion, since you're making the value be a type that implements `IntoIterator`
you got your `[]`s and `()`s backwards
Unfortunately I'm on vacation for the next week, and I've not yet tested the data roaming, so I'm not sure if/when I'll be online. But if the problem persists, maybe I can take a stab the week after...
:) I know what that's like.
Sounds great! I'm `reem` on IRC and github, feel free to ping me in either place and we can chat.
Another note: the move &amp; use-after-move are the same expression because of the enclosing `loop { }` expression, but the error message can be ambiguous and seem like it is just missing the move line. I don't know how it could be clearer, but it isn't perfect. &amp; gosh, compounding it with the implicitly moving sugar really just makes this the most confusing error.
`x` is a variable of type `&amp;'a i32`, where `'a` is the lifetime that starts on the second line where `y` is borrowed, and ends where `x` goes out of scope. `&amp;v` is an expression with type `&amp;'b i32`, where `'b` is the lifetime that begins where `v` is borrowed on the fourth line and ends when the borrow goes out of scope. Since `'a` is not a subset of `'b`, you can't assign the a value of the second type to the a variable of the first type. You can however create a new variable to hold `&amp;v`, even one with the same name: let y = 32; let x = &amp;y; let v = 42; let x = &amp;v; println!("{}", *x);
I second the recommendation to head to IRC. I have asked more questions there than I can count and people still didn't seem to mind me much :)
Interesting, thanks.
&gt; Bitcoin Embassy How about yes -_-
Cool, I was wondering when a Kafka client was going to crop up! A couple of quick thoughts: * It would be worth noting with which version(s) of Kafka this client is compatible. I'm not sure about the underlying protocols, but the Java client API sees a lot of flux even between hotfix versions. * You might consider using the builder pattern to send messages so that some settings can have defaults. Something [like this](https://github.com/zslayton/stomp-rs#message-configuration). You can use reem's [Modifier](https://github.com/reem/rust-modifier) library or roll your own. 
Interesting! - (Builder pattern) I started Rust a week back so my knowledge about the ecosystem is quite weak. The client supports 0.8.x - I will update README to reflect that. 
Right, I was thinking of the web as a whole. No more using telnet to get web pages. We now need special software for it.
Doesn't cargo want to update its index before the first build ? That would still block any attempt to build - it's less of a problem for locally established repositories, but would be one for CI systems which start fresh all the time.
I believe it only tries to update if there are any dependencies from crates.io, projects with only git and path dependencies work without needing to hit the registry.
True ! And good to know ! I just found the [configuration](https://github.com/rust-lang/crates.io-index/blob/master/config.json) that determines where downloads are taken from - so if one would have a mirror of all crates, and could override the crates.io-index location cargo uses with a locally hosted one. It's all a huge guess though.
Dito !
Up here also (Germany)
&gt; were against using mirrors like any sane package manager Huh? Both rpm and deb (which are package mangers) can be pointed to mirrors. Debian, Ubuntu, SuSE, Fedora and CentOS for example make heavy use of that. But if the topic is more fucused, e.g. onto programmig language mirrors, then I'd like to point out that [CPAN also has mirrors](http://www.cpan.org/SITES.html).
The contrast in the code example makes the example hard to read. Give me eithe real black or real white. Or, at best, both. But not darkgrey on lightgray.
It's just easier to not oversell a particular implementation. SipHash (the function, not the std lib implementation of it) *is* intended to be a keyed cryptographic hash.
You shouldn't have to change your Cargo.toml to point into git URIs just because there's an outage. It's non-trivial to manually find git repository and tags that correspond exactly to the latest packages in crates.io.
Damn, you beat me to it! I was hoping I'd be one of the first people to try this. I've been wanting an excuse to learn Rust, and it would be a good project at home to show off technical skills since I can't share much from my job.
Important: note that it's on 18th, not 15th of May (ahh, schedules). See you there! PS. We're looking for speakers, as I hope these meetups will be held (semi)regularly.
Because the post was about the safety of code with underlying ```unsafe```.
Yes, I would imagine companies of Mozilla's size would eventually use an internal mirror rather than the public one. This also has really nice other effects too: for example, a few years back, Rubygems.org got hacked. We were able to take AT&amp;T's internal mirror, and double check the degree of the breakin, most gems were actually unaffected.
Why do pony binaries also depend on libc and libgcc like rust binaries do? Go doesn't depend on anything C related, except when using cgo and that's one of the beautiful things about it. No dependencies.
I'd go even further. I don't know how big a snapshot of all most recent crate versions would be, but having a local mirror for offline use would be quite nice as well.
Any ideas of where Rust is losing a bit of time?
That â€œyou couldnâ€™t hand code any betterâ€ part is clearly wrong. Many people can hand code better.
Minor typo: `__print_hash_i64(&amp;true);` should be `__print_hash_i64(&amp;12_i64);`
I'd have said that the `use` grammar was along the lines of Use:: "use" ({"super" "::"} | "self" "::") {ident "::"} (ident | "*" | "{" ident {"," ident } "}") (with{...} being 0..* repeated parts) But I did not know about `self` in globs yet. You never stop learning (especially not in Rust :P).
Abstract return types are one of the few features left that I really want Rust to have. HKT and streaming iterators would be neat, too.
I think the point is that anything you hand-code can be placed behind a trait abstraction, without adding any run-time overhead. Do you have a specific counter-example you're thinking of?
Fixed, thanks!
You're absolutely right; I updated the text to say "less ad hoc", matching the paper. (And I likewise wish there was some useful intermediate term, but oh well.)
What is a streaming iterator? I couldn't find that name specifically on Google.
https://www.reddit.com/r/rust/comments/303a09/looking_for_more_information_on_streaming/
I know a ton of people for which this is the answer. And it's true, we have been actively encouraging people to not use Rust until Friday. This question will hopefully see many more responses in a few months :)
Basically, it would allow calls to `Iterator::next()` to borrow the iterator in the return type, which isn't allowed in the current design of the `Iterator` trait. The best example I can give is one where I would need streaming iterators to make an API design work: https://github.com/cybergeek94/multipart/blob/master/src/server/mod.rs#L269 I haven't touched this repo in a while but I should really work on bringing it up to date. This was before `Iterator` had its output type changed from a type parameter to an associated type, but it still won't allow me to do what I *wanted* to do. I was trying to have the `impl Iterator for Multipart` yield a `(String, MultipartField&lt;'a&gt;)`, the latter of which would contain an `&amp;'a mut Multipart`. The goal here was to allow the user to iterate the fields of the multipart POST request by reading directly from the underlying HTTP stream to avoid copies and allocations. The returned reader would return EOF at the end of the field, and the next iteration would return a wrapper with the reader inside advanced to the start of the next field. However, `Iterator`'s output type can only have a lifetime parameterized to its own. This is fine for iterating over collections classes, such as `&amp;[T]`, `Vec`, and `HashMap`, where each element is expected to live *at least* as long as the collection itself. However, my use here would need each `MultipartField&lt;'a&gt;` to not outlive the borrow made by `Iterator::next()`. Ideally, I could implement `Iterator` like so: impl&lt;'a&gt; Iterator for Multipart&lt;'a&gt; { // Not sure if this is correct or currently possible type Output&lt;'b&gt; = (String, MultipartField&lt;'b&gt;); // Not allowed; cannot add type parameters to trait methods not defined on the trait fn next&lt;'b&gt;(&amp;'b mut self) -&gt; (String, MultipartField&lt;'b&gt;); } So each value yielded from `next` would have to be dropped before it can be called again. It is possible to work around this using `RefCell` but this use-case doesn't suit dynamic borrowing because it would actually be possible to express it statically. The problem is the current iterator design doesn't support it. So instead, I created the `Multipart::foreach_entry` function that can guarantee the borrow length. You can see it here: https://github.com/cybergeek94/multipart/blob/master/src/server/mod.rs#L130 Edit: the reddit link in that doc-comment was broken by some naive find-and-replace refactoring. Here is the fixed link: http://www.reddit.com/r/rust/comments/2lkk4i/concrete_lifetime_vs_bound_lifetime/ For more information, see this repository: https://github.com/emk/rust-streaming
Cargo caches the dependencies, so you can build it once online and then rebuild offline. I don't know how the cache gets purged, so this might be unreliable.
http://arewewebyet.com/
Let's invent one! How about "classy polymorphism"? Sounds about right, eh? (Too bad that "class" is a bit [ad hoc over]loaded term!)
FWIW, I'm a graduate student in a computationally intensive field, and I've written a bit of Rust research code. I'm much more productive than in C, and cargo makes maintaining builds on several machines easier than what I'd experienced with Python and a few C extensions.
GOOD library support (many libraries are UNSTABLE right now), GOOD documentation, a DEPENDABLE package manager (cargo IS NOT DEPENDABLE, as we've seen recently), and most importantly, the language should be PROVEN to be sufficient for real-world applications, not one-liner gimmicks.
I think things like servo and rustc would count as real-world applications, unless you use a significatly broader definition of "one-liner gimmick" :p Could you elaborate on your definition of 'proven'? The word often comes up when talking about new technologies but it could mean anything from 'It has been around for a year and is being used by a couple of companies' to 'One of these years we will reluctantly upgrade to the C99 standard'.
&gt; I'm arguing that this is a necessary penalty in almost all use cases. Well, some, but certainly not almost allâ€¦ A realistic range of ASCII keys, which is an extremely common use case, benefit immensely from the speedup, and a *lot* of the time they don't consist of user-provided input, and as such are not an attack vector.
Cool use of AFL, I've kinda wondered myself what using it on rust would be like. I curious to try it out in the future. Can you tell me more about how you're fuzzing? I'm writing a harness for AFL (to make distributed AFL fuzzing more interesting) and I'd love to hear about how long you've been running it between finding issues, etc.
&gt;I think things like servo and rustc would count as real-world applications Sorry but they don't for me - not in the sense "I want to build an application that will get distributed to 100.000 users and I want to know it will work without problems on 100 different hardware/software combinations" or "I have this use case that isn't at all related to rustc and servo so if I hit an issue I'm dead in the water unless I know how to debug the stdlib/compiler or someone in the IRC has mercy on me". Imagine hitting a problem you can't pinpoint on your own - in a language that a handful of people even know, let alone use in your problem domain (so forget about documentation/blog posts/stack overflow). I'm OK with that kind of stuff when I don't have any pressure on me to finish my project but when I need to build and ship shit I cannot deal with unreliable tools on top of solving the problems I need to solve. Rust is in the phase where early adopters can start playing around with it and working out the pain points up during initial library development - for people to use on their weekend projects like I intend to. Once I see initial Rust apps deployed in app store, distributed to end users, used on various linux distros it will mean that those use cases have at least been tested enough to get something working. I probably won't consider using it for work until the end of the year and it will take even longer until tools gets good enough that it will match stuff you expect like IDE support with code completion/refactoring/debugging that will actually make me productive with it. All of that is assuming the language picks up and doesn't end up in D state of having a small noisy community and being ignored by most. 
This is so cool! Have you tried running afl on rustc itself at all? I've thought about trying that but haven't gotten around to it yet.
Thanks Marwes! I will re-implement those methods
Hm, what's rather annoying? The fact that cargo doesn't need to touch the registry for projects with git/path deps?!?
A long time ago, it was determined that they'd be backwards compatible to add, and so the design was put off until post-1.0. Collections were designed with HKT in mind. That said, since it was put off, there hasn't been an actual design put forth yet. They're a feature that everyone wants, but until we have a design we're happy with, "for sure" seems a bit strong. The bigger debate, and what you might be thinking of, is `do` notation. Once you have HKT, you can have monads, and a generic `do`. There's debate over if that's useful or not.
If something isn't user-provided input, then it's probably known at compile-time, and in this case why the hell would you need to hash it?
AFL does not run unit tests. It feeds input into a program and intelligently tries to make it crash. Also, I'm focusing on testing Rust libraries, not the Rust compiler itself. That would be a separate process that I currently don't know how to do.
In the time since you wrote this, that issue has been fixed by using unwind::register. Seems like patching isn't necessary anymore?
It looks like you're right. I haven't tested it yet though.
Right. And QuickCheck tests a function as a black box, whereas afl uses binary instrumentation to detect when new control-flow edges are reached. (Though it also supports blind fuzzing.)
&gt; whereas afl uses binary instrumentation to detect when new control-flow edges are reached Wow. That's dang cool.
Why so much shouting? We're right here. You don't have to yell.
Trolls will be trolls
&gt; There's debate over if that's useful or not. How can it not be useful? IMHO, this is definitely the direction Rust needs to go to make it a viable option to languages like Haskell and Scala. Maybe that's not a goal for the Rust team, and if so, it would be shame because the Rust language has so much going for it in other aspects.
Michael Sproul has put [some](https://github.com/rust-lang/rust/pull/25062) great [effort](https://github.com/rust-lang/rust/pull/24884) into improving how we expose more detailed error explanations about compiler errors. These are the codes that appear in most error messages, e.g. [E0265](http://doc.rust-lang.org/error-index.html#E0265): constX: u8 = X; fn main() {} &amp;nbsp; &lt;anon&gt;:1:1: 1:17 error: recursive constant [E0265] &lt;anon&gt;:1 const X: u8 = X; fn main() {} ^~~~~~~~~~~~~~~~ &lt;anon&gt;:1:1: 1:17 help: pass `--explain E0265` to see a detailed explanation Despite the work of many great people, there's still lots of messages without more detailed explanations: [#24407](https://github.com/rust-lang/rust/issues/24407).
Thanks Huon :)
I bet adding `-Z extra-plugins` to the rustflags in the makefile would do this, though there might be version trouble (run the stage1 build with an afl-rs compiled with stage0, etc). It sounds like a major headache though, so kudos to anyone who tries! :D
`clone_inner` is, unfortunately, not safe in the presence of reference cycles (either through `Rc` or `Cell`). Since `T` may contain a reference to itself as a `MoveCell&lt;T&gt;`, its `Clone` impl can reference that `MoveCell&lt;T&gt;` and call `put`, invaliding the immutable borrow (in this case the `self` in the `Clone` impl) while it is still active. The rest is fine though. In this case, it's safe to replace `RefCell` with `UnsafeCell` here since a call to `take` can never occur while a call to `put` is occurring, and vice versa. You know it's safe to replace a `RefCell` with an `UnsafeCell` if you know that you can't cause a panic using the `RefCell`. EDIT: Argh ninjaed by /u/eddyb; just noting that we know their safe version of `clone_inner` is safe because it is composed of `take` and `put`, which, since we know they are safe, can only create a new safe API. 
Instead of implementing this from scratch, could you not just put an `Option` into a `Mutex`/`RefCell` to get the same functionality?
How does rust implement dynamic dispatch under the hood? In C++ it's done via vtable, in Haskell it's done by implicitly passing a dictionary. I suppose it's kinda similar to C++? Since rust's trait declarations are scattered across multiple files, does the compiler need to see all the declarations before assembling them into a vtable?
Basically it's a vtable, but unlike in C++, which has the pointer to the vtable inside the class, Rust uses fat pointers, which are basically structs of two pointers, one pointing to the concrete struct in memory, and another pointing to the vtable.
Unless I'm missing something, I believe the inner field is always visible to the outside, so the `UnsafeCell` can be directly accessed even outside the module containing the `MoveCell`. Is that expected?
No, because it's not `MoveCell&lt;T&gt;(pub UnsafeCell&lt;T&gt;)`. In documentation, it will appear opaque: `pub struct MoveCell&lt;T&gt;(_);` Attempts to access the field by tuple indexing will cause a compiler error. I tend to use tuple-structs for wrappers a lot more than other people might, because it makes the code more compact, and a struct with a single named field doesn't really add any useful information: pub struct MoveCell&lt;T&gt; { inner: UnsafeCell&lt;T&gt;, } That eats up three lines, and then three lines (conventionally) for each time it's instantiated directly within the module, but is it any more clear? I don't think so.
So, when can I turn on `rust-url`? ;D
The argument goes "it doesn't play nice with impertive control flow", which I personally don't understand. That said, given that we don't even have an HKT implementation in the first place, there hasn't been much concrete arguing about it yet. Also, the `mdo` crate already exists, but isn't very popular yet...
It'd be great to see a rust-aws-cli and lib, like boto for python
So you can internally implement it as an optioned mutex, and then expose an easier API, with zero usage of unsafe code :)
&gt; I don't know how it could be clearer, but it isn't perfect. Maybe we can detect that the spans are the same, and in such a case, have the text say something like "... was moved here (on a previous loop iteration) ..."
Actually, I'm not sure that this is a typo. Ampersands were actually born as a [ligature](https://en.wikipedia.org/wiki/Typographic_ligature) of the word "et," which is Latin for "and," a fact which this blog seems to emphasize by using a font with a more spread out version of the ampersand that more clearly demonstrates the combined "e" and "t." "etc" is short for "et cetera," Latin for "and the rest," so it makes sense to combine the first two letters into an ampersand.
Since you mentioned it, any new meetup planned?
Nah, a modified `RefCell&lt;Option&lt;T&gt;&gt;` using `take()` and `UnsafeCell` seems okay.
The author states that Rust is still slower than C++ at this point. Can someone explain why is this the case? Is it a matter of Rust overhead (which I understand should be zero) or is it just a matter of optimizing the standard library, etc?
Indeed, I prefer the older *&amp;c.* to the more contemporary *etc.* In my own writing I always use *&amp;c.*; the fact that the italic ampersand in Crimson demonstrates the history of the ampersand quite nicely is just a bonus.
Not everyone is going to like Rust. That's totally okay.
â€¦ oh. I did kinda just assume that would work; my C++ is rather weak. Any suggestions on what should go there instead? What would the idiomatic way of doing such a thing be?
As always it depends, specifically. We're also faster than C++ at times. Right now, we don't do much optimization of the IR we send off to LLVM, and just rely on it to optimize things. I'd imagine that we can get some gains here, as we have more information about things like `const`ness. See also: https://github.com/rust-lang/rust/issues?page=1&amp;q=is%3Aopen+is%3Aissue+label%3AA-codegen
I'm on mobile so I can't fully express this, but check out /u/ByronBates [google-apis-rs](https://github.com/Byron/google-apis-rs) (also one of the current threads in this subreddit). He would probably be a good person to talk to about such a thing since from a high level perspective that's what he did (although only with google services instead of aws).
&gt; Or you might just end up with a nightmare like "Vec&lt;Rc&lt;RefCell&lt;Box&lt;Trait&gt;&gt;&gt;&gt;" That's what scares me too ....
I dunno, this comes across somewhat as "you suck, stop trying". What about rule 2? :P Some of the complaints, abridged: * Since unsafe exists, Rust is no better than C++ for safety. * Safe Rust is not as fast as C++, so you need to write in unsafe, thus there's no point. * C++ has fuzzers and static checkers, and you can write tests. * Rust has five incompatible kinds of pointers (example is that you can't go from having pointers to the heap to pointers to the stack without changing types). * `Vec&lt;Rc&lt;RefCell&lt;Box&lt;Trait&gt;&gt;&gt;&gt;` * Rust doesn't insert the necessary `Rc`s and `Box`es for you. * Macros are a crutch and will prevent any good IDEs from existing. * "cargo actively encourages downloading packages directly from git repositories" * "C++ doesn't restrict programmers regarding what they can or cannot use." * Smart pointers aren't perfect. * No strict description of Rust's semantics. * "the source of troubles is usually in humans" * There are no Rust jobs. To be fair, a few of these are at least partially reasonable: Rust *should* be faster on idiomatic code, there *should* be a comprehensive definition of the language's semantics, and it'd be lovely for there to be lots of Rust jobs. :D
â€¦ how did I manage to forget that!? Itâ€™s a pity that it messes up the neat alignment of the six items it at full width, but these things are sent to try us and to test our fortitude. Thanks, updated.
&gt; Having the option for private registries is really important and also really useful. Even more so if they can defer/mirror/load from an upstream e.g. within a company, have a local Crates site with the company's private libraries, and when "unknown" libraries are requested go get those on the upstream crates site (and cache them locally). Complete mirroring upfront would likely become a bad idea in time as crates.io will essentially grow unbounded.
This should be `Vec&lt;Rc&lt;RefCell&lt;Trait&gt;&gt;&gt;` soon.
I don't think equivalent C++ code is possible in this case. You have to be more specific about the type. So, there is nothing reasonable one could show without making the example more concrete w.r.t what b and c are going to be. And if you don't have a name for this type, you could still use `decltype`. Silly example: vector&lt;int&gt; v = ...; decltype(v.begin()) iter; iter = v.begin(); A less silly C++11 version is, of course: vector&lt;int&gt; v = ...; auto iter = v.begin(); Here, `auto` is fine because we gave the compiler an initializing expression. And back in the old days, where we had neither `auto` nor `decltype` we wrote this: vector&lt;int&gt; v = ...; vector&lt;int&gt;::iterator iter = v.begin(); where `iterator` is a type alias defined in the vector class template to some implementation-specific type that ought to behave like a random access iterator. HTH
Exactly. I still love C++ (it was my first language), but I've really grown to love rust. Some of the reasons I like rust, this article lists as being bad things about rust (I'm a *huge* fan of metaprogramming/macros). The author of this article doesn't have to use rust for rust to be popular. The author is obviously fine with their current tool set and that's cool. C++ is a very mature language with a lot of tooling (although it can be argued that package management and lack of modules hurt C++) that is used widely though out the industry. I somewhat agree with the author's sentiment that many people who criticize C++ have never seen production C++ code, but only through anecdotal evidence and my own experience with the developers around me, but this doesn't seem to be a reason to pick C++ over rust. Rust has a lot of things out of the box that IMO make it much more friendly to people entering low-level style development. Rust may also have a certain level of verbosity to it, but the development team seems open to syntactic sugar that provides a very clear advantage, such as `if let`. There's also more than likely a large backlog of approved RFCs for various backwards compatible syntactic enhancements that will evolve rust in a direction that's not only fast, but has a low level of overall verbosity. It is a language that's 1.0 beta (entering 1.0 release) after all. It doesn't have the decades of design behind it like C and C++ do.
Apart from anything else I feel the author is really missing the potential of _guaranteed safe manual memory management_. I can definitely see where he's coming from on the other points, his is just the conservative stance, but not recognising the potential for memory safe, efficient, networked applications seems somewhat egregious.
&gt; I dunno, this comes across somewhat as "you suck, stop trying". What about rule 2? :P I believe that refers specifically to Reddit comments. This article could be a good source of discussion for what improvements Rust needs to target. But I do agree that it seems to be pretty horribly biased and pessimistic. How many of those items can be fixed and/or are planning to be fixed? Speed, autoboxing (via placement-new), more widespread usage of Crates and less dependency on GitHub, fixes to `Rc`, documentation improvements, job opportunities... The author, which isn't the person who posted this on that site, as it was translated from Russian, seems to be comparing Rust to C++ as if Rust has been around just as long and has done nothing with all that time. They never mention once that Rust hasn't even reached 1.0 yet. Their reasoning for C++'s incumbency almost seems circular; it's incumbent because nothing else has come along to overtake it, and nothing can overtake it because it's the incumbent. C++ is superior, Rust doesn't have a chance. We should all give up and learn to love the `.cpp`. So many of their arguments stand on very shaky ground. If they had taken their time, they could have produced an honest criticism of Rust that would have made for some pretty thought-provoking discussion. But as it stands, it just sounds like C++-monoglot FUD to me. I find it ironic that their final point against Rust is one of the major reasons Rust *exists*: &gt; I can't but remind you for one more time that **the source of troubles is usually in humans, not technology**. Their emphasis. 
The company that provided the translation makes a living selling software to debug C++ memory errors. That should provide some perspective on why they're not necessarily fans of Rust.
From my experience, if you have that kind of complexity then you're doing something wrong.
I can get behind this sentiment, and maybe I should have elaborated a bit more, but I'm trying to land as much docs as I can before 1.0 :) What I'm trying to say is this: I've seen language communities, especially newer ones where people are particularly passionate, essentially turn into... this is a bit strong, but mini-cults. Where if you don't like the language, you're obviously an illliterate pleb who needs to learn how to code. This ends up creating an insular, backwards, dangerous culture. I'd prefer a culture of "we're doing cool stuff, I hope you like it, but reasonable people may not, and that's okay." I'm not really speaking about any particular language here, please don't try to 'figure out who I'm talking about' or something. While it's true that the author may have only breifly tried Rust, and not tried to understand design choices, this is going to be the first of many, many blog posts like this as we grow after 1.0. The vast, vast majority of programmers haven't even tried Rust yet. Flamebait blog post titles are a standby of today's programmer culture. We shouldn't get too hung up on it, and instead, focus on doing cool stuff with the people who _do_ get it.
`type Thingies = Vec&lt;Rc&lt;RefCell&lt;Box&lt;ThingyTrait&gt;&gt;&gt;&gt;;` and pray to the gods of deref coercion ;)
The post contains mostly subjective ranting (mostly about performance) without much technical meat, but there are some points worth discussing: * Lack of libraries and tools. Sure, any new language is gonna have this problem, but Rust has very good interoperability with C so this alleviates the library problem substantially. And the build/packaging tools are better than what's typically used in C/C++ environments. In the IDE area, yes, more work is definitely needed, but C++ IDE's aren't that great compared to what's available for C# and Java for example. I would say there is more potential to writing a good IDE for Rust than for C++. * Performance is worse than C++ in the benchmark game. Might be true, but hardly a good measurement of real application performance. What's important is that Rust has the potential to achieve the same (or even better) performance than C++. * Dynamic memory/thread analyzers cannot replace static ones. They reduce runtime performance and increase memory usage, which means they are most likely not used in production, which means they will not stop all bugs (a static analyzer can always find all bugs in a certain category). And it's enough have one bug slip trough to have a security hole. This is the main point of Rust which the author seems to have missed totally. * The many-pointer-type section isn't really valid. In C++ the situation is basically the same, but with worse safety guarantees. * Yes, learn C/C++ if you want to find a developer job today. Pretty obvious point as Rust 1.0 isn't even released yet :) 
This is my biggest gripe with the article. It's amateurish, yet it pretends to be a "sceptical view of a great professional".
Since someone pinged me here. &gt; I expect at least things like s[9], s[0:9], s:[-2:-5], s.startswith(), s.find(), s.strip(), s.upper(). And yes, I want this all with unicode strings, we're living in the year 2015. That's a flawed assumption to make in the unicode world and it's a terrible idea that it appears to work that way in Python 3. There is no reasonable behaviour for most char by char processing unless you have defined your subset specifically. Rust currently has (I believe) the best Unicode handling of any of the new programming languages out there but it requires understanding Unicode. Python promotes a bizarre world which is not even correct. For instance Python cannot do proper character transforms largely because it thinks that a unicode string is indeed a list of charpoints which is wrong for most intents and purposes. For instance Python will transform "fuÃŸ" to "FUÃŸ" which is just wrong. &gt; And things like `let mut s = "Hello".to_string();` looks overly complex to me, as if strings where an afterthought The entire opposite is true! Strings in Rust are for once correctly implemented. Very few programming languages get that part right. Python for instance completely lacks rust strings in that Python strings can never be mutable. There are just various workarounds available. The example you gave is *not* what you wrote for Python. Python does not have an equivalent for this
Isn't one of the benefits that even if Rust isn't exactly as fast as C++ because of safety-related features (bounds checks, etc.), it's more forward-looking in that it lets programmers use parallelism much more easily and effectively? Hardware is trending toward many-core systems and that's where I see projects like Servo really shining. 
You forgot to call the closure.
&gt; Since unsafe exists, Rust is no better than C++ for safety. This argument frustrates me when I hear it, because I seem to hear it often these days. It makes it fairly clear that the author has not used Rust much, and does not know much about the design intentions behind it. `unsafe` allows the user to build up safe interfaces to unsafe implementations - it's what makes Rust *work*. Without it the language would be awful to use. Just because it's there doesn't mean people are going to write entire programs in it.
Hm, could you clarify a bit why that is so? Couldn't IDE provide macro expansion similar to `rustc` command? 
&gt; &gt; Macros ... will prevent any good IDEs from existing What I found hilarious is that this is somehow more of a problem for Rust than it is for C++. I guess it's easier to write an IDE for a macro system that is completely independent of the language grammar and can expand to completely arbitrary token sequences... ...though syntax extensions are, obviously, a *big* potential problem. 
Actually, /u/afiskon *is* the author, it's the translation that's not his.
Right, fixed!
As much I agree with this, isn't situation with macros in C and C++ much worse? There, they are untyped, have uncontrollable side effects, and can silently replace keywords or identifiers that are previously introduced. Still, some IDEs exist, and they're not very bad. Rust will get at least to this level of tooling quality, I believe.
&gt; What I found hilarious is that this is somehow more of a problem for Rust than it is for C++. Well, I wouldn't agree with that, and I don't recall if the article was suggesting that it was or not. I only mean that it's enough. C++ is 9th circle of hell for tooling, but even C is excruciatingly painful. Rust can better than them both and still be so difficult it won't get to Java levels of awesome tools. My own bias is that I lament almost all programming language designers for seemingly caring nothing for tooling beyond (maybe) their compilers. It's hardly unique to Rust, unfortunately.
&gt; I don't recall if the article was suggesting that it was or not. Given the tone of the rest of the article, and that the complaint wasn't qualified with "although C++ is as bad/worse", I think it's reasonable to take it as a directed criticism of Rust *compared to C++*.
Well, just for reference: this is the original http://eax.me/cpp-will-never-die/ And there's a link to @afiskon Twitter on the right.
Sure. The first issue is that it becomes impossible to understand a file on its own terms. To obtain a parse tree, it no longer suffices to simply have a text file you look at, but you now also need to chase down dependencies (potentially a lot of them!) to find out what the definitions of macros are, and THEN you can get a parse tree, after doing some evaluation. It's a vastly more complicated and involved process. With Java, you just parse the file. Done. It can be a string that exists nowhere in the file system, and it can reference things that don't even exist, you can still parse it just fine. Then there are kinds of things you actually want tooling to do. For instance, consider this bit of (contrived) C code (as I'm better able to whip up an example with that than with Rust off the top of my head here): #define AWFUL(x) c_##x int foo(int c_y) { return AWFUL(y); } You come to your IDE, and ask it to do a rename operation on the argument to the function. What on earth should fucking happen? There's no real option but to fail here. So now you have to figure out when to fail. And then your rename refactoring is fragile, doesn't work half the time, and forget it, programmers will never get in the habit of trying to use it anyway. (And in fact, there are more issues with C here that make this worse: like trying to figure out what prototype in a .h corresponds to this, to complete the renaming, which is also hell. But Rust avoids that, I'm pretty sure.) These are extremely hard problems for any sort of macro system. I've worked on macro systems in the past, and I still don't know of a good way to solve them. &gt; Couldn't IDE provide macro expansion similar to rustc command? Yeah, no problem. It's not that working with macros is hard, it's that macros make all the other things you want to do hard. I hope this is informative and doesn't look like a rant. :)
Ah, I see where you're coming from. Yeah, I don't think C++ fans should be throwing stones about Rust's macros. :) I just think it's a big missed opportunity.
Sure it is, there's less heap allocations and indirections. It's also entirely possible to have `Vec&lt;Rc&lt;Trait&gt;&gt;` and use interior mutability in the types behind the traits objects. At that point, how would you shorten it, `[@Trait]`?
The article was about nested structures, Vec&lt;Rc&lt;RefCell&lt;Trait&gt;&gt;&gt; is still an ugly mess.
As far as I can tell, he's not even a C++ person. His main job has to do with Scala and Erlang, looking at the blog.
Well, if you have a strict macro/non-macro distinction (in Rust, each macro invocation is with `!` at the end of macro name), I think it gets much easier.
I think Rust's particular form of macros can limit the effect they have on IDEs- macro invocations are clearly separated from normal code. Further, a lot of standard macros can easily be handled by an IDE- vec!, try!, etc would be no different to handle as language features.
Yes, this is probably the best hope. Limit macros to the standard library (by culture, best practice, style guide, or even default compiler warning), and then simply write explicit handling for all of those in your tooling. This would not be a bad situation (assuming there aren't a huge number of macros in the std lib already, I don't actually know.) It's just a question of, will that happen?
Is it worse than `vector&lt;shared_ptr&lt;const Class&gt;&gt;`? Same thing (with RefCell switched to const because that's C++'s non-default)
Well, depending on Rust's future (which, alas, no one but time can tell) it may actually a better idea to learn Rust today, because when you're done, Rust is the hot shit :) But if Rust fails to get major attention, it obviously isn't. (Even though I'd say that, as a language, C++ is easier to learn than Rust is, if you know the other. The ecosystem is a whole different beast obviously)
I'm currently using it to write some log parsing tools for use with haproxy. Mostly just to get my feet wet with the language, but we'll likely end up using it to replace some more primitive tools I wrote a while ago in C for the same purpose.
Your lli version is mismatched with the version of LLVM that rustc uses. Your version doesn't understand the `dereferenceable` attribute. Additionally, LLVM IR is **not** portable.
Rust's macros are hygienic, so renaming should be less of a problem (although resolution isn't hygienic so you can still kind-of have that problem). And you can still parse code while ignoring macros (you can still miss all macro-generated macros, but that's no different from missing some files).
&gt;Just because it's there doesn't mean people are going to write entire programs in it. For instance: I've written entire college level assignment (a small game, a 2D puzzle platformer) in Rust. My game is only ~3500 lines of code, but game engines are also known for being pretty gnarly. A quick grep shows that I haven't used the `unsafe` keyword at all, across the entire codebase. Of course my game sits atop libraries with mountains of unsafe code. Hell I've even submitted patches that touch unsafe blocks in `rust-sdl2`... but that code was easy to find and fix _precisely because_ it was in an `unsafe {}` block! --- As a further aside: this game has never once segfaulted, and I've made _plenty_ of boneheaded mistakes. Its static guarantees have made me one very, very happy programmer.
When I wrote [the Rustacean learning Go post](http://www.polyglotweekly.com/2015/04/24/thoughts-of-a-rustacean-learning-go.html) I was from a similar background, which was why I tried to explicitly acknowledge that. A number of my complaints turned out to be invalid in the face of stuff I learned through feedback, and most of them were things that gophers aren't worried about due to the different mindset of programming (which is more Java-y than C++-y). When I read this post I got that same vibe; the vibe I got whilst writing that article; that the author is very new to Rust and is making conclusions based on very limited/superficial experiences. I was saddened that that wasn't acknowledged by the author (unless I'm wrong!); but /u/steveklabnik1 is right; we shouldn't get too hung up on it and work on being awesome instead! :D
Looks nice. Im still juggling back and forth between Atom and Sublime, right now using Sublime. Glad to see more Rust love on Atom though.
I would recommend removing "This error indicates" from these descriptions.
Happy cake day!
&gt; For instance Python will transform "fuÃŸ" to "FUÃŸ" which is just wrong. Well, maybe you inform yourself before claiming such things. holger:/home/schurig# python3.4 Python 3.4.2 (default, Dec 27 2014, 19:25:25) [GCC 4.9.2] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; u"fuÃŸ".upper() 'FUSS' From a german point of view, this is correct. Despite that technically there is some german upper case sharp s in unicode, no one knows it and uses it. &gt; The entire opposite is true This is in the eye of the beholder. auto s = QString("FuÃŸ"); looks much nicer for me (with the source-code in UTF-8, as it is now usual since some years in Linux). I am a lazy git, i don't want to type characters over characters for things where I assume a compile should be sane enought to find it out for me. 
So happy to see this materializing.
If macros were the only issue in C++... ... remember than C++ is not LL(n), C++'s grammar is horrid, and a loopback has to exist so the parser can query semantic analysis during the parsing phase in order to correctly understand the file. - A primitive version of a Rust IDE can use the grammar and ignore macro invocations. - There is no well working of primitive versions of C++ IDE; Eclipse is rather full-featured and its parser is *still* insufficient for all C++ cases (mix in pre-processor programming and meta-template programming, watch the resulting squigly red lines) to no fault of their own, C++'s grammar is just that hard.
This is basically correct, though I think you're being a bit pessamistic about acceptance. With 1.0 landing this week, now is the time to start looking at features that were posponed, and an RFC would be a great start toward this end.
I haven't seen much discussion of it, but this book is going to be released soon. Could be worth a look for newbies!
I like to say that if you look at the mission statement, Rust has been the same language for eight years. If you look at the feature set, Rust has been like four different langauges over its lifetime.
As a Rust newbie I was trying to get my head around lifetimes for some time now. Now it seems clear as day. Thanks a lot for this great article.
Sorry for the confusion. To create a language that can have tooling as good as the Java ecosystem. (My contention is that macros fundamentally prevent this.)
&gt; Eclipse knows how to expand C/C++ pre-processor macros and mostly deal with their consequences (which probably took the CDE guys a lot of pain implementing) For what it's worth, you might want to actually look into this. I posted a little example in the thread below (granted, that sort of example is resolved by hygiene in Rust. Well... is supposed to be resolved, but the existence of $crate leads me to believe isn't actually...) But "a lot of pain implementing" in CDE gets us a refactoring that just refuses to apply to that function parameter because it has no idea what to do. It gets us a refactoring that, when applied to a second parameter that is more normally referenced by a macro (without involving ##), will happily take a working program and transform it into a broken one. And then its compiler will report the resulting error in a confusing location. Macros don't just make all tooling harder, they make some tooling fundamentally impossible to get 100%, which no amount of effort can fix. That's why I don't like them. I think it's important for tooling to be easy and 100% effective.
Something like `Vec&lt;Rc&lt;RefCell&lt;Trait&gt;&gt;&gt;` is rare in Rust. You probably do not need a list of Refcounted pointers with interior mutability to a trait object. Also, Rust has never said anything about being concise, as Rust is about writing Rusty programs, programs that will last and that are easily understandable. `Vec&lt;Rc&lt;RefCell&lt;Trait&gt;&gt;&gt;` clearly says what is happening, and I love that. If you want a concise language, stick with Ruby.
&gt; LLVM IR is not portable. Could you please elaborate on this subject? I thought it was desigend to be?
For just a taste of the kind of issues that could crop up, see [this earlier discussion on default type parameters](https://github.com/rust-lang/rfcs/pull/213). (Neither claiming this in particular will be a big issue, nor that it will be the only one - just the kind of thing.) I suspect most of the trickiness and thorny problems are of the kind which will become apparent once someone actually starts trying to specify in detail how it all should work. (It's *possible* that it will all turn out to mesh smoothly and orthogonally and there will be no major difficulties whatsoever, but my feeling - and this is *just* a feeling - is that this probably won't be the case.) EDIT: To try to answer concrete questions: &gt; Is it difficult to get sane semantics because of lifetime parameters? Don't think so, at least not directly. From the perspective of HKT lifetimes are just another kind. Subtyping and variance (arising from lifetimes) may be a problem, however. &gt; Or because of the proliferation of built-in 'tag types' like `Sized` and `Copy`? Don't think `Copy` would interact much - `Sized` might be more interesting. Do you have anything in particular in mind? &gt; Or generating zero-overhead code? This shouldn't be an issue. Even C++ has a form of HKT (template template parameters).
&gt; As much I agree with this, isn't situation with macros in C and C++ much worse? At least C/C++ people widely agree that non-trivial macros are generally a bad idea. In Rust, macros seem to be go-to solutions for all kinds of problems. Macros doing complex thing are already quite more common in Rust than in C++, and I can only imagine it's going to get much more in the future.
Sure. That's niko's thoughts on what he would like to work on. Someone else leading the HKT charge would move that up, at least as far as I'm concerned.
No, it's not really designed to be portable: [LLVM IR is a compiler IR](http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-October/043719.html)
&gt; My own bias is that I lament almost all programming language designers for seemingly caring nothing for tooling beyond (maybe) their compilers. It's hardly unique to Rust, unfortunately. Excellent point, there are so many features that many consider "external" to a language or language ecosystem: a REPL, testing facilities (including mocks), instrumentation, reflection, package and build tools, etc. I absolutely hate that you need header files with C and C++. Header files are an optimization for the compilers and compiler writers, not the users. 
&gt; What's important is that Rust has the potential to achieve the same (or even better) performance than C++. What in Rust would give potential for better performance than C++? Also there clearly are parts of the language where Rust *doesn't* have potential for equal performance (anything requiring runtime safety checks). There Rust is, by design, slower than C++; the costs are unavoidable if you also want Rusts dominating feature, safety. Yet concerns about performance are only met with the label "subjective ranting", where some critical discussion would be incredibly more useful. I mean, how much slower would sorting an array with safe code be, for example. Does anybody know? Doesn't seem to ever be discussed, at least not in this subreddit.
Ah, it was skylight, and you're right their monitoring service is what they wrote in rust. Thank you.
&gt; . but that code was easy to find and fix precisely because it was in an unsafe {} block! Exactly! ```unsafe``` makes bugs grep'able.
Its hard to explain something to someone when their job depends on not understanding it. 
I disagree with idea that "unsafe" should be considered "ok". I like to see proud lines like this one: https://github.com/iron/iron#overview &gt; Iron is 100% safe code And @mrmacky gives good example also.
Agreeing on them being bad still doesn't mean people don't use them. Every complex project is full of them.
C++ and Java IDE features are not comparable.
For more than one child, you'd need a list like a `Vec`. If you require mutability, you'd need the `RefCell`. So you'd still end up with `Vec&lt;Rc&lt;RefCell&lt;Node&lt;T&gt;&gt;&gt;&gt;` for a generic node. You can see an implementation of this here (though it uses a linked list instead): https://github.com/SimonSapin/rust-forest/blob/513168f7998835efc06b799a1ba66ec09ac5dc9a/rctree/lib.rs#L9-L27
3.6 or maybe a development version around then.
Looks like the code samples are up on Github: https://github.com/Ivo-Balbaert/start_rust I hope it's better than most of Packt's books, most of which are of dubious quality. I've personally be asked to write (or review) books for Packt on subjects which I'm an absolute beginner, simply because my email was harvested off of some project's public email list where I was asking a question. Packt's approach seems to be quantity over quality. If you do a quick google you can find lots of people complaining about the quality of their books.
Racket's trick is that it's dynamically typed (typed racket doesn't matter), has totally hygienic macros, and doesn't try to build more than the bare-bones basics of tooling. The dynamism matters, because that precludes many kinds of tools you could build for a statically typed language, so you don't even get as far as considering what roadblock macros present. Hygiene means the macro system has taken specific effort to preserve name binding, so name binding problems are out. The trouble is everything else. I completely believe that Rust limits macros enough that we will be able to do renaming and move (if it's hygienic), highlighting, find definition, and that sort of thing. I'm curious why everyone keeps saying it's hygienic though. This prints 7 for me: #[macro_use] mod baz { const X : i32 = 6; macro_rules! foo { () =&gt; (X) } } const X : i32 = 7; fn main() { println!("The value {}", foo!() ); } Anyway. Just a simple little example of a refactoring that doesn't work on macros. Hygiene is specifically for name binding, so let's look at anything type-directed. Suppose I want to refactor a specific pair type into a named struct instead. (umm, `(FirstName, LastName)` into `Name` upon discovering maybe that wasn't a good idea. Thankfully, I have defined types like `FirstName`, so it's pretty unambiguous where this should change.) For functions, we choose what to do based on the type signature. Does the function operate on `(FirstName, LastName)`? Then now it operates on `Name`. Is it parameterized? Leave it as pairs, and uses of it on `Name` will involve wrapping/unwrapping its arguments. We can recognize certain special functions on pairs, and automatically do the right thing for them. What do we do for macros? We can either: 1. Always treat it like they're parameterized, and do the wrapping/unwrapping. But this is likely very annoyingly wrong, and programmers are upset with you that your refactoring just made everything worse. 2. Always expand the macro and do the rewriting. But then this is likely very annoyingly wrong, and programmers are upset with you that your refactoring just made everything worse. 3. Always change the macro definition body itself. But it may be applied to other types, too, and programmers are upset with you that your refactoring just broke their programs. 4. Try to be smart and pick one of the above. You'll never get it right. Programmers are upset. etc, etc. 5. Special case some macros to work correctly, and totally fail in the presence of any others. Programmers have used others, etc, upset, yadda. Hygiene makes name binding okay, but then there's types. Typed macros? Okay, then there's all kinds of dataflow analysis. And so on. Eesh, this was long. Sorry, was trying to be specific.
&gt; Many checks can be elided by using the proper structures, for example, iterators remove the need for most array access bounds checks. But what if I don't want to treat my array as a linked list? Depending on what you're trying to do, access to array indexes can still be much more practical than iterators. Unless you claim that iterators are always the only useful way to access an array, the question for speed of indexed array access is still interesting. If things like that are completely omitted every time someone talks about performance it ends up looking like hollow marketing, more interested in making shaky promises than giving solid information. Having some benchmarks or some other facts would be incredibly more useful.
&gt; This is a huge mass of fast, debugged, and time-proven code. Like OpenSSL.
I was wondering: if you have a function like fn access_array&lt;T: Copy&gt;(arr: &amp;[T; 32], idx: usize) -&gt; T { arr[idx % 32] } , would rustc/ LLVM be smart enough to drop the bound checks after optimizations? 
Exactly this. The explicit nature and strictness of the type system makes it so much easier to follow what happens in code you do not know very well. It makes code easier to understand locally.
I don't know, to be honest.
There are some other things to consider when deciding whether to go with a garbage collected language or not. I am by no means an expert, but in many GC languages, such as Java, you do not have control over when garbage collection happens. This may introduce unwanted latency. You also need a run time, which makes your language unsuitable for embedded applications or kernels. Most importantly, I think, is that rust should, in theory, be as fast as C. There are still some codegen issues, but there's no reason why it shouldn't be as fast in the future. Remember that Java wasn't nearly as fast five years ago as it is now either.
Here's a real world example of a C++ performance gotcha. I wrote a loop that was essentially: void combine(vector&lt;uint8_t&gt;&amp; dst, const vector&lt;uint8_t&gt;&amp; src) { for (size_t i = 0; i &lt; src.size(); i++) { dst[i] = std::max(dst[i], src[i]); } } Overly conservative alias analysis killed performance, because uint8_t has special-case rules (it wouldn't happen for larger ints). I only discovered it because I looked at the asm. Rust of course does not have this problem.
`Rc&lt;RefCell&lt;T&gt;&gt;` is one of the easier ways to do arbitrary graphs, albeit with the risk of creating reference cycles. At that point, you might have a `Node&lt;T&gt;` type that contains `edges: Vec&lt;Rc&lt;RefCell&lt;Node&lt;T&gt;&gt;&gt;&gt;`, and there you go. Of course, you could do something like `type Node&lt;T&gt; = Rc&lt;RefCell&lt;NodeBody&lt;T&gt;&gt;&gt;` and clean it up a bit. But the point is, `RefCell` within an `Rc` is useful in perfectly legitimate ways.
JavaScript is the most popular programming language in the world. Not C. Not C++. JavaScript. It was written in two weeks, and the tooling still sucks. To give up on Rust because it is not as popular or as much of a standard as C or C++ is stupid. To give up because the tooling isn't as good is stupid. If the C++ devs gave up on tooling they would have nothing today. I would not write a large application in Rust today. It is simply not ready. I might write a small tool and possibly port a library. This is how the ecosystem grows. They criticize Rust because it competes with their core product - a c/c++ static analyzer. 
&gt; what's the biggest conceptual issue with implementing HKT in Rust I'm on the side of hoping it not coming at all or not any time soon. I have a hard time imagining it contributing in a good way for API design in Rust. The language already is really complex and sometimes hard to understanding, HKTs will most likely not help.
I opened a few issues on the first few chapters. Hard to tell without the text!
http://doc.rust-lang.org/nightly/std/iter/trait.RandomAccessIterator.html (I haven't double checked what kinds of bounds it can do, my point is that not every single iterator moves onto some sort of specific 'next' item.)
Very little to be honest partially because I sometimes already feel quite lost about all the `Deref` that is going on. I think we should see for the next few months about what patterns emerge around the types that implement `Deref`. I would not be surprised if this sort of stuff becomes an antipattern sooner or later. What practical usecase would an abstraction over those types actually give you?
Why are macros needed?
We'll see. :) I haven't written a ton of code that would need that, as I try to stay away from Rc as much as possible, it's just one example of where HKT would be helpful as an abstraction.
They're convenient and allow for wide-ranging, elegant abstraction. I could also go into things like conditional compilation. As with any language feature there is a trade-off between the benefits of having another axis along which to abstract code vs the added complexity.
I don't see how that could be any more efficient that directly accessing an array by index. So it doesn't really help that it has "iterator" in it's name.
That is pretty sweet indeed! It implemented the modulo operation as a bitwise and because 32 is a power of two, too. Neat.
&gt; I'm curious why everyone keeps saying it's hygienic though Macros are hygienic with respect to local variables, but not global items. Improving that part of hygiene is one of the desirable features for a new macro-rules system.
This explains everything.
I am looking for Effective Rust Programming or Advance Rust Programming. For basics, rust documentation and Rust by Example are good enough.
It looks like he learned Rust just to write this book.
It's not nice to circumvent the compiler's protections like this, but yes, this code looks good. I'd prefer designing it so that `run_it` is `unsafe` and the `transmute` happens inside of it, since that gives a better description about what part of it really could go wrong. In the near future (or if you're using nightlies), you'll be able to use [`thread::scoped`](http://doc.rust-lang.org/1.0.0-beta.4/std/thread/fn.scoped.html) instead of `thread::spawn` to run a thread with a closure that captures non-static data.
It seems like you want to recreate [`scoped`](http://static.rust-lang.org/doc/master/std/thread/fn.scoped.html) functionality, which was recently destabilized. Your particular usecase seems to be safe, but it's easy to create race condition by modyfying only safe code here: Rust won't prevent you from modifying `x` from main thread, which can lead to undefined behaviour. It would be better if unsafety was hidden behind some safe interface. If you can afford to use nightly, I would advise you to just use `scoped` (it was proven [unsound](https://github.com/rust-lang/rust/issues/24292), but you have to try really hard to "break" it). By the way, it would be better to just use a handle returned by `spawn` and `join()` on that instead of creating a channel.
Hmm, I'm not sure I follow about moving the `transmute` into `run_it`. The only place way this transmute is "safe" is if the transmuter knows the new (transmuted) closure will be called before the old (transmutee?) closure goes out of scope. I'm aware of `thread::scoped`, but it's not feasible for my actual use case. I need to hand a closure off to iOS for it to run on its main thread (via `dispatch_async` off in Objective-C land).
The `DecodeResult` example confused me, and I think it isn't quite right. First, to allow the stated use case (reading values from a buffer and storing the decoded values, which still contain references to parts of the original buffer, into a vector) you want `'buf: 'decoded`, not `'decoded: 'buf`. `'decoded: 'buf` means the vector is allowed to outlive the buffer--but that would mean the vector couldn't safely have references into the buffer. I think what you meant was the other way around--the *buffer* must live at least as long as the *vector*, and possibly longer. Second, regardless of which direction the constraint is pointing, I don't think putting the lifetime constraint on the struct has any effect at all. This code compiles fine: struct DecodeResult&lt;'buf, 'decoded: 'buf, T: 'decoded&gt; { buffer: &amp;'buf [u8], decoded: &amp;'decoded mut Vec&lt;T&gt;, } fn this_compiles() { let buf = [1, 2, 3, 4, 5]; { let mut v = vec![&amp;buf[0],&amp;buf[1]]; let _ = DecodeResult{buffer:&amp;buf,decoded: &amp;mut v}; } } fn so_does_this() { let mut v = Vec::&lt;&amp;u8&gt;::new(); { let buf = [1, 2, 3, 4, 5]; let _ = DecodeResult{buffer:&amp;buf,decoded: &amp;mut v}; } } You can see it's possible to construct a `DecodeResult` regardless of whether the buffer outlives the vector or the vector outlives the buffer. Both lifetimes are already constrained to be at least the lifetime of the `DecodeResult` itself, and needn't be any bigger, so the lifetimes are effectively the same and the constraint `'decoded: 'buf` is always satisfied. It's easy to write a *function* that requires this type of lifetime constraint: fn use_dcr&lt;'buf,'decoded&gt;(dcr:&amp;mut DecodeResult&lt;'buf,'decoded,&amp;'decoded u8&gt;) { dcr.decoded.push(&amp;dcr.buffer[0]); } but the constraint being on the struct still doesn't have any effect here--if that same constraint isn't also specified on the function, it won't compile, whereas it compiles just fine if you leave it on the function but remove it from the struct. Heck, you can even leave the opposite constraint (`'decoded: 'buf`) on the struct and it still compiles just fine. [Link to the code above on playpen](http://is.gd/bwKL14) Sorry that this wrecks the nice conciseness of the example.
Ah, thank you so much! I totally over thought it. :) use std::collections::HashMap; struct A { a: HashMap&lt;String, String&gt; } trait B { fn do_something(&amp;mut self) { self.get_a().insert("hello".to_string(), "there".to_string()); } fn get_a(&amp;mut self) -&gt; &amp;mut HashMap&lt;String, String&gt;; } impl B for A { fn get_a(&amp;mut self) -&gt; &amp;mut HashMap&lt;String, String&gt; { &amp;mut self.a } }
He seems to aim for consistency with 1.0. That is a good thing. https://github.com/Ivo-Balbaert/start_rust/commits/master
&gt; pretty horribly biased and pessimistic I guess you've never met the Russians.
Sounds like a good idea. I wonder how long will it take to get something up and running.
&gt; Java has far and away the best tooling of languages out there To add emphasis this is true of C# as well, for very similar reasons.
Which is written in C, not C++.
The whole discussion around whether introducing type lambdas of some sort creates a problem in determining the proper type constructor to infer seems like it can easily be made a non-issue. Let's say that for a type `M` to be used as a first-class HKT, `M&lt;T&gt;` needs to implement `HKT&lt;T&gt;` (or `HKT&lt;(T, U, ...)&gt;` if you want to allow first-class HKTs with multiple type parameters). Writing a "type lambda" would thus be equivalent to writing an impl that accomplishes this, which, due to coherence rules, needs to be unique for every concrete type. This means that the "type constructor" is conceptually an associated type of `HKT&lt;T&gt;` which can be uniquely determined given any instantiation of that `HKT`. It follows from this model that any convenience syntax that moved these details into the background would basically have to ensure that, for any given type, there is only one first-class type constructor that can be used to construct it.
Maybe C++ is different, but my experience with "production code" is "we had to make it work / ship something", with hacks upon hacks. I'd expect research projects could spend more making the code correct. 
wonderful as always :)
While I haven't ever used Arch, and don't have experience with it's package manager, rustc is kind of useless for making anything more than small test programs without cargo. Coming up to rust 1.0, more and more of the stdlib has been moved into crates so that they can remain unstable but still usable, and the go-to functionality for a lot of problems is in small crates on crates.io. It's kind of impossible (at the moment, and this likely won't change) to program effectively in rust without cargo. At the moment, nightly cargo works fine with the beta version of rust AFAIK, although this may not be true in the future.
Are you sure? Looks the same size it's always been to me.
Maybe it will continue expanding until rusts release, then it will do something nice like transform into a Victoria secrets model or something.
Citation needed.
The article kept referring to "C/C++".
Majora's Mask has a 3 day countdown to the horrendous event that will bring death to everyone.. I mean, that's totally like releasing the 1.0 version of a software, right?
Ugly stuff happens, we can't prevent it outright. When it happens we can acknowledge our faults and strive to do better. What could be more realistic than that?
Damnit, where's the bloody ocarina when you need it...
This package reminds me about my idea that in Cargo all the package names should have two parts: user/package This way there can be multiple package of the same name, and we could reserve some user names in advance (like std, rust, servo, etc.) Anyway, interesting package!
Probably nothing to worry about.
Sure, but that unsafe code is not in iron itself, so if there are memory safety bugs, its not irons fault if it suffers from them and hence iron "on its own" is 100% memory safe. Any other definition like that will just declare everything as always being unsafe, since there will always be something equivalent to unsafe blocks far enough down - if not in the std library, then in the sense that the compiler itself produces one big blob of unsafe code while talking to llvm.
&lt;3 this is awesome!
I'm still torn between [Freddy Mercury](http://images2.fanpop.com/image/photos/13600000/Freddie-Mercury-freddie-mercury-13661123-650-976.jpg) and [young Robert De Niro](http://www.filmoria.co.uk/wp-content/uploads/2012/05/robert-de-niro-the-godfather.gif), honestly.
I agree that plain indexing often necessary, and it's true that in the worst case this has a performance overhead due to the bound checks. However, its also a fact that Rust heavily relies on llvm for optimization, so the naive code generation is usually not what gets output in the end, so its not really all that bad in practice. Something like C-style-for-loop indexing for example will most likely result in the additional bound checks getting eliminated. Sadly, due to llvm being complex and the optimization rules impossible to boil down into something simple to explain, people can't/shouldn't claim these optimizations to always fix all performance issues, so API's and access patterns get recommneded based on the worst-case. For indexing in a loop, the worst case is a bound check both per access and iteration. For iterators, its only a bound check per iteration. Hence the "user iterators" meme. So yeah, the lack of comparison boils down to there not being a guaranteed safe fast way to do indexing, and if you need it then your options for ensuring fast code are to either to profile the generated code for the regular indexing operators, or use unsafe indexing to begin with. 
The Rust community exists as a separate entity from the Mozilla community, I'm afraid you'll have to take your beef elsewhere. :P
To anyone wondering "How did they do this?!", since mods have access to the CSS of this subreddit, they can change how their comment karma looks. Here kibwen changed how his - and *his* only - looked in this subreddit. This: a.author.id-t2_7b7l2:before { content: "!!" } Is the piece of CSS that gives him two bangs before his name. And this: a.id-t2_7b7l2.moderator ~ span.score:before { content: "1844674407370955161"; } Is the one that changes his score. See how it's `a.author.id-t2_7b7l2` in both cases? Don't trust me, inspect his score element :) **EDIT**: ahah, thanks for the enhanced name :)
As an Arch user, yes it should. Just like they do with nodejs and npm.
&gt;:P