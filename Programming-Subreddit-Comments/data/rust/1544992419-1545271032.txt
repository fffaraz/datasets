&gt;You can often shorten it with an if letbinding. Maybe something like: &gt; &gt;if let (Some(file\_ref), Some(list\_ref)) = (arguments.file\_of\_configs().as\_ref(), arguments.list\_of\_configs().as\_ref()) { ... You can also shorten this: if arguments.file_of_configs().is_some() &amp;&amp; arguments.list_of_configs().is_some() { ... } else if arguments.file_of_configs().is_some() { ... } else if arguments.list_of_configs().is_some() { to something like this: match (arguments.file_of_configs(), arguments.list_of_configs()) { (Some(file_ref), Some(list_ref)) =&gt; ..., (Some(file_ref), None) =&gt; ..., (None, Some(list_ref)) =&gt; ..., _ =&gt; (), } to handle all the possible cases in this scenario.
Yes, the point is that writing browsers is pretty much smack dab in the middle of the wheelhouse of systems programming, and if Rust is having trouble there it will have trouble for other systems programming things.
Every single supposed "downside" to static binaries is doubled by containers. Those who do not learn history ‚Äî or at least those who blindly trust the "wisdom" of their predecessors who made a career dealing with dll hell ‚Äî are doomed to repeat it.
As a hypothetical example, if mrustc was written in OCaml (which I believe can bootstrap starting with a C compiler), would it still be good (security-wise) despite the fact that there is only one OCaml compiler out there?
I very much agree with all the points brought up. I believe better processes to explore the design spaces of issues will alleviate some of the hardships involved. I've not been involved in all the same discussions as withoutboats, so my experiences might differ a bit. But from what I can tell most heated discussions centered not about design-differences, but simply recognizing each others viewpoints. People proposing features have good reasons to do so. People having concerns about the features also have good reasons to do so. We seem to have lost awareness of that to some degree. Personally, I'm no longer taking part in RFC discussions (for a variety of reasons) and am much happier these days. After recent experiences on the internals discourse I'll probably cut back on that as well. I'm getting ready to do some work towards tooling enhancements I'd like to see in the near future, but due to baggage of old discussions I'm not looking forward to it at all.
&gt; But you dynamic linking lets you get/do security updates without recompiling! Building on your second point, I think given today's linux software distribution practices, dynamic linking is likely to *prevent* getting security updates. When you have a bunch of packages on a (semi-)production system, are you going to want to: # take a point release on a dynamic library which could impact who knows how many applications in unknown ways (or, perhaps, just never get released until your distro maintainers verify this doesn't happen); or, # take a point release on specific static linked applications, where you know exactly what's going to update, and that the combination of libraries linked by that application was actually tested, and the update can be released independently of readiness of other packages. What happens in practice is neither of these things: in practice, only the most critical software gets updated between major releases, if ever. Most users just install Ubuntu 18.10 or whatever and don't update until the next release (or they install an LTS, but those basically get updated as stable versions come out so the same limitations apply).
Really nice post! It's true that in the last 4 years (don't know how it was before) it changed quite a lot. I really hope that Rust could become a full time job for a lot of people but I really think it's just a dream for now: FOSS are very rarely supported by the companies using them. Anyway, I think a foundation would be a first step in that direction (and I hope that some day, my free time contributions would become paid too haha).
One super useful feature IntelliJ products have is "complete statement". Do you you have it in your plans? \[For who don't knows, the IDE not only do autocompletion but it can add necessary parenthesis, brackets, semicolon etc...\]
I completely agree with the statement that designing with Github issues is like drinking from a fire-hose. I recently bought the `rfcs.rs` domain name, and have been planning out how exactly the RFC process could be improved, because I strongly believe that github issues are an organizational nightmare for this. It worked much better back when there were not nearly as many people taking part in them, but the Rust community is certainly growing. My goal for an RFC is that, after reading an RFC's contents, it should only take about 30 seconds to a minute for someone to figure out the general consensus of an RFC, from a bird's-eye view. That includes what people have stated as improvements to an RFC, as well as its concerns and (hopefully constructive) criticisms. **This is especially important for the Final Comment Period, in my opinion.** There have been several RFCs I've wanted to understand, but have ended up taking 30+ minutes of my time just to figure out what was happening, let alone getting to a point where I could even contribute. I'm still working through the design of what would be best to include, however the basics I currently have are: ## Main page * List of RFCs in FCP * List of recently-created RFCs * List of most popular RFCs, potentially ## For each RFC: * The ability for people to thumbs-up the RFC (because everyone likes to vote for things) * One tab showing the contents of the RFC itself (and maybe a history slider, as I assume RFCs to evolve over time) * The other tab showing a list of: 1. Concerns 2. Improvements 3. Praises (if that's something that makes sense beyond a thumbs-up vote) For each Concern/Improvement/Praise, it should include: * A (one-line) title * An optional description, of any length * A pointer to somewhere within the RFC (maybe - I'm still debating the pros/cons of this) * A section to discuss this Concern/Improvement/Praise (whether flat like Github issues, or threaded like Reddit) This should hopefully be enough (if not more than enough) to allow someone to read the RFC, and understand what the general concerns are at a glance, and then dig deeper into (and contribute to) specific concerns much quicker. There are still many, many unanswered questions about this design: * How are concerns "resolved" and by whom, if at all? * Should concerns have votes? * Should concerns and improvements be side-by-side, or should improvements be in response to concerns? * Should there be a general section for discussion, not associated with any concern/improvement/praise? Could that cause fewer people to create concerns, thus bringing us back to square one? Could not having one reduce contributions? * Are these three categories enough to make RFCs more efficient? * Should there be a system in place for *developing* RFCs as a community in a central location (i.e. Pre-RFCs)? I'm certain there are many more questions than just those, however I want to start experimenting with this fairly soon. Does anyone have any thoughts on this idea? Is this enough (or too much) organization for RFCs?
Because that won't pass the borrow checker...? `a_map` must outlive the returned iterator.
1. In [the book](https://doc.rust-lang.org/book/ch10-01-syntax.html) these are called type parameters. 2. This is so that the compiler could know if `T` is a type parameter, or just type that was defined somewhere else - you can define `impl` blocks for concrete type parameters too (like `impl Point&lt;f64&gt; { ... }`). So if you write `impl Point&lt;T&gt; { ... }` the compiler will not have to guess if you meant generic type parameter, or if there's somewhere a `struct T { ... }` that you happened to import in this module - if there `&lt;T&gt;` on `impl`, then its always the former, and if no then it is the latter case.
Could you elaborate on why cross-compiling rustc is so much more difficult than cross-compiling gcc that you would rather go through this entire complicated chain just to avoid it? 
Perhaps there could even be additions for Tracking RFCs, where a bird's-eye view of those could exist as well, and kept in sync with the associated github issues.
This is great stuff and very important for Rust. I wrote a bit about improving our process and governance in 2019 as part of the first year in a three year cycle. Boats says it way better than I did and in a lot more detail. &amp;#x200B; (The good news is the core team has already been thinking and discussing a lot of this, the bad news is we have no answers yet.)
I guess you could say it became a bit.... Rusty
1. Understood. Perfect! 2. That's what I thought too, but `impl Point&lt;T&gt;` and `impl Point&lt;i32&gt;` aren't even problematic, are they? There's one impl for all cases where Point gets &lt;T&gt; and one case where Point gets a &lt;f64&gt; specifically. What would the compiler not understand about this?
What the proper response to the new website should have been is "This is a disaster, lets go back to the drawing board." (which I saw many commentators making, especially on Hacker News). Instead we for some reason charged ahead with the design, with promises to fix things eventually.
I tried once understanding the reasoning behind the feature and it was super confusing, especially those one-liner final comment period threads since they do not link to the document. It would be cool if there some way that a protocol/summary could be produced from this concerns and improvement and a history like going back commits. So, a new contributor could take a look at the current prosposel and go back to show the process. But it would be nice to mark/add a link when the protocol got updated in the comment thread.
ba dum tss! 
I don't mind the new design, but yes, the code examples and especially the key advantages should be the first thing one sees!
in GC parlance a "root" is anything GCd that's immediately reachable. Think local variables.
Hey boats, loved the post. Have you considered using artifact for helping with design docs? It's written in rust (CLI and full stack) and is designed for developers. I would love to give you a demo if you've got time! Since design docs would be in your code (and track/lint with your code) you could use PRs and git history to discuss/track them.
I don't see why functions returning `impl Trait` must be restricted to a single return type. It would be pretty straightforward to desugar this case into returning an enum that implements the trait, where each variant refers to one of the return types. This would make `impl Trait` much less confusing.
I liked the new one. :)
Ubuntu manages their own copy of openssl and backport security fixes to it, FYI.
Inspired by [https://boats.gitlab.io/blog/post/rust-2019/](https://boats.gitlab.io/blog/post/rust-2019/), not really polished and perhaps not fully formed, but wanted to get the gist of my ideas out there.
You can have optimisations and debug checks on at the same time by customising [a cargo profile](https://doc.rust-lang.org/cargo/reference/manifest.html#the-profile-sections) to have both `opt-level = 3` and `debug-assertions = true`.
&gt; This should be one of the highest resourced efforts for Rust 2019. Agreed, although it's an open topic on whether resources should be invested into the current RLS or Rust Analyzer. 
I'm curious, your post focused mainly on the performance aspect and mostly left out the memory footprint. Do you have more details on this? Especially you said that the memory needed is similar to the one by the current `dec2flt` implementation but ~2kb for `bigcomp` and ~4-8kb for `algorithm_m` seems like a big range. It's completely irrelevant on desktop nowadays, but for low memory embedded devices this could be interesting.
Definitely. I recently started playing with Flutter in VSCode (I've had enough of IntelliJ's bulk) and it finds compilation errors *instantly* - no exaggeration. Go is fast, for example, but Dart compiles so fast it makes me suspicious that it hasn't really done anything. Quite a game changer. Well it would be if bloody gradle didn't take 5 seconds to initialise itself and resolve dependencies.
Firstly, you're using some quite emotive and negative language to describe the work of other people. Just my personal view, but I don't think that's cool. That said, I can totally see how you might dislike the appearance of the new site, since aesthetics are subjective. I'm not a huge fan of it myself. Here is something to consider though; what is the problem this new design is trying to solve and in what ways did the previous site fail?
The slice iterators (`std::slice::{Iter, IterMut}`) are very similar to C++ ranges (a pair of pointers), could they be used instead of raw pointers directly? 
I wish that the survey had broken down what "IDE support" means to users. AFAIK, it didn't have any follow up questions about whether they care most about having more accurate autocompleting it or faster responses or more correct refactoring or... It seems there is just *so much* that an IDE can do for you, but I suspect most users feel strongly about only a small handful of common things, and knowing which things those actually are would be tremendously useful for this discussion and planning. Perhaps we should should organize an IDE features/desires survey?
Suppose that there's a `struct T;` just above the `impl Point&lt;T&gt; { ... }`. Now is that impl meant for all types or just for that struct? Now suppose that `struct T;` was 500 lines above, which case is it now? Now what if you added `use foo::bar::T;` at the top of the module. What happens now? All generic structs suddenly break, or is the compiler supposed to guess what you actually meant? Declaring type parameters explicitly helps both the compiler and the programmer to avoid such guessing when reading the code. 
I would recommend using [Actix Web](https://actix.rs/) over Rocket. Rocket requires a nightly compiler and does not support async I/O. The [Actor framework](https://github.com/actix/actix#features) that Actix Web is buitl upon is very useful, too. I have no idea why the Rust website is promoting Rocket instead, despite its current drawbacks. Whatever you use, make sure to develop your project in modular pieces and upload them to Crates.io as standalone crates rather than developing a monolithic project. I'm sure you'll run into a number of scenarios where you have opportunity to bolster the ecosystem in the areas you're going to target.
`T` is an identifier/name just like `f64` or `String`. There is no difference. You are able to write `impl&lt;String&gt; Point&lt;String&gt; {}` because `String` is a valid identifier. If you wrote (assuming your proposed semantics): type T = i32; impl Point&lt;T&gt; {} ‚Ä¶ then the compiler needs to check whether `T` already exists in surrounding scopes or not. In the case above, we'd implement `Point&lt;i32&gt;` because `T` and `i32` can be used interchangeably. In the case below though, we'd implement `Point&lt;T&gt;` for any given `T`: impl Point&lt;T&gt; {} As you can see, the distinction becomes dependent on the context (the scope). With a large amount of imports, you as a person won't be able to track this information anymore. Instead of explicit type parameters (like in this snippet `impl&lt;T&gt;`), you propose implicit ones. It's like declaring a function with implicit value parameters: fn f -&gt; i32 { // (a: i32, b: i32) let c = 6; a * b * c } If you mistyped a local binding `test` as `testt`, the latter suddenly (implicitly actually) becomes a parameter. Same with `impl Point&lt;ComplexF33&gt;`: You meant to write `ComplexF32` but now with your semantics applied, it means `impl&lt;ComplexF33&gt; Point&lt;ComplexF33&gt;`.
Maybe we could have some stuff in the CoC for SHOULD as well as MUST. You could say "you don't have to do these things, but you ideas will be taken more seriously if you do". It's a way of expanding the CoC without actually making more rules. PS I think BurntSushi does a great job of moderating the forums on urlo. Firm without being heavy-handed. Maybe the rule for forums can be "do what BurntSushi does" like it is with code ü§£
Thanks for reminding me to add a comment about this!
Yes perhaps I went too far. I had no problems with the original site. If there was backend issues that are not visible then they should have fixed the backend issues rather than changing the look and feel of the site.
Are there any plans to have it export a backend-agnostic display list for consumption by other applications? I could see this being used for game development asset pipelines, for example.
I'm surprised that there wasn't a mention of the [OrbTK](https://gitlab.redox-os.org/redox-os/orbtk) project for GUI, and the focus group team behind it. Rust is actually a lot further along in the GUI department than some think.
That was an oversight, apologies, and I'll fix it now. I wrote this post quickly during gaps in an otherwise full day. Thanks for the reminder!
i like the new one
\*ah\* got confused by the post title
I know /u/matklad has talked internally about pitching the idea of starting an "IDE working group", maybe that would be a good starting place to collect requests from users on what is necessary/highest value here?
If it's stupid and it works, it isn't stupid :D
I'm not boats. Artifact looks very nice but I wish I could use with it plantuml, graphviz, svgbob and all the others. Just like with org-mode.
1) I never understood why some random quotes from some random people should en-/discourage me to use/try something like a programming language. Either its great stuff or it isnt - for my scenario/usecase - but I don't need one lines from unknown people. It's not helping! 2) The old webpage had a much better "core features" text snippets to "amount of text" ratio. Useful! 3) Why did all the font size on the new page get larger overall? And way too much to scroll. 4) I generally dislike the "modern" design of horizontal sections where you never know whether you are at a page's end or not, one has to deliberately scroll down and try, or look at the scrollbar if there is still more stuff coming - why? 
Ahhh OK. Didn't even think of something that complicated that could go wrong. Thanks for explaining. Seems like there are a lot more things I still have to look at in more detail than I thought. But at least I understood this!! :-) So thanks again!
That is a valid point. Thanks a lot!
You want /r/playrust
I think he's talking about things like marketing to a larger audience, ect.
This. I've seen claims that the old site was not helpful in promoting the language to non-technical people and decision makers, but the proper way to deal with this was with *incremental* improvements, not by throwing the whole thing away and starting over with a site design that's clearly sub-par in technical features, performance, usability and arguably design, that doesn't even focus on marketing the language successfully (see the rather disappointing 'slogan', that had to be improved with community input!) - and does not provide even a fraction of the in-depth info that the old site did. A lost chance, IMHO.
I'm really excited about rust-analyzer. Coming from the Java world, which is pretty much the gold standard for IDE support, I've found working with RLS to be one of my biggest frustrations. Two questions about rust-analyzer: 1. Will it be possible to use as a library or will it be tied to the LSP? I've felt for a while that the LSP approach is somewhat antithetical to the Rust ethos of zero-cost abstractions. When writing an IDE, having two separate processes reading from the same files will never perform as well as a single process that can share buffers. I'm not sure if it's possible to write rust-analyzer in such a way that it can re-use the IDE's buffers (whether simple byte buffers or using something like ropes/piece tables), but if that's possible, it seems like it would be more Rust-y. 2. One of the areas I never see talked about in Rust IDE discussions that I remember being hugely impactful from my time working with Java IDEs is safe/hygienic refactoring. Stuff like being able to safely rename classes/methods and have it do something more intelligent than a search/replace. Working in IntelliJ, I'm sure you're well aware of all the functionality available to Java devs. Are these kinds of IDE features at all part of the plan for rust-analyzer? I wouldn't expect them to be part of an MVP, but I'd hope that they're at least part of your design considerations so that your approach doesn't preclude adding them later.
Oh wow I had no idea it was cross-platform. I‚Äôve always assumed it was Redox-specific!
You interested or nah
This subreddit is for the rust programming language.
Note that I (the poster) am not withoutboats, and I don't think he really checks reddit anymore (due to reddit being a dumpster fire). Might wanna contact him directly (via Twitter, I guess?) to get his attention.
The team behind OrbTK are professional designers / software engineers from [Ergosign](https://www.ergosign.de/en/), where they are paid to work on the project during their "Focus Time". They won the company's first focus time prize, and OrbTK is one of the developer highlights for the year. Their company seems to be quite interested in seeing the project developed. OrbTK has been designed around an ECS architecture, using the DCES ECS crate that they developed for it. The API is inspired by Flutter / React / etc. It supports a builder pattern for constructing and programming widgets. It wasn't too long ago that they finally merged their OrbTK rewrite back to Redox OS, and development has been quite active there ever since. There's been some talk of possible collaboration with Amethyst to use it for designing game UIs, in addition to its primary purpose (designing desktop applications). It also supports a web backend so that it can render the application UI in a webpage too. The current OrbRender backend is fairly primitive and uses SDL2 on Linux, though there's currently some experimentation with using WebRender as a backend. A custom solution with gfx-hal could also be a solution, though I'd imagine it'd be better if the project could benefit from WebRender's progress.
Definitely
I can run some profiling if you would like.
people got pretty excited about the [2018 RustConf closing keynote](https://kyren.github.io/2018/09/14/rustconf-talk.html), ECS in rust look really neat
Yeah, I'd be interested in that and overflow checks. Thanks.
I a disagree a foundation would not help. A way for big donors and companies to give money *specifically to Rust* (i.e. not to Mozilla with the suggestion it be used for Rust) would help the money problem.
The new website I would argue is less professional and markets even more poorly to that wider audience.
You want /r/playrust This subreddit is for the Rust programming language
also, boycut isn't even a word.
typical open source project issues, its difficult, but worth it. keep moving. I love rust community!
&gt; you can run the binary on any system that has the appropriate system libraries &gt; you're not dependent on some dynamically linked library Uhhhhhhh
I learned Rust last weekend, right after the change. So I don't feel a special attachment to either version and I like the new one better too. It's more in line with what the other languages are doing.
It has inline integration with graphviz. I do not think adding other support would be difficult. I intend to also figure out how to have plugins provide this kind of behavior (not yet implemented at all).
Thanks, I contacted them via email!
But then who gets hired or not with that foundation money? Who gets to decide?
I'
I don‚Äôt know. I am not a lawyer or organizer. But I‚Äôve worked at a few places using rust who were holding a pen over their checkbook waiting to donate to Rust but couldn‚Äôt because Mozilla doesn‚Äôt take donations specifically for it. That‚Äôs good money we‚Äôre losing!
Indeed; big Linux distros generally take security quite seriously. Here's the list of "Ubuntu security notices": https://usn.ubuntu.com And here's an example OpenSSL advisory: https://usn.ubuntu.com/3840-1/
Personally I‚Äôd like the old site with some of the new content appended to it, but then again I‚Äôm one of those old ‚Äúget off my lawn‚Äù people when it comes to design 
You know that Linux distros such as Ubuntu backport security fixes, right? Ubuntu Server has automatic upgrades enabled by default, so a lot of users are installing those fixes perhaps without even knowing it.
&gt; It's like declaring a function with implicit value parameters That's so clear, it should be in the book.
Is this also a language server or is it limited to a special editor? I'm using vim with RLS atm.
I do realize that, thanks. I also realize that those fixes are delayed by the package maintainers until they can be confirmed not to impact any other (popular) packaged software which might ever dynamically link to it. However, those exact backports and automatic upgrades are exactly why the supposed difficulty of distributing fixed static linked binaries is imaginary! My whole point is that it's *easier* and *quicker* to distribute fixes for each (static linked) package as soon as it's tested rather than having to delay release of a shared dynamic dependency until sufficiently many of its reverse dependencies are tested.
&gt; Ideally it's possible to build quite a few fast and very simple CPUs that doesn't have any complicated branch prediction logic, But branch prediction is what makes modern CPUs fast.. Without it you're kinda outta luck. &gt; make that $5 solution useless. Not sure how whatever you do with your hardware or software or whatever will make somebody hitting you with a $5 wrench until you work with them useless...
The new site doesn't even clearly *say* it's a programming language! Except in the title, but thats easy to miss, a lot of people don't see those. You have to infer that it's a language and not some framework or something from context on the page.
Amazing post, I was really waiting for someone to put words to this. I program in Rust and try to follow the langauge's development, but to me, finding out the status of upcoming features (How far along it's come, which parts of the feature will be stabilized first, etc) is almost impossible. I've tried on several occasions, and always given up. I think the impl traits incident really showed that the RFC process doesn't work that well anymore. A lot of people had no idea impl traits would also be allowed in argument position, which is an almost orthogonal feature that just happens to have the same syntax. In the end they were bundled together almost like a piece [rider legislation.](https://en.wikipedia.org/wiki/Rider_(legislation\)).
&gt; It's more in line with what the other languages are doing. ..What other languages sites? Because it's not like any i've seen. other languages have stuff like code examples and list their features and say they're actually programming languages. They may have fancier designs but there also *good* designs, and Rusts new one is fancier but.. thats about it.
Is there anyway I can get the nightly documentation to show up in the normal white color? I didn't see anything in the settings.
&gt; Instead we for some reason charged ahead with the design, with promises to fix things eventually. Thats because it was all designed behind closed doors, no community involvement at all, until a week before release where they asked for feedback they had no way to follow that late in the process, with a strict deadline to release with 2018 edition for some reason because thats better than having a good site?
That's an excellent point. This was probably forced upon them by someone higher up at Mozilla. 
In theory that could work. But I think doing it reliably enough to beat dynamic linking would require quite different 'software distribution practices' from what's common today. Well, if distro packages themselves are shipped statically linked, then sure, you can theoretically validate the reverse dependencies one-by-one... although I fear that that would lead to less-popular packages just never being updated, whereas today at least critical security fixes do make it out to the whole distro. But for a server (I assume that by "production system" you mean a server), the bigger problem is if the user builds their own software against the distro's (or other) static libraries. If said user has an active CI pipeline with continuous delivery, then hopefully they'll be safe as soon as the next build kicks off. But many installations, perhaps most, are not so organized. Whether because the user's own software is not being actively updated (anymore), or because they're on a more gradual release cadence, they're likely to just keep running the same binary for a substantial amount of time unless something breaks. Which means they won't get any updates at all. Oh, and the same applies if they're using any sort of third-party binary package. On the other hand, if there were some sort of universal dependency manager that everyone could agree to use, maybe there could be some sort of compromise where the system could re-link things automatically... Sounds complicated and probably impossible. But now that everyone's using containers, which effectively amount to statically linking everything, and newer languages like Go and Rust are simply incompatible with dynamic linking (Rust can technically dynamically link, but it's mostly useless since you can't swap out the libraries), there may be no other choice.
&gt; Rust is running a marathon, not a sprint. Please go at a pace fit for the growing the language, its organization, its community, its people, for the long haul. I want to be programming in Rust for a long, long time. Completely agree, though I don't have much to add.
I'm going to reiterate that https://www.reddit.com/r/rust/comments/8sochx/proposal_for_a_staged_rfc_process/ is what should be happening for most of these issues. Direct link: http://smallcultfollowing.com/babysteps/blog/2018/06/20/proposal-for-a-staged-rfc-process/
See: http://smallcultfollowing.com/babysteps/blog/2018/06/20/proposal-for-a-staged-rfc-process/
There's also lots of existing ideas out there on how to improve the RFC process that I'll need to review, and see how well the ideas fit into this system (as well as see if this system covers all use-cases).
What about those who develop it without getting payed? Don't they have a say? The least you could do is let them voice there concerns.
What about those who develop it without getting payed? Don't they have a say? The least you could do is let them voice there concerns.
Personally I like the new site. 
I have to say these threads are starting to get a nuisance. Yes, there were/are some honest and objective issues with the new website. But in the short time the new website has been live we've had so much debate about it and honestly most seem to take the topic way too close to heart. Making subjective/personal preferences out to be absolutely objective and that's the new thing is just awful. And many don't even consider the viewpoints of others. Piling onto it with constant threads about how awful the new site is doesn't change it. I wish we could as a community all calm down a bit on this topic. Yes, objective issues were also raised. But most of the time they were completely drowned out by subjective opinions. And I think the amount of subjective versus objective problems raised as well as the way and tone used to raise these issues were bad. I think it hindered giving the objective issues as much visibility as they deserved and hindered getting them fixed. &gt; And finally its in clear white and single color interface rather than multicolored dissonance. &lt;!-- --&gt; &gt; We went from clear and professional to something that looks like it would be a college art project. I personally prefer the new look with the "multicolored dissonance" quite a bit over the old one. Having multiple colors instead of a "clear white and single color" doesn't turn something into a "college art project". What's supposed to be bad about having some art or colors anyway? It doesn't all have to be bland. Also colors alone don't make something unprofessional. I still find the new site quite clean and professional looking and think the colors add a nice touch. That said this is very subjective, for example the whitespace in different sections could still be changed a bit in my opinion. Your post doesn't really have anything objective as far as I can see.
It seems the post has a wrong timestamp? It's "Posted on December 16, 2019" :D
I'm not up-to-date with recent talks, but one I really like is [RustConf 2017 - Shipping a Solid Rust Crate by Michael Gattozzi](https://youtu.be/t4CyEKb-ywA) because there's more than the code and "non-technical" talks are awesome. https://github.com/mgattozzi/ferris-says for the related github repo.
Wow, this takes me back to the countless hours playing Owen's wxSand as a kid on an old 800 MHz machine where big screen would slow it down. Really cool seeing it run quite well too (over 45 FPS). Would love to read a postmortem once this is finished (if it isn't already).
This is *really* cool. I would also love a write-up!
It‚Äôs a bug that will be fixed soon.
&gt; On the other hand, if there were some sort of universal dependency manager that everyone could agree to use, maybe there could be some sort of compromise where the system could re-link things automatically Sounds like... a fucking package manager. Or just a regular package manager. If yours can't package custom software and manifest its dependencies for automatic resolution then you need a better one.
That's because a lot of developers want an ecosystem of "download it from our website, install it, and run it" like on Windows which gives developers more control. The idea of "get it from your distribution's repos which compiled it attuned for their system" is better for the user but relies on the package being in the distribution's repos which develoeprs obviously don't want to wait for. A lot of distributions also purposefully do not update to the latest version because inertia is more important than the latest features, bug fixes, and bugs and developers really hate that and wich everyone would just use the latest version because no one likes getting a bug report for something that was fixed a long time ago.
I'm pleased to read that xi-editor has a community forming around it. I just built xi-mac, and it has come a long way.
Actually, Romeo was exactly what I was looking for! I've upgraded to futures-preview and replaced tokio with romio and it works great. With new futures api I do not have to move values anymore. 
My first thought is "community oriented", so A capped X amount evenly over Y top volunteer contributors in a given time frame. Less a job and more a "bonus" or "thank you".\* Maybe another cap for a given timeframe too, so that the same few top contributors don't get it every time and others get a chance. It's a thanks for contributing to rust, not a full time job. As well as hiring some full time, team members? Themselves decided by however we currently decided team members. ---- \* Though I can see this coming with all kinds problems.. Wouldn't want it to become a competition for top spots or something, or for smaller contributors to feel left out? Involving money tends to cause problems.. if any of this is even possible, legally speaking, since i'm not a lawyer or anything.
One could do this with github issues: by creating an issue and immediately locking it to collaborators only... with the understanding that it's only for status updates.
That's a pretty good point - `FromIterator` is not often used itself, so it's a bit strange to have this kind of ergonomics in it. It allows someone to do let x = vec![1, 2, 3]; let y = VecDeque::from_iter(x); without having to call `x.into_iter()` first. One reason might just be uniformity with other APIs having to do with iterators? Some other APIs, like `Vec::extend`, are greatly improved by being able to take `IntoIterator` rather than `Iterator`, so it wouldn't surprise me if there was an agreement in std to just never have any methods taking `T: Iterator` and instead make _everything_ take `T: IntoIterator` instead for consistency and convenience.
That's very nice! I wish the water was a bit more "flowy" though. Judging from GitHub it's "cellural automata based" so it does only immediate neighborhood lookup, right? It stacks quickly but spreads unrealistically slow. I wonder if it would be against the spirit and try special casing fluids using the following idea: scan "rows" of fluids from bottom to top and keep records of continuous stretches and whether they are constrained or unconstrained from sides. When calculating the next, upper row, apply a "spreading" transformation according to the record of the lower column. I'd imagine that should help the vertical spread to propagate faster, whereas now every pixel in the upper layers takes multiple ticks because it has to wait for the lower ones to spread.
I don't think funding or lack of funding has any bearing on where Rust is at now or where it's going to be in the near future. I recently heard the opinion that for the number of "ready willing and able" developers Rust has available to it it does not/has not achieved as much as it should have by now, and I must say I kind of agree. If anything I feel like it's more of a logistical/organizational issue.
This is brilliant
&gt; but relies on the package being in the distribution's repos which develoeprs obviously don't want to wait for. If your package manager requires this (i.e., it's too difficult to package software yourself) then you need a better one. The inertia is a result of dynamic linking; see above.
Glad to hear it works well for you! ‚ú®
I used to LOVE these kinds of games as a kid. Great work!
People don't want to compile themselves and apart from that almost no package manager has actual proper support for decentralized managed. Nix and Guix are really the only ones. Yes you can use checkinstall on dpkg, RPM, or Pacman or write your own ebuild but there are all sorts of problems with decentralized management. Dpkg and all the things it inspired where never written with decentralized package creation in mind.
Note that I didn't say that building your own packages was a solution to anything; merely that if your package manager doesn't make it easy, it's broken. Users of those package managers might as well switch to Windows.
Something like the powdertoy Ôºü Looks co o o o l
I've used to figure out bugs that otherwise stumped me when writing procedural macros. Very useful.
&gt;Fable I agree that it isn't better, but the old one was not the way to go to get companies to adopt it. 
&gt;I personally think nailing the IDE experience would have far more impact on attracting users than the ergonomics efforts In my experience the majority of exploring and learning a language happens directly within the IDE, with books/internet as minor supplements. I own and have flipped heavily through both "Programming Rust" and "The Rust Programming Language" books. A year or so back I started a side project in rust and made no major headway after getting some first bit of functionality working. Every few months I would fluster around and tuck it away again making no progress. A month back I tried IntelliJ and was able to put more of my ideas to work (including a full project restructure) due to the better IDE experience. It's almost difficult to express how important the IDE experience contributes to learning and enjoying a language.
Also similar to Kialo is Arguman: http://en.arguman.org
&gt; Oh no, the fungus is spreading. Let's kill it with fire! &gt; Oh no, the fire is spreading to the oil! Let's kill it with water! &gt; Oh no, water + burning oil = bad. Let's suffocate it with gas! &gt; Oh no, the gas is flammable! Great fun, thanks!
Very cool. What framework did you use?
Thats really cool! I just wish plants didnt near instantly destroy the entire water supply.. And that it was possible to put out plant fires with water. Instead water + (plants + fire) = more fire. Plants eat all the water, and then catch fire, making spread worse.
Why are we just down voting comments that say they like the new site? Would it be better to actually have a discussion on how to improve it? 
Wow putting firework on fungus and then pouring lava gives something amazing! This is really super cool :D
Powder Game was the shit when I was young. This is just as nice! Looking to see how this goes.
Calling out to a dynamically linked library is slow, for example: http://ewontfix.com/18/
Nice project. I think that the sourcecode is here https://gitlab.com/veloren/game
Is there a recommended crate that would draw an image in terminal window (like [https://github.com/hopey-dishwasher/termpix](https://github.com/hopey-dishwasher/termpix)) from a backing buffer, but that would also keep track of what is drawn, diff that with changes with the buffer and re-draw only the changed parts?
Have you heard of [url="https://stedolan.github.io/jq/"]jq[/url]?
code?
I have been watching both azul and orbtk with interest. OrbTK master doesn't build on stable, Azul just panics on OSX at the moment. There is considerable lag on OSX for OrbTK I noticed when using just the widgets example (both --release and debug). Not sure if it's the same on other systems. Apart from that, I can't see any native stylings of buttons, etc.. I am assuming this is because it uses a gl canvas or similar. I feel like it's come a long way, but still has a while to go. 
That doesn't make sense at all. If the primary goal of the package manger is to manage packages on your system, then not being able to easily rebuild any package from source does not necessarily make it "broken". In fact, I don't know any package manager that lets you do this. For example, `pacman` on Arch doesn't let you compile your own packages - that's a totally separate program (`makepkg`) with a separate package database (AUR). I guess Portage/Emerge/whatever on Gentoo does but that's because the entire distribution is based on compiling from source.
This is why we use static binaries for basically everything at my job. It simplifies *so* many things. It also lets us more precisely control releases (no worry about updating a shared library on a machine and causing changes to other programs running there), plus we can "mix-and-match" dependency versions as needed.
There are a bunch of contracting firms (integer32, ferrous systems, lyken) that do Rust things for money, as well as a [bunch of individuals](http://aturon.github.io/sponsor/). A lot of these folks are in Rust leadership, so if you want to sponsor the Rust project you can sponsor one of the folks to continue doing excellent work on the project. A foundation gets you: - nonprofit status (this is nice for donations) - the ability to consolidate cash from multiple sources (I'm skeptical we've reached the point where this is necessary) - the project itself controls where the money goes (meh ... companies giving money to rust probably have priorities anyway; and if they do want to follow the project's priorities they can look at the public roadmap) 
Yes looks exciting. I have some javascript knowledge and now learning rust. Would be happy to spend some time compiling and testing your game.
HOLY SHIT THIS IS WIKID
but certainly for a library like glibc, or whatever c std lib is in use, there are steps taken to avoid this problem? most binaries will need the c std lib
It would be useful to have output of `rustc --version --verbose` on your system.
Neither Flutter or React are anything resembling "first rate UI toolkits". I'm sorry, but for the love of Whomever quit it with the CSS stuff people. "Let's take SOME_JAVASCRIPT_THING and put it on the desktop!" is non-starter way of thinking about things. CSS is deeply flawed in many ways and by no means something particularly worth emulating.
Those smoke effects we unexpected and beautiful.
sure, `rustc --version --verbose :` `rustc 1.27.0-nightly (9fae15374 2018-05-13)` `binary: rustc` `commit-hash: 9fae1537462bb10fd17d07816efc17cfe4786806` `commit-date: 2018-05-13` `host: x86_64-unknown-linux-gnu` `release: 1.27.0-nightly` `LLVM version: 6.0` &amp;#x200B; &amp;#x200B;
Flutter 1. doesn't use CSS 2. doesn't use JavaScript 3. is a framework for mobile, not desktop applications. You don't know what you're talking about.
wow, i spent about an hour on this... lol
Great job! Takes me back :) 
As long as your only non-source input(s) to the bootstrapping process can be checked using diverse double-compilation, the goal has been met, so C -&gt; Ocaml -&gt; Rust would work if Ocaml can build from nothing but source using a DDC-verified C compiler.
&gt; &gt; &gt; (The good news is the core team has already been thinking and discussing a lot of this, the bad news is we have no answers yet.) This is not the first community where this has happened; probably not the last either. What are the lessons to learn from other open source communities that have gone through this phase?
I don't see any mention from a skim of the thread, but you should be aware that MSVC 2017 Update 9 has a new, performance-oriented implementation of [`std::from_chars`](https://en.cppreference.com/w/cpp/utility/from_chars). Some pertinent discussion and details are in [this thread](https://www.reddit.com/r/cpp/comments/a2mpaj/how_to_use_the_newest_c_string_conversion/) and its link. Maybe /u/STL will chime in...
I've personally never used the literal "complete statement" shortcut. However, I really enjoy the general feeling that you don't have to type much of the punctuation in IntelliJ, and I do want to have this experience. For example, rust-analyzer has this small fun feature that if you have a code like ``` { foo.bar() let x = spam(); } ``` Then typing `let v =` before the `foo.bar()` will add `;` after `bar()` automatically. It already has this neat behavior that `ret` is completed to `return` in unit-returning functions and `return ` in functions which return values.
Never mind, I started such a crate myself. I will post an announcement once it is in a usable condition.
That's a very old nightly build. Try running `rustup update`.
This looksike a few different issues. For one, you're on a nightly version of rust. If you're new to rust this doesn't seem to be the version you want. I'd recommend switching back to the stable version unless you absolutely need nightly features. You're also on a fairly old version of rust. I'd recommend updating to the latest stable version. As for what the error is, the library you want to run is trying to use a feature that your version of rust doesn't have by default. You can either update your rust version (recommended) or follow the instructions and add the flag enabling the feature. Since you're new to rust, I'm going to recommend switching back to the latest stable version. Run these commands rustup update rustup default stable 
&gt;rustup default stable I did that and after use " cargo run " i got another error : `cargo run :` `Compiling proc-macro2 v0.4.24` `Compiling libc v0.2.45` `Compiling version_check v0.1.5` `Compiling unicode-xid v0.1.0` `Compiling pq-sys v0.4.6` `Compiling cfg-if v0.1.6` `Compiling unicode-xid v0.0.4` `Compiling regex v0.2.11` `Compiling serde v1.0.82` `Compiling quote v0.3.15` `Compiling ucd-util v0.1.3` `Compiling ryu v0.2.7` `Compiling lazy_static v1.2.0` `Compiling utf8-ranges v1.0.2` `Compiling byteorder v1.2.7` `Compiling bitflags v0.9.1` `Compiling itoa v0.4.3` `Compiling error-chain v0.10.0` `Compiling bitflags v1.0.4` `Compiling synom v0.11.3` `Compiling proc-macro2 v0.3.8` `Compiling memchr v2.1.2` `Compiling regex-syntax v0.5.6` `Compiling thread_local v0.3.6` `Compiling syn v0.11.11` `Compiling diesel v0.16.0` `Compiling derive-error-chain v0.10.1` `Compiling aho-corasick v0.6.9` `Compiling quote v0.5.2` `Compiling quote v0.6.10` `Compiling syn v0.13.11` `Compiling syn v0.15.23` `Compiling dotenv v0.10.1` `Compiling dotenv v0.9.0` `error[E0659]: \`error_chain\` is ambiguous (derive helper attribute vs any other name)` `--&gt; /home/mehrdad/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv-0.10.1/src/lib.rs:23:40` `|` `23 | #[cfg_attr(not(feature = "backtrace"), error_chain(backtrace = "false"))]` `| ^^^^^^^^^^^ ambiguous name` `|` `note: \`error_chain\` could refer to the derive helper attribute defined here` `--&gt; /home/mehrdad/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv-0.10.1/src/lib.rs:22:17` `|` `22 | #[derive(Debug, error_chain)]` `| ^^^^^^^^^^^` `note: \`error_chain\` could also refer to the derive macro imported here` `--&gt; /home/mehrdad/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv-0.10.1/src/lib.rs:10:1` `|` `10 | #[macro_use]` `| ^^^^^^^^^^^^` `error: aborting due to previous error` `For more information about this error, try \`rustc --explain E0659\`.` `error: Could not compile \`dotenv\`.` `warning: build failed, waiting for other jobs to finish...` `error: build failed` 
I did it and got another error that I reply error message in "dagmx" reply
If we speak about performance, then rest assured that JSON based RPC is a good approach, performance wise. JSON roundtrip from editor to server and back is less than 2 ms, which is a low enough latency for any UI interaction. And the amount of data traveling between the client and the server is small, so throughput should not be a concern. If we speak about sharing memory between the client and the server, then the only thing they could share is the source code, which is a very small amount of data (tens of megabytes). Even then, the client will probably want to keep in memory only the currently opened files, it's the server who needs to process dependencies, which are typically larger then the current project. However, rust-analyzer is very purposefully not tied to the LSP protocol. It's main "interface" is [a library](https://github.com/rust-analyzer/rust-analyzer/blob/master/crates/ra_analysis/src/lib.rs) which allows three things: creating empty analysis, adding source-file changes to analysis, queering analysis for static analysis results (completion, go to definition, highlighting, etc). LSP support is then added in a separate crate as a relatively thin layer which ties these API into JSON-RPC calls and marshals the datatypes between analyzer representation (which use utf8 offsets and have rust-specific semantics) and LSP representation (utf16 and language agnostic). As for the refactorings, sure, they are planned! As with almost all IDE features, refactorings are a relatively thin layer on top of the underlying compiler/static analysis framework. So, once the core which is able to answer question about Rust code is ready, adding all kinds of fancy features on top will be a question of relatively straightforward implementation work.
It's a language server, though it uses a bunch of protocol extensions to implement features currently missing from the core LSP.
&gt;a backend-agnostic display list List of what? A simple render tree? There is [usvg](https://github.com/RazrFalcon/resvg/tree/master/usvg) for that.
Take all of what I say with a grain of salt since I rarely participate in RFC's, but do like to lurk from time to time. I personally prefer a threaded model (with an ability to cross reference). I find it easier to follow the flow of a particular conversation. I use slack a lot at work and frequently miss the ability to make a thread go more than one level deep. I think a general section for discussion would allow people to discuss ideas without distracting from the main concerns (reduce the noise), though they should be encouraged to "upgrade" a C/I/P. If they do, I think it'd be useful to encourage linking to main points of existing discussion while also providing a summary of what was discussed. This could help reduce the load on moderation too. Regarding resolved concerns (if resolving is implemented), they should still be visible (but visually distinct) so that the issues don't get re-raised. I would really prefer there to be a place to develop RFC's. Having it all on one site makes discovery easier for newer members of the community. I know when I first started, I didn't even know about the pre-RFC sections of the forums.
Something is very wrong here. You have multiple versions of the same libraries being pulled in. Specifically I believe the error says you've got a conflict between different libraries. I think you should contact the author of that YouTube video you're following because it seems they've set up a messy situation. Also given you're new to the language, I'd recommend not jumping in to something from a complex YouTube video like this. Try working through some simpler examples like the rust book.
sure dagmx, Thank you for advice :)
Thanks! It's not that good yet. There are a lot of things [to do](https://github.com/RazrFalcon/resvg/blob/master/docs/unsupported.md). Also, it took me about 6-8 month, not a year, thanks to Rust.
&gt; more accurate autocompleting it or faster responses or more correct refactoring or... Implementation wise, these all are basically the same thing: an analysis engine which understands Rust code while the code is being modified. You can't have one without the other. I think I've found the *perfect* metaphor for how IDE works internally. And IDE is basically [this](https://i.pinimg.com/originals/b8/4c/68/b84c68cfd61a2f2323466446895002bd.jpg) (&gt;!a round table on a single leg!&lt;). The leg is the compiler (and the feet are presumably the full fidelity parsing tree): it's a complex elaborate beast with name resolution, macro expansion, borrow checking, etc. The top is "IDE": completions, refactorings, type hints: basically, bells &amp; whistles the user actually interacts with. Although the leg is very intricate internally, and the top has a huge surface area, they are connected together by a relatively small interface that leg exposes and top consumes: an "object model" of the semantics of the source code. That is modules, structs, expressions, types but which a "frozen" in their final state (that is, although internally compiler runs a kind of unification algorithm for type inference, IDE knows only the final results). 
totally agree with you, same here
Agreed! That's why I primarily interested in forming a common long-term vision for how IDE support should work like.
I mean another step after that - a simple flattened linear list of drawing primitives [a la WebRender](https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/31.png). I'm unsure whether this is trivial to derive from the usvg tree or not. Having this would probably make it easier to implement new drawing backends too.
Could you summarize the relevance of this presentation?
Same here, might be interesting to give it a try sometime soon
`usvg` will return a simple tree, not a list. Not sure that you can simplify an SVG to a list. Anyway, `usvg` already creates a rather simple render tree, so a backend should do anything except rendering.
This is amazing! Played around with it a good few minutes. I was surprised about the smoke and how real it seems to look. 12FPS on my phone seems promising.
&gt; Maybe the rule for forums can be "do what BurntSushi does" like it is with code Thanks, now I desperately feel the need for a set of pins with "WWBSD" on them
I guess a "display list backend" would make sense to have. Something that basically translates 1:1 to GL/DX/whatever draw calls. Might be PR worthy?
I somehow spent an hour playing with it and had a great fun! Thanks
Haha I had the same thing with ice. &gt; Oh no, the ice is freezing all the water. Put lava on it. &gt; Oh no, the lava solidified and the ice refroze the water... Acid time
I sped up our CRT‚Äôs bignum implementation by 40%, but the core algorithm uses bignums and does lots of work. I had seen very little research or permissively-licensed code solving this problem, so the CRT was my only choice at the time. From this thread, it sounds like Rust (and glibc) have a faster approach. I am able to incorporate open-source code into MSVC‚Äôs STL, and for from_chars I would be willing to do a language rewrite, but at the moment we need such code to be licensed under the Boost Software License.
Yeah, it was a bit disconcerting the first time. 240p game and 1080p smoke
TIL: * \` overflowing\_add\` * \` wrapping\_add \` * \`std::num:: Wrapping\`
I really want to like `nom`, but the way it handles partial strings really doesn't sit well with me. Please reconsider making partial strings part of the type.
TIL: * `overflowing_add` * `wrapping_add` * `std::num:: Wrapping`
It's not really a fully general abstraction, but more for "standard" microservices. It encapsulates patterns we encountered.
I'm not the author, but the code is over here: https://github.com/maxbittker/sandspiel Dependencies are here: https://github.com/MaxBittker/sandspiel/blob/master/crate/Cargo.toml Just wasm-bindgen, js-sys, and web-sys. Looking at the code some more, it additionally looks like this is evolved directly from the Game of Life tutorial from the rust+wasm book: https://rustwasm.github.io/book/game-of-life/introduction.html This project maks me super happy :)
A thing I wished was available was better docs on how to write apps that interface with kube apis. There are frameworks in go for this (which still require you setting up codegeneration yourself for crds), but very few good general guidelines on how to write some of these things yourself. That and a usable `kubectl diff` (but that's coming in 1.13 apparently).
I'm not quite sure why the relevance of this is questioned: it's not a recent presentation, but it's on a Rust subject and intermezzOS is still a semi-active project (last commit 1 month ago). It's definitely as relevant as other reposts and many newer people have probably not been aware of the talk.
Thanks!
I'm very surprised you neved used. It's a game changer for me. The way it automatically puts \`)){;\` makes you write very fast and helps a lot in keeping the flow. &amp;#x200B; What about "auto import" instead (auto use in Rust terms)? Auto-completion for trait methods in rust it's an half-feature without automatically importing the given trait.
I'm not familiar with GL/DX, so I'm not sure what exactly do you want. The problem is that SVG is not only shapes. How do you translate text, clip, mask, filter to the GL/DX?
It‚Äôs the best introduction to ECS around. There‚Äôs also this great follow-up talk by /u/azrielh that goes into more technical depth: RustAKL: [ECS, A Programming Paradigm](https://www.reddit.com/r/rust/comments/a38mas/20181204_rustakl_ecs_a_programming_paradigm/)
You would generally have a "text display item" in the list and delegate to however you render text in your application normally. Or perhaps have the display list encode layout/glyph location information and just point to a texture atlas. As for clip/mask/filter, pushing and popping those can be display list instructions or data for that can be stored separately. WebRender implements it as a big `enum` of display items, for example: https://github.com/servo/webrender/blob/master/webrender_api/src/display_item.rs#L108
[removed]
By learning general game development concepts probably.
Hum I see, I'll check that out on Google, I guess that when I'll know that I'll be able to make a with any programming language, thanks for the advice. 
Well, it's basically how it currently works. For example, the Qt backend is just 1300 LOC. And consists mostly of the rendering itself. Yes, the current render tree can be simplified even more, but I'm trying to keep it similar to the usual SVG tree, to simplify understanding and SVG exporting.
My first idea would be that every Cell can communicate it's (directional or not) pressure to its neighboring cells, so that they can choose a privileged direction to move in. But I think this would be either too laggy or too expensive.
I would like to see multiplayer in this game ^^
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Sandspiel, a falling sand game built in Rust+WebGL](https://www.reddit.com/r/rust_gamedev/comments/a6yiuw/sandspiel_a_falling_sand_game_built_in_rustwebgl/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
start with this link and then Highlighting which part of game development you love to work on. Of course, we assume that we want to talk about game programming in general, not art and ... . and start reading this [book](https://www.amazon.co.uk/Level-Guide-Great-Video-Design/dp/1118877160/ref=pd_lpo_sbs_14_t_0/258-1531052-9257355?_encoding=UTF8&amp;psc=1&amp;refRID=Y2TWN62HK9NVQF7MR4YF) . work with team and make simple game. if you wanna make game engine, I recommend that you work with one of the existing game engines in order to become familiar with their overall performance. and I think best Game Engine that for someone wanna make game engine with rust is Unreal Engine because Unreal Engine programming language that support is c++ and rust And these two are close to each other. and read this [book](https://books.google.de/books/about/Game_Engine_Architecture.html?id=OfPRBQAAQBAJ&amp;printsec=frontcover&amp;source=kp_read_button&amp;redir_esc=y#v=onepage&amp;q&amp;f=false) for Obtaining knowledge of the functioning of game engines. I hope this information will help you. These are my research results in the past years in the field of gaming development
This sub is not about the game.
I think you need to speed up the screencast by about 5 times to be useful.
/r/playrust
Oh wait, the logo was eerily similar to the game lol mb 
Thank you lol I messed up
[`ggez`](http://ggez.rs/) is a great engine to start making a game in Rust, providing the basic Game loop &amp; handle input (and as a lot of commented examples). To learn more about Game programming concepts, I recommand [Game Programming Patterns](http://www.gameprogrammingpatterns.com/).
I'm not sure that this is a Rust-related question. As for `diesel`, the PostgreSQL support is a bit better than MySQL one.
Thanks a lot with these ressources I think I'm done for many years ^^, I think I'll start alone because I don't have a big rust experience, but if i success to make I small game I might maybe go deeper.
What is your app going to do? Stream music?
I might be biased, but I support your work heavily. IMO RLS has wrong architecture that simply cannot be fixed w/o rewrite. I also think your expertise from working on production IDEs with JetBrains allows one to trust in this project. I've dreamed for pure-Rust good-architecture IDE. That "absence of self-hosting solution is a shame" point resonates with me a lot. I think IDEs written in Java are bloated and slow, and in particular don't provide proper low-latency realtime reaction because of GC. They also hog memory like candies. Next step would be having the UI in Rust, too.
This is amazing. Not a huge fan of rap, but this is awesome. Kudos to you.
That was extremely fun to play with. Some suggestions: * When you move out of the play area while having the mouse button pressed, the game doesn't register the release. This should be fixed. * It would be lovely to be able to reset to a save state. I tried building a fireworks-driven garden seeding mechanism, but any time I test it, I destroy it.
&gt; Every time I build something, I see I'm building 3-4 times some common crates, at not so different versions. Can we do something about this? This bothered me at first too, but then I realized just how significantly better it is than having to deal with deps not being compatible because they depend on different versions of other deps with API breaking changes. I've run into this problem a lot in other languages and I'm thankful it isn't a problem with Rust.
make app with rust, diesel is ORM that developed with rust :) and we need database that rust use it with actix that actix developed with rust :) i think this question is Rust-Related buddy.
something like [Musixmatch](https://play.google.com/store/apps/details?id=com.musixmatch.android.lyrify&amp;hl=en_US). 
Nice job. Reminds me of [powder game](https://dan-ball.jp/en/javagame/dust/).
&gt; Neither Flutter or React are anything resembling "first rate UI toolkits". I'm sorry, but for the love of Whomever quit it with the CSS stuff people! I don't think you have a good idea about what Flutter is. &gt; "Let's take SOME_JAVASCRIPT_THING and put it on the desktop" is non-starter way of thinking about things. CSS is deeply flawed in many ways and by no means something particularly worth emulating. Besides the hostile approach against javascript (or any non specific library/framework) please share your thoughts about how is Flutter or the Elm approach for GUI so very wrong. Neither Flutter nor Elm (or React) are dependent on CSS. CSS is just popular because there are many people out there knowing this stuff, because they build Websites in the past and can translate their knowledge into other fields if "we" are gonna let them. Throwing peoples knowledge into the bin because you feel like its unusable is no valid point. Flutter, Elm, OrbTk has nothing to do with javascript ‚Äì anything other than its also using a programming language ‚Äì the reason why the Rust approaches are going in a direction with CSS etc. is because of WebRender as one of the best things we have to build from. If you don't think so, ok ‚Äì i encourage you to build something non SOME_JAVASCRIPT_THING/CSS resembling base library, that has a similar easy access as CSS. 
nice, and [here](http://arewegameyet.com/) you can find some Game Engine that developed with rust.
Last week we fixed the issue with stable. I have only small lags on debug mode and no lags on release mode. I've tested it on macOS and Ubuntu. But there are still some parts where we can optimize. This is on topic I will work on the next few weeks. A possible lag source could be the rendering with OrbClient. Maybe a switch to WebRender could improve it. Native styling is nothing that you just get from the OS or an other provider. All UI Toolkits that provides native styles for e.g. macOS, Windows and Linux have its own implementation of that styles, like Qt, Gtk+ and Flutter. Azul has also self created css files for native styles. OrbTk uses a self implemented CSS engine and provides a custom theme (wip) designed by two professional UX Designers. Maybe we will provide also platform specific style sheets later, but it's is currently not our priority. 
You probably just want to get a VPS and deploy your application on that.
The problem is that if crates expose their dependencies' types through their APIs you can get horrible errors if you use the same dependencies but a different version. Recently, I was using rusoto and a crate that used a different version of rusoto. The error I got was along the lines of "was expecting Region, was given Region". They were the same Region type, letter for letter, just in slightly different versions. This is what forcing one version tries to avoid. Of course, that approach is fraut with difficulties too. The number of times I've had a runtime ClassNotFoundError or MethodNotFoundError in Java is horrendous, as one library's dependencies are forced upgraded through breaking changes. The ideal in my mind is for internal dependencies that are not exposed through your crate's api you want to use the specific version. For dependencies which appear in your API you want to use the dependee's version, provided it is higher than yours and not a breaking change. (you can also argue best practice is not to expose dependecy's types in your API, but this is sometimes impractical and you usually can't change other people's code) 
&gt; Frankly, what I experience often is a startling lack of professionalism from community members, a standard of conduct which - while not below the bare minimum of appropriate behavior set by our Code of Conduct - I cannot imagine would be acceptable as a manner of communication to a colleague in a workplace. Seems like a good place to say, thank you core team and everyone else making a contribution to the Rust project. You are doing a fantastic job. As someone who mostly works on closed source software with small, experienced and professional teams, I have no idea how you manage to operate an open project of this scale. I guess this post is not a surprise in that sense, it's very difficult and there are no easy answers. 
&gt; One tab showing the contents of the RFC itself (and maybe a history slider, as I assume RFCs to evolve over time) As far as I'm aware, RFCs, once accepted, don't change. In order to see how a feature has evolved post-RFC, it's necessary to read the tracking issue and/or blog posts associated with the feature. &gt; Should there be a system in place for developing RFCs as a community in a central location (i.e. Pre-RFCs)? There is such a system, though it's largely informal. You can see RFC development at the internals boards by [searching for "pre-rfc"](https://internals.rust-lang.org/search?q=pre-rfc%20in%3Atitle%20after%3A2018-01-01). It's also common to see "Idea" and "Pre-Pre-RFC" posts soliciting feedback on unbaked ideas.
I'm not sure why people on this sub in general prefer actix so much over rocket, tbh. I find rocket's request-guard api and general feature-completeness much more valuable than actix' performance. Mind you, I'm personally quite comfortable with nightly, so it might be that that is the only reason. But once Rocket is stable, I would undoubtedly rank it higher than actix-web. I have trouble believing that every single use-case that gets posted to reddit actually needs to handle traffic large enough for async to be such a dealbreaker.
Really want to check this out, but my network provider blocks the website as a virus.. 
The wasm file itself is only 46kB (18kB with gzip). It's nice to know the file sizes are this good.
I think the smoke is just as low res as the rest of the things, it looks smoother because it's got nice gradients.
It is not. Your choice of database does NOT depend on the language you pick for your business language but rather on the requirements you have. Especially the difference between relational and non-relational databases.
That is an unfortunate problem to run into, but I understand your pain and frustration with it. &gt; (you can also argue best practice is not to expose dependecy's types in your API, but this is sometimes impractical and you usually can't change other people's code) And I think you've hit the nail on the head here. Library maintainers should never expose an underlying dependency's API unless it is absolutely necessary (and I can't really think of a case where a wrapper can't be made anyway, but I'm leaving the disclaimer because declaring blanket absolutes on practices leave you absolutely wrong). I have a belief that problems like this will diminish as Rust becomes more adopted and people write libraries with better APIs. I know for my current job, my only real limitation to a wider Rust adoption is the lack of a full-featured Oracle crate. But I don't have the time nor the patience to write a wrapper around the C libraries myself. I know this isn't a solution to your problem, though. There's a discussion I've seen about stable 1.0 crates being released and crate maintainers waiting for some things like async/wait being finished before they finally release a 1.0 stable API. When this happens and if people follow versioning properly, crates should be able to just depend on 1.x.x versions because the API of those dependencies wouldn't change and you'll always be running on a single 1.x.x version.
[Heroku](https://www.heroku.com/pricing) is actually one of the factors that motivated me to first learn Rust - they have a free tier, but you only get 512MB of RAM.
I'm running a Rust webserver (based on [Rouille](https://github.com/tomaka/rouille) on a Google Compute Engine f1-micro (free) VM. It doesn't get many hits, but Rust's low resource usage mean that there's tons of room to grow before I'll have to upgrade the VM. If you're looking for a more managed solution, I believe there's also a Heroku buildpack.
Any host which lets your run your own server process should be compatible. It's just a question of what complications may arise from the platform they choose. For example, some shared hosting offerings (eg. NearlyFreeSpeech.NET) are FreeBSD-based. I haven't used Rust for webdev yet, but I haven't had a problem with an inexpensive [BuyVM](https://buyvm.net/) plan so far and the people on the LowEndTalk forums seem to be overwhelmingly positive about their experiences with them. 
What does one need to learn to effectively contribute to rust-analyzer? Are there areas in which the community can help? (Recognizing that because it‚Äôs experimental_too much_ involvement is detrimental as well :) )
Sure, but surely we don't want an endless stream of reposts of old presentations, without any discussion? I assume (or hope) that OP posted this particular video and not a different one with some idea in mind. Is the topic perhaps related to the Rust 2019 discussions? Is there some RFC that has a connection? Did they recently see the video and come to some amazing insight?
In this respect, you are right. Which one should I choose now? Which compatibility is more and more stable for this job? Thank you for guiding me
What could be better approach for quickly making interfaces than HTML+CSS? Ive never seen anything better and stuff that is almost as easy to use is murkup anyway, so theres no that big of a difference.
First you need to choose between nosql and sql To decide I use a point system. Ask the following questions: - Do my different data entities depend on each other (+2 relational if yes, +1 nosql orherwise) - Do I read data more than I write (+1 relational if yes, +2 nosql otherwise) Etc If you have equal points you might consider a hybrid approach with some JSON embedded within mysql/postgres Sql preferences are kinda up to you, I‚Äôm a MariaDB guy but postgres is fine too. For NoSQL the choice is very wide and depends on what you want to do. Cross-hosts replication is amazing on CouchDB, mongo is fine for most usages etc Do your research on their advantages. Client availability is not really a deciding factor in general :)
Thanks for the tip. I did now, by 2, but you can adjust it in the url manually, too. 
You know, I actually have an algorithm specifically for this. It's not the *best* by any means, it still has problems, but it does make 2d cellular liquid level out a lot faster, and also makes liquid level equalize in a shape like this: | | | |--| | | | | | |--| |_____| I should probably post that at some point. Regardless, the simulation in this post is like *1000x* cooler than anything I did similarly, I just have an algorithm for that one specific problem.
I've been following this project with interest, though my impression was that it was still a long way from readiness. At some point I need to try writing a widget for this thing. &amp;#x200B; Two things that I would guess would slow OrbTK's adoption are: a) The reliance on SDL2. Maybe this could be rplaced by winit and one of the OpenGL/Vulkan libraries. b) Using an ECS that isn't SPECS. Maybe I'm wrong, but my assumption is this would cause problems for all the various projects that have already standardized on Specs.
Don't implement the CSS primitives. The CSS approach is good, but CSS the implementation is a nightmare of complexity for designs and implementors alike. At the very least resist the urge to do cascading inheritance. It's a source of bugs and bloated style sheets. And if you can, move layout out from the style sheets and put it where it belongs, the layout DSL. &amp;#x200B; This is an interesting proposal (there's an Elm library built upon this) for doings differently: [https://www.youtube.com/watch?v=NYb2GDWMIm0](https://www.youtube.com/watch?v=NYb2GDWMIm0)
Oh man this is so much fun. My favorite combo so far is (gas + cloner) + (fire + cloner) :D
Thank you for your Feedback. To a) You could be right. I evaluate WebRender with winit and I hope this will speed update the rendering and event handling. From the visual side the rendering of WebRender looks great. To b) Yes SPECS should be faster than DCES, but currently it is difficult to profit from the concurrency of SPECS because most steps have to run one after the other: event -&gt; states -&gt; layout -&gt; rendering. But should be DCES a point that costs us to much speed, maybe a switch to SPECS would be necessary. An other point that could cost us speed is that currently on every event the update method of all states are called. And there is also potential to speed up the event handling implementation in OrbTk. Those are all points on my agenda.
The audio part of Rust interests me also. My approach is to think about this more from the SuperCollider/Max side of things. Currently I'm experimenting with approaches for building audio synthesis primitives for working with blocks of audio data, where SIMD is handled for you. I have no idea if this is the right approach, or even doable, but it's interesting. &amp;#x200B; Other foundational things that are needed: 1) A good realtime allocator. One possible solution to that is here: [https://docs.rs/xalloc/0.1.0/xalloc/tlsf/index.html](https://docs.rs/xalloc/0.1.0/xalloc/tlsf/index.html) \- but it seems like it's still pretty immature, but maybe the community can take this work and make it stable. 2) A graph solution that is suitable for both static and dynamic signal graphs. Again, there's work out there, but it's more making it suitably generic and realtime ready.
I love the kind of symbiosis Fungus and plant have. Beautiful game!
Some noise could be introduced to make it look more pixelated.
Wow, I love the physics. Truly beautiful to play around with, much nicer than the original Powder Toy.
I would start with something like http://ggez.rs/ or the SDL2 bindings and make a very very simple game. Something like pong, or another ancient 2d game that inspires you a bit. This will let you wrap your head around some of the fundamental ideas, and afterwards you will know more about what questions to ask, what to look for, whether you want to use Rust to make games, and so on. 
Ports, macports, homebrew, pkgsrc. With portage, getting a new minor version before the distro maintainer bumps it is literally as easy as `cp` of the same ebuild to a new filename; then `ebuild manifest` to make sure it's reproducible (at least as far as the build itself is reproducible). Boom, new minor version ready for installation just as if the distro maintainer had done it. Once you've experienced this, yeah, all package managers which don't allow this are no better than setup.exe.
But without a client hard to use chosen database.
I would start with defining what you need your database to do, e.g. storing user data, reference to music stream endpoints, song info, lyrics, etc. You might want to consider something like elasticsearch as well for flexibility. Other important points already covered by the other contributors.
Awesome! I'm going to try next weekend!
I never thought I'd meet a package manager extremist. You're basically saying "if a package manager doesn't support this one feature I use (which most users literally have no use for) then all the other features are completely useless." I hope I don't have to further explain why that statement is stupid.
A good question! I think that rust-analyzer (and this whole Rust-IDE area) needs quit a bit of design, so this is the area where the help will be most welcomed. And this a big call: to be able to significantly affect the design and architecture of the project, one needs to be "in context", which requires a significant amount of dedicated time and focus (so, that's why the talk about funding). That said, building IDEs is not really rocket science: if you understand the basic constraints like lossless syntax trees, on-demand query evaluation, synchronization of data between the editor and the server, everything mostly makes sense. So, if someone feels ambitious and has a bunch of time to kill, reading through [rust-analyzer](https://github.com/rust-analyzer/rust-analyzer/blob/master/ARCHITECTURE.md), [IntelliJ Rust](https://github.com/intellij-rust/intellij-rust/blob/master/ARCHITECTURE.md), [Roslyn](https://github.com/dotnet/roslyn/wiki/Roslyn%20Overview), [swift's libsyntax](https://github.com/apple/swift/tree/master/lib/Syntax), [Dart Analysis Server](https://htmlpreview.github.io/?https://github.com/dart-lang/sdk/blob/master/pkg/analysis_server/doc/api.html), [IntelliJ](https://www.jetbrains.org/intellij/sdk/docs/tutorials/custom_language_support_tutorial.html) (click those links, they link to docs, not to code) should give a pretty good understanding of the problem space. And that should help one to pop up at the analyzer's issue tracker with issues/prs to make the core components better :) 
When I was new I had looked for tutorials for setting up a vps to run rust apps and couldn't find any good ones so I made my own once I got everything going. https://vishus.net/content/tutorials Shared hosting won't work for Rust like it would for PHP, you'll need a vps. I use linode but any vps provider, including digital ocean, would work just as well
That means you can't use a temporary local empty hashmap. But you can have one that lives in the object - [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=af94035caf70393e1118b12e329f50c9): ``` pub struct SimpleCapacityGraph&lt;N&gt; { nodes: HashMap&lt;N, HashMap&lt;N, (u128, u128)&gt;&gt;, no_nodes: HashMap&lt;N, (u128, u128)&gt;, } impl&lt;N&gt; SimpleCapacityGraph&lt;N&gt; where N: std::cmp::Eq + std::hash::Hash + Clone + std::fmt::Debug, { fn neighbors_with_send_capacity_iter_empty(&amp;self, a: N, capacity: u128) -&gt; impl Iterator&lt;Item = &amp;N&gt; { let a_map = match self.nodes.get(&amp;a) { Some(a_map) =&gt; a_map, None =&gt; &amp;self.no_nodes, }; let iter = a_map .keys() .filter(move |b| self.get_send_capacity(&amp;a, b) &gt;= capacity); iter } } ``` This solution costs memory equal to the size of an empty hashmap per graph. The author's solution costs memory equal to the size of a boolean plus padding *per iterator*, plus the time taken to do a match on every `Iterator::next`. This solution is not *quite* zero-overhead, but the author's certainly isn't. 
&gt; probably lots of other people have come up with similar algorithms. I've also heard from the creator of Noita (an action rogulite with falling sand style simulated pixels: [https://store.steampowered.com/app/881100/Noita/](https://store.steampowered.com/app/881100/Noita/) ) that Dwarf Fortress has something very similar. I forgot what the exact algorithm is like though.
I had a look at the source and figured it had to be a shader from [this folder](https://github.com/MaxBittker/sandspiel/tree/master/js/glsl), but I don't know enough glsl to get how it works. Would be awesome if anybody could explain it a little bit, very curious :)
That's almost impossible to do statically and would probably require very sophisticated whole program analysis and would fail anyway with any kind of FFI. A super simple example: ```rust fn push_1(values: &amp;mut Vec&lt;u32&gt;) { values.push(1); } ``` You can't even statically determine if this will allocate because the Vec could have capacity for additional elements or not. I think the only reasonable thing would be to have a profiler collect all allocations for each function call. That could be used to make a heatmap.
The author's approach only requires a boolean flag if it can't find a non-nullable pointer in the wrapped iterator. Spoiler alert: it can. So the author's approach is zero overhead.
Unpopular opinion : I actually think css is pretty smart / good.
Scaleway has a bunch of super cheap servers. 
Someone has to write it! The Rust ecosystem can‚Äôt thrive if people are not willing to create the libraries for their use :/
Two people already pointed out ggez, which is an excellent framework. r/gamedev might have some helpful general gamedev resources. If you'd like to see how a game is made in Rust, feel free to watch my stream where I develop a game in Rust over at [twitch.tv/walterpi](twitch).
You're right, your statement is quite stupid. Luckily it's not the one I made. Nowhere did I say that the other features are useless; merely that the overall software is broken. A thing can be broken while still having some useful features.
This one is pretty cool [Volatile Beauty](https://sandspiel.club/#S49DPN79STnmRRfxcM7X) (not mine) 
I own the entirety of the code for Algorithm M, and I own all but one routine (called `quorem`, which is MIT licensed from David M Gay) for bigcomp, that is, everything else is code I wrote or adapted from public domain sources. I doubt you're interested in the bigcomp algorithm anyway, since there is no restriction on heap allocation for the C++ runtime, but if you are, quorem is very simple to reverse-engineer (a short routine for fast basecase division when the quotient is &lt;= 10). The backend is very C++-like, so if you're interested in a port, I'd gladly help with the port if needed and can release portions of the code under a more permissive license. I'm working on a more generalized benchmark routine, so if you are interested in a comparison with MSVC's CRT, I will have those results later on. I will, however, need someone else to run the benchmark, since my current Windows machine is in a storage unit halfway across the country from me.
This is awesome, thank you so much for your hard work! I talked about crev in my [Rust 2019](https://vfoley.xyz/rust-2019/) post and how I think that writing and sharing code reviews of crates is going to be a very important tool against abuse.
Thank you very much, I'll investigate further.
[Vultr](https://www.vultr.com/pricing/) offer VPS's from $2.50/month.
Unless there is another way to allocate on the heap besides using `Box`, searching for the text `Box::new` should be a fairly effective heuristic for identifying heap allocations.
I agree. Often when someone makes a comment that lots of smart folks disagree with we wind up with fantastic educational answers/links and I learn stuff. &amp;#x200B;
With SPECS vs DCES - my thinking was more that projects that are already using SPECS might be reluctant to use a project that requires a different ECS. I don't know what the implications of using two ECS systems is, but it feels like something that would cause problems.
Is the algorithm something you thought of while making Starbound? Would gladly read the post if you decide to make it. 
In addition to Box, you should also consider things like Vec. Vec allocates on the heap, but not immediately all the time. Vec::new() does not allocate, but Vec::with_capacity() does. There are also even more complicated behaviors if you consider other crates like SmallVec which only allocates if its inner array isn't big enough. Trying to do this statically will probably be a big pain, so maybe try looking into the custom allocator API? I don't know how you would get the current call stack, but if you could, you could probably put this tool together. I saw an example a while back of someone using a custom allocator but delegating all the allocation calls to the system allocator. They were then able to collect stats about the program without actually having to reimplement the allocations.
`String`, `Vec`, and pretty much all of the other standard library dynamic container types also allocate on the heap.
Also - for back end audio, why not use PortAudio or libsoundio? I'm not sure which is better (PortAudio is used by SuperCollider, is heavily supported and was designed by Ross Bencina which may count for something - but libsoundio seems more flexible), but both are C based. &amp;#x200B; Obviously a pure rust library would be nice, but that's a big job.
The main purpose of DCES is the usage in OrbTk. I like SPECS to and it is not intend too and it is not intend as competitor to SPECS. But with a custom ECS I could adjust it faster with growing requirements of OrbTk like a tree based entity component storage.
This is somewhat analogous to how the JVM inserts safepoint checks throughout generated code - specifically, in function prologues and loop back-edges, so even more aggressively than the Go compiler inserts yields!
&gt; Neither Flutter or React are anything resembling "first rate UI toolkits". Flutter and React were mentioned in reference to the Rust API offered for creating and programming widgets. The "first rate UI toolkits" are in reference to GTK, Qt, etc. which OrbTK could easily compete against in the near future once all the primitives have been developed. &gt; I'm sorry, but for the love of Whomever quit it with the CSS stuff people! Both Qt and GTK use a variation of CSS. It's a natural means to enable user themes, and it works.
I see. I thought he was just looking for direct allocations to the heap but he wants to find all allocations to the heap. 
Good point! The author's approach still needs do a match though!
starting with rust probably isn't a great idea if you have zero game dev experience...
wow, dust is _incredibly_ flammable. this is super cool
Yes, you right. But i think the topic starter want to get answer about today, not about future. And today situation in Rust is: CDRS (Cassandra Driver) https://github.com/AlexPikalov/cdrs Postgres Driver https://github.com/sfackler/rust-postgres Redis Driver https://github.com/mitsuhiko/redis-rs Fix me, if i wrong.
I mean, if you directly use a sys crate, you're obviously going to get a worse experience than just using the C api directly in C. That's the reason Rust-based abstractions exist, like [glium](https://github.com/glium/glium), [gfx](https://github.com/gfx-rs/gfx), and [vulkano](https://github.com/vulkano-rs/vulkano). The "ulterior motive" behind Rust, as you say, is that all of these abstractions have zero overhead compared to directly using the equivalent C api functions, and offer none of the pitfalls.
There is an excepted RFC for cargo.toml to specify if a dependency leeks into the public interface. To implement it rusts privacy rules need to be expanded to lint against leaking something not marked. Someone just volunteered to do this, but I have not yet seen a PR. [lint Tracking Issue](https://github.com/rust-lang/rust/issues/44663). Also cargos resolver needs to learn to make all the visible dependencies match each other. I have been working on this for several months. At this point I believe I have an implementation that only gives valid solutions. But, it can easily take time exponential in the depth of the dependency tree. All of the ways I have tried to fix it have led to missing available valid solutions. [resolver Tracking Issue](https://github.com/rust-lang/cargo/issues/6129)
I have found heaptrack[1] quite useful for figuring out allocation patterns and sources. The GUI is also nice. You have to use the system allocator though (it's the default on nightly, not sure has it landed on stable) as it uses the LD_PRELOAD to trap the allocation calls. YMMV [1] https://github.com/KDE/heaptrack
Thanks, that's a great point I hadn't considered.
It's not for computer graphics like the others
Because you're using the GL API directly, things are going to get a bit more verbose in Rust (by design), like deadstone says. The logging code does something else in Rust (and appears broken?) as well as some unsafe blocks are needlessly duplicated. Here's my take: fn shader_from_source(source: &amp;CStr, kind: gl::types::GLuint) -&gt; Result&lt;gl::types::GLuint, String&gt; { unsafe { let id = gl::CreateShader(kind); gl::ShaderSource(id, 1, &amp;source.as_ptr(), std::ptr::null()); gl::CompileShader(id); let mut success: gl::types::GLint = 1; gl::GetShaderiv(id, gl::COMPILE_STATUS, &amp;mut success); if success == 0 { let mut len: gl::types::GLint = 0; gl::GetShaderiv(id, gl::INFO_LOG_LENGTH, &amp;mut len); let mut buffer = Vec::with_capacity(len as usize); gl::GetShaderInfoLog(id, len, ptr::null_mut(), buffer.as_mut_ptr()); buffer.set_len(len as usize); Err(String::from_utf8_unchecked(buffer)) } else { Ok(id) } } } I moved to a single outer unsafe scope and rewrote the error handling logic. The reason why this is more 'verbose' than in C is because it does things slightly different: 1. Instead of printing to stdout, a Result is returned with the error string as an error. This lets the caller decide what to do with the error (generally a good idea for libraries). 2. Instead of using a fixed size buffer, memory is allocated to hold the error string. The C code just uses a fixed size buffer of 512 chars and if the error is longer? though luck. 3. The mut keyword is necessary because Rust is const by default, you annotate the variables you wish to mutate. Is it worth it? For me personally? Definitely. Learning Rust made me a better C/C++ programmer. It made me understand more precisely the meaning of manual memory management and the underlying reason for getting it wrong (mutably aliased memory is the root of all evil). Is it really worth it? I've personally noticed a big dip in productivity, where I'd bang things out writing against the raw windows APIs now takes a lot longer (mostly down to less than steller autocomplete in RLS, meaning I'm constantly taken out of my flow to look up docs elsewhere). Is it really really worth it? I've always been a person interested in the underlying reasons for why things are the way they are and Rust has been invaluable in that. Oh and all the cool shit like Cargo and package management. Holy shit do I not want to ever touch a C/C++ codebase because of it.
Those are also great sources to look at. My current prototype uses cpal so is pure Rust. Obvious next steps are to understand the tradeoffs better. Regarding realtime allocation, that is definitely one path forward but one I chose not to pursue. One problem is that it's currently not at all easy to use multiple allocators in Rust. A goal of my work is that it can easily be integrated as, say, a sound engine in a game. I think my architectural principle of doing no allocation on the realtime thread, but allowing unlimited allocation in a companion engine thread, supports that goal well. In any case, SuperCollider and Max are definitely strong influences on what I'm trying to do. I regret not having referenced them in my talk, and will fix that when I get the blog post version put together.
I saw here recently that AWS lambda added support for Rust. 
You literally said "no better than setup.exe"
Will the team set their goals for 2019, and work, or are they just want our wishlist
Oh okay, that's good to know. It might be a good idea to mention that in the documentation at some point.
A different way of doing this could be through dynamic proving using dtrace (BSD,MacOS) or bpftrace (Linux). It requires a bit of scripting, but should provide accurate information of which code is causing allocations.
What if we pathfind the "highest" water pixel and then put it on top of the lowest one if there's space?
Thanks everyone for the advices, I think I'll start by making a "simple" game like Pong, it seems to be a good starting point. 
Why do you think that it's a good idea? 
It might be interesting to compare to Clang's implementation of strtod, or to Boost Qi, both of which [were at one time ~50% faster](https://tinodidriksen.com/2011/05/cpp-convert-string-to-double-speed/) than GCC's strtod.
Thanks for pointing this out. I'll give it a look.
You mean [this one](https://github.com/kubernetes/kubernetes/issues/68526)? There's also [a third-party tool](https://github.com/weaveworks/kubediff) to do it.
imo you should start with an engine like unity or unreal. they're still very powerful, but all the really difficult stuff like physics etc is taken care of for you.
The approach from https://github.com/Technolution/rustig to statically detect potential panics may also apply here
Upvoted for game programming patterns - /u/munificent is a superb teacher and that book in particular is an incredibly insightful resource.
Yee, it was the second water algorithm, the one that wasn‚Äôt compressible. I‚Äôll write it eventually but I can‚Äôt promise it‚Äôs anything new honestly, it‚Äôs possible that there are better algorithms inside e.g. powder toy.
I'm working on improving the benchmarks now, and that would be very interesting. Boost Qi derives off of Boost spirit, which I don't believe currently has a correct parser, so I may not use that benchmark.
Hum I see but my porpuse is also to learn Rust, i wanted to mix both objectives... 
The performance of this is *out of this world*. I've played any number of falling sand games and they always make my laptop rev like a jet engine. On this one, it didn't even break a sweat.
then dear god do not try to learn rust by making games. do you have any programming experience at all? game development is *very* hard and time consuming compared to most software development. go through the rust documentation first and get a grip on the language, then start with *simple* projects.
For Linux CPAL is pretty useless unfortunately. If you're doing consumer type audio stuff you want to use Pulse audio, for pro-audio stuff you want Jack. ALSA is a low level thing that you really shouldn't be talking to. PortAudio works great on Linux and OSX, not sure about Windows. libsoundio looks a lot better architecturally, but I'd worry about the developer abandoning it. SuperCollider uses a memory pool and then it's up to the Unit Generator author to request memory from it using a custom function (RTAlloc). That could certainly be done in Rust using Smart Pointers, though it would be tricky and probably involve some unsafe code. There's also the problem that you have a fixed amount of memory. Your approach sounds interesting. I'm going to have to look at the code base and look at how that works. I'd worry that it wouldn't be responsive enough for an engine like SuperCollider which is constantly creating and destroying synth graphs, but I could be wrong about that. &amp;#x200B; &amp;#x200B;
I don't see `rustc-syntax` in crates.io Did you mean something else?
Game programming is a vast field to learn. But that should not deter you from getting started with it. I can personally recommend LazyFoo's SDL tutorials because they teach you many concepts that are relevant for 2D games (sprites, collision detection, ...): [http://lazyfoo.net/tutorials/SDL/index.php](http://lazyfoo.net/tutorials/SDL/index.php) The tutorials are unfortunately in C++, but as far as I recall they do not use exotic language features so you should be fine diving in if you do a bit of additional reading on C and C++ on the side.
It's probably this semi-Langrangian technique: http://developer.download.nvidia.com/books/HTML/gpugems/gpugems_ch38.html I implemented this on my own a couple of months ago for fun and immediately recognized it from the shader names. :)
Roughly how it works in Starbound is that there is a hidden variable for each cell which is vertical pressure due to the water above it. This can be calculated over time using only neighbor water cells, where the pressure of a cell is something like the amount in the cell above plus its pressure. You then make water cells over and under fillable by some constant small amount, say 10% or 20% or so. Then, you allow water to flow from higher presser cells to lower pressure cells *laterally*, causing slight under filling and over filling. An under filled cell should take water from above it, and an over filled cell should move water above it. In this way (pressure controlling lateral movement, under / over fill controlling vertical movement), water will equalize around obstacles. This is super rough, because the details are really messy, and if you're not careful it will be super janky (even more so than Starbound!) and there are a ton of edge cases. However, it is an algorithm where the operations on a cell only depend on the neighbors, which is a requirement for it to be anywhere near fast enough. I have no idea if this is the same or similar to anything else, but it wouldn't surprise me *at all* if I was not the first person to think of this, but mine is probably in some ways at least mildly different because there seemed to be a lot of ways to do it. Before that change, the algorithm was simply to allow a liquid cell below a given cell to overfill to some constant factor like 1.1x of the fill level of the cell above it and allow fill levels to equalize laterally. This is nice because there's no pressure, but the problem is that as you get like 10 blocks down, blocks now have 1.1^10, or approx 2.6x the amount of water they visually do, and it just gets worse the higher the column, so water becomes really really compressible and it feels wrong. But seriously the stuff in this demo is really cool and there are a lot of cool reactions that are more interesting than any stuff in Starbound, *and* it's done on the GPU. I'm really interested in taking a deeper look at the source to see what all the algorithms driving it are.
A database is tangential to the language. And is more often than not, much more important. But the thing is, if you are asking, then the choice is *clear*. And even if you think you know, more often than not, the choice is still clear: - A relational database is for everyone - A NoSql is for *specialist* in a *very limited set of really really really circumstances* For RDBMS, use PostgreSQL, if wanna a centralized database, sqlite (or firebird) if wanna one for easy embedding. Both are so good at what them do, that choose anything else must be truly qualified. A NoSql is more often than not an unnecessary mistake made by noobs. I use here, the word noobs because I wanna make clear how (unnecessarily) wrong is it! Exist real context where a NoSql make sense. Use redis as cache or for simple pub-sub coordinator. ------ P.D. Is certain you will try to argue against this advice. I already know ALL OF YOUR POINTS, I already have be part of big NoSql/Rdbms projects, and still the advice is solid as is. Without more concrete reason to deviate, is the best possible advice to give (just use a RDBMS). 
Spirit.Qi is ancient; try Spirit.X3 if you reassess it. :-]
There should be a way to disable the compile step when publishing. It currently only serves as a safety check to ensure nothing broken is published (which I think is reasonable). That might solve the problem! ‚ú®
I'm fairly unfamiliar with Boost Spirit, tbh. Thanks for the tips. Is Spirit.X3 a correct parser?
I have my benchmark results tentatively up, they're somewhat biased against RapidJson (there's nothing I can do, unfortunately, since RapidJson pre-parses components from the string before actually doing strtod, and this code is very messy and long, so I have to invoke the full JSON parser, which adds maybe 80 ns of overhead). However, Lexical is ~2.5x faster than Rapidjson asymptotically, and is competitive with small inputs. I'll be publishing the benchmarks later.
I'm not sure, as I'm not sure what issues you found with Qi; but it's an entirely different codebase targeting C++14, so one would hope the issues you had were resolved in the rewrite. Current X3 docs are here: https://www.boost.org/doc/libs/release/libs/spirit/doc/x3/html/index.html
&gt; If I naively build then copy over a --target=x86_64-unknown-linux-gnu` binary, one will discover that the machine I want to run on has an incompatible version of openssl, and that the GLIBC load/run-time check is gonna fire and tell me that I have the wrong version. Okay, there are two really different things going on here. One is that you have dynamically linked OpenSSL (or some other third-party library). This is definitely a pain when trying to build portable software! Static linking is useful here. Fortunately, this has nothing at all to do with whether stdlib is statically or dynamically linked; you can control it by setting the [OPENSSL_STATIC environment variable](https://github.com/sfackler/rust-openssl/blob/master/openssl-sys/build/main.rs#L575) when building. The second is that you have dynamically linked libc. This, fundamentally, is absolutely fine. libc, and some related libraries like libm, librt, libpthread, etc, are part of the operating system, not part of your application. It is entirely appropriate to link to them dynamically. Indeed, it's only on Linux that it is even conceivable to link to them statically - on other operating systems, the libc is the only supported interface to the kernel, and you need to use the one supplied by the environment you're running in. And it's absolutely fine to dynamically link to libc etc while statically linking to third-party libraries! Your only problem is if you link to symbols in libc which are available on your build machine, but not your deployment machine. Because glibc symbols are versioned, this can happen if you link to a version of a common symbol which is available on the build machine but not the deployment machine - memcpy@GLIBC_2.14 and memcpy@GLIBC_2.2.5 are not the same! Obviously, if your program uses a symbol which just isn't there, you're stuffed, but if it uses one where there's a version difference, you should be able to compile it to call the older version. This is where my knowledge runs out - i know that in C, you could use a `symver` directive to the assembler to pick a specific version of a symbol that you knew was widely available, but i have no idea if you can do this in Rust. Looking at the pre-compiled Rust stdlib, that seems to link to very conservative versions - the one that comes with Rustup's 1.31.0 links to no symbol newer than GLIBC_2.4 (and uses the GLIBC_2.2.5 version of the [infamous](https://www.win.tue.nl/~aeb/linux/misc/gcc-semibug.html) memcpy). So you should be fine if you only touch libc via stdlib. But what if you use libc directly, or via some third-party library (eg [libc](https://github.com/rust-lang/libc)!)? The only thing i can think of is to find some old version of libc, and use that in your build process, so you get the right symbols :(. 
Filling the screen with dust then burning it.. so good
&gt; appropriate *system* libraries &gt; some dynamically linked [*third-party*] library This makes sense if you're explicit about the difference!
I don't see a benchmark in that post, so you don't get to say "slow". It certainly involves more instructions, but modern CPUs have evolved to minimise the cost of those - branch predictors and all that. 
That's a different approach, where Rust handles the he business logic, but the request itself is handled by AWS API Gateway. 
I see why there would have to be type inference for the general case (`fn bar() -&gt; impl Trait`), but I am not sure why completion would have to die when it's a concrete type. Here's a silly example: ```rust impl SomeT { fn foo(&amp;self) -&gt; SomeT fn bar(&amp;self) -&gt; SomeT ``` Is it because the "dump JSON type data" method doesn't actually include every concrete type in scope? Or does it not even attempt to look up the return type of the completion it just provided? 
Would you be so kind as to create a wandbox link demonstrating the issue so it can also be used to file a bug report against Qi?
&gt; I was the director of the 2016 US Go Congress lol no gener... &gt; it was a solid half-year before I had any desire to play Go again Oh, the game, cool. I'm glad it's not just Rust that has this problem!
I would absolutely love to see the multi-threading aspects of Rust working properly on the web. Two of the things the company I work for are currently investigating are: 1. the parallelisation of our web application. 2. integration of web assembly. They were originally looking at C++, but I have convinced them to consider Rust instead. So far they like the idea, but some of the features aren't quite there yet. Just in case anyone was wondering, we build online CAD software.
&gt; Rust is running a marathon, not a sprint. Please go at a pace fit for the growing the language, its organization, its community, its people, for the long haul. I want to be programming in Rust for a long, long time. *CAN I GET A HALLELUJAH!* I am a Java programmer by trade. I have been working in Java for over twenty years now. I will be working in Java for another ten years at least, probably twenty, maybe thirty. There are mistakes made in the first few years of Java's life that still hurt us, and will still hurt us for decades to come. If mistakes like that in Rust can be avoided by postponing a feature for six months, a year, two years, then that is very, very clearly the right thing to do if the language is going to stand the test of time. I'd rather be able to use a solid language in ten years than to boast about having the dankest async web framework next summer. 
RLS does not use that JSON data for completion at all. It uses a separate tool, \[racer\]([https://github.com/racer-rust/racer](https://github.com/racer-rust/racer)) for code completion. Racer itself knows relatively little about the semantics of the Rust languages. I don't know why it fails for chained completions though. 
From what I can see, and others have confirmed this through use, but it's simply not a correct parser and uses intermediate floats as values. This is a good approximation, but simply put, it's not correct: https://github.com/boostorg/spirit/blob/b4c5ef702bf6c28e964a84c9e9abe1a6549bce69/include/boost/spirit/home/x3/support/numeric_utils/extract_real.hpp https://github.com/boostorg/spirit/blob/b4c5ef702bf6c28e964a84c9e9abe1a6549bce69/include/boost/spirit/home/x3/support/numeric_utils/pow10.hpp This might be a decent approximation, but there is simply no big integer support anywhere from what I can see. Unless things have radically changed from the last time I used it, it's very simply not a correct parser, not does it aim to be.
Like others, I'm using a VPS. Specifically, I'm using Lightsail by Amazon. It's a flat $5 per month with plenty of room for a low traffic site.
Yeah I've already a programming experience, and i've already do program in Rust but only simple things like a chat using Tokio, only simple stuff but I wanted to find something challenging to do, I've already went through the Rust documentation... I know the basics of Rust. 
ahh ok my bad, for some reason i was under the impression you didn‚Äôt know any rust yet. in that case go for it
Here we go, as confirmed. https://wandbox.org/permlink/aepaE7D1m71oS7uN This should print `5e-324`, but since it doesn't use correct float-parsing rules, and uses intermediate floats as values, it cannot correctly parse such a string. It's a fine parser for a non-correct one, but simply put, it's not correct, nor does it aim to be correct.
I never use "complete statement" either. The way i work is to autocomplete closing delimiters when i write an opening delimiter, and then fill in the delimited space: if () if (()) if ((a + b)) if ((a + b) * c) if ((a + b) * c == map.get()) if ((a + b) * c == map.get("key")) 
Thanks. I agree with everything you said in your post. :) I recall at least [on more #Rust2019 post](https://medium.com/@GolDDranks/rust-2019-let-us-pursue-composability-70f1eb2238c3) that mentions `crev`. Hopefully we can make this 2019 wish come true! :)
Thanks! cargo publish --no-verify Did the trick! 
this is so dope. 
Sorry, my tone seems to be a bit abrasive. That shouldn't be the case, and I apologize. I don't mean to be abrasive, and I'm sorry if I sound like I am.
X3 gives \`-nan\` [https://wandbox.org/permlink/rgucdotj0s0GUEag](https://wandbox.org/permlink/rgucdotj0s0GUEag) which is a good bit nicer than silently passing. To this end, the parse now exhibits correct behavior within its bounds. &amp;#x200B;
`Vec::with_capacity(0)` is guaranteed to not allocate. Same with a `Vec&lt;()&gt;` or `Box&lt;()&gt;`. If OP want to do this statically they'll probably have some false positives. To get around that, they could have some kind of `#[i_promise_i_wont_actually_allocate()]` attribute.
I have to say I'm really impressed that it managed to maintain a framerate of no less than 24fps on mobile Firefox on my phone üòÑ no matter what crazy stuff I threw at it!
That is definitely an improvement. If you would like to, there's a concise, accurate set of difficult-to-parse floats you can test against with X3. https://github.com/ahrvoje/numerics/blob/master/strtod/strtod_tests.toml
Yay, glad it worked! :D
I've been looking through these crates, but please forgive me as I have never needed to use this functionality before: Can you please provide a list of functions that you would be concerned about for performance? 
really thanks. great explanation. I think I must use mysql or mariadb then for my projects with actix :)
You don't. ;-]
A section close to the top for alternative RFCs would be great too, especially if their "score" is also immediately listed. This way you know if there are other proposals with a similar agenda. --- One question about moderation: how do you handle authentication? Delegate to Github?
What a great live game!
&gt; Regarding resolved concerns (if resolving is implemented), they should still be visible (but visually distinct) so that the issues don't get re-raised. And maybe a status on the "resolution": irrelevant, obsolete, known, ...
I'm working on launching a side project ([byobudget.com](https://byobudget.com)). It's actix-web/sqlite3 backend with very little javascript on the frontend (just enough to use google for authenticating). I'm also working towards polishing up a special git hook that is a replacement for git submodule/subtrees in certain limited circumstances: [https://github.com/samsieber/subgit-sync](https://github.com/samsieber/subgit-sync) &amp;#x200B; I'm going to try to release a new version of rubber-duck ([https://github.com/samsieber/rubber-duck/blob/master/README.md](https://github.com/samsieber/rubber-duck/blob/master/README.md)) to have it work on stable. Well, it'll take a slightly different approach, but still should be very readable.
Based on the response of [this comment](https://reddit.com/r/rust/comments/a6rfia/rust_2019_organizational_debt/ebxo0f9?context=3), I'm working on a small design proof of concept for rfcs.rs. I've started a basic readme for https://github.com/k3d3/rfcs.rs and hope to have some screenshots early in the week. 
That's exactly what I'm thinking. Github seems to be where the community is, not just for rfcs but also crates.io and related things. Using it for auth means there are fewer things to screw up, and network effect doesn't come into play because people don't need MORE accounts to contribute. That's an interesting idea with regards to the scores - I like it! 
&gt; With regard to voting - the Rust leadership is strongly opposed to using voting as a means of gauging community opinion. There are a few factors at play, the strongest of which is that votes don't present a strong signal in a technical context. It's impossible to tell &gt; why &gt; something was voted upon. That said, it may make sense to use voting at specific points in the process--it would be interesting, for example, to use votes for controversy detection. Indeed, votes are a mixed bag. People may vote up/down because they identify (or not) with the motivation, or because they appreciate the particular solution presented, and an aggregate score doesn't tell you which is which. Actually, this makes me wonder if we should first separate *problems* from *RFCs*: - This would split the above vote, making it clearer whether people are keen to see the problem addressed, or particular supportive of the proposed solution. - This would naturally allow multiple concurrent solutions to the same problem to be presented. - This would allow notifying that a known problem is NOT considered relevant for the year to come; thereby immediately signaling to would-be RFC proposers they should not waste their time trying to propose anything until they the problem is open for proposals again.
Calling into dynamically linked libraries introduces problems for compiler optimization. For example, inlining becomes harder: [https://kristerw.blogspot.com/2016/11/inlining-shared-libraries-are-special.html?m=1.](https://kristerw.blogspot.com/2016/11/inlining-shared-libraries-are-special.html?m=1.) Also, I disagree with your point that you need a benchmark to declare something as slow. Most if not all benchmarks are meaningless, especially in blog posts.
Yes, but it's a very useful linear algebra crate -- basically the numpy of Rust. For CG stuff, I think nalgebra-glm, cgmath, and vek are pretty comparable. For general purpose linear algebra, rulinalg, nalgebra, and ndarray should be compared.
I fully agree with you that morphing rustc seems like a less than ideal way. I am afraid that rustc is relatively monolithic with some baked-in assumptions that will make a number of changes painful. This is not really particular to rustc, either, assumptions just tend to slip in. This makes rustc cumbersome to refactor, and therefore make it difficult to *explore* using rustc. I am very much looking forward to the result of rust-analyzer and where your explorations take you.
Out of curiosity, I recompiled my rust binary (a numerical simulation) and it ran 9x slower with musl vs the default glibc linking. I haven't profiled the difference, but I'm guessing it's in libm.
It's a smaller job than it looks. One thing we talked about on [#synthesizer](https://xi.zulipchat.com/#synthesizer) was starting with a known backend and then replacing it piece-meal, to eventually have a pure rust solution. PortAudio and libsoundio don't support ASIO drivers out of the box, which is kind of a headache on Windows. One issue with those libraries is more philosophical in audio software. They all work as a glorified interrupt service routine. The device has a buffer, calls your ISR (callback) over and over. Say you're making a game or a synthesizer (or a synthesizer game...), most of the time you don't care about which device is instantiated, or what's in the buffer before you fill it, or if it's interleaved/blocked, or what the size of that buffer is. You just want to fill it with a slice of audio that's already been rendered. Ideally I'd like an audio interface that allows stuff like this: // likd in a game menu or something async fn menu_handler (mut state : ApplicationState) -&gt; Application State { // do something to the menu audio_out!("menu_sound.wav"); state } Now I've got no idea how to do that safely or with low latency. But it's a goal I think we could achieve in Rust eventually, as opposed to writing a bunch of messy callbacks. There's also the issue of safety. The Borrow Checker essentially assumes that interrupts don't exist. You have to be careful with how you wrap your audio IO layer to guarantee safety, and doing that with an ergonomic interface is tricky. Essentially I think there's a lot to be gained from writing any audio layer in pure Rust, but starting from a known C/C++ library that gets things right is the best path forward. 
Related: https://crates.io/crates/qadapt (allows to verify that no allocations are made)
I have not tried it myself, but if you are able to compile to wasm you can run Rust functions on Cloudfare workers.
You probably want a VPS; e.g, DigitalOcean/Vultr (or pay up front for a few years a la SSDNodes). If you want cheap hosting per month that's shared but still gives you the ability to do stuff, WebFaction isn't bad (but they were bought by GoDaddy last year, so no idea if still good).
I added double\_conversion to my benchmarks, the new benchmarks are here: **Simple Data** [https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof\_simple\_f64.png](https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_simple_f64.png) **Denormal Series** [https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof\_denormal\_f64.png](https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_denormal_f64.png) **Large Series** [https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof\_large\_f64.png](https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_large_f64.png) I didn't add any lossy parsers, since they don't properly parse complex data, but you can extrapolate from this and see that we are likely the fastest correct parser except strtod for complex, denormal floats, and since lexical is \~5-7x faster than strtod for simple inputs, we'd likely be competitive with the lossy parsers as well.
I wonder if you could make a powder toy style thing, using continuous cellular automata, like [smoothlife](https://arxiv.org/pdf/1111.1567.pdf). It would probably be much harder to tune, but would definitely be cool. ([example of a smoothlife ruleset](https://www.youtube.com/watch?v=KJe9H6qS82I))
Done, I added comparisons to RapidJson in here. Lexical's Algorithm M implementation is quite a bit faster for all inputs: **Simple Data** [https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof\_simple\_f64.png](https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_simple_f64.png) **Denormal Series** [https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof\_denormal\_f64.png](https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_denormal_f64.png) **Large Series** [https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof\_large\_f64.png](https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_large_f64.png)
I guess there's two categories of libraries here -- CG libraries like vek, cgmath, and nalgebra-glm, and linear algebra libraries like rulinalg, nalgebra, and ndarray. For the linear algebra libraries, I'm mostly interested in whatever functions they have in common with Eigen. Maybe replicate part of [this benchmark](http://eigen.tuxfamily.org/index.php?title=Benchmark_Intel) but in Rust? Matrix multiplication/addition, matrix-vector multiplication, matrix-scalar addition/multiplication, transpose, maybe convolution, etc. For the CG libraries, I found [this benchmark] (https://github.com/mfoo/Math-Library-Test/blob/master/README.md), which might be a good point of comparison.
I started a termion based tool letting you explore file hierarchies, a little like tree but smartly trimmed to fit the screen, fuzzy searchable, showing sizes, and acting as a configurable launcher. https://github.com/Canop/broot I'm just starting rust, and only coding on evenings, so it obviously doesn't meet the highest code standard yet. I'd be grateful for observations regarding possible improvements in that regard.
I had a lot of fun playing with this! great job!
Neither ;) The first step is to draft a vision for 2019, then set some goals. The second step is to organize the community to achieve those goals, by establishing teams with mentors in charge of defining sub-goals to ease participation of volunteers. Then, and only then, will the teams and the volunteers they attract get to "actual" work. Planning for hundreds/thousands of yet-to-be-identified contributors is tough!
Yeah I don't think this is giving RapidJSON a fair test unless you extract the whole JSON parser (which I realize is a good bit of work because of all the C++ stuff in there). I might just remove it from the results if you can't compare it accurately. It would be very surprising that RapidJSON would use their own parser if it couldn't even outperform strtod like your benchmarks indicate
Getting lldb and gdb _out of the box_ will be a hit once shipped !
Nothing will put you in a Christmas Spirit like reviewing crates with Rust community. ;) _ _ ((\o/)) .-----//^\\-----. | /`| |`\ | | | | | | | | | | | | | '------===------' [source](https://asciiart.website/index.php?art=holiday/christmas/other)
And not only a team leader and an implementer, but a community herder and RFC editor!
&gt; for the number of "ready willing and able" developers Rust has available to it compared to other open source projects, it has objectively not achieved/implemented as much as it probably should have by now Seriously?! If you're talking about working on the language and stdlib, then the bar for ability is rather high, as is the bar for readiness, in terms of committable time. I'm a pretty great developer (at least my mum thinks so), and i doubt i would pass the former bar, and certainly wouldn't pass the latter, given that i have a full-time job and a part-time life. And yet, i think the Rust project has achieved a great deal. It's tackled problems no other languages have, and mostly come up with good solutions. I'm genuinely interested to hear why anyone would think differently.
...or an ALB: https://docs.aws.amazon.com/lambda/latest/dg/services-alb.html
I have a question about how the borrow checker works. This code is rejected by it: fn foo&lt;'a&gt;(a: &amp;'a mut String, b: &amp;mut &amp;'a mut String) { } fn main() { let mut s1 = String::from("asdf"); let s1Ref = &amp;mut s1; let mut s2 = String::from("qwer"); let mut s2Ref = &amp;mut s2; foo(s1Ref, &amp;mut s2Ref); println!("{}", s1Ref); println!("{}", s2Ref); } I understand why this code might not be safe, for example foo could contain this code: *b = a in which case I would have two mutable references to the same data after foo finishes. I know that the borrow checker analyses each function on its own just using the signatures of called functions. So how does the borrow checker determine in this case that this code isn't safe and that s1 is still borrowed after foo, with only its limited information? In general I would like to have a more in depth understanding on how the borrow checker works algorithmically. Do you guys have any good resources for that? 
Yeah, it's somewhat difficult to analyse mostly because of the fragmented logic all over. It may be somewhat unfair, but I think it's \*mostly\* a constant factor addition since it just needs to find the right branch to execute on. I think the rationale is that RapidJson is a lot faster for simple inputs, where strtod tends to be extremely slow, and then slower for extremely rare cases.
Rust compiles to a binary so you don't really need a runtime. Any VPS or container-based deployment should work.
CSS is kinda' Turing-complete.
Is there a tutorial or intro for OrbTk? It sounds intriguing.
A nice bit of web programming. The smoke effects look cool. Pity solids don't conduct heat - the first thing I always try and do in these is boil a pot of water. If you've never seen this kind of thing before, the canonical PC example is The Powder Toy, which is so amazing I wish there a 3D Minecraft-like version. But it's really CPU-heavy even in 2d.
Working to get ggez 0.5 workable by new year, come hell or high water. :D Progress has been erratic but we're getting there. Think we've gotten the projection math junk licked, for images and meshes. Now just have to propagate those to changes up to the text and canvas graphics systems. After that it is down to fixing/working around some dependency bugs and writing lots and lots of docs.
You should reborrow your arguments. This is not automatic unless the thing being borrowed is a method receiver (so `&amp;mut self`). I'm on mobile so can't check right now but I am 95% sure that `foo(&amp;mut *s1Ref, &amp;mut s2Ref); ` should compile just fine (just doubting whether you may have to reborrow `s2Ref` as well).
It looks like you want the features to be exclusive, but cargo crate features can only be additive. So there can be compatibility problems with this approach, although it could be unlikely given the application.
The \`flat\_map()\` idea is really cool. Also, I didn't know about \`Option.into\_iter()\`. I hope to be able to add it to the list on the post soon. Thanks!
All three of those benchmarks seem to say that RapidJSON is slower than strtod
&gt;intriguing You could check the [Readme](https://gitlab.redox-os.org/redox-os/orbtk) and the [examples](https://gitlab.redox-os.org/redox-os/orbtk/tree/master/examples). You could also build the documentation `cargo doc --no-deps --open`. A book is also planned. &amp;#x200B;
There are a few possible tools for organizing the parts of an RFC: * mind map * wiki collaboratively edited * concern tracker * checklists (e.g. for interactions with other features) Those may partially solve the *presentation* problem, but leave open the *consensus* problem: Wikis are too easy to edit, we'd like something that gives us a bit more control at the cost of more friction while formulating concerns and ideas. For those we could use a multi-tier 'sponsoring' approach, or something else entirely.
Yeah Windows support in general is a headache for audio stuff. RTAudio does seem to have better support generally. I think my concern with porting an audio library to Rust would be less doing it, and more keeping it up to date. I agree that in principle that a pure Rust audio library would be better, I just worry about the practicalities given the resources available to us. But I'm more than happy to help with such an endeavor. &gt;One issue with those libraries is more philosophical in audio software. They all work as a glorified interrupt service routine. The device has a buffer, calls your ISR (callback) over and over. Say you're making a game or a synthesizer (or a synthesizer game...), most of the time you don't care about which device is instantiated, or what's in the buffer before you fill it, or if it's interleaved/blocked, or what the size of that buffer is. You just want to fill it with a slice of audio that's already been rendered. But at a low level isn't this what I want? Sure a library built on a higher level may abstract these problems away for you based upon your preferred domain. But if I'm writing a professional audio app I need to be able to select my external audio card (I may have more than one) using the right driver (on Windows there maybe more than one). And interleaved vs block audio, data types etc - these things can be quite important. I don't know about Raph, but my audio stuff assumes block data (it's easier to work with) and f32 datatypes. On the other hand if I'm playing back a WAV file, I probably want interleaved (as that's what the file is). My vision for audio would be to have a base crate that handles access to the audio card in a standardized fashion (essentially what PortAudio/libsoundio/RTAudio do) and does the absolute minimum. And then have multiple crates built on top of that, all of which are optional. If I just want to be able to play audio files then I use simple-playback crate (which depends upon RTAudio\_RS), and it handles choosing the right backend for my filetype for me, and streaming the data in a performant fashion. As for ISR. I would have to defer on this issues to do with the borrow checker, as I don't entirely understand what those might be. But if you want to do real time audio (by which I mean I mean audio software that responds to real time events such as external audio, MIDI, OSC signals, etc) and keep latency to a minimum then you need to generate audio on a strict clock (the audio card clock). So usually it looks something like this: * **NRT Thread** \- This receives events which are placed in a queue accessible by the audio Real Time thread. * **Real time Thread** \- Woken up every blocksize samples. * **Wakeup** \- Review events from queue and update control signals/dataflow graphs on the real time thread. * **Generate Audio** \- Write Out the data for the next blockGenerate Audio for the next audio block * **Sleep** I don't think you can do realtime audio and have good latency without following that model. Now that model doesn't work perfectly with ISRs, so there's definitely scope for rethinking it, but I don't think there's a real alternative to it.
I am currently working on a parser for Nintendo Switch file formats, so I am learning "nom" and macros now. Atm I don't really get the point of why you should use nom over some dedicated functions ü§î
You're right but that's without the adjustments. I'm guessing (ballpark) that the overhead is like \~80-90s for the overall JSON parser before the float parsing kicks in (this is because the extremely fast path is hard to optimize against, since it just parses an integer and converts it to a float, which is basically the baseline for any float parser), because of the first value. For that first benchmark for simple data, that means that we go from \`1171744.3947368376\` in 10,000 iterations to \`271744.3947368376\`, or \~4x faster. If that is the case, we then get the following benchmarks, corrected: [https://imgur.com/a/HmgtpT5](https://imgur.com/a/HmgtpT5) &amp;#x200B; It's then competitive for most simple plots, and not too far behind for very complex input.
Just a nitpick, in the `new` method you get a &amp;str and promptly make it a String. You should get a String if you need ownership, the person calling it can decide what to do. I would recommend checking the r2d2 implementation for other clients to learn how to test.
I literally spent the whole day playing with this! It consumed nearly all the battery charge and nearly fried my phone, but it was great fun! Great job!
is there a better suited mechanism for this in rust?
I apologize for my ignorance but this is the first time I've heard of the term 'reborrowing', so i'm not sure whether I understood it correctly, based on your comment. How does/should `foo(&amp;mut *s1Ref, &amp;mut s2Ref);` change the behaviour of the code. Shouldn't `&amp;mut *` cancel each other out? I tried it out but the compiler error message stayed the same.
Lol don't even worry about it
This is exciting! Let us know if you want any help with it. :)
Clippy is great but I have one major issue with it - warnings are only ever printed once. Additional invocations will report nothing. Cargo check has the same issue and it‚Äôs very annoying. This means that after running either of them I can‚Äôt be sure everything is fine if I get no output. I‚Äôm sure there‚Äôs a bug about it somewhere that I can‚Äôt find right now but this has annoyed me for a long time.
How much of a pain would it be to publish multiple crates from your codebase?
So in a perfect world what I envision is a number of layers that accomplish this stuff, not an end-all-be-all audio crate (which is my personal issue with cpal, it abstracts things that I feel it shouldn't). &gt;My vision for audio would be to have a base crate that handles access to the audio card in a standardized fashion (essentially what PortAudio/libsoundio/RTAudio do) and does the absolute minimum. Totally agree with you on that. But the issue is that no driver API accesses the device in the same way, so we need robust error/warning handling for downstream crates so they can have sensible fallbacks while not limiting what features of the APIs users can take advantage of (varying buffer sizes, in-place versus out-of-place processing, multiple devices active, different sample rates for input/output, etc). For example, blocks of f32 samples for input and output. To do this in the audio layer you need to implement de/re-interleaving of audio and data type conversion. That's a non-zero cost abstraction that isn't provided by the driver APIs. RtAudio handles this in the library, but should we? By the by, we already have an rtaudio-sys crate that wraps the C API, PM me if you want access to it (it's not public at the moment). &gt; I would have to defer on this issues to do with the borrow checker, as I don't entirely understand what those might be It's basically a lifetime problem, because you're supplying the callback through an unsafe (C) interface you can wind up dropping objects before the audio stream is closed. Classic use-after-free bug, same deal as in C/C++ audio, you have to handle this explicitly when you develop your API. I understand the hard/soft real time issues (although it's debatable how strict those rules _need_ to be for different APIs), but I'd contest your layout of how the callback should work. Imho the audio callback only exists for rendering/reading audio. Deltas to the graph should be resolved in the application logic, and to propagate those to the audio thread you can either hot swap pointers at the top of the callback, or stop and restart the stream (which is under utilized as an option, imo). When it comes to what I'm talking about, what I mean to say is the audio layer should be designed with the intent of things being built on top of it. Essentially don't limit or make assumptions about what is happening downstream, and once that's done we can build cool abstractions on top of the layer. &gt;so there's definitely scope for rethinking it, but I don't think there's a real alternative to it. Write a kernel extension/module/driver in Rust that can function with audio class 3.0 devices, falling back as a system API when that's not possible. 
Yeah it's a bit annoying, I use something like `touch src/lib.rs &amp;&amp; cargo clippy`.
I wouldn't publish any of these numbers for RapidJSON, it is just not right to do so.
There's a tracking issue with both clippy and cargo (on mobile or I'd look up links). There's hope to somehow leverage the mechanism cargo-fix uses in clippy as well. The main difference is that while cargo-fix is part of the cargo code bases, clippy is currently it's own separate tool and thus can't directly access cargo's internals.
If I have a function which takes a collection of strings, what type should I use for that parameter? Currently I'm using "param: &amp;[String]", but I don't think it's the most general or most flexible type I could use.
That's a good idea. Thanks. And the reason I used &amp;str as the function argument, is that I wanted to more easily call the function with a literal string (string slice in Rust) instead of having to call into() or String::from. Maybe I should just use str? But I'm not sure that would be valid in Rust. Since I'm off for the night, I can't test but I still wanted to reply. I will follow your advice tomorrow.
How good is rls support/autocomplete in vim currently?
Being able to step into code and do all the other IDE conveniences is so so vital to me that I can't believe it's not happened already.
In Rust there is https://github.com/danburkert/prost OR https://github.com/stepancheg/rust-protobuf OR https://github.com/tafia/quick-protobuf When interfacing to other code with Protobuf messages, .proto file in proto3 syntax is available. Now... why would I want to choose one lib/crate over the other? :-/ I just want to receive an array of bytes -&gt; struct of message, or instantiate new message with certain field values and then -&gt; bytes. Advanced things like enums, oneof, repetitions etc. are used.
It's to avoid useless allocations. If the caller has a `String` that they won't use anymore they can move to `new`, otherwise they clone it (or make the `&amp;str` into a `String`). I get that allocating for every function is a hassle, but the function shouldn't hide it from you. If it doesn't need the owned `String` you pass `&amp;str` to it.
I'm looking to design a trait to provide access to both a struct containing rust primitives (u8) and a struct holding an Rc&lt;RefCell&lt;&gt;&gt; of the first struct. I think I'm close, but I can't seem to beat the lifetime issues: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c5a268fbc33e3ee08d7fe51e2e5addc1 I am ok with runtime borrow checking.
Because even though the macros generate a lot of code, the compiler ends up taking that generated code and turning it into very efficient state-machine based parsing. So you get largely readable and maintainable code that compiles down to very very efficient code. You get the best of both worlds. 
I work in infosec. Some time ago, I wrote a tool for command and control over the DNS protocol. Server was Ruby, client was C. I've been trying to re-implement the client in Rust. So far, I have basic data-over-DNS running, nothing fancy, but I'm proud because it's the first thing I've written in Rust outside of toy projects. There's not much there yet, but if anybody is curious: https://github.com/iagox86/dnscat2-tunneldrivers-dns-client
&gt;But the issue is that no driver API accesses the device in the same way, so we need robust error/warning handling for downstream crates so they can have sensible fallbacks while not limiting what features of the APIs users can take advantage of (varying buffer sizes, in-place versus out-of-place processing, multiple devices active, different sample rates for input/output, etc). Oh okay, so you envisage a library that provides a robust mechanism for querying the sound card to identify it's capabilities, provides an APi that allows you to use whatever mechanisms a sound card might have and which relies upon external crates to provide fallback mechanisms if the sound card doesn't provide them. This makes considerable sense, though the API design sounds challenging. &gt;It's basically a lifetime problem, because you're supplying the callback through an unsafe (C) interface you can wind up dropping objects before the audio stream is closed. Classic use-after-free bug, same deal as in C/C++ audio, you have to handle this explicitly when you develop your API. Oh right. Sure this makes total sense - I think I was reading way more into what you were saying. Having thought about this more (thanks for patiently going through this with me), I think I agree with you that audio callback isn't necessary. So essentially in RTAudio/PortAudio the callback does two things for us: a) Provides a mechanism for getting audio to the soundcard - think we can both agree that's terrible. b) Provides an event timer - think we both can probably agree that that's...inelegant. For (a) Write to a ring buffer (or whatever) and then hotswap it whenever the card needs audio (and make sure something sensible happens if the user hasn't managed to get audio there in time). The user probably shouldn't even need to know about this part of the library. For (b) provide a realtime scheduler that uses the sound card's clock (this should probably be in a separate module). This would be easier to use, way more flexible and could be used for a variety of other tasks (e.g. MIDI processing). &amp;#x200B;
Like [so](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=a96ebf4d97867bae078183d5be82585c).
Also you could use a generic parameter that implements Into&lt;String&gt;. fn new&lt;S: Into&lt;String&gt;&gt;(s: S) -&gt; Self { Self { connection_str: s.into() } }
intellij currently detects when I make a syntax error, but other kinds of errors are not reported and aree only reported at compilation time. Does anyone know what is this caused by? Does anyone know when all compiler errors will be IDE reported?
Shameless (ok, not quite) plug: I wrote a cargo plug-in ([\`cargo-with\`](https://github.com/cbourjau/cargo-with)) which makes it much easier to run your tests or binaries through something like \`gdb\`, \`rr\`, \`valgrind\`, ... Its rough around the edges, though, but if it works, it works! That being said: Having this as a build in feature would be amazing!
I'm debating how to design a proc-macro to basically write type and data checked FFI-externed prefaces for Rust-native functions. For example: #[arcana] fn foo(s: &amp;str)-&gt;usize {...} would become: extern "C" { #[no_mangle] fn foo(s: *mut u8, s_len: usize) -&gt; usize { //turn the pointer and len into an &amp;str and validate let out = foo_inner(safe_s); return out; } } fn foo_inner(s: &amp;str) -&gt; usize { ... } 
Sounds good. With holidays coming up, maybe I'll have some time to get started. &amp;#x200B; Would also be fun to participate in the WG meetings. Schedule is actually favorable to my other plans. I'll keep an eye on the repo.
\`fn foo&lt;T: AsRef&lt;str&gt;&gt;(param: &amp;\[T\])\`
Speaking for myself, I haven't seen this before and it was a really interesting watch. I'm glad it was posted.
Plug for japaric's heapless https://github.com/japaric/heapless &gt;static friendly data structures that don't require dynamic memory allocation &gt;The core principle behind heapless is that its data structures are backed by a static memory allocation. For example, you can think of heapless::Vec as an alternative version of std::Vec with fixed capacity and that can't be re-allocated on the fly (e.g. via push). 
I just run cargo watch in the terminal below, works great.
It sounds like you want *generic associated types* - an RFC for these was accepted but the feature hasn't been implemented or stabilized yet: https://github.com/rust-lang/rust/issues/44265
I just spent far too long building volcanoes with wooden fuses that'd cause them to blow. Great fun :)
I have just stumbled upon an example: https://github.com/stjepang/pdqsort got integrated into rust stdlib in 1.20
The exclusivity is done in this snippet from lib.rs here: #[cfg(feature = "stm32l4x1")] pub use stm32l4::stm32l4x1 as stm32; #[cfg(feature = "stm32l4x2")] pub use stm32l4::stm32l4x2 as stm32; #[cfg(feature = "stm32l4x3")] pub use stm32l4::stm32l4x3 as stm32; #[cfg(feature = "stm32l4x5")] pub use stm32l4::stm32l4x5 as stm32; #[cfg(feature = "stm32l4x6")] pub use stm32l4::stm32l4x6 as stm32; I suppose I could create an l4-hal-core that contains all the peripheral code, then publish individual crates for each device.
&gt; if you directly use a sys crate, you're obviously going to get a worse experience It‚Äôs probably not obvious if you‚Äôre new to Rust.
That sounds very useful, though I would make the attribute name something that tells you what it does i.e. `externify` or something like that.
i wasn't asking for my own codebase if thats what you're getting at, but rather trying to find something more suitable to this crate. i imagine it would be doable to separate out one common crate and several specific for each controller, but in my imagination that would end up with the common crate being almost what this crate is now and the controller-specific ones just a few macro invocations (from the common crate). so all in all i'm not sure that would be a better solution, especially for downstream crate users.
Adding a `'a` in line 22 seems to do the trick: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c5a268fbc33e3ee08d7fe51e2e5addc1
&gt; It is not. Your choice of database does NOT depend on the language you pick for your business logic but rather on the requirements you have. Except if I pick some database that doesn't have diesel or even a simple driver support in rust ‚Äî I'm going to have a bad time.
Thank you very much!
Yeah that one. Supposedly it's better in 1.13 where it's GA. The weaveworks one had numerous bugs last I tried it. Currently relying on [helm-diff](https://github.com/databus23/helm-diff) instead - but it relies on tiller. Operators, yeah that type of things. Architecture ideas and how often to sync with crds (best reference ive found is the go source for reflectors). How to actually handle the `resourceVersion` api key correctly when syncing. Haven't found any good docs on on that type of thing :(
Reborrowing makes it so that you're not passing your original reference into the function, but rather a new reference with a shorter lifetime than the previous one.
If you can get an minimum example into https://play.integer32.com/ (or any other platground) I can try to help. I posted a similar issue to this /r/rust 6 months ago, but the example + solution is no longer available in the playground. I think I remember the solution to mine, which is not obvious. But without a an example I'm unsure if they're the same issue.
Very excited about the prospect of cargo being able to distribute pre-compiled crates/binaries! This would be huge in speeding up from-scratch compile times, which is important for build automation on CI services. 
If you want to use functions, try combine which has a similar API but uses functions over macros
I'm hoping to work on a mini SCM written in Rust for projects-rs. I'm thinking I would draw inspiration from git but make it work differently internally.
"Slowly getting involved" would be more correct, and it's not strictly development. I got hired by Google to work on troubleshooting deployments of the open-source Kubernetes, and generally help people with running it and developing for it, but I'm just starting out.
 I don‚Äôt think this is possible statically. If you don‚Äôt mind the performance cost, you can use Cow.
&gt; For dependencies which appear in your API you want to use the dependee's version, provided it is higher than yours and not a breaking change. Cargo already does that? By default cargo uses the highest common semver compatible versions, unless the library has pinned a specific exact version.(but they shouldn't do that) if a library uses `v1.0.2` and you depend on `v1.0.5`, only `v1.0.5` will be used, as it's semver compatible. Or even `v1.5.0`, still compatible. For major version 0, only patch versions are considered compatible. So of `v0.1.3` and `v0.1.9`, only `v0.1.9` will be used.
Those two fragments aren't the same. The dynamic buffer on heap vs statically size buffer on stack Cstring (which might as well be a bunch of bytes) vs Definitely UTF-8 encoded string. Printing to stdout vs returning an error Also, you not comparing rust and c, you're comparing talking C to C and Rust to C. First one obviously going to be less code... &gt; I have no idea what the hell most of the Rust code is trying to accomplish. Well, maybe you should learn the basics of rust rather than go straight to interfacing with C? &gt; annotations like unsafe Disable some checks where compiled can't guarantee what's going on because you interfacing with unsafe by default language. Again, basics of rust. &gt; mut What is absurd about immutable by default? This time very basics of rust. &gt; weird buffer creation where it makes no sense You just do it wrong because you didn't read chapter 2... 
[Here ya go](https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=90adfe96f91d32af8ea7446f8bb9143f), if you want to take a look sometime. Thanks! 
[Try This](https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ae61891d9531d95f7fc57d05aa179b13) I'm not sure if the change I made to direct call is important for you. It seems bit simpler than the one I ran into (didn't need a for&lt;'a&gt;).
Or even using `impl Trait`: fn new(s: Into&amp;lt;String&amp;gt;) -&amp;gt; Self { Self { connection_str: s.into() } }
Changed parsing commands for my project https://github.com/abhijat/ya2d2 to use nom. Going to add tagging support for entries next. 
It was stated in a sense of just the actual number of developers capable of working on Rust who do actively work on Rust in *any* capacity vs. the general state of everything. That's what I was referring to above. I think you might have misunderstood me slightly?
And the no_nodes version has to do a pointer indirection (potentially, but probably not, missing the cache) *followed by* a match/pointer-equals-null check (to find that the HashMap is empty).
/u/RustMeUp's answer is good. I want to make some additional points. First, OpenGL is fundamentaly a C library. Both in a implementation and design sense. Interfacing with the raw OpenGL headers from any language besides C/C++ will result in FFI overhead. In Rust that takes the form of \`unsafe\` blocks and \`CString\` conversations. Rust provides compile-time pointer validation and built-in UTF-8 support. These tools are extremely useful most of the time but require work on the programmer's part when interacting with environments that don't support those tools (e.g. C/C++ libraries). To do a fair comparison you should at least use a pre-generated wrapper library which handles some of the overhead for you. \[gleam\]([https://crates.io/crates/gleam](https://crates.io/crates/gleam)) is the crate used by the Servo browser. Secondly, C is \*really\* good at mashing about with low-level APIs. That's what it was built for and no language will beat it at that game for the foreseeable future. Rust aims to be ok at low-level mashing while providing lots of ability to prove the correctness of code and generate powerful abstractions. The idea is that although the additional complexity can make low-level code time consuming to write initially, time is saved long-term as the resulting abstraction can be fearlessly reused without memory issues or data races. Consider Rust's \`Iterator\` abstraction, which provides lazy, functional-like access to arbitrary collection types. Implementing an iterator can be complicated but once you have an iterator, you can trivially combine it with countless other utilities within the Rust ecosystem.
&gt; For the integer parsers, they're faster, but not that much. FWIW the fastest int-to-string conversions I know of is [my one here](https://gist.github.com/Veedrac/069dd35f896de4df4e14b881a455ca47). You'd need to change it to do a mask if you don't want to pad with zeros, but it should still be fast. The minor differences with the way you do things end up mattering a fair bit. If this is interesting to you I can look at Rust-ifying it (though printing integers is fast enough most people won't care). 
If you are looking for excellent IDE support, you should check out [IntelliJ rust](https://intellij-rust.github.io). I think a lot of people are maybe put off by the fact that it‚Äôs not RLS-based, but it‚Äôs been *at least* as capable as RLS, if not even more mature/advanced. 
By default intellij uses its own internal compiler to annotate code. Because some features of the real rust compiler are not implemented, some errors are not reported. There is a setting to use cargo check for annotations (`File | Settings | Languages &amp; Frameworks | Rust | Cargo | Use cargo check to analyse code`), but it can be quit slow for big projects.
Clevercloud 
I'm also using Heroku (also with this buildpack) because Heroku also offers free PostGIS (in addition to free Postgres and Redis), and my server uses PostGIS.. Not sure which other cheap VPS-like hosters also support PostGIS.. One alternative would have been to try to build PostGIS manually on Uberspace 6 (Uberspace 7 doesn't support Postgres yet) which is probably what I'll do if/when my Heroku usage becomes too expensive..
&gt; As you mentioned though, this only used in the FCP process, which itself only takes place toward the end of the discussion If I understand the mechanism properly, it also prevents FCP from starting. This makes it useful from the point where the PR to the rfc repo begins. I've also seen RFCs be rejected and resubmitted with a smaller scope.
I'm working on making it fair, I just needed a rough benchmark before I dive in. C++ is my main language, and I've used RapidJSON in the past (and Boost, and the NCBI toolkit, etc.). These are tentatively published with major warnings, but I'm not doing a release like this. I'll fix them by tomorrow.
Thanks for the link, I'll definitely look to use this. I've been getting away with power reductions on the loop, so it's **pretty** fast, but not **this** fast.
Well, apparently there's rust-swig: https://github.com/Dushistov/rust_swig
coview would be a better name.
I've never used rust, but I think you want to do this: maxvec\[i\].push(value); where i is the index of the 1st dimension. This will get the ith vector from your structure. If you are trying to update a value at a specific coordinate (i.e. maxvec\[i\]\[j\]), than push is not the method you want to use. &amp;#x200B; You are right that maxvec\[\]\[\] doesn't have a method push, because maxvec\[\]\[\] is a value not a vector like you said. maxvec is a vector and so is maxvec\[\]
Awesome. What happens when you smoke https://sandspiel.club/#r1RtDEhFoMjEiNb1f9Vk
I appreciate your shameless plug so that I could bookmark this for the next time I want to run it, so thanks!
How about making the trait take \`self\` by value and then implementing it for references? \[Playground\](https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=82e56292b76f4e0ae1985f706dbc0f5f).
I know that people have complained about RLS, and I do agree that it is still rough, but for my relatively small, few thousand line projects, I've found that RLS actually works pretty well. It's not at my ideal state, which is where I don't have to reference the docs anymore by just using `go to def`, `show doc`, and high quality completion, but I get compile time errors to show up and with decent speed of completions in vim. I am not a fan of how much additional disk space it uses, but it's not life threatening, and I imagine it will improve over time. It would be great if `sccache` integration with Rust could be improved to improve object re-use, since right now it seems to be path dependent, which makes me get cache misses between different projects for the same crates. That and pre-packaged artifacts for common architectures would be lovely. There are some things about cargo I would like improved, but others have mentioned it in their wishlists so I won't repeat it.
I know people who can laser cut or 3d print those, if anyone wants.
Entirely correct. See here: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=93a0096c5d74f8b8c91187f8a0b8856e
That is a hilarious concept, and the code looks quite nice too. Welcome!
Do you have a specific reason to use protobufs or would `serde` be more appropriate? 
Ok I was able to fix the RapidJSON parser with a monkey patch to expose GenericReader::ParseNumber as a public method, and then use a custom handler that stores the float, and errors on anything else. RapidJSON is actually still pretty slow, but it and strtod are fast for denormal floats with 20-200 digits, a fair bit faster than my implementation, so there is obviously something I need to fix. **Simple** https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_simple_f64.png **Large** https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_large_f64.png **Denormal** https://raw.githubusercontent.com/Alexhuszagh/rust-lexical/master/lexical-benchmark/assets/atof_denormal_f64.png
You probably want this: https://github.com/crossbeam-rs/crossbeam
This works if he wants to append to the end of the inner vec. Otherwise, [insert](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.insert) should be used rather than push. 
It's formatter is non standard and doesn't respect rustfmt standards. Ui is laggy.
It‚Äôs supported formatting with rustfmt for at least a year now. Autocomplete performance used to be pretty abysmal but it has been much improved. 
[One of the best](https://www.youtube.com/watch?v=rTo2u13lVcQ), if not *the* best, talks about Rust I've ever seen. Definitely worth its time if you want to feel what really is Rust about. By the way, Jason Orendorff is the second author of "Programming Rust" book. Another video I strongly suggest to see is [Boats' recent talk on the coherence](https://youtu.be/AI7SLCubTnk?t=2572), although it's quite advance for a newbie. But still it'sa very good explanation on what the heck coherence is and why it's there in the first place. I was surprised to know that even seasoned rustaceans often don't know about it.
what about f32 and usage of f64 for parsing of them?
Ownership / borrowing question: I get that Rust gives ownership of objects on the heap to whatever blocks they're in. If I want to access them multiple times, I use a &amp; to create a reference to that object so that only that reference is owned by the block instead of the object itself so that I can continue to reference it later in my code. The common pattern I'm realizing I'm using as a result of this is that I use &amp; every where in my code until the last time I need to use that object, in which case I just let it be owned. This seems strange to me and, as such, I'm guessing I'm doing something wrong?
It works pretty well for me with [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim) and [deoplete](https://github.com/Shougo/deoplete.nvim). Auto complete could be better, but it seems to work most of the time.
I just finished a DBC format parser using nom. DBC files describe CAN networks and the layout of CAN frames e.g. what signals they contain how the frame is identified etc. CAN buses are used in cars, boats... https://crates.io/crates/can-dbc If you are curious how such files look like: https://github.com/commaai/opendbc?files=1
&gt;There are times I‚Äôd like to change a method signature, add or split a parameter, or move a module. For a single-developer project that follows strict conventions, regex is possible, but is nonetheless fragile. If you'd like a non-regex based way of doing search-replace on Rust code, you could check out [Rerast](https://github.com/google/rerast). If you have any trouble making it do what you want, feel free to file a bug and I'll try to help.
As a Gentoo user, I have no interest in this blasphemy.
I need to keep that in mind, avoiding allocations where they are not needed. I did too little C++ before, to get this kind of thinking on by default but it makes so much sense now. Thank you.
I have separate benchmarks for f64, but yes, generally, parsing f64 and converting to f32 is sometimes faster than parsing f32 since f64 is sometimes faster than f32 for all operations. However, downconverting a valid f64 to f32 may not produce the exact representation, so that's only fine if you're fine with losing data. Let's consider the easiest halfway case, a mantissa between "100000000000000000000001" and "100000000000000000000010" , or "1000000000000000000000011" (in binary, with the hidden bit). The theoretical digits are: "1.000000178813934326171875". If you use an f64 parser first for "1.00000017881393432617187499", 1-below the halfway point for rounding to f32, which should give a value of "1.00000011920928955078125", you get an intermediate value of "1.000000178813934326171875", since a 64-bit parser is **supposed** to round-up, and then the conversion to f32 incorrectly gives a value of "1.0000002384185791015625". You can confirm this is an issue with parsers that implement f32 parsing as a function of f64 parsing, like numpy, which do this for their 32-bit floats: &gt;&gt;&gt; np.float32("1.00000017881393432617187499") 1.0000002 Which is **not** the correct value.
Other modules/components already exist and use protobuf to communicate between each other, I want to replace one module with one written in Rust for greater efficiency (and first tests suggest it will run MUCH faster and smaller.. :-)
Nice. You‚Äôll also want to make sure everything is configured to be fast but correct, as RapidJson has a lot of options. By the way, in case it will help, you can divide a 128-bit number by a 64-bit number with a single div instruction on x86_64 machines
*number as in integer
I just merged the feature back into this repo :: [https://github.com/xieyuheng/tangle-rs](https://github.com/xieyuheng/tangle-rs) I apologize for the un-noticed change.
&gt;Cargo check has the same issue Wait, is this why the errors highlighting in intellij gets "stuck" so much? I frequently have to: type a letter, save, delete it, save to get it to actually show the right stuff.
I'd generally recommend taking `&amp;X` rather than `Box&lt;X&gt;` the last time, too, unless there's a reason you need ownership in that function. In general it's natural to only take borrows of data unless you really do need to own it. That way adding it doesn't break your code to add another access after the previous 'last' one either, if that makes sense?
Cool. I think one of Rust‚Äôs draw cards is really starting to be its portability. For anyone that‚Äôs curious here‚Äôs some more info on building seiri https://medium.com/@chyyran/introducing-seiri-a-music-manager-for-lots-of-music-990b464b3387
Wow! Rerast would've been extremely handy and saved me ample time: ``` 36 files changed, 178 insertions(+), 307 deletions(-) 29 files changed, 588 insertions(+), 591 deletions(-) 29 files changed, 591 insertions(+), 588 deletions(-) 41 files changed, 653 insertions(+), 489 deletions(-) 50 files changed, 617 insertions(+), 1169 deletions(-) 38 files changed, 246 insertions(+), 318 deletions(-) 34 files changed, 109 insertions(+), 106 deletions(-) 34 files changed, 215 insertions(+), 215 deletions(-) ```
Ah cool, thanks.
Yeah, I forced the user of the \`kParseFullPrecisionFlag\` for \`ParseNumber\`.
what about f32 and usage of f64 for parsing of them?
\&gt;It would be nice to have automatic clean up of unused files: &amp;#x200B; \&gt; Stale compilation artifacts. &amp;#x200B; \&gt; Old versions of crates in \~/.cargo/{registry, git} &amp;#x200B; Hi, I have been working on something like this since some time (It was my original "let's learn rust"-project). :) &amp;#x200B; &amp;#x200B; [https://github.com/matthiaskrgr/cargo-cache](https://github.com/matthiaskrgr/cargo-cache) &amp;#x200B; It can clean parts of the local \~/.cargo/ cache with a few commands and list the sizes, cleaning and stats on the the per-project target/ dir is definitely on my to do list. Feel free to give it a spin, cheers! :) 
To be honnest, you should say rust and javascript, it could attract users looking for neon example. I've open the code to know what GUI toolkit you where using, and see that the client is in js. I use relm for GUI, and as it is new, I am curious to see new projects using it. 
I'm not sure I understand this term or sentence. Could you explain further?
&gt; "let's learn rust"-project _\*opens link\*_ 604 commits =D. Shall definitely be using this, and also something to add to auto maintenance CI!
Layer of sand, layer of seed, layer of fireworks and a drip of lava makes plants grow in the air :)
Was posted less than 24 hours ago.
Yes, I know what "root" in gc context is. But when you model an arbitrary graph then you got no roots. No vertex of the graph is better than the other. So even if you got islands you still can't drop them. Unless your particular use case specifies "roots". But then this is not an ordinary general-purpose graph and should be named accoding semantics.
Sure you have roots, often there are specific nodes you directly care about, and you want things that aren't reachable to be pruned. Some graph-based systems can work that way. We're not talking about arbitrary graphs . Some graphs need GC. Others don't. It depends on the use case.
As I comment on github do like this: ```lisp (use-package lsp-mode :ensure t :config (setq lsp-print-io t) (setq lsp-rust-rls-command '("rls")) ;; (setq lsp-rust-rls-command '("rustup" "run" "nightly" "rls")) ;; (setq lsp-rust-rls-command '("rustup" "run" "nightly-2018-12-06" "rls")) (setenv "RUST_BACKTRACE" "full") (setenv "RUST_LOG" "rls::=debug") ;; Fix problem seems to be caused by upgrading lsp-mode package to v3. (unless (fboundp 'lsp-rust-enable) (defun diabolo-lsp-rust-window-progress (_workspace params) "Progress report handling. PARAMS progress report notification data." ;; Minimal implementation - we could show the progress as well. (setq id (gethash "id" params)) (setq title (gethash "title" params)) (setq msg (gethash "message" params)) (setq done (gethash "done" params)) (message "RLS: %s%s%s" title (if msg (format " \"%s\"" msg) "") (if done " done" ""))) (defun lsp-rust-enable () (require 'lsp-clients) (when (boundp 'lsp-rust-rls-command) (lsp-register-client (make-lsp-client :new-connection (lsp-stdio-connection lsp-rust-rls-command) :major-modes '(rust-mode) :server-id 'rls :notification-handlers (lsp-ht ("window/progress" 'diabolo-lsp-rust-window-progress))))) (lsp))) ) ```
Have you considered to use f64 for fast path when parsing to f32? Let we have mantissa that less than 2^53 then which max exponent can be used to get f64 value using a single `mul` or `div` operation that can be safely converted to f32 value? 
Good luck. Nice project ;-)
Or maybe just don't reexport `stm32` and let users do it if they want?
You might want to take a look at [ndarray](https://docs.rs/ndarray).
It's internal to rustc. However, there are snapshots of it distributed on crates.io: https://crates.io/crates/rustc-ap-syntax
Only if you have the "Use cargo check" (not the exact wording) setting enabled.
&gt; the fluid simulation also runs completely on the GPU, which is one reason it‚Äôs so smooth. I adapted this excellent implementation for my needs: https://github.com/PavelDoGreat/WebGL-Fluid-Simulation https://lobste.rs/s/tleiej/sandspiel_falling_sand_game_built_rust#c_khueyy
In mi notebook dual core i5 Intellij is so slow, but in my 6 core i5 desktop runs smoothly, tried sublime and vscode with rsl but it doesn‚Äôt feel so good as Intellij, don‚Äôt know much about rustfmt but to me seems pretty good the formatting, also I prefer some different formatting, so I customize the formatting in the IDE.
Refactored, hopefully according to your advice. New commit has been pushed. Care to provide more feedback? Thanks!
That's so much cleaner than having to write the generic over the function. That's a new feature in Rust, if I'm not mistaken. But I took u/pleurplus's advice, hopefully the right way, and I have a new commit up where I refactored to use `&amp;str`, and also moved tests and error parts to separate modules. Is this better than using owned data?
I find FB to be a rather bad platform for my use cases; group discussions and events. Still it is where all my contacts are, club &amp; social events are published there and other information from organisations I'm a member of. Content is king as they say. There's been quite a lot of open source social platforms, but they've not managed to attract users. How are you going to get people to start using this platform instead?
While I'm sure you have the best of intentions, this post comes off as rather harsh. Could you reword it, please?
Typically a user won't need to use this at all, it's just reexported as a just in case. `stm32` get used by all ther peripherals, for example [serial.rs](https://github.com/stm32-rs/stm32l4xx-hal/blob/master/src/serial.rs)
I am not a big fan of an IDE which re implement the compiler and doesn't contribute much back to the community. I use to be a Jetbrains fan back in my Java/Scala days. TheI have started to notice more and more major difference in the compiler,my whole code turning red and my IDE being unusable for perfectly valid code. Took them [3 years to fix it](https://youtrack.jetbrains.com/issue/SCL-10259). With the complexity of the Rust compiler, no doubt this kind of thing will happen again... I like the modularity of VSCode, RLS can be used with all major editors (atom etc.) and it's officially supported.
&gt;24 bit Hi-Res How is your dog enjoying that?
That does make sense. So what scenario would I really need to own it then?
Haven't used it, there is also [https://github.com/servo/heapsize](https://github.com/servo/heapsize)
Where is that mentioned in the readme?
It's the same thing, just new syntax. I had forgotten about it
You will likely have better success at using C/C++ libraries from your rust app
The post makes as much sense as I would expect from this user name.
If you're absolutely sure that all the text you're handling is ASCII and not UTF-8, you can unsafely use `from_utf8_unchecked`.
Currently I've switched to byte buffers instead. Already done 
&gt; There are some things about cargo I would like improved, but others have mentioned it in their wishlists so I won't repeat it. Just to say, as a member of the cargo team, we are here listening. It is good to read that you care. :-)
No, OP comes up harsh, this is just fine. If you are gonna go tell around what is absurd and what is not, you should at least have basic knowledge about it.
&gt; I don't feel like they try to do it in a way that could benefit the rest of the community. It's pretty hard to do this, technically. Usually existing community tools are just a bad fit for building an IDE on top. I've discussed Scala situation in particular (speculatively, don't know they whole story) [here](https://www.reddit.com/r/rust/comments/a37o5e/more_on_rls_version_numbering/eb5lnes). The fact that JetBrains makes a good (relative to competitors), free Scala IDE benefits the Scala community quite a bit :-)
I got speech synthesis working on windows using the winapi directly. [github](https://github.com/Eh2406/rust-reader)
Nice! I'll update [smartmail](https://github.com/dbrgn/smartmail) to the latest rumqtt version and will let you know in case I experience any problems :)
You wouldn't by any chance want to show me how?
Hmm..... Okay
&gt; If the data on the blockchain cannot be audited by consulting smart contract logic, the blockchain becomes a glorified linked timestamping service. A linked timestamping service sounds to me like a damn sensible alternative to blockchains and blockchain computation in particular. They call it an emerging cryptographic technology, but I get the same feeling reading about this as when reading about zero knowledge proofs for the first time about 20 years ago: 1. They're very cool, 2. They're a solution in search of a real world problem.
This is amazing! Thank you so much for making this! On behalf of the Cargo Team, if there is anything we can do to make this a ezere/more reliable please let us know! Looks like this is focused on cleaning `~/.cargo/`, so it compliment well the work on cleaning `/target/` that is happening at [cargo-sweep](https://github.com/holmgr/cargo-sweep). Mabey the projects shud link to each other in the readme.
For example when you want to store the passed data for an unclear amount of time. If you passed a reference, you would need to clone the object to store it for later, so you might as well pass in ownership and - if required - clone at the calling site. If you pass in a reference and clone anyway, cargo should warn you about this anyway.
I'm having fun writing classic GameBoy emulator. I finally made it to the state, where some games are pretty playable(tested Tetris, Dr. Mario, Super Mario Land), my next goals are to implement sound and link cable communication(over the network). I've started this project as exercise to learn about both Rust and emulation in general. The source code is available here: [https://github.com/JJag/gb-rust](https://github.com/JJag/gb-rust)
Postgres: (Tokio-Postgres) [https://github.com/sfackler/rust-postgres](https://github.com/sfackler/rust-postgres) MySQL: (Mysql-Async) [https://github.com/blackbeam/mysql\_async](https://github.com/blackbeam/mysql_async) CouchDB: (Sofa, disclaimer, I'm the author) [https://github.com/YellowInnovation/sofa](https://github.com/YellowInnovation/sofa) &amp;#x200B; There are lots of well-written clients out there so the situation is not that bad as you can say. There are clients for pretty much every database available. Some might require a bit of elbow grease to be used in production but that's a good opportunity to contribute back!
I'm hitting this error: ``` src/folds.rs|124 col 43 error 277| the trait bound `std::ops::Range&lt;(usize, {integer}, {integer})&gt;: std::ops::RangeBounds&lt;(u64, u8, u8)&gt;` is not satisfied || | || 124 | for (k, v) in self.highlights_by_line.range((firstline, 0, 0)..(lastline, 0, 0)) { || | ^^^^^ the trait `std::ops::RangeBounds&lt;(u64, u8, u8)&gt;` is not implemented for `std::ops::Range&lt;(usize, {integer}, {integer})&gt;` || | || = help: the following implementations were found: || &lt;std::ops::Range&lt;&amp;'a T&gt; as std::ops::RangeBounds&lt;T&gt;&gt; || &lt;std::ops::Range&lt;T&gt; as std::ops::RangeBounds&lt;T&gt;&gt; || For more information about this error, try `rustc --explain E0277`. ``` The line is mentioned, `self.highlights_by_line` is a `BTreeMap&lt;(u64, u8, u8), Hl&gt;` (where `Hl` is a C-like enum that should not matter much). The fact that I can construct and use this means that `(u64, u8, u8)` implements `Ord`, although I did not find the actual `impl`. So... shouldn't I be able to construct a `Range` from this using `..`? I'm not sure how to actually find out.. I might be able to implement `RangeBound` myself, but why is this missing? Should it be covered by [this blanket impl](https://doc.rust-lang.org/std/ops/trait.RangeBounds.html#impl-RangeBounds%3CT%3E-7)? I want my code to work on stable, so I guess I need to write the impl myself? What about the orphan rule though... what are my options here? Am I missing something obvious? 
Instant first association - Aardwolf MUD. Oh the school years...
Out of curiosity: how is rustc packaged on Gentoo? How is GCC?
[This article is golden](https://hermanradtke.com/2015/05/03/string-vs-str-in-rust-functions.html)! It explains when to use string slices, when to use Strings, what to do if you need strings in a struct, etc.
I'm not sure about rustc. I use rustup to install rustc and friends so I can be up to date. The rustc package in the Gentoo repo was old compared to installing with rustup, the last time I tried it, which was quite a while back. For GCC, you get a precompiled binary when you first install Gentoo (you could create your own if you really want), but you compile GCC from source later. Current GCC marked as stable in the Gentoo repo is 7.3.0. GCC (and glibc for that matter) take quite a long time to compile, but the repo doesn't stablize new versions super often so its not really an issue.
The link to the documentation on [crates.io](https://crates.io/crates/rumqtt) is broken
if you use rust from rustup then you are already using third-party binaries and being "blasphemous"...
That's all block chain is. A linked list of hashes already used by Git and Mercurial...
it's on a screenshot.
First off use a types library. There are several opengl/vulkan wrapper libraries with proper types as opposed to the mess that is the opengl c API. Secondly C is simpler in many ways because it let's you ignore tons of shit and do tons of unsafe shit.
&gt; You wouldn't by any chance want to show me how? Most of the logic is in https://github.com/Eh2406/rust-reader/blob/master/src/sapi.rs It was similar back at the first commit https://github.com/Eh2406/rust-reader/blob/d9017b9cc786e4dd96c580909b8d82dc068d2353/src/main.rs
Okay thanks I'll check it out
Please for love of God make RLS stable and bulletproof. I keep taking month long breaks because of how the editor integration or rls seems to break all the damn time. It's what, two years soon since 'year of the developer'.
Not on crates yet. Looking for some feedback before releasing. I'll add more documentation though
Awesome. Thanks :)
Yeah true. I was kidding, but I would prefer to be able to compile from source through the package manager and not be out of date.
We get that a lot actually ;) Aardwolf was one of the very few cute &amp; furry mascots that didn't have a trillion other brands associated with it.
The Mastodon platform already has 1 million+ users, and that is where the whole project started to form. Once we get a working demo, the excitement from them will only increase. After that it is simply a matter of advertising elsewhere. &amp;#x200B; In terms of events, and group discussion what would a better platform look like?
Thanks!
The website at [https://chyyran.moe/seiri/](https://chyyran.moe/seiri/) does not scroll for some reason. When I visited it, I initially thought that it was just a screenshot; I had to resize the window to see the download links. https://imgur.com/a/gjN35Wx
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/dlVn7NK.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20ec1qag8) 
Wrote unit tests but I have a problem running a SQL statement. I get a "cannot move out of borrowed content" error probably because I'm getting back a PooledConnection from r2d2? ```rust ‚ûú r2d2-tiberius git:(master) cargo test Compiling r2d2-tiberius v0.1.0 (/Users/sebastian/Code/libs/rust/r2d2-tiberius) error[E0507]: cannot move out of borrowed content --&gt; src/tests.rs:34:20 | 34 | let _foreach = conn.simple_query("SELECT 1+2").for_each(|row| { | ^^^^ cannot move out of borrowed content error: aborting due to previous error For more information about this error, try `rustc --explain E0507`. error: Could not compile `r2d2-tiberius`. To learn more, run the command again with --verbose.``` Can someone review the code? [Github link again](https://github.com/brokenthorn/r2d2-tiberius)
Actually Git is more advanced since it is a DAG rather than a chain. Zero-Knowlege proofs are still pretty advanced though.
At this time I recommend glium for OpenGL in Rust specifically. If OP isn't interested in OpenGL in particular, then the others are probably also interesting, but none as easy to use and learn as glium.
I think we don't need to escalate things. We can always do better to respond kindly since they are usually only momentarily upset and not trying to troll us. It's fine, and if you show someone respect they do calm down.
I personally avoid projects using stdweb (e.g. yew) since it's so different from the official wasm-bindgen approach. And not only that, the tooling, the initialization, everything is so far out that I feel like this project will day eventually.
I'd just like to extend my thanks to you for writing this much needed crate. I was going to attempt it myself, but I gave up when `tiberius` branched and went all-in on the async I/O train. The lack of good database drivers for MSSQL is the primary blocker preventing me from using more Rust in my day job.
If you really need it, it isn't difficult to setup sccache on CI. Just download and point it at an S3 bucket or use the local cache if the CI supports caching (like travis https://github.com/gluon-lang/gluon/blob/030a0f7798e6bd9a521ee8cd707eb1b853b7db5c/.travis.yml#L7). May be useful to limit the cache size as well to get faster CI startup https://github.com/gluon-lang/gluon/blob/030a0f7798e6bd9a521ee8cd707eb1b853b7db5c/.travis.yml#L73-L74. https://github.com/mozilla/sccache/
I'm working on a File Manager, whose backend is written in Rust (frontend using WebView; that seemed the best "GUI framework" for Rust at the moment).
It's entirely possible to communicate the same information without a harsh tone. Even Linus Torvalds needed to learn this lesson. For example: &gt;&gt;annotations like unsafe &gt;`unsafe` allows some forms of code which the compiler cannot verify for correctness. In this case, Rust cannot verify what OpenGL could do with the memory you are passing to it, so it would normally be forbidden. `unsafe` permits this in a strict scope. You can read more about it in the [Rustonomicon](https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html). I think this conveyed more information than the original comment, while being much more respectful. 
I think you'd put it in a where clause after the type? (this is a noob guess) 
Most games don't require that type of physics.
Implement std for windows xp
Looks like `firstline` and `lastline` are both `usize` and not `u64`. Perhaps a cast? `(firstline as u64, 0, 0)..(lastline as u64, 0, 0)`
most 2d games don't, no, but there's also a lot of tricky things besides physics which engines make a lot easier.
Is it possible to match all the variants of the enum at once given that they implement a common trait? let b: Result&lt;u8, String&gt; = Ok(3); match b { Ok(v) | Err(v) =&gt; println!("{}", v), } https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=707bf50e48257c8e25b9165e2edc194e
This is mostly what I've settled on doing. One roadblock I've run into is that implementing the trait for references makes it really difficult to return owned Lines from functions. You can't return "impl Line" because the Line is a reference. 
In a linked timestamping service, nodes don't have to be untrusted. Get five or six nodes who are reasonably independently trustworthy, unlikely to all be corrupted. Let them stamp stuff. Let them stamp each other's digests from time to time. If any of them misbehaves, just kick them out and pretend their stamps didn't happen. Even if a majority of them misbehave, it shouldn't be much more than an inconvenience. It may not work for criminal-friendly money, but it ought to work for a lot of the things people are so bloody minded about using blockchains for. Things are so much cheaper without Byzantine distrust.
Maybe you should use a separate lifetime for `&amp;mut self`? Something like: trait Foo&lt;'a, A&gt; { fn make&lt;'b&gt;(&amp;'b mut self) -&gt; A; }
I ported a generator for hyperbolic graphs: [https://github.com/mwarning/Hyperbolic-Graph-Generator](https://github.com/mwarning/Hyperbolic-Graph-Generator) that is now available as cargo package.
You cold do something like `b.map(ToString::to_string). map_err(ToString::to_string)` and match on that
I'm finally buckling down and refactoring my [MegaZeux player](https://github.com/jdm/mzxplay) to make it feasible to write unit tests for evaluating Robotic programs.
Can you describe the problem you're actually trying to solve, instead of the problem you're having with this specific approach?
Ahhh so easy, thanks a lot!
I think you are confusing frequency with sample bit depth
Instead of making the trait generic over a lifetime it often works better to make the individual methods generic over a lifetime. The following compiles for me [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=897bdfc5ab1a9a988a3b6ab27a4ea2c6) trait Foo&lt;A&gt; { fn make(&amp;mut self) -&gt; A; } impl&lt;'a, A, S&gt; Foo&lt;Vec&lt;A&gt;&gt; for S where S: Foo&lt;A&gt; { fn make(&amp;mut self) -&gt; Vec&lt;A&gt; { let mut x: Vec&lt;A&gt; = Vec::new(); x.push(self.make()); x.push(self.make()); x } }
This doesn't solve the question you're asking, but you can fix the lifetime error by reborrowing: impl&lt;'a, A, S: for &lt;'b&gt; Foo&lt;'b, A&gt;&gt; Foo&lt;'a, Vec&lt;A&gt;&gt; for S { fn make(&amp;'a mut self) -&gt; Vec&lt;A&gt; { let mut x: Vec&lt;A&gt; = Vec::new(); x.push((&amp;mut *self).make()); x.push((&amp;mut *self).make()); x } }
Can't vouch for these personally, but these could be what you're after: [https://www.youtube.com/watch?v=-Jp7sabBCp4&amp;list=PLJbE2Yu2zumDD5vy2BuSHvFZU0a6RDmgb](https://www.youtube.com/watch?v=-Jp7sabBCp4&amp;list=PLJbE2Yu2zumDD5vy2BuSHvFZU0a6RDmgb)
Unless you're on a mobile.
Thanks, I'll fix the responsive styles in a bit.
You'd have to convey that the `Line` does not outlive what it references. `impl Line + 'a` can sometimes do the trick. Otherwise you may have to add a lifetime to the trait.
Wait, if warp 0.1.0 is the first release, isn't 0.1.10 the 11th? Now i'll read the post.
This article is a bit outdated, I've since switched from TagLib-sharp and corert to a much more boring CMake and C++ setup. I still think there is promise in integrating C# with Rust though, and did a more detailed write up on how to do that here: https://medium.com/@chyyran/calling-c-natively-from-rust-1f92c506289d
Math is hard. ;_;
Looks like the key is to import `tokio::prelude::{*}` but I do not know why. This code works: use futures::sync::mpsc; use futures::Stream; use tokio::prelude::{*}; pub trait CloneReceiver: Stream where Self::Item: Clone + Send { fn clone_stream(self) -&gt; (mpsc::UnboundedReceiver&lt;Self::Item&gt;, mpsc::UnboundedReceiver&lt;Self::Item&gt;); } impl&lt;T: StreamExt + std::marker::Unpin + Send + 'static&gt; CloneReceiver for T where T::Item: Clone + Send, T::Error: std::fmt::Debug + Send { fn clone_stream(mut self) -&gt; (mpsc::UnboundedReceiver&lt;Self::Item&gt;, mpsc::UnboundedReceiver&lt;Self::Item&gt;) { let (mut tx1, rx1) = mpsc::unbounded(); let (mut tx2, rx2) = mpsc::unbounded(); tokio::spawn_async(async move { while let Some(res) = await!(self.next()) { match res { Ok(item1) =&gt; { let item2 = item1.clone(); await!(tx1.send_async(item1)).unwrap(); await!(tx2.send_async(item2)).unwrap(); }, Err(err) =&gt; error!("{:?}", err) } } }); (rx1, rx2) } } 
Rust should be the forerunner of Activity and LitePub federation technologies!
What's the problem with that `S: for&lt;'b&gt; Foo&lt;'b, A&gt;` bound? [This seems to compile and work just fine.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b2dbb5ef3a3d7ca3ccdbadfcec23585a)
:D Don't feel bad, I make off-by-one errors all the time (incl. in a recent talk)
This is kind of what makes federation resilient. As banjo mentioned, Mastodon alone is pretty big, but there are also Pleroma, PeerTube, Plume (another Rust project), and PixelFed which all do or will eventually be able to federate, allowing any member on any other platform to subscribe to activities from other domains on any other service. Less spoken of is the ability for self publishers to publish their work ala RSS or Atom directly to ActivityPub and LitePub federation. Imagine if you had a self-hosted art blog in which you posted lower-res illustrations to, and your activities directed viewers to your site to see the high res version. You no longer have to rely on Tumblr or Twitter to publish your works, but you still get access to a wide audience who would prefer to subscribe to you in the form of a Twitter-like app like Mastodon.
 b.map(|x| Box::new(x) as Box&lt;dyn Display&gt;).map_err(|x| Box::new(x) as Box&lt;dyn Display&gt;) Thanks, this solves the `Result` case but I still cannot use it with enums which do not provide the `map` method. However, the fix is simple: let b_display = match b { Ok(a) =&gt; Box::new(a) as Box&lt;dyn Display&gt;, Err(a) =&gt; Box::new(a) as Box&lt;dyn Display&gt;, }; https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a32c753545f383e762f23b0bef5fa918
This requires an allocation though, which is not ideal
Great post :+1: I'm really appreciating the value of approaching the web framework approach from two paths: [Warp (filters)](https://github.com/seanmonstar/warp/blob/master/examples/hello.rs#L6-L13) and [tower-web (macros)](https://github.com/carllerche/tower-web/blob/master/examples/hello_world.rs#L72-L117). The `Service` trait is still iterating, but I think that we are getting there. On top of being able to service HTTP, the [Service trait](https://github.com/tower-rs/tower/blob/master/tower-service/src/lib.rs) is being used to power low level [proxies](http://github.com/linkerd/linkerd2-proxy/) and databases [Noria](https://github.com/mit-pdos/noria). Driving the development with such a wide range of real world use cases is taking a bit of time, but I'm super excited about the results. Two (hopefully) final issues to address are [this](https://github.com/tower-rs/tower/issues/136) and and [this](https://github.com/tower-rs/tower/issues/137). There are a few more smaller bits of infrastructure to address before the tower-web / warp merge happens, but the rough strategy that I'm thinking of is updating the tower-web macros to generate warp filters. Then, handlers defined w/ macros will be interchangeable with warp filters.
In my application, `Foo` is a deserializer with some global state (in `self`). The `make` function takes an extra `Read` argument, but it's not important for this problem. The trait is allowing for the deserialization of a bunch of different kinds of values, and I ran into this problem when writing an instance for `Vec`. There are deserializer impls that return references to values owned by the global state, and that translates to an impl for `Foo&lt;'a, &amp;'a Bar&lt;'a&gt;&gt;`, which is why I need the lifetime parameter in the `Foo` class.
Yeah, any ideas on how to avoid it?
You could maybe do a `ref`-match and do `as &amp;dyn T` on the borrowed content. Not sure if this works though
Looks awesome. Thank you for this. I was recently looking around for an MQTT lib! In terms of feedback.. since it's targeted at IOT stuff, I think the coolest thing to add next would be \`#\[no\_std\]\` support. 
Expected music
Comparing your example with [mine](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0bae3a7f1b4f25f56ca71da4c746e0a0), I think the problem is that my "Counter" type has a lifetime parameter in it, which interferes with the bound.
the `{}`s there should be redundant.
classic fencepost issue.
See the update, where I've added another example of an impl that requires the `'a` to appear in `Foo`. With this approach, there is no way to implement `Foo&lt;&amp;A&gt;`, where the lifetime of the reference is bounded by the lifetime of the `&amp;mut self` argument.
You should read /u/matklad latest article about [rust-analyzer](https://www.reddit.com/r/rust/comments/a6ph8p/rust_analyzer_in_2018_and_2019/). In short, all IDE features depend on a common "fat" trunk of functionality (mapping source to semantics), which is still in development in the Rust ecosystem. Once that is available, then functionalities such as "Go To Definition", "Find Usages", "Rename", and even debugging will be relatively simple to implement. He called it the "One Leg Table" analogy, where establishing the mapping, in real-time, is the leg, and all the IDE functionalities are pieces of the table top.
There's two hard things in programming: Cache invalidation, naming things and off-by-one errors.
Continuing work on Grapl. https://github.com/insanitybit/grapl I want to move it to a beta stage soon. Focusing on fixing bugs, getting the architecture and data layouts stabilized, and thinking through any future changes that would be breaking so I can make sure they happen before the mythical, seemingly unachievable stable release. I'll be publishing a crate at some point for building services on AWS that use SQS triggers. I have some design stuff I'm working through and an ugly proof of concept that needs work.
Not to be confused with [Warp](https://www.aosabook.org/en/posa/warp.html), a popular web server framework for the Haskell language. ([package](https://www.stackage.org/package/warp))
Actually, tiberius is *very* good. There's just no connection pooling for it. Also thanks for your appreciation. Maybe you can help with part of the coding if you can. Right now cargo test is failing and needs fixing.
This library is aimed at more "desktop" ish clients, though that would include embedded linux devices. However all users of this crate will likely be running in a full operating system environment. It certainly would be useful to extract parts of the protocol handling items in this library to be no_std, so that embedded users could write a driver that would be compatible with something like embedded_hal!
Zero knowledge proofs are already used for private cryptocurrencies like Zcash.
&gt; Pity solids don't conduct heat - the first thing I always try and do in these is boil a pot of water. They do! You can create a pot with the wall tool, fill it with water, then apply fire from below. 
what kind of beginner are we talking about? new to programming or new to Rust? I found The Book easy to read and informative. then I just jumped into a project. when learning a young language like Rust, you need to get comfortable reading docs and source.
Yes and no. Rust has full support for [only a handful](https://forge.rust-lang.org/platform-support.html) of architectures - namely, Windows/Linux/macOS on x86. Even ARM is not guaranteed to work; the only guarantee is that Rust stdlib *compiles* there. On the other hand, platforms that are supposed to work *really actually work* out of the box. You won't find yourself writing a project for 200 lines of code and then find yourself continuously tweaking the build system for a year resulting in a 2000-LoC eldritch monstrosity just to support all reasonable versions of those three operating systems, as you would with C.
 &gt; So one the one hand it complains that StreamExt is not imported and on the other it complains that StreamExt is imported!? Probably the hint is wrong, after all, that's why it says "perhaps" ;-) This is just a guess, but maybe you need to `use tokio::prelude::stream::Stream` rather than `StreamExt` inside the function? 
If you haven't already, it might be interesting to look at wasm-bindgen? I'm pretty sure it does this kind of thing, but for a C interface intended to be used by JavaScript via WASM rather than an interface intended to be used by C.
"24 bit" and "Hi-Res" are two separate things. One refers to bit depth, one refers to sample frequency.
THANKS, THIS IS IT! This should be the default behaviour!
More solutions for advent of code. My game project in Rust has been code complete for a bit, im working on another music track, and ill probably have to make some minor code changes to play multiple tracks of music :)
I think the way you want to do it is impossible. Consider the two cases when writing that `impl&lt;'a, A, S: [something]&gt; Maker&lt;'a, Vec&lt;A&gt;&gt; for S`: 1. You don't need `A` to borrow the `Maker` that created it. You can express this as a bound `S: for&lt;'b&gt; Maker&lt;'b, A&gt;` (as you already did), and everything works as it does now. 2. You do need `A` to borrow the `Maker` (this would be expressed by using `'a` as both the `Maker`'s lifetime parameter and somewhere in `A`, like in your example `Maker&lt;'a, Chain&lt;'a&gt;&gt;`). However, in that `impl Maker&lt;'a, Vec&lt;A&gt;&gt;` you cannot make a vector that contains multiple `A`s that you got from the maker - after all, each `A` borrows that `Maker` mutably, so if you somehow managed to return multiple of them, then you could create aliasing mutable references. So in this case writing a meaningful impl is impossible.
Check out BurntSushi's advent of code 2018 repo. He writes high quality Rust. https://github.com/BurntSushi/advent-of-code each day is an exercise that you get to try on your own and then compare it with that of Soosh
I'm trying to implement the `Iterator` trait for a type wrapping a slice ([Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e8b5d17e39eec186256a045f4258b569)): struct SliceWrapper&lt;'a, T&gt; { slice: &amp;'a mut [T], index: usize, } impl&lt;'a, T&gt; Iterator for SliceWrapper&lt;'a, T&gt; { type Item = &amp;'a mut T; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { if self.index == self.slice.len() { None } else { let item = &amp;mut self.slice[self.index]; self.index += 1; Some(item) } } } This doesn't compile because `self.slice[self.index]` can't outlive `self`, according to the error message. I thought this wouldn't be a problem because `Item` has the same lifetime as `self.slice`, so why doesn't this work? (FWIW, I'm aware this is more easily implemented by forwarding `next` to an `IterMut` instead)
When your deserializers are designed like that then its already impossible to produce multiple values when they borrow the deserializer (e.g. [this does not compile](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b3ab37b819a978199616809263170b8a)). The only meaningful bound in that impl is the one you already have (because it just plainly disallows the result from borrowing the deserializer).
`tokio::prelude::Stream` is just an import of `futures::Stream`
Just here to say that I am using warp for a side project, and I am absolutely loving it. Good job :)
I have a `BTreeMap&lt;(u64, u8, u8), Hl&gt;` where `Hl` is a C-like enum. I need to do the following: All elements `(k, v)`, where `k` is larger than a given value (actually, I need that `k.0` is larger than a given value `x`, but I can look for everything that is larger then `(x, 0, 0)` instead) must be shifted: `(k, v) -&gt; ((k.0 + added, k.1., k.2), v)`. Seems I can't really get mutable access to the keys, can I? Do I need to construct a new `BTreeMap` with the new elements, and then extend the first one? Should I remove `(k, v)` from the map, saving up the values temporarily, and then insert the new element? All possible, but I feel like I'm missing an easier way.
I'm working through the [interpreter book](https://interpreterbook.com/), porting the code to Rust as I go, and using [https://github.com/J-F-Liu/pom](pom) for lexing. https://github.com/JoshMcguigan/monkey
That yarn error file has been in your repo for 8 months. Why?
Not really an answer to your question, but have you considered implementing that trait for your enum?
Is rust going to be like ruby or elixir, with a few well developed backend web frameworks, or like node and golang, with a hundred, half-assed (minimalist), partially abandoned, massive duplication of effort, backend web frameworks?
There are ways to mutate the contents of a key, but it's almost certainly not what you want. I think what you want is probably `remove` followed by `insert`, like you mentioned. Why is the modify-in-place approach bad? The problem is that there's no way to tell the map, "Hey, you know how I originally inserted value `v` with key `k`? Well...`k` got mutated in place to be `k2` now, so could you please move `(k2, v)` to its _new_ right place in the map? Kthx!" That API doesn't exist. So if you do manage to change `k` to `k2`, your `v` is permanently in the wrong place, and lookups are going to start failing in confusing and unpredictable ways. If you've ever wondered what this part of [the `BTreeMap` docs](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html) means: &gt; It is a **logic error** for a key to be modified in such a way that the key's ordering relative to any other key, as determined by the `Ord` trait, changes while it is in the map. This is normally only possible through `Cell`, `RefCell`, global state, I/O, or unsafe code. Well, this is what it means. If you mutate a key that's already in the map, all bets are off after that. It's not _undefined_ behavior per se, but you can no longer count on the map to retrieve anything you put in there. Incidentally, you might be curious what the docs are getting at with that `Cell`/`RefCell` mention. The idea there is, if you have something like an `Rc&lt;Cell&lt;i32&gt;&gt;` as a key in a map, you could `Cell::set` that `i32` to be a different value, even if another copy of the `Rc` was using the same int as a map key. That doesn't quite work directly, because `Cell` never implements `Hash`, but you could define a custom struct implementing `Hash` and containing the `Cell` to make it work. It'll cause all the problems mentioned above, so it's a terrible idea, but it's possible :)
I'm running into lifetime issues with the following code than I can only circumvent using unsafe behavior: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d77b2e765c8fe65b7bbbc248c9d312f5](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d77b2e765c8fe65b7bbbc248c9d312f5) I am able to circumvent the lifetime issues using unsafe behavior but I am wondering whether this can be done without using unsafe. What I am trying to achieve is pass a buffer to some parsing function that takes some `n` bytes out of the parsing function and returns it results + the remaining buffer `(T, &amp;mut [u8])`. This works fine with non-loopy code but as soon as I try it with for-loops I am unable to return the remaining buffer without causing lifetime issues.
Why is it named the exact same thing as [warp](http://hackage.haskell.org/package/warp), and already extant fileserver?
As you said, `foo` might store the reference to `a` inside `b`. The compiler sees this and thus determines that `b` is borrowing `a`, and consequently inside `main`, `s2Ref` is borrowing `s1Ref`. With the 2018 edition, if `s2Ref` is not used later on, the code works. But if `s2Ref` is used later in the `println`, the borrow must be held till then, making the access illegal in the `println` for `s1Ref`. In fact, in the 2018 edition, swapping your two `println`s will make the code work: // ... println!("{}", s2Ref); // last use of s2Ref println!("{}", s1Ref); // works, as s2Ref's borrow is no longer used // ... 
Forwarding to `IterMut` is the only safe approach that I know of. I have a longer answer to essentially the same question here: https://www.reddit.com/r/rust/comments/931kel/hey_rustaceans_got_an_easy_question_ask_here/e3mngte/?context=1 One way to see why the compiler's upset here, is to look at this line: self.index += 1; What if we replaced it with this line: self.index = (self.index + 1) % 2; Now the code is terribly broken. If we iterate just a couple of times, it's going to try to return another mutable reference to the first element in the list. That would totally violate Rust's fundamental "mutable references are unique" rule. But, is the compiler smart enough to know that the second version is broken? At the end of the day, the question of "will this loop ever produce the same integer twice" is undecidable. They could put a bunch of heuristics in the compiler to solve it in limited cases, but the end result would be fragile and unpredictable, and no one wants a language where "Does my code compile?" has a fragile and unpredictable answer. So instead they made the borrow checker _much_ dumber than that. It looks at the fact that you're pulling a longer-lived `&amp;mut` out from behind a shorder-lived `&amp;mut` and it throws up its hands without bothering to reason any further.
LitePub? Not sure That I know that one yet :) But yeah, there are several projects using Rust for federation activity ;) (Plume, and Rustodon are the ones that come to mind)
/u/steveklabnik could you explain this? I thought that editions would only be used for changing syntax stuff. Why does nll not work on the original edition?
Good idea, that would work if all the variants implement that trait... But this is just a matter or ergonomics: now I can copy-paste the code for each variant and it works fine, it's so I know it there's a better way, and it doesn't look like it.
We don't know yet.
If you don't care about implementing the trait, and you just wanted this behavior, I believe another option would be to specify that the &amp;mut borrow of the slice extends for as long as the returned &amp;mut T is in scope. The playground link below is my attempt at this. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b35480ec9a6f8c02ba21f6198e441ff4
According to the 2018 release blog post, (at the very end of the [Non-lexical lifetimes section](https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#non-lexical-lifetimes): &gt; We plan to backport it to Rust 2015 at a later date. I *think* there was some concern that NLL might break some existing code, so this was a cautious approach to avoid breaking code, with a plan to backport NLL after ensuring there will be no breakage.
It's not a lifetime issue. I did not check your unsafe code, but this works: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=786f9466ae94ada3a3e895b8077f778a. You shadowed `bytes` with a new variable `bytes` during the loop, but the next iteration uses the original `bytes`, which is still borrowed by `tmp`. So maybe it's a bit of a lifetime issue alright, but it feels more like you were confused by the shadowing going on. I removed all of it, though it wasn't strictly necessary.
Thanks, that sounds reasonable. I hope it won't take too long and force everybody off the ~~one true~~ 2015 edition. Steve, sorry for the hilight! :-)
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=be5a16516a2b8caa26cc2ff22db58186 The problem is that you have two binding with the same name: bytes, and this doesn't work as you would expect inside a loop. You need to somehow save the new "bytes" outside the for loop, otherwise they will be dropped before the next iteration.
They *can*, and they *will*, but they aren't *yet*.
No worries!
LitePub is the author of Pleroma's subset version of ActivityPub designed to be easier to implement and a little more privacy conscious for federation.
Looks like they implement different things: the BigDecimal crate looks to be an arbitrary-precision heap-allocated decimal type. This means it can store a much wider range of values, but will be much more expensive to manipulate and clone. The other two crates seem to implement fixed size, 128-bit floating-point decimal types. The rust-decimal crate has a custom decimal implementation using a 96-bit mantissa, an exponent that can range from 0-28 and a sign bit. The last crate actually wraps a C library (decNumber) so may be more difficult to build on some platforms/targets, and also looks to have quite a bit of overhead from the interop, as it requires some kind of thread-local context. I would probably choose BigDecimal or rust-decimal depending on if I wanted fixed-size vs variable-size decimals.
Just wanted to say that the video linked from that is pretty amazing: https://xiph.org/video/vid2.shtml
Thanks, this solved my problem. That was quite an easy solution indeed.
&gt; Audio I think you missed RustAudio https://github.com/RustAudio It has a synthetizer and a bunch of DSP stuff.
I was inspired by the `http` crate effort to see if I could come up with a similar interface for `Client` implementations so that integration libraries can be client agnostic so that they could avoid being tied to a particular version of `hyper` or other library, and instead pass in the `Client` as an argument. If I eliminate the need for a non-async interface, then it seems much more straightforward... It seems now that it would be more of a parallel to `Service`, so I was wondering what your thoughts are on such a thing @sean. Also I've used warp in production for a month or two now, so kudos!
Yes I noticed. Knowing that Diesel uses bigdecimal is a bit reassuring regarding easy persistance to a database as well and I assume the library is commonly used for that reason as well even though the rust\_decimal crate looks like an impressive piece of work!
crates.io plays a big role in portability: You no longer have to implement your own wrapper around OS functions when there's already a crate doing that (and there likely is).
That's not news. Every major language has platform abstraction libraries these days.
I personally am new to Rust but i've been in the industry for almost 2 years now. I read the book too, but I guess i'm still a little junior to map the ideas in The Book to something like my own personal project. I gave Hyper.rs a go, but there's still a lot I haven't fully grok'd yet, so I find myself stuck all too often. Futures also a lot to take in, which makes learning / using Hyper.rs all the more difficult. 
In Rust, the "unsafe" code is pretty much the "code that defies automatic auditing". If there are properties of unsafe code that can be made verifiable, i.e. safe, then they are generally standardized in some way that allows them to be used in "safe" (verifiable) code. Can you be more specific about some property that you think could be verified for "unsafe" code? 
I was thinking external tools that can test/exploit the compiled binary like a black box
Yea, a `Client` can also be a `Service`! We do that in Linkerd2.
I‚Äôm a little biased because I work there but a $5 plan from Linode should be enough for small projects. 
Oh you want like a fuzzer thing. Yeah, I don't know the specifics but that's called a "fuzzer"
You have to keep in mind that's its not because your code is in an `unsafe` block that the code is unchecked. Only a handful of rust safety features are turned off. See [https://doc.rust-lang.org/nomicon/what-unsafe-does.html#what-unsafe-rust-can-do](https://doc.rust-lang.org/nomicon/what-unsafe-does.html#what-unsafe-rust-can-do) The only things that are different in Unsafe Rust are that you can: Dereference raw pointers Call unsafe functions (including C functions, compiler intrinsics, and the raw allocator) Implement unsafe traits Mutate statics Access fields of unions What you can do is fuzz your code (send random input until it crashes). You can use for example [https://github.com/rust-fuzz/afl.rs](https://github.com/rust-fuzz/afl.rs) that will (try-to crash) your function, giving you an opportunity to find why, and what is wrong.
it's alright. it took me a while to really get Rust, and I don't get all of it. what's the issue? fighting with the borrow checker? 
Thanks!! I will look into this
Looks like fuzzing is what I was looking for. Thanks for the pointer!
[https://github.com/ctjhoa/rust-learning](https://github.com/ctjhoa/rust-learning) This is a directory of all such links.
It's easier for smaller tech communities to use this platform (for organizing local meetups for example), but still use other platforms for other things. This helps build a critical mass. Something that would be nice would be if there's a semi-official, moderated Rust presence there, like /r/rust here on Reddit.
I'm using Yew for a semi-hobby project right now and I have mixed feelings about it. It's really cool being able to (ab)use serde and other Rust crates in a front-end web app, but Yew is definitely not mature. Much of its functionality is a thin layer over the stdweb crate, which is undergoing rapid change. I've hit a few stdweb portability bugs that could have been showstoppers if what I'm making was intended for public consumption. Yew itself has some strange problems with the virtual DOM being trashed by custom components. A seasoned React user might want to rely on those but I just write functions for the time being. Some folks have also reported that the virtual DOM often re-renders parts of the tree that haven't changed, resulting in speed issues on larger trees. All that said, I want to see it succeed and I suggest at least trying it out. Keep the Gitter chat open for guidance. The mixed Rust/HTML DSL takes some getting used to, and certain parts of the documentation (including that of stdweb) make for very deep rabbit holes.
IMHO Rust @ frontend has a huge potential but is still in a very early stage...and please keep that in mind! Personally I'm tracking the progress (see https://github.com/flosse/rust-web-framework-comparison#frontend-frameworks-wasm) and the most promising approach **today** for usecases you're looking for are [seed](https://github.com/David-OConnor/seed) any [percy](https://github.com/chinedufn/percy). Yew is based on `stdweb` that has a lot of features but also is really heavy-weight. Frameworks like `seed` on the other hand are based on `wasm-bindgen` that is focused on (mostly) "zero-cost" interaction with e.g. the. DOM etc. So for now, just pick one you're comfortable with and ask again in 6 month or so and you'll probably get a different answer ;-)
I'll be writing a reddit API over the next few days, so I'll try to see if I can use the same concept to abstract the library. I'll see if I can use it for inspiration!
&gt; And I think you've hit the nail on the head here. Library maintainers should never expose an underlying dependency's API unless it is absolutely necessary (and I can't really think of a case where a wrapper can't be made anyway, but I'm leaving the disclaimer because declaring blanket absolutes on practices leave you absolutely wrong). Sometimes exposing the dependency is just good for interoperability (like, receiving something from a lib and sending to another lib). In those cases the ideal situation would be if it were added to the stdlib (like a part of futures is being added now), but sometimes it's too domain-specific for that.
See also https://fuzz.rs/book/
I find the way docs are structured around traits to be somewhat confusing. I'm not used to the idea of typeclasses / traits yet. Here's an example of a question I asked in this very subreddit. https://old.reddit.com/r/rust/comments/a2qmct/hey_rustaceans_got_an_easy_question_ask_here/ebbnlrm/ The response I got did not help me at all. I have no idea what a "blanket implementation" is. And if it doesn't work in my case then why is it in that documentation page in the first place. 
Or OS/2 warp
It's a valid criticism, and there is A LOT of churn in the server crate space right now. A lot of this is due to the evolution of the language and the futures ecosystem. We are still figuring out the best patterns. Things will settle down eventually and a few front runners will emerge.
I started working on a similar concept of a standard server interface what seems like ages ago: https://github.com/sagebind/ingots I shelved the project after a while due to lack of interest and lack of stability of needed crates. Now that the http crate exists and standard futures looming, I'm glad that things like tower-service are being worked on that can make a huge impact on the rust server app story.
Yew is the most mature Rust frontend framework, but as someone who has built a non-trivial app with Yew, I wouldn't recommend it for any serious projects. In my experience apps built with Yew are very heavy, slow to compile, and perform poorly. This is unlikely to improve since the main contributor seems to have lost interest in the project. There aren't any Rust frontend frameworks that would satisfy all the needs you listed. Even if you picked Yew you would still need to build your own router for example. That said you can definitely use Rust on the frontend with \`wasm-bindgen\` and \`web-sys\`, but it won't be easy and you'll have to figure a lot of things out yourself. However this space is moving really quickly so I'm sure we'll be in a much better place this time next year...but if you need something done soon, JS/React is probably a better choice for now.
I might have even believed you if it weren't for the fact that the screenshot clearly displays the sample rates.
Thanks for the link. Looking at seed and percy. 
Everything I've seen on front end Rust leads me to believe the ecosystem is in the experimental phase and I wouldn't trust any code written today to be idiomatic in 3 years. If you don't have to maintain it, knock yourself out with my blessing. Someone has to do the experimentation. If you're potentially saddling someone else with a mess of maintenance, I request you don't for their sake. As an observer without a horse in the race, I expect something that works like Glimmer to win out over the 3-4 vdom based experiments I've seen announced.
Thanks, After posting the question, I read more about yew and wasm and I saw the similar reaction from users. &amp;#x200B; &amp;#x200B;
&gt;web-sys didn't know about it. Checking it out. Thanks, &amp;#x200B;
&gt;Everything I've seen on front end Rust leads me to believe the ecosystem Are you referring to wasm based frameworks or even traditional ones like Actix/Rocket? This is a personal project, so I do have the liberty to experiment. &amp;#x200B; &amp;#x200B;
Yes? It shows them as 96kHz. That is overkill.
Thanks, all of what you said makes sense and for the same reasons I wasn't initially surprised that my code didn't compile ‚Äì what surprised me was that the approach that forwards to `IterMut` doesn't have the same issues. In the answer you linked to you explained it as relying on the audited unsafe code in the standard library, and that gives me some intuition for how that might work, but ultimately I don't really understand how the compiler is able to distinguish between the two. Why is `self.slice[self.index]` bound to the lifetime of `self` in the snippet I posted, while `self.iter.next()` isn't?
Ya just got hit by a dumb Cstring fiddly bit of gl error logs: the bytes needed includes a \0 that you don't want in your final string, so when you set_len you have to chop off one.
so let's look at the source for that. i just looked in the rust docs to find the `From` trait: https://doc.rust-lang.org/src/core/convert.rs.html#462-464 // From (and thus Into) is reflexive #[stable(feature = "rust1", since = "1.0.0")] impl&lt;T&gt; From&lt;T&gt; for T { fn from(t: T) -&gt; T { t } } like the comment says, it's reflexive. it's not immediately obvious why this is useful, but sometimes in rust it's a good idea to make your functions more generic: fn use_my_type&lt;T: Into&lt;MyType&gt;&gt;(maybe_my_type: T) -&gt; Result&lt;MyReturnType, MyError&gt; { return maybe_my_type.into().use(); } because all types implement `From` and `Into` for themselves, you can pass this function `MyType` in addition to any other types that might implement `Into&lt;MyType&gt;` a slightly more useful example: fn i_need_a_string&lt;T: Into&lt;String&gt;&gt;(maybe_string: T) { println!("this is the printed string: {}", maybe_string.into()); } i hope that helps with understanding traits and blanket implementations, but that is just the long way of saying that you can't use this implementation to say "turn my type T into type Y" because you haven't told the compiler anything about type Y, dig? specifically, you can't turn a `std::io::Error` into a `hyper::Error`because, even though we get a "free" implementation for `From&lt;std::io::Error&gt; for std::io::Error` and `From&lt;hyper::Error&gt; for hyper::Error`, we don't have `From&lt;std::io::Error&gt; for hyper::Error`. what i usually do here is translate the error (i haven't looked into hyper much, so excuse some inaccuracy): match io_err.kind() { io::ErrorKind::ConnectionAborted =&gt; { return hyper::Error::from("oh noes"); }, /// etc etc }
Probably going to get downvoted for this but if your use case is actually that simple I would recommend using plain vanilla javascript and as little of it as possible. Using rust through web assembly sounds far more heavy than needed here. You have to remember that whenever you compile something to run in web assembly you have to include literally every bit of code required to get it to run besides the actual browser calls, while javascript doesn't have to transport a bunch of standard library functions for ...managing sessions and doing ajax calls
As others mentioned, we are only just tentatively tipping our toes into frontend development. Everything is super experimental and I wouldn't trust any framework right now for anything remotely serious. Things will need time to mature. That said, from all the frameworks so far I like draco the most. It is quite fast and has all the essentials. I've built a non-trivial app with it. It does not support SSR yet, though.
Generally either when something you're using it for wants to own it, or when you are putting it in another `struct` which will outlive this function call (and possibly the function it was created in). For example, if you're sending something to another thread via a `mpsc` channel, you will need full ownership of that thing so that `mpsc` can be assured it won't be dropped in this thread while the other thread is using it. 
To be totally fair, it should be mentioned that the no_nodes version doesn't have to check the nullable pointer for null/nonnull before following it. This is good if the hashmap is almost always nonempty. It does still have to pay the pointer indirection+empty/nonempty check in the empty case, but like you said the cache performance here should be pretty good, especially if no_nodes can be made static. no_nodes is also useful from an organizational point of view: it provides the nicer interface where every vertex has a (possibly empty) set of neighbors (without having many copies of an empty hashmap clogging memory/cache), versus an Option&lt;Hashmap&gt;/OptionIterator/etc that needs extra boilerplate to work with.
I'm referring to the wasm stuff. It's relatively rare these days to find people building server rendered applications (they work fine, just not in vogue) so I consider frontend to be more or less synonymous with code that runs in browser. The server-side space is in fairly good shape but with async/await landing and the next round of frameworks (Tide, Warp, tower-web) on the way I expect change there as well. The difference is that both Actix and Rocket have seen pretty good adoption and their maintainers seem really committed so I think both will stick around in something close to their current form and / or if `Service` becomes THE way to do it in the future then something easy to migrate to will come along. I wouldn't hand off a project in one to a customer and have it go maintenance free for 10 years but if its being actively developed/maintained for the next 2 to 3 years I'd be comfortable committing.
https://i.imgur.com/5dLpjKR.png /r/uselessredcircle 
Didn't notice that at first... that must be a mistake. Looking at OP's source code, it marks any 24 bit audio file as hi-res.
If you have the time, I'd recommend you put together some test data, and compare answers between .Net's decimal operations, and the Rust-based libraries.
In addition to the fuzzing tools mentioned, I'd point to the various ["sanitizer" runtimes](http://compiler-rt.llvm.org/) that are provided by LLVM, and [AddressSanitizer](http://clang.llvm.org/docs/AddressSanitizer.html) in particular for detecting memory issues. For a quick example of using this in a CI pipeline, take a look at [bytes](https://github.com/carllerche/bytes/blob/ad35fbef035da3bc0b18b2042ae19cf7358fec6e/.travis.yml).
That is some seriously cool shit right there ‚ûï1Ô∏è‚É£
Very clean code: easy to read. Thanks for sharing it. Good naming. Here's some of my thoughts: take them for what they're worth (not much). * Try to avoid use of `l` as a variable name, as it can look like a `1` or an `I` or a `|` on a quick read. * It looks like you've embraced the functional style. Most of the remaining `for` loops look like they could be replaced with `map` or `for_each` or one of the other `Iterator` functions. There's a lot of "iterate-and-collect" here, but I'm not sure how much is avoidable: for example sorting is going to require a thing. * `stats_by_guard` might be better as a separate function. If you pass a block into it to select whether you want `count` or `total` you could replace the repetition between Part 1 and Part 2. * At lines 102 and 109 you should be able to use `&amp;` in the patterns to avoid having to use `*` later. I prefer this, as I think it leads to clearer code. Similarly, use pattern matching on a tuple rather than `.1` at lines 104 and 111: it's easier to read and less error-prone. * Honestly, a `nom` parser is overkill here unless you're just trying to learn `nom`. The [regex crate](https://docs.rs/regex/1.1.0/regex/) is sufficient for parsing and will lead to more compact and readable code. * Code commenting would be nice. Honestly, probably best to just `rustdoc` the thing. Yes, `rustdoc` doesn't work so good with binary crates, but it can be made to work, and it sure produces pretty code documentation. 
It all gets fuzzy after Warp 10...
I'm currently reading the rust subreddit and trying to gather up the mental strength to buckle down and learn Rust so I can write actual good programs that I can feel ok putting somewhere without making the world crumble. I've been following rust forever and just can't get myself to make the jump and learn how to use the damn thing. Rust seems much harder to learn than anything else out there...And I've learned enough of Go, C++, C#, JS, and Python to throw things together in any of those languages when I feel like it (C# is my favorite because of the standard library and the fantastic documentation from Microsoft and (and StackOverflow xd)). As an outsider, Rust just seems even farther away than any of those languages are from each other, not to mention the syntax seems like it's invented by aliens much smarter than me. There's so much going on in a standard rust program just at first glance that I feel dumb every time I look at it, but maybe that's because it's designed so you actually know what the hell is going on inside that little piece of machinery sitting on your desk (or lap if you're some kind of genius that can focus in a Starbucks). But yeah forreal doe I gotta get on this shit but I just feel like any time I'm spending not getting tangible things created is time wasted for me, which sucks because I want to give rust a go but I feel like it's going to take some very serious grinding
Yes, such a comparison would let me know how strongly to prioritize using this in our from_chars. I‚Äôm happy to compile benchmarks and run them on my machine, just let me know when you have something. Thanks!
I'd recommend using inferno, mainly because it's in the Stephen Krause web framework comparison benchmarks as being one of the fastest. 
[https://github.com/anderejd/cargo-geiger](https://github.com/anderejd/cargo-geiger)
Do you have more information on how stdweb is heavy weight? I'd love to read more about this.
This is a great analysis of all three! decimal and rust-decimal take a slightly different approach for implementation. As an example decimal supports a slighter higher precision in some situations but is implemented, trait wise, more like a float. All in all, I expect rust-decimal is modeled closer to what you‚Äôd find in .NET. Anyway, I‚Äôm the author of the rust-decimal library so am more than happy to answer any questions you might have. 
Stop boxing trait objects people, they [work just fine behind a reference](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=5d67d20594a94e1ad844f76f2f241d95). `Box&lt;T&gt;` is not magic.
&gt; zero overhead All three of those APIs have overhead. Not to say they're not worth using :)
Here is the definition of [hyper::Error](https://github.com/hyperium/hyper/blob/master/src/error.rs#L25). Further down in the file you can see some Trait implementations. As an example [this line](https://github.com/hyperium/hyper/blob/master/src/error.rs#L362) contains a trait implementation that allows you to convert a http::status::InvalidStatusCode into a Parse, which can then subsequently be converted into a hyper::Error in [this line](https://github.com/hyperium/hyper/blob/master/src/error.rs#L336). However the hyper::Error does not implement From&lt;io::Error&gt; and therefore you cannot use from to convert an io::Error into a hyper::Errror. On the other hand hyper::Error has a [constructor](https://github.com/hyperium/hyper/blob/master/src/error.rs#L190) that uses an io::Error, so I guess that you can do the following in your [original gist](https://gist.github.com/gDelgado14/73d8d838e15c7f4cf6bfdbcbd81a7a6a#file-main-rs-L41) (untested) future::err(hyper::Error::new_io(io::Error::new( io::ErrorKind::InvalidInput, "Missing field `message`", )))
There is one more vDOM-inspired project that is not mentioned here: https://github.com/rail44/squark I have not tried it yet, so take it with a grain of salt.
Yeah good idea. We could make the core and state \`no\_std\` in future but that's not the priority now :). 
I looked at all of them at some point and I'm not happy with either of them. Primarily because only one of them is based on standard (decimal), and it's a wrapper around C code. Also, it uses IBM library which uses decimal encoding I just cannot accept (densely packed decimals[1]) :) Also, from the practical point of view, binary encoding should be faster to do in software?.. As I understand, the main reason IBM went for that encoding is that they can actually put it into hardware, so they don't care about it being inefficient to do on CPU. I don't know why I'm so excited about IEEE 754-2008, but it just feels right. Similarly to f32/f64, there should be a standard-based decimal floating point which would be used most of the time (when you need decimal arithmetics). We currently use bigdecimal, but it is not fixed size (I would prefer it to be fixed size, 128-bit decimal floating point is plenty to cover practical use-cases). Also, it is not part of "num-\*" project. As far as understand, the reason was that it is not clear exactly which semantics should bigdecimal implement. I even started doing my own library, based on Intel [Decimal Floating Point library](https://software.intel.com/en-us/articles/intel-decimal-floating-point-math-library), but haven't moved far enough. The biggest stumbling block for me was that I wasn't able to find good tests that can drive such implementation (tests for Intel library look okay, but I don't think they cover all of the weird corner-cases). [1]: IEEE 754-2008 defines two encodings: in one mantissa uses just a regular binary number. This is what Intel library uses. The other encoding, one that IBM library uses, are those densely packed decimals.
I think the whole point is to reduce the surface area of unsafe code. For a real systems language you most likely need the whole power of unsafe code, but being able to encapsulate it into a data type is the big win, because then you only have to verify the internals of the data type and the interface of the data type can still be safe. 
I'm still curious about the event meeting for - -
Ultimately it's the type signature of `IterMut::next` that tells the compiler everything's ok. Here's what it has in [the docs](https://doc.rust-lang.org/std/slice/struct.IterMut.html): fn next(&amp;mut self) -&gt; Option&lt;&amp;'a mut T&gt; There's an "elided lifetime" in that `&amp;mut self` parameter, so we could equivalently write: fn next&lt;'b&gt;(&amp;'b mut self) -&gt; Option&lt;&amp;'a mut T&gt; Which makes it a bit more explicit that this signature is saying those two lifetimes are disconnected. Given _any_ `&amp;mut self`, this method will return an `&amp;mut T` that lives as long as the iterator's internal borrow of the backing slice. So when you call `IterMut::next` inside your own `next` implementation, all the compiler is doing is checking the lifetime constraints it declared against the ones you've declared, and it doesn't see a problem. That's not too big of a surprise, because you're both implementing the same `Iterator` trait. But when you try to implement iteration yourself, without calling into an existing `next` function with a declared interface, that's when the compiler starts really checking your work. (As a general rule, the borrow checker only ever takes a one-function view of the world. It's making sure that your function obeys the lifetime requirements that it declared, and while it's checking your function it pretty much takes it for granted that other functions obey the lifetimes they declared.) Here's where the standard library uses unsafe code to implement `next`: https://github.com/rust-lang/rust/blob/1.31.0/src/libcore/slice/mod.rs#L2836. It's a little hard to spot, but there's a `*` operator dereferencing a raw pointer there, which circumvents the borrow checker entirely and is only allowed within `unsafe` blocks. It's essentially conjuring an `&amp;mut T` out of thin air, with whatever lifetime it needs to have, and telling the compiler "trust me this is fine".
Nice! I was able to remove that ugly `ref`: let b_display: &amp;Display = match &amp;b { Ok(a) =&gt; a, Err(a) =&gt; a, };
Yep - locked, and comments mentioning hostility towards critics are flagged and hidden.
This is one of the weirdest parts - a rush to get the new website out as part of some kind of branding blitz. Nutty. And so they launched it with plenty of acknolwedged ommissions and weaknesses. It's sad - I hoped that quality would take a higher seat. But the **worst** part is how all of the response from the Rust people in control is _only_ about the tiny details - a color, a font, etc. No response to critique about the _process_, which is the real problem.
I think 'match ergonomics' are ugly and prefer the explicit `ref` ¬Ø\_(„ÉÑ)_/¬Ø
Not to me - this is a high quality open source project, not General Motors coordinating a new Buick launch.
Thanks for that explanation :) I'm aware that simply "changing" a key is not a good idea, but I kinda hoped for an API for that. Moreover, in my use case I'm changing the "upper part" of the map, and the order of the elements is preserved. Using `remove` followed by `insert` has the drawback that the order of the elements isn't preserved in the intermediate steps, but only after doing the full transformation... I will use `split_off` to construct new maps and move around elements. I'll only have to find the right elements to split off of (seems weird that there is no method to "split the map at this key, even if it's not in the map"). Overall my impression is that `BTreeMap` is not the right datastructure here. I'll implement my stuff, but after that I'll investigate using a simple `Vec` or so. Thanks again!
Diaspora claim to have quite a lot of users, yet of all my FB contacts two had used it and quit because nobody else was using it. I hope aardwolf succeed. For events: * Have a latest date/time for RSVP. * Limited number of attendees, with waiting list and ability to later increase the number (when you rent a bigger locale etc). * Be able to connect events to payments/tickets in a simple way. It could start out as simple as letting the event organisers be able to press a checkbox when people have paid through other means and expose an API to delegate that ability to programs. With FB you have to have a separate register about who has paid or not and the attendee list usually doesn't mean more than people might show up. * To get more content, have the ability to publish public calendars on the platform, there are plenty out there for various venues. If people can comment on such events those venues might want to publish some web view of the discussion, bringing more people to the platform. Group discussions: FB is still mostly way behind the UX of good usenet-clients in 1995. They do deliver new posts faster though. :-) * Make it easy to find your groups that has new posts and new comments on the posts you are watching. * See the new comments without having to read though all the old stuff, with the ability to expand the old stuff of course. * Multilevel threading, keeping people on track. * "Ping Xxx" comments should automatically ban the poster (or have a "share..." button to invite a friend to the discussion). * Reddit style up/down-voting. :) &amp;#x200B;
I forgot, for events, be able to invite people that are not members through e-mail and let them answer without becoming members.
Doesn't all blog/CM software these days have the ability to automatically publish extracts to FB, Twitter etc? From a non technical point of view, does federation really add any value for the average publisher?
&gt; Some of the people who write this website are contractors for Mozilla. That's (probably) why design input is ignored. Yep - one of the responses I saw from a Rust power-holder was that they had hired a professional designer. (And that this answer is sufficient to end the discussion.) Ofc, I think, "a professional designer _who sucks_". What a weird, defensive way to run a project.
Sounds like a very interesting problem. One example of a fast datastructure that's just backed by `Vec` is https://github.com/bluss/indexmap, so that might be a good strategy.
Wrong sub-reddit, chief.
Most people don't need elaborate data-structures, they are need `Vec` and occasionally `HashMap`, each of which has a safe high-quality implementation in `std`. It is a myth that developers sit around dreaming up and implementing data-structures all day. In practice, unless you are writing low-level libraries, you almost never need to write `unsafe` (even then, only very rarely). I've written many tens of thousands of lines of Rust, can count the instances of `unsafe` on one hand.
This is one of the great surprises of Rust! Yes, *in theory* it would be entirely reasonable to guess that most Rust projects would need to use a significant amount of `unsafe` code to escape the limitations of the borrow checker. However, *in practice* it turns out (shockingly!) that the *overwhelming majority* of programs can be implemented perfectly well using only safe Rust. Speaking from personal experience, I would estimate (without exaggeration) that less than 0.1% of the code in the Rust ecosystem requires `unsafe`, and that most of this `unsafe` code is used to bind to existing C and C++ APIs which are inherently unchecked, rather than to circumvent the limitations of the borrow checker when implementing tricky data structures. This is especially surprising given that a very significant fraction of the standard library makes heavy use of `unsafe` code, and could not be implemented without it. Given this fact, it would be totally reasonable to conclude that most Rust projects would encounter similar challenges. However, it turns out that this finding does not scale up, because for every 100 lines of code spent implementing a safe abstraction like `Vec` or `Mutex` using `unsafe` low-level primitives, the community can write hundreds of thousands (maybe even millions?) of lines of code productively *using* that abstraction to safely build higher-level libraries and applications. As the ecosystem matures, this ratio only gets better, because every time someone builds a new safe abstraction on top of an `unsafe` implementation (see [rayon](https://crates.io/crates/rayon) and [tokio](https://crates.io/crates/tokio) for excellent examples), the language gains an entirely new degree of freedom that prevents anyone from having to worry about those low-level details again. As a beginner, especially coming from C++, it can often be challenging to figure out how to express your programs in terms of these ready-made safe abstractions, and you will often be tempted to reach for `unsafe` under the assumption that you are facing a truly novel problem for which no solution exists; however, it is almost always the case that a change of perspective reveals some way to express your program using only safe building-blocks. Learning to think this way can be the source of many moments and frustration and revelation when learning Rust, and the community will be happy to help you every step of the way. To answer "why Rust?", I think one final remark is in order: Even when writing `unsafe` code, Rust is in my experience still a *much* much nicer and more productive language to work in than C or C++. In fact, if you were to redesign C++ from the ground up in 2018 *without* worrying about strict compile-time safety checks, I think the result would look extremely similar to `unsafe` Rust. In conclusion: your apprehension is completely legitimate, but we've been running this experiment for a few years and the surprising result is that safe Rust works *spectacularly well* in practice. If you don't believe it, try it yourself! We'd love to 
Have you blogged or anything about your progress? 
I really like the look of `seed`, it's The Elm Architecture without The Elm Language. Elm is not a bad language, but does feel somewhat limited compared to the power of Rust.
Nice work! BTW, there is an issue with the link "infer: remove Box from a returned Iterator" not pointing to anything.
Or maybe it's a trivial problem and I'm just going about it all wrong :) Thanks for pointing out indexmap, it's not what I need, but interesting nonetheless, and I should definitely browse some data structure crates to see if there's something for me in there!
What about comparison with [fx](https://github.com/antonmedv/fx)?
I'm trying to make a flappy bird clone in Amethyst because it seems like a good first project to start from scratch with.
I think you want r/playrust.
\&gt; That's all block chain is. A linked list of hashes &amp;#x200B; That's only for the "blockchain" part. Those blocks are also containers for transactions and they also have Proof of Work to prevent block spam. &amp;#x200B; The transactions are transfers of (simulated) ownership. A public key must derive the address which was the destination of a previous transaction, and the same public key must also verify the transaction's digital signature. &amp;#x200B; It's pretty neat, and if we were "smart" enough to calculate better by head, have a splendid memory and somehow communicate efficiently and worldwide by speech, we could run a cryptocurrency network (a monetary system) with our bodies and minds only, without computers at all.
I believe the correct link is https://github.com/rust-lang/rust/pull/56742
Yeah for sure, I mostly linked it to suggest "this general strategy for implementing data structures seems to work out well in practice" and not so much "this is the data structure for you."
What data structures cannot be implemented in safe-only rust? &amp;#x200B; Per "typical data structures" I'm going to guess you mean linked lists, binary trees, and cyclic graphs. All of these can be implemented in safe rust. Unsafe code is only necessary to improve the ergonomics for using the data structures and for non-trivial optimizations. &amp;#x200B; [https://docs.rs/slotmap](https://docs.rs/slotmap) describes one method, though it does use unsafe code in its implementation \*for optimization reasons\* it isn't necessary. You can create cyclic graphs using slotmap if you wanted to, without touching reference counters (internal mutability or atomics) or dereferencing raw pointers (unsafe) or allocating in the hot path.
Are any of the current wasm solutions SEO friendly?
I‚Äôm just a beginner, but: excellent question! I have had similar thoughts/questions about this as well! 
Ext. If you're counting \`Vec\` as unsafe because it uses unsafe in its implementation, you could use unsafe-free arrays for the capacity.
Beautiful game! It's impossible to put out plant fires with water.. the plant grows faster than fire is put out, and the new plant is burning too!
Not yet. Maybe when I finish I'll write summary of what I learned.
Okay, so based on that signature `IterMut::next` doesn't borrow from the `IterMut` itself, but rather from the slice it backs. Whereas `&amp;mut self.slice[self.index]` does borrow from `self.slice` (and thus also from `self`, since it's a mutable reference). I think I get it now, thanks for sticking with me!
Congrats! :) From the "About the Package" crates.io documentation I wasn't sure I understood what this library is about. Also, the documentation is unclear about what the library offers. You describe it as a "half matrix of bools". The ASCII art makes it clear you're storing a lower triangle matrix of bools. OK. And then you have this: /// Gives the internal memory index of the bitset for the given (row, column) values. /// The internal indexing starts at 0. This means that index_of(0,0) = 0. [...] /// Row is required to be bigger or equal to column. pub(crate) fn index_of(&amp;self, row: u32, column: u32) -&gt; u32 { // If you entered the indices in the wrong orther, I'll fix them for you. ;) let (a, b) = if row &gt;= column { (row, column) } else { (column, row) }; let row_sum = (a * (a + 1)) / 2; let idx = row_sum + b; idx } where the comment doesn't seem to match what you're doing. You're saying you require `row&gt;=columns` but if that's not the case you're swapping them for us. So, it's actually OK to feed it with other coordinates which makes the matrix appear full and symmetric. So what is it? Is it a lower triangle matrix or a symmetric one? :-) If it's supposed to be a symmetric matrix of bools where you internally only store the information necessary to encode it the following part of your documentation seems contradictory &gt; You can say (B, A) = true and the rest = false because if you set the (B,A) pair to true, the (A,B) pair is also true. I suggest that you stick to one model and have documentation and code align. For example, you could say that a `HalfMatrix` encodes a symmetric relation by only storing the lower half and that enabling &amp; disabling (y,x) also affects (x,y) if x!=y. This way, one could use it to represent a binary adjacency matrix of a highly connected undirected graph without worrying about whether `y&gt;=x` is satisfied when enabling, disabling or quering that connection. Also, why artificially limit the size to 5792x5792 (which should only be about 2MiB)?
Office installs are very often 32-bit by default, and I believe MS officially recommends one install the 32-bit version (for add-on compatibility it seems). You should triple-check the running instance of Excel for sure. Another thing to try is to use the gnu toolchain instead of the msvc one. (This should rule out the possibility that the msvc one might be trying to load a msvc runtime incompatible with the one that Office is using... not really sure if it can happen.) Not really related but why aren't you using cargo to build the cdylib instead of calling rustc directly?
What game do you want to make? If you just want a project to learn Rust with, make many games, each more advanced than the last instead. Start with text games. Fewer things can go wrong then. Something as simple as hangman perhaps? Then you'll learn some file reading (the dictionary), generating random numbers (the rand crate) and handling strings in Rust. Then some non realtime puzzle game like Sokoban can teach you to parse text, organize the code/data. A simple tetris clone is also easy to make to learn about real time games programming. You can get simple text graphics and non-blocking input with the pancurses crate. Add sound effects. Make them again with 2D graphics. Again with 3D graphics. With custom shaders.
There is a key misconception here, revealed by the formulation "you cannot implement **even** them", highlight mine. The assumption here is that these data structures are trivial things, so that if they need unsafe code, by extension pretty much everything needs unsafe code. But this isn't true. Data structures are complex, lifetime-wise, and also in a way very low-level; after all, a `Vec` manipulates raw memory. Application logic does not need to manipulate raw memory. Or to put it another way, unsafe use does not arise from complexity, but from low-levelness. "anything mildly complicated is going to have to rely on `unsafe`" is wrong because of this.
It's not like there's some guy sitting around telling people to invent new web frameworks.
I have no special idea, at the beginning I just wanted to do simple games like Pong, and make more and more difficult game, I know the basics of Rust but I just want to be more experienced, do stuff to know better the language. I would like to do 3d game but I'm a little be afraid of that because I absolutely don't know oh to do 3d games, should I be able to make 3d modelling or things like that? I don't know. 
Look at r/rust_gamedev too. 
Thanks for your input. It seems it was my Nightly (in Settings-&gt;Apps&amp;features) that was messing my setup. After uninstalling Nightly, it works.
Now would you look at that. Thank you for the heads up. And you're right, that designer did questionable work to put it mildly.
I strongly disagree. You *need* `unsafe` to perform allocation, because the implementation of `Box&lt;T&gt;` uses `unsafe`. Deep down the allocator is either implemented in C (requiring `unsafe` to call it), or implemented in Rust using `unsafe`. I agree that many data-structures can be implemented without *additional* use of `unsafe`, on top of what the standard library already contains. How would a data-structure automatically resize without using `Vec&lt;T&gt;` or `Box&lt;T&gt;`?
Fair enough, I considered it a possibility but I didn't bother to actually look up the [API docs](https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glGetShader.xhtml). I saw the OP's code do + 1 so I assumed the returned string length didn't have a nul terminator without thinking about it too much. Looking at the docs this seems to imply the code in the OP has even more errors.
3D games are best developed by using an engine. Amethyst have a list of 3D games engines [here](https://github.com/amethyst/amethyst/wiki/Other-Game-Engines-in-Rust). Many of them can be extended with custom shaders etc. A good idea is to get ready made assets. There are a few sites with free stuff. Look in r/gamedev for links to them.
Notice my "Ext." addition, if you don't need to reallocate (and ideally the capacity isn't too large) you can just use an array. Zero unsafe code needed. &amp;#x200B; The next step is a safe implementation of slices. Lets stretch the idea a little, now we can do this with a tuple-style linked list and trait to walk over a type-level linked list to the correct index. &amp;#x200B; I'm not saying we don't need unsafe code. I'm saying we \*could\* do without it for these data structures.
Entity Component Systems in Rust, for game development and more: https://kyren.github.io/2018/09/14/rustconf-talk.html https://www.reddit.com/r/rust/comments/a38mas/20181204_rustakl_ecs_a_programming_paradigm/ https://slide-rs.github.io/specs/
Yep! And a final tricky detail: The borrow checker will be more relaxed than this if we're talking about shared borrows, because you can "copy out" a long lived reference from behind a short lived one. But the uniqueness requirement on mutable borrows doesn't allow that, which is how we get into this predicament.
I created an (although ugly) environment that continuously builds stuff and then burns everything down. without me touching anything. you can just load it and keep watching. Kinda feels like watching evolution over years. I wish I could keep this running for few months and see actually how long this cycle can go on. https://sandspiel.club/#okqq4qcJz1kM0dQMiiLB
Fixed. Thanks!
Continuing work on [tarpaulin](https://github.com/xd009642/tarpaulin/) reading about OSX debug-ports and how they act as a replacement for ptrace on OSX. I'm also working on a GUI application for choosing optimal parameters for blocks in clock trees for embedded systems, largely for fun. 
When I have a problem working with creates like rocket or diesel, sometimes compiler suggests me how to fix it. This is really helpful. My question is, how compiler knows these suggestions? Sometimes, compiler knows the issue number to see. It means create developers prepared these messages. But, how? Does anyone know details about this?
I came up with this crate because I wanted a way to parse binary data formats as easily and efficiently as in C, but without all the safety gotchas. This solution is most useful for sparse parsing, i.e. when one isn't interested in the values of all fields, only a few (otherwise using the byteorder crate directly is probably a better choice). I'm grateful for any feedback regarding what could be improved to make this crate more useful in general. And of course I would be especially interested in any problems you find with my assumptions regarding the safety and soundness of the `View` trait and its custom derive. I wouldn't be surprised had I overlooked some detail there ;)
I'd maybe try to normalize your formulas to something like CNF, and then store the normalized form.
For development you probably want to be using rustup to manage your Rust installations rather than using the installers.
I'm not saying this user *should* use Rust, but the Rust WASM working group is trying very hard to optimize code size through projects like wasm-bindgen, and this shouldn't really be the reason not to use Rust. I certainly hope we can get to a point where no one would think to call using Rust on wasm "heavy," if we're not already there. The reason not to use Rust is that the ecosystem is very immature and that's a pain to put up with if you don't have a good reason to use Rust.
Thank you very much for your kind words and your criticism. My reason for choosing `nom` is pretty much the opposite of what you suggested; I chose it because I‚Äôm reasonably familiar with it. I didn‚Äôt think of the `regex` crate, as I don‚Äôt have too much experience with it. I‚Äôve now changed the parsing from `nom` to `regex`, but I don‚Äôt know if the result is any good.
Trees and graphs in logic don‚Äôt have to be represented as trees and graphs in memory. As per the previous comment, if there are domain specific tricks you can use like normalisation then definitely try that out. More generally, look at petgraph both for inspiration in storage methods and as something you can maybe use. 
It depends a lot on what kind of mutations you will do on the tree. If it's going to be immutable, then you can just store all your nodes in a `Vec` and have them refer to each other by index. If you want to mutate the tree, adding and removing nodes, then you might want to do a similar thing but with a `SlotMap` instead (see the slotmap crate). If you want copy-on-write semantics, (ie, you'll keep multiple versions of the tree around and want to share common subtrees to save on memory) then using reference counted pointers might indeed be the best option.
I have almost always found data structures that I need on crates.io, some of which may use unsafe. One I did not find was a suitable octree implementation, which I wrote without any unsafe as part of the `space` crate.
I think the avoidance of aliasing makes mutability safer and easier to use than other languages. Because of this, immutability is much less important in Rust than in the FP-oriented languages.
Fast as in fast transistors. &amp;#x200B; Open hardware. (CPUs, storage device chips, maybe network cards too, with open firmware of course.) If enough projects start verification from deep enough, then it becomes very hard to silence all of them (at the same time), and if there is any hidden backdoor, it'll be possible to find it. The $5 solution is great if you know who to apply it to and when. It's "great" to get passwords. But it doesn't work for silencing people.
I second this. I never create a vec of vecs unless I semantically mean I have a dynamic list of lists. I typically use nalgebra's matrix types since that is usually much more appropriate.
Yes, that's why it was ringing some bells when I saw it. Must have been a very old installation from the days when I was still wondering how to use Rust.
ah!, right.
yes, e.g. with percy you can render your site on the server and takeover the app + state in the browser afterwards :)
Maybe consider ReasonReact. Similar type system to Rust. Compiles to readable Javascript. Can interact with any JavaScript library as long as you can find or write the bindings.
The idea behind safe/unsafe Rust is not that you should expect to do everything without using unsafe. It is wrong to think of unsafe as some ugly thing that is only there because safe rust would be "inadequate" otherwise. Unsafe is an important part of the language, just like every other feature Rust offers. However, you only reach for it when necessary, and when you do, you make nice, verified, safe wrapper APIs around it. By using these safe interfaces and abstractions (whose implementations have been carefully verified), one can do many things using only safe Rust. Unsafe is only really needed for the low-level building blocks. In the end, there might be a few small isolated bits of unsafe code in a project (where that really is the best option) and those can be carefully audited (just like one would do for C code), while the rest of the project is safe. This is much better than C, where your entire project is unsafe and auditing must take everything into consideration.
The problem is that many of these "typical" data structures have all kinds of ownership and dangling pointer issues if you're not careful with them. Rust forbids creating these kinds of issues in safe code. So this means that you either need to find an existing implementation of the data structure (which uses unsafe internally), or use unsafe yourself. But really you should be reconsidering whether those data structures are really the best solution. For example linked lists are less efficient (e.g. cache-wise) than a flat vector for many applications, so "just use Vec" takes care of those cases. Also switching to more ownership-friendly data structures and relying on Rust's compile-time checks lets you do things that in other languages would be considered unacceptably dangerous and brittle to maintenance. So you might find you have a lot more power if you work with (rather than against) Rust's restrictions. It's not all perfect, but it's surprising how you can still find efficient solutions within safe Rust, even though those solutions might be quite different to what you'd do in another language. Also those solutions may have distinct advantages which only Rust gives you. This is your challenge when you choose to code in Rust.
&gt; but if you cannot implement even them, then But you can ? `Vec` can be implemented in 100% safe code on top of `Box`, `List` can be implemented in 100% safe code on top of `Option` and `Rc`, etc. That is, these data-structures are safe, and it is possible to implement them in 100% safe Rust code, that's guaranteed to be correct. However, there are more efficient ways (e.g. using less memory, less indirection, etc.) of implementing these data-structures that the compiler cannot prove correct. `unsafe` code just shifts the proof of correctness to the programmer.
Check out Philipp Oppermann's "[Writing an OS in Rust](https://os.phil-opp.com/)." I've had a lot of fun working through it. 
Thanks for chiming in @paupsnz. So my main worry is about edge cases and correctness in general which I beleave is especially important when dealing with monetary values. The crate seems well covered with tests though, and I could not think of any more tests that would be obviously relevant. &amp;#x200B; Looking into the source code I see you've added support for postgres, but I cannot see what postgres type it will serialize into or any sign of it in the documentation? And how would this work with Mysql or MSSQL?
I have finally gotten to use rust at work! Needed a small utility tool to convert some application config files into a new format, so i threw something together in rust yesterday. Works like a charm!
Very interesting idea, but what's the purpose of the project? To protect library users from malicious activity like recent \*cough\* NPM incidents? If so, how will this be implemented? Is there going to be a central "trusted" repository of proofs? Or users will trust many "popular" repositories? Also, I think it would be nice if `crev` required multiple reviewers to approve the quality of a package because otherwise, a malicious author could somehow hide malware in their crate and then submit a "proof" to a trusted repository.
Why? IMHO _crev_ is shorter and more memorable
As so many others have said, Rust isn't ready... yet. Consider doing it in elm? It's a great language and fits well with the secure and fast aspects of Rust.
Why we cannot just mask unwanted bits before conversion to f32 or pick f64 bits to f32 value manually? 
https://github.com/m4b/scroll is a similar project on binary parsing.
I think regexes and the `re_parse` crate make things a breeze for the parsing parts -- you should definitely look into it!
I made a crate that uses some tricks to refactor dynamic dispatch into runtime-`match`ing across a fixed set of types. As it turns out, this ends up being anywhere from 5x to 10x the speed, depending on how it's used. The best part is, being a relatively simple procedural macro, it requires very minimal changes to your code! For anyone interested, I wrote up a section [here](https://gitlab.com/antonok/enum_dispatch#technical-details) on the readme describing how it works, and there's another example with more detailed benchmarking information on [docs.rs](https://docs.rs/enum_dispatch).
The `unsafe` keyword does not mean that an implementation built on top of it is `unsafe`. It only means that the usage of `unsafe` could be abused if implemented incorrectly. It's useful when performing a code audit or a code review. Compared to C and C++, you can imagine that every line of code is a single `unsafe` scope, as opposed to a few snippets in the standard library.
Yep, however testing the edge cases of decimal calculations (the simple ones are already tested in all crates as far as I could tell) requires a knowledge of floting point artithmetic that I don't currently have. I.e. if some value overflows will it err or could it just provide the wrong result? Is there *any* case where a wrong result would silently be returned? Maybe it's me being overly cautious but I thought it was worth checking other people's opinions as a part of the process :)
Thanks for some very interesting points. I would also prefer if one of the decimal implementations were part of the "num-\*" project. The ideal scenario would be that it also implemented some common standard like IEEE 754-2008 as well. I didn't expect to read about DPD and Chen-Ho encoding while researching a decimal crate, but it's always nice to learn something new ;)
Unsafe explicitly marks the areas you must be careful about. Whereas in C you have no clue. Given how many common programming mistakes end up as exploits that rust prevents it's a net benefit.
Also, perhaps it's a positive that adoption of these libraries is limited. Perhaps that's exactly what the pre-1.0 version number is meant to do. It's probably preferable to massive segmentation due to having lots of major version numbers. If you adopt a pre-1.0 version library, then you should be committed to upgrading as the API improves and stabilizes.
Can resetting of last 29 bits help us to get f32 from f64 without unwanted round-up?
Strictly speaking no, but it does mean that no matter how many new platforms enter federation, you don't have to worry about "keeping up" to address that expanding audience.
Iron + Maud Stripe payments webapp thing: https://github.com/captainbland/crier Someone make me write a test.
&gt; if you have to put that stuff all over your code, then isn't that kind of losing the whole point of Rust, and might as well stick to more battle-tested and familiar C/C++? What you're basically saying is that "if I have to put 5-10% of my code in `unsafe` blocks, why don't I just use a language where 100% of my code is unsafe?". 
I fail to see why \`match\` would be faster than \`call ptr\[rsi + x\]\`. The only way I can think of this being faster is that it allows the compiler to optimize the call by knowing what's inside. So I think you are providing a way for the compiler to inline small things and makes them closer to the current location. As soon as I black\_box Zero and One implementations, the speedup is limited to 2x. Here is my experiment on godbolt: [https://rust.godbolt.org/z/a7ej-z](https://rust.godbolt.org/z/a7ej-z) Still, this can be useful to speedup some cases (known list of impl and small impls) where the speed up is massive. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; 
Translation to CNF can result in an exponential blowup, so I wouldn't do this unless you actually need CNF (e.g., for a SAT solver).
"Unsafe" is for things that would be implemented in the compiler or runtime library in "strictly safe" languages like Java. You wouldn't say that Java is unsafe because the compiler output isn't formally verified. Unsafe Rust means that when implementing, for example, vectors, we can write *code*, not *code that generates code*.
Inlining is definitely part of the benefit, but not the whole story. I do have some black\_box tests of my own in the repo ([without](https://gitlab.com/antonok/enum_dispatch/blob/master/benches/compiler-optimized.rs) black\_box compared to [with](https://gitlab.com/antonok/enum_dispatch/blob/master/benches/blackbox.rs)). Generally dynamic dispatch is done with a vtable lookup, since the compiler doesn't know the full set of possible types. Using \`match\` keeps all the associated type information packed with the struct. Of course, one downside of this approach is that it doesn't support external implementations of a trait. &amp;#x200B; I'm not sure why you're only seeing 2x speedup. I just set up a simple testbench to call your methods one million times, these are my results: test benches::dyn_blackbox ... bench: 1,673,980 ns/iter (+/- 38,153) test benches::dyn_inline ... bench: 1,194,738 ns/iter (+/- 5,306) test benches::enum_blackbox ... bench: 258,442 ns/iter (+/- 52,310) test benches::enum_inline ... bench: 266,082 ns/iter (+/- 58,947)
&gt; ~~javascript~~ Typescript FTFY. :-P But I agree with the rest.
2x speedup is by putting the blackbox in the Zero and One impls use super::ReturnsValue; pub struct One; impl ReturnsValue for One { fn return_value(&amp;self) -&gt; usize { test::black_box(1) } } test benches::boxdyn_homogeneous_vec ... bench: 5,583,330 ns/iter (+/- 36,771) test benches::customderive_homogeneous_vec ... bench: 4,665,040 ns/iter (+/- 251,604) test benches::enumdispatch_homogeneous_vec ... bench: 2,107,920 ns/iter (+/- 18,288) test benches::refdyn_homogeneous_vec ... bench: 5,839,690 ns/iter (+/- 8,121) 
For the CoW stuff, maybe the im crate?
TL;DR: It's okay to use unsafe when it's needed. The idea is to minimize the number of times you do by creating safe abstractions that wrap unsafe code.
that's what I want to do, but I need an efficient data structure for that!
with tseitin encoding the blowup is linear!
Otherwise, the compiler optimize the call to one instruction: `xor eax, eax`. So you were mostly benching the `vec[i]` resolution, which alone gives: ``` test benches::base_homogeneous_vec ... bench: 545,415 ns/iter (+/- 10,048) ```
Wow, that crate looks like just what the doctor ordered! Right down to the usage example on [crates.io](https://crates.io/crates/re-parse) being almost word-for-word my use case. Thank you very much for the tip.
Thank you! This makes a lot of sense. I do agree that reading source is an invaluable way to learn. I find myself reading quite a bit of Rust source code, and the types are often self-documenting. 
Depending on how big the tree is, and how local your accesses to it are, and how fast you need to traverse it, it may or may not be worth changing the layout for cache locality. If you walk the whole thing in sequence, or repeatedly deal with small subtrees of it, then switching to a cache-friendly structure will probably be a big win. If you deal with essentially random parts of it, then maybe not... every time you touch the tree you're likely to cache misses no matter what. If a bit of both, then maybe packing multiple nodes together into a single structure a la `BTreeMap` would get some gains. Could you be convinced to write up the results of wherever your investigations lead you? It sounds like an interesting problem!
Awesome, I can see it now. I'll have to add some more benchmarks! &amp;#x200B; I do think inlining will be pretty likely for most use cases of this crate though -- it seems to me that trait methods generally only become complex when they are exported for compatibility with external implementations, which aren't supported anyways!
I am reminded of, if I am recalling right, a research paper in the early 1970's or such that investigated every binary tree implementation they could find, and found bugs or incorrect behavior in *all* of them. Basic data structures are certainly not trivial things!
im looks good, thank you for the tip!
thank you! how does it help performance to have indices instead of pointers?
In C/C++ you need to proof-read and analyze ALL the code for correct handling of memory, pointers and (implicit) lifetimes. In Rust, you only need to proof-read the code marked as unsafe. For the remaining 99% of the code, the compiler does the job for you.
thank you! good idea, but my input is unfortunately not normalized. in fact normaization to cnf is a big part of what the program should do in the end
Is your tree of pointers too slow? 
Why? 
You don't need to reference count
Off topic... I'd really like to see your inbox
Nope. Unfortunately, if all your prior information is that you have a double-precision float, you can accurately direct the rounding. Take the example from before, if I went 1 bit above the halfway point and you set the last 29 bits to 0, you'd incorrectly round down. Fortunately, 32-bit float parsing is generally as-fast, if not faster than 64-bit float parsing, but mostly because the range of possible values is smaller (`[1e-45, 1.7e38]`) roughly, so you can discard bad cases a lot faster. Integer to float conversions are very cheap, especially when you're not actually letting the compiler do it, but directly fiddling with bits.
Im not good enough with Rust yet to know what deref coercion is, but I‚Äôm a big fan of ‚Äûexplicit is better than implicit‚Äú and I often prefer code verbosity so it‚Äôs easier to understand what is going on. I‚Äôm looking forward to reading more about this and seeing what others have to say! Sorry I don‚Äôt have more to add to this!
Cool idea. This is basically devirtualization which is especially common in JIT compilers. It would be interesting to compare against profile guided optimization, which should be able to do somewhat the same thing on AOT programs.
I highly doubt using `byteorder` directly is better for complex data. You sell yourself short, this crate looks awesome! The main advantage is the ability to *visualize* the data, even compare it side-by-side with a C-struct.
No.
This particular syntax has been bikeshedded quite a bit. I'd like to invoke stare decisis.
There is at least initial support for PGO.
I don't know about the OP, but for me I'd be happy with something that could say either may allocate or doesn't allocate. I haven't thought about it very much, but I'm not aware of anything that would make that too difficult to determine. Or have I missed something obvious?
I guess you could fork clippy and add your own lint forbidding it? I don't think anyone wants the language to fork..
Yeah, those are two use cases I really wish were done already...but they're not. Right now, I've just composed my own "raw" structs that are used by the canonical data structure under the hood in its own `FromStr` implementation. I need to finish filing the issue I started for enums -- I was doing some design thinking hoping to expedite the process.
The procedural macro API allows macro authors to create custom error messages, see this example:https://internals.rust-lang.org/t/custom-error-diagnostics-with-procedural-macros-on-almost-stable-rust/8113
There seems to be something up with the code highlighting...
I'm the author of [https://crates.io/crates/bex](https://crates.io/crates/bex) ... The "base" module in there is similar to what you're trying to do. It is my first attempt at a rust project, so I can't promise I'm doing anything sensible... But: I started with Rc and pointers initially and essentially decided it was too much trouble. So now my references are just indices into a big Vec. The \`base\` module is actually kind of the messiest of the lot... Most of my work has gone into converting the ASTs it provides into binary decision diagrams. But: if you think it might be useful for you, or just feel like comparing notes, I'd be happy to chat with you about your project. (There is also [https://crates.io/crates/boolean\_expression](https://crates.io/crates/boolean_expression) ... I started my project as an exercise for learning rust, so I didn't look too deeply into the competition... I think the author is staking his PhD thesis on it, though, so it's probably worth checking out.)
Spit out "simple" html is dead easy and will perform better form most use cases. Put a "front-end" JS framework like react or Vue is overcomplicate things for anything except heavy attempts at mimic desktop/mobile UIs. From somebody that do both, I prefer to have a "dumb" rest API with maybe html templating. For the JS part, I like how Vue is easy to integrate with normal html/css. Pick a good html framework like bulma, Foundation or Bootstrap and you are set. P.D: If you interest is to experiment, still do things the "boring and proven" way. You will finish faster and can progressively add things. 
No central repo. WoT. After it gains enough traction, it will be possible to trust only something that was reviewed by N trustd users.
Can you represent it in a spread-sheet like way? Then apply a relational view to data and you are set.
The definition of a no_std library is one that doesn't use std as a dependency.
 Now I understand. Thanks!
at least [we were warned](https://imgur.com/LM62m0N) :)
yes, merely iterating over all nodes takes hours
thank you for this solid advice! I'll investigate tomorrow ;)
thank you, I will look into those crates tomorrow, sounds very promising
I'm very interested in this, not for the performance boost, but as a way to drop the boilerplate when I want an enum over all known implementations of a trait. Advantages include being able to deserialize the enum with serde, loosening the constraints rust places on trait objects, or using crates like strum to operate on the cases. If I actually got a performance improvement in the process that would be icing on the cake.
[removed]
I think if I had a huge tree of very small nodes, I'd look at byte-packing it into blocks and then make a tree of those blocks (i.e. large subtree becomes a subblock instead of being stored inline). It would complicate modifications but would increase cache and bandwidth use. (It's a bit like tiling an image.) Tradeoffs ...
I've been looking for an approach to this and haven't been able to find one, though I feel like this has to be a solved problem. I've been trying to rewrite a Java service in Rust (mostly for educational purposes). We make typical use of inheritance and have several classes that represent different output types from this system, each corresponding to a different "type" of message. All of these objects share a large number of fields, and so inherit from a base class which contains those fields, with each subtype adding the few additional fields it needs. We have a few functions / classes that operate on that base class to perform common operations. This is the part that is difficult to "port" to Rust. In the Java situation, any method that operates on only the shared fields can just use the base class type in its arguments. In Rust this isn't possible (as far as I know), without creating a trait that defines every field that is shared, and this feels like an antipattern to me. Most things I find online when searching for solutions discuss the inheritance of behavior, not of structure. Is there a clean, standard way of approaching this? And if I'm totally off base here, and there's just a different approach I should take altogether (I know I shouldn't just try to to copy Java to Rust directly, obviously), I am **totally** up for that as well. &amp;#x200B;
&gt; I fail to see why `match` would be faster than `call ptr[rsi + x]`. Branches can be speculatively predicted, and every direction can be precomputed. An L1i/L2/L3 cache miss is a hard stall until that data gets loaded. 
These are very valid concerns - particularly when it comes to underflow cases. Consequently, rust-decimal now has a fuzz generator which allows you to generate random input/output to test against. It funnily enough uses the `C` implementation via `decimal` to help calculate the output. Consequently, the fuzzer is not perfect however does allow you to review results and see if it's completely wrong (e.g. underflow) or a precision implementation limitation (due to only using 96-bits/3-words, `decimal` has more aggressive negative rounding on underflow etc). Originally I was wanting to use the `dotnet` implementation for testing against however that was a lot tougher to get up and running (at the time). I may still move to that since it has been the primary inspiration for `rust-decimal` but for now, this gives me _some_ confidence that it's covering cases I hadn't thought of (it has helped catch a string parsing issue in the past). Ultimately I'd like to let this run on a daily CI job however I would need to get a cs version working for that. One thing which _isn't_ where I'd like it to be with `rust-decimal` is the division performance story. Other operations perform fairly well, however this is one area in which I'm not yet happy with how it performs with underflowing numbers. That being said, I wrote the fuzzer for this _exact_ reason. Before any sort of performance refactoring I wanted to make sure I had a reasonable coverage to feel confident nothing had broken. Support for `postgres` is included, and my apologies that I haven't documented this at all it seems. It currently (de)serializes from/into the `numeric` type. This is a native protocol level implementation specifically for the https://github.com/sfackler/rust-postgres library. I'm happy to add support for other databases given the demand - the interfacing library would simply need to allow for extending protocol/type support. Anyway - hope this helps answer your questions and please let me know if you have any more!
How many items are in that tree?
Disclaimer: I read this *very* quickly and so may be off-base here. If I'm understanding correctly, it sounds to me like you could make a `struct` containing all of the fields of your current base class, since these fields should be present in all message(?) variants. I'd give this struct the canonical name; if you're encoding messages, I'd call it `struct Message`. To represent the remaining information, I'd make an inner `enum`, with each variant having the additional information needed for that message type. Let's say I'm encoding HTTP errors, and for whatever reason, I want to give some extra information with the 407 response code. That might look something like this. struct HttpError { code: u16, inner: Option&lt;Inner&gt;, } enum Inner { ThisIsA407(String), } (But of course, with better names.) In general, when you know all of the variants that could possibly be used at compile-time, it's preferable to use enums (if applicable) over traits.
Nice summary. 
This example needs to be in the Book! ```Rust struct Example; impl Example { fn new() -&gt; Self; fn chain(self) -&gt; Self; fn borrow(&amp;self); fn take(self); } ```
&gt; This is basically devirtualization which is especially common in JIT compilers. This personally reminds me of GCC's speculative devirtualization optimization (see [this blog serie](http://hubicka.blogspot.com/2014/02/devirtualization-in-c-part-4-analyzing.html)). In short, in certain circumstances, GCC will determinate that a given `Base*` is quite likely to be `OneDerived*` or `TwoDerived*` rather than anything else, and will apply the following transformation: // Before: base-&gt;call(); // After: if (base-&gt;vptr == &amp;OneDerived::VTable) { base-&gt;OneDerived::call(); } else if (base-&gt;vptr == &amp;TwoDerived::VTable) { base-&gt;TwoDerived::call(); } else /* fallback */ { base-&gt;call(); } Which lets inlining kick in for the two identified cases.
Rust can be a little tricky to learn. As I'm sure you've seen, you should start with [The Book](https://doc.rust-lang.org/book/index.html) and go from there. The language absolutely does require you to understand what's going on under the hood, but the abstractions it provides make this easier to reason about. Best of luck!
No, but I basically know how to do this. I am willing to write a Clippy-like plugin for this if there are enough interest to raise $1000.
Another reason is that indirect calls have become much more expensive in some use cases due to mitigations for the recent SPECTRE vulnerabilities that abuse speculative execution. The Linux kernel is currently moving a bunch of code away from dynamic calls for this reason ([mailing list](https://lwn.net/ml/linux-kernel/cover.1543200841.git.jpoimboe@redhat.com/) or the excellent but still in the subscribers-only time period [LWN article](https://lwn.net/Articles/774743/)).
Thank you for your work on this! The goal is to switch from a C toolchain to a Rust toolchain this year.
Any plans to extend this to support the other direction; writing a struct into a byte stream/array?
&gt; It also included `tokio-proto`, but we won‚Äôt talk about that. This is funny, but I also really appreciate it. Good design takes a lot of trial and error. Sometimes people get cynical about Rust's relatively small standard library. "It doesn't even have regex support" etc etc. And that's true. But this stuff is hard! And it's hard in more ways than one! Rust has a lot of features like lifetimes and no\_std that make API design tricky, where a lot that worked for other tried-and-true languages doesn't work for Rust. And sometimes, even what the tried-and-true languages came up with [isn't ideal](http://lucumr.pocoo.org/2016/10/30/i-dont-understand-asyncio/). This stuff takes _years_ to sort out in a satisfying way. Kudos to the team for putting the processes together that make this kind of iteration happen.
All true. I think the idea behind tokio-proto is good, but there were a number of issues with the approach. We definitely attempted that way too early. @jonhoo has been exploring a reboot of the idea as tokio-tower (here: http://github.com/tower-rs/tokio-tower). The idea is similar, but the goals are different. tokio-proto tried to do way too much, tokio-tower will be for getting started.
Haha, I actually completely forgot that part of the reason I did this was so it would work nicely with serde. So yes, that is a very valid use case as well!
This is certainly accepted and idiomatic practice. I don't know of any downside.
This is _gorgeous_. A couple thoughts: - It might be worth automatically integrating with the pager when the output is long enough, like `git` does. Especially because it looks like it requires something like `less -R` by default, and most people probably don't know `-R` off the top of their heads. - A default behavior that "intelligently" expanded the "most relevant" directories would be really nice. I'm not sure what rule to use, but something like "anything that makes up more than X% of the total space I'm analyzing right now gets expanded" might be a start.
I'm glad to hear a reboot is being worked on. I was sad when `tokio-proto` died. It was really useful for my particular use case.
I think the principle downside is that preludes tend to encourage `*` imports in my experience, which can make name resolutions while reading the code a bit harder. Generally speaking, preludes are good when there exist many public API items, but where there exists a relatively small subset of API items that are very commonly used. I don't think I've had the occasion to add a prelude to any of my crates, but I've certainly seen some crates use them effectively!
This seems very similar to the [plain](https://github.com/randomites/plain) crate.
What is/was tokio proto? Tl;Dr? 
Explain?
Oh cool! I'm doing something very similar for a project of mine. Though I'm doing a few things a little differently: 1) Rather than provide individual `Uint` structures for integers, I have a `Le&lt;T&gt;` wrapper type. This is mainly a cosmetic change so that syntax highlighting correctly highlights the `u64` in a `Le&lt;u64&gt;` 2) Fallible conversions where not all possible bit-values are valid, such as `bool` and the various `NonZero` integers. I also did the trick of defining an unsafe `NonZero` trait, which lets a view of an `Option&lt;T: NonZero&gt;` work (though actually that should be called `NonZeroNiche`...). I also want enums to work ([relevant bug I found](https://github.com/rust-lang/rust/pull/56619) in the process). 3) My stuff works on aligned rather than packed data. Though that may be the wrong decision, as alignment means padding bytes, and since I'm also doing deterministic serialization which means you have to zeroize those padding bytes. Though the alignment does make it easier to do a really dirty trick where parts the datastructures are lazily initialized, and thus have `AtomicUsize` fields in them that get set during serialization if not already initialized. 4) I haven't bothered to implement big-endian. :) Greenfield project so I don't need it. 5) Unized types: basically I want `[T]` to be a valid thing to obtain a view from. I'm doing this via a `Pointee` trait that defines the size metadata for a type and thin-&gt;fat pointer conversions. 5) I'm supporting references/pointers. Which is a whole other ball of wax... :)
This is cool! I‚Äôm not sure I‚Äôll be able to use it on my current project, alas. OpenType has lots of data dependencies, refined types, and offsets, so we‚Äôre working on our own declarative binary parsing DSL. But I imagine this could be useful for less ridiculous use cases!
The variable name is highlighted in transgender pride flag colors. '''str::replace()''' swaps in "E" for "T"; the program prints out "Hello, E!"
I'm confused about the "Hello, E!" part.
Wrong subreddit. You want /r/playrust
"E", as in estrogen.
Ohhhh Okie doke makes sense now :)
From what i've read about rust, self-referencial structs and 'cyclic graphs' in general are imo the remaining major obstacle that people reach unsafe for. Crates like *rental* help, but their usage is obviously a major 'usability' hiccup, even discounting you need to know about them and their usage. I think this story needs better solutions in the standard.
https://github.com/tokio-rs/tokio-proto Basically a high-level library for making async services. Top of the readme has a link to a discussion about it's issues.
Neat
how do I tell it to skip some data that I'm not interested in?
You can make a `no_std` crate that optionally depends on std, and `no_std` crates can be used as dependencies in projects that use the standard library.
That's awesome! Gratz on the hrt (assuming you've just recently started) and the tattoo :D I've been looking for a way to subtly show my trans rustacean pride. My vague idea was to somehow combine Ferris the crab and the lobster emoji, [which is used as a symbol of trans representation.](http://time.com/5365725/lobster-emoji-trans-representation/) But I have yet to figure out a good way to combine them :)
Interesting -- reminds me of mre's [hyperjson](https://github.com/mre/hyperjson) library that he [talked](https://rust.cologne/2018/08/01/open-hyperspace.html) about at a recent meetup in Cologne.
To support external implementation (at extra dispatch time): ``` #[enum_dispatch] enum MyBehaviorEnum { MyImplementorA, MyImplementorB, External(Box&lt;MyBehavior&gt;), } ```
What about, instead of #[derive(Clone, Copy, View)] #[repr(C)] struct Animal { name: [u8; 4], number_of_heads: u8, number_of_legs: u32_le, } We had something like #[derive(Clone, Copy, View)] #[repr(C)] struct Animal { name: [u8; 4], number_of_heads: u8, #[view(u32_le)] number_of_legs: u32, } ? That way, we could use standard Rust types in the struct (which seems better for a library)
LOL, i hoped it would be only a reddit thread typo but sadly the blog title also wants to analize :D
* Raw pointers don't have deref magic, they should have it unsafely. * SIMD Intrinsics are overly paranoid about what's unsafe. * Derive could certainly be enhanced to allow the math ops.
Not going to doubt that efforts are being made to do lower the amount of what's transported but it's simply a platform limitation that basically all the niceties of javascript are preloaded for users and on simple web pages, ditching a 2kb file of javascript for an executable that needs to describe many things like allocation itself, is highly wasteful of bandwidth and as a result is inaccessible to large swathes of users for a variety of reasons.
&gt; For example, tokio::run_async will be the way to start the Tokio runtime using an async fn (or a std::future::Future). &gt; Once async/await support has had a moment to mature, Tokio will issue a breaking change and drop the _async suffix. tokio::run will take an async function by default. Why can't tokio::run receive both old futures and std futures / async fns? Old futures could be defined in terms of std futures.
For the curious, you can see a real usage of the framework here: [https://github.com/TeXitoi/rusty-clock/blob/master/src/main.rs](https://github.com/TeXitoi/rusty-clock/blob/master/src/main.rs) That's the plumbing of an ELM architecture for an alarm clock. You can skip \`fn init()\` that is mostly device configuration boilerplate.
Because there is a compat layer to go from 0.3 -&gt; 0.1 and that needs to be applied before calling run.
Theoretically, I think so. As of right now, the library currently won't know how to handle that External line -- it expects all the variants of the enum to have no parameters. &amp;#x200B; I'm not really sure why it didn't occur to me to support syntax like that to provide a custom name to variant!
could you elaborate please?
I think having preludes makes it way to easy to include everything in it. Which just makes it hard to read the code!
The over-arching question I have for all of these is: **What steps have you taken to get this noticed?** I don't know that there's anything NYAR could do here, simply because these are all at `libcore`'s level or below; I don't consider these issues in the scope of Rust's "ecosystem" (i.e., crates) so much as its fundamental offering. &gt; Raw pointers don't have deref magic, they should have it unsafely. I understand your pain! &gt; SIMD Intrinsics are overly paranoid about what's unsafe. I'm curious -- what specifically do you mean? Could you give some examples? &gt; Derive could certainly be enhanced to allow the math ops. I agree in the case of unit structs -- I think it's fuzzier for non-unit structs, where domain logic can get very different. Have you seen [`derive_more`](https://crates.io/crates/derive_more)? They have `derive`s for math ops. 
Thank you! I was thinking of getting the code overlaid on a pride flag but it would have been too visually busy at the cost of legibility. I hope you can find a design that works for you!
What about run receiving Into&lt;0.3 Future&gt; (or similar pattern), so that when you pass a 0.3 future it uses it as is, and when you pass a 0.1 future it first converts? I mean, traits should be able to abstract between those two types.
it has a depth of ~330, but most nodes are shared heavily (20/30 copies per node) and around 30.000 nodes)
You mean, so that `Animal::number_of_legs` is a `u32`? That wouldn't work, as the endianness of `u32` isn't defined; remember that `View` is trying to *directly* coerce a reference to a byte slice into a reference to a rust-compatible type, without copying. For example, `View` could be used on mem-mapped files.
Oh.. makes sense.
I tried warp some time ago. I thought the API was neat. However, when I tried to add some (fairly basic) custom functionality, I couldn't figure it out. So I looked at how warp implements its filters, however the filters are not implemented using the public API, and so cannot be used directly as a guide. I left it at that for the time. I think it would be very elegant and really prove the concept if warp were implemented with a small (public) kernel and all of the extra filters implemented using the core abstraction entirely "in userspace", if that makes sense.
My regexes for this problem looked like this (they're in Javascript, sadly): const TIMESTAMP = new RegExp( /\[\d\d\d\d-(\d\d)-(\d\d) (\d\d):(\d\d)\]/ ); const GUARD = new RegExp( /Guard #(\d+) begins shift/ ); const ASLEEP = new RegExp( /falls asleep/ ); const AWAKE = new RegExp( /wakes up/ ); I then wrote some simple manual code to check which regex matched the log line and fill in the timestamp struct. Note that this is a bit sloppy, as buggy log lines could conceivably match. Maybe I should add `^` and `$` anchors to the regexps and write more careful code, but really for this use case it doesn't matter much.
&gt; I don't even know if things like that work on Windows... [`pdcurses-sys`](https://github.com/ihalila/pdcurses-sys) allows that kind of UI to be built on Windows. [pancurses](https://github.com/ihalila/pancurses) will give you a wrapper around `ncurses-rs` or `pdcurses-sys` as appropriate for the target platform. That said, if you're building a UI like ncdu, you'll probably want to go a layer higher and use [Cursive](https://github.com/gyscos/Cursive/), which is basically a text-mode widget toolkit with pancurses as one of the supported backends.
You can [use](https://github.com/RustCrypto/traits/blob/master/digest/src/lib.rs#L20) `extern crate std;`, but it only makes sense for optional features dependent on `std`, and potentially can [create](https://github.com/rust-lang/rust/issues/38509) issues for no_std users if done wrong.
I wonder how many of the subscribers expect game videos...
Your regex code looks fine. The only thing I would change is to use different regexes for the three cases and let the regex tell you what's going on rather than doing a string match on the result. It's a matter of taste. Your way works fine and is maybe more readable, my way is going to be slightly more efficient (which doesn't matter here) and less error-prone. If you typo between the regex strings and the matching strings, you're going to have a bad time.
Sounds like something is still trying to pull in libstd somewhere. Are you running `cargo build --target &lt;your target&gt;`?
I assume not so many. We have a steady uptake in view numbers all the time and especially around conference releases.
&gt;SIMD Intrinsics are overly paranoid about what's unsafe My hope is that we will move in this [direction](https://internals.rust-lang.org/t/pre-pre-rfc-target-restriction-contexts/7163).
You need a concrete type I believe to implement that from but I could be wrong.
I'm a little surprised that touching only ~1 million entities takes hours. Are you compiling with `--release`?
I determined the exact number: 454.220 nodes, depth of 330 is still correct.
cargo-doc. The way Rust self documentation is designed and implemented, it railroads developers too heavily into describing *what* something is, rather than *how* and *why*. A concrete solution to this is hard to quantify.
A very legitimate question!! :-)
Tracing functionality would be fantastic. I had a reasonably complicated use of tokio at work earlier in the year that proved quite difficult to debug. Lots of \`println\` debugging was used, and \`tokio-trace\` would have probably made that all much smoother.
Oh, I'm dumb; I split off the bindgen generated stuff into a separate crate and I didn't set `no_std` on that. I'm still having the issue though when depending on the libc crate even with `default-features = false`
Thanks for the kind words! I mentioned `byteorder` as probably a better alternative in cases where you want to parse everything (meaning convert every integer field to its required endianess and alignment) because in these cases using `structview` doesn't provide any performance advantage over explicitly reading every field (under the hood, the integer views use `byteorder` anyway when the integers are parsed in `to_int`). Using `byteorder` would then be more familiar (I think) because it is extremely widely used. Apart from that, you avoid a dependency and a couple lines of unsafe code, which is always a plus I think. Although I see how `structview` could be valueable anyway, even when every field is to be parsed, as it saves some typing compared to directly using `byteorder`. I'm just not sure that would justify the added complexity.
I feel like there is a lot of improvement that could happen with pattern matching too. For instance I can't do something like: `for &amp;[x, y] in s.windows(2)` Because the pattern isn't exhaustive, but I think this should be allowed, with non-matching patterns panicking.
I didn‚Äôt know what it meant either. However: TIL :-)
I didn't think about that yet, no. I'm also not sure if that would be useful. `structview`'s main use case is sparse parsing, but there is no such thing as sparse writing, you always have to write all the data. Maybe something based on `serde` would be better suited to this?
I want to use the [Typed\_Arena](https://docs.rs/typed-arena/1.4.1/typed_arena/) crate to store some data, but it seems I cannot share this between threads as it uses a RefCell. I understand that RefCells cannot be shared because they lack Sync trait. What I don't get is why can I not wrap this in a global Mutex and thus serialise access. I'm just comparing to using a thread-unsafe class in C++ or java, where I would just put a mutex around every access? Is there a way to achieve the same effect in Rust
Same. Some syntax features like the `fn foo&lt;T: Clone&gt;()` I actively avoid in favor of more explicit syntax like `where` clauses, mostly because it means I can consistently write all trait bounds the same way.
[What is wlroots? Click here to find out](https://github.com/swaywm/wlroots) [Documentation](https://docs.rs/wlroots/0.2.0/wlroots/) These bindings are no where near complete and probably have bugs and other things in them. They also are unusable without the "unstable" feature flag currently because the C library is still somewhat in flux. However these bindings aim to be complete and safe and so far they seem to achieve that. If anyone wants to use this and has questions either open an issue or ping me @timidger on #sway-devel on freenode. (Also I haven't tested if it works by using cargo to install the project -- you might just want to use a git submodule since you'll want the latest changes). (Also Also this is 0.2 since wlroots released a 0.2 of some stable interfaces. The version of the library will always track wlroots until 1.0 when I'll come up with a different system)
That sounds really cool! Also way more sophisticated than what \`structview\` does. I intentionally try to keep the project simple as less code means less bugs ;) Still it would be cool to take a look at your implementation. I suppose it is not public though?
If your prelude contains everything, I think that's a good reason not to have a prelude- just put everything in the crate root instead. I'd generally put things in the prelude that very few things in your crate work without. Like, extension traits for instance - or traits which provide key methods on structures your crate provides. Enums or enum variants might belong in there, but I very rarely would include those or structs.
Future isn't a type, it's a trait. You can't implement `Into&lt;Future&gt;`.
The nice thing about simply casting a `&amp;[u8]` to some struct reference is that this doesn't do anything at runtime, simply tells the compiler to start treating this data in a different way. So creating a view doesn't cost you anything. Instead you pay the cost later (one could say "lazily") whenever you actually read an integer from one of the integer views (i.e. any integer that's wider than 1 byte), as this requires copying to ensure the correct endianess and alignment. Skipping data you are not interested in just means not calling \`to\_int\` on these fields. 
I didn't skip duplicates while iterating, that made it so slow. Skipping duplicates brings it down to less than a second. And yes, I'm compiling with release!
Awesome, I'll try updating to the new version. 
I disagree with you here. The point of self documenting code is to generate documentation for users of the code, not maintainers. 
That section gave me a chuckle, I was initially scared off from making things with Tokio because of `-proto`, things have definitely come a long way!
It's similar indeed! Though AFAICT, `plain` has a different use case, namely interpreting given memory locations as data structures. As such it has different design trade-offs than `structview`, e.g. enforcing correct alignment at runtime vs. enforcing 1-byte alignment at compile-time. It also doesn't have endianess support or a safe custom derive. Looking at the safety requirements for the `Plain` trait, they are very similar to those I determined for my `View` trait, so that's a good sign I didn't overlook something important :) 
&gt; transgender pride flag colors Are those different from the usual LGBT colours? TIL there are a lot of [variations](https://en.wikipedia.org/wiki/Rainbow_flag_\(LGBT_movement\)) on that flag.
In addition to what petertood said: custom derives can only add stuff to the struct definition, not change the original definition. So the derive couldn't change the `u32` to `u32_le` or anything. You could do that with proc-macro attributes (e.g. `#[view]`), but I guess it's not really worth it for this crate.
I get what you mean, it definitely is a goal. Many of the more straight forward filters use the private `filter_fn`, to get access to the private `Route` type. I do think that can become public at some point, but it's private as I have some ideas that might need to add a generic to `Route`. Some of the other filters, however, really *are* just composing filters like a user would: many of the `body` filters and the websocket filter come to mind.
I'm taking a library I wrote for nightly and trying to get it to run on either nightly or stable, with slightly different implementations hidden behind a feature. How do I make my doc tests not break on a non-nightly compiler? Is there anything else I should be aware of for documentation of nightly vs stable capabilities?
I tend to think prelude::* should only be used in cases where you're trying to provide a DSL -- and few things really necessitate a DSL. Otherwise, I think your crate should be organized in a way that makes wildcard imports unnecessary. This is a design challenge. 
So is your problem solved now? =)
Very cool. I've done [something similar](https://github.com/dholroyd/mpeg2ts-reader/blob/master/src/demultiplex.rs#L146-L166) (but specialised to a specific trait) in pursuit of performance. &amp;#x200B; Can `enum_dispatch` be used where the trait and the enum are in different crates? (Allowing client crates to supply the implementation is a goal of the current code.)
https://crates.io/crates/derive_builder
My hero. Thank you!
I'd really like to take some time over the holidays to contribute back some documentation, as this is a major pain point for new players. There is a [doc blitz](https://github.com/tokio-rs/doc-push) that is still ongoing. I feel that when `async/await` lands it's going to become 10x more popular than it is now. We've been using `tokio` &amp; `actix-web` in a 15k [LOC project](https://www.schoolbench.com.au/) and it's been rock solid as it stands. I've also managed to write a couple of libraries that are futures based: * [mpart-async](https://github.com/cetra3/mpart-async/): Multipart/Form Data client for the async world * [tmq](https://github.com/cetra3/tmq): ZeroMQ bindings for Tokio
Yes, if you check the window under the first image in the article you linked you'll find the article on transgender pride flags. This is the one I'm referring to [https://upload.wikimedia.org/wikipedia/commons/b/b0/Transgender\_Pride\_flag.svg](https://upload.wikimedia.org/wikipedia/commons/b/b0/Transgender_Pride_flag.svg)
(moving comment from /r/embedded as I think this post is by the author) The multicore support is really interesting, as it is becoming common in embedded. You mentioned heterogeneous devices, like Cortex M4 + M0, can you use the extra M4 instructions or are you limited to the M0 instruction set only? When I have done this in C before, I have had to either compile everything for the M0, or generate two separate images, use strange linker tricks to allow them to share symbols etc, or just hardcode in addresses of shared memory regions.
Pretty sure /u/steveklabnik1 is working on this...after he recovers from Rust 2018, that is. :P
Does this work on Windows? I got this compiler error after running `cargo install dutree`: error[E0425]: cannot find value `mode` in this scope --&gt; C:\Users\harvey\.cargo\registry\src\github.com-1ecc6299db9ec823\dutree-0.2.9\src \lib.rs:494:16 | 494 | if mode &amp; 0o002 != 0 { // dir other writable | ^^^^ not found in this scope
Maybe! Depends on what /u/KrocCamen means, exactly...
I don't think there's a way to get that to work, unfortunately. I will probably implement something like [this](https://www.reddit.com/r/rust/comments/a7n5hb/enum_dispatch_speed_up_your_dynamic_dispatched/ec4txus/) fairly soon, such that you could have it work seamlessly between internal and external implementations, but the performance would only be improved for the internal ones. Essentially, this trick only works when the types are known at the crate's compile-time, so that it can optimize calls specifically for those types. If your crate is a dependency of another crate with external types, it will have to be compiled first, so there's no way it could know about the external types.
Omg how could i not think about that! You just fix [my biggest problem with Rust](https://users.rust-lang.org/t/trait-or-enum-for-sum-types/23310) Note that your solution not only make it faster, it also helps removing all the downside of traits (object safety, etc.)
A few weeks back I presented at my local Rust Meetup. Here are my annotated slides. The talk is a brief overview of 3 parser crates that I tested out when getting started on a larger parsing project. It is not comprehensive by any means but I thought it might be useful to others. As always your feedback is appreciated! As a side note, I built the [`mdbook-presentation-preprocessor`](https://crates.io/crates/mdbook-presentation-preprocessor) crate to allow me to write this as a stand alone resource and as slide for my presentation.
Futures lack of documentation or examples covering features
&gt; generate two separate images, use strange linker tricks to allow them to share symbols This is the approach I'm currently using. I have a Cargo subcommand (`cargo-amp`, shown in [this tweet](https://mobile.twitter.com/japaricious/status/1071116410166935553)) that does the multiple compile and link step and then verifies that the layout of the shared variables are the same on both images. The implementation details about shared variables (like linker section names) are hidden behind attributes (like `#[shared]`, see linked tweet). &gt; can you use the extra M4 instructions or are you limited to the M0 instruction set only? I have not tested with heterogeneous devices yet but since you produce two images you can compile one for M4F and the other for M0+ thus you can use the respective full instruction set on both cores. I don't foresee any problem but won't know for sure until I sit down and try this out.
Those platform APIs are available to wasm as well, currently using a JS shim but in the long term without any shimming at all. It's not the case that wasm has to build *everything* from the ground up.
I wasn't thinking of crates being able to 'dynamically' expand on the set of options (thus requiring a `Box&lt;dyn MyBehavior&gt;` variant, although that would indeed be handy) -- just simply having crate A define `trait MyBehavior`, and crate B define `enum MyBehaviorEnum`. I suppose I should just try it; so lazy! e.g. with the simplistic macro I use today, crate 'B' does [this](https://github.com/m2amedia/scte35dump/blob/master/src/mpegts.rs#L80-L87). (This does basically mean that the 'bin' crate defining the application kinda needs to define the enum, since only the end-app statically knows the complete set of types it requires.)
This would be _very_ good if a team member is aware -- it's one of those intractable problems that you need some visionary to lead the way on; "documentation isn't good" is not a bike-sheddable problem. What I'd like to see is doc-comments for the overall impl block, e.g. ```rust /// Turning the crank on the AST will spit out AST Nodes. Do this when you want to... impl Iterator for AST { /// Get the next Node from the AST. fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { } ``` I.e., be able to separate *why* an Impl is provided, verses the dry description of the Impl methods (which may be more than one). Often-times with Cargo Doc you're presented with a great big wall of Impls with nothing to say what's important (and intended) for using a library, and the descriptions for the Impl methods are only describing the action of those methods, not why your Struct is even &lt;insert name of Impl here&gt; in the first place.
Nope, it does not currently work on windows https://github.com/nachoparker/dutree/blob/970323dcf7f851351bbaf42ffca163d3e87e0ce1/src/lib.rs#L489
kind of. I guess it is impossible to get this done way better, or in other words: my solution is good enough (tm) ;)
This was the approach that I thought would most likely be suitable (but I haven't had the chance to actually test it out). Will give it a shot and report back. &amp;#x200B; The enum variant would be nice, but the problem is there's no guarantee at the Enum level that every variant will have a given field (even if they all do) and we'd then have to pattern match every type to pull out the common field.
Amazing, thanks for the details, nice to see a good abstraction over the linker details.
Ah, I see what you mean now. &amp;#x200B; \`enum\_dispatch\` needs access to both the trait definition and the enum definition to expand the implementations at compile time. While it doesn't actually \*need\* to do any expansion on either the trait or enum (the impl blocks could be completely separate from both), it does need to be able to read the definitions of both, and there's no way I've found to read the syntax from another crate using a procedural macro. Do shoot me a message if you find a way though, and I can give it a shot!
I don't think we can afford to maintain separate documentation for users and developers. In my opinion, the current documentation serves the needs of both pretty well, at least as a developer starting point. For me the biggest pain point in this area is that `cargo-doc` doesn't document the internals of binary crates automatically (needs a magic flag) or perfectly (makes choices about what to include more suitable for libraries). I've filed and responded on some issues related to this.
Haha, I think those same reasons pushed me towards this solution, although I ended up losing track of them once I realized how much faster it was. Glad to see it is useful for you!
I'm actually also working on a GB emulator in rust. You're a little ahead of me, but if you need someone to bounce ideas off of, let me know! (I'm not ready to put my code up on github yet.)
&gt; **Our engineers have been alerted about this error.** &gt; &gt;Please be patient, we'll send a fix soon 
What I mean is that if you're looking at a crate for an explanation of "how does this work" and not "how do I use this library's API" then you're probably looking at _code_, not rendered documentation. Which is the purpose of having non-documentation comments. 
So, I updated rubber\_duck to work on stable. It required working around a limitation I couldn't figure out - namely, I wanted to parse a function call that wasn't really a function call, and it was giving me quite a bit of grieve because of parentheses. So that's why the stable syntax uses curly braces instead of parentheses for the function call. I'd love any suggestions on how to make it usable with parentheses.
Want font did you use? &amp;#x200B; I assume you printed it first ;)
[https://github.com/tonsky/FiraCode](https://github.com/tonsky/FiraCode)
What about `&lt;I, F&gt;(...) where I: Into&lt;F&gt;, F: Future`?
It'll never be able to resolve `F`. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8e8b855c61e6f41586e1854233e6a70a
Okay that's actually really cool
Best way of getting user input in a loop? If i want to display something on the screen in a loop, and check if a user typed a command, what is the best way of doing this, without blocking the display loop?
I'll try this here.. Any recommendations on multi-dimensional HashMaps? Is this a thing. I want to do this. ```rust let map : HashMap&lt;String,String,String&gt; = HashMap::new(); map.insert("parameter1","parameter2","value"); ``` This way I can check if something exists for the matching 2 parameters, like. ```rust if let Some(value) = map.get("linux","1.0.2") { // here I get the matching value if it exists. } ``` I'm wanting to scrap a repository, and get all the releases for that repository in a map. I can easily parse the releases to sort them by platform + version, but the problem is I want a single object to store all that stuff in (a 3DHashMap?) and then I can query entries by platform &amp; version. Seems like a database but is there such an object? Would it be easier to make a struct of items and then just put them in a Vec&lt;Struct&gt; and then have a function give a result if it exists ```rust // sorta real / sorta pseudo... fn get_matching_release(platform : &amp;str,version : &amp;str) -&gt; Option&lt;&amp;str&gt; { for release in releases { if release.platform = platform &amp;&amp; release.version == version { return Some(release.link); } } None } ``` Thanks, wondering how some of you would approach this problem.
lol author here, it was about time somebody told me that! corrected
interesting, I'll write the suggestion on github thanks :)
I just read someone elses question here and thought maybe I could use a Turple? Need to think if that makes sense. ```rust HashMap&lt;(String,String),String&gt; ```
I am not simply talking about browser API's, I'm talking about language-level constructs and api's. Alloc implementations are just one example of what's often required.
row&gt;=columns &amp;#x200B; Originally that was true, but then I realized I could just simulate a symmetric matrix by flipping them what the condition isn't true. &amp;#x200B; Also, why artificially limit the size to 5792x5792 That is a limitation of the BitSet implementation I am using. It correspond to the maximum amount of values it can store. Its still pretty big :D
Depending in how is your data, a relational (table) view could work very well and make it easier to manipulate and layout data. A full tree with unbound nesting will requiere what you ask, but if you can see it in JSON with minimal (and well know) deep then turn that into several tables probably will make thing easier. Can you give a sample in how is the actual data?
As long as `structview` isn't any *slower* than using `byteorder` directly, it seems like a win to me.
Use case: read in the struct, modify some fields, write out the struct, don't bother converting and un-converting fields that aren't touched.
Just a very quick addition. The long-term plans for Aardwolf are to integrate with the other Federated projects like PeerTube for video, and PixelFed for image sharing :) That way we are not having to re-invent what they've already done. I am actually friend with both of developers on Mastodon. 
First off, Thank you for the suggestions! I will make them known to the rest of the team, probably post a GitHub discussion. Long response, Diaspora, does indeed have a substantial user base, but I am pretty sure that it is comprised mostly of folks that didn't or weren't going to use Facebook anyways. So really the issue is more than no one they know uses it. Having used it recently (and a long time ago) I feel like the interface is incredibly Non-Intuitive. Especially for folks coming from Facebook. I am designing the interface so that it is familiar to to Facebook with some elements being borrowed from Mastodon. Hopefully that will help anyone that wants to transition :) &amp;#x200B; &amp;#x200B;
There's also https://crates.io/crates/typed-builder It isn't as polished, but it checks at compile time for missing arguments instead of returning an error.
Thank you.
This is really cool, thanks for sharing. I've been using [pom](https://github.com/J-F-Liu/pom) as a lexer while working through the [interpreter book](https://interpreterbook.com/). The relevant file in my repo is linked below if you want to take a look. https://github.com/JoshMcguigan/monkey/blob/master/src/lexer/mod.rs 
Looking at this, why not just use \`MyStruct { x: 123, y: 345, .. MyStruct::default() }\`?
You can't always implement Default, or you want the fields to be private.
I wish the compiler was smart enough to put the match out of a loop. So far I have never seen that happen.
I think your crate page is missing the Github link.